URL: http://avalon.cs.ucdavis.edu/gfink/papers/diss.ps
Refering-URL: http://avalon.cs.ucdavis.edu/gfink/research.html
Root-URL: http://www.cs.ucdavis.edu
Title: Discovering Security and Safety Flaws using Property-Based Testing  
Author: by GEORGE CLIVE FINK DAVIS 
Degree: M.S. (University of California, Davis) 1992 DISSERTATION Submitted in partial satisfaction of the requirements for the degree of DOCTOR OF PHILOSOPHY in Computer Science in the  Approved: Chair Committee in Charge  
Date: 1988  1996  
Address: Wisconsin, Madison)  
Affiliation: B.A. (University of  OFFICE OF GRADUATE STUDIES of the UNIVERSITY OF CALIFORNIA  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison/Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: The extent to which static analysis can reduce alternatives statically reduces the number of test executions required to examine the remainder. Static analysis is also used in other programming language analysis contexts, such as compilers <ref> [19, 1] </ref>. In general, compilers have weaker requirements than formal software testing tools. Compilers can, in most cases, function with only local data-flow analysis. The information needed for code scheduling and register allocation can be calculated locally. For precise testing results, it is necessary to thoroughly analyze global data-flow relationships. <p> This time, pre-condition (4) does match, with the variable bindings: variable pwd1 name pwd2 uid binding o1tAXz9qdbutk gfink o1tAXz9qdbutk 287 105 main (argc,argv) int argc; char **argv; - char name [30]; char password [30]; struct passwd *pwd; for (;;) - if (argc &gt; 1) - strcpy (name, argv <ref> [1] </ref>); argc = 1; else do - write (1, "login: ", 7); n = read (0, name, 30); while (n &lt; 2); name [n - 1] = 0; - if ((pwd = getpwnam (name)) == NULL) bad++; if (bad || strlen (pwd-&gt;pw_passwd) != 0) - write (1, "Password: ", 10); n <p> == 0 ) strcpy ( ttyname , "tty0" ) ; else - strcpy ( ttyname , "tty?" ) ; ttyname [ 3 ] = '0' + ttynr ; - for ( ; ; ) bad = 0 ; if ( argc &gt; 1 ) - strcpy ( name , argv <ref> [ 1 ] </ref> ) ; argc = 1 ; else - - write ( 1 , "login: " , 7 ) ; n = read ( 0 , name , 30 ) ; while ( n &lt; 2 ) ; name [ n - 1 ] = 0 ; - if <p> ( ttyname , "tty0" ) ; else - strcpy ( ttyname , "tty?" ) ; ttyname [ 3 ] = '0' + ttynr ; - -TADFC (717);for ( ; ; ) - - -TADFC (442);bad = 0;- ; if ( argc &gt; 1 ) - strcpy ( name , argv <ref> [ 1 ] </ref> ) ; argc = 1 ; else - - 147 write ( 1 , "login: " , 7 ) ; n = read ( 0 , name , 30 ) ; while ( n &lt; 2 ) ; name [ n - 1 ] = 0 ; -
Reference: [2] <author> Derek Andrews and Darrel Ince. </author> <title> Practical Formal Methods with VDM. </title> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: Specification languages such as Z [13] and VDM <ref> [2] </ref> can be used to fully specify a system at a level more abstract than source code. Data structures and operations can be gradually made more concrete through refinements to the specification, until at some point the boundary between specification and source code is crossed.
Reference: [3] <author> Thomas Ball and Susan Horwitz. </author> <title> Slicing programs with arbitrary control flow. In Automated and Algorithmic Debugging, </title> <booktitle> First International Workshop '93 Proceedings, </booktitle> <pages> pages 206-222, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. Slicing has additional applications to maintenance [20]. Other slicing work is described in <ref> [42, 43, 3, 15, 63] </ref>. Slicing is an active area of research and development. For automatic parallelization, output variables in a program are identified, and slices are computed for each output variable. Each slice can be executed separately. <p> This information is directly available from the edges of the data-flow graph. Data-flow graphs are typically computed with control flow graphs (CFG) and program dependence graphs <ref> [3, 20, 36, 43, 51, 52, 63] </ref>. CFG-based algorithms produce a program-independent CFG before propagating definitions. Static analysis in the Tester's Assistant is novel primarily because def-use edges are generated by propagating definitions through the structure of the program, without producing an explicit CFG. <p> The concept of basing static analysis on fine-grained representation of the program rather than a statement-based or CFG-based representation was developed in parallel with [15]. The algorithm for analyzing unstructured control constructs was developed in parallel with <ref> [3] </ref>. The algorithm of [43] is used to analyze recursive functions. Personal experience suggests that most static analysis techniques are similar to each other, but no benchmarks exist for comparing static analysis algorithms [28]. This chapter describes data-flow analysis and the specific algorithm used in the Tester's Assistant. <p> When a goto is involved, it is very hard for usage of a value in an expression to be associated with the possible assignments which may have produced the value. <ref> [3] </ref> These problems make accurate static analysis of C programs difficult, even for those programs for which it is possible to complete static analysis. Thus, it is necessary to make some approximations and reduce the accuracy or thoroughness of the analysis in order to increase the tractability of the problem. <p> & args ) &lt; 0 ) exit ( 1 ) ; fstat ( 0 , & statbuf ) ; ttynr = statbuf . st_rdev & 255 ; if ( ttynr == 0 ) strcpy ( ttyname , "tty0" ) ; else - strcpy ( ttyname , "tty?" ) ; ttyname <ref> [ 3 ] </ref> = '0' + ttynr ; - for ( ; ; ) bad = 0 ; if ( argc &gt; 1 ) - strcpy ( name , argv [ 1 ] ) ; argc = 1 ; else - - write ( 1 , "login: " , 7 ) <p> & args ) &lt; 0 ) exit ( 1 ) ; fstat ( 0 , & statbuf ) ; ttynr = statbuf . st_rdev & 255 ; if ( ttynr == 0 ) strcpy ( ttyname , "tty0" ) ; else - strcpy ( ttyname , "tty?" ) ; ttyname <ref> [ 3 ] </ref> = '0' + ttynr ; - -TADFC (717);for ( ; ; ) - - -TADFC (442);bad = 0;- ; if ( argc &gt; 1 ) - strcpy ( name , argv [ 1 ] ) ; argc = 1 ; else - - 147 write ( 1 ,
Reference: [4] <author> Thomas J. Ball and James R. Larus. </author> <title> Optimally profiling and tracing programs. </title> <type> Technical Report CS-TR-91-1031, </type> <institution> University of Wisconsin, Madison, </institution> <year> 1991. </year>
Reference-contexts: This method of instrumentation does not affect the normal semantics of the program unless the program is ill-behaved, although it will affect the timing properties of the program. If the timing properties of the program are important, then the probe effect introduced by this instrumentation will interfere. Results elsewhere <ref> [4, 66] </ref> indicate that it is possible to remove the probe effect in most situations by minimizing the number of probes and intelligently placing the probes in places such as NOP instructions following branch instructions. 112 Chapter 8 The Tester's Assistant The current implementation of the Tester's Assistant includes a static
Reference: [5] <author> Robert S. Boyer, Bernard Elspas, and Karl N. Levitt. </author> <title> Select a formal system for testing and debugging programs by symbolic execution. </title> <booktitle> In Proceedings of the International Conference on Reliable Software, </booktitle> <pages> pages 234-245, </pages> <year> 1975. </year>
Reference-contexts: This dissertation assumes that some method exits to derive test data based upon the analysis. In the worst case, this role can be taken by the human tester. The technique proposed as an extension to the property-based testing to address this need is symbolic execution <ref> [5] </ref> as by Demillo [11] and Korel [35]. 1.3 Main ideas The main idea and result of this dissertation is property-based testing. Specific ideas and results are: 1. <p> The path coverage metrics reveal program paths and sub-paths which have not been executed for any data in the test suite. The assumption made so far is that some mechanism exists for finding test data for these paths. Symbolic evaluation <ref> [5] </ref> has shown promise in addressing gaps in coverage [11, 35]. * TASPEC specifications are very detailed; the language is designed for the specific correlation between events and code, and matching these with automatic testing methods. Specifying high-level abstract constructs is possible in TASPEC.
Reference: [6] <institution> CERT advisory CA-88:01.ftpd.hole. </institution>
Reference-contexts: In order for rdist to maintain files owned by many users, rdist is run with root permissions, so it can perform any file operation (such as changing ownership and protection attributes). The slave portion of some versions of rdist has a race condition flaw <ref> [6] </ref>. The target file is copied into a temporary file and only when the file is completely written is it changed to its correct location and correct ownership.
Reference: [7] <institution> CERT advisory CA-91:20.rdist.vulnerability. </institution>
Reference-contexts: In the version of ftpd released with Sun Unix 3.2, a security flaw allows any user to gain permissions to read or write files owned by any user on the system (including 11 root) <ref> [7] </ref>. To do so, the user logs on with his or her normal user name and password. As a part of the correct authentication, a flag in the program is set. The flag records whether the user name has been authenticated.
Reference: [8] <author> Juei Chang, Debra J. Richardson, and Sriram Sankar. </author> <title> Structural specification-based testing with ADL. </title> <note> Submitted to ISSTA 1996 as a Regular Paper. </note>
Reference-contexts: Finally, if there are any specifications of ftpd, the specifications can be used to generate test data. Generating test data from specifications is not specifically part of property-based testing, but other testing methodologies contain the necessary algorithms <ref> [8, 12, 55] </ref>. The first method is simplest, because no extra work is required and the test suite is likely to be fairly complete. However in this case, the test cases aren't available, so the human tester creates some test cases by reading the ftpd manual page. <p> The goals behind using specifications in testing are establishing greater formalism for test results, and increasing the automatability and re-usability of test objects. Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data <ref> [57, 8] </ref>, specifications to create test oracles [18, 17, 53] (verifying the correctness of an execution), and specifications refined into code [26, 16, 33, 14] (and therefore having direct measurable specification-code relationships). <p> Test data can also be generated from specifications. ADL [56, 57] and TAOS have test description languages by which test data can be partitioned. Once the input domain is partitioned, generating exhaustive test data with respect to the structure of the specification is possible <ref> [55, 8] </ref>. Prior to this work, similar techniques had been used with VDM [12]. Related work generates test data from the structure of code such as in [21] and [29]. Using location specifiers, generic program-independent properties in TASPEC map automatically to source code. <p> ] ; - char name [ 30 ] ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; 138 struct stat statbuf ; char * bp , * argx <ref> [ 8 ] </ref> ; char * sh = "/bin/sh" ; char * sh2 = "/usr/bin/sh" ; if ( ioctl ( 0 , ( 1073741824 | ( ( sizeof ( struct sgttyb ) & 255 ) &lt;< 16 ) | ( 't' &lt;< 8 ) | 8 ) , & args ) <p> [ ] ; - char name [ 30 ] ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; struct stat statbuf ; char * bp , * argx <ref> [ 8 ] </ref> ; char * sh = "/bin/sh" ; char * sh2 = "/usr/bin/sh" ; if ( ioctl ( 0 , ( 1073741824 | ( ( sizeof ( struct sgttyb ) & 255 ) &lt;< 16 ) | ( 't' &lt;< 8 ) | 8 ) , & args )
Reference: [9] <author> Lori A. Clarke, Andy Podgurski, Debra J. Richardson, and Steven J. Zeil. </author> <title> A formal evaluation of data flow path selection criteria. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(11) </volume> <pages> 1318-1331, </pages> <month> November </month> <year> 1989. </year> <month> 160 </month>
Reference-contexts: Because they are processing program slices, and not the whole program, testing and analysis algorithms with higher time bounds become practical to use. For example, path-based test coverage 2 metrics are typically viewed as too expensive for practical use <ref> [9] </ref>. A new path-based coverage metric, iterative contexts, efficiently captures the sliced-based computations in the program. Testing and validation of large programs is not feasible if major portions of the test process are not automated. <p> A test suite is a set of test cases for a program. The completeness of a test suite is measured by a new code coverage metric, iterative contexts, which is stronger (i.e., detects more flaws) than previously-proposed practical code coverage metrics <ref> [39, 49, 9] </ref>. An iterative context is a sequence of assignments defining a sub-path of a possible program execution. The assignments are taken from the program slice and represent a possible computation of a value important to the target property. <p> Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on <ref> [25, 39, 9, 49, 27, 65] </ref>. This dependence, called a data-flow dependence, captures the flow of information in a program. Static analysis typically requires the calculation of all possible data-flow dependences. <p> Program analysis algorithms such as data-flow coverage tend to be at least exponential in running time <ref> [9] </ref> (if not uncomputable in the general case). No testing methodology can hope to scale to large software systems (or even to medium-sized programs such as Unix system code) using such algorithms, unless the scope is sharply limited. <p> One version of def-use coverage might require d and u to be executed in the same run of the program. Def-use pairs are used in many metrics <ref> [65, 9, 39] </ref>, and in one public domain coverage analyzer [27]. An alternate model for coverage, not utilized in the Tester's Assistant, is mutation testing [11]. Mutation testing distinguishes between the the program and closely related programs, each related program differing in only one small way from the original.
Reference: [10] <author> W. F. Clocksin and C. S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> 4th edition, </address> <year> 1994. </year>
Reference-contexts: TASPEC has an event-driven framework; events in the execution of a program drive instantiation of TASPEC objects. TASPEC constraints are compared with the TASPEC run-time state with Prolog-like inference <ref> [10] </ref>. TASPEC can express close correspondences between code and abstract semantics, which enables their translation into execution monitors and slicing criteria. TASPEC includes basic logical and temporal operators, as well as location specifiers that associate events with code features. <p> In the Tester's Assistant, programs are assumed to be well-behaved in order to simplify static analysis. Other 62 b = &a; printf (a); int f (int *i,int *j) *i = 1; printf (*j) g int a <ref> [10] </ref>; i++) (a) (b) (c) (a) pointer variable b points to a, so an assignment to *b affects the printf. (b) The behavior of the function f is changed when it is called with its two arguments aliased to each other. (c) This code fragment is not well-behaved because a is
Reference: [11] <author> Richard A. DeMillo and A. Jefferson Offutt. </author> <title> Constraint-based automatic test data generation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(9) </volume> <pages> 900-910, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: This dissertation assumes that some method exits to derive test data based upon the analysis. In the worst case, this role can be taken by the human tester. The technique proposed as an extension to the property-based testing to address this need is symbolic execution [5] as by Demillo <ref> [11] </ref> and Korel [35]. 1.3 Main ideas The main idea and result of this dissertation is property-based testing. Specific ideas and results are: 1. Property-based testing uses the specification of properties to define validation goals, and structural analysis and testing of programs to assess the fulfillment of those goals. <p> Future versions of the Tester's Assistant may be able to automate some of the steps in generating test data for gaps in coverage using techniques based upon symbolic execution <ref> [11] </ref>. 16 2.8 Correctness evaluation During each test execution, a file is written recording the TASPEC primitives activated during the test. The TASPEC evaluation engine processes this data and compares it with the property specification. <p> Def-use pairs are used in many metrics [65, 9, 39], and in one public domain coverage analyzer [27]. An alternate model for coverage, not utilized in the Tester's Assistant, is mutation testing <ref> [11] </ref>. Mutation testing distinguishes between the the program and closely related programs, each related program differing in only one small way from the original. The measure of completeness is the number of distinct, but related programs covered by the test suite. <p> The path coverage metrics reveal program paths and sub-paths which have not been executed for any data in the test suite. The assumption made so far is that some mechanism exists for finding test data for these paths. Symbolic evaluation [5] has shown promise in addressing gaps in coverage <ref> [11, 35] </ref>. * TASPEC specifications are very detailed; the language is designed for the specific correlation between events and code, and matching these with automatic testing methods. Specifying high-level abstract constructs is possible in TASPEC.
Reference: [12] <author> Jeremy Dick and Alain Faivre. </author> <title> Automating the Generation and Sequencing of Test Cases from Model-Based Specifications, </title> <booktitle> chapter 4, </booktitle> <pages> pages 268-284. </pages> <booktitle> First International Symposium of Formal Methods Europe Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Finally, if there are any specifications of ftpd, the specifications can be used to generate test data. Generating test data from specifications is not specifically part of property-based testing, but other testing methodologies contain the necessary algorithms <ref> [8, 12, 55] </ref>. The first method is simplest, because no extra work is required and the test suite is likely to be fairly complete. However in this case, the test cases aren't available, so the human tester creates some test cases by reading the ftpd manual page. <p> ADL [56, 57] and TAOS have test description languages by which test data can be partitioned. Once the input domain is partitioned, generating exhaustive test data with respect to the structure of the specification is possible [55, 8]. Prior to this work, similar techniques had been used with VDM <ref> [12] </ref>. Related work generates test data from the structure of code such as in [21] and [29]. Using location specifiers, generic program-independent properties in TASPEC map automatically to source code. Therefore, test oracles can be generated independently of descriptions of specific modules or functions.
Reference: [13] <author> Antoni Diller. </author> <title> Z: An Introduction to Formal Methods. </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: For example, specifications written in English can be easy to read and understand, but ambiguity and lack of formality make it difficult to systematically map English specifications to software systems. Diagrams such as flow-charts are graphical ways to express specifications. Specifications in formal languages such as Z <ref> [13, 61, 67] </ref> are easier to systematically (but not automatically) relate to computer programs, and can be used with formal reasoning tools, but can be harder to produce and understand. The basis of property-based testing is specification of properties. The property specification drives testing in an automated fashion. <p> Specification languages such as Z <ref> [13] </ref> and VDM [2] can be used to fully specify a system at a level more abstract than source code. Data structures and operations can be gradually made more concrete through refinements to the specification, until at some point the boundary between specification and source code is crossed.
Reference: [14] <author> Michael Edwards and David Bergstein. </author> <title> A look at the current automated capabilities of traceability. </title> <booktitle> In Proceedings of the IEEE Workshop on Real Time Applications, </booktitle> <pages> pages 204-206, </pages> <year> 1993. </year>
Reference-contexts: Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data [57, 8], specifications to create test oracles [18, 17, 53] (verifying the correctness of an execution), and specifications refined into code <ref> [26, 16, 33, 14] </ref> (and therefore having direct measurable specification-code relationships). Specification languages such as Z [13] and VDM [2] can be used to fully specify a system at a level more abstract than source code.
Reference: [15] <author> Michael D. Ernst. </author> <title> Practical fine-grained static slicing of optimized code. </title> <type> Technical Report MSR-TR-94-14, </type> <institution> Microsoft Research, </institution> <address> Redmond, WA, </address> <month> July 26, </month> <year> 1994. </year>
Reference-contexts: Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. Slicing has additional applications to maintenance [20]. Other slicing work is described in <ref> [42, 43, 3, 15, 63] </ref>. Slicing is an active area of research and development. For automatic parallelization, output variables in a program are identified, and slices are computed for each output variable. Each slice can be executed separately. <p> Portions of Tester's Assistant static analysis algorithms are similar to, or are derived from, related work. The concept of basing static analysis on fine-grained representation of the program rather than a statement-based or CFG-based representation was developed in parallel with <ref> [15] </ref>. The algorithm for analyzing unstructured control constructs was developed in parallel with [3]. The algorithm of [43] is used to analyze recursive functions. Personal experience suggests that most static analysis techniques are similar to each other, but no benchmarks exist for comparing static analysis algorithms [28].
Reference: [16] <author> George Fink, Michael Helmke, Matt Bishop, and Karl Levitt. </author> <title> An interface language between specifications and testing. </title> <type> Technical Report CSE-95-15, </type> <institution> University of California, Davis, </institution> <year> 1995. </year>
Reference-contexts: Introduction This dissertation introduces a new framework for testing computer programs: property-based testing <ref> [18, 17, 16] </ref>. Property-based testing is a testing process, driven by a specification of a property, that validates a given program for that property. A validation is an assurance that the property holds during any possible execution of the program. <p> Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data [57, 8], specifications to create test oracles [18, 17, 53] (verifying the correctness of an execution), and specifications refined into code <ref> [26, 16, 33, 14] </ref> (and therefore having direct measurable specification-code relationships). Specification languages such as Z [13] and VDM [2] can be used to fully specify a system at a level more abstract than source code. <p> 80 ) ; write ( 1 , buf , len ) ; - close ( fd ) ; - int main ( argc , argv ) int argc ; char * argv [ ] ; - char name [ 30 ] ; char password [ 30 ] ; char ttyname <ref> [ 16 ] </ref> ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; 138 struct stat statbuf ; char * bp , * argx [ 8 ] ; char * sh = "/bin/sh" ; char * sh2 = "/usr/bin/sh" ; if ( <p> chown Slice #0 : (Backward slice for function call chown slice formatted) Slice size: 62 nodes int time_out ; int main ( argc , argv ) int argc ; char * argv [ ] ; - char name [ 30 ] ; char password [ 30 ] ; char ttyname <ref> [ 16 ] </ref> ; int bad , n , ttynr , ap ; struct passwd * pwd ; for ( ; ; ) bad = 0 ; if ( ( pwd = getpwnam ( name ) ) == ( struct passwd * ) 0 ) bad ++ ; if ( bad <p> 0 and 1 (slice)==&gt;union 0 1 Slice #3 is the union of slices 0 and 1 int time_out ; int main ( argc , argv ) int argc ; char * argv [ ] ; - char name [ 30 ] ; char password [ 30 ] ; char ttyname <ref> [ 16 ] </ref> ; int bad , n , ttynr , ap ; 143 struct passwd * pwd ; for ( ; ; ) bad = 0 ; if ( ( pwd = getpwnam ( name ) ) == ( struct passwd * ) 0 ) bad ++ ; if ( <p> 80 ) ; write ( 1 , buf , len ) ; - close ( fd ) ; - int main ( argc , argv ) int argc ; char * argv [ ] ; - char name [ 30 ] ; char password [ 30 ] ; char ttyname <ref> [ 16 ] </ref> ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; struct stat statbuf ; char * bp , * argx [ 8 ] ; char * sh = "/bin/sh" ; char * sh2 = "/usr/bin/sh" ; if ( ioctl
Reference: [17] <author> George Fink, Calvin Ko, Myla Archer, and Karl Levitt. </author> <title> Towards a property-based testing environment with applications to security-critical software. </title> <booktitle> In Proceedings of the 4th Irvine Software Symposium, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: Introduction This dissertation introduces a new framework for testing computer programs: property-based testing <ref> [18, 17, 16] </ref>. Property-based testing is a testing process, driven by a specification of a property, that validates a given program for that property. A validation is an assurance that the property holds during any possible execution of the program. <p> The goals behind using specifications in testing are establishing greater formalism for test results, and increasing the automatability and re-usability of test objects. Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data [57, 8], specifications to create test oracles <ref> [18, 17, 53] </ref> (verifying the correctness of an execution), and specifications refined into code [26, 16, 33, 14] (and therefore having direct measurable specification-code relationships). Specification languages such as Z [13] and VDM [2] can be used to fully specify a system at a level more abstract than source code.
Reference: [18] <author> George Fink and Karl Levitt. </author> <title> Property-based testing of privileged programs. </title> <booktitle> In Tenth Annual Computer Security Applications Conference, </booktitle> <pages> pages 154-163. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1994. </year>
Reference-contexts: Introduction This dissertation introduces a new framework for testing computer programs: property-based testing <ref> [18, 17, 16] </ref>. Property-based testing is a testing process, driven by a specification of a property, that validates a given program for that property. A validation is an assurance that the property holds during any possible execution of the program. <p> The goals behind using specifications in testing are establishing greater formalism for test results, and increasing the automatability and re-usability of test objects. Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data [57, 8], specifications to create test oracles <ref> [18, 17, 53] </ref> (verifying the correctness of an execution), and specifications refined into code [26, 16, 33, 14] (and therefore having direct measurable specification-code relationships). Specification languages such as Z [13] and VDM [2] can be used to fully specify a system at a level more abstract than source code.
Reference: [19] <author> Charles N. Fischer and Jr. Richard J. Lebanc. </author> <title> Crafting a Compiler. </title> <publisher> The Ben-jamin/Cummings Publishing Company, </publisher> <year> 1988. </year> <month> 161 </month>
Reference-contexts: The extent to which static analysis can reduce alternatives statically reduces the number of test executions required to examine the remainder. Static analysis is also used in other programming language analysis contexts, such as compilers <ref> [19, 1] </ref>. In general, compilers have weaker requirements than formal software testing tools. Compilers can, in most cases, function with only local data-flow analysis. The information needed for code scheduling and register allocation can be calculated locally. For precise testing results, it is necessary to thoroughly analyze global data-flow relationships.
Reference: [20] <author> Keith Brian Gallagher and James R. Lyle. </author> <title> Using program slicing in software maintenance. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(8) </volume> <pages> 751-761, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Section 5.4 gives more information about slice construction. An example of slicing is in Figure 3.1. A static slice with respect to the variable x parameter of the setuid function call is shown alongside full example function. 28 3.4.1 Uses of slicing Slicing is used in software maintenance <ref> [20, 41, 63] </ref>, automatic parallelization [64], and testing and debugging [64, 63, 37]. In software maintenance, it is useful to examine the side effects of a single change to the source code. <p> In software maintenance, it is useful to examine the side effects of a single change to the source code. Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. Slicing has additional applications to maintenance <ref> [20] </ref>. Other slicing work is described in [42, 43, 3, 15, 63]. Slicing is an active area of research and development. For automatic parallelization, output variables in a program are identified, and slices are computed for each output variable. Each slice can be executed separately. <p> This information is directly available from the edges of the data-flow graph. Data-flow graphs are typically computed with control flow graphs (CFG) and program dependence graphs <ref> [3, 20, 36, 43, 51, 52, 63] </ref>. CFG-based algorithms produce a program-independent CFG before propagating definitions. Static analysis in the Tester's Assistant is novel primarily because def-use edges are generated by propagating definitions through the structure of the program, without producing an explicit CFG.
Reference: [21] <author> John B. Goodenough and Susan L. Gerhart. </author> <title> Toward a theory of test data selection. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1(12):156-173, </volume> <month> June </month> <year> 1975. </year>
Reference-contexts: Once the input domain is partitioned, generating exhaustive test data with respect to the structure of the specification is possible [55, 8]. Prior to this work, similar techniques had been used with VDM [12]. Related work generates test data from the structure of code such as in <ref> [21] </ref> and [29]. Using location specifiers, generic program-independent properties in TASPEC map automatically to source code. Therefore, test oracles can be generated independently of descriptions of specific modules or functions.
Reference: [22] <author> R. W. Gray, V. P. Heuring, S. P. Levi, A. M. Sloane, and W. M. Waite. ELI: </author> <title> A complete, flexible compiler construction system. </title> <journal> In Communications of the ACM, </journal> <volume> volume 35, </volume> <pages> pages 121-131, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: The other edge types and most of the edges are created in a pre-processing step based upon a parse tree of the program. 5.3.1 Pre-processing The basics of pre-processing are presented in Figure 5.4. First, the ELI language translator toolkit <ref> [22] </ref> and the C language description which comes with the toolkit create a concrete syntax tree, which is abstracted to produce an abstract syntax tree (AST) that serves as the basis for semantic analysis. The AST has over 50 node types, and has almost 200 different rules associated with it. <p> This additional step of manually concatenating specifi cation and code (with separators) is another artifact of the current implementation; as the Tester's Assistant becomes a more polished tool, the specification selection mechanism will become more automated. 8.2 Internals of the Tester's Assistant The Tester's Assistant is implemented using the ELI <ref> [22] </ref> language translator toolkit. ELI provides scanning, parsing, and attribute grammar packages, as well 117 as additional utility packages, all unified with a standard interface. <p> Property-based testing is a step towards making validation results from testing approach the validation results attainable from verification. 131 Appendix A TASPEC Grammar The grammar is expressed in the con language, the ELI <ref> [22] </ref> language for expressing concrete grammars. In con, literals are enclosed in single quotes. Alternate phrases for the same non-terminal are separated by "/". <p> In the derivation, some non-terminals are merged or reduced. For example, the statement, statement list, and while statement non-terminals are replaced with the single Stmt non-terminal. The final abstract syntax is in ELI's lido language <ref> [22] </ref>.
Reference: [23] <editor> David Gries. </editor> <booktitle> The Science of Programmin. Texts and Monographs in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Verification (formal proof) of security properties has the advantage of a formalized model, but case studies of verification in have shown that programs which are not written with verification in mind are difficult if not impossible to verify <ref> [23] </ref>. Property-based testing, in addition to being a technique which can be utilized by relatively untrained users, has been designed with the understanding that third-party code would regularly be its subject. Third-party testing is possible because testing is based upon generic program-independent specifications.
Reference: [24] <author> John V. Guttag and James J. Horning. </author> <title> Larch: Langauges and Tools for Formal Specification. Texts and Monographs in Computer Science. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: However, generating test cases from such a specification is not very different from generating tests from the source code due to the shared derivation of code and specification. Test oracles can also be automatically generated from other specification languages such as Larch <ref> [24] </ref> and TAOS [54, 53]. Function and procedure behavior is specified as in the refinement methods, but in a separate process from the actual coding. The specifications can then serve as independent test oracles without being influenced by implementation bias. <p> Test oracles are automatically generated from TASPEC specifications, and there is potential for relationships between specifications and other aspects of testing such as coverage. TASPEC's approach in associating specifications with code is similar to that of Larch <ref> [24] </ref>, but the concept of a TASPEC location is more general than Larch's function-level specifications. Many established languages such as Larch and Z [61] have tools and methodologies to allow formal reasoning about specifications.
Reference: [25] <author> Richard Hamlet. </author> <title> Testing programs to detect malicious faults. </title> <booktitle> In Proceedings of the IFIP Working Conference on Dependable Computing, </booktitle> <pages> pages 162-169, </pages> <month> Febru-ary </month> <year> 1991. </year>
Reference-contexts: Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on <ref> [25, 39, 9, 49, 27, 65] </ref>. This dependence, called a data-flow dependence, captures the flow of information in a program. Static analysis typically requires the calculation of all possible data-flow dependences. <p> Chapter 6 describes a series of coverage metrics, and relates them to each other in terms of strength, building on work by Hamlet <ref> [25] </ref>; this description motivates iterative contexts. As a result of Hamlet's analysis, he identifies what he labels the "locksmith" problem. The locksmith problem involves two adversaries, a thief and a locksmith. The locksmith tries to design a lock which the thief cannot open. <p> Since complete statement coverage could be achieved by executing these two statements in different executions, statement coverage is insufficient to uncover the flaw. Hamlet <ref> [25] </ref> demonstrates this point effectively using a series of simple examples of flawed code. His examples demonstrate the need for a metric more powerful than statement or branch coverage. <p> Hamlet concedes that there is no solution to the cat-and-mouse game of stronger coverage measures and more obscure code (the locksmith game from Section 3.5 <ref> [25] </ref>), but has 86 proposed Laski's technique (see Section 6.4.1) as a partial solution. As we shall see, within certain parameters it is possible to produce bullet-proof coverage metrics, and it is also possible to quantify the error potential in these metrics.
Reference: [26] <author> Michael Helmke. </author> <title> A semi-formal approach to the validation of requirements traceability from Z to C. </title> <type> Master's thesis, </type> <institution> UC Davis, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data [57, 8], specifications to create test oracles [18, 17, 53] (verifying the correctness of an execution), and specifications refined into code <ref> [26, 16, 33, 14] </ref> (and therefore having direct measurable specification-code relationships). Specification languages such as Z [13] and VDM [2] can be used to fully specify a system at a level more abstract than source code. <p> Translations between other specification languages and TASPEC can provide additional flexibility to the specification and testing phases of development. Helmke shows how translations from Z to TASPEC can assist in requirements traceability <ref> [26] </ref>. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing [25, 36, 39, 9, 49, 15, 27, 45, 51, 65]. <p> However, more developed languages with higher-level constructs, such as Z, are the standard specification languages in industry. Therefore, it would be beneficial to translate the more widely-used specification languages to the TASPEC language so the specifications can be used in property-based testing. For concrete Z specifications, Helmke <ref> [26] </ref> has shown that semi-automatic translation from Z to TASPEC is possible. * Data-flow testing is not the only approach to program testing.
Reference: [27] <author> J.R. Horgan and S. </author> <title> London. Data flow coverage and the C language. </title> <booktitle> In Proceedings of the Second Symposium on Assessment of Quality Software Development Tools, </booktitle> <pages> pages 2-10, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on <ref> [25, 39, 9, 49, 27, 65] </ref>. This dependence, called a data-flow dependence, captures the flow of information in a program. Static analysis typically requires the calculation of all possible data-flow dependences. <p> One version of def-use coverage might require d and u to be executed in the same run of the program. Def-use pairs are used in many metrics [65, 9, 39], and in one public domain coverage analyzer <ref> [27] </ref>. An alternate model for coverage, not utilized in the Tester's Assistant, is mutation testing [11]. Mutation testing distinguishes between the the program and closely related programs, each related program differing in only one small way from the original.
Reference: [28] <author> Susan Horwitz. </author> <title> Private correspondence, </title> <year> 1995. </year>
Reference-contexts: The algorithm for analyzing unstructured control constructs was developed in parallel with [3]. The algorithm of [43] is used to analyze recursive functions. Personal experience suggests that most static analysis techniques are similar to each other, but no benchmarks exist for comparing static analysis algorithms <ref> [28] </ref>. This chapter describes data-flow analysis and the specific algorithm used in the Tester's Assistant. Section 5.1 is an overview of the issues and problems in constructing a global data-flow graph of a C program statically. Section 5.2 describes the exact structure of the graph.
Reference: [29] <author> William E. Howden. </author> <title> Methodology for the generation of program test data. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-24(5):554-559, </volume> <month> May </month> <year> 1975. </year> <month> 162 </month>
Reference-contexts: Once the input domain is partitioned, generating exhaustive test data with respect to the structure of the specification is possible [55, 8]. Prior to this work, similar techniques had been used with VDM [12]. Related work generates test data from the structure of code such as in [21] and <ref> [29] </ref>. Using location specifiers, generic program-independent properties in TASPEC map automatically to source code. Therefore, test oracles can be generated independently of descriptions of specific modules or functions.
Reference: [30] <author> William E. Howden. </author> <title> Validating programs without specifications. </title> <booktitle> In Proceedings of the ACM SIGSOFT '89 Third Symposium on Software Testing, Analysis, and Verification (TAV3), </booktitle> <pages> pages 2-9, </pages> <year> 1989. </year>
Reference-contexts: The suitability of test data to cover the input value, and thus context, then, is directly related to the spread of values desired in the slice criterion, i.e., setuid (). Analysis of the domain of possible input values is outside of the scope of the work presented here (see <ref> [30] </ref> for some approaches to this problem). The Tester's Assistant identifies whether the input-related context is covered (trivially) and leaves further testing of the input domain to the analyst (see page 82). <p> When the third audit event is processed, the predicate equal (o1tAXz9qdbutk; o1tAXz9qdbutk) is added to the database. This time, pre-condition (4) does match, with the variable bindings: variable pwd1 name pwd2 uid binding o1tAXz9qdbutk gfink o1tAXz9qdbutk 287 105 main (argc,argv) int argc; char **argv; - char name <ref> [30] </ref>; char password [30]; struct passwd *pwd; for (;;) - if (argc &gt; 1) - strcpy (name, argv [1]); argc = 1; else do - write (1, "login: ", 7); n = read (0, name, 30); while (n &lt; 2); name [n - 1] = 0; - if ((pwd = getpwnam <p> This time, pre-condition (4) does match, with the variable bindings: variable pwd1 name pwd2 uid binding o1tAXz9qdbutk gfink o1tAXz9qdbutk 287 105 main (argc,argv) int argc; char **argv; - char name <ref> [30] </ref>; char password [30]; struct passwd *pwd; for (;;) - if (argc &gt; 1) - strcpy (name, argv [1]); argc = 1; else do - write (1, "login: ", 7); n = read (0, name, 30); while (n &lt; 2); name [n - 1] = 0; - if ((pwd = getpwnam (name)) == NULL) <p> &gt; 0 ) - len = read ( fd , buf , 80 ) ; write ( 1 , buf , len ) ; - close ( fd ) ; - int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; 138 struct stat statbuf ; char * bp , * argx [ 8 ] ; char * <p> read ( fd , buf , 80 ) ; write ( 1 , buf , len ) ; - close ( fd ) ; - int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; 138 struct stat statbuf ; char * bp , * argx [ 8 ] ; char * sh = "/bin/sh" ; char * <p> Time_out ( ) - time_out = 1 ; - (prog) ==&gt;slice (slice)==&gt;func chown Slice #0 : (Backward slice for function call chown slice formatted) Slice size: 62 nodes int time_out ; int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct passwd * pwd ; for ( ; ; ) bad = 0 ; if ( ( pwd = getpwnam ( name ) ) == ( <p> 1 ; - (prog) ==&gt;slice (slice)==&gt;func chown Slice #0 : (Backward slice for function call chown slice formatted) Slice size: 62 nodes int time_out ; int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct passwd * pwd ; for ( ; ; ) bad = 0 ; if ( ( pwd = getpwnam ( name ) ) == ( struct passwd * ) 0 ) <p> function call setuid slice formatted) Slice #2 is the intersection of slices 0 and 1 (slice)==&gt;union 0 1 Slice #3 is the union of slices 0 and 1 int time_out ; int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; 143 struct passwd * pwd ; for ( ; ; ) bad = 0 ; if ( ( pwd = getpwnam ( name ) ) == <p> #2 is the intersection of slices 0 and 1 (slice)==&gt;union 0 1 Slice #3 is the union of slices 0 and 1 int time_out ; int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; 143 struct passwd * pwd ; for ( ; ; ) bad = 0 ; if ( ( pwd = getpwnam ( name ) ) == ( struct passwd * ) 0 <p> &gt; 0 ) - len = read ( fd , buf , 80 ) ; write ( 1 , buf , len ) ; - close ( fd ) ; - int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; struct stat statbuf ; char * bp , * argx [ 8 ] ; char * sh <p> read ( fd , buf , 80 ) ; write ( 1 , buf , len ) ; - close ( fd ) ; - int main ( argc , argv ) int argc ; char * argv [ ] ; - char name <ref> [ 30 ] </ref> ; char password [ 30 ] ; char ttyname [ 16 ] ; int bad , n , ttynr , ap ; struct sgttyb args ; struct passwd * pwd ; struct stat statbuf ; char * bp , * argx [ 8 ] ; char * sh = "/bin/sh" ; char * sh2
Reference: [31] <author> J. C. Huang. </author> <title> Program instrumentation and software testing. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 25-32, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: with multiple contexts in parallel is left to future work. 110 if (setuid (u)) - ... - #define node37 37 - int tv001,tv002; if ((tv001 = setuid (tv002 = u), TRACEEMIT (node37), tv001 == 1 ? EVENTEMIT (6,tv002) : 0, tv001)) - - 7.3 Instrumentation Instrumentation of the C code <ref> [31] </ref> produces the data for execution monitoring (primitive events and traces). Expressions containing pertinent node locations are altered to emit the monitoring information without changing their normal functionality. The Tester's Assistant emits C code as output, the instrumentation is expressed with the conditional expression construct and auxiliary variables.
Reference: [32] <institution> ISO standard ANSI/ISO 9899-1990. </institution>
Reference-contexts: ) ; exit ( 1 ) ; --; - void Time_out ( ) - time_out = 1 ; - (inst) ==&gt;quit % 149 Appendix C Abstract Syntax for C The abstract syntax for C used in the Tester's Assistant is derived from the ANSI C standard language definition (ANSI/ISO 9899-1990) <ref> [32] </ref>. In the derivation, some non-terminals are merged or reduced. For example, the statement, statement list, and while statement non-terminals are replaced with the single Stmt non-terminal. The final abstract syntax is in ELI's lido language [22].
Reference: [33] <author> Jurrgen Borstler and Thorsten Janning. </author> <title> Traceability between requirements and design: A transformational approach. </title> <booktitle> In 16th Annual International Computer Software and Applications Conference, </booktitle> <pages> pages 362-368. </pages> <publisher> IEEE, IEEE, </publisher> <year> 1992. </year>
Reference-contexts: Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data [57, 8], specifications to create test oracles [18, 17, 53] (verifying the correctness of an execution), and specifications refined into code <ref> [26, 16, 33, 14] </ref> (and therefore having direct measurable specification-code relationships). Specification languages such as Z [13] and VDM [2] can be used to fully specify a system at a level more abstract than source code.
Reference: [34] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice Hall Software Series. Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1978. </year>
Reference-contexts: Testing and validation of large programs is not feasible if major portions of the test process are not automated. This dissertation describes the Tester's Assistant, an implementation that automates some aspects of property-based testing for the C programming language <ref> [34] </ref>. As a demonstration, property-based testing and the Tester's Assistant are applied to several security-critical programs in Unix. 1.1 The goal of testing Testing computer programs is a critical part of the software development cycle.
Reference: [35] <author> Bogdan Korel. </author> <title> Automated software test data generation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(8) </volume> <pages> 870-879, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: In the worst case, this role can be taken by the human tester. The technique proposed as an extension to the property-based testing to address this need is symbolic execution [5] as by Demillo [11] and Korel <ref> [35] </ref>. 1.3 Main ideas The main idea and result of this dissertation is property-based testing. Specific ideas and results are: 1. Property-based testing uses the specification of properties to define validation goals, and structural analysis and testing of programs to assess the fulfillment of those goals. <p> The path coverage metrics reveal program paths and sub-paths which have not been executed for any data in the test suite. The assumption made so far is that some mechanism exists for finding test data for these paths. Symbolic evaluation [5] has shown promise in addressing gaps in coverage <ref> [11, 35] </ref>. * TASPEC specifications are very detailed; the language is designed for the specific correlation between events and code, and matching these with automatic testing methods. Specifying high-level abstract constructs is possible in TASPEC.
Reference: [36] <author> Bogdan Korel and Janusz Laski. </author> <title> STAD a system for testing and debugging: User perspective. </title> <booktitle> In Second Workshop on Software Testing, Verification, and Analysis, </booktitle> <year> 1988. </year>
Reference-contexts: Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Weiser tested these ideas with a slicer for a version of Fortran [64]. He also proposed that a slicer would be useful in debugging, by slicing when an error occurs to find possible faults in the program. STAD <ref> [36, 37] </ref> uses a related concept called a dynamic slice to debug programs. <p> This information is directly available from the edges of the data-flow graph. Data-flow graphs are typically computed with control flow graphs (CFG) and program dependence graphs <ref> [3, 20, 36, 43, 51, 52, 63] </ref>. CFG-based algorithms produce a program-independent CFG before propagating definitions. Static analysis in the Tester's Assistant is novel primarily because def-use edges are generated by propagating definitions through the structure of the program, without producing an explicit CFG. <p> The use- and live-contexts of Laski and Korel <ref> [36, 39] </ref> are similar in form to iterative contexts. Required k-Tuples by Ntafos [49] unrolls def-use chains by chaining together sequences of def-use-def links, and attaches "required elements" as predicates to be satisfied before the chain matches an execution. <p> Execution of the path corresponding to the second context results in the erroneous execution. 6.4.1 Use- and live-contexts The term context comes from the work of Laski and the STAD system <ref> [39, 36] </ref>. Use contexts are similar to iterative paths; at a program assignment, all possible combinations of definitions of variables used on the right hand side form a set of use contexts as a coverage metric.
Reference: [37] <author> Bogdan Korel and Janusz Laski. </author> <title> Dynamic slicing of computer programs. </title> <journal> Journal of Systems Software, </journal> <volume> 13 </volume> <pages> 187-195, </pages> <year> 1990. </year>
Reference-contexts: A static slice with respect to the variable x parameter of the setuid function call is shown alongside full example function. 28 3.4.1 Uses of slicing Slicing is used in software maintenance [20, 41, 63], automatic parallelization [64], and testing and debugging <ref> [64, 63, 37] </ref>. In software maintenance, it is useful to examine the side effects of a single change to the source code. Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. <p> Weiser tested these ideas with a slicer for a version of Fortran [64]. He also proposed that a slicer would be useful in debugging, by slicing when an error occurs to find possible faults in the program. STAD <ref> [36, 37] </ref> uses a related concept called a dynamic slice to debug programs.
Reference: [38] <author> Carl E. Landwehr, Alan R. Bull, John P. McDermott, and William S. Choi. </author> <title> A taxonomy of computer program security flaws, with examples. </title> <type> Technical Report NRL/FR/5542-93-9591, </type> <institution> Naval Research Laboratory, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: A successful test validates that properties are not violated; if these properties form the security policy for the system, then the system is secure. Property-based testing uses a security model of the system, as well as a library of generic flaws (such as <ref> [38, 60] </ref>) specified in TASPEC, to produce a test process, whereby the target program can be certified to be free of certain types of flaws. 3.2 Specifications Specifications are descriptions of software (or hardware) systems.
Reference: [39] <author> Janusz Laski. </author> <title> Data flow testing in STAD. </title> <journal> Journal of Systems Software, </journal> <volume> 12 </volume> <pages> 3-14, </pages> <year> 1990. </year>
Reference-contexts: A test suite is a set of test cases for a program. The completeness of a test suite is measured by a new code coverage metric, iterative contexts, which is stronger (i.e., detects more flaws) than previously-proposed practical code coverage metrics <ref> [39, 49, 9] </ref>. An iterative context is a sequence of assignments defining a sub-path of a possible program execution. The assignments are taken from the program slice and represent a possible computation of a value important to the target property. <p> Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on <ref> [25, 39, 9, 49, 27, 65] </ref>. This dependence, called a data-flow dependence, captures the flow of information in a program. Static analysis typically requires the calculation of all possible data-flow dependences. <p> One version of def-use coverage might require d and u to be executed in the same run of the program. Def-use pairs are used in many metrics <ref> [65, 9, 39] </ref>, and in one public domain coverage analyzer [27]. An alternate model for coverage, not utilized in the Tester's Assistant, is mutation testing [11]. Mutation testing distinguishes between the the program and closely related programs, each related program differing in only one small way from the original. <p> The use- and live-contexts of Laski and Korel <ref> [36, 39] </ref> are similar in form to iterative contexts. Required k-Tuples by Ntafos [49] unrolls def-use chains by chaining together sequences of def-use-def links, and attaches "required elements" as predicates to be satisfied before the chain matches an execution. <p> Execution of the path corresponding to the second context results in the erroneous execution. 6.4.1 Use- and live-contexts The term context comes from the work of Laski and the STAD system <ref> [39, 36] </ref>. Use contexts are similar to iterative paths; at a program assignment, all possible combinations of definitions of variables used on the right hand side form a set of use contexts as a coverage metric.
Reference: [40] <author> Janusz Laski. </author> <title> Path expression in data flow program testing. </title> <booktitle> In Proceedings of the Fourteenth Annual International Computer Software and Applications Conference, </booktitle> <pages> pages 570-576, </pages> <month> November </month> <year> 1990. </year> <month> 163 </month>
Reference-contexts: One benefit of such a calculus would be that coverage contexts could 128 be displayed in a more lucid fashion, enabling the human tester to more easily interpret and act on the results of the coverage metric <ref> [40] </ref>. * Techniques for initial test data generation have not been specified. This lack is not necessarily a weakness in property-based testing: initial data can be provided by the developers of the software.
Reference: [41] <author> Panas E. Livadas and Stephen Croll. </author> <title> The C-Ghinsu tool. </title> <type> Technical Report SERC-TR-55-F, </type> <institution> University of Florida, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Section 5.4 gives more information about slice construction. An example of slicing is in Figure 3.1. A static slice with respect to the variable x parameter of the setuid function call is shown alongside full example function. 28 3.4.1 Uses of slicing Slicing is used in software maintenance <ref> [20, 41, 63] </ref>, automatic parallelization [64], and testing and debugging [64, 63, 37]. In software maintenance, it is useful to examine the side effects of a single change to the source code. <p> This allows old slices to be re-created by referencing these lists. Then, more complex slices are constructed by combining slices in different ways. This process has been named "dicing" by Livadas <ref> [41] </ref>. Two basic operators, [ and ", union and intersection respectively, are provided to combine slices. These operators examine each node's slice list in turn to determine the complex slice. Another slice type is a "shadow" slice.
Reference: [42] <author> Panas E. Livadas and Stephen Croll. </author> <title> Static program slicing. </title> <type> Technical Report SERC-TR-55-F, </type> <institution> University of Florida, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Property specifications expressed in TASPEC are translated automatically into test oracles that check the correctness of program executions. Explicitly specified relationships between property specifications and source code allows static analysis to be focused on the specific code relevant to the specified property; this technique is called slicing <ref> [43, 42, 63, 64] </ref>. Because they are processing program slices, and not the whole program, testing and analysis algorithms with higher time bounds become practical to use. For example, path-based test coverage 2 metrics are typically viewed as too expensive for practical use [9]. <p> Then code related to the target property and all other code related to that code are targeted for testing. The process of finding a subset of the program which has identical behavior to the full program with respect to the property is called program slicing <ref> [43, 42, 63, 64] </ref>. The property specification is also translated automatically into a test oracle for the given program. A test oracle checks the validity of a single execution of the program by analyzing the intermediate and final states of the program for inconsistencies with property specifications. <p> Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. Slicing has additional applications to maintenance [20]. Other slicing work is described in <ref> [42, 43, 3, 15, 63] </ref>. Slicing is an active area of research and development. For automatic parallelization, output variables in a program are identified, and slices are computed for each output variable. Each slice can be executed separately.
Reference: [43] <author> Panas E. Livadas and Stephen Croll. </author> <title> Program slicing. </title> <type> Technical Report SERC-TR-61-F, </type> <institution> University of Florida, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Property specifications expressed in TASPEC are translated automatically into test oracles that check the correctness of program executions. Explicitly specified relationships between property specifications and source code allows static analysis to be focused on the specific code relevant to the specified property; this technique is called slicing <ref> [43, 42, 63, 64] </ref>. Because they are processing program slices, and not the whole program, testing and analysis algorithms with higher time bounds become practical to use. For example, path-based test coverage 2 metrics are typically viewed as too expensive for practical use [9]. <p> Then code related to the target property and all other code related to that code are targeted for testing. The process of finding a subset of the program which has identical behavior to the full program with respect to the property is called program slicing <ref> [43, 42, 63, 64] </ref>. The property specification is also translated automatically into a test oracle for the given program. A test oracle checks the validity of a single execution of the program by analyzing the intermediate and final states of the program for inconsistencies with property specifications. <p> Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. Slicing has additional applications to maintenance [20]. Other slicing work is described in <ref> [42, 43, 3, 15, 63] </ref>. Slicing is an active area of research and development. For automatic parallelization, output variables in a program are identified, and slices are computed for each output variable. Each slice can be executed separately. <p> This information is directly available from the edges of the data-flow graph. Data-flow graphs are typically computed with control flow graphs (CFG) and program dependence graphs <ref> [3, 20, 36, 43, 51, 52, 63] </ref>. CFG-based algorithms produce a program-independent CFG before propagating definitions. Static analysis in the Tester's Assistant is novel primarily because def-use edges are generated by propagating definitions through the structure of the program, without producing an explicit CFG. <p> The concept of basing static analysis on fine-grained representation of the program rather than a statement-based or CFG-based representation was developed in parallel with [15]. The algorithm for analyzing unstructured control constructs was developed in parallel with [3]. The algorithm of <ref> [43] </ref> is used to analyze recursive functions. Personal experience suggests that most static analysis techniques are similar to each other, but no benchmarks exist for comparing static analysis algorithms [28]. This chapter describes data-flow analysis and the specific algorithm used in the Tester's Assistant. <p> If there are cycles in the call graph, then the algorithm of Livadas <ref> [43] </ref> is used to resolve the circular dependencies. Briefly, Livadas' algorithm iterates through a list of mutually recursive functions propagating more and more reaching definitions until a complete pass through the list produces no new definition-use edges. This algorithm is guaranteed to terminate. <p> This algorithm is guaranteed to terminate. In each analysis pass, assignments are only added to live assignment node lists. A pass where no assignments are added terminates the algorithm, and such a pass is guaranteed because the number of assignments is finite. Therefore the algorithm terminates in all cases <ref> [43] </ref>. 5.3.3 Performance bounds The biggest expense incurred with static analysis is in the live assignment propagation algorithm.
Reference: [44] <author> R. W. Lo, K. N. Levitt, and R. A. Olsson. Mcf: </author> <title> A malicious code filter. </title> <journal> Computers & Security, </journal> <volume> 14(6) </volume> <pages> 541-566, </pages> <year> 1995. </year>
Reference-contexts: the printf. (b) The behavior of the function f is changed when it is called with its two arguments aliased to each other. (c) This code fragment is not well-behaved because a is of size 10, but an assignment is made to the 11th element. tools such as lint or <ref> [45, 44] </ref> can be used to establish well-behavedness. See Figure 5.1 for examples of well-behavedness problems. If an external tool is not available, property-based testing also can be used to ascertain a property such as well-behavedness.
Reference: [45] <author> Raymond Waiman Lo. </author> <title> Static Analysis of Programs with Application to Malicious Code Detection. </title> <type> PhD thesis, </type> <institution> University of California, Davis, </institution> <year> 1992. </year>
Reference-contexts: Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> the printf. (b) The behavior of the function f is changed when it is called with its two arguments aliased to each other. (c) This code fragment is not well-behaved because a is of size 10, but an assignment is made to the 11th element. tools such as lint or <ref> [45, 44] </ref> can be used to establish well-behavedness. See Figure 5.1 for examples of well-behavedness problems. If an external tool is not available, property-based testing also can be used to ascertain a property such as well-behavedness.
Reference: [46] <author> Teresa F. Lunt. </author> <title> Automated audit trail analysis and intrusion detection: A survey. </title> <booktitle> In Proceedings of the 11th National Computer Security Conference, </booktitle> <month> October </month> <year> 1988. </year>
Reference-contexts: Third-party testing is possible because testing is based upon generic program-independent specifications. The problem of overly privileged network servers could be addressed by intrusion detection [47, 58] or other run-time methods such as audit trail analysis <ref> [46] </ref>. For this defense to be effective, wrappers and intrusion detection must always be invoked; depending on the circumstances if an error is detected the damage may already have been done.
Reference: [47] <author> Teresa F. Lunt. Ides: </author> <title> An intelligent system for detecting intruders. </title> <booktitle> In Proceedings of the Symposium: Computer Security, Threat and Countermeasures, </booktitle> <month> November </month> <year> 1990. </year>
Reference-contexts: Third-party testing is possible because testing is based upon generic program-independent specifications. The problem of overly privileged network servers could be addressed by intrusion detection <ref> [47, 58] </ref> or other run-time methods such as audit trail analysis [46]. For this defense to be effective, wrappers and intrusion detection must always be invoked; depending on the circumstances if an error is detected the damage may already have been done.
Reference: [48] <author> Brian Marick. </author> <title> Generic Coverage Tool (GCT) User's Guide. Testing Foundations, </title> <year> 1992. </year>
Reference-contexts: Operator coverage is similar to statement coverage but includes special cases for arithmetic operators, so test data of c = 0 (a special value for the second operand of the division operator) would be a second, required, case. The public domain coverage analyzer GCT <ref> [48] </ref> implements statement and operator coverage for C. A common model for coverage is that of definition-usage (def-use) pairs. &lt; d; u &gt; 30 is a def-use pair if d is a definition (assignment) of some variable, and u is a usage of that variable.
Reference: [49] <author> Simeon C. Ntafos. </author> <title> On required element testing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(6):795-803, </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: A test suite is a set of test cases for a program. The completeness of a test suite is measured by a new code coverage metric, iterative contexts, which is stronger (i.e., detects more flaws) than previously-proposed practical code coverage metrics <ref> [39, 49, 9] </ref>. An iterative context is a sequence of assignments defining a sub-path of a possible program execution. The assignments are taken from the program slice and represent a possible computation of a value important to the target property. <p> Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on <ref> [25, 39, 9, 49, 27, 65] </ref>. This dependence, called a data-flow dependence, captures the flow of information in a program. Static analysis typically requires the calculation of all possible data-flow dependences. <p> The use- and live-contexts of Laski and Korel [36, 39] are similar in form to iterative contexts. Required k-Tuples by Ntafos <ref> [49] </ref> unrolls def-use chains by chaining together sequences of def-use-def links, and attaches "required elements" as predicates to be satisfied before the chain matches an execution. Finally, iterative contexts are briefly compared with classic path coverage metrics such as all-uses and all-paths.
Reference: [50] <author> Ronald A. Olsson, Richard H. Crawford, and W. Wilson Ho. </author> <title> A dataflow approach to event-based debugging. </title> <journal> Software Practice and Experience, </journal> <volume> 21(2) </volume> <pages> 209-229, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: The Dalek debugger <ref> [50] </ref> uses a powerful language to monitor and control the behavior of the program being debugged. The concept of event handling as a monitoring and debugging tool is a feature of the Dalek debugging language which inspired the use of event handling in the Tester's Assistant.
Reference: [51] <author> K. J. Ottenstein and L.M. Ottenstein. </author> <title> The program dependence graph in a software development environment. </title> <booktitle> In Proceedings of the ACM SIG-SOFT/SIGPLAN Symposium on Practical Software Development Environments, </booktitle> <pages> pages 177-184, </pages> <year> 1984. </year> <month> 164 </month>
Reference-contexts: Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Inter-procedural analysis uses summary information generated from the data-flow graphs of individual functions. The control flow graph is augmented with dependence edges to form the program (or procedure) dependence graph (PDG <ref> [51] </ref>). If node 1 uses a value which is generated at node 2 , then there is a data dependence link between the two nodes. If the execution of node 1 is dependent upon a predicate at node2, then there is a control dependence link between the two nodes. <p> This information is directly available from the edges of the data-flow graph. Data-flow graphs are typically computed with control flow graphs (CFG) and program dependence graphs <ref> [3, 20, 36, 43, 51, 52, 63] </ref>. CFG-based algorithms produce a program-independent CFG before propagating definitions. Static analysis in the Tester's Assistant is novel primarily because def-use edges are generated by propagating definitions through the structure of the program, without producing an explicit CFG.
Reference: [52] <author> T. Reps and G. Rosay. </author> <title> Precise interprocedural chopping. </title> <booktitle> In Proceedings of the Third ACM SIGSOFT Symposium on the Foundations of Software Engineering, </booktitle> <pages> pages 41-52, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: This information is directly available from the edges of the data-flow graph. Data-flow graphs are typically computed with control flow graphs (CFG) and program dependence graphs <ref> [3, 20, 36, 43, 51, 52, 63] </ref>. CFG-based algorithms produce a program-independent CFG before propagating definitions. Static analysis in the Tester's Assistant is novel primarily because def-use edges are generated by propagating definitions through the structure of the program, without producing an explicit CFG. <p> Development of the theory of mappings between TASPEC and slice constructors is left for future work. Recent work by Reps and Rosay <ref> [52] </ref> suggests some problems with blindly intersecting and unioning slices, especially across call sites. A function that is called in a different location in two different slices appears in each slice. Therefore, the function appears in the intersection of the slices when in fact the individual slices have distinct functionality.
Reference: [53] <author> Debra Richardson. TAOS: </author> <title> Testing with analysis and oracle support. </title> <booktitle> In Proceedings of the 1994 International Symposium on Software Testing and Analysis, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: The goals behind using specifications in testing are establishing greater formalism for test results, and increasing the automatability and re-usability of test objects. Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data [57, 8], specifications to create test oracles <ref> [18, 17, 53] </ref> (verifying the correctness of an execution), and specifications refined into code [26, 16, 33, 14] (and therefore having direct measurable specification-code relationships). Specification languages such as Z [13] and VDM [2] can be used to fully specify a system at a level more abstract than source code. <p> However, generating test cases from such a specification is not very different from generating tests from the source code due to the shared derivation of code and specification. Test oracles can also be automatically generated from other specification languages such as Larch [24] and TAOS <ref> [54, 53] </ref>. Function and procedure behavior is specified as in the refinement methods, but in a separate process from the actual coding. The specifications can then serve as independent test oracles without being influenced by implementation bias.
Reference: [54] <author> Debra J. Richardson, Stephanie Leif Aha, and T. Owen O'Malley. </author> <title> Specification-based test oracles for reactive systems. </title> <booktitle> In 14th International Conference on Software Engineering, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: However, generating test cases from such a specification is not very different from generating tests from the source code due to the shared derivation of code and specification. Test oracles can also be automatically generated from other specification languages such as Larch [24] and TAOS <ref> [54, 53] </ref>. Function and procedure behavior is specified as in the refinement methods, but in a separate process from the actual coding. The specifications can then serve as independent test oracles without being influenced by implementation bias.
Reference: [55] <author> Debra J. Richardson, Owen O'Malley, and Cindy Tittle. </author> <title> Approaches to specification-based testing. </title> <booktitle> In Proceedings of the First ACM SIGSOFT '89 Third Symposium on Testing, Analysis, and Verification(TAV3), </booktitle> <pages> pages 86-96, </pages> <month> Decem-ber </month> <year> 1989. </year>
Reference-contexts: Finally, if there are any specifications of ftpd, the specifications can be used to generate test data. Generating test data from specifications is not specifically part of property-based testing, but other testing methodologies contain the necessary algorithms <ref> [8, 12, 55] </ref>. The first method is simplest, because no extra work is required and the test suite is likely to be fairly complete. However in this case, the test cases aren't available, so the human tester creates some test cases by reading the ftpd manual page. <p> Test data can also be generated from specifications. ADL [56, 57] and TAOS have test description languages by which test data can be partitioned. Once the input domain is partitioned, generating exhaustive test data with respect to the structure of the specification is possible <ref> [55, 8] </ref>. Prior to this work, similar techniques had been used with VDM [12]. Related work generates test data from the structure of code such as in [21] and [29]. Using location specifiers, generic program-independent properties in TASPEC map automatically to source code.
Reference: [56] <author> S. Sankar. </author> <title> Automatic Runtime Consistency Checking and Debugging of Formally Specified Programs. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1989. </year> <institution> Also Stanford University Department of Computer Science Technical Report No. STAN-CS-89-1282, and Computer Systems Laboratory Technical Report No. CSL-TR-89-391. </institution>
Reference-contexts: This linkage can be made easily if the unit of specification is the behavior of individual functions (or modules) in the implementation. Formal parameters can be linked with actual parameters, and so on. Test data can also be generated from specifications. ADL <ref> [56, 57] </ref> and TAOS have test description languages by which test data can be partitioned. Once the input domain is partitioned, generating exhaustive test data with respect to the structure of the specification is possible [55, 8]. Prior to this work, similar techniques had been used with VDM [12].
Reference: [57] <author> S. Sankar and R. Hayes. </author> <title> ADL | an interface definition language for specifying and testing software. </title> <type> Technical Report CMU-CS-94-WIDL-1, </type> <institution> Carnegie-Mellon University, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: The goals behind using specifications in testing are establishing greater formalism for test results, and increasing the automatability and re-usability of test objects. Earlier methods for utilizing specifications in testing fall into three categories: Specifications to generate test data <ref> [57, 8] </ref>, specifications to create test oracles [18, 17, 53] (verifying the correctness of an execution), and specifications refined into code [26, 16, 33, 14] (and therefore having direct measurable specification-code relationships). <p> This linkage can be made easily if the unit of specification is the behavior of individual functions (or modules) in the implementation. Formal parameters can be linked with actual parameters, and so on. Test data can also be generated from specifications. ADL <ref> [56, 57] </ref> and TAOS have test description languages by which test data can be partitioned. Once the input domain is partitioned, generating exhaustive test data with respect to the structure of the specification is possible [55, 8]. Prior to this work, similar techniques had been used with VDM [12].
Reference: [58] <author> S. Snapp, J. Brentano, G. Dias, et al. </author> <title> DIDS (distributed intrusion detection system) motivation, architecture, and an early prototype. </title> <booktitle> In Proceedings of the 14th National Computer Security Conference, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: Third-party testing is possible because testing is based upon generic program-independent specifications. The problem of overly privileged network servers could be addressed by intrusion detection <ref> [47, 58] </ref> or other run-time methods such as audit trail analysis [46]. For this defense to be effective, wrappers and intrusion detection must always be invoked; depending on the circumstances if an error is detected the damage may already have been done.
Reference: [59] <author> E. H. Spafford. </author> <title> The internet worm: Crisis and aftermath. </title> <journal> Communications of the ACM, </journal> <pages> pages 678-687, </pages> <month> June </month> <year> 1989. </year> <month> 165 </month>
Reference-contexts: Security flaws are still being discovered in computer programs that have been in use for many years. Many of the flaws are caused by the same basic recurring faults [60]. For example, the Internet worm <ref> [59] </ref> exploited errors in Unix 18 network programs. Examination of the flaws which caused the errors revealed them to be of an elementary nature. It is time for a concerted effort to try to prevent such flaws from occurring, i.e., with property-based testing. <p> The portion of the name that overflows onto the stack could contain code that is executed by the fingerd process. Therefore, using finger, a user could execute any arbitrary code on the remote machine. This flaw was exploited by the Internet worm <ref> [59] </ref>. A test which addresses array boundary conditions catches this flaw. 3.1.3 Approaches for establishing security There are two basic ways to provide security for a computer system hooked up to a network: 1. Actively try to detect intrusions and other insecure behavior and take corrective action. 2. <p> This section presents a simple set of specifications which detect array bounds violations in statically declared arrays, and a fragment of the extension to that specification for dynamically declared arrays. Fingerd The flaw in fingerd exploited by the Internet worm <ref> [59] </ref> was an array overflow error. Fingerd and its flaw are described in Section 3.1.2. Specifying array bounds in TASPEC If arrays are declared statically, the specification (in Figure 4.6) is quite simple. The array predicate corresponds with the declaration of an array.
Reference: [60] <author> Eugene H. Spafford. </author> <title> Common system vulnerabilities. Workshop on Future Directions in Intrusion and Misuses Detection, </title> <year> 1992. </year>
Reference-contexts: Security flaws are still being discovered in computer programs that have been in use for many years. Many of the flaws are caused by the same basic recurring faults <ref> [60] </ref>. For example, the Internet worm [59] exploited errors in Unix 18 network programs. Examination of the flaws which caused the errors revealed them to be of an elementary nature. It is time for a concerted effort to try to prevent such flaws from occurring, i.e., with property-based testing. <p> A successful test validates that properties are not violated; if these properties form the security policy for the system, then the system is secure. Property-based testing uses a security model of the system, as well as a library of generic flaws (such as <ref> [38, 60] </ref>) specified in TASPEC, to produce a test process, whereby the target program can be certified to be free of certain types of flaws. 3.2 Specifications Specifications are descriptions of software (or hardware) systems.
Reference: [61] <author> J. M. Spivey. </author> <title> The Z Notation: A Reference Manual. </title> <publisher> Prentice-Hall, </publisher> <address> London, 2nd edition, </address> <year> 1992. </year>
Reference-contexts: For example, specifications written in English can be easy to read and understand, but ambiguity and lack of formality make it difficult to systematically map English specifications to software systems. Diagrams such as flow-charts are graphical ways to express specifications. Specifications in formal languages such as Z <ref> [13, 61, 67] </ref> are easier to systematically (but not automatically) relate to computer programs, and can be used with formal reasoning tools, but can be harder to produce and understand. The basis of property-based testing is specification of properties. The property specification drives testing in an automated fashion. <p> TASPEC's approach in associating specifications with code is similar to that of Larch [24], but the concept of a TASPEC location is more general than Larch's function-level specifications. Many established languages such as Larch and Z <ref> [61] </ref> have tools and methodologies to allow formal reasoning about specifications. Currently, TASPEC has no formal reasoning facilities, so the consistency and correctness of TASPEC specifications cannot be guaranteed. Further development of the TASPEC language is necessary. No distinction is made in the syntax between an identifier and a variable.
Reference: [62] <author> Andrew S. Tanenbaum. </author> <title> Operating Systems Design and Implementation. </title> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: Section 7.3 covers details of the instrumentation. The audit trail is examined to see if any error conditions exist; examination is done according to the semantics of TASPEC. Property-based testing of the Minix login program <ref> [62] </ref> and the authentication property illustrates correctness monitoring. Given a specification such as authenticated (U ) before permissions granted (U ); the question is "How is satisfaction of this invariant determined during program execution?" TASPEC provides location parameters with which primitive events are associated with specific program locations. <p> The program used in this run is the Minix <ref> [62] </ref> login program. The program has already been run through the C pre-processor. Several interesting library functions have been specified from the command line as the Tester's Assistant program ta.exe is invoked. Several indicators as to the size of the graph are printed as analysis is complete.
Reference: [63] <author> Frank Tip. </author> <title> A survey of program slicing techniques. </title> <journal> Journal of Programming Languages, </journal> <volume> 3(3) </volume> <pages> 121-189, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Property specifications expressed in TASPEC are translated automatically into test oracles that check the correctness of program executions. Explicitly specified relationships between property specifications and source code allows static analysis to be focused on the specific code relevant to the specified property; this technique is called slicing <ref> [43, 42, 63, 64] </ref>. Because they are processing program slices, and not the whole program, testing and analysis algorithms with higher time bounds become practical to use. For example, path-based test coverage 2 metrics are typically viewed as too expensive for practical use [9]. <p> Then code related to the target property and all other code related to that code are targeted for testing. The process of finding a subset of the program which has identical behavior to the full program with respect to the property is called program slicing <ref> [43, 42, 63, 64] </ref>. The property specification is also translated automatically into a test oracle for the given program. A test oracle checks the validity of a single execution of the program by analyzing the intermediate and final states of the program for inconsistencies with property specifications. <p> Section 5.4 gives more information about slice construction. An example of slicing is in Figure 3.1. A static slice with respect to the variable x parameter of the setuid function call is shown alongside full example function. 28 3.4.1 Uses of slicing Slicing is used in software maintenance <ref> [20, 41, 63] </ref>, automatic parallelization [64], and testing and debugging [64, 63, 37]. In software maintenance, it is useful to examine the side effects of a single change to the source code. <p> A static slice with respect to the variable x parameter of the setuid function call is shown alongside full example function. 28 3.4.1 Uses of slicing Slicing is used in software maintenance [20, 41, 63], automatic parallelization [64], and testing and debugging <ref> [64, 63, 37] </ref>. In software maintenance, it is useful to examine the side effects of a single change to the source code. Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. <p> Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. Slicing has additional applications to maintenance [20]. Other slicing work is described in <ref> [42, 43, 3, 15, 63] </ref>. Slicing is an active area of research and development. For automatic parallelization, output variables in a program are identified, and slices are computed for each output variable. Each slice can be executed separately. <p> This information is directly available from the edges of the data-flow graph. Data-flow graphs are typically computed with control flow graphs (CFG) and program dependence graphs <ref> [3, 20, 36, 43, 51, 52, 63] </ref>. CFG-based algorithms produce a program-independent CFG before propagating definitions. Static analysis in the Tester's Assistant is novel primarily because def-use edges are generated by propagating definitions through the structure of the program, without producing an explicit CFG.
Reference: [64] <author> Mark Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(4):352-375, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: Property specifications expressed in TASPEC are translated automatically into test oracles that check the correctness of program executions. Explicitly specified relationships between property specifications and source code allows static analysis to be focused on the specific code relevant to the specified property; this technique is called slicing <ref> [43, 42, 63, 64] </ref>. Because they are processing program slices, and not the whole program, testing and analysis algorithms with higher time bounds become practical to use. For example, path-based test coverage 2 metrics are typically viewed as too expensive for practical use [9]. <p> Then code related to the target property and all other code related to that code are targeted for testing. The process of finding a subset of the program which has identical behavior to the full program with respect to the property is called program slicing <ref> [43, 42, 63, 64] </ref>. The property specification is also translated automatically into a test oracle for the given program. A test oracle checks the validity of a single execution of the program by analyzing the intermediate and final states of the program for inconsistencies with property specifications. <p> A static slice or simply a slice of P relative to the slicing criterion &lt;p,V&gt; is defined as the set of all statements and predicates of P that might affect the values of variable V at the point p. <ref> [64] </ref> 27 Slicing is the most important technique used in property-based testing. Program analysis algorithms such as data-flow coverage tend to be at least exponential in running time [9] (if not uncomputable in the general case). <p> An example of slicing is in Figure 3.1. A static slice with respect to the variable x parameter of the setuid function call is shown alongside full example function. 28 3.4.1 Uses of slicing Slicing is used in software maintenance [20, 41, 63], automatic parallelization <ref> [64] </ref>, and testing and debugging [64, 63, 37]. In software maintenance, it is useful to examine the side effects of a single change to the source code. Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. <p> A static slice with respect to the variable x parameter of the setuid function call is shown alongside full example function. 28 3.4.1 Uses of slicing Slicing is used in software maintenance [20, 41, 63], automatic parallelization [64], and testing and debugging <ref> [64, 63, 37] </ref>. In software maintenance, it is useful to examine the side effects of a single change to the source code. Slicing on this point in the code, then, produces a map of exactly where else in the code more alterations may be needed. <p> Weiser tested these ideas with a slicer for a version of Fortran <ref> [64] </ref>. He also proposed that a slicer would be useful in debugging, by slicing when an error occurs to find possible faults in the program. STAD [36, 37] uses a related concept called a dynamic slice to debug programs.
Reference: [65] <author> Elain J. Weyuker and Bingchiang Jeng. </author> <title> Analyzing partition testing strategies. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(7) </volume> <pages> 703-711, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Helmke shows how translations from Z to TASPEC can assist in requirements traceability [26]. 25 3.3 Static analysis Static analysis of source code is the basis of most formal software testing <ref> [25, 36, 39, 9, 49, 15, 27, 45, 51, 65] </ref>. Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on [25, 39, 9, 49, 27, 65]. <p> Many static analysis techniques use the relationship between an assignment to a variable and the usage of that variable later on <ref> [25, 39, 9, 49, 27, 65] </ref>. This dependence, called a data-flow dependence, captures the flow of information in a program. Static analysis typically requires the calculation of all possible data-flow dependences. <p> One version of def-use coverage might require d and u to be executed in the same run of the program. Def-use pairs are used in many metrics <ref> [65, 9, 39] </ref>, and in one public domain coverage analyzer [27]. An alternate model for coverage, not utilized in the Tester's Assistant, is mutation testing [11]. Mutation testing distinguishes between the the program and closely related programs, each related program differing in only one small way from the original. <p> This input data is the partition of the input space defined by that path. Typically, for test data generation, some data is selected from each partition. Path-based coverage schemes, iterative contexts among them, often do not sufficiently partition the input space to provide an effective test <ref> [65] </ref>, especially in cases where the code includes complicated arithmetic computations. The solution is to add additional constraints on the data values of paths.
Reference: [66] <author> K. Wilken, D. Goodwin, and J. Burger. </author> <title> Compiler and architecture support for low-overhead program profiling. </title> <journal> Software Practice& Experience, </journal> <note> 1996. To appear. </note>
Reference-contexts: This method of instrumentation does not affect the normal semantics of the program unless the program is ill-behaved, although it will affect the timing properties of the program. If the timing properties of the program are important, then the probe effect introduced by this instrumentation will interfere. Results elsewhere <ref> [4, 66] </ref> indicate that it is possible to remove the probe effect in most situations by minimizing the number of probes and intelligently placing the probes in places such as NOP instructions following branch instructions. 112 Chapter 8 The Tester's Assistant The current implementation of the Tester's Assistant includes a static
Reference: [67] <author> John B. Wordsworth. </author> <title> Software Development with Z. </title> <publisher> Addison-Wesley, </publisher> <address> Working-ham, England, </address> <year> 1992. </year>
Reference-contexts: For example, specifications written in English can be easy to read and understand, but ambiguity and lack of formality make it difficult to systematically map English specifications to software systems. Diagrams such as flow-charts are graphical ways to express specifications. Specifications in formal languages such as Z <ref> [13, 61, 67] </ref> are easier to systematically (but not automatically) relate to computer programs, and can be used with formal reasoning tools, but can be harder to produce and understand. The basis of property-based testing is specification of properties. The property specification drives testing in an automated fashion.
References-found: 67

