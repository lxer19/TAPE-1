URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/metric-full.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Email: Internet: ronen@wisdom.weizmann.ac.il  Internet: daphna@cs.huji.ac.il  
Title: Distance Metric between 3D Models and 2D Images for Recognition and Classification  
Author: Ronen Basri Daphna Weinshall 
Address: Rehovot 76100, Israel  91904 Jerusalem, Israel  
Affiliation: Dept. of Applied Math The Weizmann Inst. of Science  Institute of Computer Science The Hebrew University of Jerusalem  
Abstract: Similarity measurements between 3D objects and 2D images are useful for the tasks of object recognition and classification. We distinguish between two types of similarity metrics: metrics computed in image-space (image metrics) and metrics computed in transformation-space (transformation metrics). Existing methods typically use image metrics; namely, metrics that measure the difference in the image between the observed image and the nearest view of the object. Example for such a measure is the Euclidean distance between feature points in the image and their corresponding points in the nearest view. (This measure can be computed by solving the exterior orientation calibration problem.) In this paper we introduce a different type of metrics: transformation metrics. These metrics penalize for the deformations applied to the object to produce the observed image. In particular, we define a transformation metric that optimally penalizes for "affine deformations" under weak-perspective. A closed-form solution, together with the nearest view according to this metric, are derived. The metric is shown to be equivalent to the Euclidean image metric, in the sense that they bound each other from both above and below. It therefore provides an easy-to-use closed-form approximation for the commonly-used least-squares distance between models and images. We demonstrate an image understanding application, where the true dimensions of a photographed battery charger are estimated by minimizing the transformation metric. 
Abstract-found: 1
Intro-found: 1
Reference: [AG93] <author> Alter, T. D. and Grimson W. E. L., </author> <year> (1993). </year> <title> Fast and Robust 3D Recognition by Alignment, </title> <booktitle> in Proc. Fourth Inter. Conf. Computer Vision, </booktitle> <month> Berlin. </month> <journal> IEEE Trans. on Pattern Anal. Machine Intel., </journal> <volume> 18(4), </volume> <pages> 465-470, </pages> <year> 1996 </year> <month> 38 </month>
Reference-contexts: More importantly, by relying only on a small number of correspondences, alignment enables recognizing non-segmented objects in cluttered scenes in a worst-case polynomial time complexity. However such a strategy would often yield errors in estimating the transformation (see, <ref> [AG93, GHA92, GHJ92] </ref>), and so typical algorithms often try, after obtaining an initial alignment, to extend the match with more correspondences (e.g., [AG93, FB81]). Consequently, an accurate and fast estimation of the alignment transformation at this stage can reduce the amount of computation that is necessary to eliminate false hypotheses. <p> However such a strategy would often yield errors in estimating the transformation (see, [AG93, GHA92, GHJ92]), and so typical algorithms often try, after obtaining an initial alignment, to extend the match with more correspondences (e.g., <ref> [AG93, FB81] </ref>). Consequently, an accurate and fast estimation of the alignment transformation at this stage can reduce the amount of computation that is necessary to eliminate false hypotheses.
Reference: [B93] <author> Basri, R. </author> <year> (1993). </year> <title> Recognition by prototypes. Computer Vision and Pattern Recognition (CVPR-93), </title> <address> New York City, NY. </address>
Reference-contexts: Our simulations show that these bounds often provide better estimates than those provided by using alignment. Finally, our transformation metric can be used in schemes that attempt to classify objects. A scheme for classification was recently proposed <ref> [B93] </ref>, in which classes contain objects that share the same basic features in distorted positions. Our metric can be used under such a scheme to evaluate the amount of affine distortion applied to the object relative to a prototype object in order to determine its class identity.
Reference: [BU93] <author> Basri, R. and Ullman, S. </author> <year> (1993). </year> <title> The alignment of objects with smooth surfaces. Computer Vision, Graphics, </title> <booktitle> and Image Processing: Image Understanding, </booktitle> <volume> 57(3) </volume> <pages> 331-345. </pages>
Reference-contexts: Watson Research Center, Yorktown Heights, NY. 1 IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 2 objects. An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features, e.g. <ref> [R65, FB81, L85, HU87, BU93, TM87, UB91] </ref>. Since images often are noisy and models occasionally are imperfect, it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that "reasonably" aligns with the image.
Reference: [DD92] <author> DeMenthon, D. F. and Davis, L. S. </author> <year> (1992). </year> <title> Model-based object pose in 25 lines of code. </title> <booktitle> In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <address> Santa Margherita Ligure, Italy. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Machine Intel., 18 (4), 465-470, 1996 9 Since the solution in the rigid case is significantly more difficult than the solution in the affine case, often the affine solution is considered, and the rigidity constraints are used only for verification (e.g. <ref> [UB91, W93, DD92] </ref>). <p> The sub-optimal solution derived using the image metric provides a better estimate for the image metric than the affine solution, which has been used for example in <ref> [DD92] </ref> as the initial guess for computing the perspective image metric numerically. Another potential application of the metric is in evaluating hypothesized correspondences in an alignment algorithm. Alignment is a method for evaluating the similarity between models and images based on a small number of correspondences.
Reference: [FH86] <author> Faugeras, O. D. and Hebert, M. </author> <year> (1986). </year> <title> The representation, recognition, and locating of 3-D objects. </title> <journal> Int. J. of Robotics Research, </journal> <volume> 5(3) </volume> <pages> 27-52. </pages>
Reference-contexts: An analytic solution to this problem has not yet been found. (Analytic solutions to the absolute orientation problem, the least-square distance between pairs of 3D objects, have been found, see <ref> [FH86, H87, H91] </ref>. An analytic solution to the least-square distance between pairs of 2D images has not yet been found.) Consequently, numerical methods are employed (see reviews in [T87, Y89]). Such solutions often suffer from stability problems, they are computationally intensive and require a good initial guess.
Reference: [FB81] <author> Fischler, M. A. and Bolles, R. C. </author> <year> (1981). </year> <title> Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. </title> <journal> Communications of the ACM, </journal> <volume> 24 </volume> <pages> 381-395. </pages>
Reference-contexts: Watson Research Center, Yorktown Heights, NY. 1 IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 2 objects. An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features, e.g. <ref> [R65, FB81, L85, HU87, BU93, TM87, UB91] </ref>. Since images often are noisy and models occasionally are imperfect, it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that "reasonably" aligns with the image. <p> The solution in the affine case is simpler than that of the rigid case because the quadratic constraints imposed in the rigid case are not taken into account, enabling the construction of a closed-form solution. At least six points are required to find an affine solution under perspective projection <ref> [FB81] </ref>, and four are required under orthographic projection [UB91]. The affine measure bounds the rigid measure from below. The rigid measure, however, is not bounded from above, and so the actual rigid measure may sometimes be significantly larger than the computed affine measure. This is demonstrated by the following example. <p> A second approach to comparing models to images, often called alignment, involves the selection of a small subset of correspondences (alignment key), solving for the transformation using this subset, and then transforming the other points and measuring their distance from the corresponding image points. Three <ref> [FB81, RBPD81, HLON91] </ref> or four [HCLL89] points are required under perspective projection, and three points under weak perspective [U89, HU87] . The obtained distance critically depends on the choice of alignment key. Different choices produce different distance measures between the model and the image. <p> However such a strategy would often yield errors in estimating the transformation (see, [AG93, GHA92, GHJ92]), and so typical algorithms often try, after obtaining an initial alignment, to extend the match with more correspondences (e.g., <ref> [AG93, FB81] </ref>). Consequently, an accurate and fast estimation of the alignment transformation at this stage can reduce the amount of computation that is necessary to eliminate false hypotheses. <p> Therefore, typical algorithms often try, after obtaining an initial alignment, to extend the match with additional correspondences (e.g., <ref> [FB81] </ref>). The bounds derived on the image metric may be used at this stage to evaluate potential correspondences. Our simulations show that these bounds often provide better estimates than those provided by using alignment. Finally, our transformation metric can be used in schemes that attempt to classify objects.
Reference: [FMZCHR91] <author> Forsyth, D., Mundy, J. L., Zisserman, A., Coelho, C., Heller, A., and Rothwell, C. </author> <year> (1991). </year> <title> Invariant descriptors for 3-D object recognition and pose. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 971-991. </pages>
Reference-contexts: Such functions return a constant value when applied to any image of a particular model. Invariant functions were IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 5 successfully used only with special kinds of models, such as planar objects (e.g., <ref> [LSW87, FMZCHR91] </ref>). More general objects can be recognized using model-based invariant functions [W93]. For noise-free data, model-based invariant functions return zero if the image is an exact instance of the object. To account for noise, the output of these functions usually is required to be below some fixed threshold.
Reference: [GHA92] <author> Grimson, W. E. L., Huttenlocher, D. P., and Alter, T. D., </author> <year> (1992). </year> <title> Recognizing 3D Objects from 2D Images: An Error Analysis. </title> <booktitle> in Proc. IEEE Conf. Computer Vision Pat. Rec., </booktitle> <address> Urbana. </address>
Reference-contexts: More importantly, by relying only on a small number of correspondences, alignment enables recognizing non-segmented objects in cluttered scenes in a worst-case polynomial time complexity. However such a strategy would often yield errors in estimating the transformation (see, <ref> [AG93, GHA92, GHJ92] </ref>), and so typical algorithms often try, after obtaining an initial alignment, to extend the match with more correspondences (e.g., [AG93, FB81]). Consequently, an accurate and fast estimation of the alignment transformation at this stage can reduce the amount of computation that is necessary to eliminate false hypotheses. <p> While the use of few correspondences is advantageous for recognizing objects in polynomial time complexity while overcoming partial occlusion, it may often yield errors in estimating the distance between models and images (see, e.g., <ref> [GHA92] </ref>). Therefore, typical algorithms often try, after obtaining an initial alignment, to extend the match with additional correspondences (e.g., [FB81]). The bounds derived on the image metric may be used at this stage to evaluate potential correspondences.
Reference: [GHJ92] <author> Grimson, W. E. L., Huttenlocher, D. P., and Jacobs, D. W., </author> <year> (1992). </year> <title> A Study of Affine Matching with Bounded Sensor Error. </title> <booktitle> in Proc. Second European Conf. Computer Vision, </booktitle> <pages> 291-306. </pages>
Reference-contexts: More importantly, by relying only on a small number of correspondences, alignment enables recognizing non-segmented objects in cluttered scenes in a worst-case polynomial time complexity. However such a strategy would often yield errors in estimating the transformation (see, <ref> [AG93, GHA92, GHJ92] </ref>), and so typical algorithms often try, after obtaining an initial alignment, to extend the match with more correspondences (e.g., [AG93, FB81]). Consequently, an accurate and fast estimation of the alignment transformation at this stage can reduce the amount of computation that is necessary to eliminate false hypotheses.
Reference: [HLON91] <author> Haralick, R. M., Lee, C., Ottenberg, K., and Nolle, M. </author> <title> (19). Analysis and solutions of the three point perspective pose estimation problem. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 592-598, </pages> <address> Urbana-Champaign, IL. </address>
Reference-contexts: A second approach to comparing models to images, often called alignment, involves the selection of a small subset of correspondences (alignment key), solving for the transformation using this subset, and then transforming the other points and measuring their distance from the corresponding image points. Three <ref> [FB81, RBPD81, HLON91] </ref> or four [HCLL89] points are required under perspective projection, and three points under weak perspective [U89, HU87] . The obtained distance critically depends on the choice of alignment key. Different choices produce different distance measures between the model and the image.
Reference: [HCLL89] <author> Horaud, R., Conio, B., Leboulleux, O., and Lacolle, B. </author> <year> (1989). </year> <title> An analytic solution for the perspective 4-point problem. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 47 </volume> <pages> 33-44. </pages>
Reference-contexts: Three [FB81, RBPD81, HLON91] or four <ref> [HCLL89] </ref> points are required under perspective projection, and three points under weak perspective [U89, HU87] . The obtained distance critically depends on the choice of alignment key. Different choices produce different distance measures between the model and the image.
Reference: [H87] <author> Horn, B. K. P. </author> <year> (1987). </year> <title> Closed-form solution of absolute orientation using unit quater-nions. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 4 </volume> <pages> 629-642. </pages>
Reference-contexts: An analytic solution to this problem has not yet been found. (Analytic solutions to the absolute orientation problem, the least-square distance between pairs of 3D objects, have been found, see <ref> [FH86, H87, H91] </ref>. An analytic solution to the least-square distance between pairs of 2D images has not yet been found.) Consequently, numerical methods are employed (see reviews in [T87, Y89]). Such solutions often suffer from stability problems, they are computationally intensive and require a good initial guess.
Reference: [H91] <author> Horn, B. K. P. </author> <year> (1991). </year> <title> Relative orientation revisited. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 8 </volume> <pages> 1630-1638. </pages>
Reference-contexts: An analytic solution to this problem has not yet been found. (Analytic solutions to the absolute orientation problem, the least-square distance between pairs of 3D objects, have been found, see <ref> [FH86, H87, H91] </ref>. An analytic solution to the least-square distance between pairs of 2D images has not yet been found.) Consequently, numerical methods are employed (see reviews in [T87, Y89]). Such solutions often suffer from stability problems, they are computationally intensive and require a good initial guess.
Reference: [HU87] <author> Huttenlocher, D. P. and Ullman, S. </author> <year> (1987). </year> <title> Object recognition using alignment. </title> <booktitle> In Proceedings of the 1st International Conference on Computer Vision, </booktitle> <pages> pages 102-111, </pages> <address> London, England. </address> <publisher> IEEE, </publisher> <address> Washington, </address> <month> DC. </month> <journal> IEEE Trans. on Pattern Anal. Machine Intel., </journal> <volume> 18(4), </volume> <pages> 465-470, </pages> <year> 1996 </year> <month> 39 </month>
Reference-contexts: Watson Research Center, Yorktown Heights, NY. 1 IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 2 objects. An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features, e.g. <ref> [R65, FB81, L85, HU87, BU93, TM87, UB91] </ref>. Since images often are noisy and models occasionally are imperfect, it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that "reasonably" aligns with the image. <p> Three [FB81, RBPD81, HLON91] or four [HCLL89] points are required under perspective projection, and three points under weak perspective <ref> [U89, HU87] </ref> . The obtained distance critically depends on the choice of alignment key. Different choices produce different distance measures between the model and the image.
Reference: [LSW87] <author> Lamdan, Y., Schwartz, J. T., and Wolfson, H. </author> <year> (1987). </year> <title> On recognition of 3-d objects from 2-d images. </title> <type> Robotics research Technical Report 122, </type> <institution> Courant Institute of Math. Sciences, N.Y. University. </institution>
Reference-contexts: Such functions return a constant value when applied to any image of a particular model. Invariant functions were IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 5 successfully used only with special kinds of models, such as planar objects (e.g., <ref> [LSW87, FMZCHR91] </ref>). More general objects can be recognized using model-based invariant functions [W93]. For noise-free data, model-based invariant functions return zero if the image is an exact instance of the object. To account for noise, the output of these functions usually is required to be below some fixed threshold.
Reference: [L85] <author> Lowe, D. G. </author> <year> (1985). </year> <title> Three-dimensional object recognition from single two-dimensional images. </title> <type> Robotics research Technical Report 202, </type> <institution> Courant Institute of Math. Sciences, N.Y. University. </institution>
Reference-contexts: Watson Research Center, Yorktown Heights, NY. 1 IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 2 objects. An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features, e.g. <ref> [R65, FB81, L85, HU87, BU93, TM87, UB91] </ref>. Since images often are noisy and models occasionally are imperfect, it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that "reasonably" aligns with the image.
Reference: [RBPD81] <author> Rives, P., Bouthemy, B., Prasada, B., and Dubois, E. </author> <year> (1981). </year> <title> Recovering the orientation and the position of a rigid body in space from a single view. </title> <type> Technical report, </type> <address> INRS-Telecommunications, Quebec, Canada. </address>
Reference-contexts: A second approach to comparing models to images, often called alignment, involves the selection of a small subset of correspondences (alignment key), solving for the transformation using this subset, and then transforming the other points and measuring their distance from the corresponding image points. Three <ref> [FB81, RBPD81, HLON91] </ref> or four [HCLL89] points are required under perspective projection, and three points under weak perspective [U89, HU87] . The obtained distance critically depends on the choice of alignment key. Different choices produce different distance measures between the model and the image.
Reference: [R65] <author> Roberts, L. G. </author> <year> (1965). </year> <title> Machine perception of three-dimensional solids. </title> <editor> In et al, T., editor, </editor> <booktitle> Optical and Electro-Optical Information Processing. </booktitle> <publisher> M.I.T. Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Watson Research Center, Yorktown Heights, NY. 1 IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 2 objects. An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features, e.g. <ref> [R65, FB81, L85, HU87, BU93, TM87, UB91] </ref>. Since images often are noisy and models occasionally are imperfect, it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that "reasonably" aligns with the image.
Reference: [S76] <author> Strang, G. </author> <year> (1976). </year> <title> Linear algebra and its applications. </title> <publisher> Harcourt Brace Jovanovich, </publisher> <address> Orlando, Florida. </address>
Reference-contexts: Proof: The eigenvalues of the characteristic matrix B are 1 1 , 1 3 . (This is shown in Appendix E.) Since 1= 1 and 1= 2 represent the eigenvalues of a section of B it holds that (see, e.g., <ref> [S76] </ref> p. 270) 1 1 2 1 3 IEEE Trans. on Pattern Anal.
Reference: [TM87] <author> Thompson, D. W. and Mundy, J. L. </author> <year> (1987). </year> <title> Three-dimensional model matching from an unconstrained viewpoint. </title> <booktitle> In Proceedings of IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 208-220, </pages> <address> Raleigh, NC. </address>
Reference-contexts: Watson Research Center, Yorktown Heights, NY. 1 IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 2 objects. An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features, e.g. <ref> [R65, FB81, L85, HU87, BU93, TM87, UB91] </ref>. Since images often are noisy and models occasionally are imperfect, it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that "reasonably" aligns with the image.
Reference: [T87] <author> Tsai, R. </author> <year> (1987). </year> <title> A versatile camera calibration technique for high-accuracy 3d machine vision metrology using off-the-shelf tv cameras and lenses. </title> <journal> IEEE J. of Robotics and Automation, RA-3(4):323-344. </journal>
Reference-contexts: An analytic solution to the least-square distance between pairs of 2D images has not yet been found.) Consequently, numerical methods are employed (see reviews in <ref> [T87, Y89] </ref>). Such solutions often suffer from stability problems, they are computationally intensive and require a good initial guess. To avoid using numerical methods, frequently the object is allowed to undergo affine transformations instead of just rigid ones.
Reference: [U89] <author> Ullman, S. </author> <year> (1989). </year> <title> Aligning pictorial descriptions: an approach to object recognition. </title> <journal> Cognition, </journal> <volume> 32 </volume> <pages> 193-254. </pages>
Reference-contexts: Three [FB81, RBPD81, HLON91] or four [HCLL89] points are required under perspective projection, and three points under weak perspective <ref> [U89, HU87] </ref> . The obtained distance critically depends on the choice of alignment key. Different choices produce different distance measures between the model and the image.
Reference: [UB91] <author> Ullman, S. and Basri, R. </author> <year> (1991). </year> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 992-1006. </pages>
Reference-contexts: Watson Research Center, Yorktown Heights, NY. 1 IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 2 objects. An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features, e.g. <ref> [R65, FB81, L85, HU87, BU93, TM87, UB91] </ref>. Since images often are noisy and models occasionally are imperfect, it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that "reasonably" aligns with the image. <p> At least six points are required to find an affine solution under perspective projection [FB81], and four are required under orthographic projection <ref> [UB91] </ref>. The affine measure bounds the rigid measure from below. The rigid measure, however, is not bounded from above, and so the actual rigid measure may sometimes be significantly larger than the computed affine measure. This is demonstrated by the following example. <p> Machine Intel., 18 (4), 465-470, 1996 9 Since the solution in the rigid case is significantly more difficult than the solution in the affine case, often the affine solution is considered, and the rigidity constraints are used only for verification (e.g. <ref> [UB91, W93, DD92] </ref>). <p> ~y P ~r 2 k 2 s:t: ~r T 1 ~r 1 = ~r T Note first that P P + ~x and P P + ~y, two vectors in R n , both lie in a single linear subspace of dimension 3. (This follows from the fact, shown in <ref> [UB91] </ref>, that every image of a 3D object can be written as a linear combination of three independent views.) Moreover, the three columns of P lie in the same subspace.
Reference: [W93] <author> Weinshall, D. </author> <year> (1993). </year> <title> Model-based invariants for 3D vision. </title> <journal> International Journal on Computer Vision, </journal> <volume> 10(1) </volume> <pages> 27-42. </pages>
Reference-contexts: Invariant functions were IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 5 successfully used only with special kinds of models, such as planar objects (e.g., [LSW87, FMZCHR91]). More general objects can be recognized using model-based invariant functions <ref> [W93] </ref>. For noise-free data, model-based invariant functions return zero if the image is an exact instance of the object. To account for noise, the output of these functions usually is required to be below some fixed threshold. <p> Machine Intel., 18 (4), 465-470, 1996 9 Since the solution in the rigid case is significantly more difficult than the solution in the affine case, often the affine solution is considered, and the rigidity constraints are used only for verification (e.g. <ref> [UB91, W93, DD92] </ref>). <p> B is a natural extension to the 3 fi 3 model-based invariant matrix defined in <ref> [W93] </ref>. A more general definition, and its efficient computation from images, is discussed in Appendix B. 3.2 Derivation of N tr We can now define a transformation metric. Consider the affine solution.
Reference: [WT95] <author> Weinshall, D. and Tomasi, C. </author> <year> (1995). </year> <title> Linear and incremental acquisition of invariant shape models from image sequences. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(5) </volume> <pages> 512-517. </pages>
Reference-contexts: in Eq (15), and using Eq (36), we obtain B = (P + ) T P + = (Q + ) T B bas Q + The linear and incremental computation of the matrices Q and B bas from at least three images of the object points is described in <ref> [WT95] </ref>. IEEE Trans. on Pattern Anal. Machine Intel., 18 (4), 465-470, 1996 33 C Eliminating translation In this appendix we show that translation can be ignored if we set the centroids of both model and image points to be the origin.
Reference: [Y89] <author> Yuan, J. S. C. </author> <year> (1989). </year> <title> A general photogrammetric method for determining object position and orientation. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 5(2) </volume> <pages> 129-142. </pages>
Reference-contexts: An analytic solution to the least-square distance between pairs of 2D images has not yet been found.) Consequently, numerical methods are employed (see reviews in <ref> [T87, Y89] </ref>). Such solutions often suffer from stability problems, they are computationally intensive and require a good initial guess. To avoid using numerical methods, frequently the object is allowed to undergo affine transformations instead of just rigid ones.
References-found: 26

