URL: http://www-nlp.cs.umass.edu/pubs/Soderland-KDD97.ps
Refering-URL: http://ciir.cs.umass.edu/info/psfiles/tepubs/tepubs.html
Root-URL: 
Email: soderlan@cs.washington.edu  
Title: In Proceedings of Third International Conference on Knowledge Discovery and Data Mining (KDD-97) Learning to
Author: Stephen Soderland 
Note: Information  has been primarily limited to web pages that include tables of information.  A  
Address: Seattle, WA 98195-2350  
Affiliation: Dept. Computer Science Engineering University of Washington  
Abstract: There is a wealth of information to be mined from narrative text on the World Wide Web. Unfortunately, standard natural language processing (NLP) extraction techniques expect full, grammatical sentences, and perform poorly on the choppy sentence fragments that are often found on web pages. This paper 1 introduces Webfoot, a preprocessor that parses web pages into logically coherent segments based on page layout cues. Output from Webfoot is then passed on to CRYSTAL, an NLP system that learns text extraction rules from example. Webfoot and CRYSTAL transform the text into a formal representation that is equivalent to relational database entries. This is a necessary first step for knowledge discovery and other automated analysis of free text. Considerable progress has been made in natural language processing text extraction systems (Weischedel 1995) (Grishman 1995) (Krupka 1995). However, NLP techniques typically expect the text to be in the form of full, grammatical sentences. What is found on the web is often a series of brief sentence fragments such as the excerpt from a National Weather Service web page in Figure 1. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Doorenbos, R., Etzioni, O., and Weld, D. </author> <booktitle> A Scalable Comparison-Shopping Agent for the World-Wide Web In Proceedings of the First International Conference on Autonomous Agents, </booktitle> <pages> 39-48, </pages> <year> 1997. </year>
Reference: <author> Clark, P. and Niblett, T. </author> <title> The CN2 Induction Algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: Constraints: Field:: (extract Conditions) classes: Weather Condition terms: "." Field:: (extract Day) classes: Day terms: ".", "..." Field:: (extract High) terms: "HIGH", "." Coverage: 94 Errors: 1 Conditions, and High CRYSTAL uses a machine learning covering algorithm similar to Michalski's AQ algorithm (Michalski 1983) and Clark and Niblett's CN2 algorithm <ref> (Clark and Niblett 1989) </ref>. It is a supervised learning method that requires manually annotated training texts in which each reference to target concepts of the domain has been tagged. CRYSTAL begins with the most restrictive concept definitions that cover each positive training instance.
Reference: <author> Grishman, R. </author> <title> The NYU System for MUC-6 or Where's the Syntax? In Proceedings of the Sixth Message Understanding Conference, </title> <publisher> Morgan Kaufmann Publishers, </publisher> <pages> 167-175, </pages> <year> 1995. </year>
Reference: <author> Kushmerick, N., Weld, D., Doorenbos, R. </author> <title> Wrapper Induction for Information Extraction. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1997. </year>
Reference: <author> Michalski, R. S. </author> <title> A Theory and Methodology of Inductive Learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20, </volume> <pages> 111-161, </pages> <year> 1983. </year>
Reference-contexts: Concept-type Forecast ID: 459 Status: GENERALIZED Constraints: Field:: (extract Conditions) classes: Weather Condition terms: "." Field:: (extract Day) classes: Day terms: ".", "..." Field:: (extract High) terms: "HIGH", "." Coverage: 94 Errors: 1 Conditions, and High CRYSTAL uses a machine learning covering algorithm similar to Michalski's AQ algorithm <ref> (Michalski 1983) </ref> and Clark and Niblett's CN2 algorithm (Clark and Niblett 1989). It is a supervised learning method that requires manually annotated training texts in which each reference to target concepts of the domain has been tagged.
Reference: <author> Soderland, S., Fisher, D., Aseltine, J., Lehn-ert, W. </author> <title> CRYSTAL: Inducing a Conceptual Dictionary. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1314-1321, </pages> <year> 1995. </year>
Reference-contexts: This greatly expands the range of text data that can be extracted automatically from web pages. The NLP system used in these experiments is CRYSTAL, which learns domain-specific text extraction rules from examples <ref> (Soderland et al. 1995) </ref> (Soderland 1997). The remainder of this paper describes the Webfoot and CRYSTAL systems and presents empirical results for the domain of weather forecast web pages. The combination of Webfoot and CRYSTAL achieve surprisingly good performance for an NLP system operating without the aid of syntactic knowledge.
Reference: <author> Soderland, S. </author> <title> Learning Text Analysis Rules for Domain-specific Natural Language Processing. </title> <type> Ph.D. thesis, </type> <institution> technical report UM-CS-1996-087 University of Massachusetts, Amherst, </institution> <year> 1997. </year>
Reference: <author> Krupka, G. SRA: </author> <title> Description of the SRA System as Used for MUC-6. </title> <booktitle> In Proceedings of the Sixth Message Understanding Conference, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <pages> 221-236, </pages> <year> 1995. </year>
Reference: <author> Weischedel, R. </author> <title> BBN: Description of the PLUM System as Used for MUC-6. </title> <booktitle> In Proceedings of the Sixth Message Understanding Conference, </booktitle> <publisher> Morgan Kauf-mann Publishers, </publisher> <pages> 55-70, </pages> <year> 1995. </year>
References-found: 9

