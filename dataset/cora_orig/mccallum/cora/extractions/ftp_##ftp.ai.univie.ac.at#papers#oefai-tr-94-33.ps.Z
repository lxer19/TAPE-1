URL: ftp://ftp.ai.univie.ac.at/papers/oefai-tr-94-33.ps.Z
Refering-URL: http://www.ai.univie.ac.at/cgi-bin/biblio_ora?sort_by_author=yes&tailor=1&loc=0&format=ml/ml&keyword=Publications&keyword=WWW_ML&relop=/
Root-URL: 
Email: E-mail: fjuffi,johann,robertg@ai.univie.ac.at  E-mail: POLS039@cantva.canterbury.ac.nz  
Title: Machine Learning Methods for International Conflict Databases: A Case Study in Predicting Mediation Outcome  
Author: Johannes Furnkranz, Johann Petrak and Robert Trappl Jacob Bercovitch 
Note: OEFAI-TR-94-33 This work was supported by a grant of the  
Address: Schottengasse 3, A-1010 Wien  New Zealand  
Affiliation: Austrian Research Institute for Artificial Intelligence  Department of Political Science, University of Canterbury,  Austrian Federal Ministry of Science and Research  
Abstract: This paper tries to identify rules and factors that are predictive for the outcome of international conflict management attempts. We use C4.5, an advanced Machine Learning algorithm, for generating decision trees and prediction rules from cases in the CONFMAN database. The results show that simple patterns and rules are often not only more understandable, but also more reliable than complex rules. Simple decision trees are able to improve the chances of correctly predicting the outcome of a conflict management attempt. This suggests that mediation is more repetitive than conflicts per se, where such results have not been achieved so far. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bercovitch, J., J. T. Anagnoson, & D. L. </author> <title> Wille (1991). Some conceptual issues and empirical trends in the study of successful mediation in international relations. </title> <journal> Journal of Peace Research 28 (1), </journal> <pages> 7-17. </pages>
Reference-contexts: Some of the rules we have found contain aspects of previous findings with statistical analyses. Rule P1 from section 4.2 for example might in fact be considered as a special case of one of the findings of <ref> (Bercovitch, Anagnoson, and Wille 1991) </ref>, where it has been shown that as the number of fatalities increases, the likelihood that mediation initiatives will prove successful suffers a corresponding decline.
Reference: <editor> Bercovitch, J. & A. </editor> <address> Houston (1993, </address> <month> October). </month> <title> Influence of mediation characteristics and behavior on the success of mediation in international relations. Journal of Conflict Resolution 4 (4), </title> <type> 297-321. </type>
Reference-contexts: Our goal was to get very simple rules. We applied all simplification methods described in section 4.2 including feature subset selection. From the original set of variables we have manually selected ten attributes that describe the most relevant aspects (see table 9) of mediation attempts <ref> (Bercovitch and Lamare 1993) </ref>. 20 Strategy N S F % procedural 93 45 48 48.4 directive 278 146 132 52.5 communicative 215 70 145 32.6 total 586 261 325 44.5 Table 8: Mediation strategies Fatalities Mediation Environment Mediation Strategy Previous Relations of Mediator Issues Mediator Rank Table 9: Relevant features for <p> Using only fatalities for generating a decision tree would only yield 62.4% accuracy using the same grouping as in <ref> (Bercovitch and Lamare 1993) </ref>. On the other hand, the Machine Learning method has attributed a higher significance to the previous relation of the mediator (63.3%). <p> Using Machine Learning methods for a further analysis of other variables in this database is a promising topic for further research. A natural choice would be to examine the factors that influence a mediator to choose a certain mediation strategy <ref> (Bercovitch and Wells 1993) </ref>. Acknowledgements We are very grateful to Peter Billing, John C. Mallery, Dwain Mefford, Frank Pfetsch, Philip A. Schrodt, Frank L. Sherman, and Sigrid Unseld for their many helpful comments and their continuous encouragement throughout our work.
Reference: <author> Bercovitch, J. & J. W. </author> <month> Lamare </month> <year> (1993). </year> <title> The process of international mediation: An analysis of the determinants of successful and unsuccessful outcomes. </title> <journal> Australian Journal of Political Science 28, </journal> <pages> 290-305. </pages>
Reference-contexts: Our goal was to get very simple rules. We applied all simplification methods described in section 4.2 including feature subset selection. From the original set of variables we have manually selected ten attributes that describe the most relevant aspects (see table 9) of mediation attempts <ref> (Bercovitch and Lamare 1993) </ref>. 20 Strategy N S F % procedural 93 45 48 48.4 directive 278 146 132 52.5 communicative 215 70 145 32.6 total 586 261 325 44.5 Table 8: Mediation strategies Fatalities Mediation Environment Mediation Strategy Previous Relations of Mediator Issues Mediator Rank Table 9: Relevant features for <p> Using only fatalities for generating a decision tree would only yield 62.4% accuracy using the same grouping as in <ref> (Bercovitch and Lamare 1993) </ref>. On the other hand, the Machine Learning method has attributed a higher significance to the previous relation of the mediator (63.3%). <p> Using Machine Learning methods for a further analysis of other variables in this database is a promising topic for further research. A natural choice would be to examine the factors that influence a mediator to choose a certain mediation strategy <ref> (Bercovitch and Wells 1993) </ref>. Acknowledgements We are very grateful to Peter Billing, John C. Mallery, Dwain Mefford, Frank Pfetsch, Philip A. Schrodt, Frank L. Sherman, and Sigrid Unseld for their many helpful comments and their continuous encouragement throughout our work.
Reference: <author> Bercovitch, J. & J. </author> <title> Langley (1993, December). </title> <booktitle> The nature of dispute and the effectiveness of international mediation. Journal of Conflict Resolution 37 (4), </booktitle> <pages> 670-691. </pages>
Reference-contexts: Our goal was to get very simple rules. We applied all simplification methods described in section 4.2 including feature subset selection. From the original set of variables we have manually selected ten attributes that describe the most relevant aspects (see table 9) of mediation attempts <ref> (Bercovitch and Lamare 1993) </ref>. 20 Strategy N S F % procedural 93 45 48 48.4 directive 278 146 132 52.5 communicative 215 70 145 32.6 total 586 261 325 44.5 Table 8: Mediation strategies Fatalities Mediation Environment Mediation Strategy Previous Relations of Mediator Issues Mediator Rank Table 9: Relevant features for <p> Using only fatalities for generating a decision tree would only yield 62.4% accuracy using the same grouping as in <ref> (Bercovitch and Lamare 1993) </ref>. On the other hand, the Machine Learning method has attributed a higher significance to the previous relation of the mediator (63.3%). <p> Using Machine Learning methods for a further analysis of other variables in this database is a promising topic for further research. A natural choice would be to examine the factors that influence a mediator to choose a certain mediation strategy <ref> (Bercovitch and Wells 1993) </ref>. Acknowledgements We are very grateful to Peter Billing, John C. Mallery, Dwain Mefford, Frank Pfetsch, Philip A. Schrodt, Frank L. Sherman, and Sigrid Unseld for their many helpful comments and their continuous encouragement throughout our work.
Reference: <author> Bercovitch, J. & R. Wells (1993, </author> <month> January). </month> <title> Evaluating mediation strategies atheoretical and empirical analysis. </title> <type> Peace & Change 18 (1), </type> <pages> 3-25. </pages>
Reference-contexts: Our goal was to get very simple rules. We applied all simplification methods described in section 4.2 including feature subset selection. From the original set of variables we have manually selected ten attributes that describe the most relevant aspects (see table 9) of mediation attempts <ref> (Bercovitch and Lamare 1993) </ref>. 20 Strategy N S F % procedural 93 45 48 48.4 directive 278 146 132 52.5 communicative 215 70 145 32.6 total 586 261 325 44.5 Table 8: Mediation strategies Fatalities Mediation Environment Mediation Strategy Previous Relations of Mediator Issues Mediator Rank Table 9: Relevant features for <p> Using only fatalities for generating a decision tree would only yield 62.4% accuracy using the same grouping as in <ref> (Bercovitch and Lamare 1993) </ref>. On the other hand, the Machine Learning method has attributed a higher significance to the previous relation of the mediator (63.3%). <p> Using Machine Learning methods for a further analysis of other variables in this database is a promising topic for further research. A natural choice would be to examine the factors that influence a mediator to choose a certain mediation strategy <ref> (Bercovitch and Wells 1993) </ref>. Acknowledgements We are very grateful to Peter Billing, John C. Mallery, Dwain Mefford, Frank Pfetsch, Philip A. Schrodt, Frank L. Sherman, and Sigrid Unseld for their many helpful comments and their continuous encouragement throughout our work.
Reference: <author> Buchanan, B. & E. Shortliffe (Eds.) </author> <year> (1984). </year> <title> Rule-Based Expert Systems | The MYCIN Experiments of the Stanford Programming Project. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: After a discussion of the obtained results (section 5) we will summarize the most important aspects of this work in section 6. 1 2 Decision Tree Learning Rule-Based Expert Systems | like the famous MYCIN program <ref> (Buchanan and Shortliffe 1984) </ref> | were the main contributing factor to the big commercial success of Artificial Intelligence at the beginning of the 80's. These systems typically incorporate a huge number of domain-specific rules with which an inference engine is able to solve a problem.
Reference: <author> Butterworth, R. L. </author> <year> (1976). </year> <title> Managing Interstate Conflict, 1945-74: Data with Synopses. </title> <institution> Pittsburgh: University of Pittsburgh University Center for International Studies. </institution>
Reference-contexts: We have deliberately made this choice in order to illustrate the possibilites of Machine Learning without having to resort to programming skills. Schrodt (1991b) has performed similar experiments in predicting interstate conflict outcomes using the Butterworth "Interstate Security Conflicts, 1945-1974" <ref> (Butterworth 1976) </ref>. He used his own implementation of ID3, the predecessor of C4.5, to learn decision trees for predicting the effects of management efforts with respect to five different outcomes.
Reference: <author> Efron, B. </author> <year> (1982). </year> <title> The Jackknife, the Bootstrap, and Other Resampling Plans. </title> <institution> Society for Industrial and Applied Mathematics. </institution>
Reference-contexts: However, this procedure has the disadvantage that not all of the available examples can be used for learning. Another approach | bootstrapping <ref> (Efron 1982) </ref> | learns a tree from the entire set of examples and tries to estimate its accuracy by performing a high number of experiments with randomly assigned training and test sets and averaging the results. A computationally less expensive method is to perform a cross-validation (Stone 1974).
Reference: <author> Feigenbaum, E. </author> <year> (1977). </year> <title> The art of artificial intelligence 1: Themes and case studies of knowledge engineering. </title> <type> Technical Report STAN-CS-77-621, </type> <institution> Department of Computer Science, Stanford University. </institution>
Reference-contexts: These systems typically incorporate a huge number of domain-specific rules with which an inference engine is able to solve a problem. However, it was soon discovered that obtaining the rule-based knowledge from human experts is the bottleneck of expert systems <ref> (Feigenbaum 1977) </ref>. Research in Machine Learning therefore started to explore alternatives which aimed at automatically inducing the necessary knowledge from past cases. Decision tree learning algorithms are the most prominent result of this research.
Reference: <author> Hudson, V. M. </author> <year> (1991). </year> <booktitle> Artificial Intelligence and International Politics. </booktitle> <address> Boulder, </address> <publisher> CO: Westview Press. </publisher>
Reference-contexts: 1 Introduction Artificial Intelligence has lately been recognized as having some potential for supporting social scientists in political sciences <ref> (Hudson 1991) </ref>, in particular in the construction and analysis of international conflict databases. Overviews of the potential contributions and ongoing projects using AI methods for the investigation of international relations can be found in (Mallery 1988; Schrodt 1991a; Trappl 1992b; Unseld 1994).
Reference: <author> John, G. H., R. Kohavi, & K. </author> <month> Pfleger </month> <year> (1994). </year> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Machine Learning: Proceedings of the Eleventh International Conference, </booktitle> <institution> Rutgers University, </institution> <address> New Brunswick, NJ, </address> <pages> pp. 121-129. </pages> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: We report two experiments where both methods were used. The first used the default settings of C4.5, which are -m 2 and -c 25. The resulting tree is not so good. Adjusting the parameters to the domain apparently pays off, which is confirmed by <ref> (Kohavi and John 1994) </ref> where an automatic approach for finding the right values for C4.5's parameters has been investigated. In another experiment we combined the best settings of the above experiments. The 26 node tree resulting from -m 30 was simplified using the best pruning parameter tested (-c 10). <p> If C4.5 is given only a relevant subset of the possible attributes it will not be able to include irrelevant distinctions of instances near the leaves of the tree. We performed an additional experiment aimed at determining a set of relevant variables from the many variables in the database. <ref> (John, Kohavi, and Pfleger 1994) </ref> have developed a program that uses C4.5 and determines the set of attributes from which the best decision tree can be learned. <p> We have also presented a method for automatic discovery of a relevant attribute subset using a Machine Learning method <ref> (John, Kohavi, and Pfleger 1994) </ref>. Schrodt (1991b) has tried to achieve this by observing which attributes his algorithm typically selects near the root of the tree.
Reference: <author> Kohavi, R. & G. H. </author> <title> John (1994). Automatic parameter selection by minimizing estimated error. </title> <note> Submitted for publication. Available from ftp://starry.stanford.edu/pub/ronnyk/c45ap.ps. </note>
Reference-contexts: We report two experiments where both methods were used. The first used the default settings of C4.5, which are -m 2 and -c 25. The resulting tree is not so good. Adjusting the parameters to the domain apparently pays off, which is confirmed by <ref> (Kohavi and John 1994) </ref> where an automatic approach for finding the right values for C4.5's parameters has been investigated. In another experiment we combined the best settings of the above experiments. The 26 node tree resulting from -m 30 was simplified using the best pruning parameter tested (-c 10). <p> If C4.5 is given only a relevant subset of the possible attributes it will not be able to include irrelevant distinctions of instances near the leaves of the tree. We performed an additional experiment aimed at determining a set of relevant variables from the many variables in the database. <ref> (John, Kohavi, and Pfleger 1994) </ref> have developed a program that uses C4.5 and determines the set of attributes from which the best decision tree can be learned. <p> We have also presented a method for automatic discovery of a relevant attribute subset using a Machine Learning method <ref> (John, Kohavi, and Pfleger 1994) </ref>. Schrodt (1991b) has tried to achieve this by observing which attributes his algorithm typically selects near the root of the tree.
Reference: <author> Kononenko, I. & I. </author> <title> Bratko (1991). Information-based evaluation criterion for classifier's performance. </title> <booktitle> Machine Learning 6, </booktitle> <pages> 67-80. </pages> <note> 26 Mallery, </note> <author> J. C. </author> <year> (1988). </year> <title> Thinking about foreign policy: Finding an appropri-ate role for artificial intelligence computers. </title> <booktitle> Paper presented at the 1988 Annual Meeting of the International Studies Association. </booktitle>
Reference-contexts: For this reason (Schrodt 1991b) has used an entropy ratio, similar to the information score proposed in <ref> (Kononenko and Bratko 1991) </ref> which gives a higher weight to correct predictions 3 The book (Quinlan 1993) comes with the C source code of the programs. The programs are also available on disk or tape. 23 of rare classes.
Reference: <author> Mallery, J. C. </author> <year> (1994). </year> <title> Beyond correlation: Bringing artificial intelligence to events data. </title> <booktitle> International Interactions 20 (1-2), </booktitle> <pages> 101-145. </pages>
Reference: <author> Mallery, J. C. & F. L. </author> <title> Sherman (1993). Learning historical rules of major power intervention in the post-war international system. </title> <booktitle> Paper prepared for presentation at the 1993 Annual Meeting of the International Studies Association. </booktitle>
Reference-contexts: In general, dealing with single rules instead of whole trees seems to be a more promising approach. Mallery and Sherman (1993) report a variety of rules that have been learned with I 2 D <ref> (Unseld and Mallery 1993) </ref>, an improved version of ID3 that was specifically developed to deal with the structured nature of the SHERFACS dataset (Sherman 1988). However, a big problem is assessing the quality of the rules.
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell (Eds.), </editor> <booktitle> Machine Learning. An Artificial Intelligence Approach, </booktitle> <pages> pp. 463-482. </pages> <publisher> Tioga Publishing Co. </publisher>
Reference-contexts: Each subset can be characterized by the conjunction of the test conditions that the objects have to fulfill in order to arrive at this leaf. 2.2 Automated Construction of Decision Trees Decision tree learning algorithms like ID3 <ref> (Quinlan 1983) </ref> are able to construct decision trees from datasets, in which each object is described with exactly one 2 value for each of a number of variables. One of these attributes is designated as the class of the object.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <booktitle> Machine Learning 1, </booktitle> <pages> 81-106. </pages>
Reference-contexts: One of these attributes is designated as the class of the object. A small hypothetical database taken from <ref> (Quinlan 1986) </ref> is shown in figure 1. It consists of 14 observations of whether a certain person likes to take a Saturday morning walk or not.
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Finally, Machine Learning methods are already widely available. Most analyses described in this paper can be performed without significant computer background, in particular without any programming knowledge, because we have deliberately used C4.5, the best-known implemented Machine Learning tool currently available <ref> (Quinlan 1993) </ref>. This paper reports a case study where we have tried to analyze some aspects of an international conflict management database using Machine Learning methods. <p> Programs then resort to assigning the majority class or using probabilistic classification methods at the tree leaves. Simpler trees are not only more understandable, but are very often also more accurate on unseen data. For our analysis we have used the C4.5 program <ref> (Quinlan 1993) </ref> which is the direct successor of ID3. We have deliberately used an off the shelf (but state of the art) program, in order to illustrate what is possible without developing special-purpose algorithms. <p> For this reason (Schrodt 1991b) has used an entropy ratio, similar to the information score proposed in (Kononenko and Bratko 1991) which gives a higher weight to correct predictions 3 The book <ref> (Quinlan 1993) </ref> comes with the C source code of the programs. The programs are also available on disk or tape. 23 of rare classes. <p> We believe that the main contributions of this research are: * Commonly available inductive learning algorithms, in particular the C4.5 program <ref> (Quinlan 1993) </ref>, are powerful tools for data analysis. * Unsimplified rules and trees that have mostly been used in previous studies are likely to contain irrelevant tests that decrease their quality. 24 * Simple trees and rules are not only more understandable, but their use may also increase the chances of
Reference: <author> Schrodt, P. A. </author> <year> (1991a). </year> <title> Artificial intelligence and international relations: An overview. </title> <note> See Hudson (1991). </note>
Reference: <author> Schrodt, P. A. </author> <year> (1991b). </year> <title> Classification of interstate conflict outcomes using a bootstrapped ID3 algorithm. Political Analysis (2). </title>
Reference-contexts: Using the percentage of majority class examples as an evaluation is problematic, because it does not take into account the prior distribution of the examples and (if there are more than two classes) only gives information about the percentage of examples of one class. For this reason <ref> (Schrodt 1991b) </ref> has used an entropy ratio, similar to the information score proposed in (Kononenko and Bratko 1991) which gives a higher weight to correct predictions 3 The book (Quinlan 1993) comes with the C source code of the programs.
Reference: <author> Schrodt, P. A. </author> <year> (1991c). </year> <title> Pattern recognition of international event sequences: A machine learning approach. </title> <note> See Hudson (1991). </note>
Reference: <author> Sherman, F. L. </author> <year> (1988). </year> <title> Sherfacs: A new cross-paradigm, international conflict dataset. </title> <booktitle> Paper written for presentation at the 1988 annual meeting of the International Studies Association. </booktitle>
Reference-contexts: Mallery and Sherman (1993) report a variety of rules that have been learned with I 2 D (Unseld and Mallery 1993), an improved version of ID3 that was specifically developed to deal with the structured nature of the SHERFACS dataset <ref> (Sherman 1988) </ref>. However, a big problem is assessing the quality of the rules. Mallery and Sherman report the percentage of examples that are from the majority class and the total percentage of examples that are covered by a learned rule.
Reference: <author> Stone, M. </author> <year> (1974). </year> <title> Cross-validatory choice and assessment of statistical predictions. </title> <journal> Journal of the Royal Statistical Society B 36, </journal> <pages> 111-147. </pages>
Reference-contexts: A computationally less expensive method is to perform a cross-validation <ref> (Stone 1974) </ref>. A tree is learned from the entire training data, but its accuracy is estimated by splitting the available data into n subsets, learning a concept from n 1 of them and training on the n-th. This is repeated n times, such that each subset has been tested once.
Reference: <editor> Trappl, R. (Ed.) </editor> <booktitle> (1992a). Cybernetics and Systems '92, </booktitle> <address> Singapore. </address> <publisher> World Scientific. </publisher>
Reference: <author> Trappl, R. </author> <year> (1992b). </year> <title> The role of artificial intelligence in the avoidance of war. </title> <booktitle> See Trappl (1992a), </booktitle> <pages> pp. 1667-1672. </pages>
Reference: <author> Unseld, S. </author> <year> (1994, </year> <month> November). </month> <title> A selective overview of recent projects in Artificial Intelligence / International Relations. Paper prepared for the Second Workshop on the Potential Contribution of AI to the Avoidance of Crises and Wars, </title> <address> Vienna. </address>
Reference: <author> Unseld, S. D. & J. C. </author> <title> Mallery (1993). Interaction detection in complex datamodels. </title> <journal> MIT A.I. </journal> <volume> Memo No. 1298. </volume> <pages> 27 </pages>
Reference-contexts: In general, dealing with single rules instead of whole trees seems to be a more promising approach. Mallery and Sherman (1993) report a variety of rules that have been learned with I 2 D <ref> (Unseld and Mallery 1993) </ref>, an improved version of ID3 that was specifically developed to deal with the structured nature of the SHERFACS dataset (Sherman 1988). However, a big problem is assessing the quality of the rules.
References-found: 27

