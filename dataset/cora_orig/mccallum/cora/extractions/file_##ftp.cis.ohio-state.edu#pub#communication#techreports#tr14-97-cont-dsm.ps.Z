URL: file://ftp.cis.ohio-state.edu/pub/communication/techreports/tr14-97-cont-dsm.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/wormhole_pub.html
Root-URL: 
Title: How Much Does Network Contention Affect Distributed Shared Memory Performance?  
Abstract: Donglai Dai and Dhabaleswar K. Panda Technical Report OSU-CISRC-2/97-TR14 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Amza, A. L. Cox, and et al. Treadmarks: </author> <title> Shared memory computing on networks of workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems <ref> [23, 1, 19] </ref>, and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community.
Reference: [2] <author> D. C. Burger and D. A. Wood. </author> <title> Accuracy vs. Performance in Parallel Simulation of Interconnection Networks. </title> <booktitle> In Proceedings of the International Symposium on Parallel Processing, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems <ref> [2] </ref>, software DSM systems [23, 1, 19], and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community.
Reference: [3] <author> D. Dai and D. K. Panda. </author> <title> Reducing Cache Invalidation Overheads in Wormhole DSMs Using Multidestination Message Passing. </title> <booktitle> In International Conference on Parallel Processing, pages I:138-145, </booktitle> <address> Chicago, IL, </address> <month> Aug </month> <year> 1996. </year>
Reference-contexts: Other issues like memory consistency models, data pre-fetching/forwarding/updating and so on, need to be integrated 1 into the resulting designs. Our previous research <ref> [3, 4] </ref> has applied one such cost-effective collec-tive communication mechanism, i.e., multidestination message passing, to reduce the overhead of invalidations in wormhole routed DSM systems.
Reference: [4] <author> Donglai Dai and D. K. Panda. </author> <title> Efficient Schemes for Limited Directory-Based DSMs Using Multidestination Message Passing. </title> <type> Technical Report OSU-CISRC-11/96-TR61, </type> <institution> Dept. of Computer and Information Science, The Ohio State University, </institution> <month> Nov </month> <year> 1996. </year> <month> 27 </month>
Reference-contexts: Other issues like memory consistency models, data pre-fetching/forwarding/updating and so on, need to be integrated 1 into the resulting designs. Our previous research <ref> [3, 4] </ref> has applied one such cost-effective collec-tive communication mechanism, i.e., multidestination message passing, to reduce the overhead of invalidations in wormhole routed DSM systems.
Reference: [5] <author> W. J. Dally. </author> <title> Virtual Channel Flow Control. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <pages> pages 194-205, </pages> <month> Mar </month> <year> 1992. </year>
Reference-contexts: It accurately simulates the mechanisms for wormhole switching such as: distributed routing, book-keeping on channel status, and flit-level asynchronous ready/empty handshaking. For detailed information about wormhole routing, the reader is requested to refer to <ref> [5, 6, 26] </ref>. In this simulator, when a message is first injected into the network, the header flit of the message reserves the channels in the routers for the remaining 11 flits of the message, while moving forward along its path from the source to the destination.
Reference: [6] <author> W. J. Dally and C. L. Seitz. </author> <title> The Torus Routing Chip. </title> <journal> Distributed Computing, </journal> <volume> 1 </volume> <pages> 187-196, </pages> <year> 1986. </year>
Reference-contexts: It accurately simulates the mechanisms for wormhole switching such as: distributed routing, book-keeping on channel status, and flit-level asynchronous ready/empty handshaking. For detailed information about wormhole routing, the reader is requested to refer to <ref> [5, 6, 26] </ref>. In this simulator, when a message is first injected into the network, the header flit of the message reserves the channels in the routers for the remaining 11 flits of the message, while moving forward along its path from the source to the destination.
Reference: [7] <author> J. Duato. </author> <title> A New Theory of Deadlock-Free Adaptive Routing in Wormhole Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(12) </volume> <pages> 1320-1331, </pages> <year> 1993. </year>
Reference-contexts: Various network contention delays are caused by limited resources like queue sizes, injection channels, consumption channels, link contention, router contention, etc, in the system. Current and next generation networks promise to exploit performance aggressively by using different kinds of adaptive routing <ref> [7, 20, 15, 28, 32] </ref> and collective communication primitives [24], in addition to higher speed. The essence behind these communication innovations is to reduce traffic volume and network contention.
Reference: [8] <author> A. Agarwal et al. </author> <title> The MIT Alewife Machine: Architecture and Performance. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 2-13, </pages> <year> 1995. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers <ref> [8, 10, 12, 31] </ref>, estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community.
Reference: [9] <author> C. Holt et al. </author> <title> The Effects of Latency, Occupancy, and Bandwidth in Distributed Shared Memory Multiprocessors. </title> <type> Technical Report CSL-TR-95-660, </type> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: Research towards reducing network latency has been largely left to the (interconnection) network community. However, most recently, several papers <ref> [18, 9, 31] </ref> have reported that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating some of the above techniques. Under a closer examination, it can be observed that network latency contains two components: minimal communication latency and contention delays.
Reference: [10] <author> D. Lenoski et al. </author> <title> The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers <ref> [8, 10, 12, 31] </ref>, estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community. <p> On a memory block access, the first word of the block is returned in 30 processor cycles (150 ns). The successive words in the block follow in a pipelining fashion. The machine is assumed to be using a full-mapped, invalidation-based, three-state directory coherence protocol <ref> [12, 10] </ref>. The node simulator models the internal structures, and the queuing and contention at the node controller, main memory, and cache. The sizes of the queues between the internal structures and the appropriate actions taken if a queue is full are shown in Table 1.
Reference: [11] <author> D. Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models <ref> [11] </ref>, data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29]. <p> In order to avoid deadlocks, usually two separate (physical or virtual) networks are used, one for request messages and the other for response messages. For more information about request and response messages, and the associated deadlock scenarios, the reader is requested to refer to <ref> [11, 12] </ref>. Let us consider the transmission of a message from one node to another, as illustrated in Fig. 1. Various resources are required for this to succeed. First, space must be available for the message to be constructed in the sending buffer at the sender's network interface.
Reference: [12] <author> J. Kuskin et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <year> 1994. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers <ref> [8, 10, 12, 31] </ref>, estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community. <p> We consider a system architecture similar to the FLASH system <ref> [12] </ref>. Our simulator models the processor, cache, and memory access references at an instruction level and models the network at a flit transfer level. The evaluations are based on four representative applications ported from the SPLASH2 suite [13]. <p> In order to avoid deadlocks, usually two separate (physical or virtual) networks are used, one for request messages and the other for response messages. For more information about request and response messages, and the associated deadlock scenarios, the reader is requested to refer to <ref> [11, 12] </ref>. Let us consider the transmission of a message from one node to another, as illustrated in Fig. 1. Various resources are required for this to succeed. First, space must be available for the message to be constructed in the sending buffer at the sender's network interface. <p> DSM simulation implementation which we used for collecting all the results presented in this paper. 4 Simulation Environment In order to apply above methodology for evaluating the impact of network contention in a DSM system, we simulate a machine with an architecture and coherence protocol similar to the FLASH machine <ref> [12] </ref> but with some important differences described later. In this section, we first describe the important details of the simulated processing node and each of the network models that are used, and then briefly discuss the applications in our experiments. <p> On a memory block access, the first word of the block is returned in 30 processor cycles (150 ns). The successive words in the block follow in a pipelining fashion. The machine is assumed to be using a full-mapped, invalidation-based, three-state directory coherence protocol <ref> [12, 10] </ref>. The node simulator models the internal structures, and the queuing and contention at the node controller, main memory, and cache. The sizes of the queues between the internal structures and the appropriate actions taken if a queue is full are shown in Table 1.
Reference: [13] <author> S. C. Woo et al. </author> <title> The SPLASH-2 Programs: Chracterization and Methodological Considerations. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <pages> pages 24-36, </pages> <year> 1995. </year>
Reference-contexts: We consider a system architecture similar to the FLASH system [12]. Our simulator models the processor, cache, and memory access references at an instruction level and models the network at a flit transfer level. The evaluations are based on four representative applications ported from the SPLASH2 suite <ref> [13] </ref>. For an 8 fi 8 system, the results show that network contention can degrade overall performance of DSM applications by up to 60%. <p> Table 5 gives the basic traffic pattern and input sizes for the various applications. These applications are well-structured and heavily optimized for DSM machines. For more information about the applications, the reader is requested to refer to <ref> [13] </ref>. Barnes is an application representative of the class of hierarchical N-body methods, used in astrophysics, electrostatics, and plasma physics, among others. In this application, a globally shared space-motion-mass tree (its primary data structure) is continually reconstructed and repartitioned at every time-step.
Reference: [14] <author> S. K. Reinhardt et al. </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers. </title> <booktitle> In ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 48-60, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The original WWT <ref> [14] </ref> is a parallel DSM simulator developed by the Wisconsin Wind Tunnel research group. In this simulator, a constant network latency of 100 processor cycles is assigned for every message independent of the length of the message, the distance traveled, and other traffic in the network. <p> To achieve these goals, we construct a series of three network models as described below. 3.1 No-Contention Network Model (NCM) This model is an enhancement of the network model used in the original WWT simulator <ref> [14] </ref>. It assumes: 1) infinite number of sending buffers, 2) infinite number of injection channels, 3) infinite number of consumption channels, 4) infinite number of receiving buffers, and 5) no traffic interference inside the network. These assumptions guarantee that no network contention can ever occur during any communication.
Reference: [15] <author> C. J. Glass and L. Ni. </author> <title> Maximally Fully Adaptive Routing in 2D Meshes. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages I:101-104, </pages> <year> 1992. </year>
Reference-contexts: Various network contention delays are caused by limited resources like queue sizes, injection channels, consumption channels, link contention, router contention, etc, in the system. Current and next generation networks promise to exploit performance aggressively by using different kinds of adaptive routing <ref> [7, 20, 15, 28, 32] </ref> and collective communication primitives [24], in addition to higher speed. The essence behind these communication innovations is to reduce traffic volume and network contention.
Reference: [16] <author> M. Heinrich, J. Kuskin, and Others. </author> <title> The performance impact of flexibility in the stanford flash multiprocessor. </title> <booktitle> In The sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: In this simulator, a constant network latency of 100 processor cycles is assigned for every message independent of the length of the message, the distance traveled, and other traffic in the network. A DSM simulator used in the Stanford FLASH <ref> [16] </ref> research group models the network with slightly higher accuracy| network interfaces are modeled in this simulator. The network latency of every message is calculated based on the length of the message and half of the diameter of the network. <p> The network propagation time is a function of both the length and the distance traveled by the message. 3.2 Interface Only Network Model (NIM) The NIM model is an enhancement of the network model used in the FLASH project <ref> [16] </ref>. The NIM model simulates detailed management of the limited number of sending buffers, receiving buffers, injection channels, and consumption channels. The NIM model still assumes no traffic interference inside the network. Such a model captures the types of contention occurring within a network interface. <p> To illustrate how the parameters in Table 2 get translated into the times in Table 3, we show the time breakdown of contention-free remote read miss to a neighboring home node in Table 4. These memory latencies are comparable to the latencies presented in <ref> [22, 16] </ref>, reflecting the accuracy of our simulations. 4.3 Applications We use four applications | Barnes, LU, Radix, and Water in our simulation evaluation. All these are real applications and challenging computational kernels ported from the widely used SPLASH2 suite.
Reference: [17] <author> J. L. Hennessy and D. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Mor-gan Kaufmann, </publisher> <year> 1990. </year> <month> 28 </month>
Reference-contexts: The cache is assumed to operate in dual-port mode using write-back and write-allocate policies. The instruction latencies, issue rules, and memory interface are modeled based on the DLX design <ref> [17] </ref>. The memory bus is assumed to be 8 bytes wide. On a memory block access, the first word of the block is returned in 30 processor cycles (150 ns). The successive words in the block follow in a pipelining fashion.
Reference: [18] <author> C. Holt, J. P. Singh, and J. Hennessy. </author> <title> Application and Architectural Bottlenecks in Large Scale Distributed Shared Memory Machines. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 134-145, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Research towards reducing network latency has been largely left to the (interconnection) network community. However, most recently, several papers <ref> [18, 9, 31] </ref> have reported that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating some of the above techniques. Under a closer examination, it can be observed that network latency contains two components: minimal communication latency and contention delays. <p> The node simulator models the internal structures, and the queuing and contention at the node controller, main memory, and cache. The sizes of the queues between the internal structures and the appropriate actions taken if a queue is full are shown in Table 1. Following the assumptions in <ref> [18] </ref>, the node controller incurs a small fixed occupancy for purely generating a request message into the network. The same occupancy is also incurred for receiving a response message from the network.
Reference: [19] <author> Yousef Khalidi and Umakishore Ramachandran. </author> <title> An Implementation of Distributed Shared Memory. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(5) </volume> <pages> 443-464, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems <ref> [23, 1, 19] </ref>, and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community.
Reference: [20] <author> J. H. Kim and A. A. Chien. </author> <title> An Evaluation of Planar-Adaptive Routing (PAR). </title> <booktitle> In Proceedings of the Symposium on Parallel and Distributed Pro cessing, </booktitle> <pages> pages 470-478, </pages> <year> 1992. </year>
Reference-contexts: Various network contention delays are caused by limited resources like queue sizes, injection channels, consumption channels, link contention, router contention, etc, in the system. Current and next generation networks promise to exploit performance aggressively by using different kinds of adaptive routing <ref> [7, 20, 15, 28, 32] </ref> and collective communication primitives [24], in addition to higher speed. The essence behind these communication innovations is to reduce traffic volume and network contention.
Reference: [21] <author> D. A. Koufaty, X. Chen, D. K. Poulsen, and J. Torrellas. </author> <title> Data Forwarding in Scalable Shared-Memory Multiprocessors. </title> <booktitle> In ACM International Conference on Supercomputing, </booktitle> <pages> pages 255-264, </pages> <year> 1995. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating <ref> [21] </ref>, remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community.
Reference: [22] <author> D. Lenoski, J. Laudon, T. Joe, D. Nakahira, L. Stevens, A. Gupta, and J. Hennessy. </author> <title> The DASH Prototype: Logic Overhead and Performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(1) </volume> <pages> 41-61, </pages> <month> Jan </month> <year> 1993. </year>
Reference-contexts: To illustrate how the parameters in Table 2 get translated into the times in Table 3, we show the time breakdown of contention-free remote read miss to a neighboring home node in Table 4. These memory latencies are comparable to the latencies presented in <ref> [22, 16] </ref>, reflecting the accuracy of our simulations. 4.3 Applications We use four applications | Barnes, LU, Radix, and Water in our simulation evaluation. All these are real applications and challenging computational kernels ported from the widely used SPLASH2 suite.
Reference: [23] <author> K. Li and P. Hudak. </author> <title> Memory Coherence in Shared Virtual Memory Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <month> November </month> <year> 1989. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems <ref> [23, 1, 19] </ref>, and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community.
Reference: [24] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> Mar </month> <year> 1994. </year>
Reference-contexts: Current and next generation networks promise to exploit performance aggressively by using different kinds of adaptive routing [7, 20, 15, 28, 32] and collective communication primitives <ref> [24] </ref>, in addition to higher speed. The essence behind these communication innovations is to reduce traffic volume and network contention.
Reference: [25] <author> T. Mowry and A. Gupta. </author> <title> Tolerating Latency Through Software-Controlled Prefetching in Shared-Memory Multiprocessor. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <month> June </month> <year> 1991. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models [11], data pre-fetching <ref> [25] </ref>, data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29].
Reference: [26] <author> L. Ni and P. K. McKinley. </author> <title> A Survey of Wormhole Routing Techniques in Direct Networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 62-76, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: The principle of this methodology can be used to investigate one or more types of network contention in a DSM system. 2 We perform an in-depth quantitative analysis on network contention for a CC-NUMA architecture using a 2D wormhole <ref> [26] </ref> mesh interconnection network. We consider a system architecture similar to the FLASH system [12]. Our simulator models the processor, cache, and memory access references at an instruction level and models the network at a flit transfer level. <p> A load/store miss stalls the processor until the first word of data is returned. 4.2 Implementing Network Models We assume the processing nodes in the machine are connected with a pair of virtual networks sharing a physical 2D 8 fi 8 wormhole network <ref> [26] </ref>. The physical network is assumed to operate at a frequency of 200 MHz. The method adopted for modeling the network by each of the network simulators is described in detail in following three subsections. 4.2.1 No-Contention Network Model (NCM) The NCM network simulator is quite simple. <p> It accurately simulates the mechanisms for wormhole switching such as: distributed routing, book-keeping on channel status, and flit-level asynchronous ready/empty handshaking. For detailed information about wormhole routing, the reader is requested to refer to <ref> [5, 6, 26] </ref>. In this simulator, when a message is first injected into the network, the header flit of the message reserves the channels in the routers for the remaining 11 flits of the message, while moving forward along its path from the source to the destination.
Reference: [27] <author> W. Oed. </author> <title> Massively Parallel Processor System Cray T3D. </title> <institution> Cray Research GmbH, </institution> <year> 1993. </year>
Reference-contexts: Almost all of these evaluations are based on the assumption of a point-to-point communication network with some fixed (constant or a function of the network diameter) latency. Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations <ref> [27] </ref>, integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community.
Reference: [28] <author> G. D. Pifarre, L. Gravano, S. A. Felperin, and J. Sanz. </author> <title> Fully Adaptive Minimal Deadlock-Free Routing in Hypercubes, Meshes, and Other Networks: Algorithms and Simulations. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(3) </volume> <pages> 247-263, </pages> <year> 1994. </year>
Reference-contexts: Various network contention delays are caused by limited resources like queue sizes, injection channels, consumption channels, link contention, router contention, etc, in the system. Current and next generation networks promise to exploit performance aggressively by using different kinds of adaptive routing <ref> [7, 20, 15, 28, 32] </ref> and collective communication primitives [24], in addition to higher speed. The essence behind these communication innovations is to reduce traffic volume and network contention.
Reference: [29] <author> Xiaohan Qin and Jean-Loup Baer. </author> <title> On the Use and Performance of Explicit Communication Primitives in Cache-coherent Multiprocessor Systems. </title> <booktitle> In Proceedings of the Third International Symposium on High Performance Computer Architecture, </booktitle> <month> February </month> <year> 1997. </year> <month> 29 </month>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers [8, 10, 12, 31], estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives <ref> [29] </ref>. Research towards reducing network latency has been largely left to the (interconnection) network community. However, most recently, several papers [18, 9, 31] have reported that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating some of the above techniques.
Reference: [30] <author> S. K. Reinhardt, J. R. Larus, and D. A. Wood. Tempest and Typhoon: </author> <title> User-Level Shared Memory. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 325-337, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The network latency of every message is calculated based on the length of the message and half of the diameter of the network. The Typhoon <ref> [30, 31] </ref> simulator from the same Wisconsin Wind Tunnel group models the network interface and assigns 100 processor cycles to every message as the delay of the message inside the network. None of these DSM simulators has modeled the channel contention or physical link contention.
Reference: [31] <author> S. K. Reinhardt, R. W. Pfile, and D. A. Wood. </author> <title> Decoupled Hardware Support for Distributed Shared Memory. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Representative examples include various memory consistency models [11], data pre-fetching [25], data forwarding/updating [21], remote get/put operations [27], integrated or decoupled protocol controllers <ref> [8, 10, 12, 31] </ref>, estimating accuracy vs. performance in simulating DSM systems [2], software DSM systems [23, 1, 19], and explicit communication primitives [29]. Research towards reducing network latency has been largely left to the (interconnection) network community. <p> Research towards reducing network latency has been largely left to the (interconnection) network community. However, most recently, several papers <ref> [18, 9, 31] </ref> have reported that network latency is becoming a key architectural bottleneck in designing large scale DSM systems after integrating some of the above techniques. Under a closer examination, it can be observed that network latency contains two components: minimal communication latency and contention delays. <p> The network latency of every message is calculated based on the length of the message and half of the diameter of the network. The Typhoon <ref> [30, 31] </ref> simulator from the same Wisconsin Wind Tunnel group models the network interface and assigns 100 processor cycles to every message as the delay of the message inside the network. None of these DSM simulators has modeled the channel contention or physical link contention. <p> The parameters used in our simulation for these network delays are listed in Table 2. However, for a simple three-state directory-based coherence protocol, such an implementation will cause memory inconsistency due to the non-FIFO delivery between a source and destination pair. Following the method described in <ref> [31] </ref>, we modeled additional end-to-end flow control to guarantee the FIFO property of message delivery between each pair of nodes.
Reference: [32] <author> J. H. Upadhyay, V. Varavithya, and P. Mohapatra. </author> <title> Efficient and Balanced Adaptive Routing in Two-Dimensional Meshes. </title> <booktitle> In International Symposium on High Performance Computer Architecture, </booktitle> <pages> pages 112-121, </pages> <year> 1995. </year> <month> 30 </month>
Reference-contexts: Various network contention delays are caused by limited resources like queue sizes, injection channels, consumption channels, link contention, router contention, etc, in the system. Current and next generation networks promise to exploit performance aggressively by using different kinds of adaptive routing <ref> [7, 20, 15, 28, 32] </ref> and collective communication primitives [24], in addition to higher speed. The essence behind these communication innovations is to reduce traffic volume and network contention.
References-found: 32

