URL: ftp://theory.lcs.mit.edu/pub/people/oded/soft.ps
Refering-URL: http://theory.lcs.mit.edu/~oded/cryptography.html
Root-URL: 
Title: Software Protection and Simulation on Oblivious RAMs  
Author: Oded Goldreich Rafail Ostrovsky 
Abstract: Software protection is one of the most important issues concerning computer practice. There exist many heuristics and ad-hoc methods for protection, but the problem as a whole has not received the theoretical treatment it deserves. In this paper we provide theoretical treatment of software protection. We reduce the problem of software protection to the problem of efficient simulation on oblivious RAM. A machine is oblivious if the sequence in which it accesses memory locations is equivalent for any two inputs with the same running time. For example, an oblivious Turing Machine is one for which the movement of the heads on the tapes is identical for each computation. (Thus, the movement is independent of the actual input.) What is the slowdown in the running time of a machine, if it is required to be oblivious? In 1979 Pippenger and Fischer showed how a two-tape oblivious Turing Machine can simulate, on-line, a one-tape Turing Machine, with a logarithmic slowdown in the running time. We show an analogous result for the random-access machine (RAM) model of computation. In particular, we show how to do an on-line simulation of an arbitrary RAM by a probabilistic oblivious RAM with a poly-logarithmic slowdown in the running time. On the other hand, we show that a logarithmic slowdown is a lower bound. fl This paper unifies and extends abstracts of [G] and [Ost]. y Current Address: Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot, Israel. e-mail: oded@wisdom.weizmann.AC.IL z University of California at Berkeley and International Computer Science Institute at Berkeley. Supported by an NSF postdoctoral fellowship and ICSI. Part of this work was done at MIT. e-mail: rafail@cs.berkeley.edu 
Abstract-found: 1
Intro-found: 1
Reference: [AHU] <author> Aho, A.V., J.E. Hopcroft, and J.D. Ullman, </author> <title> "The Design and Analysis of Computer Algorithms" Addison-Wesley Publ. </title> <publisher> Co., </publisher> <year> 1974 </year>
Reference-contexts: Subsections 2.2 and 2.3 can be read independently of each other. 2.1 RAMs as Interactive Machines 2.1.1 The Basic Model Our concept of a RAM is the standard one (e.g., as presented in <ref> [AHU] </ref>). However, we decouple the RAM into two interactive machines, the CPU and the memory module, and explicitly discuss the interaction between the two. We begin with a definition of Interactive Turing-Machine (itm). The basic formulation is due to Manuel Blum (private communication in [GMR]).
Reference: [AKS] <author> Ajtai, M., J. Komlos, and E. </author> <title> Szemeredi "An O(n log n) Sorting Network" STOC 83. </title>
Reference-contexts: As explained above, this is implemented by binary search for 14 The simplicity of Batcher sorting network is the main reason we prefer it (in practice) upon the asymp totically superior Ajtai-Komlos-Szemeredi sorting network <ref> [AKS] </ref>. 28 the tag t (i). (2c) If f ound = true then the oblivious RAM accesses the word with tag (m + count) (which is a "dummy"). <p> ` log 2 2 ` actual accesses (to fixed locations independent of the sorted values), where ` is the number of words in the array. (We remark again that the above uses the Batcher Sorting Network [Bat], whereas, for a asymptotically superior result, one may use the AKS Sorting Network <ref> [AKS] </ref> yielding O (` log `) actual accesses.) (H1) Write all words of both buffers into one (temporary) array of 3mn words, denoted C. (Recall the above two buffers contain n + 2n = 3n buckets each containing m words.
Reference: [AKS2] <author> Ajtai, M., J. Komlos, and E. Szemeredi, "Halvers and Expanders", </author> <note> FOCS , 1992. </note>
Reference-contexts: One obvious thing is to keep some of the smaller buffers inside the cpu rather than in unprotected memory. Another saving is possible when basing the Oblivious Sorting on a sorting network with components that may sort several elements rather than two (cf., <ref> [AKS2] </ref>). 5.7 Making Hierarchical Simulation Time-Labeled In order to establish the Furthermore Claus of Theorem 3, we need to make our simulation time-labeled. (This is needed in order to be able to invoke Theorem 2.) Recall that the simulation is time-labeled if there exists a linear space computable function Q (;
Reference: [ACGS] <author> Alexi, W., B Chor, O Goldreich, and C.P Schnorr, </author> <title> "RSA and Rabin Functions: Certain Parts Are As Hard As The Whole", </title> <note> SIAM Jour on Computing, Extended Abstract in Proc 25th FOCS, </note> <year> 1984. </year>
Reference: [Bat] <author> Batcher, K. </author> <booktitle> "Sorting Networks and their Applications" AFIPS Spring Joint Computer Conference 32, </booktitle> <year> 1968, </year> <pages> pp. 307-314. </pages>
Reference-contexts: The crucial condition is that the RAM which executes the sorting can store only a fixed number of values (say 2) at a time. The idea is to "implement" Batcher's Sorting Network <ref> [Bat] </ref>, which allows one to sort n elements by performing n dlog 2 ne 2 comparisons. Each comparison is "implemented" by accessing both corresponding words, reading their contents, and then writing these values back in the desired order. <p> Yet, each of these oblivious sorting procedures can be implemented while making ` log 2 2 ` actual accesses (to fixed locations independent of the sorted values), where ` is the number of words in the array. (We remark again that the above uses the Batcher Sorting Network <ref> [Bat] </ref>, whereas, for a asymptotically superior result, one may use the AKS Sorting Network [AKS] yielding O (` log `) actual accesses.) (H1) Write all words of both buffers into one (temporary) array of 3mn words, denoted C. (Recall the above two buffers contain n + 2n = 3n buckets each
Reference: [Be] <author> Best, R. </author> <title> "Microprocessor for Executing Encrypted Programs" US Patent 4,168396 Issued September 1979. </title>
Reference-contexts: Of course, the more hardware we must physically protect, the more expensive our 3 solution is. Hence, we must also consider what is the minimal amount of physically protected hardware that we really need. It has been suggested <ref> [Be, K] </ref> to protect software against duplication by selling a a Software-Hardware-package (SH-package) consisting of a physically shielded Central Processing Unit (CPU) and an encrypted program. The CPU will contain a small ROM (Read-Only Memory unit) which stores the corresponding decryption key. <p> We note that the technology to physically shield (at least to some degree) the CPU (which, in practice, is a single computer chip) does already exist indeed, every ATM bank machine has such a protected chip. Thus, the SH-package employs feasible software and hardware measures <ref> [Be, K] </ref>. Using encryption to keep the contents of the memory secret is certainly a step in the right direction. However, as we will shortly see, this does not provide the protection one may want.
Reference: [B] <author> M. Blum, </author> <title> "Designing programs to check their work" manuscript. </title>
Reference-contexts: Another application of our technique is for data-structure checking as treated in [BEGKN] (which in turn follows Blum's notion of program checking as introduced in <ref> [B, BK] </ref>). In this setting it is desirable to maintain a data-structure while using only a small amount of reliable memory. Most of the data-structure is to maintained on an unreliable memory which can be thought of as being tampered with by an adversary.
Reference: [BK] <author> M. Blum., and S. Kannan., </author> <title> "Program correctness checking... and the design of programs that check their work" STOC 89 </title>
Reference-contexts: Another application of our technique is for data-structure checking as treated in [BEGKN] (which in turn follows Blum's notion of program checking as introduced in <ref> [B, BK] </ref>). In this setting it is desirable to maintain a data-structure while using only a small amount of reliable memory. Most of the data-structure is to maintained on an unreliable memory which can be thought of as being tampered with by an adversary.
Reference: [BEGKN] <author> M. Blum, W. Evans, P. Gemmell, S. Kannan M. </author> <title> Naor "Checking the Correctness of Memories" FOCS 91. </title>
Reference-contexts: A telling special case of their setting consists of 2n parties wishing to communicate concurrently, in n disjoint pairs, and wanting to hide information regarding the matching (the pairing). Another application of our technique is for data-structure checking as treated in <ref> [BEGKN] </ref> (which in turn follows Blum's notion of program checking as introduced in [B, BK]). In this setting it is desirable to maintain a data-structure while using only a small amount of reliable memory. <p> Most of the data-structure is to maintained on an unreliable memory which can be thought of as being tampered with by an adversary. The goal is to provide a mechanism for checking the integrity of the data so stored. As observed by Blum et. al. <ref> [BEGKN] </ref>, an oblivious simulation of RAM certainly solves the general problem (i.e., protecting any "data structure"), however it is somewhat of an over-kill and a more efficient solution is given in [BEGKN]. <p> As observed by Blum et. al. <ref> [BEGKN] </ref>, an oblivious simulation of RAM certainly solves the general problem (i.e., protecting any "data structure"), however it is somewhat of an over-kill and a more efficient solution is given in [BEGKN]. Further efficiency improvements are possible for particular data structures, such as ques and stacks, and indeed Blum et. al. [BEGKN] provide such solutions. 48 Acknowledgments The authors wish to thank Leonid Levin for introducing them to one another. <p> an oblivious simulation of RAM certainly solves the general problem (i.e., protecting any "data structure"), however it is somewhat of an over-kill and a more efficient solution is given in <ref> [BEGKN] </ref>. Further efficiency improvements are possible for particular data structures, such as ques and stacks, and indeed Blum et. al. [BEGKN] provide such solutions. 48 Acknowledgments The authors wish to thank Leonid Levin for introducing them to one another. The second author wishes to thank Silvio Micali, his Ph.D. advisor, for his generous help and his wise counsel.
Reference: [BM] <author> Blum, M., and S. Micali, </author> <title> "How to Generate Cryptographically Strong Sequences of Pseudorandom Bits", </title> <journal> SIAM J. on Comput., </journal> <volume> Vol. 13, </volume> <year> 1984, </year> <pages> pp. 850-864. </pages>
Reference-contexts: To derive results 8 for the more realistic model of a probabilistic RAM, we replace the random oracle used in the above theorems, by a pseudorandom function. The latter can be implemented, assuming the existence of one-way functions (cf. <ref> [BM, Y, ILL, H] </ref> and [GGM]), by using a short randomly chosen seed and the results remain valid with respect to adversaries running in time polynomial in the length of this seed. Our construction yields a technique of efficiently hiding the access pattern into any data-structure. <p> Detailed comments concerning such implementations will be given in the corresponding sections. Here, we merely recall that pseudo-random functions can be constructed using pseudo-random generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali <ref> [BM] </ref>, Yao [Y], Impagliazzo et. al. [ILL], and Hastad [H]).
Reference: [CW] <author> J.L. Carter J.L. and M. N. </author> <title> Wegman "Universal Classes of Hash Functions" Journal of Computer and System Sciences 18 (1979), </title> <journal> pp. </journal> <pages> 143-154. 49 </pages>
Reference: [G] <author> Goldreich, O. </author> <title> "Towards a Theory of Software Protection and simulation by Obliv--ious RAMs" STOC 87 </title> . 
Reference-contexts: An over-simplified approach is to first consider simulating a RAM by a "even more powerful RAM" which can hold f (m) words in its internal registers, where f is a suitably selected function, and then to recurse. This approach does improve over the p m overhead (cf., <ref> [G] </ref>), but falls short of obtaining a polylogarithmic overhead. Our polylogarithmic solution is based on storing the virtual memory in a random-hash table, rather than as a randomly sorted array and to recurse more carefully. However, we believe that an explicit presentation which avoids recursion is more clear.
Reference: [GO] <author> Goldreich, O. and R. </author> <title> Ostrovsky "Comprehensive Software Protection System" U.S. Patent, Serial No. </title> <publisher> 07/395.882. </publisher>
Reference: [GGM] <author> Goldreich, O., S. Goldwasser, and S. Micali, </author> <title> "How To Construct Random Functions," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> Vol. 33, No. 4 (Octo-ber 1986), </volume> <pages> 792-807. </pages>
Reference-contexts: There are two issues: The first issue is to hide from the adversary the values stored and retrieved from memory, and to prevent the adversary's attempts to change these values. This is done by use of traditional cryptographic techniques (e.g., probabilistic encryption [GM] and message authentication <ref> [GGM] </ref>). The second issue is to hide (from the adversary) the sequence of addresses accessed during the execution (hereafter referred as hiding the access pattern). Hiding the (original) memory access pattern is a completely new problem and traditional cryptographic techniques are not applicable to it. <p> To derive results 8 for the more realistic model of a probabilistic RAM, we replace the random oracle used in the above theorems, by a pseudorandom function. The latter can be implemented, assuming the existence of one-way functions (cf. [BM, Y, ILL, H] and <ref> [GGM] </ref>), by using a short randomly chosen seed and the results remain valid with respect to adversaries running in time polynomial in the length of this seed. Our construction yields a technique of efficiently hiding the access pattern into any data-structure. <p> Detailed comments concerning such implementations will be given in the corresponding sections. Here, we merely recall that pseudo-random functions can be constructed using pseudo-random generators (cf. Goldreich et. al. <ref> [GGM] </ref>), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao [Y], Impagliazzo et. al. [ILL], and Hastad [H]). <p> At this point, the reader may be annoyed by the fact that the transformation produces a random function f which may have an unbounded (or "huge") description. However, in practice, the function f will be pseudo-random <ref> [GGM] </ref>, and will have a succinct description as discussed in the Introduction. <p> We stress that the above theorem holds in the information-theoretic sense on a probabilistic-RAM (which uses a random oracle.) As noted in the Introduction, instead of random oracle we can use pseudo-random functions <ref> [GGM] </ref>, and state a practical analogue of the above theorem. <p> 44 Proof : We start by assuming, for simplicity, that there exists one-way functions which can be computed in linear space. (This follows from the existence of arbitrary one-way functions but a trivial padding argument.) Next, we invoke the constructions of Hastad et. al. [H, ILL] and Goldreich et. al. <ref> [GGM] </ref> to obtain a family of pseudorandom functions. We note that the resulting pseudorandom functions will be also computable in linear space. Using the compiler of Theorem 4, we replace all calls to the random oracle by computations of a uniformly selected (and fixed) pseudo-random function.
Reference: [GM] <author> Goldwasser S., and S. Micali, </author> <title> "Probabilistic Encryption" Jour. </title> <journal> of Computer and System Science, </journal> <volume> Vol. 28, No. 2, </volume> <year> 1984, </year> <pages> pp. 270-299. </pages>
Reference-contexts: When timed-out, the fake CPU (magically) writes to the memory the same 1 In this paper, we shall use standard notion of computational indistinguishability, as defined in <ref> [GM] </ref> and [Y]. output that the genuine CPU would have written on the "real" program (and the same input). We stress that, in the general case, the adversary may modify the communication between CPU and memory (as well as modify the contents of memory cells) in any way he wants. <p> There are two issues: The first issue is to hide from the adversary the values stored and retrieved from memory, and to prevent the adversary's attempts to change these values. This is done by use of traditional cryptographic techniques (e.g., probabilistic encryption <ref> [GM] </ref> and message authentication [GGM]). The second issue is to hide (from the adversary) the sequence of addresses accessed during the execution (hereafter referred as hiding the access pattern). Hiding the (original) memory access pattern is a completely new problem and traditional cryptographic techniques are not applicable to it.
Reference: [GMR] <author> S. Goldwasser, S. Micali and C. Rackoff, </author> <title> The Knowledge Complexity of Interactive Proof-Systems, </title> <booktitle> STOC 1985, ACM, </booktitle> <pages> pp. 291-304. </pages>
Reference-contexts: However, we decouple the RAM into two interactive machines, the CPU and the memory module, and explicitly discuss the interaction between the two. We begin with a definition of Interactive Turing-Machine (itm). The basic formulation is due to Manuel Blum (private communication in <ref> [GMR] </ref>). We augment this basic formulation by adding explicit bounds on the length of "messages" and on the size of work tape. <p> To this end, we define both the cpu and the memory as itms, 11 and associate the read-only communication tape of the cpu with the write-only communica-tion tape of the memory, and vice versa (cf. <ref> [GMR] </ref>). In addition, both cpu and memory will have the same message length (i.e., the parameter c above), however they will have drastically different work-tape size and different finite control.
Reference: [H] <author> Hastad, J., </author> <title> "Pseudo-Random Generators under Uniform Assumptions", </title> <note> STOC 90 </note> . 
Reference-contexts: To derive results 8 for the more realistic model of a probabilistic RAM, we replace the random oracle used in the above theorems, by a pseudorandom function. The latter can be implemented, assuming the existence of one-way functions (cf. <ref> [BM, Y, ILL, H] </ref> and [GGM]), by using a short randomly chosen seed and the results remain valid with respect to adversaries running in time polynomial in the length of this seed. Our construction yields a technique of efficiently hiding the access pattern into any data-structure. <p> Here, we merely recall that pseudo-random functions can be constructed using pseudo-random generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao [Y], Impagliazzo et. al. [ILL], and Hastad <ref> [H] </ref>). <p> size of the cpu's protected registers.) 44 Proof : We start by assuming, for simplicity, that there exists one-way functions which can be computed in linear space. (This follows from the existence of arbitrary one-way functions but a trivial padding argument.) Next, we invoke the constructions of Hastad et. al. <ref> [H, ILL] </ref> and Goldreich et. al. [GGM] to obtain a family of pseudorandom functions. We note that the resulting pseudorandom functions will be also computable in linear space.
Reference: [ILL] <author> R. Impagliazzo, R., L. Levin, and M. </author> <title> Luby "Pseudo-Random Generation from One-Way Functions," </title> <note> STOC 89. </note>
Reference-contexts: To derive results 8 for the more realistic model of a probabilistic RAM, we replace the random oracle used in the above theorems, by a pseudorandom function. The latter can be implemented, assuming the existence of one-way functions (cf. <ref> [BM, Y, ILL, H] </ref> and [GGM]), by using a short randomly chosen seed and the results remain valid with respect to adversaries running in time polynomial in the length of this seed. Our construction yields a technique of efficiently hiding the access pattern into any data-structure. <p> Here, we merely recall that pseudo-random functions can be constructed using pseudo-random generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao [Y], Impagliazzo et. al. <ref> [ILL] </ref>, and Hastad [H]). <p> size of the cpu's protected registers.) 44 Proof : We start by assuming, for simplicity, that there exists one-way functions which can be computed in linear space. (This follows from the existence of arbitrary one-way functions but a trivial padding argument.) Next, we invoke the constructions of Hastad et. al. <ref> [H, ILL] </ref> and Goldreich et. al. [GGM] to obtain a family of pseudorandom functions. We note that the resulting pseudorandom functions will be also computable in linear space.
Reference: [K] <author> Kent, S.T., </author> <title> "Protecting Externally Supplied Software in Small Computers" Ph.D. </title> <type> Thesis, </type> <month> MIT/LCS/TR-255 </month> <year> 1980. </year>
Reference-contexts: Of course, the more hardware we must physically protect, the more expensive our 3 solution is. Hence, we must also consider what is the minimal amount of physically protected hardware that we really need. It has been suggested <ref> [Be, K] </ref> to protect software against duplication by selling a a Software-Hardware-package (SH-package) consisting of a physically shielded Central Processing Unit (CPU) and an encrypted program. The CPU will contain a small ROM (Read-Only Memory unit) which stores the corresponding decryption key. <p> We note that the technology to physically shield (at least to some degree) the CPU (which, in practice, is a single computer chip) does already exist indeed, every ATM bank machine has such a protected chip. Thus, the SH-package employs feasible software and hardware measures <ref> [Be, K] </ref>. Using encryption to keep the contents of the memory secret is certainly a step in the right direction. However, as we will shortly see, this does not provide the protection one may want.
Reference: [LR] <author> Luby, M., and C. Rackoff, </author> <title> "Pseudo-Random Permutation Generators and Cryptographic Composition" Proc. </title> <booktitle> of 18'th SOTC, </booktitle> <year> 1986, </year> <pages> pp. 356-363. </pages>
Reference: [PF] <author> Pippengerr, N., and M.J. Fischer, </author> <title> "Relations Among Complexity Measures" JACM, </title> <booktitle> Vol 26, </booktitle> <volume> No. 2, </volume> <year> 1979, </year> <pages> pp. 361-381. </pages>
Reference-contexts: For every reasonable model of computation such a transformation does exist. The question is its cost: namely, the slowdown in the running time of the oblivious machine (when compared to the original machine). In 1979 Pippenger and Fischer <ref> [PF] </ref> showed how a one-tape Turing Machine can be simulated, on-line, by a two-tape oblivious Turing Machine, with a logarithmic slowdown in the running time. We study an analogue question for random-access machine (RAM) model of computation. <p> Then for any D, the conditional probability for a particular input given a sequence of memory accesses which occurs during an execution on that input, equals the a-priori probability for that particular input according to D. The solution of <ref> [PF] </ref> for making a single-tape Turing Machine oblivious heavily relies on the fact that the movement of the (single-tape Turing Machine) head is very "local" (i.e., immediately after accessing location i, a single-tape Turing-Machine is only able to access either location i 1 or i + 1).
Reference: [Ost] <author> Ostrovsky, R. </author> <title> "Efficient Computation on Oblivious RAMs" STOC, </title> <year> 1990. </year>
Reference: [SR] <author> Simon M., and C. Rackoff, </author> <title> "Cryptographic Defense Against Traffic Analysis", </title> <booktitle> Stoc, </booktitle> <year> 1993. </year>
Reference-contexts: We note that the above application differs from the problem of Traffic Analysis as treated by Simon and Rackoff <ref> [SR] </ref>. A telling special case of their setting consists of 2n parties wishing to communicate concurrently, in n disjoint pairs, and wanting to hide information regarding the matching (the pairing).
Reference: [Y] <author> Yao, </author> <title> A.C., "Theory and Applications of Trapdoor Functions", </title> <booktitle> 23rd FOCS, </booktitle> <year> 1982, </year> <pages> pp. 80-91. </pages>
Reference-contexts: When timed-out, the fake CPU (magically) writes to the memory the same 1 In this paper, we shall use standard notion of computational indistinguishability, as defined in [GM] and <ref> [Y] </ref>. output that the genuine CPU would have written on the "real" program (and the same input). We stress that, in the general case, the adversary may modify the communication between CPU and memory (as well as modify the contents of memory cells) in any way he wants. <p> To derive results 8 for the more realistic model of a probabilistic RAM, we replace the random oracle used in the above theorems, by a pseudorandom function. The latter can be implemented, assuming the existence of one-way functions (cf. <ref> [BM, Y, ILL, H] </ref> and [GGM]), by using a short randomly chosen seed and the results remain valid with respect to adversaries running in time polynomial in the length of this seed. Our construction yields a technique of efficiently hiding the access pattern into any data-structure. <p> Detailed comments concerning such implementations will be given in the corresponding sections. Here, we merely recall that pseudo-random functions can be constructed using pseudo-random generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao <ref> [Y] </ref>, Impagliazzo et. al. [ILL], and Hastad [H]).
References-found: 24

