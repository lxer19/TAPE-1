URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-93-08.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Title: Accurate and Precise Computation using Analog VLSI, with Applications to Computer Graphics and Neural Networks  
Author: David B. Kirk 
Degree: Thesis by  In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Note: Caltech-CS-TR-93-[0008]  
Date: 1993 (Defended March 16, 1993)  
Address: Pasadena, California  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [Aarts 90] <author> Aarts, Emile, and Jan Korst, </author> <title> "Simulated Annealing and Boltzmann Machines: A Stochastic Approach to Combinatorial Optimization and Neural Computing," </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1990. </year>
Reference: [Abu-Mostafa 88] <author> Abu-Mostafa, Yaser S., </author> <title> editor, "Complexity in Information Theory," </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference: [Alefeld 83] <author> Alefeld, G., and J. Herzberger, </author> <title> "Introduction to Interval Computations," </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: An area which we identify for future research is to incorporate the consideration of possible device variations and compensatory knob selections into the design and circuit simulation process. Potential avenues of research include using interval analysis <ref> [Alefeld 83] </ref> [Snyder 92] to chart expected values of variations, and using a simulation to validate a range of possible knob selections before fabrication of the circuits. 6.2 Constructing a Compensated Amplifier As a brief introduction to the idea of using knobs for compensation, we'll describe a compensated amplifier [Mead 90]
Reference: [Allen 87] <author> Allen, Phillip E., and Douglas R. Holberg, </author> <title> "CMOS Analog Circuit Design," </title> <publisher> Holt, Rine-hart and Winston, Inc., </publisher> <address> Fort Worth, TX, </address> <year> 1987. </year>
Reference-contexts: We can, however, make better devices by using some well-known design techniques. An example of such a technique is common-centroid layout, which can be used to reduce the effects of production variations such 1.5 Using Goals for Analog VLSI Computation 11 as dopant concentration gradients or oxide thickness. <ref> [Allen 87] </ref> and [Millman 79] describe circuit and layout techniques to reduce the effects of some common production variations. Even with clever layout tricks, we still need a reliable way to control analog circuits containing only a few components, so we can use them consistently in larger circuits.
Reference: [Alspector 93] <author> Alspector, J., R. Meir, B. Yuhas, and A. Jayakumar, </author> <title> "A Parallel Gradient Descent Method for Learning in Analog VLSI Neural Networks," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 5, </volume> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: We also estimate gradients continuously in position and time, in contrast to [Umminger 89] and [Jabri 91], which utilize discrete position gradient estimates. It is interesting to note the existence of related algorithms, developed at approximately the same time [Cauwenberghs 93] <ref> [Alspector 93] </ref> [Flower 93]. The main difference between our approach and the related algorithms is that our implementation operates in continuous time, with continuous differ 8.3 The Gradient Estimation Technique 103 entiation and integration operators. <p> The other approaches realize the integration and differentiation processes as discrete addition and subtraction operations, and use unit perturbations. [Cauwenberghs 93] provides a detailed derivation of the convergence and scaling properties of the discrete approach, and a simulation. <ref> [Alspector 93] </ref> provides a description and simulation of the use of the technique as part of a neural network hardware architecture. [Flower 93] derived a similar discrete algorithm from a node perturbation perspective in the context of multi-layer feedforward networks. <p> We can limit our technique to discrete, unit perturbations (instead of noise), discrete differentiation (subtraction), and discrete integration (addition), to make our approach more closely resemble [Cauwenberghs 93] <ref> [Alspector 93] </ref> [Flower 93]. Consequently, we believe that our technique is more general. Our work is similar in spirit to [Dembo 90] in that we don't make any explicit assumptions about the "model" that is embodied in the function f ().
Reference: [Alspector 91] <author> Alspector, J., J. W. Gannett, S. Haber, M. B. Parker, and R. Chu, </author> <title> "A VLSI-Efficient Technique for Generating Multiple Uncorrelated Noise Sources and its Application to Stochastic Neural Networks," </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <note> Vol.38, no.1, pp.109-123, January, 1991. Bibliography 141 </note>
Reference-contexts: The chip implementation can be decomposed into six distinct parts: noise source (s): an analog VLSI circuit which produces a noise function. An independent, correlation-free noise source is needed for each input dimension, designated n i (t). The noise circuit is described in <ref> [Alspector 91] </ref>.
Reference: [Alspector 88] <author> Alspector, J., B. Gupta, and R. B. Allen, </author> <title> "Performance of a Stochastic Learning Microchip," </title> <booktitle> in Advances in Neural Information Processing Systems, vol. I, </booktitle> <address> Denver Colorado, </address> <month> Nov. </month> <year> 1988. </year> <editor> D. S. Touretzky, ed., </editor> <publisher> Morgan Kauffman Publishers, </publisher> <year> 1989, </year> <pages> pp. 748-760. </pages>
Reference-contexts: Unlike previous work using noise sources in adaptive systems, we use the noise as a means of estimating the gradient of a function f (y), rather than performing an annealing process <ref> [Alspector 88] </ref>. We also estimate gradients continuously in position and time, in contrast to [Umminger 89] and [Jabri 91], which utilize discrete position gradient estimates. It is interesting to note the existence of related algorithms, developed at approximately the same time [Cauwenberghs 93] [Alspector 93] [Flower 93].
Reference: [Anderson 90] <author> Anderson, Janeen D. W., and C. A. Mead, </author> <title> "MOS Device for Long-Term Learning," </title> <type> U.S. Patent #4,953,928. </type>
Reference-contexts: This permanance of charge on a floating gate is especially attractive for a device or design compensation application, since we will often wish to compensate for errors once, and retain the same setting. Methods for adding/removing charge include hot electron injection <ref> [Anderson 90] </ref>, Fowler-Nordheim tunneling [Thomsen 91], and UV-induced electron transfer [Kerns 92b]. Kerns [Kerns 92b] describes some issues related to fabricating and using floating-gate compensated amplifiers, particularly by using UV-induced electron transfer to adjust the charge on floating gates.
Reference: [Anderson, Kerns 92] <author> Anderson, Brooke P., and Douglas Kerns, </author> <title> "Using Noise Injection and Correlation in Analog Hardware to Estimate Gradients," </title> <note> submitted to IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications. </note>
Reference-contexts: The implementation uses noise injection and multiplicative correlation to estimate derivatives, as in <ref> [Anderson, Kerns 92] </ref>. One intended application of this technique is setting circuit parameters on-chip automatically, rather than manually [Kirk 91]. Gradient descent optimization may be used to adjust synapse weights for a backpropagation or other on-chip learning implementation. <p> The approach combines the features of continuous multidimensional gradient descent and the potential for an annealing style of optimization. We present data measured from our analog VLSI implementation. This work is similar to <ref> [Anderson, Kerns 92] </ref>, but represents two advances. First, we describe the extension of the technique to multiple dimensions. Second, we demonstrate an implementation of the multi-dimensional technique in analog VLSI, and provide results measured from the chip. <p> We have fabricated a working chip containing the continuous-time multi-dimensional gradient descent circuits. This chapter includes chip data for individual circuit components, as well as the entire circuit performing multi-dimensional gradient descent and annealing. 8.3 The Gradient Estimation Technique Anderson and Kerns <ref> [Anderson, Kerns 92] </ref> describe techniques for one-dimensional gradient estimation in analog hardware. The gradient is estimated by correlating (using a multiplier) the output of a scalar function f (v (t)) with a noise source n (t), as shown in Fig. 8.1. <p> At some point en every onchip optimization process, we require at least one absolute, accurate reference. We have chosen to implement the multi-dimensional technique in analog VLSI. We will not reproduce here the one-dimensional analysis from <ref> [Anderson, Kerns 92] </ref>, but summarize some of the more important results, and provide a multi-dimensional derivation. [Anderson 92] provides a more detailed theoretical discussion. 8.4 Multi-dimensional Derivation 105 8.4 Multi-dimensional Derivation The multi-dimensional gradient descent operation that we are approximating can be written as follows: (8.1) where y and y 0
Reference: [Anderson 92] <author> Anderson, Brooke P., </author> <title> "Low-pass Filters as Expectation Operators for Multiplicative Noise," </title> <note> submitted to IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications. </note>
Reference-contexts: We have chosen to implement the multi-dimensional technique in analog VLSI. We will not reproduce here the one-dimensional analysis from [Anderson, Kerns 92], but summarize some of the more important results, and provide a multi-dimensional derivation. <ref> [Anderson 92] </ref> provides a more detailed theoretical discussion. 8.4 Multi-dimensional Derivation 105 8.4 Multi-dimensional Derivation The multi-dimensional gradient descent operation that we are approximating can be written as follows: (8.1) where y and y 0 are vectors, and the solution is obtained continuously in time t, rather than at discrete t <p> To see that Eq. 8.2 is valid, and that this result is useful for approximating Eq. 8.1, we sketch an N -dimensional extension of <ref> [Anderson 92] </ref>.
Reference: [Anderson 92b] <author> Anderson, Brooke P., </author> <title> "Various Algorithms for Optimization and Learning in Adaptive Systems," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, </institution> <month> October, </month> <year> 1992. </year>
Reference: [Babanezhad 85] <author> Babanezhad, Joseph N., and Gabor C. Temes, </author> <title> "A 20-V Four-Quadrant CMOS Analog Multiplier," </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. SC-20, No. 6, </volume> <pages> pp. 1158-1168, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: Some of these problems are described in <ref> [Babanezhad 85] </ref>, along with some additional circuitry to address the problems that are identified. Our primary concern is the cancellation of input offsets, and we assume that similar techniques can be applied to most robust and nearly linear multiplier designs.
Reference: [Barkans 90] <author> Barkans, Anthony C., </author> <title> "High Speed High Quality Antialiased Vector Generation," </title> <journal> Computer Graphics, </journal> <volume> Vol. 24, No. 4, </volume> <month> August, </month> <year> 1990, </year> <pages> pp. 319-326. </pages>
Reference-contexts: For instance, Adage implemented matrix multiplication for the purpose of performing coordinate transformations in analog circuitry, although not in VLSI. There is also a history of digital VLSI acceleration in computer graphics: geometry engines [Clark 82], hardware frame buffer assists [Rhoden 89], vector generators <ref> [Barkans 90] </ref>, systems [Voorhies 88] 7.1 Analog VLSI for Constraint Satisfaction 87 [Fuchs 89], etc. Most high-performance graphics workstations have a substantial amount of special purpose chips to provide the kind of interactive performance that we have come to expect.
Reference: [Barzel 92] <author> Barzel, Ronen, </author> <title> "Physically-Based Modeling for Computer Graphics: A Structured Approach," </title> <publisher> Academic Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Accordingly, we proceed by choosing some portion of the physical world to model, and formulating a set of equations to model it. We subscribe to a structured modeling approach described in <ref> [Barzel 92] </ref>. We choose some portion of the world to model, and decide which aspects of that portion of the world are of interest. We then formulate equations which describe the behavior of the portion of interest. <p> Given that we are attempting to model and simulate some "thing," one of the first abstractions that is made is from the model to the differential equations which describe its behavior. As described in <ref> [Barzel 92] </ref>, the next conceptual step lies in the solution of the equations. A key component of the solution is the numeric technique chosen to use in order to solve the equations, as well as the type of computation to use (analog or digital). <p> It is important to note that in these discussions, we have chosen a particular constraint to demonstrate the general technique of implementing a constraint in analog VLSI. There are many other examples of useful constraint computation that could be formulated in a similar fashion [Platt 89] <ref> [Barzel 92] </ref>, and also could be implemented in analog hardware. The particular constraint that we have chosen to implement is meant to be representative of a large set of possibilities. Our example raises the exciting prospect of implementation of extensive hardware modeling assists in analog VLSI.
Reference: [Blum 89] <author> Blum, Lenore, Mike Shub, and Steve Smale, </author> <title> "On a Theory of Computation and Complexity over the Real Numbers: NP-Completeness, Recursive Functions and Universal Machines," </title> <journal> Bulletin of the American Mathematical Society, </journal> <volume> Volume 21, Number 1, </volume> <month> July </month> <year> 1989. </year> <note> Bibliography 142 </note>
Reference: [Bult 86] <author> Bult, Klaas, and Hans Wallinga, </author> <title> "A CMOS Four-Quadrant Analog Multiplier," </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. SC-21, No. 3, </volume> <pages> pp. 430-435, </pages> <month> June </month> <year> 1986. </year>
Reference: [Cauwenberghs 93] <author> Cauwenberghs, Gert, </author> <title> "A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 5, </volume> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: We also estimate gradients continuously in position and time, in contrast to [Umminger 89] and [Jabri 91], which utilize discrete position gradient estimates. It is interesting to note the existence of related algorithms, developed at approximately the same time <ref> [Cauwenberghs 93] </ref> [Alspector 93] [Flower 93]. The main difference between our approach and the related algorithms is that our implementation operates in continuous time, with continuous differ 8.3 The Gradient Estimation Technique 103 entiation and integration operators. <p> The other approaches realize the integration and differentiation processes as discrete addition and subtraction operations, and use unit perturbations. <ref> [Cauwenberghs 93] </ref> provides a detailed derivation of the convergence and scaling properties of the discrete approach, and a simulation. [Alspector 93] provides a description and simulation of the use of the technique as part of a neural network hardware architecture. [Flower 93] derived a similar discrete algorithm from a node perturbation <p> We can limit our technique to discrete, unit perturbations (instead of noise), discrete differentiation (subtraction), and discrete integration (addition), to make our approach more closely resemble <ref> [Cauwenberghs 93] </ref> [Alspector 93] [Flower 93]. Consequently, we believe that our technique is more general. Our work is similar in spirit to [Dembo 90] in that we don't make any explicit assumptions about the "model" that is embodied in the function f ().
Reference: [Chandrasekhar 60] <author> Chandrasekhar, S., </author> <title> "Radiative Transfer," </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1960. </year>
Reference: [Chua 84] <author> Chua, Leon O., and Gui-Nian Lin, </author> <title> "Nonlinear Programming Without Computation," </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <volume> Vol. CAS-31, No. 2, </volume> <month> February </month> <year> 1984, </year> <pages> pp. 182-188. </pages>
Reference-contexts: We can then use our a priori knowledge to assist us in the optimization. This approach relates to some early work in on-chip optimization, using static connectivity circuits to solve particular linear and nonlinear programming problems [Pyne 56] <ref> [Chua 84] </ref>. One can assemble static circuits composed of resistors, capacitors, and amplifiers, which can solve nonlinear programming problems [Chua 84]. This is an example of model-based optimization, since the connection scheme is implied by the model. <p> This approach relates to some early work in on-chip optimization, using static connectivity circuits to solve particular linear and nonlinear programming problems [Pyne 56] <ref> [Chua 84] </ref>. One can assemble static circuits composed of resistors, capacitors, and amplifiers, which can solve nonlinear programming problems [Chua 84]. This is an example of model-based optimization, since the connection scheme is implied by the model.
Reference: [Clark 82] <author> Clark, James, </author> <title> "The Geometry Engine: A VLSI Geometry System for Graphics," </title> <journal> Computer Graphics, </journal> <volume> Vol. 16, No. 3, </volume> <month> July, </month> <year> 1982, </year> <pages> pp. 127-133. </pages>
Reference-contexts: There have also been more extensive uses of analog, however. For instance, Adage implemented matrix multiplication for the purpose of performing coordinate transformations in analog circuitry, although not in VLSI. There is also a history of digital VLSI acceleration in computer graphics: geometry engines <ref> [Clark 82] </ref>, hardware frame buffer assists [Rhoden 89], vector generators [Barkans 90], systems [Voorhies 88] 7.1 Analog VLSI for Constraint Satisfaction 87 [Fuchs 89], etc. Most high-performance graphics workstations have a substantial amount of special purpose chips to provide the kind of interactive performance that we have come to expect.
Reference: [Delbruck 91] <author> Delbruck, Tobias, </author> " <title> `Bump' Circuits for Computing Similarity and Dissimilarity of Analog Voltages," </title> <booktitle> Proceedings of International Joint Conference on Neural Networks, </booktitle> <address> July 8-12, 1991, Seattle Washington, </address> <pages> pp. </pages> <note> I-475-479. (Extended version as Caltech Computation and Neural Systems Memo Number 10.) </note>
Reference-contexts: The circuit in this case is a 4-dimensional variant of the bump circuit described in <ref> [Delbruck 91] </ref>. In the general case, this f () can be any scalar function or error metric, computed by some circuit. <p> Each differentiated noise signal is correlated with the differentiated function output, using the multipliers. The results are low-pass filtered, providing N partial derivative estimates, for the N input dimensions, shown for 4 dimensions in Fig. 8.3. The function f () is implemented as an 4-dimensional extension of Delbruck's <ref> [Delbruck 91] </ref> bump circuit, described in detail in Appendix C. <p> In Appendix C, we present data from a simulation of a 4-dimensional implementation of the N -d bump circuit. Results from <ref> [Delbruck 91] </ref> indicate that the bump circuit simulation is very similar to what can be expected from the chip. We also fed the noise data into the 4-d bump circuit simulation, and differentiated and correlated the results, in order to simulate the entire system. <p> anticipate that it is possible to design a version of the capacitive input structures for the Gilbert multiplier using feedback, but we have not explored such a design. 127 Appendix C Description of Operation of N-Dimensional Bump Circuit This appendix describes the operation of an extension to Delbruck's bump-anti-bump circuit <ref> [Delbruck 91] </ref>. Delbruck's circuit computes a smooth similarity measure of two voltages. As such, it computes a basis function in one dimension. Delbruck's circuit is shown in Fig. C.1. The equations of operation of the bump circuit are shown in Eq. <p> Figure C.7 shows a simulation of a 4-dimensional implementation of the N -d bump circuit. The four curves represent the response as one of the 4 input parameters is varied at a time. Results from <ref> [Delbruck 91] </ref> indicate that the bump circuit simulation is very similar to what can be expected from the chip. Appendix C.
Reference: [Dembo 90] <author> Dembo, A., and T. Kailath, </author> <title> "Model-Free Distributed Learning," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 58-70, </pages> <year> 1990. </year>
Reference-contexts: We can limit our technique to discrete, unit perturbations (instead of noise), discrete differentiation (subtraction), and discrete integration (addition), to make our approach more closely resemble [Cauwenberghs 93] [Alspector 93] [Flower 93]. Consequently, we believe that our technique is more general. Our work is similar in spirit to <ref> [Dembo 90] </ref> in that we don't make any explicit assumptions about the "model" that is embodied in the function f (). The function may be implemented as a neural network and its error metric for learning, and the multiple parameters are the input dimensions of the function.
Reference: [Denyer 81] <author> Denyer, Peter B., John Mavor, </author> <title> "MOST Transconductance Multipliers for Array Applications," </title> <journal> IEEE Proceedings, </journal> <volume> Volume 128, Pt. I, Number 3, </volume> <pages> pp. 81-86, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: be concerned with techniques for improving and controlling the performance of such multipliers, in terms of offsets (errors in controlling x 0 and y 0 ), and nonlinearities (variations in k over the operating range). 6.3.1 Two-transistor Multiplier We can actually perform quite a nice multiply operation with two transistors <ref> [Denyer 81] </ref>[Denyer 83][Tsividis 86]. <p> Since the multipliers each require two current sense amplifiers (one for I+ and one for I-), we might implement a dot product using 6 amplifiers. As suggested by <ref> [Denyer 81] </ref>, we can share one sense amplifier between all of the I+ amplifiers, and a second one between all of the I- amplifiers, so we only need two. 6.4 Constructing a Compensated Multiplier 79 The output voltage is measured relative to a reference voltage for the current sense amplifier. 2 <p> So, for each new approximate rotation matrix, we expect that the time required to produce the orthonormalized matrix will be approximately 75 microseconds. For the analog implementation, we base the performance analysis on previously reported speeds for the two transistor multiplier <ref> [Denyer 81] </ref>. Denyer reports that product rates in excess of 2 Mhz are easily achievable. Since the multipliers and constraint solution circuitry operate in parallel and in continuous time, we expect much faster convergence than in the digital discrete case described above, on the order of a few microseconds.
Reference: [Denyer 83] <author> Denyer, Peter B., Colin F. N. Cowan, John Mavor, Christopher B. Clayton, and John L. Pennock, </author> <title> "A Monolithic Adaptive Filter," </title> <journal> IEEE Proceedings, </journal> <volume> Volume 128, Pt. I, Number 3, </volume> <pages> pp. 81-86, </pages> <month> June </month> <year> 1981. </year> <note> Bibliography 143 </note>
Reference: [DeWeerth 91] <author> DeWeerth, Steven P., </author> <title> "Analog VLSI Circuits for Sensorimotor Feedback," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, </institution> <month> May, </month> <year> 1991. </year>
Reference: [Feynman 82] <author> Feynman, Richard, </author> <title> "Simulating Physics with Computers," </title> <journal> International Journal of Theoretical Physics, </journal> <volume> Vol. 21, </volume> <pages> Nos. </pages> <address> 6,7, </address> <year> 1982. </year>
Reference-contexts: Each of these ways of considering precision is appropriate for different ways of thinking about computation. When we are discussing precision in the remainder of this thesis, we will be careful to describe which definition we are using. 2.3.1 Feynman's Treatment of Accuracy and Precision in Physics Feynman <ref> [Feynman 82] </ref> discusses some of the problems associated with simulation of physics using computers. Using a general model of discrete (digital) computation, Feynman describes the simulation of "discrete" physics, a fiction created for the purposes of the discussion.
Reference: [Fleischer 90] <author> Fleischer, Kurt, John Platt, and Alan Barr, </author> <title> "An Approach to Solving the Parameter Setting Problem," </title> <booktitle> IEEE/ACM 23rd Intl Conf on System Sciences, </booktitle> <month> January </month> <year> 1990. </year>
Reference-contexts: As biologically-motivated analog VLSI circuits become increasingly complex, implying more parameters, setting these parameters by hand will become more cumbersome. Thus an automated parameter setting method can be of great value <ref> [Fleischer 90] </ref>. We wish to provide an "electronic screwdriver" that we can use to adjust operating parameters. <p> However, more complex circuits may require more sophisticated optimization methods. A wide variety of constrained optimization algorithms exist which are effective on particular classes of problems (gradient descent, quasi-Newton, simulated annealing, etc) <ref> [Platt 89, Gill 81, Press 86, Fleischer 90] </ref>, and we can choose a method appropriate to the problem at hand. Techniques such as simulated annealing can find optimal parameter combinations for multi-parameter systems with complex behavior, which gives us confidence that our methods will work for more complex circuits.
Reference: [Flower 93] <author> Flower, B., and M. Jabri, </author> <title> "Summed Weight Neuron Perturbation: An O(n) Improvement over Weight Perturbation," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <volume> Vol. 5, </volume> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: We also estimate gradients continuously in position and time, in contrast to [Umminger 89] and [Jabri 91], which utilize discrete position gradient estimates. It is interesting to note the existence of related algorithms, developed at approximately the same time [Cauwenberghs 93] [Alspector 93] <ref> [Flower 93] </ref>. The main difference between our approach and the related algorithms is that our implementation operates in continuous time, with continuous differ 8.3 The Gradient Estimation Technique 103 entiation and integration operators. <p> as discrete addition and subtraction operations, and use unit perturbations. [Cauwenberghs 93] provides a detailed derivation of the convergence and scaling properties of the discrete approach, and a simulation. [Alspector 93] provides a description and simulation of the use of the technique as part of a neural network hardware architecture. <ref> [Flower 93] </ref> derived a similar discrete algorithm from a node perturbation perspective in the context of multi-layer feedforward networks. We can limit our technique to discrete, unit perturbations (instead of noise), discrete differentiation (subtraction), and discrete integration (addition), to make our approach more closely resemble [Cauwenberghs 93] [Alspector 93] [Flower 93]. <p> architecture. <ref> [Flower 93] </ref> derived a similar discrete algorithm from a node perturbation perspective in the context of multi-layer feedforward networks. We can limit our technique to discrete, unit perturbations (instead of noise), discrete differentiation (subtraction), and discrete integration (addition), to make our approach more closely resemble [Cauwenberghs 93] [Alspector 93] [Flower 93]. Consequently, we believe that our technique is more general. Our work is similar in spirit to [Dembo 90] in that we don't make any explicit assumptions about the "model" that is embodied in the function f ().
Reference: [Fuchs 89] <author> Fuchs, Henry, J. Poulton, J. Eyles, T. Greer, J. Goldfeather, D. Ellsworth, S. Molnar, G. Turk, B. Tebbs, and L. Israel, </author> <title> "Pixel-Planes 5: A Heterogeneous Multiprocessor Graphics System Using Processor-Enhanced Memories," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. 3, </volume> <month> July, </month> <year> 1989, </year> <pages> pp. 79-88. </pages>
Reference-contexts: There is also a history of digital VLSI acceleration in computer graphics: geometry engines [Clark 82], hardware frame buffer assists [Rhoden 89], vector generators [Barkans 90], systems [Voorhies 88] 7.1 Analog VLSI for Constraint Satisfaction 87 <ref> [Fuchs 89] </ref>, etc. Most high-performance graphics workstations have a substantial amount of special purpose chips to provide the kind of interactive performance that we have come to expect. Most, if not all of this silicon is dedicated to rendering tasks.
Reference: [Gallager 68] <author> Gallager, R., </author> <title> "Information Theory and Reliable Communication," </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: The theory also helps to give us a feel for the 2.2 Complexity of Analog Computation 17 type of cost/performance tradeoffs that are involved in real computation problems. As an example, mutual information, as defined in <ref> [Gallager 68] </ref>, serves to provide us with a measure of how much the occurrence of a particular event tells us about the probability of occurrence of some other event.
Reference: [Gilbert 68] <author> Gilbert, B., </author> <title> "A Precise Four-Quadrant Multiplier with Sub-nanosecond Response," </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> SC-3:365, </volume> <year> 1968. </year>
Reference-contexts: The existence of an automated parameter setting mechanism opens up a new avenue for producing accurate analog circuits. The goal of accurately computing a function differs from the approach of providing a cheap (simple) circuit which loosely approximates the function <ref> [Gilbert 68] </ref> [Mead 89]. By providing appropriate parameters in the design of a circuit, we can ensure that the desired function is in the domain of possible circuit behaviors (given expected manufacturing tolerances). Thus we define the domain of the circuit in anticipation of the parameter setting apparatus.
Reference: [Gill 81] <author> Gill, P. E., W. Murray, and M. H. Wright, </author> <title> "Practical Optimization," </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: However, more complex circuits may require more sophisticated optimization methods. A wide variety of constrained optimization algorithms exist which are effective on particular classes of problems (gradient descent, quasi-Newton, simulated annealing, etc) <ref> [Platt 89, Gill 81, Press 86, Fleischer 90] </ref>, and we can choose a method appropriate to the problem at hand. Techniques such as simulated annealing can find optimal parameter combinations for multi-parameter systems with complex behavior, which gives us confidence that our methods will work for more complex circuits. <p> Euler's method has many well-known problems, including a sensitivity to step size. For multi-dimensional optimizations where the various parameters are at different scales, we may see oscillation, which is at best inefficient for swift convergence, and is sometimes disastrous. Techniques such as the conjugate gradient method <ref> [Gill 81] </ref> can improve performance for "difficult" optimization tasks. Even when using sophisticated programs with adaptive step sizes, the choice of an appropriate step size can continue be a problem. One cost of a sophisticated technique is the time required to perform the additional computation.
Reference: [Goodman 68] <author> Goodman, Joseph W., </author> <title> "Introduction to Fourier Optics," </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1968. </year>
Reference: [Gray 84] <author> Gray, Paul R., and Robert G. Meyer, </author> <title> "Analysis and Design of Analog Integrated Circuits," </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1984. </year> <note> Bibliography 144 </note>
Reference: [Gregorian 86] <author> Gregorian, Roubik, and Gabor C. Temes, </author> <title> "Analog MOS Integrated Circuits for Signal Processing," </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1986. </year>
Reference: [Greengard 88] <author> Greengard, Leslie, </author> <title> "The Rapid Evaluation of Potential Fields in Particle Systems," </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: An improved, hierarchical algorithm has a complexity of order N log N , due to the properties of the spatial hierarchy. An approximate solution can be obtained in linear time <ref> [Greengard 88] </ref>. A mechanical analog computer can calculate the exact solution in real (linear) time.
Reference: [Harris 91] <author> Harris, John, </author> <title> "Analog Models of Early Vision," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, </institution> <month> October, </month> <year> 1991. </year>
Reference: [Jabri 91] <author> Jabri, M., S. Pickard, P. Leong, Z. Chi, and B. Flower, </author> <title> "Architectures and Implementations of Right Ventricular Apex Signal Classifiers for Pacemakers," </title> <booktitle> IEEE Neural Information Processing Systems 1991 (NIPS 91), </booktitle> <publisher> Morgan Kaufman, </publisher> <address> San Diego, </address> <year> 1991. </year>
Reference-contexts: Unlike previous work using noise sources in adaptive systems, we use the noise as a means of estimating the gradient of a function f (y), rather than performing an annealing process [Alspector 88]. We also estimate gradients continuously in position and time, in contrast to [Umminger 89] and <ref> [Jabri 91] </ref>, which utilize discrete position gradient estimates. It is interesting to note the existence of related algorithms, developed at approximately the same time [Cauwenberghs 93] [Alspector 93] [Flower 93].
Reference: [James 76] <author> James, Glenn, et al., </author> <title> "Mathematics Dictionary," </title> <publisher> Van Nostrand Reinhold Company, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: on a determination of how much useful information you have. sample variance The sample variance of a sample fx 1 ; ; x n g whose mean is x, is defined to be i=1 (x i x) 2 =n, which is a maximum likelihood estimator if the distribution is normal <ref> [James 76] </ref>. standard deviation For a random variable, the standard deviation is defined to be the positive square root of the variance [James 76]. tacit model A tacit model is a description of an object or a concept that does not explicitly state important details, but leaves those details as implications. <p> x n g whose mean is x, is defined to be i=1 (x i x) 2 =n, which is a maximum likelihood estimator if the distribution is normal <ref> [James 76] </ref>. standard deviation For a random variable, the standard deviation is defined to be the positive square root of the variance [James 76]. tacit model A tacit model is a description of an object or a concept that does not explicitly state important details, but leaves those details as implications. An example: A car.
Reference: [Jayant 84] <author> Jayant, N. S., and Peter Noll, </author> <title> "Digital Coding of Waveforms," </title> <publisher> Prentice-Hall, Inc., </publisher> <address> En-glewood Cliffs, NJ, </address> <year> 1984. </year>
Reference: [Kerns 92a] <author> Kerns, Douglas, </author> <title> "A Compact Noise Source for VLSI Applications," </title> <note> submitted to IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications. </note>
Reference: [Kerns 92b] <author> Kerns, Douglas, </author> <title> "Experiments in Very Large Scale Analog Computation," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, </institution> <month> September, </month> <year> 1992. </year>
Reference-contexts: These wires can represent signals at different scales, as with bits, although the scale factor does not have to be two. Another way to think of the analog bits representation is that the functions f b1 (x) and f b2 (x) are successive approximations of the function f (x). <ref> [Kerns 92b] </ref> discusses multi-wire signal representations of this type, and provides some discussion of implementation issues. The second partitioning scheme that we will consider is a larger departure from digital encodings. <p> Methods for adding/removing charge include hot electron injection [Anderson 90], Fowler-Nordheim tunneling [Thomsen 91], and UV-induced electron transfer <ref> [Kerns 92b] </ref>. Kerns [Kerns 92b] describes some issues related to fabricating and using floating-gate compensated amplifiers, particularly by using UV-induced electron transfer to adjust the charge on floating gates. In addition, Kerns describes a small system (2nd-order-section delay line) built from a sequence of compensated amplifiers. <p> Methods for adding/removing charge include hot electron injection [Anderson 90], Fowler-Nordheim tunneling [Thomsen 91], and UV-induced electron transfer <ref> [Kerns 92b] </ref>. Kerns [Kerns 92b] describes some issues related to fabricating and using floating-gate compensated amplifiers, particularly by using UV-induced electron transfer to adjust the charge on floating gates. In addition, Kerns describes a small system (2nd-order-section delay line) built from a sequence of compensated amplifiers.
Reference: [Kirk 91] <author> Kirk, David B., Kurt Fleischer, Lloyd Watts, and Alan Barr, </author> <title> "Constrained Optimization Applied to the Parameter Setting Problem for Analog Circuits," </title> <booktitle> Neural Information Processing Systems 4, </booktitle> <publisher> Morgan Kaufman, </publisher> <address> Palo Alto, CA, </address> <year> 1992. </year>
Reference-contexts: The family of curves represents varying the gate voltage. The analog VLSI multipliers discussed in Chapter 6 operate in the nearly linear region to the right of a) and to the left of b). 2 be adjusted to perform to the desired accuracy <ref> [Kirk 91] </ref>. This work can be characterized as using adaptation and optimization to harness analog VLSI for more "conventional computing" applications. This approach is attractive because analog transistors provide a rich computational substrate. constant. <p> Related research has focused on increasing the accuracy and precision of computation with analog VLSI and on developing a design methodology for creating analog VLSI circuits which can be adjusted to perform to the desired accuracy <ref> [Kirk 91] </ref>. These techniques make analog VLSI more tractable for quantitative computation. This is not the first appearance of analog computation in computer graphics. There is a history of analog implementation in computer graphics. <p> The implementation uses noise injection and multiplicative correlation to estimate derivatives, as in [Anderson, Kerns 92]. One intended application of this technique is setting circuit parameters on-chip automatically, rather than manually <ref> [Kirk 91] </ref>. Gradient descent optimization may be used to adjust synapse weights for a backpropagation or other on-chip learning implementation. The approach combines the features of continuous multidimensional gradient descent and the potential for an annealing style of optimization. We present data measured from our analog VLSI implementation. <p> Sec. 8.2, we could use a more constrained input such as clocked unit perturbations, ramps, etc. 8.5 Elements of the Multi-dimensional Implementation 107 target function: a scalar function f (y 1 ; y 2 ; ; y N ) of N input variables, bounded below, which is to be minimized <ref> [Kirk 91] </ref>. The circuit in this case is a 4-dimensional variant of the bump circuit described in [Delbruck 91]. In the general case, this f () can be any scalar function or error metric, computed by some circuit.
Reference: [Kirk 92] <author> Kirk, David B., Douglas Kerns, Kurt Fleischer, and Alan Barr, </author> <title> "An Analog VLSI Implementation of Gradient Descent," </title> <booktitle> Neural Information Processing Systems 5, </booktitle> <publisher> Morgan Kaufman, </publisher> <address> Palo Alto, CA, </address> <year> 1993. </year> <note> Bibliography 145 </note>
Reference: [Korn 56] <author> Korn, Granino A., and Theresa M. Korn, </author> <title> "Electronic Analog computers," </title> <publisher> McGraw-Hill Book Company, Inc., </publisher> <address> New York, </address> <year> 1956. </year>
Reference: [Lazzaro 89] <author> Lazzaro, John, Sylvie Ryckebusch, Misha Mahowald, and Carver A. Mead, </author> <title> "Winner-take-all Networks of O(n) Complexity," </title> <booktitle> Neural Information Processing Systems 1, </booktitle> <publisher> Morgan Kaufman, </publisher> <address> Palo Alto, CA, </address> <year> 1989. </year>
Reference-contexts: We require a circuit to priority encode the N precision range blocks, and to select which block (s) is/are active. The circuit should identify which coordinate chart or charts are "in range," and disable the rest. We choose to construct a "winner-take-all" based selection circuit. The WTA circuit <ref> [Lazzaro 89] </ref> selects a winner from among N currents, and the largest current is the winner. It encodes the winner by driving the voltage high on the input (current) wire.
Reference: [Leighton 83] <author> Leighton, Frank Thomson, </author> <title> "Complexity Issues in VLSI," </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference: [Lyon 88] <author> Lyon, R. A., and C. A. Mead, </author> <title> "An Analog Electronic Cochlea," </title> <journal> IEEE Trans. Acous. Speech, and Signal Proc., </journal> <volume> Volume 36, Number 7, </volume> <month> July, </month> <year> 1988, </year> <pages> pp. 1119-1134. </pages>
Reference-contexts: normalized by the parameters a and b. 5.5 The Experiments 56 fit" of the circuit response to a mathematical square root. 2 5.5.2 Analog VLSI Cochlea As an example of a more complex system on which to test the constrained optimization technique, we chose a silicon cochlea, as described by <ref> [Lyon 88] </ref>. The silicon cochlea is a cascade of lowpass second-order filter sections arranged such that the natural frequency t of the stages decreases exponentially with distance into the cascade, while the quality factor Q of the filters is the same for each section (tap). <p> It serves to separate sound information at different frequencies. <ref> [Lyon 88] </ref> described an analog VLSI circuit that behaves as an "electronic cochlea," separating information of differing frequencies in an input electronic signal. compensated* A circuit is said to be compensatable if the circuit has been design to include parameters that can be set to improve the performance of the circuit.
Reference: [Maher 89] <author> Maher, Mary Ann, </author> <title> "A Charge-Controlled Model for MOS Transistors," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, </institution> <month> May, </month> <year> 1989. </year>
Reference: [Mahowald 91] <author> Mahowald, Misha, and Rodney Douglas, </author> <title> "A Silicon Neuron," </title> <journal> Nature, </journal> <volume> Vol. 354, No. 26, </volume> <month> December </month> <year> 1991, </year> <pages> pp. 515-518. </pages>
Reference-contexts: An alternative approach is to cast the differential equation into an analog circuit. We hope that we can obtain more accurate solutions of differential equations using analog circuits. Mahowald and Douglas <ref> [Mahowald 91] </ref> described an implementation of a "silicon neuron" which faithfully models some of the electrical behavior of biological neurons. The electro-chemical behavior of neurons is quite complex and requires significant processing time to simulate on a digital computer.
Reference: [Mahowald 92] <author> Mahowald, Misha, </author> <title> "VLSI Analogs of Neuronal Visual Processing: A Synthesis of Form and Function," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, Caltech-CS-TR-92-15, </institution> <month> May, </month> <year> 1992. </year>
Reference: [Mead 89] <author> Mead, C. A., </author> <title> "Analog VLSI and Neural Systems," </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Also, VLSI design and fabrication techniques are developing rapidly. Analog VLSI can be a very efficient use of silicon and power, producing compact and low-power implementations. There has been increasing interest recently in using analog VLSI <ref> [Mead 89] </ref> for a variety of computational tasks. Mead and others have pursued the paradigm of using individual analog transistors to model components of neural systems. <p> The second experiment uses a more complex time-varying multi-parameter system, an analog VLSI electronic cochlea. The artificial cochlea is composed of cascaded second-order section filters. 5.5.1 Square Root Experiment In the first experiment we examine a "square-root" circuit <ref> [Mead 89] </ref>, which actually computes ax ff +b, where ff is typically near 0.4. We introduce a parameter (V) into this circuit which varies ff indirectly. <p> The existence of an automated parameter setting mechanism opens up a new avenue for producing accurate analog circuits. The goal of accurately computing a function differs from the approach of providing a cheap (simple) circuit which loosely approximates the function [Gilbert 68] <ref> [Mead 89] </ref>. By providing appropriate parameters in the design of a circuit, we can ensure that the desired function is in the domain of possible circuit behaviors (given expected manufacturing tolerances). Thus we define the domain of the circuit in anticipation of the parameter setting apparatus. <p> We believe that analog VLSI has great potential as a computation substrate for implementing rendering and modeling primitive operations. We hope that the realization of this potential will open up exciting new areas of research in computer graphics. There has been increasing interest recently in using analog VLSI <ref> [Mead 89] </ref>, for a variety of computational tasks. Mead and others have pursued the paradigm of using individual analog transistors to model components of neural systems. <p> AB is much larger than (1 + B), then we have (A.24) 1 (V 1 V 2 ) : 123 Appendix B Equations of Operation of Compensated Gilbert Multiplier We could construct a compensated multiplier by adding capacitive input structures to a Gilbert transconductance multiplier or a wide-range transconductance multiplier <ref> [Mead 89] </ref>. A straightforward version has no feedback; there is merely capacitive division on the inputs. <p> An example: A car. Those parts of the car that I have not described are tacitly assumed. teleological An item that is teleological has characteristics that relate to a goal or purpose. transconductance amplifier A transconductance amplifier produces a transconductance which relates its current output to its voltage inputs <ref> [Mead 89] </ref>. transconductance multiplier A transconductance multiplier produces a transconductance which relates its current output to the product of its two differential inputs (four voltages) [Mead 89]. 140 <p> characteristics that relate to a goal or purpose. transconductance amplifier A transconductance amplifier produces a transconductance which relates its current output to its voltage inputs <ref> [Mead 89] </ref>. transconductance multiplier A transconductance multiplier produces a transconductance which relates its current output to the product of its two differential inputs (four voltages) [Mead 89]. 140
Reference: [Mead 90] <author> Mead, C. A., Allen, Timothy P., </author> <title> "Subthreshold CMOS Amplifier with Offset Adaptation," </title> <type> U.S. Patent #4,935,702. </type>
Reference-contexts: As part of the description, we briefly summarize the operation of two example building blocks. The first example is an offset-compensated amplifier, due to Mead and Allen, described in <ref> [Mead 90] </ref> and [Mead 91]. The second example is developed as part of this thesis, a family of compensated multipliers. <p> analysis [Alefeld 83] [Snyder 92] to chart expected values of variations, and using a simulation to validate a range of possible knob selections before fabrication of the circuits. 6.2 Constructing a Compensated Amplifier As a brief introduction to the idea of using knobs for compensation, we'll describe a compensated amplifier <ref> [Mead 90] </ref> [Mead 91]. The compensated amplifier design allows a simple amplifier design to be adjusted to perform more closely to the desired behavior. The basic design is the well-known CMOS transconductance amplifier (transamp) Fig. 6.1. The transamp has some undesirable shortcomings.
Reference: [Mead 91] <author> Mead, C. A., Allen, Timothy P., </author> <title> "CMOS Amplifier with Offset Adaptation," </title> <type> U.S. Patent #5,068,622. </type>
Reference-contexts: As part of the description, we briefly summarize the operation of two example building blocks. The first example is an offset-compensated amplifier, due to Mead and Allen, described in [Mead 90] and <ref> [Mead 91] </ref>. The second example is developed as part of this thesis, a family of compensated multipliers. <p> 83] [Snyder 92] to chart expected values of variations, and using a simulation to validate a range of possible knob selections before fabrication of the circuits. 6.2 Constructing a Compensated Amplifier As a brief introduction to the idea of using knobs for compensation, we'll describe a compensated amplifier [Mead 90] <ref> [Mead 91] </ref>. The compensated amplifier design allows a simple amplifier design to be adjusted to perform more closely to the desired behavior. The basic design is the well-known CMOS transconductance amplifier (transamp) Fig. 6.1. The transamp has some undesirable shortcomings. <p> The resulting relation is: (6.6) 1 (V 1 V 2 ) where B = C 1 of =C 1 of =C 2 if , and we have assumed that AB is much larger than (1 + B). The derivation in Appendix B follows the style of <ref> [Mead 91] </ref>. The response of the doubly compensated amplifier has the advantage of similar scale of the inputs, V 1 and V 2 , as well as the capability to correct for input offsets.
Reference: [Millman 79] <author> Millman, Jacob, </author> <title> "Microelectronics: Digital and Analog Circuits and Systems," </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1979. </year> <note> Bibliography 146 </note>
Reference-contexts: An example of such a technique is common-centroid layout, which can be used to reduce the effects of production variations such 1.5 Using Goals for Analog VLSI Computation 11 as dopant concentration gradients or oxide thickness. [Allen 87] and <ref> [Millman 79] </ref> describe circuit and layout techniques to reduce the effects of some common production variations. Even with clever layout tricks, we still need a reliable way to control analog circuits containing only a few components, so we can use them consistently in larger circuits.
Reference: [NAG] <author> NAG Fortran Library, </author> <title> Numerical Algorithms Group, </title> <type> 1400 Opus Place, Suite 200, </type> <address> Downers Grove, IL 60515 </address>
Reference: [Naka 91] <author> Naka, Ken-ichi, Hiroko M. Sakai, </author> <title> "The Messages in Optic Nerve Fibers and their Interpretation," </title> <journal> Brain Research Reviews, </journal> <pages> 16 (1991) pp. 135-149, </pages> <publisher> Elsevier Science Publishers. </publisher>
Reference: [O'Dell 88] <author> O'Dell, T. H., </author> <title> "Electronic Circuit Design: Art and Practice," </title> <publisher> Cambridge Universiy Press, </publisher> <address> Cambridge, England, </address> <year> 1988. </year>
Reference-contexts: This process can be applied hierarchically, producing larger systems or applications out of the compensated building blocks. Although many electronic circuits are designed with trimming or compensating capability <ref> [O'Dell 88] </ref>, this strategy has not been consistently used to design systems using analog circuits. It is the assertion of this thesis that a powerful design paradigm is created by always designing components with knobs, and planning the compensation process as part of the production of the design.
Reference: [Platt 89] <author> Platt, J. C., </author> <title> "Constrained Optimization for Neural Networks and Computer Graphics," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, Caltech-CS-TR-89-07, </institution> <month> June, </month> <year> 1989. </year>
Reference-contexts: However, more complex circuits may require more sophisticated optimization methods. A wide variety of constrained optimization algorithms exist which are effective on particular classes of problems (gradient descent, quasi-Newton, simulated annealing, etc) <ref> [Platt 89, Gill 81, Press 86, Fleischer 90] </ref>, and we can choose a method appropriate to the problem at hand. Techniques such as simulated annealing can find optimal parameter combinations for multi-parameter systems with complex behavior, which gives us confidence that our methods will work for more complex circuits. <p> It is important to note that in these discussions, we have chosen a particular constraint to demonstrate the general technique of implementing a constraint in analog VLSI. There are many other examples of useful constraint computation that could be formulated in a similar fashion <ref> [Platt 89] </ref> [Barzel 92], and also could be implemented in analog hardware. The particular constraint that we have chosen to implement is meant to be representative of a large set of possibilities. Our example raises the exciting prospect of implementation of extensive hardware modeling assists in analog VLSI.
Reference: [Press 86] <author> Press, W., Flannery, B., Teukolsky, S., Vetterling, W., </author> <title> "Numerical Recipes: </title> <booktitle> the Art of Scientific Computing," </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference-contexts: However, more complex circuits may require more sophisticated optimization methods. A wide variety of constrained optimization algorithms exist which are effective on particular classes of problems (gradient descent, quasi-Newton, simulated annealing, etc) <ref> [Platt 89, Gill 81, Press 86, Fleischer 90] </ref>, and we can choose a method appropriate to the problem at hand. Techniques such as simulated annealing can find optimal parameter combinations for multi-parameter systems with complex behavior, which gives us confidence that our methods will work for more complex circuits.
Reference: [Pyne 56] <author> Pyne, Insley B., </author> <title> "Linear Programming on an Electronic Analogue Computer," </title> <journal> Trans AIEE, </journal> <volume> Part I, </volume> <pages> 75 (1956) pp. 139-143. </pages>
Reference-contexts: We can then use our a priori knowledge to assist us in the optimization. This approach relates to some early work in on-chip optimization, using static connectivity circuits to solve particular linear and nonlinear programming problems <ref> [Pyne 56] </ref> [Chua 84]. One can assemble static circuits composed of resistors, capacitors, and amplifiers, which can solve nonlinear programming problems [Chua 84]. This is an example of model-based optimization, since the connection scheme is implied by the model.
Reference: [Rhoden 89] <author> Rhoden, Desi, and Chris Wilcox, </author> <title> "Hardware Acceleration for Window Systems," </title> <journal> Computer Graphics, </journal> <volume> Vol. 23, No. 3, </volume> <month> July, </month> <year> 1989, </year> <pages> pp. 61-67. </pages>
Reference-contexts: For instance, Adage implemented matrix multiplication for the purpose of performing coordinate transformations in analog circuitry, although not in VLSI. There is also a history of digital VLSI acceleration in computer graphics: geometry engines [Clark 82], hardware frame buffer assists <ref> [Rhoden 89] </ref>, vector generators [Barkans 90], systems [Voorhies 88] 7.1 Analog VLSI for Constraint Satisfaction 87 [Fuchs 89], etc. Most high-performance graphics workstations have a substantial amount of special purpose chips to provide the kind of interactive performance that we have come to expect.
Reference: [Rubenstein 81] <author> Rubenstein, Reuven Y., </author> <title> Simulation and the Monte Carlo Method, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1981. </year>
Reference: [Rumelhart 86] <editor> Rumelhart, D. E., and J. L. McClelland, Eds., </editor> <booktitle> "Parallel Distributed Processing: Explorations in the Microstructure of Cognition,", </booktitle> <volume> Vol. 1, </volume> <publisher> M.I.T. Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: A direct and unavoidable cost of the smoothness is the susceptibility to noise. Section 8.2 describes a technique for continuous time optimization, and actually uses noise as part of the technique. Many of the learning techniques described in the neural network literature <ref> [Rumelhart 86] </ref> are "model-based," in that the algorithms for updating neural connections are influenced by the knowledge of the "model," or, the network structure involved.
Reference: [Salam 88] <author> Salam, Fathi M. A., and Mark L. Levi, </author> <title> "Dynamical Systems Approaches to Nonlinear Problems in Systems and Circuits," </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, PA, </address> <year> 1988. </year> <note> Bibliography 147 </note>
Reference: [Scott 60] <author> Scott, Norman R., </author> <title> "Analog and Digital Computer Technology," </title> <publisher> Mcgraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1960. </year>
Reference: [Siegel 81] <author> Siegel, Robert, and John R. Howell, </author> <title> "Thermal Radiation Heat Transfer," </title> <publisher> Hemisphere Publishing, </publisher> <address> New York, </address> <year> 1981. </year>
Reference: [Sivilotti 90] <author> Sivilotti, Massimo, </author> <title> "Wiring Considerations in Analog VLSI Systems, with Application to Field-Programmable Networks," </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, Oc-tober, </institution> <year> 1990. </year>
Reference: [Snyder 92] <author> Snyder, John, </author> <title> "Interval Analysis for Computer Graphics," </title> <journal> Computer Graphics, </journal> <volume> Vol. 26, No. 2, </volume> <pages> pp. 121-130. </pages>
Reference-contexts: An area which we identify for future research is to incorporate the consideration of possible device variations and compensatory knob selections into the design and circuit simulation process. Potential avenues of research include using interval analysis [Alefeld 83] <ref> [Snyder 92] </ref> to chart expected values of variations, and using a simulation to validate a range of possible knob selections before fabrication of the circuits. 6.2 Constructing a Compensated Amplifier As a brief introduction to the idea of using knobs for compensation, we'll describe a compensated amplifier [Mead 90] [Mead 91].
Reference: [Soclof 85] <author> Soclof, Sidney, </author> <title> "Analog Integrated Circuits," </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1985. </year>
Reference: [Soroka 54] <author> Soroka, Walter W., </author> <title> "Analog Methods in Computation and Simulation," </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1954. </year>
Reference-contexts: There is some analogy in the operation of our number to signal mapping function G to the oft-lamented "scaling problem" in the analog computers from the 1940s and 50s [Tomovic 62] <ref> [Soroka 54] </ref>. The scaling problem deals with choosing analog signals to represent numbers. We are addressing a similar need to map a desired computation onto some substrate. Thus, the scaling problem is a subset of the problem we are addressing.
Reference: [Thomsen 91] <author> Thomsen, Axel, and Martin A. Brooke, </author> <title> "A Floating-Gate MOSFET with Tunneling Injector Fabricated Using a Standard Double-Polysilicon CMOS Process," </title> <journal> IEEE Electron Device Letters, </journal> <volume> Vol. 12, No. 3, </volume> <pages> pp. 111-113, </pages> <month> March, </month> <year> 1991. </year>
Reference-contexts: This permanance of charge on a floating gate is especially attractive for a device or design compensation application, since we will often wish to compensate for errors once, and retain the same setting. Methods for adding/removing charge include hot electron injection [Anderson 90], Fowler-Nordheim tunneling <ref> [Thomsen 91] </ref>, and UV-induced electron transfer [Kerns 92b]. Kerns [Kerns 92b] describes some issues related to fabricating and using floating-gate compensated amplifiers, particularly by using UV-induced electron transfer to adjust the charge on floating gates.
Reference: [Thorpe 79] <author> Thorpe, J. A., </author> <title> Elementary Topics in Differential Geometry, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: For more rigorous definitions, please see <ref> [Thorpe 79] </ref>. Glossary 138 coordinate chart A coordinate chart is a parameterization from a set of input coordinates to an output N-surface. See [Thorpe 79]. differential geometry A field of mathematics which studies N -dimensional surfaces and their properties. See [Thorpe 79]. direct method A direct method is one which guarantees <p> For more rigorous definitions, please see <ref> [Thorpe 79] </ref>. Glossary 138 coordinate chart A coordinate chart is a parameterization from a set of input coordinates to an output N-surface. See [Thorpe 79]. differential geometry A field of mathematics which studies N -dimensional surfaces and their properties. See [Thorpe 79]. direct method A direct method is one which guarantees solution of the problem, by solving the problem explicitly, rather than implicitly. <p> For more rigorous definitions, please see <ref> [Thorpe 79] </ref>. Glossary 138 coordinate chart A coordinate chart is a parameterization from a set of input coordinates to an output N-surface. See [Thorpe 79]. differential geometry A field of mathematics which studies N -dimensional surfaces and their properties. See [Thorpe 79]. direct method A direct method is one which guarantees solution of the problem, by solving the problem explicitly, rather than implicitly. <p> The blending functions add to 1, or unity. See <ref> [Thorpe 79] </ref>. precision Precision can be defined as "the degree of agreement of repeated measurements of a quantity" and, as such, is a quantification of how much useful information is present in a Glossary 139 measurement.
Reference: [Tomovic 62] <author> Tomovic, Rajko, and Walter J. Karplus, </author> <title> "High-Speed Analog Computers," </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <year> 1962. </year>
Reference-contexts: There is some analogy in the operation of our number to signal mapping function G to the oft-lamented "scaling problem" in the analog computers from the 1940s and 50s <ref> [Tomovic 62] </ref> [Soroka 54]. The scaling problem deals with choosing analog signals to represent numbers. We are addressing a similar need to map a desired computation onto some substrate. Thus, the scaling problem is a subset of the problem we are addressing.
Reference: [Toumazou 90] <author> Toumazou, C., F. J. Lidgey, and D. G. Haigh, </author> <title> "Analogue IC Design: the Current Mode Approach," </title> <publisher> Peter Peregrinus Ltd., </publisher> <address> London, United Kingdom, </address> <year> 1990. </year> <note> Bibliography 148 </note>
Reference-contexts: There are several possible benefits of the coordinate chart representation, but we only exploit one of them in our thought experiment. For a real circuit, it is reasonable to assume that a piecewise representation, as in the coordinate chart approach, permits us to more accurately compute the function. In <ref> [Toumazou 90] </ref>, Gilbert discusses the merits of piecewise function approximation for computing trigonometric functions in analog, specifically ECL, circuits.
Reference: [Traub 88] <author> Traub, J. F., G. W. Wasilkowski, H. Wozniakowski, </author> <title> "Information-based Complexity," </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: We are particularly interested in tradeoffs between accuracy, precision, and resources such as time and circuit size (silicon area). Traub's Information-Based Complexity (IBC) studies the computational complexity of infinite dimensional problems <ref> [Traub 88] </ref>. Such problems arise in continuous mathematical models as are often used in engineering, particularly when integration, optimization, and/or differentiation are involved. Since digital computers can represent only a finite set of numbers, then many continuous inputs and outputs can only be approximated.
Reference: [Tsividis 86] <author> Tsividis, Yannis, Mihai Banu, and John Khoury, </author> <title> "Continuous-Time MOSFET-C Filters in VLSI," </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <volume> Vol. CAS-33, No. 2, </volume> <pages> pp. 125-140, </pages> <month> February </month> <year> 1986. </year>
Reference-contexts: we subtract I2 from I1, we get, to a first-order approximation: (6.11) I diff = (w w 0 )(x x 0 ) : 6.3 Differential Multipliers 72 6.3.2 Four-transistor Multiplier We can cancel out more higher order nonlinearities by using a 4 transistor multiplier design, as shown in Fig. 6.6 <ref> [Tsividis 86] </ref>.
Reference: [Ullman 92] <author> Ullman, David G., </author> <title> "The Mechanical Design Process," </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Many researchers have determined that integrating goal-setting behavior into the design process has many benefits <ref> [Ullman 92] </ref>. We encourage this approach, and desire to make the choice of goals explicit, not tacit. Explicit and detailed enumeration of design goals is a powerful tool for producing successful projects. We don't mean to imply that most designers create products without having goals beforehand.
Reference: [Ullman 84] <author> Ullman, Jeffrey D., </author> <title> "Computational Aspects of VLSI," </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1984. </year>
Reference: [Umminger 89] <author> Umminger, Christopher B., and Steven P. DeWeerth, </author> <title> "Implementing Gradient Following in Analog VLSI," </title> <booktitle> Advanced Research in VLSI, </booktitle> <publisher> MIT Press, </publisher> <address> Boston, </address> <year> 1989, </year> <pages> pp. 195-208. </pages>
Reference-contexts: Unlike previous work using noise sources in adaptive systems, we use the noise as a means of estimating the gradient of a function f (y), rather than performing an annealing process [Alspector 88]. We also estimate gradients continuously in position and time, in contrast to <ref> [Umminger 89] </ref> and [Jabri 91], which utilize discrete position gradient estimates. It is interesting to note the existence of related algorithms, developed at approximately the same time [Cauwenberghs 93] [Alspector 93] [Flower 93].
Reference: [Vergis 86] <author> Vergis, Anastasios, Kenneth Steiglitz, and Bradley Dickinson, </author> <title> "The Complexity of Analog Computation," </title> <booktitle> Mathematics and Computers in Simulation 28 (1986) 91-113, </booktitle> <publisher> North-Holland. </publisher>
Reference-contexts: Although we have stated that there is a dearth of work in the area of analog complexity theory, there is some work. Vergis et al <ref> [Vergis 86] </ref> discusses the complexity of mechanical analog computation for a very restricted class of problems. Their analysis explicitly rules out quantum mechanics, other probabilistic behavior, and nonlinear devices as not applicable to their analysis. By eliminating nonlinearities, Vergis explicitly excludes those things that we are most interested in exploiting.
Reference: [Voorhies 88] <author> Voorhies, Douglas, D. Kirk, and O. Lathrop, </author> <title> "Virtual Graphics," </title> <journal> Computer Graphics, </journal> <volume> Vol. 22, No. 4, </volume> <month> August, </month> <year> 1988, </year> <pages> pp. 247-253. </pages>
Reference-contexts: For instance, Adage implemented matrix multiplication for the purpose of performing coordinate transformations in analog circuitry, although not in VLSI. There is also a history of digital VLSI acceleration in computer graphics: geometry engines [Clark 82], hardware frame buffer assists [Rhoden 89], vector generators [Barkans 90], systems <ref> [Voorhies 88] </ref> 7.1 Analog VLSI for Constraint Satisfaction 87 [Fuchs 89], etc. Most high-performance graphics workstations have a substantial amount of special purpose chips to provide the kind of interactive performance that we have come to expect. Most, if not all of this silicon is dedicated to rendering tasks.
References-found: 82

