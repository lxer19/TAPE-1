URL: http://www.cs.virginia.edu/~son/publications/dasfaa95.ps
Refering-URL: http://www.cs.virginia.edu/~son/publications.html
Root-URL: http://www.cs.virginia.edu
Title: 1 ABSTRACT Schedulers for distributed real-time database sys tems must satisfy timing constraints of transactions
Note: uling and  
Abstract: preserve data consistency. This paper presents a replica tion control algorithm, which integrates real-time sched
Abstract-found: 1
Intro-found: 1
Reference: [Abb92] <author> R.Abbott, and H.Garcia-Molina, </author> <title> "Scheduling Real-time Transactions: a Performance Evaluation", </title> <journal> ACM Trans. on Database Systems, </journal> <volume> vol. 17, no. 3, </volume> <month> Sept. </month> <year> 1992, </year> <pages> pp 513-560. </pages>
Reference-contexts: Several requests can be submitted at the same time, and many read/write operations take place simultaneously at different sites. 5.1 Metrics and Parameter Settings - 6 - The performance metric employed is the percentage of transactions that missed their deadlines (% missed) <ref> [Abb92] </ref> in the total number of transactions that were submitted to the system during the simulation period: In case their time slack is not sufficient for their minimum execution time requirements, transactions are permanently removed from the system and the tardy transactions counter is incremented. <p> The data objects accessed by transactions are chosen uniformly from the database. The deadline assigned to every incoming transaction is given by the formula <ref> [Abb92] </ref>: deadline = arrival_time + execution_time_estimate + slack_time The execution time estimate is computed as the time that the transaction would need to read the local values of the data objects in its read-set and write the new values of the data objects in its write-set in all of the token-sites,
Reference: [Ber87] <author> P.A.Bernstein, V.Hadzilacos, and N.Good-man, </author> <title> "Concurrency Control and Recovery in Database Systems", </title> <publisher> Addison-Wesley Publishing Co., </publisher> <year> 1987. </year>
Reference-contexts: The correctness proof of the quorum consensus algorithm is provided in <ref> [Ber87] </ref>. Another proof for the majority consensus algorithm is in [Tho79]. In the quorum consensus algorithm, each read (or write) operation on a data object is translated into reads (or writes) on copies of the data object in some read (or write) quorum.
Reference: [Her86] <author> M.Herlihy, </author> <title> "A Quorum-Consensus Replication Method for Abstract Data Types", </title> <journal> ACM Trans on Database Systems, </journal> <volume> Vol. 4, No. 1, </volume> <pages> pp. 32 - 53, </pages> <year> 1986. </year>
Reference-contexts: This is because if T2 is restarted right away, it will probably conict with T1 again, and be aborted again, resulting in a waste of system resources. 4.4 Correctness To establish the correctness of the algorithm, we argue that the algorithm is a special case of the quorum consensus algorithm <ref> [Her86] </ref>. The correctness proof of the quorum consensus algorithm is provided in [Ber87]. Another proof for the majority consensus algorithm is in [Tho79].
Reference: [Pu91] <author> C.Pu, and A.Leff, </author> <title> "Replica Control in Distributed Systems: An Asynchronous Approach", </title> <booktitle> ACM SIGMOD Confernece, </booktitle> <address> Denver, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: A less stringent, general-purpose consistency criterion is necessary. The new criterion should allow more real-time transactions to satisfy their timing constraints by temporarily sacrificing database consistency to some small degree. Epsilon-serializability (ESR) is such a correctness criterion, offering the possibility of maintaining mutual consistency of replicated data asynchronously <ref> [Pu91] </ref>. Inconsistent data may be seen by certain query transactions, but data will eventually converge to a consistent state. <p> If the time-stamp of the update is more current, the update is made normally, otherwise the update is omitted. 3. Epsilon-Serializability Epsilon-serializability (ESR) is a correctness criterion that enables asynchronous maintenance of mutual consistency of replicated data <ref> [Pu91] </ref>. A transaction with ESR as its correctness criterion is called an epsilon-transaction (ET). An ET is a query ET if it consists of only reads. An ET containing at least one write is an update ET. Query ETs may see an inconsistent data state produced by update ETs. <p> Among several replica control methods based on ESR, we have chosen the ordered updates approach <ref> [Pu91] </ref>. The ordered updates approach allows more con-currency than 1SR in two ways. First, query ETs can be processed in any order because they are allowed to see intermediate, inconsistent results. Second, update ETs may update different replicas of the same object asynchronously, but in the same order.
Reference: [Ram91] <author> K. Ramamritham and C.Pu, </author> <title> "A Formal Characterization of Epsilon Serializability, </title> <type> Tech. Rep., </type> <institution> Dep. of Computer and Information Science, University of Massachusetts, Massachusetts, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Since arbitrary queries may produce results beyond allowed inconsistency even within its overlap limit, it is important to restrict ET queries to have certain properties that permit tight inconsistency bounds. A first attempt in this approach is proposed in <ref> [Ram91] </ref>. It is beyond the scope of this paper to deal with such strategies. In the remainder of the paper, we assume that inconsistency bounds can be enforced by the system if necessary. 4.2.
Reference: [Son87] <author> S.H.Son, </author> <title> Synchronization of Replicated Data in Distributed Systems, </title> <journal> Information Systems, </journal> <volume> vol. 12, no. 2, </volume> <pages> pp 191-202. </pages> <year> 1987. </year>
Reference-contexts: As a consequence, data consistency might be compromised to satisfy timing constraints. In replication control methods, on the other hand, the objective is to provide a high degree of concurrency and thus faster average response time without violating data consistency <ref> [Son87] </ref>. Two different policies can be employed in order to synchronize concurrent data access of transactions and to ensure identical replica values: blocking transactions or aborting transactions. However, blocking may cause priority inversion when a high priority transaction is blocked by lower priority transactions.
Reference: [Son92] <author> S.H.Son, </author> <title> An Environment for Integrated Development and Evaluation of Real-Time Distributed Database Systems, </title> <journal> Journal of Systems Integration, </journal> <volume> vol. 2, no. 1, </volume> <month> February </month> <year> 1992, </year> <pages> pp 67-90. </pages>
Reference-contexts: World Scientific Publishing Co. Pte Ltd - 2 - base system, a message server process runs at each site and take care of the communication protocols between its site and all others. Data managers are low-level processes, running one per site, that manage the local database <ref> [Son92] </ref>. The smallest unit of data accessible to the user is called data object. In distributed database systems with replicated data objects, a logical data object is represented by a set of one or more replicated physical data objects. <p> We present a number of performance experiments for the two approaches under various assumptions about the transaction load, the percentage of update transactions in the total number of transactions submitted to the system during the simulation period, and the database size. A real-time distributed database prototyping environment <ref> [Son92] </ref> was used to build the simulation program. The environment provides the user with multiple threads of execution and guarantees the consistency of concurrently executing processes.
Reference: [Son93] <author> S. H. Son and S. Kouloumbis, </author> <title> A Token-Based Synchronization Scheme for Distributed Real-Time Databases, </title> <journal> Information Systems, </journal> <volume> vol. 18, no. 6, </volume> <month> Dec. </month> <year> 1993, </year> <pages> pp 375-389. </pages>
Reference-contexts: Epsilon-serializability is employed as the correctness criterion to guarantee the consistency of the replicated database. We also present results from the performance study of our real-time majority consensus algorithm compared to a different real-time replication control algorithm based on token-based synchronization scheme <ref> [Son93] </ref>. 2. Database Model A distributed system consists of multiple autonomous computer systems (sites) connected via a communication network. Each site maintains a local database system. <p> The favored transaction, i.e. the winner of the conict, gets the resources that it needs to proceed. 4.3. Conict Resolution Before presenting the conict resolution scheme of the algorithm, we first outline the token-based approach for comparison. A detailed description of the token-based approach is presented in <ref> [Son93] </ref>. In token-based approach, a token designates a read-write copy that contains the latest version of a data object. The site which has a token copy of a logical data object is called a token site, with respect to the logical data object.
Reference: [Tho79] <author> R.H.Thomas, </author> <title> "A Majority Consensus Approach to Concurrency Control for Multiple Copy Databases", </title> <journal> ACM Trans on Database Systems, </journal> <volume> Vol. 4, No. 2, </volume> <pages> pp. 180 - 209, </pages> <month> June </month> <year> 1979. </year>
Reference-contexts: Base variables are a joint set of its read-set and write-set. We assume that for each transaction, the write-set is a subset of the read-set. Therefore a transaction must first read a data object before writes to it. In majority consensus approach <ref> [Tho79] </ref>, transactions first read all the data objects in the read-set from its local database, and then go through the voting procedure. Having received a vote request from a transaction, the site manager first checks to see if all the base variables of the transaction are up-to-date. <p> The correctness proof of the quorum consensus algorithm is provided in [Ber87]. Another proof for the majority consensus algorithm is in <ref> [Tho79] </ref>. In the quorum consensus algorithm, each read (or write) operation on a data object is translated into reads (or writes) on copies of the data object in some read (or write) quorum.
Reference: [Yu94] <author> P. Yu, K. Wu, K. Lin, and S. H. Son, </author> <title> On Real-Time Databases: Concurrency Control and Scheduling, </title> <booktitle> Proceedings of IEEE, Special Issue on Real-Time Systems, </booktitle> <month> January </month> <year> 1994, </year> <pages> pp 140-157. </pages> - <note> 8 - % Missed deadlines % Missed deadlines % Missed deadlines % Missed deadlines % Missed deadlines % Missed deadlines </note>
Reference-contexts: 1. Introduction In real-time distributed database systems, timeliness of results can be as important as their correctness <ref> [Yu94] </ref>. The problems related to replication control such as the preservation of mutual and internal consistency become more difficult when timing constraints are imposed on transactions. Transactions must be scheduled to meet the timing constraints and to ensure data consistency.
References-found: 10

