URL: ftp://ftp.cs.yale.edu/WWW/users/westbrook/dissertation.ps.Z
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/westbrook-jeffery.html
Root-URL: http://www.cs.yale.edu
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> B. Awerbuch and Y. Shiloach. </author> <title> New connectivity and msf algorithms for shu*e-exchange network and pram. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-36:1258-1263, </volume> <year> 1987. </year>
Reference-contexts: We present remarks, conclusions, and open problems at the end of the chapter to which they are relevant, rather than in a final chapter. The results of chapter two have appeared in [27]. Chapter five is joint work with Roberto Tamassia of Brown University. 3 References for chapter 1. <ref> [1] </ref> B. Chazelle, "How to search in history," Information and Control 64 (1985), 77-99. [2] B. Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. <p> Our computational model is the pointer machine [5,6,10,12] with an added assumption about the data structure called separability. Related results follow. Tarjan [12] derived an amortized bound in this model for the set union problem without backtracking. Blum <ref> [1] </ref> derived a 17 worst-case-per-operation lower bound for the same problem. Mehlhorn, Naher, and Alt [9] derived an amortized lower bound for a related problem. Their result does not require separability. The algorithms to which our lower bound applies are called separable pointer algorithms. <p> distance at least b from the set name, i.e. case (1) applies. 2 2.5 Remarks Our bound of fi (logn=log logn) on the amortized time per operation in the set union problem with backtracking is the same as Blum's worst-case bound per operation in the set union problem without backtracking <ref> [1] </ref>. Perhaps this is not a coincidence. Our lower bound proof resembles his. Furthermore the data structure he uses to establish his upper bound can easily be extended to handle de-union operations; the worst-case bound per operation remains O (logn=log logn) and the space needed is O (n). <p> We conjecture that the bound in Theorem 3 holds for cell probe algorithms. References for chapter 2. <ref> [1] </ref> N. Blum, "On the single-operation worst-case time complexity of the disjoint set union problem," SIAM J. Comput. 15 (1986), 1021-1024. [2] M. L. Fredman and Michael E. <p> Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references <ref> [1] </ref>, [8], and [12] (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> Thus the upper bound of O (ff (m; n)) amortized time per operation for this version of the dynamic component problem is tight. References for Chapter 3 <ref> [1] </ref> B. Awerbuch and Y. Shiloach, "New connectivity and MSF algorithms for shu*e-exchange network and PRAM," IEEE Trans. on Computers C-36 (1987), pp. 1258-1263. [2] G. A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). [3] S. <p> Hopcroft and Tarjan [9] and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references <ref> [1] </ref> and [24] (see also the survey paper [10]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24].
Reference: [2] <author> G. D. Battista and R. Tamassia. </author> <title> Incremental planarity testing. </title> <booktitle> In Proc. 30th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 436-441, </pages> <year> 1989. </year>
Reference-contexts: The results of chapter two have appeared in [27]. Chapter five is joint work with Roberto Tamassia of Brown University. 3 References for chapter 1. [1] B. Chazelle, "How to search in history," Information and Control 64 (1985), 77-99. <ref> [2] </ref> B. Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. [4] R. <p> The techniques of Mehlhorn, N:aher, and Alt [9] suggest an approach to this question, which might yield at least an (log logn) bound if not an (logn=log logn) bound on the amortized time. Recently, Fredman and Saks <ref> [2] </ref> have given an (ff (m; n)) bound on the amortized cost per operation in the cell probe model of Yao [15]. It is also possible to show an (log n= log log n) bound on the worst-case cost per operation [M. Fredman, private communication, 1989]. <p> We conjecture that the bound in Theorem 3 holds for cell probe algorithms. References for chapter 2. [1] N. Blum, "On the single-operation worst-case time complexity of the disjoint set union problem," SIAM J. Comput. 15 (1986), 1021-1024. <ref> [2] </ref> M. L. Fredman and Michael E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symp. on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [3] H. N. Gabow and R. E. Tarjan, "A linear-time algorithm for a special case of disjoint set union," J. <p> References for Chapter 3 [1] B. Awerbuch and Y. Shiloach, "New connectivity and MSF algorithms for shu*e-exchange network and PRAM," IEEE Trans. on Computers C-36 (1987), pp. 1258-1263. <ref> [2] </ref> G. A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). [3] S. Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. [4] M. L. Fredman and M. E. <p> The block and bridge-block problems are fundamental problems in the study of on-line graph algorithms, a study that has wide applications to networks, CAD/CAM, and distributed computing. They appear as subproblems of other on-line graph problems, such as incremental planarity testing <ref> [2] </ref>. The incremental planarity testing problem is to maintain a representation of a planar graph as edges are being added, and to determine the first edge addition that makes the graph nonplanar.
Reference: [3] <author> G. D. Battista and R. Tamassia. </author> <title> On-line graph algorithms with spqr-trees. </title> <booktitle> In Proc. 17th ICALP, </booktitle> <year> 1990. </year> <note> To appear. </note>
Reference-contexts: Chazelle, "How to search in history," Information and Control 64 (1985), 77-99. [2] B. Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. <ref> [3] </ref> B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. [4] R. Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. [5] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. <p> For the special case of the problem in which the subsequence of union operations is known in advance, the use of address arithmetic techniques leads to an algorithm with an amortized time bound of O (1) per operation <ref> [3] </ref>. Mannila and Ukkonen [8] studied a generalization of the set union problem called set union with backtracking, in which the following third kind of operation is allowed: de-union: Undo the most recently performed union operation that has not yet been undone. <p> Blum, "On the single-operation worst-case time complexity of the disjoint set union problem," SIAM J. Comput. 15 (1986), 1021-1024. [2] M. L. Fredman and Michael E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symp. on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. <ref> [3] </ref> H. N. Gabow and R. E. Tarjan, "A linear-time algorithm for a special case of disjoint set union," J. Comput. Sys. Sci. 30 (1985), 209-221. 21 [4] G. Gambiosi, G. F. Italiano, and M. <p> Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach <ref> [3] </ref> consider the component problem for a graph undergoing edge deletions. <p> Awerbuch and Y. Shiloach, "New connectivity and MSF algorithms for shu*e-exchange network and PRAM," IEEE Trans. on Computers C-36 (1987), pp. 1258-1263. [2] G. A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). <ref> [3] </ref> S. Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. [4] M. L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [5] G. N. <p> In recent work other researchers have addressed several problems that we posed in the preliminary version of this paper [25]. Tamassia and Di Battista <ref> [3] </ref> give a data structure that uses our condensible nodes and maintains the triconnected components of a graph; m operations require O (mff (m; n)) time if the graph is initially biconnected, and O (m log n) time otherwise.
Reference: [4] <author> N. Blum. </author> <title> On the single-operation worst-case time complexity of the disjoint set union problem. </title> <journal> SIAM J. Comput., </journal> <volume> 15 </volume> <pages> 1021-1024, </pages> <year> 1986. </year>
Reference-contexts: Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. <ref> [4] </ref> R. Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. [5] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. [6] J. <p> in the worst case, since the maximum tree depth is O (logn) and all pointers on any pointer stack point to distinct elements. (From bottom to top, the pointers on P (x) point to shallower and shallower ancestors of x.) The lazy method also has an O (nlogn) space bound <ref> [4] </ref>. For any node x, consider the top printer on P (x), which is to a node, say y. <p> N. Gabow and R. E. Tarjan, "A linear-time algorithm for a special case of disjoint set union," J. Comput. Sys. Sci. 30 (1985), 209-221. 21 <ref> [4] </ref> G. Gambiosi, G. F. Italiano, and M. Talamo, "Getting back to the past in the union-find problem," 5th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science 294, Springer-Verlag, Berlin, 1988, 8-17. [5] D. E. <p> We note that for the dynamic component problem in which only edge insertions are allowed, the above reduction from disjoint set union allows us to apply both the separable pointer machine lower bound of Tarjan [10] and the cell probe model lower bound of Fredman and Saks <ref> [4] </ref>. Thus the upper bound of O (ff (m; n)) amortized time per operation for this version of the dynamic component problem is tight. References for Chapter 3 [1] B. Awerbuch and Y. <p> A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). [3] S. Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. <ref> [4] </ref> M. L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [5] G. N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 [6] J. <p> Let n be the number of elements and m the number of operations in an instance of disjoint set union. Tarjan [20] gave a lower bound of (ff (m; n)) on the amortized time per operation and Blum <ref> [4] </ref> gave a lower bound of (log n= log logn) on the worst-case time of a single operation. Both these lower bounds apply to the class of separable pointer algorithms for set union [4, 20]. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union <ref> [4, 20] </ref>.
Reference: [5] <author> G. A. Cheston. </author> <title> Incremental Algorithms in Graph Theory. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Toronto, </institution> <year> 1976. </year> <note> Technical Report No. 91. </note>
Reference-contexts: Many examples of the uses of dynamic data structures may be found in Tarjan's monograph [25] and Mehlhorn's three-volume set [15]. Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing <ref> [5] </ref>, and data structures for planar graphs [18,23]. In this dissertation we use red-black (balanced binary) trees [11], splay trees [22], and the dynamic tree data structure of Sleator and Tarjan [21,22], perhaps best known for its use in network flow problems. <p> Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. [4] R. Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. <ref> [5] </ref> M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. [6] J. Driscoll, H. N. Gabow, N. Sarnak and R. E. <p> Comput. Sys. Sci. 30 (1985), 209-221. 21 [4] G. Gambiosi, G. F. Italiano, and M. Talamo, "Getting back to the past in the union-find problem," 5th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science 294, Springer-Verlag, Berlin, 1988, 8-17. <ref> [5] </ref> D. E. Knuth, The Art of Computer Programming, Vol. 1, Fundamental Algo rithms, Addison-Wesley, Reading, MA, 1968. [6] A. N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. [7] H. Mannila and E. <p> Reif [9] gives an algorithm for the same problem that runs in time O (ng + n log n) when given an initial graph embedded in a surface of genus g. Frederickson <ref> [5] </ref> gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the isupth update. <p> Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. [4] M. L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. <ref> [5] </ref> G. N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 [6] J. Hopcroft and R. E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. [7] R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions.
Reference: [6] <author> S. Even and Y. Shiloach. </author> <title> An on-line edge deletion problem. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 28 </volume> <pages> 1-4, </pages> <year> 1981. </year> <month> 66 </month>
Reference-contexts: Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. [5] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. <ref> [6] </ref> J. Driscoll, H. N. Gabow, N. Sarnak and R. E. Tarjan, "Making data structures persistent," Proc. 18th Symp. of Foundations of Computer Science (1986), 109-121. [7] J. Driscoll, H. N. Gabow, R. Shrairman and R. E. <p> Talamo, "Getting back to the past in the union-find problem," 5th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science 294, Springer-Verlag, Berlin, 1988, 8-17. [5] D. E. Knuth, The Art of Computer Programming, Vol. 1, Fundamental Algo rithms, Addison-Wesley, Reading, MA, 1968. <ref> [6] </ref> A. N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. [7] H. Mannila and E. Ukkonen, "On the complexity of unification sequences," Third International Conference on Logic Programming, July 14-18, 1986, Lecture Notes in Computer Science 225, Springer-Verlag, New York, 1986, 122-133. [8] H. <p> The problem of finding the components of a fixed graph G is well-understood. Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan <ref> [6] </ref> and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper [7]). <p> L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [5] G. N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 <ref> [6] </ref> J. Hopcroft and R. E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. [7] R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. Rep. No. CSD 88/408, Dept. of Computer Science, U.C.
Reference: [7] <author> G. N. Frederickson. </author> <title> Data structures for on-line updating of minimum spanning trees, with applications. </title> <journal> SIAM J. Comput., </journal> <volume> 14 </volume> <pages> 781-798, </pages> <year> 1985. </year>
Reference-contexts: E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. [6] J. Driscoll, H. N. Gabow, N. Sarnak and R. E. Tarjan, "Making data structures persistent," Proc. 18th Symp. of Foundations of Computer Science (1986), 109-121. <ref> [7] </ref> J. Driscoll, H. N. Gabow, R. Shrairman and R. E. Tarjan, "Relaxed heaps: an alternative to fibonacci heaps with applications to parallel computation," Comm. ACM 31 (1988), 1343-1354. [8] S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. [9] M. <p> Mannila and Ukkonen [8] studied a generalization of the set union problem called set union with backtracking, in which the following third kind of operation is allowed: de-union: Undo the most recently performed union operation that has not yet been undone. This problem arises in Prolog interpreter memory management <ref> [7] </ref>. Mannila and Ukkonen showed how to extend path compaction techniques to handle backtracking. They posed the question of determining the inherent complexity of the problem, and they claimed an O (loglogn) amortized time bound per operation for one algorithm based on their approach. <p> E. Knuth, The Art of Computer Programming, Vol. 1, Fundamental Algo rithms, Addison-Wesley, Reading, MA, 1968. [6] A. N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. <ref> [7] </ref> H. Mannila and E. Ukkonen, "On the complexity of unification sequences," Third International Conference on Logic Programming, July 14-18, 1986, Lecture Notes in Computer Science 225, Springer-Verlag, New York, 1986, 122-133. [8] H. Mannila and E. Ukkonen, "The set union problem with backtracking," Proc. <p> Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper <ref> [7] </ref>). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 [6] J. Hopcroft and R. E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. <ref> [7] </ref> R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. Rep. No. CSD 88/408, Dept. of Computer Science, U.C. Berkeley (1988). (To appear in Handbook of Theoretical Computer Science, North-Holland.) [8] G. L. Miller and V.
Reference: [8] <author> M. L. Fredman and M. E. Saks. </author> <title> The cell probe complexity of dynamic data structures. </title> <booktitle> In Proc. 21st ACM Symposium on Theory of Computing, </booktitle> <pages> pages 345-354, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Sarnak and R. E. Tarjan, "Making data structures persistent," Proc. 18th Symp. of Foundations of Computer Science (1986), 109-121. [7] J. Driscoll, H. N. Gabow, R. Shrairman and R. E. Tarjan, "Relaxed heaps: an alternative to fibonacci heaps with applications to parallel computation," Comm. ACM 31 (1988), 1343-1354. <ref> [8] </ref> S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. [9] M. L. Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. [10] M. L. <p> For the special case of the problem in which the subsequence of union operations is known in advance, the use of address arithmetic techniques leads to an algorithm with an amortized time bound of O (1) per operation [3]. Mannila and Ukkonen <ref> [8] </ref> studied a generalization of the set union problem called set union with backtracking, in which the following third kind of operation is allowed: de-union: Undo the most recently performed union operation that has not yet been undone. This problem arises in Prolog interpreter memory management [7]. <p> N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. [7] H. Mannila and E. Ukkonen, "On the complexity of unification sequences," Third International Conference on Logic Programming, July 14-18, 1986, Lecture Notes in Computer Science 225, Springer-Verlag, New York, 1986, 122-133. <ref> [8] </ref> H. Mannila and E. Ukkonen, "The set union problem with backtracking," Proc. Thirteenth International Colloquium on Automata, Languages, and Programming (ICALP 86), Rennes, France, July 15-19, 1986, Lecture Notes in Computer Science 226, Springer-Verlag, New York, 1986, 236-243. [9] K. Mehlhorn, S. Naher, and H. <p> Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], <ref> [8] </ref>, and [12] (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. [7] R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. Rep. No. CSD 88/408, Dept. of Computer Science, U.C. Berkeley (1988). (To appear in Handbook of Theoretical Computer Science, North-Holland.) <ref> [8] </ref> G. L. Miller and V. Ramachandran, "A new graph triconnectivity algorithm and its parallelization," Proc. 19th Annual ACM Symp. on Theory of Computing (1987), pp. 335-344. [9] J. H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. [10] R. E. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union [4, 20]. La Poutre [11] has proven the (ff (m; n)) amortized cost bound in a general pointer machine model, and Fredman and Saks <ref> [8] </ref> have shown an (ff (m; n)) bound on the amortized cost per operation and an (log n= log logn) bound on the worst-case cost per operation in the cell probe model of Yao [26].
Reference: [9] <author> J. Hopcroft and R. E. Tarjan. </author> <title> Algorithm 447: Efficient algorithms for graph manipulation. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 16 </volume> <pages> 372-378, </pages> <year> 1973. </year>
Reference-contexts: Driscoll, H. N. Gabow, R. Shrairman and R. E. Tarjan, "Relaxed heaps: an alternative to fibonacci heaps with applications to parallel computation," Comm. ACM 31 (1988), 1343-1354. [8] S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. <ref> [9] </ref> M. L. Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. [10] M. L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. <p> Related results follow. Tarjan [12] derived an amortized bound in this model for the set union problem without backtracking. Blum [1] derived a 17 worst-case-per-operation lower bound for the same problem. Mehlhorn, Naher, and Alt <ref> [9] </ref> derived an amortized lower bound for a related problem. Their result does not require separability. The algorithms to which our lower bound applies are called separable pointer algorithms. <p> The techniques of Mehlhorn, N:aher, and Alt <ref> [9] </ref> suggest an approach to this question, which might yield at least an (log logn) bound if not an (logn=log logn) bound on the amortized time. <p> Mannila and E. Ukkonen, "The set union problem with backtracking," Proc. Thirteenth International Colloquium on Automata, Languages, and Programming (ICALP 86), Rennes, France, July 15-19, 1986, Lecture Notes in Computer Science 226, Springer-Verlag, New York, 1986, 236-243. <ref> [9] </ref> K. Mehlhorn, S. Naher, and H. Alt, "A lower bound for the complexity of the union-split-find problem," SIAM J. Comput. 17 (1988), 1093-1102. [10] A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. [11] R. E. <p> They give algorithms with constant query time, O (n log n) total update time in the case that G is a tree or forest, and O (mn) update time for general G, where m and n are the numbers of edges and vertices, respectively, in the initial graph. Reif <ref> [9] </ref> gives an algorithm for the same problem that runs in time O (ng + n log n) when given an initial graph embedded in a surface of genus g. <p> Rep. No. CSD 88/408, Dept. of Computer Science, U.C. Berkeley (1988). (To appear in Handbook of Theoretical Computer Science, North-Holland.) [8] G. L. Miller and V. Ramachandran, "A new graph triconnectivity algorithm and its parallelization," Proc. 19th Annual ACM Symp. on Theory of Computing (1987), pp. 335-344. <ref> [9] </ref> J. H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. [10] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 [11] R. E. <p> Figure 1 shows an undirected graph along with its blocks and bridge-blocks. The problems of finding the components, blocks, and bridge-blocks of a fixed graph are well-understood. Hopcroft and Tarjan <ref> [9] </ref> and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and [24] (see also the survey paper [10]). <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24]. Even and Shiloach <ref> [9] </ref> consider the component problem for a graph undergoing edge deletions. <p> Frederickson [10] gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the i th update. It is well-known (see, for example, <ref> [9, 24] </ref>) that if only edge insertions are allowed, the component problem can be solved by straightforward application of a fast disjoint set union algorithm. <p> Proof. The bridge-blocks and initial BBF of G 0 can be found in time O (jE 0 j) using one of the algorithms in references <ref> [9, 18] </ref>. By Lemma 1, the total number of pointer steps and condensations is O (m), giving the bound. 2 4.3 Maintaining Blocks On-line The problem of maintaining blocks on-line is similar to that of maintaining bridge-blocks, and the algorithms are almost identical.
Reference: [10] <author> R. Karp and V. Ramachandran. </author> <title> Parallel algorithms for shared memory machines. </title> <type> Technical Report CSD 88/408, </type> <institution> Dept. of Computer Science, U.C. Berkeley, </institution> <year> 1988. </year> <note> To appear in Handbook of Theoretical Computer Science, North-Holland. </note>
Reference-contexts: ACM 31 (1988), 1343-1354. [8] S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. [9] M. L. Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. <ref> [10] </ref> M. L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. Mach. 34 (1987), 596 615. [11] L. J. Guibas and R. <p> Mehlhorn, S. Naher, and H. Alt, "A lower bound for the complexity of the union-split-find problem," SIAM J. Comput. 17 (1988), 1093-1102. <ref> [10] </ref> A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. [11] R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. <p> We note that for the dynamic component problem in which only edge insertions are allowed, the above reduction from disjoint set union allows us to apply both the separable pointer machine lower bound of Tarjan <ref> [10] </ref> and the cell probe model lower bound of Fredman and Saks [4]. Thus the upper bound of O (ff (m; n)) amortized time per operation for this version of the dynamic component problem is tight. References for Chapter 3 [1] B. Awerbuch and Y. <p> L. Miller and V. Ramachandran, "A new graph triconnectivity algorithm and its parallelization," Proc. 19th Annual ACM Symp. on Theory of Computing (1987), pp. 335-344. [9] J. H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. <ref> [10] </ref> R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 [11] R. E. Tarjan, "Depth first search and linear graph algorithms," SIAM J. Com puting 1 (1972), pp. 146-160. [12] R. E. Tarjan and U. <p> Hopcroft and Tarjan [9] and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and [24] (see also the survey paper <ref> [10] </ref>). The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24]. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> Reif [24] gives an algorithm for the same problem that runs in 27 of G. Multiply-appearing vertices are articulation points. 28 time O (ng + n log n) when given an initial graph embedded in a surface of genus g. Frederickson <ref> [10] </ref> gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the i th update.
Reference: [11] <author> J. A. La Poutre. </author> <title> Lower bounds for the union-find and split-find problem on pointer machines. </title> <booktitle> In Proceedings 22nd ACM Symposium on Theory of Computing, </booktitle> <pages> pages 34-44, </pages> <year> 1990. </year>
Reference-contexts: Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. In this dissertation we use red-black (balanced binary) trees <ref> [11] </ref>, splay trees [22], and the dynamic tree data structure of Sleator and Tarjan [21,22], perhaps best known for its use in network flow problems. <p> Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. [10] M. L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. Mach. 34 (1987), 596 615. <ref> [11] </ref> L. J. Guibas and R. Sedgewick, "A Dichromatic framework for balanced trees," Proc. 19th IEEE Symp. on Foundations of Computer Science (1978), 8-21. [12] T. Ibaraki and N. Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 [13] G. F. Italiano, A. <p> For an element x, let size (x) be the number of descendants of x (including itself) in the reference forest. The logarithmic size of x, lgs (x), is log size (x). 1 We need the following lemma concerning logarithmic sizes when union by weight is used. Lemma 1 <ref> [11] </ref> Suppose union by weight is used. If node v is the parent of node w in the reference forest, then lgs (w) &lt; lgs (v). Any node has logarithmic size between 0 and log n (inclusive). <p> Mehlhorn, S. Naher, and H. Alt, "A lower bound for the complexity of the union-split-find problem," SIAM J. Comput. 17 (1988), 1093-1102. [10] A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. <ref> [11] </ref> R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. <p> The problem of finding the components of a fixed graph G is well-understood. Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan [6] and Tarjan <ref> [11] </ref> give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper [7]). <p> H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. [10] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 <ref> [11] </ref> R. E. Tarjan, "Depth first search and linear graph algorithms," SIAM J. Com puting 1 (1972), pp. 146-160. [12] R. E. Tarjan and U. Vishkin, "An efficient parallel biconnectivity algorithm," SIAM J. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union [4, 20]. La Poutre <ref> [11] </ref> has proven the (ff (m; n)) amortized cost bound in a general pointer machine model, and Fredman and Saks [8] have shown an (ff (m; n)) bound on the amortized cost per operation and an (log n= log logn) bound on the worst-case cost per operation in the cell probe
Reference: [12] <author> J. A. La Poutre, J. van Leeuwen, and M. H. Overmars. </author> <title> Maintenance of 2- and 3-edge-connected components of graphs. </title> <type> Manuscript, </type> <year> 1990. </year>
Reference-contexts: L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. Mach. 34 (1987), 596 615. [11] L. J. Guibas and R. Sedgewick, "A Dichromatic framework for balanced trees," Proc. 19th IEEE Symp. on Foundations of Computer Science (1978), 8-21. <ref> [12] </ref> T. Ibaraki and N. Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 [13] G. F. Italiano, A. Marchetti Spaccamela, U. Nanni, "Dynamic data structures for series parallel digraphs," Proc. <p> The fastest such algorithms run in O (ff (m; n)) amortized time per operation, where ff is a functional inverse of Ackermann's function [11,14]. No better bound is possible for any pointer-based algorithm that uses a separable set representation <ref> [12] </ref>. For the special case of the problem in which the subsequence of union operations is known in advance, the use of address arithmetic techniques leads to an algorithm with an amortized time bound of O (1) per operation [3]. <p> Our computational model is the pointer machine [5,6,10,12] with an added assumption about the data structure called separability. Related results follow. Tarjan <ref> [12] </ref> derived an amortized bound in this model for the set union problem without backtracking. Blum [1] derived a 17 worst-case-per-operation lower bound for the same problem. Mehlhorn, Naher, and Alt [9] derived an amortized lower bound for a related problem. Their result does not require separability. <p> Comput. 17 (1988), 1093-1102. [10] A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. [11] R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. <ref> [12] </ref> R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [14] R. E. <p> Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and <ref> [12] </ref> (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> Process. Lett. 25 (1987), pp. 65-70. [10] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 [11] R. E. Tarjan, "Depth first search and linear graph algorithms," SIAM J. Com puting 1 (1972), pp. 146-160. <ref> [12] </ref> R. E. Tarjan and U. Vishkin, "An efficient parallel biconnectivity algorithm," SIAM J. <p> Working independently and using techniques different from ours, La Poutre, van Leeuwen, and Overmars have recently also obtained an O (mff (m; n)) time bound for maintaining bridge-blocks and for maintaining three-edge connected components <ref> [12] </ref>. Their results, as well as other recent work that builds on the preliminary version of the present paper [25] are briefly discussed in Section 1.12. 4.2 Maintaining Bridge-Blocks On-Line The bridge-blocks and bridges of a connected graph have a natural tree structure that we call the bridge-block tree. <p> Galil and Italiano [private communication, 1990] use our condensible nodes in designing a data structure to maintain the 3-edge-connected components of an initially connected graph in O (mff (m; n)) total time. La Poutre, van Leeuwen and Overmars <ref> [12] </ref>, working independently, have designed a different data structure for maintaining bridge-blocks and 3-edge-connected components that runs in total time O (mff (m; n)). They claim that their approach can be extended to the problem of maintaining biconnected and triconnected components.
Reference: [13] <author> J. H. Reif. </author> <title> A topological approach to dynamic graph connectivity. </title> <journal> Inform. Process. Lett., </journal> <volume> 25 </volume> <pages> 65-70, </pages> <year> 1987. </year>
Reference-contexts: Mach. 34 (1987), 596 615. [11] L. J. Guibas and R. Sedgewick, "A Dichromatic framework for balanced trees," Proc. 19th IEEE Symp. on Foundations of Computer Science (1978), 8-21. [12] T. Ibaraki and N. Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 <ref> [13] </ref> G. F. Italiano, A. Marchetti Spaccamela, U. Nanni, "Dynamic data structures for series parallel digraphs," Proc. Workshop on Algorithms and Data Structures (WADS 89) (Lecture Notes in Computer Science), Springer-Verlag, New York (1989). [14] J. A. <p> Comput. 9 (1980), 490-508. [11] R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. <ref> [13] </ref> R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [14] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [15] A. C. Yao, "Should tables be sorted?" J. Assoc. Comput.
Reference: [14] <author> D. D. Sleator and R. E. Tarjan. </author> <title> A data structure for dynamic trees. </title> <journal> J. Comput. System Sci., </journal> <volume> 26 </volume> <pages> 362-391, </pages> <year> 1983. </year>
Reference-contexts: Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 [13] G. F. Italiano, A. Marchetti Spaccamela, U. Nanni, "Dynamic data structures for series parallel digraphs," Proc. Workshop on Algorithms and Data Structures (WADS 89) (Lecture Notes in Computer Science), Springer-Verlag, New York (1989). <ref> [14] </ref> J. A. La Poutr'e and J. van Leeuwen, "Maintenance of transitive closure and transitive reduction of graphs," Proc. International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. [15] K. Mehlhorn, Data Structures and Algorithms (3 volumes). <p> The two choices of a union rule and three choices of a compaction rule give six possible set union algorithms. Each of these has an amortized running time of O (ff (m; n)) per operation <ref> [14] </ref>. We shall describe two ways to extend these and similar algorithms to handle de-union operations. The first method is the one proposed by Mannila and Ukkonen; the second is a slight variant. We call a union operation that has been done but not yet undone live. <p> The time to maintain set names and sizes or ranks is O (1) per union or de-union; thus each union or de-union takes O (1) time, worst-case. Either union rule guarantees a maximum tree depth of O (logn) <ref> [14] </ref>; thus the worst-case time per find is O (logn). The space needed by the data structure is O (n). Mannila and Ukkonen's goal was to reduce the time per find, possibly at the cost of increasing the time per union or de-union and increasing the space. <p> Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. <ref> [14] </ref> R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [15] A. C. Yao, "Should tables be sorted?" J. Assoc. Comput.
Reference: [15] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Self-adjusting binary search trees. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 32 </volume> <pages> 652-686, </pages> <year> 1985. </year>
Reference-contexts: In developing our on-line graph algorithms, our paradigm is the use of dynamic data structures and amortized analysis. Many examples of the uses of dynamic data structures may be found in Tarjan's monograph [25] and Mehlhorn's three-volume set <ref> [15] </ref>. Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. <p> A. La Poutr'e and J. van Leeuwen, "Maintenance of transitive closure and transitive reduction of graphs," Proc. International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. <ref> [15] </ref> K. Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). [16] K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). [17] M. <p> Recently, Fredman and Saks [2] have given an (ff (m; n)) bound on the amortized cost per operation in the cell probe model of Yao <ref> [15] </ref>. It is also possible to show an (log n= log log n) bound on the worst-case cost per operation [M. Fredman, private communication, 1989]. In this powerful and general model, memory is organized into cells, each of which can hold log n bits. <p> Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [14] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. <ref> [15] </ref> A. C. Yao, "Should tables be sorted?" J. Assoc. Comput. Mach. 28 (1981), 615-628. 3 Maintaining Connected Components with Back- tracking Perhaps the most fundamental equivalence relation on the constituents of an undi-rected graph G = (V; E) is defined by its connected components.
Reference: [16] <author> R. Tamassia. </author> <title> A dynamic data structure for planar graph embedding. </title> <booktitle> In Proc. 15th Int. Conf. on Automata, Languages, and Programming, (ICALP 1988), Lecture Notes in Computer Science, </booktitle> <volume> vol. 317, </volume> <pages> pages 576-590. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: La Poutr'e and J. van Leeuwen, "Maintenance of transitive closure and transitive reduction of graphs," Proc. International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. [15] K. Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). <ref> [16] </ref> K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). [17] M. Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). [18] F. P. Preparata and R.
Reference: [17] <author> R. Tamassia. </author> <title> Dynamic Data Structures for Two-Dimensional Searching. </title> <type> PhD thesis, </type> <institution> Coordinated Science Laboratory, University of Illinois at Urbana-Champagne, </institution> <year> 1988. </year> <note> Technical Report ACT-100. 67 </note>
Reference-contexts: In developing our on-line graph algorithms, our paradigm is the use of dynamic data structures and amortized analysis. Many examples of the uses of dynamic data structures may be found in Tarjan's monograph [25] and Mehlhorn's three-volume set [15]. Another general source is the monograph of Overmars <ref> [17] </ref>. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. <p> International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. [15] K. Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). [16] K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). <ref> [17] </ref> M. Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). [18] F. P. Preparata and R. <p> Maintaining the blocks of a dynamic graph also arises in the implementation of efficient search strategies for logic programming [Graeme Port, private communication, 1988]. Tamassia <ref> [29, 17] </ref> gives a data structure for the on-line block problem that achieves O (log n) worst-case query time and O (log n) amortized update time. This paper is organized as follows.
Reference: [18] <author> R. E. Tarjan. </author> <title> Depth first search and linear graph algorithms. </title> <journal> SIAM J. Comput--ing, </journal> <volume> 1 </volume> <pages> 146-160, </pages> <year> 1972. </year>
Reference-contexts: Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). [16] K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). [17] M. Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). <ref> [18] </ref> F. P. Preparata and R. Tamassia, "Fully dynamic techniques for point location and transitive closure in planar structures," Proc. 29th IEEE Symposium on Foundations of Computer Science, (1988), 558-567. [19] H. <p> Figure 1 shows an undirected graph along with its blocks and bridge-blocks. The problems of finding the components, blocks, and bridge-blocks of a fixed graph are well-understood. Hopcroft and Tarjan [9] and Tarjan <ref> [18] </ref> give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and [24] (see also the survey paper [10]). <p> Proof. The bridge-blocks and initial BBF of G 0 can be found in time O (jE 0 j) using one of the algorithms in references <ref> [9, 18] </ref>. By Lemma 1, the total number of pointer steps and condensations is O (m), giving the bound. 2 4.3 Maintaining Blocks On-line The problem of maintaining blocks on-line is similar to that of maintaining bridge-blocks, and the algorithms are almost identical.
Reference: [19] <author> R. E. Tarjan. </author> <title> Efficiency of a good but not linear set union algorithm. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 22 </volume> <pages> 215-225, </pages> <year> 1975. </year>
Reference-contexts: Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). [18] F. P. Preparata and R. Tamassia, "Fully dynamic techniques for point location and transitive closure in planar structures," Proc. 29th IEEE Symposium on Foundations of Computer Science, (1988), 558-567. <ref> [19] </ref> H. Rohnert, "A dynamization of the all-pairs least cost path problem," Proc. 2nd Annual Symp. on Theoretical Aspects of Computer Science (Lecture Notes in Computer Science), Springer-Verlag, New York (1985), 279-286. [20] N. Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. <p> The fastest algorithms for this problem run in O (ff (m; n)) amortized time per operation 2 and O (n) space, where m is the length of the sequence, n is the total number of elements, and ff is a functional inverse of Ackermann's function <ref> [19, 23] </ref>. In this paper we study the problems of answering queries about the blocks or bridge-blocks of a dynamic graph. We allow two on-line graph update operations to be performed on an initially null graph G: make vertex (A): Add a new vertex with no incident edges to G.
Reference: [20] <author> R. E. Tarjan. </author> <title> A class of algorithms which require nonlinear time to maintain disjoint sets. </title> <journal> J. Comput. Sys. Sci., </journal> <volume> 18 </volume> <pages> 110-127, </pages> <year> 1979. </year>
Reference-contexts: Rohnert, "A dynamization of the all-pairs least cost path problem," Proc. 2nd Annual Symp. on Theoretical Aspects of Computer Science (Lecture Notes in Computer Science), Springer-Verlag, New York (1985), 279-286. <ref> [20] </ref> N. Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. ACM 29 (1986), 669-679. [21] D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. <p> Let n be the number of elements and m the number of operations in an instance of disjoint set union. Tarjan <ref> [20] </ref> gave a lower bound of (ff (m; n)) on the amortized time per operation and Blum [4] gave a lower bound of (log n= log logn) on the worst-case time of a single operation. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union <ref> [4, 20] </ref>.
Reference: [21] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, PA., </address> <year> 1983. </year>
Reference-contexts: Rohnert, "A dynamization of the all-pairs least cost path problem," Proc. 2nd Annual Symp. on Theoretical Aspects of Computer Science (Lecture Notes in Computer Science), Springer-Verlag, New York (1985), 279-286. [20] N. Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. ACM 29 (1986), 669-679. <ref> [21] </ref> D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R.
Reference: [22] <author> R. E. Tarjan. </author> <title> Amortized computational complexity. </title> <journal> SIAM J. Alg. Disc. Meth., </journal> <volume> 6 </volume> <pages> 306-318, </pages> <year> 1985. </year>
Reference-contexts: Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. In this dissertation we use red-black (balanced binary) trees [11], splay trees <ref> [22] </ref>, and the dynamic tree data structure of Sleator and Tarjan [21,22], perhaps best known for its use in network flow problems. <p> Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. ACM 29 (1986), 669-679. [21] D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. <ref> [22] </ref> D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. [24] R. E. Tarjan, "Amortized computational complexity," SIAM J.
Reference: [23] <author> R. E. Tarjan and J. van Leeuwen. </author> <title> Worst-case analysis of set union algorithms. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 31 </volume> <pages> 245-281, </pages> <year> 1984. </year>
Reference-contexts: ACM 29 (1986), 669-679. [21] D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. <ref> [23] </ref> R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. [24] R. E. Tarjan, "Amortized computational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [25] R. E. Tarjan, Data Structures and Network Algorithms. <p> The fastest algorithms for this problem run in O (ff (m; n)) amortized time per operation 2 and O (n) space, where m is the length of the sequence, n is the total number of elements, and ff is a functional inverse of Ackermann's function <ref> [19, 23] </ref>. In this paper we study the problems of answering queries about the blocks or bridge-blocks of a dynamic graph. We allow two on-line graph update operations to be performed on an initially null graph G: make vertex (A): Add a new vertex with no incident edges to G. <p> An on-line component maintenance subroutine is used in the insert edge procedure to determine if two vertices are in the same component of G and to determine the size of a component. This subroutine is a straightforward application of a fast disjoint set union algorithm <ref> [23] </ref>. Appropriate calls to the update functions of this subroutine must be made when making a new vertex or performing a component link. The tree data structure is built using condensible nodes. <p> The tree data structure is built using condensible nodes. A condensible node x consists of a block of storage, N (x), containing an arbitrary but fixed collection of fields, and a set of subnodes, S (x). The subnode sets are maintained with a fast disjoint set union algorithm <ref> [23] </ref>. The name of set S (x) is simply N (x). A condensible node is initialized with one subnode. To make a pointer p to node x, we store in p the name of some subnode s 2 S (x).
Reference: [24] <author> R. E. Tarjan and U. Vishkin. </author> <title> An efficient parallel biconnectivity algorithm. </title> <journal> SIAM J. Computing, </journal> <volume> 14 </volume> <pages> 862-874, </pages> <year> 1985. </year>
Reference-contexts: Using this data structure, our algorithms run in O (log n) amortized time per operation and O (n) space. The techniques of amortized analysis are tailor-made for analyzing algorithms based on dynamic data structures. A general overview of amortized analysis is given in the survey paper by Tarjan <ref> [24] </ref>, and many examples can be found in [15,25]. Given some cost metric such as time or space, an amortized analysis attempts to show that while some operations in an on-line sequence may have high cost, these operations must be balanced by other operations with low cost. <p> Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. <ref> [24] </ref> R. E. Tarjan, "Amortized computational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [25] R. E. Tarjan, Data Structures and Network Algorithms. Society for Industrial and Applied Mathematics, Philadelphia (1983). [26] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. <p> Hopcroft and Tarjan [9] and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and <ref> [24] </ref> (see also the survey paper [10]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24]. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> They give algorithms with constant query time, O (n log n) total update time in the case that G is a tree or forest, and O (mn) update time for general G, where m and n are the numbers of edges and vertices, respectively, in the initial graph. Reif <ref> [24] </ref> gives an algorithm for the same problem that runs in 27 of G. Multiply-appearing vertices are articulation points. 28 time O (ng + n log n) when given an initial graph embedded in a surface of genus g. <p> Frederickson [10] gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the i th update. It is well-known (see, for example, <ref> [9, 24] </ref>) that if only edge insertions are allowed, the component problem can be solved by straightforward application of a fast disjoint set union algorithm.
Reference: [25] <author> J. Westbrook and R. E. Tarjan. </author> <title> Maintaining bridge-connected and biconnected components on-line. </title> <type> Technical Report CS-TR-228-89, </type> <institution> Dept. of Computer Science, Princeton University, Princeton, NJ, </institution> <year> 1989. </year>
Reference-contexts: In developing our on-line graph algorithms, our paradigm is the use of dynamic data structures and amortized analysis. Many examples of the uses of dynamic data structures may be found in Tarjan's monograph <ref> [25] </ref> and Mehlhorn's three-volume set [15]. Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. <p> Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. [24] R. E. Tarjan, "Amortized computational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. <ref> [25] </ref> R. E. Tarjan, Data Structures and Network Algorithms. Society for Industrial and Applied Mathematics, Philadelphia (1983). [26] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [27] J. Westbrook and R. E. <p> Their results, as well as other recent work that builds on the preliminary version of the present paper <ref> [25] </ref> are briefly discussed in Section 1.12. 4.2 Maintaining Bridge-Blocks On-Line The bridge-blocks and bridges of a connected graph have a natural tree structure that we call the bridge-block tree. <p> In recent work other researchers have addressed several problems that we posed in the preliminary version of this paper <ref> [25] </ref>. Tamassia and Di Battista [3] give a data structure that uses our condensible nodes and maintains the triconnected components of a graph; m operations require O (mff (m; n)) time if the graph is initially biconnected, and O (m log n) time otherwise.

Reference: [1] <author> G. Ausiello, G. F. Italiano, A. M. Spaccamela, and U. Nanni. </author> <title> Incremental algorithms for minimal length paths. </title> <booktitle> In Proc. 1st ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 12-21, </pages> <year> 1990. </year>
Reference-contexts: We present remarks, conclusions, and open problems at the end of the chapter to which they are relevant, rather than in a final chapter. The results of chapter two have appeared in [27]. Chapter five is joint work with Roberto Tamassia of Brown University. 3 References for chapter 1. <ref> [1] </ref> B. Chazelle, "How to search in history," Information and Control 64 (1985), 77-99. [2] B. Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. <p> Our computational model is the pointer machine [5,6,10,12] with an added assumption about the data structure called separability. Related results follow. Tarjan [12] derived an amortized bound in this model for the set union problem without backtracking. Blum <ref> [1] </ref> derived a 17 worst-case-per-operation lower bound for the same problem. Mehlhorn, Naher, and Alt [9] derived an amortized lower bound for a related problem. Their result does not require separability. The algorithms to which our lower bound applies are called separable pointer algorithms. <p> distance at least b from the set name, i.e. case (1) applies. 2 2.5 Remarks Our bound of fi (logn=log logn) on the amortized time per operation in the set union problem with backtracking is the same as Blum's worst-case bound per operation in the set union problem without backtracking <ref> [1] </ref>. Perhaps this is not a coincidence. Our lower bound proof resembles his. Furthermore the data structure he uses to establish his upper bound can easily be extended to handle de-union operations; the worst-case bound per operation remains O (logn=log logn) and the space needed is O (n). <p> We conjecture that the bound in Theorem 3 holds for cell probe algorithms. References for chapter 2. <ref> [1] </ref> N. Blum, "On the single-operation worst-case time complexity of the disjoint set union problem," SIAM J. Comput. 15 (1986), 1021-1024. [2] M. L. Fredman and Michael E. <p> Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references <ref> [1] </ref>, [8], and [12] (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> Thus the upper bound of O (ff (m; n)) amortized time per operation for this version of the dynamic component problem is tight. References for Chapter 3 <ref> [1] </ref> B. Awerbuch and Y. Shiloach, "New connectivity and MSF algorithms for shu*e-exchange network and PRAM," IEEE Trans. on Computers C-36 (1987), pp. 1258-1263. [2] G. A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). [3] S. <p> Hopcroft and Tarjan [9] and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references <ref> [1] </ref> and [24] (see also the survey paper [10]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24].
Reference: [2] <author> G. D. Battista and R. Tamassia. </author> <title> Incremental planarity testing. </title> <booktitle> In Proc. 30th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 436-441, </pages> <year> 1989. </year>
Reference-contexts: The results of chapter two have appeared in [27]. Chapter five is joint work with Roberto Tamassia of Brown University. 3 References for chapter 1. [1] B. Chazelle, "How to search in history," Information and Control 64 (1985), 77-99. <ref> [2] </ref> B. Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. [4] R. <p> The techniques of Mehlhorn, N:aher, and Alt [9] suggest an approach to this question, which might yield at least an (log logn) bound if not an (logn=log logn) bound on the amortized time. Recently, Fredman and Saks <ref> [2] </ref> have given an (ff (m; n)) bound on the amortized cost per operation in the cell probe model of Yao [15]. It is also possible to show an (log n= log log n) bound on the worst-case cost per operation [M. Fredman, private communication, 1989]. <p> We conjecture that the bound in Theorem 3 holds for cell probe algorithms. References for chapter 2. [1] N. Blum, "On the single-operation worst-case time complexity of the disjoint set union problem," SIAM J. Comput. 15 (1986), 1021-1024. <ref> [2] </ref> M. L. Fredman and Michael E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symp. on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [3] H. N. Gabow and R. E. Tarjan, "A linear-time algorithm for a special case of disjoint set union," J. <p> References for Chapter 3 [1] B. Awerbuch and Y. Shiloach, "New connectivity and MSF algorithms for shu*e-exchange network and PRAM," IEEE Trans. on Computers C-36 (1987), pp. 1258-1263. <ref> [2] </ref> G. A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). [3] S. Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. [4] M. L. Fredman and M. E. <p> The block and bridge-block problems are fundamental problems in the study of on-line graph algorithms, a study that has wide applications to networks, CAD/CAM, and distributed computing. They appear as subproblems of other on-line graph problems, such as incremental planarity testing <ref> [2] </ref>. The incremental planarity testing problem is to maintain a representation of a planar graph as edges are being added, and to determine the first edge addition that makes the graph nonplanar.
Reference: [3] <author> G. D. Battista and R. Tamassia. </author> <title> On-line planarity testing. </title> <type> Technical Report CS-89-31, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1989. </year>
Reference-contexts: Chazelle, "How to search in history," Information and Control 64 (1985), 77-99. [2] B. Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. <ref> [3] </ref> B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. [4] R. Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. [5] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. <p> For the special case of the problem in which the subsequence of union operations is known in advance, the use of address arithmetic techniques leads to an algorithm with an amortized time bound of O (1) per operation <ref> [3] </ref>. Mannila and Ukkonen [8] studied a generalization of the set union problem called set union with backtracking, in which the following third kind of operation is allowed: de-union: Undo the most recently performed union operation that has not yet been undone. <p> Blum, "On the single-operation worst-case time complexity of the disjoint set union problem," SIAM J. Comput. 15 (1986), 1021-1024. [2] M. L. Fredman and Michael E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symp. on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. <ref> [3] </ref> H. N. Gabow and R. E. Tarjan, "A linear-time algorithm for a special case of disjoint set union," J. Comput. Sys. Sci. 30 (1985), 209-221. 21 [4] G. Gambiosi, G. F. Italiano, and M. <p> Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach <ref> [3] </ref> consider the component problem for a graph undergoing edge deletions. <p> Awerbuch and Y. Shiloach, "New connectivity and MSF algorithms for shu*e-exchange network and PRAM," IEEE Trans. on Computers C-36 (1987), pp. 1258-1263. [2] G. A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). <ref> [3] </ref> S. Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. [4] M. L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [5] G. N. <p> In recent work other researchers have addressed several problems that we posed in the preliminary version of this paper [25]. Tamassia and Di Battista <ref> [3] </ref> give a data structure that uses our condensible nodes and maintains the triconnected components of a graph; m operations require O (mff (m; n)) time if the graph is initially biconnected, and O (m log n) time otherwise.
Reference: [4] <author> K. Booth and G. Lueker. </author> <title> Testing for the consecutive ones property, interval graphs, and graph planarity using PQ-tree algorithms. </title> <journal> J. Comput. System Sci., </journal> <volume> 13 </volume> <pages> 335-379, </pages> <year> 1976. </year>
Reference-contexts: Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. <ref> [4] </ref> R. Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. [5] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. [6] J. <p> in the worst case, since the maximum tree depth is O (logn) and all pointers on any pointer stack point to distinct elements. (From bottom to top, the pointers on P (x) point to shallower and shallower ancestors of x.) The lazy method also has an O (nlogn) space bound <ref> [4] </ref>. For any node x, consider the top printer on P (x), which is to a node, say y. <p> N. Gabow and R. E. Tarjan, "A linear-time algorithm for a special case of disjoint set union," J. Comput. Sys. Sci. 30 (1985), 209-221. 21 <ref> [4] </ref> G. Gambiosi, G. F. Italiano, and M. Talamo, "Getting back to the past in the union-find problem," 5th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science 294, Springer-Verlag, Berlin, 1988, 8-17. [5] D. E. <p> We note that for the dynamic component problem in which only edge insertions are allowed, the above reduction from disjoint set union allows us to apply both the separable pointer machine lower bound of Tarjan [10] and the cell probe model lower bound of Fredman and Saks <ref> [4] </ref>. Thus the upper bound of O (ff (m; n)) amortized time per operation for this version of the dynamic component problem is tight. References for Chapter 3 [1] B. Awerbuch and Y. <p> A. Cheston, "Incremental algorithms in graph theory," Tech. Rep. No. 91 (PhD. Diss.), Dept. of Computer Science, University of Toronto, (1976). [3] S. Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. <ref> [4] </ref> M. L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [5] G. N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 [6] J. <p> Let n be the number of elements and m the number of operations in an instance of disjoint set union. Tarjan [20] gave a lower bound of (ff (m; n)) on the amortized time per operation and Blum <ref> [4] </ref> gave a lower bound of (log n= log logn) on the worst-case time of a single operation. Both these lower bounds apply to the class of separable pointer algorithms for set union [4, 20]. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union <ref> [4, 20] </ref>.
Reference: [5] <author> D. Cheriton and R. E. Tarjan. </author> <title> Finding minimum spanning trees. </title> <journal> SIAM J. Comput., </journal> <volume> 5 </volume> <pages> 724-742, </pages> <year> 1976. </year>
Reference-contexts: Many examples of the uses of dynamic data structures may be found in Tarjan's monograph [25] and Mehlhorn's three-volume set [15]. Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing <ref> [5] </ref>, and data structures for planar graphs [18,23]. In this dissertation we use red-black (balanced binary) trees [11], splay trees [22], and the dynamic tree data structure of Sleator and Tarjan [21,22], perhaps best known for its use in network flow problems. <p> Comput. 17 (1988), 427-462. [3] B. Chazelle and L. J. Guibas, "Fractional cascading: I. a data structuring tech nique; II. applications," Algorithmica 1 (1986), 133-191. [4] R. Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. <ref> [5] </ref> M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. [6] J. Driscoll, H. N. Gabow, N. Sarnak and R. E. <p> Comput. Sys. Sci. 30 (1985), 209-221. 21 [4] G. Gambiosi, G. F. Italiano, and M. Talamo, "Getting back to the past in the union-find problem," 5th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science 294, Springer-Verlag, Berlin, 1988, 8-17. <ref> [5] </ref> D. E. Knuth, The Art of Computer Programming, Vol. 1, Fundamental Algo rithms, Addison-Wesley, Reading, MA, 1968. [6] A. N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. [7] H. Mannila and E. <p> Reif [9] gives an algorithm for the same problem that runs in time O (ng + n log n) when given an initial graph embedded in a surface of genus g. Frederickson <ref> [5] </ref> gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the isupth update. <p> Even and Y. Shiloach, "On-line edge deletion," J. Assoc. Comp. Mach. 28 (1981), pp. 1-4. [4] M. L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. <ref> [5] </ref> G. N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 [6] J. Hopcroft and R. E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. [7] R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions.
Reference: [6] <author> N. Chiba, T. Nishizeki, S. Abe, and T. Ozawa. </author> <title> A linear algorithm for embedding planar graphs using PQ-trees. </title> <journal> J. Comput. System Sci., </journal> <volume> 30 </volume> <pages> 54-76, </pages> <year> 1985. </year>
Reference-contexts: Cole, "Searching and storing similar lists," J. Algorithms 7 (1986), 202-220. [5] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H.Rohnert, and R. E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. <ref> [6] </ref> J. Driscoll, H. N. Gabow, N. Sarnak and R. E. Tarjan, "Making data structures persistent," Proc. 18th Symp. of Foundations of Computer Science (1986), 109-121. [7] J. Driscoll, H. N. Gabow, R. Shrairman and R. E. <p> Talamo, "Getting back to the past in the union-find problem," 5th Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science 294, Springer-Verlag, Berlin, 1988, 8-17. [5] D. E. Knuth, The Art of Computer Programming, Vol. 1, Fundamental Algo rithms, Addison-Wesley, Reading, MA, 1968. <ref> [6] </ref> A. N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. [7] H. Mannila and E. Ukkonen, "On the complexity of unification sequences," Third International Conference on Logic Programming, July 14-18, 1986, Lecture Notes in Computer Science 225, Springer-Verlag, New York, 1986, 122-133. [8] H. <p> The problem of finding the components of a fixed graph G is well-understood. Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan <ref> [6] </ref> and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper [7]). <p> L. Fredman and M. E. Saks, "The Cell Probe Complexity of Dynamic Data Structures," Proc. 21st ACM Symposium on Theory of Computing, Seattle, Washington (May 1989), pp. 345-354. [5] G. N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 <ref> [6] </ref> J. Hopcroft and R. E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. [7] R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. Rep. No. CSD 88/408, Dept. of Computer Science, U.C.
Reference: [7] <author> F. Chin and D. Houck. </author> <title> Algorithms for updating minimum spanning trees. </title> <journal> J. Comput. System Sci., </journal> <volume> 16 </volume> <pages> 333-344, </pages> <year> 1978. </year> <month> 90 </month>
Reference-contexts: E. Tarjan, "Dynamic perfect hashing: upper and lower bounds," Proc. 29th IEEE Symp. of Foundations of Computer Science (1988), 524-531. [6] J. Driscoll, H. N. Gabow, N. Sarnak and R. E. Tarjan, "Making data structures persistent," Proc. 18th Symp. of Foundations of Computer Science (1986), 109-121. <ref> [7] </ref> J. Driscoll, H. N. Gabow, R. Shrairman and R. E. Tarjan, "Relaxed heaps: an alternative to fibonacci heaps with applications to parallel computation," Comm. ACM 31 (1988), 1343-1354. [8] S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. [9] M. <p> Mannila and Ukkonen [8] studied a generalization of the set union problem called set union with backtracking, in which the following third kind of operation is allowed: de-union: Undo the most recently performed union operation that has not yet been undone. This problem arises in Prolog interpreter memory management <ref> [7] </ref>. Mannila and Ukkonen showed how to extend path compaction techniques to handle backtracking. They posed the question of determining the inherent complexity of the problem, and they claimed an O (loglogn) amortized time bound per operation for one algorithm based on their approach. <p> E. Knuth, The Art of Computer Programming, Vol. 1, Fundamental Algo rithms, Addison-Wesley, Reading, MA, 1968. [6] A. N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. <ref> [7] </ref> H. Mannila and E. Ukkonen, "On the complexity of unification sequences," Third International Conference on Logic Programming, July 14-18, 1986, Lecture Notes in Computer Science 225, Springer-Verlag, New York, 1986, 122-133. [8] H. Mannila and E. Ukkonen, "The set union problem with backtracking," Proc. <p> Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper <ref> [7] </ref>). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> N. Frederickson, "On-line updating of minimum spanning trees," SIAM J. Computing 14 (1985), pp. 781-798. 25 [6] J. Hopcroft and R. E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. <ref> [7] </ref> R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. Rep. No. CSD 88/408, Dept. of Computer Science, U.C. Berkeley (1988). (To appear in Handbook of Theoretical Computer Science, North-Holland.) [8] G. L. Miller and V.
Reference: [8] <author> S. Even and H. Gazit. </author> <title> Updating distances in dynamic graphs. </title> <journal> Methods of Operations Research, </journal> <volume> 49 </volume> <pages> 371-387, </pages> <year> 1985. </year>
Reference-contexts: Sarnak and R. E. Tarjan, "Making data structures persistent," Proc. 18th Symp. of Foundations of Computer Science (1986), 109-121. [7] J. Driscoll, H. N. Gabow, R. Shrairman and R. E. Tarjan, "Relaxed heaps: an alternative to fibonacci heaps with applications to parallel computation," Comm. ACM 31 (1988), 1343-1354. <ref> [8] </ref> S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. [9] M. L. Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. [10] M. L. <p> For the special case of the problem in which the subsequence of union operations is known in advance, the use of address arithmetic techniques leads to an algorithm with an amortized time bound of O (1) per operation [3]. Mannila and Ukkonen <ref> [8] </ref> studied a generalization of the set union problem called set union with backtracking, in which the following third kind of operation is allowed: de-union: Undo the most recently performed union operation that has not yet been undone. This problem arises in Prolog interpreter memory management [7]. <p> N. Kolmogorov, "On the notion of algorithm," Uspehi Mat. Nauk. 8 (1953), 175-176. [7] H. Mannila and E. Ukkonen, "On the complexity of unification sequences," Third International Conference on Logic Programming, July 14-18, 1986, Lecture Notes in Computer Science 225, Springer-Verlag, New York, 1986, 122-133. <ref> [8] </ref> H. Mannila and E. Ukkonen, "The set union problem with backtracking," Proc. Thirteenth International Colloquium on Automata, Languages, and Programming (ICALP 86), Rennes, France, July 15-19, 1986, Lecture Notes in Computer Science 226, Springer-Verlag, New York, 1986, 236-243. [9] K. Mehlhorn, S. Naher, and H. <p> Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], <ref> [8] </ref>, and [12] (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> E. Tarjan, "Algorithm 447: Efficient algorithms for graph manipulation," Comm. ACM 16 (1973), 372-378. [7] R. Karp and V. Ramachandran, "Parallel Algorithms for Shared Memory Machines," Tech. Rep. No. CSD 88/408, Dept. of Computer Science, U.C. Berkeley (1988). (To appear in Handbook of Theoretical Computer Science, North-Holland.) <ref> [8] </ref> G. L. Miller and V. Ramachandran, "A new graph triconnectivity algorithm and its parallelization," Proc. 19th Annual ACM Symp. on Theory of Computing (1987), pp. 335-344. [9] J. H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. [10] R. E. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union [4, 20]. La Poutre [11] has proven the (ff (m; n)) amortized cost bound in a general pointer machine model, and Fredman and Saks <ref> [8] </ref> have shown an (ff (m; n)) bound on the amortized cost per operation and an (log n= log logn) bound on the worst-case cost per operation in the cell probe model of Yao [26].
Reference: [9] <author> S. Even and Y. Shiloach. </author> <title> An on-line edge deletion problem. </title> <journal> J. ACM, </journal> <volume> 28 </volume> <pages> 1-4, </pages> <year> 1981. </year>
Reference-contexts: Driscoll, H. N. Gabow, R. Shrairman and R. E. Tarjan, "Relaxed heaps: an alternative to fibonacci heaps with applications to parallel computation," Comm. ACM 31 (1988), 1343-1354. [8] S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. <ref> [9] </ref> M. L. Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. [10] M. L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. <p> Related results follow. Tarjan [12] derived an amortized bound in this model for the set union problem without backtracking. Blum [1] derived a 17 worst-case-per-operation lower bound for the same problem. Mehlhorn, Naher, and Alt <ref> [9] </ref> derived an amortized lower bound for a related problem. Their result does not require separability. The algorithms to which our lower bound applies are called separable pointer algorithms. <p> The techniques of Mehlhorn, N:aher, and Alt <ref> [9] </ref> suggest an approach to this question, which might yield at least an (log logn) bound if not an (logn=log logn) bound on the amortized time. <p> Mannila and E. Ukkonen, "The set union problem with backtracking," Proc. Thirteenth International Colloquium on Automata, Languages, and Programming (ICALP 86), Rennes, France, July 15-19, 1986, Lecture Notes in Computer Science 226, Springer-Verlag, New York, 1986, 236-243. <ref> [9] </ref> K. Mehlhorn, S. Naher, and H. Alt, "A lower bound for the complexity of the union-split-find problem," SIAM J. Comput. 17 (1988), 1093-1102. [10] A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. [11] R. E. <p> They give algorithms with constant query time, O (n log n) total update time in the case that G is a tree or forest, and O (mn) update time for general G, where m and n are the numbers of edges and vertices, respectively, in the initial graph. Reif <ref> [9] </ref> gives an algorithm for the same problem that runs in time O (ng + n log n) when given an initial graph embedded in a surface of genus g. <p> Rep. No. CSD 88/408, Dept. of Computer Science, U.C. Berkeley (1988). (To appear in Handbook of Theoretical Computer Science, North-Holland.) [8] G. L. Miller and V. Ramachandran, "A new graph triconnectivity algorithm and its parallelization," Proc. 19th Annual ACM Symp. on Theory of Computing (1987), pp. 335-344. <ref> [9] </ref> J. H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. [10] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 [11] R. E. <p> Figure 1 shows an undirected graph along with its blocks and bridge-blocks. The problems of finding the components, blocks, and bridge-blocks of a fixed graph are well-understood. Hopcroft and Tarjan <ref> [9] </ref> and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and [24] (see also the survey paper [10]). <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24]. Even and Shiloach <ref> [9] </ref> consider the component problem for a graph undergoing edge deletions. <p> Frederickson [10] gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the i th update. It is well-known (see, for example, <ref> [9, 24] </ref>) that if only edge insertions are allowed, the component problem can be solved by straightforward application of a fast disjoint set union algorithm. <p> Proof. The bridge-blocks and initial BBF of G 0 can be found in time O (jE 0 j) using one of the algorithms in references <ref> [9, 18] </ref>. By Lemma 1, the total number of pointer steps and condensations is O (m), giving the bound. 2 4.3 Maintaining Blocks On-line The problem of maintaining blocks on-line is similar to that of maintaining bridge-blocks, and the algorithms are almost identical.
Reference: [10] <author> G. N. Frederickson. </author> <title> Data structures for on-line updating of minimum spanning trees, with applications. </title> <journal> SIAM J. Comput., </journal> <volume> 14 </volume> <pages> 781-798, </pages> <year> 1985. </year>
Reference-contexts: ACM 31 (1988), 1343-1354. [8] S. Even and H. Gazit, "Updating distances in dynamic graphs," Methods of Op erations Research 49 (1985), 371-387. [9] M. L. Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. <ref> [10] </ref> M. L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. Mach. 34 (1987), 596 615. [11] L. J. Guibas and R. <p> Mehlhorn, S. Naher, and H. Alt, "A lower bound for the complexity of the union-split-find problem," SIAM J. Comput. 17 (1988), 1093-1102. <ref> [10] </ref> A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. [11] R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. <p> We note that for the dynamic component problem in which only edge insertions are allowed, the above reduction from disjoint set union allows us to apply both the separable pointer machine lower bound of Tarjan <ref> [10] </ref> and the cell probe model lower bound of Fredman and Saks [4]. Thus the upper bound of O (ff (m; n)) amortized time per operation for this version of the dynamic component problem is tight. References for Chapter 3 [1] B. Awerbuch and Y. <p> L. Miller and V. Ramachandran, "A new graph triconnectivity algorithm and its parallelization," Proc. 19th Annual ACM Symp. on Theory of Computing (1987), pp. 335-344. [9] J. H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. <ref> [10] </ref> R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 [11] R. E. Tarjan, "Depth first search and linear graph algorithms," SIAM J. Com puting 1 (1972), pp. 146-160. [12] R. E. Tarjan and U. <p> Hopcroft and Tarjan [9] and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and [24] (see also the survey paper <ref> [10] </ref>). The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24]. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> Reif [24] gives an algorithm for the same problem that runs in 27 of G. Multiply-appearing vertices are articulation points. 28 time O (ng + n log n) when given an initial graph embedded in a surface of genus g. Frederickson <ref> [10] </ref> gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the i th update.
Reference: [11] <author> H. N. Gabow and M. Stallmann. </author> <title> Efficient algorithms for graphic matroid intersection and parity (extended abstract). </title> <booktitle> In Automata, Languages, and Programming, 12 th Colloquium, Lecture Notes in Computer Science, </booktitle> <volume> vol. 194, </volume> <pages> pages 210-220. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. In this dissertation we use red-black (balanced binary) trees <ref> [11] </ref>, splay trees [22], and the dynamic tree data structure of Sleator and Tarjan [21,22], perhaps best known for its use in network flow problems. <p> Fredman, R. Sedgewick, D. D. Sleator and R. E. Tarjan, "The pairing heap: a new form of self-adjusting heap," Algorithmica 1 (1986), 111-129. [10] M. L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. Mach. 34 (1987), 596 615. <ref> [11] </ref> L. J. Guibas and R. Sedgewick, "A Dichromatic framework for balanced trees," Proc. 19th IEEE Symp. on Foundations of Computer Science (1978), 8-21. [12] T. Ibaraki and N. Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 [13] G. F. Italiano, A. <p> For an element x, let size (x) be the number of descendants of x (including itself) in the reference forest. The logarithmic size of x, lgs (x), is log size (x). 1 We need the following lemma concerning logarithmic sizes when union by weight is used. Lemma 1 <ref> [11] </ref> Suppose union by weight is used. If node v is the parent of node w in the reference forest, then lgs (w) &lt; lgs (v). Any node has logarithmic size between 0 and log n (inclusive). <p> Mehlhorn, S. Naher, and H. Alt, "A lower bound for the complexity of the union-split-find problem," SIAM J. Comput. 17 (1988), 1093-1102. [10] A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. <ref> [11] </ref> R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. <p> The problem of finding the components of a fixed graph G is well-understood. Let n be the number of vertices and m the number of edges. Hopcroft and Tarjan [6] and Tarjan <ref> [11] </ref> give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and [12] (see also the survey paper [7]). <p> H. Reif, "A topological approach to dynamic graph connectivity," Inform. Process. Lett. 25 (1987), pp. 65-70. [10] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 <ref> [11] </ref> R. E. Tarjan, "Depth first search and linear graph algorithms," SIAM J. Com puting 1 (1972), pp. 146-160. [12] R. E. Tarjan and U. Vishkin, "An efficient parallel biconnectivity algorithm," SIAM J. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union [4, 20]. La Poutre <ref> [11] </ref> has proven the (ff (m; n)) amortized cost bound in a general pointer machine model, and Fredman and Saks [8] have shown an (ff (m; n)) bound on the amortized cost per operation and an (log n= log logn) bound on the worst-case cost per operation in the cell probe
Reference: [12] <author> A. V. Goldberg, M. D. Grigoriadis, and R. E. Tarjan. </author> <title> Use of dynamic trees in a network simplex algorithm for the maximum flow problem. </title> <journal> Math. Prog., </journal> <note> to appear. </note>
Reference-contexts: L. Fredman and R. E. Tarjan, "Fibonacci heaps and their uses in improved network optimization algorithms," J. Assoc. Comput. Mach. 34 (1987), 596 615. [11] L. J. Guibas and R. Sedgewick, "A Dichromatic framework for balanced trees," Proc. 19th IEEE Symp. on Foundations of Computer Science (1978), 8-21. <ref> [12] </ref> T. Ibaraki and N. Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 [13] G. F. Italiano, A. Marchetti Spaccamela, U. Nanni, "Dynamic data structures for series parallel digraphs," Proc. <p> The fastest such algorithms run in O (ff (m; n)) amortized time per operation, where ff is a functional inverse of Ackermann's function [11,14]. No better bound is possible for any pointer-based algorithm that uses a separable set representation <ref> [12] </ref>. For the special case of the problem in which the subsequence of union operations is known in advance, the use of address arithmetic techniques leads to an algorithm with an amortized time bound of O (1) per operation [3]. <p> Our computational model is the pointer machine [5,6,10,12] with an added assumption about the data structure called separability. Related results follow. Tarjan <ref> [12] </ref> derived an amortized bound in this model for the set union problem without backtracking. Blum [1] derived a 17 worst-case-per-operation lower bound for the same problem. Mehlhorn, Naher, and Alt [9] derived an amortized lower bound for a related problem. Their result does not require separability. <p> Comput. 17 (1988), 1093-1102. [10] A Schonhage, "Storage modification machines," SIAM J. Comput. 9 (1980), 490-508. [11] R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. <ref> [12] </ref> R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [14] R. E. <p> Hopcroft and Tarjan [6] and Tarjan [11] give sequential algorithms based on depth-first search that run in time O (n + m). Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1], [8], and <ref> [12] </ref> (see also the survey paper [7]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph has been addressed in references [2,3,5,9]. Even and Shiloach [3] consider the component problem for a graph undergoing edge deletions. <p> Process. Lett. 25 (1987), pp. 65-70. [10] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintain disjoint sets," J. Comput. Sys. Sci. 18 (1979), pp. 110-127 [11] R. E. Tarjan, "Depth first search and linear graph algorithms," SIAM J. Com puting 1 (1972), pp. 146-160. <ref> [12] </ref> R. E. Tarjan and U. Vishkin, "An efficient parallel biconnectivity algorithm," SIAM J. <p> Working independently and using techniques different from ours, La Poutre, van Leeuwen, and Overmars have recently also obtained an O (mff (m; n)) time bound for maintaining bridge-blocks and for maintaining three-edge connected components <ref> [12] </ref>. Their results, as well as other recent work that builds on the preliminary version of the present paper [25] are briefly discussed in Section 1.12. 4.2 Maintaining Bridge-Blocks On-Line The bridge-blocks and bridges of a connected graph have a natural tree structure that we call the bridge-block tree. <p> Galil and Italiano [private communication, 1990] use our condensible nodes in designing a data structure to maintain the 3-edge-connected components of an initially connected graph in O (mff (m; n)) total time. La Poutre, van Leeuwen and Overmars <ref> [12] </ref>, working independently, have designed a different data structure for maintaining bridge-blocks and 3-edge-connected components that runs in total time O (mff (m; n)). They claim that their approach can be extended to the problem of maintaining biconnected and triconnected components.
Reference: [13] <author> L. J. Guibas and J. Stolfi. </author> <title> Primitives for the manipulation of general subdivisions and the computation of voronoi diagrams. </title> <journal> ACM Trans. on Graphics, </journal> <volume> 4 </volume> <pages> 74-123, </pages> <year> 1985. </year>
Reference-contexts: Mach. 34 (1987), 596 615. [11] L. J. Guibas and R. Sedgewick, "A Dichromatic framework for balanced trees," Proc. 19th IEEE Symp. on Foundations of Computer Science (1978), 8-21. [12] T. Ibaraki and N. Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 <ref> [13] </ref> G. F. Italiano, A. Marchetti Spaccamela, U. Nanni, "Dynamic data structures for series parallel digraphs," Proc. Workshop on Algorithms and Data Structures (WADS 89) (Lecture Notes in Computer Science), Springer-Verlag, New York (1989). [14] J. A. <p> Comput. 9 (1980), 490-508. [11] R. E. Tarjan, "Efficiency of a good but not linear set union algorithm," J. Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. <ref> [13] </ref> R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [14] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [15] A. C. Yao, "Should tables be sorted?" J. Assoc. Comput.
Reference: [14] <author> F. Harary. </author> <title> Graph Theory. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA., </address> <year> 1972. </year>
Reference-contexts: Katoh, "On-line computation of transitive closure for graphs," Inform. Process. Lett. 16 (1983), 95-97. 4 [13] G. F. Italiano, A. Marchetti Spaccamela, U. Nanni, "Dynamic data structures for series parallel digraphs," Proc. Workshop on Algorithms and Data Structures (WADS 89) (Lecture Notes in Computer Science), Springer-Verlag, New York (1989). <ref> [14] </ref> J. A. La Poutr'e and J. van Leeuwen, "Maintenance of transitive closure and transitive reduction of graphs," Proc. International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. [15] K. Mehlhorn, Data Structures and Algorithms (3 volumes). <p> The two choices of a union rule and three choices of a compaction rule give six possible set union algorithms. Each of these has an amortized running time of O (ff (m; n)) per operation <ref> [14] </ref>. We shall describe two ways to extend these and similar algorithms to handle de-union operations. The first method is the one proposed by Mannila and Ukkonen; the second is a slight variant. We call a union operation that has been done but not yet undone live. <p> The time to maintain set names and sizes or ranks is O (1) per union or de-union; thus each union or de-union takes O (1) time, worst-case. Either union rule guarantees a maximum tree depth of O (logn) <ref> [14] </ref>; thus the worst-case time per find is O (logn). The space needed by the data structure is O (n). Mannila and Ukkonen's goal was to reduce the time per find, possibly at the cost of increasing the time per union or de-union and increasing the space. <p> Assoc. Comput. Mach. 22 (1975), 215-225. [12] R. E. Tarjan, "A class of algorithms which require nonlinear time to maintian disjoint sets," J. Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. <ref> [14] </ref> R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [15] A. C. Yao, "Should tables be sorted?" J. Assoc. Comput.
Reference: [15] <author> D. Harel. </author> <title> On-line maintenance of the connected components of dynamic graphs. </title> <type> Unpublished manuscript, </type> <year> 1982. </year>
Reference-contexts: In developing our on-line graph algorithms, our paradigm is the use of dynamic data structures and amortized analysis. Many examples of the uses of dynamic data structures may be found in Tarjan's monograph [25] and Mehlhorn's three-volume set <ref> [15] </ref>. Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. <p> A. La Poutr'e and J. van Leeuwen, "Maintenance of transitive closure and transitive reduction of graphs," Proc. International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. <ref> [15] </ref> K. Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). [16] K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). [17] M. <p> Recently, Fredman and Saks [2] have given an (ff (m; n)) bound on the amortized cost per operation in the cell probe model of Yao <ref> [15] </ref>. It is also possible to show an (log n= log log n) bound on the worst-case cost per operation [M. Fredman, private communication, 1989]. In this powerful and general model, memory is organized into cells, each of which can hold log n bits. <p> Comput. Sys. Sci. 18 (1979), 110-127. [13] R. E. Tarjan, "Amortized comutational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [14] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. <ref> [15] </ref> A. C. Yao, "Should tables be sorted?" J. Assoc. Comput. Mach. 28 (1981), 615-628. 3 Maintaining Connected Components with Back- tracking Perhaps the most fundamental equivalence relation on the constituents of an undi-rected graph G = (V; E) is defined by its connected components.
Reference: [16] <author> J. Hopcroft and R. E. Tarjan. </author> <title> Efficient planarity testing. </title> <journal> J. ACM, </journal> <volume> 21 </volume> <pages> 549-568, </pages> <year> 1974. </year>
Reference-contexts: La Poutr'e and J. van Leeuwen, "Maintenance of transitive closure and transitive reduction of graphs," Proc. International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. [15] K. Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). <ref> [16] </ref> K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). [17] M. Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). [18] F. P. Preparata and R.
Reference: [17] <author> T. Ibaraki and N. Katoh. </author> <title> On-line computation of transitive closure for graphs. </title> <journal> Inf. Process. Lett., </journal> <volume> 16 </volume> <pages> 95-97, </pages> <year> 1983. </year>
Reference-contexts: In developing our on-line graph algorithms, our paradigm is the use of dynamic data structures and amortized analysis. Many examples of the uses of dynamic data structures may be found in Tarjan's monograph [25] and Mehlhorn's three-volume set [15]. Another general source is the monograph of Overmars <ref> [17] </ref>. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. <p> International Workshop on Graph-Theoretic Concepts in Computer Science (WG 87) (Lecture Notes in Computer Science), Springer-Verlag, New York (1988), 106-120. [15] K. Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). [16] K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). <ref> [17] </ref> M. Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). [18] F. P. Preparata and R. <p> Maintaining the blocks of a dynamic graph also arises in the implementation of efficient search strategies for logic programming [Graeme Port, private communication, 1988]. Tamassia <ref> [29, 17] </ref> gives a data structure for the on-line block problem that achieves O (log n) worst-case query time and O (log n) amortized update time. This paper is organized as follows.
Reference: [18] <author> G. F. </author> <title> Italiano. Amortized efficiency of a path retrieval data structure. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 48 </volume> <pages> 273-281, </pages> <year> 1986. </year>
Reference-contexts: Mehlhorn, Data Structures and Algorithms (3 volumes). Springer-Verlag, New York (1984). [16] K. Mehlhorn and S. Naher, "Dynamic fractional cascading," Proc. ACM Symp. on Computational Geometry, (1985). [17] M. Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). <ref> [18] </ref> F. P. Preparata and R. Tamassia, "Fully dynamic techniques for point location and transitive closure in planar structures," Proc. 29th IEEE Symposium on Foundations of Computer Science, (1988), 558-567. [19] H. <p> Figure 1 shows an undirected graph along with its blocks and bridge-blocks. The problems of finding the components, blocks, and bridge-blocks of a fixed graph are well-understood. Hopcroft and Tarjan [9] and Tarjan <ref> [18] </ref> give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and [24] (see also the survey paper [10]). <p> Proof. The bridge-blocks and initial BBF of G 0 can be found in time O (jE 0 j) using one of the algorithms in references <ref> [9, 18] </ref>. By Lemma 1, the total number of pointer steps and condensations is O (m), giving the bound. 2 4.3 Maintaining Blocks On-line The problem of maintaining blocks on-line is similar to that of maintaining bridge-blocks, and the algorithms are almost identical.
Reference: [19] <author> G. F. </author> <title> Italiano. Finding paths and deleting edges in directed acyclic graphs. </title> <journal> Inf. Process. Lett., </journal> <volume> 28 </volume> <pages> 5-11, </pages> <year> 1988. </year> <month> 91 </month>
Reference-contexts: Overmars, The Design of Dynamic Data Structures. (Lecture Notes in Com puter Science), Springer-Verlag , New York (1983). [18] F. P. Preparata and R. Tamassia, "Fully dynamic techniques for point location and transitive closure in planar structures," Proc. 29th IEEE Symposium on Foundations of Computer Science, (1988), 558-567. <ref> [19] </ref> H. Rohnert, "A dynamization of the all-pairs least cost path problem," Proc. 2nd Annual Symp. on Theoretical Aspects of Computer Science (Lecture Notes in Computer Science), Springer-Verlag, New York (1985), 279-286. [20] N. Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. <p> The fastest algorithms for this problem run in O (ff (m; n)) amortized time per operation 2 and O (n) space, where m is the length of the sequence, n is the total number of elements, and ff is a functional inverse of Ackermann's function <ref> [19, 23] </ref>. In this paper we study the problems of answering queries about the blocks or bridge-blocks of a dynamic graph. We allow two on-line graph update operations to be performed on an initially null graph G: make vertex (A): Add a new vertex with no incident edges to G.
Reference: [20] <author> G. F. Italiano, A. M. Spaccamela, and U. Nanni. </author> <title> Dynamic data structures for series parallel digraphs. </title> <booktitle> In Proc. Workshop on Algorithms and Data Structures, (WADS 89), Lecture Notes in Computer Science, </booktitle> <volume> vol. 382, </volume> <pages> pages 352-372. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: Rohnert, "A dynamization of the all-pairs least cost path problem," Proc. 2nd Annual Symp. on Theoretical Aspects of Computer Science (Lecture Notes in Computer Science), Springer-Verlag, New York (1985), 279-286. <ref> [20] </ref> N. Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. ACM 29 (1986), 669-679. [21] D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. <p> Let n be the number of elements and m the number of operations in an instance of disjoint set union. Tarjan <ref> [20] </ref> gave a lower bound of (ff (m; n)) on the amortized time per operation and Blum [4] gave a lower bound of (log n= log logn) on the worst-case time of a single operation. <p> Both these lower bounds apply to the class of separable pointer algorithms for set union <ref> [4, 20] </ref>.
Reference: [21] <author> J. A. La Poutre and J. van Leeuwen. </author> <title> Maintenance of transitive closure and transitive reduction of graphs. </title> <booktitle> In Proc. International Workshop on Graph-Theoretic Concepts in Computer Science, (WG 87), Lecture Notes in Computer Science, </booktitle> <volume> vol. 314, </volume> <pages> pages 106-120. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: Rohnert, "A dynamization of the all-pairs least cost path problem," Proc. 2nd Annual Symp. on Theoretical Aspects of Computer Science (Lecture Notes in Computer Science), Springer-Verlag, New York (1985), 279-286. [20] N. Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. ACM 29 (1986), 669-679. <ref> [21] </ref> D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R.
Reference: [22] <author> J. Paul and W. Simon. </author> <title> Decision trees and random access machines. </title> <booktitle> In Symposium uber Logik und Algolrithmik, </booktitle> <year> 1980. </year> <note> Also in K. </note> <editor> Mehlhorn, </editor> <booktitle> Sorting and Searching, </booktitle> <pages> pages 85-97, </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference-contexts: Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. In this dissertation we use red-black (balanced binary) trees [11], splay trees <ref> [22] </ref>, and the dynamic tree data structure of Sleator and Tarjan [21,22], perhaps best known for its use in network flow problems. <p> Sarnak and R. E. Tarjan, "Planar point location using persistent search trees," Comm. ACM 29 (1986), 669-679. [21] D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. <ref> [22] </ref> D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. [24] R. E. Tarjan, "Amortized computational complexity," SIAM J.
Reference: [23] <author> F. P. Preparata and R. Tamassia. </author> <title> Fully dynamic techniques for point location and transitive closure in planar structures. </title> <booktitle> In Proc. 29th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 558-567, </pages> <year> 1988. </year>
Reference-contexts: ACM 29 (1986), 669-679. [21] D. D. Sleator and R. E. Tarjan, "A data structure for dynamic trees," J. Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. <ref> [23] </ref> R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. [24] R. E. Tarjan, "Amortized computational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [25] R. E. Tarjan, Data Structures and Network Algorithms. <p> The fastest algorithms for this problem run in O (ff (m; n)) amortized time per operation 2 and O (n) space, where m is the length of the sequence, n is the total number of elements, and ff is a functional inverse of Ackermann's function <ref> [19, 23] </ref>. In this paper we study the problems of answering queries about the blocks or bridge-blocks of a dynamic graph. We allow two on-line graph update operations to be performed on an initially null graph G: make vertex (A): Add a new vertex with no incident edges to G. <p> An on-line component maintenance subroutine is used in the insert edge procedure to determine if two vertices are in the same component of G and to determine the size of a component. This subroutine is a straightforward application of a fast disjoint set union algorithm <ref> [23] </ref>. Appropriate calls to the update functions of this subroutine must be made when making a new vertex or performing a component link. The tree data structure is built using condensible nodes. <p> The tree data structure is built using condensible nodes. A condensible node x consists of a block of storage, N (x), containing an arbitrary but fixed collection of fields, and a set of subnodes, S (x). The subnode sets are maintained with a fast disjoint set union algorithm <ref> [23] </ref>. The name of set S (x) is simply N (x). A condensible node is initialized with one subnode. To make a pointer p to node x, we store in p the name of some subnode s 2 S (x).
Reference: [24] <author> J. H. Reif. </author> <title> A topological approach to dynamic graph connectivity. </title> <journal> Inf. Process. Lett., </journal> <volume> 25 </volume> <pages> 65-70, </pages> <year> 1987. </year>
Reference-contexts: Using this data structure, our algorithms run in O (log n) amortized time per operation and O (n) space. The techniques of amortized analysis are tailor-made for analyzing algorithms based on dynamic data structures. A general overview of amortized analysis is given in the survey paper by Tarjan <ref> [24] </ref>, and many examples can be found in [15,25]. Given some cost metric such as time or space, an amortized analysis attempts to show that while some operations in an on-line sequence may have high cost, these operations must be balanced by other operations with low cost. <p> Comput. Sys. Sci. 26 (1983), 362-391. [22] D. D. Sleator and R. E. Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. <ref> [24] </ref> R. E. Tarjan, "Amortized computational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [25] R. E. Tarjan, Data Structures and Network Algorithms. Society for Industrial and Applied Mathematics, Philadelphia (1983). [26] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. <p> Hopcroft and Tarjan [9] and Tarjan [18] give sequential algorithms that run in time O (n + m) where n = jV j and m = jEj. Logarithmic-time parallel algorithms for finding components, bridge-blocks, and blocks are given in references [1] and <ref> [24] </ref> (see also the survey paper [10]). The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references [5, 9, 10, 24]. <p> The problem of answering queries about edge and vertex membership in the components of a dynamic graph, i.e., a graph that is changing on-line, has been addressed in references <ref> [5, 9, 10, 24] </ref>. Even and Shiloach [9] consider the component problem for a graph undergoing edge deletions. <p> They give algorithms with constant query time, O (n log n) total update time in the case that G is a tree or forest, and O (mn) update time for general G, where m and n are the numbers of edges and vertices, respectively, in the initial graph. Reif <ref> [24] </ref> gives an algorithm for the same problem that runs in 27 of G. Multiply-appearing vertices are articulation points. 28 time O (ng + n log n) when given an initial graph embedded in a surface of genus g. <p> Frederickson [10] gives an algorithm that performs queries in constant time and edge insertions and deletions in time O ( p m i ), where m i is the number of edges in G at the time of the i th update. It is well-known (see, for example, <ref> [9, 24] </ref>) that if only edge insertions are allowed, the component problem can be solved by straightforward application of a fast disjoint set union algorithm.
Reference: [25] <author> H. Rohnert. </author> <title> A dynamization of the all pairs least cost path problem. </title> <booktitle> In Proc. 2nd Annual Symp. on Theoretical Aspects of Computer Science, (STACS 85), Lecture Notes in Computer Science, </booktitle> <volume> vol. 182, </volume> <pages> pages 279-286. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: In developing our on-line graph algorithms, our paradigm is the use of dynamic data structures and amortized analysis. Many examples of the uses of dynamic data structures may be found in Tarjan's monograph <ref> [25] </ref> and Mehlhorn's three-volume set [15]. Another general source is the monograph of Overmars [17]. Recent work has centered on such topics as fractional cascading [2,3,16], persistence [1,4,6,20], fast heaps [7,9,10], dynamic perfect hashing [5], and data structures for planar graphs [18,23]. <p> Tarjan, "Self-adjusting binary search trees," J. Assoc. Comput. Mach. 32 (1985), 652-686. [23] R. Tamassia, "A dynamic data structure for planar graph embedding" Proc. 15th Int. Conf. on Automata, Languages, and Programming (1988), 576-590. [24] R. E. Tarjan, "Amortized computational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. <ref> [25] </ref> R. E. Tarjan, Data Structures and Network Algorithms. Society for Industrial and Applied Mathematics, Philadelphia (1983). [26] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [27] J. Westbrook and R. E. <p> Their results, as well as other recent work that builds on the preliminary version of the present paper <ref> [25] </ref> are briefly discussed in Section 1.12. 4.2 Maintaining Bridge-Blocks On-Line The bridge-blocks and bridges of a connected graph have a natural tree structure that we call the bridge-block tree. <p> In recent work other researchers have addressed several problems that we posed in the preliminary version of this paper <ref> [25] </ref>. Tamassia and Di Battista [3] give a data structure that uses our condensible nodes and maintains the triconnected components of a graph; m operations require O (mff (m; n)) time if the graph is initially biconnected, and O (m log n) time otherwise.
Reference: [26] <author> D. D. Sleator and R. E. Tarjan. </author> <title> A data structure for dynamic trees. </title> <journal> J. Comput. System Sci., </journal> <volume> 26 </volume> <pages> 362-391, </pages> <year> 1983. </year>
Reference-contexts: We develop a modified version of the dynamic trees of Sleator and Tarjan that is suitable for efficient recursive algorithms, and use it to 2 reduce the running time of the algorithms for both problems to O (mff (m; n)), where ff is a functional inverse of Ackermann's function <ref> [26] </ref>. This time bound is optimal. All of the algorithms use O (n) space. <p> Conf. on Automata, Languages, and Programming (1988), 576-590. [24] R. E. Tarjan, "Amortized computational complexity," SIAM J. Alg. Disc. Meth. 6 (1985), 306-318. [25] R. E. Tarjan, Data Structures and Network Algorithms. Society for Industrial and Applied Mathematics, Philadelphia (1983). <ref> [26] </ref> R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [27] J. Westbrook and R. E. Tarjan, "Amortized analysis of algorithms for set union with backtracking," SIAM J. Comput. 18 (1989), pp. 1-11. [28] D. <p> Both these data structures answer queries in O (1) worst-case time. In Sections 1.4-1.7 we introduce the link/condense tree data structure, a modified version of the dynamic trees of Sleator and Tarjan <ref> [26, 27] </ref>, By a delicate analysis we show that this data structure reduces the amortized time per operation to O (ff (m; n)). <p> The link/condense tree. is derived from the dynamic tree data structure of Sleator and Tarjan <ref> [26, 27] </ref>. <p> As defined in [27], a dynamic tree node v contains pointers to its left and right children in the solid subtree, left (v) and right (v), and to its virtual parent, vparent (v). It also contains a bit reverse (v), used to implement eversion efficiently (see <ref> [26] </ref>). Node v may enter reversed state, in which case the meanings of left (v) and right (v) are reversed. (That is, left (v) points to the right child, and right (v) points to the left child. <p> of m biconnected component operations can be performed in worst-case time O (mff (m; n)) and O (n) space. 4.5 Eversion and Linking of Link/Condense Trees An eversion of a link/condense tree T at node u is done using the same procedure as in the dynamic tree data structure (see <ref> [26] </ref>). Node u is moved to the root of the virtual tree V by an extended splay. Following the e-splay, the right subtree of u contains the path from u to the root of T . A null splice at u is done. <p> (ff (m; n)) amortized cost bound in a general pointer machine model, and Fredman and Saks [8] have shown an (ff (m; n)) bound on the amortized cost per operation and an (log n= log logn) bound on the worst-case cost per operation in the cell probe model of Yao <ref> [26] </ref>. In this powerful and general model, memory is organized into cells, each of which can hold log n bits. In answering a query, a cell-probe algorithm is allowed to randomly access cells based on the information gathered from previous probes.
Reference: [27] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Self-adjusting binary search trees. </title> <journal> J. ACM, </journal> <volume> 32 </volume> <pages> 652-686, </pages> <year> 1985. </year>
Reference-contexts: We present remarks, conclusions, and open problems at the end of the chapter to which they are relevant, rather than in a final chapter. The results of chapter two have appeared in <ref> [27] </ref>. Chapter five is joint work with Roberto Tamassia of Brown University. 3 References for chapter 1. [1] B. Chazelle, "How to search in history," Information and Control 64 (1985), 77-99. [2] B. Chazelle, "A functional approach to data structures and its use in multidimen sional searching," SIAM J. <p> Alg. Disc. Meth. 6 (1985), 306-318. [25] R. E. Tarjan, Data Structures and Network Algorithms. Society for Industrial and Applied Mathematics, Philadelphia (1983). [26] R. E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. <ref> [27] </ref> J. Westbrook and R. E. Tarjan, "Amortized analysis of algorithms for set union with backtracking," SIAM J. Comput. 18 (1989), pp. 1-11. [28] D. Yellin, "A dynamic transitive closure algorithm," Research Report, IBM Research Division, T. J. <p> Both these data structures answer queries in O (1) worst-case time. In Sections 1.4-1.7 we introduce the link/condense tree data structure, a modified version of the dynamic trees of Sleator and Tarjan <ref> [26, 27] </ref>, By a delicate analysis we show that this data structure reduces the amortized time per operation to O (ff (m; n)). <p> The link/condense tree. is derived from the dynamic tree data structure of Sleator and Tarjan <ref> [26, 27] </ref>. <p> The variants differ significantly. We base our data structure on the implementation of dynamic trees described in <ref> [27] </ref>. The following summary description of dynamic trees is taken from [27, pp. 678], (See Figure 4.) We represent each dynamic tree T by a virtual tree V containing the same nodes as T but having a different structure. <p> The variants differ significantly. We base our data structure on the implementation of dynamic trees described in [27]. The following summary description of dynamic trees is taken from <ref> [27, pp. 678] </ref>, (See Figure 4.) We represent each dynamic tree T by a virtual tree V containing the same nodes as T but having a different structure. <p> The parent of v in T is called the true parent of v, and the parent of v in V is called the virtual parent. The solid subtrees are maintained with splay trees <ref> [27] </ref>. A splay at node x moves x to the root of its solid subtree by applying a standard binary tree rotation to every edge along the path from x to the root (Figure 6a). A rotation rearranges left and right children while preserving the symmetric order. <p> A rotation rearranges left and right children while preserving the symmetric order. Middle children are unaffected. The sequence of rotations is determined by the structure of the path <ref> [27] </ref>. The splay procedure can be extended to the full virtual tree with the addition of a second primitive called splicing, which exchanges a middle child with the left child of a solid subtree root (Figure 6b). <p> An extended splay at node v, abbreviated e-splay at v, moves v to the root of its virtual tree without changing the structure of the actual tree that the virtual tree represents. The e-splay algorithm is described fully in <ref> [27] </ref>, where it is shown that the amortized cost of an e-splay in a tree of size n is O (log n). In the dynamic tree data structure, every operation is implemented by O (1) extended splays followed by O (1) additional operations of amortized cost O (log n). <p> The link/condense data structure differs in that path-finding and condensation do not involve extended splays, while everting and linking do. We augment the dynamic tree data structure to allow pathfinding and condensation without significantly interfering with extended splays. As defined in <ref> [27] </ref>, a dynamic tree node v contains pointers to its left and right children in the solid subtree, left (v) and right (v), and to its virtual parent, vparent (v). It also contains a bit reverse (v), used to implement eversion efficiently (see [26]). <p> Node 3 becomes the leftmost node in the solid subtree rooted at w, while nodes 1 and 2 become leftmost and rightmost, respectively, in the solid subtree rooted at u. stored in v and all its ancestors in the solid subtree. Rules are given in reference <ref> [27] </ref> for updating the reversal bit and left, right and vparent pointers of the nodes affected by a rotation or splice. Note that the reversal states of a solid subtree root and its children can be determined by examining a constant number of reverse bits. <p> Dotted lines represent deferred links. (a) First pass: splaying inside solid subtrees (see <ref> [27] </ref> for details of splaying). (b) Second pass: splicing dashed edges. (c) Third pass: splaying solid subtrees between deferred links. (d) Fourth pass: converting deferred links to dashed edges, followed by splicing. (e) Fifth pass: splaying along final solid path. 46 tree root. <p> We can measure this length by the number of rotations performed, as stated at the end of Section 1.4. To analyze the cost of an operation in terms of the number of rotations, we extend the amortization argument used by Sleator and Tarjan. Let be a potential function <ref> [27, 32] </ref> defined on the virtual tree structure. <p> Sleator and Tarjan use this restricted potential function to show that in the basic dynamic tree data structure an e-splay at node v has cost at most 12lgw 0 v, where lgw 0 v is the logarithmic weight of v after the extended splay <ref> [27] </ref>. <p> (The reversal states of all nodes along the splay path are computed by an initial walk down the path.) The behavior of splaying is such that after the first two splays, v is a right child of pred (v) and pred (v) is a left child of succ (v) (see <ref> [27] </ref>). If v has no predecessor or successor, then the code involving the missing node can simply be ignored. For example, if v has no predecessor, then we need only splay at the successor. <p> From this, the rest of the results of Section 1.5 follow, and we can conclude that n 1 component links have cost O (n). Our analysis will be fairly terse, relying on results proven in reference <ref> [27] </ref>. The reader is advised to examine that paper for further details and explanation. We define = nodes x 5lgwx + X a (1 + log dsize (S)) From Lemma 1 of reference [27] we conclude the following: let x be a left or right child of y. <p> Our analysis will be fairly terse, relying on results proven in reference <ref> [27] </ref>. The reader is advised to examine that paper for further details and explanation. We define = nodes x 5lgwx + X a (1 + log dsize (S)) From Lemma 1 of reference [27] we conclude the following: let x be a left or right child of y. A single rotation of the edge between x and y has amortized cost 1 + 3 (5lgw (y) 5lgw (x)). This bounds the cost of a square-splice. <p> Therefore, at least k 2 rotations occur in the third pass. We charge 5 for each of these k 2 rotations; the additional charge accounts for 4k 8 of the rotations left over from the first two passes. From the discussion of e-splay in reference <ref> [27] </ref>, we find that even with this additional charge, the amortized cost of the final splay is at most 5 + 15lgw (t).
Reference: [28] <author> P. M. Spira and A. Pan. </author> <title> On finding and updating spanning trees and shortest paths. </title> <journal> SIAM J. Comput., </journal> <volume> 4 </volume> <pages> 375-380, </pages> <year> 1975. </year>
Reference-contexts: E. Tarjan and J. van Leeuwen, "Worst-case analysis of set union algorithms," J. Assoc. Comput. Mach. 31 (1984), 245-281. [27] J. Westbrook and R. E. Tarjan, "Amortized analysis of algorithms for set union with backtracking," SIAM J. Comput. 18 (1989), pp. 1-11. <ref> [28] </ref> D. Yellin, "A dynamic transitive closure algorithm," Research Report, IBM Research Division, T. J.
Reference: [29] <author> R. Tamassia. </author> <title> A dynamic data structure for planar graph embedding. </title> <booktitle> In Proc. 15th Int. Conf. on Automata, Languages, and Programming, (ICALP 1988), Lecture Notes in Computer Science, </booktitle> <volume> vol. 317, </volume> <pages> pages 576-590. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year> <month> 92 </month>
Reference-contexts: Maintaining the blocks of a dynamic graph also arises in the implementation of efficient search strategies for logic programming [Graeme Port, private communication, 1988]. Tamassia <ref> [29, 17] </ref> gives a data structure for the on-line block problem that achieves O (log n) worst-case query time and O (log n) amortized update time. This paper is organized as follows.
Reference: [30] <author> R. E. Tarjan. </author> <title> Sensitivity analysis of minimum spanning trees and shortest path trees. </title> <journal> Inf. Process. Lett., </journal> <volume> 14 </volume> <pages> 30-33, </pages> <year> 1982. </year>
Reference: [31] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, PA., </address> <year> 1983. </year>
Reference-contexts: The amortized cost of a condensible node operation is O (ff (k; n)). Thus the total running time is O (kff (k; n)). Since ff (a; b) = 1 for a b log log b <ref> [31] </ref>, this expression is O (n log n + m). The total time spent in the auxiliary on-line components subroutine is O (mff (m; n)), which is also O (n log n + m).
Reference: [32] <author> R. E. Tarjan. </author> <title> Amortized computational complexity. </title> <journal> SIAM J. Alg. Disc. Meth., </journal> <volume> 6 </volume> <pages> 306-318, </pages> <year> 1985. </year>
Reference-contexts: See <ref> [32] </ref> for a general discussion of amortization. 29 We also consider a restricted variant of the problem in which we are given an initially connected graph G 0 = (V 0 ; E 0 ). <p> We can measure this length by the number of rotations performed, as stated at the end of Section 1.4. To analyze the cost of an operation in terms of the number of rotations, we extend the amortization argument used by Sleator and Tarjan. Let be a potential function <ref> [27, 32] </ref> defined on the virtual tree structure. <p> The initial value of is zero, and is always positive. By a standard property of amortized analysis <ref> [32] </ref>, this implies that A (n) bounds the actual number of rotations. 2 Note that the time per rotation is O (1) plus the time for O (1) changes to pointers plus the time for O (1) operations on the deferred link sets. 50 4.7 Path-finding and Condensation in Link/Condense Trees
Reference: [33] <author> W. T. Tutte. </author> <title> Graph Theory. </title> <publisher> Addison-Wesley, </publisher> <address> Menlo Park, CA., </address> <year> 1984. </year>
Reference: [34] <author> D. Yellin. </author> <title> A dynamic transitive closure algorithm. </title> <type> Technical report, </type> <institution> IBM Research Division, T. J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <year> 1988. </year> <month> 93 </month>
References-found: 59

