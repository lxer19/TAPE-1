URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR93298-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Automatic Data Layout for Distributed-Memory Machines in the D Programming Environment Automatic Parallelization New Approaches
Author: Ulrich Kremer John Mellor-Crummey Ken Kennedy Alan Carle Christoph W. Kessler 
Address: P.O. Box 1892 Houston, TX 77251-1892  
Affiliation: Rice University  
Note: Center for Research on Parallel Computation  Published in  (editor), pages 136-152, Vieweg Advanced Studies in Computer Science, Verlag Vieweg, Wiesbaden, Germany, 1993.  
Date: February, 1993  
Pubnum: CRPC-TR93298-S  
Abstract-found: 0
Intro-found: 1
Reference: [AL93] <author> J. Anderson and M. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Program Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: However, many researchers have recognized the need for dynamic remapping and are planning to develop solutions. Knobe, Lukas, and Dally [KLD92], and Chatterjee, Gilbert, Schreiber, and Teng [CGST93] address the problem of dynamic alignment in a framework particularly suitable for SIMD machines. More recently, Anderson and Lam <ref> [AL93] </ref> have proposed techniques for automatic data layout for distributed and shared address space machines. Their approach considers dynamic remapping. 11 Algorithm DECOMP Input: program without procedure calls; problem sizes and number of processors to be used.
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <note> second edition, </note> <year> 1986. </year>
Reference-contexts: It must consider array remapping between computational phases to reduce communication costs within the computational phases or to better exploit available parallelism. Inter-phase analysis is performed on a phase control flow graph. A phase control flow graph is a control flow graph <ref> [ASU86] </ref> in which all nodes in a phase have been collapsed into a single node. Inter-phase analysis first detects the strongly connected components of the phase control flow graph in a hierarchical fashion using, for example, Tarjan intervals [Tar74].
Reference: [BFKK90] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> An interactive environment for data partitioning and distribution. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: The paper concludes with a discussion of related work and our future plans. 2 2 Compilation system The choice of a good data decomposition scheme for a program depends on the compilation system, the target machine and its size, and the problem size <ref> [BFKK90, BFKK91, LC90b, GB92, Who92] </ref>. Advances in compiler technology make it even more difficult for a programmer to predict the performance resulting from a given data decomposition scheme without compiling and running the program on the specific target system. State-of-the-art compilers perform a variety of intra- and inter-procedural optimizations.
Reference: [BFKK91] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The paper concludes with a discussion of related work and our future plans. 2 2 Compilation system The choice of a good data decomposition scheme for a program depends on the compilation system, the target machine and its size, and the problem size <ref> [BFKK90, BFKK91, LC90b, GB92, Who92] </ref>. Advances in compiler technology make it even more difficult for a programmer to predict the performance resulting from a given data decomposition scheme without compiling and running the program on the specific target system. State-of-the-art compilers perform a variety of intra- and inter-procedural optimizations. <p> For each phase, a static performance estimator will be invoked to predict the performance of each candidate scheme. The resulting performance estimates will be recorded with each decomposition scheme. A performance estimator suitable for our needs is described in detail elsewhere <ref> [BFKK91, HKK + 91] </ref>. 8 4.3 Inter-Phase Decomposition Analysis After computing a set of data decomposition schemes and estimates of their performance for each phase, the automatic data partitioner must solve the inter-phase decomposition problem to choose the best data decomposition for each phase. <p> The edges are labeled with the realignment and redistribution costs to map between the source and sink decomposition schemes. Edge weights will be determined based on the training set approach <ref> [BFKK91] </ref>. An example phase control flow graph with a single loop and the decomposition graph associated with the loop body is shown in Figure 2. For clarity the weights of nodes and edges have been omitted. The root nodes in the decomposition graph represent entry/exit decomposition schemes for the loop.
Reference: [Bri92] <author> P. Briggs. </author> <title> Register Allocation via Graph Coloring. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Procedure cloning or inlining may be applied under certain conditions to improve context for optimization [HKT91, HKT92, HHKT91, Tse93]. Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor <ref> [Car92, Wol92, Bri92] </ref>. At present, the principal target of our prototype Fortran D compilation system [Tse93] is the Intel iPSC/860. Eventually, the compilation system will target a variety of distributed-memory multiprocessors such as Intel's iPSC/860 and Paragon, Ncube's Ncube-1 and Ncube-2, and Thinking Machine Corporation's CM-5.
Reference: [Car92] <author> S. Carr. </author> <title> Memory-Hierarchy Management. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: Procedure cloning or inlining may be applied under certain conditions to improve context for optimization [HKT91, HKT92, HHKT91, Tse93]. Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor <ref> [Car92, Wol92, Bri92] </ref>. At present, the principal target of our prototype Fortran D compilation system [Tse93] is the Intel iPSC/860. Eventually, the compilation system will target a variety of distributed-memory multiprocessors such as Intel's iPSC/860 and Paragon, Ncube's Ncube-1 and Ncube-2, and Thinking Machine Corporation's CM-5.
Reference: [CGST93] <author> S. Chatterjee, J.R. Gilbert, R. Schreiber, and S-H. Teng. </author> <title> Automatic array alignment in data-parallel programs. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Albuquerque, NM, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: It is determined by the maximal dimensionalities and maximal dimensional extents of the arrays in the program. We intend to build on the inter-dimensional and intra-dimensional alignment techniques of Li and Chen [LC90a], Knobe et al. [KLS90], and Chatterjee, Gilbert, Schreiber, and Teng <ref> [CGST93] </ref>. In contrast to previous work, we will not limit ourselves to a single alignment as the result of the alignment analysis. Rather than eliminating one candidate alignment in the presence of an alignment conflict, both schemes may be added to the alignment search space [KK93]. <p> Our work is one of the first to provide a framework for automatic data layout that considers dynamic remapping. However, many researchers have recognized the need for dynamic remapping and are planning to develop solutions. Knobe, Lukas, and Dally [KLD92], and Chatterjee, Gilbert, Schreiber, and Teng <ref> [CGST93] </ref> address the problem of dynamic alignment in a framework particularly suitable for SIMD machines. More recently, Anderson and Lam [AL93] have proposed techniques for automatic data layout for distributed and shared address space machines.
Reference: [CHZ91] <author> B. Chapman, H. Herbeck, and H. Zima. </author> <title> Automatic support for data distribution. </title> <booktitle> In Proceedings of the 6th Distributed Memory Computing Conference, </booktitle> <address> Portland, OR, </address> <month> April </month> <year> 1991. </year>
Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: A solution to the single-source shortest paths problem in a directed acyclic graph is given in <ref> [CLR90] </ref>. Let k denote the maximal number of decomposition schemes for each phase and p the number of phases. The resulting time complexity is O (pk 3 ). The identification of innermost loops takes time proportional to the number of edges in the phase control flow graph.
Reference: [CMZ92] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Vienna Fortran a Fortran language extension for distributed memory multiprocessors. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <title> Languages, Compilers, and Run-Time Environments for Distributed Memory Machines. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1992. </year> <month> 13 </month>
Reference: [FHK + 90] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu. </author> <title> Fortran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The goal of the D programming tools project is to develop techniques and tools that aid scientists in the construction of programs in abstract parallel languages such as Fortran D <ref> [FHK + 90] </ref> and High Performance Fortran (HPF) [Hig93]. A short introduction to the Fortran D language is given in the appendix. <p> Each dimension of a decomposition can have a block, cyclic, or block-cyclic distribution <ref> [FHK + 90] </ref>. Block-cyclic distributions can have different block sizes. In addition, distributions with varying numbers of processors in each of the distributed dimensions of a decomposition are part of the distribution search space.
Reference: [GB92] <author> M. Gupta and P. Banerjee. </author> <title> Demonstration of automatic data partitioning techniques for parallelizing compilers on multicomputers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <month> April </month> <year> 1992. </year>
Reference-contexts: The paper concludes with a discussion of related work and our future plans. 2 2 Compilation system The choice of a good data decomposition scheme for a program depends on the compilation system, the target machine and its size, and the problem size <ref> [BFKK90, BFKK91, LC90b, GB92, Who92] </ref>. Advances in compiler technology make it even more difficult for a programmer to predict the performance resulting from a given data decomposition scheme without compiling and running the program on the specific target system. State-of-the-art compilers perform a variety of intra- and inter-procedural optimizations.
Reference: [Gup92] <author> M. Gupta. </author> <title> Automatic Data Partitioning on Distributed Memory Multicomputers. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> September </month> <year> 1992. </year>
Reference: [HA90] <author> D. Hudak and S. Abraham. </author> <title> Compiler techniques for data partitioning of sequentially iterated parallel loops. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year>
Reference: [HHKT91] <author> M. W. Hall, S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Interprocedural compilation of Fortran D for MIMD distributed-memory machines. </title> <type> Technical Report TR91-169, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: A Fortran D compiler may support optimizations that reduce or hide communication overhead, exploit parallelism, or reduce memory requirements. Procedure cloning or inlining may be applied under certain conditions to improve context for optimization <ref> [HKT91, HKT92, HHKT91, Tse93] </ref>. Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor [Car92, Wol92, Bri92]. At present, the principal target of our prototype Fortran D compilation system [Tse93] is the Intel iPSC/860.
Reference: [Hig93] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification, version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Center for Research on Parallel Computation, Rice University, Houston, TX, </institution> <month> May </month> <year> 1993. </year> <note> To appear in Scientific Programming, vol. 2, no. 1. </note>
Reference-contexts: 1 Introduction The goal of the D programming tools project is to develop techniques and tools that aid scientists in the construction of programs in abstract parallel languages such as Fortran D [FHK + 90] and High Performance Fortran (HPF) <ref> [Hig93] </ref>. A short introduction to the Fortran D language is given in the appendix.
Reference: [HKK + 91] <author> S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, and C. Tseng. </author> <title> An overview of the Fortran D programming system. </title> <booktitle> In Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: For each phase, a static performance estimator will be invoked to predict the performance of each candidate scheme. The resulting performance estimates will be recorded with each decomposition scheme. A performance estimator suitable for our needs is described in detail elsewhere <ref> [BFKK91, HKK + 91] </ref>. 8 4.3 Inter-Phase Decomposition Analysis After computing a set of data decomposition schemes and estimates of their performance for each phase, the automatic data partitioner must solve the inter-phase decomposition problem to choose the best data decomposition for each phase.
Reference: [HKT91] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albu-querque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: A Fortran D compiler may support optimizations that reduce or hide communication overhead, exploit parallelism, or reduce memory requirements. Procedure cloning or inlining may be applied under certain conditions to improve context for optimization <ref> [HKT91, HKT92, HHKT91, Tse93] </ref>. Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor [Car92, Wol92, Bri92]. At present, the principal target of our prototype Fortran D compilation system [Tse93] is the Intel iPSC/860.
Reference: [HKT92] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Evaluation of compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: A Fortran D compiler may support optimizations that reduce or hide communication overhead, exploit parallelism, or reduce memory requirements. Procedure cloning or inlining may be applied under certain conditions to improve context for optimization <ref> [HKT91, HKT92, HHKT91, Tse93] </ref>. Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor [Car92, Wol92, Bri92]. At present, the principal target of our prototype Fortran D compilation system [Tse93] is the Intel iPSC/860.
Reference: [IFKF90] <author> K. Ikudome, G. Fox, A. Kolawa, and J. Flower. </author> <title> An automatic and symbolic paral-lelization system for distributed memory parallel computers. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference: [KK93] <author> K. Kennedy and U. Kremer. </author> <title> Initial framework for automatic data layout in Fortran D: A short update on a case study. </title> <type> Technical Report CRPC-TR93-324-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: Pruning heuristics will have to be developed to restrict the alignment and distribution search spaces to manageable sizes. A first discussion of possible pruning heuristics and the sizes of their resulting search spaces can be found in <ref> [KK93] </ref>. Here we describe an initial analysis framework suitable for programs without procedure calls that contain no control flow other than loops. We assume that the problem size and the number of processors used is known at compile time. <p> In contrast to previous work, we will not limit ourselves to a single alignment as the result of the alignment analysis. Rather than eliminating one candidate alignment in the presence of an alignment conflict, both schemes may be added to the alignment search space <ref> [KK93] </ref>. The candidate alignments computed for each phase, will serve as input to distribution analysis. 4.2 Distribution Analysis Distribution analysis will consider a rich set of distribution schemes for each of the alignment schemes determined in the alignment analysis.
Reference: [KLD92] <author> K. Knobe, J.D. Lukas, and W.J. Dally. </author> <title> Dynamic alignment on distributed memory systems. </title> <booktitle> In Proceedings of the Third Workshop on Compilers for Parallel Computers, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Our work is one of the first to provide a framework for automatic data layout that considers dynamic remapping. However, many researchers have recognized the need for dynamic remapping and are planning to develop solutions. Knobe, Lukas, and Dally <ref> [KLD92] </ref>, and Chatterjee, Gilbert, Schreiber, and Teng [CGST93] address the problem of dynamic alignment in a framework particularly suitable for SIMD machines. More recently, Anderson and Lam [AL93] have proposed techniques for automatic data layout for distributed and shared address space machines.
Reference: [KLS90] <author> K. Knobe, J. Lukas, and G. Steele, Jr. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(2) </volume> <pages> 102-118, </pages> <month> February </month> <year> 1990. </year> <month> 14 </month>
Reference-contexts: The alignment space of a program is unique. It is determined by the maximal dimensionalities and maximal dimensional extents of the arrays in the program. We intend to build on the inter-dimensional and intra-dimensional alignment techniques of Li and Chen [LC90a], Knobe et al. <ref> [KLS90] </ref>, and Chatterjee, Gilbert, Schreiber, and Teng [CGST93]. In contrast to previous work, we will not limit ourselves to a single alignment as the result of the alignment analysis.
Reference: [KM91] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiling global name-space parallel loops for distributed execution. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 440-451, </pages> <month> Oc-tober </month> <year> 1991. </year>
Reference: [KN90] <author> K. Knobe and V. Natarajan. </author> <title> Data optimization: Minimizing residual interprocessor data motion on SIMD machines. </title> <booktitle> In Frontiers90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year>
Reference: [Kre93a] <author> U. Kremer. </author> <title> Automatic data layout for distributed-memory machines. </title> <type> Technical Report CRPC-TR93-299-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> February </month> <year> 1993. </year> <type> (thesis proposal). </type>
Reference-contexts: The presented solutions differ significantly in the assumptions that are made about the input language, the possible set of data decompositions, the compilation system, and the target distributed-memory machine. A more detailed discussion of some of the related work can be found in <ref> [Kre93a] </ref>. Our work is one of the first to provide a framework for automatic data layout that considers dynamic remapping. However, many researchers have recognized the need for dynamic remapping and are planning to develop solutions.
Reference: [Kre93b] <author> U. Kremer. </author> <title> NP-completeness of dynamic remapping. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year> <note> Also available as technical report CRPC-TR93-330-S (D Newsletter #8), </note> <institution> Rice University. </institution>
Reference-contexts: If we relax this restriction, for instance by allowing each decomposition scheme for a phase to only specify the layout of arrays actually referenced in the phase, the dynamic data layout problem becomes NP-complete <ref> [Kre93b] </ref>. A study of real programs will show when the restriction has to be relaxed in order to limit the number of candidate decomposition schemes for each phase.
Reference: [LC90a] <author> J. Li and M. Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing between distributed arrays. </title> <booktitle> In Frontiers90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: The alignment space of a program is unique. It is determined by the maximal dimensionalities and maximal dimensional extents of the arrays in the program. We intend to build on the inter-dimensional and intra-dimensional alignment techniques of Li and Chen <ref> [LC90a] </ref>, Knobe et al. [KLS90], and Chatterjee, Gilbert, Schreiber, and Teng [CGST93]. In contrast to previous work, we will not limit ourselves to a single alignment as the result of the alignment analysis.
Reference: [LC90b] <author> J. Li and M. Chen. </author> <title> Synthesis of explicit communication from shared-memory program references. </title> <type> Technical Report YALEU/DCS/TR-755, </type> <institution> Dept. of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: The paper concludes with a discussion of related work and our future plans. 2 2 Compilation system The choice of a good data decomposition scheme for a program depends on the compilation system, the target machine and its size, and the problem size <ref> [BFKK90, BFKK91, LC90b, GB92, Who92] </ref>. Advances in compiler technology make it even more difficult for a programmer to predict the performance resulting from a given data decomposition scheme without compiling and running the program on the specific target system. State-of-the-art compilers perform a variety of intra- and inter-procedural optimizations.
Reference: [LC91] <author> J. Li and M. Chen. </author> <title> The data alignment phase in compiling programs for distributed-memory machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(4) </volume> <pages> 213-221, </pages> <month> August </month> <year> 1991. </year>
Reference: [Ram90] <author> J. Ramanujam. </author> <title> Compile-time Techniques for Parallel Execution of Loops on Distributed Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, Ohio State University, Columbus, OH, </institution> <year> 1990. </year>
Reference: [RS89] <author> J. Ramanujam and P. Sadayappan. </author> <title> A methodology for parallelizing programs for mul-ticomputers and complex memory multiprocessors. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <address> Reno, NV, </address> <month> November </month> <year> 1989. </year>
Reference: [SS90] <author> L. Snyder and D. Socha. </author> <title> An algorithm producing balanced partitionings of data arrays. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference: [Sus91] <author> A. Sussman. </author> <title> Model-Driven Mapping onto Distributed Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> September </month> <year> 1991. </year>
Reference: [Tar74] <author> R. E. Tarjan. </author> <title> Testing flow graph reducibility. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9 </volume> <pages> 355-365, </pages> <year> 1974. </year>
Reference-contexts: A phase control flow graph is a control flow graph [ASU86] in which all nodes in a phase have been collapsed into a single node. Inter-phase analysis first detects the strongly connected components of the phase control flow graph in a hierarchical fashion using, for example, Tarjan intervals <ref> [Tar74] </ref>. For each innermost loop, the inter-phase decomposition selection problem is formulated as a single-source shortest path problem over the acyclic decomposition graph associated with the loop body. <p> The resulting time complexity is O (pk 3 ). The identification of innermost loops takes time proportional to the number of edges in the phase control flow graph. For our class of control flow graphs O (edges) = O (nodes) holds, resulting in O (p) time for Tarjan's algorithm <ref> [Tar74] </ref>. Therefore, the entire algorithm for merging decomposition schemes across phases has time complexity O (pk 3 ).
Reference: [TMC89] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA. </address> <note> CM Fortran Reference Manual, version 5.2-0.6 edition, </note> <month> September </month> <year> 1989. </year>
Reference: [Tse93] <author> C. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Rice University, Houston, TX, </institution> <month> January </month> <year> 1993. </year> <institution> Rice COMP TR93-199. </institution> <month> 15 </month>
Reference-contexts: A Fortran D compiler may support optimizations that reduce or hide communication overhead, exploit parallelism, or reduce memory requirements. Procedure cloning or inlining may be applied under certain conditions to improve context for optimization <ref> [HKT91, HKT92, HHKT91, Tse93] </ref>. Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor [Car92, Wol92, Bri92]. At present, the principal target of our prototype Fortran D compilation system [Tse93] is the Intel iPSC/860. <p> Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor [Car92, Wol92, Bri92]. At present, the principal target of our prototype Fortran D compilation system <ref> [Tse93] </ref> is the Intel iPSC/860. Eventually, the compilation system will target a variety of distributed-memory multiprocessors such as Intel's iPSC/860 and Paragon, Ncube's Ncube-1 and Ncube-2, and Thinking Machine Corporation's CM-5.
Reference: [Who91] <author> S. Wholey. </author> <title> Automatic Data Mapping for Distributed-Memory Parallel Computers. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> May </month> <year> 1991. </year>
Reference: [Who92] <author> S. Wholey. </author> <title> Automatic data mapping for distributed-memory parallel computers. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washing-ton, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The paper concludes with a discussion of related work and our future plans. 2 2 Compilation system The choice of a good data decomposition scheme for a program depends on the compilation system, the target machine and its size, and the problem size <ref> [BFKK90, BFKK91, LC90b, GB92, Who92] </ref>. Advances in compiler technology make it even more difficult for a programmer to predict the performance resulting from a given data decomposition scheme without compiling and running the program on the specific target system. State-of-the-art compilers perform a variety of intra- and inter-procedural optimizations.
Reference: [Wol92] <author> M.E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: Procedure cloning or inlining may be applied under certain conditions to improve context for optimization [HKT91, HKT92, HHKT91, Tse93]. Node compilers may perform optimizations to exploit the memory hierarchy and instruction-level parallelism available on the target node processor <ref> [Car92, Wol92, Bri92] </ref>. At present, the principal target of our prototype Fortran D compilation system [Tse93] is the Intel iPSC/860. Eventually, the compilation system will target a variety of distributed-memory multiprocessors such as Intel's iPSC/860 and Paragon, Ncube's Ncube-1 and Ncube-2, and Thinking Machine Corporation's CM-5.
References-found: 40

