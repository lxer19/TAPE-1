URL: http://www.cs.unc.edu/~scher/xrds.ps
Refering-URL: http://www.cs.unc.edu/~scher/frameless.html
Root-URL: http://www.cs.unc.edu
Title: A Human's Eye View: Motion Blur and Frameless Rendering  
Author: Ellen J. Scher Zagier 
Date: March 12, 1997  
Abstract: Frameless Rendering (FR) is a rendering paradigm which performs stochastic temporal filtering by updating pixels in a random order, based on most recent available input data, and displaying them to the screen immediately [1]. This is a departure from frame-based approaches commonly experienced in interactive graphics. A typical interactive graphics session uses a single input state to compute an entire frame. This constrains the state to be known at the time the first pixel's value is computed. Frameless Rendering samples inputs many times during the interval which begins at the start of the first pixel's computation and ends with the last pixel's computation. Thus, Frameless Rendering performs temporal supersampling it uses more samples over time. This results in an approximation to motion blur, both theoretically and perceptually. This paper explores this motion blur and its relationship to: camera open shutter time, current computer graphics motion-blur implementations, temporally antialiased images, and the Human Visual System's (HVS) motion smear quality 1 [2]. Finally, we integrate existing research results to conjecture as to how Frameless Rendering can use knowledge of the Human Visual System's blurred retinal image to direct spatiotemporal sampling. In other words, we suggest importance sampling 2 by prioritizing pixels for computation based on their importance to the visual system in discerning what is occurring in an interactive image sequence. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gary Bishop, Henry Fuchs, Leonard McMillan, and Ellen J. Scher Zagier. </author> <title> Frame-less rendering: Double buffering considered harmful. </title> <booktitle> In Computer Graphics (SIG-GRAPH '94 Proceedings), </booktitle> <pages> pages 175-176, </pages> <month> July </month> <year> 1994. </year> <month> 9 </month>
Reference-contexts: With the help of existing research, an approach for importance sampling in regions projecting onto lowest retinal velocity is suggested. 2 Previous Frameless Rendering Results Frameless Rendering: Researchers at UNC Chapel Hill illustrated that using Frameless Rendering <ref> [1] </ref> can offer a more fluid animation than traditional double buffering. This translates to quicker response time in interactive applications, with only a slight degradation of image quality.
Reference: [2] <author> David Burr. </author> <title> Visual processing of motion. </title> <booktitle> In Trends in Neuro Sciences, </booktitle> <volume> volume 9, No. 7, </volume> <month> July </month> <year> 1986. </year>
Reference-contexts: An open shutter with a duration of 120 - 125 ms better approximates the motion-induced motion smear appearing on the retina, than frames where all pixels have been computed from the exact same time step. Exploiting Motion Smear: Visual information is accumulated over an interval of approximately 125 ms <ref> [2] </ref>. The retinal image, an integration of this information, is blurred or smeared. The newest information has the greatest photoreceptor response. An appropriately weighted integral can model this integration over time. A camera shutter integrates evenly over time.
Reference: [3] <author> Robert L. Cook, Thomas Porter, and Loren Carpenter. </author> <title> Distributed ray tracing. </title> <booktitle> In Computer Graphics (SIGGRAPH '84 Proceedings), </booktitle> <volume> volume 18, </volume> <pages> pages 137-45, </pages> <month> July </month> <year> 1984. </year> <title> Monte Carlo distribution of rays to get gloss, translucency, penumbras, depth of field, motion blur. </title>
Reference-contexts: Frameless Rendering is a spatial subsampler as well, that is, fewer spatial samples are computed for each Frameless Rendering snapshot. Motion blur implementations in computer graphics <ref> [3] </ref>, [6] perform temporal supersampling as well. <p> Some Frameless Rendering implementations exhibit a similar artifact when inputs are not sampled densely enough. See Figure 2. A method very similar to the temporal supersampling method just described was developed for raytraced images. It is known as distributed ray tracing <ref> [3] </ref>. Distributed ray tracing assumes an a priori expense for spatial antialiasing, such as 16 samples per pixel. These samples are typically derived from system input state at a single instant in time.
Reference: [4] <author> Michael P. Eckert and Gershon Buchsbaum. </author> <title> The significance of eye movements and image acceleration for coding. In A.B. </title> <editor> Watson, editor, </editor> <booktitle> Digital Images and Human Vision, </booktitle> <pages> pages 90-97, </pages> <year> 1993. </year>
Reference-contexts: How then is the motion picture and television industry able to successfully substitute blurred frames without introducing visible image degradation? The conflict is resolved by understanding that the eye acts as a filter <ref> [4] </ref>. Because the eye tracks motion, the final retinal velocity may be lower than the original image velocity. <p> or more of the following non-orthogonal conditions hold: * Low predictability of motion: If the observer does not know what to expect, then he or she cannot easily track the motion. * Motion acceleration: Object acceleration is correlated with an inability to eye-track at the same rate as the motion <ref> [4] </ref>. This is because a changing velocity is difficult to predict. So, it is a sub-class of the category above.
Reference: [5] <author> Bernd Girod. </author> <title> Eye movements and coding of video sequences. </title> <editor> In T. R. Hsing, editor, </editor> <booktitle> SPIE Visual Communications and image Processing, </booktitle> <pages> pages 398-405, </pages> <year> 1988. </year>
Reference-contexts: Bottom right: Double ball drop - `rear curtain' shot, that is, flash taken at the end of the interval. Photos: c fl1997 Dan Crawford. Studies show that humans are sensitive to spatial blur with image velocities up to at least 9.4 deg/sec <ref> [5] </ref>. How then is the motion picture and television industry able to successfully substitute blurred frames without introducing visible image degradation? The conflict is resolved by understanding that the eye acts as a filter [4]. <p> The motion picture industry presents blurred images to human observers and high quality sequences are perceived. Some computer-generated, motion-blurred sequences also effect a high quality perception. In fact, the quality is enhanced because of reducing temporal aliasing artifacts. But Girod's work <ref> [5] </ref>, and other corroborated studies, have found that human observers can detect artificial blur under many conditions. The images we see on television successfully exploit the HVS motion smear quality because the sequences contain high image acceleration, low predictability of motion, and complex scene motion.
Reference: [6] <author> Jonathan D. Korein and Norman I. Badler. </author> <title> Temporal anti-aliasing in computer generated animation. </title> <booktitle> In Computer Graphics (SIGGRAPH '83 Proceedings), </booktitle> <volume> volume 17, </volume> <pages> pages 377-388, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: Frameless Rendering is a spatial subsampler as well, that is, fewer spatial samples are computed for each Frameless Rendering snapshot. Motion blur implementations in computer graphics [3], <ref> [6] </ref> perform temporal supersampling as well. <p> The point spread function encapsulates the motion in the scene over an interval. The result is a blurred spatial domain image. Another method, again with the goal of capturing the motion occurring in between frames, is a straightforward temporal supersampling method based on spatial super-sampling techniques <ref> [6] </ref>. A complete image sequence is computed at a higher frame rate than the final 30 f ps playback rate. The experiment illustrated in the paper computes frames 4 times as densely, a total of 120 frames of information per second of final animation.
Reference: [7] <author> M. Potmesil and I. Chakravarty. </author> <title> Modelling motion blur in computer-generated images. </title> <booktitle> In Computer Graphics (SIGGRAPH '83 Proceedings), </booktitle> <volume> volume 17, </volume> <pages> pages 389-399, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: Early attempts at motion blur were designed as a solution to temporal aliasing as well as mimicking a camera shutter. One strategy for introducing motion blur is to convolve each frequency domain image with a point spread function <ref> [7] </ref>. The point spread function encapsulates the motion in the scene over an interval. The result is a blurred spatial domain image. Another method, again with the goal of capturing the motion occurring in between frames, is a straightforward temporal supersampling method based on spatial super-sampling techniques [6].
Reference: [8] <author> Ellen J. Scher Zagier. Frameless antialiasing. </author> <type> Technical Report UNC-CS-TR-95-026, </type> <institution> Department of Computer Science, University of North Carolina at Chapel Hill, </institution> <year> 1995. </year>
Reference-contexts: If there is time for x number of samples to be computed at time t then all x samples should be computed and displayed. If there is not enough time to compute all samples then Frameless antialiasing theory <ref> [8] </ref> suggests updating as many samples as possible, but choosing those samples pseudo-randomly to avoid visible artifactual patterns. A side-by-side comparison illustrates a clear advantage to updating samples as computed versus waiting for all samples to be computed.
Reference: [9] <author> Robert Sekuler and Randolph Blake. </author> <title> Perception. </title> <publisher> McGraw-Hill Publishing Company, </publisher> <address> New York, </address> <year> 1990. </year> <month> 10 </month>
Reference-contexts: Finally, it is important to throw a wrench into all of this theory. The perceived motion is not always a straightforward matter. There are documented cases of induced motion, although no actual motion is presented to the observer <ref> [9] </ref>. An example of apparent motion in the absence of actual motion, is the `waterfall' effect. If a person stares at a waterfall for a long period of time, and then looks away, they will perceive motion of equal velocity and acceleration in the opposite direction.
References-found: 9

