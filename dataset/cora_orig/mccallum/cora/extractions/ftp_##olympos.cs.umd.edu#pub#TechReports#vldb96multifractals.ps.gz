URL: ftp://olympos.cs.umd.edu/pub/TechReports/vldb96multifractals.ps.gz
Refering-URL: http://www.cs.umd.edu/~christos/selpapers.html
Root-URL: 
Email: christos@cs.umd.edu  favi,matiasg@research.att.com  
Title: Modeling skewed distributions using multifractals and the  
Author: `- law' Christos Faloutsos Yossi Matias Avi Silberschatz 
Date: February 23, 1996  
Address: College Park, MD 20742  Murray Hill, NJ 07974  
Affiliation: Dept. of Computer Science and Institute of Systems Research Univ. of Maryland  Bell Labs  
Abstract: PAPER NO. 1077 The focus of this paper is on the characterization of the skewness of an attribute-value distribution and on the extrapolations for interesting parameters. More specifically, given a vector with the highest h multiplicities ~m = (m 1 ; m 2 ; :::; m h ), and some frequency moments F q = P i , (e.g., q = 0; 2), we provide effective schemes for obtaining estimates about either its statistics or subsets/supersets of the relation. We assume an 80/20 law, and specifically, a p=(1 p) law. This law gives a distribution which is commonly known in the fractals literature as `multifractal'. We show how to estimate p from the given information (first few multiplicities, and a few moments), and present the results of our experimentations on real data. Our results demonstrate that schemes based on our multifractal assumption consistently outperforms those schemes based on the uniformity assumption, which are commonly used in current DBMSs. Moreover, our schemes can be used to provide estimates for supersets of a relation, which the uniformity assumption based schemes can not not provide at all.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, Yossi Matias, and M. Szegedi. </author> <title> The space complexity of approximating the frequency moments. </title> <booktitle> In Proc. 28th ACM Symp. on Theory of Computing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: These are called 'high-biased' histograms, and seem to be the state of the art, in current commercial systems. Ioannidis and Christodoulakis [8] showed that they have the smallest error among several classes of histograms for self-joins. In our previous work [5] <ref> [1] </ref> we have proposed on-line algorithms to maintain probabilistically the first n multiplicities, as well as a few frequency moments F q = P q There are two main ideas that distinguish the present work from the current state-of-the-art: The first is the proposal to use the multi-fractal assumption, as opposed <p> The probabilistic algorithms of <ref> [1] </ref> can easily handle keep track of such frequency moments The frequency moments are useful to characterize the skeweness of the distribution. Intuitively, the q-th frequency moments gives the size of joining the table q times with itself on the attribute under discussion.
Reference: [2] <author> Alberto Belussi and Christos Faloutsos. </author> <title> Estimating the selectivity of spatial queries using the `correlation' fractal dimension. </title> <booktitle> Proc. of VLDB, </booktitle> <pages> pages 299-310, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: For example, a range query would be: estimate the number of cities in Colorado; a spatial-join query would be estimate the number of pairs of cities that are closer than 10 miles to each other <ref> [2] </ref>.
Reference: [3] <author> A.F. Cardenas. </author> <title> Analysis and performance of inverted data base structures. </title> <journal> CACM, </journal> <volume> 18(5) </volume> <pages> 253-263, </pages> <month> May </month> <year> 1975. </year>
Reference-contexts: As mentioned before, assuming a multi-fractal distribution, we compute the N , p, k parameters, and then use Eq. 10 to estimate the vocabulary of the sub-set/super-set. Under the uniformity assumption, the best we can do is to consider a generalization of Cardenas' formula <ref> [3] </ref>: we know that we have F 0 buckets and N 0 records; we also know the frequency that the first h buckets are chosen; thus each bucket is chosen with probability p i , which is computed as follows: p i = m i =N i h (15) where N
Reference: [4] <author> Christos Faloutsos and H.V. Jagadish. </author> <title> On b-tree indices for skewed distributions. </title> <booktitle> In 18th VLDB Conference, </booktitle> <pages> pages 363-374, </pages> <address> Vancouver, British Columbia, </address> <month> August </month> <year> 1992. </year> <note> Also available as. </note>
Reference-contexts: The question is: how accurate our predictions are. This is the topic of the experimental section. 4 Experiments We used several real datasets: * 'VFN' were the first names (actually: 'very first names', by omitting middle names etc), from an on-line telephone catalog <ref> [4] </ref>. * 'SALES' the dollar amounts of sales for customers, with accuracy 1, 10 and 100 dollars, respectively, for SALES1, SALES10 and SALES100. 9 Dataset N F 0 m max VFN 11657 3269 288 SALES1 213603 246 71565 SALES10 21507 246 7157 SALES100 2309 246 716 BIBLE 791448 12561 63924 PSALMS
Reference: [5] <author> P. Gibbons, Yossi Matias, and A. Witkowski. </author> <title> Practical maintenance algorithms for high-biased histograms using probabilistic filtering. </title> <type> unpublished manuscript, </type> <month> December </month> <year> 1995. </year>
Reference-contexts: These are called 'high-biased' histograms, and seem to be the state of the art, in current commercial systems. Ioannidis and Christodoulakis [8] showed that they have the smallest error among several classes of histograms for self-joins. In our previous work <ref> [5] </ref> [1] we have proposed on-line algorithms to maintain probabilistically the first n multiplicities, as well as a few frequency moments F q = P q There are two main ideas that distinguish the present work from the current state-of-the-art: The first is the proposal to use the multi-fractal assumption, as <p> the p and k parameters to yield a multifractal distribution that will match the given data As we mentioned, this problem is very realistic: most of the commercial systems keep some `high-end biased' histograms [9] for query optimization; probabilistic on-line algorithms for maintaining such histograms have just recently been proposed <ref> [5] </ref> There are two sets of results: The first set tries to express the p and k parameters as functions of the given data. The second set tries to estimate other quantities of interest (eg, median value etc), for a given multifractal distribution with parameters p and k.
Reference: [6] <author> Peter J. Haas, Jeffrey F. Naughton, S. Seshadri, </author> <title> and Lynne Stokes. Sampling-based estimation of the number of distinct values of an attribute. </title> <booktitle> Proc. of VLDB, </booktitle> <pages> pages 311-322, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: As we show later, we can estimate the number of distinct values F 0 for a subset or a superset of a given relation. The state of the art in this area seems to be the work of Haas et al <ref> [6] </ref> which uses two different estimators, and, depending on the perceived skeweness, it chooses the appropriate one each time. Previous work includes [7] etc., whose estimators are superseded by [6]. <p> The state of the art in this area seems to be the work of Haas et al <ref> [6] </ref> which uses two different estimators, and, depending on the perceived skeweness, it chooses the appropriate one each time. Previous work includes [7] etc., whose estimators are superseded by [6]. As we show later, our proposed multi-fractal assumption leads to very good estimates, with estimation error about the same as the best available estimator. 2.4 Introduction to Multi-fractals An excellent introduction to multifractals is in [13]. <p> Based on the BIBLE dataset, we estimated the samples of it (ROMANS, PSALMS and JEREMIAH). Notice that the work of Haas et al. <ref> [6] </ref> is not directly applicable, because it assumes that we know all the multiplicities of the given dataset, as opposed to only the h highest, that is our setting. <p> Notice that our estimates give low errors (40-60%), which are comparable to the errors of much more sophisticated estimation algorithms: Haas et al <ref> [6] </ref>, using all the statistics about the dataset, report that, for a 10% sample of 'highly skewed' distributions, the relative error ( j ^ F 0 F 0 j=F 0 ) was on the average 23% (maximum: 95%) for the so-called Shlosser estimator, which was the best performer for 'high-skew distributions'.
Reference: [7] <author> Wen-Chi Hou and Gultekin Ozsoyoglu. </author> <title> Statistical estimators for aggregate relational algebra queries. </title> <journal> ACM TODS, </journal> <volume> 16(4) </volume> <pages> 600-654, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: The state of the art in this area seems to be the work of Haas et al [6] which uses two different estimators, and, depending on the perceived skeweness, it chooses the appropriate one each time. Previous work includes <ref> [7] </ref> etc., whose estimators are superseded by [6]. As we show later, our proposed multi-fractal assumption leads to very good estimates, with estimation error about the same as the best available estimator. 2.4 Introduction to Multi-fractals An excellent introduction to multifractals is in [13].
Reference: [8] <author> Yannis E. Ioannidis and Stavros Christodoulakis. </author> <title> Optimal histograms for limiting worst-case error propagation in the size of join results. </title> <journal> ACM TODS, </journal> <volume> 18(4) </volume> <pages> 709-748, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: CDR-8803012, EEC-94-02384, IRI-8958546 and IRI-9205273), with matching funds from Empress Software Inc. and Thinking Machines Inc. 1 For the attribute values that we have no information about, the typical assumption is the uniformity assumption <ref> [8] </ref>. This is typically the information that we keep track of, in order to estimate selectivities for query optimization. <p> Ioannidis and Poosala [9] suggest keeping the frequencies of a few frequent attributes, and making the uniformity assumption for the rest. These are called 'high-biased' histograms, and seem to be the state of the art, in current commercial systems. Ioannidis and Christodoulakis <ref> [8] </ref> showed that they have the smallest error among several classes of histograms for self-joins.
Reference: [9] <author> Yannis E. Ioannidis and Viswanath Poosala. </author> <title> Balancing histogram optimality and practicality for query result size estimation. </title> <booktitle> ACM SIGMOD, </booktitle> <pages> pages 233-244, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Typically [15] the RDBMSs keep the total number of records N for a relation, the total number of distinct values F 0 for a given attribute, and lately, the high-biased histogram <ref> [9] </ref> (that is, the first few most common values, along with their multiplicity = occurrence frequency). <p> Ioannidis and Poosala <ref> [9] </ref> suggest keeping the frequencies of a few frequent attributes, and making the uniformity assumption for the rest. These are called 'high-biased' histograms, and seem to be the state of the art, in current commercial systems. <p> 2; : : :; h and thenumber of distinct attribute values F 0 . * Estimate the p and k parameters to yield a multifractal distribution that will match the given data As we mentioned, this problem is very realistic: most of the commercial systems keep some `high-end biased' histograms <ref> [9] </ref> for query optimization; probabilistic on-line algorithms for maintaining such histograms have just recently been proposed [5] There are two sets of results: The first set tries to express the p and k parameters as functions of the given data. <p> Such estimates are useful in numerous applications, such as (a) traditional query optimization, supplementing the high-end histogram methods that is currently the state of the art <ref> [9] </ref> (b) decision support systems, where extrapolations for subsets and supersets are important. Experiments on several real datasets showed that the multifractal assumption gives significantly better 13 estimates than the 'uniformity' assumption, for several useful statistical quantities.
Reference: [10] <author> B.B. Mandelbrot. </author> <title> The stable paretian income distribution when the apparent exponent is near zero. </title> <journal> Int. Econ. Rev., </journal> <volume> 4 </volume> <pages> 111-115, </pages> <year> 1963. </year>
Reference-contexts: distributions in physics, or commodities (water, gold, etc) distributions on earth etc., follow a rule like `the first half of the region contains a fraction p of the gold, and so on, recursively, for each sub-region.' Similarly, financial data and salary distributions follow similar patterns (Pareto's law of income distribution <ref> [10] </ref>). With the above rule, we assume that the address space (eg., the unit interval) is recursively decomposed at k levels; each decomposition halves the input interval in two. Thus, eventually we have 2 k sub-intervals (=buckets = slots) of length 2 k . <p> N records, bias p and order k, for a subset of N 0 records we estimate its `vocabulary' ^ F 0 0 as given by ^ F 0 k X C k m p m 8 Median and percentiles Salaries and incomes follow very skewed distributions [14, p. 35] [12], <ref> [10] </ref> Our upcoming experiments (see section 4 show that sales patterns seem to do the same. Thus, given a relation with salaries, the question is to find the median salary, given little information (eg., the first few top salaries).
Reference: [11] <author> M. Muralikrishna and David J. DeWitt. </author> <title> Equi-depth histograms for estimating selectivity factors for multi-dimensional queries. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> pages 28-36, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: directions. 2 2 Survey Background Here we present the state of the art in histogram methods, a discussion on previous models for skewed distributions (`Zipf' and `generalized Zipf' [16] etc) and some related methods for estimation using sampling; we also give an introduction to multi-fractals. 2.1 Histograms DeWitt and Muralikrishna <ref> [11] </ref> studied multi-dimensional histograms. Ioannidis and Poosala [9] suggest keeping the frequencies of a few frequent attributes, and making the uniformity assumption for the rest. These are called 'high-biased' histograms, and seem to be the state of the art, in current commercial systems.
Reference: [12] <author> V. </author> <title> Pareto. Oeuvres Completes. </title> <type> Droz, </type> <institution> Geneva, </institution> <month> 1896. </month>
Reference-contexts: with N records, bias p and order k, for a subset of N 0 records we estimate its `vocabulary' ^ F 0 0 as given by ^ F 0 k X C k m p m 8 Median and percentiles Salaries and incomes follow very skewed distributions [14, p. 35] <ref> [12] </ref>, [10] Our upcoming experiments (see section 4 show that sales patterns seem to do the same. Thus, given a relation with salaries, the question is to find the median salary, given little information (eg., the first few top salaries).
Reference: [13] <author> Heinz-Otto Peitgen, Hartmut Juergens, and Dietmar Saupe. </author> <title> Chaos and Fractals: </title> <booktitle> New Frontiers of Science. </booktitle> <publisher> Springer-Verlag New York Inc., </publisher> <year> 1992. </year>
Reference-contexts: Previous work includes [7] etc., whose estimators are superseded by [6]. As we show later, our proposed multi-fractal assumption leads to very good estimates, with estimation error about the same as the best available estimator. 2.4 Introduction to Multi-fractals An excellent introduction to multifractals is in <ref> [13] </ref>. Their relationship with the 80-20 `law' is very close, and seem to appear often: Schroeder [14] claim that several real distributions follow a rule reminiscent of the 80-20 rule in databases.
Reference: [14] <author> Manfred Schroeder. </author> <title> Fractals, Chaos, Power Laws: Minutes From an Infinite Paradise. W.H. </title> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1991. </year> <month> 14 </month>
Reference-contexts: Specifically for text (English, as well as several other languages, as Zipf showed experimentally [16]) Schroeder <ref> [14] </ref> gives the following formula (its notation is adapted to our notation): m r r ln (1:78F 0 ) Several models for non-uniform distributions have appeared; however, we focus on the ones that seem to match real-life distributions. <p> Their relationship with the 80-20 `law' is very close, and seem to appear often: Schroeder <ref> [14] </ref> claim that several real distributions follow a rule reminiscent of the 80-20 rule in databases. <p> by a multi-fractal with N records, bias p and order k, for a subset of N 0 records we estimate its `vocabulary' ^ F 0 0 as given by ^ F 0 k X C k m p m 8 Median and percentiles Salaries and incomes follow very skewed distributions <ref> [14, p. 35] </ref> [12], [10] Our upcoming experiments (see section 4 show that sales patterns seem to do the same. Thus, given a relation with salaries, the question is to find the median salary, given little information (eg., the first few top salaries).
Reference: [15] <author> P.G. Selinger, D.D. Astrahan, R.A. Chamberlain, R.A. Lorie, and T.G. Price. </author> <title> Access path selection in a relational database management system. </title> <booktitle> Proc. ACM-SIGMOD, </booktitle> <pages> pages 23-34, </pages> <year> 1979. </year>
Reference-contexts: 1 Introduction The goal of this paper is to estimate several measures for a distribution of attribute values, given the `standard' information that commercial RDBMSs keep about the distributions. Typically <ref> [15] </ref> the RDBMSs keep the total number of records N for a relation, the total number of distinct values F 0 for a given attribute, and lately, the high-biased histogram [9] (that is, the first few most common values, along with their multiplicity = occurrence frequency).
Reference: [16] <author> G.K. Zipf. </author> <title> Human Behavior and Principle of Least Effort: an Introduction to Human Ecology. </title> <publisher> Addison Wesley, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1949. </year>
Reference-contexts: Section 4 shows experimental results on real data. Section 5 lists the conclusions and future research directions. 2 2 Survey Background Here we present the state of the art in histogram methods, a discussion on previous models for skewed distributions (`Zipf' and `generalized Zipf' <ref> [16] </ref> etc) and some related methods for estimation using sampling; we also give an introduction to multi-fractals. 2.1 Histograms DeWitt and Muralikrishna [11] studied multi-dimensional histograms. Ioannidis and Poosala [9] suggest keeping the frequencies of a few frequent attributes, and making the uniformity assumption for the rest. <p> Definition 2.3 The rank-frequency plot of a set of multiplicities sorted in descending order is the plot of m r versus the rank r, with both axes logarithmic described in section 4). 2.2 Models for nonuniformity Probably the earliest model for non-uniform distributions is the Zipf distribution <ref> [16] </ref>. According to this model, the i-th highest multiplicity m i is given by the formula: m r C=r (5) For = 1 we have the Zipf distribution; for 6= 1 we have a `generalized Zipf' distribution with parameter . <p> Specifically for text (English, as well as several other languages, as Zipf showed experimentally <ref> [16] </ref>) Schroeder [14] gives the following formula (its notation is adapted to our notation): m r r ln (1:78F 0 ) Several models for non-uniform distributions have appeared; however, we focus on the ones that seem to match real-life distributions.
References-found: 16

