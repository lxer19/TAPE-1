URL: http://www.cs.ucsd.edu/users/mihir/papers/qp.ps.gz
Refering-URL: http://www.cs.ucsd.edu/users/mihir/papers/complexity-papers.html
Root-URL: http://www.cs.ucsd.edu
Title: Complexity of Approximating a Nonlinear Program  
Author: Mihir Bellare Phillip Rogaway 
Keyword: approximation, optimization, probabilistically checkable proofs, quadratic programming, nonlinear programming.  
Address: San Diego, 9500 Gilman Drive, La Jolla, CA 92093.  CA 95616, USA.  
Affiliation: Department of Computer Science Engineering, Mail Code 0114, University of California at  Department of Computer Science, University of California at Davis, Davis,  
Note: The  
Email: E-mail: mihir@cs.ucsd.edu  e-mail: rogaway@cs.davis.edu.  
Date: March 1992  
Abstract: Appears in Journal of Mathematical Programming B, Vol. 69, No. 3, pp. 429-441, September 1995. Also in Complexity of Numerical Optimization, Ed. P. M. Pardalos, World Scientific, 1993. Preliminary version appeared as IBM Research Report RC 17831, March 1992. Abstract We consider the problem of finding the maximum of a multivariate polynomial inside a convex polytope. We show that there is no polynomial time approximation algorithm for this problem, even one with a very poor guarantee, unless P = NP. We show that even when the polynomial is quadratic (i.e. quadratic programming) there is no polynomial time approximation unless NP is contained in quasi-polynomial time. Our results rely on recent advances in the theory of interactive proof systems. They exemplify an interesting interplay of discrete and continuous mathematics|using a combinatorial argument to get a hardness result for a continuous optimization problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arora and S. Safra, </author> <title> "Probabilistic checking of proofs; a new characterization of NP," </title> <booktitle> Proceedings of the Thirty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: In combinatorial optimization, many important problems defied such efforts for years. Recently, however, powerful techniques to indicate hardness of approximation have emerged; using interactive proofs, this exciting work has been able to settle the approximation complexity of a host of combinatorial optimization problems about which little was known before <ref> [16, 1, 2] </ref>. Typically, these results indicate hardness of approximation by showing that the existence of an approximation algorithm would imply an unbelievably efficient deterministic algorithm for NP. Here we apply these techniques to nonlinear optimization. <p> polynomial programming, and then turn to the special case of most interest: quadratic programming. 1.1 The Complexity of Polynomial Programming polynomial programming is the problem of finding the maximum of a multivariate polynomial f (x 1 ; : : : ; x n ) inside S = f x 2 <ref> [0; 1] </ref> n : Ax b g, a "feasible region" specified by a set of linear constraints. This problem is known to be solvable in polynomial space [11] but is not known to be in NP. <p> Denote by f fl and f fl the maximum and minimum of f inside S, respectively. Following [25, 3, 30, 29], we say an algorithm is a -approximation, for : N ! <ref> [0; 1] </ref>, if it computes ~ f satisfying j ~ f f fl j (n)[f fl f fl ]. (It was pointed out by Vavasis [30, 29] that it is important, in the context of continuous optimization, to use this definition, as opposed to ones, more frequently used in combinatorial optimization, <p> Quadratic Programming quadratic programming is the special case of polynomial programming in which the polynomial f is of total degree 2; that is, maximize f (x 1 ; : : : ; x n ) = P ij c ij x i x j inside S = f x 2 <ref> [0; 1] </ref> n : Ax b g. It is probably the most important of the nonlinear optimization problems, with applications including economics, planning and genetics. On the positive side, quadratic programming is known to be in NP [28]. The convex case admits a polynomial time solution [21]. <p> The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate. Subsequent constructions of proof systems of lower complexity has lead to better results on the hardness of approximation <ref> [16, 1, 2, 7, 17, 9] </ref>. To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of [16, 1, 2]. <p> To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of <ref> [16, 1, 2] </ref>. The reduction underlies a simple special case of a theorem of Ebenegger, Hammer and de Werra [13], who show that the maximal size of an independent set in a graph is the maximum of some multivariate polynomial associated to it. <p> Definition 2.1 Let (S; g) be an optimization problem, k k a map from strings to N, and a map from N to <ref> [0; 1] </ref>. <p> All numbers in problem instances are integers; this eliminate issues concerning computational complexity over the reals. Furthermore, the integers in problem instances are specified in unary; since our results are negative, this makes them stronger. In all the programming problems the feasible region is restricted to a subset of <ref> [0; 1] </ref> n and the utility functions are continuous, so all (non-degenerate) instances are bounded. independent set Instance: A graph G = (V; E). Solutions: W V is a solution if it is an independent set: for each u; v 2 W , fu; vg 62 E. <p> Together this encodes a polynomial f (x 1 ; : : : ; x n ) = P t h Q i . Also an m fi n integer matrix A and an integer m-vector b. Solutions: A vector x 2 <ref> [0; 1] </ref> n is a solution if Ax b. <p> Together, this encodes the polynomial f (x 1 ; : : : ; x n ) = P t h Q Q i Solutions: Any vector x 2 <ref> [0; 1] </ref> n is a solution. Utility of Solutions: A solution x has utility f (x). quadratic programming Instance: A number n and, for each i; j 2 f1; : : : ; ng with i j, an integer c ij . <p> Together this encodes the quadratic polynomial f (x) = P ij c ij x i x j . Also an m fi n integer matrix A and an integer m-vector b. Solutions: A vector x 2 <ref> [0; 1] </ref> n is a solution if Ax b. Utility of Solutions: A solution x has utility f (x). independent set was shown hard to approximate by [16, 1, 2]. Stating the last of these results in terms of our definition we get the result we will use. <p> Also an m fi n integer matrix A and an integer m-vector b. Solutions: A vector x 2 [0; 1] n is a solution if Ax b. Utility of Solutions: A solution x has utility f (x). independent set was shown hard to approximate by <ref> [16, 1, 2] </ref>. Stating the last of these results in terms of our definition we get the result we will use. Theorem 2.2 Assume P 6= NP. Then there is a constant ffi &gt; 0 such that independent set has no polynomial time, (1 n ffi )-approximation algorithm. <p> The accepting probability of the verifier V at w is the maximum of ACC V;(A;B) (w) over all possible pairs (A; B) of provers. We denote it by ACC V (w). If 7 L is a language and * a function of N to <ref> [0; 1] </ref>, we say that V has error probability * with respect to L if the following two conditions hold: first, w 2 L implies ACC V (w) = 1; second, w 62 L implies ACC V (w) &lt; *(jwj). <p> This is a degree = max u deg (u) polynomial in m = jEj variables. An algorithm which reduces independent set to polynomial programming-restricted case constructs from graph G the polynomial f described above, obtains an estimate of its maximum in <ref> [0; 1] </ref> m , and then returns this as its own estimate for the size of the maximal independent set in G.
Reference: [2] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy, </author> <title> "Proof verification and hardness of approximation problems," </title> <booktitle> Proceedings of the Thirty Third Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: In combinatorial optimization, many important problems defied such efforts for years. Recently, however, powerful techniques to indicate hardness of approximation have emerged; using interactive proofs, this exciting work has been able to settle the approximation complexity of a host of combinatorial optimization problems about which little was known before <ref> [16, 1, 2] </ref>. Typically, these results indicate hardness of approximation by showing that the existence of an approximation algorithm would imply an unbelievably efficient deterministic algorithm for NP. Here we apply these techniques to nonlinear optimization. <p> Then there is a constant 2 (0; 1) such that quadratic programming has no polynomial time, -approximation algorithm. The value of that can be achieved in the above depends on the "error probability" achievable by a two prover, one round proof for NP. Combining results of <ref> [2] </ref> and [15] with our proof, it is possible to show that can be taken to be any constant less than 1=3. 1.3 Background, Techniques and Related Work Our results rely on recent advances in the theory of interactive proof systems and the connection of these to approximation problems. <p> The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate. Subsequent constructions of proof systems of lower complexity has lead to better results on the hardness of approximation <ref> [16, 1, 2, 7, 17, 9] </ref>. To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of [16, 1, 2]. <p> To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of <ref> [16, 1, 2] </ref>. The reduction underlies a simple special case of a theorem of Ebenegger, Hammer and de Werra [13], who show that the maximal size of an independent set in a graph is the maximum of some multivariate polynomial associated to it. <p> Also an m fi n integer matrix A and an integer m-vector b. Solutions: A vector x 2 [0; 1] n is a solution if Ax b. Utility of Solutions: A solution x has utility f (x). independent set was shown hard to approximate by <ref> [16, 1, 2] </ref>. Stating the last of these results in terms of our definition we get the result we will use. Theorem 2.2 Assume P 6= NP. Then there is a constant ffi &gt; 0 such that independent set has no polynomial time, (1 n ffi )-approximation algorithm. <p> If constant error probability suffices, the complexity can be reduced to logarithmic. The following result is derived by applying a transformation of [19] to the main result of <ref> [2] </ref>. Theorem 2.5 There is a constant * &lt; 1 such that sat has a two prover, one round proof with complexity O (log n) and error probability *. The current best value for the constant c in the first theorem is c = 3 [14, 22]. <p> The current best value for the constant c in the first theorem is c = 3 [14, 22]. For the second it is possible to achieve any constant * &gt; 1=2 (cf. <ref> [2, 15] </ref>). 3 The Complexity of Polynomial Programming We prove Theorem 1.1. Let G = (V; E) be an instance of independent set. We will construct from G an instance f of polynomial programming-restricted case where f fl = G fl and kf k is polynomially bounded in kGk. <p> In particular, from the reduction of Motzkin and Strauss [24], in conjunction with the result of <ref> [2] </ref>, say, the best one may (directly) conclude is that there is a constant c &gt; 0 such that quadratic programming has no polynomial time, n c -approximation (as long P 6= NP).
Reference: [3] <author> G. Ausiello, A. D'Atri, and M. Protasi, </author> <title> "Structure preserving reductions among convex optimization problems," </title> <journal> Journal of Computer and System Sciences 21, </journal> <pages> 136-153, </pages> <year> 1980. </year>
Reference-contexts: This problem is known to be solvable in polynomial space [11] but is not known to be in NP. Denote by f fl and f fl the maximum and minimum of f inside S, respectively. Following <ref> [25, 3, 30, 29] </ref>, we say an algorithm is a -approximation, for : N ! [0; 1], if it computes ~ f satisfying j ~ f f fl j (n)[f fl f fl ]. (It was pointed out by Vavasis [30, 29] that it is important, in the context of continuous <p> A non-degenerate instance w is bounded if g fl (w) and g fl (w) are finite. Following <ref> [25, 3, 30, 29] </ref> we measure the quality of an approximation ~g by seeing how much it differs from g fl , as measured in units of jg fl g fl j. <p> We thank Stephen Vavasis for much helpful information on the subject of nonlinear optimization, and especially for explaining to us the importance of using the right definition of a -approximation. We thank Rajeev Motwani for drawing our attention to <ref> [3] </ref>. We thank an anonymous referee for comments. Work done while the first author was at the IBM T.J. Watson Research Center, New York, and the second author was at the LAN System Design group, IBM Personal Software Products, Austin.
Reference: [4] <author> L. Babai and S. Moran, </author> <title> "Arthur-Merlin games: A randomized proof system, and a hierarchy of complexity classes," </title> <journal> J. Computer and System Sciences 36, </journal> <pages> 254-276, </pages> <year> 1988. </year> <month> 11 </month>
Reference-contexts: We give a brief summary of relevant work in this area. Interactive proofs were introduced by Goldwasser, Micali and Rackoff [20] and Babai and Moran <ref> [4] </ref>. Ben-Or, Goldwasser, Kilian and Wigderson [10] extended these ideas to define a notion 4 of multi-prover interactive proofs.
Reference: [5] <author> L. Babai, L. Fortnow, and C. Lund, </author> <title> "Non-deterministic exponential time has two-prover interac-tive protocols," </title> <booktitle> Computational Complexity 1, </booktitle> <pages> 3-40, </pages> <year> 1991. </year>
Reference-contexts: Interactive proofs were introduced by Goldwasser, Micali and Rackoff [20] and Babai and Moran [4]. Ben-Or, Goldwasser, Kilian and Wigderson [10] extended these ideas to define a notion 4 of multi-prover interactive proofs. A fundamental result in this area is that of Babai, Fortnow and Lund <ref> [5] </ref> which equates the class MIP of languages possessing multi-prover interactive proofs of membership with the class NEXP of languages recognizable in non-deterministic exponential time. <p> Applications of interactive proofs to the derivation of hardness of approximation results emerged in the work of Condon [12] and Feige, Goldwasser, Lovasz, Safra and Szegedy [16]. The latter exploited the above mentioned result of <ref> [5] </ref> to show that the size of a maximum independent set in a graph is hard to approximate. Subsequent constructions of proof systems of lower complexity has lead to better results on the hardness of approximation [16, 1, 2, 7, 17, 9].
Reference: [6] <author> M. Bellare, </author> <title> "Interactive proofs and approximation: reductions from two provers in one round," </title> <booktitle> Proceedings of the Second Israel Symposium on Theory and Computing Systems, </booktitle> <year> 1993. </year> <note> Appeared earlier as IBM Research Report RC 17969, </note> <year> 1992. </year>
Reference-contexts: Meanwhile the original work of Feige [14] on which some of our results were based has also been incorporated into this same joint paper with Lovasz [18]. The present work and <ref> [18, 6] </ref> were the first to use two prover, one round proofs to show hardness of approximation results. Later these proofs systems were also used by [23]. quartic programming is the special case of polynomial programming in which the objective function is a polynomial of degree four.
Reference: [7] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Russell, </author> <title> "Efficient probabilistically checkable proofs and applications to approximation," </title> <booktitle> Proceedings of the Twenty Fifth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1993. </year>
Reference-contexts: The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate. Subsequent constructions of proof systems of lower complexity has lead to better results on the hardness of approximation <ref> [16, 1, 2, 7, 17, 9] </ref>. To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of [16, 1, 2]. <p> Since quadratic programming is a special case of quartic programming, the results of Theorems 1.2 and 1.3 apply. However, in this case a stronger result than Theorem 1.3 was obtained in <ref> [7] </ref>: assuming P 6= NP the authors show that for any constant 2 (0; 1), quartic programming has no polynomial time, -approximation algorithm. The same was shown by Tardos [27] to hold for cubic programming.
Reference: [8] <author> M. Bellare and P. Rogaway, </author> <title> "The complexity of approximating a nonlinear program," </title> <note> IBM Research Report RC 17831, 1992. Also appears in Complexity of Numerical Optimization, </note> <editor> Ed. P.M. Parda-los, </editor> <publisher> World Scientific, </publisher> <year> 1993. </year>
Reference-contexts: The same was shown by Tardos [27] to hold for cubic programming. Today we know that the result is true for quadratic programming itself (Feige and Kilian [17]). A preliminary version of this paper appeared as <ref> [8] </ref>. 2 Preliminaries The notation j j will be used to denote the absolute value of a number, the length of a string, or the size of a set; the context will disambiguate. An optimization problem is specified by a pair (S; g).
Reference: [9] <author> M. Bellare and M. Sudan, </author> <title> "Improved non-approximability results," </title> <booktitle> Proceedings of the Twenty Sixth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: To provide the best possible one it is convenient to make a slightly stronger assumption, namely that NP is different from coRP. Under this assumption, results of <ref> [9] </ref> combined with our proof imply that for ffi &lt; 1=8, polynomial programming has no polynomial time, (1 n ffi )-approximation algorithm. Problem instances in our results include only integers for their numbers, and the results hold even when these integers are encoded in unary. <p> The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate. Subsequent constructions of proof systems of lower complexity has lead to better results on the hardness of approximation <ref> [16, 1, 2, 7, 17, 9] </ref>. To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of [16, 1, 2]. <p> Theorem 2.2 Assume P 6= NP. Then there is a constant ffi &gt; 0 such that independent set has no polynomial time, (1 n ffi )-approximation algorithm. Under stronger assumptions one can specify quite good values for ffi. Specifically, the following is implied by <ref> [9] </ref>: if NP 6= coRP and ffi &lt; 1=4 then there is no polynomial time, (1n ffi )-approximation algorithm for independent set. A two-prover, one-round interactive proof system involves a probabilistic, polynomial time verifier, V , and a pair of (computationally unbounded, deterministic) provers, A and B.
Reference: [10] <author> M. Ben-Or, S. Goldwasser, J. Kilian, and A. Wigderson, </author> <title> "Multi-prover interactive proofs: how to remove intractability assumptions," </title> <booktitle> Proceedings of the Twentieth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1988. </year>
Reference-contexts: We give a brief summary of relevant work in this area. Interactive proofs were introduced by Goldwasser, Micali and Rackoff [20] and Babai and Moran [4]. Ben-Or, Goldwasser, Kilian and Wigderson <ref> [10] </ref> extended these ideas to define a notion 4 of multi-prover interactive proofs.
Reference: [11] <author> J. Canny, </author> <title> "Some algebraic and geometric computations in PSPACE," </title> <booktitle> Proceedings of the Twentieth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1988. </year>
Reference-contexts: This problem is known to be solvable in polynomial space <ref> [11] </ref> but is not known to be in NP. Denote by f fl and f fl the maximum and minimum of f inside S, respectively.
Reference: [12] <author> A. Condon, </author> <title> "The complexity of the max word problem and the power of one-way interactive proof systems," </title> <booktitle> Proceedings of the Eighth Annual Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science Vol. </booktitle> <volume> 480, </volume> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Applications of interactive proofs to the derivation of hardness of approximation results emerged in the work of Condon <ref> [12] </ref> and Feige, Goldwasser, Lovasz, Safra and Szegedy [16]. The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate.
Reference: [13] <author> C. Ebenegger, P. Hammer, and D. de Werra, </author> <title> "Pseudo-boolean functions and stability of graphs," in Algebraic and Combinatorial Methods in Operations Research, </title> <journal> Annals of Discrete Mathematics, </journal> <volume> vol. 19, </volume> <pages> 83-97, </pages> <year> 1984. </year>
Reference-contexts: The reduction underlies a simple special case of a theorem of Ebenegger, Hammer and de Werra <ref> [13] </ref>, who show that the maximal size of an independent set in a graph is the maximum of some multivariate polynomial associated to it. Two prover, one round proofs are multi-prover proofs in which there are only two provers and the interaction is restricted to one round. <p> Acknowledgments We are grateful to Peter Hammer, who, during a visit to Dartmouth College, described the work in <ref> [13] </ref> which inspired our initial results. We thank Stephen Vavasis for much helpful information on the subject of nonlinear optimization, and especially for explaining to us the importance of using the right definition of a -approximation. We thank Rajeev Motwani for drawing our attention to [3].
Reference: [14] <author> U. Feige, </author> <title> "NEXPTIME has two-provers one-round proof systems with exponentially small error probability," </title> <type> Manuscript, </type> <year> 1991. </year>
Reference-contexts: Two prover, one round proofs are multi-prover proofs in which there are only two provers and the interaction is restricted to one round. Using techniques of Lapidot and Shamir [22], it was shown by Feige <ref> [14] </ref> that two provers and one round of interaction suffice to recognize any L 2 NEXP with exponentially small error probability. This result, "scaled down" to NP (cf. Theorem 2.4) is the basis for our proof of Theorem 1.2. A different result about two prover, one round proofs (cf. <p> Theorem 2.5) is the basis of the proof of Theorem 1.3. The particular association of a quadratic program to a two-prover, one-round interactive proof that we use was independently discovered by Feige and Lovasz [18]. Meanwhile the original work of Feige <ref> [14] </ref> on which some of our results were based has also been incorporated into this same joint paper with Lovasz [18]. The present work and [18, 6] were the first to use two prover, one round proofs to show hardness of approximation results. <p> Important to our results is the fact that NP-complete languages have two prover one round proofs of very low complexity. As usual, sat denotes the decision problem for satisfiability of Boolean formulas. Theorem 2.4 <ref> [14, 22] </ref> There is a constant c &gt; 0 such that sat has a two prover, one round proof with complexity O (log c n) and error probability 1=n. If constant error probability suffices, the complexity can be reduced to logarithmic. <p> Theorem 2.5 There is a constant * &lt; 1 such that sat has a two prover, one round proof with complexity O (log n) and error probability *. The current best value for the constant c in the first theorem is c = 3 <ref> [14, 22] </ref>. For the second it is possible to achieve any constant * &gt; 1=2 (cf. [2, 15]). 3 The Complexity of Polynomial Programming We prove Theorem 1.1. Let G = (V; E) be an instance of independent set.
Reference: [15] <author> U. Feige, </author> <title> "On the success probability of the two provers in one round proof systems," </title> <booktitle> Proceedings of the Sixth Annual Conference on Structure in Complexity Theory, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: Then there is a constant 2 (0; 1) such that quadratic programming has no polynomial time, -approximation algorithm. The value of that can be achieved in the above depends on the "error probability" achievable by a two prover, one round proof for NP. Combining results of [2] and <ref> [15] </ref> with our proof, it is possible to show that can be taken to be any constant less than 1=3. 1.3 Background, Techniques and Related Work Our results rely on recent advances in the theory of interactive proof systems and the connection of these to approximation problems. <p> The current best value for the constant c in the first theorem is c = 3 [14, 22]. For the second it is possible to achieve any constant * &gt; 1=2 (cf. <ref> [2, 15] </ref>). 3 The Complexity of Polynomial Programming We prove Theorem 1.1. Let G = (V; E) be an instance of independent set. We will construct from G an instance f of polynomial programming-restricted case where f fl = G fl and kf k is polynomially bounded in kGk.
Reference: [16] <author> U. Feige, S. Goldwasser, L. Lov asz, S. Safra, and M. Szegedy, </author> <title> "Approximating clique is almost NP-complete," </title> <booktitle> Proceedings of the Thirty Second Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: In combinatorial optimization, many important problems defied such efforts for years. Recently, however, powerful techniques to indicate hardness of approximation have emerged; using interactive proofs, this exciting work has been able to settle the approximation complexity of a host of combinatorial optimization problems about which little was known before <ref> [16, 1, 2] </ref>. Typically, these results indicate hardness of approximation by showing that the existence of an approximation algorithm would imply an unbelievably efficient deterministic algorithm for NP. Here we apply these techniques to nonlinear optimization. <p> Applications of interactive proofs to the derivation of hardness of approximation results emerged in the work of Condon [12] and Feige, Goldwasser, Lovasz, Safra and Szegedy <ref> [16] </ref>. The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate. <p> The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate. Subsequent constructions of proof systems of lower complexity has lead to better results on the hardness of approximation <ref> [16, 1, 2, 7, 17, 9] </ref>. To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of [16, 1, 2]. <p> To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of <ref> [16, 1, 2] </ref>. The reduction underlies a simple special case of a theorem of Ebenegger, Hammer and de Werra [13], who show that the maximal size of an independent set in a graph is the maximum of some multivariate polynomial associated to it. <p> Also an m fi n integer matrix A and an integer m-vector b. Solutions: A vector x 2 [0; 1] n is a solution if Ax b. Utility of Solutions: A solution x has utility f (x). independent set was shown hard to approximate by <ref> [16, 1, 2] </ref>. Stating the last of these results in terms of our definition we get the result we will use. Theorem 2.2 Assume P 6= NP. Then there is a constant ffi &gt; 0 such that independent set has no polynomial time, (1 n ffi )-approximation algorithm.
Reference: [17] <author> U. Feige and J. Kilian, </author> <title> "Two prover protocols Low error at affordable rates," </title> <booktitle> Proceedings of the Twenty Sixth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: The latter exploited the above mentioned result of [5] to show that the size of a maximum independent set in a graph is hard to approximate. Subsequent constructions of proof systems of lower complexity has lead to better results on the hardness of approximation <ref> [16, 1, 2, 7, 17, 9] </ref>. To prove Theorem 1.1 we reduce the problem of computing the size of a maximal independent set in a graph to polynomial programming in an approximation-preserving way and then apply the maximum independent set approximation hardness results of [16, 1, 2]. <p> The same was shown by Tardos [27] to hold for cubic programming. Today we know that the result is true for quadratic programming itself (Feige and Kilian <ref> [17] </ref>). A preliminary version of this paper appeared as [8]. 2 Preliminaries The notation j j will be used to denote the absolute value of a number, the length of a string, or the size of a set; the context will disambiguate.
Reference: [18] <author> U. Feige, and L. Lov asz, </author> <title> "Two-prover one round proof systems: their power and their problems," </title> <booktitle> Proceedings of the Twenty Fourth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1992. </year>
Reference-contexts: A different result about two prover, one round proofs (cf. Theorem 2.5) is the basis of the proof of Theorem 1.3. The particular association of a quadratic program to a two-prover, one-round interactive proof that we use was independently discovered by Feige and Lovasz <ref> [18] </ref>. Meanwhile the original work of Feige [14] on which some of our results were based has also been incorporated into this same joint paper with Lovasz [18]. The present work and [18, 6] were the first to use two prover, one round proofs to show hardness of approximation results. <p> The particular association of a quadratic program to a two-prover, one-round interactive proof that we use was independently discovered by Feige and Lovasz <ref> [18] </ref>. Meanwhile the original work of Feige [14] on which some of our results were based has also been incorporated into this same joint paper with Lovasz [18]. The present work and [18, 6] were the first to use two prover, one round proofs to show hardness of approximation results. <p> Meanwhile the original work of Feige [14] on which some of our results were based has also been incorporated into this same joint paper with Lovasz [18]. The present work and <ref> [18, 6] </ref> were the first to use two prover, one round proofs to show hardness of approximation results. Later these proofs systems were also used by [23]. quartic programming is the special case of polynomial programming in which the objective function is a polynomial of degree four.
Reference: [19] <author> L. Fortnow, J. Rompel, and M. Sipser, </author> <title> "On the power of multiprover interactive protocols," </title> <booktitle> Proceedings of the Third Annual Conference on Structure in Complexity Theory, IEEE, </booktitle> <year> 1988. </year>
Reference-contexts: If constant error probability suffices, the complexity can be reduced to logarithmic. The following result is derived by applying a transformation of <ref> [19] </ref> to the main result of [2]. Theorem 2.5 There is a constant * &lt; 1 such that sat has a two prover, one round proof with complexity O (log n) and error probability *.
Reference: [20] <author> S. Goldwasser, S. Micali, and C. Rackoff, </author> <title> "The knowledge complexity of interactive proofs," </title> <journal> SIAM J. Computing 18(1), </journal> <pages> 186-208, </pages> <year> 1989. </year>
Reference-contexts: We give a brief summary of relevant work in this area. Interactive proofs were introduced by Goldwasser, Micali and Rackoff <ref> [20] </ref> and Babai and Moran [4]. Ben-Or, Goldwasser, Kilian and Wigderson [10] extended these ideas to define a notion 4 of multi-prover interactive proofs.
Reference: [21] <author> M. Kozlov, S. Tarasov, and L. Ha cijan, </author> <title> "Polynomial solvability of convex quadratic programming," </title> <journal> Dokl. Akad. Nauk SSSR 248, </journal> <pages> 1049-1051, </pages> <year> 1979. </year> <journal> Translated in Soviet Math Dokl. </journal> <volume> 20, </volume> <pages> 1108-1111. </pages>
Reference-contexts: It is probably the most important of the nonlinear optimization problems, with applications including economics, planning and genetics. On the positive side, quadratic programming is known to be in NP [28]. The convex case admits a polynomial time solution <ref> [21] </ref>. The concave and indefinite cases admit -approximation algorithms which, for any constant 2 (0; 1), are polynomial time under certain conditions on the objective function [29, 30]. The general case admits a weak polynomial time approximation algorithm; specifically, one which achieves a (1 fi (n 2 ))-approximation [31].
Reference: [22] <author> D. Lapidot and A. Shamir, </author> <title> "Fully parallelized multi-prover protocols for NEXP-time," </title> <booktitle> Proceedings of the Thirty Second Annual Symposium on the Foundations of Computer Science, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: Two prover, one round proofs are multi-prover proofs in which there are only two provers and the interaction is restricted to one round. Using techniques of Lapidot and Shamir <ref> [22] </ref>, it was shown by Feige [14] that two provers and one round of interaction suffice to recognize any L 2 NEXP with exponentially small error probability. This result, "scaled down" to NP (cf. Theorem 2.4) is the basis for our proof of Theorem 1.2. <p> Important to our results is the fact that NP-complete languages have two prover one round proofs of very low complexity. As usual, sat denotes the decision problem for satisfiability of Boolean formulas. Theorem 2.4 <ref> [14, 22] </ref> There is a constant c &gt; 0 such that sat has a two prover, one round proof with complexity O (log c n) and error probability 1=n. If constant error probability suffices, the complexity can be reduced to logarithmic. <p> Theorem 2.5 There is a constant * &lt; 1 such that sat has a two prover, one round proof with complexity O (log n) and error probability *. The current best value for the constant c in the first theorem is c = 3 <ref> [14, 22] </ref>. For the second it is possible to achieve any constant * &gt; 1=2 (cf. [2, 15]). 3 The Complexity of Polynomial Programming We prove Theorem 1.1. Let G = (V; E) be an instance of independent set.
Reference: [23] <author> C. Lund and M. Yannakakis, </author> <title> "On the hardness of approximating minimization problems," </title> <booktitle> Proceedings of the Twenty Fifth Annual Symposium on the Theory of Computing, ACM, </booktitle> <year> 1993. </year> <month> 12 </month>
Reference-contexts: The present work and [18, 6] were the first to use two prover, one round proofs to show hardness of approximation results. Later these proofs systems were also used by <ref> [23] </ref>. quartic programming is the special case of polynomial programming in which the objective function is a polynomial of degree four. Since quadratic programming is a special case of quartic programming, the results of Theorems 1.2 and 1.3 apply.
Reference: [24] <author> T. Motzkin, and E. Straus, </author> <title> "Maxima for graphs and a new proof of a theorem by Tuan," </title> <journal> Notices of the American Mathematical Society 11, </journal> <pages> 533-540, </pages> <year> 1964. </year>
Reference-contexts: In particular, from the reduction of Motzkin and Strauss <ref> [24] </ref>, in conjunction with the result of [2], say, the best one may (directly) conclude is that there is a constant c &gt; 0 such that quadratic programming has no polynomial time, n c -approximation (as long P 6= NP). Intuitively, the problem is with the particular functional relationship that [24] <p> <ref> [24] </ref>, in conjunction with the result of [2], say, the best one may (directly) conclude is that there is a constant c &gt; 0 such that quadratic programming has no polynomial time, n c -approximation (as long P 6= NP). Intuitively, the problem is with the particular functional relationship that [24] establish between the size of a maximum size independent set in a graph and the maximum of its associated program: for this function, even a big change in maximum independent set size translates into a small change in the maximum of the associated program.
Reference: [25] <author> A. Nemirovsky, and D. Yudin, Slozhnost' Zadach i Effektivnost' Metodov Optimizatsii, </author> <year> 1979. </year> <title> Translated by E. Dawson as Problem Complexity and Method Efficiency in Optimization, </title> <publisher> John Wiley and Sons, </publisher> <year> 1983. </year>
Reference-contexts: This problem is known to be solvable in polynomial space [11] but is not known to be in NP. Denote by f fl and f fl the maximum and minimum of f inside S, respectively. Following <ref> [25, 3, 30, 29] </ref>, we say an algorithm is a -approximation, for : N ! [0; 1], if it computes ~ f satisfying j ~ f f fl j (n)[f fl f fl ]. (It was pointed out by Vavasis [30, 29] that it is important, in the context of continuous <p> A non-degenerate instance w is bounded if g fl (w) and g fl (w) are finite. Following <ref> [25, 3, 30, 29] </ref> we measure the quality of an approximation ~g by seeing how much it differs from g fl , as measured in units of jg fl g fl j.
Reference: [26] <author> S. Sahni, </author> <title> "Computationally related problems," </title> <journal> SIAM J. of Computing 3, </journal> <volume> No. 4, </volume> <pages> 262-279, </pages> <year> 1974. </year>
Reference-contexts: The general case admits a weak polynomial time approximation algorithm; specifically, one which achieves a (1 fi (n 2 ))-approximation [31]. On the negative side, quadratic programming is NP-hard <ref> [26] </ref>. In fact, the existence of a polynomial time :75n 1 -approximation algorithm for this problem already implies P = NP [30]. In other words, finding an excellent approximation algorithm is unlikely. We improve this result to show that even finding a terrible approximation algorithm is unlikely.
Reference: [27] <author> G. Tardos, </author> <title> "Mutli-prover encoding schemes and three prover proof systems," </title> <booktitle> Proceedings of the Ninth Annual Conference on Structure in Complexity Theory, IEEE, </booktitle> <year> 1994. </year>
Reference-contexts: However, in this case a stronger result than Theorem 1.3 was obtained in [7]: assuming P 6= NP the authors show that for any constant 2 (0; 1), quartic programming has no polynomial time, -approximation algorithm. The same was shown by Tardos <ref> [27] </ref> to hold for cubic programming. Today we know that the result is true for quadratic programming itself (Feige and Kilian [17]).
Reference: [28] <author> S. Vavasis, </author> <title> "Quadratic programming is in NP," </title> <journal> Info. Proc. Letters 36, </journal> <pages> 73-77, </pages> <year> 1990. </year>
Reference-contexts: It is probably the most important of the nonlinear optimization problems, with applications including economics, planning and genetics. On the positive side, quadratic programming is known to be in NP <ref> [28] </ref>. The convex case admits a polynomial time solution [21]. The concave and indefinite cases admit -approximation algorithms which, for any constant 2 (0; 1), are polynomial time under certain conditions on the objective function [29, 30].
Reference: [29] <author> S. Vavasis, </author> <title> "Approximation algorithms for indefinite quadratic programming," </title> <type> TR 91-1228, </type> <institution> Dept. of Computer Science, Cornell University, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: This problem is known to be solvable in polynomial space [11] but is not known to be in NP. Denote by f fl and f fl the maximum and minimum of f inside S, respectively. Following <ref> [25, 3, 30, 29] </ref>, we say an algorithm is a -approximation, for : N ! [0; 1], if it computes ~ f satisfying j ~ f f fl j (n)[f fl f fl ]. (It was pointed out by Vavasis [30, 29] that it is important, in the context of continuous <p> Following [25, 3, 30, 29], we say an algorithm is a -approximation, for : N ! [0; 1], if it computes ~ f satisfying j ~ f f fl j (n)[f fl f fl ]. (It was pointed out by Vavasis <ref> [30, 29] </ref> that it is important, in the context of continuous optimization, to use this definition, as opposed to ones, more frequently used in combinatorial optimization, which measure the quality of an approximation compared only to f fl . <p> The reasons for this are outside the scope of this paper, but Section 2 contains a brief discussion and the reader is referred to <ref> [30, 29] </ref> for more information.) Notice that a 0-approximation is optimal, while the value of f at any feasible point is a 1-approximation. A 1-approximation is therefore easy to find. <p> On the positive side, quadratic programming is known to be in NP [28]. The convex case admits a polynomial time solution [21]. The concave and indefinite cases admit -approximation algorithms which, for any constant 2 (0; 1), are polynomial time under certain conditions on the objective function <ref> [29, 30] </ref>. The general case admits a weak polynomial time approximation algorithm; specifically, one which achieves a (1 fi (n 2 ))-approximation [31]. On the negative side, quadratic programming is NP-hard [26]. <p> A non-degenerate instance w is bounded if g fl (w) and g fl (w) are finite. Following <ref> [25, 3, 30, 29] </ref> we measure the quality of an approximation ~g by seeing how much it differs from g fl , as measured in units of jg fl g fl j. <p> Another such attribute is the invariance under affine linear transformations of the feasible region and the objective function. For more information on the definition we refer the reader to <ref> [30, 29] </ref>. It is not required that an approximation algorithm "find" the point with the specified utility; it is not even required that there exist a point ~y 2 S (w) such that ~g = g (w; ~y). This is therefore a weak notion of approximation.
Reference: [30] <author> S. Vavasis, </author> <title> "On approximation algorithms for concave programming," Recent Advances in Global Optimization, </title> <editor> C. A. Floudas and P.M. </editor> <booktitle> Pardalos, </booktitle> <pages> pp. 3-18, </pages> <publisher> Princeton University Press, </publisher> <year> 1992. </year>
Reference-contexts: This problem is known to be solvable in polynomial space [11] but is not known to be in NP. Denote by f fl and f fl the maximum and minimum of f inside S, respectively. Following <ref> [25, 3, 30, 29] </ref>, we say an algorithm is a -approximation, for : N ! [0; 1], if it computes ~ f satisfying j ~ f f fl j (n)[f fl f fl ]. (It was pointed out by Vavasis [30, 29] that it is important, in the context of continuous <p> Following [25, 3, 30, 29], we say an algorithm is a -approximation, for : N ! [0; 1], if it computes ~ f satisfying j ~ f f fl j (n)[f fl f fl ]. (It was pointed out by Vavasis <ref> [30, 29] </ref> that it is important, in the context of continuous optimization, to use this definition, as opposed to ones, more frequently used in combinatorial optimization, which measure the quality of an approximation compared only to f fl . <p> The reasons for this are outside the scope of this paper, but Section 2 contains a brief discussion and the reader is referred to <ref> [30, 29] </ref> for more information.) Notice that a 0-approximation is optimal, while the value of f at any feasible point is a 1-approximation. A 1-approximation is therefore easy to find. <p> On the positive side, quadratic programming is known to be in NP [28]. The convex case admits a polynomial time solution [21]. The concave and indefinite cases admit -approximation algorithms which, for any constant 2 (0; 1), are polynomial time under certain conditions on the objective function <ref> [29, 30] </ref>. The general case admits a weak polynomial time approximation algorithm; specifically, one which achieves a (1 fi (n 2 ))-approximation [31]. On the negative side, quadratic programming is NP-hard [26]. <p> On the negative side, quadratic programming is NP-hard [26]. In fact, the existence of a polynomial time :75n 1 -approximation algorithm for this problem already implies P = NP <ref> [30] </ref>. In other words, finding an excellent approximation algorithm is unlikely. We improve this result to show that even finding a terrible approximation algorithm is unlikely. To state the result we first need some definitions. <p> A non-degenerate instance w is bounded if g fl (w) and g fl (w) are finite. Following <ref> [25, 3, 30, 29] </ref> we measure the quality of an approximation ~g by seeing how much it differs from g fl , as measured in units of jg fl g fl j. <p> Another such attribute is the invariance under affine linear transformations of the feasible region and the objective function. For more information on the definition we refer the reader to <ref> [30, 29] </ref>. It is not required that an approximation algorithm "find" the point with the specified utility; it is not even required that there exist a point ~y 2 S (w) such that ~g = g (w; ~y). This is therefore a weak notion of approximation.
Reference: [31] <author> S. Vavasis, </author> <title> "Polynomial time weak approximation algorithms for quadratic programming," in Complexity in Numerical Optimization, </title> <editor> Panos Pardalos (editor), </editor> <year> 1992. </year> <month> 13 </month>
Reference-contexts: The concave and indefinite cases admit -approximation algorithms which, for any constant 2 (0; 1), are polynomial time under certain conditions on the objective function [29, 30]. The general case admits a weak polynomial time approximation algorithm; specifically, one which achieves a (1 fi (n 2 ))-approximation <ref> [31] </ref>. On the negative side, quadratic programming is NP-hard [26]. In fact, the existence of a polynomial time :75n 1 -approximation algorithm for this problem already implies P = NP [30]. In other words, finding an excellent approximation algorithm is unlikely.
References-found: 31

