URL: http://www.cs.ucc.ie/~dgb/papers/UK3.ps.Z
Refering-URL: http://www.cs.ucc.ie/~dgb/publist.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: tony@minster.york.ac.uk  Email: d.bridge@cs.ucc.ie  
Title: Towards a Theory of Optimal Similarity Measures way of learning a similarity measure from the
Author: A D Griffiths D G Bridge 
Note: `best'  
Address: York, York YO1 5DD, UK  Republic of Ireland  
Affiliation: Department of Computer Science, University of  Department of Computation, University College, Cork,  
Abstract: The effectiveness of a case-based reasoning system is known to depend critically on its similarity measure. However, it is not clear whether there are elusive and esoteric similarity measures which might improve the performance of a case-based reasoner if substituted for the more commonly used measures. This paper therefore deals with the problem of choosing the best similarity measure, in the limited context of instance-based learning of classifications of a discrete example space. We consider both `fixed' similarity measures and `learnt' ones. In the former case, we give a definition of a similarity measure which we believe to be `optimal' w.r.t. the current prior distribution of target concepts and prove its optimality within a restricted class of similarity measures. We then show how this `optimal' similarity measure is instantiated by some specific prior distributions, and conclude that a very simple similarity measure is as good as any other in these cases. In a further section, we then show how our definition leads naturally to a conjecture about the 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D W Aha. </author> <title> Tolerating noisy, irrelevant and novel attributes in instance-based learning algorithms. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 36 </volume> <pages> 267-287, </pages> <year> 1992. </year>
Reference-contexts: Normally, a case-base is compatible with some target concept t * B N s.t. for each exemplar (d; n) * CB, t (d) = n. The similarity measure is a total function in D N fi D N ! <ref> [0; 1] </ref> which returns a real value indicating the degree of similarity between its two arguments. <p> Many IBL algorithms use a weighted similarity measure which counts the `overlap' between two descriptions but assigns weights to each of the variables of the representation to indicate their importance or `relevance'. The simplest form of these measures may be defined by a `weight vector' w * <ref> [0; 1] </ref> N : w (d 1 ; d 2 ) = P N N X w i fi (1 j (d 1 ) i (d 2 ) i j) (3) If the weight vector w has weight 1 in all elements then w treats all dimensions of the representation equally <p> Well-ordered Similarity Measure. A similarity measure * (D N fi D N ) ! <ref> [0; 1] </ref> is well-ordered w.r.t. the prior distribution iff, given three descriptions d; d 0 ; d 00 * D N , the similarity of d to d 0 is as great as the similarity of d to d 00 only if the prior probability of a target concept assigning the <p> if :9d * D N (d; 1) * CB then set CB = CB [ f (d i ; 1)g for j = 1 to N do else set CB = CB [ f (d i ; 0)g forall 1 i N if f [i; 0] = 1 _ f <ref> [i; 1] </ref> = 1 then set w i = 1 else set w i = 0 RETURN V S-CBR (s) = h hCB; w i Fig. 3. <p> D N (d; 1) * CB then set CB = CB [ f (d i ; 1)g for j = 1 to N do else set CB = CB [ f (d i ; 0)g forall 1 i N if f [i; 0] = 1 then set U = U <ref> [ fu i g if f [i; 1] </ref> = 1 then set U = U [ fu i g RETURN V S-CBR3 (s) = h hCB; U i Fig. 5. <p> then set CB = CB [ f (d i ; 1)g for j = 1 to N do else set CB = CB [ f (d i ; 0)g forall 1 i N if f [i; 0] = 1 then set U = U [ fu i g if f <ref> [i; 1] </ref> = 1 then set U = U [ fu i g RETURN V S-CBR3 (s) = h hCB; U i Fig. 5. <p> It would be interesting to instantiate equation (9) with a prior distribution corresponding to the bias toward `naturally occurring classification problems' assumed in general purpose learners such as IB4 <ref> [1] </ref> or PEBLS [3], and to compare the learner derived that way with existing instance-based learners. 2.
Reference: 2. <author> M Anthony and N Biggs. </author> <title> Computational Learning Theory. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: CB1 ( H ) is also certainly less efficient for learning monomial target concepts than the `standard' (non case-based) learning algorithm for monomials [18] <ref> [2] </ref>, and [8] shows that CB1 ( H ) is easily out-performed on monomial target concepts by an instance-based learner which changes the weights assigned to a weighted similarity measure (Figure 4, below). The performance of CB1 ( H ) is therefore relatively poor. <p> A better approach might be if the information in f is used directly. In [11], we noted that the information held in the f array directly corresponds to the monomial hypothesis chosen by the standard algorithm for monomials [18] <ref> [2] </ref> (which we call `M ').
Reference: 3. <author> S Cost and S Salzberg. </author> <title> A weighted nearest neighbour algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10(1) </volume> <pages> 37-66, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: It would be interesting to instantiate equation (9) with a prior distribution corresponding to the bias toward `naturally occurring classification problems' assumed in general purpose learners such as IB4 [1] or PEBLS <ref> [3] </ref>, and to compare the learner derived that way with existing instance-based learners. 2.
Reference: 4. <author> B Faltings. </author> <title> Probabilistic indexing for case-based prediction. </title> <editor> In E Plaza and D Leake, editors, </editor> <booktitle> Case-Based Reasoning Research and Development. Proceedings of the Second International Conference on Case-Based Reasoning, </booktitle> <address> ICCBR-97. Providence, RI, </address> <month> July </month> <year> 1997., </year> <booktitle> Lecture Notes in Artificial Intelligence vol. </booktitle> <volume> 1266, </volume> <pages> pages 611-622. </pages> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: the probability of equal classification of d and d 00 : (d; d 0 ) (d; d 00 ) ! ft * B N jt (d) = t (d 0 )g ft * B N jt (d) = t (d 00 )g 2 Very similar comments precede Faltings' recent formalisation <ref> [4] </ref>.
Reference: 5. <author> C Globig, </author> <title> K P Jantke, S Lange, and Y Sakakibara. On case-based learnability of languages. </title> <journal> New Generation Computing, </journal> <volume> 15(1), </volume> <year> 1997. </year>
Reference-contexts: On the other hand, several theoretical studies [12] <ref> [5] </ref> show that the power of instance-based learning is extended if the learner is allowed to change its definition of similarity.
Reference: 6. <author> C Globig and S Lange. </author> <title> Case-based representability of classes of boolean functions. </title> <booktitle> In ECAI-96: Proceedings of Twelfth European Conference on Artificial Intelligence, </booktitle> <pages> pages 117-121, </pages> <year> 1996. </year>
Reference-contexts: Their experiments show that a similarity measure may maximise the accuracy of a learner in one experiment but be surpassed by a different similarity measure in another experiment. Similarly, in <ref> [6] </ref>, Globig and Lange show that the choice of similarity measure critically affects the number of examples needed to represent a particular function, but that there is no `universal' similarity measure which will efficiently represent any target function.
Reference: 7. <author> C Globig and S Wess. </author> <title> Symbolic learning and nearest-neighbour classification. </title> <editor> In H-H Bock, W Lenski, and M M Richter, editors, </editor> <booktitle> Information Systems and Data Analysis: Prospects, Foundations, Applications. Proceedings of the 17th Annual Conference of the Gesellschaft fur Klassification e.V. </booktitle> <institution> University of Kaiserslautern, </institution> <address> March 3-5, 1993. </address> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Experiments by Globig and Wess show empirically that the effectiveness of an instance-based learning (IBL) algorithm depends on the similarity measure used <ref> [7] </ref>. Their experiments show that a similarity measure may maximise the accuracy of a learner in one experiment but be surpassed by a different similarity measure in another experiment.
Reference: 8. <author> A D Griffiths. </author> <title> Inductive Generalisation in Case-Based Reasoning Systems. </title> <type> PhD thesis, </type> <note> Published as Technical Report YCST-97-02, </note> <institution> Department of Computer Science, University of York, </institution> <address> York YO1 5DD, UK, </address> <year> 1997. </year>
Reference-contexts: This paper describes work in progress and so x5 concludes with several comments about how the work can be progressed further. This work is an overview of results presented in <ref> [8] </ref>; full details of all the claims and notation may be found there. 2 Definitions The paper is concerned with the problem of classifying instances drawn from a finite, discrete example space. <p> In our work this term is reserved for a different kind of entity [9] <ref> [8] </ref>. pair of elements hx i ; n i i in x t we have t (x i ) = n i . <p> Note that Figure 1 actually defines a family of learners since the definition is parameterised by the similarity measure . for i = 1 to m do RETURN CB1 ()(s) = h hCB;i Fig. 1. CB1 () Learning Algorithm <ref> [8, Defn 5.3.1] </ref>. s = h (d i ; n i )i m i=1 is a training sample from (D N fi f0; 1g) m . In [8] we took the similarity measure H and measured the accuracy of CB1 ( H ) on monomial target concepts. <p> CB1 () Learning Algorithm [8, Defn 5.3.1]. s = h (d i ; n i )i m i=1 is a training sample from (D N fi f0; 1g) m . In <ref> [8] </ref> we took the similarity measure H and measured the accuracy of CB1 ( H ) on monomial target concepts. <p> The results of some of these experiments, measuring the accuracy of CB1 ( H ) on target concepts in the spaces M 6;1 , M 6;2 and M 6;3 , are shown in Figure 2. Methodology for the experiments is described in <ref> [8] </ref>. The figure shows how concepts from M 6;1 are learnt more slowly than concepts from M 6;2 , which are learnt more slowly than concepts from M 6;3 . <p> Methodology for the experiments is described in [8]. The figure shows how concepts from M 6;1 are learnt more slowly than concepts from M 6;2 , which are learnt more slowly than concepts from M 6;3 . Fig. 2. <ref> [8, Fig 5.3] </ref> Average Learning Curve for Monomial Concepts t * M 6;k (CB1 ( H )) In addition, we observed that CB1 ( H ) was not noticeably more efficient than an extremely simple `rote-learning' algorithm L 2 [10] [8]. <p> Fig. 2. [8, Fig 5.3] Average Learning Curve for Monomial Concepts t * M 6;k (CB1 ( H )) In addition, we observed that CB1 ( H ) was not noticeably more efficient than an extremely simple `rote-learning' algorithm L 2 [10] <ref> [8] </ref>. CB1 ( H ) is also certainly less efficient for learning monomial target concepts than the `standard' (non case-based) learning algorithm for monomials [18] [2], and [8] shows that CB1 ( H ) is easily out-performed on monomial target concepts by an instance-based learner which changes the weights assigned to <p> In addition, we observed that CB1 ( H ) was not noticeably more efficient than an extremely simple `rote-learning' algorithm L 2 [10] <ref> [8] </ref>. CB1 ( H ) is also certainly less efficient for learning monomial target concepts than the `standard' (non case-based) learning algorithm for monomials [18] [2], and [8] shows that CB1 ( H ) is easily out-performed on monomial target concepts by an instance-based learner which changes the weights assigned to a weighted similarity measure (Figure 4, below). The performance of CB1 ( H ) is therefore relatively poor. <p> Theorem 5. Let be any prior distribution on B N . A separated similarity measure will be optimal with respect to and the space of separated similarity measures if and only if is well-ordered with respect to . Proof. The proof is given in <ref> [8] </ref> (Theorem C.0.1). It outline, the proof considers only E (L; x; x), defined E (L; x; x) = ft * B N jL (x t )(x) 6= t (x)g. <p> Proof. The derivation is very similar to that of Proposition 7. In total there are 2 k N k-literal monomial expressions e.g. <ref> [8, Propn 5.1.2] </ref>, while k of these will be positive on a specific description d 1 * D N . Of these, exactly N ffi concepts will also classify d 2 positively. Hence result. ut Propositions 6, 7 and 8 carry a number of implications. <p> This discussion therefore supports (but does not strictly prove) the assertion that no similarity measure can do better than H in the experiments described in <ref> [8] </ref> and that the learning curves shown in Figure 2 represent the limit of efficiency that can be achieved by CB1 (), using any possible similarity measure, when learning monomial target concepts. 4 Optimal `Learnt' Similarity Measures x3 showed there are experiments, such as learning monomial target concepts, where an instance-based <p> All weights are 1 initially. A weight changes to zero iff two positive examples are observed which disagree on that bit of the representation. M 6;2 and M 6;3 . Experimental conditions can again be found in <ref> [8] </ref>. The figure shows the learning curves starting from the same initial accuracies as observed in Figure 2. The learning curves however achieve a close to perfect classification accuracy much more quickly than the learning curves for CB1 ( H ) shown in that figure. <p> V S-CBR Learning Algorithm for Concepts in M N [19, Fig 4]. s = h (d i ; n i )i m i=1 is a training sample from (D N fi f0; 1g) m . Fig. 4. <ref> [8, Fig 6.1] </ref> Average Learning Curve for Monomial Concepts t * M 6;k (V S-CBR) discards information about the target concept when it computes the weight vec-tor w. <p> V S-CBR2 Learning Algorithm for Concepts in M N <ref> [8, Defn 8.3.1] </ref>. s = h (d i ; n i )i m i=1 is a training sample from (D N fi f0; 1g) m . navely. <p> This follows from the logic of a `constituent analysis' <ref> [8] </ref> [11]. Once the correct similarity measure has been identified by V S-CBR3, then the learner needs only one positive exemplar and one negative exemplar in the case-base to correctly identify the target concept. <p> As in V S--CBR however, the number of examples needed by V S-CBR3 to infer a good similarity measure increases linearly in the number of irrelevant variables <ref> [8] </ref> [11]. Thus, overall, we would also expect the sample complexity of V S-CBR3 to increase in the number of irrelevant variables, as indicated. The picture for V S-CBR2 is less clear, since we have not yet been able to characterise the hypotheses of this learner. <p> by k-term DNF, k-DNF, k-term CNF and k-CNF propositional formulae. x4 shows how the canonical similarity measure of x3 also suggests a `new' instance-based learning algorithm V S-CBR2 for learning monomial concepts which we believe to be more efficient than the algorithm V S-CBR [19] which we have studied previously <ref> [8] </ref> [11]. We also defined V S-CBR3, a further variant of V S-CBR which we also hope to be more efficient than the original algorithm.
Reference: 9. <author> A D Griffiths and D G Bridge. </author> <title> Formalising the knowledge content of case memory systems. </title> <editor> In I D Watson, editor, </editor> <booktitle> Progress in Case-Based Reasoning: Proceedings of the First UK Workshop on Case-Based Reasoning, </booktitle> <address> Salford UK, </address> <month> Jan </month> <year> 1995, </year> <booktitle> Lecture Notes in Artificial Intelligence vol. </booktitle> <volume> 1020, </volume> <pages> pages 32-41. </pages> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: In our work this term is reserved for a different kind of entity <ref> [9] </ref> [8]. pair of elements hx i ; n i i in x t we have t (x i ) = n i .
Reference: 10. <author> A D Griffiths and D G Bridge. </author> <title> A yardstick for the evaluation of case-based classifiers. </title> <booktitle> In (Forthcoming) Proceedings of Second UK Workshop on Case-Based Reasoning, </booktitle> <address> Salford UK, </address> <month> Apr </month> <year> 1996. </year>
Reference-contexts: Fig. 2. [8, Fig 5.3] Average Learning Curve for Monomial Concepts t * M 6;k (CB1 ( H )) In addition, we observed that CB1 ( H ) was not noticeably more efficient than an extremely simple `rote-learning' algorithm L 2 <ref> [10] </ref> [8]. <p> Where d 1 and d 2 are distinct, however, consider that there are four distinct classifications for the pair of variables hd 1 ; d 2 i, one where both are 0, 3 We consider monomial target concepts here out of continuity from our previous work <ref> [10] </ref> [11].
Reference: 11. <author> A D Griffiths and D G Bridge. </author> <title> PAC analyses of a `similarity learning' IBL al-gorithm. </title> <editor> In E Plaza and D Leake, editors, </editor> <booktitle> Case-Based Reasoning Research and Development. Proceedings of the Second International Conference on Case-Based Reasoning, </booktitle> <address> ICCBR-97. Providence, RI, </address> <month> July </month> <year> 1997., </year> <booktitle> Lecture Notes in Artificial Intelligence vol. </booktitle> <volume> 1266, </volume> <pages> pages 445-454. </pages> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Where d 1 and d 2 are distinct, however, consider that there are four distinct classifications for the pair of variables hd 1 ; d 2 i, one where both are 0, 3 We consider monomial target concepts here out of continuity from our previous work [10] <ref> [11] </ref>. <p> Instead, we conjecture a number of hypotheses which we expect to be confirmed in our forthcoming evaluation of these algorithms. tailored to monomial target concepts; it will not correctly identify non-monomial targets. Its operation is straightforward [19] <ref> [11] </ref>: Only the first positive example in the training sample is added to the case base. All other positive examples are discarded. All negative examples in the training sample are added to the case-base. <p> A better approach might be if the information in f is used directly. In <ref> [11] </ref>, we noted that the information held in the f array directly corresponds to the monomial hypothesis chosen by the standard algorithm for monomials [18] [2] (which we call `M '). <p> This follows from the logic of a `constituent analysis' [8] <ref> [11] </ref>. Once the correct similarity measure has been identified by V S-CBR3, then the learner needs only one positive exemplar and one negative exemplar in the case-base to correctly identify the target concept. <p> As in V S--CBR however, the number of examples needed by V S-CBR3 to infer a good similarity measure increases linearly in the number of irrelevant variables [8] <ref> [11] </ref>. Thus, overall, we would also expect the sample complexity of V S-CBR3 to increase in the number of irrelevant variables, as indicated. The picture for V S-CBR2 is less clear, since we have not yet been able to characterise the hypotheses of this learner. <p> k-term DNF, k-DNF, k-term CNF and k-CNF propositional formulae. x4 shows how the canonical similarity measure of x3 also suggests a `new' instance-based learning algorithm V S-CBR2 for learning monomial concepts which we believe to be more efficient than the algorithm V S-CBR [19] which we have studied previously [8] <ref> [11] </ref>. We also defined V S-CBR3, a further variant of V S-CBR which we also hope to be more efficient than the original algorithm.
Reference: 12. <editor> K P Jantke. </editor> <title> Case-based learning in inductive inference. </title> <booktitle> In COLT92: Proceedings of the Fifth ACM Workshop on Computational Learning Theory, </booktitle> <address> July 92, Pittsburgh PA, </address> <pages> pages 218-223. </pages> <publisher> ACM Press, </publisher> <year> 1992. </year>
Reference-contexts: On the other hand, several theoretical studies <ref> [12] </ref> [5] show that the power of instance-based learning is extended if the learner is allowed to change its definition of similarity.
Reference: 13. <author> T M Mitchell. </author> <title> Generalisation as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18(2) </volume> <pages> 203-226, </pages> <year> 1982. </year>
Reference-contexts: be found, since Figure 6 as it stands defines an algorithm which has exponential execution time in the worst case. (It should be possible to calculate the similarity measure V S more efficiently from properties of the training sample or from a more efficient representation such as a version space <ref> [13] </ref>.) The algorithm initialises V S to the set of all monomial concepts M N ; the initial similarity measure used by V S-CBR2 is therefore equivalent to H (w.r.t. the retrieval orderings defined by the two measures; see Proposition 7). <p> In addition, the comparison of V S-CBR2 and V S-CBR3 with other `efficient' algorithms for learning monomial target concepts, such as the `standard' algorithm [18] and Version Space <ref> [13] </ref>, would provide a very useful comparison of instance-based and non instance-based methods and demonstrate whether inductive learning using the `case-based representation' hCB; i has any fundamental differences (w.r.t. sample complexity and efficiency) from other (non case-based) learning algorithms. 5 Conclusions The main results of this paper are presented in x3
Reference: 14. <author> M M Richter. </author> <title> Classification and learning of similarity measures. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the German Society for Classification (Gesellschaft fur Klassifikation e.V.). </booktitle> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: ) fl will be written x, while a training sample x t * (D N fi f0; 1g) fl is a sequence of examples from D N `labelled' according to the target function t so that for each 1 These orderings were first noted by Richter, Wess et al [16] <ref> [14] </ref> [19] who refer to these orderings as `preference relations'. In our work this term is reserved for a different kind of entity [9] [8]. pair of elements hx i ; n i i in x t we have t (x i ) = n i .
Reference: 15. <author> M M Richter. </author> <title> On the notion of similarity in case-based reasoning. </title> <editor> In R della Garcia, R Kruse, and R Viertl, editors, </editor> <booktitle> Workshop Papers: Mathematical and Statistical Methods in Artificial Intelligence, </booktitle> <month> September </month> <year> 1994, </year> <title> Udina, Italy, Courses and Lectures: </title> <journal> International Centre for Mechanical Sciences, </journal> <volume> Vol 363, </volume> <pages> pages 171 - 183. </pages> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: of similarity measures, is a function * s.t. for any other similarity measure 0 * , the accuracy of the instance-based learner CB1 () will be no less than the accuracy of CB1 ( 0 ). 9m 0 * N 8m m 0 EA (;) (m) EA (;) (m) Richter <ref> [15] </ref> suggests that the similarity between two objects should be defined as the probability that the two objects share the same classification.
Reference: 16. <author> M M Richter and S Wess. </author> <title> Similarity, uncertainty and case-based reasoning in PATDEX. </title> <editor> In R S Boyer, editor, </editor> <booktitle> Automated Reasoning Essays in Honour of Woody Bledsoe, </booktitle> <pages> pages 249-265. </pages> <publisher> Kluwer, </publisher> <year> 1991. </year>
Reference-contexts: N ) fl will be written x, while a training sample x t * (D N fi f0; 1g) fl is a sequence of examples from D N `labelled' according to the target function t so that for each 1 These orderings were first noted by Richter, Wess et al <ref> [16] </ref> [14] [19] who refer to these orderings as `preference relations'. In our work this term is reserved for a different kind of entity [9] [8]. pair of elements hx i ; n i i in x t we have t (x i ) = n i .
Reference: 17. <author> C Schaffer. </author> <title> A conservation law for generalization performance. </title> <booktitle> In Machine Learning: Proceedings of Eleventh International Conference ML94, </booktitle> <pages> pages 259-265. </pages> <publisher> Mor-gan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: This illustrates the fundamental idea from learning theory that all generalisation strategies are equivalent when all possible classifications of the example space are equally likely c.f. [21] <ref> [17] </ref>. Proposition 7 on the other hand describes a similarity measure which correlates negatively with ffi, the number of values on which two descriptions disagree.
Reference: 18. <author> L G Valiant. </author> <title> Deductive learning. </title> <journal> Philosophical Transactions of the Royal Philosophical Society of London A, </journal> <volume> 312 </volume> <pages> 441-446, </pages> <year> 1984. </year>
Reference-contexts: CB1 ( H ) is also certainly less efficient for learning monomial target concepts than the `standard' (non case-based) learning algorithm for monomials <ref> [18] </ref> [2], and [8] shows that CB1 ( H ) is easily out-performed on monomial target concepts by an instance-based learner which changes the weights assigned to a weighted similarity measure (Figure 4, below). The performance of CB1 ( H ) is therefore relatively poor. <p> A better approach might be if the information in f is used directly. In [11], we noted that the information held in the f array directly corresponds to the monomial hypothesis chosen by the standard algorithm for monomials <ref> [18] </ref> [2] (which we call `M '). <p> The picture for V S-CBR2 is less clear, since we have not yet been able to characterise the hypotheses of this learner. In addition, the comparison of V S-CBR2 and V S-CBR3 with other `efficient' algorithms for learning monomial target concepts, such as the `standard' algorithm <ref> [18] </ref> and Version Space [13], would provide a very useful comparison of instance-based and non instance-based methods and demonstrate whether inductive learning using the `case-based representation' hCB; i has any fundamental differences (w.r.t. sample complexity and efficiency) from other (non case-based) learning algorithms. 5 Conclusions The main results of this paper
Reference: 19. <author> S Wess and C Globig. </author> <title> Case-based and symbolic classification A case study. </title> <editor> In S Wess, K-D Althoff, and M M Richter, editors, </editor> <booktitle> Topics in CBR: Selected papers from the First European Workshop on Case-Based Reasoning - EWCBR-93, </booktitle> <address> Kaiserslautern, Germany, </address> <month> November '93, </month> <booktitle> Lecture Notes in Computer Science vol. </booktitle> <volume> 837, </volume> <pages> pages 77-91. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: fl will be written x, while a training sample x t * (D N fi f0; 1g) fl is a sequence of examples from D N `labelled' according to the target function t so that for each 1 These orderings were first noted by Richter, Wess et al [16] [14] <ref> [19] </ref> who refer to these orderings as `preference relations'. In our work this term is reserved for a different kind of entity [9] [8]. pair of elements hx i ; n i i in x t we have t (x i ) = n i . <p> Instead, we conjecture a number of hypotheses which we expect to be confirmed in our forthcoming evaluation of these algorithms. tailored to monomial target concepts; it will not correctly identify non-monomial targets. Its operation is straightforward <ref> [19] </ref> [11]: Only the first positive example in the training sample is added to the case base. All other positive examples are discarded. All negative examples in the training sample are added to the case-base. <p> V S-CBR Learning Algorithm for Concepts in M N <ref> [19, Fig 4] </ref>. s = h (d i ; n i )i m i=1 is a training sample from (D N fi f0; 1g) m . <p> example, by linear threshold functions, or by k-term DNF, k-DNF, k-term CNF and k-CNF propositional formulae. x4 shows how the canonical similarity measure of x3 also suggests a `new' instance-based learning algorithm V S-CBR2 for learning monomial concepts which we believe to be more efficient than the algorithm V S-CBR <ref> [19] </ref> which we have studied previously [8] [11]. We also defined V S-CBR3, a further variant of V S-CBR which we also hope to be more efficient than the original algorithm.
Reference: 20. <author> D Wettschereck, D W Aha, and T Mohri. </author> <title> A review and comparative evaluation of feature weighting methods for lazy learning algorithms. </title> <type> Technical Report AIC-95-012, </type> <institution> Navy Center for Applied Research in AI, Naval Research Laboratory, </institution> <address> Washington, DC 20375-5337, USA, </address> <year> 1995. </year>
Reference-contexts: V S-CBR is an example of the large family of IBL algorithms which change their similarity measure but only in a limited way, namely through choosing different weights for a similarity measure similar to equation (3) <ref> [20] </ref>.
Reference: 21. <author> D H Wolpert. </author> <title> On the connection between in-sample testing and generalisation error. </title> <journal> Complex Systems, </journal> <volume> 6 </volume> <pages> 47-94, </pages> <year> 1992. </year>
Reference-contexts: This illustrates the fundamental idea from learning theory that all generalisation strategies are equivalent when all possible classifications of the example space are equally likely c.f. <ref> [21] </ref> [17]. Proposition 7 on the other hand describes a similarity measure which correlates negatively with ffi, the number of values on which two descriptions disagree.
References-found: 21

