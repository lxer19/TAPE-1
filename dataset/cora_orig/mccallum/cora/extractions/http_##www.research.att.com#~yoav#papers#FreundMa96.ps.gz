URL: http://www.research.att.com/~yoav/papers/FreundMa96.ps.gz
Refering-URL: http://www.research.att.com/~yoav/publications.html
Root-URL: 
Email: yoav@research.att.com  mansour@math.tau.ac.il  
Phone: 2  
Title: Learning under persistent drift  
Author: Yoav Freund and Yishay mansour ? 
Address: 600 Mountain Avenue Murray Hill, NJ 07974-0636 USA  Tel-Aviv 69978 ISRAEL.  
Affiliation: 1 AT&T Laboratories,  Dept. of Computer Science Tel Aviv University  
Abstract: In this paper we study learning algorithms for environments which are changing over time. Unlike most previous work, we are interested in the case where the changes might be rapid but their "direction" is relatively constant. We model this type of change by assuming that the target distribution is changing continuously at a constant rate from one extreme distribution to another. We show in this case how to use a simple weighting scheme to estimate the error of an hypothesis, and using this estimate, to minimize the error of the prediction.
Abstract-found: 1
Intro-found: 1
Reference: [Bar92] <author> Bartlett. </author> <title> Learning with slowly changing distribution. </title> <booktitle> In Proceedings of the Workshop on Computational Learning Theory, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <pages> pages 243-252, </pages> <year> 1992. </year>
Reference-contexts: The drawbacks of this assumption have been widely recognized, and a considerable amount of work was devoted to study the cases where either the distribution <ref> [Bar92, BL96] </ref> or the target function [HL94, BBDK96] changes over time. Clearly, without constraints on the way the distribution or target function change over time, it is hopeless to achieve any meaningful learning result. The most common and natural assumption is that the changes are not drastic. <p> The most common and natural assumption is that the changes are not drastic. A formal way to say this is that the distance between two consecutive distributions (target functions) is bounded by some parameter. This approach was the main subject of previous research <ref> [HL94, Bar92, BL96, BBDK96] </ref>, and has developed interesting learning results. Common to the results in [HL94, Bar92, BL96] is the assumption that the rate of drift is sufficiently small that the same hypothesis is good for a sufficiently long period of time. <p> A formal way to say this is that the distance between two consecutive distributions (target functions) is bounded by some parameter. This approach was the main subject of previous research [HL94, Bar92, BL96, BBDK96], and has developed interesting learning results. Common to the results in <ref> [HL94, Bar92, BL96] </ref> is the assumption that the rate of drift is sufficiently small that the same hypothesis is good for a sufficiently long period of time. <p> So far, this setup follows the standard framework of agnostic learning [Vap82, Hau92]. However, the examples are not identically distributed, but generated independently at random according to different distributions over X fi [0; 1]. This is the model suggested by Bartlett <ref> [Bar92] </ref>, however, here we make the additional assumption that the distributions are changing with time in a way that can be approximated, for short periods of of time, by a constant rate drift.
Reference: [BBDK96] <author> Peter Bartlett, Shai Ben-David, and Sanjeev Kulkarni. </author> <title> Learning chang ing concepts by exploiting the structure of change. </title> <booktitle> In Proceedings of the Workshop on Computational Learning Theory, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1996. </year>
Reference-contexts: The drawbacks of this assumption have been widely recognized, and a considerable amount of work was devoted to study the cases where either the distribution [Bar92, BL96] or the target function <ref> [HL94, BBDK96] </ref> changes over time. Clearly, without constraints on the way the distribution or target function change over time, it is hopeless to achieve any meaningful learning result. The most common and natural assumption is that the changes are not drastic. <p> The most common and natural assumption is that the changes are not drastic. A formal way to say this is that the distance between two consecutive distributions (target functions) is bounded by some parameter. This approach was the main subject of previous research <ref> [HL94, Bar92, BL96, BBDK96] </ref>, and has developed interesting learning results. Common to the results in [HL94, Bar92, BL96] is the assumption that the rate of drift is sufficiently small that the same hypothesis is good for a sufficiently long period of time. <p> The persistent-drift assumption is an assumption about the first order in the expansion, it assumes that it is the rate of change that is more or less constant. This model has a similar motivation to the model of structured change suggested by Bartlett, Ben David and Kulkarni <ref> [BBDK96] </ref>. However, we restrict ourselves to the special case in which the change (in both the concept and the input distribution) is a linear function of time.
Reference: [BL96] <author> Rakesh D. Barve and Philip M. </author> <title> Long. On the complexity of learning from drifting distributions. </title> <booktitle> In Proceedings of the Workshop on Computational Learning Theory, </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1996. </year>
Reference-contexts: The drawbacks of this assumption have been widely recognized, and a considerable amount of work was devoted to study the cases where either the distribution <ref> [Bar92, BL96] </ref> or the target function [HL94, BBDK96] changes over time. Clearly, without constraints on the way the distribution or target function change over time, it is hopeless to achieve any meaningful learning result. The most common and natural assumption is that the changes are not drastic. <p> The most common and natural assumption is that the changes are not drastic. A formal way to say this is that the distance between two consecutive distributions (target functions) is bounded by some parameter. This approach was the main subject of previous research <ref> [HL94, Bar92, BL96, BBDK96] </ref>, and has developed interesting learning results. Common to the results in [HL94, Bar92, BL96] is the assumption that the rate of drift is sufficiently small that the same hypothesis is good for a sufficiently long period of time. <p> A formal way to say this is that the distance between two consecutive distributions (target functions) is bounded by some parameter. This approach was the main subject of previous research [HL94, Bar92, BL96, BBDK96], and has developed interesting learning results. Common to the results in <ref> [HL94, Bar92, BL96] </ref> is the assumption that the rate of drift is sufficiently small that the same hypothesis is good for a sufficiently long period of time.
Reference: [Hau92] <author> David Haussler. </author> <title> Decision theoretic generalization of the pac model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100 </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: Note that each of these distributions defines both a distribution over the input space and a distribution of outputs for each input Probfyjxg. So far, this setup follows the standard framework of agnostic learning <ref> [Vap82, Hau92] </ref>. However, the examples are not identically distributed, but generated independently at random according to different distributions over X fi [0; 1]. <p> We cannot use the existing theorems, because they are stated for the case in which all examples are drawn from the same distribution. Luckily, the proofs given by Haussler <ref> [Hau92] </ref>, which are based on techniques of Pollard [Pol84] do not use the fact that all examples are drawn from the same distribution, and very slight alteration to these proofs lead to the following theorem, which is a slight alteration of Corollary 2 in [Hau92]: Theorem 4. <p> Luckily, the proofs given by Haussler <ref> [Hau92] </ref>, which are based on techniques of Pollard [Pol84] do not use the fact that all examples are drawn from the same distribution, and very slight alteration to these proofs lead to the following theorem, which is a slight alteration of Corollary 2 in [Hau92]: Theorem 4. Let F be a permissible family of functions from a set Z into [0,1] with pseudo-dimension d &lt; 1. Assume m 1. <p> We should comment that no attempt has been made to optimize the constants in this theorem. Two observations show that the proof given by Haussler <ref> [Hau92] </ref> can be used essentially verbatim. The proof uses a trick of using two samples and permuting elements among them. The first observation is that all the permutations are done pairwise between elements with the same index in the two samples, thus all the requirements for identical distributions still hold.
Reference: [HL94] <author> David Helmbold and Phill Long. </author> <title> Tracking drifting concepts by minimizing disagreements. </title> <journal> Machine Learning, </journal> <volume> 14(1) </volume> <pages> 27-46, </pages> <year> 1994. </year> <note> A preliminary version appeared in Proceedings of COLT 1991, 13-23. </note>
Reference-contexts: The drawbacks of this assumption have been widely recognized, and a considerable amount of work was devoted to study the cases where either the distribution [Bar92, BL96] or the target function <ref> [HL94, BBDK96] </ref> changes over time. Clearly, without constraints on the way the distribution or target function change over time, it is hopeless to achieve any meaningful learning result. The most common and natural assumption is that the changes are not drastic. <p> The most common and natural assumption is that the changes are not drastic. A formal way to say this is that the distance between two consecutive distributions (target functions) is bounded by some parameter. This approach was the main subject of previous research <ref> [HL94, Bar92, BL96, BBDK96] </ref>, and has developed interesting learning results. Common to the results in [HL94, Bar92, BL96] is the assumption that the rate of drift is sufficiently small that the same hypothesis is good for a sufficiently long period of time. <p> A formal way to say this is that the distance between two consecutive distributions (target functions) is bounded by some parameter. This approach was the main subject of previous research [HL94, Bar92, BL96, BBDK96], and has developed interesting learning results. Common to the results in <ref> [HL94, Bar92, BL96] </ref> is the assumption that the rate of drift is sufficiently small that the same hypothesis is good for a sufficiently long period of time. <p> Helmbold and Long <ref> [HL94] </ref> suggested using a similar weighted average to optimize the bounds on the performance of their algorithm. The main difference is in the assumption about the rate of change. While in [HL94] the rate of change is slow, and a single function is suited to fit all the recent examples, we <p> Helmbold and Long <ref> [HL94] </ref> suggested using a similar weighted average to optimize the bounds on the performance of their algorithm. The main difference is in the assumption about the rate of change. While in [HL94] the rate of change is slow, and a single function is suited to fit all the recent examples, we allow rapid changes, and it may be that a function that fits well at the start of the window will fit poorly at its end. <p> This main structural difference manifests itself in the weights. In <ref> [HL94] </ref> all the weights are positive, and this it corresponds to the assumption that the achievable prediction error is of the same order as the rate of drift.
Reference: [Pol84] <author> David Pollard. </author> <title> Convergence of Stochastic Processes. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: To do that we use Bernstein's Inequality (see e.g. <ref> [Pol84] </ref>): Lemma 1 Bernstein. Let Y 1 ; : : : ; Y n be independent random variables with zero means and and bounded ranges: jY i j M . Write 2 i for the variance of Y i . Suppose V 2 1 + + 2 n . <p> We cannot use the existing theorems, because they are stated for the case in which all examples are drawn from the same distribution. Luckily, the proofs given by Haussler [Hau92], which are based on techniques of Pollard <ref> [Pol84] </ref> do not use the fact that all examples are drawn from the same distribution, and very slight alteration to these proofs lead to the following theorem, which is a slight alteration of Corollary 2 in [Hau92]: Theorem 4.
Reference: [Val84] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: 1 Introduction One of the oversimplifying assumptions made in the PAC model <ref> [Val84] </ref> is that all the examples are drawn from the same distribution, and that the target function does not change with time.
Reference: [Vap82] <author> V. N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Note that each of these distributions defines both a distribution over the input space and a distribution of outputs for each input Probfyjxg. So far, this setup follows the standard framework of agnostic learning <ref> [Vap82, Hau92] </ref>. However, the examples are not identically distributed, but generated independently at random according to different distributions over X fi [0; 1].
References-found: 8

