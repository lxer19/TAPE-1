URL: http://ic-www.arc.nasa.gov/ic/jair-www/volume2/schaerf95a.ps
Refering-URL: http://www.cs.washington.edu/research/jair/abstracts/schaerf95a.html
Root-URL: 
Email: aschaerf@dis.uniroma1.it  shoham@flamingo.stanford.edu  moshet@ie.technion.ac.il  
Title: Adaptive Load Balancing: A Study in Multi-Agent Learning  
Author: Andrea Schaerf Yoav Shoham Moshe Tennenholtz 
Address: "La Sapienza", Via Salaria 113, I-00198 Roma, Italy  Stanford, CA 94305, USA  32000, Israel  
Affiliation: Dipartimento di Informatica e Sistemistica Universita di Roma  Robotics Laboratory, Computer Science Department Stanford University,  Faculty of Industrial Engineering and Management Technion, Haifa  
Note: Journal of Artificial Intelligence Research 2 (1995) 475-500 Submitted 10/94; published 5/95  
Abstract: We study the process of multi-agent reinforcement learning in the context of load balancing in a distributed system, without use of either central coordination or explicit communication. We first define a precise framework in which to study adaptive load balancing, important features of which are its stochastic nature and the purely local information available to individual agents. Given this framework, we show illuminating results on the interplay between basic adaptive behavior parameters and their effect on system efficiency. We then investigate the properties of adaptive load balancing in heterogeneous populations, and address the issue of exploration vs. exploitation in that context. Finally, we show that naive use of communication may not improve, and might even harm system efficiency.
Abstract-found: 1
Intro-found: 1
Reference: <author> Abdel-Fattah, Y. M. </author> <year> (1983). </year> <title> Stochastic automata modeling of certain problems of collective behavior. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 13 (3), </volume> <pages> 236-241. </pages>
Reference: <author> Altenberg, L., & Feldman, M. W. </author> <year> (1987). </year> <title> Selection, generalized transmission, and the evolution of modifier genes. I. The reduction principle. </title> <journal> Genetics, </journal> <volume> 117, </volume> <pages> 559-572. </pages>
Reference-contexts: The framework of co-learning is similar in some respects to a number of dynamic frameworks in economics (Kandori, Mailath, & Rob, 1991), physics (Kinderman & Snell, 1980), computational ecologies (Huberman & Hogg, 1988), and biology <ref> (Altenberg & Feldman, 1987) </ref>. Our study of adaptive load balancing can be treated as a study in co-learning. Relevant to our work is also the literature in the field of Learning Automata (see Naren-dra & Thathachar, 1989).
Reference: <author> Arthur, W. </author> <year> (1994). </year> <title> Inductive reasoning, bounded rationality and the bar problem. </title> <type> Tech. rep. </type> <institution> 94-03-014 (working paper), Santa Fe Institute. </institution> <note> Appeared also in American Economic Review 84. </note>
Reference-contexts: However, there are other real-life situations related to our model in areas different from classical distributed computer systems. A canonical problem related to our model is the following one <ref> (Arthur, 1994) </ref>: An agent, embedded in a multi-agent system, has to select among a set of bars (or a set of restaurants). <p> Our model is closely related to models of decision-making in management and organization theory (e.g., Malone, 1987) and applies a reinforcement learning perspective to that context. This makes our work related to psychological models of decision-making <ref> (Arthur, 1994) </ref>. 496 Adaptive Load Balancing: A Study in Multi-Agent Learning 10. Summary This work applies the idea of multi-agent reinforcement learning to the problem of load balancing in a loosely-coupled multi-agent system, in which agents need to adapt to one another as well as to a changing environment.
Reference: <author> Axelrod, R. </author> <year> (1984). </year> <title> The Evolution of Cooperation. </title> <address> New York: </address> <publisher> Basic Books. </publisher>
Reference-contexts: What we have shown is how, for a fixed value of w, coexisting populations adopting different values of n interact. Similar results are obtained when we fix the value of n and 8. This is in fact an illuminating instance of the well-known prisoners dilemma <ref> (Axelrod, 1984) </ref>. 489 Schaerf, Shoham, & Tennenholtz - 0.01 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 62 64 66 Weight of the estimator parameter (w 2 ) A e a e i e e T k n : T 2 use two different values for w.
Reference: <author> Bertsekas, D., & Tsitsiklis, J. </author> <year> (1989). </year> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: Our results about the disagreement between selfish interest of agents and the common interest of the population is in sharp contrast to previous work on multi-agent learning (Shoham & Tennenholtz, 1992, 1994) and to the dynamic programming perspective of earlier work on distributed systems <ref> (Bertsekas & Tsitsiklis, 1989) </ref>. Moreover, we explore how the interaction between different agent types affects the system's efficiency as well as 494 Adaptive Load Balancing: A Study in Multi-Agent Learning the individual agent's efficiency. <p> In spite of the differences, there are some similarities between our work and the abovementioned work. One important similarity is the use of learning procedures. This is in difference from the more classical work on parallel and distributed computation <ref> (Bertsekas & Tsitsiklis, 1989) </ref> which applies numerical and iterative methods to the solution of problems in network flow and parallel computing. Other similarities are related to our study of the division of the society into groups.
Reference: <author> Billard, E., & Pasquale, J. </author> <year> (1993). </year> <title> Effects of delayed communication in dynamic group formation. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23 (5), </volume> <pages> 1265-1275. </pages>
Reference-contexts: Other similarities are related to our study of the division of the society into groups. This somewhat resembles work on group formation <ref> (Billard & Pasquale, 1993) </ref> in distributed computer systems. The information sharing we allow in Section 7 is similar to the limited communication discussed by Tan (1993). In the classification of load-balancing problems given by Ferrari (1985), our work falls into the category of load-independent and non-preemptive pure load-balancing.
Reference: <author> Blackburn, J. M. </author> <year> (1936). </year> <title> Acquisition to skill: An analysis of learning curves. </title> <note> IHRB Report No. 73. </note>
Reference: <author> Bond, A. H., & Gasser, L. </author> <year> (1988). </year> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Ablex Publishing Corporation. </publisher>
Reference-contexts: Basically, in this paper we wish to investigate how far one can go using only purely local feedback and without the use of any global information (Kaelbling, 1993; Sutton, 1992). 476 Adaptive Load Balancing: A Study in Multi-Agent Learning 1987), and in distributed AI <ref> (e.g., Bond & Gasser, 1988) </ref>. Although some motivations of the above-mentioned lines of research are similar, the settings discussed have some essential differences.
Reference: <author> Bonomi, F., Doshi, B., Kaufmann, J., Lee, T., & Kumar, A. </author> <year> (1990). </year> <title> A case study of adaptive load balancing algorithm. </title> <journal> Queuing Systems, </journal> <volume> 7, </volume> <pages> 23-49. </pages>
Reference-contexts: The problems we investigate can be also seen as sender-initiated problems, although in our case the sender is the agent and not the (overloaded) resource. 495 Schaerf, Shoham, & Tennenholtz One may wonder how our work differs from other work on adaptive load balancing in Operations Research (OR) <ref> (e.g., queuing theory Bonomi, Doshi, Kaufmann, Lee, & Kumar, 1990) </ref>. Indeed, there are some commonalities. In both OR and our work, individual decisions are made locally, based on information obtained dynamically during runtime.
Reference: <author> Durfee, E. H., Lesser, V. R., & Corkill, D. D. </author> <year> (1987). </year> <title> Coherent cooperation among communicating problem solvers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36, </volume> <pages> 1275-1291. </pages> <note> 497 Schaerf, </note> <author> Shoham, & Tennenholtz Eager, D., Lazowska, E., & Zahorjan, J. </author> <year> (1986). </year> <title> Adaptive load sharing in homogeneous distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12 (5), </volume> <pages> 662-675. </pages>
Reference: <author> El-Fattah, Y. M. </author> <year> (1980). </year> <title> Stochastic automata modeling of certain problems of collective behavior. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 10 (6), </volume> <pages> 304-314. </pages>
Reference: <author> Ferrari, D. </author> <year> (1985). </year> <title> A study of load indices for load balancing schemes. </title> <type> Tech. rep. </type> <institution> Ucb/CSD 86/262, Computer Science Division (EECS), Univ. of California, Berkeley. </institution>
Reference: <author> Ferrari, D., Serazzi, G., & Zeigner, A. </author> <year> (1983). </year> <title> Measurement and Tuning of Computer Systems. </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: This function is probabilistic. We first define the following function pd 0 ( E [ee A ] n if jd A (R) = 0 2. Using parallel processing terminology, T can be viewed as a stretch factor, which quantifies the stretching of a program's processing time due to multiprogramming <ref> (Ferrari, Serazzi, & Zeigner, 1983) </ref>. 480 Adaptive Load Balancing: A Study in Multi-Agent Learning where n is a positive real-valued parameter and E [ee A ] represents the average of the values of ee A (R) over all resources satisfying jd A (R) &gt; 0.
Reference: <author> Fox, M. S. </author> <year> (1981). </year> <title> An organizational view of distributed systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 11, </volume> <pages> 70-80. </pages>
Reference: <author> Glockner, A., & Pasquale, J. </author> <year> (1993). </year> <title> Coadaptive behavior in a simple distributed job scheduling system. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23 (3), </volume> <pages> 902-907. </pages>
Reference: <author> Gmytrasiewicz, P., Durfee, E., & Wehe, D. </author> <year> (1991). </year> <title> The utility of communication in coordinating intelligent agents. </title> <booktitle> In Proc. of the 9th Nat. Conf. on Artificial Intelligence (AAAI-91), </booktitle> <pages> pp. 166-172. </pages>
Reference: <author> Huberman, B. A., & Hogg, T. </author> <year> (1988). </year> <title> The behavior of computational ecologies. </title> <editor> In Huber-man, B. A. (Ed.), </editor> <booktitle> The Ecology of Computation. </booktitle> <publisher> Elsevier Science. </publisher>
Reference-contexts: This part of our study supplies useful guidelines for a systems designer who may force all the agents to work based on a common selection rule. Our observations, although somewhat related to previous observations made in other contexts and models <ref> (Huberman & Hogg, 1988) </ref>, enable to demonstrate aspects of purely local adaptive behavior in a non-trivial model. <p> The framework of co-learning is similar in some respects to a number of dynamic frameworks in economics (Kandori, Mailath, & Rob, 1991), physics (Kinderman & Snell, 1980), computational ecologies <ref> (Huberman & Hogg, 1988) </ref>, and biology (Altenberg & Feldman, 1987). Our study of adaptive load balancing can be treated as a study in co-learning. Relevant to our work is also the literature in the field of Learning Automata (see Naren-dra & Thathachar, 1989).
Reference: <author> Kaelbling, L. </author> <year> (1993). </year> <title> Learning in Embedded Systems. </title> <publisher> MIT Press. </publisher>
Reference-contexts: In our family of rules, called , which partially resembles the learning rules discussed in the learning automata literature (Narendra & Thathachar, 1989), and partially resembles the interval estimation algorithm <ref> (Kaelbling, 1993) </ref>, agents do not maintain complete history of their experience. Instead, each agent, A, condenses this history into 479 Schaerf, Shoham, & Tennenholtz a vector, called the efficiency estimator, and denoted by ee A .
Reference: <author> Kandori, M., Mailath, G., & Rob, R. </author> <year> (1991). </year> <title> Learning, mutation and long equilibria in games. </title> <institution> Mimeo. University of Pennsylvania. </institution>
Reference-contexts: The framework of co-learning is similar in some respects to a number of dynamic frameworks in economics <ref> (Kandori, Mailath, & Rob, 1991) </ref>, physics (Kinderman & Snell, 1980), computational ecologies (Huberman & Hogg, 1988), and biology (Altenberg & Feldman, 1987). Our study of adaptive load balancing can be treated as a study in co-learning.
Reference: <author> Kinderman, R., & Snell, S. L. </author> <year> (1980). </year> <title> Markov Random Fields and their Applications. </title> <publisher> American Mathematical Society. </publisher>
Reference-contexts: The framework of co-learning is similar in some respects to a number of dynamic frameworks in economics (Kandori, Mailath, & Rob, 1991), physics <ref> (Kinderman & Snell, 1980) </ref>, computational ecologies (Huberman & Hogg, 1988), and biology (Altenberg & Feldman, 1987). Our study of adaptive load balancing can be treated as a study in co-learning. Relevant to our work is also the literature in the field of Learning Automata (see Naren-dra & Thathachar, 1989).
Reference: <author> Kosoresow, A. P. </author> <year> (1993). </year> <title> A fast first-cut protocol for agent coordination. </title> <booktitle> In Proc. of the 11th Nat. Conf. on Artificial Intelligence (AAAI-93), </booktitle> <pages> pp. 237-242. </pages>
Reference: <author> Kraus, S., & Wilkenfeld, J. </author> <year> (1991). </year> <title> The function of time in cooperative negotiations. </title> <booktitle> In Proc. of the 9th Nat. Conf. on Artificial Intelligence (AAAI-91), </booktitle> <pages> pp. 179-184. </pages>
Reference: <author> Lesser, V. R. </author> <year> (1991). </year> <title> A retrospective view of FA/C distributed problem solving. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 21 (6), </volume> <pages> 1347-1362. </pages>
Reference-contexts: In order to profitably use the shared data, we should allow for some form of reasoning about the fact that the data is shared. This problem however is out of the scope of this paper <ref> (see e.g., Lesser, 1991) </ref>. In order to understand the behavior of the system when CNs and NCNs face each other, we consider an NCN of 80 agents together with a set of CNs of equal size, for different values of that size.
Reference: <author> Malone, T. W. </author> <year> (1987). </year> <title> Modeling coordination in organizations and markets. </title> <journal> Management Science, </journal> <volume> 33 (10), </volume> <pages> 1317-1332. </pages>
Reference-contexts: The agents are autonomous entities which negotiate among themselves (Zlotkin & Rosenschein, 1993; Kraus & Wilkenfeld, 1991) on the use of shared resources. Alternatively, the agents (called managers in this case) may negotiate the task to be executed with the processors which may execute it <ref> (Malone, 1987) </ref>. The model we adopt has the flavor of models used in distributed AI and organization theory. We assume a strict separation between agents and resources. Jobs arrive to agents who make decisions about where to execute them. The resources are passive (i.e., do not make decisions). <p> Last but not least, our work is related to work applying organization theory and management techniques to the field of Distributed AI (Fox, 1981; Malone, 1987; Durfee, Lesser, & Corkill, 1987). Our model is closely related to models of decision-making in management and organization theory <ref> (e.g., Malone, 1987) </ref> and applies a reinforcement learning perspective to that context. This makes our work related to psychological models of decision-making (Arthur, 1994). 496 Adaptive Load Balancing: A Study in Multi-Agent Learning 10.
Reference: <author> Mehra, P. </author> <year> (1992). </year> <title> Automated Learning of Load-Balancing Strategies For A Distributed Computer System. </title> <type> Ph.D. thesis, </type> <institution> Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign. </institution> <note> 498 Adaptive Load Balancing: A Study in Multi-Agent Learning Mehra, </note> <author> P., & Wah, B. W. </author> <year> (1993). </year> <title> Population-based learning of load balancing policies for a distributed computer system. </title> <booktitle> In Proceedings of Computing in Aerospace 9 Conference, AIAA, </booktitle> <pages> pp. 1120-1130. </pages>
Reference: <author> Mirchandaney, R., & Stankovic, J. </author> <year> (1986). </year> <title> Using stochastic learning automata for job scheduling in distributed processing systems. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 3, </volume> <pages> 527-552. </pages>
Reference-contexts: We concentrate on the case where a job can be executed using any of the resources. Although somewhat restricting, this is a common practice in much work in distributed systems <ref> (Mirchandaney & Stankovic, 1986) </ref>.
Reference: <author> Mirchandaney, R., Towsley, D., & Stankovic, J. </author> <year> (1989). </year> <title> Analysis of the effects of delays on load sharing. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38 (11), </volume> <pages> 1513-1525. </pages>
Reference: <author> Narendra, K., & Thathachar, M. A. L. </author> <year> (1989). </year> <title> Learning Automata: An Introduction. </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: The actual action to be performed, based on the information received from other computers, may be controlled in various ways. One of the ways adopted to control the related decisions is through learning automata <ref> (Narendra & Thathachar, 1989) </ref>. In the above-mentioned work each agent is associated with a set of resources, where both the agent and the related resources are associated with a node in the distributed system. Much work in management science and in distributed AI adopts a somewhat complementary view. <p> In principle, our set of SRs captures the two most robust aspects of these observations: "The law of effect" (Thronkide, 1898) and the "Power law of practice" (Black-burn, 1936). In our family of rules, called , which partially resembles the learning rules discussed in the learning automata literature <ref> (Narendra & Thathachar, 1989) </ref>, and partially resembles the interval estimation algorithm (Kaelbling, 1993), agents do not maintain complete history of their experience. Instead, each agent, A, condenses this history into 479 Schaerf, Shoham, & Tennenholtz a vector, called the efficiency estimator, and denoted by ee A .
Reference: <author> Narendra, K., & Wheeler Jr., R. M. </author> <year> (1983). </year> <title> An N-player sequential stochastic game with identical payoffs. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 13 (6), </volume> <pages> 1154-1158. </pages>
Reference: <author> Pulidas, S., Towsley, D., & Stankovic, J. </author> <year> (1988). </year> <title> Imbedding gradient estimators in load balancing algorithms. </title> <booktitle> In Proceedings of the 8th International Conference on Distributed Computer Systems, IEEE, </booktitle> <pages> pp. 482-489. </pages>
Reference: <author> Sen, S., Sekaran, M., & Hale, J. </author> <year> (1994). </year> <title> Learning to coordinate without sharing information. </title> <booktitle> In Proc. of the 12th Nat. Conf. on Artificial Intelligence (AAAI-94). </booktitle>
Reference: <author> Shoham, Y., & Tennenholtz, M. </author> <year> (1992). </year> <title> Emergent conventions in multi-agent systems: initial experimental results and observations. </title> <booktitle> In Proc. of the 3rd Int. Conf. on Principles of Knowledge Representation and Reasoning (KR-92), </booktitle> <pages> pp. 225-231. </pages>
Reference-contexts: We will assume w is fixed to a given value while discussing BCSR. In our previous work <ref> (Shoham & Tennenholtz, 1992, 1994) </ref>, we showed that learning rules that strongly resemble BCSR are useful for several natural multi-agent learning settings. This suggests that we need to carefully study it in the case of adaptive load balancing. <p> However, if all of the agents are non-cooperative then all of them will lose. 8 In conclusion, the selfish interest of an agent does not match with the interest of the population. This is contrary to results obtained in other basic contexts of multi-agent learning <ref> (Shoham & Tennenholtz, 1992) </ref>. What we have shown is how, for a fixed value of w, coexisting populations adopting different values of n interact. Similar results are obtained when we fix the value of n and 8. <p> Our results about the disagreement between selfish interest of agents and the common interest of the population is in sharp contrast to previous work on multi-agent learning <ref> (Shoham & Tennenholtz, 1992, 1994) </ref> and to the dynamic programming perspective of earlier work on distributed systems (Bertsekas & Tsitsiklis, 1989). <p> This work too, however, tends to be based on some form of communication among the agents, whereas in our case the load balancing is obtained purely from a learning activity. This article is related to our previous work on co-learning <ref> (Shoham & Tennenholtz, 1992, 1994) </ref>.
Reference: <author> Shoham, Y., & Tennenholtz, M. </author> <year> (1994). </year> <title> Co-learning and the evolution of social activity. </title> <type> Tech. rep. STAN-CS-TR-94-1511, </type> <institution> Dept. of Computer Science, Stanford University. </institution>
Reference: <author> Sutton, R. </author> <year> (1992). </year> <title> Special issue on reinforcement learning. </title> <booktitle> Machine Learning, </booktitle> <pages> 8 (3-4). </pages>
Reference-contexts: All rights reserved. Schaerf, Shoham, & Tennenholtz How should an agent choose an appropriate resource in order to optimize these measures? Here we make an important assumption, in the spirit of reinforcement learning <ref> (Sutton, 1992) </ref>: The information available to the agent is only its prior experience.
Reference: <author> Tan, M. </author> <year> (1993). </year> <title> Multi-agent reinforcement learning: Independent vs. </title> <booktitle> cooperative agents. In Proceedings of the 10th International Conference on Machine Learning. </booktitle>
Reference: <author> Thronkide, E. L. </author> <title> (1898). Animal intelligence: An experimental study of the associative processes in animals. </title> <journal> Psychological Monographs, </journal> <volume> 2. </volume>
Reference: <author> Watkins, C. </author> <year> (1989). </year> <title> Learning With Delayed Rewards. </title> <type> Ph.D. thesis, </type> <institution> Cambridge University. </institution>
Reference-contexts: We also observe the following phenomenon: Given a fixed n (resp. a fixed w) the average time-per-token is non-monotonic in w (resp. in n). This phenomenon is strongly related to the issue of exploration versus exploitation mentioned before and to phenomena observed in the study of Q-learning <ref> (Watkins, 1989) </ref>. We also notice how the two parameters n and w interplay. In fact, for each value of w the minimum of the time per token value is obtained with a different value of n.
Reference: <author> Wellman, M. P. </author> <year> (1993). </year> <title> A market-oriented programming environment and its application to distributed multicommodity flow problems. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1, </volume> <pages> 1-23. </pages>
Reference: <author> Wheeler Jr., R. M., & Narendra, K. </author> <year> (1985). </year> <title> Learning models for decentralized decision making. </title> <journal> Automatica, </journal> <volume> 21 (4), </volume> <pages> 479-484. </pages> <note> 499 Schaerf, </note> <author> Shoham, & Tennenholtz Yanco, H., & Stein, L. </author> <year> (1993). </year> <title> An adaptive communication protocol for cooperating mobile robots. </title> <booktitle> In From Animals to Animats: Proceedings of the Second International Conference on the Simulation of Adaptive Behavior, </booktitle> <pages> pp. 478-485. </pages>
Reference: <author> Zhou, S. </author> <year> (1988). </year> <title> A trace-driven simulation study of dynamic load balancing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14 (9), </volume> <pages> 1327-1341. </pages>
Reference: <author> Zlotkin, G., & Rosenschein, J. S. </author> <year> (1993). </year> <title> A domain theory for task oriented negotiation. </title> <booktitle> In Proc. of the 13th Int. Joint Conf. on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pp. 416-422. 500 </pages>
References-found: 41

