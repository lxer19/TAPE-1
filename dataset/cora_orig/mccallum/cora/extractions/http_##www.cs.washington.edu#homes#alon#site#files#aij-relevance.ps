URL: http://www.cs.washington.edu/homes/alon/site/files/aij-relevance.ps
Refering-URL: http://www.cs.washington.edu/homes/alon/site/PaperAbstractPresentation_bib33.html
Root-URL: 
Email: levy@research.att.com  fikes@cs.stanford.edu  sagiv@cs.huji.ac.il  
Title: Speeding Up Inferences Using Relevance Reasoning: A Formalism and Algorithms  
Author: Alon Y. Levy Richard E. Fikes Yehoshua Sagiv 
Address: 600 Mountain Ave., Room 2C-406, Murray Hill, NJ, 07974  701 Welch Road, Bldg. C Palo Alto, California 94304  Jerusalem, Israel  
Affiliation: AT&T Bell Laboratories  KSL, Stanford University  Dept. of Computer Science Hebrew University,  
Abstract: Irrelevance reasoning refers to the process in which a system reasons about which parts of its knowledge are relevant (or irrelevant) to a specific query. Aside from its importance in speeding up inferences from large knowledge bases, relevance reasoning is crucial in advanced applications such as modeling complex physical devices and information gathering in distributed heterogeneous systems. This article presents a novel framework for studying the various kinds of irrelevance that arise in inference and efficient algorithms for relevance reasoning. We present a proof-theoretic framework for analyzing definitions of irrelevance. The framework makes the necessary distinctions between different notions of irrelevance that are important when using them for speeding up inferences. We describe the query-tree algorithm which is a sound, complete and efficient algorithm for automatically deriving certain kinds of irrelevance claims for Horn-rule knowledge bases and several extensions. Finally, we describe experimental results that show that significant speedups (often orders of magnitude) are obtained by employing the query-tree in inference. 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Serge Abiteboul and Richard Hull. </author> <title> Data functions, datalog and negation. </title> <booktitle> In Proceedings of ACM SIGMOD 1988 International Conference on Management of Data, </booktitle> <year> 1988. </year>
Reference-contexts: constraints Follows from [48] Follows from [78] Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 [61] [55] Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from <ref> [1] </ref>.
Reference: [2] <author> Sanjaya Addanki, R. Cremonini, and J. Penberthy. </author> <title> Reasoning about assumptions in graphs of models. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference: [3] <author> Alan R. Anderson and Nuel D. Belnap. </author> <title> Entailment. </title> <publisher> Princeton University Press, </publisher> <address> Prince-ton, New Jersey, </address> <year> 1975. </year> <title> 18 This assumes each block is at least of size 3. If this doesn't hold, we simply add another dummy column to each block, and leave it unchanged in all the rules. </title> <type> 53 </type>
Reference-contexts: A related concept discussed in the formal logic community is relevance logics (e.g., <ref> [3, 24, 5] </ref>). The key idea in relevance logics is to modify the logic and the inference rules such that only relevant implications can be made. However, two issues are still largely open in this field.
Reference: [4] <author> Yigal Arens, Craig A. Knoblock, and Wei-Min Shen. </author> <title> Query reformulation for dy-namic information integration. </title> <journal> International Journal on Intelligent and Cooperative Information Systems, </journal> <volume> (6) </volume> 2/3:99-130, June 1996. 
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. <p> Such queries are usually complex (built from many sub-queries), and interpreted constraints play a major role in them. Predicate move-around is currently being implemented in a commercial decision support system. Information gathering in distributed heterogeneous environments: An important application of knowledge representation is the integration of multiple information sources <ref> [38, 4, 31, 60, 90] </ref>. So called mediator systems provide access to a large number of information sources (such as databases, knowledge bases and text files).
Reference: [5] <author> Arnon Avron. </author> <title> Whither relevance logic? Journal of Philosophical Logic, </title> <booktitle> 21 </booktitle> <pages> 243-281, </pages> <year> 1992. </year>
Reference-contexts: A related concept discussed in the formal logic community is relevance logics (e.g., <ref> [3, 24, 5] </ref>). The key idea in relevance logics is to modify the logic and the inference rules such that only relevant implications can be made. However, two issues are still largely open in this field.
Reference: [6] <author> F. Baader and B. </author> <title> Hollunder. A terminological knowledge representation system with complete inference algorithm. </title> <booktitle> In In Proceedings of the Workshop on Processing Declarative Knowledge, PDK-91, Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 67-86. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: In particular, any description logic with decidable subsump tion can be viewed as a sort language (e.g. <ref> [12, 72, 6] </ref>). * Finite, given relation: Often, a given relation that is relatively small and stable can be best viewed as a constraint. Any given finite relation satisfies the properties that we require.
Reference: [7] <author> F. Bacchus, A. J. Grove, J. Y. Halpern, and D. Koller. </author> <title> Statistical foundations for default reasoning. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <year> 1993. </year>
Reference-contexts: A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. Irrelevance reasoning also plays an important role in nonmonotonic reasoning <ref> [71, 36, 7] </ref>, belief revision [35] and learning (e.g., [30, 66, 74]). The focus of this paper is on using relevance reasoning to speed up inferences in large knowledge bases.
Reference: [8] <author> F. Bancilhon, D. Maier, Y. Sagiv, and J. Ullman. </author> <title> Magic sets and other strange ways to implement logic programs. </title> <booktitle> In Proceedings of the Fifth ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 1-15, </pages> <year> 1986. </year>
Reference-contexts: It should be noted that the savings achieved by employing the query-tree are orthogonal to methods that develop optimal strategies for searching the space (e.g., rule and subgoal ordering [42, 84]) and methods that use run-time bindings (combined with tabulation) to prune the search <ref> [8, 9, 93] </ref>. Therefore, the experimental validation presented here does not follow from experiments validating these other methods. Organization of the Paper The paper is organized as follows. Section 2 describes the space of definitions of irrelevance and compares properties of various definitions. <p> creating indices that will not be used. 14 Finally, it should be emphasized that the optimizations obtained by using the query-tree are orthogonal to those achieved by methods that derive optimal rule and goal orderings [42, 84] or methods that use run-time bindings (combined with tabulation) to prune the search <ref> [8, 9, 93] </ref>. Whereas these methods look for optimal ways to search the space, the query-tree identifies parts of the space that are guaranteed not to contain solutions and is independent of any run-time bindings. <p> It tells us which tuples in the database are guaranteed to be irrelevant to the query; therefore, we can apply a filter to the database relations as a first step in query evaluation. Moreover, the query-tree can also be combined with other optimization methods such as magic-sets <ref> [8, 9] </ref> and algorithms based on message-passing [91]. A novel query optimization algorithm for SQL queries, predicate move-around, based on the query-tree is described in [58].
Reference: [9] <author> Catriel Beeri and Raghu Ramakrishnan. </author> <title> On the power of magic. </title> <booktitle> In Proceedings of the Sixth ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 269-283, </pages> <year> 1987. </year>
Reference-contexts: It should be noted that the savings achieved by employing the query-tree are orthogonal to methods that develop optimal strategies for searching the space (e.g., rule and subgoal ordering [42, 84]) and methods that use run-time bindings (combined with tabulation) to prune the search <ref> [8, 9, 93] </ref>. Therefore, the experimental validation presented here does not follow from experiments validating these other methods. Organization of the Paper The paper is organized as follows. Section 2 describes the space of definitions of irrelevance and compares properties of various definitions. <p> creating indices that will not be used. 14 Finally, it should be emphasized that the optimizations obtained by using the query-tree are orthogonal to those achieved by methods that derive optimal rule and goal orderings [42, 84] or methods that use run-time bindings (combined with tabulation) to prune the search <ref> [8, 9, 93] </ref>. Whereas these methods look for optimal ways to search the space, the query-tree identifies parts of the space that are guaranteed not to contain solutions and is independent of any run-time bindings. <p> It tells us which tuples in the database are guaranteed to be irrelevant to the query; therefore, we can apply a filter to the database relations as a first step in query evaluation. Moreover, the query-tree can also be combined with other optimization methods such as magic-sets <ref> [8, 9] </ref> and algorithms based on message-passing [91]. A novel query optimization algorithm for SQL queries, predicate move-around, based on the query-tree is described in [58].
Reference: [10] <author> J. A. Blakeley, N. Coburn, and P. A. Larson. </author> <title> Updating derived relations: detecting irrelevant and autonomously computable updates. </title> <journal> Transactions of Database Systems, </journal> <volume> 14(3) </volume> <pages> 369-400, </pages> <year> 1989. </year>
Reference-contexts: An important contribution of our framework is that it sheds light on the problem of detecting when a query is independent of an update <ref> [26, 10] </ref>. In [63], we show that the problem of independence of a query from a deletion update can be equivalently formulated as the problem of detecting weak irrelevance in our framework (specifically, detecting W I (; ; ; DI 1 ; D )).
Reference: [11] <author> Daniel Bobrow, </author> <title> editor. Qualitative reasoning about physical systems. </title> <publisher> North Holland, </publisher> <year> 1984. </year>
Reference-contexts: As a result, the representation is likely to be too complex for any given task, thereby leading to inefficient reasoning. * Modeling complex physical devices: Tasks such as diagnosis, design and simulation require a model of a given physical device <ref> [11, 22] </ref>. However, the adequacy of a model depends heavily on the task for which it is used, and reasoning directly with the most detailed model of the system would be intractable.
Reference: [12] <author> Alexander Borgida and Peter Patel-Schneider. </author> <title> A semantics and complete algorithm for subsumption in the CLASSIC description logic. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 277-308, </pages> <year> 1994. </year>
Reference-contexts: In particular, any description logic with decidable subsump tion can be viewed as a sort language (e.g. <ref> [12, 72, 6] </ref>). * Finite, given relation: Often, a given relation that is relatively small and stable can be best viewed as a constraint. Any given finite relation satisfies the properties that we require.
Reference: [13] <author> Alex Brodsky and Yehoshua Sagiv. </author> <title> On termination of datalog programs. </title> <editor> In J. M. Nico-las W. Kim and S. Nishio, editors, </editor> <booktitle> Deductive and Object-Oriented Databases, </booktitle> <pages> pages 47-64. </pages> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <year> 1990. </year>
Reference-contexts: Although, in general, there is no termination condition that will guarantee completeness of the query-tree, it is important to find limited cases in which it does, and to find cases in which it captures most irrelevance claims encountered in practice. Recent work on termination <ref> [13, 80, 79] </ref> may be helpful in this context. Acknowledgements The authors would like to thank Ed Feigenbaum, Michael Genesereth, Matt Ginsberg and Pandu Nayak for many discussions about the material presented in this paper.
Reference: [14] <author> Maurice Bruynooghe, Danny De-Schreye, and B. Krekels. </author> <title> Compiling control. </title> <journal> Journal of Logic Programming, </journal> <pages> pages (6) 135-162, </pages> <year> 1989. </year>
Reference-contexts: is p 1 ), and therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning [29, 81], partial evaluation of logic programs [85, 67, 15], 39 automated reasoning <ref> [52, 14] </ref>, and deductive databases [86, 89]. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis. <p> Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs <ref> [14] </ref>, tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis.
Reference: [15] <author> Maurice Bruynooghe, Danny De-Schreye, and Bern Martens. </author> <title> A general criterion for avoiding infinite unfolding during partial deduction of logic programs. </title> <booktitle> In Proceedings of the International Symposium on Logic Programming, </booktitle> <pages> pages 117-131, </pages> <year> 1991. </year>
Reference-contexts: Since interpreted predicates play a key role in many applications, this is an important feature of the query-tree. The query-tree can also be viewed as a tool for partial evaluation of constraint logic programs <ref> [85, 67, 15] </ref>, but is distinguished from previous work in that area in that it provides completeness also in the presence of recursive rules and interpreted predicates. * We describe experimental results that show that significant speedups (often orders of magnitude) are obtained by employing the query-tree in inference. <p> appears in a rule whose consequent is p 1 ), and therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning [29, 81], partial evaluation of logic programs <ref> [85, 67, 15] </ref>, 39 automated reasoning [52, 14], and deductive databases [86, 89]. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis.
Reference: [16] <author> R. Carnap. </author> <title> Logical Foundations of Probability. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1950. </year>
Reference-contexts: The notion of irrelevance has appeared in many contexts in research in AI and related fields. However, most of the time researchers use the term informally. Formal analyses of irrelevance have been discussed by philosophers as early as [47], <ref> [16] </ref> and [34]. The main thrust of these analyses was to try to capture our common-sense notions of irrelevance by a formal definition. Most of the work focuses on formulating properties of the notion of irrelevance and finding definitions that satisfy those properties. <p> Note that since the number of possible assignments for the free variables is finite, the set of answers to a query is finite. 5 Broadly, we can take two possible approaches to analyzing irrelevance. The first ap-proach, which has been pursued by several philosophers (e.g., <ref> [47, 16, 34] </ref>), is to try to capture our common-sense notion of irrelevance with a formal definition. In that approach, we would consider a formal definition of irrelevance and check whether it satisfies properties that we consider natural for our intuitive notion of irrelevance. <p> that are relevant to the query, and therefore which information sources need to be accessed. 15 In SQL terminology a predicate refers to a constraint in the query. 38 7 Related Work 7.1 Analysis of Irrelevance As mentioned earlier, the notion of irrelevance has been studied in the philosophy literature <ref> [47, 16, 34] </ref>, but the thrust of these works was to analyze the common-sense notion of irrelevance and not its computational uses. A related concept discussed in the formal logic community is relevance logics (e.g., [3, 24, 5]).
Reference: [17] <author> Ashok Chandra, Dexter Kozen, and Larry Stockmeyer. </author> <title> Alternation. </title> <journal> Journal of the ACM, </journal> <pages> pages 28(1): 114-133, </pages> <year> 1981. </year>
Reference-contexts: Furthermore, since the query-tree does not contain nodes with unsatisfiable labels, d must be a symbolic derivation in sat . 2 9.4 Proof of Theorem 4.3 The theorem is proved by reducing the acceptance problem of a linear-space alternating Turing machine (ATM) <ref> [17] </ref> to the problem of finding irrelevance of rules.
Reference: [18] <author> C. L. Chang. </author> <title> Resolution plans in theorem proving. </title> <booktitle> In Proceedings of the Sixth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 143-148, </pages> <year> 1979. </year>
Reference-contexts: However, connection graphs only capture a subset of the possible dependencies between clauses. Specifically, they only show that two clauses connected to a link are unifiable, but say nothing about the relationship between clauses connected via longer paths in the graph. Other work <ref> [83, 18] </ref> has considered following only certain walks on the graph. However, these walks are not guaranteed to encode valid derivations, as are the paths encoded in the query-tree. Work on connection graphs has also not considered semantics of interpreted predicates.
Reference: [19] <author> William J. Clancey. </author> <title> The advantages of abstract control knowledge in expert system design. </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence, </booktitle> <pages> pages 74-78, </pages> <address> Los Altos, CA, 1983. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: issue: * Although the speedups are significantly bigger using the first set of rules in each pair, we still achieve significant savings even when the rules are carefully crafted such that the constraints are used to control the search. * Writing rules with such built-in control has many disadvantages (see <ref> [19] </ref>). It is extremely difficult to write such rules in practice and is a very error-prone task. Consequently, we expect rules would usually be written without such crafting. * Crafting a set of rules with such built-in control can however be done easily using the query-tree.
Reference: [20] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation and application to logic programs. </title> <journal> Journal of Logic Programming, </journal> <volume> 13 (2-3):103-179, </volume> <year> 1992. </year>
Reference-contexts: Others have used rule folding/unfolding in their analysis. In all these works, the common idea is to evaluate the rules over an abstract interpretation of the domain <ref> [20] </ref>, i.e., to evaluate the rules over a domain consisting of abstract descriptions of possible domain elements. The key issue common to these works is when to terminate the application of the rules (i.e., when to terminate the the creation of the graph).
Reference: [21] <author> Adnan Darwiche. </author> <title> A logical notion of conditional independence. </title> <booktitle> In Working Notes of the AAAI Fall Symposium on Relevance, </booktitle> <month> November, </month> <year> 1994, 1994. </year>
Reference-contexts: Consequently, the work has not been concerned with how to use irrelevance for speeding up inference or how to design algorithms for detecting irrelevance. Within AI, the notion of irrelevance was investigated in the context of probabilistic reasoning <ref> [70, 21, 23] </ref> and used there to control inference in Bayesian belief networks. In the context of logical knowledge bases, Subramanian [88], and more recently Lakermeyer [53], investigated several formal definitions of irrelevance. <p> In contrast, our analysis of irrelevance assumes that the underlying logic remains unchanged. Within AI, the notion of irrelevance was used rather informally in various works, such as RLL [41] and compositional modeling [32]. Irrelevance was also investigated extensively in the context of probabilistic reasoning <ref> [70, 21, 23] </ref>. However, in that context, irrelevance has a natural definition based on the notion of conditional independence which does not carry over to the context of logical knowledge bases. The work most related to ours is the analysis of irrelevance given by Subramanian [87, 88].
Reference: [22] <author> Randall Davis. </author> <title> Diagnostic reasoning based on structure and behavior. </title> <journal> Artificial Intelligence, </journal> <volume> 24 </volume> <pages> 347-410, </pages> <year> 1984. </year>
Reference-contexts: As a result, the representation is likely to be too complex for any given task, thereby leading to inefficient reasoning. * Modeling complex physical devices: Tasks such as diagnosis, design and simulation require a model of a given physical device <ref> [11, 22] </ref>. However, the adequacy of a model depends heavily on the task for which it is used, and reasoning directly with the most detailed model of the system would be intractable.
Reference: [23] <author> Denise L. Draper. </author> <title> Relevance measures for localized partial evaluation of belief networks. </title> <booktitle> In Working Notes of the AAAI Fall Symposium on Relevance, </booktitle> <month> November, </month> <year> 1994, 1994. </year>
Reference-contexts: Consequently, the work has not been concerned with how to use irrelevance for speeding up inference or how to design algorithms for detecting irrelevance. Within AI, the notion of irrelevance was investigated in the context of probabilistic reasoning <ref> [70, 21, 23] </ref> and used there to control inference in Bayesian belief networks. In the context of logical knowledge bases, Subramanian [88], and more recently Lakermeyer [53], investigated several formal definitions of irrelevance. <p> In contrast, our analysis of irrelevance assumes that the underlying logic remains unchanged. Within AI, the notion of irrelevance was used rather informally in various works, such as RLL [41] and compositional modeling [32]. Irrelevance was also investigated extensively in the context of probabilistic reasoning <ref> [70, 21, 23] </ref>. However, in that context, irrelevance has a natural definition based on the notion of conditional independence which does not carry over to the context of logical knowledge bases. The work most related to ours is the analysis of irrelevance given by Subramanian [87, 88].
Reference: [24] <author> Michael Dunn. </author> <title> Relevance logic and entailment. </title> <editor> In Dov Gabbay and Franz Guenthner, editors, </editor> <booktitle> Handbook of Philosophical Logic, Volume III. Alternatives to Classical Logic, </booktitle> <pages> pages 117-224. </pages> <address> D. </address> <publisher> Reidel Publishing Company, Dordrecht, Holland, </publisher> <year> 1986. </year>
Reference-contexts: A related concept discussed in the formal logic community is relevance logics (e.g., <ref> [3, 24, 5] </ref>). The key idea in relevance logics is to modify the logic and the inference rules such that only relevant implications can be made. However, two issues are still largely open in this field.
Reference: [25] <author> Charles Elkan. </author> <title> A decision procedure for conjunctive query disjointness. </title> <booktitle> In Proceedings of the 8th ACM Symp. on Principles of Database Systems, </booktitle> <year> 1989. </year>
Reference-contexts: Typically, these procedures are efficient. For example, for conjunctive order constraints over dense domains, testing equivalence is cubic in the number of variables [89] (but over integers or when disjunctive constraints are allowd the problem is NP-hard. See <ref> [25] </ref> for a discussion of some of these issues). The properties we require are satisfied by a wide class of interpreted predicates.
Reference: [26] <author> Charles Elkan. </author> <title> Independence of logic database queries and updates. </title> <booktitle> In Proceedings of the 9th ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 154-160, </pages> <year> 1990. </year>
Reference-contexts: An important contribution of our framework is that it sheds light on the problem of detecting when a query is independent of an update <ref> [26, 10] </ref>. In [63], we show that the problem of independence of a query from a deletion update can be equivalently formulated as the problem of detecting weak irrelevance in our framework (specifically, detecting W I (; ; ; DI 1 ; D )).
Reference: [27] <author> Thomas Ellman. </author> <title> Abstraction via approximate symmetry. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 916-921, </pages> <year> 1993. </year>
Reference-contexts: Automatic creation of abstractions: Reasoning with multiple levels of abstraction is an effective method for reasoning in complex domains, and has been used in several fields of AI (e.g., planning [77, 50], theorem proving [73, 40] and constraint satisfaction <ref> [27] </ref>). An abstraction is obtained by removing some detail from the representation, such as collapsing a set of predicates into one denoting their union or projecting out arguments of relations.
Reference: [28] <author> Oren Etzioni. </author> <title> Why PRODIGY/EBL works. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference-contexts: In fact, explanation based learning systems [69] do exactly the opposite; that is, they add redundant rules (which, in our framework, would be considered weakly irrelevant). The utility of adding such rules is a subject of ongoing research (e.g., <ref> [68, 28, 44, 30] </ref>). For strong irrelevance, savings are guaranteed for many cases. For example, if the claim SI (; ; ; DI 2 ; D ) holds (i.e., all derivations of the query are considered), then deriving 12 from costs no more than deriving it from .
Reference: [29] <author> Oren Etzioni. </author> <title> Acquiring search-control knowledge via static analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 62, </volume> <year> 1993. </year>
Reference-contexts: depends on p 2 if p 2 appears in a rule whose consequent is p 1 ), and therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning <ref> [29, 81] </ref>, partial evaluation of logic programs [85, 67, 15], 39 automated reasoning [52, 14], and deductive databases [86, 89]. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. <p> Some have also used graph--like representations of the rules, such as problem space graphs <ref> [29] </ref>, connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis. <p> In EBL, new rules are added to the knowledge base that compress sequences of inference into a single rule. The key issue in this approach is the utility of the added rules [68, 30]. Adding too many rules may have the inverse effect of slowing down inference. Etzioni <ref> [29] </ref> has shown that much of the speedups obtained by EBL can be obtained by merely doing static analysis of the rules in the knowledge base.
Reference: [30] <author> Oren Etzioni and Steven Minton. </author> <title> Why EBL produces overly-specific knowledge: A critique of the PRODIGY approaches. </title> <booktitle> In Proceedings of the Machine Learning Conference, </booktitle> <year> 1992. </year>
Reference-contexts: A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. Irrelevance reasoning also plays an important role in nonmonotonic reasoning [71, 36, 7], belief revision [35] and learning (e.g., <ref> [30, 66, 74] </ref>). The focus of this paper is on using relevance reasoning to speed up inferences in large knowledge bases. <p> In fact, explanation based learning systems [69] do exactly the opposite; that is, they add redundant rules (which, in our framework, would be considered weakly irrelevant). The utility of adding such rules is a subject of ongoing research (e.g., <ref> [68, 28, 44, 30] </ref>). For strong irrelevance, savings are guaranteed for many cases. For example, if the claim SI (; ; ; DI 2 ; D ) holds (i.e., all derivations of the query are considered), then deriving 12 from costs no more than deriving it from . <p> The goal of Explanation Based Learning [69] is also to speed up inferences. In EBL, new rules are added to the knowledge base that compress sequences of inference into a single rule. The key issue in this approach is the utility of the added rules <ref> [68, 30] </ref>. Adding too many rules may have the inverse effect of slowing down inference. Etzioni [29] has shown that much of the speedups obtained by EBL can be obtained by merely doing static analysis of the rules in the knowledge base.
Reference: [31] <author> Oren Etzioni and Dan Weld. </author> <title> A softbot-based interface to the internet. </title> <journal> CACM, </journal> <volume> 37(7) </volume> <pages> 72-76, </pages> <year> 1994. </year>
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. <p> Such queries are usually complex (built from many sub-queries), and interpreted constraints play a major role in them. Predicate move-around is currently being implemented in a commercial decision support system. Information gathering in distributed heterogeneous environments: An important application of knowledge representation is the integration of multiple information sources <ref> [38, 4, 31, 60, 90] </ref>. So called mediator systems provide access to a large number of information sources (such as databases, knowledge bases and text files).
Reference: [32] <author> Brian Falkenhainer and Ken Forbus. </author> <title> Compositional modeling: Finding the right model for the job. </title> <journal> Artificial Intelligence, </journal> <volume> 51 </volume> <pages> 95-143, </pages> <year> 1991. </year>
Reference-contexts: In contrast, our analysis of irrelevance assumes that the underlying logic remains unchanged. Within AI, the notion of irrelevance was used rather informally in various works, such as RLL [41] and compositional modeling <ref> [32] </ref>. Irrelevance was also investigated extensively in the context of probabilistic reasoning [70, 21, 23]. However, in that context, irrelevance has a natural definition based on the notion of conditional independence which does not carry over to the context of logical knowledge bases.
Reference: [33] <author> Richard Fikes, Mark Cutkosky, Thomas Gruber, and Jeffrey Van Baalen. </author> <title> Knowledge sharing technology, project overview. </title> <note> Knowledge Systems Laboratory technical report No. KSL 91-71, </note> <year> 1991. </year>
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user.
Reference: [34] <author> Peter Gardenfors. </author> <title> On the logic of relevance. </title> <journal> Sythese, </journal> <volume> 37 </volume> <pages> 351-367, </pages> <year> 1978. </year>
Reference-contexts: The notion of irrelevance has appeared in many contexts in research in AI and related fields. However, most of the time researchers use the term informally. Formal analyses of irrelevance have been discussed by philosophers as early as [47], [16] and <ref> [34] </ref>. The main thrust of these analyses was to try to capture our common-sense notions of irrelevance by a formal definition. Most of the work focuses on formulating properties of the notion of irrelevance and finding definitions that satisfy those properties. <p> Note that since the number of possible assignments for the free variables is finite, the set of answers to a query is finite. 5 Broadly, we can take two possible approaches to analyzing irrelevance. The first ap-proach, which has been pursued by several philosophers (e.g., <ref> [47, 16, 34] </ref>), is to try to capture our common-sense notion of irrelevance with a formal definition. In that approach, we would consider a formal definition of irrelevance and check whether it satisfies properties that we consider natural for our intuitive notion of irrelevance. <p> In general, irrelevance claims in our space are not preserved under equivalence of the subject, query, or knowledge base. Although preservation under equivalence has been considered natural for a common-sense notion of irrelevance <ref> [34] </ref>, we believe that it is not necessarily appropriate when analyzing irrelevance for the purpose of speeding up inferences. Property A5 identifies some cases in which irrelevance claims are preserved under equivalence. Property A6 is similar in the sense that it shows when irrelevance claims are closed under negation. <p> that are relevant to the query, and therefore which information sources need to be accessed. 15 In SQL terminology a predicate refers to a constraint in the query. 38 7 Related Work 7.1 Analysis of Irrelevance As mentioned earlier, the notion of irrelevance has been studied in the philosophy literature <ref> [47, 16, 34] </ref>, but the thrust of these works was to analyze the common-sense notion of irrelevance and not its computational uses. A related concept discussed in the formal logic community is relevance logics (e.g., [3, 24, 5]).
Reference: [35] <author> Peter Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. Irrelevance reasoning also plays an important role in nonmonotonic reasoning [71, 36, 7], belief revision <ref> [35] </ref> and learning (e.g., [30, 66, 74]). The focus of this paper is on using relevance reasoning to speed up inferences in large knowledge bases.
Reference: [36] <author> Hector Geffner and Judea Pearl. </author> <title> A framework for reasoning with defaults. In H.E. </title> <editor> Kyburg, R. Loui, and G Carlson, editors, </editor> <title> Knowledge Representation and Defeasible Reasoning. </title> <publisher> Academic Press, </publisher> <address> Dordrecht, Netherlands, </address> <year> 1990. </year>
Reference-contexts: A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. Irrelevance reasoning also plays an important role in nonmonotonic reasoning <ref> [71, 36, 7] </ref>, belief revision [35] and learning (e.g., [30, 66, 74]). The focus of this paper is on using relevance reasoning to speed up inferences in large knowledge bases.
Reference: [37] <author> Michael R. Genesereth. </author> <title> An overview of metalevel architectures. </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence, </booktitle> <pages> pages 119-123, </pages> <address> Los Altos, CA, 1983. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Irrelevance reasoning is a specific form of meta-level reasoning <ref> [45, 37, 54] </ref>, in which we reason about the knowledge in the knowledge base, as opposed to using the knowledge base to reason about the domain.
Reference: [38] <author> Michael R. Genesereth. </author> <title> An agent-based framework for software interoperability. </title> <booktitle> In Proceedings of the Software Technology Conference, </booktitle> <address> Los Angeles, CA, </address> <year> 1992. </year>
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. <p> Such queries are usually complex (built from many sub-queries), and interpreted constraints play a major role in them. Predicate move-around is currently being implemented in a commercial decision support system. Information gathering in distributed heterogeneous environments: An important application of knowledge representation is the integration of multiple information sources <ref> [38, 4, 31, 60, 90] </ref>. So called mediator systems provide access to a large number of information sources (such as databases, knowledge bases and text files).
Reference: [39] <author> Michael R. Genesereth and Nils J. Nilsson. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1987. </year>
Reference-contexts: Tautologies can be shown to be weakly irrelevant (with respect to DI 1 and D ) and, therefore, are removed by the tautology elimination strategy <ref> [39] </ref>. 3 Automatically Deriving Irrelevance Claims A key question that we address in this article is how (and under what conditions) irrelevance claims can be derived automatically. Specifically, we are interested in two problems. <p> Using this relationship we obtain, in addition to the characterization of independence of deletion updates, also a complete characterization of independence of insertion updates. 5 A literal is pure if and only if it has no instance that is complementary to an instance of another literal in the knowledge base <ref> [39] </ref>. 14 two sets of predicates in the KB: base predicates (often called EDB predicates) and derived predicates (IDB predicates). The base predicates are those that appear in the ground facts of G. The derived predicates are those that appear in the consequents of the rules.
Reference: [40] <author> Fausto Giunchiglia and Toby Walsh. </author> <title> A theory of abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 56 (3), </volume> <month> October </month> <year> 1992. </year>
Reference-contexts: Automatic creation of abstractions: Reasoning with multiple levels of abstraction is an effective method for reasoning in complex domains, and has been used in several fields of AI (e.g., planning [77, 50], theorem proving <ref> [73, 40] </ref> and constraint satisfaction [27]). An abstraction is obtained by removing some detail from the representation, such as collapsing a set of predicates into one denoting their union or projecting out arguments of relations.
Reference: [41] <author> Russell Greiner. RLL-1: </author> <title> A representation language language. Stanford Heuristic Programming Project, </title> <note> HPP-80-9 (Working Paper), </note> <year> 1980. </year>
Reference-contexts: The first is devising clean and intuitive semantics for these logics, and the second is providing tractable inference for them. In contrast, our analysis of irrelevance assumes that the underlying logic remains unchanged. Within AI, the notion of irrelevance was used rather informally in various works, such as RLL <ref> [41] </ref> and compositional modeling [32]. Irrelevance was also investigated extensively in the context of probabilistic reasoning [70, 21, 23]. However, in that context, irrelevance has a natural definition based on the notion of conditional independence which does not carry over to the context of logical knowledge bases.
Reference: [42] <author> Russell Greiner. </author> <title> Finding optimal derivation strategies in a redundant knowledge base. </title> <journal> Artificial Intelligence, </journal> <volume> 50(1) </volume> <pages> 95-116, </pages> <year> 1991. </year>
Reference-contexts: Furthermore, the savings grow as the size of the knowledge base grows, indicating that our methods will scale up. It should be noted that the savings achieved by employing the query-tree are orthogonal to methods that develop optimal strategies for searching the space (e.g., rule and subgoal ordering <ref> [42, 84] </ref>) and methods that use run-time bindings (combined with tabulation) to prune the search [8, 9, 93]. Therefore, the experimental validation presented here does not follow from experiments validating these other methods. Organization of the Paper The paper is organized as follows. <p> This way one can avoid creating indices that will not be used. 14 Finally, it should be emphasized that the optimizations obtained by using the query-tree are orthogonal to those achieved by methods that derive optimal rule and goal orderings <ref> [42, 84] </ref> or methods that use run-time bindings (combined with tabulation) to prune the search [8, 9, 93]. Whereas these methods look for optimal ways to search the space, the query-tree identifies parts of the space that are guaranteed not to contain solutions and is independent of any run-time bindings. <p> The query-tree encodes exactly the space of derivations that an inference engine should search, thereby identifying parts of the space that can be safely ignored. Another approach to speeding up inference that was considered is finding optimal strategies for searching 40 a given space <ref> [84, 42, 43] </ref>. The query-tree can be used to complement and extend these methods in two ways. First, by delimiting the actual space that needs to be searched, some search paths can be eliminated from consideration when looking for the optimal search strategy. <p> The query-tree can be used to complement and extend these methods in two ways. First, by delimiting the actual space that needs to be searched, some search paths can be eliminated from consideration when looking for the optimal search strategy. Second, the methods described by Smith [84] and Greiner <ref> [42] </ref> require a graph-like representation of the possible derivations of the query. The query-tree provides such a representation which treats recursion and interpreted atoms in a principled way, unlike the representations that are currently used.
Reference: [43] <author> Russell Greiner. </author> <title> Learning efficient query processing strategies. </title> <booktitle> In Proceedings of the Eleventh ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <address> San Diego, CA., </address> <year> 1992. </year>
Reference-contexts: The query-tree encodes exactly the space of derivations that an inference engine should search, thereby identifying parts of the space that can be safely ignored. Another approach to speeding up inference that was considered is finding optimal strategies for searching 40 a given space <ref> [84, 42, 43] </ref>. The query-tree can be used to complement and extend these methods in two ways. First, by delimiting the actual space that needs to be searched, some search paths can be eliminated from consideration when looking for the optimal search strategy.
Reference: [44] <author> Russell Greiner and Igor Jurisica. </author> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <year> 1992. </year>
Reference-contexts: In fact, explanation based learning systems [69] do exactly the opposite; that is, they add redundant rules (which, in our framework, would be considered weakly irrelevant). The utility of adding such rules is a subject of ongoing research (e.g., <ref> [68, 28, 44, 30] </ref>). For strong irrelevance, savings are guaranteed for many cases. For example, if the claim SI (; ; ; DI 2 ; D ) holds (i.e., all derivations of the query are considered), then deriving 12 from costs no more than deriving it from .
Reference: [45] <author> Patrick J. Hayes. </author> <title> Computation and deduction. </title> <booktitle> In Proceedings of the 1973 Mathematical Foundations of Computer Science Symposium, </booktitle> <institution> Czechoslovakian Academy of Sciences, </institution> <year> 1973. </year>
Reference-contexts: Irrelevance reasoning is a specific form of meta-level reasoning <ref> [45, 37, 54] </ref>, in which we reason about the knowledge in the knowledge base, as opposed to using the knowledge base to reason about the domain.
Reference: [46] <author> Yumi Iwasaki and Alon Y. Levy. </author> <title> Automated model selection for simulation. </title> <booktitle> In Pro--ceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1183-1190, </pages> <year> 1994. </year>
Reference: [47] <author> J. M. </author> <title> Keynes. A Treatise on Probability. </title> <publisher> Macmillan, </publisher> <address> London, </address> <year> 1921. </year>
Reference-contexts: The notion of irrelevance has appeared in many contexts in research in AI and related fields. However, most of the time researchers use the term informally. Formal analyses of irrelevance have been discussed by philosophers as early as <ref> [47] </ref>, [16] and [34]. The main thrust of these analyses was to try to capture our common-sense notions of irrelevance by a formal definition. Most of the work focuses on formulating properties of the notion of irrelevance and finding definitions that satisfy those properties. <p> Note that since the number of possible assignments for the free variables is finite, the set of answers to a query is finite. 5 Broadly, we can take two possible approaches to analyzing irrelevance. The first ap-proach, which has been pursued by several philosophers (e.g., <ref> [47, 16, 34] </ref>), is to try to capture our common-sense notion of irrelevance with a formal definition. In that approach, we would consider a formal definition of irrelevance and check whether it satisfies properties that we consider natural for our intuitive notion of irrelevance. <p> that are relevant to the query, and therefore which information sources need to be accessed. 15 In SQL terminology a predicate refers to a constraint in the query. 38 7 Related Work 7.1 Analysis of Irrelevance As mentioned earlier, the notion of irrelevance has been studied in the philosophy literature <ref> [47, 16, 34] </ref>, but the thrust of these works was to analyze the common-sense notion of irrelevance and not its computational uses. A related concept discussed in the formal logic community is relevance logics (e.g., [3, 24, 5]).
Reference: [48] <author> M. Kifer. </author> <title> On safety, domain independence, and capturability of database queries. </title> <booktitle> In Proceedings of the International Conference on Data and Knowledge Bases, </booktitle> <address> Jerusalem, </address> <year> 1988. </year>
Reference-contexts: Language Strong Irrelevance Weak Irrelevance All Minimal Minimal Support All Derivations Derivations Derivations Derivations Horn rules with Decidable Decidable no recursion or constraints Follows from <ref> [48] </ref> Follows from [78] Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 [61] [55] Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1].
Reference: [49] <author> A. Klug. </author> <title> On conjunctive queries containing inequalities. </title> <journal> Journal of the ACM, </journal> <pages> pages 35(1): 146-160, </pages> <year> 1988. </year>
Reference-contexts: Language Strong Irrelevance Weak Irrelevance All Minimal Minimal Support All Derivations Derivations Derivations Derivations Horn rules with Decidable Decidable no recursion or constraints Follows from [48] Follows from [78] Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from <ref> [49] </ref> Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 [61] [55] Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1].
Reference: [50] <author> Craig A. Knoblock. </author> <title> Learning abstraction hierarchies for problem solving. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Los Altos, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In this section we briefly describe how our algorithms can be used in other applications of relevance reasoning. Automatic creation of abstractions: Reasoning with multiple levels of abstraction is an effective method for reasoning in complex domains, and has been used in several fields of AI (e.g., planning <ref> [77, 50] </ref>, theorem proving [73, 40] and constraint satisfaction [27]). An abstraction is obtained by removing some detail from the representation, such as collapsing a set of predicates into one denoting their union or projecting out arguments of relations.
Reference: [51] <author> Craig A. Knoblock and Alon Y. Levy, </author> <title> editors. </title> <booktitle> Working Notes of the AAAI Spring Symposium on Information Gathering from Heterogeneous Distributed Environments. American Association for Artificial Intelligence., </booktitle> <year> 1995. </year>
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user.
Reference: [52] <author> Robert Kowalski. </author> <title> A proof procedure using connection graphs. </title> <journal> Journal of the ACM, </journal> <pages> pages 22(4): 572-595, </pages> <year> 1975. </year>
Reference-contexts: is p 1 ), and therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning [29, 81], partial evaluation of logic programs [85, 67, 15], 39 automated reasoning <ref> [52, 14] </ref>, and deductive databases [86, 89]. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis. <p> Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs <ref> [52] </ref>, compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis. <p> As seen in Section 5, such control leads to significant speedups. This finer level of control cannot be achieved using their rules. Connection graphs <ref> [52] </ref> were also developed for the purpose of focusing a theorem prover by precomputing all the possible pairs of resolvable clauses.
Reference: [53] <author> Gerhard Lakermeyer. </author> <title> A logical account of relevance. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 853-859, </pages> <year> 1995. </year>
Reference-contexts: Within AI, the notion of irrelevance was investigated in the context of probabilistic reasoning [70, 21, 23] and used there to control inference in Bayesian belief networks. In the context of logical knowledge bases, Subramanian [88], and more recently Lakermeyer <ref> [53] </ref>, investigated several formal definitions of irrelevance. However, the issues of automatically deriving irrelevance claims and the utility of irrelevance reasoning were left largely open, and consequently relevance reasoning has not been applied in any effective way.
Reference: [54] <author> Douglas B. Lenat, Randall Davis, Jon Doyle, and Michael R. Genesereth. </author> <title> Reasoning about reasoning. </title> <editor> In Frederick Hayes-Roth, Donald A. Waterman, and Douglas B. Lenat, editors, </editor> <title> Building Expert Systems. </title> <publisher> Addison Wesley, </publisher> <address> Reading Mass., </address> <year> 1983. </year>
Reference-contexts: Irrelevance reasoning is a specific form of meta-level reasoning <ref> [45, 37, 54] </ref>, in which we reason about the knowledge in the knowledge base, as opposed to using the knowledge base to reason about the domain.
Reference: [55] <author> Alon Y. Levy. </author> <title> Irrelevance Reasoning in Knowledge Based Systems. </title> <type> PhD thesis, </type> <institution> Stan-ford University, Stanford, </institution> <address> CA, </address> <year> 1993. </year>
Reference-contexts: Strong Irrelevance Weak Irrelevance All Minimal Minimal Support All Derivations Derivations Derivations Derivations Horn rules with Decidable Decidable no recursion or constraints Follows from [48] Follows from [78] Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 [61] <ref> [55] </ref> Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1]. Function-free Horn with Undecidable Stratified Negation Lemma 9.2 [55] Lemma 9.1 Function-free Horn with Decidable Undecidable negated base predicates Section 4 + [59] [55] Lemma 9.1 Datalog with unary <p> Derivations Horn rules with Decidable Decidable no recursion or constraints Follows from [48] Follows from [78] Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 [61] <ref> [55] </ref> Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1]. Function-free Horn with Undecidable Stratified Negation Lemma 9.2 [55] Lemma 9.1 Function-free Horn with Decidable Undecidable negated base predicates Section 4 + [59] [55] Lemma 9.1 Datalog with unary base Decidable predicates [59] Table 1: Decidability of deriving irrelevance claims 4 <p> Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 [61] <ref> [55] </ref> Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1]. Function-free Horn with Undecidable Stratified Negation Lemma 9.2 [55] Lemma 9.1 Function-free Horn with Decidable Undecidable negated base predicates Section 4 + [59] [55] Lemma 9.1 Datalog with unary base Decidable predicates [59] Table 1: Decidability of deriving irrelevance claims 4 The Query-tree Deriving strong irrelevance claims requires that we meet several challenges. <p> constraints (datalog) Section 4 [61] <ref> [55] </ref> Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1]. Function-free Horn with Undecidable Stratified Negation Lemma 9.2 [55] Lemma 9.1 Function-free Horn with Decidable Undecidable negated base predicates Section 4 + [59] [55] Lemma 9.1 Datalog with unary base Decidable predicates [59] Table 1: Decidability of deriving irrelevance claims 4 The Query-tree Deriving strong irrelevance claims requires that we meet several challenges. <p> Section 4.2 describes the algorithm for constructing the query-tree, and Section 4.3 discusses the complexity of building the query-tree. The query-tree algorithm, as we describe here, is an instance of a general method for encoding sets of derivations <ref> [55] </ref>. Intuitively, by changing the contents of node labels in the query-tree, it can be designed to encode various sets of derivations (e.g., minimal derivations), and therefore, used for deriving other strong irrelevance claims. <p> problem of a linear-space alternating Turing machine (ATM) to the problem of detecting strong irrelevance of rules. 4.4 Extensions of the Query-Tree The Query-Tree Method: The query-tree algorithm, as described above, is one instance of a general method for encoding a possibly infinite set of derivations via a finite structure <ref> [55, 61, 59, 64] </ref>. The method is based on encoding an infinite number of derivations by identifying a labeling scheme, i.e., a finite set of labels, such that terminating the construction of the tree based on label equivalence guarantees that the query-tree encodes exactly a desired set of derivations. <p> Inferring Irrelevance claims from External Sources: As stated earlier, irrelevance claims can either be derived solely based on inspecting (parts of ) the knowledge base, or can be inferred from irrelevance claims that are given by a user. In <ref> [55, 62] </ref>, it is shown that even for strong irrelevance, deriving all the irrelevance claims that follow from a given irrelevance claim is undecidable in function-free Horn rule theories. However, the query-tree can be used as a sound inference procedure for irrelevance claims. <p> As a result, facts that can only be parts of derivations of the query that contain f (and are therefore strongly irrelevant if f is strongly irrelevant) will also not appear in the query-tree. The details of the algorithm are described in <ref> [55] </ref>. 5 Using the Query-Tree to Speed Up Inferences In this section, we explore two ways in which the query-tree can be used to speed up inferences. In the first, the query-tree is used to decide which ground facts and rules are strongly irrelevant to a given class of queries.
Reference: [56] <author> Alon Y. Levy. </author> <title> Creating abstractions using relevance reasoning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 588-594, </pages> <year> 1994. </year>
Reference-contexts: In this paper, we consider the case in which is a fact or set of facts. Other irrelevance subjects, such as objects, relation arguments and refinements of predicates are discussed briefly in Section 6 and in more detail in <ref> [56] </ref>. 2 Alternative definitions are also possible. For example, in the case of a closed-formula query, one might return unknown if neither nor : is derivable; in the case of a query with free variables, one might return just the first variable binding that satisfies the query. <p> An abstraction will be useful if the detail removed is irrelevant to the particular query, i.e., any answer obtained in the abstract theory holds in the original one as well. Otherwise the system will have to backtrack between different representations. In <ref> [56] </ref> we describe a generalization of the framework discussed in this paper, where we consider different subjects of irrelevance, such as arguments of relations and distinctions between predicates.
Reference: [57] <author> Alon Y. Levy, Richard E. Fikes, and Yehoshua Sagiv. </author> <title> A proof-theoretic approach to irrelevance: </title> <booktitle> Foundations and applications. In Working Notes of the AAAI Fall Symposium on Relevance, </booktitle> <month> November, </month> <year> 1994, 1994. </year>
Reference-contexts: In fact, the inability of current AI systems to ignore irrelevant information is a major obstacle in scaling up such systems. Irrelevance reasoning refers to the process in 1 This paper consists of material that was earlier published in several conference papers <ref> [61, 62, 57] </ref>. 1 which the system reasons about which parts of its knowledge are relevant (or irrelevant) to a specific query, either by automatically inspecting the knowledge base or by exploiting explicit irrelevance-claims given by a user.
Reference: [58] <author> Alon Y. Levy, Inderpal Singh Mumick, and Yehoshua Sagiv. </author> <title> Query optimization by predicate move-around. </title> <booktitle> In Proceedings of the 20th VLDB Conference, Santiago, Chile, </booktitle> <pages> pages 96-107, </pages> <year> 1994. </year>
Reference-contexts: Moreover, the query-tree can also be combined with other optimization methods such as magic-sets [8, 9] and algorithms based on message-passing [91]. A novel query optimization algorithm for SQL queries, predicate move-around, based on the query-tree is described in <ref> [58] </ref>. The predicate move-around 15 algorithm is an extension of the query-tree that deals with additional features of SQL such as aggregate queries (Min, Max, Avg), functional dependencies, and negation.
Reference: [59] <author> Alon Y. Levy, Inderpal Singh Mumick, Yehoshua Sagiv, and Oded Shmueli. </author> <title> Equivalence, query-reachability and satisfiability in datalog extensions. </title> <booktitle> In Proceedings of 57 the Twelfth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <address> Washington D.C., </address> <pages> pages 109-122, </pages> <year> 1993. </year>
Reference-contexts: Function-free Horn with Undecidable Stratified Negation Lemma 9.2 [55] Lemma 9.1 Function-free Horn with Decidable Undecidable negated base predicates Section 4 + <ref> [59] </ref> [55] Lemma 9.1 Datalog with unary base Decidable predicates [59] Table 1: Decidability of deriving irrelevance claims 4 The Query-tree Deriving strong irrelevance claims requires that we meet several challenges. <p> Function-free Horn with Undecidable Stratified Negation Lemma 9.2 [55] Lemma 9.1 Function-free Horn with Decidable Undecidable negated base predicates Section 4 + <ref> [59] </ref> [55] Lemma 9.1 Datalog with unary base Decidable predicates [59] Table 1: Decidability of deriving irrelevance claims 4 The Query-tree Deriving strong irrelevance claims requires that we meet several challenges. <p> problem of a linear-space alternating Turing machine (ATM) to the problem of detecting strong irrelevance of rules. 4.4 Extensions of the Query-Tree The Query-Tree Method: The query-tree algorithm, as described above, is one instance of a general method for encoding a possibly infinite set of derivations via a finite structure <ref> [55, 61, 59, 64] </ref>. The method is based on encoding an infinite number of derivations by identifying a labeling scheme, i.e., a finite set of labels, such that terminating the construction of the tree based on label equivalence guarantees that the query-tree encodes exactly a desired set of derivations. <p> EDB-labels: The label of a node includes information on negative and positive literals that can appear in the derivation tree. Using these labels, we encode exactly the set of satisfiable derivations when rules include negated base predicates in the antecedents <ref> [59] </ref>. 27 3. IC-labels: The label of a node includes partial instantiations of integrity constraints (i.e., clauses with only negative literals) that are satisfied by the derivation tree. Using this labeling schemes we can decide strong irrelevance for some classes of Horn theories that include integrity constraints [64].
Reference: [60] <author> Alon Y. Levy, Anand Rajaraman, and Joann J. Ordille. </author> <title> Query answering algorithms for information agents. </title> <booktitle> In Proceedings of the AAAI Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 40-47, </pages> <year> 1996. </year>
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. <p> Such queries are usually complex (built from many sub-queries), and interpreted constraints play a major role in them. Predicate move-around is currently being implemented in a commercial decision support system. Information gathering in distributed heterogeneous environments: An important application of knowledge representation is the integration of multiple information sources <ref> [38, 4, 31, 60, 90] </ref>. So called mediator systems provide access to a large number of information sources (such as databases, knowledge bases and text files).
Reference: [61] <author> Alon Y. Levy and Yehoshua Sagiv. </author> <title> Constraints and redundancy in Datalog. </title> <booktitle> In The Proceedings of the Eleventh ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <address> San Diego, CA., </address> <pages> pages 67-80, </pages> <year> 1992. </year>
Reference-contexts: In fact, the inability of current AI systems to ignore irrelevant information is a major obstacle in scaling up such systems. Irrelevance reasoning refers to the process in 1 This paper consists of material that was earlier published in several conference papers <ref> [61, 62, 57] </ref>. 1 which the system reasons about which parts of its knowledge are relevant (or irrelevant) to a specific query, either by automatically inspecting the knowledge base or by exploiting explicit irrelevance-claims given by a user. <p> The notion of irrelevance discussed by Levy and Sagiv in <ref> [61] </ref> can be couched in our framework as SI (; ; ; DI 2 ; D m ), where D m is the set of all minimal derivations of the query. Finally, several resolution strategies are based on removing irrelevant clauses. <p> Language Strong Irrelevance Weak Irrelevance All Minimal Minimal Support All Derivations Derivations Derivations Derivations Horn rules with Decidable Decidable no recursion or constraints Follows from [48] Follows from [78] Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 <ref> [61] </ref> [55] Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1]. <p> Derivations Derivations Horn rules with Decidable Decidable no recursion or constraints Follows from [48] Follows from [78] Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 <ref> [61] </ref> [55] Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1]. <p> problem of a linear-space alternating Turing machine (ATM) to the problem of detecting strong irrelevance of rules. 4.4 Extensions of the Query-Tree The Query-Tree Method: The query-tree algorithm, as described above, is one instance of a general method for encoding a possibly infinite set of derivations via a finite structure <ref> [55, 61, 59, 64] </ref>. The method is based on encoding an infinite number of derivations by identifying a labeling scheme, i.e., a finite set of labels, such that terminating the construction of the tree based on label equivalence guarantees that the query-tree encodes exactly a desired set of derivations. <p> Tag labels: The label of a node also includes information on the ancestry of that node. As a result, the query-tree encodes exactly the set of minimal derivations of the query <ref> [61] </ref>. 2. EDB-labels: The label of a node includes information on negative and positive literals that can appear in the derivation tree. Using these labels, we encode exactly the set of satisfiable derivations when rules include negated base predicates in the antecedents [59]. 27 3.
Reference: [62] <author> Alon Y. Levy and Yehoshua Sagiv. </author> <title> Exploiting irrelevance reasoning to guide problem solving. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 138-144, </pages> <year> 1993. </year>
Reference-contexts: In fact, the inability of current AI systems to ignore irrelevant information is a major obstacle in scaling up such systems. Irrelevance reasoning refers to the process in 1 This paper consists of material that was earlier published in several conference papers <ref> [61, 62, 57] </ref>. 1 which the system reasons about which parts of its knowledge are relevant (or irrelevant) to a specific query, either by automatically inspecting the knowledge base or by exploiting explicit irrelevance-claims given by a user. <p> Inferring Irrelevance claims from External Sources: As stated earlier, irrelevance claims can either be derived solely based on inspecting (parts of ) the knowledge base, or can be inferred from irrelevance claims that are given by a user. In <ref> [55, 62] </ref>, it is shown that even for strong irrelevance, deriving all the irrelevance claims that follow from a given irrelevance claim is undecidable in function-free Horn rule theories. However, the query-tree can be used as a sound inference procedure for irrelevance claims.
Reference: [63] <author> Alon Y. Levy and Yehoshua Sagiv. </author> <title> Queries independent of updates. </title> <booktitle> In Proceedings of the 19th VLDB Conference, Dublin, Ireland, </booktitle> <pages> pages 171-181, </pages> <year> 1993. </year>
Reference-contexts: An important contribution of our framework is that it sheds light on the problem of detecting when a query is independent of an update [26, 10]. In <ref> [63] </ref>, we show that the problem of independence of a query from a deletion update can be equivalently formulated as the problem of detecting weak irrelevance in our framework (specifically, detecting W I (; ; ; DI 1 ; D )). <p> Identifying this relationship has led to the development of novel algorithms for detecting independence, based on algorithms for determining strong and weak irrelevance (see <ref> [63] </ref> for details). 4 A definition of irrelevance is described by Srivastava and Ramakrishnan in [86].
Reference: [64] <author> Alon Y. Levy and Yehoshua Sagiv. </author> <title> Semantic query optimization in datalog programs. </title> <booktitle> In Proceedings of the 14th ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <address> San Jose, CA, </address> <pages> pages 163-173, </pages> <year> 1995. </year>
Reference-contexts: problem of a linear-space alternating Turing machine (ATM) to the problem of detecting strong irrelevance of rules. 4.4 Extensions of the Query-Tree The Query-Tree Method: The query-tree algorithm, as described above, is one instance of a general method for encoding a possibly infinite set of derivations via a finite structure <ref> [55, 61, 59, 64] </ref>. The method is based on encoding an infinite number of derivations by identifying a labeling scheme, i.e., a finite set of labels, such that terminating the construction of the tree based on label equivalence guarantees that the query-tree encodes exactly a desired set of derivations. <p> IC-labels: The label of a node includes partial instantiations of integrity constraints (i.e., clauses with only negative literals) that are satisfied by the derivation tree. Using this labeling schemes we can decide strong irrelevance for some classes of Horn theories that include integrity constraints <ref> [64] </ref>. Relaxing the Finiteness Property: The most stringent requirement we imposed on the constraint language is the Finiteness Property, which requires that we can only generate a finite number of labels on the predicates, using operations of join, selection, and projection.
Reference: [65] <author> Alon Y. Levy, Divesh Srivastava, and Thomas Kirk. </author> <title> Data model and query evaluation in global information systems. </title> <journal> Journal of Intelligent Information Systems, </journal> <note> Special Issue on Networked Information Discovery and Retrieval, 5 (2), </note> <month> September </month> <year> 1995. </year>
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. <p> The application of our framework and algorithms to such a setting is described in <ref> [65] </ref>. In [65] as in the TSIMMIS system [90], a mediator contains a set of Horn rules describing how to combine information from the various sources. In such an architecture, the information sources are viewed as containing the base relations, and their descriptions provide integrity constraints on these relations. <p> The application of our framework and algorithms to such a setting is described in <ref> [65] </ref>. In [65] as in the TSIMMIS system [90], a mediator contains a set of Horn rules describing how to combine information from the various sources. In such an architecture, the information sources are viewed as containing the base relations, and their descriptions provide integrity constraints on these relations.
Reference: [66] <author> Nick Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. Irrelevance reasoning also plays an important role in nonmonotonic reasoning [71, 36, 7], belief revision [35] and learning (e.g., <ref> [30, 66, 74] </ref>). The focus of this paper is on using relevance reasoning to speed up inferences in large knowledge bases.
Reference: [67] <author> J.W. Lloyd and J.C. Shepherdson. </author> <title> Partial evaluation in logic programming. </title> <journal> Journal of Logic Programming, </journal> (11):217-242, 1991. 
Reference-contexts: Since interpreted predicates play a key role in many applications, this is an important feature of the query-tree. The query-tree can also be viewed as a tool for partial evaluation of constraint logic programs <ref> [85, 67, 15] </ref>, but is distinguished from previous work in that area in that it provides completeness also in the presence of recursive rules and interpreted predicates. * We describe experimental results that show that significant speedups (often orders of magnitude) are obtained by employing the query-tree in inference. <p> appears in a rule whose consequent is p 1 ), and therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning [29, 81], partial evaluation of logic programs <ref> [85, 67, 15] </ref>, 39 automated reasoning [52, 14], and deductive databases [86, 89]. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis.
Reference: [68] <author> Steve Minton. </author> <title> Quantitative results concerning the utility of explanation based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference-contexts: In fact, explanation based learning systems [69] do exactly the opposite; that is, they add redundant rules (which, in our framework, would be considered weakly irrelevant). The utility of adding such rules is a subject of ongoing research (e.g., <ref> [68, 28, 44, 30] </ref>). For strong irrelevance, savings are guaranteed for many cases. For example, if the claim SI (; ; ; DI 2 ; D ) holds (i.e., all derivations of the query are considered), then deriving 12 from costs no more than deriving it from . <p> The goal of Explanation Based Learning [69] is also to speed up inferences. In EBL, new rules are added to the knowledge base that compress sequences of inference into a single rule. The key issue in this approach is the utility of the added rules <ref> [68, 30] </ref>. Adding too many rules may have the inverse effect of slowing down inference. Etzioni [29] has shown that much of the speedups obtained by EBL can be obtained by merely doing static analysis of the rules in the knowledge base.
Reference: [69] <author> Steven Minton, Jaime Carbonell, Craig Knoblock, D. Kuokka, Oren Etzioni, and Yolanda Gil. </author> <title> Explanation based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40 </volume> <pages> 63-118, </pages> <year> 1989. </year>
Reference-contexts: However, the utility of removing an irrelevant fact is a more subtle issue. Removing a fact that is only weakly irrelevant may not speed up inference. In fact, explanation based learning systems <ref> [69] </ref> do exactly the opposite; that is, they add redundant rules (which, in our framework, would be considered weakly irrelevant). The utility of adding such rules is a subject of ongoing research (e.g., [68, 28, 44, 30]). For strong irrelevance, savings are guaranteed for many cases. <p> The query-tree provides such a representation which treats recursion and interpreted atoms in a principled way, unlike the representations that are currently used. Consequently, it can be used as a basis for extending such techniques to fully incorporate knowledge about interpreted atoms. The goal of Explanation Based Learning <ref> [69] </ref> is also to speed up inferences. In EBL, new rules are added to the knowledge base that compress sequences of inference into a single rule. The key issue in this approach is the utility of the added rules [68, 30].
Reference: [70] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: Consequently, the work has not been concerned with how to use irrelevance for speeding up inference or how to design algorithms for detecting irrelevance. Within AI, the notion of irrelevance was investigated in the context of probabilistic reasoning <ref> [70, 21, 23] </ref> and used there to control inference in Bayesian belief networks. In the context of logical knowledge bases, Subramanian [88], and more recently Lakermeyer [53], investigated several formal definitions of irrelevance. <p> In contrast, our analysis of irrelevance assumes that the underlying logic remains unchanged. Within AI, the notion of irrelevance was used rather informally in various works, such as RLL [41] and compositional modeling [32]. Irrelevance was also investigated extensively in the context of probabilistic reasoning <ref> [70, 21, 23] </ref>. However, in that context, irrelevance has a natural definition based on the notion of conditional independence which does not carry over to the context of logical knowledge bases. The work most related to ours is the analysis of irrelevance given by Subramanian [87, 88].
Reference: [71] <author> Judea Pearl. </author> <title> System Z: A natural ordering of defaults with tractable applications to nonmonotic reasoning. </title> <editor> In Moshe Y. Vardi, editor, </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 121-135. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference-contexts: A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. Irrelevance reasoning also plays an important role in nonmonotonic reasoning <ref> [71, 36, 7] </ref>, belief revision [35] and learning (e.g., [30, 66, 74]). The focus of this paper is on using relevance reasoning to speed up inferences in large knowledge bases.
Reference: [72] <author> C. Petalson. </author> <title> The BACK system : an overview. </title> <journal> In Proceedings of the SIGART bulletin, </journal> <volume> volume 2(3), </volume> <pages> pages 114-119, </pages> <year> 1991. </year> <month> 58 </month>
Reference-contexts: In particular, any description logic with decidable subsump tion can be viewed as a sort language (e.g. <ref> [12, 72, 6] </ref>). * Finite, given relation: Often, a given relation that is relatively small and stable can be best viewed as a constraint. Any given finite relation satisfies the properties that we require.
Reference: [73] <author> D. Plaisted. </author> <title> Theorem proving with abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 16 </volume> <pages> 47-108, </pages> <year> 1981. </year>
Reference-contexts: Automatic creation of abstractions: Reasoning with multiple levels of abstraction is an effective method for reasoning in complex domains, and has been used in several fields of AI (e.g., planning [77, 50], theorem proving <ref> [73, 40] </ref> and constraint satisfaction [27]). An abstraction is obtained by removing some detail from the representation, such as collapsing a set of predicates into one denoting their union or projecting out arguments of relations.
Reference: [74] <author> R. Bharat Rao, Russell Greiner, and Tom Hancock. </author> <title> Exploiting the absence of irrelevant information: What you don't know can help you. </title> <booktitle> In Working Notes of the AAAI Fall Symposium on Relevance, </booktitle> <month> November, </month> <year> 1994, 1994. </year>
Reference-contexts: A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. Irrelevance reasoning also plays an important role in nonmonotonic reasoning [71, 36, 7], belief revision [35] and learning (e.g., <ref> [30, 66, 74] </ref>). The focus of this paper is on using relevance reasoning to speed up inferences in large knowledge bases.
Reference: [75] <author> Irma S. Rombauer and Marion Rombauer-Becker. </author> <title> Joy of Cooking. </title> <publisher> Bobbs Merrill Company Inc., </publisher> <address> N.Y.C., N.Y, </address> <year> 1975. </year>
Reference-contexts: A wine domain consisting of a knowledge base of 50 rules describing various wines and dishes and compatibilities between them (based in part on <ref> [75] </ref>) (examples 7-8). 3. A student-advisor domain using a knowledge base about computer science Ph.D grad uates, including advisor, school and graduation dates (examples 9-10). 4. The goodP ath example, using the rules in Example 2 (examples 1-2).
Reference: [76] <author> Stuart Russell. </author> <title> The complete guide to MRS. </title> <type> Technical Report KSL-85-12, </type> <institution> Knowledge Systems Laboratory, Department of Computer Science, Stanford University, </institution> <address> CA, </address> <year> 1985. </year>
Reference-contexts: In the third domain, search trees have a low branching factor (which was from student to advisor). 11 The speedups attained by removing irrelevant facts (the ratio of BC1 to BC2) were also tested using the backward chainer of Epikit (a commercial implementation of MRS <ref> [76] </ref>) and with Quintus Prolog. The speedups attained were even better than those reported here. However, we could not use these tools for testing BC3 because we could not modify the control of the backward chainers. In the experiments, we tested several rule and goal orderings.
Reference: [77] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: In this section we briefly describe how our algorithms can be used in other applications of relevance reasoning. Automatic creation of abstractions: Reasoning with multiple levels of abstraction is an effective method for reasoning in complex domains, and has been used in several fields of AI (e.g., planning <ref> [77, 50] </ref>, theorem proving [73, 40] and constraint satisfaction [27]). An abstraction is obtained by removing some detail from the representation, such as collapsing a set of predicates into one denoting their union or projecting out arguments of relations.
Reference: [78] <author> Y. Sagiv and M. Yannakakis. </author> <title> Equivalence among relational expressions with the union and difference operators. </title> <journal> Journal of the ACM, </journal> <volume> 27(4) </volume> <pages> 633-655, </pages> <year> 1981. </year>
Reference-contexts: Language Strong Irrelevance Weak Irrelevance All Minimal Minimal Support All Derivations Derivations Derivations Derivations Horn rules with Decidable Decidable no recursion or constraints Follows from [48] Follows from <ref> [78] </ref> Non-recursive Horn Decidable Decidable with constraints Section 4 Follows from [49] Recursive function-free Decidable Undecidable Horn, no constraints (datalog) Section 4 [61] [55] Lemma 9.1 Function-free Horn with Decidable Undecidable constraints Section 4 [61] [55] Lemma 9.1 Arbitrary Horn rules Undecidable Follows from [1].
Reference: [79] <author> Yehoshua Sagiv. </author> <title> On testing effective computability of magic programs. </title> <editor> In C. Delobel, M. Kifer, and Y. Masunaga, editors, </editor> <booktitle> Proceedings of the Second International Conference on Deductive and Object-Oriented Databases, </booktitle> <address> Munich, Germany., </address> <pages> pages 244-262, </pages> <year> 1991. </year>
Reference-contexts: Although, in general, there is no termination condition that will guarantee completeness of the query-tree, it is important to find limited cases in which it does, and to find cases in which it captures most irrelevance claims encountered in practice. Recent work on termination <ref> [13, 80, 79] </ref> may be helpful in this context. Acknowledgements The authors would like to thank Ed Feigenbaum, Michael Genesereth, Matt Ginsberg and Pandu Nayak for many discussions about the material presented in this paper.
Reference: [80] <author> Yehoshua Sagiv. </author> <title> A termination test for logic programs. </title> <editor> In V. Saraswat and K. Ueda, editors, </editor> <booktitle> Proceedings of the 1991 International Symposium on Logic Programming, </booktitle> <pages> pages 518-532. </pages> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Although, in general, there is no termination condition that will guarantee completeness of the query-tree, it is important to find limited cases in which it does, and to find cases in which it captures most irrelevance claims encountered in practice. Recent work on termination <ref> [13, 80, 79] </ref> may be helpful in this context. Acknowledgements The authors would like to thank Ed Feigenbaum, Michael Genesereth, Matt Ginsberg and Pandu Nayak for many discussions about the material presented in this paper.
Reference: [81] <author> A. Segre and C. Elkan. </author> <title> A high-performance explanation-based learning algorithm. </title> <journal> Artificial Intelligence, </journal> <volume> 69 </volume> <pages> 1-50, </pages> <year> 1994. </year>
Reference-contexts: depends on p 2 if p 2 appears in a rule whose consequent is p 1 ), and therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning <ref> [29, 81] </ref>, partial evaluation of logic programs [85, 67, 15], 39 automated reasoning [52, 14], and deductive databases [86, 89]. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89].
Reference: [82] <author> Oded Shmueli. </author> <title> Equivalence of datalog queries is undecidable. </title> <journal> Journal of Logic Programming, </journal> <volume> 15 </volume> <pages> 231-241, </pages> <year> 1993. </year>
Reference-contexts: Conversely, if r is redundant, that means that for every 2 P , if is derivable, there is a derivation that doesn't contain r. Therefore, W I (r; ; P ; DI 2 ; D ) holds. However, it follows from <ref> [82] </ref> that determining redundancy of rules is undecidable for datalog theories even without interpreted predicates. Therefore, weak irrelevance is undecidable. 2 The next lemma shows that strong irrelevance is undecidable when we allow the rules to have stratified negation. <p> The two sets of rules are said to equivalent if P 1 P 2 and P 2 P 1 . Testing equivalence of two function-free sets of rules is undecidable <ref> [82] </ref>.
Reference: [83] <author> Susan Sickel. </author> <title> A search technique for clause interconnectivity graphs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-25(8):823-835, </volume> <year> 1976. </year>
Reference-contexts: However, connection graphs only capture a subset of the possible dependencies between clauses. Specifically, they only show that two clauses connected to a link are unifiable, but say nothing about the relationship between clauses connected via longer paths in the graph. Other work <ref> [83, 18] </ref> has considered following only certain walks on the graph. However, these walks are not guaranteed to encode valid derivations, as are the paths encoded in the query-tree. Work on connection graphs has also not considered semantics of interpreted predicates.
Reference: [84] <author> David Smith. </author> <title> Controlling Inference. </title> <type> PhD thesis, </type> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <year> 1986. </year>
Reference-contexts: Furthermore, the savings grow as the size of the knowledge base grows, indicating that our methods will scale up. It should be noted that the savings achieved by employing the query-tree are orthogonal to methods that develop optimal strategies for searching the space (e.g., rule and subgoal ordering <ref> [42, 84] </ref>) and methods that use run-time bindings (combined with tabulation) to prune the search [8, 9, 93]. Therefore, the experimental validation presented here does not follow from experiments validating these other methods. Organization of the Paper The paper is organized as follows. <p> This way one can avoid creating indices that will not be used. 14 Finally, it should be emphasized that the optimizations obtained by using the query-tree are orthogonal to those achieved by methods that derive optimal rule and goal orderings <ref> [42, 84] </ref> or methods that use run-time bindings (combined with tabulation) to prune the search [8, 9, 93]. Whereas these methods look for optimal ways to search the space, the query-tree identifies parts of the space that are guaranteed not to contain solutions and is independent of any run-time bindings. <p> The query-tree encodes exactly the space of derivations that an inference engine should search, thereby identifying parts of the space that can be safely ignored. Another approach to speeding up inference that was considered is finding optimal strategies for searching 40 a given space <ref> [84, 42, 43] </ref>. The query-tree can be used to complement and extend these methods in two ways. First, by delimiting the actual space that needs to be searched, some search paths can be eliminated from consideration when looking for the optimal search strategy. <p> The query-tree can be used to complement and extend these methods in two ways. First, by delimiting the actual space that needs to be searched, some search paths can be eliminated from consideration when looking for the optimal search strategy. Second, the methods described by Smith <ref> [84] </ref> and Greiner [42] require a graph-like representation of the possible derivations of the query. The query-tree provides such a representation which treats recursion and interpreted atoms in a principled way, unlike the representations that are currently used.
Reference: [85] <author> Donald A. Smith and Timothy J. Hickey. </author> <title> Partial evaluation of a CLP language. </title> <booktitle> In Proceedings of the International Symposium on Logic Programming, </booktitle> <pages> pages 119-138, </pages> <year> 1990. </year>
Reference-contexts: Since interpreted predicates play a key role in many applications, this is an important feature of the query-tree. The query-tree can also be viewed as a tool for partial evaluation of constraint logic programs <ref> [85, 67, 15] </ref>, but is distinguished from previous work in that area in that it provides completeness also in the presence of recursive rules and interpreted predicates. * We describe experimental results that show that significant speedups (often orders of magnitude) are obtained by employing the query-tree in inference. <p> appears in a rule whose consequent is p 1 ), and therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning [29, 81], partial evaluation of logic programs <ref> [85, 67, 15] </ref>, 39 automated reasoning [52, 14], and deductive databases [86, 89]. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis.
Reference: [86] <author> Divesh Srivastava and Raghu Ramakrishnan. </author> <title> Pushing constraint selections. </title> <journal> Journal of Logic Programming, </journal> <volume> 16(3-4):361-414, </volume> <year> 1993. </year>
Reference-contexts: Identifying this relationship has led to the development of novel algorithms for detecting independence, based on algorithms for determining strong and weak irrelevance (see [63] for details). 4 A definition of irrelevance is described by Srivastava and Ramakrishnan in <ref> [86] </ref>. Their definition is equivalent to strong irrelevance when DI 2 is used for derivation irrelevance and is applied to the set of all derivations of the query; that is, their definition is equivalent to SI (; ; ; DI 2 ; D ). <p> therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning [29, 81], partial evaluation of logic programs [85, 67, 15], 39 automated reasoning [52, 14], and deductive databases <ref> [86, 89] </ref>. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis. <p> Moreover, the query-tree algorithm combines a forward chaining evaluation of the rules followed by a backward chaining evaluation of refined rules. Consequently, with the exception of <ref> [86] </ref>, only the query-tree can be shown to be complete in more than straightforward cases (i.e., in the presence of recursion and interpreted predicates). Recall that completeness guarantees that the query-tree encodes precisely the set of desired derivations. <p> Recall that completeness guarantees that the query-tree encodes precisely the set of desired derivations. A completeness result closely related to Theorem 4.2 was obtained independently by Srivastava and Ramakrishnan <ref> [86] </ref>. They describe an algorithm that uses fold/unfold transformations to obtain a rewritten set of rules in which the most tight constraint is computed for every relation mentioned in the rules.
Reference: [87] <author> D. Subramanian and M.R. Genesereth. </author> <title> The relevance of irrelevance. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Altos, CA, 1987. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 59 </pages>
Reference-contexts: Consequently, there is some derivation D of from such that Base (D) 6j= . The KB consisting of Base (D) is a subset of and does not entail . Consequently, W I 1 (; ; ) holds. 2 A variation of this definition, which is described in <ref> [87] </ref>, can be formulated in our space as W I (; ; ; DI 4 ; D ). Couching Subramanian's definitions in our framework shows how 13 other definitions in the space overcome some of the limitations of her definitions. <p> However, in that context, irrelevance has a natural definition based on the notion of conditional independence which does not carry over to the context of logical knowledge bases. The work most related to ours is the analysis of irrelevance given by Subramanian <ref> [87, 88] </ref>. Subramanian's motivations for analyzing irrelevance are similar to ours; namely, reformulating the knowledge base to create one that is simpler and will therefore lead to more efficient inference. <p> Subramanian also defined a class of computational-irrelevance claims whose exploitation leads to computational savings, but only gave some straightforward examples of such claims. Our class of strong irrelevance claims is a prime example of computational-irrelevance claims. It should be noted that in <ref> [87] </ref>, a definition of strong-irrelevance is given. However, instances satisfying this definition are not necessarily instances of computational irrelevance. Finally, Subramanian discusses several algorithms for detecting irrelevance. However, they focus on the case of propositional logic KBs and require answering the query as part of the algorithm.
Reference: [88] <author> Devika Subramanian. </author> <title> A Theory of Justified Reformulations. </title> <type> PhD thesis, </type> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <year> 1989. </year>
Reference-contexts: Within AI, the notion of irrelevance was investigated in the context of probabilistic reasoning [70, 21, 23] and used there to control inference in Bayesian belief networks. In the context of logical knowledge bases, Subramanian <ref> [88] </ref>, and more recently Lakermeyer [53], investigated several formal definitions of irrelevance. However, the issues of automatically deriving irrelevance claims and the utility of irrelevance reasoning were left largely open, and consequently relevance reasoning has not been applied in any effective way. <p> Therefore, we describe a space of possible definitions of irrelevance, and investigate the properties of various definitions within this space. Our space is based on a proof-theoretic analysis of irrelevance, i.e., on investigating the ways in which formulas can participate in derivations of the query. In contrast, Subramanian <ref> [88] </ref> described a meta-theoretic account of irrelevance. Her framework considers only the formulas in the KB, not the possible derivations of the query. Consequently, we are able to make finer distinctions than those made in Subramanian's framework. <p> We mention several of these comparisons below. Subramanian investigates several definitions of irrelevance. In our framework, all these definitions are instances of weak irrelevance. The main definition investigated in <ref> [88] </ref> is the following: Definition 2.6: Let be a fact, be a query, and be a knowledge base. <p> However, in that context, irrelevance has a natural definition based on the notion of conditional independence which does not carry over to the context of logical knowledge bases. The work most related to ours is the analysis of irrelevance given by Subramanian <ref> [87, 88] </ref>. Subramanian's motivations for analyzing irrelevance are similar to ours; namely, reformulating the knowledge base to create one that is simpler and will therefore lead to more efficient inference.
Reference: [89] <author> Jeffrey D. Ullman. </author> <title> Principles of Database and Knowledge-base Systems, Volumes I, II. </title> <publisher> Computer Science Press, </publisher> <address> Rockville MD, </address> <year> 1989. </year>
Reference-contexts: The procedures needed to compute the closure operations, equivalence, and satisfiability are assumed to be given. Typically, these procedures are efficient. For example, for conjunctive order constraints over dense domains, testing equivalence is cubic in the number of variables <ref> [89] </ref> (but over integers or when disjunctive constraints are allowd the problem is NP-hard. See [25] for a discussion of some of these issues). The properties we require are satisfied by a wide class of interpreted predicates. <p> However, allowing stratified negation causes strong irrelevance to be undecidable. 8 It should be noted that when rules contain stratified negation, we consider stratified semantics as opposed to classical first order semantics <ref> [89] </ref>. Finally, the table shows that slight variations in defining the minimality of derivations can cause the decidability of strong irrelevance with respect to minimal derivations to change significantly. In this article, we focus on the algorithm for deciding strong irrelevance. <p> First, as implied by the definition of strong irrelevance, in order to deem a fact f strongly irrelevant to a query 8 Rules are said to be stratified <ref> [89] </ref> if there are no dependency cycles that involve negations between the predicates in the KB. <p> therefore does not enable relevance reasoning beyond simple reachability tests. 7.2 Static Analysis of Rules Several other authors have considered static analysis of rules for different purposes, such as explanation based learning [29, 81], partial evaluation of logic programs [85, 67, 15], 39 automated reasoning [52, 14], and deductive databases <ref> [86, 89] </ref>. Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis. <p> Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata [92] and rule/goal graphs <ref> [89] </ref>. Others have used rule folding/unfolding in their analysis. In all these works, the common idea is to evaluate the rules over an abstract interpretation of the domain [20], i.e., to evaluate the rules over a domain consisting of abstract descriptions of possible domain elements. <p> Therefore, weak irrelevance is undecidable. 2 The next lemma shows that strong irrelevance is undecidable when we allow the rules to have stratified negation. In our discussion, we assume perfect model semantics of the rules (cf. <ref> [89] </ref>). 16 Lemma 9.2: Let P be a set of function-free Horn rules with stratified negation and r 2 P .
Reference: [90] <author> Jeffrey D. Ullman. </author> <title> Information integration using logical views. </title> <booktitle> In Proceedings of the International Conference on Database Theory, to appear, </booktitle> <year> 1997. </year>
Reference-contexts: A growing body of work in AI has the goal of designing architectures for integrating multiple sources of information and providing high level querying facilities over them, thereby freeing a user from the need to know about specific information sources <ref> [33, 38, 4, 31, 51, 65, 60, 90] </ref>. A key issue that needs to be addressed by these systems is the ability to automatically determine which information sources are relevant to a given query posed by a user. <p> Such queries are usually complex (built from many sub-queries), and interpreted constraints play a major role in them. Predicate move-around is currently being implemented in a commercial decision support system. Information gathering in distributed heterogeneous environments: An important application of knowledge representation is the integration of multiple information sources <ref> [38, 4, 31, 60, 90] </ref>. So called mediator systems provide access to a large number of information sources (such as databases, knowledge bases and text files). <p> The application of our framework and algorithms to such a setting is described in [65]. In [65] as in the TSIMMIS system <ref> [90] </ref>, a mediator contains a set of Horn rules describing how to combine information from the various sources. In such an architecture, the information sources are viewed as containing the base relations, and their descriptions provide integrity constraints on these relations.
Reference: [91] <author> Allen Van-Gelder. </author> <title> A message passing framework for logical query evaluation. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 155-165, </pages> <year> 1986. </year>
Reference-contexts: Moreover, the query-tree can also be combined with other optimization methods such as magic-sets [8, 9] and algorithms based on message-passing <ref> [91] </ref>. A novel query optimization algorithm for SQL queries, predicate move-around, based on the query-tree is described in [58]. The predicate move-around 15 algorithm is an extension of the query-tree that deals with additional features of SQL such as aggregate queries (Min, Max, Avg), functional dependencies, and negation.
Reference: [92] <author> Moshe Y. Vardi. </author> <title> Automata theory for database theoreticians. </title> <booktitle> In Proceedings of the Eighth Symposium on Principles of Database Systems (PODS), </booktitle> <pages> pages 83-92, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Some have also used graph--like representations of the rules, such as problem space graphs [29], connection graphs [52], compilation graphs [14], tree-automata <ref> [92] </ref> and rule/goal graphs [89]. Others have used rule folding/unfolding in their analysis. In all these works, the common idea is to evaluate the rules over an abstract interpretation of the domain [20], i.e., to evaluate the rules over a domain consisting of abstract descriptions of possible domain elements.
Reference: [93] <author> Laurent Vieille. </author> <title> Recursive query processing: The power of logic. </title> <journal> Theoretical Computer Science, </journal> <volume> 69 </volume> <pages> 1-53, </pages> <year> 1989. </year> <month> 60 </month>
Reference-contexts: It should be noted that the savings achieved by employing the query-tree are orthogonal to methods that develop optimal strategies for searching the space (e.g., rule and subgoal ordering [42, 84]) and methods that use run-time bindings (combined with tabulation) to prune the search <ref> [8, 9, 93] </ref>. Therefore, the experimental validation presented here does not follow from experiments validating these other methods. Organization of the Paper The paper is organized as follows. Section 2 describes the space of definitions of irrelevance and compares properties of various definitions. <p> creating indices that will not be used. 14 Finally, it should be emphasized that the optimizations obtained by using the query-tree are orthogonal to those achieved by methods that derive optimal rule and goal orderings [42, 84] or methods that use run-time bindings (combined with tabulation) to prune the search <ref> [8, 9, 93] </ref>. Whereas these methods look for optimal ways to search the space, the query-tree identifies parts of the space that are guaranteed not to contain solutions and is independent of any run-time bindings.
References-found: 93

