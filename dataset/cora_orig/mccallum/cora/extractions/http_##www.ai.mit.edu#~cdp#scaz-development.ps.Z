URL: http://www.ai.mit.edu/~cdp/scaz-development.ps.Z
Refering-URL: http://www.ai.mit.edu/people/scaz/scaz.html
Root-URL: 
Email: scaz@ai.mit.edu  
Title: Building Behaviors Developmentally: A New Formalism  
Author: Brian Scassellati 
Address: 545 Technology Square Cambridge, MA, 02139, USA  
Affiliation: MIT Artificial Intelligence Lab  
Abstract: This paper advocates a developmental approach to building complex interactive behaviors for robotic systems. A developmental methodology is advantageous because it provides a structured decomposition of complex tasks, because it facilitates learning, and because it allows for a gradual increase in task complexity. The developmental approach provides a structured means both of dividing a task among research units, as well as a metric for evaluating the progress of the task. Initial work with developmental modeling has also hinted that these skill decompositions may make the overall task easier to accomplish through the re-use of knowledge gained from developmental precursors. We report here on two projects of building behaviors developmentally for a humanoid robot. In the first project, the robot learned to reach to a visual target by following a developmental progression similar to those observed in infants. The second project outlines a proposal for building social skills developmentally. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baron-Cohen, S. </author> <year> (1995), </year> <title> Mindblindness, </title> <publisher> MIT Press. </publisher>
Reference: <author> Brooks, R. A., Ferrell, C., Irie, R., Kemp, C. C., Mar-janovic, M., Scassellati, B. & Williamson, M. </author> <year> (1998), </year> <title> Alternative Essences of Intelligence, </title> <booktitle> in `Proceedings of the American Association of Artificial Intelligence'. In submission. </booktitle>
Reference-contexts: We are interested in shared attention as a precursor to social communication for two reasons. First, we believe that by using a developmental program to build social capabilities we will be able to achieve a wide range of natural interactions with untrained observers <ref> (Brooks, Ferrell, Irie, Kemp, Marjanovic, Scassellati & Williamson 1998) </ref>. Constructing a machine that can recognize the social cues from a human observer allows for more natural human-machine interaction and creates possibilities for machines to learn by directly observing untrained human instructors.
Reference: <author> Diamond, A. </author> <year> (1990), </year> <title> Development and Neural Bases of Higher Cognitive Functions, Vol. 608, New York Academy of Sciences, chapter Developmental Time Course in Human Infants and Infant Monkeys, </title> <booktitle> and the Neural Bases, of Inhibitory Control in Reaching, </booktitle> <pages> pp. 637-676. </pages>
Reference-contexts: Instead, we look to infant development for examples of how to build these behaviors. Diamond has shown that children between the ages of 5 and 12 months undergo a number of distinct de velopmental stages <ref> (Diamond 1990) </ref> . By the age of 5 months, the infant has already gained a significant amount of motor control over her eyes and neck, but is just beginning to use her arms to reach deliberately for objects. <p> Go to step 2. The system trains to reach reliably within approximately 700 reaches, which requires 90 minutes of training. This system is not yet capable of generic hand-eye coordination, but the developmental progression that we have modeled here provides insights on how to generalize this skill (see <ref> (Diamond 1990) </ref>). Although the developmental framework in this task greatly simplifies the computation necessary, the ballistic reaching task could be accomplished with a brute-force approach using current technology without resorting to a developmental approach.
Reference: <author> Frith, U. </author> <year> (1990), </year> <title> Autism : Explaining the Enigma, </title> <publisher> Basil Blackwell. </publisher>
Reference-contexts: Evidence from childhood development shows that not all mechanisms for shared attention are present from birth (Hobson 1993). There are also developmental disorders, such as Autism, 1 that appear to affect shared attention <ref> (Frith 1990) </ref>. We begin with a developmental model from (Baron-Cohen 1995).
Reference: <author> Hobson, R. P. </author> <year> (1993), </year> <title> Autism and the Development of Mind, </title> <publisher> Erlbaum. </publisher>
Reference-contexts: Evidence from childhood development shows that not all mechanisms for shared attention are present from birth <ref> (Hobson 1993) </ref>. There are also developmental disorders, such as Autism, 1 that appear to affect shared attention (Frith 1990). We begin with a developmental model from (Baron-Cohen 1995).
Reference: <author> Johnson, M. H. </author> <year> (1993), </year> <title> Constraints on Cortical Plasticity, </title> <editor> in M. H. Johnson, ed., </editor> <title> `Brain Development and Cognition: A Reader', </title> <publisher> Blackwell, Oxford, </publisher> <pages> pp. 703-721. </pages>
Reference-contexts: A system that begins simple and becomes gradually more complex allows for more efficient learning. For example, infants are born with low acuity vision which simplifies the visual input they must process. The infant's visual performance develops in step with their ability to process the influx of stimulation <ref> (Johnson 1993) </ref>. The same is true for the motor system. Newborn infants do not have independent control over each degree of freedom of their limbs, but through a gradual increase in the granularity of their motor control they learn to coordinate the full complexity of their bodies.
Reference: <author> Jordan, M. I. & Rumelhart, D. E. </author> <year> (1992), </year> <title> `Forward Models: supervised learning with a distal teacher', </title> <booktitle> Cognitive Science 16, </booktitle> <pages> 307-354. </pages>
Reference-contexts: However, our third problem is that the error signal is in the coordinate frame of the input to our mapping, not the coordinates of the output. To train a system in this way, we use a learning technique similar to the distal supervised learning of <ref> (Jordan & Rumelhart 1992) </ref>; we train a forward map of the sys tem ~ F which is the inverse of the ballistic map ~ B. The forward kinematic model ~ F is useful in that it gives an expectation of where to look to find the arm.
Reference: <author> Karmiloff-Smith, A., Klima, E., Bellugi, U., Grant, J. & Baron-Cohen, S. </author> <year> (1995), </year> <title> `Is there a social module? Language, face processing, and theory of mind in individuals with Williams Syndrome', </title> <journal> Journal of Cognitive Neuroscience 7:2, </journal> <pages> 196-208. </pages>
Reference: <author> Marjanovic, M. J., Scassallati, B. & Williamson, M. M. </author> <year> (1996), </year> <title> Self-Taught Visually-Guided Pointing for a Humanoid Robot, </title> <booktitle> in `From Animals to Animats: Proc 1996 Society of Adaptive Behaviour', Society of Adaptive Behavior. </booktitle>
Reference-contexts: Following the developmental progression simplifies the second step of this task, as we will see below. More information on this project can be found in <ref> (Marjanovic, Scassallati & Williamson 1996) </ref>. To learn the saccade map, the system simply attempts to foveate objects and learns from its mistakes. This map is implemented as a 17 fi 17 interpolated lookup table, which is trained by the following algorithm: 1.
Reference: <author> Povinelli, D. J. & Preuss, T. M. </author> <year> (1995), </year> <title> `Theory of mind: evolutionary history of a cognitive specialization', </title> <booktitle> Trends in Neuroscience. </booktitle>
Reference-contexts: The second step will be to engage in shared attention by interpolation of gaze. Povinelli and Preuss report that in all of the great apes, when a caretaker moves its gaze to a new location, the child will move its gaze to that same location <ref> (Povinelli & Preuss 1995) </ref>. This basic form of imitation serves to focus the child's attention on the same object that the caregiver is attending to. This functional imitation appears simple, but involves many separate proficiencies, as we will see in the following section.
Reference: <author> Scassellati, B. </author> <year> (1996), </year> <title> Mechanisms of Shared Attention for a Humanoid Robot, in `Embodied Cognition and Action: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: The primary focus of this research is to investigate how individuals develop the skills to recognize and produce these social cues by implementing models of this developmental progression on our humanoid robot. A more detailed account of this project can be found in <ref> (Scassellati 1996) </ref>. We are interested in shared attention as a precursor to social communication for two reasons. <p> What Baron-Cohen's model does not provide is a task-level decomposition of necessary skills and the developmental mechanisms that provide for transition between his stages. Our current work is on identifying and implementing a developmental account of one possible skill decomposition <ref> (Scassellati 1996) </ref>. The skill decomposition that we are pursuing can be broken down into four stages: gaze monitoring, interpolation of gaze, identifying pointing, and utilizing pointing. The first step in producing mechanisms of shared attention is gaze monitoring, the tendency to monitor what the caregiver is looking at.
Reference: <author> Scassellati, B. </author> <year> (1998a), </year> <title> A Binocular, Foveated Active Vision System, </title> <type> Technical report, </type> <institution> MIT Artificial Intelligence Lab. </institution> <note> In submission. </note>
Reference-contexts: Current Results The hardware platform that we use for vision is a binocular, foveated, active vision system <ref> (Scassellati 1998a) </ref> shown in Figure 1. 2 There are two cameras per eye, one which captures a wide-angle view of the periphery (approximately 110 ffi field of view) and one which captures a narrow-angle view of the central (foveal) area (approximately 20 ffi field of view with the same resolution).
Reference: <author> Scassellati, B. </author> <year> (1998b), </year> <title> Finding Eyes and Faces with a Foveated Vision System, </title> <booktitle> in `Proceedings of the American Association of Artificial Intelligence'. In submission. </booktitle>
Reference-contexts: Saccade to the target using a learned sensori-motor mapping. 4. Convert the location in the peripheral image to a foveal location using a learned mapping. 5. Extract the image of the eye from the foveal image. Further details about this method can be found in <ref> (Scassellati 1998b) </ref>. To identify face locations, the peripheral image is converted to grayscale and passed through a pre-filter stage. The pre-filter allows us to search only locations 2 Two additional copies of this platform exist as desktop development platforms.
Reference: <author> Sinha, P. </author> <year> (1996), </year> <title> Perceiving and recognizing three-dimensional forms, </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference-contexts: A combination of the pre-filter and some early-rejection optimizations allows us to run face detection at 20 Hz with little accuracy loss. Face detection is done with a method called "ratio templates" designed to recognize frontal views of faces under varying lighting conditions <ref> (Sinha 1996) </ref>. A ratio template is composed of a number of regions and a number of relations, as shown in Figure 2. Overlaying the template with a grayscale image, each region is convolved with the grayscale image to give the average grayscale value for that region.
Reference: <author> Thelen, E. </author> <year> (1993), </year> <title> Self-Organization in Developmental Processes: Can Systems Approaches Work?, </title> <editor> in M. </editor> <publisher> H. </publisher>
Reference-contexts: A process where the acuity of both sensory and motor systems are gradually increased significantly reduces the difficulty of the learning problem <ref> (Thelen 1993) </ref>. Development does not only consist of a gradual increase in internal complexity, but also a gradual increase in the complexity of the external world. The complexity of the infant's external world is carefully structured by the caregiver.
Reference: <author> Johnson, ed., </author> <title> `Brain Development and Cognition: A Reader', </title> <publisher> Blackwell, Oxford, </publisher> <pages> pp. 555-591. </pages>
Reference: <author> Williamson, M. </author> <year> (1995), </year> <title> Series Elastic Actuators, </title> <type> Master's thesis, </type> <institution> MIT Department of Electrical Engineering and Computer Science. </institution>
Reference-contexts: Mechanically, Cog has a torso with a two degree-of-freedom (DOF) waist, a one DOF torso twist, and a three DOF neck. Two six DOF arms, each joint powered by a motor through a series torsional spring, exhibit a natural compliant behavior similar to human arms <ref> (Williamson 1995) </ref>. The head assembly consists of a three DOF active vision system with two active "eyes," each eye composed of two (a wide peripheral and a narrow foveal) CCD cameras.
References-found: 17

