URL: http://www.cs.purdue.edu/research/cse/publications/conf-journal/aij-paper.ps.gz
Refering-URL: http://www.cs.purdue.edu/homes/ttd/resume.html
Root-URL: http://www.cs.purdue.edu
Email: email: fjoshi,ttd,jrr,saw,enhg@cs.purdue.edu  
Phone: Phone: 317-494-7821, Fax: 317-494-0739  
Title: On Learning and Adaptation in Multiagent Systems: A Scientific Computing Perspective  
Author: Anupam Joshi, Tzvetan Drashansky, John Rice, Sanjiva Weerawarana and Elias Houstis 
Note: SciAgents, for cooperative and distributed scientific computing.  
Address: West Lafayette, IN 47907-1398 USA  
Affiliation: Department of Computer Sciences Purdue University  
Abstract: Systems with interacting agents are now being proposed to solve many problems grouped together under the "distributed problem solving" umbrella. For such systems to work properly, it is necessary that agents learn from their environment and adapt their behaviour accordingly. We investigate such systems in the context of scientific computing. The physical world consists of interacting system, and its overall behaviour emerges from the interacting local behaviours of its constituents.In this paper we present a system which uses a combination of neuro-fuzzy learning and static adaptation to coordinate the activity of multiple agents. An epistemic utility based formulation is used to automatically generate the exemplars for learning, making the process unsupervised. We illustrate how these techniques can be used to convert a standalone, single agent system into a collaborative, multiagent one, and present some results from a preliminary implementation. We also present the design and architecture of a multiagent system, named 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Cammarata et al., </author> <title> Strategies of Cooperation in Distributed Problem Solving, </title> <booktitle> Readings in Distributed Artificial Intelligence (Bond and Gasser, </booktitle> <editor> eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1988, </year> <pages> pp. 102-105. </pages>
Reference-contexts: They reported results using both an hierarchical organization, as well as an "anarchic committee" organisation, and found that the latter was as good as, and sometimes better than the former. Cammarata and coauthors <ref> [1] </ref> espouse strategies for cooperation. They analyze the problems faced by the groups of agents involved in distributed problem solving, and infer a set of requirements on information distribution and organizational policies.
Reference: [2] <author> G. Carpenter, S. Grossberg, and S. Rosen, </author> <title> Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system, </title> <booktitle> Neural Networks 4 (1991), </booktitle> <pages> 759-771. </pages>
Reference: [3] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K.E. Schauser, E. Santos, R. Subramonian, and T. von Eicken, </author> <title> LogP: Towards a Realistic Model of Parallel Computations, </title> <booktitle> Proceedings of the fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (New York), ACM, </booktitle> <year> 1993, </year> <pages> pp. 1-12. </pages>
Reference-contexts: Accurate analytic methods for this do not exist and learning about how all PDE solvers run on all such configurations is impractical. However, a few relatively simple models of parallel computations are useful in predicting speedup. The logP <ref> [3] </ref> and E (P)[22] models are the realistic of them.
Reference: [4] <author> T. Drashansky, A. Joshi, and J.R. Rice, </author> <title> SciAgents AnAgent Based Environment for Distributed, Cooperative Scientific Computing, </title> <type> Tech. Report TR-95-029, </type> <institution> Dept. Comp. Sci., Purdue University, </institution> <year> 1995, </year> <note> (submitted to Tools with AI '95). </note>
Reference-contexts: We are developing an environment which addresses these issues and allows disparate pieces of scientific 3 software to collaborate in solving a problem. We call this system SciAgents <ref> [4] </ref>. <p> Such features are common in models of physical events or processes. An example of such a problem is given on Figure 3. It models the temperature distribution in a small system of 4 different substances (with different laws for temperature distribution), a heater, and a sink. In <ref> [4, 5, 6] </ref> we argue that "simple" model solvers (for a single PDE defined on a single domain, for example) like //ELLPACK [14] can be used to solve the submodels.
Reference: [5] <author> T. T. Drashansky, </author> <title> A Software Architecture of Collaborating Agents for Solving PDEs, </title> <type> Tech. Report TR-95-010, </type> <institution> Dept. Comp. Sci., Purdue University, </institution> <year> 1995, </year> <title> (M.S. </title> <type> thesis). </type>
Reference-contexts: Such features are common in models of physical events or processes. An example of such a problem is given on Figure 3. It models the temperature distribution in a small system of 4 different substances (with different laws for temperature distribution), a heater, and a sink. In <ref> [4, 5, 6] </ref> we argue that "simple" model solvers (for a single PDE defined on a single domain, for example) like //ELLPACK [14] can be used to solve the submodels. <p> The overall behaviour of the agents is based on the interface relaxation technique. For PDE based models it is described in detail in <ref> [6, 5, 24] </ref>. It uses the physical relations between the parts of the system modeled by mathematical formulas involving the solutions of the submodels in the individual neighboring subdomains and their derivatives.
Reference: [6] <author> T. T. Drashansky and J. R. Rice, </author> <title> Processing PDE Interface Conditions - II, </title> <type> Tech. Report TR-94-066, </type> <institution> Dept. Comp. Sci., Purdue University, </institution> <year> 1994. </year>
Reference-contexts: Such features are common in models of physical events or processes. An example of such a problem is given on Figure 3. It models the temperature distribution in a small system of 4 different substances (with different laws for temperature distribution), a heater, and a sink. In <ref> [4, 5, 6] </ref> we argue that "simple" model solvers (for a single PDE defined on a single domain, for example) like //ELLPACK [14] can be used to solve the submodels. <p> The overall behaviour of the agents is based on the interface relaxation technique. For PDE based models it is described in detail in <ref> [6, 5, 24] </ref>. It uses the physical relations between the parts of the system modeled by mathematical formulas involving the solutions of the submodels in the individual neighboring subdomains and their derivatives. <p> Typically, for second order PDEs, there are two physical or mathematical conditions involving values and normal derivatives of the solutions on the neighboring subdomains. Examples for common interface conditions are given in <ref> [6, 24] </ref>. The interface relaxation technique can be described briefly as follows. Step 1. Choose initial information as boundary conditions to determine the submodel solutions in each subdomain. Step 2. Solve the submodel in each subdomain and obtain a local solution. Step 3.
Reference: [7] <author> T. Finin et al., </author> <title> Draft Specification of the KQML Agent-Communication Language, DARPA Knowledge Sharing Initiative, External Interfaces Working Group, 1993. [8] , KQML as an Agent Communication Language, </title> <booktitle> Proc. III Intl.Conf. on Information and Knowledge Management, ACM, </booktitle> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: A similar scheme, mutatis mutandis, is used to obtain the other required parameters and the estimates for the amount of the solver's computing load. 5.2.2 Interagent Communication and Agent Architecture In SciAgents at the highest level communication is done using the Knowledge Query and Manipulation Language (KQML <ref> [7, 8] </ref>) from ARPA's knowledge sharing initiative. We adhere to the declarative approach in the agent interaction due to the heterogeneous environment of SciAgents . The contents of the messages is in the high-level language S-KIF for scientific computing. <p> The messages are given in a somewhat abreviated KQML <ref> [7, 8] </ref> format. Only the fields that contribute to understanding the message semantics are given, others, e.g., the :ontology field are skipped. The content of the messages is given in S-KIF [12] a knowledge exchange language for scientific computing being developed at Purdue.
Reference: [9] <author> R. Fisher, </author> <title> The use of multiple measurements in taxonomic problems, </title> <journal> Annals of Eugenics 7 (1936), </journal> <volume> no. 2, </volume> <pages> 179-188. </pages>
Reference-contexts: The mechanism which adjusts the class hyperboxes is altered to allow for class overlaps where the data demands it. Initial results from this approach have been very promising, both on I-PYTHIA data, as well as classical test data such as the IRIS <ref> [9] </ref>. The details regarding this method, as well as these results 5 can be found in [29]. We are also studying other improvements to this method using techniques from computational geometry. The method as it stands tries to form classes by using isothetic hyperboxes.
Reference: [10] <editor> R. Fritzson et. al., </editor> <title> KQML- A Language and Protocol for Knowledge and Information Exchange, </title> <booktitle> Proc. 13th Intl. Distributed Artificial Intelligence Workshop, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: It would then switch into a learning mode by itself, without waiting for any other agent to explicitly indicate a change in its capabilities. The backbone of any agent based system is the ability to communicate effectively among agents. In recent years the Knowledge Query and Manipulation Language, (KQML) <ref> [10] </ref> has been proposed as a medium of interagent communication. KQML was developed by the DARPA Knowledge Sharing Initiative External Interfaces Working Group especially for agent based communication. KQML based communications is based on a protocol defining performatives.
Reference: [11] <author> E. Gallopoulos, E. Houstis, and J.R. Rice, </author> <title> Computer as Thinker/Doer: Problem-Solving Environments for Computational Science, </title> <booktitle> IEEE Computational Science and Enginerring 1 (1994), </booktitle> <volume> no. 2, </volume> <pages> 11-23. </pages>
Reference-contexts: Some of these agents are no more than subroutine libraries in the classical sense, others are very much larger and more sophisticated fl This work was supported in part by NSF awards ASC 9404859 and CCR 9202536, AFOSR award F49620-92-J-0069 and ARPA ARO award DAAH04-94-G-0010 1 Problem Solving Environments <ref> [11] </ref>. We believe that this approach will allow locally interacting problem solving agents to decompose a complex computation into a distributed collection of self contained computations.
Reference: [12] <author> M. R. Genesereth and R. E. Fikes, </author> <title> Knowledge Interchange Format, Ver. 3.0 Reference Manual, </title> <institution> Comp. Sci. Dept., Stanford University, </institution> <year> 1992. </year>
Reference-contexts: The messages are given in a somewhat abreviated KQML [7, 8] format. Only the fields that contribute to understanding the message semantics are given, others, e.g., the :ontology field are skipped. The content of the messages is given in S-KIF <ref> [12] </ref> a knowledge exchange language for scientific computing being developed at Purdue. The :language field is, therefore, the same for all messages and is not included in the messages. The format of the parts in "&lt; &gt;" is not given in detail.
Reference: [13] <editor> B. Hayes-Roth et al., Guardian. </editor> <title> A Prototype Intelligent Agent for Intensive-care Monitoring, </title> <booktitle> Artif. Intell. Med 4 (1992), </booktitle> <volume> no. 2, </volume> <pages> 165-185. </pages>
Reference-contexts: In section 5 we introduce the design and architecture of a Multidisciplinary Problem Solving Environment that we are currently developing. 2 Background and Related Work Many agent-based systems have been developed <ref> [43, 34, 40, 33, 13] </ref>, which demonstrate the advantages of the agent technology. One of their important aspects is their modularity and flexibility. It is very easy to dynamically add or remove agents, to move agents around the computing network, and to organize the user interface.
Reference: [14] <author> E. N. Houstis and J. R. Rice, </author> <title> Parallel ELLPACK: A Development and Problem Solving Environment for High Performance Computing Machines, Programming Environments for High Level Scientific Problem Solving, </title> <publisher> North Holland, </publisher> <year> 1992, </year> <pages> pp. 229-243. 29 </pages>
Reference-contexts: A good example for such solvers is //ELLPACK <ref> [14, 31] </ref> which is designed to handle Partial Differential Equations (PDE) models. It is generally accepted, however, that universal solvers for the complex heterogeneous models described earlier cannot be built. Different software for solving each individual problem or small class of problems is necessary. <p> It models the temperature distribution in a small system of 4 different substances (with different laws for temperature distribution), a heater, and a sink. In [4, 5, 6] we argue that "simple" model solvers (for a single PDE defined on a single domain, for example) like //ELLPACK <ref> [14] </ref> can be used to solve the submodels. Their expected behaviour, computing locally and interacting with the neighboring solvers, effectively translates into a behavior 12 of local problem solver agents. The task of "relaxing" the interface conditions between adjacent subdomains is given to mediator agents.
Reference: [15] <editor> E. Houstis et al., </editor> <booktitle> The PYTHIA projet, Proc. First Intl. Conf. on Neural, Parallel and Scientific Computing, </booktitle> <year> 1995, </year> <note> (to appear). </note>
Reference-contexts: We call this system SciAgents [4]. SciAgents will help in the realization of Multidisciplinary Problem Solving Environments (MPSEs), where individual solution software running on networked, heterogeneous software will interact to provide solutions of complex mathematical models. 2.2 PYTHIA In the PYTHIA <ref> [15] </ref> project, our aim is to develop a system that will accept a description of a problem from the user, and then automatically select the appropriate numerical solver and computing platform, along with values for the various associated parameters.
Reference: [16] <editor> A. Joshi et al., </editor> <title> The Use of Neural Networks to Support Intelligent Scientific Computing, </title> <booktitle> Proc. IEEE Intl. Conf. Neural Networks, </booktitle> <publisher> IEEE, IEEE Press, </publisher> <month> July </month> <year> 1995. </year>
Reference-contexts: In recent work, we have 1 The format is a characteristic vector, whose elements denote various PDE properties. 4 applied various learning techniques to this single agent problem. Specifically, we have used Bayesian belief nets [41], neural networks <ref> [16] </ref> and fuzzy systems [29]. We now apply learning to the multiagent scenario.
Reference: [17] <author> Y. Lashkari, M. Metral, and P. Maes, </author> <title> Collaborative Interface Agents, </title> <booktitle> Proceedings AAAI '94, AAAI, </booktitle> <year> 1994. </year>
Reference-contexts: During the LM, an I-PYTHIA agent asks all other known agents for solutions about a particular type of problem. It collects all the answers, including its own, and then chooses the best result as the solution. In effect, each agent is using what has been described in <ref> [17] </ref> as "desperation based" communication. While in this mode, each agent is also "learning" the mapping from problem class to the agent which gave the best solution. The best solution in LM is computed by the epistemic utility formulation described earlier. <p> It evaluates the answers received 9 correctly classified Mean Median problems (of 23) Error Error 22 0.061488 0.00001 Table 1: Results from learning the problem type to agent mapping according to the reasonableness criterion defined earlier. If none is "reasonable" then we switch to an "exploratory" communication mode <ref> [17] </ref>. Figure 2 illustrates the layered systems of each I-PYTHIA agent that are involved in this process. If PYTHIA does not believe an agent has given a plausible solution, it will ask the next best agent, until all agents are exhausted. This is facilitated by our fuzzy learning algorithm.
Reference: [18] <author> K. Lehrer, </author> <title> Theory of Knowledge, </title> <publisher> Westview Press, </publisher> <address> Boulder, CO, USA, </address> <year> 1990. </year>
Reference-contexts: Clearly an unsupervised learning approach is needed, which learns without any user intervention. We propose an alternate approach formulated in terms of epistemic utility. We summarize the ideas here following Lehrer's presentation <ref> [18] </ref> of internal coherence and personal justification in humans. The basic idea here is that each agent has an acceptance system, which it uses to accept certain hypothesis as true. This system is based on two principles, obtaining truth and avoiding error. <p> Further, let p (q) be the probability that q is true. Then, the reasonableness of accepting q can be defined <ref> [18] </ref> as: r (q) = p (q)U t (q) + p (not (q))U f (q): Such formulations of reasonableness derive from the work of Issac Levi [21], and from the work by Neyman & Pearson on rational decisionmaking [27, 26].
Reference: [19] <author> V. R. Lesser, </author> <title> A Retrospective View of FA/C Distributed Problem Solving, </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 21 (1991), </journal> <volume> no. 6, </volume> <pages> 1347-1363. </pages>
Reference-contexts: They point out that in a DPS scenario, different agents may have different capabilities, limited knowledge and resources, and thus differing appropriateness in solving the problem at hand. Lesser et. al <ref> [19] </ref> describes the FA/C (functionally accurate, cooperative) architecture in which agents exchange partial and tentative results in order to converge to a solution. Most of these coordination and cooperation techniques however, are static in nature.
Reference: [20] <author> I. Levi, </author> <title> The Enterprise of Knowledge, </title> <publisher> The MIT Press, </publisher> <address> CAmbridge, MA, USA, </address> <year> 1980. </year> <title> [21] , Decisions and Revisions, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, U.K., </address> <year> 1984. </year>
Reference-contexts: The complement of power probability, and the false alarm rate are also refered to as errors of type I and type II, respectively. Levi's work <ref> [21, 20] </ref> is a philosophical treatise, delaing with the process of human decision making in general, and scientific enquiry in particular. He has developed a theory of epistemic utility which deals with decisionmaking by a single rational agent.
Reference: [22] <author> D. Marinescu and J.R. Rice, </author> <title> On the scalability of Asynchronous Parallel Computations, </title> <editor> J. </editor> <booktitle> Parallel and Distributed Computing 22 (1994). </booktitle>
Reference: [23] <author> E. Mascarenhas and V. Rego, Ariadne: </author> <title> Architecture of a Portable Threads System Supporting Mobile Processes, </title> <type> Tech. Report CSD-TR-95-017, </type> <institution> Dept. Comp. Sci., Purdue University, </institution> <year> 1995. </year>
Reference-contexts: Our multiagent system will be responsive to this dynamic behaviour, and will adapt by moving computations around. The overhead associated with migrating processes can be substantial. However, there has been recent work <ref> [23] </ref> in this area which shows promise for providing an efficient migration paradigm by using threads of control. It has been shown to be extremely effective in simulations [30]. 4 Architecture and Implementation of C-PYTHIA We have developed a preliminary implementation of the ideas outlined in the preceding sections.
Reference: [24] <author> Mo Mu and J. R. Rice, </author> <title> Modeling with Collaborating PDE Solvers | Theory and Practice, </title> <type> Tech. Report TR-94-056, </type> <institution> Dept. Comp. Sci., Purdue University, </institution> <year> 1994. </year>
Reference-contexts: The overall behaviour of the agents is based on the interface relaxation technique. For PDE based models it is described in detail in <ref> [6, 5, 24] </ref>. It uses the physical relations between the parts of the system modeled by mathematical formulas involving the solutions of the submodels in the individual neighboring subdomains and their derivatives. <p> Typically, for second order PDEs, there are two physical or mathematical conditions involving values and normal derivatives of the solutions on the neighboring subdomains. Examples for common interface conditions are given in <ref> [6, 24] </ref>. The interface relaxation technique can be described briefly as follows. Step 1. Choose initial information as boundary conditions to determine the submodel solutions in each subdomain. Step 2. Solve the submodel in each subdomain and obtain a local solution. Step 3.
Reference: [25] <author> S. Newton and S. Mitra, </author> <title> Self organizing leader clustering in a neural network using a fuzzy learning rule, </title> <booktitle> SPIE Proc. 1565: adaptive signal processing, SPIE, </booktitle> <year> 1991. </year>
Reference-contexts: The basic idea of the method we use was proposed by Simpson [35, 36], and is a variation of the leader cluster algorithm, enhanced with the notion of fuzziness. Similar methods have been proposed by Newton <ref> [25] </ref> and Grossberg et. al.[2]. Simpson describes a supervised learning neural network classifier that uses fuzzy sets to describe pattern classes. Each fuzzy set is the fuzzy union of several n-dimensional hyperboxes. Such hyperboxes define a region in n-dimensional pattern space that have patterns with full-class membership.
Reference: [26] <author> J. Neyman, </author> <title> Basic Ideas and Some Recent Results of the Thoery of Testing Statistical Hypotheses, </title> <journal> J. Royal Stat. Soc. </journal> <volume> 105 (1942), </volume> <pages> 292-327. </pages>
Reference-contexts: Then, the reasonableness of accepting q can be defined [18] as: r (q) = p (q)U t (q) + p (not (q))U f (q): Such formulations of reasonableness derive from the work of Issac Levi [21], and from the work by Neyman & Pearson on rational decisionmaking <ref> [27, 26] </ref>. The work of Neyman & Pearson deals with decision making when prior probabilities of the truth of hypothesis are not available. Consider a binary decision problem, with H 0 and H 1 as the two competing hypotheses.
Reference: [27] <author> J. Neyman and E.S. Pearson, </author> <title> The Testing of Statistical Hypotheses in Relations to Probabilities a priori, </title> <journal> Proc. Cambridge Phil. Soc. </journal> <volume> 29 (1932), </volume> <pages> 492-510. </pages>
Reference-contexts: Then, the reasonableness of accepting q can be defined [18] as: r (q) = p (q)U t (q) + p (not (q))U f (q): Such formulations of reasonableness derive from the work of Issac Levi [21], and from the work by Neyman & Pearson on rational decisionmaking <ref> [27, 26] </ref>. The work of Neyman & Pearson deals with decision making when prior probabilities of the truth of hypothesis are not available. Consider a binary decision problem, with H 0 and H 1 as the two competing hypotheses.
Reference: [28] <author> T. Oates et al., </author> <title> Cooperative Information Gathering: A Distributed Problem Solving Approach, </title> <type> Tech. Report TR-94-66, </type> <institution> UMASS, </institution> <year> 1994. </year>
Reference-contexts: Agent-based systems can minimize centralized control. Hitherto, the agent-based paradigm has not been used widely in scientific computing. We believe that using it in handling complex mathematical models is natural and direct. It allows distributed problem solving <ref> [28] </ref> which is distinct from merely using distributed computing. The expected behaviour of the simple model solvers, computing locally and interacting with the neighboring solvers, effectively translates into a behaviour of a local problem solver agent. The task of mediating interface conditions between adjacent subproblems is given to mediator agents.
Reference: [29] <author> N. Ramakrishnan et al., </author> <title> Neuro-Fuzzy Systems for Intelligent Scientific Computing, </title> <type> Tech. Report TR-95-026, </type> <institution> Dept. Comp. Sci., Purdue University, </institution> <year> 1995. </year>
Reference-contexts: In recent work, we have 1 The format is a characteristic vector, whose elements denote various PDE properties. 4 applied various learning techniques to this single agent problem. Specifically, we have used Bayesian belief nets [41], neural networks [16] and fuzzy systems <ref> [29] </ref>. We now apply learning to the multiagent scenario. <p> Initial results from this approach have been very promising, both on I-PYTHIA data, as well as classical test data such as the IRIS [9]. The details regarding this method, as well as these results 5 can be found in <ref> [29] </ref>. We are also studying other improvements to this method using techniques from computational geometry. The method as it stands tries to form classes by using isothetic hyperboxes. Clearly, this approach is extremely naive, since it would cover regions of space that did not belong to a class. <p> If PYTHIA determines no plausible solution exists among its agents or itself, then PYTHIA will give the answer that "was best". When giving such an answer, the user will be notified of PYTHIA's lack of confidence. In Table 1, we illustrate the results obtained by our neuro-fuzzy learning scheme <ref> [29] </ref>. As mentioned earlier, the task was to learn a mapping from a problem to the agent best able to solve it. To this end, we chose some elliptic PDE problems from [32].
Reference: [30] <author> V. Rego et al., </author> <title> Process Mobility in Distributed Memory Simulation Systems, </title> <booktitle> Proc. Winter Simulation Conference, </booktitle> <year> 1993, </year> <pages> pp. 722-730. </pages>
Reference-contexts: The overhead associated with migrating processes can be substantial. However, there has been recent work [23] in this area which shows promise for providing an efficient migration paradigm by using threads of control. It has been shown to be extremely effective in simulations <ref> [30] </ref>. 4 Architecture and Implementation of C-PYTHIA We have developed a preliminary implementation of the ideas outlined in the preceding sections. The overall sytem architecture is illustrated in Figure 1. <p> The main issue is then the correct distribution of the solver agents to balance the load. This can be done by the global execution interface in several ways. One is to reassign agents <ref> [30] </ref> to appropriate computing units; another is to split some subdomains further and distribute them to separate computing units.
Reference: [31] <author> J. R. Rice and R. F. Boisvert, </author> <title> Solving Elliptic Problems Using ELLPACK, </title> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: A good example for such solvers is //ELLPACK <ref> [14, 31] </ref> which is designed to handle Partial Differential Equations (PDE) models. It is generally accepted, however, that universal solvers for the complex heterogeneous models described earlier cannot be built. Different software for solving each individual problem or small class of problems is necessary.
Reference: [32] <author> John R. Rice, Elias N. Houstis, and Wayne R. Dyksen, </author> <title> A population of linear, second order, elliptic partial differential equations on rectangular domains, part I, </title> <booktitle> Mathematics of Computation 36 (1981), </booktitle> <pages> 475-484. 30 </pages>
Reference-contexts: In Table 1, we illustrate the results obtained by our neuro-fuzzy learning scheme [29]. As mentioned earlier, the task was to learn a mapping from a problem to the agent best able to solve it. To this end, we chose some elliptic PDE problems from <ref> [32] </ref>. These were distributed amongst several I-PYTHIA agents, so that each agent mostly had problems of the same type. This data was then used as input to the learning scheme. As table 1 shows, we obtained extremely high classification rates, and correspondingly low values for mean and median error.
Reference: [33] <author> J. C. Schlimmer and L. A. Hermens, </author> <title> Software Agents: Completing Patternsand Constructing User Interfaces, </title> <journal> Journal of Artificial Intelligence Research 1 (1993), </journal> <volume> no. </volume> <pages> 61-89. </pages>
Reference-contexts: In section 5 we introduce the design and architecture of a Multidisciplinary Problem Solving Environment that we are currently developing. 2 Background and Related Work Many agent-based systems have been developed <ref> [43, 34, 40, 33, 13] </ref>, which demonstrate the advantages of the agent technology. One of their important aspects is their modularity and flexibility. It is very easy to dynamically add or remove agents, to move agents around the computing network, and to organize the user interface.
Reference: [34] <author> Y. Shoham, </author> <title> Agent-Oriented Programming, </title> <booktitle> Artificial Intelligence 60 (1993), </booktitle> <volume> no. 1, </volume> <pages> 51-92. </pages>
Reference-contexts: We thus propose a combination of nativist and empiricist approaches to the problem. We should perhaps elaborate here on our use of the term agent, since it has been much (ab)used in literature. To paraphrase what Shoham said in his seminal work <ref> [34] </ref>, "agenthood lies inthe mind of the programmer". For us, agents are software (and hardware) systems that were designed to solve some task in a standalone fashion. Thus they accept some input data, and produce specific results. <p> In section 5 we introduce the design and architecture of a Multidisciplinary Problem Solving Environment that we are currently developing. 2 Background and Related Work Many agent-based systems have been developed <ref> [43, 34, 40, 33, 13] </ref>, which demonstrate the advantages of the agent technology. One of their important aspects is their modularity and flexibility. It is very easy to dynamically add or remove agents, to move agents around the computing network, and to organize the user interface.
Reference: [35] <author> P.K. Simpson, </author> <title> Fuzzy min-max neural networks-part I: Classification, </title> <journal> IEEE Trans. Neural Networks 3 (1992), </journal> <month> 776-786. </month> <title> [36] , Fuzzy min-max neural networks-part II: Clustering, </title> <journal> IEEE Trans. Fuzzy Systems 1 (1993), </journal> <volume> no. 1, </volume> <pages> 32-45. </pages>
Reference-contexts: A conventional, binary membership function would not model this situation accurately. We feel that such fuzziness will be inherent in the learning task whenever agents model complex, real world problems. The basic idea of the method we use was proposed by Simpson <ref> [35, 36] </ref>, and is a variation of the leader cluster algorithm, enhanced with the notion of fuzziness. Similar methods have been proposed by Newton [25] and Grossberg et. al.[2]. Simpson describes a supervised learning neural network classifier that uses fuzzy sets to describe pattern classes.
Reference: [37] <author> R. G. Smith and R. Davis, </author> <title> Frameworks for Cooperation in Distributed Problem Solving, </title> <booktitle> Readings in Distributed Artificial Intelligence (Bond and Gasser, </booktitle> <editor> eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1988, </year> <pages> pp. 61-70. </pages>
Reference-contexts: The ability of the agents to autonomously pursue their goals can resolve the problems during the solution process without user intervention. This allows seamless derivation of the global solution. 2 Several researchers have addressed the issue of coordinating multiagent systems. For instance Smith and Davis <ref> [37] </ref> propose two forms of multiagent cooperation, task sharing and result sharing. Task sharing essentially involves creating subtasks, and then farming them off to other agents. In this sense, it is closer to pure distributed computation. Result sharing is more data directed.
Reference: [38] <author> W.C. Stirling, </author> <title> Coordinated Intelligent Control via Epistemic Utiliyu Theory, </title> <booktitle> IEEE Control Systems (1993), </booktitle> <pages> 21-29. </pages>
Reference-contexts: Like much of decision theory, it is based on the notion of maximizing utility, but differs in as much as its formulation of what utility is. Based on his work, Stirling & Morrow have recently proposed schemes that are used for coordinated intelligent control <ref> [38, 39] </ref>. In the case of C-PYTHIA, each I-PYTHIA agent produces a number denoting confidence in its recommendation being correct, so p (q) is trivially defined, and p (not (q)) is simply 1 p (q). The utility is a more tricky measure.
Reference: [39] <author> W.C. Stirling and D.R. Morrell, </author> <title> Convex Bayes Decision Theory, </title> <journal> IEEE Trans. System, Man and Cybernetics 21 (1991), </journal> <pages> 173-183. </pages>
Reference-contexts: Like much of decision theory, it is based on the notion of maximizing utility, but differs in as much as its formulation of what utility is. Based on his work, Stirling & Morrow have recently proposed schemes that are used for coordinated intelligent control <ref> [38, 39] </ref>. In the case of C-PYTHIA, each I-PYTHIA agent produces a number denoting confidence in its recommendation being correct, so p (q) is trivially defined, and p (not (q)) is simply 1 p (q). The utility is a more tricky measure.
Reference: [40] <author> L. Z. Varga et. al., </author> <title> Integrating Intelligent Systems into a Cooperating Community for Electricity Distribution Management, </title> <journal> International Journal of Expert Systems with Applications 7 (1994), </journal> <volume> no. </volume> <pages> 4. </pages>
Reference-contexts: In section 5 we introduce the design and architecture of a Multidisciplinary Problem Solving Environment that we are currently developing. 2 Background and Related Work Many agent-based systems have been developed <ref> [43, 34, 40, 33, 13] </ref>, which demonstrate the advantages of the agent technology. One of their important aspects is their modularity and flexibility. It is very easy to dynamically add or remove agents, to move agents around the computing network, and to organize the user interface.
Reference: [41] <author> S. Weerawarana, </author> <title> Problem Solving Environments for Partial Differential Equation Based Systems, </title> <type> Ph.D. thesis, </type> <institution> Dept. Comp. Sci., Purdue University, </institution> <year> 1994. </year>
Reference-contexts: Other parameters reflect confidence measures of the agent in proposing the method and hardware. In recent work, we have 1 The format is a characteristic vector, whose elements denote various PDE properties. 4 applied various learning techniques to this single agent problem. Specifically, we have used Bayesian belief nets <ref> [41] </ref>, neural networks [16] and fuzzy systems [29]. We now apply learning to the multiagent scenario. <p> The user's high-level view of the SciAgents' architecture is shown in Figure 6. There is a global communication medium which is used by all entities called a software bus <ref> [41] </ref>. The agent instantiator communicates with the user through the user interface builder and uses the software bus to communicate with the templates in order to instantiate various agents. <p> We adhere to the declarative approach in the agent interaction due to the heterogeneous environment of SciAgents . The contents of the messages is in the high-level language S-KIF for scientific computing. This is based on a language we developed for PDE data called PDESpec <ref> [41] </ref>. Using KQML for the inter agent communication in SciAgents ensures portability, compatibility, and better opportunities for extensions and the inclusion of agents built by others. The software architecture of the local problem solver agents reflects our desire to reuse existing software for solving general single-domain PDE problems. <p> The messages are grouped according to the agent that services them (receives them). Within the messages serviced by a given type of agent there is no particular order although messages with common topic are likely to be found together. The software bus <ref> [41] </ref> is a guaranteed delivery communication system, hence, the messages do not require explicit acknowlegements. In a number of cases, however, the sender needs more than just information whether its message has been delivered.
Reference: [42] <author> R. Wesson et al., </author> <title> Network Structures for Distributed Situation Assessment, </title> <booktitle> Readings in Distributed Artificial Intelligence (Bond and Gasser, </booktitle> <editor> eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1988, </year> <pages> pp. 71-89. </pages>
Reference-contexts: In this sense, it is closer to pure distributed computation. Result sharing is more data directed. Different agents are solving different tasks, and keep on exchanging partial results to cooperate. They also proposed using "contract nets", to distribute tasks. Wesson et. al showed <ref> [42] </ref> how many intelligent sensor devices could pool their knowledge to obtain an accurate overall assessment of the situation. The specific task presented in their work involved detecting moving entities, even though each "sensor agent" saw only a part of the environment.
Reference: [43] <author> M. Wooldridge and N. Jennings, </author> <title> Intelligent Agents: </title> <journal> Theory and Practice, </journal> <note> (submitted to Knowledge Engineering Review), 1994. 31 </note>
Reference-contexts: In section 5 we introduce the design and architecture of a Multidisciplinary Problem Solving Environment that we are currently developing. 2 Background and Related Work Many agent-based systems have been developed <ref> [43, 34, 40, 33, 13] </ref>, which demonstrate the advantages of the agent technology. One of their important aspects is their modularity and flexibility. It is very easy to dynamically add or remove agents, to move agents around the computing network, and to organize the user interface.
References-found: 40

