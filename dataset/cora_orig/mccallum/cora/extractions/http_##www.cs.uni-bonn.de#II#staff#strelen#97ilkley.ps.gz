URL: http://www.cs.uni-bonn.de/II/staff/strelen/97ilkley.ps.gz
Refering-URL: http://www.cs.uni-bonn.de/II/staff/strelen/SelectedPapers.htm
Root-URL: http://cs.uni-bonn.de
Title: Loss Queueing Networks with Bursty Arrival Processes and Phase Type Service Times: Approximate Analysis  
Author: Johann Christoph Strelen Rheinische Friedrich-Wilhelms-Universitat Bonn 
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. O. Allen. </author> <title> Probability, Statistics and Queueing Theory. </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: Here we did not use the third degree of freedom: The third moment can also be taken into account <ref> [1, page 151] </ref>. Now we consider bursty arrivals using a hyperexponential distribution. <p> aggregate Z c;j defines a macro proba bility or aggregate probability PfZ 2 Z c;j g: r c (j) = z2Z c;j We collect the aggregate probabilities of a partition Z c into tuples r c and, in turn, these into R 4 By (2), the aggregation function A : <ref> [0; 1] </ref> n ! [0; 1] jN 1 j fi : : : fi [0; 1] jN C j ; p 7! R; is defined. It calculates the macro probabilities for given state probabilities. <p> a macro proba bility or aggregate probability PfZ 2 Z c;j g: r c (j) = z2Z c;j We collect the aggregate probabilities of a partition Z c into tuples r c and, in turn, these into R 4 By (2), the aggregation function A : <ref> [0; 1] </ref> n ! [0; 1] jN 1 j fi : : : fi [0; 1] jN C j ; p 7! R; is defined. It calculates the macro probabilities for given state probabilities. <p> c;j g: r c (j) = z2Z c;j We collect the aggregate probabilities of a partition Z c into tuples r c and, in turn, these into R 4 By (2), the aggregation function A : <ref> [0; 1] </ref> n ! [0; 1] jN 1 j fi : : : fi [0; 1] jN C j ; p 7! R; is defined. It calculates the macro probabilities for given state probabilities. The states of the system components are described by the random variables Z k : Z T ! S k ; z 7! z k . <p> In fact, the MED is completely determined by all MED parameters ae c;j ; ae for short. By (6) and (2), the disaggregation function is defined: D : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! [0; 1] n ; R 7! : It calculates the MED over the state space for given aggregate probabilities. <p> In fact, the MED is completely determined by all MED parameters ae c;j ; ae for short. By (6) and (2), the disaggregation function is defined: D : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! [0; 1] n ; R 7! : It calculates the MED over the state space for given aggregate probabilities. <p> In fact, the MED is completely determined by all MED parameters ae c;j ; ae for short. By (6) and (2), the disaggregation function is defined: D : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! [0; 1] n ; R 7! : It calculates the MED over the state space for given aggregate probabilities. Instead of calculating the steady state probabilities q of a Markov chain we determine an approximation p = D (R) where R = T (R) holds. <p> Instead of calculating the steady state probabilities q of a Markov chain we determine an approximation p = D (R) where R = T (R) holds. Here the function T is defined as follows: T : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! R 7! A D (R)P : This approximation p and its marginal probabilities R are referred to as steady state disaggregation-aggregation product-form (DA) solution. <p> Instead of calculating the steady state probabilities q of a Markov chain we determine an approximation p = D (R) where R = T (R) holds. Here the function T is defined as follows: T : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! R 7! A D (R)P : This approximation p and its marginal probabilities R are referred to as steady state disaggregation-aggregation product-form (DA) solution. In fact, only the marginal probabilities R and the MED parameters ae and G must be calculated.
Reference: [2] <author> W. J. Stewart (ed.). </author> <title> Numerical Solution of Markov Chains. </title> <publisher> Marcel Dekker, </publisher> <address> New York, Basel, Hong Kong, </address> <year> 1991. </year> <month> 87/9 </month>
Reference-contexts: The measures are calculated from the state probabilities of the Markov chain. Unfortunately, the number of states grows quickly as the complexity of the model increases. This is why much research was done about the solution of large Markov chains <ref> [2, 7, 3] </ref>. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration [8].
Reference: [3] <author> W. J. Stewart (ed.). </author> <title> Computation with Markov Chains. </title> <publisher> Kluwer, </publisher> <year> 1995. </year>
Reference-contexts: The measures are calculated from the state probabilities of the Markov chain. Unfortunately, the number of states grows quickly as the complexity of the model increases. This is why much research was done about the solution of large Markov chains <ref> [2, 7, 3] </ref>. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration [8].
Reference: [4] <author> B.R. Haverkort. </author> <title> Approximate analysis of networks of PH/PH/1/K queues: Test results. </title> <note> Accepted for publication in Annals of Operations Research, </note> <year> 1997. </year>
Reference-contexts: Also other authors who developed fixed point techniques observed that proofs of existence of a solution, of the uniqueness, and of convergence are difficult to state, as well as bounds for the accuracy, for example Haverkort <ref> [4] </ref>. But in [8] the existence of DA solutions is proven, and it is proven that there is always an aggregation with only a small number of aggregates for which an approximating product form (6) exists which is as accurate as desired.
Reference: [5] <author> A. M. Kagan, J. V. Linnik, and C. R. Rao. </author> <title> Characterization Problems in Mathematical Statistics. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: First, the distribution satisfies the macro probabilities, R = A (); and secondly, maximizes the entropy. According to the product-form theorem, see <ref> [5, theorem 13.2.1, page 409] </ref>, this maximum entropy distribution (MED) is uniquely determined and has a product form, (z) = ae 1;z 1 : : : ae C;z C =G; (6) where the ae c;z c &gt; 0 are some real numbers, and G is a normalizing constant.
Reference: [6] <author> M. F. Neuts. </author> <title> Structured Stochastic Matrices of M/G/1-Type and their Applications. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: According to <ref> [6, page 231] </ref> a probability distribution F () on [0; 1) is of phase type if it is the distribution of the time until absorption in a finite-state Markov chain with a single absorbing state, that is, there exists a probability vektor (fi; fi ) and a generator matrix " 0
Reference: [7] <author> W. J. Stewart. </author> <title> Introduction to the numerical solution of Markov chains. </title> <publisher> Princeton University Press, </publisher> <year> 1994. </year>
Reference-contexts: The measures are calculated from the state probabilities of the Markov chain. Unfortunately, the number of states grows quickly as the complexity of the model increases. This is why much research was done about the solution of large Markov chains <ref> [2, 7, 3] </ref>. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration [8].
Reference: [8] <author> J. Ch. Strelen. </author> <title> Approximate product form solutions for Markov chains. Accepted for publication in Performance Evaluation, </title> <year> 1997. </year>
Reference-contexts: This is why much research was done about the solution of large Markov chains [2, 7, 3]. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration <ref> [8] </ref>. This is a general approximate technique for finite state Markov chains with discrete time which is based on aggregation. The calculated state probabilities are in product form; we call them disaggregation-aggregation product-form (DA) solutions. <p> It is interesting to note that the steady state probabilities of separable queueing networks are equal to DA solutions calculated according to suitably chosen aggregates. Here our DA method is exact. In <ref> [8] </ref> we propose also a description technique which we call transition classes. It is defined in the terms system components, component 87/1 states, state transitions, transition probabili-ties. This technique helps to structure the design of the Markov models and renders possible to generate the Markov chain automatically. <p> 0 &lt; k 0 ; k 0 otherwise: 87/6 The new phase is u ;k (z) = j; the other system components remain unchanged, u ;i (z) = z i if i 6= k: 3 Disaggregation Aggregation Iteration In this section we survey the DA method, details are given in <ref> [8] </ref>. Our proposed solution technique needs dis-aggregation: Given positive macro probabilities R, a distribution over Z T is defined as follows where is a n-vector with the probabilities (z); z 2 Z T . First, the distribution satisfies the macro probabilities, R = A (); and secondly, maximizes the entropy. <p> Also other authors who developed fixed point techniques observed that proofs of existence of a solution, of the uniqueness, and of convergence are difficult to state, as well as bounds for the accuracy, for example Haverkort [4]. But in <ref> [8] </ref> the existence of DA solutions is proven, and it is proven that there is always an aggregation with only a small number of aggregates for which an approximating product form (6) exists which is as accurate as desired. <p> Moreover, the accuracy could be sub stantially ameliorated in all examples if more and suitably chosen aggregates are considered. These matters are discussed in <ref> [8] </ref>. 4 Numerical Examples Here we consider the steady state probabilities of the component states. Other performance measures are calculated from them. Therefore their accuracy is of particular interest.
Reference: [9] <author> J. Ch. Strelen, B. Bark, J. Becker, and V. Jonas. </author> <title> Analysis of queueing networks with blocking using a new aggregation technique. </title> <note> Accepted for publication in Annals of Operations Research, </note> <year> 1997. </year>
Reference-contexts: In [10] transition classes and the DA technique are applied to queueing networks with different service disciplines like priorities and polling, Coxian service and interar-rival time distributions, blocking, or fork and join. Queueing networks with repetitive service blocking are discussed more thoroughly in <ref> [9] </ref>. Here we use transition classes and the DA technique for approximate solutions of loss queueing networks with phase type (PH) service time distributions and bursty arrival processes which can be modeled using hyperexpo-nential interarrival times. In this paper we consider steady state solutions.
Reference: [10] <author> J. Ch. Strelen. </author> <title> Approximate disaggre-gation aggregation solutions for general queueing networks. </title> <note> In Proceedings of the ESM 97 Conference. To appear, 1997. 87/10 </note>
Reference-contexts: This technique helps to structure the design of the Markov models and renders possible to generate the Markov chain automatically. With the transition classes a model can be immediately simulated. Furthermore this idea turns out to be usefull for the DA technique. In <ref> [10] </ref> transition classes and the DA technique are applied to queueing networks with different service disciplines like priorities and polling, Coxian service and interar-rival time distributions, blocking, or fork and join. Queueing networks with repetitive service blocking are discussed more thoroughly in [9].
References-found: 10

