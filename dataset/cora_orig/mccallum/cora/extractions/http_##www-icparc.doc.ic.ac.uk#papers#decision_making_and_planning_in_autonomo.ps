URL: http://www-icparc.doc.ic.ac.uk/papers/decision_making_and_planning_in_autonomo.ps
Refering-URL: http://www-icparc.doc.ic.ac.uk/papers.html
Root-URL: 
Email: skd@doc.ic.ac.uk  jf@acl.icnet.uk  davide@isl.co.uk  p.hammond@brunel.ac.uk  
Title: A flexible architecture for autonomous agents IC-Parc  Integral Solutions Limited  
Author: William Penney J. Fox D. Elsdon Basingstoke P. Hammond 
Date: February 19, 1996  
Address: London SW7 2AZ England  London WC2A 3PX England  RG26 5EG England  Middlesex UB8 3PH England  
Affiliation: Laboratory Imperial College  Advanced Computation Laboratory Imperial Cancer Research Fund  Hampshire  Department of Computer Science Brunel University  
Abstract: fl The RED project was initiated by the Imperial Cancer Research Fund and Queen Mary and Westfield College and supported under the DTI/SERC project ITD 4/1/9053: Safety-Critical Systems Initiative. The authors would like to thank Integral Solutions Ltd for project management, Masons Solicitors and Lloyds Register for their stimulating studies of sociolegal issues and software safety, and Paul Krause of the Imperial Cancer Research Fund and Simon Parsons of Queen Mary and Westfield College, for many helpful discussions. We would particularly like to remember Mike Clarke who shared in the conception of the project but who sadly died during its course. This paper was completed while SKD was working at the Computer Science Department of Queen Mary and Westfield College, London. PH was previously at the Advanced Computation Laboratory, Imperial Cancer Research Fund, London. 
Abstract-found: 1
Intro-found: 1
Reference: [All84] <author> J. F. Allen. </author> <title> Towards a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 123-154, </pages> <year> 1984. </year>
Reference-contexts: detail here; a full technical definition of the language is available on request. 4.1 Modelling the environment: properties and occurrences R 2 L is built from two kinds of concept: static properties (e.g., the patient has a cold) and dynamic occurrences (e.g., the patient is given chemotherapy) as described by <ref> [All84] </ref>. An occurrence is either an event or a process. We consider the set of all R 2 L symbols sorted into properties (for A flexible architecture for autonomous agents 10 example, weight_loss) and actions (for example, injection). <p> The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based <ref> [All84, Hum79, HS91] </ref>, first-order [Hau87, Sho87, McD82], discrete and linear [EH86, vB91] in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them.
Reference: [Aqv85] <author> L. Aqvist. </author> <title> Deontic logic. </title> <editor> In D. Gabbay and R. Guenthner, editors, </editor> <booktitle> Extensions of Classical Logic, volume 2 of Handbook of Philosophical Logic, </booktitle> <pages> pages 605-714. </pages> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: Ordering and equality relations are added to the logic as two special predicate symbols. Suppose D is an arbitrary dictionary with the the top element 4. The modal operators of LR 2 L corresponding to belief [FH88, Hin62], goal [CL90] and obligations <ref> [Aqv85, Che80, vW51] </ref> are hbeli, hgoali and hoblgi respectively. In addition, for each dictionary symbol d 2 D, we have a modal operator hsup d i for support.
Reference: [BHW81] <author> R. H. Bonczek, C. W. Holsapple, and A. B. Whinston. </author> <title> Foundation of Decision Support Systems. </title> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: Symbolic Decision Theory is formalised using classical predicate logic and a number of non-classical logics for specialised forms of inference which are required (e.g. for hypothesis generation, argumentation about decision options, and commitment; [Fox91, FK92]. Other authors have proposed classical and non-classical logics for building decision support systems <ref> [BHW81, CH85, BK94] </ref>, but we have placed greater emphasis in our work on developing an explicit theory of decision-making under uncertainty, as A flexible architecture for autonomous agents 8 summarised in the above decision cycle.
Reference: [BK94] <author> H. K. Bhargava and S. O. Kimbrough. </author> <title> Editor's introduction to the special issue on logic modelling. </title> <booktitle> Decision Support Systems, </booktitle> <volume> 11 </volume> <pages> 101-102, </pages> <year> 1994. </year>
Reference-contexts: Symbolic Decision Theory is formalised using classical predicate logic and a number of non-classical logics for specialised forms of inference which are required (e.g. for hypothesis generation, argumentation about decision options, and commitment; [Fox91, FK92]. Other authors have proposed classical and non-classical logics for building decision support systems <ref> [BHW81, CH85, BK94] </ref>, but we have placed greater emphasis in our work on developing an explicit theory of decision-making under uncertainty, as A flexible architecture for autonomous agents 8 summarised in the above decision cycle.
Reference: [BTA93] <author> BTA. </author> <title> Guidelines on the management of asthma. </title> <journal> THORAX: The Journal of the British Thoratic Society, </journal> <volume> 48 </volume> <pages> 1-24, </pages> <year> 1993. </year>
Reference-contexts: When a repeat-until type of scheduling constraint is present in a plan specification then additional recursive rules are generated in addition to the primary rule. Consider the following plan related to chronic asthma treatment for children <ref> [BTA93] </ref>: plan:: subsequent_treatment pre_conditions child & asthma subtasks oxygen_treatment; drug_salbutamol scheduling_constraints first (oxygen_treatment); after (oxygen_treatment, repeat (every (minute (30)), drug_salbutamol, until (patient_has_improved))) abort_conditions none. <p> Consider a method for prescribing a steroid rescue course for asthmatic children which requires that a dose for pred-nisolone of 1-2 mg/kg body weight should be used for five days <ref> [BTA93] </ref>. This can be represented in R 2 L as follows: plan:: steroid_rescue_course pre_conditions child & high_asthma_exacerbation subtasks prednisolone_mg1_2/kg scheduling_constraints repeat (every (hour (24)), prednisolone_mg1_2/kg, count (5)) abort_conditions none.
Reference: [CH85] <author> M. C. Chen and L. J. Henschen. </author> <title> On the use and internal structure of logic-based decision support systems. </title> <booktitle> Decision Support Systems, </booktitle> <volume> 1 </volume> <pages> 205-219, </pages> <year> 1985. </year>
Reference-contexts: Symbolic Decision Theory is formalised using classical predicate logic and a number of non-classical logics for specialised forms of inference which are required (e.g. for hypothesis generation, argumentation about decision options, and commitment; [Fox91, FK92]. Other authors have proposed classical and non-classical logics for building decision support systems <ref> [BHW81, CH85, BK94] </ref>, but we have placed greater emphasis in our work on developing an explicit theory of decision-making under uncertainty, as A flexible architecture for autonomous agents 8 summarised in the above decision cycle.
Reference: [Che80] <author> B. Chellas. </author> <title> Modal Logic. </title> <publisher> Cambridge University Press, </publisher> <year> 1980. </year> <title> A flexible architecture for autonomous agents 34 </title>
Reference-contexts: Ordering and equality relations are added to the logic as two special predicate symbols. Suppose D is an arbitrary dictionary with the the top element 4. The modal operators of LR 2 L corresponding to belief [FH88, Hin62], goal [CL90] and obligations <ref> [Aqv85, Che80, vW51] </ref> are hbeli, hgoali and hoblgi respectively. In addition, for each dictionary symbol d 2 D, we have a modal operator hsup d i for support.
Reference: [CL90] <author> P. R. Cohen and H. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42, </volume> <year> 1990. </year>
Reference-contexts: Ordering and equality relations are added to the logic as two special predicate symbols. Suppose D is an arbitrary dictionary with the the top element 4. The modal operators of LR 2 L corresponding to belief [FH88, Hin62], goal <ref> [CL90] </ref> and obligations [Aqv85, Che80, vW51] are hbeli, hgoali and hoblgi respectively. In addition, for each dictionary symbol d 2 D, we have a modal operator hsup d i for support. <p> the following axiom: 8t 1 8t 2 (p [t 1 ; t 2 ] ! p (t 1 ; t 2 )) (4) A flexible architecture for autonomous agents 26 Modal axioms of LR 2 L We adopt a set of standard axioms of beliefs which can be found in <ref> [CL90, FH88, HM85, MvdHV91] </ref>: :hbeli ? (5) hbeliF ^ hbeli (F ! G) ! hbeliG (6) hbeliF ! hbelihbeliF (7) :hbeliF ! hbeli:hbeliF (8) Axiom (5) expresses that an inconsistency is not believable by a decision maker. The derivation of the symbol ? from the database implies inconsistency. <p> The exclusion also avoids the unnecessary contributions to the aggregation process for F . We adopt the following two standard axioms of goals <ref> [CL90, Wai94] </ref>: :hgoali ? (13) hgoaliF ^ hgoali (F ! G) ! hgoaliG (14) Axiom (13) says that something that is impossible to achieve cannot be a goal of a decision maker. Axiom (14) states that all the logical consequences of a decision maker's goal are goals themselves. <p> Axiom (14) states that all the logical consequences of a decision maker's goal are goals themselves. According to <ref> [CL90] </ref>, worlds compatible with a decision maker's goals must be included in those compatible with the decision maker's beliefs. This is summarised in the following axiom: hbeliF ! hgoaliF (15) A database is full of decision maker's belief.
Reference: [Das92] <author> S. K. Das. </author> <title> Deductive Databases and Logic Programming. </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: Conventional integrity constraints may be defined as properties which a knowledge base is required to satisfy <ref> [Das92] </ref>. For example, a person's age must be less than or equal to 150. Such constraints help to avoid inconsistent, incomplete and inaccurate knowledge bases and address problems in Group III, (a) and (b). Safety constraints on the other hand are constraints on the behaviour of the system. <p> Thus, the following axiom should be considered for a rational decision maker: hsup 4 iF ! hbeliF This axiom, of course, assumes that an assertion and its negation are not simultaneously derivable with the top element as support, that is, an integrity constraint <ref> [Das92] </ref> of the following form: hsup 4 iF ^ hsup 4 i:F !? It is difficult to maintain consistency of a database in the presence of the above axiom, particularly when the database is constructed from different sources; mutual inconsistency and mistakes sometimes need to be tolerated.
Reference: [Das95a] <author> S. K. Das. </author> <title> Formalising safety in decision support systems. </title> <editor> In C. J. Mitchell and V. Stavridou, editors, </editor> <booktitle> Proceedings of the IMA Conference on Mathematics of Dependable Systems, </booktitle> <pages> pages 49-61. </pages> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: This section addresses this difficulty by proposing that systems should be able to explicitly anticipate possible hazards at runtime [Fox93, HHDW94]. The safety of a decision support system <ref> [Das95a] </ref> is the property that any actions recommended by the system will have minimal undesirable consequences. Such consequences may result from recommendations which have arisen in any of the following situations: Group I (a) Hardware failure. (b) Human error in the context of operating and maintenance, installation. <p> A goal will be considered achieved (resp. active) in a state if it is derivable (resp. not derivable) in the state. A decision maker is not obliged to carry out something impossible to achieve, that is <ref> [Das95a] </ref>: :hoblgi ? (16) Obligations are closed under tautological equivalence which provides the the following rule of inference: if ` F $ G then ` hoblgiF $ hoblgiG (17) Obligations are goals but the converse are not necessarily so and this provides the final axiom of LR 2 L: hoblgiF !
Reference: [Das95b] <author> S. K. Das. </author> <title> A logical reasoning with preference. </title> <booktitle> Decision Support Systems, </booktitle> <volume> 15 </volume> <pages> 19-25, </pages> <year> 1995. </year>
Reference-contexts: In other words, the support d is for the set of assertions uniquely characterised by the set of worlds W 0 . Aggregation of arguments introduces a hierarchy of preferences <ref> [Das95b] </ref> among the set of all possible worlds accessible from w by the relation R t b . The maximal elements and possibly some elements from the top of the hierarchy of this preference structure will be called goal worlds.
Reference: [Dav92] <author> R. Davis. </author> <title> Foundation of Commonsense Reasoning. </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: This is a matter of concern both for developing AI theory and practice (e.g. if KBSs are to be deployed in safety critical applications). The situation is improving rapidly due to the increasing availability of specialised reasoning formalisms (see <ref> [Dav92] </ref> for a discussion of formalisation of common sense concepts and [KC93] for a review of quantitative and logical approaches to hypothetical reasoning).
Reference: [DFK96] <author> S. K. Das, J. Fox, and P. Krause. </author> <title> A unified framework for hypothetical and practical reasoning (1): </title> <booktitle> theoretical foundations. In to appear in The Proceedings of the International Conference on Formal and Applied Practical Reasoning. </booktitle> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1996. </year>
Reference-contexts: The project aimed to address theoretical and practical issues, notably concerned with soundness and safety of such agents. It has resulted in a consolidated architecture which has a number of features of theoretical interest <ref> [DFK96] </ref>) and has been demonstrated on a range of medical applications [FD96]. The paper is intended to provide a sufficiently comprehensive presentation to permit applications designers and experimentalists to reconstruct it and explore its operational properties, and theoreticians to analyse its properties with respect to formal work in the literature. <p> In the rest of the paper we consider only closed LR 2 L formulae with respect to temporal variables. Axioms of LR 2 L The axioms of LR 2 L is divided into classical, temporal [DHss] and modal <ref> [DFK96] </ref>. Classical axioms We consider every instance of a propositional tautology to be an axiom. Those instances of propositional tautologies can be constructed using temporal propositions may involve any number of modal operators, for example, hbelip (i 1 ; i 2 ) ! hbelip (i 1 ; i 2 ). <p> A formula F is said to be valid if F is true in every model. The soundness and completeness result can be stated as follows (see <ref> [DHss, DFK96] </ref> for detail): for every formula F 2 LR 2 L, j= F if and only if ` F . A flexible architecture for autonomous agents 30 Medical example This example illustrates the semantics presented in the previous section.
Reference: [DHss] <author> S. K. Das and P. Hammond. </author> <title> Managing tasks using an interval-based temporal logic. </title> <journal> Journal of Applied Intelligence, </journal> <note> in press. </note>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time <ref> [DHss] </ref> is interval-based [All84, Hum79, HS91], first-order [Hau87, Sho87, McD82], discrete and linear [EH86, vB91] in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them. <p> In the rest of the paper we consider only closed LR 2 L formulae with respect to temporal variables. Axioms of LR 2 L The axioms of LR 2 L is divided into classical, temporal <ref> [DHss] </ref> and modal [DFK96]. Classical axioms We consider every instance of a propositional tautology to be an axiom. <p> A formula F is said to be valid if F is true in every model. The soundness and completeness result can be stated as follows (see <ref> [DHss, DFK96] </ref> for detail): for every formula F 2 LR 2 L, j= F if and only if ` F . A flexible architecture for autonomous agents 30 Medical example This example illustrates the semantics presented in the previous section.
Reference: [DW89] <author> S. K. Das and M. H. Williams. </author> <title> A path finding method for checking integrity in deductive databases. </title> <journal> Data and Knowledge Engineering, </journal> <volume> 4 </volume> <pages> 223-244, </pages> <year> 1989. </year>
Reference-contexts: Meta-level reasoning is also required to ensure that the constraints satisfy the knowledge base, that is, each constraint is a theorem of the knowledge base. We have employed an extension of path finding method <ref> [DW89] </ref> to achieve this. Syntax of LR 2 L Suppose P is the set of all propositions, divided into properties and actions and includes the special property symbol &gt; (true). The set of integers represents constants or time points in the logic, and we have the usual arithmetic function symbols.
Reference: [EH86] <author> E. A. Emerson and J. Y. Halpern. </author> <title> `Sometime' and `Not Never' revisited: on branching versus linear time temporal logic. </title> <journal> Journal of the Association of Computing Machinery, </journal> <volume> 33 </volume> <pages> 151-178, </pages> <year> 1986. </year>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based [All84, Hum79, HS91], first-order [Hau87, Sho87, McD82], discrete and linear <ref> [EH86, vB91] </ref> in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them. Although the underlying language of LR 2 L is temporal propositional we allow temporal quantifications and arithmetic expressions, for manipulation of temporal intervals.
Reference: [FD96] <author> J. Fox and S. K. Das. </author> <title> A unified framework for hypothetical and practical reasoning (2): lessons from medical applications. </title> <booktitle> In to appear in The Proceedings of the International Conference on Formal and Applied Practical Reasoning. </booktitle> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1996. </year>
Reference-contexts: The project aimed to address theoretical and practical issues, notably concerned with soundness and safety of such agents. It has resulted in a consolidated architecture which has a number of features of theoretical interest [DFK96]) and has been demonstrated on a range of medical applications <ref> [FD96] </ref>. The paper is intended to provide a sufficiently comprehensive presentation to permit applications designers and experimentalists to reconstruct it and explore its operational properties, and theoreticians to analyse its properties with respect to formal work in the literature. <p> In earlier work we have therefore developed an explicit framework to address these problems. "Symbolic decision theory" incorporates a set of inference processes that, together, implement a complete problem solving and decision cycle ([DFK96] <ref> [FD96] </ref>). Symbolic Decision Theory is formalised using classical predicate logic and a number of non-classical logics for specialised forms of inference which are required (e.g. for hypothesis generation, argumentation about decision options, and commitment; [Fox91, FK92]. <p> Within this limitation on the autonomy of the applications built to date we believe that our examples provide good evidence of the practical viability of the model. An overview of the medical applications demonstrated so far can be found in <ref> [FD96] </ref>. 8 Conclusions We have presented a general framework for the design of knowledge-based agents which is intended to incorporate a more comprehensive account of decision making and action execution than other agent designs, and avoids the ad hoc features of many knowledge based systems.
Reference: [FDE94] <author> J. Fox, S. K. Das, and D. Elsdon. </author> <title> Decision making and planning in autonomous systems: theory, </title> <booktitle> technology and applications. In Proceedings of the ECAI Workshop on Decision Theory for DAI Applications, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: In particular the atomic actions of a plan must be scheduled with respect to any other actions which have been previously scheduled as a result of problem-solving or decision processes required for achieving the goal, or other goals raised by the agent <ref> [FDE94] </ref>. Note that the present work is not concerned with the process of constructing plans, but only with making choices between alternative prepared plans, and carrying them out.
Reference: [FH88] <author> R. Fagin and J. Y. Halpern. </author> <title> Belief, awareness and limited reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 34 </volume> <pages> 39-76, </pages> <year> 1988. </year>
Reference-contexts: Ordering and equality relations are added to the logic as two special predicate symbols. Suppose D is an arbitrary dictionary with the the top element 4. The modal operators of LR 2 L corresponding to belief <ref> [FH88, Hin62] </ref>, goal [CL90] and obligations [Aqv85, Che80, vW51] are hbeli, hgoali and hoblgi respectively. In addition, for each dictionary symbol d 2 D, we have a modal operator hsup d i for support. <p> the following axiom: 8t 1 8t 2 (p [t 1 ; t 2 ] ! p (t 1 ; t 2 )) (4) A flexible architecture for autonomous agents 26 Modal axioms of LR 2 L We adopt a set of standard axioms of beliefs which can be found in <ref> [CL90, FH88, HM85, MvdHV91] </ref>: :hbeli ? (5) hbeliF ^ hbeli (F ! G) ! hbeliG (6) hbeliF ! hbelihbeliF (7) :hbeliF ! hbeli:hbeliF (8) Axiom (5) expresses that an inconsistency is not believable by a decision maker. The derivation of the symbol ? from the database implies inconsistency.
Reference: [FK92] <author> J. Fox and P. Krause. </author> <title> Qualitative frameworks for decision support: lessons from medicine. </title> <journal> The Knowledge Engineering Review, </journal> <volume> 7 </volume> <pages> 19-33, </pages> <year> 1992. </year>
Reference-contexts: Symbolic Decision Theory is formalised using classical predicate logic and a number of non-classical logics for specialised forms of inference which are required (e.g. for hypothesis generation, argumentation about decision options, and commitment; <ref> [Fox91, FK92] </ref>. Other authors have proposed classical and non-classical logics for building decision support systems [BHW81, CH85, BK94], but we have placed greater emphasis in our work on developing an explicit theory of decision-making under uncertainty, as A flexible architecture for autonomous agents 8 summarised in the above decision cycle.
Reference: [FKA92] <author> J. Fox, P. J. Krause, and S. Ambler. </author> <title> Arguments, contradictions and practical reasoning. </title> <booktitle> In Proceedings of the European Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: In classical logic an argument is a sequence of inferences leading to a conclusion. The usual interest of the logician is in procedures by which arguments may be used to establish the validity (truth or falsity) of a formula. In LA (a logic of argumentation <ref> [FKA92, KAEGF95] </ref>, a variant of intuitionistic logic which defines a set of inference rules for constructing arguments) arguments do not necessarily prove formulae but may merely indicate support for (or doubt about) them. <p> An argument schema is like an ordinary inference rule with support (&lt;candidate&gt;, &lt;sign&gt;) as its consequent, where &lt;sign&gt; is drawn from a dictionary of qualitative or quantitative repre sentations of support candidate <ref> [FKA92, KAEGF95] </ref>. An example of an R 2 L argument is elderly =&gt; support (cancer, d1) where F is cancer, the ground is elderly =&gt; cancer and the support is d1. <p> This meta-predicate has the form: netsupport (&lt;candidate&gt;, &lt;support&gt;) It computes the support for the specified candidate using an aggregation algorithm (discussed in Appendix A) selected from a library of aggregation algorithms <ref> [FKA92, KAEGF95] </ref>. The netsupport meta-predicates computes the support for the specified candidate by using the argument schemas specified in arguments. Not every decision (commitment) requires the netsupport meta-predicate. Consider the following example in which we require an "eager" commitment rule which will immediately respond to any hazardous situation that occurs. <p> For example, elements ++ and 1 are the top elements of the two dictionaries dict (Qual) and dict (P rob) respectively. A number of different dictionaries for reasoning under uncertainty have been discussed in <ref> [FKA92, KAEGF95] </ref>, together with their mathematical foundations and their relation to classical probability and other uncertainty formalisms.
Reference: [Fox91] <author> J. Fox. </author> <title> Decision support systems and qualitative and reasoning. </title> <booktitle> In Proceedings of the IMACS International Workshop on Decision Support Systems and Qualitative Reasoning, </booktitle> <pages> pages 43-62. </pages> <publisher> North-Holland, </publisher> <month> March </month> <year> 1991. </year> <title> A flexible architecture for autonomous agents 35 </title>
Reference-contexts: Symbolic Decision Theory is formalised using classical predicate logic and a number of non-classical logics for specialised forms of inference which are required (e.g. for hypothesis generation, argumentation about decision options, and commitment; <ref> [Fox91, FK92] </ref>. Other authors have proposed classical and non-classical logics for building decision support systems [BHW81, CH85, BK94], but we have placed greater emphasis in our work on developing an explicit theory of decision-making under uncertainty, as A flexible architecture for autonomous agents 8 summarised in the above decision cycle.
Reference: [Fox93] <author> J. Fox. </author> <title> On the soundness and safety of expert systems. </title> <journal> Artificial Intelligence in Medicine, </journal> <volume> 5 </volume> <pages> 159-179, </pages> <year> 1993. </year>
Reference-contexts: This section addresses this difficulty by proposing that systems should be able to explicitly anticipate possible hazards at runtime <ref> [Fox93, HHDW94] </ref>. The safety of a decision support system [Das95a] is the property that any actions recommended by the system will have minimal undesirable consequences. <p> However, soundness is a necessary but not sufficient condition for safe decision making <ref> [Fox93] </ref>. Even if an R 2 L decision engine is properly specified, formally verified and correctly implemented it may still give advice which is wrong and even unsafe.
Reference: [Hau87] <author> B. A. Haugh. </author> <title> Non-standard semantics for the method of temporal arguments. </title> <booktitle> In Proceedings of the 10th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 449-455, </pages> <year> 1987. </year>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based [All84, Hum79, HS91], first-order <ref> [Hau87, Sho87, McD82] </ref>, discrete and linear [EH86, vB91] in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them.
Reference: [Her95] <author> S. I. Herbert. </author> <title> Informatics for care protocols and guidelines: towards a European knowledge model. </title> <editor> In C. Gordon and J. P. Christensen, editors, </editor> <booktitle> Health Telematics for Clinical Guidelines and Protocols, </booktitle> <pages> pages 27-42. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, </address> <year> 1995. </year>
Reference-contexts: This particular control scheme has proved adequate for the scheduling required by the medical applications we have looked at, though a more complex control scheme could be introduced. More complex schemes have been suggested (e.g. for executing general medical therapy plans <ref> [Her95] </ref> though it is not currently clear what the general requirements of a more elaborate scheme are. Currently the default behaviour of the agent's scheduling functions is only to recommend that pre-conditions should be brought about or particular plan/actions be performed at particular times.
Reference: [HHDW94] <author> P. Hammond, A. L. Harris, S. K. Das, and J. C. Wyatt. </author> <title> Safety and decision support in oncology. </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> 33 </volume> <pages> 371-381, </pages> <year> 1994. </year>
Reference-contexts: Action2 is necessary part of Plan AND Action2 produces Effect AND Effect is potentially hazardous AND Action1 aggravates or makes Effect more likely AND Action1 has alternative without Effect This is a safety principle which was abstracted by a careful analysis of about 50 cancer treatment protocols by Peter Hammond <ref> [HHDW94] </ref>. Nine safety principles of this kind which can be evaluated during the commitment step were in fact identified. <p> This section addresses this difficulty by proposing that systems should be able to explicitly anticipate possible hazards at runtime <ref> [Fox93, HHDW94] </ref>. The safety of a decision support system [Das95a] is the property that any actions recommended by the system will have minimal undesirable consequences.
Reference: [Hin62] <author> J. Hintikka. </author> <title> Knowledge and Belief. </title> <publisher> Cornell University Press, </publisher> <year> 1962. </year>
Reference-contexts: Ordering and equality relations are added to the logic as two special predicate symbols. Suppose D is an arbitrary dictionary with the the top element 4. The modal operators of LR 2 L corresponding to belief <ref> [FH88, Hin62] </ref>, goal [CL90] and obligations [Aqv85, Che80, vW51] are hbeli, hgoali and hoblgi respectively. In addition, for each dictionary symbol d 2 D, we have a modal operator hsup d i for support.
Reference: [HJF94] <author> J. Huang, N. R. Jennings, and J. Fox. </author> <title> Cooperation in distributed medical care. </title> <booktitle> In Second International Conference on Cooperative Information Systems, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Elsewhere we have proposed a set of primitive message schemas for composing such inter-agent transactions, and for negotiating and revising commitments between agents (e.g. where requests or commands cannot be satisfied due to resource, timing or other limitations) <ref> [HJF94] </ref>.
Reference: [HM85] <author> J. Y. Halpern and Y. O. Moses. </author> <title> A guide to the modal logics of knowledge and belief. </title> <booktitle> In Proceedings of the 9th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 480-490, </pages> <year> 1985. </year>
Reference-contexts: the following axiom: 8t 1 8t 2 (p [t 1 ; t 2 ] ! p (t 1 ; t 2 )) (4) A flexible architecture for autonomous agents 26 Modal axioms of LR 2 L We adopt a set of standard axioms of beliefs which can be found in <ref> [CL90, FH88, HM85, MvdHV91] </ref>: :hbeli ? (5) hbeliF ^ hbeli (F ! G) ! hbeliG (6) hbeliF ! hbelihbeliF (7) :hbeliF ! hbeli:hbeliF (8) Axiom (5) expresses that an inconsistency is not believable by a decision maker. The derivation of the symbol ? from the database implies inconsistency.
Reference: [HS91] <author> J. Y. Halpern and Y. Shoham. </author> <title> A propositional modal logic of time intervals. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 38 </volume> <pages> 935-962, </pages> <year> 1991. </year>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based <ref> [All84, Hum79, HS91] </ref>, first-order [Hau87, Sho87, McD82], discrete and linear [EH86, vB91] in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them.
Reference: [Hum79] <author> I. L. Humberstone. </author> <title> Interval semantics for tense logics: some remarks. </title> <journal> Journal of Philosophical Logic, </journal> <year> 1979. </year>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based <ref> [All84, Hum79, HS91] </ref>, first-order [Hau87, Sho87, McD82], discrete and linear [EH86, vB91] in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them.
Reference: [KAEGF95] <author> P. J. Krause, S. J. Ambler, M. Elvang-Goransson, and J. Fox. </author> <title> A logic of argumentation for uncertain reasoning. </title> <booktitle> Computational Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: In classical logic an argument is a sequence of inferences leading to a conclusion. The usual interest of the logician is in procedures by which arguments may be used to establish the validity (truth or falsity) of a formula. In LA (a logic of argumentation <ref> [FKA92, KAEGF95] </ref>, a variant of intuitionistic logic which defines a set of inference rules for constructing arguments) arguments do not necessarily prove formulae but may merely indicate support for (or doubt about) them. <p> In our system all distinct arguments of candidates are of interest (intuitively, the more arguments we have for F the greater is our knowledge about the validity of F). We therefore distinguish distinct arguments by identifying the unique grounds of each (essentially a normalised proof term in LA <ref> [KAEGF95] </ref>) and a sign drawn from some dictionary which indicates the support provided to F by the argument. <p> An argument schema is like an ordinary inference rule with support (&lt;candidate&gt;, &lt;sign&gt;) as its consequent, where &lt;sign&gt; is drawn from a dictionary of qualitative or quantitative repre sentations of support candidate <ref> [FKA92, KAEGF95] </ref>. An example of an R 2 L argument is elderly =&gt; support (cancer, d1) where F is cancer, the ground is elderly =&gt; cancer and the support is d1. <p> A flexible architecture for autonomous agents 13 The theory of argumentation and methods for aggregating arguments in different representations of uncertainty is reviewed in <ref> [KAEGF95] </ref>. An outline of the concept of a dictionary and its use is given in Appendix A. A commitment rule is like an ordinary rule with one of add (&lt; property &gt; = &lt; temporal property &gt;) schedule (&lt; action &gt; = &lt; temporal action &gt;) as its consequent. <p> This meta-predicate has the form: netsupport (&lt;candidate&gt;, &lt;support&gt;) It computes the support for the specified candidate using an aggregation algorithm (discussed in Appendix A) selected from a library of aggregation algorithms <ref> [FKA92, KAEGF95] </ref>. The netsupport meta-predicates computes the support for the specified candidate by using the argument schemas specified in arguments. Not every decision (commitment) requires the netsupport meta-predicate. Consider the following example in which we require an "eager" commitment rule which will immediately respond to any hazardous situation that occurs. <p> For example, elements ++ and 1 are the top elements of the two dictionaries dict (Qual) and dict (P rob) respectively. A number of different dictionaries for reasoning under uncertainty have been discussed in <ref> [FKA92, KAEGF95] </ref>, together with their mathematical foundations and their relation to classical probability and other uncertainty formalisms.
Reference: [KC93] <author> P. Krause and D. Clark. </author> <title> Representing Uncertain Knowledge: An artificial intelligence approach. </title> <publisher> Intellect, Oxford, </publisher> <year> 1993. </year>
Reference-contexts: The situation is improving rapidly due to the increasing availability of specialised reasoning formalisms (see [Dav92] for a discussion of formalisation of common sense concepts and <ref> [KC93] </ref> for a review of quantitative and logical approaches to hypothetical reasoning). Nevertheless, even modern KBSs are not entirely satisfactory in that they lack a well-defined framework for dealing with all aspects of decision making, and hence a basis for establishing their soundness. <p> Every dictionary has a characteristic aggregation function for aggregating arguments. Consider the argument presented above and the following one: positive_biopsy =&gt; support (cancer, d3) Considering the dictionary as dict (P rob), the two arguments can be aggregated by using a special case of Dempster's epistemic probability <ref> [KC93] </ref> giving the value d1 + d3 d1 fi d3. This formula can be generalised incrementally if there are more than two arguments for the candidate cancer.
Reference: [Lev86] <author> N. G. Leveson. </author> <title> Software safety: why, what, and how. </title> <journal> ACM Computing Surveys, </journal> <volume> 18, </volume> <year> 1986. </year>
Reference-contexts: Formal methods for specifying and verifying safety-critical components of software are also increasingly advocated <ref> [Lev86] </ref>. To build knowledge based systems for safety critical decision making and planning, however, additional techniques are needed because the formal integrity of software and knowledge bases may not be sufficient to ensure that the advice given or actions recommended in complex situations will always be appropriate.
Reference: [McD82] <author> D. V. McDermott. </author> <title> A temporal logic for reasoning about processes and plans. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 101-155, </pages> <year> 1982. </year>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based [All84, Hum79, HS91], first-order <ref> [Hau87, Sho87, McD82] </ref>, discrete and linear [EH86, vB91] in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them.
Reference: [MvdHV91] <author> J.-J. Ch. Meyer, W. van der Hoek, and G. A. W. Vreeswijk. </author> <title> Epistemic logic for computer science: a tutorial (part one). </title> <journal> EATCS, </journal> <volume> 44 </volume> <pages> 242-270, </pages> <year> 1991. </year>
Reference-contexts: the following axiom: 8t 1 8t 2 (p [t 1 ; t 2 ] ! p (t 1 ; t 2 )) (4) A flexible architecture for autonomous agents 26 Modal axioms of LR 2 L We adopt a set of standard axioms of beliefs which can be found in <ref> [CL90, FH88, HM85, MvdHV91] </ref>: :hbeli ? (5) hbeliF ^ hbeli (F ! G) ! hbeliG (6) hbeliF ! hbelihbeliF (7) :hbeliF ! hbeli:hbeliF (8) Axiom (5) expresses that an inconsistency is not believable by a decision maker. The derivation of the symbol ? from the database implies inconsistency.
Reference: [RG91] <author> A. S. Rao and M. P. Georgeff. </author> <title> Modelling rational agents within a BDI-architecture. </title> <booktitle> In Proceedings of the Knowledge Representation and Reasoning, </booktitle> <pages> pages 473-484, </pages> <year> 1991. </year>
Reference-contexts: functions to make decisions under uncertainty in a principled way, and (3) demonstrate ways in which an agent based on the framework can detect hazards and reason about the safety of its actions. 7.2 Agent theory As an agent theory the domino model is similar to the BDI agent concept <ref> [RG91] </ref> in that it shares mentalistic ideas [Sho93] like beliefs, desires (goals), and intentions (plans). The main theoretical extensions to agent theory are the ability to reason about, and make decisions under, uncertainty.
Reference: [Sho87] <author> Y. Shoham. </author> <title> Temporal logics in AI: semantical and ontological considerations. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 89-104, </pages> <year> 1987. </year>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based [All84, Hum79, HS91], first-order <ref> [Hau87, Sho87, McD82] </ref>, discrete and linear [EH86, vB91] in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them.
Reference: [Sho93] <author> Y. Shoham. </author> <title> Agent-oriented programming. </title> <journal> Artificial Intelligence, </journal> <volume> 60 </volume> <pages> 51-92, </pages> <year> 1993. </year> <title> A flexible architecture for autonomous agents 36 </title>
Reference-contexts: a principled way, and (3) demonstrate ways in which an agent based on the framework can detect hazards and reason about the safety of its actions. 7.2 Agent theory As an agent theory the domino model is similar to the BDI agent concept [RG91] in that it shares mentalistic ideas <ref> [Sho93] </ref> like beliefs, desires (goals), and intentions (plans). The main theoretical extensions to agent theory are the ability to reason about, and make decisions under, uncertainty.
Reference: [Tay95] <author> P. Taylor. </author> <title> Decision support for image interpretation: a mammography workstation. </title> <editor> In Bizais, Barillot, and Di Paola, editors, </editor> <booktitle> Image Processing and Medical Imaging. </booktitle> <address> Dordrecht: </address> <publisher> Kluwer, </publisher> <year> 1995. </year>
Reference-contexts: The workstation provides support for clinical decision making and therapy plan management as described here. In addition, however, certain data acquisition operations are implemented with automated image analysis analysis operators which extract information from the image and feed this into the decision making process <ref> [Tay95] </ref>. Autonomous robotic systems are a major goal of artificial intelligence research.
Reference: [VB90] <author> S. Vere and T. Bickmore. </author> <title> A basic agent. </title> <journal> Computational Intelligence, </journal> <volume> 6 </volume> <pages> 41-60, </pages> <year> 1990. </year>
Reference-contexts: Zero-order agents react to environmental conditions (mediated by sensors, command processors, or whatever) and respond by evaluating some function which yields a result or effect. Countless pieces of conventional software (e.g. industrial manipulators, software gophers) and AI systems (e.g. basic agents <ref> [VB90] </ref>, intelligent agents [WJ95]) satisfy this minimal definition. It is consequently somewhat unilluminating since these systems have various other capabilities which we wish to position with respect to the theory of agents.
Reference: [vB91] <editor> J. van Benthem. </editor> <booktitle> The logic of time. </booktitle> <address> Dordrecht, </address> <year> 1991. </year>
Reference-contexts: The approach taken in LR 2 L towards reasoning about time [DHss] is interval-based [All84, Hum79, HS91], first-order [Hau87, Sho87, McD82], discrete and linear <ref> [EH86, vB91] </ref> in nature. Intervals are represented by their boundary time points. All properties and actions in a knowledge base have a time interval associated with them. Although the underlying language of LR 2 L is temporal propositional we allow temporal quantifications and arithmetic expressions, for manipulation of temporal intervals.
Reference: [vW51] <author> G. H. von Wright. </author> <title> Deontic logic. </title> <journal> Mind, </journal> <volume> 60 </volume> <pages> 1-15, </pages> <year> 1951. </year>
Reference-contexts: Ordering and equality relations are added to the logic as two special predicate symbols. Suppose D is an arbitrary dictionary with the the top element 4. The modal operators of LR 2 L corresponding to belief [FH88, Hin62], goal [CL90] and obligations <ref> [Aqv85, Che80, vW51] </ref> are hbeli, hgoali and hoblgi respectively. In addition, for each dictionary symbol d 2 D, we have a modal operator hsup d i for support.
Reference: [Wai94] <author> J. </author> <title> Wainer. Yet another semantics of goals and goal priorities. </title> <booktitle> In Proceedings of the 11th European Conference on Artificial Intelligence, </booktitle> <pages> pages 269-273, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: The exclusion also avoids the unnecessary contributions to the aggregation process for F . We adopt the following two standard axioms of goals <ref> [CL90, Wai94] </ref>: :hgoali ? (13) hgoaliF ^ hgoali (F ! G) ! hgoaliG (14) Axiom (13) says that something that is impossible to achieve cannot be a goal of a decision maker. Axiom (14) states that all the logical consequences of a decision maker's goal are goals themselves. <p> Two such axioms concerned with goals <ref> [Wai94] </ref> are (a) if a decision maker has a goal of having a goal then s/he has this goal and the converse (b) if a decision maker has a goal of not having a goal then s/he has not got this goal and vice versa.
Reference: [WJ95] <author> M. Wooldridge and N. R. Jennings. </author> <title> Intelligent agents: </title> <journal> theory and practice. The Knowledge Engineering Review, </journal> <volume> 10 </volume> <pages> 1-38, </pages> <year> 1995. </year>
Reference-contexts: The heart of this paper is concerned with methods of knowledge representation and reasoning which address these requirements. 2.2 The nature of an intelligent agent A recent review of the theory and practice of intelligent agents <ref> [WJ95] </ref> attempts to define the concept with respect to two general usages. <p> Zero-order agents react to environmental conditions (mediated by sensors, command processors, or whatever) and respond by evaluating some function which yields a result or effect. Countless pieces of conventional software (e.g. industrial manipulators, software gophers) and AI systems (e.g. basic agents [VB90], intelligent agents <ref> [WJ95] </ref>) satisfy this minimal definition. It is consequently somewhat unilluminating since these systems have various other capabilities which we wish to position with respect to the theory of agents. <p> We have several motivations for attempting to construct such a third-order agent: 1. To contribute to the development of agent theory, within the tradition leading from classical automata and planning systems to recent proposals for rational or intelligent agents <ref> [WJ95] </ref>. 2. To experiment with a specific agent technology in order to evaluate its practical advantages over current technologies. This work lies within the tradition of knowledge based systems for knowledge-rich domains, such as medicine. 3. To explore ways of ensuring the safe operation of intelligent agents.
Reference: [WMW89] <author> R. J. Wieringa, J. J. Meyer, and H. Weigand. </author> <title> Specifying dynamic and deontic integrity constraints. </title> <journal> Data and Knowledge Engineering, </journal> <volume> 4 </volume> <pages> 157-189, </pages> <year> 1989. </year>
Reference-contexts: Such constraints help to avoid inconsistent, incomplete and inaccurate knowledge bases and address problems in Group III, (a) and (b). Safety constraints on the other hand are constraints on the behaviour of the system. We model such constraints here in terms of the deontic concepts of obligation and permission <ref> [WMW89] </ref> on system actions.
References-found: 46

