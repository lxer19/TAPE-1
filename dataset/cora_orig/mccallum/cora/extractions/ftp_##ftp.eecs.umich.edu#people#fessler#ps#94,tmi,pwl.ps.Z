URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/94,tmi,pwl.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/jour.html
Root-URL: http://www.eecs.umich.edu
Title: Penalized Weighted Least-Squares Image Reconstruction for Positron Emission Tomography  
Author: Jeffrey A. Fessler, Member IEEE 
Keyword: Emission tomography, image reconstruction, accidental coincidences.  
Date: 13(2):290-300, JUNE 1994. 1  
Note: IEEE TRANS. MEDICAL IMAGING,  
Abstract: This paper presents an image reconstruction method for positron-emission tomography (PET) based on a penalized, weighted least-squares (PWLS) objective. For PET measurements that are precorrected for accidental coincidences, we argue statistically that a least-squares objective function is as appropriate, if not more so, than the popular Poisson likelihood objective. We propose a simple data-based method for determining the weights that accounts for attenuation and detector efficiency. A nonnegative successive over-relaxation (+SOR) algorithm converges rapidly to the global minimum of the PWLS objective. Quantitative simulation results demonstrate that the bias/variance tradeoff of the PWLS+SOR method is comparable to the maximum-likelihood expectation-maximization (ML-EM) method (but with fewer iterations), and is improved relative to the conventional filtered backprojection (FBP) method. Qualitative results suggest that the streak artifacts common to the FBP method are nearly eliminated by the PWLS+SOR method, and indicate that the proposed method for weighting the measurements is a significant factor in the improvement over FBP. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. C. Kak and M. Slaney. </author> <title> Principles of computerized tomographic imaging. </title> <publisher> IEEE Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: To determine the kernel of the matrix P 0 P , Sauer and Bouman projected and then backprojected a point source. Here, we use the following analytical approximation: f (r) = 2r; r 2 <ref> [0; 1] </ref> 2 (arcsin (1=r) + (r p ; which is shown in Figure 2 (cf [40, Fig. 11] and [52, Fig. 1] ). This function has the expected 1=r asymptotic form, but is well behaved near zeroas it must be for a discrete system.
Reference: [2] <author> P. T. Fox, M. A. Mintun, E. M. Reiman, and M. E. Raichle. </author> <title> Enhanced detection of focal brain responses using intersubject averaging and change-distribution analysis of subtracted PET images. Journal of Cerebral Blood Flow and Metabolism, </title> <address> 8(5):642653, </address> <year> 1988. </year>
Reference-contexts: There were about 750K prompt coincidences and 20K delayed coincidences for the slice shown. The noise structure is strikingly different. The reduction in streak artifacts may lead to improved detection of lower contrast lesions. It may also improve the detection of brain activation foci by statistical criteria <ref> [2] </ref>. Readers who are accustomed to simulated ML-EM studies without accidental coincidences may find the grey background in Fig. 9 to be unexpected. This positive bias is apparently due to the unmodeled accidental coincidences events, and continues to persist after hundreds of iterations.
Reference: [3] <author> S. C. Huang, D. K. Mahoney, and M. E. Phelps. </author> <title> Quantitation in positron emission computed tomography: 8. Effects of nonlinear parameter estimation on functional images. </title> <journal> Journal of Computer Assisted Tomography, </journal> <volume> 11(2):314325, </volume> <year> 1987. </year>
Reference-contexts: How one chooses to tradeoff bias and variance is clearly task dependent. For certain kinetic estimation tasks, uptake bias leads to inaccuracies in functional parameters <ref> [3] </ref>. On the other hand, some increase in variance may be tolerable for such tasks since one is generally fitting a low-order parametric model to multiple images. For PWLS+SOR, the parameter fi controls this tradeoff.
Reference: [4] <author> E. J. Hoffman, S. C. Huang, and M. E. Phelps. </author> <title> Quantitation in positron emission computed tomography: 1. Effect of object size. </title> <journal> Journal of Computer Assisted Tomography, </journal> <volume> 3(3):299308, </volume> <year> 1979. </year>
Reference: [5] <author> J. S. Liow and S. C. Strother. </author> <title> Practical tradeoffs between noise, quantita-tion, and number of iterations for maximum likelihood-based reconstructions. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 10(4):563571, </volume> <month> December </month> <year> 1991. </year>
Reference: [6] <author> J. S. Liow and S. C. Strother. </author> <title> The quantitative performance of maximum likelihood based reconstruction with image wide resolution convergence. Journal of Nuclear Medicine (Abstract Book), </title> <address> 33(5):871, </address> <month> May </month> <year> 1992. </year>
Reference: [7] <author> J. A. Fessler, W. L. Rogers, N. H. Clinthorne, G. D. Hutchins, and R. A. Koeppe. </author> <title> Quantification of the human basal ganglia via iterative reconstruction. Journal of Nuclear Medicine (Abstract Book), </title> <address> 33(5):878, </address> <month> May </month> <year> 1992. </year>
Reference: [8] <author> G. T. Herman. </author> <title> Image Reconstruction from Projections: The Fundamentals of Computerized Tomography. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: There may be non-quadratic penalty functions that result in an even more favorable bias-variance tradeoff. It remains to be seen whether or not the benefits of such penalty functions are significant enough to outweigh the increased computational requirements for a non-quadratic objective. As observed by Herman <ref> [8, p. 107] </ref> long before the advent of fast workstations: It is unlikely that an efficacious reconstruction algorithm would for long remain unused solely because of computational reasons.
Reference: [9] <author> R. M. Lewitt. </author> <title> Multidimensional digital image representations using generalized Kaiser-Bessel window functions. </title> <journal> J. Optical Society Amer. Ser. A, </journal> <volume> 7(10):18341846, </volume> <month> October </month> <year> 1990. </year>
Reference: [10] <author> M. A. Mintun, P. T. Fox, and M. E. Raichle. </author> <title> A highly accurate method of localizing regions of neuronal activity in the human brain with positron emission tomography. Journal of Cerebral Blood Flow and Metabolism, </title> <address> 9(1):96103, </address> <year> 1989. </year>
Reference: [11] <author> S. C. Huang, E. J. Hoffman, M. E. Phelps, and D. E. Kuhl. </author> <title> Quantitation in positron emission computed tomography: 3. Effect of sampling. </title> <journal> Journal of Computer Assisted Tomography, </journal> <volume> 4(6):819826, </volume> <year> 1980. </year>
Reference: [12] <author> R. H. Huesman. </author> <title> The effects of a finite number of projection angles and finite lateral sampling of projections on the propagation of statistical errors in transverse section reconstruction. </title> <journal> Phys. Med. Biol., </journal> <volume> 22(3):511521, </volume> <year> 1977. </year>
Reference: [13] <author> A. O. Hero, J. A. Fessler, and W. L. Rogers. </author> <title> A fast recursive algorithm for computing CR-type bounds for image reconstruction problems. </title> <booktitle> In Conf. Record of the IEEE Nuclear Science Symposium and Medical Imaging Conference, </booktitle> <volume> volume 2, </volume> <pages> pages 11881190, </pages> <year> 1992. </year>
Reference: [14] <author> A. O. Hero and J. A. Fessler. </author> <title> A recursive algorithm for computing CR-type bounds on estimator covariance. </title> <journal> IEEE Transactions on Information Theory, </journal> <note> 1993. In press. </note>
Reference: [15] <author> J. A. Fessler and A. O. Hero. </author> <title> Cramer-Rao bounds for biased estimators in image restoration. </title> <booktitle> In Proc. Midwest Symposium on Circuits and Systems, </booktitle> <year> 1993. </year>
Reference: [16] <author> D. G. Politte and D. L. Snyder. </author> <title> Corrections for accidental coincidences and attenuation in maximum-likelihood image reconstruction for positron-emission tomography. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 10(1):8289, </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: Alternatively, one could exploit the spatial smoothness of AC events, form an estimate of their means using the delayed-window measurements, and then incorporate those estimates as known AC means into the ML-IB method of Politte and Snyder <ref> [16] </ref>. In principle such methods would have the advantage that they retain the higher-order moments associated with the skewness of the Poisson distribution, whereas a Gaussian approximation only models the first and second moments. Whether that theoretical advantage produces practical improvements is an open question. <p> When AC effects are included in the Poisson case, the ML-IB method of Politte and Snyder apparently requires that the resolution and kernel sieves be equal, in which case the method of sieves is equivalent 4 to post-filtering the ML image estimate <ref> [16] </ref>. Therefore the method of sieves retains the slow convergence of the ML-EM algorithm, for which a few hundred [33], if not several thousand [6,35] iterations are required. A more flexible approach is to incorporate a smoothness penalty or prior [36,37,38,39], which is particularly straightforward with the WLS similarity measure.
Reference: [17] <author> C. E. Floyd, R. J. Jaszczak, and R. E. Coleman. </author> <title> Inverse Monte Carlo: A unified reconstruction algorithm for SPECT. </title> <journal> IEEE Transactions on Nuclear Science, </journal> <volume> 32(1):779785, </volume> <month> February </month> <year> 1985. </year>
Reference: [18] <author> B. W. Silverman, M. C. Jones, J. D. Wilson, and D. W. Nychka. </author> <title> A smoothed EM approach to indirect estimation problems, with particular reference to stereology and emission tomography. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 52(2):271324, </volume> <year> 1990. </year>
Reference: [19] <author> G. Germano and E. J. Hoffman. </author> <title> An investigation of methods for pileup rejection for 2-D array detectors employed in high resolution PET. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 10(2):223227, </volume> <month> June </month> <year> 1991. </year>
Reference: [20] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 39(1):138, </volume> <year> 1977. </year>
Reference: [21] <author> L. A. Shepp and Y. Vardi. </author> <title> Maximum likelihood reconstruction for emission tomography. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 1(2):113122, </volume> <month> October </month> <year> 1982. </year>
Reference: [22] <author> K. Lange and R. Carson. </author> <title> EM reconstruction algorithms for emission and transmission tomography. </title> <journal> Journal of Computer Assisted Tomography, </journal> <volume> 8(2):306316, </volume> <month> April </month> <year> 1984. </year>
Reference-contexts: If one could acquire separate sinograms for the prompt and delayed coincidences, then one could consider jointly estimating 2 the AC means and the j 's from the two sinograms <ref> [22] </ref>. Alternatively, one could exploit the spatial smoothness of AC events, form an estimate of their means using the delayed-window measurements, and then incorporate those estimates as known AC means into the ML-IB method of Politte and Snyder [16].
Reference: [23] <author> A. J. Rockmore and A. Macovski. </author> <title> A maximum likelihood approach to emission image reconstruction from projections. </title> <journal> IEEE Transactions on Nuclear Science, </journal> <volume> 23:14281432, </volume> <year> 1976. </year>
Reference: [24] <author> Y. Vardi, L. A. Shepp, and L. Kaufman. </author> <title> A statistical model for positron emission tomography. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 80(389):837, </volume> <month> March </month> <year> 1985. </year>
Reference: [25] <author> E. J. Hoffman, S. C. Huang, M. E. Phelps, and D. E. Kuhl. </author> <title> Quantita-tion in positron emission computed tomography: 4. Effect of accidental coincidences. </title> <journal> Journal of Computer Assisted Tomography, </journal> <volume> 5(3):391400, </volume> <year> 1981. </year>
Reference: [26] <author> M. E. Casey and E. J. Hoffman. </author> <title> Quantitation in positron emission computed tomography: 7. A technique to reduce noise in accidental coincidence measurements and coincidence efficiency calibration. </title> <journal> Journal of Computer Assisted Tomography, </journal> <volume> 10(5):845850, </volume> <year> 1986. </year>
Reference: [27] <author> A. Gelman. </author> <title> Topics in Image Reconstruction for Emission Tomography. </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <address> Cambridge, MA., </address> <month> April </month> <year> 1990. </year>
Reference: [28] <author> T. J. Spinks, T. Jones, M. C. Gilardi, and J. D. Heather. </author> <title> Physical performance of the latest generation of commercial positron scanner. </title> <journal> IEEE Transactions on Nuclear Science, </journal> <volume> 35(1):721725, </volume> <month> February </month> <year> 1988. </year>
Reference: [29] <author> R. Billingsley. </author> <title> Probability and Measure. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: The bottom figure shows the approximation by a Gaussian distribution also with mean 9 and with variance 11. As measured by the O 2 statistic, the Gaussian distribution is the better approximation. Of course for large means, the Poisson distribution is also approximately Gaussian by the Central Limit Theorem <ref> [29] </ref>. But this example illustrates that even for small true rates and 10% accidental coincidence rates, a Gaussian approximation is as appropriate, if not more so, than the Poisson approximation.
Reference: [30] <author> N. H. Clinthorne, J. A. Fessler, G. D. Hutchins, and W. L. Rogers. </author> <title> Joint maximum likelihood estimation of emission and attenuation densities in PET. </title> <booktitle> In Conf. Record of the IEEE Nuclear Science Symposium and Medical Imaging Conference, </booktitle> <volume> volume 3, </volume> <pages> pages 19271932, </pages> <year> 1991. </year> <note> FESSLER: PWLS PET RECONSTRUCTION 9 </note>
Reference: [31] <author> J. A. Fessler, N. H. Clinthorne, and W. Leslie Rogers. </author> <title> On complete data spaces for PET reconstruction algorithms. </title> <journal> IEEE Transactions on Nuclear Science, </journal> <volume> 40(4):10551061, </volume> <month> August </month> <year> 1993. </year>
Reference: [32] <author> D. L. Snyder and M. I. Miller. </author> <title> The use of sieves to stabilize images produced with the EM algorithm for emission tomography. </title> <journal> IEEE Transactions on Nuclear Science, </journal> <volume> 32(5):38643871, </volume> <month> October </month> <year> 1985. </year>
Reference-contexts: Objective Function Objective functions based solely on the measurement statistics, be they Poisson or Gaussian, perform poorly due to the ill-conditioned nature of tomographic reconstruction. Unregular-ized methods produce increasingly noisy images with iteration <ref> [32] </ref>. To remedy this problem, several regularization methods have been investigated that impose smoothness constraints on the image estimate. One approach is the method of sieves [33,34].
Reference: [33] <author> D. L. Snyder, M. I. Miller, L. J. Thomas, and D. G. Politte. </author> <title> Noise and edge artifacts in maximum-likelihood reconstructions for emission tomography. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 6(3):228238, </volume> <month> September </month> <year> 1987. </year>
Reference-contexts: Therefore the method of sieves retains the slow convergence of the ML-EM algorithm, for which a few hundred <ref> [33] </ref>, if not several thousand [6,35] iterations are required. A more flexible approach is to incorporate a smoothness penalty or prior [36,37,38,39], which is particularly straightforward with the WLS similarity measure. <p> Many penalty functions R () have been proposed for image reconstruction [36,37,41,42,43,44,45,46], some of which aim 4 Under the often disregarded assumption that the smoothing operator and the projection operator commute <ref> [33, eqn. (12)] </ref>. 4 IEEE TRANS. MEDICAL IMAGING, 13 (2):290-300, JUNE 1994. to smooth uniform regions while maintaining edge sharpness.
Reference: [34] <author> S. Geman and C. R. Hwang. </author> <title> Nonparametric maximum likelihood estimation by the method of sieves. </title> <journal> The Annals of Statistics, </journal> <volume> 10(2):401414, </volume> <year> 1982. </year>
Reference: [35] <author> T. R. Miller, J. W. Wallis, C. S. Butler, M. I. Miller, and D. L. Snyder. </author> <title> Improved brain SPECT by maximum-likelihood reconstruction. Journal of Nuclear Medicine (Abstract Book), </title> <address> 33(5):964, </address> <month> May </month> <year> 1992. </year>
Reference: [36] <author> S. Geman and D. E. McClure. </author> <title> Bayesian image analysis: An application to single photon emission tomography. </title> <journal> In Proc. of Stat. Comp. Sect. of Amer. Stat. Assoc., </journal> <pages> pages 1218, </pages> <year> 1985. </year>
Reference: [37] <author> S. Geman and D. E. McClure. </author> <title> Statistical methods for tomographic image reconstruction. </title> <journal> Proc. 46 Sect. ISI, Bull. ISI, </journal> <volume> 52:521, </volume> <year> 1987. </year>
Reference: [38] <author> Z. Liang, R. Jaszczak, and K. </author> <title> Greer. On Bayesian image reconstruction from projections: Uniform and nonuniform a priori source information. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 8(3):227235, </volume> <month> September </month> <year> 1989. </year>
Reference: [39] <author> J. A. Fessler, N. H. Clinthorne, and W. L. Rogers. </author> <title> Regularized emission image reconstruction using imperfect side information. </title> <journal> IEEE Transactions on Nuclear Science, </journal> <volume> 39(5):14641471, </volume> <month> October </month> <year> 1992. </year>
Reference: [40] <author> K. Sauer and C. Bouman. </author> <title> A local update strategy for iterative reconstruction from projections. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 41(2):534548, </volume> <month> February </month> <year> 1993. </year>
Reference-contexts: A more flexible approach is to incorporate a smoothness penalty or prior [36,37,38,39], which is particularly straightforward with the WLS similarity measure. Sauer and Bouman <ref> [40] </ref> have proposed one approach in the context of X-ray transmission tomography that we have adapted to PET reconstruc tion. <p> A special case of the +SOR method is the Gauss-Siedel algorithm [49,50], which has been applied to transmission tomography by Sauer and Bouman <ref> [40] </ref>. In the Bayesian literature it is known as ICM [51]. The +SOR algorithm updates each image parameter individually by minimizing the objective function (6) over that parame ter while holding the other parameters fixed. Since our objective is quadratic, the minimization is computed analytically (no line searches are required). <p> Furthermore, if ! 2 (0; 1], then the sequence of estimates monotonically decreases . The convergence rate of the SOR algorithm depends on !. Sauer and Bouman analyzed the convergence properties of Gauss-Siedel (! = 1) <ref> [40] </ref>, and in the remainder of this section we apply their analysis method to SOR. First, decompose the Hessian (8) by: H = L + D + L ; where D is the diagonal of H , and L is a strictly lower triangu lar matrix. <p> can be compactly written [47]: = (1 !) + !D (A or i+1 0 i 0 1 This sequence converges geometrically, and its convergence rate is governed by the eigenvalues of G ! = (D + !L) 1 ((! 1)D + !L ) (11) FESSLER: PWLS PET RECONSTRUCTION 5 (cf <ref> [40, eqn. (24)] </ref> for ! = 1). To analyze the eigenvalues of G ! as a function of !, we adopt simplifications similar to those in [40], i.e.: = oe 2 I, and the matrices P 0 P , R, and H are circulant-block-circulant. <p> To analyze the eigenvalues of G ! as a function of !, we adopt simplifications similar to those in <ref> [40] </ref>, i.e.: = oe 2 I, and the matrices P 0 P , R, and H are circulant-block-circulant. The latter assumption implies that multiplication by any of these matrices is equivalent to periodic convolution of the image by a spatially-invariant 2D kernel. <p> Here, we use the following analytical approximation: f (r) = 2r; r 2 [0; 1] 2 (arcsin (1=r) + (r p ; which is shown in Figure 2 (cf <ref> [40, Fig. 11] </ref> and [52, Fig. 1] ). This function has the expected 1=r asymptotic form, but is well behaved near zeroas it must be for a discrete system. <p> Then the eigenvalues of G ! are given by g ! (f x ; f y ) = K D + ! l (f x ; f y ) where ? denotes complex conjugate (cf (11) and <ref> [40, eqn. (25)] </ref> ). Figures 3 and 4 show plots of max jg ! (f x ; )j and max jg ! (; f y )j for fi = 1 and a few values of !. <p> The threshold of 7 ensures that the method is not overly sensitive to bins with only a few counts. ACKNOWLEDGEMENT The author thanks K. Sauer for generously providing a preprint of <ref> [40] </ref>, W. L. Rogers for reading and suggesting improvements to the paper, N. Clinthorne, A. Hero, and P. Chiao for ongoing debates and thoughtful questions, R. Wahl for suggesting the FDG application, and a reviewer for noting the relationship to linear complementarity.
Reference: [41] <author> T. Hebert and R. Leahy. </author> <title> A generalized EM algorithm for 3-D Bayesian reconstruction from Poisson data using Gibbs priors. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 8(2):194202, </volume> <month> June </month> <year> 1989. </year>
Reference: [42] <author> K. Lange. </author> <title> Convergence of EM image reconstruction algorithms with Gibbs smoothing. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 9(4):439446, </volume> <month> December </month> <year> 1990. </year> <title> Corrections, </title> <month> June </month> <year> 1991. </year>
Reference: [43] <author> P. J. Green. </author> <title> Bayesian reconstructions from emission tomography data using a modified EM algorithm. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 9(1):8493, </volume> <month> March </month> <year> 1990. </year>
Reference: [44] <author> V. E. Johnson, W. H. Wong, X. Hu, and C. T. Chen. </author> <title> Image restoration using Gibbs priors: Boundary modeling, treatment of blurring, and selection of hyperparameter. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(5):413425, </volume> <month> May </month> <year> 1991. </year>
Reference: [45] <author> I. G. Zubal, M. Lee, A. Rangarajan, C. R. Harrell, and G. Gindi. </author> <title> Bayesian reconstruction of SPECT images using registered anatomical images as priors. Journal of Nuclear Medicine (Abstract Book), </title> <address> 33(5):963, </address> <month> May </month> <year> 1992. </year>
Reference: [46] <author> D. S. Lalush and B. M. W. Tsui. </author> <title> A generalized Gibbs prior for maximum a posteriori-EM SPECT reconstruction with fast and stable convergence properties. Journal of Nuclear Medicine (Abstract Book), </title> <address> 33(5):832, </address> <month> May </month> <year> 1992. </year>
Reference: [47] <author> K. G. Murty. </author> <title> Linear Complementarity, Linear and Nonlinear Programming. </title> <publisher> Helderman Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: Although successive algorithms are difficult to parallelize in general, parallel methods for +SOR are available [48]. F. Convergence Properties Since is strictly convex by Theorem 1, it follows from <ref> [47, p. 465] </ref> that there is a unique ^ 0 that minimizes (i.e., satisfies the Karush-Kuhn-Tucker conditions [47, p. 560] ), and that the +SOR sequence converges from any initial estimate to that unique minimum for ! 2 (0; 2) [47, p. 372] ). <p> Although successive algorithms are difficult to parallelize in general, parallel methods for +SOR are available [48]. F. Convergence Properties Since is strictly convex by Theorem 1, it follows from [47, p. 465] that there is a unique ^ 0 that minimizes (i.e., satisfies the Karush-Kuhn-Tucker conditions <ref> [47, p. 560] </ref> ), and that the +SOR sequence converges from any initial estimate to that unique minimum for ! 2 (0; 2) [47, p. 372] ). Furthermore, if ! 2 (0; 1], then the sequence of estimates monotonically decreases . <p> Since is strictly convex by Theorem 1, it follows from [47, p. 465] that there is a unique ^ 0 that minimizes (i.e., satisfies the Karush-Kuhn-Tucker conditions [47, p. 560] ), and that the +SOR sequence converges from any initial estimate to that unique minimum for ! 2 (0; 2) <ref> [47, p. 372] </ref> ). Furthermore, if ! 2 (0; 1], then the sequence of estimates monotonically decreases . The convergence rate of the SOR algorithm depends on !. <p> First, decompose the Hessian (8) by: H = L + D + L ; where D is the diagonal of H , and L is a strictly lower triangu lar matrix. Then without the nonnegativity constraint, the SOR method can be compactly written <ref> [47] </ref>: = (1 !) + !D (A or i+1 0 i 0 1 This sequence converges geometrically, and its convergence rate is governed by the eigenvalues of G ! = (D + !L) 1 ((! 1)D + !L ) (11) FESSLER: PWLS PET RECONSTRUCTION 5 (cf [40, eqn. (24)] for !
Reference: [48] <author> W. Niethammer. </author> <title> A note on the implementation of the successive overre-laxation method for linear complementarity problems. Numerical Algorithms, </title> <address> 4(1):197200, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Note that the updates to ^ are done sequentially in place, in contrast to most reconstruction algorithms that simultaneously update all pixels. Although successive algorithms are difficult to parallelize in general, parallel methods for +SOR are available <ref> [48] </ref>. F.
Reference: [49] <author> D. M. Young. </author> <title> Iterative Solution of Large Linear Systems. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1971. </year>
Reference: [50] <author> G. Gullberg et al. </author> <title> Maximum entropy reconstruction with constraints: iterative algorithms for solving the primal and dual programs. </title> <editor> In C. N. de Graaf and M. A. Viergever, editors, </editor> <booktitle> Proc. Tenth Intl. Conf. on Information Processing in Medical Imaging, </booktitle> <pages> pages 181200. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [51] <author> J. Besag. </author> <title> On the statistical analysis of dirty pictures. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 48(3):259302, </volume> <year> 1986. </year>
Reference-contexts: A special case of the +SOR method is the Gauss-Siedel algorithm [49,50], which has been applied to transmission tomography by Sauer and Bouman [40]. In the Bayesian literature it is known as ICM <ref> [51] </ref>. The +SOR algorithm updates each image parameter individually by minimizing the objective function (6) over that parame ter while holding the other parameters fixed. Since our objective is quadratic, the minimization is computed analytically (no line searches are required).
Reference: [52] <author> N. H. Clinthorne, T. S. Pan, P. C. Chiao, W. L. Rogers, and J. A. Sta-mos. </author> <title> Preconditioning methods for improved convergence rates in iterative reconstructions. </title> <journal> IEEE Transactions on Medical Imaging, </journal> <volume> 12(1):7883, </volume> <month> March </month> <year> 1993. </year>
Reference-contexts: Here, we use the following analytical approximation: f (r) = 2r; r 2 [0; 1] 2 (arcsin (1=r) + (r p ; which is shown in Figure 2 (cf [40, Fig. 11] and <ref> [52, Fig. 1] </ref> ). This function has the expected 1=r asymptotic form, but is well behaved near zeroas it must be for a discrete system.
Reference: [53] <author> P. J. Green. </author> <title> Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resistant alternatives. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 46(2):149192, </volume> <year> 1984. </year>
Reference-contexts: There remain several questions pertaining to the PWLS method that may be worth pursuing. These include: 1) What is the optimal voxel size? 2) How should the different system response for direct and cross planes be incorporated? 3) Would a method such as iteratively-reweighted least-squares <ref> [53] </ref> for variance estimation improve performance enough to offset its considerable computational cost? (The results of our comparison using ideal variances suggest not.) and 4) Should the non-negativity constraint be enforced in all situations? If the non-negativity constraint is unneeded or undesirable for some tasks, then there may be even faster

References-found: 53

