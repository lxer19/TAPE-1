URL: ftp://ftp.cs.wisc.edu/tech-reports/reports/91/tr1005.ps.Z
Refering-URL: http://www.cs.wisc.edu/~arch/uwarch/tech_reports/tech_reports.html
Root-URL: 
Title: International Symposium on Shared Memory Multiprocessing, Tokyo Japan, April 1991 An Analysis of Synchronization Mechanisms
Author: Philip J. Woest and James R. Goodman 
Address: Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: Abstract The granularity of computation achievable in a shared-memory multiprocessor is limited by the time required for process communication, that is, synchronization and data sharing. Therefore, reducing delays associated with process communication directly affects the minimum parcel of computation that can be efficiently executed. QOLB (formerly called QOSB) is a recently proposed hardware primitive for minimizing communication overhead by overlapping communication delays with computation. We investigate QOLB and a QOLB-inspired software synchronization method, comparing their effectiveness in supporting critical sections (i.e. locks). We show that substantial reductions in communication latency may be achieved over other hardware and software mechanisms by using QOLB's ability to simultaneously synchronize on and prefetch shared data, allowing these communication latencies to be overlapped with computation. We also analyze the performance of additional hardware and software techniques for implementing locks, counters, and barriers. Some observations are reported on the efficiency of various methods of notifying processes of an event, and on the effects of locality on the performance of barrier synchronization methods. 
Abstract-found: 1
Intro-found: 1
Reference: [AGGW90] <author> Aboulenein, N. M., S. Gjessing, J. R. Good-man, and P. J. Woest, </author> <title> Hardware Support for Synchronization in the Scalable Coherent Interface (SCI), </title> <institution> University of Wisconsin-Madison, Computer Science Technical Report #984, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: QOLB provides its greatest advantages in a network that allows multiple outstanding requests and has a high latency/bandwidth product. It is currently being investigated in two contexts: (1) the Multicube topology [GoWo88] employing a broadcast-based cache coherence protocol, and (2) the Scalable Coherent Interface (SCI) <ref> [AGGW90] </ref>, a proposed IEEE standard multiprocessor interface supporting point-to-point links and a nonbroadcast-based cache coherence protocol. Two software algorithms inspired by QOLB have been developed. Each of these implements queues as software-maintained data structures.
Reference: [AdHi90] <author> Adve, S. V., and M. D. Hill, </author> <title> Weak Ordering ANew Definition, </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990, </year> <pages> pp. 2-14. </pages>
Reference-contexts: Sequential consistency [Lamp79] deals with the correct observable ordering of memory accesses. Several models of weaker forms of consistency have been developed, for example <ref> [DuSB86, Good89, AdHi90, GLLG90] </ref>. Relaxing the restrictions on sequential consistency using QOLB is the subject of a separate study [WoGo91]. 4 Cold start misses are also ignored. effects by mitigating tree saturation effects 5 .
Reference: [Ande90] <author> Anderson, T. E., </author> <title> The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <month> January </month> <year> 1990, </year> <pages> pp. 6-16. </pages>
Reference-contexts: Two software algorithms inspired by QOLB have been developed. Each of these implements queues as software-maintained data structures. Anderson <ref> [Ande90] </ref> presents a scheme to implement a queue using Fetch&Add an array of flags, and a counter. Mellor-Crummey and Scott [MeSc90] present a second algorithm that implements a software queue using Compare&Swap and pointers. <p> QOLB Locks. The MCS algorithm [MeSc90] implements queue-based locks in software, rather than in hardware, as QOLB does. It improves on Anderson's lock algorithm <ref> [Ande90] </ref> by forcing all spinning to be performed locally. An atomic Swap operation and an atomic Compare&Swap operation are provided, along with both Fetch and Store, as at-memory primitives.
Reference: [BrMW85] <author> Brantley, W. C., K. P. McAuliffe, and J. Weiss, </author> <title> RP3 Processor-Memory Element, </title> <booktitle> Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1985, </year> <pages> pp 782-789. </pages>
Reference-contexts: A number of hardware primitives have been proposed as a basis for process synchronization in shared-memory multiprocessors. These include traditional Test&Set and Unset, Test&Test&Set [RuSe84], the full/empty bits of the HEP multiprocessor [Smit81], and Fetch&Add [GoLR83], as well as generalizations, known collectively as Fetch&F operations <ref> [GGKM83, BrMW85, ZhYe87] </ref>. Unfortunately, most synchronization algorithms which rely on these primitives require spinning over the interconnect or, as in the case of using Test&Test&Set to acquire a lock, cause excessive bus traffic. <p> Finally, the most significant impact of large queues is likely to be the reduction of hot-spot hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 The QOLB primitive is complete in the sense that no other hardware support is needed to assure correct synchronization, i.e., even fences <ref> [BrMW85] </ref> are unnecessary. Sequential consistency [Lamp79] deals with the correct observable ordering of memory accesses. Several models of weaker forms of consistency have been developed, for example [DuSB86, Good89, AdHi90, GLLG90].
Reference: [Broo86] <author> Brooks, E. D., </author> <title> The Butterfly Barrier, </title> <journal> International Journal of Parallel Programming, </journal> <month> August </month> <year> 1986, </year> <pages> pp 295-307. </pages>
Reference-contexts: Serial Barrier Using Fetch&Increment. While it is natural to separate the two functions of counting arrivals and global notification, it is also possible to combine them, as in the case of the butterfly barrier <ref> [Broo86] </ref>. This algorithm requires a process to perform log n pairwise synchronizations, the pairs being chosen in such a way that a process can complete all of the synchronizations only when all processes have reached the barrier. An improved algorithm, the dissemination barrier, has also been developed and studied [HeFM88].
Reference: [DuSB86] <author> Dubois, M., C. Scheurich, and F. Briggs, </author> <title> Memory Access Buffering in Multiprocessor, </title> <booktitle> Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1986, </year> <pages> pp. 434-442. </pages>
Reference-contexts: Sequential consistency [Lamp79] deals with the correct observable ordering of memory accesses. Several models of weaker forms of consistency have been developed, for example <ref> [DuSB86, Good89, AdHi90, GLLG90] </ref>. Relaxing the restrictions on sequential consistency using QOLB is the subject of a separate study [WoGo91]. 4 Cold start misses are also ignored. effects by mitigating tree saturation effects 5 .
Reference: [GLLG90] <author> Gharachorloo, K., D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy, </author> <title> Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors, </title> <booktitle> Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990, </year> <pages> pp. 15-26. </pages>
Reference-contexts: Sequential consistency [Lamp79] deals with the correct observable ordering of memory accesses. Several models of weaker forms of consistency have been developed, for example <ref> [DuSB86, Good89, AdHi90, GLLG90] </ref>. Relaxing the restrictions on sequential consistency using QOLB is the subject of a separate study [WoGo91]. 4 Cold start misses are also ignored. effects by mitigating tree saturation effects 5 .
Reference: [GoVW89] <author> Goodman, J. R., M. K. Vernon, and P. J. Woest, </author> <title> A Set of Efficient Synchronization Primitives for a Large-Scale Shared-Memory Multiprocessor, </title> <booktitle> Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS III), </booktitle> <month> April </month> <year> 1989, </year> <pages> pp. 64-75. </pages>
Reference-contexts: Unfortunately, most synchronization algorithms which rely on these primitives require spinning over the interconnect or, as in the case of using Test&Test&Set to acquire a lock, cause excessive bus traffic. The QOLB 2 primitive, was proposed <ref> [GoVW89] </ref> to alleviate these problems, as well as to provide additional benefits by reducing memory latency. It is a shared-memory operation that adds a processor to a hardware queue of waiters for a line. QOLB allows a process to spin on a locally-cached shadow copy of a line. <p> The software algorithm for maintaining QOLB queues is discussed in the section on performance. The QOLB mechanism allows for efficient process synchronization by providing a direct implementation of hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 2 QOLB (Queue On Lock Bit) is pronounced Colby. It was originally was called QOSB in <ref> [GoVW89] </ref> but was changed to be more precise. binary semaphores. As a non-blocking operation, QOLB can prefetch (i.e. make local) a line of data while a process performs useful work. Combining these two operations along with a simple software convention, QOLB becomes a synchronizing prefetch operation. <p> The synchronization scenarios chosen for this study consist of locks (especially for pairwise sharing), counters, barriers, and global event notification. These scenarios are the same as those proposed by Goodman, Vernon, and Woest <ref> [GoVW89] </ref> with one exception. The work queue scenario has been replaced by incrementing a counter. The provision of fast counters represents the crux of the problem of implementing highly parallel queues, and is much more general. <p> Thus, it is possible to reduce the latency of a critical section to the processor time for executing the critical section code. The QOLB lock scheme is shown as Algorithm 2. An extended discussion is given elsewhere <ref> [GoVW89] </ref>. procedure acquire (lock) begin QOLB (lock) while (test&set (lock)) QOLB (lock) end acquire (lock) "critical work" unset (lock) Algorithm 2. QOLB Locks. The MCS algorithm [MeSc90] implements queue-based locks in software, rather than in hardware, as QOLB does. <p> Of all of the serial algorithms studied in the lock section, QOLB locks performed the best. The fastest pipelined algorithm is a Fetch&Increment operation performed at memory. The choice of a software combining method is that developed in a previous work <ref> [GoVW89] </ref>. <p> The sys tem size is 1024 processors, with the actual number of competing processors given by the x-axis. nodes that it had performed the combining for. New combining is now allowed to continue in a following wave. The interested reader is directed elsewhere <ref> [GoVW89] </ref> for a more detailed description. hardware combining is indistinguishable from the baseline. The performance for the algorithms is as one would predict. <p> Even if Fetch&F primitives could be issued as non-blocking operations, it would be much more difficult to structure the computation of an application to issue the multiple steps of an appropriate prefetching algorithm correctly. The study of counter algorithms demonstrates the effectiveness of the software combining algorithm presented elsewhere <ref> [GoVW89] </ref>. Even with only 64 participating processes software combining performs as well as a pipelined Fetch&Increment operation. Thus, it holds much promise for implementing efficient counters without resorting to hardware combining. The barrier synchronization study demonstrates that software algorithms can be constructed that experience a logarithmic number of interconnect latencies.
Reference: [Good89] <author> Goodman, J. R., </author> <title> Cache Consistency and Sequential Consistency, Scalable Coherent Interface (SCI), IEEE P1596 Standards Group, </title> <type> Technical Report #61, </type> <month> March </month> <year> 1989. </year>
Reference-contexts: Sequential consistency [Lamp79] deals with the correct observable ordering of memory accesses. Several models of weaker forms of consistency have been developed, for example <ref> [DuSB86, Good89, AdHi90, GLLG90] </ref>. Relaxing the restrictions on sequential consistency using QOLB is the subject of a separate study [WoGo91]. 4 Cold start misses are also ignored. effects by mitigating tree saturation effects 5 .
Reference: [GoWo88] <author> Goodman, J. R., and P. J. Woest, </author> <title> The Wisconsin Multicube: A New Large-Scale Cache-Coherent Multiprocessor, </title> <booktitle> Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1988, </year> <pages> pp. 422-431. </pages>
Reference-contexts: QOLB provides its greatest advantages in a network that allows multiple outstanding requests and has a high latency/bandwidth product. It is currently being investigated in two contexts: (1) the Multicube topology <ref> [GoWo88] </ref> employing a broadcast-based cache coherence protocol, and (2) the Scalable Coherent Interface (SCI) [AGGW90], a proposed IEEE standard multiprocessor interface supporting point-to-point links and a nonbroadcast-based cache coherence protocol. Two software algorithms inspired by QOLB have been developed. Each of these implements queues as software-maintained data structures. <p> To assist in the analysis, a model of a shared-memory cache-coherent multiprocessor was constructed. This model is very similar to the the Multicube topology <ref> [GoWo88] </ref>, especially in its implementation of the interconnect, with a directory-based cache coherence protocol. The model consists of a multidimensional grid of buses (the global interconnect), with processing nodes located at the intersections. A node consists of a processor, a two-level cache hierarchy, and a portion of main memory.
Reference: [GoLR83] <author> Gottlieb, A., B. D. Lubachevsky, and L. Rudolph, </author> <title> Basic Techniques for the Efficient Coordination of Very Large Numbers of Cooperating Sequential Processors, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <month> April </month> <year> 1983, </year> <pages> pp. 164-189. </pages>
Reference-contexts: A number of hardware primitives have been proposed as a basis for process synchronization in shared-memory multiprocessors. These include traditional Test&Set and Unset, Test&Test&Set [RuSe84], the full/empty bits of the HEP multiprocessor [Smit81], and Fetch&Add <ref> [GoLR83] </ref>, as well as generalizations, known collectively as Fetch&F operations [GGKM83, BrMW85, ZhYe87]. Unfortunately, most synchronization algorithms which rely on these primitives require spinning over the interconnect or, as in the case of using Test&Test&Set to acquire a lock, cause excessive bus traffic.
Reference: [GGKM83] <author> Gottlieb, A., R. Grishman, C. P. Kruskal, K. P. McAuliffe, L. Rudolph, And M. Snir, </author> <title> The NYU Ultracomputer -- Designing an MIMD, Shared Memory Parallel Machine, </title> <journal> IEEE Transactions on Computers, </journal> <month> February - 13 - </month> <year> 1983, </year> <pages> pp. 175-189. </pages>
Reference-contexts: A number of hardware primitives have been proposed as a basis for process synchronization in shared-memory multiprocessors. These include traditional Test&Set and Unset, Test&Test&Set [RuSe84], the full/empty bits of the HEP multiprocessor [Smit81], and Fetch&Add [GoLR83], as well as generalizations, known collectively as Fetch&F operations <ref> [GGKM83, BrMW85, ZhYe87] </ref>. Unfortunately, most synchronization algorithms which rely on these primitives require spinning over the interconnect or, as in the case of using Test&Test&Set to acquire a lock, cause excessive bus traffic.
Reference: [HeFM88] <author> Hensgen, D., R. Finkel, and U. Manber, </author> <title> Two Algorithms for Barrier Synchronization, </title> <journal> International Journal of Parallel Programming, </journal> <year> 1988, </year> <pages> pp. 1-17. </pages>
Reference-contexts: This algorithm requires a process to perform log n pairwise synchronizations, the pairs being chosen in such a way that a process can complete all of the synchronizations only when all processes have reached the barrier. An improved algorithm, the dissemination barrier, has also been developed and studied <ref> [HeFM88] </ref>. This algorithm reduces the cost of synchronizations by making them one-way and employing a different pattern of processor-to-memory writes. Two copies of the synchronization variables are used to ensure that there is no interference between consecutively executed barriers. The dissemination barrier is given as Algorithm 6. <p> Dissemination (Butterfly) Barrier. Hensgen, Finkel, and Manber propose a second algorithm called a tournament barrier <ref> [HeFM88] </ref>. In this scheme processes race up a binary tree. Since the winner is statically determined at each level, the loser simply writes a flag to let the winner know that it has reached the barrier.
Reference: [KMRS88] <author> Karlin, A. R., M. S. Manasse, L. Rudolph, and D. D. Sleator, </author> <title> Competitive Snoopy Caching, </title> <journal> Algorithmica, </journal> <volume> 3, </volume> <year> 1988, </year> <pages> pp. 79-119. </pages>
Reference-contexts: Barrier performance can generally be improved if processes are assigned to processors in a specific order and there is sufficient symmetry in the interconnect. For hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 6 Read-sharing refers to the situation where a large number of processors simultaneously attempt to read a shared variable <ref> [KMRS88] </ref>. the Multicube architecture and the previously described partner and parent functions of the dissemination and tournament barriers, the latency of the interconnect is substantially reduced. Synchronization operations are required to traverse only a single stage of the interconnect, independent of the number of stages.
Reference: [Lamp79] <author> Lamport, L., </author> <title> How to Make a Multiprocessor Computer that Correctly Executes Mul-tiprocess Programs, </title> <journal> IEEE Transactions on Computers, </journal> <month> September </month> <year> 1979, </year> <pages> pp. 690-691. </pages>
Reference-contexts: Finally, the most significant impact of large queues is likely to be the reduction of hot-spot hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 The QOLB primitive is complete in the sense that no other hardware support is needed to assure correct synchronization, i.e., even fences [BrMW85] are unnecessary. Sequential consistency <ref> [Lamp79] </ref> deals with the correct observable ordering of memory accesses. Several models of weaker forms of consistency have been developed, for example [DuSB86, Good89, AdHi90, GLLG90].
Reference: [MeSc90] <author> Mellor-Crummey, J. M., and M. L. Scott, </author> <title> Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors, </title> <institution> University of Rochester, Computer Science Technical Report #342, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: Two software algorithms inspired by QOLB have been developed. Each of these implements queues as software-maintained data structures. Anderson [Ande90] presents a scheme to implement a queue using Fetch&Add an array of flags, and a counter. Mellor-Crummey and Scott <ref> [MeSc90] </ref> present a second algorithm that implements a software queue using Compare&Swap and pointers. Although these algorithms provide queues for locks in software, they introduce substantial synchronization and data acquisition delays. Discussion and analysis of these algorithms are postponed until the section on performance. <p> Results are provided for three algorithms: spin-locks, QOLB locks, and a software queue-based locking mechanism (MCS locks <ref> [MeSc90] </ref>). Both idle and busy lock performance are studied. Locks are compared for two types of computation, the first where the critical section is empty, and the second where the critical section performs some simple function, for example, incrementing a counter. <p> The QOLB lock scheme is shown as Algorithm 2. An extended discussion is given elsewhere [GoVW89]. procedure acquire (lock) begin QOLB (lock) while (test&set (lock)) QOLB (lock) end acquire (lock) "critical work" unset (lock) Algorithm 2. QOLB Locks. The MCS algorithm <ref> [MeSc90] </ref> implements queue-based locks in software, rather than in hardware, as QOLB does. It improves on Anderson's lock algorithm [Ande90] by forcing all spinning to be performed locally. An atomic Swap operation and an atomic Compare&Swap operation are provided, along with both Fetch and Store, as at-memory primitives.
Reference: [PfNo85] <author> Pfister, G. A., and V. A. Norton, </author> <title> Hot Spot Contention and Combining in Multistage Interconnection Networks, </title> <booktitle> Proceedings of the 1985 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1985, </year> <pages> pp. 790-797. </pages>
Reference-contexts: Busy locks are commonly found in many situations, especially those involving pairwise sharing, whenever one process is waiting for data being written by another. However, if a lock is released before it is requested then the lock is considered to be idle. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 5 See <ref> [PfNo85] </ref> for a discussion of hot-spot contention and tree sa turation. - 5 - It should be pointed out that serialized access to data implies that, in a large-scale shared-memory multiprocessor, high contention for a lock will cause a severe bottleneck.
Reference: [RaSV90] <author> Ramachandran, U., M. Solomon, and M. K. Vernon, </author> <title> Hardware Support for Interprocess Communication, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <month> June </month> <year> 1990, </year> <pages> pp. 318-329. </pages>
Reference-contexts: Unfortunately, implementations of send and receive result in primitives that require a significant amount of processor time to execute, although they can be sped up by the use of special hardware <ref> [RaSV90] </ref>. This situation is exacerbated if the operating system is invoked, which requires context switches. Thus message passing systems experience substantial latencies for process communication, much longer than those of a typical shared-memory operation.
Reference: [RuSe84] <author> Rudolph, L., and Z. Segall, </author> <title> Dynamic Decentralized Cache Schemes for MIMD Parallel Processors, </title> <booktitle> Proceedings of the 11th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1984, </year> <pages> pp. 340-347. </pages>
Reference-contexts: A number of hardware primitives have been proposed as a basis for process synchronization in shared-memory multiprocessors. These include traditional Test&Set and Unset, Test&Test&Set <ref> [RuSe84] </ref>, the full/empty bits of the HEP multiprocessor [Smit81], and Fetch&Add [GoLR83], as well as generalizations, known collectively as Fetch&F operations [GGKM83, BrMW85, ZhYe87].
Reference: [Smit81] <author> Smith, B. J., </author> <booktitle> Architecture and Applications of the HEP Multiprocessor Computer System SPIE Vol. 298 Real-Time Signal Processing IV (1981), </booktitle> <pages> pp. 241-248. </pages> <note> Also appears in Supercomputers: Design and Applications, IEEE Catalog Number EHO219-6. </note>
Reference-contexts: A number of hardware primitives have been proposed as a basis for process synchronization in shared-memory multiprocessors. These include traditional Test&Set and Unset, Test&Test&Set [RuSe84], the full/empty bits of the HEP multiprocessor <ref> [Smit81] </ref>, and Fetch&Add [GoLR83], as well as generalizations, known collectively as Fetch&F operations [GGKM83, BrMW85, ZhYe87]. Unfortunately, most synchronization algorithms which rely on these primitives require spinning over the interconnect or, as in the case of using Test&Test&Set to acquire a lock, cause excessive bus traffic.
Reference: [WoGo91] <author> Woest, P. J., and J. R. Goodman, </author> <title> QOLB Consistency, </title> <note> in preparation. </note>
Reference-contexts: Sequential consistency [Lamp79] deals with the correct observable ordering of memory accesses. Several models of weaker forms of consistency have been developed, for example [DuSB86, Good89, AdHi90, GLLG90]. Relaxing the restrictions on sequential consistency using QOLB is the subject of a separate study <ref> [WoGo91] </ref>. 4 Cold start misses are also ignored. effects by mitigating tree saturation effects 5 . Fortunately, few algorithms in this study exhibit hot spots, and the ones mostly likely to benefit from large queues are those that already perform poorly in comparison to other algorithms.
Reference: [YeTL87] <author> Yew, P. C., N. F. Tzeng, and D. H. Lawrie, </author> <title> Distributing Hot-Spot Addressing in Large-Scale Multiprocessors, </title> <journal> IEEE Transactions on Computers, </journal> <month> April </month> <year> 1987, </year> <pages> pp 388-395. </pages>
Reference-contexts: Since barriers need to handle large numbers of processes efficiently, tree-based combining algorithms have been proposed to allow processes to declare themselves as having arrived. Such an algorithm, employing Fetch&Increment and a tree of counters, was analyzed by Yew, Tzeng, and Lawrie <ref> [YeTL87] </ref>. The second part, notifying processes that the barrier has been reached, is a useful technique in any instance - 9 - requiring notification of a global event, such as in major-ity (or k out of n) decisions, or for indicating the successful termination of a parallel search.
Reference: [ZhYe87] <author> Zhu, C. Q., and P. C. Yew, </author> <title> A Scheme to Enforce Data Dependence on Large Multiprocessor Systems, </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> June </month> <year> 1987, </year> <pages> pp. 726-739. </pages>
Reference-contexts: A number of hardware primitives have been proposed as a basis for process synchronization in shared-memory multiprocessors. These include traditional Test&Set and Unset, Test&Test&Set [RuSe84], the full/empty bits of the HEP multiprocessor [Smit81], and Fetch&Add [GoLR83], as well as generalizations, known collectively as Fetch&F operations <ref> [GGKM83, BrMW85, ZhYe87] </ref>. Unfortunately, most synchronization algorithms which rely on these primitives require spinning over the interconnect or, as in the case of using Test&Test&Set to acquire a lock, cause excessive bus traffic.
References-found: 23

