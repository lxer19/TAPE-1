URL: ftp://ftp.cs.umass.edu/pub/osl/papers/sigir96.ps.gz
Refering-URL: http://spa-www.cs.umass.edu/bibliography.html
Root-URL: 
Email: fcahoon,mckinleyg@cs.umass.edu  
Title: Performance Evaluation of a Distributed Architecture for Information Retrieval  
Author: Brendon Cahoon Kathryn S. McKinley 
Address: Amherst, MA 01003,  
Affiliation: Department of Computer Science, University of Massachusetts,  
Abstract: Information explosion across the Internet and elsewhere offers access to an increasing number of document collections. In order for users to effectively access these collections, information retrieval (IR) systems must provide coordinated, concurrent, and distributed access. In this paper, we describe a fully functional distributed IR system based on the Inquery unified IR system. To refine this prototype, we implement a flexible simulation model that analyzes performance issues given a wide variety of system parameters and configurations. We present a series of experiments that measure response time, system utilization, and identify bottlenecks. We vary numerous system parameters, such as the number of users, text collections, terms per query, and workload to generalize our results for other distributed IR systems. Based on our initial results, we recommend simple changes to the prototype and evaluate the changes using the simulator. Because of the significant resource demands of information retrieval, it is not difficult to generate workloads that overwhelm system resources regardless of the architecture. However under some realistic workloads, we demonstrate system organizations for which response time gracefully degrades as the workload increases and performance scales with the number of processors. This scalable architecture includes a surprisingly small number of brokers through which a large number of clients and servers communicate. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. J. Burkowski. </author> <title> Retrieval performance of a distributed text database utilizing a parallel process document server. </title> <booktitle> In 1990 International Symposium On Databases in Parallel and Distributed Systems, </booktitle> <pages> pages 71-79, </pages> <address> Trinity College, Dublin, Ireland, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: We experiment with very large text collections; up to 128 GB of data. Prior work has not examined such large systems. We also base our distributed system on a proven, effective retrieval engine. Burkowski reports on a simulation study which measures the retrieval performance of a distributed IR system <ref> [1] </ref>. The experiments explore two strategies for distributing a fixed workload across a small number number of servers. This work is the most closely related to our work, but differs in several ways.
Reference: [2] <author> B. Cahoon and K. S. McKinley. </author> <title> Performance analysis of distributed information retrieval architectures. </title> <type> Technical Report UM-CS-1995-054, </type> <institution> Department of Computer Science, University of Massachusetts, Amherst, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: The summary and document size determine the time to send it across the network. We discuss these parameters and our reasons for choosing specific values in greater depth in a technical report <ref> [2] </ref>. Unless otherwise stated, the clients, connection server, and Inquery servers operate as described in Section 2. We allocate each of the basic components in the distributed system to its own host. Each host contains its own processor, memory, and secondary storage. <p> For each series of graphs, we display the corresponding values of the parameters listed in Table 1. We refer the interested reader to our technical report for more results <ref> [2] </ref>. 4 Experiments and Results In this section, we present the results from four sets of experiments. Two of the experiments use the prototype architecture that we implemented. In the first experiment, we study the effect of equally distributing a single database among each of the Inquery servers.
Reference: [3] <author> J. P. Callan, W. B. Croft, and J. Broglio. </author> <title> TREC and TIPSTER experiments with INQUERY. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 31(3) </volume> <pages> 327-343, </pages> <month> May/June </month> <year> 1995. </year>
Reference-contexts: During our investigation we identify potential bottlenecks and study the effects of various architectures and parameters. Our goal is to use resources efficiently by maximizing parallelism and ensuring scalability. We also maintain the effectiveness, in terms of recall and precision <ref> [3] </ref>, of a stand-alone IR system. The results show that the implemented system performs well for small configurations when the Inquery servers process queries quickly. However, as the size of the system increases, bottlenecks begin to degrade performance. <p> Inquery accepts natural language or structured queries. For query operations, the system outputs a list of documents ranked by relevance. Internally, the system stores the text collections as an inverted file. Previous work demonstrates that Inquery is an effective retrieval system for large, full-text databases <ref> [3] </ref>. 3 Simulation Model In this section, we present a simulation model for exploring distributed IR system architectures. Simulation techniques provide an effective and flexible platform for analyzing large and complex distributed systems.
Reference: [4] <author> J. P. Callan, W. B. Croft, and S. M. Harding. </author> <title> The IN-QUERY retrieval system. </title> <booktitle> In Proceedings of the 3rd International Conference on Database and Expert System Applications, </booktitle> <address> Valencia, Spain, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: The focus of this paper is to design appropriate distributed information retrieval architectures by analyzing the performance of potential systems under a variety of work-loads. We begin with a prototype implementation of a distributed information retrieval system using Inquery; an inference network, full-text information retrieval model <ref> [4] </ref>. Our system adopts a variation of the client-server paradigm that consists of clients connected to Inquery server retrieval engines through a connection server, a central administration broker, as illustrated in Figure 1. <p> The Inquery system is a probabilistic retrieval model that is based upon a Bayesian inference network <ref> [4] </ref>. Inquery accepts natural language or structured queries. For query operations, the system outputs a list of documents ranked by relevance. Internally, the system stores the text collections as an inverted file.
Reference: [5] <author> J. P. Callan, Z. Lu, and W. B. Croft. </author> <title> Searching distributed collections with inference networks. </title> <booktitle> In Proceedings of the 18th International Conference on Research and Development in Information Retrieval, </booktitle> <address> Seattle, WA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: For example, one collection may be irrelevant to a particular query, but if the user includes it, the overall response may still include its top ranked responses. Other research is investigating techniques to automatically select appropriate collections with respect to specific queries <ref> [5, 14] </ref>. The connection server does not maintain intermediate results for document retrieval commands; it simply forwards a document as soon as the Inquery server sends it. 2.3 Inquery Servers The Inquery server uses the Inquery retrieval engine to provide IR services.
Reference: [6] <author> W. B. Croft, R. Cook, and D. Wilder. </author> <title> Providing government information on the internet: Experiences with THOMAS. </title> <booktitle> In The Second International Conference on the Theory and Practice of Digital Libraries, </booktitle> <address> Austin, TX, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: We examined several different text collections and query sets to obtain system measurements. We examined TIPSTER 1, a large heterogeneous collection of full-text articles and abstracts [8], a database containing the Congressional Record for the 103rd Congress <ref> [6] </ref>, and a small collection of abstracts from the Communications of the ACM [7]. The simulator uses a simple, yet accurate model to represent query evaluation time. <p> We present results that measure system response time, utilization, and identify bottlenecks. Our results show that our architecture provides scalable performance when clients enter small queries. Small queries are a realistic workload, since several studies of existing IR systems demonstrate that users tend to use small queries <ref> [6] </ref>. By adding a small number of connection servers to coordinate a large number of clients and Inquery servers the system can maintain scalable performance at higher work-loads. When the system bottleneck is the Inquery server, as for large queries, it is more difficult to achieve reasonable performance.
Reference: [7] <author> E. A. Fox. </author> <title> Characterization of two new experimental collections in computer and information science containing textual and bibliographic concepts. </title> <type> Technical Report 83-561, </type> <institution> Cornell University, </institution> <address> Ithaca, NY, </address> <month> September </month> <year> 1983. </year>
Reference-contexts: We examined TIPSTER 1, a large heterogeneous collection of full-text articles and abstracts [8], a database containing the Congressional Record for the 103rd Congress [6], and a small collection of abstracts from the Communications of the ACM <ref> [7] </ref>. The simulator uses a simple, yet accurate model to represent query evaluation time. We found that evaluation time is very strongly related to the number of terms in the query and the frequency of each of the terms.
Reference: [8] <editor> D. Harman, editor. </editor> <booktitle> The First Text REtrieval Conference (TREC1). National Institute of Standards and Technology Special Publication 200-217, </booktitle> <address> Gaithersburg, MD, </address> <year> 1992. </year>
Reference-contexts: We examined several different text collections and query sets to obtain system measurements. We examined TIPSTER 1, a large heterogeneous collection of full-text articles and abstracts <ref> [8] </ref>, a database containing the Congressional Record for the 103rd Congress [6], and a small collection of abstracts from the Communications of the ACM [7]. The simulator uses a simple, yet accurate model to represent query evaluation time.
Reference: [9] <author> B-S. Jeong and E. Omiecinski. </author> <title> Inverted file partitioning schemes in multiple disk systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 6(2) </volume> <pages> 142-153, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: He assumes a worst case workload where each user broadcasts queries to all servers without any think time. We experiment with larger distributed configurations, we vary the number of clients, and use a more realistic user workload. Other researchers have investigated various data partitioning schemes for distributed IR systems <ref> [12, 13, 11, 9] </ref>. We address this issue in the experiments in Section 4.1. Although we only consider one partitioning scheme, we improve upon their results in several ways. Our experiments include results for both small and large configurations. Previous research has investigated only small configurations.
Reference: [10] <author> J. R. </author> <title> Jump. YACSIM Reference Manual. </title> <institution> Rice University, </institution> <note> version 2.1.1 edition, </note> <year> 1993. </year>
Reference-contexts: Furthermore, simulation models allow us to easily define very large systems and examine their performance in a controlled environment. To implement the simulator, we use YACSIM, a process oriented discrete event simulation language <ref> [10] </ref>. YACSIM contains a set of data structures and library routines that manage user created processes and resources. Its process oriented nature enables the structure of the simulator to closely reflect the actual system.
Reference: [11] <author> I. A. Macleod, T. P. Martin, B. Nordin, and J. R. Phillips. </author> <title> Strategies for building distributed information retrieval systems. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 23(6) </volume> <pages> 511-528, </pages> <year> 1987. </year>
Reference-contexts: He assumes a worst case workload where each user broadcasts queries to all servers without any think time. We experiment with larger distributed configurations, we vary the number of clients, and use a more realistic user workload. Other researchers have investigated various data partitioning schemes for distributed IR systems <ref> [12, 13, 11, 9] </ref>. We address this issue in the experiments in Section 4.1. Although we only consider one partitioning scheme, we improve upon their results in several ways. Our experiments include results for both small and large configurations. Previous research has investigated only small configurations.
Reference: [12] <author> A. Tomasic. </author> <title> Distributed Queries and Incremental Updates In Information Retrieval Systems. </title> <type> PhD thesis, </type> <institution> Princeton University, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: He assumes a worst case workload where each user broadcasts queries to all servers without any think time. We experiment with larger distributed configurations, we vary the number of clients, and use a more realistic user workload. Other researchers have investigated various data partitioning schemes for distributed IR systems <ref> [12, 13, 11, 9] </ref>. We address this issue in the experiments in Section 4.1. Although we only consider one partitioning scheme, we improve upon their results in several ways. Our experiments include results for both small and large configurations. Previous research has investigated only small configurations.
Reference: [13] <author> A. Tomasic and H. Garcia-Molina. </author> <title> Performance of inverted indices in shared-nothing distributed text document information retrieval systems. </title> <booktitle> In Proceedings of the Second International Conference on Parallel and Distributed Information Systems, </booktitle> <address> San Diego, CA, </address> <year> 1993. </year>
Reference-contexts: He assumes a worst case workload where each user broadcasts queries to all servers without any think time. We experiment with larger distributed configurations, we vary the number of clients, and use a more realistic user workload. Other researchers have investigated various data partitioning schemes for distributed IR systems <ref> [12, 13, 11, 9] </ref>. We address this issue in the experiments in Section 4.1. Although we only consider one partitioning scheme, we improve upon their results in several ways. Our experiments include results for both small and large configurations. Previous research has investigated only small configurations.
Reference: [14] <author> E. M. Voorhees, N. K. Gupta, and B. Johnson-Laird. </author> <title> Learning collection fusion strategies. </title> <booktitle> In Proceedings of the 18th International Conference on Research and Development in Information Retrieval, </booktitle> <address> Seattle, WA, </address> <year> 1995. </year>
Reference-contexts: For example, one collection may be irrelevant to a particular query, but if the user includes it, the overall response may still include its top ranked responses. Other research is investigating techniques to automatically select appropriate collections with respect to specific queries <ref> [5, 14] </ref>. The connection server does not maintain intermediate results for document retrieval commands; it simply forwards a document as soon as the Inquery server sends it. 2.3 Inquery Servers The Inquery server uses the Inquery retrieval engine to provide IR services.
Reference: [15] <author> D. Wolfram. </author> <title> Applying informetric characteristics of data bases to IR system file design, part I: Informetric models. </title> <booktitle> In formation Processing & Management, </booktitle> <volume> 28(1) </volume> <pages> 121-133, </pages> <year> 1992. </year> <month> 9 </month>
Reference-contexts: We use a negative binomial distribution that matches the observed distribu tion of query lengths from our query sets. Distribution of Terms in Queries (QTF). Researchers do not agree on a commonly accepted distribution for term frequencies in queries <ref> [15] </ref>. We examined our query sets to determine an appropriate distribution. The query term frequency distributions for the query sets are similar but the distributions are complex and do not closely match a mathematical function.
References-found: 15

