URL: file://ftp.cis.ohio-state.edu/pub/hpce/compiler/Papers/LCPC95-twolevel.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~chh/Publication/compiler-papers.html
Root-URL: 
Email: fkaushik,chh,sadayg@cis.ohio-state.edu  
Title: Compiling Array Statements for Efficient Execution on Distributed-Memory Machines: Two-level Mappings  
Author: S. D. Kaushik, C.-H. Huang, and P. Sadayappan 
Address: Columbus, OH 43210.  
Affiliation: Dept. of Computer and Information Science, The Ohio State University,  
Abstract: In languages such as High Performance Fortran (HPF), array statements are used for expressing data parallelism. In compiling array statements for distributed-memory machines, efficient enumeration of local index sets and communication sets is important. The virtual processor approach, among several other methods, has been proposed for efficient enumeration of these index sets. In this paper, using simple mathematical properties of regular sections, we extend the virtual processor approach to address the memory allocation and index set enumeration problems for array statements involving arrays mapped using the two-level mapping supported by HPF. Performance results on the Cray T3D are presented to demonstrate the efficacy of the extensions and identify various tradeoffs associated with the proposed method.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> B. M. Chapman, P. Mehrotra, and H. P. Zima. </author> <title> Vienna Fortran a Fortran language extension for distributed memory multiprocessors. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <booktitle> Language, Compilers and Runtime Environments for Distributed Memory Machines, </booktitle> <pages> pages 39-62. </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Languages such as High Performance Fortran (HPF) [3, 10], Fortran-D [4], and Vienna Fortran <ref> [1] </ref> provide a programming environment which allows annotation of single address space programs with distribution directives specifying the mapping of arrays to processors of a distributed-memory machine.
Reference: 2. <author> S. Chatterjee, J. R. Gilbert, F. J. E. Long, R. Schreiber, and S.-H. Teng. </author> <title> Generating local addresses and communication sets for data parallel programs. </title> <booktitle> In Proc. of ACM Symposium on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 149-158, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: These closed forms are then used in the virtual processor domain for efficient enumeration of the communication and local index sets. The problem of local index set identification was addressed by Chatterjee et al. <ref> [2] </ref> using a finite-state machine (FSM) to traverse the local index space. Stichnoth et al. [11] address the problem of index set and processor set identification. The formulation proposed has similarities to an instance of the virtual processor approach. <p> The formulation proposed has similarities to an instance of the virtual processor approach. The implementation of the Fortran-D compiler at Rice University is being extended to handle arrays with block-cyclic distributions [6]. An approach similar to the FSM approach <ref> [2] </ref> for determining the local memory access sequence is used and efficient algorithms for computing the FSM for frequently occuring cases are presented. A linear-time algorithm for constructing the FSM which improves the asymptotic complexity of the algorithm presented in [6] was presented in [8].
Reference: 3. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Rice University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Languages such as High Performance Fortran (HPF) <ref> [3, 10] </ref>, Fortran-D [4], and Vienna Fortran [1] provide a programming environment which allows annotation of single address space programs with distribution directives specifying the mapping of arrays to processors of a distributed-memory machine.
Reference: 4. <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C.-W. Tseng, and M. Wu. </author> <title> Fortran-D language specification. </title> <type> Technical Report TR-91-170, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Languages such as High Performance Fortran (HPF) [3, 10], Fortran-D <ref> [4] </ref>, and Vienna Fortran [1] provide a programming environment which allows annotation of single address space programs with distribution directives specifying the mapping of arrays to processors of a distributed-memory machine.
Reference: 5. <author> S. K. S. Gupta, S. D. Kaushik, C.-H. Huang, and P. Sadayappan. </author> <title> On compiling array expressions for efficient execution on distributed-memory machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 1995. To appear. </note>
Reference-contexts: If the arrays have only block or cyclic distributions, then the data index sets and the processor sets can be characterized using regular sections for closed forms <ref> [5, 9] </ref>. However, for the general block-cyclic distribution, closed form characterization of these sets using simple regular sections is not possible. Several approaches have addressed the efficient execution of array statements involving block-cyclically distributed arrays. <p> Several approaches have addressed the efficient execution of array statements involving block-cyclically distributed arrays. A virtual processor approach to efficiently enumerate the data index sets and processor sets is presented in <ref> [5, 7] </ref>. The approach is based on viewing a block-cyclic distribution as a block (or cyclic) distribution on a set of virtual processors, which are cyclically (or block-wise) mapped to physical processors. <p> These holes should be removed by allocating memory only for those template cells with which array elements are aligned. The indexing methods presented in <ref> [5, 7] </ref> are directly applicable for an array statement involving arrays which are distributed using a two-level mapping when existence of holes in the local memory arrays is acceptable. <p> The array statement in Eq. 1, is equivalent to the following array statement in terms of the sections of the templates T 1 and T 2 : The methods developed in <ref> [5, 7] </ref>, when applied to the array statement in Eq. 2, will construct the data index sets and local index sets in terms of the local indices of T 1 and T 2 . <p> Specifically two problems have to be addressed: Local Memory Allocation: Determining the exact amount of the memory to be allocated for the distributed array in a processor's local memory. Index Translation: The closed forms developed in <ref> [5, 7] </ref> for data and local index sets are expressed as simple regular sections in terms of indices of T loc. New closed forms in terms of indices of A loc for enumerating the send and receive data index sets and the local index set are to be developed. <p> Next, we develop a procedure for performing the translation between the local template section and the local array section. Using this procedure, the parameterized closed forms for the send and receive data index sets and the local index sets for one-level mappings developed in <ref> [5, 7] </ref> can be extended to those for the two-level mappings. Using the results for the block and cyclically distributed arrays, the virtual processor approach for handling block-cyclically distributed templates is extended. <p> section and a local array section as shown in Section 2.2. 2.2 Index Set Translation For block and cyclically distributed arrays, the local index sets and data index sets for the array statement in Eq. 2, can be expressed as simple regular sections of the uncompressed local array T loc <ref> [5] </ref>. We now show that a regular section in T loc corresponds to a regular section in A loc for block and cyclically distributed templates and develop a strategy for performing the translation. <p> = u 0 + q 1 + pb; s = s 0 : For the cyclically distributed template we have l = q 1 + p + l 0 P; u = q 1 + p + u 0 P; s = s 0 P Furthermore, the techniques developed in <ref> [5, 7] </ref> guarantee that every cell in the template section T (l : u : s) has an array element aligned with it. <p> For details of the virtual processor approach the reader is referred to <ref> [5, 7] </ref>. The virtual processor approach is based on viewing a block-cyclic distribution as a block (or cyclic) distribution on a set of virtual processors, which are cyclically (or block-wise) mapped to the physical processors. <p> Given a template section, T (l : u : s) the characterization of the active virtual processors on a processor, can be performed using techniques similar to those presented in <ref> [5, 7] </ref>. Depending on the set of virtual processor for which memory has been allocated, some translation of this set of active virtual processors will have to be performed [7]. <p> Given a template section, T ( ~ l : ~u : c fl s) the characterization of the active virtual processors on a processor, i.e., the set of virtual processors to which elements of the template section are mapped, can be performed using techniques similar to those presented in <ref> [5, 7] </ref>. Depending on the set of virtual processors for which memory has been allocated, some translation and compression of this set of active virtual processors will need to be performed [7].
Reference: 6. <author> S. Hiranandani, K. Kennedy, J. Mellor-Crummey, and A. Sethi. </author> <title> Advanced compilation techniques for Fortran D. </title> <type> Technical Report CRPC-TR-93-338, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Stichnoth et al. [11] address the problem of index set and processor set identification. The formulation proposed has similarities to an instance of the virtual processor approach. The implementation of the Fortran-D compiler at Rice University is being extended to handle arrays with block-cyclic distributions <ref> [6] </ref>. An approach similar to the FSM approach [2] for determining the local memory access sequence is used and efficient algorithms for computing the FSM for frequently occuring cases are presented. A linear-time algorithm for constructing the FSM which improves the asymptotic complexity of the algorithm presented in [6] was presented <p> block-cyclic distributions <ref> [6] </ref>. An approach similar to the FSM approach [2] for determining the local memory access sequence is used and efficient algorithms for computing the FSM for frequently occuring cases are presented. A linear-time algorithm for constructing the FSM which improves the asymptotic complexity of the algorithm presented in [6] was presented in [8]. The key idea behind the construction is the recognition that the local index space for a block-cyclically distributed array is an integer lattice spanned by a basis of dimensionality two.
Reference: 7. <author> S. D. Kaushik. </author> <title> Compile-Time and Run-Time Strategies for Array Statement Execution on Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, The Ohio State University, </institution> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: Several approaches have addressed the efficient execution of array statements involving block-cyclically distributed arrays. A virtual processor approach to efficiently enumerate the data index sets and processor sets is presented in <ref> [5, 7] </ref>. The approach is based on viewing a block-cyclic distribution as a block (or cyclic) distribution on a set of virtual processors, which are cyclically (or block-wise) mapped to physical processors. <p> These holes should be removed by allocating memory only for those template cells with which array elements are aligned. The indexing methods presented in <ref> [5, 7] </ref> are directly applicable for an array statement involving arrays which are distributed using a two-level mapping when existence of holes in the local memory arrays is acceptable. <p> The array statement in Eq. 1, is equivalent to the following array statement in terms of the sections of the templates T 1 and T 2 : The methods developed in <ref> [5, 7] </ref>, when applied to the array statement in Eq. 2, will construct the data index sets and local index sets in terms of the local indices of T 1 and T 2 . <p> Specifically two problems have to be addressed: Local Memory Allocation: Determining the exact amount of the memory to be allocated for the distributed array in a processor's local memory. Index Translation: The closed forms developed in <ref> [5, 7] </ref> for data and local index sets are expressed as simple regular sections in terms of indices of T loc. New closed forms in terms of indices of A loc for enumerating the send and receive data index sets and the local index set are to be developed. <p> Next, we develop a procedure for performing the translation between the local template section and the local array section. Using this procedure, the parameterized closed forms for the send and receive data index sets and the local index sets for one-level mappings developed in <ref> [5, 7] </ref> can be extended to those for the two-level mappings. Using the results for the block and cyclically distributed arrays, the virtual processor approach for handling block-cyclically distributed templates is extended. <p> Section 5 provides conclusions. 2 Block and Cyclically Distributed Templates The evaluation of the regular section characterization of the array elements mapped to a processor uses several results about the intersection, translation, expansion, and compression of regular sections. For details of these results the reader is referred to <ref> [7] </ref>. In this section, we address the memory allocation and indexing problem for block and cyclically distributed templates. Consider an array A (m 1 : n 1 ) aligned with a template T (q 1 : r 1 ) at a stride c and an offset a. <p> = u 0 + q 1 + pb; s = s 0 : For the cyclically distributed template we have l = q 1 + p + l 0 P; u = q 1 + p + u 0 P; s = s 0 P Furthermore, the techniques developed in <ref> [5, 7] </ref> guarantee that every cell in the template section T (l : u : s) has an array element aligned with it. <p> The above formulas are instantiated to obtain specific closed forms for block and cyclically distributed templates in <ref> [7] </ref>. 3 Virtual Processor Approach for Two-Level Mappings We now extend the memory allocation scheme and the index translation scheme to block-cyclically distributed templates using the virtual processor approach. For details of the virtual processor approach the reader is referred to [5, 7]. <p> For details of the virtual processor approach the reader is referred to <ref> [5, 7] </ref>. The virtual processor approach is based on viewing a block-cyclic distribution as a block (or cyclic) distribution on a set of virtual processors, which are cyclically (or block-wise) mapped to the physical processors. <p> Given a template section, T (l : u : s) the characterization of the active virtual processors on a processor, can be performed using techniques similar to those presented in <ref> [5, 7] </ref>. Depending on the set of virtual processor for which memory has been allocated, some translation of this set of active virtual processors will have to be performed [7]. <p> Depending on the set of virtual processor for which memory has been allocated, some translation of this set of active virtual processors will have to be performed <ref> [7] </ref>. We now describe the allocation scheme for the virtual-cyclic view. 3.2 Virtual Cyclic View Consider array A (m 1 : n 1 ) aligned with a template T (q 1 : r 1 ) at a stride c and an offset a. <p> Hence based on on the requirement for the non-empty intersection of two regular sections, a virtual processor v may have array elements mapped to it if gcd (c; P fl b)j (q 1 + v a m 1 c) <ref> [7] </ref>. The first virtual processor v f on a processor p can be found by noting that the v f 2 (p fl b : p fl b + b 1) and gcd (c; P fl b)j (q 1 + v f a m 1 c). <p> Given a template section, T ( ~ l : ~u : c fl s) the characterization of the active virtual processors on a processor, i.e., the set of virtual processors to which elements of the template section are mapped, can be performed using techniques similar to those presented in <ref> [5, 7] </ref>. Depending on the set of virtual processors for which memory has been allocated, some translation and compression of this set of active virtual processors will need to be performed [7]. <p> Depending on the set of virtual processors for which memory has been allocated, some translation and compression of this set of active virtual processors will need to be performed <ref> [7] </ref>. <p> All the reported times are in microseconds. Due to lack of space we present only the performance figures for a cyclic (720) distribution with virtual block view. For other performance figures refer to <ref> [7] </ref>. Table 1 presents the table generation times. For all the data points considered it can be observed that the table generation time for the indexing scheme with hole-compression is greater than that for the scheme without hole-compression.
Reference: 8. <author> K. Kennedy, N. Nedeljkovic', and A. Sethi. </author> <title> A linear-time algorithm for computing the memory access sequence in data-parallel programs. </title> <type> Technical Report CRPC-TR94485-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: A linear-time algorithm for constructing the FSM which improves the asymptotic complexity of the algorithm presented in [6] was presented in <ref> [8] </ref>. The key idea behind the construction is the recognition that the local index space for a block-cyclically distributed array is an integer lattice spanned by a basis of dimensionality two.
Reference: 9. <author> C. Koelbel. </author> <title> Compile-time generation of communication for scientific programs. </title> <booktitle> In Proc. of Supercomputing '91, </booktitle> <pages> pages 101-110, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: If the arrays have only block or cyclic distributions, then the data index sets and the processor sets can be characterized using regular sections for closed forms <ref> [5, 9] </ref>. However, for the general block-cyclic distribution, closed form characterization of these sets using simple regular sections is not possible. Several approaches have addressed the efficient execution of array statements involving block-cyclically distributed arrays.
Reference: 10. <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, and M. Zosel. </author> <title> High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction Languages such as High Performance Fortran (HPF) <ref> [3, 10] </ref>, Fortran-D [4], and Vienna Fortran [1] provide a programming environment which allows annotation of single address space programs with distribution directives specifying the mapping of arrays to processors of a distributed-memory machine.
Reference: 11. <author> J. M. Stichnoth. </author> <title> Efficient compilation of array statements for private memory multicomputers. </title> <type> Technical Report CMU-CS-93-109, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: These closed forms are then used in the virtual processor domain for efficient enumeration of the communication and local index sets. The problem of local index set identification was addressed by Chatterjee et al. [2] using a finite-state machine (FSM) to traverse the local index space. Stichnoth et al. <ref> [11] </ref> address the problem of index set and processor set identification. The formulation proposed has similarities to an instance of the virtual processor approach. The implementation of the Fortran-D compiler at Rice University is being extended to handle arrays with block-cyclic distributions [6].
Reference: 12. <author> A. Thirumalai and J. Ramanujam. </author> <title> Code generation and optimization for array statments in HPF. </title> <type> Technical Report TR-94-12-02, </type> <institution> Dept. of Electrical and Computer Engineering, Louisiana State University, </institution> <year> 1994. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: An approach for the local index set and communication set enumeration based on identifying the basis for the integer lattice and exploiting pattern repetition in the send and receive sets was presented in <ref> [12] </ref>. HPF supports a two-level mapping of data arrays to the abstract processor grid. The language introduces a Cartesian grid referred to as a template.
References-found: 12

