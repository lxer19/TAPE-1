URL: http://www.cc.gatech.edu/grads/b/Gary.N.Boone/papers/reagent.ps.Z
Refering-URL: http://www.cs.gatech.edu/grads/b/Gary.N.Boone/professional.html
Root-URL: 
Email: gboone@cc.gatech.edu  
Title: Concept Features in Re:Agent, an Intelligent Email Agent  
Author: Gary Boone 
Keyword: Electronic mail, intelligent agents, machine learning, information management, feature selection, concept features  
Web: www.cc.gatech.edu/~gboone  
Affiliation: Georgia Institute of Technology  
Abstract: An important issue in the application of machine learning techniques to information management tasks is the nature of features extracted from textual information. We have created an intelligent email agent that can learn actions such as filtering, prioritizing, downloading to palmtops, and forwarding email to voicemail using automatic feature extraction. Our agent's new feature extraction approach is based on first learning concepts present within the mail, then using these concepts as features for learning actions to perform on the messages. What features should be chosen? This paper describes the concept features approach and considers two sources for learning conceptual features: groups defined by the user and groups defined by the agent's task. Additionally, features may be defined by vectorized examples or keywords. Experimental results are provided for an email sorting task. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Managing corporate communications in the information age. http://www.pitneybowes.com/pbi/whatsnew/ releases/communication options.htm. Institute for the Future (IFTF), the Gallup Organization and San Jose State University, commissioned by Pitney Bowes Inc. </institution>
Reference-contexts: 1 Introduction The Internet, World Wide Web, communications networks, and widespread computation and storage are rapidly creating a world in which information is ubiquitous and inexpensive. The disadvantage of access, however, is inundation. Popular media describe an alarming situation in which individuals are spending more and more time filtering information <ref> [10, 1] </ref>. The flood of irrelevant, often unwanted, data has created a need for intelligent information management systems that automate the selection, sorting, presentation, storage, and retrieval of emails, faxes, voicemail, phone-pager text, web pages and other forms of information we encounter daily.
Reference: [2] <author> Marko Balabanovic and Yoav Shoham. </author> <title> Learning information retrieval agents: Experiments with automated web browsing. </title> <booktitle> In AAAI-95 Spring Symposium on Information Gathering from Heterogenous, Distributed Environments, </booktitle> <year> 1995. </year>
Reference-contexts: However, in some cases, there is structure; an intelligent system should use it when available. For example, although the body of email is unstructured, the sender, routing, and recipient information is explicitly labeled. One solution is to design an agent capable of extracting useful statistical features from documents <ref> [12, 2] </ref>. Once transformed into a feature vector, learning algorithms can be trained to apply the appropriate actions. The use of a machine learning approach allows the email agent to learn from the user.
Reference: [3] <author> Suzanna Becker and Mark Plumbley. </author> <title> Unsupervised neural network learning procedures for feature extraction and classification. </title> <journal> Journal of Applied Intelligence, </journal> <volume> 6 </volume> <pages> 1-21, </pages> <year> 1996. </year>
Reference-contexts: The conceptual features approach represents a balance between statistical classification and complete understanding. It may be suggested that the agent should be able to infer conceptual features automatically by choosing features which best predict the training data. Several researchers have considered this approach <ref> [3, 4, 8, 14] </ref>. For example, Latent Semantic Analysis uses singular value decomposition to find a set of orthogonal factors which best represents the semantic structure of the documents [6].
Reference: [4] <author> Chris Clack, Jonny Farrington, Peter Lidwell, and Tina Yu. </author> <title> Autonomous document classification for business. </title> <booktitle> In Proceedings of the 1997 International Conference on Autonomous Agents, </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: The conceptual features approach represents a balance between statistical classification and complete understanding. It may be suggested that the agent should be able to infer conceptual features automatically by choosing features which best predict the training data. Several researchers have considered this approach <ref> [3, 4, 8, 14] </ref>. For example, Latent Semantic Analysis uses singular value decomposition to find a set of orthogonal factors which best represents the semantic structure of the documents [6].
Reference: [5] <author> William W. Cohen. </author> <title> Learning rules that classify e-mail. </title> <booktitle> In Proceeding of the AAAI Spring Symposium on Machine Learning in Information Access, </booktitle> <year> 1996. </year>
Reference-contexts: Stop-listing was used to remove common words such as and and the. Their classification learning algorithms consisted of a rule-induction method and a k-nearest neighbor method. Like Maes and Kozierok, they used trust thresholds to allow the agent act autonomously for high-confidence predictions. Cohen <ref> [5] </ref> used a weighted vector approach similar to the one we used. He created an algorithm that learned rules based on keywords in particular fields.
Reference: [6] <author> Scott Deerwester, Susan T. Dumais, and Richard Harshman. </author> <title> Indexing by latent semantic analysis. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(6) </volume> <pages> 391-407, </pages> <year> 1990. </year>
Reference-contexts: Several researchers have considered this approach [3, 4, 8, 14]. For example, Latent Semantic Analysis uses singular value decomposition to find a set of orthogonal factors which best represents the semantic structure of the documents <ref> [6] </ref>. However, because any database of text examples will contain a small number of examples for each of a large number of topics, automatic feature extraction will generate many incorrect feature words [14].
Reference: [7] <author> B. Doorenbos, O. Etzioni, and D. Weld. </author> <title> A scalable comparison-shopping agent for the world-wide web. </title> <booktitle> In Proceedings of the 1997 International Conference on Autonomous Agents, </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping <ref> [7] </ref>, newsgroup reading [13, 25], interface assistance [29, 24], information retrieval [15], and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain.
Reference: [8] <author> David J. Finton and Yu Hen Hu. </author> <title> Importance-based feature extraction for reinforcement learning. </title> <editor> In et al. Thomas Petsche, editor, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> volume 3. </volume> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The conceptual features approach represents a balance between statistical classification and complete understanding. It may be suggested that the agent should be able to infer conceptual features automatically by choosing features which best predict the training data. Several researchers have considered this approach <ref> [3, 4, 8, 14] </ref>. For example, Latent Semantic Analysis uses singular value decomposition to find a set of orthogonal factors which best represents the semantic structure of the documents [6].
Reference: [9] <author> William B. Frakes and Ricardo Baeza-Yates. </author> <title> Information Retreival: Data Structures and Algorithms. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: If words are used as features, the vector space has a dimensionality equivalent to the number of feature words used. This approach requires the feature words to be chosen carefully or severely limited via stop-listing, the reduction of words to a limited set of words deemed useful to categorizing <ref> [9] </ref>. Without such limits, the dimensionality will be too large to utilize machine learning algorithms, which often require low or moderate dimensions. The concept features approach reduces the dimensionality for the action learner by first learning only a relatively few high-level concept features.
Reference: [10] <author> S. C. Gwynne and John F. Dickerson. </author> <title> Lost in the email. Time Magazine, </title> <month> April </month> <year> 1997. </year> <pages> pp. 88-90. </pages>
Reference-contexts: 1 Introduction The Internet, World Wide Web, communications networks, and widespread computation and storage are rapidly creating a world in which information is ubiquitous and inexpensive. The disadvantage of access, however, is inundation. Popular media describe an alarming situation in which individuals are spending more and more time filtering information <ref> [10, 1] </ref>. The flood of irrelevant, often unwanted, data has created a need for intelligent information management systems that automate the selection, sorting, presentation, storage, and retrieval of emails, faxes, voicemail, phone-pager text, web pages and other forms of information we encounter daily.
Reference: [11] <author> Jonathan Helfman and Charles Isbell. Ishmail: </author> <title> Immediate identification of important information. </title> <type> Technical report, </type> <institution> AT&T Labs, </institution> <year> 1995. </year>
Reference-contexts: Even for the headers with known content, the utility of their information is limited. Knowing the sender of an email is useful, but often the same sender discusses different topics. Some form of content understanding is required. The current generation of email filtering packages, including Elm Filter [27], Ishmail <ref> [11] </ref>, and Procmail [26], requires user-written rules to interpret and sort email. For example, when Procmail, which uses regular expressions, finds a match in a specified line of text, the email is forwarded, appended to a mailbox file, or piped to another program.
Reference: [12] <author> David Hull, Jan Pedersen, and Hinrich Schuetze. </author> <title> Document routing as statistical classification. </title> <booktitle> In AAAI Spring Symposium on Machine Learning in Information Access, </booktitle> <address> Palo Alto, CA, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: However, in some cases, there is structure; an intelligent system should use it when available. For example, although the body of email is unstructured, the sender, routing, and recipient information is explicitly labeled. One solution is to design an agent capable of extracting useful statistical features from documents <ref> [12, 2] </ref>. Once transformed into a feature vector, learning algorithms can be trained to apply the appropriate actions. The use of a machine learning approach allows the email agent to learn from the user.
Reference: [13] <author> Tomonari Kamba, Krishna Bharat, and Michael Albers. </author> <title> The krakatoa chronicle: An interactive, personalized newspaper on the web. </title> <booktitle> In Proceedings of the Fourth International World-Wide Web Conference, </booktitle> <address> Boston, MA, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading <ref> [13, 25] </ref>, interface assistance [29, 24], information retrieval [15], and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain.
Reference: [14] <author> Daphne Koller and Mehran Sahami. </author> <title> Toward optimal feature selection. </title> <editor> In Lorenza Saitta, editor, </editor> <booktitle> Machine Learning: Proceedings of the Thirteenth International Conference. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: The conceptual features approach represents a balance between statistical classification and complete understanding. It may be suggested that the agent should be able to infer conceptual features automatically by choosing features which best predict the training data. Several researchers have considered this approach <ref> [3, 4, 8, 14] </ref>. For example, Latent Semantic Analysis uses singular value decomposition to find a set of orthogonal factors which best represents the semantic structure of the documents [6]. <p> However, because any database of text examples will contain a small number of examples for each of a large number of topics, automatic feature extraction will generate many incorrect feature words <ref> [14] </ref>. The concept features approach allows the user to guide the learning process by suggesting actual conceptual features present in the text. The construction of these features is natural to users with sorted email. Future work will consider direct comparisons of these techniques.
Reference: [15] <author> Daphne Koller and Yoav Shoham. </author> <title> Information agents: A new challenge for ai. </title> <journal> IEEE Expert, </journal> <pages> pages 8-10, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading [13, 25], interface assistance [29, 24], information retrieval <ref> [15] </ref>, and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain.
Reference: [16] <author> Bruce Krulwich. </author> <title> Learning document category descriptions through the extraction of semantically significant phrases. </title> <booktitle> In Proceedings of the IJCAI Workshop on Data Engineering for Inductive Learning, </booktitle> <year> 1995. </year>
Reference-contexts: Indeed, many researchers have recognized the utility of this approach. Terveen, for example, provides an agent/user col-laboration interface for creating email-handling rules [28]. Krulwich's document handling agent queries the user to solicit categories for documents in which the user indicates interest <ref> [16] </ref>. In some systems, the features are fixed by the programmer; for example a particular set of words or fields may be prespecified. In our system, the agent learns the features automatically based on the task or on user suggestions about the training email's content.
Reference: [17] <editor> Yazdi Lashkari, Max Metral, and Pattie Maes. </editor> <booktitle> Collaborative interface agents. In Proceedings of the Twelfth National Conference on Artificial Intelligence, volume 1, </booktitle> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year> <note> AAAI Press. </note>
Reference-contexts: The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading [13, 25], interface assistance [29, 24], information retrieval [15], and email management <ref> [19, 17, 20] </ref>. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain.
Reference: [18] <author> Henry Lieberman. Letizia: </author> <title> An agent that assists web browsing. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: To appear in the Second International Conference on Autonomous Agents (Agents '98) Minneapolis/St. Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing <ref> [18, 21] </ref>, web shopping [7], newsgroup reading [13, 25], interface assistance [29, 24], information retrieval [15], and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques.
Reference: [19] <author> P. Maes and R. Kozierok. </author> <title> Learning interface agents. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 459-465, </pages> <address> Washington, D.C., July 1993. </address> <publisher> MIT Press. </publisher>
Reference-contexts: The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading [13, 25], interface assistance [29, 24], information retrieval [15], and email management <ref> [19, 17, 20] </ref>. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain. <p> Rule-based systems can be challenging for users due to the difficulty of not only determining the rule that achieves the desired result, but also writing it with the correct syntax. There have been several attempts to automate the management of email. Maes and Kozierok <ref> [19] </ref> created an email agent that observed the user interacting with email. The system inferred rules by storing situation-action pairs; when it observed a situation similar to one it had seen before, it suggested the associated action.
Reference: [20] <author> Terry R. Payne and Peter Edwards. </author> <title> Learn: An investigation of learning issues in a mail agent interface. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 11 </volume> <pages> 1-32, </pages> <year> 1997. </year>
Reference-contexts: The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading [13, 25], interface assistance [29, 24], information retrieval [15], and email management <ref> [19, 17, 20] </ref>. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain. <p> The system used a confidence threshold to determine whether to make a suggestion to the user. A second threshold allowed the user to tell the agent to automatically execute the action without confirmation. Payne and Edwards <ref> [20] </ref> considered two methods to learn to automatically classify email. They used features consisting of the words in the From and Subject fields and the top 10 most frequent words in the body. Stop-listing was used to remove common words such as and and the.
Reference: [21] <author> Michael Pazzani, Daniel Billsus, and Jack Muramatsu. Syskill & webert: </author> <title> Identifying interesting web sites. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1996. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: To appear in the Second International Conference on Autonomous Agents (Agents '98) Minneapolis/St. Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing <ref> [18, 21] </ref>, web shopping [7], newsgroup reading [13, 25], interface assistance [29, 24], information retrieval [15], and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques.
Reference: [22] <author> Gerard Salton. </author> <title> Automatic Text Processing. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: The cluster center is stored in the feature for future use. In addition to saving calculation time during feature extraction by eliminating the need to calculate distances to every example, using the cluster center aids classification in some circumstances <ref> [22] </ref>. The similarity between vectorized messages is given by the dot product of the tfidf vectors. Because these vectors are normalized, this calculation gives their cosine angle; similar messages are separated by small angles. Given an email message, the feature extraction process creates a feature representation of the message.
Reference: [23] <author> Gerard Salton and Chris Buckley. </author> <title> Term weighting approaches in automatic text retrieval. </title> <type> Technical report, </type> <institution> Cornell University, Department of Computer Science, </institution> <year> 1987. </year>
Reference-contexts: The resulting feature vector is used by the action learning algorithm to classify the email. If the feature uses examples, the example emails are first converted to vector space representations. Our email algorithms operate on a representation based on tfidf vectors commonly used in Information Retrieval <ref> [23] </ref>. An email message is first transformed into a vector of word counts where each count is divided by the number of other documents in which the word occurs. This term frequency/inverse document frequency approach weights each word according to how unique it is within the body of emails.
Reference: [24] <author> Jeffrey C. Schlimmer and Leonard A. Hermens. </author> <title> Software agents: Completing patterns and constructing user interfaces. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 61-89, </pages> <year> 1993. </year>
Reference-contexts: Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading [13, 25], interface assistance <ref> [29, 24] </ref>, information retrieval [15], and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain.
Reference: [25] <author> B. Sheth and P. Maes. </author> <title> Evolving agents for personalized information filtering. </title> <booktitle> In Ninth Conference on Artificial Intelligence for Applications, </booktitle> <pages> pages 345-352, </pages> <address> Orlanda, FL, March 1993. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading <ref> [13, 25] </ref>, interface assistance [29, 24], information retrieval [15], and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain.
Reference: [26] <author> Germany Stephen R. van den Berg at RWTH-Aachen. </author> <title> procmail|autonomous mail processor. </title>
Reference-contexts: Knowing the sender of an email is useful, but often the same sender discusses different topics. Some form of content understanding is required. The current generation of email filtering packages, including Elm Filter [27], Ishmail [11], and Procmail <ref> [26] </ref>, requires user-written rules to interpret and sort email. For example, when Procmail, which uses regular expressions, finds a match in a specified line of text, the email is forwarded, appended to a mailbox file, or piped to another program.
Reference: [27] <author> D. Taylor. </author> <title> Mail filtering on the fly: The elm filter program. </title> <type> Technical Report STL-88-4, </type> <institution> Hewlitt-Packard Laboratories, </institution> <address> Palo Alto, CA, </address> <month> February </month> <year> 1988. </year>
Reference-contexts: Even for the headers with known content, the utility of their information is limited. Knowing the sender of an email is useful, but often the same sender discusses different topics. Some form of content understanding is required. The current generation of email filtering packages, including Elm Filter <ref> [27] </ref>, Ishmail [11], and Procmail [26], requires user-written rules to interpret and sort email. For example, when Procmail, which uses regular expressions, finds a match in a specified line of text, the email is forwarded, appended to a mailbox file, or piped to another program.
Reference: [28] <author> Loren G. Terveen and La Tondra Murray. </author> <title> Helping users program their personal agents. </title> <booktitle> In Proceedings of the 1996 Conference on Human Factors in Computing Systems (CHI '96), </booktitle> <pages> pages 355-361, </pages> <address> Vancouver, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: By watching the user interact with documents, an agent can learn the information tasks, the user preferences and interests, and example solution techniques. Indeed, many researchers have recognized the utility of this approach. Terveen, for example, provides an agent/user col-laboration interface for creating email-handling rules <ref> [28] </ref>. Krulwich's document handling agent queries the user to solicit categories for documents in which the user indicates interest [16]. In some systems, the features are fixed by the programmer; for example a particular set of words or fields may be prespecified.
Reference: [29] <author> Andy Wood, Anind Dey, and Gregory D. Abowd. Cy-berdesk: </author> <title> Automated integration of desktop and network services. </title> <booktitle> In Proceedings of the 1997 Conference on Human Factors in Computing Systems (CHI '97), </booktitle> <year> 1997. </year>
Reference-contexts: Paul, May 10-13, 1998. The intelligent agent has emerged as a paradigm in which programs are created as proxies for humans in interactions with computers. Agent-based approaches have been used in web browsing [18, 21], web shopping [7], newsgroup reading [13, 25], interface assistance <ref> [29, 24] </ref>, information retrieval [15], and email management [19, 17, 20]. We have developed an intelligent information management agent based on numerical machine learning techniques. To validate our approach in a real-world setting, we chose email management as the test domain.
References-found: 29

