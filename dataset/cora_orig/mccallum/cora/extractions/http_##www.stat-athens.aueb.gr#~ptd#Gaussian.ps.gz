URL: http://www.stat-athens.aueb.gr/~ptd/Gaussian.ps.gz
Refering-URL: http://www.stat-athens.aueb.gr/~ptd/papers.htm
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Bayesian inference for nondecomposable graphical Gaussian models  
Author: Petros Dellaportas Paolo Giudici and Gareth Roberts 
Abstract: In this paper we propose a method to calculate the posterior probability of a nondecomposable graphical Gaussian model. Our proposal is based on a new device to sample from Wishart distributions, conditional on the graphical constraints. As a result, our methodology allows Bayesian model selection within the whole class of graphical Gaussian models, including nondecomposable ones.
Abstract-found: 1
Intro-found: 1
Reference: <author> Billingsley P. </author> <year> (1979). </year> <title> Probability and measure. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Cox D.R. and Wermuth, N. </author> <year> (1993), </year> <title> Linear dependencies represented by chain graphs. </title> <journal> Statist. Sci. </journal> <volume> 8, </volume> <pages> 204-283. </pages>
Reference: <author> Dawid, A.P. and Lauritzen, S.L. </author> <year> (1993). </year> <title> Hyper Markow Laws in the statistical analysis of decomposable graphical models. </title> <journal> Ann. Statist. </journal> <volume> 21, </volume> <pages> 1272-1317. </pages>
Reference-contexts: More precisely, we shall assume: P G = N p (0; K 1 where N p (0; K 1 G ) indicates a multivariate Gaussian distribution, with zero expected value and precision K G , such that P G be Markov over G <ref> (see, e.g. Dawid and Lauritzen, 1993) </ref>. The statistical model specified in (1) is known as a graphical Gaussian model (Speed and Kiiveri, 1986). To understand the constraints imposed on K G by the graphical structure, we need a preliminary definition.
Reference: <author> Dickey, J.M. </author> <year> (1971). </year> <title> The weighted likelihood ratio, linear hypotheses on normal location parameters. </title> <journal> Ann. Math. Statist. </journal> <volume> 42, </volume> <pages> 204-223. </pages>
Reference: <author> Dempster, A.P. </author> <year> (1972). </year> <title> Covariance selection. </title> <type> Biometrics 28, </type> <pages> 157-175. </pages>
Reference: <author> Giudici, P. </author> <year> (1996). </year> <title> Learning in graphical Gaussian models. In Bayesian Statistics 5 (J.M. </title> <editor> Bernardo, J.O. Berger, A.P. Dawid, A.F.M. Smith eds), </editor> <publisher> Oxford University Press, Oxford. </publisher> <address> 13 Lauritzen, S.L. </address> <year> (1996). </year> <title> Graphical models. </title> <publisher> Oxford University Press, Oxford. </publisher>
Reference: <author> Madigan, D. and Raftery, A.E. </author> <year> (1995). </year> <title> Model selection and accounting for model uncertainty in graphical models using Occam's window. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 89, </volume> <pages> 1535-1546. </pages>
Reference: <author> Speed, T.P. and Kiiveri, H. </author> <year> (1986). </year> <title> Gaussian Markov distributions over finite graphs. </title>
Reference-contexts: Dawid and Lauritzen, 1993). The statistical model specified in (1) is known as a graphical Gaussian model <ref> (Speed and Kiiveri, 1986) </ref>. To understand the constraints imposed on K G by the graphical structure, we need a preliminary definition. Consider an arbitrary multivariate Gaussian distribution, with K G positive definite.
Reference: <editor> Ann. Statist. </editor> <volume> 14, </volume> <pages> 138-150. </pages>
Reference: <author> Tierney, L. </author> <year> (1994). </year> <title> Markov Chains for exploring posterior distributions. </title> <journal> Ann. </journal> <volume> Statist.22, </volume> <pages> 1701-1762. </pages>
Reference-contexts: Whittaker, 1990). 6 COMMENTS AND EXTENSIONS An alternative procedure for performing the sampling from the conditional Wishart using the same importance weights as derived in Section 4 uses the independence sampler <ref> (see e.g. Tierney, 1994) </ref>. Using the independence sampler allows flexibility in extending our methodology in several ways. 12 For instance, a mean parameter can parametrise the graphical Gaussian model in 2.

References-found: 10

