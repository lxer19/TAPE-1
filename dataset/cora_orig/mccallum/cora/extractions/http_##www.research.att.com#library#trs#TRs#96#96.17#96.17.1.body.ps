URL: http://www.research.att.com/library/trs/TRs/96/96.17/96.17.1.body.ps
Refering-URL: http://www.research.att.com/library/trs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: ON COMBINING FREQUENCY WARPING AND SPECTRAL SHAPING IN HMM BASED SPEECH RECOGNITION  
Author: Alexandros Potamianos and Richard C. Rose 
Address: Murray Hill, NJ 07974, U.S.A.  
Affiliation: AT&T Labs,  
Abstract: Frequency warping approaches to speaker normalization have been proposed and evaluated on various speech recognition tasks [1, 2, 3]. These techniques have been found to significantly improve performance even for speaker independent recognition from short utterances over the telephone network. In maximum likelihood (ML) based model adaptation a linear transformation is estimated and applied to the model parameters in order to increase the likelihood of the input utterance. The purpose of this paper is to demonstrate that significant advantage can be gained by performing frequency warping and ML speaker adaptation in a unified framework. A procedure is described which compensates utterances by simultaneously scaling the frequency axis and reshaping the spectral energy contour. This procedure is shown to reduce the error rate in a telephone based connected digit recognition task by 30-40%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Andreou, T. Kamm, and J. Cohen, </author> <title> "Experiments in Vocal Tract Normalization," </title> <booktitle> Proc. the CAIP Workshop: Frontiers in Speech Recognition II, </booktitle> <year> 1994. </year>
Reference: [2] <author> R. Roth, et. al., </author> <title> "Dragon Systems' 1994 Large Vocabulary Continuous Speech Recognizer" Proc. </title> <booktitle> of the Spoken Language Systems Technology Workshop, </booktitle> <year> 1995. </year>
Reference: [3] <author> L. Lee and R.C. Rose, </author> <title> "Efficient Frequency Warping Procedures for Telephone Based Speech Recognition," </title> <booktitle> Proc. ICASSP 96, </booktitle> <month> May, </month> <year> 1996. </year>
Reference-contexts: A discussion of the application of frequency warping as applied to childrens' speech recognition using HMM models trained from adult speakers is given in Section 4. Finally, discussion and summary is provided in Sections 5 and 6. 2. SPEAKER NORMALIZATION USING FREQUENCY WARPING In <ref> [3] </ref>, an efficient frequency warping algorithm for speaker normalization was proposed and applied to telephone based speech recognition. The frequency warping approach to speaker normalization compensates mainly for inter-speaker vocal tract length variability by linear warping of the frequency axis by a factor ff. <p> By applying frequency warping during both training and recognition it was shown that word error rate can be reduced by approximately 20%. The frequency warping algorithm described in <ref> [3] </ref> is briefly presented next. Frequency warping is implemented in the mel-frequency filterbank front-end by linear scaling of the spacing and bandwidth of the filters. Scaling the front-end filterbank is equivalent to resampling the spectral envelope using a compressed or expanded frequency range. The speaker normalization algorithm works as follows.
Reference: [4] <author> C. J. Leggetter and P. C. Woodland, </author> <title> "Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models," </title> <booktitle> Computer Speech and Language, </booktitle> <volume> vol. 9, </volume> <pages> pp. 171-185, </pages> <year> 1995. </year>
Reference-contexts: Model adaptation techniques have been used for improving the match between a set of adaptation utterances and the hidden Markov model (HMM) used during recognition. The parameters of a linear transformation are estimated using a maximum likelihood criterion and the transformation is applied to the HMM parameters <ref> [4] </ref>. A common problem among these techniques is the existence of speakers in a population whose speech recognition performance does not improve after adaptation. This can be especially true for unsupervised, single utterance based adaptation scenarios.
Reference: [5] <author> T. Matsui and S. </author> <title> Furui,"N-best-based instantaneous speaker adaptation method for speech recognition", </title> <booktitle> Proc. ICSLP, Oc, </booktitle> <year> 1996. </year>
Reference-contexts: In a separate study, Matsui and Furui estimated the transformation, h fl (), by searching over the set of N-best candidates alone <ref> [5] </ref>. For each model and each string candidate, we solve for the ^fl ff;H n which maximizes where optimum model transformation is computed with respect to an ensemble of models and an ensemble of word transcriptions. where optimum transformation is applied on the observation sequence.
Reference: [6] <author> D. C. Burnett and M. Fanty, </author> <title> "Rapid unsupervised adaptation to children's speech on a connected-digit task," </title> <booktitle> in Proc. ICSLP, </booktitle> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: Note that for children speakers, up to 30% expansion of the frequency scale is allowed during frequency warping. Similar children speaker adaptation experiments were reported in <ref> [6] </ref>. Despite the small amount of data used to estimate the optimal warping factor (one to ten words) and the simplicity of the transformation (linear warping) the speaker normalization algorithm can provide word error rate reduction up to 70% for mismatched training and testing speaker populations.
References-found: 6

