URL: http://www.aic.nrl.navy.mil/papers/1997/AIC-97-001.ps.Z
Refering-URL: http://www.aic.nrl.navy.mil/~aha/pub-details.html
Root-URL: 
Email: Email: ricci@irst.itc.it, aha@aic.nrl.navy.mil  
Phone: Phone: ++39 461 314334 FAX: ++39 461 302040  
Title: Extending Local Learners with Error-Correcting Output Codes 1  
Author: Francesco Ricci David W. Aha 
Keyword: Case-based learning,  
Note: classification, error-correcting output codes  
Address: 38050 Povo (TN), Italy  Code 5510 Washington, DC 20375 USA  
Affiliation: Istituto per la Ricerca Scientifica e Tecnologica  Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory,  
Abstract: Error-correcting output codes (ECOCs) represent classes with a set of output bits, where each bit encodes a binary classification task corresponding to a unique partition of the classes. Algorithms that use ECOCs learn the function corresponding to each bit, and combine them to generate class predictions. ECOCs can reduce both variance and bias errors for multiclass classification tasks when the errors made at the output bits are not correlated. They work well with algorithms that eagerly induce global classifiers (e.g., C4.5) but do not assist simple local classifiers (e.g., nearest neighbor), which yield correlated predictions across the output bits. This is distressing because local learning algorithms for classification are preferable to global classifiers for some types of applications. We show that the output bit predictions of local learners can be decorrelated by selecting different features for each bit. We present promising empirical results for this combination of ECOCs, nearest neighbor, and feature selection. We also describe modifications to the schemata racing algorithm for feature selection that improve its ability to retrieve good feature subsets in this context. 
Abstract-found: 1
Intro-found: 1
Reference: [ Aha and Bankert, 1997 ] <author> D. W. Aha and R. L. Bankert. </author> <title> Cloud classification using error-correcting output codes. </title> <booktitle> Artificial Intelligence Applications: Natural Science, Agriculture, and Environmental Science, </booktitle> <volume> 11 </volume> <pages> 13-28, </pages> <year> 1997. </year>
Reference-contexts: We found similar behavior with k &gt; 1 in other experiments (not reported here). Previous research on ECOCs did not stress feature selection, which is crucial for some tasks. Due to their low training costs, nearest neighbor classifiers are excellent for use with expensive feature selection approaches <ref> [ Aha and Bankert, 1997 ] </ref> . Perhaps the most effective feature selectors are those that guide search using feedback from the classifier itself. This is expensive because it requires evaluating the classifier on many feature subsets. This is good motivation for using an inexpensive classifier such as nearest neighbor.
Reference: [ Aha et al., 1991 ] <author> David W. Aha, Dennis Kibler, and Mark K. Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 37-66, </pages> <year> 1991. </year>
Reference-contexts: Therefore, we extended IB1 <ref> [ Aha et al., 1991 ] </ref> , an implementation of nearest neighbor, to use different features when computing distances for each output bit.
Reference: [ Aha, 1992 ] <author> D. W. Aha. </author> <title> Tolerating noisy, irrelevant, and novel attributes in instance-based learning algorithms. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 36 </volume> <pages> 267-287, </pages> <year> 1992. </year>
Reference-contexts: In one-per-class each bit function separates the examples in one class from the remaining examples (i.e., exactly one output bit in a one-per-class codeword has value 1; all others have value 0). Learning algorithms that use one-per-class encodings induce a separate concept description per class <ref> [ Quinlan, 1993; Aha, 1992 ] </ref> , where positive instances of a class c i are negative instances for all other classes c j (i6=j). Winner-take-all networks are examples of classifiers that use one-per-class output encodings.
Reference: [ Bottou and Vapnik, 1992 ] <author> Leon Bottou and Vladimir Vapnik. </author> <title> Local learning algorithms. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 888-900, </pages> <year> 1992. </year>
Reference-contexts: However, ECOCs do not benefit local learning algorithms <ref> [ Kong and Dietterich, 1995; Bottou and Vapnik, 1992 ] </ref> , which predict classifications for a query q based only on information from examples local (i.e., nearby) to q. In Section 1.2, we explain that this limitation occurs because a local learner's predictions are correlated across the output bits.
Reference: [ Breiman, 1996 ] <author> Leo Breiman. </author> <title> Bias, variance, and arcing classifiers. </title> <type> Technical Report 460, </type> <institution> University of California, Berkeley, </institution> <month> April </month> <year> 1996. </year>
Reference-contexts: The reason why IB1 ecoc reduces IB1 atomic 's expected error is linked to the bias/variance dilemma [ Geman et al., 1992 ] . The nearest neighbor classifier usually has small variance and high bias <ref> [ Breiman, 1996 ] </ref> . In a forthcoming paper we shall shown that IB1 ecoc reduces the bias component at the cost of a smaller increase in variance. Bias is reduced because of feature selection whereas variance is increased by the random nature of the racing schemata algorithm.
Reference: [ Dietterich and Bakiri, 1995 ] <author> T. G. Dietterich and G. Bakiri. </author> <title> Solving multiclass learning problems via error-correcting output codes. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 263-286, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Error-correcting output codes (ECOCs) can help distinguish classes in classification tasks with m &gt; 2 classes by encoding error-correcting capabilities in their output representation. This can increase the classification accuracy of global learning algorithms <ref> [ Dietterich and Bakiri, 1995 ] </ref> (e.g., C4.5 [ Quinlan, 1993 ] , backpropagation [ Rumelhart et al., 1986 ] ), which induce classification boundaries that are heuristically determined using all training examples. <p> Example Output Representations Class Output Representation Name Atomic Distributed One-Per-Class ECOC Earthling 1 100 00000 Martian 2 010 11100 Italian 3 001 00111 s i = (s i1 ; : : : ; s il ) of l codeletters (e.g., <ref> [ Dietterich and Bakiri, 1995 ] </ref> ). The most popular atomic strategy sets l = 1; it uses a single codeletter to represent class labels. Learning algorithms that use this approach (e.g., C4.5 [ Quinlan, 1993 ] ) induce a single concept description that distinguishes all class boundaries. <p> We describe in the following how to generate ECOC codewords. Atomic and one-per-class codewords are generated as explained in Section 1.1. Algorithms for generating ECOC codewords should maximize both row and column separation. For classification tasks where m7, create codewords uses the exhaustive codes technique <ref> [ Dietterich and Bakiri, 1995 ] </ref> . It creates all 2 m1 1 possible codewords that are both column and row separated. The resulting codewords have Hamming distance h = 2 m2 .
Reference: [ Geman et al., 1992 ] <author> Stuart Geman, Alie Bienenstock, and Rene Doursat. </author> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: Thus, our contributions are useful for multiclass classification tasks where (1) feature selection is needed and (2) obtaining high predictive accuracy is a priority. The reason why IB1 ecoc reduces IB1 atomic 's expected error is linked to the bias/variance dilemma <ref> [ Geman et al., 1992 ] </ref> . The nearest neighbor classifier usually has small variance and high bias [ Breiman, 1996 ] . In a forthcoming paper we shall shown that IB1 ecoc reduces the bias component at the cost of a smaller increase in variance.
Reference: [ Kong and Dietterich, 1995 ] <author> E. B. Kong and T. G Dietterich. </author> <title> Error-correcting output coding cor-rects bias and variance. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 313-321, </pages> <address> Tahoe City, CA, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, ECOCs do not benefit local learning algorithms <ref> [ Kong and Dietterich, 1995; Bottou and Vapnik, 1992 ] </ref> , which predict classifications for a query q based only on information from examples local (i.e., nearby) to q. In Section 1.2, we explain that this limitation occurs because a local learner's predictions are correlated across the output bits.
Reference: [ Maron and Moore, 1997 ] <author> O. Maron and A. W. Moore. </author> <title> The racing algorithm: model selection for lazy learners. </title> <journal> Artificial Intelligence Review, </journal> <pages> pages 193-225, </pages> <year> 1997. </year>
Reference-contexts: This in turn allows a different nearest neighbor to be selected for each bit's prediction, which decorrelates the output bit errors. We also describe a modification of the schemata racing feature selector <ref> [ Maron and Moore, 1997 ] </ref> that is more appropriate for this context. <p> It returns the subset of features selected by a variant of the schemata racing algorithm <ref> [ Maron and Moore, 1997 ] </ref> that we introduce here. Race-schemata searches over the space of schemata strings p 2 P of length d, the number of features, whose characters are 0's (feature is not selected), 1's (selected) and ?'s (selected with probability 50%).
Reference: [ Merz and Murphy, 1996 ] <author> C. Merz and P. M. Murphy. </author> <title> UCI repository of machine learning databases. </title> <note> [http://www.ics.uci.edu/~mlearn/MLRepository.html], 1996. </note>
Reference-contexts: In particular, Section 3.2 summarizes results when using the atomic output representation without feature selection plus all three output representations when using feature selection. 3.1 Data Sets We selected seven data sets (Table 2) from the UCI Repository <ref> [ Merz and Murphy, 1996 ] </ref> that have only numeric or boolean features, no missing values, and at least four classes.
Reference: [ Perrone and Cooper, 1993 ] <author> M. P. Perrone and L. N. Cooper. </author> <title> When networks disagree: Ensemble methods for hybrid neural networks. </title> <editor> In R. J. Mammone, editor, </editor> <title> Neural Networks for Speech and Image Processing. </title> <publisher> Chapman and Hall, </publisher> <address> Philadelphia, PA, </address> <year> 1993. </year>
Reference-contexts: Variance results from random variation and noise in the training set and from any random behaviors of the learning algorithm itself. It can be reduced by averaging the contributions of multiple predictions <ref> [ Perrone and Cooper, 1993 ] </ref> . ECOCs reduce variance through a voting process: because Hamming distance determines the "winning" prediction (i.e., closest codeword), each output bit prediction corresponds to a vote for classes whose codewords match the predicted value. Bias instead refers to an algorithm's systematic errors.
Reference: [ Quinlan, 1993 ] <author> J.R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Error-correcting output codes (ECOCs) can help distinguish classes in classification tasks with m &gt; 2 classes by encoding error-correcting capabilities in their output representation. This can increase the classification accuracy of global learning algorithms [ Dietterich and Bakiri, 1995 ] (e.g., C4.5 <ref> [ Quinlan, 1993 ] </ref> , backpropagation [ Rumelhart et al., 1986 ] ), which induce classification boundaries that are heuristically determined using all training examples. <p> The most popular atomic strategy sets l = 1; it uses a single codeletter to represent class labels. Learning algorithms that use this approach (e.g., C4.5 <ref> [ Quinlan, 1993 ] </ref> ) induce a single concept description that distinguishes all class boundaries. Atomic class labels are limited; they cannot be related by a continuous distance measure. <p> In one-per-class each bit function separates the examples in one class from the remaining examples (i.e., exactly one output bit in a one-per-class codeword has value 1; all others have value 0). Learning algorithms that use one-per-class encodings induce a separate concept description per class <ref> [ Quinlan, 1993; Aha, 1992 ] </ref> , where positive instances of a class c i are negative instances for all other classes c j (i6=j). Winner-take-all networks are examples of classifiers that use one-per-class output encodings. <p> This ensures that the errors of the output bit predictions are uncorrelated. They reported that ECOCs often significantly increased the classification accuracies for C4.5 <ref> [ Quinlan, 1993 ] </ref> and networks trained by backpropagation [ Rumelhart et al., 1986 ] , although training ECOCs is slow because they must learn l concepts (i.e., one per output bit).
Reference: [ Rumelhart et al., 1986 ] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructures of Cognition. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: 1 Introduction Error-correcting output codes (ECOCs) can help distinguish classes in classification tasks with m &gt; 2 classes by encoding error-correcting capabilities in their output representation. This can increase the classification accuracy of global learning algorithms [ Dietterich and Bakiri, 1995 ] (e.g., C4.5 [ Quinlan, 1993 ] , backpropagation <ref> [ Rumelhart et al., 1986 ] </ref> ), which induce classification boundaries that are heuristically determined using all training examples. <p> This ensures that the errors of the output bit predictions are uncorrelated. They reported that ECOCs often significantly increased the classification accuracies for C4.5 [ Quinlan, 1993 ] and networks trained by backpropagation <ref> [ Rumelhart et al., 1986 ] </ref> , although training ECOCs is slow because they must learn l concepts (i.e., one per output bit).
Reference: [ Stanfill and Waltz, 1986 ] <author> C. Stanfill and D. Waltz. </author> <title> Toward memory-based reasoning. </title> <journal> Communication of ACM, </journal> <volume> 29 </volume> <pages> 1213-1229, </pages> <year> 1986. </year>
Reference-contexts: We avoided data sets with symbolic features because they often require distinct weighting metrics (e.g., <ref> [ Stanfill and Waltz, 1986 ] </ref> ), which complicates isolating the effects of feature selection. Data sets with fewer than four classes do not greatly benefit from ECOCs. We also used three additional proprietary data sets concerning cloud classification. We will use abbreviations for the data set names.
Reference: [ Zhang et al., 1992 ] <author> X. Zhang, J. Mesirov, and D. Waltz. </author> <title> Hybrid system for protein structure pre-diction. </title> <journal> Journal of Molecular Biology, </journal> <volume> 225 </volume> <pages> 1049-1063, </pages> <year> 1992. </year> <month> 11 </month>
Reference-contexts: Bias instead refers to an algorithm's systematic errors. These can also be reduced by voting, but only when the individual predictions are uncorrelated, such as by averaging the contributions of different prediction algorithms (e.g., <ref> [ Zhang et al., 1992 ] </ref> ). Alternatively, the same algorithm can be used multiple times, but it must vote on different subproblems (i.e., using different class decision boundaries) that cause the algorithm to generate different bias errors.
References-found: 15

