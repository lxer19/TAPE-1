URL: http://www.cs.wisc.edu/~thain/projects/dirt-paper.ps
Refering-URL: http://www.cs.wisc.edu/~thain/
Root-URL: 
Title: Distributed Requests for Tuples (DIRT) in a Linda System  
Author: Douglas Thain Suan Hsi Yong 
Date: 8 May 1998  
Abstract: Linda is a system for communication between cooperating processes. DIRT is a Linda implementation where storage is distributed among a tree of servers connected by an internet. Requests for data are widely distributed through the tree, while new data is kept near where it is created. We find that a central server coordinating multiple clients requires a large granularity to overcome network latency. In a simple DIRT system, we successfully make use of forty hosts in a cooperative computation. In a more complex system, we develop techniques for moving data closer to where it is needed.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Callsen, I. Cheng, P. Hagen, </author> <title> The AUC C++ Linda System, Edinburgh Parallel Computing Centre, </title> <type> TR 91-13, </type> <year> 1991. </year>
Reference: [2] <author> N. Carriero and D. Gelernter, </author> <title> The S/Net's Linda Kernel, </title> <journal> ACM Transactions on Computer Systems Vol. </journal> <volume> 4 No. </volume> <month> 2 (May </month> <year> 1986), </year> <pages> pp. 110-129. </pages>
Reference-contexts: 1 Introduction A Linda system, as described in <ref> [2] </ref>, consists of an abstract global storage space called a tuple space, in which ordered tuples of information are stored. Linda clients interact with the tuple space through four commands: in, out, read, and eval. <p> The in and out commands block when no matching tuples are found. The original implementation of Linda on the S/Net <ref> [2] </ref> connected eight nodes on a local bus. By taking advantage of the fixed time it took to broadcast a message to all nodes on the bus, this im 1 plementation replicated each tuple to every node in the network, thus sacrificing memory usage for speed. <p> The cluster was subjected to student use in addition to our measurements. 3.2.1 Ping-Pong The ping-pong application is described in <ref> [2] </ref>. One client transmits a "pong" tuple for every "ping" tuple received, while another client does the opposite. We use this simple application to measure the latency of a tuple space operation, and the limit on the number of clients a single server can handle. <p> The ping-pong benchmark measures servers under continuous load from clients. Other applications are likely to be less demanding, allowing a larger numbers of clients per server. 9 3.2.2 Matrix Multiplication The first matrix multiplication algorithm used in <ref> [2] </ref> assigns to each worker process an individual matrix element to compute. <p> We require a rather large granularity to achieve a useful speedup. We applied several optimizations to the matrix multiplication algorithm as presented in <ref> [2] </ref>. * Each worker is assigned one row to compute. * Each worker receives both matrices immediately. The time to request additional rows or columns far outweighs the time to transmit the whole matrix. * Matrices are cached. Each element in the computation is assigned a unique name. <p> As such, it appears one of our goals, which was to keep computations in subtrees separate as much as possible, has not succeeded with this benchmark. 3.4 Tuple Promotion tuple promotion disabled and enabled. This matrix multiplication benchmark is the same as that presented in <ref> [2] </ref>; since tuple promotion only affects read requests, we needed a benchmark that was read intensive. 12 The results show a consistent improvement with tuple promotion in all cases except with a single worker process.
Reference: [3] <author> D. Gelernter, D. Kaminsky, </author> <title> Supercomputing out of Recycled Garbage: Preliminary Experience with Piranha, </title> <type> Technical Report 883, </type> <institution> Yale University Department of Computer Science, </institution> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Modern applications of Linda are more suited towards a collection of workstations connected by an internet. Examples are Piranha <ref> [3] </ref>, a scheme for locating idle machines, and Lifestreams [6], a system for organizing and collaborating on documents. We wish to design a Linda system that will operate effectively over a wide area internet, where participants may have fast communication links to close neighbors, but slower links to distant machines.
Reference: [4] <author> J. Narem, </author> <title> An Informal Operational Semantics of C-Linda V2.3.5., </title> <type> Technical Report 839, </type> <institution> Yale University Department of Computer Science, </institution> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: ( "lark", x, int c ); The syntax for template items in in and read commands require an extension to the C language (which is why Linda is often referred to as a programming language); supporting it would require the development of a new compiler for all Linda applications (see <ref> [4] </ref>). We instead choose a cleaner interface, modelled off of the C++ stream abstraction, that takes advantage of operator overloading.
Reference: [5] <author> O. Thomas, </author> <title> A Linda Kernel for Unix Networks, Linda-Like Systems and Their Implementation, Edinburgh Parallel Computing Center, </title> <type> TR 91-13, </type> <year> 1991. </year>
Reference-contexts: This performance over TCP is significantly longer than the 1-2 ms achieved by the S/Net. However, this result is comparable to those from the UDP broadcast implementation presented in <ref> [5] </ref>. We will have to reconsider the granularity of our applications in this light. As client pairs are added, latency increases slowly up to 64 ms per cycle for 11 clients. Above 11 clients, latency increases drastically.
Reference: [6] <author> E. Freeman and D. Gelernter, Lifestreams: </author> <title> A Storage Model for Personal Data ACM SIGMOD Bulletin, </title> <month> March, </month> <year> 1996. </year> <month> 14 </month>
Reference-contexts: Modern applications of Linda are more suited towards a collection of workstations connected by an internet. Examples are Piranha [3], a scheme for locating idle machines, and Lifestreams <ref> [6] </ref>, a system for organizing and collaborating on documents. We wish to design a Linda system that will operate effectively over a wide area internet, where participants may have fast communication links to close neighbors, but slower links to distant machines.
References-found: 6

