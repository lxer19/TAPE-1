URL: ftp://ftp.cs.berkeley.edu/ucb/sprite/papers/measureSOSP91.ps
Refering-URL: http://www.cs.berkeley.edu/~brewer/cs262.html
Root-URL: 
Title: Measurements of a Distributed File System  
Author: Mary G. Baker, John H. Hartman, Michael D. Kupfer, Ken W. Shirriff, and John K. Ousterhout 
Address: Berkeley, CA 94720  
Affiliation: Computer Science Division Electrical Engineering and Computer Sciences University of California,  
Abstract: We analyzed the user-level file access patterns and caching behavior of the Sprite distributed file system. The first part of our analysis repeated a study done in 1985 of the BSD UNIX file system. We found that file throughput has increased by a factor of 20 to an average of 8 Kbytes per second per active user over 10-minute intervals, and that the use of process migration for load sharing increased burst rates by another factor of six. Also, many more very large (multi-megabyte) files are in use today than in 1985. The second part of our analysis measured the behavior of Sprite's main-memory file caches. Client-level caches average about 7 Mbytes in size (about one-quarter to one- third of main memory) and filter out about 50% of the traffic between clients and servers. 35% of the remaining server traffic is caused by paging, even on workstations with large memories. We found that client cache consistency is needed to prevent stale data errors, but that it is not invoked often enough to degrade overall system performance. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Cheriton, D. R., </author> <title> ``The V Kernel: A Software Base for Distributed Systems'', </title> <booktitle> IEEE Software 1, </booktitle> <month> 2 (April </month> <year> 1984), </year> <pages> 19-43. </pages>
Reference-contexts: Second, several network-oriented operating systems and file systems have been developed during the last decade, e.g. AFS [4], Amoeba [7], Echo [3], Locus [14], NFS [16], Sprite [9], and V <ref> [1] </ref>; they provide transparent network file systems and, in some cases, the ability for a single user to harness many workstations to work on a single task.
Reference: 2. <author> Douglis, F. and Ousterhout, J., </author> <title> ``Transparent Process Migration: Design Alternatives and the Sprite Implementation'', </title> <journal> SoftwarePractice & Experience 21, </journal> <month> 7 (July </month> <year> 1991). </year>
Reference-contexts: The Sprite kernel's facilities are almost identical to those of UNIX, and most of the applications running on the cluster are standard UNIX applications. Sprite has two features that made it a particularly interesting candidate for measurement: its network file system [17] and process migration <ref> [2] </ref>. Sprite's network file system provides a single-system image: there is a single shared file hierarchy with no local disks. <p> Thus the Sprite file system encourages users to share files. The second interesting feature of Sprite is its process migration mechanism, which makes it easy for users to offload jobs to idle machines in the cluster <ref> [2] </ref>. The most common use of process migration is through pmake, a reimplementation of the make utility that uses migration to generate multiple targets in parallel. Pmake is used for all compilations in the cluster and also for simulations and other tasks. <p> The policy used to select hosts for migration tends to reuse the same hosts over and over again, which may July 25, 1991 - 9 - allow some reuse of data in the caches <ref> [2] </ref>. It is encourag-ing to see evidence that a load-sharing scheme such as process migration does not negate the benefits of file caching. Our measurements support the BSD study's predictions that caches will be more successful at absorbing reads than writes.
Reference: 3. <author> Hisgen, A., Birrell, A., Mann, T., Schroeder, M. and Swart, G., </author> <title> ``Availability and Consistency Tradeoffs in the Echo Distributed File System'', </title> <booktitle> Proceedings of the Second Workshop on Workstation Operating Systems, </booktitle> <month> September </month> <year> 1989, </year> <pages> 49-53. </pages>
Reference-contexts: First, computing environments have changed dramatically over the last six years, from relatively slow time-shared machines (VAX-11/780s in the BSD study) to today's much faster personal workstations. Second, several network-oriented operating systems and file systems have been developed during the last decade, e.g. AFS [4], Amoeba [7], Echo <ref> [3] </ref>, Locus [14], NFS [16], Sprite [9], and V [1]; they provide transparent network file systems and, in some cases, the ability for a single user to harness many workstations to work on a single task.
Reference: 4. <author> Howard, J. H., Kazar, M. L., Menees, S. G., Nichols, D. A., Satyanarayanan, M., Sidebotham, R. N. and West, M. J., </author> <title> ``Scale and Performance in a Distributed File System'', </title> <journal> ACM Transactions on Computer Systems 6, </journal> <month> 1 (February </month> <year> 1988), </year> <pages> 51-81. </pages>
Reference-contexts: First, computing environments have changed dramatically over the last six years, from relatively slow time-shared machines (VAX-11/780s in the BSD study) to today's much faster personal workstations. Second, several network-oriented operating systems and file systems have been developed during the last decade, e.g. AFS <ref> [4] </ref>, Amoeba [7], Echo [3], Locus [14], NFS [16], Sprite [9], and V [1]; they provide transparent network file systems and, in some cases, the ability for a single user to harness many workstations to work on a single task. <p> The Importance of Cache Consistency Sprite's caching mechanism provides ``perfect'' consistency: it guarantees that each read operation will return the most recently written data for the file, even if the file is being read and written simultaneously on more than one machine. Most network file systems, such as AFS <ref> [4] </ref> and NFS [16], don't provide such strong consistency guarantees.
Reference: 5. <author> Kazar, M. L., Leverett, B. W., Anderson, O. T., Apostolides, V., Bottos, B. A., Chutani, S., Everhart, C. F., Mason, W. A., Tu, S. and Zayas, E. R., </author> <title> ``DEcorum File System Architectural Overview'', </title> <booktitle> Proceedings of the Summer 1990 USENIX Conference, </booktitle> <address> Anaheim, CA, </address> <month> June 11-15 </month> <year> 1990, </year> <month> 151164. </month>
Reference-contexts: The modified scheme makes a file cacheable again as soon as it has been closed by enough clients to eliminate the concurrent write-sharing. The second alternative is a token-based scheme similar to that implemented in the Locus [14], Echo [6], and DEcorum <ref> [5] </ref> file systems. In this approach a file is always cacheable on at least one client.
Reference: 6. <author> Mann, T., Hisgen, A. and Swart, G., </author> <title> An Algorithm for Data Replication, </title> <institution> Digital Systems Research Center Tech. </institution> <type> Rep. 46, </type> <month> June </month> <year> 1989. </year>
Reference-contexts: The modified scheme makes a file cacheable again as soon as it has been closed by enough clients to eliminate the concurrent write-sharing. The second alternative is a token-based scheme similar to that implemented in the Locus [14], Echo <ref> [6] </ref>, and DEcorum [5] file systems. In this approach a file is always cacheable on at least one client.
Reference: 7. <author> Mullender, S., van Rossum, G., Tanenbaum, A., van Renesse, R. and van Staveren, H., </author> <title> ``Amoeba: A Distributed Operating System for the 1990s'', </title> <booktitle> IEEE Computer 23, </booktitle> <month> 5 (May </month> <year> 1990), </year> <pages> 44-53. </pages>
Reference-contexts: First, computing environments have changed dramatically over the last six years, from relatively slow time-shared machines (VAX-11/780s in the BSD study) to today's much faster personal workstations. Second, several network-oriented operating systems and file systems have been developed during the last decade, e.g. AFS [4], Amoeba <ref> [7] </ref>, Echo [3], Locus [14], NFS [16], Sprite [9], and V [1]; they provide transparent network file systems and, in some cases, the ability for a single user to harness many workstations to work on a single task.
Reference: 8. <author> Nelson, M. N. and Duffy, J. A., </author> <title> Feasibility of Network Paging and a Page Server Design, Term project, </title> <type> CS 262, </type> <institution> Department of EECS, University of California, Berkeley, </institution> <month> May </month> <year> 1984. </year>
Reference-contexts: Although the BSD study did not explicitly measure paging activity, Nelson and Duffy measured paging traffic on one of the same machines used for the BSD study at about the same time and found an average paging rate of about 3 Kbytes per second <ref> [8] </ref>. The BSD study measured about 4 Kbytes of raw file traffic per second, so paging accounted for about 43% of all I/O traffic at that time.
Reference: 9. <author> Nelson, M. N., Welch, B. B. and Ousterhout, J. K., </author> <title> ``Caching in the Sprite Network File System'', </title> <journal> ACM Transactions on Computer Systems 6, </journal> <month> 1 (February </month> <year> 1988), </year> <pages> 134-154. </pages>
Reference-contexts: Second, several network-oriented operating systems and file systems have been developed during the last decade, e.g. AFS [4], Amoeba [7], Echo [3], Locus [14], NFS [16], Sprite <ref> [9] </ref>, and V [1]; they provide transparent network file systems and, in some cases, the ability for a single user to harness many workstations to work on a single task. <p> We made our measurements on a collection of about 40 10-MIPS workstations all running the Sprite operating system <ref> [9, 12] </ref>. Four of the workstations served as file servers, and the rest were diskless clients. Our results are presented in two groups. The first group of results parallels the analysis of the BSD study. <p> File Cache Measurements One of the most important features of the Sprite system is its mechanism for caching file data in main memory <ref> [9] </ref>.
Reference: 10. <author> Nelson, M. N., </author> <title> Physical Memory Management in a Network Operating System, </title> <type> PhD Thesis, </type> <institution> University of California, Berkeley, </institution> <month> November </month> <year> 1988. </year> <note> Also available as Technical Report UCB/CSD 88/471. </note>
Reference-contexts: As described in <ref> [10] </ref>, the virtual memory system receives preference: a physical page used for virtual memory cannot be converted to a file cache page unless it has been unreferenced for at least 20 minutes.
Reference: 11. <author> Ousterhout, J. K., Da Costa, H., Harrison, D., Kunze, J. A., Kupfer, M. and Thompson, J. G., </author> <title> ``A TraceDriven Analysis of the UNIX 4.2 BSD File System'', </title> <booktitle> Proceedings of the 10th Symposium on Operating System Principles, </booktitle> <address> Orcas Island, WA, </address> <month> December </month> <year> 1985, </year> <pages> 15-24. </pages> <month> July 25, </month> <year> 1991 </year> <month> - 14 </month> - 
Reference-contexts: 1. Introduction In 1985 a group of researchers at the University of California at Berkeley performed a trace-driven analysis of the UNIX 4.2 BSD file system <ref> [11] </ref>. That study, which we call ``the BSD study,'' showed that average file access rates were only a few hundred bytes per second per user for engineering and office applications, and that many files had lifetimes of only a few seconds. <p> Ousterhout et al. have a more complete discussion of the tracing approach <ref> [11] </ref>. One of the most difficult tasks in tracing a network of workstations is coordinating the traces from many machines. Our task was greatly simplified because most of the information we wished to trace was available on the Sprite file servers. <p> The All Users column contains values for all active users; the Users with Migrated Processes column considers only users with active migrated processes during the interval. The BSD Study column reports the average numbers from <ref> [11] </ref> for comparison. Measurements that weren't available are labeled NA. The numbers in parentheses are standard deviations. For the average number of active users they are the standard deviations of each interval from the long-term average across all intervals.
Reference: 12. <author> Ousterhout, J., Cherenson, A., Douglis, F., Nelson, M. and Welch, B., </author> <title> ``The Sprite Network Operating System'', </title> <booktitle> IEEE Computer 21, </booktitle> <month> 2 (February </month> <year> 1988), </year> <pages> 23-36. </pages>
Reference-contexts: We made our measurements on a collection of about 40 10-MIPS workstations all running the Sprite operating system <ref> [9, 12] </ref>. Four of the workstations served as file servers, and the rest were diskless clients. Our results are presented in two groups. The first group of results parallels the analysis of the BSD study.
Reference: 13. <author> Ousterhout, J., </author> <title> ``Why Aren't Operating Systems Getting Faster As Fast As Hardware?'', </title> <booktitle> Proceedings of the Summer 1990 USENIX Conference, </booktitle> <address> Anaheim, CA, </address> <month> June 11-15 </month> <year> 1990, </year> <pages> 247-256. </pages>
Reference-contexts: Previous studies have shown that open/close times on a client using a network file system are a factor of four or five slower than those on a machine with a local file system <ref> [13] </ref>. This difference in open/close times could account for the relatively small change in file open times despite the large improvement in processor speed. 4.3.
Reference: 14. <author> G. J. Popek and B. J. Walker, eds., </author> <title> The LOCUS Distributed System Architecture, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: Second, several network-oriented operating systems and file systems have been developed during the last decade, e.g. AFS [4], Amoeba [7], Echo [3], Locus <ref> [14] </ref>, NFS [16], Sprite [9], and V [1]; they provide transparent network file systems and, in some cases, the ability for a single user to harness many workstations to work on a single task. <p> The modified scheme makes a file cacheable again as soon as it has been closed by enough clients to eliminate the concurrent write-sharing. The second alternative is a token-based scheme similar to that implemented in the Locus <ref> [14] </ref>, Echo [6], and DEcorum [5] file systems. In this approach a file is always cacheable on at least one client.
Reference: 15. <author> Rosenblum, M. and Ousterhout, J. K., </author> <title> ``The Design and Implementation of a Log-Structured File System'', </title> <booktitle> Proceedings of the 13th Symposium on Operating System Principles, Asilomar, </booktitle> <address> CA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: If read hit ratios continue to improve, then writes will eventually dominate file system performance and new approaches, such as longer writeback intervals, non-volatile cache memories, and log-structured file systems <ref> [15] </ref>, will become attractive. We found that many users access file data in a way that assumes cache consistency among workstations, and that they will be inconvenienced on a daily basis if full consistency is not provided.
Reference: 16. <author> Sandberg, R., Goldberg, D., Kleiman, S., Walsh, D. and Lyon, B., </author> <title> ``Design and Implementation of the Sun Network Filesystem'', </title> <booktitle> Proceedings of the Summer 1985 USENIX Conference, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1985, </year> <pages> 119-130. </pages>
Reference-contexts: Second, several network-oriented operating systems and file systems have been developed during the last decade, e.g. AFS [4], Amoeba [7], Echo [3], Locus [14], NFS <ref> [16] </ref>, Sprite [9], and V [1]; they provide transparent network file systems and, in some cases, the ability for a single user to harness many workstations to work on a single task. <p> Most network file systems, such as AFS [4] and NFS <ref> [16] </ref>, don't provide such strong consistency guarantees. <p> To estimate the negative impact of a weaker cache consistency scheme, we used our trace data to simulate a cache consistency mechanism similar to that used in some NFS implementations <ref> [16] </ref>. In the simulated mechanism, a client considers data in its cache to be valid for a fixed interval of time; on the next access to the file after the expiration of the interval, the client checks with the file's server and updates its cache if necessary.
Reference: 17. <author> Welch, B. B., </author> <title> Naming, State Management, and User-Level Extensions in the Sprite Distributed File System, </title> <type> PhD Thesis, </type> <institution> University of California, Berkeley, </institution> <month> February </month> <year> 1990. </year> <note> Also available as Technical Report UCB/CSD 90/567. July 25, 1991 - 15 </note> - 
Reference-contexts: The Sprite kernel's facilities are almost identical to those of UNIX, and most of the applications running on the cluster are standard UNIX applications. Sprite has two features that made it a particularly interesting candidate for measurement: its network file system <ref> [17] </ref> and process migration [2]. Sprite's network file system provides a single-system image: there is a single shared file hierarchy with no local disks.
References-found: 17

