URL: ftp://cl-ftp.dfki.uni-sb.de/pub/papers/local/coling96.ps.gz
Refering-URL: http://cl-www.dfki.uni-sb.de/cl/papers/cl-abstracts.html
Root-URL: 
Email: fkasper,kriegerg@dfki.uni-sb.de  
Title: Modularizing Codescriptive Grammars for Efficient Parsing  
Author: Walter Kasper and Hans-Ulrich Krieger 
Address: Stuhlsatzenhausweg 3, D-66123 Saarbrucken, Germany  
Affiliation: German Research Center for Artificial Intelligence (DFKI)  
Abstract: Unification-based theories of grammar allow to integrate different levels of linguistic descriptions in the common framework of typed feature structures. Dependencies among the levels are expressed by corefer-ences. Though highly attractive theoretically, using such codescriptions for analysis creates problems of efficiency. We present an approach to a modular use of code-scriptions on the syntactic and semantic level. Grammatical analysis is performed by tightly coupled parsers running in tandem, each using only designated parts of the grammatical description. In the paper we describe the partitioning of grammatical information for the parsers and present results about the performance.
Abstract-found: 1
Intro-found: 1
Reference: <author> Halvorsen, Per-Kristian and Ronald M. Kaplan. </author> <year> 1988. </year> <title> Projections and Semantic Description in Lexical-Functional Grammar. </title> <booktitle> In Proceedings of 5th Generation Computer Systems, </booktitle> <pages> pages 1116-1122. </pages>
Reference-contexts: Similar approaches, especially for the syntax-semantics interface, have been suggested for all major kinds of unification-based theories, such as LFG or CUG. <ref> (Halvorsen and Kaplan, 1988) </ref> call such approaches codescriptive in contrast to the approach of description by analysis which is closely related to sequential architectures where linguistic levels correspond to components, operating on the basis of the (complete) analysis results of lower levels.
Reference: <author> Jones, Neil D., Carsten K. Gomard, and Peter Stestoft 1993. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <address> New York: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: specific than the corresponding input values: s^v s and s^v v. 4.4.3 Partial Evaluation Partial evaluation, as known from func-tional/logic programming, is a method of carrying out parts of computation at compile time that would otherwise be done at run time, hence improving run time performance of programs; see, e.g., <ref> (Jones, Gomard, and Stestoft, 1993) </ref>. Analogous to partial evaluation of definite clauses, we can partially evaluate annotated grammar rules, since they drive the derivation. Partial evaluation means here to substitute type symbols by their expanded definitions.
Reference: <author> Kasper, Walter and Hans-Ulrich Krieger. </author> <year> 1996. </year> <title> Inte gration of Prosodic and Grammatical Information in the Analysis of Dialogs. </title> <type> Verbmobil Report. </type>
Reference-contexts: To deal with this, prosodic information is taken into account; see <ref> (Kasper and Krieger, 1996) </ref> for more details. of distributed processing. <p> For speech parsing, the nodes represent points of times and edges represent word hypotheses/paths in the word lattice. The parsers communicate by exchanging hypotheses, bottom-up hypotheses from syntax to semantics and top-down hypotheses from semantics to syntax; see <ref> (Kasper, Krieger, Spilker, and Weber, 1996) </ref> for an in-depth description of the current setup. * Bottom-up hypotheses are emitted by the syn-parser and sent to the sem-parser. They undergo verification at the semantic level. <p> We have used this scheme in that the sem-parser operates on the full-size grammar, whereas the speech parser directly communicates with the word recognizer. This makes sense since the word lattice parser processes an order of magnitude more hypotheses than the sem-parser; see <ref> (Kasper, Krieger, Spilker, and Weber, 1996) </ref> for more details.
Reference: <author> Kasper, Walter, Hans-Ulrich Krieger, Jorg Spilker, and Hans Weber. </author> <year> 1996. </year> <title> From Word Hypotheses to Logical Form: An Efficient Interleaved Approach. </title> <type> Verbmobil Report. </type>
Reference-contexts: To deal with this, prosodic information is taken into account; see <ref> (Kasper and Krieger, 1996) </ref> for more details. of distributed processing. <p> For speech parsing, the nodes represent points of times and edges represent word hypotheses/paths in the word lattice. The parsers communicate by exchanging hypotheses, bottom-up hypotheses from syntax to semantics and top-down hypotheses from semantics to syntax; see <ref> (Kasper, Krieger, Spilker, and Weber, 1996) </ref> for an in-depth description of the current setup. * Bottom-up hypotheses are emitted by the syn-parser and sent to the sem-parser. They undergo verification at the semantic level. <p> We have used this scheme in that the sem-parser operates on the full-size grammar, whereas the speech parser directly communicates with the word recognizer. This makes sense since the word lattice parser processes an order of magnitude more hypotheses than the sem-parser; see <ref> (Kasper, Krieger, Spilker, and Weber, 1996) </ref> for more details.
Reference: <author> Kay, Martin, Jean Mark Gawron, and Peter Norvig. </author> <year> 1994. </year> <title> Verbmobil. A Translation System for Face-to-Face Dialog. </title> <booktitle> CSLI Lecture Notes, </booktitle> <volume> volume 33. </volume> <publisher> Chicago University Press. </publisher> <address> number of sentences: </address> <note> 56 average length: 7.6 SynSem Syn SemNA SemQA % % % run time: 30.6 15.2 50 15.4 50 45.8 150 #readings: 1.7 2.1 123 1.7 100 1.8 105 #hypotheses: 53.0 58.1 110 53.9 102 81.3 153 #chart edges: 192.0 215.0 112 58.1 30 301.1 156 in non-autonomous mode, SemQA the results for sem-parser as quasi-autonomous semantic parser. The percentage values are relative to SynSem. </note>
Reference: <author> Krieger, Hans-Ulrich and Ulrich Schafer. </author> <year> 1994. </year> <month> TDL| </month>
Reference-contexts: Important considerations in the design of the system were 1. increasing the performance, 2. achieving incremental and interactive be haviour, 3. minimizing the overhead in communication between the processors. We used a mid-size HPSG-kind German grammar written in the TDL formalism <ref> (Krieger and Schafer, 1994) </ref>. The grammar cospecifies syntax and semantics in the attributes syn and sem. A simplified example is shown in the lexical entry for the verb come in Fig. 1. In the following section, we start with a top-down view of the architecture.
References-found: 6

