URL: http://www.cs.cmu.edu/~stage3/publications/95/conferences/chi/paper.ps
Refering-URL: http://alice.cs.cmu.edu/stage3/Publications.html
Root-URL: 
Email: pausch-@uvacs.cs.virginia.edu  
Title: Virtual Reality on a WIM: Interactive Worlds in Miniature user observation indicates that users adapt
Author: Richard Stoakley, Matthew J. Conway, Randy Pausch 
Keyword: virtual reality, three-dimensional interaction, two-handed interaction, information visualization  
Note: (804) 982-2200  Informal  
Address: Charlottesville, VA 22903 -stoakley conway  
Affiliation: The University of Virginia Department of Computer Science  
Abstract: This paper explores a user interface technique which augments an immersive head tracked display with a handheld miniature copy of the virtual environment. We call this interface technique the Worlds in Miniature (WIM) metaphor. In addition to the first-person perspective offered by a virtual reality system, a World in Miniature offers a second dynamic viewport onto the virtual environment. Objects may be directly manipulated either through the immersive viewport or through the three-dimensional viewport offered by the WIM. In addition to describing object manipulation, this paper explores ways in which Worlds in Miniature can act as a single unifying metaphor for such application independent interaction techniques as object selection, navigation, path planning, and visualization. The WIM metaphor offers multiple points of view and multiple scales at which the user can operate, without requiring explicit modes or commands. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Apple Computer, Inc., </author> <title> Hyperscript Language Guide: The Hypertalk Language. </title> <publisher> Addison-Wesley 1988. </publisher>
Reference-contexts: A logical extension of this notion is that these snapshots can act as jump points to different spaces or times, much the same way hypertext systems sometimes have thumbnail pictures of previously visited documents <ref> [1] </ref>. Selecting a WIM would cause the immersive environment to change to that particular world [9] (video figure 2 Multiple WIMs). Multiple WIMs enable users to multiplex their attention much the same way Window Managers allow this in 2D.
Reference: [2] <author> Eric A. Bier, Maureen C. Stone, Ken Pier , William Buxton, Tony D. DeRose, Toolglass and Magic Lenses: </author> <title> The See-Through Interface. </title> <booktitle> SIGGRAPH '93, </booktitle> <pages> pp. 73-80. </pages>
Reference-contexts: He found this surface invaluable in constraining the user s input to a plane. The system was not immersive and presented a single scale at any given time. Aspects of Bier s Toolglass and Magic Lenses <ref> [2] </ref> work, closely resemble a two-dimensional analog to the WIM. For example, when using a magnification lens, objects can easily be manipulated at a convenient scale, while maintaining much of the surrounding context. <p> Here, the WIM might act as a filter; similar to a three-dimensional version of Biers magic lenses <ref> [2] </ref> or one of Fitzmaurice s active maps [10]. Three-Dimensional Design: the WIM serves many of the same functions that architectural models have traditionally served (e.g. massing model, parti diagram). <p> Two-Handed Interaction Our implementation of the WIM metaphor takes advantage of several previously published results in the field of motor behavior that have not been fully exploited in a head tracked virtual environment <ref> [2] </ref> [12]. The most important of these results state that a humans dominant (preferred) hand makes its motions relative to the coordinate system specified by the nondominant hand, and the preferred hand s motion is generally at a f iner grain [12].
Reference: [3] <author> Jeff Butterworth, Andrew Davidson, Stephen Hench, Marc Olano, 3DM: </author> <title> A Three Dimensional Modeler Using a Head-Mounted Display. </title> <booktitle> Proceedings 1992 Symposium on Interactive 3D Graphics, </booktitle> <pages> pp. 135-138. </pages>
Reference-contexts: This work is also three-dimensional but non-immersive and directly manipulates an object at one-to-one scale in a fishtank VR paradigm. 3DM <ref> [3] </ref> was an immersive three-dimensional drawing package, but provided only one point of view at a time and required the user to change scale or y explicitly to manip ulate objects which were currently out of arm s reach. But-terworth states that users sometimes found the scaling disorienting.
Reference: [4] <author> Richard A. </author> <title> Bolt. </title> <journal> PutThat-There. </journal> <volume> SIGGRAPH '80, </volume> <pages> pp. 262-270. </pages>
Reference-contexts: Common approaches include raycasting [10] [22] and selection cones [14]. Both of these techniques suffer from object occlusion and therefore need to be tied closely with some mechanism that can quickly establish different points of view. PutThat-There <ref> [4] </ref> used selection via a combination of pointing and naming (or description). Pointing in this two-dimensional application is analogous to raycasting in virtual environments.
Reference: [5] <author> Frederick P. Brooks, </author> <title> Grasping Reality Through Illusion: Interactive Graphics Serving Science. </title> <booktitle> SIGCHI '88, </booktitle> <pages> pp. 1-11. </pages>
Reference-contexts: User Reactions We observed users in order to see how viable a solution the WIM interface was to several types of tasks. While it was not our intention for the study to produce concrete numbers, we were after what Brooks refers to as interesting Observations <ref> [5] </ref>.
Reference: [6] <author> Robert DeLine, </author> <type> Masters Thesis. </type> <month> Alice: </month> <title> A Rapid Pro-totyping System for Three-Dimensional Interactive Graphical Environments. </title> <institution> University of Virginia, </institution> <month> May, </month> <year> 1993. </year>
Reference-contexts: The environment itself (in miniature) becomes its own widget for manipulating objects in the environment [26]. clipboard and buttonball props. Software and Equipment The Kit of Parts modeler was implemented using the Alice Rapid Prototyping System <ref> [6] </ref> running the simulation on a Sun Microsystems Sparc 10 and rendering on a Silicon Graphics Onyx Reality Engine 2 . Typical rendering rates were about 25 frames per second ( FPS), while simulation rates were typically 6 FPS.
Reference: [7] <author> Rudy Darken, John Sibert, </author> <title> A Toolset for Navigation in Virtual Environments. </title> <booktitle> UIST '93, </booktitle> <pages> pp. 157-165. </pages>
Reference-contexts: For example, when using a magnification lens, objects can easily be manipulated at a convenient scale, while maintaining much of the surrounding context. Previous Work in Navigation We define navigation to cover two related tasks: movement through a 3D space and determining orientation relative to the surrounding environment. Darkens <ref> [7] </ref> discussion of navigating virtual environments enumerates many important techniques and compares their relative strengths and weaknesses. Several of the navigation techniques presented were WIM-like maps, but were primarily two-dimensional in nature. Through the WIM interface, some of these techniques have been extended into the third dimension. <p> Dropping a trail of crumbs is not as useful if you cannot see the trail in context <ref> [7] </ref>. Measuring distances: the WIM can be configured to display distances between distant (or very closely spaced) points that are difficult to reach at the immersive one-to-one scale. The WIM also provides a convenient tool for measuring areas and volumes.
Reference: [8] <author> Steven Feiner, Clifford Beshers, </author> <title> Visualizing n-Dimensional Virtual Worlds with n-vision. </title> <booktitle> Proceedings 1990 Symposium on Interactive 3D Graphics, </booktitle> <pages> pp. 37-38. </pages>
Reference-contexts: Multiple WIMs enable users to multiplex their attention much the same way Window Managers allow this in 2D. These multiple views into the virtual world, allow the user to visually compare different scales and/or different locations <ref> [8] </ref>. MANIPULATING THE WIM Through the exploration of the previous interfaces, several issues arose concerning the interface between the human and the WIM tool.
Reference: [9] <author> Scott Fisher, </author> <title> The AMES Virtual Environment Workstation (VIEW). </title> <note> SIGGRAPH '89 Course #29 Notes. </note>
Reference-contexts: He found this scene in hand metaphor particularly good for quickly viewing the bounding-cube edges of a scene. The scene in hand task was a unimanual operation which employed ratcheting to perform large rotations. The work most closely resembling the WIM interface was Fishers map cube in virtual reality <ref> [9] </ref>. The NASA VIEW system used a three-dimensional miniature map of the immersive world to help navigate. In addition, the VIEW system used multiple two-dimensional viewports to jump from one place in the virtual environment to another . A users manipulation of the map cube was unimanual. <p> A logical extension of this notion is that these snapshots can act as jump points to different spaces or times, much the same way hypertext systems sometimes have thumbnail pictures of previously visited documents [1]. Selecting a WIM would cause the immersive environment to change to that particular world <ref> [9] </ref> (video figure 2 Multiple WIMs). Multiple WIMs enable users to multiplex their attention much the same way Window Managers allow this in 2D. These multiple views into the virtual world, allow the user to visually compare different scales and/or different locations [8].
Reference: [10] <author> George Fitzmaurice, </author> <title> Situated Information Spaces and Spatially Aware. </title> <journal> Communications of the ACM, </journal> <volume> 36 (7), </volume> <year> 1993, </year> <pages> pp. 39-49. </pages>
Reference-contexts: A users manipulation of the map cube was unimanual. A similar map-cube concept was referred to as the Gods-eye-view in the Super Cockpit project [11]. Previous Work in Object Selection Many researchers have explored methods for selecting objects in a virtual world. Common approaches include raycasting <ref> [10] </ref> [22] and selection cones [14]. Both of these techniques suffer from object occlusion and therefore need to be tied closely with some mechanism that can quickly establish different points of view. PutThat-There [4] used selection via a combination of pointing and naming (or description). <p> Here, the WIM might act as a filter; similar to a three-dimensional version of Biers magic lenses [2] or one of Fitzmaurice s active maps <ref> [10] </ref>. Three-Dimensional Design: the WIM serves many of the same functions that architectural models have traditionally served (e.g. massing model, parti diagram).
Reference: [11] <author> Dr. Thomas A. Furness, III, </author> <title> The Super Cockpit and Human Factors Challenges. </title> <institution> Human Interface Technology (HIT) Laboratory of the Washington Technology Center, </institution> <month> September </month> <year> 1986 </year>
Reference-contexts: In addition, the VIEW system used multiple two-dimensional viewports to jump from one place in the virtual environment to another . A users manipulation of the map cube was unimanual. A similar map-cube concept was referred to as the Gods-eye-view in the Super Cockpit project <ref> [11] </ref>. Previous Work in Object Selection Many researchers have explored methods for selecting objects in a virtual world. Common approaches include raycasting [10] [22] and selection cones [14].
Reference: [12] <author> Yves Guiard, </author> <title> Asymmetric Division of Labor in Human Skilled Bimanual Action: The Kinematic Chain as a Model. </title> <journal> The Journal of Motor Behavior , pp. </journal> <pages> 486-517, </pages> <year> 1987. </year>
Reference-contexts: The input props controlled the point of view by rotating the objects base plane. Hinckleys [13] work with props exploited the asymmetric use of hands, which follows from work by Guiard <ref> [12] </ref>. This work showed how a prop in the nondominant hand can be used to specify a coordinate system with gross orientation, while the user s preferred hand can be used for fine grain positioning relative to that coordinate system. <p> Two-Handed Interaction Our implementation of the WIM metaphor takes advantage of several previously published results in the field of motor behavior that have not been fully exploited in a head tracked virtual environment [2] <ref> [12] </ref>. The most important of these results state that a humans dominant (preferred) hand makes its motions relative to the coordinate system specified by the nondominant hand, and the preferred hand s motion is generally at a f iner grain [12]. <p> been fully exploited in a head tracked virtual environment [2] <ref> [12] </ref>. The most important of these results state that a humans dominant (preferred) hand makes its motions relative to the coordinate system specified by the nondominant hand, and the preferred hand s motion is generally at a f iner grain [12]. In our case, the nondominant hand establishes a coordinate system with the clipboard and the dominant hand performs f ine grained picking and manipulation operations.
Reference: [13] <author> Ken Hinckley, Randy Pausch, John C. Goble, Neal F. Kassell, </author> <title> Passive Real-World Interface Props for Neu-rosurgical Visualization. </title> <booktitle> SIGCHI '94, </booktitle> <pages> pp. 452-458. </pages>
Reference-contexts: The input props controlled the point of view by rotating the objects base plane. Hinckleys <ref> [13] </ref> work with props exploited the asymmetric use of hands, which follows from work by Guiard [12].
Reference: [14] <author> Jiandong Liang, Mark Green, JDCAD: </author> <booktitle> A Highly Interactive 3D Modeling System . 3rd International Conference on CAD, </booktitle> <pages> pp. 217-222, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: A similar map-cube concept was referred to as the Gods-eye-view in the Super Cockpit project [11]. Previous Work in Object Selection Many researchers have explored methods for selecting objects in a virtual world. Common approaches include raycasting [10] [22] and selection cones <ref> [14] </ref>. Both of these techniques suffer from object occlusion and therefore need to be tied closely with some mechanism that can quickly establish different points of view. PutThat-There [4] used selection via a combination of pointing and naming (or description). <p> For example: the user can reach into the WIM to select a distant object (taking advantage of the greater than 1:1 scale of the WIM), and then reach out to the immersive world to move the WIM-selected object at a distance in 1:1 scale [22] <ref> [14] </ref> all the while viewing the scene in the WIM. Rotation Our current implementation allows users to rotate objects, through ratcheting (repeated grabbing, rotating and releasing) [24] and is therefore more awkward than a rotation done with just the fingers [14]. <p> the WIM-selected object at a distance in 1:1 scale [22] <ref> [14] </ref> all the while viewing the scene in the WIM. Rotation Our current implementation allows users to rotate objects, through ratcheting (repeated grabbing, rotating and releasing) [24] and is therefore more awkward than a rotation done with just the fingers [14]. Interestingly, some users found it just as ef fective to grab the object and to counter - rotate the entire WIM. In our current implementation, rotation is gridded to 30 degree increments, primarily to assist in aligning rectilinear objects [14]. <p> more awkward than a rotation done with just the fingers <ref> [14] </ref>. Interestingly, some users found it just as ef fective to grab the object and to counter - rotate the entire WIM. In our current implementation, rotation is gridded to 30 degree increments, primarily to assist in aligning rectilinear objects [14]. We found that if the rotation grid is too course (greater than about 45 degrees), some people assume that they cannot rotate at all and if set to 15 degrees or less, users report that aligning rectilinear objects is very difficult. <p> This animated movement helps maintain visual continuity <ref> [14] </ref>. Another useful form of update delay is batch update. Here, the user makes several changes to the WIM and then issues an explicit command (e.g. pressing the second button on the buttonball) to cause the immersive environment to commit to the current layout of the WIM.
Reference: [15] <author> John Lassiter, </author> <title> Principles of Traditional Animation Applied to 3D Computer Animation. </title> <booktitle> SIGGRAPH '87, </booktitle> <pages> pp. 35-44. </pages>
Reference-contexts: We find that immediate update of the camera while the user is manipulating the camera proxy is highly disorienting, instead we wait until the user has stopped moving the camera, and then use a smooth slow-in/ slow-out animation <ref> [15] </ref> to move the camera to its new position. This animated movement helps maintain visual continuity [14]. Another useful form of update delay is batch update.
Reference: [16] <author> Donald Norman, </author> <title> The Design of Everyday Things . Doubleday. </title> <year> 1988. </year>
Reference-contexts: Shape of Props Like all real world artifacts, the shape of the props and the users experience suggest things about the usage of the props <ref> [16] </ref>. For example, the shape of the clipboard says something to users about its preferred orientation.
Reference: [17] <author> Randy Pausch, M. Anne Shackelford, </author> <note> Dennis Proffitt, </note>
Reference-contexts: INTRODUCTION Many benefits have been claimed formally and informally for using immersive three-dimensional displays. While virtual reality technology has the potential to give the user a better understanding of the space he or she inhabits, and can improve performance in some tasks <ref> [17] </ref>, it can easily present a virtual world to the user that is just as confusing, limiting and ambiguous as the real world.
References-found: 17

