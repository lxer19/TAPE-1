URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-401.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Parametrized Structure from Motion for 3D Adaptive Feedback Tracking of Faces  
Author: Tony S. Jebara and Alex Pentland 
Date: November 28th, 1996  
Address: Cambridge, MA 02139  
Affiliation: Media Laboratory, Massachusetts Institute of Technology  
Abstract: MIT Media Laboratory, Perceptual Computing Technical Report #401 Submitted to CVPR November 1996 Abstract A real-time system is described for automatically detecting, modeling and tracking faces in 3D. A closed loop approach is proposed which utilizes structure from motion to generate a 3D model of a face and then feed back the estimated structure to constrain feature tracking in the next frame. The system initializes by using skin classification, symmetry operations, 3D warping and eigenfaces to find a face. Feature trajectories are then computed by SSD or correlation-based tracking. The trajectories are simultaneously processed by an extended Kalman filter to stably recover 3D structure, camera geometry and facial pose. Adaptively weighted estimation is used in this filter by modeling the noise characteristics of the 2D image patch tracking technique. In addition, the structural estimate is constrained by using parametrized models of facial structure (eigen-heads). The Kalman filter's estimate of the 3D state and motion of the face predicts the trajectory of the features which constrains the search space for the next frame in the video sequence. The feature tracking and Kalman filtering closed loop system operates at 30Hz. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.D. </author> <title> Alter, "3D Pose from 3 Corresponding Points under Weak-Perspective Projection", </title> <journal> A.I. </journal> <volume> Memo No. 1378, </volume> <year> 1992. </year>
Reference-contexts: This alignment was done by manually selecting the 4 points and then using a least-squares iterative fit of the 3D anchor points. Using the computed average 3D model, a Weak-Perspective-3-Points <ref> [1] </ref> computation can then be used to align its eyes and nose to the ones found in a 2D image.
Reference: [2] <author> A. Azarbayejani and A. Pentland, </author> <title> "Recursive Estimation of Motion, Structure and Focal Length", </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <month> June </month> <year> 1995. </year>
Reference-contexts: the trackers are integrated appropriately to achieve a global explanation of the scene which can be fed back to constrain their individual behaviour and avoid feature loss. 4 Structure from Motion Recently, structure from motion has been reformulated into a stable recursive estimation problem and been shown to converge reliably <ref> [2] </ref>. By remapping the data into a new parametrized representation, what was essentially an under-constrained problem becomes uniquely solvable with no numerical "ill-conditioning". 4.1 Stable Representation for Recursive Estimation The objective of SfM is to recover 3D structure, motion and camera geometry. <p> These form the "internal state vector", x of the system under observation. These internal states are to be recovered by observation measurements of the system. For a thorough justification of the internal state vector representation, consult Azarbayejani and Pentland <ref> [2] </ref>. One internal state parameter is the camera geometry. Instead of trying to estimate focal length to describe the camera, we esti mate fi = 1 f . The structure of points on the 3D object is represented with one parameter per point instead of an XYZ spatial location.
Reference: [3] <author> M. Bolduc, G. Sela and M.D. Levine, </author> <title> "Fast computation of multiscalar symmetry in foveated images", </title> <booktitle> Proceedings of the Conference on Computer Architectures for Machine Perception, </booktitle> <pages> pp. 2-11, </pages> <year> 1995. </year>
Reference-contexts: We then propose the use of the dark symmetry transform <ref> [3] </ref> [7] [9] [6]. This is an annular sampling region which detects edge configurations that enclose an object. However, unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected.
Reference: [4] <author> A. Gelb, </author> <title> "Applied Optimal Estimation", </title> <publisher> M.I.T. Press, </publisher> <year> 1996. </year>
Reference-contexts: Traditionally, the noise covariance matrix is denoted R and is n fi n where n is the number of measurements in the observation vector y. The role of R in the computation of the Kalman gain matrix described by Equation 9. Adaptive Kalman filtering <ref> [4] </ref> proposes the use of a dynamically varying R matrix that changes with the arrival of new observation vectors to model the confidence of the new data.
Reference: [5] <author> G.D. Hager and P.N. Buelhumeur, </author> <title> "Real-Time Tracking of Image Regions with Changes in Geometry and Illumination", </title> <booktitle> IEEE Conference on Comnputer Vision and Pattern Recognition, </booktitle> <pages> pp. 403-410, </pages> <year> 1996. </year>
Reference-contexts: move away from the localization during the time the detection was being computed. 3 2D Feature Tracking Having determined the locations of facial features in the image, it is now possible to define a number of windows on the face which will be used for template matching via SSD correlation <ref> [5] </ref>. Using a simple mapping, a set of windows are overlayed upon the face automatically from the data gathered in the face detection stage. A typical initialization result is shown in Figure 9. Eight tracking windows are initialized on the nose, the mouth tips and the eyes automatically as shown.
Reference: [6] <author> T. S. Jebara, </author> <title> "3D Pose Estimation and Normalization for Face Recognition", </title> <institution> Bachelor's ThesisMcGill Centre for Intelligent Machines, </institution> <year> 1996. </year>
Reference-contexts: By warping the image at various anchor points and minimizing "Distance From Face Space", the system finds the most likely locations of eyes, nose and mouth from all possible candidates. The algorithm <ref> [6] </ref> is explained in further detail below. 2.1 Skin Classification using EM Human skin forms a dense manifold in color space which makes it an easy feature to detect in images [10]. <p> We then propose the use of the dark symmetry transform [3] [7] [9] <ref> [6] </ref>. This is an annular sampling region which detects edge configurations that enclose an object. However, unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected.
Reference: [7] <author> M.F. Kelly and M.D. Levine, </author> <title> "Annular Symmetry Operators: A Method for Locating and Describing Objects", </title> <booktitle> Fifth International Conference on Computer Vision, </booktitle> <pages> pp. 1016-1021, </pages> <year> 1995. </year>
Reference-contexts: We then propose the use of the dark symmetry transform [3] <ref> [7] </ref> [9] [6]. This is an annular sampling region which detects edge configurations that enclose an object. However, unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected.
Reference: [8] <author> B. Moghaddam and A. Pentland, </author> <title> "Probabilistic Visual Learning for Object Detection", </title> <booktitle> Fifth International Conference on Computer Vision, </booktitle> <pages> pp. 786-793, </pages> <year> 1995. </year>
Reference-contexts: We also approximate its distance to the training set of faces (distance to face-space) or how 'face-like' it is using this represen (a) Initial Localization (b) Final Localization 1 2 3 4 5 6 7 8 9 10 11 12 Nose Positions and their Corresponding DFFS tation <ref> [8] </ref>. The training set of faces is mapped into this eigenspace and the distribution of the coefficients and residuals is modeled as a Gaussian density. The maximum likelihood estimate for the probability of a data point fitting this model is computed using this Gaussian.
Reference: [9] <author> D. Reisfeld and Y. Yeshurun, </author> <title> "Robust detection of facial features by generalized symmetry", </title> <booktitle> 11th IAPR International Conference on Pattern Recognition, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 117-120, </pages> <year> 1992. </year>
Reference-contexts: We then propose the use of the dark symmetry transform [3] [7] <ref> [9] </ref> [6]. This is an annular sampling region which detects edge configurations that enclose an object. However, unlike template matching, a perceptual measure of symmetric enclosure is computed and blob centers are detected.
Reference: [10] <author> B. Sheile and A. Weibel, </author> <title> "Gaze Tracking Based on Face Color", </title> <booktitle> International Workshop on Face and Gesture Recognition, </booktitle> <address> Zurich, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: The algorithm [6] is explained in further detail below. 2.1 Skin Classification using EM Human skin forms a dense manifold in color space which makes it an easy feature to detect in images <ref> [10] </ref>. We obtain multiple training samples of skin from images of several individuals of varying skin tone and under varying illumination conditions. Each pixel in this distribution forms a 3 element vector, [R G B].
Reference: [11] <author> P.J. Phillips and Y. Vardi, </author> <title> "Data-driven Methods in Face Recognition", </title> <booktitle> International Workshop on Face and Gesture Recogntion, </booktitle> <pages> pp. 65-70, </pages> <year> 1995. </year>
Reference-contexts: Each side of this new 2D face undergoes histogram fitting to normalize its illumination <ref> [11] </ref>. Two transfer functions are computed: one for mapping the left half of the face to a desired histogram (i.e. a histogram of a well-illuminated face) and the other for mapping the right half of the face.
References-found: 11

