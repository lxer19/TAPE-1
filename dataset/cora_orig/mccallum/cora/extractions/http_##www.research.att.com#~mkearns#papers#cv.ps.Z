URL: http://www.research.att.com/~mkearns/papers/cv.ps.Z
Refering-URL: http://www.research.att.com/~mkearns/
Root-URL: 
Email: mkearns@research.att.com  
Title: A Bound on the Error of Cross Validation Using the Approximation and Estimation Rates, with
Author: Michael Kearns 
Note: When the  
Address: Murray Hill, NJ 07974  
Affiliation: AT&T Bell Laboratories  
Abstract: We give an analysis of the generalization error of cross validation in terms of two natural measures of the difficulty of the problem under consideration: the approximation rate (the accuracy to which the target function can be ideally approximated as a function of the number of hypothesis parameters), and the estimation rate (the deviation between the training and generalization errors as a function of the number of hypothesis parameters). The approximation rate captures the complexity of the target function with respect to the hypothesis model, and the estimation rate captures the extent to which the hypothesis model suffers from overfitting. Using these two measures, we give a rigorous and general bound on the error of cross validation. The bound clearly shows the tradeoffs involved with making fl the fraction of data saved for testing too large or too small. By optimizing the bound with respect to fl, we then argue (through a combination of formal analysis, plotting, and controlled experimentation) that the following qualitative properties of cross validation behavior should be quite robust to significant changes in the underlying model selection problem: 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barron. </author> <title> Universal approximation bounds for superpositions of a sigmoidal function. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 19 </volume> <pages> 930-944, </pages> <year> 1991. </year>
Reference-contexts: In this paper we concentrate on the simplest version of cross validation. Unlike the methods mentioned above, which use the entire sample for training the h d , in cross validation we choose a parameter fl 2 <ref> [0; 1] </ref>, which determines the split between training and test data. Given the input sample S of m examples, let S 0 be the subsample consisting of the first (1 fl)m examples in S, and S 00 the subsample consisting of the last flm examples. <p> First we give examples of the approximation rate that we will examine in some detail following the general bound on * cv (m). The Intervals Problem. In this problem, the input space X is the real interval <ref> [0; 1] </ref>, and the class H d of the structure consists of all boolean step functions over [0; 1] of at most d steps; thus, each function partitions the interval [0; 1] into at most d disjoint segments (not necessarily of equal width), and assigns alternating positive and negative labels to <p> The Intervals Problem. In this problem, the input space X is the real interval <ref> [0; 1] </ref>, and the class H d of the structure consists of all boolean step functions over [0; 1] of at most d steps; thus, each function partitions the interval [0; 1] into at most d disjoint segments (not necessarily of equal width), and assigns alternating positive and negative labels to these segments. <p> The Intervals Problem. In this problem, the input space X is the real interval <ref> [0; 1] </ref>, and the class H d of the structure consists of all boolean step functions over [0; 1] of at most d steps; thus, each function partitions the interval [0; 1] into at most d disjoint segments (not necessarily of equal width), and assigns alternating positive and negative labels to these segments. Thus, the input space is one-dimensional, but the structure contains arbitrarily complex functions over [0; 1]. <p> <ref> [0; 1] </ref> of at most d steps; thus, each function partitions the interval [0; 1] into at most d disjoint segments (not necessarily of equal width), and assigns alternating positive and negative labels to these segments. Thus, the input space is one-dimensional, but the structure contains arbitrarily complex functions over [0; 1]. It is easily verified that our assumption that the VC dimension of H d is O (d) holds here, and that the fitting number obeys d max (m) m. <p> This is important, since in practice we do not expect to have precise knowledge of * g (d), since it depends on the target function and input distribution. Following the work of Barron <ref> [1] </ref>, who shows a c=d bound on * g (d) for the case of neural networks with one hidden layer under a squared error generalization measure (where c is a measure of target function complexity in terms of a Fourier transform integrability condition) 2 , in the later part of the
Reference: [2] <author> A. R. Barron and T. M. </author> <title> Cover. Minimum complexity density estimation. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37 </volume> <pages> 1034-1054, </pages> <year> 1991. </year>
Reference-contexts: emphasizes asymptotic statistical properties, or the exact calculation of the generalization error for simple models. (The literature is too large to survey here; foundational papers include those of Stone [7, 8].) Our approach here is somewhat different, and is primarily inspired by two sources: the work of Barron and Cover <ref> [2] </ref>, who introduced the idea of bounding the error of a model selection method (MDL in their case) in terms of a quantity known as the index of resolvability; and the work of Vapnik [9], who provides extremely powerful and general tools for uniformly bounding the deviations between training and generalization <p> Following the example of Barron and Cover's analysis of MDL performance in the context of density estimation <ref> [2] </ref>, we propose the approximation rate as a natural measure of the complexity of f and D in relationship to the chosen structure H 1 H d . Thus we define the approximation rate function * g (d) to be * g (d) = min h2H d f* g (h)g. <p> Again by standard Chernoff bound arguments, this introduces an additional p fl error term, resulting in our final bound. This concludes the proof sketch. In the bounds given by (1) and (2), the minfg expression is analogous to Barron and Cover's index of resolvability <ref> [2] </ref>; the final term in the bounds represents the error introduced by the testing phase of cross validation.
Reference: [3] <author> D. Haussler, M. Kearns, H.S. Seung, and N. Tishby. </author> <title> Rigourous learning curve bounds from statistical mechanics. </title> <booktitle> In Proceedings of the Seventh Annual ACM Confernce on Computational Learning Theory, </booktitle> <pages> pages 76-87, </pages> <year> 1994. </year>
Reference-contexts: Indeed, much of the recent work on the statistical physics theory of learning curves has documented the wide variety of behaviors that such deviations may assume <ref> [6, 3] </ref>. <p> It would be interesting to try to identify natural problems for which one or more of these properties is strongly violated; a potential source for such problems may be those for which the underlying learning curve deviates from classical power law behavior <ref> [6, 3] </ref>. 8 ACKNOWLEDGEMENTS I give warm thanks to Yishay Mansour, Dana Ron and Yoav Freund for their contributions to this work and for many interesting discussions. The code used in the experiments was written by Andrew Ng.
Reference: [4] <author> M. Kearns, Y. Mansour, A. Ng, and D. Ron. </author> <title> An experimental and theoretical comparison of model selection methods. </title> <booktitle> In Proceedings of the Eigth Annual ACM Conference on Computational Learning Theory, </booktitle> <year> 1995. </year>
Reference-contexts: we now use the more accurate test penalty term p log ((1 fl)m)=(flm) since we are no longer concerned with simplifying the calculation. 8 A nice feature of the intervals problem is the fact that training error minimization can be performed in almost linear time using a dynamic programming approach <ref> [4] </ref>. would be interesting to verify this prediction experimentally, perhaps on a different problem where the predicted effect is more pronounced. 7 POWER LAW DECAY AND THE PERCEPTRON PROBLEM For the cases where the approximation rate * g (d) obeys either power law decay or is that derived for the perceptron
Reference: [5] <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry, </title> <booktitle> volume 15 of Series in Computer Science. World Scientific, </booktitle> <year> 1989. </year>
Reference-contexts: We are given a training sample S of f , consisting of m random examples drawn according to D and labeled by f (with the labels possibly corrupted by noise). In many model selection methods (such as Rissanen's Minimum Description Length Principle <ref> [5] </ref> and Vapnik's Guaranteed Risk Minimization [9]), for each value of d = 1; 2; 3; : : : we give the entire sample S and d to the learning algorithm L to obtain the function h d minimizing the training error in H d .
Reference: [6] <author> H. S. Seung, H. Sompolinsky, and N. Tishby. </author> <title> Statistical mechanics of learning from examples. </title> <journal> Physical Review, </journal> <volume> A45:6056-6091, </volume> <year> 1992. </year>
Reference-contexts: in &lt; N ), and the target function is a function in H s with all s nonzero weights equal to 1, then it can be shown that the approximation rate function * g (d) is * g (d) = (1=) cos 1 ( d=N ) for d &lt; s <ref> [6] </ref>, and of course * g (d) = 0 for d s. <p> Indeed, much of the recent work on the statistical physics theory of learning curves has documented the wide variety of behaviors that such deviations may assume <ref> [6, 3] </ref>. <p> It would be interesting to try to identify natural problems for which one or more of these properties is strongly violated; a potential source for such problems may be those for which the underlying learning curve deviates from classical power law behavior <ref> [6, 3] </ref>. 8 ACKNOWLEDGEMENTS I give warm thanks to Yishay Mansour, Dana Ron and Yoav Freund for their contributions to this work and for many interesting discussions. The code used in the experiments was written by Andrew Ng.
Reference: [7] <author> M. Stone. </author> <title> Cross-validatory choice and assessment of statistical predictions. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 36 </volume> <pages> 111-147, </pages> <year> 1974. </year>
Reference-contexts: There is a large and interesting literature on cross validation methods, which often emphasizes asymptotic statistical properties, or the exact calculation of the generalization error for simple models. (The literature is too large to survey here; foundational papers include those of Stone <ref> [7, 8] </ref>.) Our approach here is somewhat different, and is primarily inspired by two sources: the work of Barron and Cover [2], who introduced the idea of bounding the error of a model selection method (MDL in their case) in terms of a quantity known as the index of resolvability; and
Reference: [8] <author> M. Stone. </author> <title> Asymptotics for and against cross-validation. </title> <journal> Biometrika, </journal> <volume> 64(1) </volume> <pages> 29-35, </pages> <year> 1977. </year>
Reference-contexts: There is a large and interesting literature on cross validation methods, which often emphasizes asymptotic statistical properties, or the exact calculation of the generalization error for simple models. (The literature is too large to survey here; foundational papers include those of Stone <ref> [7, 8] </ref>.) Our approach here is somewhat different, and is primarily inspired by two sources: the work of Barron and Cover [2], who introduced the idea of bounding the error of a model selection method (MDL in their case) in terms of a quantity known as the index of resolvability; and
Reference: [9] <author> V. N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: is somewhat different, and is primarily inspired by two sources: the work of Barron and Cover [2], who introduced the idea of bounding the error of a model selection method (MDL in their case) in terms of a quantity known as the index of resolvability; and the work of Vapnik <ref> [9] </ref>, who provides extremely powerful and general tools for uniformly bounding the deviations between training and generalization errors. We combine these methods to give a new and general analysis of cross validation performance. <p> For concreteness, here we adopt an idealized version of this division of labor. We assume a nested sequence of function classes H 1 H d , called the structure <ref> [9] </ref>, where H d is a class of boolean functions of d parameters, each function being a mapping from some input space X into f0; 1g. For simplicity, in this paper we assume that the Vapnik-Chervonenkis (VC) dimension [10, 9] of the class H d is O (d). <p> For simplicity, in this paper we assume that the Vapnik-Chervonenkis (VC) dimension <ref> [10, 9] </ref> of the class H d is O (d). To remove this assumption, one simply replaces all occurrences of d in our bounds by the VC dimension of H d . <p> We are given a training sample S of f , consisting of m random examples drawn according to D and labeled by f (with the labels possibly corrupted by noise). In many model selection methods (such as Rissanen's Minimum Description Length Principle [5] and Vapnik's Guaranteed Risk Minimization <ref> [9] </ref>), for each value of d = 1; 2; 3; : : : we give the entire sample S and d to the learning algorithm L to obtain the function h d minimizing the training error in H d . <p> However, for many natural problems it is both convenient and accurate to rely on a universal estimation rate bound provided by the powerful theory of uniform convergence: Namely, for any f , D and any structure the function (d; m) = p is an estimation rate bound <ref> [9] </ref> 4 . Depending upon the details of the problem, it is sometimes appropriate to omit the log (m=d) factor, and often appropriate to refine the p d=m behavior to a function that interpolates smoothly between d=m behavior for small * t to p d=m for large * t .

References-found: 9

