URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/SRC-104.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/
Root-URL: http://www.cs.berkeley.edu
Title: 104 New-Value Logging in the Echo Replicated File System  
Author: Andy Hisgen, Andrew Birrell, Charles Jerian, Timothy Mann, Garret Swart 
Address: 130 Lytton Avenue Palo Alto, California 94301  
Affiliation: Systems Research Center  
Date: June 23, 1993  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Berkeley Unix 4.3 Reno release. </institution> <note> rename(2) system call manual page, </note> <year> 1990. </year>
Reference-contexts: We thought these strong semantics would be useful to clients, for instance in implementing logs. Second, EchoBox file rename is atomic; in Berkeley Unix, the rename system call guarantees only that if the target name was bound before the rename was attempted, it will be bound to something afterwards <ref> [1] </ref>. Unix programmers often use rename to commit a larger update. Providing these strengthened semantics was easy, given that we were building on EchoDisk. We now present a representative set of procedures from the EchoBox interface. PROCEDURE NewSession (): SessionID; NewSession initializes a client machine's session with this server.
Reference: [2] <author> Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Echo was in active use from November 1990 to November 1992, when the evolution of our laboratory's hardware and software base led us to retire the system. At its peak, Echo had about 50 users. 2 For a survey of logging techniques, see Bernstein <ref> [2] </ref> and Haerder [11]. 2 that important file system operations, such as renaming a file, can be performed atomically. In none of these cases do the logging restrictions have a significant impact on file system performance, but they do make the task of implementation more difficult. <p> Because processing an Update record is idempotent, no additional machinery, such as per-page log sequence numbers, is needed to avoid doing it twice <ref> [2, chapter 6] </ref>[10]. Since redoing updates is done entirely within the EchoDisk module, the client of EchoDisk does not have to write special redo procedures. This is simpler 8 than logging algorithms that require redo procedures, because a redo procedure is different from the original do code.
Reference: [3] <author> Anupam Bhide, Elmootazbellah N. Elnozahy, and Stephen P. Morgan. </author> <title> Implicit replication in a network file server. </title> <booktitle> In Proc. Workshop on the Management of Replicated Data, </booktitle> <pages> pages 85-90. </pages> <publisher> IEEE Computer Society, </publisher> <month> November </month> <year> 1990. </year>
Reference-contexts: Several file system implementations have demonstrated the advantages of logging. The Cedar file system implements directories as a B-tree, using logging to maintain the B-tree invariants [12]. The Harp file system and the HA-NFS file system provide replicated NFS service, and use logging to assist in replication and failover <ref> [3, 4, 19] </ref>. The Alpine file system uses logging to provide transactional semantics to file system clients [6]. The Sprite log-structured file system is radically different from these other systems and from Echo, in that all data lives in the log [26].
Reference: [4] <author> Anupam Bhide, Elmootazbellah N. Elnozahy, and Stephen P. Morgan. </author> <title> A highly available network file server. </title> <booktitle> In USENIX Winter Conference Proceedings, </booktitle> <pages> pages 199-205. </pages> <publisher> USENIX Association, </publisher> <year> 1991. </year>
Reference-contexts: Several file system implementations have demonstrated the advantages of logging. The Cedar file system implements directories as a B-tree, using logging to maintain the B-tree invariants [12]. The Harp file system and the HA-NFS file system provide replicated NFS service, and use logging to assist in replication and failover <ref> [3, 4, 19] </ref>. The Alpine file system uses logging to provide transactional semantics to file system clients [6]. The Sprite log-structured file system is radically different from these other systems and from Echo, in that all data lives in the log [26].
Reference: [5] <author> Andrew D. Birrell, Andy Hisgen, Charles Jerian, Timothy Mann, and Garret Swart. </author> <title> The Echo distributed file system. </title> <type> Research report, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: However, the bounds on the log size are large enough 1 Other Echo goals include location-transparent global naming and distributed caching between clients and servers. These aspects of Echo are discussed more fully in an overview paper <ref> [5] </ref> and in several additional papers [13, 14, 15, 21, 28]. The Echo system is no longer under development or in use, but we speak of it in the present tense throughout this paper to avoid awkwardness. <p> When a replica becomes disconnected, the epoch numbers of the remaining connected replicas are all set to a new value larger than any that has been used before. This process uses a multi-phase algorithm that is resilient to failures; see our other papers <ref> [5, 22] </ref> for details. When the replica reconnects, the fact that its epoch number is smaller reveals that it is out of date. When a replica is disconnected and later becomes reconnected, we must bring its array of disk pages and its log into agreement with the up-to-date replicas. <p> EchoBox guarantees to execute the update RPCs in pipeline 3 The additional functionality beyond Unix includes support for richer access control lists and support for gluing together individual file system volumes (i.e., subtrees) into a single global name space <ref> [5, 15] </ref>. 18 order. An update RPC returns to the client machine only after the update is persistent on disk. 4 Because of the pipeline, each client may have several RPCs in progress to a server.
Reference: [6] <author> Mark R. Brown, Karen N. Kolling, and Edward A. Taft. </author> <title> The Alpine file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(4) </volume> <pages> 261-293, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: The Harp file system and the HA-NFS file system provide replicated NFS service, and use logging to assist in replication and failover [3, 4, 19]. The Alpine file system uses logging to provide transactional semantics to file system clients <ref> [6] </ref>. The Sprite log-structured file system is radically different from these other systems and from Echo, in that all data lives in the log [26].
Reference: [7] <author> A. Chang, M. F. Mergen, R. K. Rader, J. A. Roberts, and S. L. Porter. </author> <title> Evolution of storage facilites in AIX Version 3 for RISC System/6000 processors. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 34(1), </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: The published descriptions of their design are vague on how the necessary locking at the file system layer, beyond that provided by their virtual storage manager, is achieved <ref> [7, 8] </ref>. Transarc's Episode file system uses old-value/new-value logging with a bounded log and support for abort.
Reference: [8] <author> Albert Chang and Mark F. Mergen. </author> <title> 801 storage: Architecture and programming. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 28-50, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The published descriptions of their design are vague on how the necessary locking at the file system layer, beyond that provided by their virtual storage manager, is achieved <ref> [7, 8] </ref>. Transarc's Episode file system uses old-value/new-value logging with a bounded log and support for abort.
Reference: [9] <author> Sailesh Chutani, Owen T. Anderson, Michael L. Kazar, Bruce W. Leverett, W. Anthony Mason, and Robert N. Sidebotham. </author> <title> The Episode file system. </title> <booktitle> In USENIX Winter Conference Proceedings, </booktitle> <pages> pages 43-60. </pages> <publisher> USENIX Association, </publisher> <year> 1992. </year>
Reference-contexts: This umbrella transaction either commits or aborts in its entirety <ref> [9] </ref>. Echo's use of new-value logging allowed a clean separation of our overall design, into a layer that implements logging and recovery (EchoDisk), and a layer that implements file system accesses and updates (EchoBox). The EchoBox layer is not involved in recovery.
Reference: [10] <author> James Gray. </author> <title> Notes on data base operating systems. </title> <type> Research Report RJ 2188 (30001), </type> <institution> IBM Research Laboratory, </institution> <address> San Jose, California, </address> <year> 1978. </year>
Reference-contexts: Also, the log plus an old backup copy could be used to recover from media failure, a technique called fuzzy dump in the database literature <ref> [10] </ref>. Disk replication has a minor impact on writing pages to their home locations. The writing is performed sequentially to the different replicas. If it were overlapped, we would risk corrupting the page on all replicas (say, from power failure).
Reference: [11] <author> Theo Haerder and Andreas Reuther. </author> <title> Principles of transaction-oriented database recovery. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4) </volume> <pages> 287-317, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: Echo was in active use from November 1990 to November 1992, when the evolution of our laboratory's hardware and software base led us to retire the system. At its peak, Echo had about 50 users. 2 For a survey of logging techniques, see Bernstein [2] and Haerder <ref> [11] </ref>. 2 that important file system operations, such as renaming a file, can be performed atomically. In none of these cases do the logging restrictions have a significant impact on file system performance, but they do make the task of implementation more difficult.
Reference: [12] <author> Robert Hagmann. </author> <title> Reimplementing the Cedar file system using logging and group commit. </title> <booktitle> In Proc. 11th Symp. on Operating Systems Principles, </booktitle> <pages> pages 155-162. </pages> <publisher> ACM SIGOPS, </publisher> <month> November </month> <year> 1987. </year> <month> 37 </month>
Reference-contexts: Logging allows more complex operations, such as file rename, to be atomic. Several file system implementations have demonstrated the advantages of logging. The Cedar file system implements directories as a B-tree, using logging to maintain the B-tree invariants <ref> [12] </ref>. The Harp file system and the HA-NFS file system provide replicated NFS service, and use logging to assist in replication and failover [3, 4, 19]. The Alpine file system uses logging to provide transactional semantics to file system clients [6]. <p> We could have partially protected against this vulnerability by choosing to write log pages twice on the same physical disk whenever the disk is not replicated. This would protect us against bad disk blocks, but not failures of the entire disk. The Cedar logging file system uses this technique <ref> [12] </ref>. Unreplicated disks are also vulnerable to media errors in the array of home pages. A file system scavenger [12, 18] at the EchoBox layer could partially recover from such errors (and also from unreadable log pages). <p> This would protect us against bad disk blocks, but not failures of the entire disk. The Cedar logging file system uses this technique [12]. Unreplicated disks are also vulnerable to media errors in the array of home pages. A file system scavenger <ref> [12, 18] </ref> at the EchoBox layer could partially recover from such errors (and also from unreadable log pages).
Reference: [13] <author> Andy Hisgen, Andrew Birrell, Charles Jerian, Timothy Mann, and Garret Swart. </author> <title> Some consequences of excess load on the Echo replicated file system. </title> <booktitle> In Proc. 2nd Workshop on the Management of Replicated Data, </booktitle> <pages> pages 92-95. </pages> <publisher> IEEE Computer Society, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: However, the bounds on the log size are large enough 1 Other Echo goals include location-transparent global naming and distributed caching between clients and servers. These aspects of Echo are discussed more fully in an overview paper [5] and in several additional papers <ref> [13, 14, 15, 21, 28] </ref>. The Echo system is no longer under development or in use, but we speak of it in the present tense throughout this paper to avoid awkwardness. <p> RPC support in our environment was significantly better than TCP support <ref> [13, 27] </ref>. 19 PROCEDURE ReadFile ( sid: SessionID; fid: FileID; filePosition: INTEGER; nbytes: INTEGER; VAR (*OUT*) buf: ARRAY OF BYTE); ReadFile copies nbytes of the file fid starting at filePosition into the buffer buf.
Reference: [14] <author> Andy Hisgen, Andrew Birrell, Chuck Jerian, Timothy Mann, Michael Schroeder, and Garret Swart. </author> <title> Granularity and semantic level of replication in the Echo distributed file system. </title> <booktitle> In Proc. Workshop on the Management of Replicated Data, </booktitle> <pages> pages 2-4. </pages> <publisher> IEEE Computer Society, </publisher> <month> November </month> <year> 1990. </year>
Reference-contexts: However, the bounds on the log size are large enough 1 Other Echo goals include location-transparent global naming and distributed caching between clients and servers. These aspects of Echo are discussed more fully in an overview paper [5] and in several additional papers <ref> [13, 14, 15, 21, 28] </ref>. The Echo system is no longer under development or in use, but we speak of it in the present tense throughout this paper to avoid awkwardness. <p> To clients of the EchoDisk interface, the disk replication is invisible; they see a single array of pages, with single-copy semantics. 13 Thus, replication of persistent storage is beneath the EchoBox file system layer. Another Echo paper discusses the advantages and disadvantages of this design choice <ref> [14] </ref>. The log is essential in keeping the replicas consistent. During crash recovery, the log reveals which data was in the middle of being updated, and thus may be different on the different replicas. Recovery uses the log to bring the replicas back into agreement.
Reference: [15] <author> Andy Hisgen, Andrew Birrell, Timothy Mann, Michael Schroeder, and Garret Swart. </author> <title> Availability and consistency tradeoffs in the Echo distributed file system. </title> <booktitle> In Proc. 2nd Workshop on Workstation Operating Systems, </booktitle> <pages> pages 49-54. </pages> <publisher> IEEE Computer Society, </publisher> <month> September </month> <year> 1989. </year>
Reference-contexts: However, the bounds on the log size are large enough 1 Other Echo goals include location-transparent global naming and distributed caching between clients and servers. These aspects of Echo are discussed more fully in an overview paper [5] and in several additional papers <ref> [13, 14, 15, 21, 28] </ref>. The Echo system is no longer under development or in use, but we speak of it in the present tense throughout this paper to avoid awkwardness. <p> EchoBox guarantees to execute the update RPCs in pipeline 3 The additional functionality beyond Unix includes support for richer access control lists and support for gluing together individual file system volumes (i.e., subtrees) into a single global name space <ref> [5, 15] </ref>. 18 order. An update RPC returns to the client machine only after the update is persistent on disk. 4 Because of the pipeline, each client may have several RPCs in progress to a server.
Reference: [16] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Sidebotham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The algorithm enables a client machine to cache files and directories, including caching of write-behind. The Echo distributed caching algorithm is similar to those of the Sprite and Andrew file systems <ref> [16, 17, 24] </ref>, and is discussed in detail in a separate paper [21]. Thus, EchoBox is used by a client machine that handles caching. The client machine also handles failover between EchoBox server replicas. Caching and failover had several significant impacts on the design of the EchoBox interface.
Reference: [17] <author> Michael L. Kazar. </author> <title> Synchronization and caching issues in the Andrew file system. </title> <booktitle> In USENIX Winter Conference Proceedings, </booktitle> <pages> pages 27-36. </pages> <publisher> USENIX Association, </publisher> <month> February </month> <year> 1988. </year>
Reference-contexts: The algorithm enables a client machine to cache files and directories, including caching of write-behind. The Echo distributed caching algorithm is similar to those of the Sprite and Andrew file systems <ref> [16, 17, 24] </ref>, and is discussed in detail in a separate paper [21]. Thus, EchoBox is used by a client machine that handles caching. The client machine also handles failover between EchoBox server replicas. Caching and failover had several significant impacts on the design of the EchoBox interface.
Reference: [18] <author> Butler W. Lampson. </author> <title> Hints for computer system design. </title> <journal> IEEE Software, </journal> <volume> 1(1) </volume> <pages> 11-28, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: This would protect us against bad disk blocks, but not failures of the entire disk. The Cedar logging file system uses this technique [12]. Unreplicated disks are also vulnerable to media errors in the array of home pages. A file system scavenger <ref> [12, 18] </ref> at the EchoBox layer could partially recover from such errors (and also from unreadable log pages).
Reference: [19] <author> Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Luiba Shrira, and Michael Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proc. 13th Symp. on Operating Systems Principles, </booktitle> <pages> pages 226-238. </pages> <publisher> ACM SIGOPS, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: Several file system implementations have demonstrated the advantages of logging. The Cedar file system implements directories as a B-tree, using logging to maintain the B-tree invariants [12]. The Harp file system and the HA-NFS file system provide replicated NFS service, and use logging to assist in replication and failover <ref> [3, 4, 19] </ref>. The Alpine file system uses logging to provide transactional semantics to file system clients [6]. The Sprite log-structured file system is radically different from these other systems and from Echo, in that all data lives in the log [26].
Reference: [20] <author> David Lomet. MLR: </author> <title> A recovery method for multi-level systems. </title> <booktitle> In Proc. SIGMOD Conference, </booktitle> <pages> pages 185-194. </pages> <booktitle> ACM SIGMOD, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: In return, operational logging allows more cleverness, including more compact logs and fancier type-specific locking [23]. We would like to see a file server design of similar aspirations to ours based on operational or multi-level logging <ref> [20] </ref>, worked out to a similar level of detail. Acknowledgements Extensive comments from Mark R. Brown improved the organization of the paper. 36
Reference: [21] <author> Timothy Mann, Andrew Birrell, Andy Hisgen, Charles Jerian, and Garret Swart. </author> <title> A coherent distributed file cache with directory write-behind. </title> <type> Research Report 103, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: However, the bounds on the log size are large enough 1 Other Echo goals include location-transparent global naming and distributed caching between clients and servers. These aspects of Echo are discussed more fully in an overview paper [5] and in several additional papers <ref> [13, 14, 15, 21, 28] </ref>. The Echo system is no longer under development or in use, but we speak of it in the present tense throughout this paper to avoid awkwardness. <p> The algorithm enables a client machine to cache files and directories, including caching of write-behind. The Echo distributed caching algorithm is similar to those of the Sprite and Andrew file systems [16, 17, 24], and is discussed in detail in a separate paper <ref> [21] </ref>. Thus, EchoBox is used by a client machine that handles caching. The client machine also handles failover between EchoBox server replicas. Caching and failover had several significant impacts on the design of the EchoBox interface. <p> The hard-link count on the file deleted-FileID is decremented by one. If it is now zero, and if no client machines still have the file open, the file is destroyed. (The Echo distributed client-server caching algorithm keeps track of how many clients still have a file open <ref> [21] </ref>.) The space that had been consumed by this file is not available immediately for use by other calls; rather, there is a short non-deterministic delay. The ctime and mtime of con-tainingDirectory are set to versionStamp. <p> When the Echo distributed client-server caching algorithm <ref> [21] </ref> reveals that nobody has an orphan file open, EchoBox can remove the file from its orphan list and delete the file, returning its pages to the disk space allocator and removing it from the fid map.
Reference: [22] <author> Timothy Mann, Andy Hisgen, and Garret Swart. </author> <title> An algorithm for data replication. </title> <type> Research Report 46, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> June </month> <year> 1989. </year> <month> 38 </month>
Reference-contexts: When a replica becomes disconnected, the epoch numbers of the remaining connected replicas are all set to a new value larger than any that has been used before. This process uses a multi-phase algorithm that is resilient to failures; see our other papers <ref> [5, 22] </ref> for details. When the replica reconnects, the fact that its epoch number is smaller reveals that it is out of date. When a replica is disconnected and later becomes reconnected, we must bring its array of disk pages and its log into agreement with the up-to-date replicas.
Reference: [23] <author> C. Mohan, Don Haderle, Bruce Lindsay, Hamid Pirahesh, and Peter Schwarz. </author> <title> ARIES: A transaction recovery method supporting fine-granularity locking and partial rollbacks using write-ahead logging. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(1) </volume> <pages> 94-162, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The redo procedures are, in general, different from the original do procedures, requiring more code. And they are more complicated than the simple byte copying that recovery performs in new-value logging. In return, operational logging allows more cleverness, including more compact logs and fancier type-specific locking <ref> [23] </ref>. We would like to see a file server design of similar aspirations to ours based on operational or multi-level logging [20], worked out to a similar level of detail. Acknowledgements Extensive comments from Mark R. Brown improved the organization of the paper. 36
Reference: [24] <author> Michael N. Nelson, Brent B. Welch, and John K. Ousterhout. </author> <title> Caching in the Sprite network file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 134-154, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The algorithm enables a client machine to cache files and directories, including caching of write-behind. The Echo distributed caching algorithm is similar to those of the Sprite and Andrew file systems <ref> [16, 17, 24] </ref>, and is discussed in detail in a separate paper [21]. Thus, EchoBox is used by a client machine that handles caching. The client machine also handles failover between EchoBox server replicas. Caching and failover had several significant impacts on the design of the EchoBox interface.
Reference: [25] <author> Jehan-Francois Paris. </author> <title> Voting with witnesses: A consistency scheme for replicated files. </title> <booktitle> In Proc. 6th Intl. Conf. on Distributed Computer Systems, </booktitle> <pages> pages 606-612. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1986. </year>
Reference-contexts: In configurations with an even number of disk replicas, witnesses are used to break ties <ref> [25] </ref>. Ownership is subject to timeout. Therefore the current primary must refresh its ownership periodically. If the primary fails to do so for any reason (crash of primary, slowness of primary, loss of communication with disk, failure of disk) it loses ownership.
Reference: [26] <author> Mendel Rosenblum and John K. Ousterhout. </author> <title> The design and implementation of a log-structured file system. </title> <booktitle> In Proc. 13th Symp. on Operating Systems Principles, </booktitle> <pages> pages 1-15. </pages> <publisher> ACM SIGOPS, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: The Alpine file system uses logging to provide transactional semantics to file system clients [6]. The Sprite log-structured file system is radically different from these other systems and from Echo, in that all data lives in the log <ref> [26] </ref>. Echo is a distributed file system, one of whose major goals is to achieve high availability by replication of disks and servers. 1 We were therefore attracted to logging as an implementation technique.
Reference: [27] <author> Michael D. Schroeder and Michael Burrows. </author> <title> Performance of Firefly RPC. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1) </volume> <pages> 1-17, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: RPC support in our environment was significantly better than TCP support <ref> [13, 27] </ref>. 19 PROCEDURE ReadFile ( sid: SessionID; fid: FileID; filePosition: INTEGER; nbytes: INTEGER; VAR (*OUT*) buf: ARRAY OF BYTE); ReadFile copies nbytes of the file fid starting at filePosition into the buffer buf.
Reference: [28] <author> Garret Swart, Andrew Birrell, Andy Hisgen, Charles Jerian, and Timothy Mann. </author> <title> Availability in the Echo file system. </title> <type> Research report, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: However, the bounds on the log size are large enough 1 Other Echo goals include location-transparent global naming and distributed caching between clients and servers. These aspects of Echo are discussed more fully in an overview paper [5] and in several additional papers <ref> [13, 14, 15, 21, 28] </ref>. The Echo system is no longer under development or in use, but we speak of it in the present tense throughout this paper to avoid awkwardness.
Reference: [29] <author> Charles P. Thacker and Lawrence C. Stewart. Firefly: </author> <title> A multiprocessor workstation. </title> <booktitle> In Proc. 2nd Intl. Conf. on Architectural Support for Programming Languages and Operating Systems. ACM and IEEE Computer Society, </booktitle> <month> October </month> <year> 1987. </year> <month> 39 </month>
Reference-contexts: We force them to serialize only for EndTrans-action. Our desire for high concurrency is motivated by the fact that our server hardware is a shared-memory multiprocessor, the Firefly <ref> [29] </ref>. On a uniprocessor, it would be adequate for an update to acquire a long-term exclusive lock the first time it needs to allocate or deallocate storage, releasing it only after EndTransaction.
References-found: 29

