URL: http://www.Ultimode.com/~wray/graphbib.ps.Z
Refering-URL: http://www.Ultimode.com/~wray/graphbib/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A guide to the literature on learning probabilistic networks from data  
Author: Wray Buntine 
Keyword: Bayesian networks, graphical models, hidden variables, learning, learning structure, probabilistic networks, knowledge discovery.  
Note: IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, TO APPEAR (FINAL DRAFT) 1  
Abstract: This literature review discusses different methods under the general rubric of learning Bayesian networks from data, and includes some overlapping work on more general probabilistic networks. Connections are drawn between the statistical, neural network, and uncertainty communities, and between the different methodological communities, such as Bayesian, description length, and classical statistics. Basic concepts for learning and Bayesian networks are introduced and methods are then reviewed. Methods are discussed for learning parameters of a probabilistic network, for learning the structure, and for learning hidden variables. The presentation avoids formal definitions and theorems, as these are plentiful in the literature, and instead illustrates key concepts with simplified examples. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Heckerman, A. Mamdani, and M. Wellman, </author> <title> "Real-world applications of Bayesian networks: Introduction", </title> <journal> Communications of the ACM, </journal> <volume> vol. 38, no. 3, </volume> <year> 1995. </year> <journal> 14 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, </journal> <note> TO APPEAR (FINAL DRAFT) </note>
Reference: [2] <author> T.S. Verma and J. Pearl, </author> <title> "Equivalence and synthesis of causal models", </title> <note> In Bonissone [157]. </note>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], [56], [99] and without [100], [101], <ref> [2] </ref>, [102], and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3].
Reference: [3] <author> P. Spirtes, C. Glymour, and R. Scheines, </author> <title> Causation, Prediction, and Search, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], [56], [99] and without [100], [101], [2], [102], and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in <ref> [3] </ref>. In some cases, only a class of equivalent graphs can be reconstructed from data, and in other cases latent variables and their properties cannot be identified uniquely.
Reference: [4] <author> D. Heckerman and R. Shachter, </author> <title> "A definition and graphical representation for causality", </title> <note> In Besnard and Hanks [158]. </note>
Reference: [5] <author> J. Pearl, </author> <title> "Graphical models, causality, and intervention", </title> <journal> Statistical Science, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 266-273, </pages> <year> 1993. </year>
Reference: [6] <author> S.L. Lauritzen and D.J. Spiegelhalter, </author> <title> "Local computations with probabilities on graphical structures and their application to expert systems (with discussion)", </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 50, no. 2, </volume> <pages> pp. 240-265, </pages> <year> 1988. </year>
Reference: [7] <author> S. Wright, </author> <title> "Correlation and causation", </title> <journal> Journal of Agricultural Research, </journal> <volume> vol. 20, </volume> <pages> pp. 557-585, </pages> <year> 1921. </year>
Reference: [8] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems, </title> <publisher> Mor-gan Kaufmann, </publisher> <year> 1988. </year>
Reference: [9] <author> R.A. Howard and J.E. Matheson, </author> <title> "Influence diagrams", in The Principles and Applications of Decision Analysis, </title> <editor> R.A. Howard and J.E. Matheson, Eds. </editor> <title> Strategic Decisions Group, </title> <address> Menlo Park, CA, </address> <year> 1981. </year>
Reference: [10] <author> C. Glymour, R. Scheines, P. Spirtes, and K. Kelly, </author> <title> Discovering Causal Structure, </title> <publisher> Morgan Academic Press, </publisher> <address> San Diego, CA, </address> <year> 1987. </year>
Reference: [11] <author> S. Mishra and P.P. Shenoy, </author> <title> "Attitude formation models: Insights from TETRAD", </title> <booktitle> In Cheeseman and Oldford [159], </booktitle> <pages> pp. 223-232. </pages>
Reference: [12] <author> R. Scheines, </author> <title> "Inferring causal structure among unmeasured variables", </title> <booktitle> In Cheeseman and Oldford [159], </booktitle> <pages> pp. 197-204. </pages>
Reference-contexts: These identification methods have lead to some of the earliest algorithms for learning structure from data [103], [56], and a related approach that also combines cross validation to address model selection is [104]. Identification methods are also used in TETRAD II, the successor to TETRAD <ref> [12] </ref>. The theory of network identification from data and network equivalence are a precursor to techniques for learning from medium sized samples of Fig. 7. <p> But Bayesian methods do equivalent things in the large sample case to the independence tests used by identification algorithms, and the strict ordering is not entirely necessary for the Bayesian algorithms [32], [37]. A variety of hybrid algorithms exist [59], [104], <ref> [12] </ref>, [73] that provide a rich source of ideas for future development. X. Constructing learning software For a variety of network structures with latent variables and different parametric nodes (Logistic, Poisson, and other forms), the BUGS program can generate Gibbs samplers automatically [154], [86].
Reference: [13] <author> B.D. Ripley, </author> <title> "Network methods in statistics", in Probability, </title> <journal> Statistics and Optimization, F.P. Kelly, Ed., </journal> <pages> pp. 241-253. </pages> <publisher> Wi-ley & Sons, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: B. Hypothesis testing approaches Hypothesis testing is the standard model selection strategy from classical statistics. For probabilistic networks methods are well developed and a variety of statistical software exists [28], [43], <ref> [13] </ref>. As mentioned before, the problem is that this is only a viable approach if a small number of hypotheses are being tested. Clever or greedy search techniques can help here [128] by reducing the number of hypothesis tests required.
Reference: [14] <author> J.A. Hertz, A.S. Krogh, and R.G. Palmer, </author> <title> Introduction to the Theory of Neural Computation, </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference: [15] <author> J.R. Quinlan, C4.5: </author> <title> Programs for Machine Learning, </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: The maximum likelihood parameter values are therefore said to over-fit the data. This is a well-known problem in supervised learning, for instance as addressed by pruning methods for classification trees [64], <ref> [15] </ref>. The Bayesian Maximum a-posterior (MAP) approach extends the maximum likelihood approach by introducing a prior probability. Good introductions to this simplified Bayesian approach and some of its extensions can be found in [79], [80]. <p> For discrete variables at least, the problem of learning Bayesian networks from complete data is related to the problem of learning classification trees, exemplified by the CART algorithm [64] in statistics and ID3 and C4 in artificial intelligence <ref> [15] </ref>. This relationship holds because the sample likelihood for a binary classification tree can be represented as a product of independent binomial distributions, just like the sample likelihood for the Bayesian networks on binary variables described in Section III. Both problems also have a similar parametric structure. <p> Both problems also have a similar parametric structure. The classification tree problem has a long history and has been studied from the perspective of applied statistics [64], ar tificial intelligence <ref> [15] </ref>, Bayesian statistics [118], minimum description length (MDL) [119], [120], genetic algorithms, and computational learning theory. An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in [121], and the relationship between the two approaches is discussed in [122].
Reference: [16] <author> F. Hayes-Roth, D.A. Waterman, and D. Lenat, Eds., </author> <title> Building Expert Systems, </title> <publisher> Addison Wesley, </publisher> <year> 1983. </year>
Reference: [17] <editor> D. Michie, </editor> <booktitle> "Current developments in expert systems", in Applications of Expert Systems, </booktitle> <editor> J.R. Quinlan, Ed. </editor> <publisher> Addison Wesley, </publisher> <address> London, </address> <year> 1987. </year>
Reference: [18] <author> J.R. Quinlan, P.J. Compton, K.A. Horn, and L. Lazarus, </author> <title> "Inductive knowledge acquisition: A case study", in Applications of Expert Systems, </title> <editor> J.R. Quinlan, Ed. </editor> <publisher> Addison Wesley, </publisher> <address> London, </address> <year> 1987. </year>
Reference: [19] <author> M. Henrion and D.R. Cooley, </author> <title> "An experimental comparison of knowledge engineering for expert systems and for decision analysis", </title> <booktitle> in Sixth National Conference on Artificial Intelligence, Seattle, 1987, American Association for Artificial Intelligence, </booktitle> <pages> pp. 471-476. </pages>
Reference: [20] <author> D. Heckerman, </author> <title> "Probabilistic similarity networks", </title> <journal> Networks, </journal> <volume> vol. 20, </volume> <pages> pp. 607-636, </pages> <year> 1990. </year>
Reference: [21] <author> R.M. Neal, </author> <title> "Connectionist learning of belief networks", </title> <journal> Artificial Intelligence, </journal> <volume> vol. 56, </volume> <pages> pp. 71-113, </pages> <year> 1992. </year>
Reference-contexts: More recent versions of these clustering algorithms search over possible structures as well [51]. Some algorithms do not fit neatly into the categories above. Learning Markov (undirected) networks from data is related to the early Boltzmann machine from neural networks <ref> [21] </ref>. Also the earlier Bayesian methods seemed to require as input a strict ordering of variables [35], [121], whereas the identification algorithms did not require this. So one thought is a combination of Bayesian with identification algorithms [33].
Reference: [22] <author> L.K. Saul, T. Jaakkola, and M.I. Jordan, </author> <title> "Mean field theory for sigmoid belief networks", </title> <type> Technical Report 9501, </type> <institution> Computational Cognitive Science, MIT, </institution> <year> 1995. </year>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], <ref> [22] </ref> Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93].
Reference: [23] <author> W. Buntine, </author> <title> "Operations for learning with graphical models", </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> vol. 2, </volume> <pages> pp. 159-225, </pages> <year> 1994, </year> <note> JAIR is mirrored at several sites including URL http://www.cs.washington.edu /research/jair/home.html. </note>
Reference-contexts: Notice how it is effected by both the prior and the likelihood. Many general algorithms exist for addressing parameter fitting problems of probabilistic networks: missing and latent variables, large samples, recursive or incremental techniques, special nodes, and subjective priors [26], [24], [81], [25], <ref> [23] </ref>, [42] Table III lists the major techniques and their application. References given are introductions, new extensions or examples of their use, and are by no means a thorough list of references in the area. <p> This is called the Bayes factor and a variety of techniques and approximations exist for computing it [25], [26], <ref> [23] </ref>. The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], [141], [142], [143], [37], [38]. <p> Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], [37], <ref> [23] </ref>, and a thesis covering many of the issues is [36]. The full Bayesian approach is a predictive one: rather than returning the single "best" network, the aim might be to perform prediction or estimate probabilities for new cases. <p> A general Bayesian algorithm family for inference that applies in any context, parameter fitting or structure learning, is the Markov Chain Monte Carlo (MCMC) family of algorithms. An introduction is given in [149], <ref> [23] </ref>, and an extensive review is given by [87]. This family uses the following kind of trick. Suppose we wish to sample from the distribution p (A; B; C). In general this might be a complex distribution and no convenient sampling algorithm may be known. <p> MCMC methods can be used for parameter fitting, to sample different network parameters, and for structure learning, to sample from different possible probabilistic network structures. Use of MCMC methods for learning probabilistic networks is discussed in [85], [144], [147], [146], <ref> [23] </ref>. Madigan, Gavrin and Raftery [146] refer to the use of MCMC methods for averaging over multiple probabilistic networks|the full predictive approach|as Markov Chain Monte Carlo Model Composition (MC 3 ). The key distinction between Bayesian and non-Bayesian methods is the use of priors. <p> An exposition of the techniques used by algorithms for learning Bayesian networks| decomposition, exact Bayes factors, and differentiation| all readily automated|can be found in <ref> [23] </ref>, [156].
Reference: [24] <author> M.A. Tanner, </author> <title> Tools for Statistical Inference, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1993. </year>
Reference-contexts: Notice how it is effected by both the prior and the likelihood. Many general algorithms exist for addressing parameter fitting problems of probabilistic networks: missing and latent variables, large samples, recursive or incremental techniques, special nodes, and subjective priors [26], <ref> [24] </ref>, [81], [25], [23], [42] Table III lists the major techniques and their application. References given are introductions, new extensions or examples of their use, and are by no means a thorough list of references in the area. <p> A good general introduction to Bayesian methods for learning Bayesian networks can be found in [79]. Advanced introductions and reviews of Bayesian methods for learning can be found in [25], [26], <ref> [24] </ref>. The Bayesian approach has many different approximations.
Reference: [25] <author> R.E. Kass and A.E. Raftery, </author> <title> "Bayes factors and model uncertainty", </title> <journal> Journal of the American Statistical Association, </journal> <volume> vol. 90, </volume> <pages> pp. 773-795, </pages> <year> 1995. </year>
Reference-contexts: Notice how it is effected by both the prior and the likelihood. Many general algorithms exist for addressing parameter fitting problems of probabilistic networks: missing and latent variables, large samples, recursive or incremental techniques, special nodes, and subjective priors [26], [24], [81], <ref> [25] </ref>, [23], [42] Table III lists the major techniques and their application. References given are introductions, new extensions or examples of their use, and are by no means a thorough list of references in the area. <p> Variations of this method are popular in neural networks [91], having been a feature of early methods [92], and have proven to yield computational BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 9 Algorithm Problems Refs. MAP general <ref> [25] </ref> Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. <p> Variations of this method are popular in neural networks [91], having been a feature of early methods [92], and have proven to yield computational BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 9 Algorithm Problems Refs. MAP general <ref> [25] </ref> Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. <p> A good general introduction to Bayesian methods for learning Bayesian networks can be found in [79]. Advanced introductions and reviews of Bayesian methods for learning can be found in <ref> [25] </ref>, [26], [24]. The Bayesian approach has many different approximations. <p> This is called the Bayes factor and a variety of techniques and approximations exist for computing it <ref> [25] </ref>, [26], [23]. The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], [141], [142], [143], [37], [38].
Reference: [26] <author> J.M. Bernardo and A.F.M. Smith, </author> <title> Bayesian Theory, </title> <publisher> John Wiley, </publisher> <address> Chichester, </address> <year> 1994. </year>
Reference-contexts: Notice how it is effected by both the prior and the likelihood. Many general algorithms exist for addressing parameter fitting problems of probabilistic networks: missing and latent variables, large samples, recursive or incremental techniques, special nodes, and subjective priors <ref> [26] </ref>, [24], [81], [25], [23], [42] Table III lists the major techniques and their application. References given are introductions, new extensions or examples of their use, and are by no means a thorough list of references in the area. <p> sense that a learning algorithm, given a sufficiently large sample, will invariably return a hypothesis (graphical structure and parameters) close to the "truth"? This question is formalized and addressed from several angles in computational learning theory [97] under the name of identification and learnability, as well as in statistics [78], <ref> [26] </ref> under the name of consistency. This is the situation of N ! 1 in Fig. 7. In Bayesian networks, this question is confounded by the existence of equivalence classes of graphs (one example of a redundant model [78]) and by the use of hidden or latent variables. <p> See, for instance, the efforts made to compare different learning algorithms in [30], and consider that a statistical methodology is a higher level of abstraction than a learning algorithm. A discussion of the Bayesian perspective on the issues of learning appears in <ref> [26] </ref>, touching on prior probabilities, and subjective statistical analysis. Different disciplines have addressed these problems in parallel while they attempted to extend the classical maximum likelihood and hypothesis testing approaches from statistics. <p> A good general introduction to Bayesian methods for learning Bayesian networks can be found in [79]. Advanced introductions and reviews of Bayesian methods for learning can be found in [25], <ref> [26] </ref>, [24]. The Bayesian approach has many different approximations. <p> This is called the Bayes factor and a variety of techniques and approximations exist for computing it [25], <ref> [26] </ref>, [23]. The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], [141], [142], [143], [37], [38].
Reference: [27] <author> W.L. Buntine, </author> <title> "Graphical models for discovering knowledge", in Advances in Knowledge Discovery and Data Mining, </title> <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. S. Uthurasamy, Eds. </editor> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference: [28] <author> R. Almond, </author> <title> "Software for belief networks", World wide web site, </title> <note> URL is http://bayes.stat.washington.edu/almond/ belief.html, </note> <year> 1995. </year>
Reference-contexts: B. Hypothesis testing approaches Hypothesis testing is the standard model selection strategy from classical statistics. For probabilistic networks methods are well developed and a variety of statistical software exists <ref> [28] </ref>, [43], [13]. As mentioned before, the problem is that this is only a viable approach if a small number of hypotheses are being tested. Clever or greedy search techniques can help here [128] by reducing the number of hypothesis tests required.
Reference: [29] <editor> AUAI, </editor> <booktitle> Association for Uncertainty in Artificial Intelligence, </booktitle> <institution> Home Page, sited at Thinkbank, Berkeley, </institution> <year> 1995, </year> <title> World wide web site, </title> <note> URL is http://www.auai.org/. </note>
Reference: [30] <editor> D. Michie, D.J. Spiegelhalter, and C.C. Taylor, Eds., </editor> <title> Machine Learning, Neural and Statistical Classification, </title> <publisher> Ellis Horword, </publisher> <address> Hertfordshire, England, </address> <year> 1994. </year>
Reference-contexts: Partly, this stems from the apparent impossibility of handling smaller sample learning problems in any objective manner, and the difficulty of establishing a basis on which a statistical methodology can be judged. See, for instance, the efforts made to compare different learning algorithms in <ref> [30] </ref>, and consider that a statistical methodology is a higher level of abstraction than a learning algorithm. A discussion of the Bayesian perspective on the issues of learning appears in [26], touching on prior probabilities, and subjective statistical analysis.
Reference: [31] <author> S.L. Lauritzen, B. Thiesson, </author> <title> and D.J. Spiegelhalter, "Diagnostic systems created by model selection methods: A case study", </title> <booktitle> In Cheeseman and Oldford [159], </booktitle> <pages> pp. 143-152. </pages>
Reference: [32] <author> Remco R. Bouckaert, </author> <title> "Properties of Bayesian belief network learning algorithms", In de Mantaras and Poole [160]. </title>
Reference-contexts: Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], <ref> [32] </ref>. A general Bayesian algorithm family for inference that applies in any context, parameter fitting or structure learning, is the Markov Chain Monte Carlo (MCMC) family of algorithms. An introduction is given in [149], [23], and an extensive review is given by [87]. <p> So one thought is a combination of Bayesian with identification algorithms [33]. But Bayesian methods do equivalent things in the large sample case to the independence tests used by identification algorithms, and the strict ordering is not entirely necessary for the Bayesian algorithms <ref> [32] </ref>, [37]. A variety of hybrid algorithms exist [59], [104], [12], [73] that provide a rich source of ideas for future development. X.
Reference: [33] <author> M. Singh and M. Valtorta, </author> <title> "An algorithm for the construction of Bayesian network structures from data", </title> <booktitle> In Heckerman and Mamdani [161], </booktitle> <pages> pp. 259-265. </pages>
Reference-contexts: Also the earlier Bayesian methods seemed to require as input a strict ordering of variables [35], [121], whereas the identification algorithms did not require this. So one thought is a combination of Bayesian with identification algorithms <ref> [33] </ref>. But Bayesian methods do equivalent things in the large sample case to the independence tests used by identification algorithms, and the strict ordering is not entirely necessary for the Bayesian algorithms [32], [37].
Reference: [34] <author> C.F. Aliferis and G.F. Cooper, </author> <title> "An evaluation of an algorithm for inductive learning of Bayesian belief networks using simulated data sets", </title> <booktitle> In de Mantaras and Poole [160], </booktitle> <pages> pp. 8-14. </pages>
Reference: [35] <author> G.F. Cooper and E.H. Herskovits, </author> <title> "A Bayesian method for the induction of probabilistic networks from data", </title> <type> Report SMI-91-01, </type> <institution> Section of Medical Informatics, University of Pittsburgh, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: This is called the Bayes factor and a variety of techniques and approximations exist for computing it [25], [26], [23]. The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], <ref> [35] </ref>, [121], [111], [112], [68], [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. <p> Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], [68], [143], [144], [145], <ref> [35] </ref>, [146], [147]. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32]. <p> Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors [68], [111], [121], [37], <ref> [35] </ref>, [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> IX. More on Learning Structure An exact algorithm for handling incomplete data or missing values can be found in [151]. The problems involved here for exact methods were previously explained in <ref> [35] </ref>. While impractical for larger problems, this could serve as a tool to benchmark on non-trivial sized problems for the many approximate algorithms that exist, for instance, some are mentioned in Table III. Simple clustering algorithms learn Bayesian networks with a single latent/hidden variable at the root of the network. <p> Some algorithms do not fit neatly into the categories above. Learning Markov (undirected) networks from data is related to the early Boltzmann machine from neural networks [21]. Also the earlier Bayesian methods seemed to require as input a strict ordering of variables <ref> [35] </ref>, [121], whereas the identification algorithms did not require this. So one thought is a combination of Bayesian with identification algorithms [33].
Reference: [36] <author> R.R. Bouckaert, </author> <title> Bayesian Belief Networks: from Inference to Construction, </title> <type> PhD thesis, </type> <institution> Faculteit Wiskunde en Informatica, Utrecht Universiteit, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], [37], [23], and a thesis covering many of the issues is <ref> [36] </ref>. The full Bayesian approach is a predictive one: rather than returning the single "best" network, the aim might be to perform prediction or estimate probabilities for new cases. For instance, one might be interested in the probability of new cases based on the sample, p (new-casejsample).
Reference: [37] <author> D. Heckerman, D. Geiger, and D. Chickering, </author> <title> "Learning Bayesian networks: The combination of knowledge and statistical data", </title> <type> Technical Report MSR-TR-94-09 (Revised), </type> <institution> Mi-crosoft Research, Advanced Technology Division, </institution> <month> July </month> <year> 1994, </year> <note> To appear, Machine Learning Journal. </note>
Reference-contexts: Network equivalence is an important concept used in some Bayesian techniques for learning Bayesian networks from data, used in advanced work on priors for Bayesian networks [105], <ref> [37] </ref>. This will be discussed later. VI. <p> The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], [141], [142], [143], <ref> [37] </ref>, [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], [37], [23], and a thesis covering <p> [112], [68], [141], [142], [143], <ref> [37] </ref>, [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], [37], [23], and a thesis covering many of the issues is [36]. The full Bayesian approach is a predictive one: rather than returning the single "best" network, the aim might be to perform prediction or estimate probabilities for new cases. <p> Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], [68], [143], [144], [145], [35], [146], [147]. Computational aspects of finding the best l networks are discussed in <ref> [37] </ref>. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32]. A general Bayesian algorithm family for inference that applies in any context, parameter fitting or structure learning, is the Markov Chain Monte Carlo (MCMC) family of algorithms. <p> Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors [68], [111], [121], <ref> [37] </ref>, [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> Both informative priors [68], [111], [121], <ref> [37] </ref>, [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> This gives a set of functional equations that the prior should satisfy. This basic theory and other properties of priors for Bayesian networks is discussed in [105], extending techniques presented in <ref> [37] </ref>. The ability to use a variety of informative, subjective priors for Bayesian networks is one of their strengths. Informative priors can include constraints and preferences on the structure of the network [121], [37], as well as preferences on the probabilities, and even using the expert to generate "imaginary data" [146]. <p> theory and other properties of priors for Bayesian networks is discussed in [105], extending techniques presented in <ref> [37] </ref>. The ability to use a variety of informative, subjective priors for Bayesian networks is one of their strengths. Informative priors can include constraints and preferences on the structure of the network [121], [37], as well as preferences on the probabilities, and even using the expert to generate "imaginary data" [146]. An example in the language of chain graphs (an extension to Bayesian networks) is given by [38]. <p> An example in the language of chain graphs (an extension to Bayesian networks) is given by [38]. The potential for using Bayesian networks as a basis for knowledge refinement has been suggested by [121], <ref> [37] </ref>, [111], [146], and in applications this offers an integrated approach to the development and maintenance of intelligent systems, long considered one of the potential fruits of artificial intelligence. IX. More on Learning Structure An exact algorithm for handling incomplete data or missing values can be found in [151]. <p> So one thought is a combination of Bayesian with identification algorithms [33]. But Bayesian methods do equivalent things in the large sample case to the independence tests used by identification algorithms, and the strict ordering is not entirely necessary for the Bayesian algorithms [32], <ref> [37] </ref>. A variety of hybrid algorithms exist [59], [104], [12], [73] that provide a rich source of ideas for future development. X.
Reference: [38] <author> Stren Htjsgaard and Bo Thiesson, </author> <title> "BIFROST | Block recursive models Induced From Relevant knowledge, Observations, and Statistical Techniques", </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> vol. 19, no. 2, </volume> <pages> pp. 155-175, </pages> <year> 1995. </year>
Reference-contexts: The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], [141], [142], [143], [37], <ref> [38] </ref>. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. <p> Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors [68], [111], [121], [37], [35], <ref> [38] </ref>, [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> Informative priors can include constraints and preferences on the structure of the network [121], [37], as well as preferences on the probabilities, and even using the expert to generate "imaginary data" [146]. An example in the language of chain graphs (an extension to Bayesian networks) is given by <ref> [38] </ref>. The potential for using Bayesian networks as a basis for knowledge refinement has been suggested by [121], [37], [111], [146], and in applications this offers an integrated approach to the development and maintenance of intelligent systems, long considered one of the potential fruits of artificial intelligence. IX.
Reference: [39] <author> R.D. Shachter and D. Heckerman, </author> <title> "Thinking backwards for knowledge acquisition", </title> <journal> AI Magazine, </journal> <volume> vol. 8, no. </volume> <month> Fall, </month> <pages> pp. 55-61, </pages> <year> 1987. </year>
Reference: [40] <author> E. Charniak, </author> <title> "Bayesian networks without tears", </title> <journal> AI Magazine, </journal> <volume> vol. 12, no. 4, </volume> <pages> pp. 50-63, </pages> <year> 1991. </year>
Reference: [41] <author> M. Henrion, J.S. Breese, and E.J. Horvitz, </author> <title> "Decision analysis and expert systems", </title> <journal> AI Magazine, </journal> <volume> vol. 12, no. 4, </volume> <pages> pp. 64-91, </pages> <year> 1991. </year>
Reference-contexts: Some of the work relevant to learning here comes from statisticians who generally have more experience [106], [107] and decision analysts who use these methods in constructing systems and working with experts <ref> [41] </ref>, [108].
Reference: [42] <author> J. Whittaker, </author> <title> Graphical Models in Applied Multivariate Statistics, </title> <publisher> Wiley, </publisher> <year> 1990. </year>
Reference-contexts: Notice how it is effected by both the prior and the likelihood. Many general algorithms exist for addressing parameter fitting problems of probabilistic networks: missing and latent variables, large samples, recursive or incremental techniques, special nodes, and subjective priors [26], [24], [81], [25], [23], <ref> [42] </ref> Table III lists the major techniques and their application. References given are introductions, new extensions or examples of their use, and are by no means a thorough list of references in the area. <p> Maximum likelihood and hypothesis-testing methods provide techniques for comparing one structure to another, "shall add an arc here?" "Is model S c better than model S f ?" This is done, for instance, using the likelihood ratio test <ref> [42] </ref>, [43]. Repeated use of this test can lead to problems because, by chance, hypothesis tests at the 95% confidence level should fail 1 in 20 times, and hundreds of such tests may need to be made when learning a network structure from data.
Reference: [43] <author> D. Edwards, </author> <title> Introduction to Graphical Modelling, </title> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Maximum likelihood and hypothesis-testing methods provide techniques for comparing one structure to another, "shall add an arc here?" "Is model S c better than model S f ?" This is done, for instance, using the likelihood ratio test [42], <ref> [43] </ref>. Repeated use of this test can lead to problems because, by chance, hypothesis tests at the 95% confidence level should fail 1 in 20 times, and hundreds of such tests may need to be made when learning a network structure from data. <p> B. Hypothesis testing approaches Hypothesis testing is the standard model selection strategy from classical statistics. For probabilistic networks methods are well developed and a variety of statistical software exists [28], <ref> [43] </ref>, [13]. As mentioned before, the problem is that this is only a viable approach if a small number of hypotheses are being tested. Clever or greedy search techniques can help here [128] by reducing the number of hypothesis tests required.
Reference: [44] <author> D. Heckerman, </author> <title> "Bayesian networks for knowledge representation and learning", in Advances in Knowledge Discovery and Data Mining, </title> <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. S. Uthurasamy, Eds. </editor> <publisher> MIT Press, </publisher> <year> 1995, </year> <note> An extended version is available as MSR-TR-95-06 from Microsoft Research, </note> <institution> Advanced Technology Division. </institution>
Reference: [45] <author> B.D. Ripley, </author> <title> Spatial Statistics, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference: [46] <author> S.L. Lauritzen, A.P. Dawid, B.N. Larsen, and H.-G. Leimer, </author> <title> "Independence properties of directed Markov fields", </title> <journal> Networks, </journal> <volume> vol. 20, </volume> <pages> pp. 491-505, </pages> <year> 1990. </year>
Reference: [47] <author> S. Lauritzen and N. Wermuth, </author> <title> "Graphical models for associations between variables, some of which are qualitative and some quantitative", </title> <journal> Annals of Statistics, </journal> <volume> vol. 17, </volume> <pages> pp. 31-57, </pages> <year> 1989. </year>
Reference: [48] <author> W.L. Buntine, </author> <title> "Chain graphs for learning", </title> <note> In Besnard and Hanks [158]. </note>
Reference: [49] <author> P. Tino, B.G. Horne, C.L., </author> <title> Giles P.C., and Collingwood, "Finite state machines and recurrent neural networks -automata and dynamical systems approaches", </title> <type> Technical Report UMIACS-TR-95-1, </type> <institution> Institute for Advanced Computer Studies, University of Maryland, </institution> <year> 1995, </year> <title> To be published in Progress in Neural Networks special volume on "Temporal Dynamics and Time-Varying Pattern Recognition,"(eds) J.E. </title> <editor> Dayhoff and O. Omid-var, </editor> <publisher> Ablex Publishing. </publisher>
Reference: [50] <author> N. Wermuth and S.L. Lauritzen, </author> <title> "On substantive research hypotheses, conditional independence graphs and graphical chain models", </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 51, no. 3, </volume> <year> 1989. </year>
Reference: [51] <author> R. Hanson, J. Stutz, and P. Cheeseman, </author> <title> "Bayesian classification with correlation and inheritance", </title> <booktitle> In IJCAI91 [162]. </booktitle>
Reference-contexts: Simple clustering algorithms learn Bayesian networks with a single latent/hidden variable at the root of the network. So these kinds of problems have been addressed in a limited sense for many years in the AI and statistics community [152]. A Bayesian method is [153], <ref> [51] </ref>. Likewise. missing values can be handled by the well known EM algorithm [76], or more accurately by Gibbs sampling [85]. More recent versions of these clustering algorithms search over possible structures as well [51]. Some algorithms do not fit neatly into the categories above. <p> A Bayesian method is [153], <ref> [51] </ref>. Likewise. missing values can be handled by the well known EM algorithm [76], or more accurately by Gibbs sampling [85]. More recent versions of these clustering algorithms search over possible structures as well [51]. Some algorithms do not fit neatly into the categories above. Learning Markov (undirected) networks from data is related to the early Boltzmann machine from neural networks [21].
Reference: [52] <author> T.L. Dean and M.P. Wellman, </author> <title> Planning and Control, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1991. </year>
Reference: [53] <author> W.B. </author> <title> Poland, Decision Analysis with Continuous and Discrete Variables: A Mixture Distribution Approach, </title> <type> PhD thesis, </type> <institution> Department of Engineering Economic Systems, Stanford University, Stanford, </institution> <address> CA, </address> <year> 1994. </year> <title> BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 15 </title>
Reference: [54] <author> P. Dagum, A. Galper, E. Horvitz, and A. Seiver, </author> <title> "Uncertain reasoning and forecasting", </title> <journal> International Journal of Forecasting, </journal> <note> 1994, Submitted. </note>
Reference-contexts: A full implementation in described in [94]. Extensions have been made to Gaussians and other popular nodes types for the Bayesian network [95]. When combined with some structure elicitation, techniques for parameter fitting can prove powerful in applications, for instance in dynamic models in the medical domain [96], <ref> [54] </ref>. V. Structure identification methods Ignoring the issue of sample size for the moment, a difficult question is whether particular network structures with or without latent variables are identifiable in the limit with probability 1.
Reference: [55] <author> J. Pearl, </author> <title> "Causal diagrams for empirical research", </title> <type> Technical Report R-218-L, </type> <institution> Cognitive Systems Laboratory, Computer Science Department, University of California, </institution> <address> Los Angeles, </address> <year> 1994, </year> <note> To appear in Biometrika. </note>
Reference: [56] <author> J. Pearl and T.S. Verma, </author> <title> "A theory of inferred causation", </title> <booktitle> in Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <editor> J.A. Allen, R. Fikes, and E. Sandewall, </editor> <booktitle> Eds., </booktitle> <pages> pp. 441-452. </pages> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], <ref> [56] </ref>, [99] and without [100], [101], [2], [102], and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3]. <p> In some cases, only a class of equivalent graphs can be reconstructed from data, and in other cases latent variables and their properties cannot be identified uniquely. These identification methods have lead to some of the earliest algorithms for learning structure from data [103], <ref> [56] </ref>, and a related approach that also combines cross validation to address model selection is [104]. Identification methods are also used in TETRAD II, the successor to TETRAD [12]. <p> Other early work on structure learning was often based on the identification results discussed in the previous section, for instance [103], <ref> [56] </ref>, [104], [117]. Problems like learning the structure of a Bayesian network suffer when samples are smaller. This happens because of over-fitting in the structure space, similar to over-fitting in the parameter space discussed previously.
Reference: [57] <author> J. Pearl, </author> <title> "On the identification of nonparametric structural equations", </title> <type> Technical Report R-207, </type> <institution> Cognitive Systems Laboratory, Computer Science Department, University of California, </institution> <address> Los Angeles, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], [56], [99] and without [100], [101], [2], [102], and more recently involving causality where variables are manipulated <ref> [57] </ref>. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3]. In some cases, only a class of equivalent graphs can be reconstructed from data, and in other cases latent variables and their properties cannot be identified uniquely.
Reference: [58] <author> D. Heckerman, </author> <title> "A Bayesian approach to learning causal networks", </title> <note> In Besnard and Hanks [158]. </note>
Reference-contexts: The assumption of prior equivalence sets these two priors equal, something not applicable if the network has a causal interpretation <ref> [58] </ref>. This gives a set of functional equations that the prior should satisfy. This basic theory and other properties of priors for Bayesian networks is discussed in [105], extending techniques presented in [37].
Reference: [59] <author> P. Spirtes, C. Meek, and T. Richardson, </author> <title> "Causal inference in the presence of latent variables and selection bias", </title> <booktitle> In Besnard and Hanks [158], </booktitle> <pages> pp. 499-506. </pages>
Reference-contexts: But Bayesian methods do equivalent things in the large sample case to the independence tests used by identification algorithms, and the strict ordering is not entirely necessary for the Bayesian algorithms [32], [37]. A variety of hybrid algorithms exist <ref> [59] </ref>, [104], [12], [73] that provide a rich source of ideas for future development. X. Constructing learning software For a variety of network structures with latent variables and different parametric nodes (Logistic, Poisson, and other forms), the BUGS program can generate Gibbs samplers automatically [154], [86].
Reference: [60] <author> A.P. Dawid and S.L. Lauritzen, </author> <title> "Hyper Markov laws in the statistical analysis of decomposable graphical models", </title> <journal> Annals of Statistics, </journal> <volume> vol. 21, no. 3, </volume> <pages> pp. 1272-1317, </pages> <year> 1993. </year>
Reference-contexts: Both informative priors [68], [111], [121], [37], [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], <ref> [60] </ref>, [37], [150]. For instance, consider structures S d and S e from Fig. 6.
Reference: [61] <author> W. Lam and F. Bacchus, </author> <title> "Using causal information and local measures to learn Bayesian networks", </title> <booktitle> In Heckerman and Mamdani [161], </booktitle> <pages> pp. 243-250. </pages>
Reference-contexts: Search bounds, for instance [134], are one area where the information complexity approach takes advantage of the techniques developed in information theory. Suzuki has developed a branch and bound technique for learning Bayesian networks based on information-theoretic bounds [73]. For Bayesian networks, MDL has been applied by <ref> [61] </ref>, [135], [136]. E. Resampling approaches Modern statistics has developed a variety of resampling schemes for addressing over-fitting in parametric situations 12 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, TO APPEAR (FINAL DRAFT) like learning networks. Resampling refers to the fact that pseudo-samples are created from the original sample.
Reference: [62] <author> D. Heckerman and D. Geiger, </author> <title> "Learning Bayesian networks: A unification for discrete and Gaussian domains", </title> <note> In Besnard and Hanks [158]. </note>
Reference: [63] <author> O.E. Barndorff-Nielsen, </author> <title> Information and exponential families in statistical theory, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1978. </year>
Reference: [64] <author> L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone, </author> <title> Classification and Regression Trees, </title> <publisher> Wadsworth, </publisher> <address> Belmont, </address> <year> 1984. </year>
Reference-contexts: The maximum likelihood parameter values are therefore said to over-fit the data. This is a well-known problem in supervised learning, for instance as addressed by pruning methods for classification trees <ref> [64] </ref>, [15]. The Bayesian Maximum a-posterior (MAP) approach extends the maximum likelihood approach by introducing a prior probability. Good introductions to this simplified Bayesian approach and some of its extensions can be found in [79], [80]. <p> The basic problem is that model selection focuses on choosing a single "best" model. For discrete variables at least, the problem of learning Bayesian networks from complete data is related to the problem of learning classification trees, exemplified by the CART algorithm <ref> [64] </ref> in statistics and ID3 and C4 in artificial intelligence [15]. This relationship holds because the sample likelihood for a binary classification tree can be represented as a product of independent binomial distributions, just like the sample likelihood for the Bayesian networks on binary variables described in Section III. <p> Both problems also have a similar parametric structure. The classification tree problem has a long history and has been studied from the perspective of applied statistics <ref> [64] </ref>, ar tificial intelligence [15], Bayesian statistics [118], minimum description length (MDL) [119], [120], genetic algorithms, and computational learning theory. An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in [121], and the relationship between the two approaches is discussed in [122].
Reference: [65] <author> H. Linhart and W. Zucchini, </author> <title> Model Selection, </title> <publisher> Wiley, </publisher> <year> 1986. </year>
Reference: [66] <author> S.L. Sclove, </author> <title> "Small-sample and large-sample statistical model selection criteria", </title> <booktitle> In Cheeseman and Oldford [159], </booktitle> <pages> pp. 31-39. </pages>
Reference-contexts: These approaches replace the sample likelihood by a modified score that is to be maximized. Examples include the penalized likelihood, Akaike information criteria (AIC), the Bayesian information criteria (BIC) and others <ref> [66] </ref>, [129].
Reference: [67] <author> A.E. Raftery, </author> <title> "Bayesian model selection in social research (with discussion by gelman & rubin, and hauser, and a rejoiner)", in Sociological Methodology 1995, </title> <editor> P.V. Marsden, Ed. Blackwells, </editor> <address> Cambridge, Mass., </address> <year> 1995. </year>
Reference-contexts: A comparable problem in the statistics literature is variable subset selection in regression. In this problem, one seeks to find a subset of variables on which to base a linear regression. The pitfalls of hypothesis testing in this context are discussed in <ref> [67] </ref>. The basic problem is that model selection focuses on choosing a single "best" model. <p> The BIC criteria and some related variations are asymtotically Bayesian but avoid specification of the prior, and are similar to variations of the minimum information complexity approaches described below. Examples for undirected probabilistic networks with the BIC criteria appear in <ref> [67] </ref>. D. Minimum information complexity approaches There are several different schools under the general rubric of minimizing some information complexity measure ("code length"), for instance minimum description length (MDL) [130], minimum message length [131], and minimum complexity [132].
Reference: [68] <author> D. Madigan and A.E. Raftery, </author> <title> "Model selection and accounting for model uncertainty in graphical models using Occam's window", </title> <journal> Journal of the American Statistical Association, </journal> <volume> vol. 89, </volume> <pages> pp. 1535-1546, </pages> <year> 1994. </year>
Reference-contexts: The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], <ref> [68] </ref>, [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], [37], [23], <p> [121], [111], [112], <ref> [68] </ref>, [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], [37], [23], and a thesis covering many of the issues is [36]. The full Bayesian approach is a predictive one: rather than returning the single "best" network, the aim might be to perform prediction or estimate probabilities for new cases. <p> Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], <ref> [68] </ref>, [143], [144], [145], [35], [146], [147]. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32]. <p> The key distinction between Bayesian and non-Bayesian methods is the use of priors. Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors <ref> [68] </ref>, [111], [121], [37], [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6.
Reference: [69] <author> D. Haussler, M. Kearns, H.S. Seung, and N. Tishby, </author> <title> "Rigorous learning curve bounds from statistical mechanics", </title> <booktitle> in Proceedings of the Seventh ACM Conference on Computational Learning Theory, </booktitle> <editor> M. Warmuth, Ed. </editor> <year> 1994, </year> <pages> pp. 76-87, </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: [70] <author> D. Haussler, </author> <title> "Decision theoretic generalizations of the PAC model for neural net and other learning applications", </title> <journal> Information and Control, </journal> <volume> vol. 100, no. 1, </volume> <pages> pp. 78-150, </pages> <month> Sept. </month> <year> 1992. </year>
Reference: [71] <author> D.M. Chickering, </author> <title> "Learning bayesian networks is np-complete", </title> <booktitle> Submitted to Proceedings of AI and Statistics, </booktitle> <year> 1995. </year>
Reference: [72] <author> K.-U. Hoffgen, </author> <title> "Learning and robust learning of product distributions", </title> <note> Research Report Nr. 464, revised May 1993, </note> <institution> Fach-bereich Informatik, Universitat Dortmund, </institution> <year> 1993. </year>
Reference: [73] <author> J. Suzuki, </author> <title> "On an efficient mdl learning procedure using branch and bound technique", </title> <type> Technical Report COMP95-27 (1995-06), </type> <institution> Institute of Electronics, Information and Communication Engineers, </institution> <year> 1995. </year>
Reference-contexts: Search bounds, for instance [134], are one area where the information complexity approach takes advantage of the techniques developed in information theory. Suzuki has developed a branch and bound technique for learning Bayesian networks based on information-theoretic bounds <ref> [73] </ref>. For Bayesian networks, MDL has been applied by [61], [135], [136]. E. Resampling approaches Modern statistics has developed a variety of resampling schemes for addressing over-fitting in parametric situations 12 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, TO APPEAR (FINAL DRAFT) like learning networks. <p> But Bayesian methods do equivalent things in the large sample case to the independence tests used by identification algorithms, and the strict ordering is not entirely necessary for the Bayesian algorithms [32], [37]. A variety of hybrid algorithms exist [59], [104], [12], <ref> [73] </ref> that provide a rich source of ideas for future development. X. Constructing learning software For a variety of network structures with latent variables and different parametric nodes (Logistic, Poisson, and other forms), the BUGS program can generate Gibbs samplers automatically [154], [86].
Reference: [74] <author> D. Edwards, </author> <title> "Hierarchical interaction models", </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 51, no. 3, </volume> <year> 1989. </year>
Reference: [75] <author> R. Jirousek and S. Preucil, </author> <title> "On the effective implementation of the iterative proportional fitting procedure", </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> vol. 19, no. 2, </volume> <pages> pp. 177-189, </pages> <year> 1995. </year>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network <ref> [75] </ref> mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93].
Reference: [76] <author> S.L. Lauritzen, </author> <title> "The EM algorithm for graphical association models with missing data", </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> vol. 19, no. 2, </volume> <pages> pp. 191-201, </pages> <year> 1995. </year>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], <ref> [76] </ref>, [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. <p> So these kinds of problems have been addressed in a limited sense for many years in the AI and statistics community [152]. A Bayesian method is [153], [51]. Likewise. missing values can be handled by the well known EM algorithm <ref> [76] </ref>, or more accurately by Gibbs sampling [85]. More recent versions of these clustering algorithms search over possible structures as well [51]. Some algorithms do not fit neatly into the categories above. Learning Markov (undirected) networks from data is related to the early Boltzmann machine from neural networks [21].
Reference: [77] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin, </author> <title> "Maximum likelihood from incomplete data via the EM algorithm", </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 39, </volume> <pages> pp. 1-38, </pages> <year> 1977. </year>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values <ref> [77] </ref>, [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies.
Reference: [78] <author> G. Casella and R.L. Berger, </author> <title> Statistical Inference, </title> <publisher> Wadsworth & Brooks/Cole, </publisher> <address> Belmont, CA, </address> <year> 1990. </year>
Reference-contexts: introduction see <ref> [78] </ref>). <p> the sense that a learning algorithm, given a sufficiently large sample, will invariably return a hypothesis (graphical structure and parameters) close to the "truth"? This question is formalized and addressed from several angles in computational learning theory [97] under the name of identification and learnability, as well as in statistics <ref> [78] </ref>, [26] under the name of consistency. This is the situation of N ! 1 in Fig. 7. In Bayesian networks, this question is confounded by the existence of equivalence classes of graphs (one example of a redundant model [78]) and by the use of hidden or latent variables. <p> the name of identification and learnability, as well as in statistics <ref> [78] </ref>, [26] under the name of consistency. This is the situation of N ! 1 in Fig. 7. In Bayesian networks, this question is confounded by the existence of equivalence classes of graphs (one example of a redundant model [78]) and by the use of hidden or latent variables. For instance, consider the networks given in Fig. 6 again. The Bayesian networks (d) and (e) have equivalent probability models but the Bayesian network for (f) is different. <p> If the "true" model has one single equivalent representative in the hypothesis space, then the maximum likelihood approach is consistent in the sense that in the limit of a large sample it will converge on this "truth" <ref> [78] </ref>. The maximum likelihood method can also be viewed as a simplification of most other approaches, so it is an important starting point for everyone.
Reference: [79] <author> D. Heckerman, </author> <title> "A tutorial on learning Bayesian networks", </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research, Advanced Technology Division, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: The Bayesian Maximum a-posterior (MAP) approach extends the maximum likelihood approach by introducing a prior probability. Good introductions to this simplified Bayesian approach and some of its extensions can be found in <ref> [79] </ref>, [80]. The approach places a probability distribution on the unknown parameters and reasons about them using the axioms of probability theory. The likelihood is augmented with a prior that gives the initial belief about before seeing any data. <p> In its full form the Bayesian approach requires specification of a prior probability (for a tutorial and a list of references, see [139]). A good general introduction to Bayesian methods for learning Bayesian networks can be found in <ref> [79] </ref>. Advanced introductions and reviews of Bayesian methods for learning can be found in [25], [26], [24]. The Bayesian approach has many different approximations.
Reference: [80] <author> R.A. Howard, </author> <title> "Decision analysis: perspectives on inference, decision, and experimentation", </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 58, no. 5, </volume> <year> 1970. </year>
Reference-contexts: The Bayesian Maximum a-posterior (MAP) approach extends the maximum likelihood approach by introducing a prior probability. Good introductions to this simplified Bayesian approach and some of its extensions can be found in [79], <ref> [80] </ref>. The approach places a probability distribution on the unknown parameters and reasons about them using the axioms of probability theory. The likelihood is augmented with a prior that gives the initial belief about before seeing any data.
Reference: [81] <author> R. Musick, J. Catlett, and S. Russell, </author> <title> "Decision theoretic sub-sampling for induction on large databases", </title> <booktitle> in Machine Learning: Proc. of the Tenth International Conference, </booktitle> <address> Amherst, Massachusetts, 1993, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Notice how it is effected by both the prior and the likelihood. Many general algorithms exist for addressing parameter fitting problems of probabilistic networks: missing and latent variables, large samples, recursive or incremental techniques, special nodes, and subjective priors [26], [24], <ref> [81] </ref>, [25], [23], [42] Table III lists the major techniques and their application. References given are introductions, new extensions or examples of their use, and are by no means a thorough list of references in the area.
Reference: [82] <author> A. Azevedo-Filho and R.D. Shachter, </author> <title> "Laplace's method approximations for probabilistic inference in belief networks with continuous variables", </title> <booktitle> In de Mantaras and Poole [160], </booktitle> <pages> pp. 28-36. </pages>
Reference-contexts: Variations of this method are popular in neural networks [91], having been a feature of early methods [92], and have proven to yield computational BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 9 Algorithm Problems Refs. MAP general [25] Laplace 2nd-order approx. [25], <ref> [82] </ref> EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies.
Reference: [83] <author> Bo Thiesson, </author> <title> "Accelerated quantification of Bayesian networks with incomplete data", </title> <booktitle> in Proceedings of First International Conference on Knowledge Discovery and Data Mining, </booktitle> <editor> U. M. Fayyad and R. Uthurusamy, Eds., </editor> <year> 1995, </year> <note> To appear. </note>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], <ref> [83] </ref> IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93].
Reference: [84] <author> Z. Ghahramani, </author> <title> "Factorial learning and the EM algorithm", </title> <booktitle> in Advances in Neural Information Processing Systems 7 (NIPS*94), </booktitle> <editor> G. Tesauro, D.S. Touretzky, and T.K. Leen, Eds. </editor> <booktitle> 1994, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments <ref> [84] </ref>, [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93].
Reference: [85] <author> J. York and D. Madigan, </author> <title> "Markov chain Monte Carlo methods for hierarchical Bayesian expert systems", </title> <booktitle> In Cheeseman and Oldford [159], </booktitle> <pages> pp. 445-452. </pages>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments <ref> [85] </ref>, [86] MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93]. <p> MCMC methods can be used for parameter fitting, to sample different network parameters, and for structure learning, to sample from different possible probabilistic network structures. Use of MCMC methods for learning probabilistic networks is discussed in <ref> [85] </ref>, [144], [147], [146], [23]. Madigan, Gavrin and Raftery [146] refer to the use of MCMC methods for averaging over multiple probabilistic networks|the full predictive approach|as Markov Chain Monte Carlo Model Composition (MC 3 ). The key distinction between Bayesian and non-Bayesian methods is the use of priors. <p> So these kinds of problems have been addressed in a limited sense for many years in the AI and statistics community [152]. A Bayesian method is [153], [51]. Likewise. missing values can be handled by the well known EM algorithm [76], or more accurately by Gibbs sampling <ref> [85] </ref>. More recent versions of these clustering algorithms search over possible structures as well [51]. Some algorithms do not fit neatly into the categories above. Learning Markov (undirected) networks from data is related to the early Boltzmann machine from neural networks [21].
Reference: [86] <author> W.R. Gilks, A. Thomas, </author> <title> and D.J. Spiegelhalter, "A language and program for complex Bayesian modelling", </title> <journal> The Statistician, </journal> <volume> vol. 43, </volume> <pages> pp. 169-178, </pages> <year> 1993. </year>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], <ref> [86] </ref> MCMC approximate moments [87], [88] TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93]. <p> X. Constructing learning software For a variety of network structures with latent variables and different parametric nodes (Logistic, Poisson, and other forms), the BUGS program can generate Gibbs samplers automatically [154], <ref> [86] </ref>. This effectively allows data analysis algorithms to be compiled from specifications given as a probabilistic network, and the technique addresses a number of non-trivial data analysis problems [155], [86]. <p> with latent variables and different parametric nodes (Logistic, Poisson, and other forms), the BUGS program can generate Gibbs samplers automatically [154], <ref> [86] </ref>. This effectively allows data analysis algorithms to be compiled from specifications given as a probabilistic network, and the technique addresses a number of non-trivial data analysis problems [155], [86]. Unfortunately, Gibbs sampling without much thought to domain specific optimization can be time intensive because convergence may be slow, so other methods need to be developed to make this approach more widely applicable.
Reference: [87] <author> R.M. Neal, </author> <title> "Probabilistic inference using Markov chain Monte Carlo methods", </title> <type> Technical Report CRG-TR-93-1, </type> <institution> Dept. of Computer Science, University of Toronto, </institution> <year> 1993. </year>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments <ref> [87] </ref>, [88] TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93]. <p> A general Bayesian algorithm family for inference that applies in any context, parameter fitting or structure learning, is the Markov Chain Monte Carlo (MCMC) family of algorithms. An introduction is given in [149], [23], and an extensive review is given by <ref> [87] </ref>. This family uses the following kind of trick. Suppose we wish to sample from the distribution p (A; B; C). In general this might be a complex distribution and no convenient sampling algorithm may be known.
Reference: [88] <author> Radford M. Neal, </author> <title> Bayesian Learning for Neural Networks, </title> <type> PhD thesis, </type> <institution> University of Toronto, Graduate Department of Computer Science, </institution> <month> October </month> <year> 1994, </year> <note> Available via FTP from ftp://cs.toronto.edu/pub/radford/thesis.ps.Z. </note>
Reference-contexts: MAP general [25] Laplace 2nd-order approx. [25], [82] EM missing and hidden values [77], [76], [83] IPF undirected network [75] mean field approximate moments [84], [22] Gibbs approximate moments [85], [86] MCMC approximate moments [87], <ref> [88] </ref> TABLE III Some general algorithms for parameter fitting savings in many studies. An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93]. <p> They can even be used for instance, to estimate posterior predictions when learning with complex parametric systems such as sigmoidal feed-forward neural networks <ref> [88] </ref>.
Reference: [89] <author> P. McCullagh and J.A. Nelder, </author> <title> Generalized Linear Models, </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <note> second edition, </note> <year> 1989. </year>
Reference-contexts: Used in conjunction with these methods are a large number of optimization techniques, for finding a MAP, or computing the various quantities used in the Laplace approximation. Several optimization techniques are specific to parameter fitting in learning. This includes the Fisher Scoring method <ref> [89] </ref>, which is an approximate Newton-Raphson algorithm, and stochastic optimization which computes gradients on subsamples or individual cases at a time [90].
Reference: [90] <author> H. Robbins and S. Munro, </author> <title> "A stochastic optimization method", </title> <journal> Annals of Mathematical Statistics, </journal> <volume> vol. 22, </volume> <pages> pp. 400-407, </pages> <year> 1951. </year>
Reference-contexts: Several optimization techniques are specific to parameter fitting in learning. This includes the Fisher Scoring method [89], which is an approximate Newton-Raphson algorithm, and stochastic optimization which computes gradients on subsamples or individual cases at a time <ref> [90] </ref>. Variations of this method are popular in neural networks [91], having been a feature of early methods [92], and have proven to yield computational BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 9 Algorithm Problems Refs.
Reference: [91] <author> M.F. Mtller, </author> <title> Efficient Training of Feed-Forward Neural Networks, </title> <type> PhD thesis, </type> <institution> Aarhus University, Aarhus, Denmark, </institution> <year> 1993. </year>
Reference-contexts: Several optimization techniques are specific to parameter fitting in learning. This includes the Fisher Scoring method [89], which is an approximate Newton-Raphson algorithm, and stochastic optimization which computes gradients on subsamples or individual cases at a time [90]. Variations of this method are popular in neural networks <ref> [91] </ref>, having been a feature of early methods [92], and have proven to yield computational BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 9 Algorithm Problems Refs.
Reference: [92] <author> David E. Rumelhart, James L. McClelland, </author> <title> and the PDP Research Group, </title> <editor> Eds., </editor> <booktitle> Parallel Distributed Processing, </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: This includes the Fisher Scoring method [89], which is an approximate Newton-Raphson algorithm, and stochastic optimization which computes gradients on subsamples or individual cases at a time [90]. Variations of this method are popular in neural networks [91], having been a feature of early methods <ref> [92] </ref>, and have proven to yield computational BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 9 Algorithm Problems Refs.
Reference: [93] <author> D.J. Spiegelhalter and S.L. Lauritzen, </author> <title> "Sequential updating of conditional probabilities on directed graphical structures", </title> <journal> Networks, </journal> <volume> vol. 20, </volume> <pages> pp. 579-605, </pages> <year> 1990. </year>
Reference-contexts: An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in <ref> [93] </ref>. This uses Bayesian methods to overcome the problems of sparse data, by defining a Dirichlet prior of entries for the probability tables. A full implementation in described in [94]. Extensions have been made to Gaussians and other popular nodes types for the Bayesian network [95].
Reference: [94] <author> K.G. Olesen, S.L. Lauritzen, and F.V. Jensen, "aHUGIN: </author> <title> A systems creating adaptive causal probabilistic networks", </title> <editor> In Dubois et al. </editor> <volume> [163], </volume> <pages> pp. 223-229. </pages>
Reference-contexts: An extension of parameter fitting to handle sequential (on-line) learning and missing data is described in [93]. This uses Bayesian methods to overcome the problems of sparse data, by defining a Dirichlet prior of entries for the probability tables. A full implementation in described in <ref> [94] </ref>. Extensions have been made to Gaussians and other popular nodes types for the Bayesian network [95]. When combined with some structure elicitation, techniques for parameter fitting can prove powerful in applications, for instance in dynamic models in the medical domain [96], [54]. V.
Reference: [95] <author> F.J. Diez, </author> <title> "Parameter adjustment in Bayesian networks. the generalized noisy OR-gate", </title> <booktitle> In Heckerman and Mamdani [161], </booktitle> <pages> pp. 99-105. </pages>
Reference-contexts: This uses Bayesian methods to overcome the problems of sparse data, by defining a Dirichlet prior of entries for the probability tables. A full implementation in described in [94]. Extensions have been made to Gaussians and other popular nodes types for the Bayesian network <ref> [95] </ref>. When combined with some structure elicitation, techniques for parameter fitting can prove powerful in applications, for instance in dynamic models in the medical domain [96], [54]. V.
Reference: [96] <author> G.M. Provan, </author> <title> "Tradeoffs in constructing and evaluating temporal influence diagrams", </title> <booktitle> In Heckerman and Mamdani [161], </booktitle> <pages> pp. 40-47. </pages>
Reference-contexts: A full implementation in described in [94]. Extensions have been made to Gaussians and other popular nodes types for the Bayesian network [95]. When combined with some structure elicitation, techniques for parameter fitting can prove powerful in applications, for instance in dynamic models in the medical domain <ref> [96] </ref>, [54]. V. Structure identification methods Ignoring the issue of sample size for the moment, a difficult question is whether particular network structures with or without latent variables are identifiable in the limit with probability 1.
Reference: [97] <author> S. Ben-David and M. Jacovi, </author> <title> "On learning in the limit and non-uniform (*; ffi)-learning", </title> <booktitle> in Proceedings of the Sixth ACM Workshop on Computational Learning Theory, </booktitle> <editor> L. Pitt, Ed. </editor> <year> 1993, </year> <pages> pp. 209-217, </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: estimate various probabilities, can the "true" probabilistic network be reconstructed at all in the sense that a learning algorithm, given a sufficiently large sample, will invariably return a hypothesis (graphical structure and parameters) close to the "truth"? This question is formalized and addressed from several angles in computational learning theory <ref> [97] </ref> under the name of identification and learnability, as well as in statistics [78], [26] under the name of consistency. This is the situation of N ! 1 in Fig. 7.
Reference: [98] <author> P. Spirtes and T. Verma, </author> <title> "Equivalence of causal models with latent variables", </title> <type> Report CMU-PHIL-33, </type> <institution> Philosophy, Carnegie Mellon University, </institution> <year> 1992. </year>
Reference-contexts: Therefore, Bayesian networks (d) and (e) have equivalent sample likelihoods and cannot be distinguished from data without some additional criteria or knowledge, whereas the Bayesian network (f) could be identified from data alone. A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables <ref> [98] </ref>, [56], [99] and without [100], [101], [2], [102], and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3].
Reference: [99] <author> T. Verma and J. Pearl, </author> <title> "An algorithm for deciding if a set of observed independencies has a causal explanation", </title> <editor> In Dubois et al. </editor> <volume> [163]. </volume>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], [56], <ref> [99] </ref> and without [100], [101], [2], [102], and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3].
Reference: [100] <author> M. Frydenberg, </author> <title> "The chain graph Markov property", </title> <journal> Scandi-navian Journal of Statistics, </journal> <volume> vol. 17, </volume> <pages> pp. 333-353, </pages> <year> 1990. </year>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], [56], [99] and without <ref> [100] </ref>, [101], [2], [102], and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3].
Reference: [101] <author> D. Geiger, T. Verma, and J. Pearl, </author> <title> "Identifying independence in Bayesian networks", </title> <journal> Networks, </journal> <volume> vol. 20, </volume> <pages> pp. 507-534, </pages> <year> 1990. </year>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], [56], [99] and without [100], <ref> [101] </ref>, [2], [102], and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3].
Reference: [102] <author> S.A. Andersson, D. Madigan, and M.D. Perlman, </author> <title> "On the Markov equivalence of chain graphs, undirected graphs, and acyclic digraphs", </title> <type> Technical Report #281, </type> <institution> Department of Statistics, University of Washington, </institution> <address> Seattle, WA, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: A theoretical tool used to analyze identifiability is the equivalence of graphical models with latent variables [98], [56], [99] and without [100], [101], [2], <ref> [102] </ref>, and more recently involving causality where variables are manipulated [57]. A thorough treatment of the issues of equivalence, latent variables, and causality appears in [3].
Reference: [103] <author> P. Spirtes and C. Glymour, </author> <title> "An algorithm for fast recovery of sparse causal graphs", </title> <journal> Social Science Computing Reviews, </journal> <volume> vol. 9, no. 1, </volume> <pages> pp. 62-72, </pages> <year> 1991. </year>
Reference-contexts: In some cases, only a class of equivalent graphs can be reconstructed from data, and in other cases latent variables and their properties cannot be identified uniquely. These identification methods have lead to some of the earliest algorithms for learning structure from data <ref> [103] </ref>, [56], and a related approach that also combines cross validation to address model selection is [104]. Identification methods are also used in TETRAD II, the successor to TETRAD [12]. <p> Other early work on structure learning was often based on the identification results discussed in the previous section, for instance <ref> [103] </ref>, [56], [104], [117]. Problems like learning the structure of a Bayesian network suffer when samples are smaller. This happens because of over-fitting in the structure space, similar to over-fitting in the parameter space discussed previously.
Reference: [104] <author> R.M. Fung and S.L. Crawford, </author> <title> "A system for induction of probabilistic models", </title> <journal> in Eighth National Conference on Artificial 16 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, </journal> <note> TO APPEAR (FINAL DRAFT) Intelligence, </note> <institution> Boston, Massachusetts, </institution> <year> 1990, </year> <journal> American Association for Artificial Intelligence, </journal> <pages> pp. 762-779. </pages>
Reference-contexts: These identification methods have lead to some of the earliest algorithms for learning structure from data [103], [56], and a related approach that also combines cross validation to address model selection is <ref> [104] </ref>. Identification methods are also used in TETRAD II, the successor to TETRAD [12]. The theory of network identification from data and network equivalence are a precursor to techniques for learning from medium sized samples of Fig. 7. <p> Other early work on structure learning was often based on the identification results discussed in the previous section, for instance [103], [56], <ref> [104] </ref>, [117]. Problems like learning the structure of a Bayesian network suffer when samples are smaller. This happens because of over-fitting in the structure space, similar to over-fitting in the parameter space discussed previously. <p> An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in [121], and the relationship between the two approaches is discussed in [122]. Another adaptation, which is not quite as direct, is the Constructor algorithm of <ref> [104] </ref> which adapts the cost-complexity technique from the CART algorithm for trees. There are a variety of heuristic techniques developed for trees, including the handling of missing values [123] and the discretization of real-valued attributes [124], which have yet to find their way into algorithms for probabilistic networks. VIII. <p> Resampling refers to the fact that pseudo-samples are created from the original sample. A popular approach is cross validation, applied by <ref> [104] </ref>. Resampling schemes have been used to great success in applied multivariate statistics, see for instance a tutorial in [137]. <p> But Bayesian methods do equivalent things in the large sample case to the independence tests used by identification algorithms, and the strict ordering is not entirely necessary for the Bayesian algorithms [32], [37]. A variety of hybrid algorithms exist [59], <ref> [104] </ref>, [12], [73] that provide a rich source of ideas for future development. X. Constructing learning software For a variety of network structures with latent variables and different parametric nodes (Logistic, Poisson, and other forms), the BUGS program can generate Gibbs samplers automatically [154], [86].
Reference: [105] <author> D. Geiger and D. Heckerman, </author> <title> "A characterization of the Dirichlet distribution with application to learning Bayesian networks", </title> <note> In Besnard and Hanks [158]. </note>
Reference-contexts: Network equivalence is an important concept used in some Bayesian techniques for learning Bayesian networks from data, used in advanced work on priors for Bayesian networks <ref> [105] </ref>, [37]. This will be discussed later. VI. <p> Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in <ref> [105] </ref>. Good summaries of this line of work can be found in [111], [68], [144], [37], [23], and a thesis covering many of the issues is [36]. <p> The assumption of prior equivalence sets these two priors equal, something not applicable if the network has a causal interpretation [58]. This gives a set of functional equations that the prior should satisfy. This basic theory and other properties of priors for Bayesian networks is discussed in <ref> [105] </ref>, extending techniques presented in [37]. The ability to use a variety of informative, subjective priors for Bayesian networks is one of their strengths.
Reference: [106] <author> R.L. Winkler, </author> <title> "The quantification of judgment: Some methodological suggestions", </title> <journal> SIAM Journal on Computing, </journal> <volume> vol. 62, </volume> <pages> pp. 1105-1120, </pages> <year> 1967. </year>
Reference-contexts: Some of the work relevant to learning here comes from statisticians who generally have more experience <ref> [106] </ref>, [107] and decision analysts who use these methods in constructing systems and working with experts [41], [108].
Reference: [107] <author> D.J. Spiegelhalter, R.C.G. Bull, and K. Bull, </author> <title> "Assessment, criticism and improvement of imprecise subjective probabilities for a medical expert system", </title> <editor> In Henrion et al. </editor> <volume> [164], </volume> <pages> pp. 285-294. </pages>
Reference-contexts: Some of the work relevant to learning here comes from statisticians who generally have more experience [106], <ref> [107] </ref> and decision analysts who use these methods in constructing systems and working with experts [41], [108].
Reference: [108] <author> M.G. Morgan and M. Henrion, </author> <title> Uncertainty: A Guide to Dealing with Uncertainty in Quantitative Risk and Policy Analysis, </title> <publisher> Cambridge University Press, </publisher> <year> 1990. </year>
Reference-contexts: Some of the work relevant to learning here comes from statisticians who generally have more experience [106], [107] and decision analysts who use these methods in constructing systems and working with experts [41], <ref> [108] </ref>.
Reference: [109] <author> D. Kahneman, P. Slovic, and A. Tversky, </author> <title> Judgement under Uncertainty: Heuristics and Biases, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1982. </year>
Reference-contexts: complemented with prior knowledge and constraints if reliable and useful results are to be obtained. * Prior knowledge can often only be obtained from the domain experts by the manual process of knowledge elicitation. * Domain experts can be poor at judging their own limitations and capabilities, and estimating probabilities <ref> [109] </ref>. One of the common mistakes of beginners is to assume that the expert's claims are valid.
Reference: [110] <author> P. Langley and H.A. Simon, </author> <title> "Applications of machine learning and rule induction", </title> <journal> CACM, </journal> <note> 1995, To appear. </note>
Reference-contexts: A domain expert may be needed just to circumscribe the learning component: which variables might be used, what is being predicted from what, and so forth. Sometimes this is crucial to success, and the learning algorithm used is almost incidental <ref> [110] </ref>. A number of techniques exist at the interface of learning and knowledge acquisition. Diagnostics are measures used to evaluate particular model assumptions [111], [112] [113].
Reference: [111] <author> D.J. Spiegelhalter, A.P. Dawid, S.L. Lauritzen, and R.G. Cow-ell, </author> <title> "Bayesian analysis in expert systems", </title> <journal> Statistical Science, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 219-283, </pages> <year> 1993. </year>
Reference-contexts: Sometimes this is crucial to success, and the learning algorithm used is almost incidental [110]. A number of techniques exist at the interface of learning and knowledge acquisition. Diagnostics are measures used to evaluate particular model assumptions <ref> [111] </ref>, [112] [113]. <p> The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], <ref> [111] </ref>, [112], [68], [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], <p> [35], [121], <ref> [111] </ref>, [112], [68], [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], [144], [37], [23], and a thesis covering many of the issues is [36]. The full Bayesian approach is a predictive one: rather than returning the single "best" network, the aim might be to perform prediction or estimate probabilities for new cases. <p> Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], <ref> [111] </ref>, [32]. A general Bayesian algorithm family for inference that applies in any context, parameter fitting or structure learning, is the Markov Chain Monte Carlo (MCMC) family of algorithms. An introduction is given in [149], [23], and an extensive review is given by [87]. <p> Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors [68], <ref> [111] </ref>, [121], [37], [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> An example in the language of chain graphs (an extension to Bayesian networks) is given by [38]. The potential for using Bayesian networks as a basis for knowledge refinement has been suggested by [121], [37], <ref> [111] </ref>, [146], and in applications this offers an integrated approach to the development and maintenance of intelligent systems, long considered one of the potential fruits of artificial intelligence. IX. More on Learning Structure An exact algorithm for handling incomplete data or missing values can be found in [151].
Reference: [112] <author> D.J. Spiegelhalter and R.G. Cowell, </author> <title> "Learning in probabilistic expert systems", </title> <editor> In Bernardo et al. </editor> <volume> [165], </volume> <pages> pp. 447-465. </pages>
Reference-contexts: Sometimes this is crucial to success, and the learning algorithm used is almost incidental [110]. A number of techniques exist at the interface of learning and knowledge acquisition. Diagnostics are measures used to evaluate particular model assumptions [111], <ref> [112] </ref> [113]. <p> The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], <ref> [112] </ref>, [68], [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105].
Reference: [113] <author> R.G. Cowell, </author> <title> A.P. Dawid, and D.J. Spiegelhalter, "Sequential model criticism in probabilistic expert systems", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 15, </volume> <pages> pp. 209-219, </pages> <year> 1993. </year>
Reference-contexts: Sometimes this is crucial to success, and the learning algorithm used is almost incidental [110]. A number of techniques exist at the interface of learning and knowledge acquisition. Diagnostics are measures used to evaluate particular model assumptions [111], [112] <ref> [113] </ref>.
Reference: [114] <author> K.B. Laskey, </author> <title> "Sensitivity analysis for probability assessments in Bayesian networks", </title> <booktitle> In Heckerman and Mamdani [161], </booktitle> <pages> pp. 136-142. </pages>
Reference-contexts: Sometimes this is crucial to success, and the learning algorithm used is almost incidental [110]. A number of techniques exist at the interface of learning and knowledge acquisition. Diagnostics are measures used to evaluate particular model assumptions [111], [112] [113]. Sensitivity analysis <ref> [114] </ref> measures the sensitivity of the results of a study to the model assumptions, using the same techniques taught to engineers everywhere: wiggle the inputs to the model (in the case of learning, this means the constraints and priors) and watch how the output of 10 IEEE TRANSACTIONS ON KNOWLEDGE AND
Reference: [115] <author> C.K. Chow and C.N. Liu, </author> <title> "Approximating discrete probability distributions with dependence trees", </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 14, </volume> <pages> pp. 462-467, </pages> <year> 1968. </year>
Reference-contexts: VII. Learning structure from data The earliest result in structure learning was the Chow and Liu algorithm for learning trees from data <ref> [115] </ref>. This algorithm learns a Bayesian network whose shape is a tree. If there are k variables, then there are O (k 2 ) trees, much less than the exponential number of Bayesian networks.
Reference: [116] <author> E.H. Herskovits and G.F. Cooper, "Kutato: </author> <title> An entropy-driven system for construction of probabilistic expert systems from databases", </title> <booktitle> In Bonissone [157], </booktitle> <pages> pp. 54-62. </pages>
Reference-contexts: Furthermore, the computational complexity of searching for a tree shaped network requires at most a quadratic number of network evaluations. Herskovits and Cooper <ref> [116] </ref> demonstrated on a problem of significant size that complex structure learning was possible from quite reasonable sample sizes (in their case, about 10,000), despite being faced with a potentially exponential sample complexity and an NP-complete search problem. <p> The results from computational learning theory for bounding the onset of the large sample phase are useful for deciding when to do this. For Bayesian networks, the maximum likelihood approach has been applied by [127], <ref> [116] </ref>. The paper by Herskovits and Cooper was the major breakthrough in learning Bayesian networks. It was clear from this paper that MDL and Bayesian methods, which extend the maximum likelihood approach, could be applied in all their detail. B.
Reference: [117] <author> S. Srinivas, S. Russell, and A. Agogino, </author> <title> "Automated construction of sparse Bayesian networks", </title> <editor> In Henrion et al. </editor> <volume> [164], </volume> <pages> pp. 295-308. </pages>
Reference-contexts: Other early work on structure learning was often based on the identification results discussed in the previous section, for instance [103], [56], [104], <ref> [117] </ref>. Problems like learning the structure of a Bayesian network suffer when samples are smaller. This happens because of over-fitting in the structure space, similar to over-fitting in the parameter space discussed previously.
Reference: [118] <author> W.L. Buntine, </author> <title> "Learning classification trees", </title> <booktitle> In Hand [166], </booktitle> <pages> pp. 182-201. </pages>
Reference-contexts: Both problems also have a similar parametric structure. The classification tree problem has a long history and has been studied from the perspective of applied statistics [64], ar tificial intelligence [15], Bayesian statistics <ref> [118] </ref>, minimum description length (MDL) [119], [120], genetic algorithms, and computational learning theory. An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in [121], and the relationship between the two approaches is discussed in [122].
Reference: [119] <author> J. Rissanen, </author> <title> Stochastic Complexity in Statistical Enquiry, </title> <publisher> World Scientific, </publisher> <year> 1989. </year>
Reference-contexts: Both problems also have a similar parametric structure. The classification tree problem has a long history and has been studied from the perspective of applied statistics [64], ar tificial intelligence [15], Bayesian statistics [118], minimum description length (MDL) <ref> [119] </ref>, [120], genetic algorithms, and computational learning theory. An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in [121], and the relationship between the two approaches is discussed in [122].
Reference: [120] <author> C.S. Wallace and J.D. Patrick, </author> <title> "Coding decision trees", </title> <journal> Machine Learning, </journal> <volume> vol. 11, </volume> <pages> pp. 7-22, </pages> <year> 1993. </year>
Reference-contexts: Both problems also have a similar parametric structure. The classification tree problem has a long history and has been studied from the perspective of applied statistics [64], ar tificial intelligence [15], Bayesian statistics [118], minimum description length (MDL) [119], <ref> [120] </ref>, genetic algorithms, and computational learning theory. An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in [121], and the relationship between the two approaches is discussed in [122].
Reference: [121] <author> W.L. Buntine, </author> <title> "Theory refinement of Bayesian networks", </title> <booktitle> in Uncertainty in Artificial Intelligence: Proceedings of the Seventh Conference, </booktitle> <editor> B.D. D'Ambrosio, P. Smets, and P.P. Bonis-sone, Eds., </editor> <address> Los Angeles, CA, </address> <year> 1991. </year>
Reference-contexts: An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in <ref> [121] </ref>, and the relationship between the two approaches is discussed in [122]. Another adaptation, which is not quite as direct, is the Constructor algorithm of [104] which adapts the cost-complexity technique from the CART algorithm for trees. <p> The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], <ref> [121] </ref>, [111], [112], [68], [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. <p> Bayesian methods for learning probabilistic networks in this more general sense can be found in <ref> [121] </ref>, [68], [143], [144], [145], [35], [146], [147]. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32]. <p> Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors [68], [111], <ref> [121] </ref>, [37], [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> Both informative priors [68], [111], <ref> [121] </ref>, [37], [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> The ability to use a variety of informative, subjective priors for Bayesian networks is one of their strengths. Informative priors can include constraints and preferences on the structure of the network <ref> [121] </ref>, [37], as well as preferences on the probabilities, and even using the expert to generate "imaginary data" [146]. An example in the language of chain graphs (an extension to Bayesian networks) is given by [38]. <p> An example in the language of chain graphs (an extension to Bayesian networks) is given by [38]. The potential for using Bayesian networks as a basis for knowledge refinement has been suggested by <ref> [121] </ref>, [37], [111], [146], and in applications this offers an integrated approach to the development and maintenance of intelligent systems, long considered one of the potential fruits of artificial intelligence. IX. More on Learning Structure An exact algorithm for handling incomplete data or missing values can be found in [151]. <p> Some algorithms do not fit neatly into the categories above. Learning Markov (undirected) networks from data is related to the early Boltzmann machine from neural networks [21]. Also the earlier Bayesian methods seemed to require as input a strict ordering of variables [35], <ref> [121] </ref>, whereas the identification algorithms did not require this. So one thought is a combination of Bayesian with identification algorithms [33].
Reference: [122] <author> W.L. Buntine, </author> <title> "Classifiers: A theoretical and empirical study", </title> <booktitle> In IJCAI91 [162]. </booktitle>
Reference-contexts: An adaptation of a successful tree algorithm to an algorithm for learning Bayesian networks appears in [121], and the relationship between the two approaches is discussed in <ref> [122] </ref>. Another adaptation, which is not quite as direct, is the Constructor algorithm of [104] which adapts the cost-complexity technique from the CART algorithm for trees.
Reference: [123] <author> J.R. Quinlan, </author> <title> "Unknown attribute values in induction", </title> <booktitle> in Proceedings of the Sixth International Machine Learning Workshop, A.M. </booktitle> <editor> Segre, Ed., </editor> <publisher> Cornell, </publisher> <address> New York, 1989, </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Another adaptation, which is not quite as direct, is the Constructor algorithm of [104] which adapts the cost-complexity technique from the CART algorithm for trees. There are a variety of heuristic techniques developed for trees, including the handling of missing values <ref> [123] </ref> and the discretization of real-valued attributes [124], which have yet to find their way into algorithms for probabilistic networks. VIII. Statistical Methodology In most work on learning structure, researchers have applied standard statistical methodology for fitting models and handling over-fitting.
Reference: [124] <author> U.M. Fayyad and K.B. Irani, </author> <title> "Multi-valued interval discretiza-tion of continuous-valued attributes for classification learning", </title> <booktitle> in International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France, </address> <year> 1993, </year> <title> IJCAI, </title> <publisher> Inc., </publisher> <pages> pp. 1022-1027, </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Another adaptation, which is not quite as direct, is the Constructor algorithm of [104] which adapts the cost-complexity technique from the CART algorithm for trees. There are a variety of heuristic techniques developed for trees, including the handling of missing values [123] and the discretization of real-valued attributes <ref> [124] </ref>, which have yet to find their way into algorithms for probabilistic networks. VIII. Statistical Methodology In most work on learning structure, researchers have applied standard statistical methodology for fitting models and handling over-fitting. It is therefore appropriate to discuss these standard methodologies, done so in this section.
Reference: [125] <author> Ron Kohavi, George John, Richard Long, David Manley, and Karl Pfleger, "MLC++: </author> <title> A machine learning library in C++", </title> <booktitle> in Tools with Artificial Intelligence. </booktitle> <year> 1994, </year> <pages> pp. 740-743, </pages> <note> IEEE Computer Society Press, Available by anonymous ftp from: starry.Stanford.EDU:pub/ronnyk/mlc/toolsmlc.ps. </note>
Reference-contexts: In general, the many different structure learning methods are extensions of the general algorithms summarized in Table III. In some cases, this can be as simple as placing a model selection wrapper around a parameter fitting system <ref> [125] </ref>, in other cases more sophistication is layered on top. It is perhaps unfortunate that so many different, competing statistical methodologies exist to address essentially the same problem.
Reference: [126] <author> S. Kullback, </author> <title> Information Theory and Statistics, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1959. </year>
Reference-contexts: These two approaches are equivalent <ref> [126] </ref>, and they are also well known to suffer from over-fitting, as discussed in Section IV.
Reference: [127] <author> D. Geiger, </author> <title> "An entropy-based learning algorithm of Bayesian conditional trees", </title> <editor> In Dubois et al. </editor> <volume> [163], </volume> <pages> pp. 92-97. </pages>
Reference-contexts: The results from computational learning theory for bounding the onset of the large sample phase are useful for deciding when to do this. For Bayesian networks, the maximum likelihood approach has been applied by <ref> [127] </ref>, [116]. The paper by Herskovits and Cooper was the major breakthrough in learning Bayesian networks. It was clear from this paper that MDL and Bayesian methods, which extend the maximum likelihood approach, could be applied in all their detail. B.
Reference: [128] <author> D. Edwards and T. Havranek, </author> <title> "A fast model selection procedure for large families of models", </title> <journal> Journal of the American Statistical Association, </journal> <volume> vol. 82, no. 397, </volume> <pages> pp. 205-211, </pages> <year> 1987. </year>
Reference-contexts: For probabilistic networks methods are well developed and a variety of statistical software exists [28], [43], [13]. As mentioned before, the problem is that this is only a viable approach if a small number of hypotheses are being tested. Clever or greedy search techniques can help here <ref> [128] </ref> by reducing the number of hypothesis tests required. Another way for thinking about this is to deal with multiple hypotheses: let hypothesis testing return a set of possible models rather than expecting it to isolate a single one [128]. <p> Clever or greedy search techniques can help here <ref> [128] </ref> by reducing the number of hypothesis tests required. Another way for thinking about this is to deal with multiple hypotheses: let hypothesis testing return a set of possible models rather than expecting it to isolate a single one [128]. This strategy then resembles a Bayesian approach where multiple models are considered. This is discussed in the context of probabilistic networks below. C.
Reference: [129] <author> R.B. Poland and R.D. Shachter, </author> <title> "Three approaches to probability model selection", </title> <booktitle> In de Mantaras and Poole [160], </booktitle> <pages> pp. 478-483. </pages>
Reference-contexts: These approaches replace the sample likelihood by a modified score that is to be maximized. Examples include the penalized likelihood, Akaike information criteria (AIC), the Bayesian information criteria (BIC) and others [66], <ref> [129] </ref>.
Reference: [130] <author> J. Rissanen, </author> <title> "Stochastic complexity", </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 49, no. 3, </volume> <pages> pp. 223-239, </pages> <year> 1987. </year>
Reference-contexts: Examples for undirected probabilistic networks with the BIC criteria appear in [67]. D. Minimum information complexity approaches There are several different schools under the general rubric of minimizing some information complexity measure ("code length"), for instance minimum description length (MDL) <ref> [130] </ref>, minimum message length [131], and minimum complexity [132]. A simple approximation for MDL is equivalent to the BIC above, but other variations involve statistical quantities such as the Fisher Information, and hypothesis dependent complexity measures chosen particularly for the domain.
Reference: [131] <author> C.S. Wallace and P.R. Freeman, </author> <title> "Estimation and inference by compact encoding", </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 49, no. 3, </volume> <pages> pp. 240-265, </pages> <year> 1987. </year>
Reference-contexts: Examples for undirected probabilistic networks with the BIC criteria appear in [67]. D. Minimum information complexity approaches There are several different schools under the general rubric of minimizing some information complexity measure ("code length"), for instance minimum description length (MDL) [130], minimum message length <ref> [131] </ref>, and minimum complexity [132]. A simple approximation for MDL is equivalent to the BIC above, but other variations involve statistical quantities such as the Fisher Information, and hypothesis dependent complexity measures chosen particularly for the domain.
Reference: [132] <author> A.R. </author> <title> Barron and T.M. Cover, "Minimum complexity density estimation", </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 37, no. 4, </volume> <year> 1991. </year>
Reference-contexts: Examples for undirected probabilistic networks with the BIC criteria appear in [67]. D. Minimum information complexity approaches There are several different schools under the general rubric of minimizing some information complexity measure ("code length"), for instance minimum description length (MDL) [130], minimum message length [131], and minimum complexity <ref> [132] </ref>. A simple approximation for MDL is equivalent to the BIC above, but other variations involve statistical quantities such as the Fisher Information, and hypothesis dependent complexity measures chosen particularly for the domain. These approaches are popular among engineers and computer scientists who learn coding and information theory as undergraduates.
Reference: [133] <author> J.J. Oliver and R.A. Baxter, </author> <title> "Mml and bayesianism: similarities and differences", </title> <type> Technical Report 206, </type> <institution> Monash University, Melbourne, </institution> <year> 1994. </year>
Reference-contexts: These approaches are popular among engineers and computer scientists who learn coding and information theory as undergraduates. From one perspective, these methods are related to Bayesian MAP methods although there are subtle differences <ref> [133] </ref>. One advantage that some proponents claim of this approach (particularly those in the MDL school) is that it requires no prior and is hence objective. In most instances a corresponding "implicit prior" can be constructed from the code.
Reference: [134] <author> P. Smyth, </author> <title> "Admissible stochastic complexity models for classification problems", </title> <booktitle> In Hand [166], </booktitle> <pages> pp. 335-347. </pages>
Reference-contexts: In most instances a corresponding "implicit prior" can be constructed from the code. Some authors use this approach so that they can use Bayesian methods in disguise without being ridiculed by their anti-Bayesian colleagues. Search bounds, for instance <ref> [134] </ref>, are one area where the information complexity approach takes advantage of the techniques developed in information theory. Suzuki has developed a branch and bound technique for learning Bayesian networks based on information-theoretic bounds [73]. For Bayesian networks, MDL has been applied by [61], [135], [136]. E.
Reference: [135] <author> W. Lam and F. Bacchus, </author> <title> "Learning Bayesian belief networks: An approach based on the MDL principle", </title> <journal> Computational Intelligence, </journal> <volume> vol. 10, no. 4, </volume> <year> 1994. </year>
Reference-contexts: Search bounds, for instance [134], are one area where the information complexity approach takes advantage of the techniques developed in information theory. Suzuki has developed a branch and bound technique for learning Bayesian networks based on information-theoretic bounds [73]. For Bayesian networks, MDL has been applied by [61], <ref> [135] </ref>, [136]. E. Resampling approaches Modern statistics has developed a variety of resampling schemes for addressing over-fitting in parametric situations 12 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, TO APPEAR (FINAL DRAFT) like learning networks. Resampling refers to the fact that pseudo-samples are created from the original sample.
Reference: [136] <author> J. Suzuki, </author> <title> "A construction of Bayesian networks from databases based on an MDL scheme", </title> <booktitle> In Heckerman and Mamdani [161], </booktitle> <pages> pp. 266-273. </pages>
Reference-contexts: Search bounds, for instance [134], are one area where the information complexity approach takes advantage of the techniques developed in information theory. Suzuki has developed a branch and bound technique for learning Bayesian networks based on information-theoretic bounds [73]. For Bayesian networks, MDL has been applied by [61], [135], <ref> [136] </ref>. E. Resampling approaches Modern statistics has developed a variety of resampling schemes for addressing over-fitting in parametric situations 12 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, TO APPEAR (FINAL DRAFT) like learning networks. Resampling refers to the fact that pseudo-samples are created from the original sample.
Reference: [137] <author> B. Efron and R. Tibshirani, </author> <title> "Statistical data analysis in the computer age", </title> <journal> Science, </journal> <volume> vol. 253, </volume> <pages> pp. 390-395, </pages> <year> 1991. </year>
Reference-contexts: Resampling refers to the fact that pseudo-samples are created from the original sample. A popular approach is cross validation, applied by [104]. Resampling schemes have been used to great success in applied multivariate statistics, see for instance a tutorial in <ref> [137] </ref>. Their strength lies in the fact that they are reliable black box method that can be used without requiring some of the complex mathematical treatment found in the Bayesian or minimum complexity methods [138].
Reference: [138] <author> Ron Kohavi, </author> <title> "A study of cross validation and bootstrap for accuracy estimation and model selection", </title> <booktitle> in International Joint Conference on Artificial Intelligence, Montreal, 1995, IJCAI, </booktitle> <publisher> Inc., Morgan Kaufmann. </publisher>
Reference-contexts: Their strength lies in the fact that they are reliable black box method that can be used without requiring some of the complex mathematical treatment found in the Bayesian or minimum complexity methods <ref> [138] </ref>. These resampling schemes therefore provide a good benchmark for comparison with more complex schemes which have additional mathematical and implementation pitfalls. Their theoretical justification is large sample, although they have empirical successes in the small sample case for a wide range of problems. F.
Reference: [139] <author> W.L. Buntine, </author> <title> "Prior probabilities", </title> <note> Tutorial slides available through URL http://www.Thinkbank.com/wray/, 1994. </note>
Reference-contexts: In its full form the Bayesian approach requires specification of a prior probability (for a tutorial and a list of references, see <ref> [139] </ref>). A good general introduction to Bayesian methods for learning Bayesian networks can be found in [79]. Advanced introductions and reviews of Bayesian methods for learning can be found in [25], [26], [24]. The Bayesian approach has many different approximations.
Reference: [140] <author> G.F. Cooper and E.H. Herskovits, </author> <title> "A Bayesian method for the induction of probabilistic networks from data", </title> <journal> Machine Learning, </journal> <volume> vol. 9, no. 4, </volume> <pages> pp. 309-348, </pages> <year> 1992. </year>
Reference-contexts: This is called the Bayes factor and a variety of techniques and approximations exist for computing it [25], [26], [23]. The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many <ref> [140] </ref>, [35], [121], [111], [112], [68], [141], [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105].
Reference: [141] <author> R.D. Shachter, D.M. Eddy, and V. Hasselblad, </author> <title> "An influence diagram approach to medical technology assessment", in Influence Diagrams, Belief Nets and Decision Analysis, R.M. Oliver and J.Q. Smith, </title> <booktitle> Eds., </booktitle> <pages> pp. 321-350. </pages> <publisher> Wiley, </publisher> <year> 1990. </year>
Reference-contexts: The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], <ref> [141] </ref>, [142], [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105].
Reference: [142] <author> G. Consonni and P. Giudici, </author> <title> "Learning in probabilistic expert systems", </title> <booktitle> in Workshop on Probabilistic Expert Systems, </booktitle> <editor> R. Scozzafava, Ed., </editor> <address> Roma, </address> <month> October </month> <year> 1993, </year> <pages> pp. 57-78. </pages>
Reference-contexts: The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], [141], <ref> [142] </ref>, [143], [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105].
Reference: [143] <author> J.C. York, </author> <title> Bayesian Methods for the Analysis of Misclassified and Incomplete Multivariate Discrete Data, </title> <type> PhD thesis, </type> <institution> University of Washington, </institution> <address> Seattle, WA, </address> <year> 1992. </year>
Reference-contexts: The basic technique for Bayesian learning of Bayesian network structures from complete data uses standard Bayesian methods, and was worked out in one form or another, by many [140], [35], [121], [111], [112], [68], [141], [142], <ref> [143] </ref>, [37], [38]. Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. <p> Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], [68], <ref> [143] </ref>, [144], [145], [35], [146], [147]. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32].
Reference: [144] <author> D. Madigan and J. York, </author> <title> "Bayesian graphical models for discrete data", </title> <type> Technical Report #259, </type> <institution> Department of Statistics, University of Washington, </institution> <address> Seattle, WA, </address> <month> November </month> <year> 1993, </year> <note> Submitted to International Statistical review. </note>
Reference-contexts: Certainly, these techniques use standard Bayesian manipulations and should be obvious to most students of Bayesian theory. The general case for the exponential family is worked through in [105]. Good summaries of this line of work can be found in [111], [68], <ref> [144] </ref>, [37], [23], and a thesis covering many of the issues is [36]. The full Bayesian approach is a predictive one: rather than returning the single "best" network, the aim might be to perform prediction or estimate probabilities for new cases. <p> Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], [68], [143], <ref> [144] </ref>, [145], [35], [146], [147]. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32]. <p> MCMC methods can be used for parameter fitting, to sample different network parameters, and for structure learning, to sample from different possible probabilistic network structures. Use of MCMC methods for learning probabilistic networks is discussed in [85], <ref> [144] </ref>, [147], [146], [23]. Madigan, Gavrin and Raftery [146] refer to the use of MCMC methods for averaging over multiple probabilistic networks|the full predictive approach|as Markov Chain Monte Carlo Model Composition (MC 3 ). The key distinction between Bayesian and non-Bayesian methods is the use of priors.
Reference: [145] <author> D. Madigan, A.E. Raftery, J.C. York, J.M. Bradshaw, and R.G. Almond, </author> <title> "Strategies for graphical model selection", </title> <booktitle> In Cheese-man and Oldford [159], </booktitle> <pages> pp. 91-100. </pages>
Reference-contexts: Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], [68], [143], [144], <ref> [145] </ref>, [35], [146], [147]. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32].
Reference: [146] <author> D. Madigan, J. Gavrin, and A.E. Raftery, </author> <title> "Eliciting prior information to enhance the predictive performance of bayesian graphical models", </title> <journal> Communications in Statistics, </journal> <note> 1995, To appear. </note>
Reference-contexts: Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], [68], [143], [144], [145], [35], <ref> [146] </ref>, [147]. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32]. <p> MCMC methods can be used for parameter fitting, to sample different network parameters, and for structure learning, to sample from different possible probabilistic network structures. Use of MCMC methods for learning probabilistic networks is discussed in [85], [144], [147], <ref> [146] </ref>, [23]. Madigan, Gavrin and Raftery [146] refer to the use of MCMC methods for averaging over multiple probabilistic networks|the full predictive approach|as Markov Chain Monte Carlo Model Composition (MC 3 ). The key distinction between Bayesian and non-Bayesian methods is the use of priors. <p> MCMC methods can be used for parameter fitting, to sample different network parameters, and for structure learning, to sample from different possible probabilistic network structures. Use of MCMC methods for learning probabilistic networks is discussed in [85], [144], [147], <ref> [146] </ref>, [23]. Madigan, Gavrin and Raftery [146] refer to the use of MCMC methods for averaging over multiple probabilistic networks|the full predictive approach|as Markov Chain Monte Carlo Model Composition (MC 3 ). The key distinction between Bayesian and non-Bayesian methods is the use of priors. <p> Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors [68], [111], [121], [37], [35], [38], <ref> [146] </ref>, [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6. <p> The ability to use a variety of informative, subjective priors for Bayesian networks is one of their strengths. Informative priors can include constraints and preferences on the structure of the network [121], [37], as well as preferences on the probabilities, and even using the expert to generate "imaginary data" <ref> [146] </ref>. An example in the language of chain graphs (an extension to Bayesian networks) is given by [38]. The potential for using Bayesian networks as a basis for knowledge refinement has been suggested by [121], [37], [111], [146], and in applications this offers an integrated approach to the development and maintenance <p> preferences on the probabilities, and even using the expert to generate "imaginary data" <ref> [146] </ref>. An example in the language of chain graphs (an extension to Bayesian networks) is given by [38]. The potential for using Bayesian networks as a basis for knowledge refinement has been suggested by [121], [37], [111], [146], and in applications this offers an integrated approach to the development and maintenance of intelligent systems, long considered one of the potential fruits of artificial intelligence. IX. More on Learning Structure An exact algorithm for handling incomplete data or missing values can be found in [151].
Reference: [147] <author> J. York, D. Madigan, I. Heuch, </author> <title> and R.T. Lie, "Estimation of the proportion of congenital malformations using double sampling: Incorporating covariates and accounting for model uncertainty", </title> <journal> Applied Statistics, </journal> <volume> vol. 44, </volume> <pages> pp. 227-242, </pages> <year> 1995. </year>
Reference-contexts: Bayesian methods for learning probabilistic networks in this more general sense can be found in [121], [68], [143], [144], [145], [35], [146], <ref> [147] </ref>. Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities [148], [111], [32]. <p> MCMC methods can be used for parameter fitting, to sample different network parameters, and for structure learning, to sample from different possible probabilistic network structures. Use of MCMC methods for learning probabilistic networks is discussed in [85], [144], <ref> [147] </ref>, [146], [23]. Madigan, Gavrin and Raftery [146] refer to the use of MCMC methods for averaging over multiple probabilistic networks|the full predictive approach|as Markov Chain Monte Carlo Model Composition (MC 3 ). The key distinction between Bayesian and non-Bayesian methods is the use of priors. <p> Priors can unfortunately be complex mathematically, so poorly chosen priors can make a Bayesian method perform poorly against other methods|a real danger in the case of Bayesian networks because of their semi-parametric nature. Both informative priors [68], [111], [121], [37], [35], [38], [146], <ref> [147] </ref>, and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], [150]. For instance, consider structures S d and S e from Fig. 6.
Reference: [148] <author> R. Musick, </author> <title> "Minimal assumption distribution propogation in belief networks", </title> <booktitle> In Heckerman and Mamdani [161], </booktitle> <pages> pp. 251-258. </pages>
Reference-contexts: Computational aspects of finding the best l networks are discussed in [37]. A related concern is how to combine the posterior network probabilities efficiently and to compute conditional posterior probabilities <ref> [148] </ref>, [111], [32]. A general Bayesian algorithm family for inference that applies in any context, parameter fitting or structure learning, is the Markov Chain Monte Carlo (MCMC) family of algorithms. An introduction is given in [149], [23], and an extensive review is given by [87].
Reference: [149] <author> B.D. Ripley, </author> <title> Stochastic Simulation, </title> <publisher> John Wiley & Sons, </publisher> <year> 1987. </year>
Reference-contexts: A general Bayesian algorithm family for inference that applies in any context, parameter fitting or structure learning, is the Markov Chain Monte Carlo (MCMC) family of algorithms. An introduction is given in <ref> [149] </ref>, [23], and an extensive review is given by [87]. This family uses the following kind of trick. Suppose we wish to sample from the distribution p (A; B; C). In general this might be a complex distribution and no convenient sampling algorithm may be known.
Reference: [150] <author> D. Heckerman, D. Geiger, and D. Chickering, </author> <title> "Learning Bayesian networks: The combination of knowledge and statistical data", In de Mantaras and Poole [160]. </title>
Reference-contexts: Both informative priors [68], [111], [121], [37], [35], [38], [146], [147], and non-informative priors can be used. A fundamental assumption is that equivalent network structures should have equivalent priors on their parameters [121], [60], [37], <ref> [150] </ref>. For instance, consider structures S d and S e from Fig. 6.
Reference: [151] <author> G.F. Cooper, </author> <title> "A method for learning belief networks that contain hidden variables", </title> <journal> Journal of Intelligent Information Systems, </journal> <note> 1994, To appear. Also in Proceedings of the Workshop on Knowledge Discovery in Databases, </note> <year> 1993, </year> <pages> 112-124. </pages>
Reference-contexts: IX. More on Learning Structure An exact algorithm for handling incomplete data or missing values can be found in <ref> [151] </ref>. The problems involved here for exact methods were previously explained in [35]. While impractical for larger problems, this could serve as a tool to benchmark on non-trivial sized problems for the many approximate algorithms that exist, for instance, some are mentioned in Table III.
Reference: [152] <author> D.M. Titterington, A.F.M. Smith, and U.E. Makov, </author> <title> Statistical Analysis of Finite Mixture Distributions, </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester, </address> <year> 1985. </year>
Reference-contexts: Simple clustering algorithms learn Bayesian networks with a single latent/hidden variable at the root of the network. So these kinds of problems have been addressed in a limited sense for many years in the AI and statistics community <ref> [152] </ref>. A Bayesian method is [153], [51]. Likewise. missing values can be handled by the well known EM algorithm [76], or more accurately by Gibbs sampling [85]. More recent versions of these clustering algorithms search over possible structures as well [51].
Reference: [153] <author> P. Cheeseman, M. Self, J. Kelly, W. Taylor, D. Freeman, and J. Stutz, </author> <title> "Bayesian classification", </title> <booktitle> in Seventh National Conference on Artificial Intelligence, </booktitle> <address> Saint Paul, Minnesota, </address> <year> 1988, </year> <journal> American Association for Artificial Intelligence, </journal> <pages> pp. 607-611. </pages>
Reference-contexts: Simple clustering algorithms learn Bayesian networks with a single latent/hidden variable at the root of the network. So these kinds of problems have been addressed in a limited sense for many years in the AI and statistics community [152]. A Bayesian method is <ref> [153] </ref>, [51]. Likewise. missing values can be handled by the well known EM algorithm [76], or more accurately by Gibbs sampling [85]. More recent versions of these clustering algorithms search over possible structures as well [51]. Some algorithms do not fit neatly into the categories above.
Reference: [154] <author> A. Thomas, D.J. Spiegelhalter, and W.R. Gilks, </author> <title> "BUGS: A program to perform Bayesian inference using Gibbs sampling", </title> <editor> In Bernardo et al. </editor> <volume> [165], </volume> <pages> pp. 837-42. </pages>
Reference-contexts: X. Constructing learning software For a variety of network structures with latent variables and different parametric nodes (Logistic, Poisson, and other forms), the BUGS program can generate Gibbs samplers automatically <ref> [154] </ref>, [86]. This effectively allows data analysis algorithms to be compiled from specifications given as a probabilistic network, and the technique addresses a number of non-trivial data analysis problems [155], [86].
Reference: [155] <author> W.R. Gilks, D.G. Clayton, D.J. Spiegelhalter, N.G. Best, A.J. McNeil, L.D. Sharples, and A.J. Kirby, </author> <title> "Modelling complexity: BUNTINE: A GUIDE TO THE LITERATURE ON LEARNING GRAPHICAL MODELS FROM DATA 17 applications of Gibbs sampling in medicine", </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 55, </volume> <pages> pp. 39-102, </pages> <year> 1993. </year>
Reference-contexts: This effectively allows data analysis algorithms to be compiled from specifications given as a probabilistic network, and the technique addresses a number of non-trivial data analysis problems <ref> [155] </ref>, [86]. Unfortunately, Gibbs sampling without much thought to domain specific optimization can be time intensive because convergence may be slow, so other methods need to be developed to make this approach more widely applicable.
Reference: [156] <author> W.L. Buntine, </author> <title> "Networks for learning", </title> <booktitle> in 50th Session of the International Statistical Institute, </booktitle> <address> Beijing, China, </address> <year> 1995, </year> <note> Invited lecture. </note>
Reference-contexts: An exposition of the techniques used by algorithms for learning Bayesian networks| decomposition, exact Bayes factors, and differentiation| all readily automated|can be found in [23], <ref> [156] </ref>.
Reference: [157] <editor> Piero Bonissone, Ed., </editor> <booktitle> Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Cambridge, Mas-sachusetts, </address> <year> 1990. </year>
Reference: [158] <author> P. Besnard and S. </author> <title> Hanks, </title> <editor> Eds., </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Eleventh Conference, </booktitle> <address> Montreal, Canada, </address> <year> 1995. </year>
Reference: [159] <author> P. Cheeseman and R.W. Oldford, Eds., </author> <title> Selecting Models from Data: </title> <booktitle> Artificial Intelligence and Statistics IV, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: [160] <author> R. Lopez de Mantaras and D. Poole, </author> <title> Eds., </title> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Tenth Conference, </booktitle> <address> Seattle, WA, </address> <year> 1994. </year>
Reference: [161] <editor> D. Heckerman and A. Mamdani, Eds., </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Ninth Conference, </booktitle> <address> Washington, DC, </address> <year> 1993. </year>
Reference: [162] <editor> IJCAI91, Ed., </editor> <booktitle> International Joint Conference on Artificial Intelligence, </booktitle> <address> Sydney, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [163] <author> D. Dubois, </author> <title> M.P. Wellman, B.D. </title> <editor> D'Ambrosio, and P. Smets, Eds., </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Eight Conference, </booktitle> <address> Stanford, CA, </address> <year> 1992. </year>
Reference: [164] <editor> M. Henrion, R. Shachter, L.N. Kanal, and J. Lemmer, Eds., </editor> <booktitle> Uncertainty in Artificial Intelligence 5, </booktitle> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference: [165] <author> J.M. Bernardo, J.O. Berger, A.P. Dawid, and A.F.M. Smith, Eds., </author> <title> Bayesian Statistics 4, </title> <publisher> Oxford University Press, </publisher> <year> 1992. </year>

References-found: 165

