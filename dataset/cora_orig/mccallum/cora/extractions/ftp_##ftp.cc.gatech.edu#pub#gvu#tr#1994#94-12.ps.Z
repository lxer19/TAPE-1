URL: ftp://ftp.cc.gatech.edu/pub/gvu/tr/1994/94-12.ps.Z
Refering-URL: http://www.cs.gatech.edu/gvu/reports/1994/
Root-URL: 
Email: -martin,foley-@cc.gatech.edu  
Title: BEFORE AND AFTER SNAPSHOTS things, Inference Bear lets you align, center move, resize, create and
Author: Martin R. Frank James D. Foley 
Address: Atlanta, Georgia 30332-0280  
Affiliation: Graphics, Visualization Usability Center Georgia Institute of Technology  
Note: FROM  Among other  
Abstract: 1 This is Frank, M. and J. Foley, Inferring Behavior From Before and After Snapshots, Technical Report git-gvu-94-12, Georgia Institute of Technology, Graphics, Visualization & Usability Center, April 1994. INFERENCE BEAR: INFERRING BEHAVIOR ABSTRACT We present Inference Bear (Inference Based On Before And After Snapshots) which lets users build functional graphical user interfaces by demonstration. Inference Bear is the f irst Programming By Demonstration system based on the abstract inference engine described in [5]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Cypher, A., Eager: </author> <title> Programming Repetitive Tasks by Example, </title> <booktitle> Proceedings of CHI91, </booktitle> <address> New Orleans, </address> <publisher> Louisiana, </publisher> <pages> pp. 33-39. </pages>
Reference-contexts: Peridot [9] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [10] focuses on creating application-specific objects. Metamouse [8] learns graphical procedures by example. Druid [13] lets users attach simple functionality such as enabling, disabling, hiding and showing to buttons. Eager <ref> [1] </ref> watches users perform operations and detects and automates repetition. DEMO [14,2] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. Chimera [7] infers constraints between graphical objects given multiple snapshots. Finally , Marquise [11] uses domain knowledge in order to support building graphical editors. <p> Objs) No not applica ble Graphical Procedure Druid b [13] 1990 No Yes No None None No Event Recording Script Eager <ref> [1] </ref> 1991 (Prediction) No not applica ble not applica ble not applica ble No Event Recording Macro DEMO [2,14] 1991/92 No Yes Yes High Explicit (Aux. Objs) Yes (DEMO II) Compressed Snapshots Response Description Chimera [7] 1991 No No No High Explicit c (Aux.
Reference: [2] <author> Fisher, G., D. Busse and D. W olber, </author> <title> Adding Rule-Based Reasoning to a Demonstrational Interface B u i l d e r, P r o c e e d i n g s o f U I ST 9 2 , Mo n t e r e y , California, </title> <month> November </month> <year> 1992, </year> <pages> pp. 89-97. </pages>
Reference: [3] <author> Foley, J., W. Kim, S. Kovacevic and K. </author> <title> Murray , Defining Interfaces at a High Level of Abstraction , IEEE Software, </title> <month> Jan. </month> <year> 1989, </year> <pages> pp. 25-32. </pages>
Reference-contexts: The current user interface design is shown in the middle of the figure (labelled Design Mode). In this example, the design consists of two buttons a and b which are connected by line line. The middle control panel belongs to UIDE, the User Interface Design Environment <ref> [3] </ref>. In the context of this paper, it suffices to know that it lets you open the two text editors shown to the right and that it can switch the current design to run mode by reading and executing their specif ications.
Reference: [4] <author> Frank, M. and J. Foley, </author> <title> Model-Based User Interface Design by Example and by Interview, </title> <booktitle> Proceedings of UIST93, </booktitle> <address> Atlanta, Georgia, </address> <month> Nov. </month> <year> 1993, </year> <pages> pp. 129-137. </pages>
Reference-contexts: Finally, the right-hand control panel provides the interface to advanced tools that the designer can use in this environment. The Interview Tool helps the designer fill in the textual specifications by asking questions based on the current user interface layout. It is described in <ref> [4] </ref> and will not be further discussed here. The Inference Bear is the tool we are concerned with - it lets designers describe the behavior of the user interface by demonstration. For example, it can infer the specification shown in the Interface Model editor of Figure 1.
Reference: [5] <author> Frank, M. and J. Foley, </author> <title> A Pure Reasoning Engine for Programmning By Demonstration, </title> <type> Technical Report git-gvu-94-11, </type> <institution> Georgia Institute of Technology, Graphics, Visualization and Usability Center, Atlanta, Georgia, </institution> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Snapshots have been used in earlier demonstrational systems, such as [7], which lets the user take snapshots of valid states. Before and After snapshots add sequentiality to the demonstration. Inference Bear is build on top of two main components. The first component is an abstract demonstrational inference engine <ref> [5] </ref>, the second one is an interactive user interface builder [6]. Consequently, Inference Bear only adds a modest amount of additional code which combines these. PROGRAMMING BY DEMONSTRATION We shortly review previous work. Peridot [9] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. <p> Some systems use auxiliary objects such as guide wires to let the user specify the relevant objects and their relationship. Inference Bear limits the number of objects it considers implicitly but not heuristically <ref> [5] </ref>. The sixth column describes if the inferencing is based on rules or on an algorithm. The advantage of rule-based systems is that they can encode commonly used behavior. <p> This is done by bringing the user interface de 4 sign to the state it should go to, and by pressing the After Snapshot button to let the system know that one is done. The system now responds by running the inference engine <ref> [5] </ref> on this example. The designer than tests if the inferred behavior is the one she had in mind by either reading the inferred specification or by going to Run mode and testing it interactively. <p> INFERENCE BEAR ANATOMY As mentioned earlier, Inference Bear uses the demonstrational engine described in <ref> [5] </ref>. The most notable characteristic of this engine is that it does not contain domain knowledge. We do not want to explain the inferencing process here but will only describe the user visible effects of using a domain-independent engine. <p> However, we feel that the inconvenience of sometimes giving more examples is normally offset by the higher generality of the inference engine. Another effect introduced by using the inference engine of <ref> [5] </ref> is that a variable has to be changed in a demonstration before the inference engine attempts to use it in its inferences. This is exemplified in the inference of Figure 6 - the width of the button has never been changed at this point.
Reference: [6] <author> Khme, T. and M. Schneider-Hufschmidt, </author> <title> SX/Tools - A n O p e n D e s i g n E n v i r o n m e n t f o r A d a p t a b le Multimedia User Interfaces, </title> <journal> Computer Graphics Forum, </journal> <volume> 11(3), </volume> <month> Sept. </month> <year> 1992, </year> <pages> pp. 93-105. </pages>
Reference-contexts: Before and After snapshots add sequentiality to the demonstration. Inference Bear is build on top of two main components. The first component is an abstract demonstrational inference engine [5], the second one is an interactive user interface builder <ref> [6] </ref>. Consequently, Inference Bear only adds a modest amount of additional code which combines these. PROGRAMMING BY DEMONSTRATION We shortly review previous work. Peridot [9] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [10] focuses on creating application-specific objects. Metamouse [8] learns graphical procedures by example. <p> Snapshot-taking records a series of states. The last column describes the output of the inferencing process. 3 THE DESIGN ENVIRONMENT upper three windows with the dark background are the control panels of its main components. The left-hand control panel belongs to the interface builder we are using <ref> [6] </ref>. It allows to open toolboxes and user interface designs. Two such toolboxes are shown on the left (mislabelled Adapter). The current user interface design is shown in the middle of the figure (labelled Design Mode).
Reference: [7] <author> Kurlander, D. and S. Feiner, </author> <title> Inferring Constraints from Multiple Snapshots, </title> <type> Technical Report cucs-008-91, </type> <institution> Compute r Scie nce De par tment, Columbia University, </institution> <note> May 1991 (also to appear in the ACM Transactions On Graphics). </note>
Reference-contexts: A single example is sufficient for simple behavior, more examples are required to infer more complex behavior. Snapshots have been used in earlier demonstrational systems, such as <ref> [7] </ref>, which lets the user take snapshots of valid states. Before and After snapshots add sequentiality to the demonstration. Inference Bear is build on top of two main components. The first component is an abstract demonstrational inference engine [5], the second one is an interactive user interface builder [6]. <p> Metamouse [8] learns graphical procedures by example. Druid [13] lets users attach simple functionality such as enabling, disabling, hiding and showing to buttons. Eager [1] watches users perform operations and detects and automates repetition. DEMO [14,2] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. Chimera <ref> [7] </ref> infers constraints between graphical objects given multiple snapshots. Finally , Marquise [11] uses domain knowledge in order to support building graphical editors. All of these systems use by-demonstration techniques but they are not easily compared because they have dif ferent goals and use different techniques. <p> Objs) Yes (DEMO II) Compressed Snapshots Response Description Chimera <ref> [7] </ref> 1991 No No No High Explicit c (Aux. Objs) No Snapshots Two-Way Constraints Marquise [11] 1993 No Optional d Yes Low None Yes Event Recording LISP Code Inference Bear 1994 No No Yes Medium Implicit No Ev. Rec. and Snapshots Script Table 1.
Reference: [8] <author> Maulsby, D., I. Witten and K. Kittlitz, Metamouse: </author> <title> Specifying Graphical Pr ocedures by Example , Proceedings of Siggraph89, </title> <journal> pp. </journal> <pages> 127-136. </pages>
Reference-contexts: Consequently, Inference Bear only adds a modest amount of additional code which combines these. PROGRAMMING BY DEMONSTRATION We shortly review previous work. Peridot [9] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [10] focuses on creating application-specific objects. Metamouse <ref> [8] </ref> learns graphical procedures by example. Druid [13] lets users attach simple functionality such as enabling, disabling, hiding and showing to buttons. Eager [1] watches users perform operations and detects and automates repetition. DEMO [14,2] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. <p> Dynamic Object Creation + Deletion Capabilities (Subjective) Strength in Geometric Relations Internals Search Space Reduction Internals Is Rule Based Internals Temporary Behavior Storage Internals Output Peridot [9] 1987 (Query) Yes No Low None Yes Snapshots One-Way Constraints Lapidary [10] 1989 No Yes No Low None No Snapshots One-Way Constraints Metamouse <ref> [8] </ref> 1989 (Prediction) No No Medium Explicit a (Aux. <p> It takes an example with a dif ferent button width to make the intended inference because the inference engines vision is based on motion. (Another demonstrational system bases its vision on proximity <ref> [8] </ref>.) This is often puzzling to novice users. However, once they learn how to use the inference mechanism they can use it in a wide range of situations. USABILITY TESTING Observing actual users is the lithmus test of any demonstrational system. We have informally tested Inference Bear in usability studies.
Reference: [9] <author> Myers, B., </author> <title> Creating User Interfaces By Demonstration, </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: The first component is an abstract demonstrational inference engine [5], the second one is an interactive user interface builder [6]. Consequently, Inference Bear only adds a modest amount of additional code which combines these. PROGRAMMING BY DEMONSTRATION We shortly review previous work. Peridot <ref> [9] </ref> supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [10] focuses on creating application-specific objects. Metamouse [8] learns graphical procedures by example. Druid [13] lets users attach simple functionality such as enabling, disabling, hiding and showing to buttons. <p> Interface Is Eager (Constantly Watches User) Interface Uses A Clarification Dialog Capabilities Dynamic Object Creation + Deletion Capabilities (Subjective) Strength in Geometric Relations Internals Search Space Reduction Internals Is Rule Based Internals Temporary Behavior Storage Internals Output Peridot <ref> [9] </ref> 1987 (Query) Yes No Low None Yes Snapshots One-Way Constraints Lapidary [10] 1989 No Yes No Low None No Snapshots One-Way Constraints Metamouse [8] 1989 (Prediction) No No Medium Explicit a (Aux.
Reference: [10] <author> Myers, B., B. Vander Zanden and R. Dannenber g, </author> <title> Creating Graphical Interactive Application Objects B y D e m o n s t r a t i o n , P r o c e e d i n g s o f U I S T 8 9 , Williamsburg, </title> <address> Virginia, </address> <month> Nov. </month> <year> 1989, </year> <pages> pp. 95-104. </pages>
Reference-contexts: Consequently, Inference Bear only adds a modest amount of additional code which combines these. PROGRAMMING BY DEMONSTRATION We shortly review previous work. Peridot [9] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary <ref> [10] </ref> focuses on creating application-specific objects. Metamouse [8] learns graphical procedures by example. Druid [13] lets users attach simple functionality such as enabling, disabling, hiding and showing to buttons. Eager [1] watches users perform operations and detects and automates repetition. <p> Interface Is Eager (Constantly Watches User) Interface Uses A Clarification Dialog Capabilities Dynamic Object Creation + Deletion Capabilities (Subjective) Strength in Geometric Relations Internals Search Space Reduction Internals Is Rule Based Internals Temporary Behavior Storage Internals Output Peridot [9] 1987 (Query) Yes No Low None Yes Snapshots One-Way Constraints Lapidary <ref> [10] </ref> 1989 No Yes No Low None No Snapshots One-Way Constraints Metamouse [8] 1989 (Prediction) No No Medium Explicit a (Aux. <p> This is because Inference Bear does not use domain knowledge in its inferencing but rather solves sets of equations. 1. The same approach was taken in Lapidary <ref> [10] </ref>.
Reference: [11] <author> Myers, B., R. McDaniel, D. Kosbie, Marquise: </author> <title> C r e a t i n g C o m p l e t e U s e r I n t e r f a c e s B y Demonstration, </title> <booktitle> Proceedings of INTERCHI93, </booktitle> <address> Amsterdam, Netherlands, </address> <month> April </month> <year> 1993, </year> <pages> pp. 293-300. </pages>
Reference-contexts: Eager [1] watches users perform operations and detects and automates repetition. DEMO [14,2] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. Chimera [7] infers constraints between graphical objects given multiple snapshots. Finally , Marquise <ref> [11] </ref> uses domain knowledge in order to support building graphical editors. All of these systems use by-demonstration techniques but they are not easily compared because they have dif ferent goals and use different techniques. Nevertheless, we make an attempt to classify them in Table 1. <p> Objs) Yes (DEMO II) Compressed Snapshots Response Description Chimera [7] 1991 No No No High Explicit c (Aux. Objs) No Snapshots Two-Way Constraints Marquise <ref> [11] </ref> 1993 No Optional d Yes Low None Yes Event Recording LISP Code Inference Bear 1994 No No Yes Medium Implicit No Ev. Rec. and Snapshots Script Table 1. Overview of Demonstrational Systems if the system reduces the number of objects that it checks for relationships.
Reference: [12] <author> O lse n , D. </author> <title> a n d K . Al la n, Cre ati ng I n te ra c tiv e Techniques by Symbolically Solving Geometric Constraints, </title> <booktitle> Proceedings of UIST90, </booktitle> <address> Snowbird, Utah, </address> <month> Oct </month> <year> 1990, </year> <pages> pp. 102-107. </pages>
Reference: [13] <author> Singh, G., C. Kok and T. Ngan, Druid: </author> <title> A System For Demonstrational Rapid User Interface Development , Proceedings of UIST90, </title> <address> Snowbird, Utah, </address> <month> Oct. </month> <year> 1990, </year> <pages> pp. 167-177. </pages>
Reference-contexts: PROGRAMMING BY DEMONSTRATION We shortly review previous work. Peridot [9] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [10] focuses on creating application-specific objects. Metamouse [8] learns graphical procedures by example. Druid <ref> [13] </ref> lets users attach simple functionality such as enabling, disabling, hiding and showing to buttons. Eager [1] watches users perform operations and detects and automates repetition. DEMO [14,2] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. Chimera [7] infers constraints between graphical objects given multiple snapshots. <p> Objs) No not applica ble Graphical Procedure Druid b <ref> [13] </ref> 1990 No Yes No None None No Event Recording Script Eager [1] 1991 (Prediction) No not applica ble not applica ble not applica ble No Event Recording Macro DEMO [2,14] 1991/92 No Yes Yes High Explicit (Aux.
Reference: [14] <author> Wolbe r, D. and G. </author> <title> Fishe r , A Demonstrational Te c h n i q u e F o r D e v e l o p i n g I n t e r f a c e s W i t h Dynamically Created Objects , Proceedings of UIST91, </title> <type> Hilton Head, </type> <institution> South Carolina, </institution> <month> November </month> <year> 1991, </year> <pages> pages 221-230. </pages>
References-found: 14

