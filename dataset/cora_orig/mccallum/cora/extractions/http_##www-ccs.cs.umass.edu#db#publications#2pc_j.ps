URL: http://www-ccs.cs.umass.edu/db/publications/2pc_j.ps
Refering-URL: http://www-ccs.cs.umass.edu/db/publications/
Root-URL: 
Title: Characterization and Optimization of Commit Processing Performance in Distributed Database Systems  
Author: Jayant Haritsa Krithi Ramamritham Ramesh Gupta 
Keyword: Distributed Database, Commit Protocol, Two Phase Commit, Three Phase Commit, Performance Evaluation  
Address: Bangalore 560012, India Amherst 01003, U.S.A.  
Affiliation: Database Systems Lab, SERC Dept. of Computer Science Indian Institute of Science Univ. of Massachusetts  
Abstract: A significant body of literature is available on distributed transaction commit protocols. Surprisingly, however, the relative merits of these protocols have not been sufficiently studied with respect to their quantitative impact on transaction processing performance. Also, even though several optimizations have been suggested to improve the performance of the ubiquitous Two-Phase Commit (2PC) protocol, none have addressed the fact that under 2PC the data updated by a transaction during its data processing phase remains unavailable to other transactions during its commit processing phase and, worse, there is no inherent bound on the duration of this unavailability. This paper addresses both these issues. First, using a detailed simulation model of a distributed database system, we profile the transaction throughput performance of a representative set of commit protocols, including 2PC, Presumed Abort, Presumed Commit and 3PC. Second, we propose and evaluate a new commit protocol, OPT, that allows transactions to "optimistically" borrow the updated data of transactions currently in their commit phase. This borrowing is controlled to ensure that cascading aborts, usually associated with the use of dirty data, do not occur. The new protocol is easy to implement and incorporate in current systems, and can coexist, often synergistically, with many of the optimizations proposed earlier including current industry standard protocols such as Presumed Commit and Presumed Abort. The experimental results show that distributed commit processing can have considerably more influence than distributed data processing on the throughput performance and that the choice of commit protocol clearly affects the magnitude of this influence. Among the protocols evaluated, the new optimistic commit protocol provides the best transaction throughput performance for a variety of workloads and system configurations. In fact, OPT's peak throughput is often close to the upper bound on achievable peak performance. Even more interestingly, when data contention is significant, integrating OPT with the non-blocking three-phase commit protocol provides better peak throughput performance than all of the standard two-phase blocking protocols evaluated in our study. Further, OPT makes efficient use of the borrowing approach and its performance is robust for practical workloads. In short, OPT is a portable, practical, high-performance, efficient and robust distributed commit protocol. fl A partial and preliminary version of the results presented here appeared earlier in Revisiting Commit Processing in Distributed Database Systems, Proc. of ACM SIGMOD Intl. Conf. on Management of Data, Tucson, Arizona, May 1997. 
Abstract-found: 1
Intro-found: 1
Reference: [AA90] <author> D. Agrawal and A. Abbadi, </author> <title> "Locks with Constrained Sharing", </title> <booktitle> Proc. of 9th Symp. on Principles of Database Systems (PODS), </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: In short, OPT implements a controlled lending policy. 6 Similar, but unrelated, strategies of allowing access to uncommitted data have been used earlier for developing improved concurrency control protocols (see, for example, <ref> [AA90, RS96] </ref>). 7 This expectation is not valid in conjunction with concurrency control protocols that delay conflict resolution for example, validation-based techniques. 11 3.2 Integrating Prior 2PC Optimizations with OPT The optimistic premise underlying the OPT protocol was described above.
Reference: [AC95] <author> Y. Al-Houmaily and P. Chrysanthis, </author> <title> "Two-Phase Commit in Gigabit-Networked Distributed Databases", </title> <booktitle> Proc. of 8th Intl. Conf. on Parallel and Distributed Computing Systems, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., <ref> [AC95, LL93, MLO86, SBCM95] </ref>) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. Thorough quantitative performance evaluation with regard to overall transaction processing metrics such as mean response time or peak throughput has, however, received virtually no attention. <p> These include linear 2PC [Gra78], distributed 2PC [OV91], Unsolicited Vote (UV) [Sto79], Early Prepare (EP) and Coordinator Log (CL) [SC90, SC93] protocols. More recently, the Implicit Yes Vote (IYV) protocol <ref> [AC95] </ref> and the two-phase abort (2PA) protocol [BC96] have been proposed for distributed database systems that are expected to be connected by extremely high speed (gigabits per second) networks. <p> A difficulty with this approach is that ensuring WAL and the rolling back of aborted transactions becomes more complex and cumbersome since these functionalities have to be implemented over the network at remote sites <ref> [AC95] </ref>. As mentioned earlier in Section 2.3, the PC protocol introduces an additional force-write (the collecting log record) and therefore incurs more overheads as compared to the PA protocol for both aborted transactions as well as read-only transactions. <p> Mechanisms for minimizing the logging activity of PC and making its overheads comparable to that of PA have been proposed in [LL93] and [ACL97]. The recently proposed Implicit Yes Vote (IYV) protocol <ref> [AC95, AC96] </ref> and two-phase abort (2PA) protocols [BC95, BC96] are designed to exploit the high data transfer rates of gigabit networks. In a gigabit network, the number of messages exchanged, and not the size of the messages, is the primary concern.
Reference: [AC96] <author> Y. Al-Houmaily and P. Chrysanthis, </author> <title> "The Implicit-Yes Vote Commit Protocol with Delegation of Commitment", </title> <booktitle> Proc. of 9th Intl. Conf. on Parallel and Distributed Computing Systems, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: Mechanisms for minimizing the logging activity of PC and making its overheads comparable to that of PA have been proposed in [LL93] and [ACL97]. The recently proposed Implicit Yes Vote (IYV) protocol <ref> [AC95, AC96] </ref> and two-phase abort (2PA) protocols [BC95, BC96] are designed to exploit the high data transfer rates of gigabit networks. In a gigabit network, the number of messages exchanged, and not the size of the messages, is the primary concern.
Reference: [ACL87] <author> R. Agrawal, M. Carey and M. Livny, </author> <title> "Concurrency Control Performance Modeling: Alternatives and Implications", </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 12(4), </volume> <year> 1987. </year>
Reference-contexts: A page that is read is updated with probability U pdateP rob. 9 A transaction that is aborted is restarted after a delay and makes the same data accesses as its original incarnation, that is, restarts are not "fake" <ref> [ACL87] </ref>. <p> The duration of the delay is equal to the average transaction response time this is the same heuristic as that used in most of the earlier transaction management studies <ref> [ACL87, CL88, CL89, CL91] </ref> the goal of the heuristic is to ensure that the data conflict that resulted in the abort does not recur. <p> As the multiprogramming level is increased beyond a certain level, however, the system starts thrashing due to data contention, resulting in degraded transaction throughput. This behavior is similar to those observed in earlier transaction management studies (e.g. <ref> [ACL87, CL88, CL89, CL91, FHRT93] </ref>). Comparing the relative performance of the protocols in Figure 4a, we observe that the centralized system (CENT) performs the best, as expected, and that the peak performance of distributed processing/centralized commit (DPCC) is close to that of CENT. <p> In this sense, data contention is a more "fundamental" determinant of database system performance. For this experiment, the physical resources (CPUs and disks) were made "infinite", that is, there is no queueing for these resources <ref> [ACL87] </ref>. The other parameter values are the same as those used in Experiment 1. The results of this experiment are shown in Figures 5a through 5d. In these figures, as in the previous experiment, CENT shows the best performance and the performance of DPCC is close to that of CENT. <p> For example, for a surprise abort percentage of 3 in the pure DC case, the crossover occurs at an MPL of 7 for OPT and OPT-PA. The reason for the crossover is the following: In our model, as in earlier transaction management studies (e.g. <ref> [ACL87] </ref>), aborted transactions are delayed before restarting with the delay period set equal to the average response time. This delay effectively becomes a crude way of controlling the data contention in the system.
Reference: [ACL97] <author> Y. Al-Houmaily, P. Chrysanthis and S. Levitan, </author> <title> "An Argument in Favor of the Presumed Commit Protocol", </title> <booktitle> Proc. of 13th IEEE Intl. Conf. on Data Engineering, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: Mechanisms for minimizing the logging activity of PC and making its overheads comparable to that of PA have been proposed in [LL93] and <ref> [ACL97] </ref>. The recently proposed Implicit Yes Vote (IYV) protocol [AC95, AC96] and two-phase abort (2PA) protocols [BC95, BC96] are designed to exploit the high data transfer rates of gigabit networks. In a gigabit network, the number of messages exchanged, and not the size of the messages, is the primary concern.
Reference: [Bha87] <editor> B. Bhargava, (editor), </editor> <title> Concurrency and Reliability in Distributed Database Systems, </title> <publisher> Van Nostrand Rein-hold, </publisher> <year> 1987. </year>
Reference-contexts: Most importantly, this guarantee is valid even in the presence of site or network failures. Over the last two decades, a variety of commit protocols have been proposed by database researchers (see <ref> [Koh81, Bha87, OV91] </ref> for surveys). These include the classical two phase commit (2PC) protocol [Gra78, LS76], its variations such as presumed commit and presumed abort [LL93, MLO86], and three phase commit (3PC) [Ske81].
Reference: [BC95] <author> S. Banerjee and P. Chrysanthis, </author> <title> "Data Sharing and Recovery in Gigabit-Networked Databases", </title> <booktitle> Proc. of 4th Intl. Conf. on Computer Communications and Networks, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: Mechanisms for minimizing the logging activity of PC and making its overheads comparable to that of PA have been proposed in [LL93] and [ACL97]. The recently proposed Implicit Yes Vote (IYV) protocol [AC95, AC96] and two-phase abort (2PA) protocols <ref> [BC95, BC96] </ref> are designed to exploit the high data transfer rates of gigabit networks. In a gigabit network, the number of messages exchanged, and not the size of the messages, is the primary concern.
Reference: [BC96] <author> S. Banerjee and P. Chrysanthis, </author> <title> "A Fast and Robust Failure Recovery Scheme for Shared-Nothing Gigabit-Networked Databases", </title> <booktitle> Proc. of 9th Intl. Conf. on Parallel and Distributed Computing Systems, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: These include linear 2PC [Gra78], distributed 2PC [OV91], Unsolicited Vote (UV) [Sto79], Early Prepare (EP) and Coordinator Log (CL) [SC90, SC93] protocols. More recently, the Implicit Yes Vote (IYV) protocol [AC95] and the two-phase abort (2PA) protocol <ref> [BC96] </ref> have been proposed for distributed database systems that are expected to be connected by extremely high speed (gigabits per second) networks. We give a brief description of these other protocols below and also discuss how (some of) these can be integrated with OPT. <p> Mechanisms for minimizing the logging activity of PC and making its overheads comparable to that of PA have been proposed in [LL93] and [ACL97]. The recently proposed Implicit Yes Vote (IYV) protocol [AC95, AC96] and two-phase abort (2PA) protocols <ref> [BC95, BC96] </ref> are designed to exploit the high data transfer rates of gigabit networks. In a gigabit network, the number of messages exchanged, and not the size of the messages, is the primary concern.
Reference: [BHG87] <author> P. Bernstein, V. Hadzilacos and N. Goodman, </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Although this implies that dirty reads are permitted, there is no danger of incurring cascading aborts <ref> [BHG87] </ref> since the borrowing is done in a controlled manner. The protocol is easy to implement and to incorporate in current systems, and can be integrated, often synergistically, with most other optimizations proposed earlier. <p> Each cohort that is ready to commit first force-writes a 4 It is impossible to design commit protocols that are completely non-blocking to both site and link failures <ref> [BHG87] </ref>. However, the number of simultaneous failures that can be tolerated before blocking arises depends on the protocol design. 6 prepare log record to its local stable storage and then sends a yes vote to the master. <p> 6 We will hereafter refer to this protocol as OPT. 3.1 Aborts in OPT do not Cascade An important point to note here is that OPT's policy of using uncommitted data is generally not recommended in database systems since this can potentially lead to the well-known problem of cascading aborts <ref> [BHG87] </ref> if the transaction whose dirty data has been accessed is later aborted. However, for the OPT protocol, this problem is alleviated due to two reasons: 1. <p> However, the CPU overheads of message transfer, given by the 9 A page write operation is always preceded by a read for the same page; that is, there are no "blind writes" <ref> [BHG87] </ref>. 17 M sgCP U parameter, are taken into account at both the sending and the receiving sites. <p> The commit protocol is initiated when the transaction has completed its data processing. 4.5 Concurrency Control For transaction concurrency control (CC), we use the distributed strict two-phase locking (2PL) protocol <ref> [BHG87] </ref>. Transactions, through their cohorts, set read locks on pages that they read and update locks on pages that need to be updated. All locks are held until the receipt of the prepare message from the master.
Reference: [CKL90] <author> M. Carey, S. Krishnamurthi and M. Livny, </author> <title> "Load Control for Locking: The `Half-and-Half' Approach", </title> <booktitle> Proc. of 9th Symp. on Principles of Database Systems, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: We also emphasize the peak throughput achieved by each protocol since this represents its maximum attainable performance and, by using a suitable admission control policy (for example, Half-and-Half <ref> [CKL90] </ref>), the throughput can be maintained at this level in high-performance systems.
Reference: [CL88] <author> M. Carey and M. Livny, </author> <title> "Distributed Concurrency Control Performance: A Study of Algorithms, Distribution, and Replication", </title> <booktitle> Proc. of 14th Intl. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: In light of the above, it seems reasonable to expect that the results of detailed studies of commit protocol performance would be available to assist distributed database system designers in making an informed choice (as is the case with, for example, distributed concurrency control <ref> [CL88, CL89, CL91, FHRT93] </ref>). Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., [AC95, LL93, MLO86, SBCM95]) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. <p> Our simulation model is similar to the one used in <ref> [CL88] </ref> to study distributed concurrency control protocols. The model consists of a database that is distributed, in a non-replicated manner, over N sites connected by a network. Figure 3 shows the general structure of the model. <p> The duration of the delay is equal to the average transaction response time this is the same heuristic as that used in most of the earlier transaction management studies <ref> [ACL87, CL88, CL89, CL91] </ref> the goal of the heuristic is to ensure that the data conflict that resulted in the abort does not recur. <p> We do not explicitly model the overheads for detecting deadlocks or for concurrency control since (a) these costs would be similar across all the commit protocols, and (b) they are usually negligible compared to the overall cost of accessing data <ref> [CL88] </ref>. 4.6 Surprise Aborts With the 2PL CC mechanism described above, there is no possibility of serializability-induced aborts occurring in the commit phase, as mentioned in Section 3.1. <p> As the multiprogramming level is increased beyond a certain level, however, the system starts thrashing due to data contention, resulting in degraded transaction throughput. This behavior is similar to those observed in earlier transaction management studies (e.g. <ref> [ACL87, CL88, CL89, CL91, FHRT93] </ref>). Comparing the relative performance of the protocols in Figure 4a, we observe that the centralized system (CENT) performs the best, as expected, and that the peak performance of distributed processing/centralized commit (DPCC) is close to that of CENT.
Reference: [CL89] <author> M. Carey and M. Livny, </author> <title> "Parallelism and Concurrency Control Performance in Distributed Database Machines", </title> <booktitle> Proc. of ACM SIGMOD Conf., </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: In light of the above, it seems reasonable to expect that the results of detailed studies of commit protocol performance would be available to assist distributed database system designers in making an informed choice (as is the case with, for example, distributed concurrency control <ref> [CL88, CL89, CL91, FHRT93] </ref>). Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., [AC95, LL93, MLO86, SBCM95]) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. <p> The duration of the delay is equal to the average transaction response time this is the same heuristic as that used in most of the earlier transaction management studies <ref> [ACL87, CL88, CL89, CL91] </ref> the goal of the heuristic is to ensure that the data conflict that resulted in the abort does not recur. <p> As the multiprogramming level is increased beyond a certain level, however, the system starts thrashing due to data contention, resulting in degraded transaction throughput. This behavior is similar to those observed in earlier transaction management studies (e.g. <ref> [ACL87, CL88, CL89, CL91, FHRT93] </ref>). Comparing the relative performance of the protocols in Figure 4a, we observe that the centralized system (CENT) performs the best, as expected, and that the peak performance of distributed processing/centralized commit (DPCC) is close to that of CENT.
Reference: [CL91] <author> M. Carey and M. Livny, </author> <title> "Conflict Detection Tradeoffs for Replicated Data", </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 16(4), </volume> <year> 1991. </year>
Reference-contexts: In light of the above, it seems reasonable to expect that the results of detailed studies of commit protocol performance would be available to assist distributed database system designers in making an informed choice (as is the case with, for example, distributed concurrency control <ref> [CL88, CL89, CL91, FHRT93] </ref>). Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., [AC95, LL93, MLO86, SBCM95]) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. <p> The duration of the delay is equal to the average transaction response time this is the same heuristic as that used in most of the earlier transaction management studies <ref> [ACL87, CL88, CL89, CL91] </ref> the goal of the heuristic is to ensure that the data conflict that resulted in the abort does not recur. <p> As the multiprogramming level is increased beyond a certain level, however, the system starts thrashing due to data contention, resulting in degraded transaction throughput. This behavior is similar to those observed in earlier transaction management studies (e.g. <ref> [ACL87, CL88, CL89, CL91, FHRT93] </ref>). Comparing the relative performance of the protocols in Figure 4a, we observe that the centralized system (CENT) performs the best, as expected, and that the peak performance of distributed processing/centralized commit (DPCC) is close to that of CENT.
Reference: [Coo82] <author> E. Cooper, </author> <title> "Analysis of Distributed Commit Protocols", </title> <booktitle> Proc. of ACM Sigmod Conf., </booktitle> <month> June </month> <year> 1982. </year>
Reference-contexts: We are aware of only two exceptions in this regard: (1) In <ref> [Coo82] </ref>, the expected number of sites that are decision-blocked after a failure was determined through a probabilistic analysis. <p> It compared the performance of commit protocols in a client/server type of database environment. As explained below, the scope and methodology of both these studies is considerably different from ours. The first difference with Cooper's work <ref> [Coo82] </ref> arises from our focus being prepared data blocking, not decision blocking. The former is of relevance to this paper because of our interest in studying the performance effects of commit protocols on normal transaction processing.
Reference: [Esw76] <author> K. Eswaran et al, </author> <title> "The Notions of Consistency and Predicate Locks in a Database Systems", </title> <journal> Comm. of ACM, </journal> <month> 19(11), </month> <year> 1976. </year>
Reference-contexts: to local data conflicts, and (b) the sibling cohorts are also expected to eventually vote to commit since they have survived all the data conflicts that occurred prior to their sending of the workdone messages. 7 In fact, if we assume that a locking-based concurrency control mechanism such as 2PL <ref> [Esw76] </ref> is used, it is easy to verify that there is no possibility of sibling cohorts aborting, during the commit processing period, due to serializability considerations. Therefore, an abort vote can arise only due to other reasons such as violation of integrity constraints, software errors, system failure, etc.
Reference: [FHRT93] <author> P. Franaszek, J. Haritsa, J. Robinson and A. Thomasian, </author> <title> "Distributed Concurrency Control based on Limited Wait-Depth", </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <month> November </month> <year> 1993. </year>
Reference-contexts: In light of the above, it seems reasonable to expect that the results of detailed studies of commit protocol performance would be available to assist distributed database system designers in making an informed choice (as is the case with, for example, distributed concurrency control <ref> [CL88, CL89, CL91, FHRT93] </ref>). Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., [AC95, LL93, MLO86, SBCM95]) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. <p> As the multiprogramming level is increased beyond a certain level, however, the system starts thrashing due to data contention, resulting in degraded transaction throughput. This behavior is similar to those observed in earlier transaction management studies (e.g. <ref> [ACL87, CL88, CL89, CL91, FHRT93] </ref>). Comparing the relative performance of the protocols in Figure 4a, we observe that the centralized system (CENT) performs the best, as expected, and that the peak performance of distributed processing/centralized commit (DPCC) is close to that of CENT.
Reference: [Gra78] <author> J. Gray, </author> <booktitle> "Notes on Database Operating Systems", Operating Systems: An Advanced Course, Lecture Notes in Computer Science, </booktitle> <volume> 60, </volume> <year> 1978 </year>
Reference-contexts: Most importantly, this guarantee is valid even in the presence of site or network failures. Over the last two decades, a variety of commit protocols have been proposed by database researchers (see [Koh81, Bha87, OV91] for surveys). These include the classical two phase commit (2PC) protocol <ref> [Gra78, LS76] </ref>, its variations such as presumed commit and presumed abort [LL93, MLO86], and three phase commit (3PC) [Ske81]. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed. <p> For this model, a variety of transaction commit protocols have been devised, most of which are based on the classical two phase commit (2PC) protocol <ref> [Gra78] </ref>, described later in this section. <p> This is usually implemented by using logging mechanisms such as WAL (write-ahead-logging) <ref> [Gra78] </ref>, which maintain sequential histories of transaction actions in stable storage. The protocol also assumes that, if necessary, log records can be force-written, that is, written synchronously to stable storage. <p> The cost of each forced log write is the same as the cost of writing a data page to the disk. The overheads of flushing the transaction log records related to data processing (i.e., WAL <ref> [Gra78] </ref>), however, are not modeled. This is because these records are generated during the cohort's data phase and are therefore independent of the choice of commit protocol. <p> This supports our above conclusion. 7 Other Commit Protocols and Optimizations A variety of commit protocols have also been proposed in the literature in addition to those evaluated in our study (2PC,PA,PC,3PC). These include linear 2PC <ref> [Gra78] </ref>, distributed 2PC [OV91], Unsolicited Vote (UV) [Sto79], Early Prepare (EP) and Coordinator Log (CL) [SC90, SC93] protocols. <p> We give a brief description of these other protocols below and also discuss how (some of) these can be integrated with OPT. We also consider commit protocols that have been proposed with a relaxed notion of atomicity in mind. 7.1 Protocols Satisfying Traditional Atomicity The linear 2PC <ref> [Gra78] </ref> protocol (also known as nested 2PC ) reduces the number of the message-exchanges in 2PC by ordering all the cohorts in a linear chain for communication purposes. This, however, is done at the cost of concurrency in the commit processing, resulting in larger commit processing times.
Reference: [Gra81] <author> J. Gray, </author> <title> "The Transaction Concept: Virtues and Limitations", </title> <booktitle> Proc. of 7th Intl. Conf. on Very Large Data Bases, </booktitle> <year> 1981. </year>
Reference-contexts: Third, the compensation transactions need to be designed in advance so that they can be executed as soon as errors are detected this means that the transaction workload must be fully characterized a priori. Finally, "real actions" <ref> [Gra81] </ref> such as firing a weapon or dispensing cash may not be compensatable at all [LKS91a]. 8 Related Performance Work As mentioned in the Introduction, virtually all the earlier performance studies of commit protocols have been limited to comparing protocols based on the number of messages and the number of force-writes
Reference: [Gup97] <author> R. Gupta, </author> <title> "Commit Processing in Distributed On-Line and Real-Time Transaction Processing Systems", M.Sc.(Engg.) </title> <type> Thesis, </type> <institution> SERC, Indian Institute of Science, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: The detailed results for all the sequential experiments are available in <ref> [Gup97] </ref> for illustrative purposes, we present here the results for the baseline RC+DC and pure DC situations in Figures 11a and 11b, respectively. 32 5.9 Other Experiments We conducted several other experiments to explore various regions of the workload space. <p> These include workloads with different database sizes, non-zero think times, etc. The relative performance of the protocols in these additional experiments remained qualitatively similar to that seen in the experiments described here (see <ref> [Gup97] </ref> for the details). 6 Lending Variations of OPT In the previous section, we quantitatively demonstrated that the OPT approach is conducive to good performance. <p> Similar differences exist in the descriptions of the other protocols as well (see <ref> [Gup97] </ref> for details). 9 Conclusions In this paper, we have quantitatively investigated the performance implications of supporting distributed transaction atomicity.
Reference: [GHRS96] <author> R. Gupta, J. Haritsa, K. Ramamritham and S. Seshadri, </author> <title> "Commit Processing in Distributed Real-Time Database Systems", </title> <booktitle> Proc. of 17th IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: This, in essence, is a "win-win" situation. 1 A suitably modified version of OPT exhibited similar good performance characteristics in our recent research on commit processing in distributed real-time database systems <ref> [GHRS96, GHR97] </ref>. 4 * OPT's design is based on the assumption that transactions that lend their uncommitted data will almost always commit.
Reference: [GHR97] <author> R. Gupta, J. Haritsa and K. Ramamritham, </author> <title> "More Optimism about Real-Time Distributed Commit Processing", </title> <booktitle> Proc. of 18th IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: This, in essence, is a "win-win" situation. 1 A suitably modified version of OPT exhibited similar good performance characteristics in our recent research on commit processing in distributed real-time database systems <ref> [GHRS96, GHR97] </ref>. 4 * OPT's design is based on the assumption that transactions that lend their uncommitted data will almost always commit.
Reference: [Koh81] <author> W. Kohler, </author> <title> "A Survey of Techniques for Synchronization and Recovery in Decentralized Computer Systems", </title> <journal> ACM Computing Surveys, </journal> <volume> 13(2), </volume> <month> June </month> <year> 1981. </year>
Reference-contexts: Most importantly, this guarantee is valid even in the presence of site or network failures. Over the last two decades, a variety of commit protocols have been proposed by database researchers (see <ref> [Koh81, Bha87, OV91] </ref> for surveys). These include the classical two phase commit (2PC) protocol [Gra78, LS76], its variations such as presumed commit and presumed abort [LL93, MLO86], and three phase commit (3PC) [Ske81].
Reference: [KLS90] <author> H. Korth, E. Levy and A. Silberschatz, </author> <title> "A Formal Approach to Recovery by Compensating Transactions", </title> <booktitle> Proc. of 16th VLDB Conf., </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: While the compensation-based approach certainly appears to have the potential to improve transaction response times, yet there are quite a few practical difficulties. First, the standard notion of transaction atomicity is not supported instead, a "relaxed" notion of atomicity <ref> [KLS90, LKS91a, LKS91b] </ref> is provided. Second, the design of a compensating transaction is an application-specific task since it is based on the application semantics.
Reference: [Lin84] <author> B. Lindsay et al, </author> <title> "Computation and Communication in R fl : A Distributed Database Manager", </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 2(1), </volume> <year> 1984. </year>
Reference-contexts: transaction can decide to initiate a commit operation and thus become the root of the transaction commit tree [MD94, SBCM95]. 3 In the most general case, each of the cohorts may itself spawn off sub-transactions at other sites, leading to the "tree of processes" transaction structure of System R fl <ref> [Lin84] </ref> for simplicity, we only consider a two-level tree here. 5 To ensure that such major disruptions do not occur, efforts have been made to design "non-blocking commit protocols".
Reference: [LAA94] <author> M. Liu, D. Agrawal and A. El Abbadi, </author> <title> "The Performance of Two-Phase Commit Protocols in the Presence of Site Failures", </title> <booktitle> Proc. of 24th Intl. Symp. on Fault-Tolerant Computing, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: It compared a variety of two-phase and three-phase protocols, including 2PC, Linear 2PC and 3PC, with regard to this metric. (2) In <ref> [LAA94] </ref>, end-user metrics similar to those evaluated in our study were considered and evaluated using a simulation model. It compared the performance of commit protocols in a client/server type of database environment. As explained below, the scope and methodology of both these studies is considerably different from ours. <p> Secondly, we explicitly model both message and logging overheads, whereas their analysis incorporated only message overheads. Finally, we include the industry-standard PA and PC protocols in our evaluation, whereas their work predated these protocols. Turning to <ref> [LAA94] </ref>, recall that we model a fully distributed database environment wherein each site can host both transaction masters and transaction cohorts. In contrast, a client/server database type of environment is considered in [LAA94], where the master of a transaction resides at the client site and the cohorts of the transaction are <p> Turning to <ref> [LAA94] </ref>, recall that we model a fully distributed database environment wherein each site can host both transaction masters and transaction cohorts. In contrast, a client/server database type of environment is considered in [LAA94], where the master of a transaction resides at the client site and the cohorts of the transaction are executed at the server sites. Apart from this major difference in the system model, there are many other significant differences: 1.
Reference: [LKS91a] <author> E. Levy, H. Korth and A. Silberschatz, </author> <title> "An optimistic commit protocol for distributed transaction management", </title> <booktitle> Proc. of ACM SIGMOD Conf., </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: While the compensation-based approach certainly appears to have the potential to improve transaction response times, yet there are quite a few practical difficulties. First, the standard notion of transaction atomicity is not supported instead, a "relaxed" notion of atomicity <ref> [KLS90, LKS91a, LKS91b] </ref> is provided. Second, the design of a compensating transaction is an application-specific task since it is based on the application semantics. <p> Finally, "real actions" [Gra81] such as firing a weapon or dispensing cash may not be compensatable at all <ref> [LKS91a] </ref>. 8 Related Performance Work As mentioned in the Introduction, virtually all the earlier performance studies of commit protocols have been limited to comparing protocols based on the number of messages and the number of force-writes that 15 These papers consider real-time database environments but their approach is also applicable to
Reference: [LKS91b] <author> E. Levy, H. Korth and A. Silberschatz, </author> <title> "A theory of relaxed atomicity", </title> <booktitle> Proc. of ACM Symp. on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1991. </year> <month> 44 </month>
Reference-contexts: While the compensation-based approach certainly appears to have the potential to improve transaction response times, yet there are quite a few practical difficulties. First, the standard notion of transaction atomicity is not supported instead, a "relaxed" notion of atomicity <ref> [KLS90, LKS91a, LKS91b] </ref> is provided. Second, the design of a compensating transaction is an application-specific task since it is based on the application semantics.
Reference: [LL93] <author> B. Lampson and D. Lomet, </author> <title> "A New Presumed Commit Optimization for Two Phase Commit", </title> <booktitle> Proc. of 19th Intl. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Over the last two decades, a variety of commit protocols have been proposed by database researchers (see [Koh81, Bha87, OV91] for surveys). These include the classical two phase commit (2PC) protocol [Gra78, LS76], its variations such as presumed commit and presumed abort <ref> [LL93, MLO86] </ref>, and three phase commit (3PC) [Ske81]. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed. <p> In addition, several log records are generated, some of which have to be "forced", that is, flushed to disk immediately in a synchronous manner. Due to this series of synchronous message and logging overheads, commit processing can result in a significant increase in transaction response times <ref> [LL93, SBCM95, SJR91] </ref>. Therefore, the choice of commit protocol is an important design decision for distributed database systems. <p> Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., <ref> [AC95, LL93, MLO86, SBCM95] </ref>) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. Thorough quantitative performance evaluation with regard to overall transaction processing metrics such as mean response time or peak throughput has, however, received virtually no attention. <p> Mechanisms for minimizing the logging activity of PC and making its overheads comparable to that of PA have been proposed in <ref> [LL93] </ref> and [ACL97]. The recently proposed Implicit Yes Vote (IYV) protocol [AC95, AC96] and two-phase abort (2PA) protocols [BC95, BC96] are designed to exploit the high data transfer rates of gigabit networks.
Reference: [LM94] <author> M. C. Little and D. L. McCue, </author> <title> C++SIM User's Guide Public Release 1.5, </title> <institution> Dept. of Computing Science, Univ. of Newcastle upon Tyne, U.K., </institution> <year> 1994. </year>
Reference-contexts: The simulator was written in C++SIM <ref> [LM94] </ref>, an object-oriented simulation testbed, and the experiments were conducted on UltraSparc workstations running Solaris 2.5 operating system.
Reference: [LS76] <author> B. Lampson and H. Sturgis, </author> <title> "Crash Recovery in a Distributed Data Storage System", </title> <type> Tech. Report, </type> <institution> Xerox Palo Alto Research Center, </institution> <year> 1976. </year>
Reference-contexts: Most importantly, this guarantee is valid even in the presence of site or network failures. Over the last two decades, a variety of commit protocols have been proposed by database researchers (see [Koh81, Bha87, OV91] for surveys). These include the classical two phase commit (2PC) protocol <ref> [Gra78, LS76] </ref>, its variations such as presumed commit and presumed abort [LL93, MLO86], and three phase commit (3PC) [Ske81]. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed.
Reference: [Moh92] <author> C. Mohan et al, </author> <title> "ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging", </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 17(1), </volume> <year> 1992. </year>
Reference-contexts: The above modifications do not appear difficult to incorporate in current database system software. In fact, some of them are already provided in current DBMS for example, the high-performance industrial-strength ARIES recovery system <ref> [Moh92] </ref> implements operation logging to support semantically rich lock modes that permit updating of uncommitted data.
Reference: [MD94] <author> C. Mohan and D. Dievendorff, </author> <title> "Recent Work on Distributed Commit Protocols, </title> <journal> and Recoverable Messaging and Queuing" Data Engineering Bulletin, </journal> <volume> 17(1), </volume> <year> 1994. </year>
Reference-contexts: transaction processing grinding to a halt (as explained in Section 2.4), and they are therefore termed as "blocking protocols". 2 An alternative model is the "peer-to-peer" environment, wherein any cohort in the transaction can decide to initiate a commit operation and thus become the root of the transaction commit tree <ref> [MD94, SBCM95] </ref>. 3 In the most general case, each of the cohorts may itself spawn off sub-transactions at other sites, leading to the "tree of processes" transaction structure of System R fl [Lin84] for simplicity, we only consider a two-level tree here. 5 To ensure that such major disruptions do not <p> The above optimizations of 2PC have been implemented in a number of database products including Tandem's TMF, DEC's VAX/VMS, Transarc's Encina and USL's TUXEDO. In fact, PA is now part of the ISO-OSI and X/OPEN distributed transaction processing standards <ref> [MD94, SBCM95] </ref>. 2.4 Three Phase Commit A fundamental problem with all of the above protocols is that cohorts may become blocked in the event of a site failure and remain blocked until the failed site recovers.
Reference: [MLO86] <author> C. Mohan, B. Lindsay and R. Obermarck, </author> <title> "Transaction Management in the R fl Distributed Database Management System", </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 11(4), </volume> <year> 1986. </year>
Reference-contexts: Over the last two decades, a variety of commit protocols have been proposed by database researchers (see [Koh81, Bha87, OV91] for surveys). These include the classical two phase commit (2PC) protocol [Gra78, LS76], its variations such as presumed commit and presumed abort <ref> [LL93, MLO86] </ref>, and three phase commit (3PC) [Ske81]. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed. <p> Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., <ref> [AC95, LL93, MLO86, SBCM95] </ref>) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. Thorough quantitative performance evaluation with regard to overall transaction processing metrics such as mean response time or peak throughput has, however, received virtually no attention. <p> In the remainder of this section, we briefly describe the 2PC protocol and a few popular variations of this protocol complete descriptions are available in <ref> [MLO86, Ske81, SBCM95] </ref>. <p> The above sequence of actions is shown pictorially in Figure 1. 2.2 Presumed Abort As described above, the 2PC protocol requires transmission of several messages and writing or force-writing of several log records. A variant of the 2PC protocol, called presumed abort (PA) <ref> [MLO86] </ref>, tries to reduce these message and logging overheads by requiring all participants to follow, during failure recovery, an "in the no-information case, abort" rule. <p> In this variation, called presumed commit (PC) <ref> [MLO86] </ref>, the overheads are reduced for committing transactions, rather than aborted transactions, by requiring all participants to follow, during failure recovery, an "in the no-information case, commit" rule. <p> In our understanding of commit protocols, there is no relationship between the timing of data updates and specific protocols in fact, no mention of data updates is made in <ref> [MLO86] </ref>, the paper in which the PA and PC protocols were first proposed. <p> We should note that the above conclusion is limited to the update-oriented transaction workloads considered here PA and PC have additional optimizations for fully or partially read-only transactions <ref> [MLO86] </ref> that may have a significant impact in workloads having a large fraction of these kinds of transactions. 3.
Reference: [OV91] <author> M. Ozsu and P. Valduriez, </author> <title> Principles of Distributed Database Systems, </title> <publisher> Prentice-Hall, </publisher> <year> 1991. </year>
Reference-contexts: Most importantly, this guarantee is valid even in the presence of site or network failures. Over the last two decades, a variety of commit protocols have been proposed by database researchers (see <ref> [Koh81, Bha87, OV91] </ref> for surveys). These include the classical two phase commit (2PC) protocol [Gra78, LS76], its variations such as presumed commit and presumed abort [LL93, MLO86], and three phase commit (3PC) [Ske81]. <p> These protocols, in the event of a site failure, permit transactions that had cohorts executing at the failed site to terminate at the operational sites without waiting for the failed site to recover <ref> [OV91, Ske81] </ref>. 4 To achieve their functionality, however, they usually incur additional messages and forced-log-writes than their blocking counterparts. In general, "two-phase" commit protocols are susceptible to blocking whereas "three-phase" commit protocols are non-blocking. <p> This supports our above conclusion. 7 Other Commit Protocols and Optimizations A variety of commit protocols have also been proposed in the literature in addition to those evaluated in our study (2PC,PA,PC,3PC). These include linear 2PC [Gra78], distributed 2PC <ref> [OV91] </ref>, Unsolicited Vote (UV) [Sto79], Early Prepare (EP) and Coordinator Log (CL) [SC90, SC93] protocols. <p> This, however, is done at the cost of concurrency in the commit processing, resulting in larger commit processing times. In distributed 2PC <ref> [OV91] </ref>, each cohort broadcasts its vote to all other cohorts. This means that each cohort can independently arrive at the final decision without needing to have this information communicated by the master.
Reference: [RS96] <author> R. Rastogi and A. Silberschatz, </author> <title> "On Commutativity Relationship for Atomicity and Serializability in Database Systems", </title> <booktitle> Proc. of IEEE Intl. Conf. on Data Engineering, </booktitle> <year> 1996. </year>
Reference-contexts: In short, OPT implements a controlled lending policy. 6 Similar, but unrelated, strategies of allowing access to uncommitted data have been used earlier for developing improved concurrency control protocols (see, for example, <ref> [AA90, RS96] </ref>). 7 This expectation is not valid in conjunction with concurrency control protocols that delay conflict resolution for example, validation-based techniques. 11 3.2 Integrating Prior 2PC Optimizations with OPT The optimistic premise underlying the OPT protocol was described above.
Reference: [SBCM95] <author> G. Samaras, K. Britton, A. Citron and C. Mohan, </author> <title> "Two-Phase Commit Optimizations in a Commercial Distributed Environment", </title> <journal> Journal of Distributed and Parallel Databases, </journal> <volume> 3, </volume> <booktitle> 1995 (also in Proc. of 9th Intl. Conf. on Data Engineering (ICDE), </booktitle> <year> 1993). </year>
Reference-contexts: In addition, several log records are generated, some of which have to be "forced", that is, flushed to disk immediately in a synchronous manner. Due to this series of synchronous message and logging overheads, commit processing can result in a significant increase in transaction response times <ref> [LL93, SBCM95, SJR91] </ref>. Therefore, the choice of commit protocol is an important design decision for distributed database systems. <p> Surprisingly, however, most of the earlier performance studies of commit protocols (e.g., <ref> [AC95, LL93, MLO86, SBCM95] </ref>) have been limited to comparing protocols based on the number of messages and the number of log-writes that they incur. Thorough quantitative performance evaluation with regard to overall transaction processing metrics such as mean response time or peak throughput has, however, received virtually no attention. <p> transaction processing grinding to a halt (as explained in Section 2.4), and they are therefore termed as "blocking protocols". 2 An alternative model is the "peer-to-peer" environment, wherein any cohort in the transaction can decide to initiate a commit operation and thus become the root of the transaction commit tree <ref> [MD94, SBCM95] </ref>. 3 In the most general case, each of the cohorts may itself spawn off sub-transactions at other sites, leading to the "tree of processes" transaction structure of System R fl [Lin84] for simplicity, we only consider a two-level tree here. 5 To ensure that such major disruptions do not <p> In the remainder of this section, we briefly describe the 2PC protocol and a few popular variations of this protocol complete descriptions are available in <ref> [MLO86, Ske81, SBCM95] </ref>. <p> The above optimizations of 2PC have been implemented in a number of database products including Tandem's TMF, DEC's VAX/VMS, Transarc's Encina and USL's TUXEDO. In fact, PA is now part of the ISO-OSI and X/OPEN distributed transaction processing standards <ref> [MD94, SBCM95] </ref>. 2.4 Three Phase Commit A fundamental problem with all of the above protocols is that cohorts may become blocked in the event of a site failure and remain blocked until the failed site recovers. <p> Apart from PA and PC, a variety of other optimizations have been proposed for the 2PC protocol. A comprehensive description and analysis of such optimizations is presented in <ref> [SBCM95] </ref>. <p> In our experiments, however, we found that these protocols provide tangible benefits over 2PC only in a few restricted situations. PC performed well only when the degree of distribution was high in current applications, however, the degree of distribution is usually quite low <ref> [SBCM95] </ref>. PA, on the other hand, performed only marginally better than 2PC even when the probability of surprise aborts was close to thirty percent in practice, surprise aborts occur only occasionally.
Reference: [SC90] <author> J. Stamos and F. Cristian, </author> <title> "A Low-Cost Atomic Commit Protocol", </title> <booktitle> Proc. of 9th Symp. on Reliable Distributed Systems, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: These include linear 2PC [Gra78], distributed 2PC [OV91], Unsolicited Vote (UV) [Sto79], Early Prepare (EP) and Coordinator Log (CL) <ref> [SC90, SC93] </ref> protocols. More recently, the Implicit Yes Vote (IYV) protocol [AC95] and the two-phase abort (2PA) protocol [BC96] have been proposed for distributed database systems that are expected to be connected by extremely high speed (gigabits per second) networks. <p> Thus, releasing the read locks would compromise the serializability semantics of the transaction. Moreover, a cohort in UV has to force-write a prepared log record each time it responds with the workdone message. In <ref> [SC90, SC93] </ref>, a combination of the UV and the PC protocols, called Early Prepare (EP), is proposed. They also propose a Coordinator Log (CL) protocol for client/server environments wherein cohorts piggyback the log records on the workdone messages to the master, instead of force-writing them locally.
Reference: [SC93] <author> J. Stamos and F. Cristian, </author> <title> "Coordinator Log Transaction Execution Protocol", </title> <journal> Journal of Distributed and Parallel Databases, </journal> <volume> 1(4), </volume> <year> 1993. </year>
Reference-contexts: These include linear 2PC [Gra78], distributed 2PC [OV91], Unsolicited Vote (UV) [Sto79], Early Prepare (EP) and Coordinator Log (CL) <ref> [SC90, SC93] </ref> protocols. More recently, the Implicit Yes Vote (IYV) protocol [AC95] and the two-phase abort (2PA) protocol [BC96] have been proposed for distributed database systems that are expected to be connected by extremely high speed (gigabits per second) networks. <p> Thus, releasing the read locks would compromise the serializability semantics of the transaction. Moreover, a cohort in UV has to force-write a prepared log record each time it responds with the workdone message. In <ref> [SC90, SC93] </ref>, a combination of the UV and the PC protocols, called Early Prepare (EP), is proposed. They also propose a Coordinator Log (CL) protocol for client/server environments wherein cohorts piggyback the log records on the workdone messages to the master, instead of force-writing them locally.
Reference: [SJR91] <author> P. Spiro, A. Joshi and T. Rengarajan, </author> <title> "Designing an Optimized Transaction Commit Protocol", </title> <journal> Digital Technical Journal, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: In addition, several log records are generated, some of which have to be "forced", that is, flushed to disk immediately in a synchronous manner. Due to this series of synchronous message and logging overheads, commit processing can result in a significant increase in transaction response times <ref> [LL93, SBCM95, SJR91] </ref>. Therefore, the choice of commit protocol is an important design decision for distributed database systems.
Reference: [SLKS92] <author> N. Soparkar, E. Levy, H. Korth and A. Silberschatz, </author> <title> "Adaptive Commitment for Real-Time Distributed Transactions", TR-92-15, </title> <type> CS, </type> <institution> Univ. of Texas (Austin), </institution> <year> 1992. </year>
Reference-contexts: Identifying and handling such deadlocks will impose extra overheads on the system. 7.3 Protocols Satisfying Relaxed Atomicity through Compensations A radically different approach to improving commit protocol performance is explored in <ref> [SLKS92, Yoo94] </ref>. 15 Here, individual sites are allowed to unilaterally commit the idea is that unilateral commitment results in improved response times. If it is later found that the decision is not consistent globally, "compensation" transactions are used to rectify the errors.
Reference: [Ske81] <author> D. Skeen, </author> <title> "Nonblocking Commit Protocols", </title> <booktitle> Proc. of ACM SIGMOD Conf., </booktitle> <month> June </month> <year> 1981. </year>
Reference-contexts: Over the last two decades, a variety of commit protocols have been proposed by database researchers (see [Koh81, Bha87, OV91] for surveys). These include the classical two phase commit (2PC) protocol [Gra78, LS76], its variations such as presumed commit and presumed abort [LL93, MLO86], and three phase commit (3PC) <ref> [Ske81] </ref>. To achieve their functionality, these commit protocols typically require exchange of multiple messages, in multiple phases, between the participating sites where the distributed transaction executed. In addition, several log records are generated, some of which have to be "forced", that is, flushed to disk immediately in a synchronous manner. <p> These protocols, in the event of a site failure, permit transactions that had cohorts executing at the failed site to terminate at the operational sites without waiting for the failed site to recover <ref> [OV91, Ske81] </ref>. 4 To achieve their functionality, however, they usually incur additional messages and forced-log-writes than their blocking counterparts. In general, "two-phase" commit protocols are susceptible to blocking whereas "three-phase" commit protocols are non-blocking. <p> In the remainder of this section, we briefly describe the 2PC protocol and a few popular variations of this protocol complete descriptions are available in <ref> [MLO86, Ske81, SBCM95] </ref>. <p> It is easy to see that if the duration of the blocked period is significant, major disruption of transaction processing activity could result. To address the blocking problem, a three phase commit (3PC) protocol was proposed in <ref> [Ske81] </ref>. This protocol achieves a non-blocking capability by inserting an extra phase, called the "precommit phase", in between the two phases of the 2PC protocol. In the precommit phase, a preliminary decision is reached regarding the fate of the transaction.
Reference: [Sto79] <author> M. Stonebraker, </author> <title> "Concurrency Control and Consistency of Multiple Copies of Data in Distributed IN-GRES", </title> <journal> IEEE Trans. on Software Engg., </journal> <volume> 5(3), </volume> <year> 1979. </year>
Reference-contexts: This supports our above conclusion. 7 Other Commit Protocols and Optimizations A variety of commit protocols have also been proposed in the literature in addition to those evaluated in our study (2PC,PA,PC,3PC). These include linear 2PC [Gra78], distributed 2PC [OV91], Unsolicited Vote (UV) <ref> [Sto79] </ref>, Early Prepare (EP) and Coordinator Log (CL) [SC90, SC93] protocols. More recently, the Implicit Yes Vote (IYV) protocol [AC95] and the two-phase abort (2PA) protocol [BC96] have been proposed for distributed database systems that are expected to be connected by extremely high speed (gigabits per second) networks. <p> The tradeoff here is between the reduction in commit processing time and the increase in message overheads due to the cohort vote broadcasts. The protocol used in the Distributed Ingres database system is called Unsolicited Vote (UV) <ref> [Sto79] </ref>. Here, cohorts enter the prepared state at the time of sending the workdone message itself. Thus, the workdone message acts as a implicit yes vote eliminating the need for sending the prepare messages by the master. <p> not appear to combine well is with protocols that allow cohorts to enter the prepared state unilaterally and therefore run the risk of having to revert to a processing state in case the master subsequently sends additional work to the cohort (for example, the Unsolicited Vote protocol of Distributed Ingres <ref> [Sto79] </ref>). 5. OPT's design is based on the assumption that transactions that lend their uncommitted data will almost always commit.
Reference: [Tri82] <author> K. S. Trivedi, </author> <title> Probability and Statistics with Reliability, Queueing, </title> <booktitle> and Computer Science Applications, </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: In practice, the average number of concurrent borrowings per site, B, can be expected to be significantly lower than the above upper bounds, as shown by the following estimator, based on Little's Law <ref> [Tri82] </ref> and simple combinatorics: B = (M P L p) fl p fl c where p = M P L fl AvgP reparedStateDuration AvgResponseT ime is the average number of prepared cohorts, and c = 1 D D + C 1 ! max (0;DC) k (D k) is the probability of <p> The commit processing, however, is like that of a cen 11 Since we are using a closed queueing model, the inverse relationship between throughput and response time (as per Little's Law <ref> [Tri82] </ref>) makes either a sufficient performance metric. 19 Table 2: Baseline Parameter Settings N umSites 8 N umCP U s 2 DBSize 8000 pages N umDataDisks 3 T ransT ype Parallel N umLogDisks 1 DistDegree 3 P ageCP U 5 ms CohortSize 6 pages P ageDisk 20 ms U pdateP rob
Reference: [Yoo94] <author> Y. Yoon, </author> <title> "Transaction Scheduling and Commit Processing for Real-Time Distributed Database Systems", </title> <type> Ph.D. Thesis, </type> <institution> Korea Adv. Inst. of Science and Technology, </institution> <month> May </month> <year> 1994. </year> <month> 45 </month>
Reference-contexts: Identifying and handling such deadlocks will impose extra overheads on the system. 7.3 Protocols Satisfying Relaxed Atomicity through Compensations A radically different approach to improving commit protocol performance is explored in <ref> [SLKS92, Yoo94] </ref>. 15 Here, individual sites are allowed to unilaterally commit the idea is that unilateral commitment results in improved response times. If it is later found that the decision is not consistent globally, "compensation" transactions are used to rectify the errors.
References-found: 44

