URL: ftp://ftp.huji.ac.il/users/yish/yish.icmas95.ps
Refering-URL: http://www.cs.huji.ac.il/~yish/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: yish@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Time and the Prisoner's Dilemma  of multiagent systems; Prisoner's Dilemma  
Author: Yishay Mor and Jeffrey S. Rosenschein ph: ---- 
Keyword: Conceptual  
Note: and theoretical foundations  
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Institute of Computer Science Hebrew University  
Abstract: This paper examines the integration of computational complexity into game theoretic models. The example focused on is the Prisoner's Dilemma, repeated for a finite length of time. We show that a minimal bound on the players' computational ability is sufficient to enable cooperative behavior. In addition, a variant of the repeated Prisoner's Dilemma game is suggested, in which players have the choice of opting out. This modification enriches the game and suggests dominance of cooperative strategies. Competitive analysis is suggested as a tool for investigating sub-optimal (but computationally tractable) strategies and game theoretic models in general. Using competitive analysis, it is shown that for bounded players, a sub-optimal strategy might be the optimal choice, given resource limitations. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Axelrod, R., and Hamilton, W. </author> <year> 1981. </year> <title> The evolution of cooperation. </title> <booktitle> Science 211(4489) </booktitle> <pages> 1390-1396. </pages>
Reference: <author> Axelrod, R. </author> <year> 1984. </year> <title> The Evolution of Cooperation. </title> <address> New York: </address> <publisher> Basic Books. </publisher>
Reference-contexts: Vanberg and Congleton, in (Vanberg & Con-gleton 1992), claim that opting out ("Exit" in their terminology) is the moral choice, and show that Opt-for-Tat is more successful than Tit-for-Tat in Axelrod-type tournaments <ref> (Axelrod 1984) </ref>. We start by comparing the OPD game to traditional approaches, namely to games played by rational players and to the IPD game.
Reference: <author> Binmore, K., and Samuelson, L. </author> <year> 1994. </year> <title> Drifting to equilibrium. </title> <type> Unpublished manuscript. </type>
Reference: <author> Fikes, R.; Engelmore, R.; Farquhar, A.; and Pratt, W. </author> <year> 1995. </year> <title> Network-based information brokers. </title> <booktitle> In The AAAI Spring Workshop on Information Gathering from Distributed, Heterogeneous Environments. </booktitle>
Reference-contexts: The power of cooperation in such problems has been studied in (Hogg & Huber-mann 1993). Other examples of domains for which work of the type presented here is relevant can be found in <ref> (Fikes et al. 1995) </ref> and in (Foner 1995). Foner's system explicitly relies on autonomous agents' cooperation. He describes a scenario in which agents post ads on a network, advertising their wish to buy or sell some item.
Reference: <author> Foner, L. N. </author> <year> 1995. </year> <title> Clustering and information sharing in an ecology of cooperating agents. </title> <booktitle> In The AAAI Spring Workshop on Information Gathering from Distributed, Heterogeneous Environments. </booktitle>
Reference-contexts: The power of cooperation in such problems has been studied in (Hogg & Huber-mann 1993). Other examples of domains for which work of the type presented here is relevant can be found in (Fikes et al. 1995) and in <ref> (Foner 1995) </ref>. Foner's system explicitly relies on autonomous agents' cooperation. He describes a scenario in which agents post ads on a network, advertising their wish to buy or sell some item.
Reference: <author> Fortnow, L., and Whang, D. </author> <year> 1994. </year> <title> Optimality and domination in repeated games with bounded players. </title> <type> Technical report, </type> <institution> Department of Computer Science University of Chicago, Chicago. </institution>
Reference: <author> Gilboa, I., and Samet, D. </author> <year> 1989. </year> <title> Bounded vs. unbounded rationality: The tyranny of the weak. </title> <booktitle> Games and Economic Behavior 1 </booktitle> <pages> 213-221. </pages>
Reference: <author> Hogg, T., and Hubermann, B. A. </author> <year> 1993. </year> <title> Better than the best: The power of cooperation. </title> <editor> In Nadel, L., and Stein, D., eds., </editor> <booktitle> 1992 Lectures in Complex Systems, volume V of SFI Studies in the Sciences of Complexity. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher> <pages> 163-184. </pages>
Reference-contexts: The task of finding papers on the Internet, as presented in the example above, can be seen as a distributed search problem. The power of cooperation in such problems has been studied in <ref> (Hogg & Huber-mann 1993) </ref>. Other examples of domains for which work of the type presented here is relevant can be found in (Fikes et al. 1995) and in (Foner 1995). Foner's system explicitly relies on autonomous agents' cooperation.
Reference: <author> Kalai, E. </author> <year> 1990. </year> <title> Bounded rationality and strategic complexity in repeated games. </title> <editor> In Ichiishi, T.; Ney-man, A.; and Tauman, Y., eds., </editor> <booktitle> Game Theory and Aplications. </booktitle> <address> San Diego: </address> <publisher> Academic Press. </publisher> <pages> 131-157. </pages>
Reference-contexts: From the agent designer's point of view, it enables him to design a strategy that will impose cooperation on his agent's opponent. Related Work A thorough and comprehensive survey of the basic literature on bounded rationality and repeated PD appears in <ref> (Kalai 1990) </ref>. Axelrod (Axelrod & Hamilton 1981; Axelrod 1984) reports on his famous computer tournament and analyzes social systems accordingly. <p> <ref> (Kalai 1990) </ref>. Axelrod (Axelrod & Hamilton 1981; Axelrod 1984) reports on his famous computer tournament and analyzes social systems accordingly. Most of the work on this subject has centered on various automata as models of bounded rationality; (Papadimitriou 1992; Gilboa & Samet 1989; Fortnow & Whang 1994) and others (see (Kalai 1990) for an extensive bibliography) deal with finite state automata with a limited number of states, and (Megiddo & Wigderson 1986) examines Turing machines with a bounded number of states. <p> Finite Time Repeated Prisoner's Dilemma In this section we deal with a game of PD that is repeated for a finite time (which we call the FTPD game). Previous work <ref> (Kalai 1990) </ref> focused on finite or infinite iterated PD (IPD). The basic idea is that two players play PD for N rounds. In each round, once both have made their move (effectively simulta-neously), they get the payoffs defined by the PD game matrix.
Reference: <author> Kaniel, R. </author> <year> 1994. </year> <title> On the equipment rental problem. </title> <type> Master's thesis, </type> <institution> Hebrew University. </institution>
Reference-contexts: The intuition behind this is, that if maximizing expected payoff is too expensive com-putationally, the next best thing to do is to ensure the highest possible "security level," protecting oneself best against the worst (max-min). In order to evaluate satisfying strategies, we use the method of competitive analysis. Kaniel <ref> (Kaniel 1994) </ref> names Sleator and Tarjan (Sleator & Tarjan 1984) as the initiators of this approach. The idea is to use the ratio between the satisfying strategy's payoff and that of a maximizing strategy as a quantifier of the satisfying strategy's performance. We begin by defining the concepts introduced above.
Reference: <author> Kreps, D.; Milgrom, P.; Roberts, J.; and Wilson, R. </author> <year> 1982. </year> <title> Rational cooperation in finitely repeated Prisoners' Dilemma. </title> <journal> ,journal of Economic Theory 27(2) </journal> <pages> 245-252. </pages>
Reference: <author> Megiddo, N., and Wigderson, A. </author> <year> 1986. </year> <title> On play by means of computing machines. </title> <booktitle> In Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> 259-274. </pages>
Reference-contexts: Most of the work on this subject has centered on various automata as models of bounded rationality; (Papadimitriou 1992; Gilboa & Samet 1989; Fortnow & Whang 1994) and others (see (Kalai 1990) for an extensive bibliography) deal with finite state automata with a limited number of states, and <ref> (Megiddo & Wigderson 1986) </ref> examines Turing machines with a bounded number of states.
Reference: <author> Mor, Y. </author> <year> 1995. </year> <title> Computational approaches to rational choice. </title> <type> Master's thesis, </type> <institution> Hebrew University. </institution> <note> In preparation. </note>
Reference-contexts: However, this is a technical problem, and can be overcome by technical means, for instance by setting P = 0 or H = *. See <ref> (Mor 1995) </ref> for further discussion. A D C W P S 0 T R 0 H 0 Rules of the FTPD Game: * 2 players play PD repeatedly for N clock ticks, N given as input to players. * At each round, players can choose C (cooperate), or D (defect). <p> Once opting out is introduced, this is no longer necessary. The possibility of opting out also makes the game less vulnerable to noise, and provides fertile ground for studying learning in the PD game context. These issues are beyond the scope of the current paper; see <ref> (Mor 1995) </ref> for further discussion. One last motivation for this line of work is sociological: "breaking up a relationship" is a common way of punishing defectors in repeated human interactions. <p> Theorem 6 In the IPD game with opting out, if P &gt; Q &gt; ^ Q and H &lt; 0, then the only Nash equilibrium is &lt; D N ; D N &gt;. Proof. The standard reasoning of backward induction works in this game; see <ref> (Mor 1995) </ref> for the full proof. From now on we will deal only with the OPD game. For simplicity's sake, we will assume Q = 0, and ^ Q = H = *. Let us define the full context of the game. Rules of the OPD Game: 1. <p> This is the intuition behind Theorem 7. In the next section we will attempt to quantify this claim. Theorem 7 The expected payoff when playing against a cooperative opponent is higher than when playing against an unknown one. Proof. (Sketch See <ref> (Mor 1995) </ref> for a more detailed proof.) Whatever A's move is for the first round, his payoff against a cooperative opponent is at least as high as against an unknown one. If he plays anything other then C, his opponent becomes unknown, and the proof is complete. <p> This theorem follows directly from Theorem 3 and Theorem 7. The full proof can be found in <ref> (Mor 1995) </ref>. 4 The problematic condition is instantaneous rematch-ing. There are 2 necessary and sufficient conditions for this to happen: 1. Opting out can be done in the same round the opponent waits. 2. <p> The second condition is unjustifiable in any realistic setting. The first condition returns to a player's ability to "watch the opponent" without waiting, mentioned in Footnote 3. In <ref> (Mor 1995) </ref> we show different assumptions that make this condition possible. Sub-Optimal Strategies In considering whether to opt out or not, player A has to assess his expected payoff against his current opponent B, the probability B will opt out given A's actions, and his expected payoff after opting out. <p> Actually, it is easy to show that const = 1 q fl [(r + 1)R S] where r is the expected number of rounds a player has to wait for a rematch <ref> (Mor 1995) </ref>. <p> Related work revisited The possibility of opting out makes cooperative, non-vengeful strategies even stronger. This tool can be further developed into a strategy-designing tool <ref> (Mor 1995) </ref>. We wish to demonstrate this claim using the examples presented in the introduction of this paper. In domains like the paper-searching agents or Foner's ad-agents, cooperative information sharing is a desir able, if not required, behavior.
Reference: <author> Nowak, M., and Sigmund, K. </author> <year> 1993. </year> <title> A strategy of win-stay lose-shift that outperforms tit-for-tat in the prisoner's dilemma game. </title> <booktitle> Nature 364 </booktitle> <pages> 56-58. </pages>
Reference: <author> Papadimitriou, C. H. </author> <year> 1992. </year> <title> On players with a bounded ,number of states. </title> <booktitle> Games and Economic Behavior 4 </booktitle> <pages> 122-131. </pages>
Reference-contexts: Such a pattern is highly non-robust and will collapse in the presence of noise. Papadimitriou, in <ref> (Papadimitriou 1992) </ref>, analyzes a 3-player variant of the PD game. This game is played in two stages: first, every player chooses a partner, then if two players choose each other, they play PD. <p> Theorem 4 If R &gt; 0, then there exists a cooperative equilibrium of the FTPD game. takes time for the player. Technically, we will say that a CB player can perform at most k binary XORs in one clock tick, and k &lt; log 2 N . 2 Papadimitriou <ref> (Papadimitriou 1992) </ref> makes a distinction between design complexity and decision complexity. In our model, decision complexity forces a player to play W, while design complexity is not yet handled.
Reference: <author> Rapoport, A.; Chammah, A.; Dwyer, J.; and Gyr, J. </author> <year> 1962. </year> <title> Three-person non-zero-sum nonnegotiable games. </title> <booktitle> Behavioral Science 7 </booktitle> <pages> 38-58. </pages>
Reference-contexts: The "always defect" equilibrium of PD is in a sense paradoxical; it contradicts some of our basic intuitions about intelligent behavior, and stands in contrast to psychological evidence <ref> (Rapoport et al. 1962) </ref>. The root of this paradox is the assumption of rationality, which implies unlimited computational power; it is precisely the unlimited computational power of rational agents that both allows and requires them to perform the unlimited backward induction in the repeated PD.
Reference: <author> Simon, H. A. </author> <year> 1969. </year> <booktitle> The Sciences of the Artificial. </booktitle> <address> Cambridge Massachusetts: </address> <publisher> The MIT Press. </publisher>
Reference: <author> Simon, H. A. </author> <year> 1983. </year> <title> Models of Bounded Rationality. </title> <address> Cambridge Massachusetts: </address> <publisher> The MIT Press. </publisher>
Reference: <author> Sleator, D. D., and Tarjan, R. E. </author> <year> 1984. </year> <title> Amortized efficiency of list rules. </title> <booktitle> STOC 16 </booktitle> <pages> 488-492. </pages>
Reference-contexts: In order to evaluate satisfying strategies, we use the method of competitive analysis. Kaniel (Kaniel 1994) names Sleator and Tarjan <ref> (Sleator & Tarjan 1984) </ref> as the initiators of this approach. The idea is to use the ratio between the satisfying strategy's payoff and that of a maximizing strategy as a quantifier of the satisfying strategy's performance. We begin by defining the concepts introduced above.
Reference: <author> Vanberg, V. J., and Congleton, R. D. </author> <year> 1992. </year> <title> Rationality, morality, and exit. </title> <journal> American Political Science Review 86(2) </journal> <pages> 418-431. </pages>
Reference-contexts: These issues are beyond the scope of the current paper; see (Mor 1995) for further discussion. One last motivation for this line of work is sociological: "breaking up a relationship" is a common way of punishing defectors in repeated human interactions. Vanberg and Congleton, in <ref> (Vanberg & Con-gleton 1992) </ref>, claim that opting out ("Exit" in their terminology) is the moral choice, and show that Opt-for-Tat is more successful than Tit-for-Tat in Axelrod-type tournaments (Axelrod 1984).
References-found: 20

