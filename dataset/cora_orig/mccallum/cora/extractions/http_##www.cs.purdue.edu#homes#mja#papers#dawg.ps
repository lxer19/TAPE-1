URL: http://www.cs.purdue.edu/homes/mja/papers/dawg.ps
Refering-URL: http://www.cs.purdue.edu/coast/coast-library.html
Root-URL: http://www.cs.purdue.edu
Email: mja@cs.purdue.edu.  
Title: Compact Recognizers of Episode Sequences  
Author: Alberto Apostolico Mikhail J. Atallah 
Keyword: Index Terms Algorithms, pattern matching, subsequence and episode searching, DAWG, suffix automaton, compact subsequence automaton, skip-edge DAWG, forward failure function, skip-link.  
Note: This author gratefully acknowledges support from the COAST Project at Purdue and its sponsors.  
Address: Building, West Lafayette, IN 47907, USA.  
Affiliation: Purdue University Universita di Padova  Purdue University  COAST Laboratory and Department of Computer Sciences, Purdue University, Computer Sciences  
Abstract: Given two strings T = a 1 : : : a n and P = b 1 : : : b m over an alphabet , the problem of testing whether P occurs as a subsequence of T is trivially solved in linear time. It is also known that a simple O(n log jj) time preprocessing of T makes it easy to decide subsequently for any P and in at most jP j log jj character comparisons, whether P is a subsequence of T . These problems become more complicated if one asks instead whether P occurs as a subsequence of some substring Y of T of bounded length. This paper presents an automaton built on the textstring T and capable of identifying all distinct minimal substrings Y of X having P as a subsequence. By a substring Y being minimal with respect to P , it is meant that P is not a subsequence of any proper substring of Y . For every minimal substring Y , the automaton recognizes the occurrence of P having lexicographically smallest sequence of symbol positions in Y . It is not difficult to realize such an automaton in time and space O(n 2 ) for a text of n characters. One result of this paper consists of bringing those bounds down to linear or O(n log n), respectively, depending on whether the alphabet is bounded or of arbitrary size, thereby matching the respective complexities of off-line exact string searching. Having built the automaton, the search for all lexicographically earliest occurrences of P in X is carried out in time O(n + P m i=1 rocc i i log n log jj), where rocc i is the number of distinct minimal substrings of T having b 1 : : : b i as a subsequence. All log factors appearing in the above bounds can be further reduced to log log by resort to known integer-handling data structures. fl Department of Computer Sciences, Purdue University, Computer Sciences Building, West Lafayette, IN 47907, USA, and Dipartimento di Elettronica e Informatica, Universita di Padova, Via Gradenigo 6/A, 35131 Padova, Italy. axa@cs.purdue.edu. Work partially supported by NSF Grant CCR-9700276, by NATO Grant CRG 900293, by the National Research Council of Italy, and by British Engineering and Physical Sciences Research Council Grant GR/L19362. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Apostolico and Z. Galil (Eds.), </author> <title> Pattern Matching Algorithms, </title> <publisher> Oxford University Press, </publisher> <address> New York (1997). </address>
Reference-contexts: Notable among these constructions are those resulting in structures such as subword trees and graphs (refer to, e.g., <ref> [1] </ref>, [4]). Notice that the answer to the typical query is now only whether or not the pattern appears in the text. If one wanted to locate 2 all the occurrences as well, then the time would become O (jwj + occ), where occ denotes the total number of occurrences.
Reference: [2] <author> A. Apostolico and C. Guerra, </author> <title> The Longest Common Subsequence Problem Revisited, </title> <journal> Algorithmica, </journal> <volume> 2, </volume> <month> 315-336 </month> <year> (1987). </year>
Reference-contexts: For this, all is needed is a pointer leading, for every position of T and every alphabet symbol, to the closest position occupied by that symbol. Slightly more complicated arrangements, such as developed in <ref> [2] </ref>, can accommodate within preprocessing time O (n log jj) and space linear in T also the case of an arbitrary alphabet size, though introducing an extra log jj cost factor in the search for P . <p> We explain first how this can work on the original array in which X is stored. We resort to a global table CLOSE, defined as follows <ref> [2] </ref>: CLOSE is regarded as subdivided into blocks of size jj, With p = jmodjj (j = 1; 2; :::; n), CLOSE [j] contains the smallest position larger than j where there is an occurrence of s p , the pth symbol of the alphabet. <p> Then, closest (i; p) can be computed from CLOSE and the sorted list of occurrences of s p in X in O (log jj) time. We refer to <ref> [2] </ref> for details. <p> It is also likely that the log n factors could be made to disappear entirely by resort to amortized finger searches such as, e.g., in <ref> [2] </ref>. 13
Reference: [3] <author> A. Blumer, J. Blumer, A. Ehrenfeucht, D. Haussler, M.T. Chen and J. Seiferas, </author> <title> The Smallest Automaton Recognizing the Subwords of a Text, </title> <booktitle> Theoretical Computer Science , 40, </booktitle> <month> 31-55 </month> <year> (1985). </year>
Reference-contexts: Our solution rests on an adaptation of the partial minimal automaton recognizing all subwords of a word, also known as the DAWG (Directed Acyclic Word Graph) <ref> [3] </ref> associated with that word. Let V be the set of all subwords of the text T , and P i (i = 1; 2; :::; m) be the ith prefix of P . <p> Deleting from A above the nonaccepting state and all of its incoming arcs yields the DAWG associated with X . An example DAWG for X = abbbaabaa is reported in Figure 1. 4 We refer to, e.g., <ref> [3, 4] </ref>, for the construction of a DAWG. Here we recall some basic properties of this structure. This is clearly a directed acyclic graph with one sink and one source, where every state lies on a path from the source to the sink. Moreover, the following two properties hold [3, 4]. <p> e.g., <ref> [3, 4] </ref>, for the construction of a DAWG. Here we recall some basic properties of this structure. This is clearly a directed acyclic graph with one sink and one source, where every state lies on a path from the source to the sink. Moreover, the following two properties hold [3, 4]. Property 1 For any word X , the sequence of labels on each distinct path from the source to the sink of the DAWG of X represents one distinct suffix of X .
Reference: [4] <author> M. Crochemore and W. Rytter, </author> <title> Text Algorithms, </title> <publisher> Oxford University Press, </publisher> <address> New York (1994). </address>
Reference-contexts: Notable among these constructions are those resulting in structures such as subword trees and graphs (refer to, e.g., [1], <ref> [4] </ref>). Notice that the answer to the typical query is now only whether or not the pattern appears in the text. If one wanted to locate 2 all the occurrences as well, then the time would become O (jwj + occ), where occ denotes the total number of occurrences. <p> Deleting from A above the nonaccepting state and all of its incoming arcs yields the DAWG associated with X . An example DAWG for X = abbbaabaa is reported in Figure 1. 4 We refer to, e.g., <ref> [3, 4] </ref>, for the construction of a DAWG. Here we recall some basic properties of this structure. This is clearly a directed acyclic graph with one sink and one source, where every state lies on a path from the source to the sink. Moreover, the following two properties hold [3, 4]. <p> e.g., <ref> [3, 4] </ref>, for the construction of a DAWG. Here we recall some basic properties of this structure. This is clearly a directed acyclic graph with one sink and one source, where every state lies on a path from the source to the sink. Moreover, the following two properties hold [3, 4]. Property 1 For any word X , the sequence of labels on each distinct path from the source to the sink of the DAWG of X represents one distinct suffix of X .
Reference: [5] <author> G. Das, R. Fleischer, L. G~asieniek, D. Gunopulos, J. Karkkainen, </author> <title> Episode Matching, </title> <booktitle> CPM'97, Proceedings of the 8th Annual Symposium on Combinatorial Pattern Matching, </booktitle> <editor> (A. Apostolico and J. Hein, Eds.), </editor> <publisher> Springer Verlag LNCS 1264, </publisher> <month> 12-27 </month> <year> (1997). </year>
Reference-contexts: Algorithms for the so-called episode matching problem, which consists of finding the earliest occurrences of P in all minimal realizations of P in T have been given previously in <ref> [5] </ref>. An occurrence i 1 i 2 : : : i m of P in a realization Y is an earliest occurrence if the string i 1 i 2 : : : i m is lexicographically smallest with respect to any other possible occurrence of P in Y . <p> The algorithms in <ref> [5] </ref> perform within roughly O (nm) time, without resorting to any auxiliary structure or index based on the structure of the text.
Reference: [6] <author> D.B. Johnson, </author> <title> A Priority Queue in which Initialization and Queue Operations Take O(log log n) Time, </title> <journal> Math. Sys. Th., </journal> <volume> 15, </volume> <month> 295-309 </month> <year> (1982). </year>
Reference-contexts: We conclude by pointing out that all log factors apperaring in our claims can be reduced to log log at the expense of some additional bookkeeping, by deploying data structures especially suited for storing integers in a known range <ref> [6] </ref>. It is also likely that the log n factors could be made to disappear entirely by resort to amortized finger searches such as, e.g., in [2]. 13
Reference: [7] <author> S. Kumar and E.H. Spafford, </author> <title> A Pattern-Matching Model for Instrusion Detection, </title> <booktitle> Proceedings of the National Computer Security Conference, </booktitle> <year> 1994, </year> <pages> pp. 11-21. </pages>
Reference-contexts: Variants of this problem arise in numerous applications, ranging from information retrieval and data mining (see, e.g., [8]) to molecular sequence analysis (see, e.g., [9]) and intrusion and misuse detection in a computer system (see, e.g., <ref> [7] </ref>).
Reference: [8] <author> H. Mannila, H. Toivonen and A.I. Vercamo, </author> <title> Discovering Frequent Episodes in Sequences, </title> <booktitle> KDD'95, Proceedings of the 1st International Conference on Knowledge Discovery and Data Mining, </booktitle> <publisher> AAAI Press, </publisher> <month> 210-215 </month> <year> (1995). </year>
Reference-contexts: 1 Introduction We consider the problem of detecting occurrences of a pattern string as a subsequence of a substring of bounded length of a larger text string. Variants of this problem arise in numerous applications, ranging from information retrieval and data mining (see, e.g., <ref> [8] </ref>) to molecular sequence analysis (see, e.g., [9]) and intrusion and misuse detection in a computer system (see, e.g., [7]).
Reference: [9] <author> M. Waterman, </author> <title> Introduction to Computational Biology, </title> <publisher> Chapman and Hall (1995). </publisher> <pages> 14 </pages>
Reference-contexts: Variants of this problem arise in numerous applications, ranging from information retrieval and data mining (see, e.g., [8]) to molecular sequence analysis (see, e.g., <ref> [9] </ref>) and intrusion and misuse detection in a computer system (see, e.g., [7]).
References-found: 9

