URL: http://cobar.cs.umass.edu/pubfiles/relfeed.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: internet: fhaines,croftg@cs.umass.edu  
Title: Relevance Feedback and Inference Networks  
Author: David Haines and W. Bruce Croft 
Address: Amherst MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: Relevance feedback, which modifies queries using judgements of the relevance of a few, highly-ranked documents, has historically been an important method for increasing the performance of information retrieval systems. In this paper, we extend the inference network model introduced by Turtle and Croft to include relevance feedback techniques. The difference between relevance feedback on text abstracts and full text collections is studied. Preliminary results for relevance feedback on the structured queries supported by the inference net model are also reported.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. K. Chang, C. Cirillo, and J. Razon. </author> <title> Evaluation of Feedback Retrieval using Modified Freezing, Residual Collection, and Test and Control Groups, </title> <booktitle> chapter 17, </booktitle> <pages> pages 355-370. </pages> <publisher> Prentice-Hall Inc., </publisher> <year> 1971. </year> <title> in The SMART Retrieval System: Experiments in Automatic Document Processing. </title>
Reference-contexts: When assessing the effectiveness of relevance feedback, the ranks of these judged documents are not relevant and may even be misleading. They must be factored out of the evaluation of the effectiveness of relevance feedback. We do this by using the residual collection method <ref> [1] </ref>. Judged documents are removed from the document rankings produced by both the original query and the relevance feedback query. Recall-precision values are then used to summarize performance. These recall-precision values measure performance for only those documents the user hasn't seen.
Reference: [2] <author> W. Bruce Croft, Howard R. Turtle, and David D. Lewis. </author> <title> The use of phrases and structured queries in information retrieval. </title> <booktitle> In Proceedings of the 14th Annual International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 32-45, </pages> <address> Chicago, </address> <year> 1991. </year> <pages> SIGIR. </pages>
Reference-contexts: Since these models do not make use of any linguistic or domain knowledge, it is unlikely that they will afford performance gains that cannot be achieved with normal probabilistic relevance feedback. The development of an effective relevance feedback mechanism for Boolean and structured queries <ref> [2] </ref> is a potentially important area for further research. Encod ing feedback information in a structured query could improve performance more than in a simple query since it is possible to encode information in the structured query that can not be represented in a simple vector of terms. <p> We used two query sets. The first was a 50 query subset of the standard natural language queries that we have used in many previous experiments. The second set, which was used for testing feedback with structured queries, augmented these 50 queries by adding manually selected phrases <ref> [2] </ref>. The WEST collection consists of 11,953 full text legal documents. It contains approximately 250 megabytes of text. The documents contain an average of approximately 3,250 words and 530 unique terms. We used a set of 34 natural language queries provided with the WEST collection as the standard query set. <p> For both the WEST and CACM collections, the following three experiments were tried: 1. Relevance feedback on queries containing phrase operators <ref> [2] </ref>. 2. Relevance feedback with all phrase operators replaced by proximity operators. With proximity operators, the belief in phrase concepts is based entirely on the presence of the words in proximity to each other. 3.
Reference: [3] <author> Mark E. Frisse and S. B. Cousins. </author> <title> Information retrieval from hypertext: Update on the dynamic medical handbook project. </title> <booktitle> In Proceedings of Hypertext 89, </booktitle> <pages> pages 199-212. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: Evidential feedback is appropriate in the document network which is largely determined by the characteristics of the collection. Frisse and Cousins <ref> [3] </ref> use this approach to implement feedback in a hierarchy of index terms associated with a hypertext medical handbook. Altering dependencies is appropriate when the initial network is known to be an approximation to the correct distribution and we obtain better information about the nature of the true distribution.
Reference: [4] <author> Donna Harman. </author> <title> Relevance feedback and other query modification techniques. </title> <editor> In W. B. Frakes and R. S. Baeza-Yates, editors, </editor> <booktitle> Information Retrieval: Data Structures and Algorithms, chapter 11, </booktitle> <pages> pages 241-263. </pages> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: Full text collections are becoming increasingly important, and there is the possibility that the increased amount of text in the identified relevant documents will make the selection and weighting of terms more difficult. 1.1 Prior Work Work on relevance feedback methods in information retrieval has a long history <ref> [16, 4] </ref>. Rocchio [13] describes an elegant approach to relevance feedback in the vector space model. He shows how the optimal vector space query can be derived using vector addition and subtraction if the sets of relevant and non-relevant documents are known.

Reference: [6] <author> D. J. Harper. </author> <title> Relevance Feedback in Document Retrieval Systems: An Evaluation of Probablis-tic Strategies. </title> <type> PhD thesis, </type> <institution> Cambridge University, </institution> <year> 1980. </year>
Reference: [7] <author> Judea Pearl. </author> <title> Probablistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann Publishers Inc, </publisher> <year> 1988. </year>
Reference-contexts: Section 3 describes the experiments which are carried out using two test collections. Section 4 reports the results, and Section 5 summarizes them. 2 Relevance Feedback and Inference Networks 2.1 The Inference Net Model Turtle and Croft [18, 19] introduced the inference network model of reasoning under uncertainty <ref> [7] </ref> to information retrieval. Like simpler probabilistic retrieval models, this is a probability-based method that follows the probability ranking principle [11].
Reference: [8] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: It computes a measure of the predictiveness of the term occurrence for relevance. This measure is equivalent to the information gain measure used in the ID3 learning algorithm <ref> [8] </ref> to select nodes in a decision tree. However, the classification algorithm that is used is quite different. 2. PMIM: This computes the EMIM score for just the state where the term is present and the document is relevant.
Reference: [9] <author> Tadeusz Radecki. </author> <title> Incorporation of relevance feedback into boolean retrieval systems. </title> <booktitle> In Proceedings of the 6th Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 133-150. SIGIR, </pages> <year> 1983. </year>
Reference-contexts: network model adds new terms as parents of a query node using a weighted sum link matrix, and re-estimates the relative weights of the parents' contributions to that weighted sum. 2.3 Feedback with Structured Queries A number of models have been proposed for using relevance feedback with Boolean retrieval systems <ref> [14, 17, 10, 9] </ref>. While some of these models have been shown to significantly improve performance when compared to conventional Boolean retrieval, they are not attractive in the context of the network model.
Reference: [10] <author> Tadeusz Radecki. </author> <title> Probabilistic methods for ranking output documents in conventional boolean retrieval systems. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 24(3) </volume> <pages> 281-302, </pages> <year> 1988. </year>
Reference-contexts: network model adds new terms as parents of a query node using a weighted sum link matrix, and re-estimates the relative weights of the parents' contributions to that weighted sum. 2.3 Feedback with Structured Queries A number of models have been proposed for using relevance feedback with Boolean retrieval systems <ref> [14, 17, 10, 9] </ref>. While some of these models have been shown to significantly improve performance when compared to conventional Boolean retrieval, they are not attractive in the context of the network model.
Reference: [11] <author> S. E. Robertson. </author> <title> The probability ranking principle in IR. </title> <journal> Journal of Documentation, </journal> <volume> 33(4) </volume> <pages> 294-304, </pages> <year> 1977. </year>
Reference-contexts: Like simpler probabilistic retrieval models, this is a probability-based method that follows the probability ranking principle <ref> [11] </ref>. However, rather than ranking documents by their calculated probability that the document is relevant, (given the selected document and query), it ranks them based on the probability that a document satisfies the user's information need.
Reference: [12] <author> S. E. Robertson and Karen Sparck-Jones. </author> <title> Relevance weighting of search terms. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 27 </volume> <pages> 129-146, </pages> <year> 1976. </year>
Reference-contexts: In the vector space model, then, relevance feedback involves changing weights associated with query terms and adding new terms to the original query. In the probabilistic model described by Robertson and Sparck-Jones <ref> [12] </ref> and Van Rijsbergen [21], relevance feedback is described in different terms. In this model, documents are ranked using a (generally) linear discriminant function in which each term corresponds to a representation concept in the collection.
Reference: [13] <author> J.J. Rocchio. </author> <title> Relevance Feedback in Information Retrieval, </title> <booktitle> chapter 14, </booktitle> <pages> pages 313-323. </pages> <publisher> Prentice-Hall Inc., </publisher> <year> 1971. </year> <title> in The SMART Retrieval System: Experiments in Automatic Document Processing. </title>
Reference-contexts: Rocchio <ref> [13] </ref> describes an elegant approach to relevance feedback in the vector space model. He shows how the optimal vector space query can be derived using vector addition and subtraction if the sets of relevant and non-relevant documents are known. <p> The portion above the horizontal dividing line can be constructed before any query is asked. The section below is the expression of the user's information need and has been created specifically for this request. 2.2 Relevance Feedback In the vector space model, the basic relevance feedback strategy <ref> [13] </ref> for producing a new query, given an old query and relevance judgements, is as follows: Q new = Q old + fi rel jD i j X nonrel D i (1) where the summation is taken over the known relevant and nonrelevant documents, and the D i represent document vectors.
Reference: [14] <author> Gerald Salton. </author> <title> Automatic Text Processing: The Transformation, analysis and Retrieval of Information by Computer. </title> <address> Addision-Wesley, Reading MA, </address> <year> 1989. </year>
Reference-contexts: network model adds new terms as parents of a query node using a weighted sum link matrix, and re-estimates the relative weights of the parents' contributions to that weighted sum. 2.3 Feedback with Structured Queries A number of models have been proposed for using relevance feedback with Boolean retrieval systems <ref> [14, 17, 10, 9] </ref>. While some of these models have been shown to significantly improve performance when compared to conventional Boolean retrieval, they are not attractive in the context of the network model.
Reference: [15] <author> Gerald Salton and Chris Buckley. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(4) </volume> <pages> 288-297, </pages> <year> 1990. </year>
Reference-contexts: Perhaps the relative importance of that term should also be increased. Given the apparent effectiveness of relevance feedback techniques <ref> [15, 5] </ref>, it is important that any proposed model of information retrieval includes these techniques. fl This research was supported by a contract with West Publishing Company, and by the NSF Center for Intelligent Information Retrieval at the University of Massachusetts. <p> One of the purposes of this paper is to show how feedback techniques can be used with this model. This includes both simple techniques, as described by Salton and Buckley <ref> [15] </ref>, and techniques that exploit the ability of the inference net model to represent structure in the query. The other major topic addressed in this paper is the effect of full text collections on relevance feedback techniques. <p> New terms are added to query by adding terms found in the relevant documents. The importance of query terms is adjusted by adding and subtracting corresponding weights found in relevant and non-relevant documents. In a recent paper, Salton and Buckley <ref> [15] </ref> report the results of a number of relevance feedback techniques on a variety of document collections. In all but one collection, Salton and Buckley found average increases in precision, averaged over five collections, ranging from 60% to 90%. 1 For two collections they found increases of 170%. <p> They are plausible as we expect terms that are related to relevance to occur often in relevant docu ments. 3.1.3 Relative Weighting of Query Terms and Added Terms It is possible that terms from different sources should not be given the same weight. Salton and Buckley <ref> [15] </ref> found that during relevance feedback a 75%-25% weighting split between terms from relevant documents and terms from non-relevant documents was better than equal weighting. This does not precisely correspond with our experimental setup as we do not consider nonrelevant documents.
Reference: [16] <author> Gerald Salton and Michael J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: For example, if all the documents, that the user judges as relevant, contain a particular term, then that term may be a good one to add to the original query <ref> [16] </ref>. Perhaps the relative importance of that term should also be increased. <p> Full text collections are becoming increasingly important, and there is the possibility that the increased amount of text in the identified relevant documents will make the selection and weighting of terms more difficult. 1.1 Prior Work Work on relevance feedback methods in information retrieval has a long history <ref> [16, 4] </ref>. Rocchio [13] describes an elegant approach to relevance feedback in the vector space model. He shows how the optimal vector space query can be derived using vector addition and subtraction if the sets of relevant and non-relevant documents are known.
Reference: [17] <author> Gerald Salton, E. Voorhees, and Edward A. Fox. </author> <title> A comparison of two methods for boolean query relevance feedback. </title> <booktitle> Information Processing and Management, </booktitle> 20(5/6):637-651, 1984. 
Reference-contexts: network model adds new terms as parents of a query node using a weighted sum link matrix, and re-estimates the relative weights of the parents' contributions to that weighted sum. 2.3 Feedback with Structured Queries A number of models have been proposed for using relevance feedback with Boolean retrieval systems <ref> [14, 17, 10, 9] </ref>. While some of these models have been shown to significantly improve performance when compared to conventional Boolean retrieval, they are not attractive in the context of the network model.
Reference: [18] <author> Howard R. </author> <title> Turtle. Inference Networks for Document Retrieval. </title> <type> PhD thesis, </type> <institution> University of Mas-sachusetts, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: Section 3 describes the experiments which are carried out using two test collections. Section 4 reports the results, and Section 5 summarizes them. 2 Relevance Feedback and Inference Networks 2.1 The Inference Net Model Turtle and Croft <ref> [18, 19] </ref> introduced the inference network model of reasoning under uncertainty [7] to information retrieval. Like simpler probabilistic retrieval models, this is a probability-based method that follows the probability ranking principle [11]. <p> The probabilistic model does, in fact, indicate that the addition of these terms, up to a point, should improve performance. Although the inference net model is a probabilistic model, there are differences from earlier models <ref> [18] </ref>. In particular, because this model does not use Bayesian inversion, there are no probabilities that correspond directly to p i and q i . This means that feedback in the inference net model is not the same as in the model described by Robertson and Sparck-Jones. <p> In the network model, queries are represented by links between query nodes and the information need node, and query term weights are represented using the "weighted sum" form of the link matrix at the information need node <ref> [18] </ref>. This operator takes as input the probabilities from the parent nodes and a vector of weights that describes how much each parent should contribute to the final probability.
Reference: [19] <author> Howard R. Turtle and W. Bruce Croft. </author> <title> Inference networks for document retrieval. </title> <booktitle> In Proceedings of the 13th International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 1-24, </pages> <address> Brussels, Belgium, </address> <month> September </month> <year> 1990. </year> <pages> SIGIR. </pages>
Reference-contexts: Thanks also to Michael Gordon and the Cognitive Science and Machine Intelligence Laboratory at the University of Michigan. 0 The inference net model recently described by Turtle and Croft <ref> [19, 20] </ref> has been shown to be an effective and general basis for an information retrieval system. One of the purposes of this paper is to show how feedback techniques can be used with this model. <p> Section 3 describes the experiments which are carried out using two test collections. Section 4 reports the results, and Section 5 summarizes them. 2 Relevance Feedback and Inference Networks 2.1 The Inference Net Model Turtle and Croft <ref> [18, 19] </ref> introduced the inference network model of reasoning under uncertainty [7] to information retrieval. Like simpler probabilistic retrieval models, this is a probability-based method that follows the probability ranking principle [11]. <p> In other words each document is evaluated seperately, not as part of a set of more than one relevant document. The probabilities associated with child nodes are based on the probabilities of their parents and on a "link information retrieval) (not files)). matrix" <ref> [19] </ref> that specifies how to combine the evidence from the parents. The "link matrices" between the d i nodes and the r j nodes represent the evidence for the proposition that this concept occurs in this document.
Reference: [20] <author> Howard R. Turtle and W. Bruce Croft. </author> <title> A comparison of text retrieval models. </title> <journal> Computer Journal, </journal> <volume> 35(3) </volume> <pages> 279-290, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Thanks also to Michael Gordon and the Cognitive Science and Machine Intelligence Laboratory at the University of Michigan. 0 The inference net model recently described by Turtle and Croft <ref> [19, 20] </ref> has been shown to be an effective and general basis for an information retrieval system. One of the purposes of this paper is to show how feedback techniques can be used with this model.
Reference: [21] <author> C. J. van Rijsbergen. </author> <note> Information Retrieval, Second Edition. Butterworths, </note> <year> 1979. </year>
Reference-contexts: In the vector space model, then, relevance feedback involves changing weights associated with query terms and adding new terms to the original query. In the probabilistic model described by Robertson and Sparck-Jones [12] and Van Rijsbergen <ref> [21] </ref>, relevance feedback is described in different terms. In this model, documents are ranked using a (generally) linear discriminant function in which each term corresponds to a representation concept in the collection.
References-found: 20

