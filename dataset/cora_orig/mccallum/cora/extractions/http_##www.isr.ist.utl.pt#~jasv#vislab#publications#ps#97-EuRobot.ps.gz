URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/ps/97-EuRobot.ps.gz
Refering-URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/publications.html
Root-URL: 
Email: fajmb,jasvg@isr.ist.utl.pt  
Title: Visual Behaviours for Binocular Tracking  
Author: Alexandre Bernardino Jose Santos-Victor 
Address: 1096 Lisboa Codex, Portugal  
Affiliation: Instituto de Sistemas e Robotica Instituto Superior Tecnico  
Abstract: This paper presents a binocular tracking system based on the integration of visual behaviours. Biologically motivated behaviours, Vergence and Pursuit, cooperate as parallel, complementary and highly coupled processes in the tracking system, simplifying the acquisition of perceptual information and system modeling and control. The use of a space variant image representation and low-level visual cues as feedback signals in a closed loop control architecture, allow real-time and reliable performance for each behaviour, despite the low precision of the algorithms and modeling errors. The behaviours are integrated and the overall system is implemented in a stereo head running at real-time (12.5 Hz), without any specific processing hardware. Results are presented for objects of different shapes and motions, illustrating that tracking can be robustly achieved by the cooperation of purposively designed behaviours, tuned to specific subgoals. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Andersson. </author> <title> Dynamic sensing in a ping-pong playing robot. </title> <journal> IEEE J. Robotics and Automation, </journal> <volume> 5(6) </volume> <pages> 728-739, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: These include trajectory reconstruction [3], egomotion estimation [10], object recognition [6] and navigation, which are important subjects in current robotics research. In structured conditions, where objects have constrained shapes or motions, or move in simple backgrounds, some tracking systems have been successfully employed <ref> [13, 1] </ref>. However, in complex and dynamic environments, where restrictions about the kind of objects or motions cannot be made, most systems lack robustness, reactivity and flexibility.
Reference: [2] <author> P. Aschwanden and W. Guggenbuhl. </author> <title> Experimental results from a comparative study on correlation-type registration algorithms. </title> <editor> In W. Forstner and St. Ruwiedel, editors, </editor> <title> Robust Computer Vision. </title> <type> Wichmann, </type> <year> 1992. </year>
Reference-contexts: By relying on closed loop control, it is still possible to achieve vergence with low precision algorithms and coarse system calibration. 3.1 Sensing Strategy In order to obtain estimates of target disparity, correlation between the stereo images is used. The Sum of Squared Differences <ref> [2] </ref> is a frequently used measure of similarity, given by: SSD [I 1 (i; j) ; I 2 (i; j)] = i;j 2 and is minimal for the higher similarity between images.
Reference: [3] <author> A. Bernardino. Seguimento binocular de alvos moveis baseado em imagens log-polar. </author> <type> Master's thesis, </type> <institution> Instituto Superior Tecnico, Lisbon, Portu-gal, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Many computer and robot vision problems can improve their performance by tracking objects in the visual field. These include trajectory reconstruction <ref> [3] </ref>, egomotion estimation [10], object recognition [6] and navigation, which are important subjects in current robotics research. In structured conditions, where objects have constrained shapes or motions, or move in simple backgrounds, some tracking systems have been successfully employed [13, 1]. <p> In both behaviours, visual sensing is made on log-polar images. The log-polar mapping [21] provides a non-uniform resolution geometry which is similar to the distribution of photo-receptors in the human retina, resulting in both algorithmic and perceptual advantages over the usual cartesian representation <ref> [3, 4] </ref>. The focus of this paper is on the design, integration and test of these behaviours. The design includes sen-sor and motor (control) aspects, but special attention is given to sensoring strategies. Control issues are currently well established and can be formalized in several ways. <p> Currently, only target disparity measures are used to control the vergence angle. For symmetrical ver-gence ( l = r ), small variations in vergence angle have an approximate linear relation with disparity for a large range of depth <ref> [3] </ref>. Thus, a variational kinematics model for vergence is given by: ffi- ' fl d d (1) where d is the target horizontal disparity and fl d depends on system calibration parameters. <p> Having an higher resolution in the center of the images, where the target is expected to be, the areas belonging to the target are dominant in the computation of the correlation index, reducing the negative influence of background elements <ref> [3, 5] </ref>. 3.2 Control Strategy The disparity estimates obtained by the sensing strategy are integrated in a standard feedback architecture. They are acquired at each time step and used as input to a motor strategy. Its output is used as position commands to motor servoing control. <p> Figure 4 illustrates this geometry. motors We assume that for a centered target, small variations of pan and tilt angles produce linear changes in image plane position, which a good approximation for the range of tilt angles attainable by the stereo head Medusa, (45 o ; 45 o ) <ref> [3] </ref>: ffi t ' fl y y (2) In biological visual systems, pursuit movements are accomplished by saccadic and smooth pursuit movements that respond to target position and velocity errors in the retina [7].
Reference: [4] <author> A. Bernardino and J. Santos-Victor. </author> <title> Sensor geometry for dynamic vergence: characterization and performance analysis. </title> <booktitle> In Proc. of the Workshop on Performance Characteristics of Vision Algorithms, </booktitle> <address> Cambridge, UK, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: In both behaviours, visual sensing is made on log-polar images. The log-polar mapping [21] provides a non-uniform resolution geometry which is similar to the distribution of photo-receptors in the human retina, resulting in both algorithmic and perceptual advantages over the usual cartesian representation <ref> [3, 4] </ref>. The focus of this paper is on the design, integration and test of these behaviours. The design includes sen-sor and motor (control) aspects, but special attention is given to sensoring strategies. Control issues are currently well established and can be formalized in several ways.
Reference: [5] <author> A. Bernardino and J. Santos-Victor. </author> <title> Vergence control for robotic heads using log-polar images. </title> <booktitle> In Proc. of the 1996 IEEE/RJS International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 1264-1271, </pages> <address> Osaka, Japan, November 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Having an higher resolution in the center of the images, where the target is expected to be, the areas belonging to the target are dominant in the computation of the correlation index, reducing the negative influence of background elements <ref> [3, 5] </ref>. 3.2 Control Strategy The disparity estimates obtained by the sensing strategy are integrated in a standard feedback architecture. They are acquired at each time step and used as input to a motor strategy. Its output is used as position commands to motor servoing control.
Reference: [6] <author> K. Brunnstrom, J. Eklundh, and T. Uhlin. </author> <title> Active fixation for scene exploration. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 17(2) </volume> <pages> 137-162, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Many computer and robot vision problems can improve their performance by tracking objects in the visual field. These include trajectory reconstruction [3], egomotion estimation [10], object recognition <ref> [6] </ref> and navigation, which are important subjects in current robotics research. In structured conditions, where objects have constrained shapes or motions, or move in simple backgrounds, some tracking systems have been successfully employed [13, 1].
Reference: [7] <author> R. Carpenter. </author> <title> Movements of the eyes. </title> <address> Pion, Lon-don, </address> <year> 1988. </year>
Reference-contexts: Space Variant Image Resolution: One of the main reasons for the existence of ocular movements is the space variant density of photo-receptors in the retina, distinguishing between a central high resolution area - the fovea and the low resolution peripheral zone <ref> [7] </ref>. Combining this feature with the ability to move the eyes over the visual field, it is possible to obtain the information needed to perform the desired tasks, without considering all the data contained in uniformly sampled images. Hence, the processing effort is concentrated in the foveal area. <p> Depth cues such as binocular disparity and accommodation are important inputs to the vergence control system, and humans rely also on other cues such as motion and shading <ref> [7] </ref>. Currently, only target disparity measures are used to control the vergence angle. For symmetrical ver-gence ( l = r ), small variations in vergence angle have an approximate linear relation with disparity for a large range of depth [3]. <p> the range of tilt angles attainable by the stereo head Medusa, (45 o ; 45 o ) [3]: ffi t ' fl y y (2) In biological visual systems, pursuit movements are accomplished by saccadic and smooth pursuit movements that respond to target position and velocity errors in the retina <ref> [7] </ref>. For our purposes, we consider the pursuit behaviour composed by a sensoring module that extracts from the images target position and velocity estimates, and an appropriate control module.
Reference: [8] <author> D. Coombs and C. Brown. </author> <title> Real-time binocular smooth pursuit. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 11(2) </volume> <pages> 147-164, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Binocularity: Although many researchers have faced the tracking problem as a monocular one [15, 16], binocularity can provide major benefits. Not only it is possible to recover depth from the tracked object but also binocular fusion greatly simplifies figure-ground segmentation <ref> [8] </ref>. Ocular Movements: The most influent ocular movements in biological systems are saccadic, vergence and smooth pursuit movements [18]. Saccadic and smooth pursuit movements use retinal position and velocity errors, respectively, in order to compensate lateral motion of the target. <p> When the target is verged, its location in each of the stereo images is approximately the same, and the segmentation problem can be addressed by zero disparity filtering <ref> [8] </ref>. Algorithms for the extraction of zero disparity points in the images are developed based on vertical gradient matching and care is taken to cope with the log-polar representation of images.
Reference: [9] <author> B. Espiau, F. Chaumette, and P. Rives. </author> <title> A new approach to visual servoing in robotics. </title> <journal> IEEE J. Robotics and Automation, </journal> <volume> 8(3) </volume> <pages> 313-326, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The focus of this paper is on the design, integration and test of these behaviours. The design includes sen-sor and motor (control) aspects, but special attention is given to sensoring strategies. Control issues are currently well established and can be formalized in several ways. The visual servoing approach <ref> [9] </ref> provides ways for motor control with visual feedback from position or pose of known objects in simple backgrounds.
Reference: [10] <author> C. Fermuller and Y. Aloimonos. </author> <title> The role of fixation in visual motion analysis. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 11(2) </volume> <pages> 165-186, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Many computer and robot vision problems can improve their performance by tracking objects in the visual field. These include trajectory reconstruction [3], egomotion estimation <ref> [10] </ref>, object recognition [6] and navigation, which are important subjects in current robotics research. In structured conditions, where objects have constrained shapes or motions, or move in simple backgrounds, some tracking systems have been successfully employed [13, 1].
Reference: [11] <author> D. Fleet, A. Jepson, and M. Jenkin. </author> <title> Phase-based disparity measurement. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 53(2) </volume> <pages> 198-210, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Thus, a variational kinematics model for vergence is given by: ffi- ' fl d d (1) where d is the target horizontal disparity and fl d depends on system calibration parameters. Traditional algorithms to calculate explicit disparity measures include cepstral filtering [17] and phase correlation <ref> [11] </ref>, but these techniques are very time consuming, and therefore, not very adequate for real-time applications.
Reference: [12] <author> G. Franklin, J. Powell, and M. Workman. </author> <title> Digital Control of Dynamic Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: In the present case, a simple pole-placement technique was used but other techniques are available in the literature <ref> [12] </ref>. 4.4 Coordination In this section we have presented the visuomotor behaviours that compose the tracking system. The vergence behaviour and the pursuit behaviour extract different measures from the images and control different motor actions, requiring a low coordination effort.
Reference: [13] <author> D. Gennery. </author> <title> Visual tracking of known three-dimensional objects. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7(3) </volume> <pages> 243-270, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: These include trajectory reconstruction [3], egomotion estimation [10], object recognition [6] and navigation, which are important subjects in current robotics research. In structured conditions, where objects have constrained shapes or motions, or move in simple backgrounds, some tracking systems have been successfully employed <ref> [13, 1] </ref>. However, in complex and dynamic environments, where restrictions about the kind of objects or motions cannot be made, most systems lack robustness, reactivity and flexibility.
Reference: [14] <author> B. Horn and B. Shunk. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: Velocity Error Velocity estimation could be simply done by differencing the position data. However, position estimates have a considerable amount of noise which would be amplified by this strategy. Other well known technique for velocity estimation is the optical flow <ref> [14] </ref> which provides velocity estimates for each point in the image. The integration of the normal flow vectors 2 for each point belonging to the target, provides a stable velocity measure and good noise rejection. <p> Thus, dynamic effects are due only to motor dynamics, which 2 Normal flow is the projection of the optical flow vector in the direction of the image gradient. Is the only observable component of the optical flow due to the aperture problem <ref> [14] </ref>. we assume to be first order. To have smoother trajectories, motors will be controlled in velocity mode.
Reference: [15] <author> D. Koller, K. Daniilidis, and H. Nagel. </author> <title> Model-based object tracking in monocular image sequences of road traffic scenes. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(3) </volume> <pages> 257-281, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: These solutions are fl Partially funded by projects PRAXIS/3/3.1/TPR/23/94 and JNICT-PBIC/TPR/2550/95. applied to the current problem showing several advantages over other more straightforward approaches. Binocularity: Although many researchers have faced the tracking problem as a monocular one <ref> [15, 16] </ref>, binocularity can provide major benefits. Not only it is possible to recover depth from the tracked object but also binocular fusion greatly simplifies figure-ground segmentation [8]. Ocular Movements: The most influent ocular movements in biological systems are saccadic, vergence and smooth pursuit movements [18].
Reference: [16] <author> D. Lowe. </author> <title> Robust model-based motion tracking through the integration of search and estimation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 113-122, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: These solutions are fl Partially funded by projects PRAXIS/3/3.1/TPR/23/94 and JNICT-PBIC/TPR/2550/95. applied to the current problem showing several advantages over other more straightforward approaches. Binocularity: Although many researchers have faced the tracking problem as a monocular one <ref> [15, 16] </ref>, binocularity can provide major benefits. Not only it is possible to recover depth from the tracked object but also binocular fusion greatly simplifies figure-ground segmentation [8]. Ocular Movements: The most influent ocular movements in biological systems are saccadic, vergence and smooth pursuit movements [18].
Reference: [17] <author> K. Ludwig, H. Neumann, and B. Neumann. </author> <title> Robust estimation of local stereoscopic depth. </title> <editor> In W. Forstner and St. Ruwiedel, editors, </editor> <title> Robust Computer Vision. </title> <type> Wichmann, </type> <year> 1992. </year>
Reference-contexts: Thus, a variational kinematics model for vergence is given by: ffi- ' fl d d (1) where d is the target horizontal disparity and fl d depends on system calibration parameters. Traditional algorithms to calculate explicit disparity measures include cepstral filtering <ref> [17] </ref> and phase correlation [11], but these techniques are very time consuming, and therefore, not very adequate for real-time applications.
Reference: [18] <author> D. Robinson. </author> <title> The oculomotor control system: A review. </title> <journal> Proc. of the IEEE, </journal> <volume> 56(6), </volume> <month> June </month> <year> 1968. </year>
Reference-contexts: Not only it is possible to recover depth from the tracked object but also binocular fusion greatly simplifies figure-ground segmentation [8]. Ocular Movements: The most influent ocular movements in biological systems are saccadic, vergence and smooth pursuit movements <ref> [18] </ref>. Saccadic and smooth pursuit movements use retinal position and velocity errors, respectively, in order to compensate lateral motion of the target. Vergence movements, instead, are mainly based on disparity cues to compensate motion in depth.
Reference: [19] <author> J. Santos-Victor, G. Sandini, F. Curotto, and S. Garibaldi. </author> <title> Divergent stereo in autonomous navigation : From bees to robots. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 14(2) </volume> <pages> 159-177, </pages> <year> 1995. </year>
Reference-contexts: This fact led some researchers to search for motivation on biological systems that could help on the design of the required solutions <ref> [19] </ref>. The tracking system presented in this paper is implemented on an active vision stereo head (Medusa [20]) and follows some existing solutions on the visual system of humans and other animals.
Reference: [20] <author> J. Santos-Victor, F. van Trigt, and J. Sentieiro. </author> <title> Medusa a stereo head for active vision. </title> <booktitle> In Proc. of the Int. Symposium on Intelligent Robotic Systems, </booktitle> <address> Grenoble, France, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: This fact led some researchers to search for motivation on biological systems that could help on the design of the required solutions [19]. The tracking system presented in this paper is implemented on an active vision stereo head (Medusa <ref> [20] </ref>) and follows some existing solutions on the visual system of humans and other animals. These solutions are fl Partially funded by projects PRAXIS/3/3.1/TPR/23/94 and JNICT-PBIC/TPR/2550/95. applied to the current problem showing several advantages over other more straightforward approaches.
Reference: [21] <author> E. Schwartz. </author> <title> Spatial mapping in the primate sensory projection : Analytic structure and relevance to perception. </title> <journal> Biological Cybernetics, </journal> <volume> 25 </volume> <pages> 181-194, </pages> <year> 1977. </year>
Reference-contexts: These behaviours are separable as they acquire different stimuli and control different motions but are highly coupled in the sense that each one depends on the performance of the other. In both behaviours, visual sensing is made on log-polar images. The log-polar mapping <ref> [21] </ref> provides a non-uniform resolution geometry which is similar to the distribution of photo-receptors in the human retina, resulting in both algorithmic and perceptual advantages over the usual cartesian representation [3, 4]. The focus of this paper is on the design, integration and test of these behaviours.
References-found: 21

