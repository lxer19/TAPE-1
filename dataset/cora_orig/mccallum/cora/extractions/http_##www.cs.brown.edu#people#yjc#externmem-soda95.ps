URL: http://www.cs.brown.edu/people/yjc/externmem-soda95.ps
Refering-URL: http://www.cs.brown.edu/people/yjc/
Root-URL: http://www.cs.brown.edu/
Title: Chapter 1 External-Memory Graph Algorithms  
Author: Yi-Jen Chiang Michael T. Goodrich zx Edward F. Grove -k Roberto Tamassia Darren Erik Vengroff flyy Jeffrey Scott Vitter -zz 
Note: Supported in part by the National Science Foundation, by the U.S. Army Research Office, and by the Advanced Research Projects Agency.  Supported in part by the National Science Foundation under grants CCR-9003299, IRI-9116843, and CCR-9300079.  k Supported in part by the U.S. Army Research Office under grant DAAH04-93-G-0076. yy Supported in part by the U.S. Army Research Office under grant DAAL03-91-G-0035 and by the National Science Foundation under grant DMR-9217290.  
Address: Box 1910, Brown Univer sity, Providence, RI 02912-1910.  Baltimore, MD 21218-2694  Box 90129, Duke Univer sity, Durham, NC 27708-0129.  
Affiliation: Department of Computer Science,  Department of Computer Science, The Johns Hopkins University,  Department of Computer Science,  
Abstract: We present a collection of new techniques for designing and analyzing efficient external-memory algorithms for graph problems and illustrate how these techniques can be applied to a wide variety of specific problems. Our results include: * Proximate-neighboring. We present a simple method for deriving external-memory lower bounds via reductions from a problem we call the "proximate neighbors" problem. We use this technique to derive non-trivial lower bounds for such problems as list ranking, expression tree evaluation, and con nected components. * PRAM simulation. We give methods for efficiently simulating PRAM computations in external memory, even for some cases in which the PRAM algorithm is not work-optimal. We apply this to derive a number of optimal (and simple) external-memory graph algorithms. * Time-forward processing. We present a general technique for evaluating circuits (or "circuit-like" computations) in external memory. We also use this in a deterministic list ranking algorithm. zz Supported in part by the National Science Foundation under grant CCR-9007851 and by the U.S. Army Research Office under grants DAAL03-91-G-0035 and DAAH04-93-G-0076. * Deterministic 3-coloring of a cycle. We give several optimal methods for 3-coloring a cycle, which can be used as a subroutine for finding large independent sets for list ranking. Our ideas go beyond a straightforward PRAM simulation, and may be of independent interest. * External depth-first search. We discuss a method for performing depth first search and solving related problems efficiently in external memory. Our technique can be used in conjunction with ideas due to Ullman and Yannakakis in order to solve graph problems involving closed semi-ring computations even when their assumption that vertices fit in main memory does not hold. Our techniques apply to a number of problems, including list ranking, which we discuss in detail, finding Euler tours, expression-tree evaluation, centroid decomposition of a tree, least-common ancestors, minimum spanning tree verification, connected and biconnected components, minimum spanning forest, ear decomposition, topological sorting, reachability, graph drawing, and visibility representation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal and J. S. Vitter. </author> <title> The input/output complexity of sorting and related problems. </title> <journal> Communications of the ACM, </journal> <volume> 31(9) </volume> <pages> 1116-1127, </pages> <year> 1988. </year>
Reference-contexts: Early work in external-memory algorithms for parallel disk systems concentrated largely on fundamental problems such as sorting, matrix multiplication, and FFT <ref> [1, 19, 26] </ref>. The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research [1, 6, 7, 8, 26]. <p> The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research <ref> [1, 6, 7, 8, 26] </ref>. More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12]. <p> In external memory, however, it is not generally possible to perform arbitrary permutations in a linear number (O (scan (N ))) of I/Os. Instead, it is well-known that fi (perm (N )) I/Os are required in the worst case <ref> [1, 26] </ref> where perm (N ) = min D ; sort (N ) When M or B is extremely small, N=D = O (B scan (N )) may be smaller than sort (N ). <p> Then at least one of these permutations requires fi (perm (N )) I/Os. Proof Sketch. The proof is an adaptation and generalization of that given by Aggarwal and Vitter <ref> [1] </ref> for the special case ff = 1 and c = 0. 2 In order to apply the lower bound of Lemma 2.1 to graph problems, we will first use it to prove a lower bound on the proximate neighbors problem. <p> In the final phase, for each i = 3; ::; log (t+1) N 1, we re-color the nodes with color i by assigning them a new color in the range <ref> [0; 1; 2] </ref>. This phase is performed iteratively in O (log (t+1) N + sort (N i )) 1 The notation log (k) N is defined recursively as follows: log (1) N = log N , and log (i+1) N = log log (i) N , for i 1.
Reference: [2] <author> R. J. Anderson and G. L. Miller. </author> <title> A simple randomized parallel algorithm for list-ranking. </title> <journal> Info. Proc. Letters, </journal> <volume> 33(5) </volume> <pages> 269-273, </pages> <year> 1990. </year>
Reference-contexts: We present algorithms that use an optimal fi (sort (N )) I/O operations. The lower bound for the problem comes from Corollary 2.1. 5.1 An Algorithmic Framework for List Ranking. Our algorithmic framework is adapted from the work of Anderson and Miller <ref> [2] </ref>. It has also been used by Cole and Vishkin [5], who developed a deterministic version of Anderson and Miller's randomized algorithm. Initially, we assign rank (v) = 1 for each node v in list L. This can be done in O (scan (N )) I/Os. We then proceed recursively. <p> The details of how this independent set is produced are what separate our algorithms from one another. Once we have a large independent set S, we use O (1) sorts and scans to bridge each node v in the set, as described in <ref> [2] </ref>. We then recursively solve the problem on the remaining nodes. Finally, we use O (1) sorts and scans to re-integrate the nodes in S into the final solution. <p> The simplest way to produce a large independent set is a randomized approach based on that first proposed by Anderson and Miller <ref> [2] </ref>. We scan along the input, flipping a fair coin for each vertex v. We then make two copies of the input, sorting one by vertex and the other by successor. <p> In the final phase, for each i = 3; ::; log (t+1) N 1, we re-color the nodes with color i by assigning them a new color in the range <ref> [0; 1; 2] </ref>. This phase is performed iteratively in O (log (t+1) N + sort (N i )) 1 The notation log (k) N is defined recursively as follows: log (1) N = log N , and log (i+1) N = log log (i) N , for i 1.
Reference: [3] <author> O. Berkman and U. Vishkin. </author> <title> Recursive star-tree parallel data structure. </title> <type> Technical report, </type> <institution> Institue for Advanced Computer Studies, Univ. of Maryland, College Park, </institution> <year> 1990. </year>
Reference-contexts: Centroid decomposition of a tree can be performed similarly. The least common ancestor problem can be reduced to the range minima problem using Euler Tour and list ranking <ref> [3] </ref>. We construct a search tree S with O (N=B) leaves, each a block storing B data items. Tree S is a complete (M=B)-ary tree with O (log M=B (N=B)) levels, where each internal node v of S corresponds to the items in the subtree S v rooted at v.
Reference: [4] <author> F. Y. Chin, J. Lam, and I. Chen. </author> <title> Efficient parallel algorithms for some graph problems. </title> <journal> Comm. of the ACM, </journal> <volume> 25(9) </volume> <pages> 659-665, </pages> <year> 1982. </year>
Reference-contexts: If this never happens, then T is an MST. For connected components and minimum spanning forest, our algorithm is based on that of Chin et al. <ref> [4] </ref>. Each iteration performs a constant number of sorts on current edges and one list ranking to reduce the number of vertices by a constant factor. After O (log (V =M )) iterations we fit the remaining M vertices to the main memory and solve the problem easily.
Reference: [5] <author> R. Cole and U. Vishkin. </author> <title> Deterministic coin tossing with applications to optimal list-ranking. </title> <journal> Information and Control, </journal> <volume> 70(1) </volume> <pages> 32-53, </pages> <year> 1986. </year>
Reference-contexts: The lower bound for the problem comes from Corollary 2.1. 5.1 An Algorithmic Framework for List Ranking. Our algorithmic framework is adapted from the work of Anderson and Miller [2]. It has also been used by Cole and Vishkin <ref> [5] </ref>, who developed a deterministic version of Anderson and Miller's randomized algorithm. Initially, we assign rank (v) = 1 for each node v in list L. This can be done in O (scan (N )) I/Os. We then proceed recursively. <p> In this phase we produce a (log (t+1) N )-coloring. We omit the details in this extended abstract. The method is based upon a non-trivial adaptation of the deterministic coin tossing technique of Cole and Vishkin <ref> [5] </ref>. The total number of I/Os performed in this phase is O (t sort (N ) + (log (t+1) N ) 2 ). 3.
Reference: [6] <author> T. H. Cormen. </author> <title> Virtual Memory for Data Parallel Computing. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research <ref> [1, 6, 7, 8, 26] </ref>. More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12]. <p> We show in subsequent sections how to combine these techniques with more sophisticated strategies to design efficient external-memory algorithms for a number of graph problems. Related work on simulating PRAM computations in external memory was done by Cormen <ref> [6] </ref>. The use of PRAM simulation for prefetch-ing, without the important consideration of blocking, is explored by Vishkin [25]. 3.1 Generic Simulation of an O (N ) Space PRAM Algorithm. We begin by considering how to simulate a PRAM algorithm that uses N processors and O (N ) space.
Reference: [7] <author> T. H. Cormen. </author> <title> Fast permuting in disk arrays. </title> <journal> Journal of Parallel and Distributed Computing, 17(1-2):41-57, </journal> <volume> Jan./Feb. </volume> <year> 1993. </year>
Reference-contexts: The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research <ref> [1, 6, 7, 8, 26] </ref>. More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12].
Reference: [8] <author> T. H. Cormen, T. Sundquist, and L. F. Wisniewski. </author> <title> Asymptotically tight bounds for performing BMMC permutations on parallel disk systems. </title> <type> Technical Report PCS-TR94-223, </type> <institution> Dartmouth College Dept. of Computer Science, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research <ref> [1, 6, 7, 8, 26] </ref>. More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12].
Reference: [9] <author> E. Feuerstein and A. Marchetti-Spaccamela. </author> <title> Memory paging for connectivity and path problems in graphs. </title> <booktitle> In Proc. Int. Symp. on Algorithms and Comp., </booktitle> <year> 1993. </year>
Reference-contexts: Vishkin [25] uses PRAM simulation to facilitate prefetching for various problems, but without taking blocking issues into account. Also worth noting is recent work [11] on some graph traversal problems; this work primarily addresses the problem of storing graphs, however, not in performing specific computations on them. Related work <ref> [9] </ref> proposes a framework for studying memory management problems for maintaining connectivity information and paths on graphs. Other than these papers, we do not know of any previous work on I/O-efficient graph algorithms. 1.3 Our Results.
Reference: [10] <author> P. G. Franciosa and M. Talamo. </author> <title> Orders, implicit k-sets representation and fast halfplane searching. </title> <booktitle> In Proc. Workshop on Orders, Algorithms and Applications (ORDAL'94), </booktitle> <pages> pages 117-127, </pages> <year> 1994. </year>
Reference-contexts: More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12]. Further results in this area have recently been obtained in <ref> [10, 27] </ref>. There has also been some work on selected graph problems, including the investigations by Ullman and Yannakakis [23] on problems involving transitive closure computations.
Reference: [11] <author> M. T. Goodrich, M. H. Nodine, and J. S. Vitter. </author> <title> Blocking for external graph searching. </title> <booktitle> In Proc. ACM SIGACT-SIGMOD-SIGART Symp. on Principles of Database Sys., </booktitle> <pages> pages 222-232, </pages> <year> 1993. </year>
Reference-contexts: This work, however, restricts its attention to problem instances where the set of vertices fits into main memory but the set of edges does not. Vishkin [25] uses PRAM simulation to facilitate prefetching for various problems, but without taking blocking issues into account. Also worth noting is recent work <ref> [11] </ref> on some graph traversal problems; this work primarily addresses the problem of storing graphs, however, not in performing specific computations on them. Related work [9] proposes a framework for studying memory management problems for maintaining connectivity information and paths on graphs.
Reference: [12] <author> M. T. Goodrich, J.-J. Tsay, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory computational geometry. </title> <booktitle> In IEEE Foundations of Comp. Sci., </booktitle> <pages> pages 714-723, </pages> <year> 1993. </year>
Reference-contexts: More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry <ref> [12] </ref>. Further results in this area have recently been obtained in [10, 27]. There has also been some work on selected graph problems, including the investigations by Ullman and Yannakakis [23] on problems involving transitive closure computations. <p> Using the technique described above to process the pairs V at a time, this takes O ((E=V )sort (V )) I/Os. Finally, we construct tuples consisting of the edges of G, their weights and the lowest common ancestors of their endpoints, and, using the batch filtering technique of <ref> [12] </ref>, we filter these tuples through T 0 , V at a time. This batch filtering takes O ((E=V )sort (V )) I/Os. When a tuple hits the lowest common ancestor of the endpoints of its edge, it splits into two queries, one continuing on towards each of its endpoints.
Reference: [13] <author> D. R. Karger. </author> <title> Global min-cuts in RNC and other ramifications of a simple mincut algorithm. </title> <booktitle> In Proc. 4th ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 21-30, </pages> <year> 1993. </year>
Reference-contexts: Note that all these problems can be solved within the bound of computing minimum spanning forest. Our randomized algorithm reduces this latter bound by decreasing in each iteration the numbers of both edges and vertices by a constant factor, using an external-memory variation of the random sampling technique by <ref> [13, 15] </ref> and the previously mentioned minimum spanning tree verification method. Planar st-graphs were first introduced by Lempel, Even, and Cederbaum [16], and have a variety of applications in Computational Geometry, motion planning, and VLSI layout.
Reference: [14] <author> V. King. </author> <title> A simpler minimum spanning tree verification algorithm, </title> <year> 1994. </year>
Reference-contexts: If K &gt; N we process the queries in batches of N at a time. For the minimum spanning tree (MST) verification problem, our technique is based on that of King <ref> [14] </ref>. We verify that a given tree T is an MST of a graph G by verifying that each edge (u; v) in G has weight at least as large as that of the heaviest edge on the path from u to v in T .
Reference: [15] <author> P. Klein and R. Tarjan. </author> <title> A randomized linear-time algorithm for finding minimum spanning trees. </title> <booktitle> In Proc. ACM Symp. on Theory of Computing, </booktitle> <year> 1994. </year>
Reference-contexts: Note that all these problems can be solved within the bound of computing minimum spanning forest. Our randomized algorithm reduces this latter bound by decreasing in each iteration the numbers of both edges and vertices by a constant factor, using an external-memory variation of the random sampling technique by <ref> [13, 15] </ref> and the previously mentioned minimum spanning tree verification method. Planar st-graphs were first introduced by Lempel, Even, and Cederbaum [16], and have a variety of applications in Computational Geometry, motion planning, and VLSI layout.
Reference: [16] <author> A. Lempel, S. Even, and I. Cederbaum. </author> <title> An algorithm for planarity testing of graphs. In Theory of Graphs, </title> <booktitle> Int. Symp. </booktitle> <address> (Rome, </address> <year> 1966), </year> <pages> pages 215-232. </pages> <publisher> Gordon and Breach, </publisher> <address> New York, </address> <year> 1967. </year>
Reference-contexts: Planar st-graphs were first introduced by Lempel, Even, and Cederbaum <ref> [16] </ref>, and have a variety of applications in Computational Geometry, motion planning, and VLSI layout.
Reference: [17] <author> Y. Maon, B. Schieber, and U. Vishkin. </author> <title> Parallel ear decomposition search and st-numbering in graphs. </title> <journal> Theoretical Computer Science, </journal> <volume> 47(3) </volume> <pages> 277-296, </pages> <year> 1986. </year>
Reference-contexts: For biconnected components, we adapt the PRAM algorithm of Tarjan and Vishkin [22], which requires generating an arbitrary spanning tree, evaluating an expression tree, and computing connected components of a newly created graph. For ear decomposition, we modify the PRAM algorithm of Maon et al. <ref> [17] </ref>, which requires generating an arbitrary spanning tree, performing batched lowest common ancestor queries, and evaluating an expression tree. Note that all these problems can be solved within the bound of computing minimum spanning forest.
Reference: [18] <author> M. H. Nodine and J. S. Vitter. </author> <title> Deterministic distribution sort in shared and distributed memory multiprocessors. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Furthermore, for simplicity, we restrict the discussion to the D = 1 case of one disk. The load balancing issues that arise with multiple disks are handled with balancing techniques akin to <ref> [18, 26] </ref>. The 3-coloring algorithm consists of three phases. Colors and node IDs are represented by integers. 1. In this phase we construct an initial N -coloring of L by assigning a distinct color in the range [0; ; N 1] to each node.
Reference: [19] <author> M. H. Nodine and J. S. Vitter. </author> <title> Paradigms for optimal sorting with multiple disks. </title> <booktitle> In Proc. of the 26th Hawaii Int. Conf. on Systems Sciences, </booktitle> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: each of these primitives: scan (x) = x ; which represents the number of I/Os needed to read x items striped across the disks, and sort (x) = x log M=B B which is proportional to the optimal number of I/Os needed to sort x items striped across the disk <ref> [19] </ref>. 1.2 Previous Work. Early work in external-memory algorithms for parallel disk systems concentrated largely on fundamental problems such as sorting, matrix multiplication, and FFT [1, 19, 26]. The main focus of this early work was therefore directed at problems that involved permutation at a basic level. <p> Early work in external-memory algorithms for parallel disk systems concentrated largely on fundamental problems such as sorting, matrix multiplication, and FFT <ref> [1, 19, 26] </ref>. The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research [1, 6, 7, 8, 26]. <p> In the presence of multiple disks, however, we must be sure to guarantee that each bucket is stored roughly evenly across the parallel disks; this is the fundamental problem addressed in <ref> [19] </ref>. An overview of a possible approach is to keep one block of main memory allocated to each bucket.
Reference: [20] <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> IEEE Comp., </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: In coming years we can expect the significance of the I/O bottleneck to increase to the point that we can ill afford to ignore it, since technological advances are increasing CPU speeds at an annual rate of 40-60% while disk transfer rates are only increasing by 7-10% annually <ref> [20] </ref>. Unfortunately, the overwhelming majority of the vast literature on graph algorithms ignores this bottleneck and simply assumes that data completely fits in main memory (as in the usual RAM model).
Reference: [21] <author> R. Tamassia and J. S. Vitter. </author> <title> Optimal cooperative search in fractional cascaded data structures. </title> <booktitle> In Proc. 2nd ACM Symosium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 307-316, </pages> <year> 1990. </year>
Reference-contexts: Planar st-graphs were first introduced by Lempel, Even, and Cederbaum [16], and have a variety of applications in Computational Geometry, motion planning, and VLSI layout. We obtain the given upper bounds by modifying the PRAM algorithms of Tamassia and Vit-ter <ref> [21] </ref>, and applying the list ranking and the PRAM simulation techniques. 7 Depth First Search and Closed Semi-Ring Computation Many algorithms for problems on directed graphs are easily solved in main memory by depth first search (DFS).
Reference: [22] <author> R. Tarjan and U. Vishkin. </author> <title> Finding biconnected components and computing tree functions in logarithmic parallel time. </title> <journal> SIAM J. Computing, </journal> <volume> 14(4) </volume> <pages> 862-874, </pages> <year> 1985. </year>
Reference-contexts: After O (log (V =M )) iterations we fit the remaining M vertices to the main memory and solve the problem easily. For biconnected components, we adapt the PRAM algorithm of Tarjan and Vishkin <ref> [22] </ref>, which requires generating an arbitrary spanning tree, evaluating an expression tree, and computing connected components of a newly created graph.
Reference: [23] <author> J. D. Ullman and M. Yannakakis. </author> <title> The input/output complexity of transitive closure. </title> <journal> Annals of Mathematics and Artificial Intellegence, </journal> <volume> 3 </volume> <pages> 331-360, </pages> <year> 1991. </year>
Reference-contexts: For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12]. Further results in this area have recently been obtained in [10, 27]. There has also been some work on selected graph problems, including the investigations by Ullman and Yannakakis <ref> [23] </ref> on problems involving transitive closure computations. This work, however, restricts its attention to problem instances where the set of vertices fits into main memory but the set of edges does not. Vishkin [25] uses PRAM simulation to facilitate prefetching for various problems, but without taking blocking issues into account. <p> Then one can compute the strongly connected components of G and perform a topological sorting on the strongly connected components using O ((1 + V =M )scan (E) + V ) I/Os. Ullman and Yannakakis have recently presented external-memory techniques for computing the transitive closure of a directed graph <ref> [23] </ref>. They solve this problem using O (dfs (V; E) + scan (V 2 p where dfs (V; E) is the number of I/Os needed to perform DFS on the input graph in order to find strongly connected components and topologically sort it.
Reference: [24] <author> D. E. Vengroff. </author> <title> A transparent parallel I/O environment. </title> <booktitle> In Proc. 1994 DAGS Symposium on Parallel Computation, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Note that E = O (V ) for these graphs. lines has been written using an alpha version of TPIE, a transparent parallel I/O environment designed to facilitate the implementation of I/O efficient algorithms from a variety of domains <ref> [24] </ref>. We expect to implement additional algorithms using TPIE and publish empirical results regarding their efficiency in the near future.
Reference: [25] <author> U. </author> <title> Vishkin. </title> <type> Personal communication, </type> <year> 1992. </year>
Reference-contexts: This work, however, restricts its attention to problem instances where the set of vertices fits into main memory but the set of edges does not. Vishkin <ref> [25] </ref> uses PRAM simulation to facilitate prefetching for various problems, but without taking blocking issues into account. Also worth noting is recent work [11] on some graph traversal problems; this work primarily addresses the problem of storing graphs, however, not in performing specific computations on them. <p> Related work on simulating PRAM computations in external memory was done by Cormen [6]. The use of PRAM simulation for prefetch-ing, without the important consideration of blocking, is explored by Vishkin <ref> [25] </ref>. 3.1 Generic Simulation of an O (N ) Space PRAM Algorithm. We begin by considering how to simulate a PRAM algorithm that uses N processors and O (N ) space. In order to simulate such a PRAM algorithm, we first consider how to simulate a single step.
Reference: [26] <author> J. S. Vitter and E. A. M. Shriver. </author> <title> Algorithms for parallel memory I: Two-level memories. </title> <journal> Algorithmica, </journal> <volume> 12(2), </volume> <year> 1994. </year>
Reference-contexts: Problem instances can be in the range 10 10 N 10 12 . Our measure of performance for external-memory algorithms is the standard notion of I/O complexity for parallel disks <ref> [26] </ref>. We define an input/output operation (or simply I/O for short) to be the process of simultaneously reading or writing D blocks of data, one to or from each of the D disks. The total amount of data transferred in an I/O is thus DB items. <p> Early work in external-memory algorithms for parallel disk systems concentrated largely on fundamental problems such as sorting, matrix multiplication, and FFT <ref> [1, 19, 26] </ref>. The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research [1, 6, 7, 8, 26]. <p> The main focus of this early work was therefore directed at problems that involved permutation at a basic level. Indeed, just the problem of implementing various classes of permutation has been a central theme in external-memory I/O research <ref> [1, 6, 7, 8, 26] </ref>. More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12]. <p> In external memory, however, it is not generally possible to perform arbitrary permutations in a linear number (O (scan (N ))) of I/Os. Instead, it is well-known that fi (perm (N )) I/Os are required in the worst case <ref> [1, 26] </ref> where perm (N ) = min D ; sort (N ) When M or B is extremely small, N=D = O (B scan (N )) may be smaller than sort (N ). <p> Furthermore, for simplicity, we restrict the discussion to the D = 1 case of one disk. The load balancing issues that arise with multiple disks are handled with balancing techniques akin to <ref> [18, 26] </ref>. The 3-coloring algorithm consists of three phases. Colors and node IDs are represented by integers. 1. In this phase we construct an initial N -coloring of L by assigning a distinct color in the range [0; ; N 1] to each node.
Reference: [27] <author> B. Zhu. </author> <title> Further computational geometry in secondary memory. </title> <booktitle> In Proc. Int. Symp. on Algorithms and Computation, </booktitle> <year> 1994. </year>
Reference-contexts: More recently, external-memory research has moved towards solving problems that are not as directly related to the permutation problem. For example Goodrich, Tsay, Vengroff, and Vitter study a number of problems in computational geometry [12]. Further results in this area have recently been obtained in <ref> [10, 27] </ref>. There has also been some work on selected graph problems, including the investigations by Ullman and Yannakakis [23] on problems involving transitive closure computations.
References-found: 27

