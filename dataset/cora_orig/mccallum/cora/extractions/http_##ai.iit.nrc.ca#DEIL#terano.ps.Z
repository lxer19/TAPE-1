URL: http://ai.iit.nrc.ca/DEIL/terano.ps.Z
Refering-URL: http://ai.iit.nrc.ca/DEIL/abstracts.html
Root-URL: 
Email: email: fterano, ishinog@gssm.otsuka.tsukuba.ac.jp  
Phone: phone: +81-3-3942-6855, facsimile: +81-3-3942-6829  
Title: Data Analyses Using Simulated Breeding and Inductive Learning Methods  
Author: Takao TERANO and Yoko ISHINO 
Address: address: 3-29-1 Otsuka, Bunkyo-ku, Tokyo 112, Japan  
Affiliation: Graduate School of Systems Management, The University of Tsukuba, Tokyo  
Abstract: Marketing decision making tasks require the acquisition of efficient decision rules from noisy questionnaire data. Unlike popular learning-from-example methods, in such tasks, we must interpret the characteristics of the data without clear features of the data nor pre-determined evaluation criteria. The problem is how domain experts get simple, easy-to-understand, and accurate knowledge from noisy data. This paper describes a novel method to acquire efficient decision rules from questionnaire data using both simulated breeding and inductive learning techniques. The basic ideas of the method are that simulated breeding is used to get the effective features from the questionnaire data and that inductive learning is used to acquire simple decision rules from the data. The simulated breeding is one of the Genetic Algorithm based techniques to subjectively or interactively evaluate the qualities of offspring generated by genetic operations. The proposed method has been qualitatively and quantitatively validated by a case study on consumer product questionnaire data: the acquired rules are simpler than the results from the direct application of inductive learning; a domain expert admits that they are easy to understand; and they are at the same level on the accuracy compared with the other methods. 
Abstract-found: 1
Intro-found: 1
Reference: [Aaker et al. 1980] <author> Aaker, D. A., Day, G. S. </author> : <title> Marketing Research: Private and Public Sector Decisions. </title> <publisher> John-Wiley, </publisher> <year> 1980. </year>
Reference-contexts: For example, multivariate analysis [Kendall 1980] has been the main statistical tool used for analysis of questionnaire data. During the analysis, emphasis has been placed on understanding trends after identifying target data. Furthermore, marketing requires use of quantitative as well as qualitative analysis <ref> [Aaker et al. 1980] </ref>. Unfortunately, there are no statistical tools to facilitate to satisfy both requirements simultaneously. On the other hand, AI-based techniques for concept learning do not assume such conditions, however, they involve combinatorial feature selection problems.
Reference: [Bala et al. 1994] <author> Bala, J. W., De Jong, K, Pachowicz, P. W.: </author> <title> Multistrategy Learning from Engineering Data by Integrating Inductive Generalization and Genetic Algorithms. </title> <editor> in Michalski, R., Tecuci, G. (eds.): </editor> <title> Machine Learning IV: A Multistrategy Approach. </title> <publisher> Morgan-Kaufmann, </publisher> <pages> pp. 471-488, </pages> <year> 1994. </year>
Reference-contexts: Therefore, the size of the search space is 2 16 , which seems small to use Genetic Algorithms, however, it is enough large for using Simulated Breeding. For example, the size is as same as the ones in the researches which solve feature selection problems using GA techniques <ref> [Bala et al. 1994] </ref>, [Vafaie et al. 1994]. This means that the selection of appropriate features within only 16 candidates requires various kinds of efforts. The experimental system SIBILE was implemented on a Sun Sparc Station. <p> For example, [Vafaie et al. 1994] has investigated automated feature selection for inductive learning program AQ with GA-based techniques. The task domain is the classification of texture images with 18 features. The objective function of GA is defined based on the accuracy of the decision rules or classifiers. <ref> [Bala et al. 1994] </ref> has proposed another multistrategy approach to use GA to improve the performance of classification rules generated by AQ. However, these researches differ from our problem in the aspect that objective functions to evaluated are explicitly given.
Reference: [Buntine et al. 1992] <author> Buntine, W., Niblett, T.: </author> <title> A Further Comparison of Splitting Rules for Decision-Tree Induction. </title> <journal> Machine Learning, </journal> <volume> Vol. 8, </volume> <pages> pp. 75-86, </pages> <year> 1992. </year>
Reference-contexts: Compared with these researches, our method also implicitly utilizes the expertize of the users on the marketing domains. Researches on the improvement of decision tree have been diverging in recent years (e.g., <ref> [Buntine et al. 1992] </ref>, [Schaffer 1993], and [Weiss et al. 1994]). There have been few attempts so far, we think that GA-based techniques will be able to contribute to the directions. In [Shapiro 1987], structured induction techniques are stated to be useful to develop expert systems.
Reference: [Clark et al. 1992] <author> Clark, L. A., Pregibon, D.: </author> <title> Tree-Based Model. in Chambers, </title> <editor> J.M., Hastie T. J., (eds.) </editor> <title> Statistical Models in S AT&T Bell Laboratories, </title> <year> 1992. </year>
Reference-contexts: The main difference between ID3 or C4.5 and AID to partition the data is that the former applies the concept of information entropy and that the latter utilizes the variance of the data. In the estimation, we have used S statistical package <ref> [Clark et al. 1992] </ref>. In the evaluation, after several trials, we have set the pruning parameter k equal to 5 in order to avoid both over- and under-fitting.
Reference: [Davis 1991] <editor> Davis, L. (ed.): </editor> <booktitle> Handbook of Genetic Algorithms. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: Dawkins has shown that through use of form constraints, such as left and right side symmetry and segment structures, which are both often since in living objects, figures resembling living objects can be developed. To use GA techniques, it is necessary to define the objective function in advance (e.g., <ref> [Davis 1991] </ref>). However, for problems where human subjective judgments play an important role, the definition of evaluation function is not an easy task.
Reference: [Dawkins 1986] <author> Dawkins, R.: The Blind Watchmaker. W. W. Norton, </author> <year> 1986. </year>
Reference-contexts: Simulated breeding can improve breeds by selecting the parent for the next generation from among the pheno-types developed based on human preference. An example of an earlier system related to simulated breeding was developed by R. Dawkins in the Blind Watchmaker <ref> [Dawkins 1986] </ref>. Dawkins has shown that through use of form constraints, such as left and right side symmetry and segment structures, which are both often since in living objects, figures resembling living objects can be developed. <p> The selected two parents are preserved for the next generation. The rest m-2 offspring are replaced by the corresponding new m-2 offspring. Step 5: Repeat the Steps Steps 2 to 4 are repeated until an appropriate decision tree or set of decision rules is obtained. As are illustrated in <ref> [Dawkins 1986] </ref> and [Unemi 1994], the steps required to obtain the appropriate results are very small.
Reference: [De Jong et al. 1991] <author> De Jong, K. A., Spears, W. M.: </author> <title> Learning Concept Classification Rules Using Genetic Algorithms. </title> <booktitle> Proc. IJCAI'91, </booktitle> <pages> pp. 651-656, </pages> <year> 1991. </year>
Reference-contexts: The roles of background knowledge to improve the performance of learning are also investigated in various researches. [Hirsh et al. 1994] uses such knowledge to the domain of genome informatics, [Janikow 1993] utilizes symbol-based genetic operations in his learning system, and <ref> [De Jong et al. 1991] </ref> proposes GA-based generation techniques for classification rules. Compared with these researches, our method also implicitly utilizes the expertize of the users on the marketing domains.
Reference: [Goldberg 1989] <author> Goldberg, D. E.: </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Step 4: Application of Genetic Algorithm The trees selected in Step 3 are set as parents, and new product characteristics are determined by genetic operations. The GA techniques we have adopted are based on the Simple GA found in <ref> [Goldberg 1989] </ref>. The corresponding chromosomes of the selected decision trees become parents for genetic operations. We apply uniform-crossover operations to them in order to get new sets of features to broaden the variety of offspring.
Reference: [Hirsh et al. 1994] <author> Hirsh, H., Noordewier, M.: </author> <title> Using Background Knowledge to Improve Inductive Learning: A Case Study in Molecular Biology. </title> <journal> IEEE Expert, </journal> <volume> Vol. 9, No. 5, </volume> <pages> pp. 3-6, </pages> <year> 1994. </year>
Reference-contexts: However, these researches differ from our problem in the aspect that objective functions to evaluated are explicitly given. The roles of background knowledge to improve the performance of learning are also investigated in various researches. <ref> [Hirsh et al. 1994] </ref> uses such knowledge to the domain of genome informatics, [Janikow 1993] utilizes symbol-based genetic operations in his learning system, and [De Jong et al. 1991] proposes GA-based generation techniques for classification rules.
Reference: [Janikow 1993] <author> Janikow, C.Z.: </author> <title> A Knowledge-Intensive Generic Algorithm for Supervised Learning. </title> <journal> Machine Learning, </journal> <volume> Vol. 13, </volume> <pages> pp. 189-228, </pages> <year> 1993. </year>
Reference-contexts: However, these researches differ from our problem in the aspect that objective functions to evaluated are explicitly given. The roles of background knowledge to improve the performance of learning are also investigated in various researches. [Hirsh et al. 1994] uses such knowledge to the domain of genome informatics, <ref> [Janikow 1993] </ref> utilizes symbol-based genetic operations in his learning system, and [De Jong et al. 1991] proposes GA-based generation techniques for classification rules. Compared with these researches, our method also implicitly utilizes the expertize of the users on the marketing domains.
Reference: [John et al.1994] <author> John, G. H., Kohavi, R., Pfleger, K.: </author> <title> Irrelevant Feature and the Subset Selection Problem. </title> <booktitle> Proc. Machine Learning-94, </booktitle> <pages> pp. 121-128, </pages> <year> 1994. </year>
Reference-contexts: Hence, selection of appropriate features becomes necessary. Various studies have been conducted to deal with the problem of interactions between features ([Kira et al. 1992], [Liu et al. 1992], <ref> [John et al.1994] </ref>). That is, feature selection intrinsically has combinatorial characteristics. In general sense, in the following sections, we will propose a method to solve the feature selection problem in inductive learning by the simulated breeding method.
Reference: [Kendall 1980] <author> Kendall, M.: </author> <title> Multivariate Analysis, </title> <booktitle> 2nd Edition. </booktitle> <address> Charles Griffin, </address> <year> 1980. </year>
Reference-contexts: Traditionally, statistical methods have been used for these analyses, however, conventional techniques in statistics are too weak because they usually assume the linearity of the models and the form of distributions of the data. For example, multivariate analysis <ref> [Kendall 1980] </ref> has been the main statistical tool used for analysis of questionnaire data. During the analysis, emphasis has been placed on understanding trends after identifying target data. Furthermore, marketing requires use of quantitative as well as qualitative analysis [Aaker et al. 1980].
Reference: [Kira et al. 1992] <author> Kira, K., Rendell, L. A.: </author> <title> The Feature Selection Problem: Traditional Methods and a New Algorithm. </title> <booktitle> Proc. AAAI'92, </booktitle> <pages> 129-134, </pages> <year> 1992 </year>
Reference: [Liu et al. 1992] <author> Liu, W. Z., White, A. P.: </author> <title> The Importance of Attribute Selection Measures in Decision Tree Induction. </title> <journal> Machine Learning, </journal> <volume> Vol. 15, </volume> <pages> pp. 25-41, </pages> <year> 1994. </year>
Reference-contexts: On the other hand, machine learning which attempts to incorporate all features in a decision tree is too complex [Menger 1989a]. Hence, selection of appropriate features becomes necessary. Various studies have been conducted to deal with the problem of interactions between features ([Kira et al. 1992], <ref> [Liu et al. 1992] </ref>, [John et al.1994]). That is, feature selection intrinsically has combinatorial characteristics. In general sense, in the following sections, we will propose a method to solve the feature selection problem in inductive learning by the simulated breeding method.
Reference: [Menger 1989a] <author> Mingers, J.: </author> <title> An Empirical Comparison of Selection Measures for Decision-Tree Induction. </title> <journal> Machine Learning, </journal> <volume> Vol. 3, </volume> <pages> pp. 319-342, </pages> <year> 1989. </year>
Reference-contexts: The performance of the results are compatible. However, we believe that the explainability of the results for domain experts from machine learning is better than the one from statistical methods. On the other hand, machine learning which attempts to incorporate all features in a decision tree is too complex <ref> [Menger 1989a] </ref>. Hence, selection of appropriate features becomes necessary. Various studies have been conducted to deal with the problem of interactions between features ([Kira et al. 1992], [Liu et al. 1992], [John et al.1994]). That is, feature selection intrinsically has combinatorial characteristics.
Reference: [Menger 1989b] <author> Mingers, J.: </author> <title> An Empirical Comparison of Pruning Methods for Decision-Tree Induction. </title> <journal> Machine Learning, </journal> <volume> Vol. 4, </volume> <pages> pp. 227-243, </pages> <year> 1989. </year>
Reference: [Quinlan 1986] <author> Quinlan, J. R. </author> <year> (1986): </year> <title> Induction for Decision Trees. </title> <booktitle> Machine Learning 1-1: </booktitle> <pages> 81-106 </pages>
Reference-contexts: To use GA techniques, it is necessary to define the objective function in advance (e.g., [Davis 1991]). However, for problems where human subjective judgments play an important role, the definition of evaluation function is not an easy task. The method most representative of inductive machine learning is ID3 <ref> [Quinlan 1986] </ref> which gives a decision tree or a set of decision rules as an output for the results of classification learning analysis on features and attribute-value pairs. Our research adopts C4.5 [Quinlan 1993] a noise tolerant successor of ID3.
Reference: [Quinlan 1993] <author> Quinlan, J. R. </author> <year> (1993): </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan-Kaufmann </publisher>
Reference-contexts: The method most representative of inductive machine learning is ID3 [Quinlan 1986] which gives a decision tree or a set of decision rules as an output for the results of classification learning analysis on features and attribute-value pairs. Our research adopts C4.5 <ref> [Quinlan 1993] </ref> a noise tolerant successor of ID3.
Reference: [SAS 1985] <institution> SAS User's Guide. SAS Institute Inc., </institution> <year> 1985. </year>
Reference-contexts: The outputs of LD only give the classification results and no explanations, as is usual in statistical methods. Please refer to e.g., [Weiss et al. 1991] for the detail of the method. We have used the SAS statistical package <ref> [SAS 1985] </ref> to estimate the questionnaire data. The third method, AID is a tree-based technique in statistical analyses, which can be used for the classification problem. In AID, selecting appropriate variables or features, a given set of data are recursively partitioned into two subset.
Reference: [Schaffer 1993] <author> Schaffer, C.: </author> <title> Overfitting Avoidance as Bias. </title> <journal> Machine Learning, </journal> <volume> Vol. 10, </volume> <pages> pp. 153-178, </pages> <year> 1993. </year>
Reference-contexts: Compared with these researches, our method also implicitly utilizes the expertize of the users on the marketing domains. Researches on the improvement of decision tree have been diverging in recent years (e.g., [Buntine et al. 1992], <ref> [Schaffer 1993] </ref>, and [Weiss et al. 1994]). There have been few attempts so far, we think that GA-based techniques will be able to contribute to the directions. In [Shapiro 1987], structured induction techniques are stated to be useful to develop expert systems.
Reference: [Shapiro 1987] <author> Shapiro, Alen D.: </author> <title> Structured Induction in Expert Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Researches on the improvement of decision tree have been diverging in recent years (e.g., [Buntine et al. 1992], [Schaffer 1993], and [Weiss et al. 1994]). There have been few attempts so far, we think that GA-based techniques will be able to contribute to the directions. In <ref> [Shapiro 1987] </ref>, structured induction techniques are stated to be useful to develop expert systems.
Reference: [Sims 1992] <author> Sims, K.: </author> <title> Interactive Evolution of Dynamical Systems. </title> <editor> in Varela, F. J., Bourgine, P. (eds.) </editor> : <booktitle> Toward a Practice of Autonomous Systems Proc. 1st European Conf. Artificial Life, </booktitle> <publisher> MIT Press, </publisher> <pages> pp. 171-178, </pages> <year> 1992. </year>
Reference-contexts: The idea of simulated breeding is similar to the ones of simulated evolution or interactive evolution in computer graphics arts <ref> [Sims 1992] </ref>. In both cases, individuals judged by human experts to have some efficient features are allowed to breed their offspring. The judgements are subjectively or interactively done. In such cases where the evaluation function is not clearly defined, simulated breeding methods can be used.
Reference: [Unemi 1994] <author> Unemi, T.: </author> <title> Genetic Algorithms and Computer Graphics Arts (in Japanese). </title> <journal> Journal of Japanese Society for Artificial Intelligence, </journal> <volume> Vol. 9, No. 4, </volume> <pages> pp. 42-47, </pages> <year> 1994 </year>
Reference-contexts: In Section 6, we discuss on the related work, and in Section 7, summary and concluding remarks are given. 1 2 Simulated Breeding and Inductive Learning Techniques Simulated breeding is one of the GA-based techniques to evolve offspring <ref> [Unemi 1994] </ref>. The idea of simulated breeding is similar to the ones of simulated evolution or interactive evolution in computer graphics arts [Sims 1992]. In both cases, individuals judged by human experts to have some efficient features are allowed to breed their offspring. The judgements are subjectively or interactively done. <p> The rest m-2 offspring are replaced by the corresponding new m-2 offspring. Step 5: Repeat the Steps Steps 2 to 4 are repeated until an appropriate decision tree or set of decision rules is obtained. As are illustrated in [Dawkins 1986] and <ref> [Unemi 1994] </ref>, the steps required to obtain the appropriate results are very small.
Reference: [Vafaie et al. 1994] <author> Vafaie, H., De Jong, K. A.: </author> <title> Improving a Rule Induction System Using Genetic Algorithms. </title> <editor> in Michalski, R., Tecuci, G. (eds.): </editor> <title> Machine Learning IV: A Multistrategy Approach. </title> <publisher> Morgan-Kaufmann, </publisher> <pages> pp. 453-470, </pages> <year> 1994 </year>
Reference-contexts: For example, the size is as same as the ones in the researches which solve feature selection problems using GA techniques [Bala et al. 1994], <ref> [Vafaie et al. 1994] </ref>. This means that the selection of appropriate features within only 16 candidates requires various kinds of efforts. The experimental system SIBILE was implemented on a Sun Sparc Station. <p> For example, <ref> [Vafaie et al. 1994] </ref> has investigated automated feature selection for inductive learning program AQ with GA-based techniques. The task domain is the classification of texture images with 18 features.
Reference: [Weiss et al. 1991] <author> Weiss, S. M., Kulikowski, C. A.: </author> <title> Computer Systems that Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning and Expert Systems. </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Our research adopts C4.5 [Quinlan 1993] a noise tolerant successor of ID3. As are stated in <ref> [Weiss et al. 1991] </ref>, inductive learning or concept learning techniques in Artificial Intelligence, and classification of data via statistical methods (for example, the linear discrimination method) will give similar classification results, if we are able to assume the linear distribution of sample data. The performance of the results are compatible. <p> The outputs of LD only give the classification results and no explanations, as is usual in statistical methods. Please refer to e.g., <ref> [Weiss et al. 1991] </ref> for the detail of the method. We have used the SAS statistical package [SAS 1985] to estimate the questionnaire data. The third method, AID is a tree-based technique in statistical analyses, which can be used for the classification problem.
Reference: [Weiss et al. 1994] <author> Weiss, S. M., Indurkhya, N.: </author> <title> Decision Tree Pruning: Biased or Optimal? Proc. </title> <booktitle> AAAI'94, </booktitle> <pages> pp. 626-632, </pages> <year> 1994. </year>
Reference-contexts: Compared with these researches, our method also implicitly utilizes the expertize of the users on the marketing domains. Researches on the improvement of decision tree have been diverging in recent years (e.g., [Buntine et al. 1992], [Schaffer 1993], and <ref> [Weiss et al. 1994] </ref>). There have been few attempts so far, we think that GA-based techniques will be able to contribute to the directions. In [Shapiro 1987], structured induction techniques are stated to be useful to develop expert systems.
References-found: 26

