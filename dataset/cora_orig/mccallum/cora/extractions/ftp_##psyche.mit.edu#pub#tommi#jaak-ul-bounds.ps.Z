URL: ftp://psyche.mit.edu/pub/tommi/jaak-ul-bounds.ps.Z
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00056.html
Root-URL: 
Email: ftommi,jordang@psyche.mit.edu  
Title: Computing upper and lower bounds on likelihoods in intractable networks  
Author: Tommi S. Jaakkola and Michael I. Jordan 
Address: Cambridge, MA 02139  
Affiliation: Department of Brain and Cognitive Sciences Massachusetts Institute of Technology  
Abstract: We present deterministic techniques for computing upper and lower bounds on marginal probabilities in sigmoid and noisy-OR networks. These techniques become useful when the size of the network (or clique size) precludes exact computations. We illustrate the tightness of the bounds by numerical experi ments.
Abstract-found: 1
Intro-found: 1
Reference: <author> P. Dayan, G. Hinton, R. Neal, and R. </author> <title> Zemel (1995). The Helmholtz machine. </title> <booktitle> Neural Computation 7: </booktitle> <pages> 889-904. </pages>
Reference: <author> P. Dagum and M. </author> <title> Luby (1993). Approximate probabilistic reasoning in Bayesian belief networks is NP-hard. </title> <booktitle> Artificial Intelligence 60: </booktitle> <pages> 141-153. </pages>
Reference-contexts: These bounds together yield interval bounds on the desired probabilities. Although the problem of finding such intervals to predescribed accuracy is NP-hard <ref> (Dagum and Luby, 1993) </ref>, bounds that can be computed efficiently may nevertheless yield intervals that are accurate enough to be useful in practice. fl To appear in Proceedings of the Twelfth Conference on Uncertainty in AI.
Reference: <author> B. </author> <month> D'Ambrosio </month> <year> (1994). </year> <title> Symbolic probabilistic inference in large BN20 networks. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelli--gence. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> G. Hinton, P. Dayan, B. Frey, and R. </author> <title> Neal (1995). The wake-sleep algorithm for unsupervised neural networks. </title> <booktitle> Science 268: </booktitle> <pages> 1158-1161. </pages>
Reference: <author> D. </author> <title> Heckerman (1989). A tractable inference algorithm for diagnosing multiple diseases. </title> <booktitle> In Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> T. Jaakkola, L. Saul, and M. </author> <title> Jordan (1996). Fast learning by bounding likelihoods in sigmoid-type belief networks. </title> <booktitle> To appear in Advances of Neural Information Processing Systems 8. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: They can define interval bounds for the marginals and can be used to improve the accuracy of decision making in intractable networks. Toward extending the work presented in this paper we note that both the upper and lower bounds can be improved by considering a mixture partitioning <ref> (Jaakkola & Jordan, 1996) </ref> of the space of marginalized variables instead of using a completely factorized approximation. Furthermore, the restriction of the upper bounds for two-level networks can be overcome, for example, by interlacing them with sampling techniques, although other extensions may be possible as well.
Reference: <author> T. Jaakkola and M. </author> <title> Jordan (1996). Mixture model approximations for belief networks. </title> <note> Manuscript in preparation. </note>
Reference-contexts: They can define interval bounds for the marginals and can be used to improve the accuracy of decision making in intractable networks. Toward extending the work presented in this paper we note that both the upper and lower bounds can be improved by considering a mixture partitioning <ref> (Jaakkola & Jordan, 1996) </ref> of the space of marginalized variables instead of using a completely factorized approximation. Furthermore, the restriction of the upper bounds for two-level networks can be overcome, for example, by interlacing them with sampling techniques, although other extensions may be possible as well.
Reference: <author> F. V. Jensen, S. L. Lauritzen, and K. G. </author> <month> Olesen </month> <year> (1990). </year> <title> Bayesian updating in causal probabilistic networks by local computations. </title> <journal> Computational Statistics Quarterly 4: </journal> <pages> 269-282. </pages>
Reference: <author> S. L. Lauritzen and D. J. </author> <month> Spiegelhalter </month> <year> (1988). </year> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Roy. Statist. Soc. </journal> <volume> B 50 </volume> <pages> 154-227. </pages>
Reference-contexts: Numerical specification of these dependencies in the form of potentials or probability tables enables quantitative computation of beliefs about the values of the variables on the basis of acquired evidence. The computations involved, i.e., propagation of beliefs, can be handled by now standard exact methods <ref> (Lauritzen & Spiegelhal-ter, 1988, Jensen et al. 1990) </ref>. Junction trees serve as representational platforms for these exact probabilistic calculations and are constructed from directed graphical representations via moralization and triangulation.
Reference: <author> P. McCullagh & J. A. </author> <title> Nelder (1983). Generalized linear models. </title> <publisher> London: Chapman and Hall. </publisher>
Reference-contexts: The parameters specifying these conditional probabilities are the real valued "weights" ij . We note that the choice of this dependency model is not arbitrary but is rooted in logistic regression in statistics <ref> (McCullagh & Nelder, 1983) </ref>. Furthermore, this form of dependency corresponds to the assumption that the odds from each parent of a node combine multiplicatively; the weights ij in this interpretation bear a relation to log-odds.
Reference: <author> R. Neal. </author> <title> Connectionist learning of belief networks (1992). </title> <booktitle> Artificial Intelligence 56: </booktitle> <pages> 71-113. </pages>
Reference-contexts: Large clique sizes (arising from dense connectivity) lead not only to long execution times but also involve exponentially many parameters that must be assessed or learned. The latter issue is generally addressed via parsimonious representations such as the logistic sigmoid <ref> (Neal, 1992) </ref> or the noisy-OR function (Pearl, 1988). We consider both of these representations in the current paper. We stay within a directed framework and thereby retain the compactness of these representations throughout our inference and estimation algorithms.
Reference: <author> J. </author> <title> Pearl (1988). Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann: </publisher> <address> San Mateo. </address>
Reference-contexts: 1 INTRODUCTION A graphical model provides an explicit representation of qualitative dependencies among the variables associated with the nodes of the graph <ref> (Pearl, 1988) </ref>. Numerical specification of these dependencies in the form of potentials or probability tables enables quantitative computation of beliefs about the values of the variables on the basis of acquired evidence. <p> Large clique sizes (arising from dense connectivity) lead not only to long execution times but also involve exponentially many parameters that must be assessed or learned. The latter issue is generally addressed via parsimonious representations such as the logistic sigmoid (Neal, 1992) or the noisy-OR function <ref> (Pearl, 1988) </ref>. We consider both of these representations in the current paper. We stay within a directed framework and thereby retain the compactness of these representations throughout our inference and estimation algorithms. Saul et al. (1996) derived a rigorous lower bound for sigmoid belief networks.
Reference: <author> L. K. Saul, T. Jaakkola, and M. I. </author> <title> Jordan (1996). Mean field theory for sigmoid belief networks. </title> <type> JAIR 4: </type> <pages> 61-76. </pages>
Reference: <author> L. Saul and M. </author> <title> Jordan (1996). Exploiting tractable substructures in intractable networks. </title> <booktitle> To appear in Advances of Neural Information Processing Systems 8. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> M. A. Shwe, B. Middleton, D. E. Heckerman, M. Hen-rion, E. J. Horvitz. H. P. Lehmann, G. F. </author> <title> Cooper (1991). Probabilistic diagnosis using a reformulation of the INTERNIST-1/QMR knowledge base. </title> <journal> Meth. Inform. Med. </journal> <volume> 30: </volume> <pages> 241-255. </pages>
Reference-contexts: While the lower bounds we obtain are applicable to generic network structures, the upper bounds are currently restricted to two-level networks. Although a serious restriction, there are nonetheless many potential applications for such upper bounds, including the probabilistic reformulation of the QMR knowledge base <ref> (Shwe et al., 1991) </ref>. We emphasize finally that our focus in this paper is on techniques of bounding rather than on all-encompassing inference algorithms; tailoring the bounds for specific problems or merging them with exact methods may yield a considerable advantage. The paper is structured as follows.
References-found: 15

