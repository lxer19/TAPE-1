URL: http://www.cs.duke.edu/~majercik/AAAI98.ps
Refering-URL: http://www.cs.duke.edu/~majercik/HomePage.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fmajercik,mlittmang@cs.duke.edu  
Title: Using Caching to Solve Larger Probabilistic Planning Problems  
Author: Stephen M. Majercik and Michael L. Littman 
Address: Durham, NC 27708-0129  
Affiliation: Department of Computer Science Duke University  
Abstract: Probabilistic planning algorithms seek effective plans for large, stochastic domains. maxplan is a recently developed algorithm that converts a planning problem into an E-Majsat problem, an NP PP -complete problem that is essentially a probabilistic version of Sat, and draws on techniques from Boolean satisfiabil-ity and dynamic programming to solve the E-Majsat problem. This solution method is able to solve planning problems at state-of-the-art speeds, but it depends on the ability to store a value for each CNF subformula encountered in the solution process and is therefore quite memory intensive; searching for moderate-size plans even on simple problems can exhaust memory. This paper presents two techniques, based on caching, that overcome this problem without significant performance degradation. The first technique uses an LRU cache to store a fixed number of subformula values. The second technique uses a heuristic based on a measure of subformula difficulty to selectively save the values of only those subformulas whose values are sufficiently difficult to compute and are likely to be reused later in the solution process. We report results for both techniques on a stochastic test problem. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Kautz, H., and Selman, B. </author> <year> 1996. </year> <title> Pushing the envelope: Planning, propositional logic, and stochastic search. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> 1194-1201. </pages> <publisher> AAAI Press/The MIT Press. </publisher>
Reference-contexts: Littman, Goldsmith, & Mund-henk (1998) provide a survey of relevant results. Membership in this complexity class suggests a solution strategy analogous to that of satplan <ref> (Kautz & Sel-man 1996) </ref>, a successful deterministic planner that converts a planning problem into a satisfiability (Sat) problem and solves the Sat problem instead. <p> The first two conditions are not probabilistic and can be encoded in a straightforward manner <ref> (Kautz & Selman 1996) </ref>, but the third condition is complicated by the fact that chance variables sometimes intervene between actions and their effects on propositions. The conversion process is detailed elsewhere (Ma-jercik & Littman 1998); here we summarize some key facts.
Reference: <author> Kautz, H., and Selman, B. </author> <year> 1998. </year> <title> The role of domain-specific knowledge in the planning as satisfiability framework. </title> <booktitle> To appear in Proceedings of the Fourth International Conference on Artificial Intelligence Planning. </booktitle>
Reference: <author> Kushmerick, N.; Hanks, S.; and Weld, D. S. </author> <year> 1995. </year> <title> An algorithm for probabilistic planning. </title> <journal> Artificial Intelligence 76(1-2):239-286. </journal>
Reference-contexts: This plan succeeds with near certainty (probability 0.9669) and maxplan finds it in approximately 8 seconds on a Sun Ultra-1 Model 140 with 128 Mbytes of memory. COMPARISONS We compared maxplan to three other planning techniques (Majercik & Littman 1998): * buridan <ref> (Kushmerick, Hanks, & Weld 1995) </ref>, a classical AI planning technique that extends partial-order planning to probabilistic domains, * Plan enumeration with dynamic programming for plan evaluation (enum), and * Dynamic programming (incremental pruning) to solve the corresponding finite-horizon partially ob servable mdp (pomdp).
Reference: <author> Littman, M. L.; Goldsmith, J.; and Mundhenk, M. </author> <year> 1998. </year> <title> The computational complexity of probabilistic plan existence and evaluation. </title> <note> Submitted. </note>
Reference-contexts: In a propositional planning domain, states are specified as assignments to a set of propositional variables. If we place reasonable bounds|polynomial in the size of the planning problem|on both plan size and plan horizon, the planning problem is NP PP - complete <ref> (Littman, Goldsmith, & Mundhenk 1998) </ref> (perhaps easier than PSPACE-complete) and may be amenable to heuristics. Littman, Goldsmith, & Mund-henk (1998) provide a survey of relevant results. <p> In the same way that deterministic planning can be expressed as the NP-complete problem Sat, probabilistic plan ning can be expressed as the NP PP -complete problem E-Majsat <ref> (Littman, Goldsmith, & Mundhenk 1998) </ref>: Given a Boolean formula with choice variables (variables whose truth status can be arbitrarily set) and chance variables (variables whose truth status is determined by a set of independent probabilities), find the setting of the choice variables that maximizes the probability of a satisfying assign ment <p> The first two conditions are not probabilistic and can be encoded in a straightforward manner (Kautz & Selman 1996), but the third condition is complicated by the fact that chance variables sometimes intervene between actions and their effects on propositions. The conversion process is detailed elsewhere <ref> (Ma-jercik & Littman 1998) </ref>; here we summarize some key facts. The total number of variables in the formula is V = (A+P +R)N +P , where A, P , and R are the number of actions, propositions, and random propositions, respectively. <p> In general, a brute-force computation of a CNF subfor-mula value is not feasible. To prune the number of assignments that must be considered, full DPLL uses several variable selection heuristics <ref> (Majercik & Littman 1998) </ref>. Our modified DPLL uses only one of these; we select, whenever possible, a variable that appears alone in an active clause and assign the appropriate value (unit propagation, UNIT). <p> If we split on a choice (chance) variable, we return the maximum (probability weighted average) of assigning True to the variable and recurring or assigning False and recurring. The splitting heuristic used is critical to the algorithm's efficiency; experiments <ref> (Majercik & Littman 1998) </ref> indicate that splitting on the variable that would appear earliest in the plan|time-ordered splitting (TIME)|is a very successful heuristic. The solver still scaled exponentially with plan horizon, however, even on some simple plan-evaluation computations. <p> This greatly extends the size of the plan we can feasibly evaluate <ref> (Majercik & Littman 1998) </ref>. We tested modified DPLL (UNIT/TIME) on the full plan-generation problem in Sand-Castle-67 for plan horizons ranging from 1 to 10. <p> The optimal 10-step plan is D-E-D-E-E-D-E-D-E-E (D = dig-moat, E = erect-castle). This plan succeeds with near certainty (probability 0.9669) and maxplan finds it in approximately 8 seconds on a Sun Ultra-1 Model 140 with 128 Mbytes of memory. COMPARISONS We compared maxplan to three other planning techniques <ref> (Majercik & Littman 1998) </ref>: * buridan (Kushmerick, Hanks, & Weld 1995), a classical AI planning technique that extends partial-order planning to probabilistic domains, * Plan enumeration with dynamic programming for plan evaluation (enum), and * Dynamic programming (incremental pruning) to solve the corresponding finite-horizon partially ob servable mdp (pomdp). <p> We also compared the scaling behavior of maxplan to that of enum and pomdp on two problems: Sand-Castle-67 and Disarming-Multiple-Bombs <ref> (Ma-jercik & Littman 1998) </ref>. maxplan scales exponentially (O (2:24 N )) as the horizon increases in Sand-Castle-67. enum, as expected, also scales exponentially (O (2:05 N )). But pomdp, remarkably, scales linearly as the horizon increases. <p> Finally, the current planner assumes complete unob-servability and produces an optimal straight-line plan; a practical planner must be able to represent and reason about conditional plans, which can take advantage of circumstances as they evolve, and looping plans, which can express repeated actions compactly <ref> (Littman, Goldsmith, & Mundhenk 1998) </ref>. CONCLUSIONS We have described an approach to probabilistic planning that converts the planning problem to an equivalent E-Majsat problem|a type of Boolean satisfi-ability problem|and then solves that problem.
Reference: <author> Littman, M. L. </author> <year> 1997. </year> <title> Probabilistic propositional planning: Representations and complexity. </title> <booktitle> In Proceedings of the Fourteenth National Conference on Artificial Intelligence, </booktitle> <pages> 748-754. </pages> <publisher> AAAI Press/The MIT Press. </publisher>
Reference-contexts: In this work, we assume a completely unobservable domain|the effects of previous actions cannot be used in selecting the current action; thus, optimal plans are sequences of actions. maxplan represents planning domains in the sequential-effects-tree (st) representation <ref> (Littman 1997) </ref>. For each action, there is an ordered set of decision trees, one for each proposition, describing how the propositions change as a function of the state and action, perhaps probabilistically. A formal description of st is available (Littman 1997); a brief example follows. <p> of actions. maxplan represents planning domains in the sequential-effects-tree (st) representation <ref> (Littman 1997) </ref>. For each action, there is an ordered set of decision trees, one for each proposition, describing how the propositions change as a function of the state and action, perhaps probabilistically. A formal description of st is available (Littman 1997); a brief example follows. Sand-Castle-67 is a simple probabilistic planning domain concerned with building a sand castle at the beach (Figure 1). The domain has four states, described by combinations of two Boolean propositions, moat and castle (propositions appear in boldface).
Reference: <author> Majercik, S. M., and Littman, M. L. </author> <year> 1998. </year> <title> MAX-PLAN: A new approach to probabilistic planning. </title> <booktitle> To appear in Proceedings of the Fourth International Conference on Artificial Intelligence Planning. </booktitle>
Reference-contexts: In general, a brute-force computation of a CNF subfor-mula value is not feasible. To prune the number of assignments that must be considered, full DPLL uses several variable selection heuristics <ref> (Majercik & Littman 1998) </ref>. Our modified DPLL uses only one of these; we select, whenever possible, a variable that appears alone in an active clause and assign the appropriate value (unit propagation, UNIT). <p> If we split on a choice (chance) variable, we return the maximum (probability weighted average) of assigning True to the variable and recurring or assigning False and recurring. The splitting heuristic used is critical to the algorithm's efficiency; experiments <ref> (Majercik & Littman 1998) </ref> indicate that splitting on the variable that would appear earliest in the plan|time-ordered splitting (TIME)|is a very successful heuristic. The solver still scaled exponentially with plan horizon, however, even on some simple plan-evaluation computations. <p> This greatly extends the size of the plan we can feasibly evaluate <ref> (Majercik & Littman 1998) </ref>. We tested modified DPLL (UNIT/TIME) on the full plan-generation problem in Sand-Castle-67 for plan horizons ranging from 1 to 10. <p> The optimal 10-step plan is D-E-D-E-E-D-E-D-E-E (D = dig-moat, E = erect-castle). This plan succeeds with near certainty (probability 0.9669) and maxplan finds it in approximately 8 seconds on a Sun Ultra-1 Model 140 with 128 Mbytes of memory. COMPARISONS We compared maxplan to three other planning techniques <ref> (Majercik & Littman 1998) </ref>: * buridan (Kushmerick, Hanks, & Weld 1995), a classical AI planning technique that extends partial-order planning to probabilistic domains, * Plan enumeration with dynamic programming for plan evaluation (enum), and * Dynamic programming (incremental pruning) to solve the corresponding finite-horizon partially ob servable mdp (pomdp).
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: There are other important comparisons that should be made; belief networks and influence diagrams <ref> (Pearl 1988) </ref> are closely related to our work and there are efficient techniques for evaluating them, but their performance relative to maxplan is unknown. Table 1 summarizes the performance of maxplan on two probabilistic planning problems described by Kush-merick, Hanks, & Weld (1995).
References-found: 7

