URL: http://www.wi.leidenuniv.nl/home/joost/chapter6.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/home/joost/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Feature selection through Functional Links with Evolutionary Computation for Neural Networks  
Author: S. Haring J.N. Kok M.C. van Wezel 
Address: Netherlands  
Affiliation: Department of Computer Science Leiden University, The  
Abstract: In this paper we describe different ways to select and transform features using evolutionary computation. The features are intended to serve as inputs to a feedforward network. The first way is the selection of features using a standard genetic algorithm, and the solution found specifies whether a certain feature should be present or not. We show that for the prediction of unemployment rates in various European countries, this is a succesfull approach. In fact, this kind of selection of features is a special case of so-called functional links. Functional links transform the input pattern space to a new pattern space. As functional links one can use polynomials, or more general functions. Both can be found using evolutionary computation. Polynomial functional links are found by evolving a coding of the powers of the polynomial. For symbolic functions we can use genetic programming. Genetic programming finds the symbolic functions that are to be applied to the inputs. We compare the workings of the latter two methods on two artificial datasets, and on a real-world medical image dataset.
Abstract-found: 1
Intro-found: 1
Reference: [BOSvW94] <author> B. Back, G. Oosterom, K. Sere, and M. van Wezel. </author> <title> A comparative study of neural networks in bankruptcy prediction. </title> <booktitle> In Proceedings of the 10th Conference on Artificial Intelligence Research in Finland, </booktitle> <address> Turku, Finland, </address> <year> 1994, </year> <pages> pages 140-148. </pages> <booktitle> Finnish Artificial Intelligence Society, </booktitle> <year> 1994. </year>
Reference-contexts: We obtain a significant decrease in error levels. Also other applications have shown the potential of this method (see for example <ref> [BSvW95, BOSvW94] </ref>). Then we considered two artificial pattern classification problems. For both problems we know the optimal functional links; it is our goal to investigate whether an evolutionary algorithm can find these functional links. We also investigate whether one of both coding schemes is to be preferred over the other.
Reference: [Bra95] <author> J. Branke. </author> <title> Evolutionary algorithms for neural network design and training. </title> <booktitle> In Proceedings of the First Nordic Workshop on Genetic Algorithms and its Applications, </booktitle> <year> 1995. </year>
Reference-contexts: EC is especially suited for that kind of optimization problems. Many combinations of neural networks and evolutionary computation can be found in the literature; an extensive overview is given in <ref> [Bra95] </ref>. Evolutionary computation has two major applications for neural networks: (i) it has been used as an alternative to learning rules like back-propagation to find appropriate connection weights [MD89, TSVdM93, YHLK94]; (ii) evolutionary computation has been used to determine good network connection schemes [MTH89, Kit90, Man93].
Reference: [BSvW95] <author> B. Back, K. Sere, and M. van Wezel. </author> <title> Bankruptcy prediction (choosing the best set of bankruptcy predictors. </title> <booktitle> In Proceedings of the Nordic Workshop on Genetic Algorithms, </booktitle> <address> Waasa University, Finland, </address> <year> 1995, </year> <pages> pages 295-299, </pages> <year> 1995. </year>
Reference-contexts: We obtain a significant decrease in error levels. Also other applications have shown the potential of this method (see for example <ref> [BSvW95, BOSvW94] </ref>). Then we considered two artificial pattern classification problems. For both problems we know the optimal functional links; it is our goal to investigate whether an evolutionary algorithm can find these functional links. We also investigate whether one of both coding schemes is to be preferred over the other.
Reference: [CL91] <author> Eric I. Chang and Richard P. Lipmann. </author> <title> Using genetic algorithms to improve pattern classification performance. </title> <booktitle> In Advances in Neural 9 Information Processing Systems, </booktitle> <volume> volume 3, </volume> <pages> pages 797-803. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: This is not an easy task because the number of possible feature subsets grows exponentially with the available number of features. Using the functional link with binary encoding, we hope to arrive at a near-optimal feature subset. This method was originally proposed in <ref> [CL91] </ref>. Next we discuss the so-called polynomial encoding. A functional link has as input a pattern x = (x 1 ; : : : ; x D ), and as output a scalar.
Reference: [Hol75] <author> J.H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The University of Michican Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Evolutionary computation (EC) is the generic term for a number algorithms that are based on an evolutionary concept, examples are genetic algorithms <ref> [Hol75] </ref> and genetic programming [Koz92]. EC is based on a set of potential solutions; in our application a solution is a configuration of functional links. In the evolutionary process repeatedly candidate solutions are recombined to new candidates to seek for good solutions.
Reference: [HVK94] <author> S. Haring, M.A. Viergever, and J.N. Kok. </author> <title> Kohonen networks for mul-tiscale image segmentation. </title> <journal> Image and Vision Computing, </journal> <volume> 6(12) </volume> <pages> 339-344, </pages> <year> 1994. </year>
Reference-contexts: Classification results on the test image for both encoding schemes are presented in Figure 8. With symbolic encoding we achieve surprisingly good results, which are competitive to results that we obtained in <ref> [HVK94] </ref>.
Reference: [Kit90] <author> H. Kitano. </author> <title> Designing neural networks using genetic algortithms with graph generation. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 461-476, </pages> <year> 1990. </year>
Reference-contexts: Evolutionary computation has two major applications for neural networks: (i) it has been used as an alternative to learning rules like back-propagation to find appropriate connection weights [MD89, TSVdM93, YHLK94]; (ii) evolutionary computation has been used to determine good network connection schemes <ref> [MTH89, Kit90, Man93] </ref>. There are also studies that have a closer relation to our approach. Examples are the studies of [KS91] and [Rog91]. Both papers concern evolutionary algorithms to search for functions to be used for input transformation.
Reference: [Koz92] <editor> J. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> mit Press, </publisher> <year> 1992. </year>
Reference-contexts: Evolutionary computation (EC) is the generic term for a number algorithms that are based on an evolutionary concept, examples are genetic algorithms [Hol75] and genetic programming <ref> [Koz92] </ref>. EC is based on a set of potential solutions; in our application a solution is a configuration of functional links. In the evolutionary process repeatedly candidate solutions are recombined to new candidates to seek for good solutions. <p> Hence, as a string represents a transformation of a pattern space, the dimension of the transformed pattern spaces is equal for all strings. Next we come to the symbolic encoding. The concept of genetic programming was introduced by <ref> [Koz92] </ref>. In genetic programming each string in the population is a symbolic expression, which can be seen as a tree built of a number of basic functions. In this manner it is possible to represent complex programs by a single string.
Reference: [KS91] <author> H. Kargupta and R.E. Smith. </author> <title> System identification with evolving polynomial networks. </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 370-376. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: There are also studies that have a closer relation to our approach. Examples are the studies of <ref> [KS91] </ref> and [Rog91]. Both papers concern evolutionary algorithms to search for functions to be used for input transformation. However, different basic functions, and different networks are used in in these studies.
Reference: [Man93] <author> M. Mandischer. </author> <title> Representation and evolution of neural networks. </title> <booktitle> In Proceedings of the Conference on Artificial Neural Networks and Genetic Algorithms, </booktitle> <pages> pages 643-649, </pages> <address> Heidelberg, 1993. </address> <publisher> Springer. </publisher>
Reference-contexts: Evolutionary computation has two major applications for neural networks: (i) it has been used as an alternative to learning rules like back-propagation to find appropriate connection weights [MD89, TSVdM93, YHLK94]; (ii) evolutionary computation has been used to determine good network connection schemes <ref> [MTH89, Kit90, Man93] </ref>. There are also studies that have a closer relation to our approach. Examples are the studies of [KS91] and [Rog91]. Both papers concern evolutionary algorithms to search for functions to be used for input transformation.
Reference: [MD89] <author> D.J. Montana and L. Davis. </author> <title> Training feedfoward networks using genetic algorithms. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 762-767, </pages> <year> 1989. </year>
Reference-contexts: Many combinations of neural networks and evolutionary computation can be found in the literature; an extensive overview is given in [Bra95]. Evolutionary computation has two major applications for neural networks: (i) it has been used as an alternative to learning rules like back-propagation to find appropriate connection weights <ref> [MD89, TSVdM93, YHLK94] </ref>; (ii) evolutionary computation has been used to determine good network connection schemes [MTH89, Kit90, Man93]. There are also studies that have a closer relation to our approach. Examples are the studies of [KS91] and [Rog91].
Reference: [MTH89] <author> G.F. Miller, P.M. Todd, and S.U. Hegde. </author> <title> Designing neural networks using genetic algorithms. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 379-384. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Evolutionary computation has two major applications for neural networks: (i) it has been used as an alternative to learning rules like back-propagation to find appropriate connection weights [MD89, TSVdM93, YHLK94]; (ii) evolutionary computation has been used to determine good network connection schemes <ref> [MTH89, Kit90, Man93] </ref>. There are also studies that have a closer relation to our approach. Examples are the studies of [KS91] and [Rog91]. Both papers concern evolutionary algorithms to search for functions to be used for input transformation.
Reference: [Pao89] <author> Y. Pao. </author> <title> Adaptive Pattern Recognition and Neural Networks. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: In section 3 results of our methods are given on artificial and real data, and section 4 gives a short discussion. 2 Functional Links To increase the capabilities of networks so-called functional links can be added <ref> [Pao89] </ref>. With functional links the input pattern space is transformed to a new pattern space.
Reference: [PS56] <author> T. Parsons and N.J. Smelser. </author> <title> Study in the Integration of Economic and Social Theory. </title> <publisher> Routledge and Keganpaul ltd., </publisher> <year> 1956. </year>
Reference-contexts: A multilayer perceptron neural network is better suited for this task than linear methods because there is theoretical reason to believe that there exist non-linear relationships between various input features we used and the unemployment rate <ref> [PS56, vWH95] </ref>. The task of the GA was to select the most indicative subset of 11 possible input features. 4 error of the best string in the population, whereas the upper line represents the error of the average network in the population.
Reference: [Rog91] <author> D. Rogers. G/SPLINES: </author> <title> A hybrid of friedman's multivariate adaptive regression splines (MARS) algorithm with Holland's genetic algorithm. </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 384-391. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: There are also studies that have a closer relation to our approach. Examples are the studies of [KS91] and <ref> [Rog91] </ref>. Both papers concern evolutionary algorithms to search for functions to be used for input transformation. However, different basic functions, and different networks are used in in these studies.
Reference: [TSVdM93] <author> D. Thierens, J. Suykens, J. Vandewalle, and B. de Moor. </author> <title> Genetic weight optimization of a feedforward network controller. </title> <booktitle> In Proceedings of the Conference on Artificial Neural Networks and Genetic Algorithms, </booktitle> <pages> pages 658-663, </pages> <address> Heidelberg, 1993. </address> <publisher> Springer. </publisher>
Reference-contexts: Many combinations of neural networks and evolutionary computation can be found in the literature; an extensive overview is given in [Bra95]. Evolutionary computation has two major applications for neural networks: (i) it has been used as an alternative to learning rules like back-propagation to find appropriate connection weights <ref> [MD89, TSVdM93, YHLK94] </ref>; (ii) evolutionary computation has been used to determine good network connection schemes [MTH89, Kit90, Man93]. There are also studies that have a closer relation to our approach. Examples are the studies of [KS91] and [Rog91].
Reference: [vWH95] <editor> J.A.M. van Wezel and M. Havekes. Economie en Samenleving: een internationaal vergelijk van het arbeidsbestel (in Dutch). </editor> <publisher> Lemma publishers BV, </publisher> <year> 1995. </year>
Reference-contexts: A multilayer perceptron neural network is better suited for this task than linear methods because there is theoretical reason to believe that there exist non-linear relationships between various input features we used and the unemployment rate <ref> [PS56, vWH95] </ref>. The task of the GA was to select the most indicative subset of 11 possible input features. 4 error of the best string in the population, whereas the upper line represents the error of the average network in the population.
Reference: [YHLK94] <author> B. Yoon, D.J. Holmes, G. Langholz, and A. Kandel. </author> <title> Efficient genetic algorithms for training layered feedforward networks. </title> <journal> Information Sciences, </journal> <volume> 76 </volume> <pages> 67-85, </pages> <year> 1994. </year> <month> 10 </month>
Reference-contexts: Many combinations of neural networks and evolutionary computation can be found in the literature; an extensive overview is given in [Bra95]. Evolutionary computation has two major applications for neural networks: (i) it has been used as an alternative to learning rules like back-propagation to find appropriate connection weights <ref> [MD89, TSVdM93, YHLK94] </ref>; (ii) evolutionary computation has been used to determine good network connection schemes [MTH89, Kit90, Man93]. There are also studies that have a closer relation to our approach. Examples are the studies of [KS91] and [Rog91].
References-found: 18

