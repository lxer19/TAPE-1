URL: http://www.cs.unc.edu/~anderson/papers/rtdb97.ps.Z
Refering-URL: http://www.cs.unc.edu/~anderson/papers.html
Root-URL: http://www.cs.unc.edu
Title: Implementing Hard Real-Time Transactions on Multiprocessors  
Author: James H. Anderson, Rohit Jain, and Srikanth Ramamurthy 
Address: Chapel Hill  
Affiliation: Department of Computer Science, University of North Carolina at  
Abstract: We present a new approach to implementing real-time transactions on memory-resident data on shared-memory multiprocessors. This approach allows hard deadlines to be supported without undue overhead. In our approach, transactions are implemented by invoking wait-free library routines. Concurrency control is embedded within these routines, so no special support for data management is required of the kernel or from underlying server processes. These routines reduce the overhead involved in executing transactions by exploiting the way transactions are interleaved on priority-based real-time systems. We present evidence that shows that our approach often entails substantially less overhead than more conventional priority inheritance schemes.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 184-193. </pages>
Reference-contexts: These routines reduce the overhead involved in executing transactions by exploiting the way transactions are interleaved on priority-based real-time systems. As a result, they perform much better than previous implementations of wait-free transactions proposed for asynchronous systems <ref> [1] </ref>. Since transactions in our implementation are executed in a wait-free manner, they are not susceptible to deadlock or priority inversion, and schedulability can be checked using scheduling conditions for independent tasks. <p> If a task experiences repeated interferences, then its operation is eventually completed by another task. Care must be taken to ensure that each operation is executed at most once, and that a helped task can retrieve its return values from memory. With most helping implementations that have been proposed <ref> [1, 2, 9] </ref>, performance is at least linear in the number of tasks sharing an object. In a recent paper [4], we showed that the cost of helping can be greatly reduced on priority-based real-time uniprocessor systems by using a technique called incremental helping . <p> Before a task is allowed to do this, however, it must first help any previously announced transaction (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per task <ref> [1, 2, 9] </ref>. In addition, with incremental helping, each task helps at most one other task, while in helping schemes for asynchronous systems, each task helps all other tasks in the worst case. <p> Thus, instead of writing "MEM <ref> [1] </ref> := MEM [10]", the programmer would write "Write (1; Read (10))". Figure 6 shows a simple example transaction, which enqueues an item onto a shared queue. This transaction would be executed by calling Exec (Enqueue ). <p> For example, in real-time systems, each task must complete execution by a specified deadline. Unless deadlines are unrealistically large, it would be impossible for a 32- or 64-bit counter to cycle during the execution of one task. 12 implementing CAS2 from simpler primitives are known <ref> [1, 5, 10] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [8], but no current machines support this implementation.
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> Proceedings of the Ninth International Workshop on Distributed Algorithms, Lecture Notes in Computer Science 972, </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1995, </year> <pages> pp. 168-182. </pages>
Reference-contexts: If a task experiences repeated interferences, then its operation is eventually completed by another task. Care must be taken to ensure that each operation is executed at most once, and that a helped task can retrieve its return values from memory. With most helping implementations that have been proposed <ref> [1, 2, 9] </ref>, performance is at least linear in the number of tasks sharing an object. In a recent paper [4], we showed that the cost of helping can be greatly reduced on priority-based real-time uniprocessor systems by using a technique called incremental helping . <p> Before a task is allowed to do this, however, it must first help any previously announced transaction (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per task <ref> [1, 2, 9] </ref>. In addition, with incremental helping, each task helps at most one other task, while in helping schemes for asynchronous systems, each task helps all other tasks in the worst case. <p> With wait-free algorithms, worst-case execution times are easily computed. The only other means of implementing wait-free linked lists that we know of is to use universal constructions <ref> [2, 9] </ref>. Although we did not test against such constructions, they entail very high helping overhead. As a result, they would likely perform much worse than our list implementation.
Reference: [3] <author> J. Anderson, S. Ramamurthy, M. Moir, and K. Jeffay, </author> <title> "Lock-Free Transactions for Real-Time Systems", </title> <booktitle> Proceedings of the First International Workshop on Real-Time Databases: Issues and Applications, </booktitle> <month> March </month> <year> 1996, </year> <pages> pp. 107-114. </pages> <note> Expanded version to appear in Real-Time Database Systems: </note> <editor> Issues and Applications, </editor> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: On uniprocessors, the number of transaction restarts over an interval of time can be bounded (assuming memory-resident data) <ref> [3] </ref>, and thus hard-deadline transactions can be supported. However, bounding the effects of repeated restarts due to conflicts across processors in a multiprocessor system does not seem practical. When using lock-based concurrency control schemes on multiprocessors, mechanisms are needed to bound the effects of priority inversion. <p> The implementation is based on a lock-free transaction implementation for real-time uniprocessors presented previously in <ref> [3] </ref>. This previous implementation has been modified for application on shared-memory multiprocessors by using a cyclic helping scheme. Our implementation is defined by four procedures, Exec, Help, Read, and Write, which are given in Figure 5. Variable declarations that are used in these procedures are given in Figure 4.
Reference: [4] <author> J. Anderson, S. Ramamurthy, and R. </author> <title> Jain "Implementing Wait-Free Objects on Priority-Based Systems", </title> <type> manuscript, </type> <month> January </month> <year> 1997. </year>
Reference-contexts: With most helping implementations that have been proposed [1, 2, 9], performance is at least linear in the number of tasks sharing an object. In a recent paper <ref> [4] </ref>, we showed that the cost of helping can be greatly reduced on priority-based real-time uniprocessor systems by using a technique called incremental helping . The general idea of incremental helping is illustrated in Figure 2. <p> Despite our current limitations in conducting definitive performance studies, we have conducted a preliminary study to evaluate the effectiveness of cyclic helping. In this study, a wait-free linked-list implementation based on cyclic helping presented by us elsewhere <ref> [4] </ref> was compared with a lock-free list implementation presented recently by Greenwald and Cheriton [8]. These experiments were performed on a five-processor SGI-R10000 machine. The priority-based preemption model was simulated at the user level.
Reference: [5] <author> H. Attiya and E. Dagan, </author> <title> "Universal Operations: Unary versus Binary", </title> <booktitle> Proceedings of the 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1996, </year> <pages> pp. 223-232. </pages>
Reference-contexts: For example, in real-time systems, each task must complete execution by a specified deadline. Unless deadlines are unrealistically large, it would be impossible for a 32- or 64-bit counter to cycle during the execution of one task. 12 implementing CAS2 from simpler primitives are known <ref> [1, 5, 10] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [8], but no current machines support this implementation.
Reference: [6] <author> B. Bershad, </author> <title> "Practical Considerations for Non-Blocking Concurrent Objects", </title> <booktitle> Proceedings of the 13th international Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. pages 264-274. </pages>
Reference-contexts: An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [8], but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad <ref> [6] </ref>, but this approach can be problematic to actually implement (see [8] for details). Fortunately, as shown in Section 5, CCAS appears to be much easier to implement than CAS2. If CAS is available, then CCAS can be implemented in just a few instructions.
Reference: [7] <author> R. Bettati, </author> <title> End-to-End Scheduling to Meet Deadlines in Distributed Systems, </title> <type> Ph.D. Thesis, </type> <institution> Computer Science Department, University of Illinois at Urbana-Champaign, </institution> <month> March </month> <year> 1994. </year> <month> 19 </month>
Reference-contexts: This is certainly due to the fact that these schemes give rise to such large blocking overheads. Researchers at the University of Illinois have proposed an "end-to-end" approach for sharing resources in multiprocessors, in which tasks are converted into a sequence of periodic subtasks using heuristics <ref> [7, 17] </ref>. Each subtask can perform either local computation or a single-processor transaction. Heuristics are used to deduce appropriate release times and deadlines for the subtasks of a task based on the timing requirements of that task. Subtasks are scheduled on a per-processor basis, using uniprocessor scheduling schemes.
Reference: [8] <author> M. Greenwald and D. Cheriton, </author> <title> "The Synergy Between Non-blocking Synchronization and Operating Sys--tem Structure", </title> <booktitle> Proceedings of the USENIX Association Second Symposium on Operating Systems Design and Implementation, </booktitle> <year> 1996, </year> <pages> pp. 123-136 </pages>
Reference-contexts: An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton <ref> [8] </ref>, but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad [6], but this approach can be problematic to actually implement (see [8] for details). Fortunately, as shown in Section 5, CCAS appears to be much easier to implement than CAS2. <p> An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton <ref> [8] </ref>, but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad [6], but this approach can be problematic to actually implement (see [8] for details). Fortunately, as shown in Section 5, CCAS appears to be much easier to implement than CAS2. If CAS is available, then CCAS can be implemented in just a few instructions. <p> In this study, a wait-free linked-list implementation based on cyclic helping presented by us elsewhere [4] was compared with a lock-free list implementation presented recently by Greenwald and Cheriton <ref> [8] </ref>. These experiments were performed on a five-processor SGI-R10000 machine. The priority-based preemption model was simulated at the user level. <p> Another lock-free list implementation, which uses only CAS, was recently proposed by Valois [18]. Although we did not test against Valois' algorithm, Greenwald and Cheriton report that their algorithm is faster than his algorithm by a factor of about three under low contention, and about ten under high contention <ref> [8] </ref>. Greenwald and Cheriton also reported that their algorithm outperformed a fast spin lock algorithm with backoff. We believe it is highly doubtful that OS-based multiprocessor locking protocols like the MPCP and the DPCP could exhibit performance close to that of either our algorithm or Greenwald and Cheriton's.
Reference: [9] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 5, </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: If a task experiences repeated interferences, then its operation is eventually completed by another task. Care must be taken to ensure that each operation is executed at most once, and that a helped task can retrieve its return values from memory. With most helping implementations that have been proposed <ref> [1, 2, 9] </ref>, performance is at least linear in the number of tasks sharing an object. In a recent paper [4], we showed that the cost of helping can be greatly reduced on priority-based real-time uniprocessor systems by using a technique called incremental helping . <p> Before a task is allowed to do this, however, it must first help any previously announced transaction (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per task <ref> [1, 2, 9] </ref>. In addition, with incremental helping, each task helps at most one other task, while in helping schemes for asynchronous systems, each task helps all other tasks in the worst case. <p> With wait-free algorithms, worst-case execution times are easily computed. The only other means of implementing wait-free linked lists that we know of is to use universal constructions <ref> [2, 9] </ref>. Although we did not test against such constructions, they entail very high helping overhead. As a result, they would likely perform much worse than our list implementation.
Reference: [10] <author> A. Israeli and L. Rappoport, </author> <title> "Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives", </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1994, </year> <pages> pp. 151-160. </pages>
Reference-contexts: Thus, instead of writing "MEM [1] := MEM <ref> [10] </ref>", the programmer would write "Write (1; Read (10))". Figure 6 shows a simple example transaction, which enqueues an item onto a shared queue. This transaction would be executed by calling Exec (Enqueue ). <p> For example, in real-time systems, each task must complete execution by a specified deadline. Unless deadlines are unrealistically large, it would be impossible for a 32- or 64-bit counter to cycle during the execution of one task. 12 implementing CAS2 from simpler primitives are known <ref> [1, 5, 10] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [8], but no current machines support this implementation.
Reference: [11] <author> V. Lortz, </author> <title> An Object-Oriented Real-Time Database System for Multiprocessors, </title> <type> Ph.D. Thesis, </type> <institution> Computer Science Department, University of Michigan, </institution> <year> 1994. </year>
Reference-contexts: Lortz and Shin have implemented a hard real-time database system called MDARTS (Multiprocessor Database Architecture for Real-Time Systems), in which both RPC transactions and concurrent shared-memory-based transactions are supported <ref> [11] </ref>. This was the first (and perhaps only) actual implementation of a hard real-time multiprocessor database server with reasonable performance. However, concurrency control in MDARTS is somewhat limiting.
Reference: [12] <author> R. Rajkumar, </author> <title> "Real-Time Synchronization Protocols for Shared Memory Multiprocessors", </title> <booktitle> Proceedings of the International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1990, </year> <pages> pp. 116-123. </pages>
Reference-contexts: The most well-known solution to this problem in uniprocessors is the priority ceiling protocol (PCP) [15, 16]. To ensure predictability in multiprocessor systems, Rajkumar et al. proposed the distributed PCP (DPCP) and the multiprocessor PCP (MPCP), both of which extend the PCP <ref> [12, 13, 14] </ref>. Both approaches assume a model in which a task can perform one or more transactions. In the DPCP, global resources are guarded by synchronization processors.
Reference: [13] <author> Raghunathan Rajkumar, </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach, </title> <publisher> Kluwer Academic Publications, </publisher> <year> 1991. </year>
Reference-contexts: The most well-known solution to this problem in uniprocessors is the priority ceiling protocol (PCP) [15, 16]. To ensure predictability in multiprocessor systems, Rajkumar et al. proposed the distributed PCP (DPCP) and the multiprocessor PCP (MPCP), both of which extend the PCP <ref> [12, 13, 14] </ref>. Both approaches assume a model in which a task can perform one or more transactions. In the DPCP, global resources are guarded by synchronization processors.
Reference: [14] <author> R. Rajkumar, L. Sha, and J. Lehoczky, </author> <title> "Real-Time Synchronization Protocols for Multiprocessors", </title> <booktitle> Proceedings of the IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1988, </year> <pages> pp. 259-269. </pages>
Reference-contexts: The most well-known solution to this problem in uniprocessors is the priority ceiling protocol (PCP) [15, 16]. To ensure predictability in multiprocessor systems, Rajkumar et al. proposed the distributed PCP (DPCP) and the multiprocessor PCP (MPCP), both of which extend the PCP <ref> [12, 13, 14] </ref>. Both approaches assume a model in which a task can perform one or more transactions. In the DPCP, global resources are guarded by synchronization processors.
Reference: [15] <author> L. Sha, R. Rajkumar, and J. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time System Synchronization", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 39, No. 9, </volume> <month> September </month> <year> 1990, </year> <pages> pp. 1175-1185. </pages>
Reference-contexts: When using lock-based concurrency control schemes on multiprocessors, mechanisms are needed to bound the effects of priority inversion. The most well-known solution to this problem in uniprocessors is the priority ceiling protocol (PCP) <ref> [15, 16] </ref>. To ensure predictability in multiprocessor systems, Rajkumar et al. proposed the distributed PCP (DPCP) and the multiprocessor PCP (MPCP), both of which extend the PCP [12, 13, 14]. Both approaches assume a model in which a task can perform one or more transactions.
Reference: [16] <author> L. Sha, R. Rajkumar, S. Son, and C. Chang, </author> <title> "A Real-Time Locking Protocol", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 40, No. 7, </volume> <year> 1991, </year> <pages> pp. 793-800. </pages>
Reference-contexts: When using lock-based concurrency control schemes on multiprocessors, mechanisms are needed to bound the effects of priority inversion. The most well-known solution to this problem in uniprocessors is the priority ceiling protocol (PCP) <ref> [15, 16] </ref>. To ensure predictability in multiprocessor systems, Rajkumar et al. proposed the distributed PCP (DPCP) and the multiprocessor PCP (MPCP), both of which extend the PCP [12, 13, 14]. Both approaches assume a model in which a task can perform one or more transactions.
Reference: [17] <author> J. Sun, R. Bettati, and J. W.-S. Liu, </author> <title> "Using End-to-End Scheduling Approach to Schedule Tasks with Shared Resources in Multiprocessor Systems", </title> <booktitle> Proceedings of the 11th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: This is certainly due to the fact that these schemes give rise to such large blocking overheads. Researchers at the University of Illinois have proposed an "end-to-end" approach for sharing resources in multiprocessors, in which tasks are converted into a sequence of periodic subtasks using heuristics <ref> [7, 17] </ref>. Each subtask can perform either local computation or a single-processor transaction. Heuristics are used to deduce appropriate release times and deadlines for the subtasks of a task based on the timing requirements of that task. Subtasks are scheduled on a per-processor basis, using uniprocessor scheduling schemes.
Reference: [18] <author> J. Valois, </author> <title> "Lock-Free Linked Lists using Compare-and-Swap", </title> <booktitle> Proceedings of the 14th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 214-222. 20 </pages>
Reference-contexts: Our algorithm also outperforms theirs as the length of the list is increased, although graphs showing this have been omitted due to space limitations. Another lock-free list implementation, which uses only CAS, was recently proposed by Valois <ref> [18] </ref>. Although we did not test against Valois' algorithm, Greenwald and Cheriton report that their algorithm is faster than his algorithm by a factor of about three under low contention, and about ten under high contention [8].
References-found: 18

