URL: ftp://iamftp.unibe.ch/pub/TechReports/1996/iam-96-002.ps.gz
Refering-URL: 
Root-URL: 
Email: email: ackerman,bunke@iam.unibe.ch  
Title: Combination of Classifiers on the Decision Level for Face Recognition  
Author: Bernard Achermann and Horst Bunke 
Date: January 1996  
Address: Bern, Neubruckstrasse 10, CH-3012 Bern  
Affiliation: Institut fur Informatik und angewandte Mathematik Universitat  
Pubnum: IAM-96-002  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Cao, M. Shridhar, and M. Ahmadi. </author> <title> Fusion of Classifiers with Fuzzy Integrals. </title> <booktitle> In Proceedings 3d International Conference on Document Analysis and Recognition, Montreal, Canada, </booktitle> <volume> volume 1, </volume> <pages> pages 108-111. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> August </month> <year> 1995. </year>
Reference: [2] <author> B.V. Dasarathy. </author> <title> Decision Fusion. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: Good textbooks covering the important topics of sensor fusion are those by Waltz and Llinas [19], and Hall [5]. An extended bibliography and a collection of fundamental papers are provided by Dasarathy <ref> [2] </ref>. Basically, there are two research communities with high interest in sensor fusion: developers of military applications (automatic target recognition, tactical decision systems), and researchers in non-military areas (robotics, pattern recognition) with a more general interest in sensor fusion. <p> Ref. [19] has a strong emphasis on military questions, whereas [5] and <ref> [2] </ref> are concerned with general sensor fusion. Other researchers, like Ho [6] in word recognition, have their focus mainly on the application field and are interested in sensor fusion only in order to get better recognition rates for their specific problem.
Reference: [3] <author> K. Fukunaga. </author> <title> Introduction to Statistical Pattern Recognition. </title> <publisher> Academic Press, </publisher> <address> 2 edition, </address> <year> 1990. </year>
Reference-contexts: In this case, one may assume that the classifier was able to designate a clear favourite class. Therefore, there is high evidence for a correct classification. A profound discussion of class separability and the behaviour of classifiers may be found in Fukunaga <ref> [3] </ref>. Among others, there exist the following types of transformations: * Linear * Logarithmic * Exponential * Logistic All these transformations do not affect the order of the transformed classifier ranking, because they are based on monotone functions.
Reference: [4] <author> A. Garzotto. Vollautomatische Erkennung von Schriftzeichen in gedrucktem Schriftgut. </author> <type> PhD thesis, </type> <institution> Universitat Zurich, </institution> <year> 1994. </year>
Reference: [5] <author> D.L. Hall. </author> <title> Mathematical Techniques in Multi-Sensor Data Fusion. </title> <publisher> Artech House, Inc., </publisher> <year> 1992. </year>
Reference-contexts: Because it is a rather new discipline within computer science, however, there is no widely recognized theory around yet. Good textbooks covering the important topics of sensor fusion are those by Waltz and Llinas [19], and Hall <ref> [5] </ref>. An extended bibliography and a collection of fundamental papers are provided by Dasarathy [2]. <p> Basically, there are two research communities with high interest in sensor fusion: developers of military applications (automatic target recognition, tactical decision systems), and researchers in non-military areas (robotics, pattern recognition) with a more general interest in sensor fusion. Ref. [19] has a strong emphasis on military questions, whereas <ref> [5] </ref> and [2] are concerned with general sensor fusion. Other researchers, like Ho [6] in word recognition, have their focus mainly on the application field and are interested in sensor fusion only in order to get better recognition rates for their specific problem. <p> In the following paragraphs, we summarize the key points of combining classifiers. It is mostly based on [19] and <ref> [5] </ref>. The idea of combining multiple inputs to infer informations about the actual environment is very natural. It is done by humans in everyday life, since we are all the time combining acoustic, visual, tactile, olfactory and thermal informations to react on the world around us. <p> In our case, we expect a higher recognition rate and a higher reliability of the results. Hall <ref> [5] </ref> gives a list of benefits of data fusion: * Robust operational performance * Extended spatial coverage * Extended temporal coverage * Increased confidence * Reduced ambiguity * Improved detection * Enhanced spatial resolution * Improved system reliability * Increased dimensionality Some interesting rules of thumb are given by Nahan and <p> of data fusion: * Robust operational performance * Extended spatial coverage * Extended temporal coverage * Increased confidence * Reduced ambiguity * Improved detection * Enhanced spatial resolution * Improved system reliability * Increased dimensionality Some interesting rules of thumb are given by Nahan and Pokoski (cited according to Hall <ref> [5] </ref>): 1. Combining data from multiple inaccurate sensors (having an individual probability of correct inference less than 0.5) does not provide a significant overall advantage. 2.
Reference: [6] <author> T.K. Ho. </author> <title> A Theory of Multiple Classifier Systems and Its Application to Visual Word Recognition. </title> <type> PhD thesis, </type> <institution> Departement of Computer Science, State University of New York at Buffalo, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Ref. [19] has a strong emphasis on military questions, whereas [5] and [2] are concerned with general sensor fusion. Other researchers, like Ho <ref> [6] </ref> in word recognition, have their focus mainly on the application field and are interested in sensor fusion only in order to get better recognition rates for their specific problem. In the following paragraphs, we summarize the key points of combining classifiers. It is mostly based on [19] and [5]. <p> They may be found empirically or by computing the recognition rates of the sensors with a test set. Those recognition probabilities may be used as weights. An alternative is described by Ho <ref> [6, 7] </ref> where the weights are computed by fitting a regression plane to the data. Recently, Lam and Suen [12] presented an approach where the weights are optimized using a genetic algorithm. All these methods choose the weights dependent on the performance of the classifiers.
Reference: [7] <author> T.K. Ho, J.J. Hull, </author> <title> and S.N. Srihari. Decision Combination in Multiple Classifier Systems. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16(1) </volume> <pages> 66-75, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: They may be found empirically or by computing the recognition rates of the sensors with a test set. Those recognition probabilities may be used as weights. An alternative is described by Ho <ref> [6, 7] </ref> where the weights are computed by fitting a regression plane to the data. Recently, Lam and Suen [12] presented an approach where the weights are optimized using a genetic algorithm. All these methods choose the weights dependent on the performance of the classifiers.
Reference: [8] <author> Y.S. Huang and C.Y. Suen. </author> <title> A Method of Combining Multiple Classifiers A Neural Network Approach. </title> <booktitle> In Proceedings 12th IAPR International Conference on Pattern Recognition (ICPR), Jerusalem, Israel, </booktitle> <volume> volume 2, </volume> <pages> pages 473-475. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: With this background in mind, it is clear that any statistical classification method, including artificial neural networks, may be applied to the problem. For additional information concerning the use of neural networks refer to Huang and Suen <ref> [8] </ref>, or Lee and Srihari [13].
Reference: [9] <author> Y. Ito, T. Ohashi, and T. Ejima. </author> <title> Considerations on Designing a Decision-Tree with Multiple Features. </title> <booktitle> In Proceedings 4th International Workshop on Frontiers in Handwriting Recognition (IWFHR), </booktitle> <address> Taipei, Taiwan, </address> <pages> pages 362-369, </pages> <month> December </month> <year> 1994. </year>
Reference: [10] <author> L. Lam and C.Y. Suen. </author> <title> A Theoretical Analysis of the Application of Majority Voting to Pattern Recognition. </title> <booktitle> In Proceedings 12th IAPR International Conference on Pattern Recognition (ICPR), Jerusalem, Israel, </booktitle> <volume> volume 2, </volume> <pages> pages 418-420. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: Often there is a very high probability to end up in a draw. For more details on voting strategies see Mandler and Schurmann [14] or Lam and Suen <ref> [10, 11] </ref>. 2.5.2 Rank Based Strategies As stated previously it isn't always possible to deal with the scores of the individual classifiers, since they may not be comparable.
Reference: [11] <author> L. Lam and C.Y. Suen. </author> <title> Increasing Experts for Majority Vote in OCR: Theoretical Considerations and Strategies. </title> <booktitle> In Proceedings 4th International Workshop on Frontiers in Handwriting Recognition, </booktitle> <pages> pages 245-254, </pages> <year> 1994. </year>
Reference-contexts: Often there is a very high probability to end up in a draw. For more details on voting strategies see Mandler and Schurmann [14] or Lam and Suen <ref> [10, 11] </ref>. 2.5.2 Rank Based Strategies As stated previously it isn't always possible to deal with the scores of the individual classifiers, since they may not be comparable.
Reference: [12] <author> L. Lam and C.Y. Suen. </author> <title> Optimal Combinations of Pattern Classifiers. </title> <journal> Pattern Recognition Letters, </journal> <volume> 16 </volume> <pages> 945-954, </pages> <year> 1995. </year> <month> 37 </month>
Reference-contexts: Those recognition probabilities may be used as weights. An alternative is described by Ho [6, 7] where the weights are computed by fitting a regression plane to the data. Recently, Lam and Suen <ref> [12] </ref> presented an approach where the weights are optimized using a genetic algorithm. All these methods choose the weights dependent on the performance of the classifiers. Voting methods only take into account a small part of the classifier's result, since they are exclusively based on the first rank.
Reference: [13] <author> D.-S. Lee and S.N. Srihari. </author> <title> A Theory of Classifier Combination: The Neural Network Ap--proach. </title> <booktitle> In Proceedings 3d International Conference on Document Analysis and Recognition. Montreal, Canada, </booktitle> <volume> volume 1, </volume> <pages> pages 42-45. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: With this background in mind, it is clear that any statistical classification method, including artificial neural networks, may be applied to the problem. For additional information concerning the use of neural networks refer to Huang and Suen [8], or Lee and Srihari <ref> [13] </ref>. Other approaches are based on decision trees ([9]), production rules, fuzzy logic ([1]), blackboard architectures ([4]) and regression analysis. 3 Practical Combination Experiments in Face Recognition 3.1 Face Classifiers The results of the practical experiments presented in this report are based on the combination of classifiers for face recognition.
Reference: [14] <author> E. Mandler and J. Schurmann. </author> <title> Combining the Classification Results of Independant Classifiers Based on the Dempster-Shafer Theory of Evidence. In E.S. </title> <editor> Gelsema and L.N. Kanal, editors, </editor> <booktitle> Pattern Recognition and Artificial Intelligence, </booktitle> <pages> pages 381-393. </pages> <publisher> Elsevier, </publisher> <year> 1988. </year>
Reference-contexts: Voting methods only take into account a small part of the classifier's result, since they are exclusively based on the first rank. Often there is a very high probability to end up in a draw. For more details on voting strategies see Mandler and Schurmann <ref> [14] </ref> or Lam and Suen [10, 11]. 2.5.2 Rank Based Strategies As stated previously it isn't always possible to deal with the scores of the individual classifiers, since they may not be comparable.
Reference: [15] <author> C. Nyffenegger. </author> <title> Gesichtserkennung mit Hidden-Markov-Modellen. </title> <type> Master's thesis, </type> <institution> Institut fur Informatik und angewandte Mathematik, Universitat Bern, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: The approach we used is similar to the method of Samaria described in [17] and is in detail presented in Nyffenegger's thesis <ref> [15] </ref>. An introduction to hidden Markov models is provided by Rabiner in [16]. Generally, HMMs are working on one-dimensional signals or feature vectors. Images instead contain two-dimensional information. In order to make HMMs applicable to images, we reduce the image information to one-dimensional vectors by applying a sliding window.
Reference: [16] <author> L.R. Rabiner. </author> <title> A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(2) </volume> <pages> 257-286, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: The approach we used is similar to the method of Samaria described in [17] and is in detail presented in Nyffenegger's thesis [15]. An introduction to hidden Markov models is provided by Rabiner in <ref> [16] </ref>. Generally, HMMs are working on one-dimensional signals or feature vectors. Images instead contain two-dimensional information. In order to make HMMs applicable to images, we reduce the image information to one-dimensional vectors by applying a sliding window.
Reference: [17] <author> F.S. Samaria. </author> <title> Face Recognition Using Hidden Markov Models. </title> <type> PhD thesis, </type> <institution> Trinity College, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: The approach we used is similar to the method of Samaria described in <ref> [17] </ref> and is in detail presented in Nyffenegger's thesis [15]. An introduction to hidden Markov models is provided by Rabiner in [16]. Generally, HMMs are working on one-dimensional signals or feature vectors. Images instead contain two-dimensional information.
Reference: [18] <author> M.A. Turk and A.P. Pentland. </author> <title> Eigenfaces for Recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 71-86, </pages> <year> 1991. </year>
Reference-contexts: The results of the less trained classifier are listed in Figures 3 and 38. 3.1.3 Full Face Classification with Eigenfaces This full face classifier is an implementation of the eigenface approach proposed by Turk and Pentland <ref> [18] </ref>. The basic idea is to represent a face as a linear combination of a small number of base vectors. It is supposed that the coefficients of this linear combination are characteristic for the face of a certain person.
Reference: [19] <author> E. Waltz and J. Llinas. </author> <title> Multisensor Data Fusion. </title> <publisher> Artech House, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Since about 1988, there has been an explosive growth of publications and conferences. Because it is a rather new discipline within computer science, however, there is no widely recognized theory around yet. Good textbooks covering the important topics of sensor fusion are those by Waltz and Llinas <ref> [19] </ref>, and Hall [5]. An extended bibliography and a collection of fundamental papers are provided by Dasarathy [2]. <p> Basically, there are two research communities with high interest in sensor fusion: developers of military applications (automatic target recognition, tactical decision systems), and researchers in non-military areas (robotics, pattern recognition) with a more general interest in sensor fusion. Ref. <ref> [19] </ref> has a strong emphasis on military questions, whereas [5] and [2] are concerned with general sensor fusion. <p> In the following paragraphs, we summarize the key points of combining classifiers. It is mostly based on <ref> [19] </ref> and [5]. The idea of combining multiple inputs to infer informations about the actual environment is very natural. It is done by humans in everyday life, since we are all the time combining acoustic, visual, tactile, olfactory and thermal informations to react on the world around us.
Reference: [20] <author> K. Yu, B. Achermann, C. Nyffenegger, X.-Y. Jiang, H. Bunke, and E.G. </author> <title> Schukat-Talamazzini. </title> <editor> Kombination von Frontal- und Profilanalyse menschlicher Gesichter. In G. Sagerer, S. Posch, and F. Kummert, editors, </editor> <booktitle> Mustererkennung 1995. Verstehen akustischer und visueller Information. 17. DAGM-Symposium, Bielefeld, </booktitle> <pages> pages 327-334. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1995. </year>
Reference-contexts: In the last years there has been a growing interest in sensor fusion methods. Experiments in character recognition, word recognition and robotics have shown promising results. Furthermore, we implemented a heuristic approach to combine two different face classifiers (for details about our previous work see <ref> [20] </ref>) which also showed good results. Therefore, we decided to expand our investigations in a systematic way on different combination methods and on the combination of more than two classifiers. <p> However, this flexible determination allows a very sophisticated tuning of the combination classifier, especially for large training sets. This is certainly an advantage of this method. 2.5.5 Method of Yu This method is in detail described in our paper <ref> [20] </ref>. It is a rank based classifier, where it is additionally tried to integrate the computation of weights based on the expected quality and the discrimination ability of the two involved pattern classifiers C 1 (HMM classifier) and C 2 (profile classifier). <p> The results of the eigenface classifier are shown in Figures 3 and 39. The figures show that the method performs very well. 3.1.4 Profile Classification This classifier is based on a comparison of the profile shape of human faces. The details are described in our papers [21] and <ref> [20] </ref>. The method consists of the following processing steps: * Determination of fiducial points The profile line of a given image of a human side view is extracted. <p> The pattern classifiers used in this work, for instance, yield various scores. The profile classifier computes the score as the distance (in pixels) between the presented profile line and the intervals in the models (for further details refer to our previous papers [21] and <ref> [20] </ref>). Theoretically this function may have values between 0 and 1. Experimentally we found values in the range of 0 and 30000. The HMM classifier instead yields a score s = 2 log p, which is derived from a probability. The value may theoretically range from 0 to 1 again.
Reference: [21] <author> K. Yu, X.-Y. Jiang, and H. Bunke. </author> <title> Face Recognition by Facial Profile Analysis. </title> <editor> In M. Bich-sel, editor, </editor> <booktitle> Proceedings International Workshop on Automatic Face and Gesture Recognition, </booktitle> <address> Zurich, </address> <pages> pages 208-213, </pages> <month> June </month> <year> 1995. </year> <month> 38 </month>
Reference-contexts: The results of the eigenface classifier are shown in Figures 3 and 39. The figures show that the method performs very well. 3.1.4 Profile Classification This classifier is based on a comparison of the profile shape of human faces. The details are described in our papers <ref> [21] </ref> and [20]. The method consists of the following processing steps: * Determination of fiducial points The profile line of a given image of a human side view is extracted. <p> The extraction of the fiducial points is based on the local curvature of the profile line (for further details see <ref> [21] </ref>). Additionally, a line L is computed with minimal quadratic distance to the points between the chin and the forehead point. * Canonical position Based on the fiducial points a canonical position is computed for the presented profile line. <p> The pattern classifiers used in this work, for instance, yield various scores. The profile classifier computes the score as the distance (in pixels) between the presented profile line and the intervals in the models (for further details refer to our previous papers <ref> [21] </ref> and [20]). Theoretically this function may have values between 0 and 1. Experimentally we found values in the range of 0 and 30000. The HMM classifier instead yields a score s = 2 log p, which is derived from a probability.
References-found: 21

