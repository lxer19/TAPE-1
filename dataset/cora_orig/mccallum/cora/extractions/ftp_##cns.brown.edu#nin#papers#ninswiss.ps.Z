URL: ftp://cns.brown.edu/nin/papers/ninswiss.ps.Z
Refering-URL: http://www.math.tau.ac.il/~nin/research.html
Root-URL: 
Email: fnin,reisfeld,hezyg@math.tau.ac.il  
Title: Extraction of Facial Features for Recognition using Neural Networks  
Author: Nathan Intrator Daniel Reisfeld Yehezkel Yeshurun 
Address: Ramat Aviv 69978, Israel  
Affiliation: Department of Computer Science Tel-Aviv University  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Bellman, </author> <title> Adaptive Control Processes. </title> <publisher> Princeton, </publisher> <address> NJ: </address> <publisher> Princeton University Press, </publisher> <year> 1961. </year>
Reference-contexts: Such recognition is difficult since grey level images are vectors in a very high dimensional space and are thus subject to the "curse of dimensionality" <ref> [1] </ref> which essentially says that the number of training patterns needed for robust classification, should be ridiculously high.
Reference: [2] <author> P. J. Huber, </author> <title> "Projection pursuit. (with discussion)," </title> <journal> The Annals of Statistics, </journal> <volume> vol. 13, </volume> <pages> pp. 435-475, </pages> <year> 1985. </year>
Reference-contexts: The search for projections is at the heart of projection pursuit methods <ref> [2] </ref> and artificial neural networks (ANN). Taking this approach, one is then confronted with the task of finding optimal projections. A commonly used method is based on second order statistics of the data where one extracts the directions maximizing the variance the principal components of the data [3, 4].
Reference: [3] <author> M. Kirby and L. Sirovich, </author> <title> "Application of the karhunen-loeve procedure for characterization of human faces," </title> <journal> IEEE Transactions Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, no. 1, </volume> <pages> pp. 103-108, </pages> <year> 1990. </year>
Reference-contexts: Taking this approach, one is then confronted with the task of finding optimal projections. A commonly used method is based on second order statistics of the data where one extracts the directions maximizing the variance the principal components of the data <ref> [3, 4] </ref>. We show that feature extraction based on principal components is not good enough, and feature extraction based on higher order statistics improves classification results. Interpretability of network results is not clear, and in general does not shed much light on the way recognition is performed.
Reference: [4] <author> M. Turk and A. Pentland, </author> <title> "Eigenfaces for recognition," </title> <journal> J. of Cognitive Neuroscience, </journal> <volume> vol. 3, </volume> <pages> pp. 71-86, </pages> <year> 1991. </year>
Reference-contexts: Taking this approach, one is then confronted with the task of finding optimal projections. A commonly used method is based on second order statistics of the data where one extracts the directions maximizing the variance the principal components of the data <ref> [3, 4] </ref>. We show that feature extraction based on principal components is not good enough, and feature extraction based on higher order statistics improves classification results. Interpretability of network results is not clear, and in general does not shed much light on the way recognition is performed. <p> This method extends the interpretability associated with linear or logistic regression to feed-forward neural networks. face (left) 4 Methodology We used a subset of the MIT Media Lab database of face images (see Figure 3) courtesy of Turk and Pentland <ref> [4] </ref>. Previous results using the same preprocessing and dimensionality reduction using receptive fields and radial basis function networks have been described in [21]. The database we used contained 27 instances of each of 16 different persons. The images were taken under varying illumination and camera location.
Reference: [5] <author> N. Intrator, </author> <title> "Combining exploratory projection pursuit and projection pursuit regression with application to neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 443-455, </pages> <year> 1993. </year>
Reference-contexts: In addition we apply a recently-introduced method for neural network interpretation to study the effect on recognition performance of different regions in the pixel images. We adapt an approach for dimensionality reduction and classification which is based on a combination of supervised and unsupervised learning <ref> [5] </ref>. The supervised learning seeks projections that minimize mean squared error between the output of a feed-forward network and the class label of the image. The unsupervised learning seeks projections which demonstrate some interesting structure in the data, essentially by measuring deviation from normal distribution in the form of multi-modality. <p> In addition to plain vanilla feed-forward net trained with back-propagation of error, we have trained several networks to get ensemble network results. This performed significantly better than each of the networks separately. On top of this, we have used a hybrid training method <ref> [5] </ref>. This method is based on a formulation that combines unsupervised (exploratory) methods for finding structure (extracting features) and supervised methods for reducing classification error. The unsupervised training portion is aimed at finding features such as clusters.
Reference: [6] <author> A. Yarbus, </author> <title> Eye Movements and Vision. </title> <address> New York: </address> <publisher> Plenum Press, </publisher> <year> 1967. </year>
Reference-contexts: The mechanisms of attention and fixation enable primates to reduce the amount of information and processing. Most of the photo-receptors of the retina are located at the fovea the part of the eye with the highest resolution and the eyes rapidly move from one fixation point to another <ref> [6] </ref>. Moreover, resources are not allocated uniformly over the field of view: When a primate focuses his attention on a location, events occurring at that location are responded to more rapidly, give rise to enhanced electrical activity, and can be reported at a lower threshold [7].
Reference: [7] <author> M. Posner and S. Peterson, </author> <title> "The attention system of the human brain," </title> <journal> Annual Review of Neuroscience, </journal> <volume> vol. 13, </volume> <pages> pp. 25-42, </pages> <year> 1990. </year>
Reference-contexts: Moreover, resources are not allocated uniformly over the field of view: When a primate focuses his attention on a location, events occurring at that location are responded to more rapidly, give rise to enhanced electrical activity, and can be reported at a lower threshold <ref> [7] </ref>. We have introduced an interest operator, inspired by the intuitive notion of symmetry, as a computer vision analogue to attention and fixation [8, 9]. Our interest operator the generalized symmetry transform [9] assigns a symmetry magnitude and a symmetry orientation to every pixel.
Reference: [8] <author> D. Reisfeld, H. Wolfson, and Y. Yeshurun, </author> <title> "Detection of interest points using symmetry," </title> <booktitle> in Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <address> (Osaka, Japan), </address> <pages> pp. 62-65, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: We have introduced an interest operator, inspired by the intuitive notion of symmetry, as a computer vision analogue to attention and fixation <ref> [8, 9] </ref>. Our interest operator the generalized symmetry transform [9] assigns a symmetry magnitude and a symmetry orientation to every pixel. In the usual math ematical notion, an object is regarded symmetric if it is invariant to the application of certain transformations, called symmetry operations.
Reference: [9] <author> D. Reisfeld, H. Wolfson, and Y. Yeshurun, </author> <title> "Context free attentional operators: the generalized symmetry transform," </title> <journal> Int. J. of Computer Vision, Special Issue on Qualitative Vision, </journal> <volume> vol. 14, </volume> <pages> pp. 119-130, </pages> <year> 1995. </year>
Reference-contexts: We have introduced an interest operator, inspired by the intuitive notion of symmetry, as a computer vision analogue to attention and fixation <ref> [8, 9] </ref>. Our interest operator the generalized symmetry transform [9] assigns a symmetry magnitude and a symmetry orientation to every pixel. In the usual math ematical notion, an object is regarded symmetric if it is invariant to the application of certain transformations, called symmetry operations. <p> We have introduced an interest operator, inspired by the intuitive notion of symmetry, as a computer vision analogue to attention and fixation [8, 9]. Our interest operator the generalized symmetry transform <ref> [9] </ref> assigns a symmetry magnitude and a symmetry orientation to every pixel. In the usual math ematical notion, an object is regarded symmetric if it is invariant to the application of certain transformations, called symmetry operations. Our symmetry transform does not require the knowledge of the object's shape. <p> Equipped with facial feature detector, the image preprocessing involves a normalization procedure based on an affine transformations which is deter mined by the locations of the eyes and mouth. A demonstration and further details are given in <ref> [9] </ref>. 3 Feature Extraction We have employed several variations of the frequently used feed-forward artificial neural network for classification. We have chosen to use feed-forward artificial neural networks due to their ability to cope with very high dimensional data, thus making them excellent candidates to perform recognition from pixel values.
Reference: [10] <author> D. Reisfeld and Y. Yeshurun, </author> <title> "Robust detection of facial features by generalized symmetry," </title> <booktitle> in Proceedings of the 11th IAPR International Conference on Pattern Recognition, (The Hague, The Netherlands), </booktitle> <pages> pp. </pages> <address> A117-120, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: We have turned the generalized symmetry transform into an effective facial features detector using various transformations on the symmetry map along with some basic geometrical relations <ref> [10] </ref>. The eyes and mouth using the symmetry map and geometrical constraints transformation of the symmetry map includes various operations that can be applied also to edge maps such as projecting the symmetry values on the horizon, edge linking, and using local maxima for locating anchor points.
Reference: [11] <author> K. Hornik, M. Stinchcombe, and H. White, </author> <title> "Universal approximation of an unknown mapping and its derivatives using multilayer feed-forward networks," </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 3, </volume> <pages> pp. 551-560, </pages> <year> 1990. </year>
Reference-contexts: The class of functions that can be approximated by a back-propagation type network is very large; This architecture (with an unlimited number of projections) can uniformly approximate arbitrary continuous functions on compact sets, as well as their derivatives <ref> [11] </ref>, and do so efficiently. The error is efficiently propagated backwards to the previous (hidden) layer for modification of their synaptic weights (projections).
Reference: [12] <author> G. Wahba, </author> <title> Splines Models for Observational Data. </title> <booktitle> Philadelphia: Series in Applied Mathematics, </booktitle> <volume> Vol. 59, </volume> <publisher> SIAM, </publisher> <year> 1990. </year>
Reference-contexts: Since this method can approximate any continuous function, great care should be taken so that the variance of the estimator is not large, namely, that the model does not "overfit" the training data <ref> [12, 13, for discussion] </ref>. This can be done using some form of complexity regularization [14, for example] or by weight elimination penalties which aim to reduce the effective number of parameters in the model [15, for review].
Reference: [13] <author> S. Geman, E. Bienenstock, and R. Dour--sat, </author> <title> "Neural networks and the bias-variance dilemma," </title> <journal> Neural Computation, </journal> <volume> vol. 4, </volume> <pages> pp. 1-58, </pages> <year> 1992. </year>
Reference-contexts: Since this method can approximate any continuous function, great care should be taken so that the variance of the estimator is not large, namely, that the model does not "overfit" the training data <ref> [12, 13, for discussion] </ref>. This can be done using some form of complexity regularization [14, for example] or by weight elimination penalties which aim to reduce the effective number of parameters in the model [15, for review]. <p> These results are best explained by the bias/variance tradeoff <ref> [13, for review] </ref>. The effort to control the bias via bias constraints, increases the variance in single networks, however, the network averaging which does not affect the bias, reduces the variance so that the ensemble result is better.
Reference: [14] <author> A. R. Barron and R. L. Barron, </author> <title> "Statistical learning networks: A unifying view," </title> <booktitle> in Computing Science and Statistics: Proc. 20th Symp. Interface (E. Wegman, </booktitle> <publisher> ed.), </publisher> <pages> pp. 192-203, </pages> <month> Wash-ington, </month> <title> DC.: </title> <journal> American Statistical Association, </journal> <year> 1988. </year>
Reference-contexts: Since this method can approximate any continuous function, great care should be taken so that the variance of the estimator is not large, namely, that the model does not "overfit" the training data [12, 13, for discussion]. This can be done using some form of complexity regularization <ref> [14, for example] </ref> or by weight elimination penalties which aim to reduce the effective number of parameters in the model [15, for review]. In addition to plain vanilla feed-forward net trained with back-propagation of error, we have trained several networks to get ensemble network results.
Reference: [15] <author> A. S. Weigend, D. E. Rumelhart, and B. A. Hu-berman, </author> <title> "Generalization by weight-elimination with application to forecasting," </title> <booktitle> in Advances in Neural Information Processing Systems (R. </booktitle> <editor> P. Lippmann, J. E. Moody, and D. S. Touretzky, eds.), </editor> <volume> vol. 3, </volume> <pages> pp. 875-882, </pages> <address> San Mateo, CA: </address> <publisher> Mor-gan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: This can be done using some form of complexity regularization [14, for example] or by weight elimination penalties which aim to reduce the effective number of parameters in the model <ref> [15, for review] </ref>. In addition to plain vanilla feed-forward net trained with back-propagation of error, we have trained several networks to get ensemble network results. This performed significantly better than each of the networks separately. On top of this, we have used a hybrid training method [5].
Reference: [16] <author> E. L. Bienenstock, L. N. Cooper, and P. W. Munro, </author> <title> "Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex," </title> <journal> Journal Neuro-science, </journal> <volume> vol. 2, </volume> <pages> pp. 32-48, </pages> <year> 1982. </year>
Reference-contexts: The application of the hybrid training in a feed-forward neural network is done by modifying the learning rule of the hidden units to reflect the additional constraints (Figure 2). The unsupervised feature extraction which we used, is based on the biologically motived BCM neuron <ref> [16] </ref>.
Reference: [17] <author> N. Intrator and J. I. Gold, </author> <title> "Three-dimensional object recognition of gray level images: The usefulness of distinguishing features," </title> <journal> Neural Computation, </journal> <volume> vol. 5, </volume> <pages> pp. 61-74, </pages> <year> 1993. </year>
Reference-contexts: It was found to be applicable for extracting features from very high dimensional vector spaces <ref> [17] </ref>. Below is a brief description of the unsupervised portion of the network, see [18] for details.
Reference: [18] <author> N. Intrator and L. N. Cooper, </author> <title> "Objective function formulation of the BCM theory of visual cortical plasticity: Statistical connections, stability conditions," </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 5, </volume> <pages> pp. 3-17, </pages> <year> 1992. </year>
Reference-contexts: It was found to be applicable for extracting features from very high dimensional vector spaces [17]. Below is a brief description of the unsupervised portion of the network, see <ref> [18] </ref> for details. <p> In the results reported here, a feed-forward architecture with a single hidden layer of 12 units was used in all the experiments. Training was done using the back-propagation algorithm [19] for the supervised part and using the projection pursuit learning <ref> [18] </ref> for the unsupervised part. For comparison, we also report classification results based on other classification techniques. The calculation of significance of the object features for recognition was done via a newly introduced method for interpreting neural networks which is described elsewhere [20].
Reference: [19] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams, </author> <title> "Learning internal representations by error propagation," in Parallel Distributed Processing (D. </title> <editor> E. Rumelhart and J. L. McClelland, eds.), </editor> <volume> vol. 1, </volume> <pages> pp. 318-362, </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: In practice, the stochastic version of the differential equation can be used as the learning rule. In the results reported here, a feed-forward architecture with a single hidden layer of 12 units was used in all the experiments. Training was done using the back-propagation algorithm <ref> [19] </ref> for the supervised part and using the projection pursuit learning [18] for the unsupervised part. For comparison, we also report classification results based on other classification techniques.
Reference: [20] <author> O. Intrator and N. Intrator, </author> <title> "Using neural networks for interpretation of nonlinear models," </title> <journal> in American Statistical Society: 1993 Proceedings of the Statistical Computing Section, </journal> <pages> pp. 244-249, </pages> <institution> American Statistical Association, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: For comparison, we also report classification results based on other classification techniques. The calculation of significance of the object features for recognition was done via a newly introduced method for interpreting neural networks which is described elsewhere <ref> [20] </ref>. This method extends the interpretability associated with linear or logistic regression to feed-forward neural networks. face (left) 4 Methodology We used a subset of the MIT Media Lab database of face images (see Figure 3) courtesy of Turk and Pentland [4]. <p> There are various robustification issues related to the nonuniqueness property of ANN solutions. Full details of the method are described in <ref> [20] </ref>. The extremum parts of the images (both negative dark, and positive bright) indicate the important features. Notice that the head outline, eyes and mouth are more salient on the Hybrid BCM/BP method (right) than on the BP method (left). This is more consistent with psychophysical experiments [24, 25, 26].
Reference: [21] <author> S. Edelman, D. Reisfeld, and Y. Yeshurun, </author> <title> "Learning to recognize faces from examples," </title> <booktitle> in Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <address> (Santa Margherita Ligure, Italy), </address> <pages> pp. 787-791, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Previous results using the same preprocessing and dimensionality reduction using receptive fields and radial basis function networks have been described in <ref> [21] </ref>. The database we used contained 27 instances of each of 16 different persons. The images were taken under varying illumination and camera location. Of the 27 images, 17 were randomly chosen for each person to be used in training, while the remaining 10 were used for testing.
Reference: [22] <author> W. P. Lincoln and J. Skrzypek, </author> <title> "Synergy of clustering multiple back-propagation networks," </title> <booktitle> in Advances in Neural Information Processing Systems (D. </booktitle> <editor> S. Touretzky and R. P. Lippmann, eds.), </editor> <volume> vol. 2, </volume> <pages> pp. 650-657, </pages> <address> San Mateo, CA: </address> <publisher> Mor-gan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: This method corresponds to using a uniform prior on the weight space under Bayesian setup, but can simply be considered as reducing the variance of the network outputs (considered as random variables) by summing over an ensemble of networks <ref> [22] </ref>. Two points are worth mentioning in the results. First, as is often found, network ensemble reduces classification error.
Reference: [23] <author> O. Comay and N. Intrator, </author> <title> "Ensemble training: Some recent experiments with postal zip data," </title> <booktitle> in Proceedings of the 10th Israeli Conference on AICV (R. </booktitle> <editor> Basri, U. J. Schild, and Y. Stein, </editor> <booktitle> eds.), </booktitle> <pages> pp. 201-206, </pages> <publisher> Elsevier, </publisher> <year> 1993. </year>
Reference-contexts: An indication of the increased variance can be seen by the increased standard deviation of the results for the hybrid method. These results complement a different set of experiments which tried to study the effect of variance constraints on feed-forward neural networks <ref> [23] </ref>. Interpretability of the networks Although a total of 12 features were extracted (using 12 hidden units), only 7 of the projections appear to be different. This gives the surprising result that an efficient dimensionality reduction can give good classification performance of 16 different faces using only 7 features.
Reference: [24] <author> G. Davis, H. Ellis, and J. Shepherd, </author> <title> "Face recognition accuracy as a function of mode of representation," </title> <journal> Journal of Applied Psychology, </journal> <volume> vol. 63, </volume> <pages> pp. 180-187, </pages> <year> 1978. </year>
Reference-contexts: The extremum parts of the images (both negative dark, and positive bright) indicate the important features. Notice that the head outline, eyes and mouth are more salient on the Hybrid BCM/BP method (right) than on the BP method (left). This is more consistent with psychophysical experiments <ref> [24, 25, 26] </ref>. Such interpretability method may be useful for human psychophysics studies, and for possible comparison between human and machine recognition, and for the study of object features.
Reference: [25] <author> N. Haig, </author> <title> "Investigating face recognition with an image processor computer," in Aspects of Face Processing (H. </title> <editor> Ellis, M. Jeeves, F. Newcombe, and A. W. Young, eds.), </editor> <publisher> Dordrecht: Martinus Nijhoff, </publisher> <year> 1986. </year>
Reference-contexts: The extremum parts of the images (both negative dark, and positive bright) indicate the important features. Notice that the head outline, eyes and mouth are more salient on the Hybrid BCM/BP method (right) than on the BP method (left). This is more consistent with psychophysical experiments <ref> [24, 25, 26] </ref>. Such interpretability method may be useful for human psychophysics studies, and for possible comparison between human and machine recognition, and for the study of object features.
Reference: [26] <author> I. Fraser and D. Parker, </author> <title> "Reaction time measures of feature saliency in perceptual integration task," in Aspects of Face Processing (H. </title> <editor> El-lis, M. Jeeves, F. Newcombe, and A. Young, eds.), </editor> <publisher> Dordrecht: Martinus Nijhoff, </publisher> <year> 1986. </year>
Reference-contexts: The extremum parts of the images (both negative dark, and positive bright) indicate the important features. Notice that the head outline, eyes and mouth are more salient on the Hybrid BCM/BP method (right) than on the BP method (left). This is more consistent with psychophysical experiments <ref> [24, 25, 26] </ref>. Such interpretability method may be useful for human psychophysics studies, and for possible comparison between human and machine recognition, and for the study of object features.
References-found: 26

