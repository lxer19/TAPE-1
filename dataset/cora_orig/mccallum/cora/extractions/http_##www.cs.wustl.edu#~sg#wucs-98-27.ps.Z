URL: http://www.cs.wustl.edu/~sg/wucs-98-27.ps.Z
Refering-URL: http://www.cs.wustl.edu/~sg/
Root-URL: http://www.cs.wustl.edu
Email: sg@cs.wustl.edu  kwek@eecs.wsu.edu  sscott@cse.unl.edu  
Title: Agnostic Learning of Geometric Patterns  
Author: Sally A. Goldman Stephen S. Kwek Stephen D. Scott 
Note: An earlier version appears in Proceedings of the Tenth Annual ACM Conference on Computational Learning Theory, 1997 Supported in part by NSF NYI Grant CCR-9357707 with matching funds provided by Xerox PARC and WUTA.  
Date: December 1998  
Address: St. Louis, MO 63130-4899  Pullman, WA 99164-1035  Lincoln, NE 68588-0115  
Affiliation: Dept. of Computer Science Washington University  School of Electrical Engineering and Computer Science Washington State University  Dept. of Computer Science and Engineering University of Nebraska  
Pubnum: WUCS-98-27  
Abstract: Goldberg, Goldman, and Scott demonstrated how the problem of recognizing a landmark from a one-dimensional visual image can be mapped to that of learning a one-dimensional geometric pattern and gave a PAC algorithm to learn that class. In this paper, we present an efficient on-line agnostic learning algorithm for learning the class of constant-dimension geometric patterns. Our algorithm can tolerate both classification and attribute noise. By working in higher dimensional spaces we can 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Our belief is that these algorithms will be robust against many types of noise, including those for which they have no known theoretical guarantees. 3 The On-Line, Agnostic Learning Model and Winnow In this paper we consider the on-line (or mistake-bound) learning model <ref> [1, 23] </ref> as applied to concept learning (i.e. the classification of each example is 1 or 0). <p> Using the virtual weights technique will allow our time complexity to be polynomial in the size of the examples and the size of the target concept. It is also well known that learning algorithms in the mistake-bound model can be mapped to PAC algorithms <ref> [1, 24] </ref>. A PAC (probably approximately correct) algorithm [34, 35] is an off-line algorithm that draws examples randomly according to an arbitrary, unknown probability distribution and with probability 1ffi outputs a hypothesis with error *, where the parameters * and ffi are given as inputs to the algorithm. <p> Note that the mistake bound M need not be known in this mapping. This gives us the following theorem. Theorem 3 <ref> [1, 23] </ref> Winnow with an unknown mistake bound M can be converted to a PAC algorithm with sample complexity M 1 + 2 : The time complexity is O (N ) times the sample complexity. A better bound can be attained if M is known [24]. <p> It is well known that efficient on-line algorithms can be easily turned into efficient PAC algorithms (Section 3), but not all efficient PAC algorithms have efficient on-line counterparts <ref> [1, 24] </ref>. Thus a robot equipped with this paper's algorithm can learn as it goes, but one using Goldman and Scott's algorithm cannot. <p> For example, the coordinates in each dimension could be specified by a sequence of triples h (a i ; b i ; t i )i, 1 i w, where [a i ; b i ] <ref> [1; s] </ref> represents an interval on the current axis and t i is the number of points uniformly distributed in [a i ; b i ] (we would require [a i ; b i ] " [a j ; b j ] = ; for all i 6= j).
Reference: [2] <author> J. A. Aslam and S. E. Decatur. </author> <title> Specification and simulation of statistical query algorithms for efficiency and noise tolerance. </title> <journal> Journal of Computer and System Sciences, </journal> <note> 1998. To appear. </note>
Reference-contexts: Goldman and Scott [13] gave an efficient algorithm that uses the statistical query model <ref> [2, 18] </ref> to PAC learn the class of continuous one-dimensional geometric patterns under high noise rates (any rate &lt; 1=2 of classification noise). They also performed an empirical study of how well their algorithm worked on both simulated and real data.
Reference: [3] <author> P. Auer. </author> <title> On learning from multi-instance examples: Empirical evaluation of a theoretical approach. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference (ICML '97), </booktitle> <pages> pages 21-29. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1997. </year>
Reference-contexts: Later, Auer <ref> [3] </ref> modified that algorithm (making it more practical) and gave an empirical analysis of the modified algorithm. In the above papers, each example is classified as positive if at least one of its points is inside the target box. <p> Auer et al. [4] gave an efficient PAC algorithm for learning a single axis-parallel box in &lt; d from multiple-instance examples if each instance is drawn independently from an arbitrary distribution over &lt; d . This algorithm is also polynomial in d. Later, Auer <ref> [3] </ref> modified that algorithm (making it more practical) and 21 gave an empirical analysis of the modified algorithm. In the above papers, each example is classified as positive if at least one of its points is inside the target box.
Reference: [4] <author> P. Auer, P. M. Long, and A. Srinivasan. </author> <title> Approximating hyper-rectangles: Learning and pseudo-random sets. </title> <booktitle> In Proceedings of the Twenty-Ninth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 314-323. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: Long and Tan [27] described an efficient PAC algorithm for learning a single axis-parallel box in Q d from multiple-instance examples under a product distribution where Q denotes the set of rationals and d need not be constant. Auer et al. <ref> [4] </ref> gave an efficient PAC algorithm for learning a single axis-parallel box in &lt; d from multiple-instance examples if each instance is drawn independently from an arbitrary distribution over &lt; d . <p> Subsequently, Long and Tan [27] described an efficient PAC algorithm for learning a single axis-parallel box in Q d (where Q denotes the set of rationals) from multiple-instance examples if each instance is drawn independently from a product distribution and d need not be constant. Auer et al. <ref> [4] </ref> gave an efficient PAC algorithm for learning a single axis-parallel box in &lt; d from multiple-instance examples if each instance is drawn independently from an arbitrary distribution over &lt; d . This algorithm is also polynomial in d.
Reference: [5] <author> Peter Auer and Manfred Warmuth. </author> <title> Tracking the best disjunction. </title> <booktitle> Machine Learning, </booktitle> <year> 1998. </year> <note> To appear in the Special Issue on Context Sensitivity and Concept drift. </note>
Reference-contexts: Another major difference between these algorithms is that Winnow's mistake bound is logarithmic in N whereas the Perceptron algorithm's mistake bound can be linear in N in the worst case [20]. Recently Auer and Warmuth <ref> [5] </ref>, in generalizing the work of Littlestone [25], showed that Winnow makes at most O (A + K log N ) mistakes on any sequence of trials where the target K-disjunction makes at most A attribute errors. <p> Thus we have the following interpretation of the mistake bound in the presence of attribute errors 4 . Theorem 1 <ref> [5] </ref> Suppose in a sequence of trials for on-line learning an unknown boolean concept defined by K of N possible attributes, the best K-disjunction makes M opt mistakes (classification errors). <p> Then Winnow, running with ff = 1:75, each initial weight = 1=N , and = (ff ln ff)=(ff 2 1), makes at most 2:75KM opt + 4:92K (ln N 1) + 4:92 mistakes. Auer and Warmuth <ref> [5] </ref> also offer a version of Winnow that tolerates concept shift (i.e. the target disjunction may change completely in time). When a weight is sufficiently small, they do not demote it any further. Specifically, no weight is allowed to fall below fi=N for some fi 0. <p> Then the total number of shifts in T trials is Z = P T t=1 z t . Again, since a prediction mistake by the optimal K-disjunction corresponds to at most K attribute errors, we get the following mistake bound in the presence of shifting concepts. Theorem 2 <ref> [5] </ref> Suppose in a sequence of trials for on-line learning a sequence of unknown boolean concepts, each defined by K of N possible attributes, the best sequence of K-disjunctions makes M opt mistakes (classification errors) and the sequence of disjunctions includes Z total shifts. <p> It can be shown that the bounds of Theorems 1 and 2 are optimal up to constants if no information other than N is known <ref> [5] </ref>. Better bounds can be achieved if we tune Winnow using knowledge of K, Z, and A. One method of tuning Winnow is to apply the weighted majority algorithm, as demonstrated by Littlestone and Warmuth [26].
Reference: [6] <author> G. Bakiri. </author> <title> Converting English text to speech: A machine learning approach. </title> <type> Technical Report 91-30-2, </type> <institution> Oregon State University, Corvallis, </institution> <address> OR, </address> <year> 1991. </year>
Reference-contexts: Here the learner learns a collection of classifiers, each classifier providing one bit of the code for a particular value. ECOCs are used so that multiple codes map to the same value, making the learning algorithm more robust. These methods have a successful empirical history <ref> [6, 8, 9, 36, 21] </ref>. Finally, another interesting direction is to further study the possibilities for applying our techniques to learn other geometric concepts under the multiple-instance model as well as exploring other meaningful rules to classify the multiple-instance examples.
Reference: [7] <author> N.H. Bshouty, P.W. Goldberg, S.A. Goldman, and H.D. Mathias. </author> <title> Exact learning of discretized geometric concepts. </title> <journal> SIAM Journal of Computing, </journal> <note> 1998. To appear. </note>
Reference-contexts: Removing the exponential dependence on d from our time bounds would be a very difficult task. It is well known (see e.g. Maass and Warmuth [28] or Bshouty et al. <ref> [7] </ref>) that learning unions of at most k d-dimensional boxes (with single-instance examples) in time polynomial in d with X base = f0; 1g d yields an algorithm for learning k-term DNF formulas over d variables in time polynomial in k and d.
Reference: [8] <author> T. G. Dietterich and G. Bakiri. </author> <title> Error-correcting output codes: A general method for improving multiclass inductive learning programs. </title> <booktitle> In Proceedings of AAAI '91, </booktitle> <pages> pages 572-577. </pages> <publisher> AAAI Press/MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Here the learner learns a collection of classifiers, each classifier providing one bit of the code for a particular value. ECOCs are used so that multiple codes map to the same value, making the learning algorithm more robust. These methods have a successful empirical history <ref> [6, 8, 9, 36, 21] </ref>. Finally, another interesting direction is to further study the possibilities for applying our techniques to learn other geometric concepts under the multiple-instance model as well as exploring other meaningful rules to classify the multiple-instance examples.
Reference: [9] <author> T. G. Dietterich and G. Bakiri. </author> <title> Solving multiclass learning problems via error-correcting output codes. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 263-286, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: To do this, our algorithms need to learn multi-valued (versus only binary) functions. One approach to converting binary function learners to multi-valued function learners is via the use of error-correcting output codes (ECOCs) <ref> [32, 9] </ref>. Here the learner learns a collection of classifiers, each classifier providing one bit of the code for a particular value. ECOCs are used so that multiple codes map to the same value, making the learning algorithm more robust. <p> Here the learner learns a collection of classifiers, each classifier providing one bit of the code for a particular value. ECOCs are used so that multiple codes map to the same value, making the learning algorithm more robust. These methods have a successful empirical history <ref> [6, 8, 9, 36, 21] </ref>. Finally, another interesting direction is to further study the possibilities for applying our techniques to learn other geometric concepts under the multiple-instance model as well as exploring other meaningful rules to classify the multiple-instance examples.
Reference: [10] <author> Thomas G. Dietterich, Richard H. Lathrop, and Tomas Lozano-Perez. </author> <title> Solving the multiple-instance problem with axis-parallel rectangles. </title> <journal> Artificial Intelligence, </journal> <note> 1996. To appear. </note>
Reference-contexts: To our knowledge, these classes of patterns are more complex than any class of geometric patterns previously studied. Finally, our algorithms are tolerant of concept shift. There is also a relationship between this work and the task of learning from multiple-instance examples <ref> [10] </ref>. In the multiple-instance learning model, the target concept is a boolean function, each example is a collection of instances, and the example (collection) is classified as positive iff at least one of its elements is mapped to positive by the target concept. <p> This class generalizes the class of single axis-parallel boxes with multi-instance examples, which has potential applications in the area of drug discovery <ref> [10] </ref>. We conclude in Section 9. 2 The Landmark Matching Problem In this section we explore in further depth how this work might apply to the landmark matching problem (or other signal processing problems). <p> The continuous version using the L 2 norm was studied by Goldberg [12], yielding a PAC algorithm. While our class is more restrictive, our algorithm is on-line, agnostic, and can handle concept shift. 8 Learning from Multiple-Instance Examples Recently, motivated by drug discovery, Dietterich et al. <ref> [10] </ref> introduced the notion of learning from multiple-instance examples where the target concept is simply a boolean function, each example is a collection of instances, and the example (collection) is classified as positive if and only if at least one of its elements is mapped to 1 by the target concept.
Reference: [11] <author> P. Goldberg, S. A. Goldman, and S. D. Scott. </author> <title> PAC learning of one-dimensional patterns. </title> <journal> Machine Learning, </journal> <volume> 25(1) </volume> <pages> 51-70, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The matching algorithm must determine if the robot is near L (i.e. in a small circle centered around L). Because the visual image may change significantly as small movements around L are made, the pattern matching approach encounters difficulties. Goldberg, Goldman and Scott <ref> [11, 13] </ref> proposed using a learning algorithm to construct an accurate hypothesis for performing landmark matching. They obtained their training data by converting the visual data into one-dimensional geometric patterns. <p> Each example (instance) is a configuration of up to n points from f1; : : : ; sg, where it is labeled according to whether or not it visually resembles the target pattern based on the Hausdorff metric (for example, see Gruber [14]). Goldberg, Goldman and Scott <ref> [11] </ref> gave an Occam-based PAC algorithm for learning the class of one-dimensional geometric patterns from the continuous domain. Following that work, Goldman and Scott [13] gave a statistical query algorithm (and hence a noise-tolerant PAC algorithm) for the same class.
Reference: [12] <author> Paul Goldberg. </author> <title> PAC Learning Geometrical Figures. </title> <type> PhD thesis, </type> <institution> University of Edin-burgh, </institution> <year> 1992. </year>
Reference-contexts: There is at least one of the n points in the instance contained within the width-2 interval defined by each of the k target points. Further we note that Goldberg <ref> [12] </ref> has shown that it is NP-complete to find a sphere in the given metric space (i.e. one-dimensional patterns of points on the line under the Hausdorff metric) consistent with a given set of positive and negative examples of an unknown sphere in the given metric space. <p> The continuous version using the L 2 norm was studied by Goldberg <ref> [12] </ref>, yielding a PAC algorithm.
Reference: [13] <author> S. A. Goldman and S. D. Scott. </author> <title> A theoretical and empirical study of a noise-tolerant algorithm to learn geometric patterns. </title> <booktitle> Machine Learning, </booktitle> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: The matching algorithm must determine if the robot is near L (i.e. in a small circle centered around L). Because the visual image may change significantly as small movements around L are made, the pattern matching approach encounters difficulties. Goldberg, Goldman and Scott <ref> [11, 13] </ref> proposed using a learning algorithm to construct an accurate hypothesis for performing landmark matching. They obtained their training data by converting the visual data into one-dimensional geometric patterns. <p> Goldberg, Goldman and Scott [11] gave an Occam-based PAC algorithm for learning the class of one-dimensional geometric patterns from the continuous domain. Following that work, Goldman and Scott <ref> [13] </ref> gave a statistical query algorithm (and hence a noise-tolerant PAC algorithm) for the same class. <p> We then apply Winnow [23] to obtain our agnostic learning algorithm, and the virtual weight technique of Maass and Warmuth [28] to make our algorithm efficient. In some experimental work performed by Goldman and Scott <ref> [13] </ref> it was found that in moving from the processed one-dimensional visual image to a one-dimensional pattern, too much key information was lost. We define a class of two-dimensional geometric patterns for which the important features from the visual image are incorporated in the two-dimensional pattern. <p> Thus to give even further evidence that the class of one-dimensional patterns is significantly more complex than the union of intervals on the real line, observe that the consistency problem for the latter class is trivial to solve. Goldman and Scott <ref> [13] </ref> gave an efficient algorithm that uses the statistical query model [2, 18] to PAC learn the class of continuous one-dimensional geometric patterns under high noise rates (any rate &lt; 1=2 of classification noise). <p> Thus each concept T 2 T is a collection of concepts from C base . Note that this class is a slight generalization of the discretized and bounded version of the class studied by Goldman and Scott <ref> [13] </ref> since in that paper, all intervals are the same fixed width, whereas here we allow the intervals' widths to vary. The classification of an example X 2 X n with respect to a concept T = ft 1 ; :::; t k g 2 T is defined as follows. <p> algorithm is always efficient and the shift-tolerant algorithm is efficient if Z = O (log c s) for some constant c. 6 Efficient Agnostic Learning of Two-Dimensional Patterns To motivate our definition of a two-dimensional geometric pattern, we now review some findings from the experimental work of Goldman and Scott <ref> [13] </ref>.
Reference: [14] <author> P. M. Gruber. </author> <title> Approximation of convex bodies. </title> <editor> In P. M. Gruber and J. M. Willis, editors, </editor> <title> Convexity and its Applications. </title> <publisher> Brikhauser Verlag, </publisher> <year> 1983. </year>
Reference-contexts: Each example (instance) is a configuration of up to n points from f1; : : : ; sg, where it is labeled according to whether or not it visually resembles the target pattern based on the Hausdorff metric (for example, see Gruber <ref> [14] </ref>). Goldberg, Goldman and Scott [11] gave an Occam-based PAC algorithm for learning the class of one-dimensional geometric patterns from the continuous domain. Following that work, Goldman and Scott [13] gave a statistical query algorithm (and hence a noise-tolerant PAC algorithm) for the same class.
Reference: [15] <author> D. Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Inform. Comput., </journal> <volume> 100(1) </volume> <pages> 78-150, </pages> <month> September </month> <year> 1992. </year> <month> 24 </month>
Reference-contexts: The performance of the on-line learner is measured by the total loss over all trials, which is equivalent to the number of prediction mistakes made when using the discrete loss function. Our on-line learning algorithms are agnostic <ref> [15, 19] </ref> in the sense that they make no assumptions whatsoever about the target concept to be learned. Instead, we compare their performance with the performance of the best hypothesis selected from a comparison or "touchstone" class.
Reference: [16] <author> D. Haussler, M. Kearns, N. Littlestone, and M. K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Inform. Comput., </journal> <volume> 95(2) </volume> <pages> 129-161, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Littlestone showed that it is possible to convert a mistake-bounded algorithm to a PAC algorithm with sample complexity O 1 i ffi + M by drawing a sample and then running the on-line algorithm on the sample, saving all the hypotheses created by the on-line algorithm. Then hypothesis testing <ref> [16] </ref> is used to select the best hypothesis by evaluating them all on a new sample. We repeat his main result here.
Reference: [17] <author> J. Hong, X. Tan, B. Pinette, R. Weiss, and E. Riseman. </author> <title> Image-based homing. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 12(1) </volume> <pages> 38-45, </pages> <year> 1992. </year>
Reference-contexts: Scott of using learning versus pattern matching for the landmark matching problem can be applied to a wide range of data, the rest of their work was specific to the data from an imaging system that generates a one-dimensional array of light intensities (called a signature) taken at eye level <ref> [17, 22, 29, 33] </ref>. The motivation for using one-dimensional data is to reduce the processing time. For some settings, such as an office environment, it seems feasible that the signature taken at eye level is sufficient.
Reference: [18] <author> M. Kearns. </author> <title> Efficient noise-tolerant learning from statistical queries. </title> <booktitle> In Proc. 25th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 392-401. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Goldman and Scott [13] gave an efficient algorithm that uses the statistical query model <ref> [2, 18] </ref> to PAC learn the class of continuous one-dimensional geometric patterns under high noise rates (any rate &lt; 1=2 of classification noise). They also performed an empirical study of how well their algorithm worked on both simulated and real data.
Reference: [19] <author> Michael J. Kearns, Robert E. Schapire, and Linda M. Sellie. </author> <title> Toward efficient agnostic learning. </title> <journal> Machine Learning, </journal> 17(2/3):115-142, 1994. 
Reference-contexts: The performance of the on-line learner is measured by the total loss over all trials, which is equivalent to the number of prediction mistakes made when using the discrete loss function. Our on-line learning algorithms are agnostic <ref> [15, 19] </ref> in the sense that they make no assumptions whatsoever about the target concept to be learned. Instead, we compare their performance with the performance of the best hypothesis selected from a comparison or "touchstone" class.
Reference: [20] <author> J. Kivinen, M. K. Warmuth, and P. Auer. </author> <title> The perceptron algorithm vs. Winnow: Linear vs. logarithmic mistake bounds when few input variables are relevant. </title> <journal> Artificial Intelligence, </journal> <note> 1998. To appear. </note>
Reference-contexts: Another major difference between these algorithms is that Winnow's mistake bound is logarithmic in N whereas the Perceptron algorithm's mistake bound can be linear in N in the worst case <ref> [20] </ref>. Recently Auer and Warmuth [5], in generalizing the work of Littlestone [25], showed that Winnow makes at most O (A + K log N ) mistakes on any sequence of trials where the target K-disjunction makes at most A attribute errors.
Reference: [21] <author> Eun Bae Kong and Thomas G. Dietterich. </author> <title> Error-correcting output coding corrects bias and variance. </title> <booktitle> In Proc. 12th International Conference on Machine Learning, </booktitle> <pages> pages 313-321. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: Here the learner learns a collection of classifiers, each classifier providing one bit of the code for a particular value. ECOCs are used so that multiple codes map to the same value, making the learning algorithm more robust. These methods have a successful empirical history <ref> [6, 8, 9, 36, 21] </ref>. Finally, another interesting direction is to further study the possibilities for applying our techniques to learn other geometric concepts under the multiple-instance model as well as exploring other meaningful rules to classify the multiple-instance examples.
Reference: [22] <author> T. Levitt and D. Lawton. </author> <title> Qualitative navigation for mobile robots. </title> <journal> Artificial Intelligence, </journal> <volume> 44(3) </volume> <pages> 305-360, </pages> <year> 1990. </year>
Reference-contexts: Scott of using learning versus pattern matching for the landmark matching problem can be applied to a wide range of data, the rest of their work was specific to the data from an imaging system that generates a one-dimensional array of light intensities (called a signature) taken at eye level <ref> [17, 22, 29, 33] </ref>. The motivation for using one-dimensional data is to reduce the processing time. For some settings, such as an office environment, it seems feasible that the signature taken at eye level is sufficient.
Reference: [23] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: We then apply Winnow <ref> [23] </ref> to obtain our agnostic learning algorithm, and the virtual weight technique of Maass and Warmuth [28] to make our algorithm efficient. <p> Our belief is that these algorithms will be robust against many types of noise, including those for which they have no known theoretical guarantees. 3 The On-Line, Agnostic Learning Model and Winnow In this paper we consider the on-line (or mistake-bound) learning model <ref> [1, 23] </ref> as applied to concept learning (i.e. the classification of each example is 1 or 0). <p> An important result in this model is Littlestone's on-line noise-tolerant algorithm Winnow <ref> [23] </ref> for learning K-disjunctions of boolean attributes when there is a large number N of total attributes and N AE K. (The N K attributes not in the target K-disjunction are considered irrelevant.) Winnow makes predictions based on a linear threshold function ^y t = 1 if i=1 w i x <p> Note that the mistake bound M need not be known in this mapping. This gives us the following theorem. Theorem 3 <ref> [1, 23] </ref> Winnow with an unknown mistake bound M can be converted to a PAC algorithm with sample complexity M 1 + 2 : The time complexity is O (N ) times the sample complexity. A better bound can be attained if M is known [24].
Reference: [24] <author> N. Littlestone. </author> <title> From on-line to batch learning. </title> <booktitle> In Proc. 2nd Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 269-284, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Using the virtual weights technique will allow our time complexity to be polynomial in the size of the examples and the size of the target concept. It is also well known that learning algorithms in the mistake-bound model can be mapped to PAC algorithms <ref> [1, 24] </ref>. A PAC (probably approximately correct) algorithm [34, 35] is an off-line algorithm that draws examples randomly according to an arbitrary, unknown probability distribution and with probability 1ffi outputs a hypothesis with error *, where the parameters * and ffi are given as inputs to the algorithm. <p> Theorem 3 [1, 23] Winnow with an unknown mistake bound M can be converted to a PAC algorithm with sample complexity M 1 + 2 : The time complexity is O (N ) times the sample complexity. A better bound can be attained if M is known <ref> [24] </ref>. Littlestone showed that it is possible to convert a mistake-bounded algorithm to a PAC algorithm with sample complexity O 1 i ffi + M by drawing a sample and then running the on-line algorithm on the sample, saving all the hypotheses created by the on-line algorithm. <p> Then hypothesis testing [16] is used to select the best hypothesis by evaluating them all on a new sample. We repeat his main result here. Theorem 4 <ref> [24] </ref> Winnow with a known mistake bound 5 M can be converted to a PAC algorithm with sample complexity 1 2 + 4M + 32 ln (M + 2) 2 = O 1 1 + M : 5 Technically, all we require is that M is a known upper bound on <p> It is well known that efficient on-line algorithms can be easily turned into efficient PAC algorithms (Section 3), but not all efficient PAC algorithms have efficient on-line counterparts <ref> [1, 24] </ref>. Thus a robot equipped with this paper's algorithm can learn as it goes, but one using Goldman and Scott's algorithm cannot.
Reference: [25] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 147-156, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Another major difference between these algorithms is that Winnow's mistake bound is logarithmic in N whereas the Perceptron algorithm's mistake bound can be linear in N in the worst case [20]. Recently Auer and Warmuth [5], in generalizing the work of Littlestone <ref> [25] </ref>, showed that Winnow makes at most O (A + K log N ) mistakes on any sequence of trials where the target K-disjunction makes at most A attribute errors.
Reference: [26] <author> N. Littlestone and M. K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: Better bounds can be achieved if we tune Winnow using knowledge of K, Z, and A. One method of tuning Winnow is to apply the weighted majority algorithm, as demonstrated by Littlestone and Warmuth <ref> [26] </ref>. One more issue we must contend with is that a direct implementation of Winnow in our setting requires that the number of attributes (and thus the computation time) be exponential in the number of bits required to represent an instance and a concept. <p> One method of tuning Winnow is to apply the weighted majority algorithm, as demonstrated by Littlestone and Warmuth <ref> [26] </ref>. Note that we need not require the coordinates in each dimension to be integers from f1; : : : ; sg, so long as there are a finite number of them.
Reference: [27] <author> Philip M. Long and Lei Tan. </author> <title> PAC learning axis-aligned rectangles with respect to product distributions from multiple-instance examples. </title> <booktitle> In Proc. 9th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 228-234. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1996. </year>
Reference-contexts: In the multiple-instance learning model, the target concept is a boolean function, each example is a collection of instances, and the example (collection) is classified as positive iff at least one of its elements is mapped to positive by the target concept. Long and Tan <ref> [27] </ref> described an efficient PAC algorithm for learning a single axis-parallel box in Q d from multiple-instance examples under a product distribution where Q denotes the set of rationals and d need not be constant. <p> Their model is primarily motivated by the problem of predicting whether a molecule would bind at a particular site. They argued empirically that axis-parallel rectangles are good hypotheses for this and other similar learning problems. Subsequently, Long and Tan <ref> [27] </ref> described an efficient PAC algorithm for learning a single axis-parallel box in Q d (where Q denotes the set of rationals) from multiple-instance examples if each instance is drawn independently from a product distribution and d need not be constant.
Reference: [28] <author> Wolfgang Maass and Manfred K. Warmuth. </author> <title> Efficient learning with virtual threshold gates. </title> <journal> Information and Computation, </journal> <note> 1998. To appear. </note>
Reference-contexts: We then apply Winnow [23] to obtain our agnostic learning algorithm, and the virtual weight technique of Maass and Warmuth <ref> [28] </ref> to make our algorithm efficient. In some experimental work performed by Goldman and Scott [13] it was found that in moving from the processed one-dimensional visual image to a one-dimensional pattern, too much key information was lost. <p> We circumvent this problem by applying the virtual weight technique of Maass and Warmuth <ref> [28] </ref> to implicitly maintain the weights. The basic idea is to simulate Winnow by grouping 4 Note that we can interpret attribute errors as noise in the attributes or classification noise instead of an agnostic result. <p> We first give a general definition for a class of geometric patterns and show how we apply Winnow. Then we use the virtual weights technique of Maass and Warmuth <ref> [28] </ref> to obtain an efficient agnostic algorithm. 11 5.1 Reduction to Winnow In this section we describe how we convert the problem of learning geometric patterns into the problem of learning a disjunction over a set of variables, for which we can then apply Winnow. <p> We now use the virtual weight technique of Maass and Warmuth <ref> [28] </ref> to implicitly maintain the weights. The basic idea is to simulate Winnow by grouping concepts that "behave alike" into blocks. <p> Note that m depends polynomially on the mistake bound 9 of our algorithm and n, the maximum number of points per example. We group the weights associated with the attributes from A by using an adaptation of Maass and Warmuth's algorithm <ref> [28] </ref> for learning unions of boxes in fixed dimension. (The grouping of the weights for A comp is similar.) The difference is that our examples are configurations of n points instead of single points. Suppose we want to predict the classification of an example X. <p> Removing the exponential dependence on d from our time bounds would be a very difficult task. It is well known (see e.g. Maass and Warmuth <ref> [28] </ref> or Bshouty et al. [7]) that learning unions of at most k d-dimensional boxes (with single-instance examples) in time polynomial in d with X base = f0; 1g d yields an algorithm for learning k-term DNF formulas over d variables in time polynomial in k and d.
Reference: [29] <author> B. Pinette. </author> <title> Image-Based Navigation Through Large-Scaled Environments. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, Amherst, </institution> <year> 1993. </year>
Reference-contexts: Scott of using learning versus pattern matching for the landmark matching problem can be applied to a wide range of data, the rest of their work was specific to the data from an imaging system that generates a one-dimensional array of light intensities (called a signature) taken at eye level <ref> [17, 22, 29, 33] </ref>. The motivation for using one-dimensional data is to reduce the processing time. For some settings, such as an office environment, it seems feasible that the signature taken at eye level is sufficient. <p> Their images (referred to as signatures) consisted of s + 1 distinct light intensity values. (In the data from Pinette <ref> [29] </ref> that they used, s = 359.) Each signature is pre-processed by computing its first derivative and then normalizing it by dividing each of the s derivative values by the difference between the signature's maximum and minimum values.
Reference: [30] <author> L. Pitt and L. Valiant. </author> <title> Computational limitations on learning from examples. </title> <journal> J. ACM, </journal> <volume> 35 </volume> <pages> 965-984, </pages> <year> 1988. </year>
Reference-contexts: So for this concept class it is NP-hard to solve the consistent hypothesis problem, and by applying results of Pitt and Valiant <ref> [30] </ref>, assuming NP 6= RP, we cannot PAC learn C k;n if the hypothesis is constrained to come from C k 0 ;n for any k 0 k. Thus from Theorems 3 and 4, we cannot learn C k;n using C k 0 ;n in the on-line setting either.
Reference: [31] <author> F. Rosenblatt. </author> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psych. Rev., </journal> <volume> 65 </volume> <pages> 386-407, </pages> <year> 1958. </year> <note> (Reprinted in Neurocomputing (MIT Press, 1988).). </note>
Reference-contexts: On a false positive prediction, for each attribute x i that is 1, Winnow demotes the weight w i by dividing it by ff. Winnow is similar to the classical Perceptron algorithm <ref> [31] </ref>, except that the Perceptron algorithm updates its weights additively while Winnow uses multiplicative weight updates. Another major difference between these algorithms is that Winnow's mistake bound is logarithmic in N whereas the Perceptron algorithm's mistake bound can be linear in N in the worst case [20].
Reference: [32] <author> R. E. Schapire. </author> <title> Using output codes to boost multiclass learning problems. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference (ICML '97), </booktitle> <pages> pages 313-321. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1997. </year>
Reference-contexts: To do this, our algorithms need to learn multi-valued (versus only binary) functions. One approach to converting binary function learners to multi-valued function learners is via the use of error-correcting output codes (ECOCs) <ref> [32, 9] </ref>. Here the learner learns a collection of classifiers, each classifier providing one bit of the code for a particular value. ECOCs are used so that multiple codes map to the same value, making the learning algorithm more robust.
Reference: [33] <author> H. Suzuki and S. Arimoto. </author> <title> Visual control of autonomous mobile robot based on self-organizing model for pattern learning. </title> <journal> Journal of Robotic Systems, </journal> <volume> 5(5) </volume> <pages> 453-470, </pages> <year> 1988. </year>
Reference-contexts: Scott of using learning versus pattern matching for the landmark matching problem can be applied to a wide range of data, the rest of their work was specific to the data from an imaging system that generates a one-dimensional array of light intensities (called a signature) taken at eye level <ref> [17, 22, 29, 33] </ref>. The motivation for using one-dimensional data is to reduce the processing time. For some settings, such as an office environment, it seems feasible that the signature taken at eye level is sufficient.
Reference: [34] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Commun. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: It is also well known that learning algorithms in the mistake-bound model can be mapped to PAC algorithms [1, 24]. A PAC (probably approximately correct) algorithm <ref> [34, 35] </ref> is an off-line algorithm that draws examples randomly according to an arbitrary, unknown probability distribution and with probability 1ffi outputs a hypothesis with error *, where the parameters * and ffi are given as inputs to the algorithm.
Reference: [35] <author> L. G. Valiant. </author> <title> Learning disjunctions of conjunctions. </title> <booktitle> In Proceedings of the 9th International Joint Conference on Artificial Intelligence, </booktitle> <volume> vol. 1, </volume> <pages> pages 560-566, </pages> <address> Los Angeles, California, </address> <year> 1985. </year> <booktitle> International Joint Committee for Artificial Intelligence. </booktitle>
Reference-contexts: It is also well known that learning algorithms in the mistake-bound model can be mapped to PAC algorithms [1, 24]. A PAC (probably approximately correct) algorithm <ref> [34, 35] </ref> is an off-line algorithm that draws examples randomly according to an arbitrary, unknown probability distribution and with probability 1ffi outputs a hypothesis with error *, where the parameters * and ffi are given as inputs to the algorithm.
Reference: [36] <author> D. Wettschereck and T. G. Dietterich. </author> <title> Improving the performance of radial basis function networks by learning center locations. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 4, </volume> <pages> pages 1133-1140. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1992. </year> <month> 26 </month>
Reference-contexts: Here the learner learns a collection of classifiers, each classifier providing one bit of the code for a particular value. ECOCs are used so that multiple codes map to the same value, making the learning algorithm more robust. These methods have a successful empirical history <ref> [6, 8, 9, 36, 21] </ref>. Finally, another interesting direction is to further study the possibilities for applying our techniques to learn other geometric concepts under the multiple-instance model as well as exploring other meaningful rules to classify the multiple-instance examples.
References-found: 36

