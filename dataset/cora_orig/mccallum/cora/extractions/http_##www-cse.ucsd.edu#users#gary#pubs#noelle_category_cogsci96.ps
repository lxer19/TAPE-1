URL: http://www-cse.ucsd.edu/users/gary/pubs/noelle_category_cogsci96.ps
Refering-URL: http://www.cse.ucsd.edu/users/gary/
Root-URL: 
Email: fdnoelle,garyg@cs.ucsd.edu  
Title: Modeling Interference Effects In Instructed Category Learning  
Author: David C. Noelle and Garrison W. Cottrell 
Address: La Jolla, CA 92093-0114  
Affiliation: Computer Science Engineering 0114 University of California, San Diego  
Abstract: Category learning is often seen as a process of inductive generalization from a set of class-labeled exemplars. Human learners, however, often receive direct instruction concerning the structure of a category before being presented with examples. Such explicit knowledge may often be smoothly integrated with knowledge garnered by exposure to instances, but some interference effects have been observed. Specifically, errors in instructed rule following may sometimes arise after the repeated presentation of correctly labeled exemplars. Despite perfect consistency between instance labels and the provided rule, such inductive training can drive categorization behavior away from rule following and towards a more prototype-based or instance-based pattern. In this paper we present a general connectionist model of instructed category learning which captures this kind of interference effect. We model instruction as a sequence of inputs to a network which transforms such advice into a modulating force on classification behavior. Exemplar-based learning is modeled in the usual way: as weight modification via backpropagation. The proposed architecture allows these two sources of information to interact in a psychologically plausible manner. Simulation results are provided on a simple instructed category learning task, and these results are compared with human performance on the same task. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, S. W. and Brooks, L. R. </author> <year> (1991). </year> <title> Specializing the operation of an explicit rule. </title> <journal> Journal of Experimental Psychology: General, </journal> <volume> 120(1), </volume> <pages> 3-19. </pages>
Reference: <author> Elman, J. L. </author> <year> (1990). </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14(2), </volume> <pages> 179-211. </pages>
Reference-contexts: Initially, this network must be inductively trained to understand the language of instruction. This may be accomplished using a version of backpropagation through time (BPTT) (Rumelhart et al., 1986) in which error is backpropa-gated for only a single time step, much as is done for Simple Recurrent Networks <ref> (Elman, 1990) </ref>. A training regimen similar to that used by the architecturally similar Sentence Gestalt network (St. John & McClelland, 1990) may be used, requiring an external error signal only at the final output layer.
Reference: <author> Kruschke, J. K. and Erickson, M. A. </author> <year> (1994). </year> <title> Learning of rules that have high-frequency exceptions: New empirical data and a hybrid connectionist model. </title> <editor> In Ram, A. and Eiselt, K. (Eds.), </editor> <booktitle> Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 514-519). </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Alternatively, some hidden units could be architecturally isolated from the instruction inputs, forcing them to encode only similarity information. This would result in a dual route mechanism, similar in general configuration to the rule enhanced ALCOVE model <ref> (Kruschke & Erickson, 1994) </ref>. Categorization instructions would be allowed to modulate only rule-based hidden units, leaving other hidden units unaffected by the structure of the instructional language.
Reference: <author> Luce, R. D. </author> <year> (1963). </year> <title> Detection and recognition. </title> <editor> In Luce, R. D., Bush, R. R., and Galanter, E. (Eds.), </editor> <booktitle> Handbook of Mathematical Psychology, </booktitle> <pages> volume 1 (pp. 103-189). </pages> <address> New York, NY: </address> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: The activation levels at these outputs where normalized into conditional class probabilities using Luce ratios <ref> (Luce, 1963) </ref>. The hidden layer consisted of eight processing elements. The result was a network which produced probabilistic categorization judgements from two continuous features and an encoding of an instructed classification rule (or the absence of such a rule).
Reference: <author> Noelle, D. C. and Cottrell, G. W. </author> <year> (1995). </year> <title> A connectionist model of instruction following. </title> <editor> In Moore, J. D. and Lehman, J. F. (Eds.), </editor> <booktitle> Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 369-374). </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: It appears, in these experiments, as if an exemplar-based inductive learning process is directly interfering with an instruction-based rule application process. The goal of this paper is to demonstrate that our previously proposed connectionist model of instructed learning <ref> (Noelle & Cottrell, 1995) </ref> may capture and account for this interference effect. To this end, we discuss one psychological experiment in which this phenomenon has appeared, review our modeling framework for instructed learning, and present the results of applying our model to the discussed experimental domain. <p> Our goal is to show that an interference effect of this type may be explained by our connectionist model. A Connectionist Model The modeling approach we advocate here is based on our connectionist model of learning by being told <ref> (Noelle & Cot-trell, 1995) </ref>. This model arises from the recognition that the weight update techniques typically used for inductive learning in artificial neural networks are simply too slow to account for the high speed of behavior change which occurs in response to direct instruction.
Reference: <author> Nosofsky, R. M., Clark, S. E., and Shin, H. J. </author> <year> (1989). </year> <title> Rules and exemplars in categorization, identification, and recognition. Journal of Experimental Psychology: Learning, Memory, </title> <journal> and Cognition, </journal> <volume> 15(2), </volume> <pages> 282-304. </pages>
Reference: <author> Plaut, D. C. and McClelland, J. L. </author> <year> (1993). </year> <title> Generalization with componential attractors: Word and nonword reading in an attractor network. </title> <booktitle> In Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 824-829). </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Such novel attractors, corresponding to newly received instructions, come into existence through the componential interaction of basins sculpted via past experience with the instructional language <ref> (Plaut & McClelland, 1993) </ref>. Under this view, advice is seen as a sequence of input activity, presented to a network which transforms such sequences into appropriate behavior. Our proposed general architecture is shown in Figure 2, on the left.
Reference: <author> Rumelhart, D. E., Hinton, G. E., and Williams, R. J. </author> <year> (1986a). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E., McClelland, J. L., and the PDP Research Group (Eds.), </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition (ch. 8). </booktitle> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Shanks, D. R. and St. John, M. F. </author> <year> (1994). </year> <title> Characteristics of dissociable human learning systems. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 17(3), </volume> <pages> 367-447. </pages>
Reference-contexts: Sometimes human subjects presented with labeled exemplars appear to induce explicit classification rules, and sometimes induced category structures are better captured by prototype-based or instance-based representations. Much evidence has been gathered suggesting that these two kinds of category representation result from two dissociable learning mechanisms <ref> (Shanks & St. John, 1994) </ref>, so a question arises as to how these two processes are integrated in common learning tasks. In terms of instructed category learning, this question becomes one of how categorization rules provided by direct instruction interact with exemplar-based knowledge to form a learned category structure.
Reference: <author> St. John, M. F. </author> <year> (1992). </year> <title> Leaning language in the service of a task. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 271-276). </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: By backpropagating error from the final category outputs in this way, the internal representation of instruction sequences, maintained at the plan layer, may be learned in the service of the categorization task <ref> (St. John, 1992) </ref>. Once the network has learned to represent advice at the plan layer, no further weight modifications are needed to exhibit immediate behavior change in response to instruction. This is the point at which induction and instruction become integrated in this model.
Reference: <author> St. John, M. F. and McClelland, J. L. </author> <year> (1990). </year> <title> Learning and applying contextual constraints in sentence comprehension. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 46(1-2), 217-257. </pages>
Reference-contexts: A training regimen similar to that used by the architecturally similar Sentence Gestalt network <ref> (St. John & McClelland, 1990) </ref> may be used, requiring an external error signal only at the final output layer. The output units encode categorization judgements for specific input stimuli in the context of instructions presented at the advice layer.
References-found: 11

