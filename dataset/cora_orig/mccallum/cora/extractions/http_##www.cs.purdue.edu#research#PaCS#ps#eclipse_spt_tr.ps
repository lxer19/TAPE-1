URL: http://www.cs.purdue.edu/research/PaCS/ps/eclipse_spt_tr.ps
Refering-URL: http://www.cs.purdue.edu/research/PaCS/eclipse.html
Root-URL: http://www.cs.purdue.edu
Email: fknop,edm,regog@cs.purdue.edu  vss@mathcs.emory.edu  
Title: Concurrent and Fail-Safe Replicated Simulations on Heterogeneous Networks: An Introduction to EcliPSe  
Author: Felipe Knop Edward Mascarenhas Vernon Rego V. S. Sunderam 
Keyword: concurrent simulation, heterogeneous cluster computation, replication, fault tolerance  
Note: To appear in: Simulation Practice and Theory  Acknowledgements: Research supported in part by NATO-CRG900108, NSF CCR-9102331, ONR 9310233, and ARO-93G0045. The first author was supported by CNPq-Brazil, process number 260059/91.9.  
Address: West Lafayette, Indiana 47907-1398, USA  Atlanta, Georgia 30322, USA  
Affiliation: Department of Computer Sciences Purdue University  Department of Math and Computer Science Emory University  
Abstract: Purdue University Department of Computer Sciences Technical Report 95-014 February 28, 1995 Abstract This paper presents an overview of the ACES parallel software system and, in particular, an introduction to the EcliPSe layer of the system. The ACES system is a fault-tolerant, layered software system for heterogeneous-network based cluster computing. The EcliPSe toolkit, which resides on an upper layer, was constructed specifically for replication-based and domain-decomposition based simulation applications. It is not, however, restricted to simulations and supports any message-passing form of parallel processing. By taking advantage of networks of heterogeneous machines, generally idle workstations, EcliPSe programs can achieve supercomputer level performance with little programming effort. This was a motivating factor in EcliPSe's design. We present an overview of key application-level features in EcliPSe, a new user interface, support for fault-tolerant simulation, and performance results for three simple but large scale and representative experiments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Biles, D. Daniels, and T. O'Donnell, </author> <title> Statistical considerations in simulation on a network of microcomputers, </title> <booktitle> in: Proceedings of the Winter Simulation Conference, </booktitle> <address> San Francisco, CA (1985) 388-393. </address>
Reference-contexts: An alternate and also complementary approach to model distribution is model replication, which is the approach adopted by the EcliPSe toolkit. This fact was already recognized by simulation researchers investigating the statistical consequences of parallel sampling (e.g., see Biles et al <ref> [1] </ref> and Heidelberger [6]). Instead of distributing a single model over n processors, n replications of the same model are made to run on the n distinct processors.
Reference: [2] <author> K. Chung, </author> <title> A Concurrent Composite Computational Model for Stochastic Simulation, </title> <type> Ph.D. Thesis, </type> <institution> Purdue University, West Lafayette, IN, </institution> <year> 1993. </year>
Reference-contexts: In addition, using a two-level protocol shared with Conch, EcliPSe supports a robust form of failure-resilient computing at the user-level. Resident at the uppermost layer, the Sol (Simulation Object Library) system facilitates the construction of simulation models and other parallel applications in a variety of domains <ref> [2, 3] </ref>. Sol is a C++ based library, designed to support the event-scheduling and process-interaction views, based on the object-orient paradigm. Sol provides applications with a variety of simulation event calendars and other data structures for the rapid development of simulation models. 1 A process (e.g.
Reference: [3] <author> K. Chung, J. Sang, and V. Rego, Sol-es: </author> <title> An object-oriented platform for event-scheduled simulations, </title> <booktitle> in Proceedings of The Summer Simulation Conference, </booktitle> <address> Boston, MA, </address> <year> (1993) </year> <month> 972-977. </month>
Reference-contexts: In addition, using a two-level protocol shared with Conch, EcliPSe supports a robust form of failure-resilient computing at the user-level. Resident at the uppermost layer, the Sol (Simulation Object Library) system facilitates the construction of simulation models and other parallel applications in a variety of domains <ref> [2, 3] </ref>. Sol is a C++ based library, designed to support the event-scheduling and process-interaction views, based on the object-orient paradigm. Sol provides applications with a variety of simulation event calendars and other data structures for the rapid development of simulation models. 1 A process (e.g.
Reference: [4] <author> H. Clark and B. McMillin, </author> <title> DAWGS a distributed compute server utilizing idle workstations. </title> <note> Journal of parallel and distributed computing 14 (2) (1992) 175-186. </note>
Reference-contexts: Some cluster-computing systems provide transparent checkpoint and recovery, in the sense that no programming effort is required <ref> [4, 14, 21] </ref>. The drawback of this approach is a heavy checkpoint overhead, since the complete address space of all processes involved must be saved at each checkpoint.
Reference: [5] <author> R.M. Fujimoto, </author> <title> Parallel discrete event simulation, </title> <journal> Communications of the ACM, </journal> <note> 33 (10) (1990) 30-53. </note>
Reference-contexts: To reduce execution times, researchers have suggested some techniques for multiprocessor-based simulation. Considerable attention has been given to distributing a model over a number of processors in order to speed up the generation of a single sample path, in particular for discrete-event simulation <ref> [5] </ref>. Examples of this approach include the conservative [17] and the optimistic [8] protocols of distributed simulation. In addition to the complexities of application-level and system-level software development for distributed simulation, performance is often adversely affected by synchronization overheads intrinsic to distributed systems.
Reference: [6] <author> P. Heidelberger, </author> <title> Discrete event simulations and parallel processing: statistical properties, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <note> 9 (6) (1988) 1114-1132. </note>
Reference-contexts: An alternate and also complementary approach to model distribution is model replication, which is the approach adopted by the EcliPSe toolkit. This fact was already recognized by simulation researchers investigating the statistical consequences of parallel sampling (e.g., see Biles et al [1] and Heidelberger <ref> [6] </ref>). Instead of distributing a single model over n processors, n replications of the same model are made to run on the n distinct processors.
Reference: [7] <author> D. Heller and P. M. Ferguson, </author> <title> Motif Programming Manual for OSF/Motif release 1.2 (O'Reilly & Associates, </title> <address> Sebastopol, CA, </address> <year> 1994). </year>
Reference-contexts: We have found the graphical user interface to be useful for EcliPSe applications. We next describe the EclGen interface, the monitor code generator, and features of the automatically generated code. 2.3.1 EcliPSe Code Generator EclGen is an X/Motif <ref> [7] </ref> based tool that makes use of menus, dialogs, and direct manipulation (point and click) to input an EcliPSe specification, and then generates the EcliPSe data type declarations code and the monitor code that handles those data types.
Reference: [8] <author> D. Jefferson, </author> <title> Virtual time, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <note> 7 (3) (1985) 404-425. </note>
Reference-contexts: Considerable attention has been given to distributing a model over a number of processors in order to speed up the generation of a single sample path, in particular for discrete-event simulation [5]. Examples of this approach include the conservative [17] and the optimistic <ref> [8] </ref> protocols of distributed simulation. In addition to the complexities of application-level and system-level software development for distributed simulation, performance is often adversely affected by synchronization overheads intrinsic to distributed systems.
Reference: [9] <author> F. Knop and V. Rego, </author> <title> Parallel cluster labeling in a network of workstations, </title> <note> Submitted for publication, </note> <institution> Purdue University, West Lafayette, IN, </institution> <year> 1995. </year>
Reference-contexts: Sol and Ariadne provide constructs for process-based simulation, Conch supports generic message-passing distributed programs, and EcliPSe has constructs geared towards replication programs, but also supports more general forms of parallel applications such as that described in <ref> [9] </ref>. EcliPSe's features such as the tree-combining, data diffusing, multiple monitors, and granularity control are essential in avoiding serializing bottlenecks and therefore allow better scalability. Also essential in achieving good scalability are Conch's support for different interconnection schemes, which take advantage of the communication topology to reduce communication times.
Reference: [10] <author> F. Knop, V. Rego, and V. Sunderam, </author> <title> EcliPSe User Manual. </title> <type> Technical report, </type> <institution> Purdue University, West Lafayette, IN, </institution> <year> 1993. </year>
Reference-contexts: For example, suppose that samplers produce an array of 10 double precision numbers for the monitor. The declaration of this data item is simply: eclipse_decls - double type_result <ref> [10] </ref>; - The eclipse decls block defines the region that the preprocessor is supposed to act on. <p> Interfacing the remainder of the application with the code generated by EclGen is simple for EcliPSe applications mainly because these applications are well-structured and belong to a set of basic forms <ref> [10] </ref>. An example structure for an M/GI/1 application is shown in Figure 3. In this figure the eclipse_decls portion of the main () function and the monitor () function are completely generated by EclGen. <p> For EcliPSe applications the monitor must contain code that determines when the computation should terminate. This termination checking function, which is either a user-written function or an EcliPSe (built-in) function, is also specified here. Several built-in functions are available to aid in different types of EcliPSe applications (see <ref> [10] </ref>). The input data file name for the distinct data types read in must also be specified. They may be used to input simulation parameters at run time. Details for each data type include the name, type, diffuse or combine, and grainsize. <p> The termination check function can be provided by the user. For termination policies like auto-scheduling until all work is completed, until a specified confidence level is obtained (see <ref> [10] </ref>) or some other application-specific policy, the users must supply a termination function. Code for timing information is also generated automatically.
Reference: [11] <author> F. Knop, V. Rego, and V. Sunderam, </author> <title> EcliPSe: A system for fault-tolerant replicative computations, </title> <booktitle> in Proceedings of the IEEE/USP International Symposium on High-Performance Computing, </booktitle> <address> S ao Paulo, Brazil (1994) 17-34. </address>
Reference-contexts: The details of how this is accomplished, as well as a more in-depth description of fault tolerance in EcliPSe, are presented in [13]. 4 Performance Measurement EcliPSe applications support a variety of computation structures (see <ref> [11] </ref>) and execute on a number of machine environments. Bottlenecks in a distributed application, however, may impair execution performance, resulting in a waste of computational resources.
Reference: [12] <author> F. Knop, V. Rego, and V. Sunderam, </author> <title> EcliPSe: a system for parallel execution of replication-oriented applications, In preparation, </title> <institution> Purdue University, West Lafayette, </institution> <note> IN. </note>
Reference-contexts: The goal is to demonstrate the utility of some of the main features described in the paper, and to give some indication of EcliPSe's performance on typical applications with different computation structures. Another set of experiments is reported in <ref> [12] </ref>. 5.1 Machines The experiments were conducted on a network of 177 SUN IPC SPARC workstations located at the ENAD laboratories at Purdue University. These machines reside on four distinct local area networks, all connected via a single gateway. <p> Examples of domain-decomposed applications are given in <ref> [12] </ref>. 5.2.1 M/GI/1 queue simulation: replication In this program (hereafter referred to as mg1), each replication simulates an M/GI/1 queue for a fixed number of arrivals. Based on batch-means, the statistics sent to the monitor include mean system delay and maximum number of customers found in the queue. <p> For fewer than 64 processes, the normal combining program was slightly (up to 5%) faster. This happens because of combining overhead imposed on the samplers and also because of delay incurred by samples arriving at the monitor (as explained in <ref> [12] </ref>). For a larger number of processes, the normal 17 combining program was not able to take advantage of the extra samplers, and an explanation for this can be found in Figure 7: the monitor is overloaded with work generated by a high influx of messages.
Reference: [13] <author> F. Knop, V. Rego, V. Sunderam, and A. Ferrari, </author> <title> Failure-resilient computations in the EcliPSe system, </title> <booktitle> in Proceedings of the International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL (1994) III-184-III-187. </address>
Reference-contexts: By taking advantage of the application's structure, EcliPSe programs can often achieve an almost negligible checkpoint overhead, which in turn drastically reduces the fault tolerance performance penalty. The details of how this is accomplished, as well as a more in-depth description of fault tolerance in EcliPSe, are presented in <ref> [13] </ref>. 4 Performance Measurement EcliPSe applications support a variety of computation structures (see [11]) and execute on a number of machine environments. Bottlenecks in a distributed application, however, may impair execution performance, resulting in a waste of computational resources.
Reference: [14] <author> J. Le on, A.L. Fisher, and P. Steenkiste, </author> <title> Fail-safe PVM: a portable package for distributed programming with transparent recovery. </title> <type> Technical Report CMU-CS-93-124, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1993. </year>
Reference-contexts: Some cluster-computing systems provide transparent checkpoint and recovery, in the sense that no programming effort is required <ref> [4, 14, 21] </ref>. The drawback of this approach is a heavy checkpoint overhead, since the complete address space of all processes involved must be saved at each checkpoint.
Reference: [15] <author> E. Mascarenhas and V. Rego, DisplA: </author> <title> A Graphical Display Server for Concurrent Computations, In preparation, </title> <type> Technical report, </type> <institution> Purdue University, West Lafayette, IN, </institution> <year> 1994. </year>
Reference-contexts: The DisplA library provides a user with a simple interface, allowing for calls that can create application specific dialogs and receive input from the user <ref> [15] </ref>. Using the Setup panel and clicking on options available, a user can select/deselect the plotting of histograms for CPU occupation-level, CPU load, in/out packet rate, etc. 14 To enable DisplA, a user simply needs to link the application with the DisplA library.
Reference: [16] <author> E. Mascarenhas and V. Rego, GenA: </author> <title> A GUI for Generation of ACES Applications, In preparation, </title> <type> Technical report, </type> <institution> Purdue University, West Lafayette, </institution> <note> IN. </note>
Reference: [17] <author> J. Misra, </author> <title> Distributed discrete-event simulation, </title> <journal> Computing surveys, </journal> <note> 18 (1) (1986) 39-65. </note>
Reference-contexts: Considerable attention has been given to distributing a model over a number of processors in order to speed up the generation of a single sample path, in particular for discrete-event simulation [5]. Examples of this approach include the conservative <ref> [17] </ref> and the optimistic [8] protocols of distributed simulation. In addition to the complexities of application-level and system-level software development for distributed simulation, performance is often adversely affected by synchronization overheads intrinsic to distributed systems.
Reference: [18] <author> H. Nakanishi, V. Rego, and V. Sunderam, </author> <title> Superconcurrent simulation of polymer chains on heterogeneous networks, 1992 Gordon Bell Prize Paper in: </title> <booktitle> Proceedings of the Fifth High-Performance Computing and Communications Conference: Supercomputing '92, </booktitle> <address> Minneapolis, MN (1992) 561-569. </address>
Reference-contexts: Since its inception, EcliPSe has been successful in demonstrating the practical viability of executing replication-based or domain decomposition-based simulations on heterogeneous networks of processors. Indeed, an early prototype demonstrated price-winning performance (a project <ref> [18] </ref> using the EcliPSe prototype was awarded the 1992 Gordon Bell Prize for price-performance by the IEEE Computer Society.) in the investigation of universal constants in a polymer physics application which executed on a country-wide network of 192 processors.
Reference: [19] <author> V. J. Rego and V. S. Sunderam, </author> <title> Experiments in Concurrent Stochastic Simulation: The EcliPSe Paradigm. </title> <note> Journal of Parallel and Distributed Computing 14 (1) (1992) 66-84. </note>
Reference-contexts: The remainder of the paper is focused on the EcliPSe layer, which is responsible for providing the base for efficient parallel simulations. The present version of EcliPSe is a robust and re-engineered version of the prototype presented in <ref> [19, 22] </ref>, and has already been used in production applications, such as the work described in [20]. A significant feature present in the new system is the capacity for fault-tolerance. Section 2 presents an overview of EcliPSe, highlighting the main features. <p> Based on batch-means, the statistics sent to the monitor include mean system delay and maximum number of customers found in the queue. The regenerative method may also be used (as was done in <ref> [19] </ref>) to estimate these quantities. The monitor utilizes results from independent parallel 15 replications to build a confidence interval for both statistics. Though times between the reporting of samples can be large, the monitor can be overworked if a large number of processes is used.
Reference: [20] <author> M.D. Rintoul, J. Moon, and H. Nakanishi, </author> <title> Statistics of self-avoiding walks on randomly diluted lattice, </title> <journal> Phys. Rev. </journal> <volume> E 49 (1994) 2790-2803. </volume> <pages> 23 </pages>
Reference-contexts: The present version of EcliPSe is a robust and re-engineered version of the prototype presented in [19, 22], and has already been used in production applications, such as the work described in <ref> [20] </ref>. A significant feature present in the new system is the capacity for fault-tolerance. Section 2 presents an overview of EcliPSe, highlighting the main features. Section 3 presents a brief overview of its fault-tolerance features, and Section 4 describes a performance monitoring tool for EcliPSe applications. <p> As an example, a 20-element integer state vector is saved by all samplers at a checkpoint, and then restored in a rollback, with the following declaration: int type_ft_proc <ref> [20] </ref> (ft_proc &lt;state_array&gt;); where state_array is a user-provided pointer to the data being saved. A similar array used for saving and restoring a monitor's state is declared by replacing ft_proc by ft_mon in the type declaration above.
Reference: [21] <author> G.C. Shoja, </author> <title> A distributed facility for load sharing and parallel processing among workstations. </title> <journal> Journal of systems and software, </journal> <note> 14 (3) (1991) 163-172. </note>
Reference-contexts: Some cluster-computing systems provide transparent checkpoint and recovery, in the sense that no programming effort is required <ref> [4, 14, 21] </ref>. The drawback of this approach is a heavy checkpoint overhead, since the complete address space of all processes involved must be saved at each checkpoint.
Reference: [22] <author> V. S. Sunderam and V. J. Rego, </author> <title> EcliPSe: A system for High Performance Concurrent Simulation, </title> <journal> Software-Practice and Experience, </journal> <note> 21 (11) (1991) 1189-1219. </note>
Reference-contexts: 1 Introduction The EcliPSe software system was originally designed to support straightforward and semi-automatic concurrent execution of stochastic simulation applications in a variety of parallel and distributed environments <ref> [22] </ref>. Since its inception, EcliPSe has been successful in demonstrating the practical viability of executing replication-based or domain decomposition-based simulations on heterogeneous networks of processors. <p> The remainder of the paper is focused on the EcliPSe layer, which is responsible for providing the base for efficient parallel simulations. The present version of EcliPSe is a robust and re-engineered version of the prototype presented in <ref> [19, 22] </ref>, and has already been used in production applications, such as the work described in [20]. A significant feature present in the new system is the capacity for fault-tolerance. Section 2 presents an overview of EcliPSe, highlighting the main features.
Reference: [23] <author> B. Topol, Conch: </author> <title> Second generation heterogeneous computing, </title> <type> Technical report, Master thesis, </type> <institution> Department of Math and Computer Science, Emory University, </institution> <address> Atlanta, GA, </address> <year> 1992. </year>
Reference-contexts: Each of the layers hosts a software system that may be used without knowledge of, or simply without explicit use of the other components in the system. A brief description of each of the component layers is given below. The lowermost layer hosts a streamlined software base called Conch <ref> [23] </ref>, providing higher layers with a virtual multiprocessor machine serviced by an efficient interprocess communications library. Given a set of heterogeneous machines and some user-specified topology, Conch builds a powerful multiprocessor environment where processes 1 communicate with the aid of several message-passing primitives.
Reference: [24] <author> L.H. Turcotte, </author> <title> A survey of software environments for exploiting networked computing resources, </title> <type> Technical report, </type> <institution> Engineering Research Center for Computational Field Simulation, Mississippi State University, </institution> <month> June </month> <year> 1993. </year> <pages> APPENDIX </pages>
Reference-contexts: The ACES project is an effort geared towards producing a software base for simulation applications atop cluster computing systems <ref> [24] </ref>, which are systems consisting of heterogeneous networks of workstations and massively parallel hardware multiprocessors.
References-found: 24

