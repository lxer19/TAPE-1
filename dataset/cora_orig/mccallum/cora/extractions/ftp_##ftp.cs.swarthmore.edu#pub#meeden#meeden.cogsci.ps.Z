URL: ftp://ftp.cs.swarthmore.edu/pub/meeden/meeden.cogsci.ps.Z
Refering-URL: http://www.cs.swarthmore.edu/~meeden/
Root-URL: 
Email: meeden@cs.indiana.edu gem@cogsci.indiana.edu blank@cs.indiana.edu  
Title: Emergent Control and Planning in an Autonomous Vehicle  
Author: Lisa Meeden and Gary McGraw and Douglas Blank 
Address: Bloomington, Indiana 47405  
Affiliation: Department of Computer Science Center for  Indiana University  
Note: Appeared in Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society  Research on Concepts and Cognition  
Abstract: We use a connectionist network trained with reinforcement to control both an autonomous robot vehicle and a simulated robot. We show that given appropriate sensory data and architectural structure, a network can learn to control the robot for a simple navigation problem. We then investigate a more complex goal-based problem and examine the plan-like behavior that emerges. 
Abstract-found: 1
Intro-found: 1
Reference: [Ackley and Littman, 1990] <author> Ackley, D. H. and Littman, M. L. </author> <year> (1990). </year> <title> Generalization and scaling in reinforcement learning. </title> <editor> In Touretsky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 550-557. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: There is not necessarily one "right" action for a given situation, and even if there were, it might not be known a priori. In all of our experiments, the control networks were trained with a modified version of the complementary reinforcement back-propagation (CRBP) learning algorithm <ref> [Ackley and Littman, 1990] </ref>. Back-propagation learning requires precise error measures for each output produced by a network. CRBP provides these exact error measures from the abstract reward and punishment signals as follows. A forward propagation of the input values produces a real-valued search vector S.
Reference: [Chapman and Agre, 1987] <author> Chapman, D. and Agre, P. E. </author> <year> (1987). </year> <title> Abstract reasoning as emergent from concrete activity. </title> <editor> In Georgeff, M. P. and Lansky, A. L., editors, </editor> <booktitle> Reasoning about actions and plans: Proceedings of the 1986 6 Workshop, </booktitle> <pages> pages 411-424. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference-contexts: In the next set of experiments we apply these design insights to a more difficult problem. 5.2 The light as food problem Since we believe that abstract reasoning abilities, such as planning, arise developmentally from concrete activity <ref> [Chapman and Agre, 1987] </ref>, a connectionist, autonomous agent controller should also be able to exhibit plan-like behavior if given a more complex problem. For this problem, a goal unit was added to the input layer.
Reference: [Elman, 1990] <author> Elman, J. L. </author> <year> (1990). </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 179-212. </pages>
Reference-contexts: Activations from the hidden layer on the previous time step are copied into the context units directly. The simple recurrence of the context units allows the network to have a limited short-term memory of its past states <ref> [Elman, 1990] </ref>. We refer to the simple recurrent networks as SRNs and the feed-forward networks (without context memory) as FFNs. The four output units of the standard network determine what the activity of the motors will be for the next time step.
Reference: [Maes, 1990] <author> Maes, P. </author> <year> (1990). </year> <title> Guest editorial: Designing autonomous agents. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> (6):1-2. 
Reference-contexts: Some consensus exists about how to design autonomous agents. There should be a relatively direct coupling between perception and action, control should be distributed and decentralized, and most importantly, there should be a dynamic interaction between the environment and the agent <ref> [Maes, 1990] </ref>. However, no such consensus exists on the best method to implement these design features. Connectionist networks can easily accommodate all these design features and we believe they can be effective mechanisms for controlling autonomous agents.
Reference: [Martin, 1992] <author> Martin, F. </author> <year> (1992). </year> <title> Mini board 2.0 technical reference. </title> <publisher> MIT Media Lab, </publisher> <address> Cambridge MA 02139. </address>
Reference-contexts: Similarly, we can evaluate the utility of contextual memory and different training subtasks such as auto-association and prediction. 3. Carbot|an autonomous robot 3.1 The autonomous vehicle Our robot, called carbot, is a modified toy car (6 fi 9 inches) controlled by a programmable mini-board (designed by <ref> [Martin, 1992] </ref>). Carbot was inexpensive to build, primarily because it makes use of primitive sensors|no lasers, video, or sonar. It has two servomotors; one controls forward and backward motion and the other steering.
Reference: [Russell and Wefald, 1991] <author> Russell, S. and Wefald, E. </author> <year> (1991). </year> <title> Do the Right Thing: Studies in Limited Rationality. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address> <month> 7 </month>
Reference-contexts: Such an agent is autonomous to the extent that its behavior is determined by its immediate inputs and past experience, rather than by its built-in control <ref> [Russell and Wefald, 1991] </ref>. We are interested in investigating the cognitive capabilities of autonomous agents. We believe that cognitive behavior can emerge from the reactive, situated activity of autonomous agents. Some consensus exists about how to design autonomous agents.
References-found: 6

