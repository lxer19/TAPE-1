URL: http://www.cs.berkeley.edu/~kkeeton/Papers/isca98-distribute-final.ps
Refering-URL: http://www.cs.berkeley.edu/~kkeeton/Papers/index.html
Root-URL: 
Title: Abstract  
Abstract: Commercial applications are an important, yet often overlooked, workload with significantly different characteristics from technical workloads. The potential impact of these differences is that computers optimized for technical workloads may not provide good performance for commercial applications, and these applications may not fully exploit advances in processor design. To evaluate these issues, we use hardware counters to measure architectural features of a four-processor Pentium Pro-based server running a TPC-C-like workload on an Informix database. We examine the effectiveness of out-of-order execution, branch prediction, speculative execution, superscalar issue and retire, caching and multiprocessor scaling. We find that out-of-order execution, superscalar issue and retire, and branch prediction are not as effective for database workloads as they are for technical workloads, such as SPEC. We find that caches are effective at reducing processor traffic to memory; even larger caches would be helpful to satisfy more data requests. Multiprocessor scaling of this workload is good, but even modest bus utilization degrades application memory latency, limiting database throughput. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Barroso and K. G harachorloo. </author> <title> System design considerations for a commercial application environment, </title> <booktitle> presented at the First Workshop on Computer Architecture Evaluation using Commercial Workloads (CAECW 98) , in conjunction with the Fourth High Performance Computer Architecture Conference (HPCA-4), </booktitle> <month> February </month> <year> 1998. </year>
Reference-contexts: Several recent studies began the examination of the architectural impacts of transaction processing database workloads for symmetric multiprocessors. Most of the studies have focused on some variation of the now-defunct DebitCredit benchmark, also known in various incarnations as TP1, TPC-A, and TPC-B <ref> [1] </ref> [5] [15] [21] [24] [26]. (This benchmark has been withdrawn by the Transaction Processing Council.) A few have examined the more complex TPC-C order-entry workload [6] [15]. Only two of these papers have explored the effectiveness of out-of-order execution for the TPC-B workload [1] [24]. <p> incarnations as TP1, TPC-A, and TPC-B <ref> [1] </ref> [5] [15] [21] [24] [26]. (This benchmark has been withdrawn by the Transaction Processing Council.) A few have examined the more complex TPC-C order-entry workload [6] [15]. Only two of these papers have explored the effectiveness of out-of-order execution for the TPC-B workload [1] [24]. None examine the effectiveness of out-of-order processors for TPC-C. In general, we observe that these papers corroborate our findings, with a few exceptions. <p> Several other recent studies indicate that both larger (e.g., up to 8 MB L2) and more associative (e.g., up to four-way) caches, with longer cache lines (e.g., 64 to 128 bytes), are beneficial to OLTP workloads, including TPC-C <ref> [1] </ref> [15] [24]. Our conversations with database experts suggest that the instruction stream can be effectively cached for all commercially available databases. Data accesses are more difficult to absorb, however, because the data footprint is much (e.g., up to an order of magnitude [15]) larger than the instruction footprint. <p> Other researchers have demonstrated some execution time improvements from out-of-order and increasing issue width for TPC-B <ref> [1] </ref> [24]. [24] reports only a modest 25% speedup from out-of-order, due predominantly to the high percentage of I/O-induced idle time due to their undercon figured simulated disk system. 6 Multiprocessor scaling issues In this section, we explore the scalability of the Pentium Pro architecture for running database workloads as the <p> Particularly problematic are cache misses to dirty data in other processors caches <ref> [1] </ref> [17]. This difficulty arises in some architectures because the dirty data must be implicitly written back to memory before being read into the requesting processors cache. <p> As the cache size increases to up to 8 MB, the percentage could be quite large. Indeed, Barroso and Gharachorloo report that roughly 60% of misses require a cacheto-cache transfer for dirty data for an 8 MB cache <ref> [1] </ref>. 6.4 Is the fourstate (MESI) invalidation-based cache coherence protocol worthwhile for OLTP? Cache lines may be in one of four states in this protocol: modified (M), exclusive (E), shared (S), or invalid (I). Some coherence protocols dont distinguish between exclusive (exclusive clean) and modified (exclusive dirty).
Reference: [2] <author> D. Bhandarkar and J. </author> <title> D ing. Performance characterization of the Pentium Pro processor. </title> <booktitle> In Proc. of HPCA-3 , Febru-ary, </booktitle> <year> 1997. </year>
Reference-contexts: The Pentium Pro retires up to three mops per clock cycle, yielding a theoretical minimum cycles per mop (CPm) of 0.33. A more detailed description of the Pentium Pros architectural features can be found in <ref> [2] </ref> [3] [8] [11] [19]. We will also present additional details in subsequent sections, when discussing our measurement results. 2.4 Software architecture We measured a tuned prototype version of Informix Online Dynamic Server [10], running on Windows NT 4.0 with service pack 3. <p> The remaining time is spent in system mode, with less than 1% idle time. Considering this ~78%/~22% breakdown, we can compute an overall CPI for the system of 3.39. In contrast, the majority of the SPEC 95 programs have a CPI between 0.5 and 1.5 on the Pentium Pro <ref> [2] </ref>. Table 3 presents the cycles per macroinstruction, CPI, and the cycles per microinstruction, CPm, for the database and the operating system. We can decompose the monolithic CPI numbers by determining computation and stall cycles. <p> Instruction-related stalls count the number of cycles instruction fetch is stalled for any reason, including L1 instruction cache misses, ITLB misses, ITLB faults, and other minor stalls <ref> [2] </ref> [11]. Putting these components together, we compute a CPI value that very closely approximates the measured value. For the database, our estimates are within 3% to 5% of the measured value; our operating system estimates are typically within 10%. <p> In all three cases, the database experiences a high percentage (e.g., 60 - 75%) of cycles where zero instructions (or mops) are decoded or retired. In contrast, the SPEC integer programs with high L2 cache miss rates show many fewer cycles (i.e., 35% to 51%) with no instructions decoded <ref> [2] </ref>. Similar behavior is exhibited for SPEC program retirement profiles. Since there is only a modest benefit from the triple-instruction-decode and -retire cycles, this workload may not need a machine with such wide superscalar macroinstruction decode and retire capabilities. <p> Macroinstruction retirement profile. In the Pentium Pro, up to three x86 instructions can be retired in a single cycle. average number of mops per macroinstruction is around 1.35 for the SPEC programs <ref> [2] </ref>. This implies that the database utilizes more complex x86 instructions than the SPEC programs do. 5.2 How effective is branch prediction? Branch behavior for the database and operating system is shown in Table 10. Branches comprise about 21% of database instructions. <p> This ratio is in contrast to the SPEC workloads, where all programs except one integer program exhibit a BTB miss ratio of less than about 30%. Most SPEC BTB miss ratios are well below 15% <ref> [2] </ref>. One reason for this branch and BTB behavior is that the compilation process used for the database application employed only traditional compiler optimization techniques, but did not employ more advanced optimization techniques, such as profile-based optimization. <p> Finally, we note that the speculative execution factor, or the number of macroinstructions decoded divided by the macroinstructions retired, is 1.4 for the database. The speculative execution factor for nearly all SPEC programs is between 1 and 1.3 <ref> [2] </ref>. 5.3 Is out-of-order execution successful at hiding stalls? The Pentium Pro implements dynamic execution using an out-of-order, speculative execution engine, which employs register renaming and non-blocking caches. <p> Thus, out-of-order execution is somewhat effectively overlapping the CPI components to achieve a lower actual CPI. In contrast, the CPI of SPEC programs is about 20% to 50% lower than the individual components due to overlapped execution <ref> [2] </ref>. Since fewer of these components are being overlapped for the database workload, we conclude that out-of-order and speculative execution provide less value for database workloads than for SPEC workloads.
Reference: [3] <author> R. P. Colwell and R. L. Steck. </author> <title> A 0.6um BiCMOS processor with dynamic execution, </title> <booktitle> In International Solid State Circuits Conference (ISSCC) Digest of Technical Papers , February 1995, </booktitle> <pages> pages 176-177. </pages>
Reference-contexts: The Pentium Pro retires up to three mops per clock cycle, yielding a theoretical minimum cycles per mop (CPm) of 0.33. A more detailed description of the Pentium Pros architectural features can be found in [2] <ref> [3] </ref> [8] [11] [19]. We will also present additional details in subsequent sections, when discussing our measurement results. 2.4 Software architecture We measured a tuned prototype version of Informix Online Dynamic Server [10], running on Windows NT 4.0 with service pack 3.
Reference: [4] <author> D. Culler and J. P. Singh. </author> <booktitle> Parallel Computer Architecture: </booktitle>
References-found: 4

