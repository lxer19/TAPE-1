URL: http://www.cs.tamu.edu/faculty/yen/publications/tsmc-pap.ps
Refering-URL: http://www.cs.tamu.edu/faculty/yen/publications/index.html
Root-URL: http://www.cs.tamu.edu
Title: A Hybrid Approach to Modeling Metabolic Systems Using Genetic Algorithm and Simplex Method  
Author: John Yen MEMBER, IEEE* James C. Liaoy Bogju Lee* David Randolph* 
Address: College Station, TX 77843-3112 yDepartment  College Station, TX 77843-3122  
Affiliation: Robotics, and Intelligent Systems Research, Department of Computer Science, Texas A&M University,  of Chemical Engineering, Texas A&M University,  
Note: to appear in IEEE Transactions on Systems, Man, and Cybernetics. *Center for Fuzzy Logic,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K. A. Dejong, </author> <title> Analysis of the behavior of a class of genetic adaptive systems, </title> <type> PhD thesis, </type> <institution> Department of Computer and Communication Sciences, University of Michigan, </institution> <year> 1975. </year>
Reference-contexts: They operate on a set of solutions rather than on one solution, hence multiple frontiers are searched simultaneously. The only feedback used by the genetic algorithm is the fitness evaluation. The GA has been shown to be an effective search techniques on a wide range of difficult optimization problems <ref> [1, 2, 22, 23] </ref>. 8 A.1 Real-coded GA A real-coded GA is a genetic algorithm representation that uses floating point [24]. A chromosome in real-coded GA becomes a vector of floating point numbers. <p> It has been shown that ASA outperformed GA on De Jong's test functions [34]. IV. Integrating Genetic Algorithms and the Simplex Method While genetic algorithms (GAs) have shown to be effective for solving a wide range of optimization problems <ref> [1] </ref>, its convergence speed is typically much slower than local optimization techniques. It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . <p> Our experiments indicated that our simplex-GA hybrid is superior to all other four alternative methods for the sin maximization problem. VII. Application to De Jong's F5 Function Minimization Problem We further tested our simplex-GA hybrid using De Jong's F5 function minimization problem <ref> [1] </ref>.
Reference: [2] <author> D. E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning, </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: They operate on a set of solutions rather than on one solution, hence multiple frontiers are searched simultaneously. The only feedback used by the genetic algorithm is the fitness evaluation. The GA has been shown to be an effective search techniques on a wide range of difficult optimization problems <ref> [1, 2, 22, 23] </ref>. 8 A.1 Real-coded GA A real-coded GA is a genetic algorithm representation that uses floating point [24]. A chromosome in real-coded GA becomes a vector of floating point numbers. <p> This is achieved by combining Equations 3 and 5 into the following equation: X p = X + ff (X X w ) (6) where ff is a random variable taking its value from the interval <ref> [0, 2] </ref> based on a predetermined probability distribution. A probability distribution used in our application is a triangular probability density function that peaks at 1, and reaches zero probability at 0 and 2 respectively. <p> This has often been referred to as staged hybrid in the literature [16]. G-bit Improvement G-bit improvement is one of the pipelining hybrids that uses a simple local optimization method by searching the neighbors of the best chromosomes in each generation <ref> [2] </ref>. The original idea of G-bit improvement on binary GA is as follows: 1. Select one or more of the best strings from the current population. 2. Sweep bit by bit, performing successive one-bit changes to the subject string or strings, retaining the better of the last two alternatives. 3.
Reference: [3] <author> H. Kargupta and R. E. Smith, </author> <title> "System identification with evolving polynomial networks," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year>
Reference: [4] <author> K. Kristinnson and G. A. Dumont, </author> <title> "System identification and control using genetic algorithms," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 22, no. 5, </volume> <pages> pp. 1033-1046, </pages> <year> 1992. </year>
Reference: [5] <author> H. Iba, T. Kurita, H. deGaris, and T. Sato, </author> <title> "System identification using structured genetic algorithms," </title> <booktitle> In Proceedings of 5th International Conference on Genetic Algorithms, </booktitle> <address> Urbana-Champaign, IL, </address> <month> July </month> <year> 1993. </year>
Reference: [6] <author> D. M. Etter, M. J. Hicks, and K. H. Cho, </author> <title> "Recursive adaptive filter design using an adaptive genetic algorithm," </title> <booktitle> In Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 82), </booktitle> <volume> volume 2, </volume> <pages> pp. 635-638, </pages> <address> Paris, France, </address> <month> May </month> <year> 1982. </year>
Reference: [7] <author> S. Uckun, S. Bagchi, and K. Kawamura, </author> <title> "Managing genetic search in job shop scheduling," </title> <journal> IEEE Expert, </journal> <volume> vol. 8, no. 5, </volume> <pages> pp. 15-24, </pages> <year> 1993. </year>
Reference: [8] <author> A. B. Conru, </author> <title> "A genetic approach to the cable harness routing problem," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference: [9] <author> D. P. Kwok and F. Sheng, </author> <title> "Genetic algorithm and simulated annealing for optimal robot arm pid control," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference: [10] <author> D. Park and A. Kandel, </author> <title> "Genetic-based new fuzzy reasoning models with application to fuzzy control," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 24, no. 1, </volume> <pages> pp. 39-47, </pages> <year> 1994. </year>
Reference: [11] <author> T. Smith and K. A. DeJong, </author> <title> "Genetic algorithms applied to the calibration of information driven models of us migration patterns," </title> <booktitle> In Proceedings of 12th annual Pittsburgh Conference on Modeling and Simulation, </booktitle> <pages> pp. 955-959, </pages> <address> Pittsburgh, PA, </address> <year> 1981. </year>
Reference: [12] <author> D. J. Janson and J. F. Frenzel, </author> <title> "Training product unit neural networks with genetic algorithms," </title> <journal> IEEE Expert, </journal> <volume> vol. 8, no. 5, </volume> <pages> pp. 26-33, </pages> <year> 1993. </year>
Reference: [13] <author> M. F. Bramlette, </author> <title> "Finding maximum flow with random and genetic search," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference: [14] <author> P. S. de Souza and S. N. Talukdar, </author> <title> "Genetic algorithm in asynchronous teams," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 392-397, </pages> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: V SUCDH d (F U M ARAT E)=dt = V SUCDH V F UM d (M ALARAT E)=dt = V F UM V MDH Table 2: ODE's of glucose metabolic model 6 (a) 7 combining a GA and a local search technique into a hybrid approach often produces certain benefits <ref> [16, 14, 15, 21] </ref>. This is because a hybrid approach can combine the merits of the GA with those of a local search technique. Because of the GA, a hybrid approach is less likely to be trapped in a local optimum than a local search technique. <p> It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum. <p> The A-Teams (Asynchronous Teams) methodology describes the first kind of combination by mating the GA with Newton's Method <ref> [14] </ref>. A.3 Hierarchical Hybrids A hierarchical hybrid GA uses a GA and another optimization technique at two different levels of an optimization problem. An example of hierarchical hybrid is the hybrid of the genetic algorithm and the Multivariate Adaptive Regression Splines (MARS) to create the G/SPLINES algorithm [15].
Reference: [15] <author> D. Rogers, "G/SPLINES: </author> <title> A hybrid of Friedman's multivariate adaptive regression splines (MARS) algorithm with Holland's genetic algorithm," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 384-391, </pages> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year> <month> 41 </month>
Reference-contexts: V SUCDH d (F U M ARAT E)=dt = V SUCDH V F UM d (M ALARAT E)=dt = V F UM V MDH Table 2: ODE's of glucose metabolic model 6 (a) 7 combining a GA and a local search technique into a hybrid approach often produces certain benefits <ref> [16, 14, 15, 21] </ref>. This is because a hybrid approach can combine the merits of the GA with those of a local search technique. Because of the GA, a hybrid approach is less likely to be trapped in a local optimum than a local search technique. <p> It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum. <p> A.3 Hierarchical Hybrids A hierarchical hybrid GA uses a GA and another optimization technique at two different levels of an optimization problem. An example of hierarchical hybrid is the hybrid of the genetic algorithm and the Multivariate Adaptive Regression Splines (MARS) to create the G/SPLINES algorithm <ref> [15] </ref>. In this 13 hierarchical hybrid, the GA searches for the best structure of a spline model at a high level, whereas the parameters of the spline model are computed using regression.
Reference: [16] <author> K. E. Mathias, L. D. Whitley, C. Stork, and T. Kusuma, </author> <title> "Staged hybrid genetic search for seismic data imaging," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pp. 356-361, </pages> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: V SUCDH d (F U M ARAT E)=dt = V SUCDH V F UM d (M ALARAT E)=dt = V F UM V MDH Table 2: ODE's of glucose metabolic model 6 (a) 7 combining a GA and a local search technique into a hybrid approach often produces certain benefits <ref> [16, 14, 15, 21] </ref>. This is because a hybrid approach can combine the merits of the GA with those of a local search technique. Because of the GA, a hybrid approach is less likely to be trapped in a local optimum than a local search technique. <p> Although local optimization in a hybrid often results in a faster convergence, it has been shown that too much local optimization can interfere with the search for a global optimum by drawing the genetic algorithm's attention to local optima too quickly, leading to premature convergence <ref> [16] </ref>. Thus, while local optimization might improve the speed of the analysis, it may also reduce the quality of the final solution found. Thus, designing a hybrid approach for an application involves a careful analysis of these tradeoffs. <p> This has often been referred to as staged hybrid in the literature <ref> [16] </ref>. G-bit Improvement G-bit improvement is one of the pipelining hybrids that uses a simple local optimization method by searching the neighbors of the best chromosomes in each generation [2]. The original idea of G-bit improvement on binary GA is as follows: 1.
Reference: [17] <author> H. Ishibuchi, N. Yamamoto, T. Murata, and H. Tanaka, </author> <title> "Genetic algorithms and neighborhood search algorithms for fuzzy flowshop scheduling problems," </title> <journal> Fuzzy Sets and Systems, </journal> <volume> vol. 67, no. 1, </volume> <pages> pp. 81-100, </pages> <year> 1994. </year>
Reference-contexts: It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [18] <author> J. Yen, J. C. Liao, D. Randolph, and B. Lee, </author> <title> "A hybrid approach to modeling metabolic systems using genetic algorithm and simplex method," </title> <booktitle> In Proceedings of the 11th IEEE Conference on Artificial Intelligence for Applications (CAIA95), </booktitle> <pages> pp. 277-283, </pages> <address> Los Angeles, CA, </address> <month> Feburary </month> <year> 1995. </year>
Reference-contexts: B.2 Our Elite-based Simplex-GA Hybrid We developed an alternative simplex-GA hybrid independently by applying a concurrent version of probabilistic simplex operator to top ranking chromosomes <ref> [18] </ref>. Hence, our approach is based on the elite-based hybrid GA architecture. Concurrent Simplex A concurrent simplex is very much like the classical simplex methods with one minor difference.
Reference: [19] <author> J. A. Nelder and R. Mead, </author> <title> "A simplex method for function minimization," </title> <journal> Computer Journal, </journal> <volume> vol. 7, </volume> <pages> pp. 308-313, </pages> <year> 1965. </year>
Reference-contexts: B.2 Nelder-Mead Simplex Method Nelder and Mead developed a modification to the basic simplex method that allows the procedure to adjust its search step according to the evaluation result of the new point generated <ref> [19] </ref>. This is achieved in three ways.
Reference: [20] <author> J. Renders and S. Flasse, </author> <title> "Hybrid methods using genetic algorithms for global optimization," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 26, no. 2, </volume> <pages> pp. 243-258, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Consequently, they are less likely to be trapped in local optima, but their computational cost is higher. The distinction between local search methods and global search methods is referred to as the "exploitation-exploration" trade-off in Renders' recent work <ref> [20] </ref>. While the global search methods often focus on "exploration", the local search methods focus on "exploitation". Like most global search methods, genetic algorithms (GAs) are not easily entrapped in local minima. On the other hand, they typically converge slowly. <p> It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [21] <author> D. B. McGarrah and R. S. Judson, </author> <title> "Analysis of the genetic algorithm method of molecular conformation determination," </title> <journal> Journal of Computational Chemistry, </journal> <volume> vol. 14, no. 11, </volume> <pages> pp. 1385-1395, </pages> <year> 1993. </year>
Reference-contexts: V SUCDH d (F U M ARAT E)=dt = V SUCDH V F UM d (M ALARAT E)=dt = V F UM V MDH Table 2: ODE's of glucose metabolic model 6 (a) 7 combining a GA and a local search technique into a hybrid approach often produces certain benefits <ref> [16, 14, 15, 21] </ref>. This is because a hybrid approach can combine the merits of the GA with those of a local search technique. Because of the GA, a hybrid approach is less likely to be trapped in a local optimum than a local search technique. <p> It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [22] <author> J. H. Holland, </author> <title> Adaptation in Natural and Artificial Systems, </title> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: Because we will compare our approach with Adaptive Simulated Annealing at a later point, we also review the basics of simulated annealing. A. Genetic Algorithms Genetic algorithms are global search and optimization techniques modeled from natural genetics, exploring search space by incorporating a set of candidate solutions in parallel <ref> [22] </ref>. A genetic algorithm (GA) maintains a population of candidate solutions where each solution is usually coded as a binary string called a chromosome. A chromosome also referred to as a genotype encodes a parameter set (i.e., a candidate solution) for a set of variables being optimized. <p> They operate on a set of solutions rather than on one solution, hence multiple frontiers are searched simultaneously. The only feedback used by the genetic algorithm is the fitness evaluation. The GA has been shown to be an effective search techniques on a wide range of difficult optimization problems <ref> [1, 2, 22, 23] </ref>. 8 A.1 Real-coded GA A real-coded GA is a genetic algorithm representation that uses floating point [24]. A chromosome in real-coded GA becomes a vector of floating point numbers. <p> At the end of sweep, insert the best structure (or k-best structures) into the population and continue the normal genetic search. 3 The underlying foundation of this search strategy is Holland's Schema Theory <ref> [22] </ref>. 4 These four categories are not mutually exclusive, because a specific hybrid approach can belong to multiple categories.
Reference: [23] <author> Z. Michalewicz, </author> <title> Genetic Algorithms + Data Structures = Evolution Programs, </title> <publisher> Springer Verlag, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: They operate on a set of solutions rather than on one solution, hence multiple frontiers are searched simultaneously. The only feedback used by the genetic algorithm is the fitness evaluation. The GA has been shown to be an effective search techniques on a wide range of difficult optimization problems <ref> [1, 2, 22, 23] </ref>. 8 A.1 Real-coded GA A real-coded GA is a genetic algorithm representation that uses floating point [24]. A chromosome in real-coded GA becomes a vector of floating point numbers. <p> We test it using De Jong's F5 function minimization problem in the 23 24 25 next section. The testbed used in this section is a function maximization problem used by Renders and Bersini [35], which is actually an instance of a function family introduced by Michalewicz in <ref> [23] </ref>: f (~x) = i=1 i fi x 2 where x i 2 [0; ]. We chose the function maximization problem because there are many (exactly N !) local minima in this function. As m grows, finding maxima of this function becomes more and more difficult.
Reference: [24] <author> C. Z. Janikow and Z. Michalewicz, </author> <title> "An experimental comparison of binary and floating point representation in genetic algorithms," </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 31-36, </pages> <address> San Diego, CA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: The GA has been shown to be an effective search techniques on a wide range of difficult optimization problems [1, 2, 22, 23]. 8 A.1 Real-coded GA A real-coded GA is a genetic algorithm representation that uses floating point <ref> [24] </ref>. A chromosome in real-coded GA becomes a vector of floating point numbers. With some modifications of genetic operators, real-coded GAs have resulted in better performance than binary-coded GA for certain problems [24]. We briefly describe below some modified genetic operators recommended for real-coded GA. <p> 22, 23]. 8 A.1 Real-coded GA A real-coded GA is a genetic algorithm representation that uses floating point <ref> [24] </ref>. A chromosome in real-coded GA becomes a vector of floating point numbers. With some modifications of genetic operators, real-coded GAs have resulted in better performance than binary-coded GA for certain problems [24]. We briefly describe below some modified genetic operators recommended for real-coded GA. The crossover operator of a real-coded GA is analogous to that of binary-coded GA except that its crossover points fall between genes (i.e., encoded parameters). Two mutation operators have been proposed for real-coded GA.
Reference: [25] <author> J. Kowalik and M. R. Osborne, </author> <title> Methods for Unconstrained Optimization Problems, </title> <address> New York: </address> <publisher> American Elsevier, </publisher> <year> 1968. </year>
Reference-contexts: We then describe two modifications to the basic simplex method. Before we elaborate on simplex method, we should point out that another kind of local search methods is the gradient-based method, which uses the gradient of the function being optimized as the promising search direction <ref> [25] </ref>. Examples of common gradient methods include steepest descent [26], Newton strategies [27], Powell's version of conjugate directions [28], and Hooke and Jeeves' pattern search [29, 27].
Reference: [26] <author> R. W. Daniels, </author> <title> An Introduction to Numerical Methods and Optimization Techniques, </title> <publisher> North-Holland, </publisher> <address> New York, NY, </address> <year> 1978. </year>
Reference-contexts: Before we elaborate on simplex method, we should point out that another kind of local search methods is the gradient-based method, which uses the gradient of the function being optimized as the promising search direction [25]. Examples of common gradient methods include steepest descent <ref> [26] </ref>, Newton strategies [27], Powell's version of conjugate directions [28], and Hooke and Jeeves' pattern search [29, 27].
Reference: [27] <author> H. P. Schwefel, </author> <title> Numerical optimization of computer models, </title> <publisher> John Wiley & Sons, </publisher> <year> 1981. </year>
Reference-contexts: Before we elaborate on simplex method, we should point out that another kind of local search methods is the gradient-based method, which uses the gradient of the function being optimized as the promising search direction [25]. Examples of common gradient methods include steepest descent [26], Newton strategies <ref> [27] </ref>, Powell's version of conjugate directions [28], and Hooke and Jeeves' pattern search [29, 27]. <p> Examples of common gradient methods include steepest descent [26], Newton strategies [27], Powell's version of conjugate directions [28], and Hooke and Jeeves' pattern search <ref> [29, 27] </ref>.
Reference: [28] <author> M. J. D. Powell, </author> <title> "An efficient method for finding the minimum of a function of several variables without calculating derivatives," </title> <journal> Computer Journal, </journal> <volume> vol. 7, </volume> <pages> pp. 155-162, </pages> <year> 1964. </year>
Reference-contexts: Examples of common gradient methods include steepest descent [26], Newton strategies [27], Powell's version of conjugate directions <ref> [28] </ref>, and Hooke and Jeeves' pattern search [29, 27].
Reference: [29] <author> R. Hooke and T. A. Jeeves, </author> <title> "Direct search solution of numerical and statistical problems," </title> <journal> Journal of the ACM, </journal> <volume> vol. 8, </volume> <pages> pp. 212-229, </pages> <year> 1961. </year>
Reference-contexts: Examples of common gradient methods include steepest descent [26], Newton strategies [27], Powell's version of conjugate directions [28], and Hooke and Jeeves' pattern search <ref> [29, 27] </ref>.
Reference: [30] <author> W. Spendley, G. R. Hext, and F. R. Himsworth, </author> <title> "Sequential application of simplex designs in optimization and evolutionary operation," </title> <journal> Technometrics, </journal> <volume> vol. 4, </volume> <pages> pp. 441-461, </pages> <year> 1962. </year>
Reference-contexts: B.1 Basic Simplex Method The basic simplex method was first introduced by Spendley et. al <ref> [30] </ref>. A simplex is defined by a number of points equal to one more than the number of dimensions of the search space.
Reference: [31] <author> S. Kirkpatrick, C. D. Galatti, and M. P. Vecchi, </author> <title> "Optimization by simulated annealing," </title> <journal> Science, </journal> <volume> vol. 220, </volume> <pages> pp. 671-680, </pages> <year> 1983. </year>
Reference-contexts: It may also facilitate the fine-tuning of solutions around an optimum. C. Simulated Annealing The basic idea of simulated annealing technique is that it tries to avoid being trapped in local minima by making an "uphill" move (for a minimization problem) occasionally <ref> [31, 32] </ref>.
Reference: [32] <author> P. J. M. van Laarhoven and E. H. L. </author> <title> Arts, Simulated Annealing: Theory and Applications, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1987. </year> <month> 42 </month>
Reference-contexts: It may also facilitate the fine-tuning of solutions around an optimum. C. Simulated Annealing The basic idea of simulated annealing technique is that it tries to avoid being trapped in local minima by making an "uphill" move (for a minimization problem) occasionally <ref> [31, 32] </ref>.
Reference: [33] <author> L. Ingber, </author> <title> "Simulated annealing: Practice versus theory," </title> <booktitle> Mathematical and Computer Modeling, </booktitle> <volume> vol. 18, no. 11, </volume> <pages> pp. 29-57, </pages> <year> 1993. </year>
Reference-contexts: During the initial stage of the simulated annealing search, the system is more likely to accept uphill moves because T is high. As the search proceeds, the probability of accepting uphill moves gradually decreases because T becomes lower. C.1 Adaptive Simulated Annealing Adaptive Simulated Annealing (ASA) <ref> [33] </ref> is a variant of the simulated annealing technique where the annealing schedule for the temperature decreases exponentially in annealing time. ASA also introduces re-annealing so that it permits adaptation to changing sensitivities in the multi-dimensional parameter space. ASA attempts to "stretch out" the range over the insensitive parameters.
Reference: [34] <author> L. Ingber and B. Rosen, </author> <title> "Genetic algorithms and very fast simulated annealing: A comparison," </title> <booktitle> Mathematical and Computer Modeling, </booktitle> <volume> vol. 16, no. 11, </volume> <pages> pp. 87-100, </pages> <year> 1992. </year>
Reference-contexts: ASA also introduces re-annealing so that it permits adaptation to changing sensitivities in the multi-dimensional parameter space. ASA attempts to "stretch out" the range over the insensitive parameters. It has been shown that ASA outperformed GA on De Jong's test functions <ref> [34] </ref>. IV. Integrating Genetic Algorithms and the Simplex Method While genetic algorithms (GAs) have shown to be effective for solving a wide range of optimization problems [1], its convergence speed is typically much slower than local optimization techniques.
Reference: [35] <author> J. Renders and H. Bersini, </author> <title> "Hybridizing genetic algorithms with hill-climbing methods for global optimization: Two possible ways," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pp. 312-317, </pages> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum. <p> Examples of elite-based hybrid GA include G-bit improvement on GA and our simplex-GA hybrid. The partition-based hybrid GA was introduced in Renders-Bersini's work, even though they did not give this architecture a name <ref> [35] </ref>. As we shall see later in Section VIII, the choice between these two architectures can have a significant impact on the performance of a hybrid GA system. B. <p> The parameters of R-B hybrid are those reported in their paper for a function maximization problem: 0.5 simplex probability, 0.2 crossover probability, and 0.2 average probability <ref> [35] </ref>. <p> In this section, we test it using a function maximization problem. We test it using De Jong's F5 function minimization problem in the 23 24 25 next section. The testbed used in this section is a function maximization problem used by Renders and Bersini <ref> [35] </ref>, which is actually an instance of a function family introduced by Michalewicz in [23]: f (~x) = i=1 i fi x 2 where x i 2 [0; ]. We chose the function maximization problem because there are many (exactly N !) local minima in this function. <p> As m grows, finding maxima of this function becomes more and more difficult. Renders and Bersini used two instances of this function family to test their hybrid approach by setting N to 10, and m to 10 and 100 respectively <ref> [35] </ref>. These problems are 10-dimensional optimization problems. Theoretical maxima of these two functions are 9.660 (for m=10) and 9.655 (for m=100). <p> For the R-B hybrid, we used the parameters that gave the best performance in their experiments (i.e., 0.2, 0.2, and 0.5 for the crossover probability, the average probability, and the simplex probability, respectively) <ref> [35] </ref>. Fig. 16 plots the average best fitness vs number of trials for the two function maximization problems. Because the performance of the 100% concurrent simplex is much worse than the other three approaches, they are not included in the figures. <p> The ASA was not robust in that it only found the optimum in three runs out of ten runs for the difficult problem (m=100). We need to clarify a few differences between the result of our experiments and those reported by Renders and Bersini <ref> [35] </ref>. The GA outperformed the R-B hybrid for both problems in our experiment, but was outperformed by the R-B hybrid in their experiment. One of the differences between the two experiments is the maximum trials allowed.
Reference: [36] <author> D. H. Ackley, </author> <title> Stochastic Iterated Genetic Hillclimbing, </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1987. </year>
Reference-contexts: It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [37] <author> G. Dozier, J. Bowen, and D. Bahler, </author> <title> "Solving small and large scale constraint satisfaction problems using a heuristic-based microgenetic algorithm," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [38] <author> T. Murata and H. Ishibuchi, </author> <title> "Performance evaluation of genetic algorithms for flowshop scheduling problems," </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [39] <author> J. </author> <type> Renders, </type> <institution> Algorithmes Genetiques et Reseaux de Neurones: Applications a la Commande de Pro-cessus, Hermes, Paris, France, </institution> <year> 1994. </year>
Reference-contexts: It can 11 only recombine good guesses hoping that one recombination will have a better fitness than both of its parents 3 . Because of this limitation, many researchers have combined GAs with other optimization techniques to develop hybrid genetic algorithms <ref> [35, 14, 15, 36, 37, 38, 17, 21, 20, 39] </ref>. The purpose of such hybrid systems is to speed up the rate of convergence while retaining the ability to avoid being easily entrapped at a local optimum.
Reference: [40] <author> J. J. Grefenstette, </author> <note> User's Guide to GENESIS Verison 5.0, </note> <year> 1990. </year>
Reference-contexts: Application to Metabolic Modeling We have successfully applied our simplex-GA hybrid optimization approach to the metabolic modeling problem described in Section II. We implemented the approach by modifying the code of GENESIS <ref> [40] </ref>. In this section, we describe the design of this application and the empirical results obtained, which is compared with those of original real-coded GA, concurrent simplex, the R-B hybrid approach, Adaptive Simulated Annealing (ASA), and the G-bit improvement on real-coded GA.
Reference: [41] <author> M. Caracotsios and W. E. Stewart, </author> <title> DDASAC Double Precision Differential Algebraic Sensitivity Analysis Code, </title> <year> 1984. </year>
Reference-contexts: The Fitness Evaluation: To evaluate the fitness of a chromosome, we assign the parameter values in the chromosome to their corresponding parameters. We then evaluate the metabolic model with these parameter assignment by simulating the model using DDASAC (Double precision Differential Algebraic Sensitivity Analysis Code) <ref> [41] </ref> with thirty time steps. Even though the metabolic model consists of forty four state variables, only three of them can actually be observed during experiments (i.e., GLU , P Y R, and ffKET O).
Reference: [42] <author> J. Grefenstette, </author> <title> "GENESIS: A system for using genetic search procedures," </title> <booktitle> In Proceedings of the 1984 Conference of Intelligent Systems and Machines, </booktitle> <pages> pp. 161-165, </pages> <year> 1984. </year> <month> 43 </month>
Reference-contexts: The software package for model simulation DDASAC was originated from M. Caracotsios and W. E. Stewart. The GENESIS implementation of GA was developed by John J. Grefenstette <ref> [42] </ref>. 38 (a) (b) a conventional simplex 39 (a) and (b) a conventional simplex 40
References-found: 42

