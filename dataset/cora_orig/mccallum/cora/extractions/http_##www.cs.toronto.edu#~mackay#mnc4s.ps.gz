URL: http://www.cs.toronto.edu/~mackay/mnc4s.ps.gz
Refering-URL: http://www.cs.toronto.edu/~mackay/README.html
Root-URL: http://www.cs.toronto.edu
Title: Good Codes based on Very Sparse Matrices  
Author: David J.C. MacKay and Radford M. Neal 
Abstract: Note: the following paper was completed 6th October 1995 and was published in "Cryptography and Coding. 5th IMA Conference", ed. Colin Boyd, Lecture Notes in Computer Science number 1025, pp. 100-111 (1995) Springer, Berlin. Unfortunately this paper contains two errors with respect to Gallager's work on low density parity check codes. We gained the impression from the literature that "the sparse parity check codes studied by Gallager are bad," but this is in fact not the case. We also had the impression that Gallager's decoding algorithm was the same as Meier and Staffelbach's, and that our use of belief propagation was a new innovation. However, Gallager in fact proposed and used the identical belief propagation algorithm in 1962. We became aware of these errors shortly before the IMA conference on Cryptography and Coding (December 1995). We established that Gallager's low density parity check codes share all the `goodness' properties of the `MN' codes presented in this paper, and that their empirical performance is superior, as described in our more recent papers. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Andreassen, M. Woldbye, B. Falck, and S. Andersen. </author> <title> MUNIN a causal probabilistic network for the interpretation of electromyographic findings. </title> <booktitle> In Proc. of the 10th National Conf. on AI, AAAI: </booktitle> <address> Menlo Park CA., </address> <pages> pages 121-123, </pages> <year> 1987. </year>
Reference-contexts: However, it is interesting to implement the decoding algorithm that would be appropriate if there were no cycles, on the assumption that the errors introduced might be relatively small (c.f. <ref> [1] </ref>).
Reference: 2. <author> E. R. Berlekamp. </author> <title> Algebraic Coding Theory. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: In principle, it may be possible in some cases to make a BCH decoder that corrects more than t errors, but according to Berlekamp <ref> [2] </ref>, "little is known about: : : how to go about finding the solutions" and "if there are more than t + 1 errors then the situation gets very complicated very quickly." Similarly, for RM codes of minimum distance d, performance was computed assuming that more than bd=2c errors cannot be
Reference: 3. <author> T. M. Cover and J. A. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: We now describe theoretical properties that we have proved for MN codes. We then describe empirical results with a practical decoding algorithm. 2.5 Theoretical properties proven for MN codes In [6] we prove properties of these codes by studying properties of a `typical set decoder' <ref> [3] </ref> for the decoding problem Ax = z, averaging over an ensemble of random matrices A. We prove two theorems (our proofs are computer-aided), whose implications are as follows. 0 0.4 0.8 0.001 0.01 0.1 Capacity t=6 t=4 Fig. 3. Main theoretical result.
Reference: 4. <author> R. G. Gallager. </author> <title> Low density parity check codes. </title> <journal> IRE Trans. Info. Theory, </journal> <volume> IT-8:21-28, </volume> <month> Jan </month> <year> 1962. </year>
Reference-contexts: One might therefore hope that it is practical to solve this decoding problem. The decoding problem is of the type studied by Gallager <ref> [4] </ref>. However, the sparse parity check codes studied by Gallager are bad. The trick that makes MN codes good is the construction in terms of an invertible matrix. We now describe theoretical properties that we have proved for MN codes. <p> This means that every bit's `friends' (other bits that are parents of its children) consist of t non-overlapping sets of bits as shown in (f). 4 Belief network decoding We have developed a `belief net decoder' for the problem Ax = z mod 2, which generalizes the methods of Gallager <ref> [4] </ref> and Meier and Staffelbach [9] by using methods of belief propagation over networks [11]. We refer to the elements z n corresponding to each row n = 1 : : : N of A as checks. <p> set ^x k to 1 if q 1 k &gt; 0:5 and see if the checks A ^ x = z are all satisfied, halting when they are, and declaring a failure if some maximum number of iterations (e.g., 1000) occurs without successful decoding. 4.2 Relationship to Gallager's algorithm Gallager <ref> [4] </ref> and Meier and Staffelbach [9] implemented algorithms very similar to this belief net decoder, also studied by Mihaljevic and Golic [10].
Reference: 5. <author> D. J. C. MacKay. </author> <title> Free energy minimization algorithm for decoding and cryptanalysis. </title> <journal> Electronics Letters, </journal> <volume> 31(6) </volume> <pages> 446-447, </pages> <year> 1995. </year>
Reference-contexts: In sections 3 and 4 we describe empirical results of computer experiments using first a free energy minimization algorithm <ref> [5] </ref> and second a `belief propagation' algorithm for decoding. <p> We first attempted to solve the decoding problem using a variational free energy minimization algorithm <ref> [5] </ref>. We found that as the block size N was increased at a constant information rate, the performance improved. <p> These probabilities can be computed efficiently using forward and backward passes (c.f. <ref> [5] </ref>), in which products of the differences ffiq nk j q 0 nk q 1 are computed. We obtain ffir nk j r 0 nk r 1 nk from the identity: ffir nk = (1) z n Y ffiq nk 0 : (10) Vertical pass.
Reference: 6. <author> D. J. C. MacKay and R. M. Neal. </author> <title> Good codes based on very sparse matrices. </title> <note> Available from http://131.111.48.24/, 1995. </note>
Reference-contexts: We regret that lack of space prevents presentation of all our theoretical and experimental results. The full text of this paper may be found elsewhere <ref> [6] </ref>. 1 Background In 1948, Shannon [14] proved that there exist block codes, for a given memoryless channel, that achieve arbitrarily small probability of error * at any communication rate R up to the capacity C of the channel. We will refer to such code families as `very good' codes. <p> At the same time it can be proved that these codes are very good, in that se-quences of codes exist which, when optimally decoded, achieve information rates up to the Shannon limit of the binary symmetric channel <ref> [6] </ref>. In sections 3 and 4 we describe empirical results of computer experiments using first a free energy minimization algorithm [5] and second a `belief propagation' algorithm for decoding. <p> Redundant sources of this type can be produced from other sources by using a variation on arithmetic coding [16, 13]; one simply reverses the role of encoder and decoder in a standard arithmetic coder based on a model corresponding to the sparse messages <ref> [6] </ref>. Given that the source is already redundant, we are no longer constrained to have N &gt; K. In MN codes, N may be less than K, equal to K or greater than K. <p> This is expected to improve the properties of the ensemble of codes, for reasons explained in <ref> [6] </ref>. 3. One can further constrain the matrix [C s C n ] so that the topology of the corresponding belief network does not contain short cycles. <p> The trick that makes MN codes good is the construction in terms of an invertible matrix. We now describe theoretical properties that we have proved for MN codes. We then describe empirical results with a practical decoding algorithm. 2.5 Theoretical properties proven for MN codes In <ref> [6] </ref> we prove properties of these codes by studying properties of a `typical set decoder' [3] for the decoding problem Ax = z, averaging over an ensemble of random matrices A. <p> In the case where the error bars extend down to the bottom of the error probability axis, no decoding errors occurred in more than 100,000 trials. 5 Discussion Our experiments have demonstrated excellent error correction at rates well above the Gilbert bound. In <ref> [6] </ref> we give an analysis of two practical decoding algorithms.
Reference: 7. <author> F. J. MacWilliams and N. J. A. Sloane. </author> <title> The theory of error-correcting codes. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1977. </year>
Reference-contexts: The Gilbert bound GV (f n ) is GV (f n ) = 1 H 2 (2f n ) f n &lt; 1=4 (2) This is the rate at which one can communicate with a code whose codewords satisfy the Gilbert-Varshamov minimum distance bound, assuming bounded distance decoding <ref> [7] </ref>. 2.1 Conventional linear codes, and the ideas behind MN codes A linear error correcting code can be represented by a N by K binary matrix G (the generator matrix), such that a binary message s is encoded as the vector t = Gs mod 2 (figure 1a). (Note that our
Reference: 8. <author> R. J. </author> <title> McEliece. The theory of information and coding: a mathematical framework for communication. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1977. </year>
Reference-contexts: Since 1948, few constructive and practical codes that are good have been found, fewer still that are practical, and none at all that are both practical and very good <ref> [8] </ref>. Goppa's recent algebraic geometry codes (reviewed in [15]) appear to be both practical and good, but we believe that the literature has not established whether they are very good. In this paper we present a new code family that we call `MN codes'.
Reference: 9. <author> W. Meier and O. Staffelbach. </author> <title> Fast correlation attacks on certain stream ciphers. </title> <journal> J. Cryptology, </journal> <volume> 1 </volume> <pages> 159-176, </pages> <year> 1989. </year>
Reference-contexts: `friends' (other bits that are parents of its children) consist of t non-overlapping sets of bits as shown in (f). 4 Belief network decoding We have developed a `belief net decoder' for the problem Ax = z mod 2, which generalizes the methods of Gallager [4] and Meier and Staffelbach <ref> [9] </ref> by using methods of belief propagation over networks [11]. We refer to the elements z n corresponding to each row n = 1 : : : N of A as checks. <p> if q 1 k &gt; 0:5 and see if the checks A ^ x = z are all satisfied, halting when they are, and declaring a failure if some maximum number of iterations (e.g., 1000) occurs without successful decoding. 4.2 Relationship to Gallager's algorithm Gallager [4] and Meier and Staffelbach <ref> [9] </ref> implemented algorithms very similar to this belief net decoder, also studied by Mihaljevic and Golic [10].
Reference: 10. <author> M. J. Mihaljevic and J. D. Golic. </author> <title> Convergence of a Bayesian iterative error-correction procedure on a noisy shift register sequence. </title> <booktitle> In Advances in Cryptology - EUROCRYPT 92, </booktitle> <volume> volume 658, </volume> <pages> pages 124-137. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: are all satisfied, halting when they are, and declaring a failure if some maximum number of iterations (e.g., 1000) occurs without successful decoding. 4.2 Relationship to Gallager's algorithm Gallager [4] and Meier and Staffelbach [9] implemented algorithms very similar to this belief net decoder, also studied by Mihaljevic and Golic <ref> [10] </ref>.
Reference: 11. <author> J. Pearl. </author> <title> Probabilistic reasoning in intelligent systems: networks of plausible inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1988. </year>
Reference-contexts: consist of t non-overlapping sets of bits as shown in (f). 4 Belief network decoding We have developed a `belief net decoder' for the problem Ax = z mod 2, which generalizes the methods of Gallager [4] and Meier and Staffelbach [9] by using methods of belief propagation over networks <ref> [11] </ref>. We refer to the elements z n corresponding to each row n = 1 : : : N of A as checks. <p> We aim, given the observed checks, to compute the marginal posterior probabilities P (x k = 1jz; A) for each k. Algorithms for the computation of such marginal probabilities in belief networks are found in <ref> [11] </ref>. These computations are expected to be intractable for the belief net corresponding to our problem Ax = z mod 2 because its topology contains many cycles.
Reference: 12. <author> W. W. Peterson and E. J. Weldon, Jr. </author> <title> Error-Correcting Codes. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, Massachusetts, 2nd edition, </address> <year> 1972. </year>
Reference-contexts: We found that the results were best for t = 3 and became steadily worse as t increased. In figure 5 we compare two MN codes with BCH codes, which are described in <ref> [12] </ref> as "the best known constructive codes" for memoryless noisy channels, and with Reed-Muller (RM) codes (block sizes up to 1024). Figure 5 shows the codes' probability of block error versus their rate. All relevant BCH codes listed in [12] are included. <p> compare two MN codes with BCH codes, which are described in <ref> [12] </ref> as "the best known constructive codes" for memoryless noisy channels, and with Reed-Muller (RM) codes (block sizes up to 1024). Figure 5 shows the codes' probability of block error versus their rate. All relevant BCH codes listed in [12] are included. To compute the probability of error for BCH codes we evaluated the probability of more than t errors in n bits, as specified in the (n; k; t) description of the code.
Reference: 13. <author> J. Rissanen and G. G. Langdon. </author> <title> Arithmetic coding. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 23 </volume> <pages> 149-162, </pages> <year> 1979. </year>
Reference-contexts: Consecutive source symbols are independent and identically distributed. Redundant sources of this type can be produced from other sources by using a variation on arithmetic coding <ref> [16, 13] </ref>; one simply reverses the role of encoder and decoder in a standard arithmetic coder based on a model corresponding to the sparse messages [6]. Given that the source is already redundant, we are no longer constrained to have N &gt; K.
Reference: 14. <author> C. E. Shannon. </author> <title> A mathematical theory of communication. </title> <journal> Bell Sys. Tech. J., </journal> <volume> 27 </volume> <pages> 379-423, 623-656, </pages> <year> 1948. </year>
Reference-contexts: We regret that lack of space prevents presentation of all our theoretical and experimental results. The full text of this paper may be found elsewhere [6]. 1 Background In 1948, Shannon <ref> [14] </ref> proved that there exist block codes, for a given memoryless channel, that achieve arbitrarily small probability of error * at any communication rate R up to the capacity C of the channel. We will refer to such code families as `very good' codes.
Reference: 15. <author> M. A. Tsfasman. </author> <title> Algebraic-geometric codes and asymptotic problems. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 33(1-3):241-256, </volume> <year> 1991. </year>
Reference-contexts: Since 1948, few constructive and practical codes that are good have been found, fewer still that are practical, and none at all that are both practical and very good [8]. Goppa's recent algebraic geometry codes (reviewed in <ref> [15] </ref>) appear to be both practical and good, but we believe that the literature has not established whether they are very good. In this paper we present a new code family that we call `MN codes'. These codes have a very sparse structure that shows promise for practical decoding.
Reference: 16. <author> I. H. Witten, R. M. Neal, and J. G. Cleary. </author> <title> Arithmetic coding for data compression. </title> <journal> Communications of the ACM, </journal> <volume> 30(6) </volume> <pages> 520-540, </pages> <year> 1987. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Consecutive source symbols are independent and identically distributed. Redundant sources of this type can be produced from other sources by using a variation on arithmetic coding <ref> [16, 13] </ref>; one simply reverses the role of encoder and decoder in a standard arithmetic coder based on a model corresponding to the sparse messages [6]. Given that the source is already redundant, we are no longer constrained to have N &gt; K.
References-found: 16

