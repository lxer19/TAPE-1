URL: http://www.cs.ucsb.edu/~cfu/papers/ICPP95.ps
Refering-URL: http://www.cs.ucsb.edu/Research/rapid_sweb/RAPID.html
Root-URL: http://www.cs.ucsb.edu
Email: ftyang,cfug@cs.ucsb.edu gerasoulis@cs.rutgers.edu vivek sarkar@vnet.ibm.com  
Title: Mapping Iterative Task Graphs on Distributed Memory Machines  
Author: Tao Yang Cong Fu Apostolos Gerasoulis Vivek Sarkar 
Address: ADTI, 555 Bailey Ave.  Santa Barbara, CA 93106 New Brunswick, NJ 08903 San Jose, CA 95141  
Affiliation: Dept. of Computer Science Dept. of Computer Science  University of California Rutgers University IBM Software Solutions Division  
Abstract: This paper addresses the problem of scheduling iterative task graphs on distributed memory architectures with nonzero communication overhead. The proposed algorithm incorporates techniques of software pipelining, graph unfolding and directed acyclic graph scheduling. The goal of optimization is to minimize overall parallel time, which is achieved by balancing processor loads, exploring task parallelism within and across iterations, overlapping communication and computation, and eliminating unnecessary communication. This paper gives a method to execute static schedules, studies the sensitivity of run-time performance when weights are not estimated accurately at compile-time, and presents experimental results to demonstrate the effectiveness of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Adams, and H. Jordan, </author> <title> Is SOR color-blind?, </title> <journal> SIAM J. Sci. Stat. Comp, </journal> <volume> 7 (1986), </volume> <pages> pp 490-506. </pages>
Reference-contexts: But still the DAG scheduling contributes more than 60% to the final performance. Sparse matrix computation. In solving a sparse matrix system, the SOR iterative methods could be used <ref> [1] </ref>. The left part of Fig. 7, shows an ITG based on the SOR method for a sparse matrix, assuming that the convergence test is not conducted in every iteration but every few hundreds of iterations instead. Some of the edges in this graph are marked distance 1.
Reference: [2] <author> A. Aiken and A. Nicolau, </author> <title> Optimal Loop Parallelization, </title> <booktitle> SIG-PLAN 88 Conf. on Programming Language Design and Implementation. </booktitle> <address> pp.308-317. </address>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. Software pipelin-ing <ref> [2, 11, 15, 19, 22] </ref> is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism. <p> Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. Software pipelin-ing [2, 11, 15, 19, 22] is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques <ref> [2, 18] </ref> have also been developed to allow a compiler to explore more paral lelism. Our work has been motivated by the above research but takes into consideration the characteristics of asynchronous parallelism and the impact of communication. <p> has a high complexity and it is not feasible if N is unknown. 2) Applying a DAG algorithm for one iteration can only exploit parallelism within one iteration but not across iterations. 3) The (b). idea of exploring parallelism within and across iterations has been proposed for instruction-level software pipelining <ref> [2, 15] </ref>. In [11], a near-optimal scheduling algorithm for pipelining with no communication delay is proposed. We need to extend this result to incorporate communication optimization with load balancing since communication is a major overhead in a message-passing machine. <p> We need to extend this result to incorporate communication optimization with load balancing since communication is a major overhead in a message-passing machine. The optimal solution for a special class of ITGs has been studied in [5]. Graph unfolding techniques <ref> [2, 18] </ref> can increase the number of tasks within each iteration and thus more parallelism could be explored. Our goal is to only examine tasks from few iterations (limited by the unfolding factor f ) but explore parallelism of the entire iteration space. <p> There is no prelude and postlude. However the periodic pattern is not unique. Another pattern is T 8 ; T 6 at [90; 180). The prelude is T 1 6 and the postlude is T 3 8 . Notice that in instruction-level software pipelining <ref> [2] </ref>, a global periodic pattern (a pattern which starts at the same time for all processors) is computed and this is not feasible in message-passing machines with asynchronous communication. In our approach, a local periodic pattern is produced. <p> Our approach is based on the idea of "periodic execution" in software pipelining. The difference is that in instruction-level pipelining, periodic pattern is global usually <ref> [2] </ref> while in a distributed memory machine, we use local period patterns to utilize asynchronous parallelism. Our code does not have separate prelude and postlude parts, and in this way the code length can be shortened. The starting time of task instances depends on the iteration number k.
Reference: [3] <author> L. Carter, J. Ferrante and S. F. Hummel, </author> <title> Efficient parallelism via hierarchical tiling, </title> <booktitle> Proc. of 7th SIAM Conf. on Parallel Processing for Scientific Computing, </booktitle> <month> Feb. </month> <year> 1995, </year> <pages> 680-685. </pages>
Reference-contexts: BCSSTK14 and BCSSTK15. 7 Conclusions Our experiments show that the automatic scheduling algorithm for ITGs delivers good performance on message-passing architectures. Our work is useful for assisting performance prediction in compilation optimization such as program partitioning <ref> [3, 17, 21] </ref>. Currently we are implementing code generation and run-time support for executing ITG schedules and investigating applications in sparse matrix computations. Acknowledgement This was supported in part by NSF RIA CCR-9409695 and by ARPA contract DABT-63-93-C-0064.
Reference: [4] <author> Y-C Chung and S. Ranka, </author> <title> Applications and performance analysis of a compile-time optimization application for list scheduling algorithms on distributed memory multiprocessors, </title> <booktitle> Supercomputing 92, </booktitle> <pages> pp. 512-521. </pages>
Reference-contexts: Mapping weighted iterative task graphs on message-passing architectures requires the exploration of both task and loop parallelism. Task parallelism has been addressed in the context of DAG (Directed Acyclic Graphs) scheduling <ref> [4, 16, 20, 24, 27] </ref>. Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21].
Reference: [5] <author> P. Chretienne, </author> <title> Cyclic scheduling with communication delays: a polynomial special case. </title> <month> Dec </month> <year> 1993. </year> <type> Tech Report, </type> <institution> LITP. </institution>
Reference-contexts: We need to extend this result to incorporate communication optimization with load balancing since communication is a major overhead in a message-passing machine. The optimal solution for a special class of ITGs has been studied in <ref> [5] </ref>. Graph unfolding techniques [2, 18] can increase the number of tasks within each iteration and thus more parallelism could be explored. Our goal is to only examine tasks from few iterations (limited by the unfolding factor f ) but explore parallelism of the entire iteration space.
Reference: [6] <author> R. Cytron, </author> <title> Doacross: Beyond vectorization for multiprocessors, </title> <booktitle> Proc. of the 1986 Inter. Conf. on Parallel Processing, </booktitle> <address> St. Charles, </address> <publisher> Ill,1986, </publisher> <pages> pp. 836-844. </pages>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. <ref> [6, 17, 21] </ref>. Software pipelin-ing [2, 11, 15, 19, 22] is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism.
Reference: [7] <author> T. H. Dunigan, </author> <title> Performance of the INTEL iPSC/860 and nCUBE 6400 Hypercube, </title> <institution> ORNL/TM-11790, Oak Ridge National Lab., TN, </institution> <year> 1991. </year>
Reference-contexts: The startup delays for T 1 ; T 2 ; ; T 8 are 0, 40, 20, 60, 0, 20, 50, 90 respectively. 3.6 Optimization for communication con tention So far we have not considered the processor distance. It has been shown (e.g. <ref> [7] </ref>) in the modern processor architectures, the distance factor does not affect the cost of communication significantly because of wormhole routing technology. However, this routing scheme requires the exclusive use of channels, and there exists communication contention if network traffic is heavy.
Reference: [8] <author> I. S. Duff, R. G. Grimes and J. G. Lewis, </author> <title> Users' Guide for the Harwell-Boeing Sparse Matrix Collection, </title> <publisher> TR-PA-92-86. </publisher>
Reference-contexts: Some of the edges in this graph are marked distance 1. The unmarked edges have distance 0. The right part of Fig.7 is the simulated scheduling performance for sparse matrices in the Harwell-Boeing Test Suites <ref> [8] </ref>. We use matrix BCSSTK14 arising from structural analysis for the roof of Omni Coliseum at Atlanta and matrix BCSSTK15 for Module of an offshore platform. While parallelism in a sparse matrix computation is limited, this algorithm is able to explore a decent amount of parallelism.
Reference: [9] <author> H. El-Rewini, T. G. Lewis and H. H. Ali, </author> <title> Task Scheduling in Parallel and Distributed Systems, </title> <publisher> Prentice Hall, </publisher> <year> 1994. </year>
Reference-contexts: Our goal is to only examine tasks from few iterations (limited by the unfolding factor f ) but explore parallelism of the entire iteration space. We need to derive a small unfolding factor for general graphs so that the complexity of scheduling is not too high. <ref> [9] </ref> presented an approach to optimal unfolding for a special case. The problem of scheduling with communication is much harder than that without communication [20]. Our algorithm needs to eliminate unnecessary communication and overlap communication with computation. The above communication optimization should be consistent with the goal of load balancing.
Reference: [10] <author> H. Gabow and R. Tarjan, </author> <title> Faster scaling algorithms for network problems, </title> <journal> SIAM J. Computing, </journal> <month> Oct </month> <year> 1989. </year>
Reference-contexts: These inequalities can be solved in a complexity of O ( p * ) using the shortest path algorithm <ref> [10] </ref> where constant * is the desired accuracy in finding the minimum fi such that fi fl (G) fi fi fl (G) + *. Seq (G) = i=1 t i . For Fig.1 (a), * is chosen as 0.5 and fi is computed as 40. Granularity.
Reference: [11] <author> F. Gasperoni and U. </author> <title> Schweigelshohn Scheduling Loops on Parallel Processors: A simple algorithm with close to optimum performance. </title> <booktitle> Proc. of CONPAR 92 , pp. </booktitle> <pages> 613-624. </pages>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. Software pipelin-ing <ref> [2, 11, 15, 19, 22] </ref> is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism. <p> In <ref> [11] </ref>, a near-optimal scheduling algorithm for pipelining with no communication delay is proposed. We need to extend this result to incorporate communication optimization with load balancing since communication is a major overhead in a message-passing machine. The optimal solution for a special class of ITGs has been studied in [5]. <p> This transformation was first proposed in <ref> [11] </ref> for mapping graphs when communication is zero. We can show such a transformation is still valid for our case by carefully designing the ITG schedule in Section 3.5. The resulting graph after edge deletions is a DAG. We call the transformed graph the kernel DAG K (G f ).
Reference: [12] <author> A. Gerasoulis, J. Jiao, and T. Yang, </author> <title> A multistage approach to scheduling task graphs. To appear in DIMACS Book Series on Parallel Processing of Discrete Optimization Problems. AMS publisher. Edited by P.M. </title> <editor> Pardalos, K.G. Ramakrishnan, and M.G.C. </editor> <publisher> Resende. </publisher>
Reference-contexts: 2) If the number of clusters is larger than p, we use a simple load balancing heuristic to balance the processor load. 3) We further order the execution of tasks within each processor using the RCP algorithm [26] with a goal of overlapping communication with computation to hide communication latency. <ref> [12] </ref> conducted a comparison of this approach with a higher complexity ETF method [14] and found that this approach has a much lower complexity but a competitive performance. The one-stage approach uses the idea of the DSC algorithm [25] but limits the number of clusters to p.
Reference: [13] <author> A. Gerasoulis and T. Yang, </author> <title> On the Granularity and Clustering of Directed Acyclic Task Graphs, </title> <journal> IEEE Trans. on Parallel and Distributed Systems., </journal> <volume> Vol. 4, no. 6, </volume> <month> June </month> <year> 1993, </year> <pages> pp 686-701. </pages>
Reference-contexts: We will verify this in our experiments. The theorem also indicates that program partitioning that produces ITGs should make g (G) not too small. This is consistent to the previous results <ref> [13] </ref>. 5 Run-time execution and sensitivity analysis 5.1 A schedule executing method We assume that the target is a message-passing parallel machine, each processor has its own private memory and a communication buffer to hold the outgoing and incoming messages.
Reference: [14] <author> J. J. Hwang, Y. C. Chow, F. D. Anger, and C. Y. Lee, </author> <title> Scheduling precedence graphs in systems with interprocessor communication times, </title> <journal> SIAM J. Comput., </journal> <pages> pp. 244-257, </pages> <year> 1989. </year>
Reference-contexts: simple load balancing heuristic to balance the processor load. 3) We further order the execution of tasks within each processor using the RCP algorithm [26] with a goal of overlapping communication with computation to hide communication latency. [12] conducted a comparison of this approach with a higher complexity ETF method <ref> [14] </ref> and found that this approach has a much lower complexity but a competitive performance. The one-stage approach uses the idea of the DSC algorithm [25] but limits the number of clusters to p. The detail is in [28]. <p> Theorem 1 Given a DAG R and p processors, the parallel time produced by this algorithm is bounded by P T (R) (1 1=p + 1=g (R))CP (R) + Seq (R)=p where CP (R) is the length of the critical path in this graph R. The ETF algorithm <ref> [14] </ref> has a similar performance bound with a complexity O (pv 2 ) while our algorithm has a lower complexity O ((v + e) log v). 3.5 Constructing an ITG schedule The DAG scheduling produces processor assignment P roc (i) and the starting time fl i for each task T i
Reference: [15] <author> M. Lam, </author> <title> Software pipelining: an effective scheduling technique for VLIW machines, </title> <booktitle> ACM Conf. on Programming Language Design and Implementation, </booktitle> <year> 1988, </year> <pages> 318-328. </pages>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. Software pipelin-ing <ref> [2, 11, 15, 19, 22] </ref> is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism. <p> has a high complexity and it is not feasible if N is unknown. 2) Applying a DAG algorithm for one iteration can only exploit parallelism within one iteration but not across iterations. 3) The (b). idea of exploring parallelism within and across iterations has been proposed for instruction-level software pipelining <ref> [2, 15] </ref>. In [11], a near-optimal scheduling algorithm for pipelining with no communication delay is proposed. We need to extend this result to incorporate communication optimization with load balancing since communication is a major overhead in a message-passing machine.
Reference: [16] <author> C. McCreary and H. Gill, </author> <title> Automatic Determination of Grain Size for Efficient Parallel Processing, </title> <journal> Communications of ACM, </journal> <month> Sept. </month> <year> 1989, </year> <pages> 1073-1078. </pages>
Reference-contexts: Mapping weighted iterative task graphs on message-passing architectures requires the exploration of both task and loop parallelism. Task parallelism has been addressed in the context of DAG (Directed Acyclic Graphs) scheduling <ref> [4, 16, 20, 24, 27] </ref>. Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21].
Reference: [17] <author> C. D. Polychronopoulos, </author> <title> Parallel Programming and Compilers, </title> <publisher> Kluwer Academic, </publisher> <year> 1988. </year>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. <ref> [6, 17, 21] </ref>. Software pipelin-ing [2, 11, 15, 19, 22] is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism. <p> BCSSTK14 and BCSSTK15. 7 Conclusions Our experiments show that the automatic scheduling algorithm for ITGs delivers good performance on message-passing architectures. Our work is useful for assisting performance prediction in compilation optimization such as program partitioning <ref> [3, 17, 21] </ref>. Currently we are implementing code generation and run-time support for executing ITG schedules and investigating applications in sparse matrix computations. Acknowledgement This was supported in part by NSF RIA CCR-9409695 and by ARPA contract DABT-63-93-C-0064.
Reference: [18] <author> K. K. Parhi and D. G. Messerschmitt, </author> <title> Static rate-optimal scheduling of iterative dataflow programs via optimum unfolding, </title> <journal> IEEE Trans. on Computers, </journal> <volume> 40:2, </volume> <year> 1991, </year> <pages> pp. 178-195. </pages>
Reference-contexts: Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. Software pipelin-ing [2, 11, 15, 19, 22] is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques <ref> [2, 18] </ref> have also been developed to allow a compiler to explore more paral lelism. Our work has been motivated by the above research but takes into consideration the characteristics of asynchronous parallelism and the impact of communication. <p> We need to extend this result to incorporate communication optimization with load balancing since communication is a major overhead in a message-passing machine. The optimal solution for a special class of ITGs has been studied in [5]. Graph unfolding techniques <ref> [2, 18] </ref> can increase the number of tasks within each iteration and thus more parallelism could be explored. Our goal is to only examine tasks from few iterations (limited by the unfolding factor f ) but explore parallelism of the entire iteration space. <p> This graph is called G f . The new graph needs to be executed only bN=f c iterations. We use the unfolding algorithm proposed in <ref> [18] </ref> to construct G f . For example, unfolding the ITG in Fig. 1 (a) with f = 2 results in an ITG shown in Fig. 1 (b). Notice the unfolded graph has the following properties [18]: fi fl (G f ) = f fi fl (G). 3.3 Graph transformation We <p> We use the unfolding algorithm proposed in <ref> [18] </ref> to construct G f . For example, unfolding the ITG in Fig. 1 (a) with f = 2 results in an ITG shown in Fig. 1 (b). Notice the unfolded graph has the following properties [18]: fi fl (G f ) = f fi fl (G). 3.3 Graph transformation We transform G f into a DAG so that the DAG scheduling technique could be applied. Define DIV (x; y) as the largest integer that is less than or equal to x=y, i.e. bx=yc.
Reference: [19] <author> R. Reiter, </author> <title> Scheduling parallel computations, </title> <journal> Journal of ACM, </journal> <month> Oct </month> <year> 1968, </year> <pages> pp. 590-599. </pages>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. Software pipelin-ing <ref> [2, 11, 15, 19, 22] </ref> is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism. <p> Thus placing two tasks together in one processor to take advantage of data locality could eliminate some communication overhead although it might reduce parallelism. A trade-off between parallelization and communication locality must be addressed. We will use the concept of integer-periodic schedul ing <ref> [19] </ref> as in instruction-level software pipelining and structure a schedule as follows: all instances of task T i are assigned to the same processor. <p> This is the well-known optimal rate (the smallest iteration interval) of pipelining when communication cost is zero and there is a sufficient number of processors <ref> [19] </ref>.
Reference: [20] <author> V. Sarkar, </author> <title> Partitioning and Scheduling Parallel Programs for Execution on Multiprocessors, </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Mapping weighted iterative task graphs on message-passing architectures requires the exploration of both task and loop parallelism. Task parallelism has been addressed in the context of DAG (Directed Acyclic Graphs) scheduling <ref> [4, 16, 20, 24, 27] </ref>. Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. <p> It is known that communication in such systems suffers high startup cost and data locality must be explored. In the task model, exploring data locality means to localize data communication between tasks by assigning them in the same processor <ref> [20] </ref>. The main focus of our work is to guide task mapping based on the theory of graph scheduling and minimize the performance difference between the proposed solution and an optimal solution. <p> We need to derive a small unfolding factor for general graphs so that the complexity of scheduling is not too high. [9] presented an approach to optimal unfolding for a special case. The problem of scheduling with communication is much harder than that without communication <ref> [20] </ref>. Our algorithm needs to eliminate unnecessary communication and overlap communication with computation. The above communication optimization should be consistent with the goal of load balancing. We assume that communication between two tasks is zero if these two tasks are mapped to the same processor.
Reference: [21] <author> V. Sarkar and R. Thekkath, </author> <title> A general framework for iteration-reordering loop transformations, </title> <booktitle> ACM Conf. on Programming Language Design and Implementation, </booktitle> <year> 1992, </year> <pages> 175-187. </pages>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. <ref> [6, 17, 21] </ref>. Software pipelin-ing [2, 11, 15, 19, 22] is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism. <p> BCSSTK14 and BCSSTK15. 7 Conclusions Our experiments show that the automatic scheduling algorithm for ITGs delivers good performance on message-passing architectures. Our work is useful for assisting performance prediction in compilation optimization such as program partitioning <ref> [3, 17, 21] </ref>. Currently we are implementing code generation and run-time support for executing ITG schedules and investigating applications in sparse matrix computations. Acknowledgement This was supported in part by NSF RIA CCR-9409695 and by ARPA contract DABT-63-93-C-0064.
Reference: [22] <author> V. H. Van Dongen, G. R. Gao and Q. </author> <title> Ning A polynomial time method for optimal software pipelining. </title> <booktitle> Proc. of CONPAR 92, </booktitle> <pages> pp. 613-624. </pages>
Reference-contexts: Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. Software pipelin-ing <ref> [2, 11, 15, 19, 22] </ref> is an important technique proposed for instruction-level loop scheduling on VLIW and superscalar architectures. Loop unrolling or graph unfolding techniques [2, 18] have also been developed to allow a compiler to explore more paral lelism.
Reference: [23] <author> R. Wolski and J. Feo, </author> <title> Program Partitioning for NUMA Multiprocessor Computer Systems, </title> <editor> J. </editor> <booktitle> of Parallel and Distributed Computing, </booktitle> <year> 1993. </year>
Reference: [24] <author> M. Y. Wu and D. Gajski, Hypertool: </author> <title> A programming aid for message-passing systems, </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 1, no. 3, pp.330-343, </volume> <year> 1990. </year>
Reference-contexts: Mapping weighted iterative task graphs on message-passing architectures requires the exploration of both task and loop parallelism. Task parallelism has been addressed in the context of DAG (Directed Acyclic Graphs) scheduling <ref> [4, 16, 20, 24, 27] </ref>. Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21].
Reference: [25] <author> T. Yang and A. Gerasoulis. </author> <title> DSC: Scheduling parallel tasks on an unbounded number of processors, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 5, No. 9, </volume> <pages> 951-967, </pages> <year> 1994. </year>
Reference-contexts: The result of the DAG scheduling is used for constructing the ITG schedule in Section 3.5. Both algorithms have a complexity O ((v + e) log v) 1 . Our multi-stage approach contains the following mapping operations: 1) Assign tasks to a set of clusters using the DSC Algorithm <ref> [25] </ref>. <p> The one-stage approach uses the idea of the DSC algorithm <ref> [25] </ref> but limits the number of clusters to p. The detail is in [28]. We apply this algorithm to the given DAG and also the reversed graph.
Reference: [26] <author> T. Yang and A. Gerasoulis. </author> <title> List scheduling with and without communication. </title> <booktitle> Parallel Computing, 19(1993), </booktitle> <pages> 1321-1344. </pages>
Reference-contexts: and Tasks in the same cluster will be executed in the same processor. 2) If the number of clusters is larger than p, we use a simple load balancing heuristic to balance the processor load. 3) We further order the execution of tasks within each processor using the RCP algorithm <ref> [26] </ref> with a goal of overlapping communication with computation to hide communication latency. [12] conducted a comparison of this approach with a higher complexity ETF method [14] and found that this approach has a much lower complexity but a competitive performance.
Reference: [27] <author> T. Yang and A. Gerasoulis, </author> <title> PYRROS: Static Task Scheduling and Code Generation for Message-Passing Multiprocessors, </title> <booktitle> Proc. of 6th ACM Inter. Confer. on Supercomputing, </booktitle> <address> Wash-ington D.C., </address> <year> 1992, </year> <pages> pp. 428-437. </pages>
Reference-contexts: Mapping weighted iterative task graphs on message-passing architectures requires the exploration of both task and loop parallelism. Task parallelism has been addressed in the context of DAG (Directed Acyclic Graphs) scheduling <ref> [4, 16, 20, 24, 27] </ref>. Using graph scheduling algorithms for iterative computation is not feasible since the number of iterations may be too large or may not even be known at compile-time. Loop scheduling has been studied extensively in the previous work e.g. [6, 17, 21]. <p> The starting time fl i and the processor assignment P roc (i) of each task T i are provided. In mapping the kernel DAG, we use two algorithms: one is a multistage algorithm designed for the PYRROS system <ref> [27] </ref>, another is a one-stage algorithm. We will choose the smaller one between two solutions produced by these algorithms. The result of the DAG scheduling is used for constructing the ITG schedule in Section 3.5. Both algorithms have a complexity O ((v + e) log v) 1 . <p> In this step, we incorporate the processor distance factor in estimating communication overhead and perform a series of pairwise interchanges to adjust the ITG schedule. The complexity is O (p 2 (v log v + e)). A similar strategy is used in PYRROS <ref> [27] </ref>. It should be noted that communication contention exists in other routing schemes. Modeling contention is hard and more investigation is needed. 4 Analysis The overall time complexity of this algorithm is O ( ve log 2 Seq (G) * +p 2 (v log v +e)). <p> When executing each individual task, the task receives the data items it needs, performs computation, and then sends out data produced to its children (using aggregate multicasting if possible). The style is simi lar to the one used in the PYRROS system <ref> [27] </ref>. Let o max = max T x 2T asks (j) o x . Let o min = min T x 2Tasks (j) o x .
Reference: [28] <author> T. Yang, C. Fu, A. Gerasoulis and V. Sarkar, </author> <title> Scheduling Iterative Task Graphs on Distributed Memory Machines, </title> <type> Technical Report TRCS95-07, </type> <institution> UCSB, </institution> <year> 1995. </year>
Reference-contexts: We assume that N is very large and our analysis mea sures the asymptotic performance of scheduling. We also assume that the given graph always has a cycle. The acyclic case is discussed in <ref> [28] </ref>. 3 The Scheduling Algorithm The algorithm for mapping an ITG on p processors contains the six steps. 3.1 Computing performance parameters Smallest iteration interval. We first estimate the maximum performance this task graph could achieve. <p> The one-stage approach uses the idea of the DSC algorithm [25] but limits the number of clusters to p. The detail is in <ref> [28] </ref>. We apply this algorithm to the given DAG and also the reversed graph. This algorithm can obtain the optimum for fork, join, coarse grained tree DAGs if there is a sufficient number of processors and has the following bound.
References-found: 28

