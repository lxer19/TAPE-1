URL: ftp://ftp.cs.ucsd.edu/pub/berman/hpdc96.ps
Refering-URL: http://www.cs.ucsd.edu/groups/hpcl/apples/hetpubs.html
Root-URL: 
Email: fberman,richg@cs.ucsd.edu  
Title: Scheduling From the Perspective of the Application  
Author: Francine Berman and Richard Wolski 
Address: La Jolla, Calif. 92093  
Affiliation: Department of Computer Science and Engineering U. C. San Diego  
Abstract: In this paper, we focus on the problem of scheduling applications on metacomputing systems. We introduce the concept of application-centric scheduling in which everything about the system is evaluated in terms of its impact on the application. Application-centric scheduling is used by virtually all metacomputer programmers to achieve performance on metacomputing systems. We describe two successful metacomputing applications to illustrate this approach, and describe AppLeS scheduling agents which generalize the application-centric scheduling approach. Finally, we show preliminary results which compare AppLeS-derived schedules with conventional strip and blocked schedules for a two-dimensional Jacobi code. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> APPLES. </author> <note> http://www-cse.ucsd.edu/users/berman/ apples.html. </note>
Reference-contexts: The Heterogeneous Application Template (HAT) is an interface in which the user provides specific information about the structure, characteristics and current implementations of the 2 For more information on AppLeS, visit the AppLeS home page <ref> [1] </ref>. agent. application and its tasks. The Models are used for performance estimation, planning and resource selection.
Reference: [2] <author> BERMAN, F., WOLSKI, R., FIGUEIRA, S., SCHOPF, J., AND SHAO, G. </author> <title> Application-level scheduling on distributed heterogeneous networks. </title> <note> Submitted to Supercomputing '96. </note>
Reference-contexts: A full treatment of the Jacobi2D scheduling example can be found in <ref> [2] </ref>. Our purpose in including an outline of the Jacobi2D example in this paper is to demonstrate the efficiency of the AppLeS approach, and to contrast the partitions developed by an intelligent user and the AppLeS scheduler.
Reference: [3] <author> BREWER, E. A. </author> <title> High-level oprimization via automated statistical modeling. </title> <booktitle> In Proceedings of Principles and Practice of Parallel Programming, PPoPP'95 (1995), </booktitle> <pages> pp. 80-91. </pages>
Reference-contexts: Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], [9], [23], etc.). Concepts from application-level scheduling are related to <ref> [3] </ref>, [16], [27], [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS. An important difference, however, is that AppLeS includes user-specific as well as application-specific information in its scheduling decisions.
Reference: [4] <author> CASAVANT, T., AND KUHL, J. </author> <title> A taxonomy of scheduling in general-purpose distributed computing systems. </title> <journal> 11 IEEE Transactions on Software Engineering 14, </journal> <month> 2 (February </month> <year> 1988). </year>
Reference-contexts: Scalability is an issue - researchers have sought algorithms that provide good performance for both increasing numbers of tasks and processors ([30], [22], [23], <ref> [4] </ref>, etc.). In this model, multiprocessor 2 nodes are generally thought of as having uniform capabilities and a single scheduler is in control of all relevant resources.
Reference: [5] <author> CLEO. </author> <note> http://w4.lns.cornell.edu/public/ public.html. </note>
Reference-contexts: After describing these applications, we consider common characteristics of these implementations that must be considered to achieve good scheduling performance. 2.1 CLEO/NILE A Data Parallel Metacomputer Application To explore the question of why there is so little antimatter in the universe, high energy physicists from the CLEO project <ref> [5] </ref> collide beams of positrons with beams of electrons and analyze several secondary subatomic particles which result from these collisions. The beams are generated by the Cornell CESR storage ring and collide inside a detector embedded in a magnetic field and equipped with sensors.
Reference: [6] <author> FEITELSON, D. </author> <title> A survey of scheduling in multipro-grammed parallel systems. </title> <type> Tech. Rep. RC 19790 (87657), </type> <institution> IBM Research Division, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: In the parallel setting, scheduling of multiprocessor resources is done by a single scheduler which controls all execution sites. Considerable work has been done to develop scheduling strategies for individual parallel applications on multiprocessors and multicomputers <ref> [6] </ref>, and for job scheduling multiple applications on such sites [26, 21]. Scalability is an issue - researchers have sought algorithms that provide good performance for both increasing numbers of tasks and processors ([30], [22], [23], [4], etc.).
Reference: [7] <author> FIGUEIRA, S. M., AND BERMAN, F. </author> <title> Modeling the effects of contention on the performance of heterogeneous applications. </title> <booktitle> Proceedings of the High Performance Distributed Computing Conference (1996). </booktitle>
Reference-contexts: If the target resources for the application are lightly loaded, then the system appears lightly loaded to the application regardless of the load on other resources. If the candidate resources are heavily loaded, then the system appears heavily loaded. 1 For a formal treatment of slowdown see <ref> [7] </ref> 3.3 Application-Specific Resource Locality 3D-REACT is composed of two dependent tasks. The performance of 3D-REACT depends on tuning the pipeline size of the application to fit a fast network link between CalTech and SDSC, and overlapping computation and communication concurrently to amortize communication costs.
Reference: [8] <author> FINK, S. J., BADEN, S. B., AND KOHN, S. R. </author> <title> Flexible communication mechanisms for dynamic structured applications. </title> <booktitle> Proceedings of IRREGULAR `96. </booktitle>
Reference-contexts: region i A i = the area of region i P i = the time required for processor i to compute a single point locally C i = the time for processor i to send and receive its borders Finally, the code was actuated on the target resources using KeLP <ref> [8] </ref>, an object-oriented run-time facility for adaptive grid problems. A full treatment of the Jacobi2D scheduling example can be found in [2].
Reference: [9] <author> FREUND, R., Ed. </author> <booktitle> Proceedings of the 1996 IPPS Workshop on Heterogeneous Computing. </booktitle>
Reference-contexts: In addition, we are progressing on an implementation which uses PVM [20] as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], <ref> [9] </ref>, [23], etc.). Concepts from application-level scheduling are related to [3], [16], [27], [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS.
Reference: [10] <author> GEHRINF, J., AND REINFELD, A. </author> <title> Mars a framework for minimizing the job execution time in a metacom-puting environment. </title> <booktitle> Proceedings of Future General Computer Systems (1996). </booktitle>
Reference-contexts: Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], [9], [23], etc.). Concepts from application-level scheduling are related to [3], [16], [27], [31]. The Mars project <ref> [10] </ref>, whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS. An important difference, however, is that AppLeS includes user-specific as well as application-specific information in its scheduling decisions.
Reference: [11] <author> GLOBUS. </author> <note> http://www.mcs.anl.gov/globus. </note>
Reference-contexts: Parallel computing fostered a revolution in the development of algorithms, computer architectures, and programming environments all designed to support concurrency. Similarly, metacomputing is fostering a revolution in the development of network architectures and software methodologies which enable the efficient aggregation of resources into huge resource pools <ref> [11, 14, 25, 20] </ref>. However, meta-computing systems must also allow for the smooth introduction of new hardware and software components while leveraging the capabilities and cost-effectiveness of older, existing systems. <p> Each application will have its own AppLeS whose task it is to select resources, determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. AppLeS agents are not resource management systems; they rely on systems such as Globus <ref> [11] </ref>, Legion [14], PVM [20], etc. to perform that function. <p> AppLeS is currently a work-in-progress. The software has been designed and the underlying building blocks are currently being prototyped. We are working with researchers from the Legion project [14] and from the Globus project <ref> [11] </ref> to prototype AppLeS as an application-level scheduler for these resource management systems. In addition, we are progressing on an implementation which uses PVM [20] as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application.
Reference: [12] <author> GUSTAFSON, J. </author> <title> The consequences of fixed time performance measurement. </title> <booktitle> Proceedings of the 25th Hawaii International Conference on System Sciences (Jan 1992), </booktitle> <pages> 113-124. </pages>
Reference-contexts: In general, performance criteria vary with the user and the application. Most users employ common criteria such as execution time, speedup (fixed-size or fixed-time <ref> [12] </ref>), 5 cost of execution cycles, etc., although performance goals vary considerably over metacomputing applications. Moreover, distinct users will attempt to optimize their usage of same metacomputing resources for different performance criteria at the same time.
Reference: [13] <author> HENSGEN, D. A., MOORE, L., KIDD, T., FREUND, R., KEITH, E., KUSSOW, M., LIMA, J., AND CAMPBELL, M. </author> <title> Adding rescheduling to and integrating condor with smartnet. </title> <booktitle> Proceedings of the Heterogeneous workshop (1995). </booktitle>
Reference-contexts: In addition, we are progressing on an implementation which uses PVM [20] as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], <ref> [13] </ref>, [19], [24], [9], [23], etc.). Concepts from application-level scheduling are related to [3], [16], [27], [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS.
Reference: [14] <author> LEGION. </author> <note> http://www.cs.virginia.edu/mentat/ legion/legion.html. </note>
Reference-contexts: Parallel computing fostered a revolution in the development of algorithms, computer architectures, and programming environments all designed to support concurrency. Similarly, metacomputing is fostering a revolution in the development of network architectures and software methodologies which enable the efficient aggregation of resources into huge resource pools <ref> [11, 14, 25, 20] </ref>. However, meta-computing systems must also allow for the smooth introduction of new hardware and software components while leveraging the capabilities and cost-effectiveness of older, existing systems. <p> Each application will have its own AppLeS whose task it is to select resources, determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. AppLeS agents are not resource management systems; they rely on systems such as Globus [11], Legion <ref> [14] </ref>, PVM [20], etc. to perform that function. <p> AppLeS is currently a work-in-progress. The software has been designed and the underlying building blocks are currently being prototyped. We are working with researchers from the Legion project <ref> [14] </ref> and from the Globus project [11] to prototype AppLeS as an application-level scheduler for these resource management systems. In addition, we are progressing on an implementation which uses PVM [20] as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application.
Reference: [15] <author> LEVI, B. G. </author> <title> The geometric phase shows up in chemical reactions. </title> <booktitle> Physics Today 46, </booktitle> <month> 3 (March </month> <year> 1993), </year> <pages> 17-19. </pages>
Reference-contexts: Physical chemists Wu and Kupperman have refined this calculation by including a property known as the geometric phase <ref> [15] </ref>. Berry first called attention to this phase in a variety of physical systems. The inclusion of this phase alters the calculation so that symmetry may be used to to achieve a more precise result with respect to the basic laws of quantum dynamics.
Reference: [16] <author> LOWECAMP, B., AND BEGUELIN, A. </author> <title> ECO: Efficient collective operations for communication on heterogeneous networks. </title> <booktitle> Proceedings of IPPS (April 1996). </booktitle>
Reference-contexts: Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], [9], [23], etc.). Concepts from application-level scheduling are related to [3], <ref> [16] </ref>, [27], [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS. An important difference, however, is that AppLeS includes user-specific as well as application-specific information in its scheduling decisions.
Reference: [17] <author> MARZULLO, K., OGG, M., RICCIARDI, A., AMOROSO, A., CALKINS, F., AND ROTHFUS, E. Nile: </author> <title> Wide-area computing for high energy physics. </title> <booktitle> Proceedings of the 1996 SIGOPS Conference. </booktitle>
Reference-contexts: A compute-intensive program called recompress recomputes all the raw data to take advantage of improvements in detector calibration and reconstruction algorithms. This program currently requires 24 200-MIP workstations computing for three months roughly every two years, and must be scheduled so as to not seriously impact ongoing experiments <ref> [17] </ref>. Events generated by collisions currently occupy one terabyte of storage a year. The roar data is kept on disk while the rest of the data must be kept on tape.
Reference: [18] <author> NILE. </author> <note> http://www.nile.utexas.edu/. </note>
Reference-contexts: The analysis programs are typically data parallel. Metcomputing is a natural approach for this application due to the structure of the analysis and the resource requirements of the data. The NILE <ref> [18] </ref> project is a National Challenge project focused on the development of a scalable and fault-tolerant infrastructure to support the distributed storage and analysis of CLEO data.
Reference: [19] <author> PRUYNE, J., AND LIVNY, M. </author> <title> Parallel processing on dynamic resources with carmi. </title> <booktitle> In Proceedings of the Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <address> IPPS '95 (April 1995). </address>
Reference-contexts: In addition, we are progressing on an implementation which uses PVM [20] as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], <ref> [19] </ref>, [24], [9], [23], etc.). Concepts from application-level scheduling are related to [3], [16], [27], [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS.
Reference: [20] <author> PVM. </author> <note> http://www.epm.ornl.gov:80/pvm/. </note>
Reference-contexts: Parallel computing fostered a revolution in the development of algorithms, computer architectures, and programming environments all designed to support concurrency. Similarly, metacomputing is fostering a revolution in the development of network architectures and software methodologies which enable the efficient aggregation of resources into huge resource pools <ref> [11, 14, 25, 20] </ref>. However, meta-computing systems must also allow for the smooth introduction of new hardware and software components while leveraging the capabilities and cost-effectiveness of older, existing systems. <p> Each application will have its own AppLeS whose task it is to select resources, determine a performance-efficient schedule, and to implement that schedule with respect to the appropriate resource management systems. AppLeS agents are not resource management systems; they rely on systems such as Globus [11], Legion [14], PVM <ref> [20] </ref>, etc. to perform that function. As such, each AppLeS agent is an application-management system which derives and coordinates a schedule for the application for the benefit of the end-user. 4.1 Design of the AppLeS Agents In this subsection, we describe the design of an individual AppLeS agent 2 . <p> We are working with researchers from the Legion project [14] and from the Globus project [11] to prototype AppLeS as an application-level scheduler for these resource management systems. In addition, we are progressing on an implementation which uses PVM <ref> [20] </ref> as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], [9], [23], etc.). Concepts from application-level scheduling are related to [3], [16], [27], [31].
Reference: [21] <author> RUDOLPH, L., AND FEITELSON, D., </author> <title> Eds. </title> <booktitle> Proceedings of the 1996 IPPS Workshop on Job Scheduling Strategies for Parallel Processing. </booktitle>
Reference-contexts: In the parallel setting, scheduling of multiprocessor resources is done by a single scheduler which controls all execution sites. Considerable work has been done to develop scheduling strategies for individual parallel applications on multiprocessors and multicomputers [6], and for job scheduling multiple applications on such sites <ref> [26, 21] </ref>. Scalability is an issue - researchers have sought algorithms that provide good performance for both increasing numbers of tasks and processors ([30], [22], [23], [4], etc.).
Reference: [22] <author> SARKAR, V. </author> <title> Automatic partitioning of a program dependence graph into parallel tasks. </title> <journal> IBM Journal of Research and Devlopment 35, </journal> <note> 5/6 (Sept/Nov 1991). </note>
Reference-contexts: Scalability is an issue - researchers have sought algorithms that provide good performance for both increasing numbers of tasks and processors ([30], <ref> [22] </ref>, [23], [4], etc.). In this model, multiprocessor 2 nodes are generally thought of as having uniform capabilities and a single scheduler is in control of all relevant resources.
Reference: [23] <author> SHIRAZI, B., HURSON, A., AND KAVI, K. </author> <title> Scheduling and Load Balancing in Parallel and Distributed Systems. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference-contexts: Scalability is an issue - researchers have sought algorithms that provide good performance for both increasing numbers of tasks and processors ([30], [22], <ref> [23] </ref>, [4], etc.). In this model, multiprocessor 2 nodes are generally thought of as having uniform capabilities and a single scheduler is in control of all relevant resources. <p> In addition, we are progressing on an implementation which uses PVM [20] as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], [9], <ref> [23] </ref>, etc.). Concepts from application-level scheduling are related to [3], [16], [27], [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS. An important difference, however, is that AppLeS includes user-specific as well as application-specific information in its scheduling decisions.
Reference: [24] <author> SIEGEL, H., ANTONIO, J., METZGER, R., TAN, M., AND LI, Y. A. </author> <title> Heterogeneous computing. </title> <type> Tech. rep., </type> <institution> Purdue University EE Technical Report TR-EE 94-37. </institution>
Reference-contexts: In addition, we are progressing on an implementation which uses PVM [20] as the underlying substrate. Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], <ref> [24] </ref>, [9], [23], etc.). Concepts from application-level scheduling are related to [3], [16], [27], [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS.
Reference: [25] <author> TANNENBAUM, T., AND LITZKOW, M. </author> <title> The condor distributed processing system. </title> <journal> Dr. </journal> <note> Dobbs Journal (Febru-ary 1995). </note>
Reference-contexts: Parallel computing fostered a revolution in the development of algorithms, computer architectures, and programming environments all designed to support concurrency. Similarly, metacomputing is fostering a revolution in the development of network architectures and software methodologies which enable the efficient aggregation of resources into huge resource pools <ref> [11, 14, 25, 20] </ref>. However, meta-computing systems must also allow for the smooth introduction of new hardware and software components while leveraging the capabilities and cost-effectiveness of older, existing systems.
Reference: [26] <author> WAN, M., MOORE, R., KREMENEK, G., AND STEUBE, K. </author> <title> A batch scheduler for the intel paragon MPP system with a non-contiguous node allocation. </title> <booktitle> Proceedings of the Workshop on Job Scheduling Strategies for Parallel Processing (1996). </booktitle>
Reference-contexts: In the parallel setting, scheduling of multiprocessor resources is done by a single scheduler which controls all execution sites. Considerable work has been done to develop scheduling strategies for individual parallel applications on multiprocessors and multicomputers [6], and for job scheduling multiple applications on such sites <ref> [26, 21] </ref>. Scalability is an issue - researchers have sought algorithms that provide good performance for both increasing numbers of tasks and processors ([30], [22], [23], [4], etc.).
Reference: [27] <author> WEISSMAN, J. </author> <title> The interference paradigm for network job scheduling. </title> <booktitle> Proceedings of the IPPS Workshop on Heterogeneous Computing (1996). </booktitle>
Reference-contexts: Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], [9], [23], etc.). Concepts from application-level scheduling are related to [3], [16], <ref> [27] </ref>, [31]. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS. An important difference, however, is that AppLeS includes user-specific as well as application-specific information in its scheduling decisions.
Reference: [28] <author> WU, M., AND KUPPERMANN, A. </author> <title> Casa quantum chemical reaction dynamics. In CASA Gigabit Network Testbed Annual Report (1994). </title>
Reference-contexts: In the metacomputing setting, resources are often managed by separate schedulers which are not coordinated. For example, CASA applications like 3D-REACT, an ab initio chemical simulation code <ref> [28] </ref>, have coordinated execution on an Intel Delta (and subsequently a Paragon) at CalTech and a Cray C90 at SDSC over a HiPPI-SONET gateway and SONET wide-area link. The Delta (Paragon) and the C90 are under the control of different systems, different schedulers, and belong to distinct administrative domains. <p> The execution time for the code on the distributed platform is just under 5 hours (wall clock time) <ref> [28] </ref>. All resources are dedicated. Currently, once a full set of surface functions (LHSF calculations) and the corresponding number of Log-D calculations have been performed, the ASY computation determines whether the calculation should stop.
Reference: [29] <author> WU, Y.-S. M., AND KUPPERMANN, A. </author> <title> Prediction of the effect of the geometric phase on product rotational state distributions and integral cross sections. </title> <journal> Chemical Physics Letters 201 (January 1993), </journal> <pages> 178-86. </pages>
Reference-contexts: Performance will vary greatly based on contention for resources. 2.2 3-D REACT ATask Parallel Metacomputer Application Quantum mechanical reactive dynamics is used to predict the energy levels of various chemical reactions from first principles. The 3D-REACT quantum mechanical application <ref> [29] </ref> simulates a hydrogen-deuterium reaction of H + D 2 =) HD + D: The hydrogen-deuterium reaction is studied because it is one of the simplest reactions that can be calculated from first principles.
Reference: [30] <author> YANG, T., AND GERASOULIS, A. </author> <title> DSC: Scheduling parallel tasks on an unbounded number of processors. </title> <journal> IEEE Transactions on Parallal and Distributed Systems 5, </journal> <volume> 9 (1994), </volume> <pages> 951-967. </pages>
Reference: [31] <author> ZHANG, X., AND YAN, Y. </author> <title> A framework of performance prediction of parallel computing nondedicated heterogeneous NOW. </title> <booktitle> In Proceedings of the 1995 International Conference on Parallel Processing (1995), </booktitle> <pages> pp. 163-7. </pages>
Reference-contexts: Note that AppLeS essentially develops a customized scheduler for each application. This differs from the approach taken in much of the scheduling literature ([21], [13], [19], [24], [9], [23], etc.). Concepts from application-level scheduling are related to [3], [16], [27], <ref> [31] </ref>. The Mars project [10], whose goal is to produce general-purpose software, is similar in scope and intent to AppLeS. An important difference, however, is that AppLeS includes user-specific as well as application-specific information in its scheduling decisions.
References-found: 31

