URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-93-09.ps.Z
Refering-URL: http://www.cse.ucsc.edu/~golding/
Root-URL: http://www.cse.ucsc.edu
Title: Modeling replica divergence in a weak-consistency protocol for global-scale distributed data bases  
Author: Richard A. Golding Darrell D. E. Long 
Note: Supported in part while at the University of California by the Concurrent Systems Project at Hewlett-Packard Laboratories and by a graduate fellowship from the Santa Cruz Operation. Supported in part by the National Science Foundation under Grant NSF CCR-9111220 and by the Office of Naval Research under Grant N00014-92-J-1807.  
Address: Amsterdam, The Netherlands  UCSC-CRL-93-09  Santa Cruz, CA 95064  
Affiliation: Vrije Universiteit,  University of California, Santa Cruz  Concurrent Systems Laboratory Computer and Information Sciences University of California, Santa Cruz  
Abstract: Distributed database systems for wide-area networks must scale to very large numbers of replicas in order to provide acceptable availability and response time. Weak-consistency replication protocols, such as the timestamped anti-entropy (TSAE) protocol we have developed, allow a database to scale to hundreds or thousands of replicas. The TSAE protocol allows updates to be processed by a single replica, then propagated from one replica to another in the background, causing replicas to temporarily diverge. The divergence is resolved in a short time and is resolved correctly even in the presence of temporary replica failure and network partition. We present a detailed analysis of the update propagation latency and the divergence between replicas caused by this protocol. 
Abstract-found: 1
Intro-found: 1
Reference: [Agrawal91] <author> D. Agrawal and A. Malpani. </author> <title> Efficient dissemination of information in computer networks. </title> <journal> Computer Journal, </journal> <volume> 34(6) </volume> <pages> 534-41, </pages> <month> December </month> <year> 1991. </year> <month> 13 </month>
Reference-contexts: This alternate protocol was discovered independently by Agrawal and Malpani <ref> [Agrawal91] </ref>. 6 TABLE 1: Partner selection policies. Random policies: Uniform Every other replica has an equal probability of being randomly selected. Distance-biased Nearby replicas have a greater probability than more distant replicas of being randomly selected.
Reference: [Alon87] <author> Noga Alon, Amnon Barak, and Udi Manber. </author> <title> On disseminating information reliably without broadcasting. </title> <booktitle> Proceedings of the 7th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 74-81, </pages> <year> 1987. </year>
Reference-contexts: Topological policies: Ring Organizes the replicas into a ring. Binary tree Replicas are organized into a binary tree, and messages are propagated randomly along the arcs in the tree. Mesh Organizes the replicas into a two-dimensional rectangular mesh. Alon et al. <ref> [Alon87] </ref> proposed the latin square policy, which guarantees that a message is received by all replicas in O (log n) time (assuming no replica failure). A latin square is an N fi N matrix of N entries, where every row and column includes every entry once. <p> The uniform, latin squares, and distance-biased policies give essentially identical performance. Age-biased appears to provide slightly better performance, which would appear to contradict the claim by Alon that the latin squares policy is fastest <ref> [Alon87] </ref>. We believe the difference arises from a slight difference in implementation: Alon's implementation requires that every replica propagate messages in well-defined rounds, while this simulation allows propagation to occur at random intervals. This may mitigate some of the benefit derived from Alon's latin squares policy. <p> We are encouraged by the performance of the distance-biased partner selection policy. Similar policies can be used in the Internet to encourage traffic between nearby sites and to avoid saturating long-distance links. The random policy appears to be within a constant factor of optimal <ref> [Alon87] </ref>. Acknowledgments John Wilkes, of the Concurrent Systems Project at Hewlett-Packard Laboratories, and Kim Taylor, of UC Santa Cruz, assisted the initial development of these protocols. George Neville-Neil, Leendert van Doorn, Bruce Montague, and Mary Long gave helpful comments on this paper.
Reference: [Demers88] <author> Alan Demers, Dan Greene, Carl Hauser, Wes Irish, John Larson, Scott Shenker, Howard Sturgis, Dan Swinehart, and Doug Terry. </author> <title> Epidemic algorithms for replicated database maintenance. </title> <journal> Operating Systems Review, </journal> <volume> 22(1) </volume> <pages> 8-32, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Several Refdbms databases are replicated at sites in North America and Europe. Other existing information systems, such as Usenet [Quarterman86] and the Xerox Clearinghouse system <ref> [Oppen81, Demers88] </ref>, use other weak-consistency techniques. Our work formalizes and improves on these ad hoc approaches, providing a single framework for analyzing, comparing, and implementing them [Golding92c]. Clients using a weakly-consistent service can observe out-of-date or inconsistent information, unlike clients of a service that provides single-copy serializability. <p> Some weak-consistency protocols, such as TSAE, allow replicas to order messages causally or totally. Several protocols that provide weakly consistent replication have been proposed. The Xerox Clearinghouse <ref> [Demers88, Oppen81] </ref> name service used three epidemic replication protocols, including best-effort multicast, rumor mongery, and anti-entropy. Of these three, only anti-entropy provided reliable delivery, and it could not support message reordering or provably reliable log purges. <p> The uniform policy assigns every replica an equal probability of being selected as partner. Uniform selection can lead to overloaded network links in an internetwork where the physical topology is less connected than the logical. Demers et al. compared uniform to distance-biased selection <ref> [Demers88] </ref>. Their study found that biasing partner selection by distance could reduce traffic on critical intercontinental links by more than an order of magnitude.
Reference: [Emtage92] <author> Alan Emtage and Peter Deutsch. </author> <title> Archie an electronic directory service for the Internet. </title> <booktitle> Proceedings of the Winter Conference, </booktitle> <pages> pages 93-110. </pages> <publisher> Usenix Association, </publisher> <month> January </month> <year> 1992. </year>
Reference-contexts: Further, in January 1993 the Internet included more than 1.3 million hosts with an estimated 12 million users [Lottor93]. This has led to query loads on some services exceeding the capacity of a single server and the network links that support it <ref> [Emtage92] </ref>. Any replication protocol that requires interactive communication with many replicas will not work in this environment. The introduction of mobile computers exacerbates this problem further. These systems spend most of their time disconnected from other systems, or perhaps connected by an expensive or low-bandwidth link.
Reference: [Gifford79] <author> D. K. Gifford. </author> <title> Weighted voting for replicated data. </title> <booktitle> Proceedings of the 7th ACM Symposium on Operating Systems Principles (Pacific Grove, California), </booktitle> <pages> pages 150-62, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: The mechanism can be tailored to the specific needs of the service by combining the appropriate low-level communication, group management, and message management modules, which can provide guarantees ranging from traditional single-copy serializability using a strongly-consistent protocol such as quorum consensus <ref> [Gifford79, Thomas79] </ref>, to a weak-consistency mechanism using the timestamped anti-entropy (TSAE) protocol that we have developed. Weak-consistency protocols, sometimes called epidemic replication protocols, provide eventual message delivery. A database update is sent as a message to one replica.
Reference: [Golding92a] <author> Richard Golding. </author> <title> End-to-end performance prediction for the Internet progress report. </title> <type> Technical report UCSC-CRL-92-26. </type> <institution> Computer and Information Sciences Board, University of California at Santa Cruz, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: Latency affects the response time of the application, and can vary from a few milliseconds, for two hosts connected by an Ethernet, to several hundred milliseconds for hosts on different continents communicating through the Internet. Packet loss rates often reach 40%, and can go higher <ref> [Golding92a] </ref>. Further, the Internet has many points that, on failure, partition the network, and at any given time it is usually partitioned into several non-communicating networks. Further, in January 1993 the Internet included more than 1.3 million hosts with an estimated 12 million users [Lottor93].
Reference: [Golding92b] <author> Richard A. Golding. </author> <title> Weak-consistency group communication and membership. </title> <type> PhD thesis, </type> <note> published as Technical report UCSC-CRL-92-52. </note> <institution> Computer and Information Sciences Board, University of California at Santa Cruz, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: It also maintains enough information to support correct truncation of message logs, as well as causal or total message delivery orders. 1 We have used the TSAE protocol to prototype a large-scale, wide-area distributed bibliographic database management system, called Refdbms <ref> [Golding92b] </ref>. Several Refdbms databases are replicated at sites in North America and Europe. Other existing information systems, such as Usenet [Quarterman86] and the Xerox Clearinghouse system [Oppen81, Demers88], use other weak-consistency techniques. <p> We discuss this measure in Section 4. We have evaluated the fault tolerance of message delivery and of the group management mechanism, and the network traffic imposed by the protocol, as we have reported elsewhere <ref> [Golding93, Golding92b] </ref>. In the remainder of this section we will justify why weak-consistency protocols are necessary for the large-scale wide area systems that are currently being built. <p> However, the protocol itself was notably inefficient. The composition of TSAE with a causal message ordering module is equivalent to the Lazy Replication system. 2.2 Timestamped anti-entropy The TSAE protocol is a new group communication protocol that provides reliable, eventual delivery <ref> [Golding92b] </ref>. Like other weak-consistency protocols, update messages originate at a single replica and are propagated in the background to others. Unlike most others, TSAE can support total or causal message delivery orders, mobile computer systems, and provably correct purging of message logs.
Reference: [Golding92c] <author> Richard A. Golding and Darrell D. E. </author> <title> Long. Design choices for weak-consistency group communication. </title> <type> Technical report UCSC-CRL-92-45. </type> <institution> Computer and Information Sciences Board, University of California at Santa Cruz, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: We have developed an architecture for constructing wide-area services that uses group communication to implement a replicated service <ref> [Golding92c] </ref>. A number of replicas or servers form a group, and coordinate their actions using a group communication mechanism. <p> Other existing information systems, such as Usenet [Quarterman86] and the Xerox Clearinghouse system [Oppen81, Demers88], use other weak-consistency techniques. Our work formalizes and improves on these ad hoc approaches, providing a single framework for analyzing, comparing, and implementing them <ref> [Golding92c] </ref>. Clients using a weakly-consistent service can observe out-of-date or inconsistent information, unlike clients of a service that provides single-copy serializability. <p> Unlike some other work on distributed consistency, we reason about consistency using real time that could be measured by an outside observer rather than a virtual time measure. We have developed a framework for constructing and classifying group communication mechanisms <ref> [Golding92c] </ref>. In this approach, we classify a mechanism by the latency and reliability of message delivery, and by the order in which messages are delivered to the service. The communication protocol can deliver messages synchronously, within a bounded time, or eventually in a finite but unbounded time.
Reference: [Golding93] <author> Richard A. Golding and Darrell D. E. </author> <title> Long. Simulation modeling of weak-consistency protocols. </title> <booktitle> Proceedings of the International Workshop on Modeling, Analysis, </booktitle> <institution> and Simulation of Computer and Telecommunication Systems (MASCOTS), </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: We discuss this measure in Section 4. We have evaluated the fault tolerance of message delivery and of the group management mechanism, and the network traffic imposed by the protocol, as we have reported elsewhere <ref> [Golding93, Golding92b] </ref>. In the remainder of this section we will justify why weak-consistency protocols are necessary for the large-scale wide area systems that are currently being built.
Reference: [Ladin90] <author> Rivka Ladin, Barbara Liskov, Liuba Shrira, and Sanjay Ghemawat. </author> <title> Lazy replication: exploiting the semantics of distributed services. </title> <type> Technical report MIT/LCS/TR-484. </type> <institution> Laboratory for Computer Science, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: The Xerox Clearinghouse [Demers88, Oppen81] name service used three epidemic replication protocols, including best-effort multicast, rumor mongery, and anti-entropy. Of these three, only anti-entropy provided reliable delivery, and it could not support message reordering or provably reliable log purges. The Lazy Replication system <ref> [Ladin90] </ref> supported causal and total message orderings, including orderings that respected casual relations caused outside the replica group. However, the protocol itself was notably inefficient.
Reference: [Lamport78] <author> Leslie Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-65, </pages> <year> 1978. </year>
Reference-contexts: The ordering can be total, so that every message is delivered in the same order at every replica; causal, so that the ordering may be different at different replicas as long as every ordering respects potential causal relations between messages <ref> [Lamport78] </ref>; or unordered, where the ordering is not coordinated between replicas. Some weak-consistency protocols, such as TSAE, allow replicas to order messages causally or totally. Several protocols that provide weakly consistent replication have been proposed.
Reference: [Lottor93] <author> Mark Lottor. </author> <title> Internet Domain Survey. </title> <type> Technical report. </type> <institution> Network Information Systems Center, SRI International, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Further, the Internet has many points that, on failure, partition the network, and at any given time it is usually partitioned into several non-communicating networks. Further, in January 1993 the Internet included more than 1.3 million hosts with an estimated 12 million users <ref> [Lottor93] </ref>. This has led to query loads on some services exceeding the capacity of a single server and the network links that support it [Emtage92]. Any replication protocol that requires interactive communication with many replicas will not work in this environment. The introduction of mobile computers exacerbates this problem further.
Reference: [Mockapetris87] <author> P. Mockapetris. </author> <title> Domain names concepts and facilities. Request for comments 1034. </title> <booktitle> ARPA Network Working Group, </booktitle> <month> November </month> <year> 1987. </year>
Reference-contexts: Many wide-area services have extremely low update rates; some services write new entries and never change them. A low update rate means that anti-entropy has a better chance of propagating an update before another update enters the system. In the Domain Name Service <ref> [Mockapetris87] </ref>, a particular host name or address rarely changes more than once every few months. In systems like Refdbms, new entries are added, corrected quickly, then remain stable. We expect the update rate for most wide-area services to be much lower than the anti-entropy rate.
Reference: [Oppen81] <author> D. C. Oppen and Y. K. Dahl. </author> <title> The Clearinghouse: a decentralized agent for locating named objects in a distributed environment. </title> <type> Technical report OPD-T8103. </type> <institution> Xerox Office Products Division, </institution> <address> Palo Alto, Ca, </address> <year> 1981. </year> <month> 14 </month>
Reference-contexts: Several Refdbms databases are replicated at sites in North America and Europe. Other existing information systems, such as Usenet [Quarterman86] and the Xerox Clearinghouse system <ref> [Oppen81, Demers88] </ref>, use other weak-consistency techniques. Our work formalizes and improves on these ad hoc approaches, providing a single framework for analyzing, comparing, and implementing them [Golding92c]. Clients using a weakly-consistent service can observe out-of-date or inconsistent information, unlike clients of a service that provides single-copy serializability. <p> Some weak-consistency protocols, such as TSAE, allow replicas to order messages causally or totally. Several protocols that provide weakly consistent replication have been proposed. The Xerox Clearinghouse <ref> [Demers88, Oppen81] </ref> name service used three epidemic replication protocols, including best-effort multicast, rumor mongery, and anti-entropy. Of these three, only anti-entropy provided reliable delivery, and it could not support message reordering or provably reliable log purges.
Reference: [Quarterman86] <author> John S. Quarterman and Josiah C. Hoskins. </author> <title> Notable computer networks. </title> <journal> Communications of the ACM, </journal> <volume> 29(10) </volume> <pages> 932-71, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: Several Refdbms databases are replicated at sites in North America and Europe. Other existing information systems, such as Usenet <ref> [Quarterman86] </ref> and the Xerox Clearinghouse system [Oppen81, Demers88], use other weak-consistency techniques. Our work formalizes and improves on these ad hoc approaches, providing a single framework for analyzing, comparing, and implementing them [Golding92c].
Reference: [Thomas79] <author> R. H. Thomas. </author> <title> A majority consensus approach to concurrency control. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4 </volume> <pages> 180-209, </pages> <year> 1979. </year>
Reference-contexts: The mechanism can be tailored to the specific needs of the service by combining the appropriate low-level communication, group management, and message management modules, which can provide guarantees ranging from traditional single-copy serializability using a strongly-consistent protocol such as quorum consensus <ref> [Gifford79, Thomas79] </ref>, to a weak-consistency mechanism using the timestamped anti-entropy (TSAE) protocol that we have developed. Weak-consistency protocols, sometimes called epidemic replication protocols, provide eventual message delivery. A database update is sent as a message to one replica.
Reference: [Turek92] <author> John Turek and Dennis Shasha. </author> <title> The many faces of consensus in distributed systems. </title> <journal> IEEE Computer, </journal> <volume> 25(6) </volume> <pages> 8-17, </pages> <month> June </month> <year> 1992. </year> <month> 15 </month>
Reference-contexts: Strong consistency requirements are impossible to meet in the most general cases, and expensive in others. For example, if there are no bounds on message delivery time it is not possible to guarantee consistency <ref> [Turek92] </ref>. If replicas can fail in arbitrary ways, providing reliable delivery is equivalent to Byzantine Agreement. For most applications the Internet can be treated as an unreliable network with bounded communication latency.
References-found: 17

