URL: http://siesta.cs.wustl.edu:80/~sg/uav.ps.Z
Refering-URL: http://siesta.cs.wustl.edu:80/~sg/
Root-URL: 
Email: sg@cs.wustl.edu  kwek@cs.wustl.edu  sds@cs.wustl.edu  
Title: Learning From Examples With Unspecified Attribute Values (Extended Abstract)  
Author: Sally A. Goldman Stephen S. Kwek Stephen D. Scott 
Address: St. Louis, MO 63130-4899  St. Louis, MO 63130-4899  St. Louis, MO 63130-4899  
Affiliation: Dept. of Computer Science Washington University  Dept. of Computer Science Washington University  Dept. of Computer Science Washington University  
Date: 1997 1  
Note: In Proceedings of the Tenth Annual ACM Conference on Computational Learning Theory, to appear,  Supported in part by NSF NYI Grant CCR-9357707 with matching funds provided by Xerox PARC and WUTA.  
Abstract: We introduce the UAV learning model in which some of the attributes in the examples are unspecified. In our model, an example x is classified positive (resp., negative) if all possible assignments for the unspecified attributes result in a positive (resp., negative) classification. Otherwise the classification given to x is "?" (for unknown). Given an example x in which some attributes are unspecified, the oracle UAV-MQ responds with the classification of x. Given a hypothesis h, the oracle UAV-EQ returns an example x (that could have unspecified attributes) for which h(x) is incorrect. We show that any class learnable in the exact model using the MQ and EQ oracles is also learnable in the UAV model using the MQ and UAV-EQ oracles as long as the counterexamples provided by the UAV-EQ oracle have a logarithmic number of unspecified attributes. We also show that any class learnable in the exact model using the MQ and EQ oracles is also learnable in the UAV model using the UAV-MQ and UAV-EQ oracles as well as an oracle to evaluate a given boolean formula on an example with unspecified attributes. (For some hypothesis classes such as decision trees and unate formulas the evaluation can be done in polynomial time without an oracle.) We also study the learnability of a universal class of decision trees under the UAV model and of DNF formulas under a representation-dependent vari ation of the UAV model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Aizenstein and L. Pitt. </author> <title> Exact learning of read-twice DNF formulas. </title> <booktitle> In Proc. 32th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 170-179. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 16, 14], read-twice DNF formulas <ref> [1] </ref>, k-term DNF formulas [11, 18], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [2] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Inform. Comput., </journal> <volume> 75(2) </volume> <pages> 87-106, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata <ref> [2] </ref>, Horn sentences [4], read-once formulas [5, 16, 14], read-twice DNF formulas [1], k-term DNF formulas [11, 18], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [3] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: The attributes could be provided by the output of feature extractors which sometimes are unable to determine whether or not a given feature is present. In this paper we introduce a variant of Angluin's exact learning model <ref> [3] </ref> in which some of the attribute 2 values are left unspecified. When first defining the PAC model, Valiant [35] also suggested a variation in which some attribute values are unspecified, but he did not study this variation. <p> relationship between the UAV and RUAV models, and then prove that the class of DNF formulas is learnable under the RUAV model using RUAV-MQ and RUAV-EQ oracles (no evaluation oracle is needed). 2 OUR LEARNING MODEL We assume the reader is familiar with the exact learning model introduced by Angluin <ref> [3] </ref>. As suggested by Valiant [35], we consider when the target concept is defined over n boolean variables x 1 ; : : : ; x n with an instance space X n = f0; 1; flg n , where "fl" indicates that the corresponding variable is unspecified. <p> For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 26, 33, 24] </ref> and when there is attribute noise [32, 21, 27]. There has also been some work in which the answers to membership queries are noisy or missing [29, 7, 34, 6, 12]. <p> Since the class of singletons can be represented by trees in T with O (n) nodes and the class of singletons cannot be learned with standard membership queries <ref> [3] </ref>, T cannot be learned using standard membership queries. This provides a second example (along with read-once formulas, see Section 3) demonstrating that the UAV-MQ oracle is more powerful than standard MQ oracle. We denote the size of a tree T by jT j. <p> Finally, since PositiveCompletion and Extract-Term make O (n 2 ) and O (n) membership queries re spectively, we have the desired result. 7 OPEN PROBLEMS In this paper, we introduced a variant of Angluin's <ref> [3] </ref> exact learning model where some of the attributes in the examples are unspecified. While we gave some initial results for this model, many interesting questions have been raised.
Reference: [4] <author> D. Angluin, M. Frazier, and L. Pitt. </author> <title> Learning conjunctions of Horn clauses. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 147-164, </pages> <year> 1992. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata [2], Horn sentences <ref> [4] </ref>, read-once formulas [5, 16, 14], read-twice DNF formulas [1], k-term DNF formulas [11, 18], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [5] <author> D. Angluin, L. Hellerstein, and M. Karpinski. </author> <title> Learning read-once formulas with queries. </title> <journal> J. ACM, </journal> <volume> 40 </volume> <pages> 185-210, </pages> <year> 1993. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata [2], Horn sentences [4], read-once formulas <ref> [5, 16, 14] </ref>, read-twice DNF formulas [1], k-term DNF formulas [11, 18], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. <p> It is known that read-once formulas are exactly learnable using only constrained instance queries [22] or using these restricted projective equivalence queries [23]. Thus read-once formulas are exactly learnable in the UAV model using only the UAV-MQ oracle. Furthermore, it is known <ref> [5] </ref> that a polynomial number of calls to the MQ oracle is not sufficient. This demonstrates (as one would expect) that the UAV-MQ oracle is more powerful than the MQ oracle.
Reference: [6] <author> D. Angluin and M. Krik~is. </author> <title> Learning with malicious membership queries and exceptions. </title> <booktitle> In Proc. 7th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 57-66. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [29, 7, 34, 6, 12] </ref>.
Reference: [7] <author> D. Angluin and D. K. </author> <title> Slonim. Randomly fallible teachers: learning monotone DNF with an incomplete membership oracle. </title> <journal> Machine Learning, </journal> <volume> 14(1) </volume> <pages> 7-26, </pages> <year> 1994. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [29, 7, 34, 6, 12] </ref>.
Reference: [8] <author> R. Bareiss B. W. Porter and R. Holte. </author> <title> Concept learning and heuristic classification in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 229-263, </pages> <year> 1990. </year>
Reference-contexts: Thus in the UAV model, the complexity of the ternary target function has the same complexity as that of the defining boolean function. There has been some empirical work studying the task of learning from incomplete data <ref> [8, 28, 13] </ref>. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner [30, 31] studied the problem of learning accurate default concepts to be used when working with incomplete data. <p> Also, instead of an adversary choosing which attributes are unspecified, in their model a total example is drawn from some fixed distribution and then some attribute values become unspecified according to some probability distribution. They investigate, under various conditions, whether the strategies <ref> [8, 28, 13] </ref> that are used in practice converge to some optimum hypothesis in the limit and the sample complexities required to achieve a certain PAC-like learning criterion.
Reference: [9] <author> S. Ben-David and E. Dichterman. </author> <title> Learning with restricted focus of attention. </title> <booktitle> In Proc. 6th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 287-296. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: A learning model that has very similar motivations to the UAV model is the model of RFA (restricted focus of attention) learnability <ref> [9, 10] </ref>. The k-RFA model is a variant of the PAC model in which for each example only k attributes (of the n attributes), as selected by the learner, are specified.
Reference: [10] <author> A. Birkendorf, E. Dichterman, J. Jackson, N. Klas-ner, and H. U. Simon. </author> <title> On restricted-focus-of-attention learnability of Boolean functions. </title> <booktitle> In Proc. 9th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 205-216. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1996. </year>
Reference-contexts: A learning model that has very similar motivations to the UAV model is the model of RFA (restricted focus of attention) learnability <ref> [9, 10] </ref>. The k-RFA model is a variant of the PAC model in which for each example only k attributes (of the n attributes), as selected by the learner, are specified.
Reference: [11] <author> A. Blum and S. Rudich. </author> <title> Fast learning of k-term DNF formulas with queries. </title> <booktitle> In Proceedings of Twenty-Fourth ACM Symposium on Theory of Computing, </booktitle> <pages> pages 382-389. </pages> <publisher> ACM, </publisher> <year> 1992. </year> <month> 12 </month>
Reference-contexts: can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 16, 14], read-twice DNF formulas [1], k-term DNF formulas <ref> [11, 18] </ref>, etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [12] <author> A. Blum, P. Chalasani, S. A. Goldman, and D. K. </author> <title> Slonim. Learning with unreliable boundary queries. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 98-107. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [29, 7, 34, 6, 12] </ref>.
Reference: [13] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <booktitle> Wadsworth International Group, </booktitle> <year> 1984. </year>
Reference-contexts: Thus in the UAV model, the complexity of the ternary target function has the same complexity as that of the defining boolean function. There has been some empirical work studying the task of learning from incomplete data <ref> [8, 28, 13] </ref>. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner [30, 31] studied the problem of learning accurate default concepts to be used when working with incomplete data. <p> Also, instead of an adversary choosing which attributes are unspecified, in their model a total example is drawn from some fixed distribution and then some attribute values become unspecified according to some probability distribution. They investigate, under various conditions, whether the strategies <ref> [8, 28, 13] </ref> that are used in practice converge to some optimum hypothesis in the limit and the sample complexities required to achieve a certain PAC-like learning criterion.
Reference: [14] <author> N. Bshouty, T. Hancock, L. Hellerstein, and M. Karpinski. </author> <title> An algorithm to learn read-once threshold formulas, and transformations between learning models. </title> <journal> Computational Complexity, </journal> <volume> 4 </volume> <pages> 37-61, </pages> <year> 1994. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata [2], Horn sentences [4], read-once formulas <ref> [5, 16, 14] </ref>, read-twice DNF formulas [1], k-term DNF formulas [11, 18], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [15] <author> N. H. Bshouty, R. Cleve, S. Kannan, and C. Ta-mon. </author> <title> Oracles and queries that are sufficient for exact learning. </title> <booktitle> In Proc. 7th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 130-139. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: Furthermore, it is known [5] that a polynomial number of calls to the MQ oracle is not sufficient. This demonstrates (as one would expect) that the UAV-MQ oracle is more powerful than the MQ oracle. Bshouty, Cleve, Kannan and Tamon <ref> [15] </ref> show that DNF formulas can be learned in randomized expected polynomial time with equivalence queries and the aid of an NP oracle. Using this result, they also show that DNF formulas can be learned using subset and super-set queries.
Reference: [16] <author> N. H. Bshouty, T. R. Hancock, and L. Hellerstein. </author> <title> Learning arithmetic read-once formulas. </title> <booktitle> In Proc. 24th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 370-381. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata [2], Horn sentences [4], read-once formulas <ref> [5, 16, 14] </ref>, read-twice DNF formulas [1], k-term DNF formulas [11, 18], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [17] <author> N. H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <booktitle> In Proceedings of the 34rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 302-311. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1993. </year>
Reference-contexts: Finally, a corresponding model of UAV PAC Learning can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees <ref> [17] </ref>, deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 16, 14], read-twice DNF formulas [1], k-term DNF formulas [11, 18], etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. <p> in polynomial time in the UAV model using only the UAV-EQ oracle, then C is exactly learnable in the standard model in polynomial time using only the EQ oracle. 5 LEARNING ORDERED DECISION TREES WITH A UAV-MQ ORACLE Combining our results from the last section with Bshouty's decision tree algorithm <ref> [17] </ref>, we can learn the class of decision trees in the UAV model using the UAV-MQ, UAV-EQ, and EV oracles. As discussed in Section 2, for the class of decision trees, we can implement the EV oracle efficiently.
Reference: [18] <author> N. H. Bshouty. </author> <title> Simple learning algorithms using divide and conquer. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 447-453. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: can be naturally defined. 3 RELATED WORK Within the exact learning model a number of interesting polynomial time algorithms have been presented to learn target classes such as decision trees [17], deterministic finite automata [2], Horn sentences [4], read-once formulas [5, 16, 14], read-twice DNF formulas [1], k-term DNF formulas <ref> [11, 18] </ref>, etc. For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice.
Reference: [19] <author> M. Frazier, S. Goldman, N. Mishra, and L. Pitt. </author> <title> Learning from a consistently ignorant teacher. </title> <booktitle> In Proc. 7th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 328-339. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: In other related work, Frazier, Goldman, Mishra, and Pitt <ref> [19] </ref> introduce a learning model that captures the idea that teachers may have gaps in their knowledge.
Reference: [20] <author> R. Greiner, A. Grove, and D. Roth. </author> <title> Learning active classifiers. </title> <booktitle> In Proc. 13th Int. Conf. on Machine Learning, </booktitle> <pages> pages 207-215. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: There has been some research in this direction (such as the work of Greiner, Grove and Roth <ref> [20] </ref>). By allowing the cost to possibly be infinite this could model the situation in which some unspecified attributes could be obtained (at some given cost), yet the values of some unspecified attributes are just not available.
Reference: [21] <author> S. A. Goldman and R. H. Sloan. </author> <title> Can PAC learning algorithms tolerate random attribute noise? Algo-rithmica, </title> <booktitle> 14 </booktitle> <pages> 70-84, </pages> <year> 1995. </year>
Reference-contexts: Although different from the goals of our work, there has been work on learning when the examples may be mislabeled [3, 26, 33, 24] and when there is attribute noise <ref> [32, 21, 27] </ref>. There has also been some work in which the answers to membership queries are noisy or missing [29, 7, 34, 6, 12].
Reference: [22] <author> T. Hancock. </author> <title> Identifying -decision trees and -formulas with constrained instance queries. </title> <type> Manuscript, </type> <institution> Harvard University, </institution> <year> 1989. </year>
Reference-contexts: Finally, there have been two oracles studied that are similar to the UAV-MQ oracle: the constrained instance oracle <ref> [22] </ref> and the projective equivalence oracle [23]. We use CIQ to denote a constrained instance query, and PEQ to denote a projective equivalence query. <p> It is known that read-once formulas are exactly learnable using only constrained instance queries <ref> [22] </ref> or using these restricted projective equivalence queries [23]. Thus read-once formulas are exactly learnable in the UAV model using only the UAV-MQ oracle. Furthermore, it is known [5] that a polynomial number of calls to the MQ oracle is not sufficient.
Reference: [23] <author> L. Hellerstein and M. Karpinski. </author> <title> Learning read-once formulas using membership queries. </title> <booktitle> In Proc. of the Second Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 146-161. </pages> <publisher> Morgan Kauf-mann, </publisher> <year> 1989. </year>
Reference-contexts: Finally, there have been two oracles studied that are similar to the UAV-MQ oracle: the constrained instance oracle [22] and the projective equivalence oracle <ref> [23] </ref>. We use CIQ to denote a constrained instance query, and PEQ to denote a projective equivalence query. <p> It is known that read-once formulas are exactly learnable using only constrained instance queries [22] or using these restricted projective equivalence queries <ref> [23] </ref>. Thus read-once formulas are exactly learnable in the UAV model using only the UAV-MQ oracle. Furthermore, it is known [5] that a polynomial number of calls to the MQ oracle is not sufficient.
Reference: [24] <author> M. Kearns and M. Li. </author> <title> Learning in the presence of malicious errors. </title> <journal> SIAM J. Comput., </journal> <volume> 22 </volume> <pages> 807-837, </pages> <year> 1993. </year>
Reference-contexts: For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 26, 33, 24] </ref> and when there is attribute noise [32, 21, 27]. There has also been some work in which the answers to membership queries are noisy or missing [29, 7, 34, 6, 12].
Reference: [25] <author> M. J. Kearns and R. E. Schapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In Proc. of the 31st Symposium on the Foundations of Comp. Sci., </booktitle> <pages> pages 382-391. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1990. </year>
Reference-contexts: Thus we feel it is important 4 for our model to classify examples that have unspecified attributes. This requirement has lead us to have a three-valued (versus binary) output. Some work that has similar motivations is the p-concepts model of Kearns and Schapire <ref> [25] </ref>.
Reference: [26] <author> P. D. Laird. </author> <title> Learning from Good and Bad Data. </title> <booktitle> Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 26, 33, 24] </ref> and when there is attribute noise [32, 21, 27]. There has also been some work in which the answers to membership queries are noisy or missing [29, 7, 34, 6, 12].
Reference: [27] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Com-put. Learning Theory, </booktitle> <pages> pages 147-156, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although different from the goals of our work, there has been work on learning when the examples may be mislabeled [3, 26, 33, 24] and when there is attribute noise <ref> [32, 21, 27] </ref>. There has also been some work in which the answers to membership queries are noisy or missing [29, 7, 34, 6, 12].
Reference: [28] <author> J. R. Quinlan. </author> <title> Unknown attribute values in induction. </title> <booktitle> In Proceedings of the 6th International Machine Learning Workshop, </booktitle> <pages> pages 164-168, </pages> <year> 1989. </year>
Reference-contexts: Thus in the UAV model, the complexity of the ternary target function has the same complexity as that of the defining boolean function. There has been some empirical work studying the task of learning from incomplete data <ref> [8, 28, 13] </ref>. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner [30, 31] studied the problem of learning accurate default concepts to be used when working with incomplete data. <p> Also, instead of an adversary choosing which attributes are unspecified, in their model a total example is drawn from some fixed distribution and then some attribute values become unspecified according to some probability distribution. They investigate, under various conditions, whether the strategies <ref> [8, 28, 13] </ref> that are used in practice converge to some optimum hypothesis in the limit and the sample complexities required to achieve a certain PAC-like learning criterion.
Reference: [29] <author> Y. Sakakibara. </author> <title> On learning from queries and counterexamples in the presence of noise. </title> <journal> Inform. Proc. Lett., </journal> <volume> 37(5) </volume> <pages> 279-284, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [29, 7, 34, 6, 12] </ref>.
Reference: [30] <author> D. Schuurmans and R. Greiner. </author> <title> Learning default concepts. </title> <booktitle> In Proceedings of the Tenth Canadian Conference on Artificial Intelligence, </booktitle> <pages> pages 519-523, </pages> <year> 1994. </year>
Reference-contexts: There has been some empirical work studying the task of learning from incomplete data [8, 28, 13]. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner <ref> [30, 31] </ref> studied the problem of learning accurate default concepts to be used when working with incomplete data.
Reference: [31] <author> D. Schuurmans and R. Greiner. </author> <title> Learning to Classify Incomplete Examples, chapter 6. </title> <publisher> MIT Press, </publisher> <year> 1997. </year>
Reference-contexts: There has been some empirical work studying the task of learning from incomplete data [8, 28, 13]. With the goal of giving a theoretical explanation for the observed empirical phenomena, Schuurmans and Greiner <ref> [30, 31] </ref> studied the problem of learning accurate default concepts to be used when working with incomplete data.
Reference: [32] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In Proc. 1st Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 97-103, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although different from the goals of our work, there has been work on learning when the examples may be mislabeled [3, 26, 33, 24] and when there is attribute noise <ref> [32, 21, 27] </ref>. There has also been some work in which the answers to membership queries are noisy or missing [29, 7, 34, 6, 12].
Reference: [33] <author> R. H. Sloan. </author> <title> Types of noise in data for concept learning. </title> <booktitle> In Proc. 1st Annu. Workshop on Com-put. Learning Theory, </booktitle> <pages> pages 91-96, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For all of these classes it is known (using information-theoretic arguments), that neither membership queries nor equivalence queries alone suffice. Although different from the goals of our work, there has been work on learning when the examples may be mislabeled <ref> [3, 26, 33, 24] </ref> and when there is attribute noise [32, 21, 27]. There has also been some work in which the answers to membership queries are noisy or missing [29, 7, 34, 6, 12].
Reference: [34] <author> R. H. Sloan and G. Turan. </author> <title> Learning with queries but incomplete information. </title> <booktitle> In Proc. 7th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 237-245. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: There has also been some work in which the answers to membership queries are noisy or missing <ref> [29, 7, 34, 6, 12] </ref>.
Reference: [35] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Commun. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: In this paper we introduce a variant of Angluin's exact learning model [3] in which some of the attribute 2 values are left unspecified. When first defining the PAC model, Valiant <ref> [35] </ref> also suggested a variation in which some attribute values are unspecified, but he did not study this variation. In our new model, the examples are drawn from f0; 1; flg n where "fl" denotes unspecified. <p> As suggested by Valiant <ref> [35] </ref>, we consider when the target concept is defined over n boolean variables x 1 ; : : : ; x n with an instance space X n = f0; 1; flg n , where "fl" indicates that the corresponding variable is unspecified.
References-found: 35

