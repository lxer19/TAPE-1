URL: http://www.cs.umr.edu/techreports/93-16.ps
Refering-URL: http://www.cs.umr.edu/techreports/
Root-URL: 
Title: A General Method for Maximizing the Error-Detecting Ability of Distributed Algorithms 1 2  
Author: Martina Schollmeyer and Bruce McMillin 
Date: June 23, 1993 CSC 93-16  
Abstract: The bound on component failures and their spatial distribution govern the fault tolerance of any candidate error-detecting algorithm. For distributed memory multiprocessors, the specific algorithm and the topology of the processor interconnection network define these bounds. This paper introduces the maximal fault index, derived from the system topology and local communication patterns, to demonstrate how a maximal number of simultaneous (Byzantine) component failures can be tolerated for a particular interconnection network and error-detecting algorithm. The index is used to design a fault-tolerant mapping of processes to processor groups such that the error-detecting ability of the algorithm is preserved for certain multiple simultaneous processor failures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.M. Andrews. </author> <title> Using executable assertions for testing and fault tolerance. </title> <booktitle> Proceedings of the 9th FTCS, </booktitle> <pages> pages 102-105, </pages> <year> 1979. </year>
Reference-contexts: These algorithms can be generated by using executable 15 3-cube. assertions for error detection [12], <ref> [1] </ref>. Assertions can, for example, be obtained from program verification. A properly chosen set of assertions guarantees that, when operationally evaluated, such as in Changeling [12], the program meets its specifications or an error will be flagged.
Reference: [2] <author> F. Cristian, H. Aghili, and R. </author> <title> Strong. Atomic broadcast: From simple message diffusion to byzantine agreement. </title> <booktitle> Proceedings of the 15th FTCS, </booktitle> <pages> pages 200-206, </pages> <year> 1985. </year>
Reference-contexts: must satisfy the following relation: For i 2 f1; 2; Qg; fi fi fi a i;i 4 j6=i (K) 3 (k) fi fi fi ! To verify the post assertion, each process will send its last computed value of u (K) other members of its CE using message diffusion 3 <ref> [2] </ref>. By checking the different versions that arrive on these paths [12], each processor in the CE must receive identical versions of a sent message or will detect an error if inconsistencies between messages from the same sender are discovered.
Reference: [3] <author> W. Dally and C. Seitz. </author> <title> The torus routing chip. </title> <journal> Journal of Distributed Computing, </journal> <volume> 1(3) </volume> <pages> 187-196, </pages> <year> 1986. </year>
Reference-contexts: Frequently, algorithms restrict interprocessor communication to adjacent processors to improve efficiency. However, new routing technologies, such as wormhole routing, make the delivery of messages to processors that are a distance of more than one away almost as efficient as direct communication <ref> [3] </ref>. We allow for both types of interactions in the communication environment. Definition 2.1 The communication environment (CE) of a processor P i is the set of processors from which P i will receive information during the execution of a program. This set includes P i as well.
Reference: [4] <author> J. Fortes and C. Raghavendra. </author> <title> Graceful degradable processor arrays. </title> <journal> IEEE Trans. On Computers, </journal> <volume> C-34:1033-1044, </volume> <month> November </month> <year> 1985. </year>
Reference-contexts: Section 6 provides an example of how this form of assessment can be used in an error-detecting matrix relaxation algorithm. 3 2 Terminology for MPS Topologies In this paper we examine fixed-topology multiprocessor systems as discussed in <ref> [4] </ref>, [8], [11], [17].
Reference: [5] <author> M. Garey and Johnson D. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year> <month> 19 </month>
Reference-contexts: in NP. fl Lemma 4.2 A variant of the 0,1 integer programming problem in which all components of ~y are required to be in 0,1, called 0,1-integer programming, which is NP-complete, even if all components of each ~x, b and all components of ~c are required to be in 0,1 <ref> [5] </ref>, can be reduced to the FTD problem in polynomial time. The proof for Lemma 4.2 is given in [18].
Reference: [6] <author> D. Gu, D.J. Rosenkrantz, and S.S. Ravi. </author> <title> Determining performance measures of algorithm-based fault-tolerant systems. </title> <journal> J. of Parallel and Distributed Comp., </journal> <volume> 18(1) </volume> <pages> 56-70, </pages> <year> 1993. </year>
Reference-contexts: Section 6 provides an example of how this form of assessment can be used in an error-detecting matrix relaxation algorithm. 3 2 Terminology for MPS Topologies In this paper we examine fixed-topology multiprocessor systems as discussed in [4], [8], [11], [17]. In contrast to <ref> [6] </ref> we do not examine whether an algorithm can detect all combinations of up to k faults, where k is a specified bound, but we assume that the algorithm has been designed with a certain local fault tolerance t l , for each communication environment [13]. The analysis in [6] can <p> to <ref> [6] </ref> we do not examine whether an algorithm can detect all combinations of up to k faults, where k is a specified bound, but we assume that the algorithm has been designed with a certain local fault tolerance t l , for each communication environment [13]. The analysis in [6] can determine whether every combination of up to t l faults can be detected, and it provides the minimum number of simultaneous faults for which this condition does not hold any more.
Reference: [7] <author> R.W. </author> <title> Hamming. Error detecting and error correcting codes. </title> <journal> Bell Syst. Tech. J., </journal> <volume> 29 </volume> <pages> 147-160, </pages> <month> April </month> <year> 1950. </year>
Reference-contexts: Specifically, for d = 3, B (n; 3) = 2 m n + 1 according to <ref> [7] </ref>. This provides an upper bound for the maximal fault index. An example for a 3-cube where a set of two faulty nodes which do not interfere with each others' computations and communications are marked is given in Figure 10 (left).
Reference: [8] <author> J. Hayes. </author> <title> A graph model for fault-tolerant computing systems. </title> <journal> IEEE Trans. On Computers, </journal> <volume> C-25:875-883, </volume> <month> September </month> <year> 1976. </year>
Reference-contexts: Section 6 provides an example of how this form of assessment can be used in an error-detecting matrix relaxation algorithm. 3 2 Terminology for MPS Topologies In this paper we examine fixed-topology multiprocessor systems as discussed in [4], <ref> [8] </ref>, [11], [17].
Reference: [9] <author> R. Hummel and S. Zucker. </author> <title> On the foundations of relaxation labeling processes. </title> <journal> PAMI, </journal> <volume> PAMI-5(3):267-287, </volume> <month> May </month> <year> 1984. </year>
Reference-contexts: Relaxation can be used in such diverse problem ranging from relaxation labeling <ref> [9] </ref> in distributed scene analysis to computational partial differential equation solvers [14].
Reference: [10] <author> J. Jou and J. Abraham. </author> <title> Fault-tolerant matrix arithmetic and signal processing on highly parallel computing structures. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 74(5) </volume> <pages> 732-741, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: A fault-tolerant mapping of the nodes onto a smaller set of processors is given in Figure 10 (right). 6 A Specific Example of an Error-Detecting Algo rithm Error-detecting algorithms work by checking, at run time, for hardware, communication <ref> [10] </ref>, and software errors [14]. These algorithms can be generated by using executable 15 3-cube. assertions for error detection [12], [1]. Assertions can, for example, be obtained from program verification.
Reference: [11] <author> T. Leighton and C. Leierson. </author> <title> Wafer-scale integration of systolic arrays. </title> <journal> IEEE Trans. On Computers, </journal> <volume> C-34:448-461, </volume> <month> May </month> <year> 1985. </year>
Reference-contexts: Section 6 provides an example of how this form of assessment can be used in an error-detecting matrix relaxation algorithm. 3 2 Terminology for MPS Topologies In this paper we examine fixed-topology multiprocessor systems as discussed in [4], [8], <ref> [11] </ref>, [17].
Reference: [12] <author> H. Lutfiyya, M. Schollmeyer, and B. McMillin. </author> <title> Fault-tolerant distributed sort generated from a verification proof outline. </title> <booktitle> 2nd Responsive Systems Symposium, 1992. </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: These algorithms can be generated by using executable 15 3-cube. assertions for error detection <ref> [12] </ref>, [1]. Assertions can, for example, be obtained from program verification. A properly chosen set of assertions guarantees that, when operationally evaluated, such as in Changeling [12], the program meets its specifications or an error will be flagged. <p> These algorithms can be generated by using executable 15 3-cube. assertions for error detection <ref> [12] </ref>, [1]. Assertions can, for example, be obtained from program verification. A properly chosen set of assertions guarantees that, when operationally evaluated, such as in Changeling [12], the program meets its specifications or an error will be flagged. In general, we add executable assertions after each statement, which then verify that the previous statement was executed correctly. In case of an error, the assertions can force the program to halt execution to indicate the faulty condition. <p> The desired topology of the interconnection network for this computation is a two-dimensional mesh. The data exchange pattern for this algorithm corresponds to a communication with all adjacent processors in the mesh, which we described in Section 5.1.2 as the star pattern. 16 6.2 Error-Detecting Matrix Relaxation Using Changeling <ref> [12] </ref>, a program verification proof outline based on axiomatic semantics 2 is used to construct an error-detecting matrix relaxation. <p> By checking the different versions that arrive on these paths <ref> [12] </ref>, each processor in the CE must receive identical versions of a sent message or will detect an error if inconsistencies between messages from the same sender are discovered. The system of equations to be solved by the relaxation algorithm has a unique solution.
Reference: [13] <author> B. McMillin. </author> <title> Reliable parallel processing: The application-oriented paradigm. </title> <type> Ph.D Thesis, </type> <institution> Computer Science Department, Michigan State University, </institution> <year> 1988. </year>
Reference-contexts: In contrast to [6] we do not examine whether an algorithm can detect all combinations of up to k faults, where k is a specified bound, but we assume that the algorithm has been designed with a certain local fault tolerance t l , for each communication environment <ref> [13] </ref>. The analysis in [6] can determine whether every combination of up to t l faults can be detected, and it provides the minimum number of simultaneous faults for which this condition does not hold any more.
Reference: [14] <author> B. McMillin and L. Ni. </author> <title> Executable assertion development for the distributed parallel environment. </title> <booktitle> Proceedings of the 12th International COMPSAC, </booktitle> <pages> pages 284-291, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: A fault-tolerant mapping of the nodes onto a smaller set of processors is given in Figure 10 (right). 6 A Specific Example of an Error-Detecting Algo rithm Error-detecting algorithms work by checking, at run time, for hardware, communication [10], and software errors <ref> [14] </ref>. These algorithms can be generated by using executable 15 3-cube. assertions for error detection [12], [1]. Assertions can, for example, be obtained from program verification. <p> Relaxation can be used in such diverse problem ranging from relaxation labeling [9] in distributed scene analysis to computational partial differential equation solvers <ref> [14] </ref>.
Reference: [15] <author> B. McMillin and L. Ni. </author> <title> Reliable distributed sorting through the application-oriented fault tolerance paradigm. </title> <journal> IEEE Trans. of Parallel and Distributed Computing, </journal> <volume> 3(4) </volume> <pages> 411-420, </pages> <year> 1992. </year>
Reference-contexts: For simplification, we will focus only on processor failures, since a processor failure can be described by the failure of all its links, and a link failure can be described by indicating a processor failure <ref> [15] </ref>. We assume the worst-case fault model of Byzantine (malicious) behavior where a faulty process can lose or modify messages. We can check for lost messages as well as inconsistency of the data by sending multiple copies of the same message through node-disjoint paths.
Reference: [16] <author> P. Ramanathan and S. Chalasani. </author> <title> Resource placement in k-ary n-cubes. </title> <booktitle> Proc. Intern. Conf. on Parallel Processing, </booktitle> <address> II:133-140, </address> <year> 1992. </year>
Reference-contexts: For P faulty and t l = 1, none of these processors must be faulty. In the ideal case we obtain a distribution of faulty processors that is identical to the perfect 1-adjacency placement of resources, where each non-resource node is adjacent to exactly one resource <ref> [16] </ref>, which in our case is a faulty component. [16] show that the number of resource nodes in a k-ary n-cube for perfect 1-adjacency is X = k n =(2n + 1); k &gt; 2 a torus-connected mesh (wrap-around not shown), and the fault-tolerant mapping. 14 which must be an integer. <p> In the ideal case we obtain a distribution of faulty processors that is identical to the perfect 1-adjacency placement of resources, where each non-resource node is adjacent to exactly one resource <ref> [16] </ref>, which in our case is a faulty component. [16] show that the number of resource nodes in a k-ary n-cube for perfect 1-adjacency is X = k n =(2n + 1); k &gt; 2 a torus-connected mesh (wrap-around not shown), and the fault-tolerant mapping. 14 which must be an integer.
Reference: [17] <author> A. Rosenberg. </author> <title> The diogenes approach to testable fault-tolerant arrays of processors. </title> <journal> IEEE Trans. On Computers, </journal> <volume> C-32:902-910, </volume> <month> October </month> <year> 1983. </year>
Reference-contexts: Section 6 provides an example of how this form of assessment can be used in an error-detecting matrix relaxation algorithm. 3 2 Terminology for MPS Topologies In this paper we examine fixed-topology multiprocessor systems as discussed in [4], [8], [11], <ref> [17] </ref>. In contrast to [6] we do not examine whether an algorithm can detect all combinations of up to k faults, where k is a specified bound, but we assume that the algorithm has been designed with a certain local fault tolerance t l , for each communication environment [13].
Reference: [18] <author> M. Schollmeyer and B. McMillin. </author> <title> A general method for maximizing the error-detecting ability of distributed algorithms. </title> <institution> UMR Department of Computer Science Technical Report CS-93-16, </institution> <year> 1993. </year> <month> 20 </month>
Reference-contexts: The proof for Lemma 4.2 is given in <ref> [18] </ref>.
References-found: 18

