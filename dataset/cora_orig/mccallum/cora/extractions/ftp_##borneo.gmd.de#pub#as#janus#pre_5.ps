URL: ftp://borneo.gmd.de/pub/as/janus/pre_5.ps
Refering-URL: http://borneo.gmd.de/AS/janus/publi/publi.html
Root-URL: 
Title: Hyperplane Dynamics as a Means to Understanding Back-Propagation Learning and Network Plasticity  
Author: Frank J. Smieja 
Note: for Complex Systems  
Date: March 1992, revised  1994  
Address: Schlo Birlinghoven, 52357 St. Augustin, Germany.  
Affiliation: German National Research Centre for Computer Science (GMD),  
Abstract: The processing performed by a feed-forward neural network is often interpreted through use of decision hyperplanes at each layer. The adaptation process, however, is normally explained using the picture of gradient descent of an error landscape. In this paper the dynamics of the decision hyperplanes is used as the model of the adaptation process. A electro-mechanical analogy is drawn where the dynamics of hyperplanes is determined by interaction forces between hyperplanes and the particles which represent the patterns. Relaxation of the system is determined by increasing hyperplane inertia (mass). This picture is used to clarify the dynamics of learning, and to go some way to explaining learning deadlocks and escaping from certain local minima. Furthermore network plasticity is introduced as a dynamic property of the system, and its reduction as a necessary consequence of information storage. Hyper-plane inertia is used to explain and avoid destructive relearning in trained networks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ahmad and G. Tesauro. </author> <title> A study of scaling and generalization in neural networks. </title> <booktitle> In Abstracts of the First Annual Meeting of the INNS, supplement to Neural Networks, Vol 1, </booktitle> <address> Boston, Mass., </address> <month> September </month> <year> 1988. </year>
Reference-contexts: It has the properties: f () 2 <ref> [0; 1] </ref> (1) f () 0:5 if 0 &lt; 0:5 otherwise. (3) The output decision hyperplane determines the values of that cause the output to lie on the transition between two logical interpretations. <p> This observation is also known as the "boundary 12 Frank J. Smieja pattern" effect and has been empirically studied by other researchers <ref> [1, 14] </ref>. Furthermore, it is worth noting that, in Figure 5, l p is measured in units of M . Thus, as the mass of the hyperplane increases, its range of influence decreases. <p> The masses of the hidden hyperplanes should be set at initial values such that the influence of each hyperplane, as indicate in the range curve shown in Figure 5, covers the whole input space. For a <ref> [0; 1] </ref> 2 input space a good value would appear to be about 0:25. The output hyperplane on the other hand can start with a higher value, because the patterns are initially very near.
Reference: [2] <author> T. Ash. </author> <title> Dynamic node creation in backpropagation networks. </title> <journal> Connection Science, </journal> <volume> 1(4), </volume> <year> 1989. </year>
Reference-contexts: That is why when many hyperplanes are used to solve an easy problem many are thrown out early on. The solution to this obvious Hyperplane Dynamics 23 16. (time and resource) wastage is to add properly initialized hyperplanes successively, as described in <ref> [2] </ref>. 7.3 Difficult problems Some problems may be of such a type that they may be represented by superposition of a much easier problem and a small (in terms of input patterns) also easy perturbing problem.
Reference: [3] <author> D. S. Broomhead and D. Lowe. </author> <title> Multivariable functional interpolation and adaptive networks. </title> <journal> Complex Systems, </journal> <volume> 2 </volume> <pages> 321-355, </pages> <year> 1988. </year>
Reference-contexts: This is precisely the claim made in the perceptron convergence theorem [12]. It could be shown here in an intuitive way using the hyperplane interpretation. This important part of the back-propagation iteration goal has been shown in general to have this form <ref> [3] </ref>. 14 Frank J. Smieja vectors ~ ~ 1 and ~ ~ 2 , are to be mapped to opposite sides.
Reference: [4] <author> S.E. Fahlman and C. Lebiere. </author> <title> The cascade-correlation learning architecture. </title> <editor> In D. S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle> <publisher> Morgen Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: This is the recoil force on a particle, from a hyperplane that is itself not able to move further. This effect is known as the "moving targets problem" in back-propagation learning <ref> [4] </ref>. The output hyperplane (s) try to solve as much as possible through their own positioning, but a few particles will be left on the wrong sides because the problem is not linearly separable. <p> This is because more and more are mapped correctly as one propagates up through the network. This is the reverse of the way most constructive algorithms <ref> [4, 10, 5] </ref> go about the task of mapping.
Reference: [5] <author> M. Frean. </author> <title> The upstart algorithm: a method for constructing and training feed-forward neural networks. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 198-209, </pages> <year> 1990. </year>
Reference-contexts: This is because more and more are mapped correctly as one propagates up through the network. This is the reverse of the way most constructive algorithms <ref> [4, 10, 5] </ref> go about the task of mapping.
Reference: [6] <author> J. F. Kolen and J. B. Pollack. </author> <title> Back propagation is sensitive to initial conditions. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 269-280, </pages> <year> 1990. </year>
Reference-contexts: This gives a good range of hyperplanes that slice the distribution of input patterns. The orientations are randomly initialized. from the origin are small, and the orientations randomly chosen. The importance of initial weight configurations has been often noted, see for example <ref> [6] </ref>. With our representation of the system it is easier to see what kind of Hyperplane Dynamics 17 HU space. a difference they can make.
Reference: [7] <author> J. K. Kruschke and J. R. Movellan. </author> <title> Benefits of gain: Speeded learning and minimal hidden layers in back-propagation networks. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 21(1), </volume> <year> 1991. </year> <title> Hyperplane Dynamics 27 </title>
Reference-contexts: We believe the idea of a hyperplane mass has not explicitly been employed before in any description of back-propagation. Normally it is mentioned that "weights just get ever larger" without really understanding how important this is. We are aware of only one other technique <ref> [7] </ref> that indirectly makes use of a quantity similar to mass. The interpretation was used to explain pictorially the learning dynamics of backpropagation with hidden layers, and how the information is stored in the network in the form of hyperplane mass. The importance of weight initialization was made intuitively obvious.
Reference: [8] <author> R. P. Lippmann. </author> <title> An introduction to computing with neural nets. </title> <journal> IEEE ASSP Magazine, </journal> <month> April </month> <year> 1987. </year>
Reference-contexts: The latter option is only possible in this perceptron-like network for linearly separable problems <ref> [8] </ref>, which indicates "problem solved".
Reference: [9] <author> P. Lorraine and D. Corson. </author> <title> Electromagnetic Fields and Waves. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1970. </year>
Reference-contexts: The center of mass for this system we define as that point on the plate nearest the origin, a distance ~x away (see Figure 4). A useful analogy for an interaction is electrostatics (see, for example, <ref> [9] </ref>). Let us distinguish the two plate surfaces using the vector ~n, which points from the negative to the positive surface. Imagine the plate h to possess an overall uniform charge +q h on its positive surface, and q h on its negative surface (Figure 1).
Reference: [10] <author> M. Mezard and J-P. Nadal. </author> <title> Learning in feedforward layered networks: The tiling algorithm. </title> <journal> Journal of Physics A, </journal> <volume> 22(12) </volume> <pages> 2191-2203, </pages> <year> 1989. </year>
Reference-contexts: This is because more and more are mapped correctly as one propagates up through the network. This is the reverse of the way most constructive algorithms <ref> [4, 10, 5] </ref> go about the task of mapping.
Reference: [11] <author> H. Muhlenbein. </author> <title> Limitations of multilayer perceptrons steps towards genetic neural networks. </title> <journal> Parallel Computing, </journal> <volume> 14(3) </volume> <pages> 249-260, </pages> <year> 1990. </year>
Reference-contexts: Then it may be too late. One such example is the "= 1" problem <ref> [11] </ref>. All patterns with one bit on must be mapped to 1, and the rest to 0. The main problem (in terms of interaction strength) here is the separation of all the &gt; 1-bit patterns from the 1-bit patterns. <p> It takes a long time because the hyperplane is already quite massive, due to the many other correctly mapped patterns. In such exceptional circumstances, the minimal solution (defined in <ref> [11] </ref>) consists of one hyperplane separating just this single pattern from the rest of the patterns, in the input layer.
Reference: [12] <author> F. Rosenblatt. </author> <title> Principles of Neurodynamics. </title> <publisher> Spartan Books, </publisher> <address> New York, </address> <year> 1959. </year>
Reference-contexts: In other words the hyperplane looks for the position that would be found by a least squares approximation through the points specified by the particle positions. This is precisely the claim made in the perceptron convergence theorem <ref> [12] </ref>. It could be shown here in an intuitive way using the hyperplane interpretation. This important part of the back-propagation iteration goal has been shown in general to have this form [3]. 14 Frank J.
Reference: [13] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <journal> Nature, </journal> <volume> 323(533), </volume> <year> 1986. </year>
Reference-contexts: In the back-propagation algorithm the weights ~w to the output unit are changed by the following amount each update epoch (assuming batch update 1 ): ~w = p 1 When online (or per-sample) learning is performed in small steps it approximates to batch learning <ref> [13] </ref>. 4 Frank J. Smieja where f p0 is the differential of the output node function, t p is the target value for pattern ~ ~ p at the output unit, and o p is the actual network output value for this pattern.
Reference: [14] <author> A. Schutte. </author> <title> How can multi-layer perceptrons classify. </title> <booktitle> In Proceedings of the Workshop on Distributed Adaptive Neural Information Processing, GMD, </booktitle> <address> St Augustin, April 1989. </address> <publisher> Oldenbourg Verlag. </publisher>
Reference-contexts: This observation is also known as the "boundary 12 Frank J. Smieja pattern" effect and has been empirically studied by other researchers <ref> [1, 14] </ref>. Furthermore, it is worth noting that, in Figure 5, l p is measured in units of M . Thus, as the mass of the hyperplane increases, its range of influence decreases.
Reference: [15] <author> F. J. Smieja. </author> <title> Neural network constructive algorithms: Trading generalization for learning efficiency? Circuits, </title> <journal> Systems and Signal Processing, </journal> <volume> 12(2) </volume> <pages> 331-374, </pages> <year> 1993. </year>
Reference-contexts: This is the reverse of the way most constructive algorithms [4, 10, 5] go about the task of mapping. They start at the top, mapping more and more patterns as the networks grow in the direction nearer the output <ref> [15] </ref>. * To extend to the N O output-unit case, the only change needed is to perform a summation in eqn. (43) over the output hyperplanes k for the mass and potential terms: q j N O X M k g k (l p )q k 5 The significance of hyperplane
Reference: [16] <author> F. J. Smieja and H. Muhlenbein. </author> <title> The geometry of multilayer perceptron solutions. </title> <journal> Parallel Computing, </journal> <volume> 14 </volume> <pages> 261-275, </pages> <year> 1990. </year>
Reference-contexts: The index j labels the hidden hyperplanes. Hidden-unit (HU) space <ref> [16] </ref> is cartesian and defined by the orthonormal set of vectors f~e j g, j = 1; : : : ; N H .
References-found: 16

