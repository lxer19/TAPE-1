URL: ftp://ftp.cs.toronto.edu/pub/radford/sff.ps.Z
Refering-URL: http://www.cs.toronto.edu/~radford/sff.abstract.html
Root-URL: 
Title: Learning Stochastic Feedforward Networks  
Author: Radford M. Neal 
Date: November, 1990  
Affiliation: Department of Computer Science University of Toronto  
Abstract: Connectionist learning procedures are presented for "sigmoid" and "noisy-OR" varieties of stochastic feedforward network. These networks are in the same class as the "belief networks" used in expert systems. They represent a probability distribution over a set of visible variables using hidden variables to express correlations. Conditional probability distributions can be exhibited by stochastic simulation for use in tasks such as classification. Learning from empirical data is done via a gradient-ascent method analogous to that used in Boltzmann machines, but due to the feedforward nature of the connections, the negative phase of Boltzmann machine learning is unnecessary. Experimental results show that, as a result, learning in a sigmoid feedforward network can be faster than in a Boltzmann machine. These networks have other advantages over Boltzmann machines in pattern classification and decision making applications, and provide a link between work on connectionist learning and work on the representation of expert knowledge. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ackley, D. H., Hinton, G. E., and Sejnowski, T. J. </author> <title> (1985) A learning algorithm for Boltzmann machines, </title> <journal> Cognitive Science, </journal> <volume> vol. 9, </volume> <pages> pp. 147-169. </pages> <editor> Also found in D. Waltz and J. A. Feldman (editors), </editor> <title> Connectionist Models and Their Implications: </title> <booktitle> Readings from Cognitive 32 Science, </booktitle> <address> Norwood, New Jersey: </address> <publisher> Ablex. </publisher>
Reference-contexts: Introduction The work reported here began with the desire to find a network architecture that shared with Boltzmann machines <ref> [6, 1, 7] </ref> the capacity to learn arbitrary probability distributions over binary vectors, but that did not require the negative phase of Boltzmann machine learning. It was hypothesized that eliminating the negative phase would improve learning performance. <p> A review of Boltzmann machines The Boltzmann machine <ref> [6, 1, 7] </ref> is most naturally viewed as a device for modeling a probability distribution, from which conditional distributions for use in pattern completion and classification may be derived. In the limit as probabilities approach zero and one, deterministic input-output mappings can be represented as well.
Reference: [2] <author> Bridle, J. S. </author> <title> (1989) Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition, </title> <editor> in F. Fougelman-Soulie and J. Herault (editors) Neuro-computing: </editor> <booktitle> Algorithms, Architectures, and Applications, </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The output of unit c, representing P (Class = c j Input), is set to exp (X c )= P i exp (X i ), where X i is the total input of unit i <ref> [2] </ref>. Distributions over a vector of output attributes can be represented using several such clusters, under the assumption that the probabilities for the various attributes are independent. Stochastic networks have the more general capacity to exhibit distributions over a large output vector in which there are arbitrary dependencies among attributes.
Reference: [3] <author> Dempster, A. P., Laird, N. M., and Rubin, D. B. </author> <title> (1977) Maximum likelihood from incomplete data via the EM algorithm (with discussion), </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 39, </volume> <pages> pp. 1-38. </pages>
Reference-contexts: For comparison, results from a maximum-likelihood fit of a mixture model with six components to the training data using the EM algorithm <ref> [3, 15] </ref> are given as well, evaluated on a test sample of 5000 items. <p> For noisy-OR networks, one possibility is to apply a stochastic version of the EM algorithm <ref> [3] </ref>. This seems feasible provided that the efficacy of each input to a unit in forcing the unit to take on the value 1 is made explicit in a set of auxiliary units that are stochastically simulated along with the main units.
Reference: [4] <author> Derthick, M. </author> <title> (1984) Variations on the Boltzmann machine learning algorithm, </title> <type> Technical Report CMU-CS-84-120, </type> <institution> Pittsburg: Carnegie-Mellon University, Department of Computer Science. </institution>
Reference-contexts: Regarding point (6), one would expect any problems with overfitting to be similar for the various networks, since they all have the same number of free parameters. The learning procedure used. Numerous variations of the Boltzmann machine learning procedure have been tried <ref> [4] </ref>, each of which requires fixing a number of parameters, such as the learning rate, and the temperatures in an annealing schedule.
Reference: [5] <author> Henrion, M. </author> <title> (1988) Towards efficient probabilistic diagnosis in multiply connected belief networks, </title> <editor> in R. M. Oliver and J. Q. </editor> <title> Smith (editors) Influence Diagrams, Belief Nets and Decision Analysis (proceedings of a conference entitled `Influence diagrams for decision analysis, inference, and prediction', </title> <address> Berkeley, USA, 1988), Chichester, England: </address> <publisher> John Wiley. </publisher>
Reference-contexts: Even if some of the preceding units are not connected to unit i, more compact specifications will generally be necessary. One method, termed the "noisy-OR" model <ref> [11, 5] </ref>, views the units as 0=1 valued OR-gates with the preceding units as inputs. An input of 1 does not invariably force a unit to take on the value 1, however. <p> The particular properties of the noisy-OR model might also be desirable for technical reasons; they are exploited in the heuristic diagnostic search algorithm of <ref> [5] </ref>, for example. Noisy-OR and sigmoid units can also be mixed in the same network, and for that matter, encorporating a Boltzmann machine as a sub-network is not impossible. Making decisions. Stochastic feedforward networks are compatible with the "influence diagrams" used to formulate decision problems.
Reference: [6] <author> Hinton, G. E., Sejnowski, T. J., and Ackley, D. H. </author> <title> (1984) Boltzmann machines: Constraint satisfaction networks that learn, </title> <type> Technical Report CMU-CS-84-119, </type> <institution> Pittsburg: Carnegie-Mellon University, Department of Computer Science. </institution>
Reference-contexts: Introduction The work reported here began with the desire to find a network architecture that shared with Boltzmann machines <ref> [6, 1, 7] </ref> the capacity to learn arbitrary probability distributions over binary vectors, but that did not require the negative phase of Boltzmann machine learning. It was hypothesized that eliminating the negative phase would improve learning performance. <p> A review of Boltzmann machines The Boltzmann machine <ref> [6, 1, 7] </ref> is most naturally viewed as a device for modeling a probability distribution, from which conditional distributions for use in pattern completion and classification may be derived. In the limit as probabilities approach zero and one, deterministic input-output mappings can be represented as well.
Reference: [7] <author> Hinton, G. E. and Sejnowski, T. J. </author> <title> (1986) Learning and relearning in Boltzmann machines, </title> <editor> in D. E. Rumelhart and J. L. McClelland (editors), </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations, </booktitle> <address> Cambridge, Mas-sachusetts: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Introduction The work reported here began with the desire to find a network architecture that shared with Boltzmann machines <ref> [6, 1, 7] </ref> the capacity to learn arbitrary probability distributions over binary vectors, but that did not require the negative phase of Boltzmann machine learning. It was hypothesized that eliminating the negative phase would improve learning performance. <p> A review of Boltzmann machines The Boltzmann machine <ref> [6, 1, 7] </ref> is most naturally viewed as a device for modeling a probability distribution, from which conditional distributions for use in pattern completion and classification may be derived. In the limit as probabilities approach zero and one, deterministic input-output mappings can be represented as well. <p> Effect of failure to reach equilibrium. Although it was not a major factor in the experiment described here, failure to reach equilibrium in the simulations is noted as a problem in <ref> [7] </ref>, where it is observed that after a period of good progress learning can "go sour", as weights are built up to values where they form large energy barriers that inhibit settling to the equilibrium distribution. The authors prescribe "weight-decay" as a partial solution. <p> More ambitiously, in parts of the network where causal connections are not clear to the expert a pool of hidden units could be included and their weights trained from empirical data. A problem with this approach is that the resulting networks may be hard to interpret. Using "weight decay" <ref> [7] </ref> to encourage some weights to go to zero might help. The desire to keep the network's operation intelligible to the experts might also lead one to use the noisy-OR model for conditional probabilities, despite the superior learning performance seen using sigmoid units. <p> Biological modeling. Stochastic feedforward networks also provide additional options for modeling of real neural processes. Although analogies between the negative phase of Boltzmann machine learning and dream sleep are speculated upon in <ref> [7] </ref>, it may well turn out that the negative phase is biologically implausible. The work here shows that this would not necessarily be fatal to the idea that stochastic simulation plays some role in learning in the brain.
Reference: [8] <author> Lauritzen, S. L. and Spiegelhalter, D. J. </author> <title> (1988) Local computations with probabilities on graphical structures and their application to expert systems (with discussion), </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 50, no. 2, </volume> <pages> pp. 157-224. </pages>
Reference-contexts: One can also easily generate a sample from the distribution for S. However, computing conditional probabilities and sampling from conditional distributions are in general difficult problems. Various methods for computing exact conditional probabilities in belief networks have been proposed <ref> [11, 13, 8] </ref>, but all are either restricted to special forms of network or have exponential time complexity in the worst case. It appears that the only plausible method of sampling from conditional distributions in belief networks with high connectivity is stochastic simulation, described by Pearl [10, 11]. <p> The need in such applications to integrate knowledge derived from experts with that derived from empirical data has been recognized by workers in the area (see the discussion in <ref> [8] </ref>, for example). The learning procedures described in this paper may contribute to solving this problem. One possible approach would be for the expert to specify the structure of a belief network (i.e. the causal connections), while leaving the numeric values of the forward conditional probabilities to be estimated empirically.
Reference: [9] <author> Oliver, R. M. and Smith, J. Q. </author> <title> (1990) Influence Diagrams, Belief Nets and Decision Analysis (proceedings of a conference entitled `Influence diagrams for decision analysis, inference, and prediction', </title> <address> Berkeley, USA, 1988), Chichester, England: </address> <publisher> John Wiley. </publisher>
Reference-contexts: A look at belief networks Belief networks, also known as "Bayesian networks", "causal networks", "influence diagrams", and "relevance diagrams", are designed, like Boltzmann machines, to represent a probability distribution over a set of attributes. Study of these networks by Pearl [11] and others <ref> [9] </ref> has been motivated principally by the desire to represent knowledge obtained from human experts, however. Accordingly, hard-to-interpret parameters such as the weights in a Boltzmann machine have been avoided in favour of more intuitive representations of conditional probabilities. Definition of belief networks.
Reference: [10] <author> Pearl, J. </author> <title> (1987) Evidential reasoning using stochastic simulation of causal models, </title> <journal> Artificial Intelligence, </journal> <volume> vol. 32, no. 2, </volume> <pages> pp. 245-257. </pages>
Reference-contexts: It appears that the only plausible method of sampling from conditional distributions in belief networks with high connectivity is stochastic simulation, described by Pearl <ref> [10, 11] </ref>. As with Boltzmann machines, a step in the simulation requires selecting a new value for unit i from its distribution conditional on the values of the other units.
Reference: [11] <author> Pearl, J. </author> <title> (1988) Probabilistic Reasoning in Intelligent System: Networks of Plausible Inference, </title> <address> San Mateo, California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Maximum likelihood, gradient-ascent learning can be done with a local Hebb-type rule. These networks turn out to fall within the general class of "belief networks" studied by Pearl <ref> [11] </ref> and others as a means of representing probabilistic knowledge in expert systems. However, the specific network architectures considered by Pearl do not use a sigmoid probability function. <p> A look at belief networks Belief networks, also known as "Bayesian networks", "causal networks", "influence diagrams", and "relevance diagrams", are designed, like Boltzmann machines, to represent a probability distribution over a set of attributes. Study of these networks by Pearl <ref> [11] </ref> and others [9] has been motivated principally by the desire to represent knowledge obtained from human experts, however. Accordingly, hard-to-interpret parameters such as the weights in a Boltzmann machine have been avoided in favour of more intuitive representations of conditional probabilities. Definition of belief networks. <p> One can also easily generate a sample from the distribution for S. However, computing conditional probabilities and sampling from conditional distributions are in general difficult problems. Various methods for computing exact conditional probabilities in belief networks have been proposed <ref> [11, 13, 8] </ref>, but all are either restricted to special forms of network or have exponential time complexity in the worst case. It appears that the only plausible method of sampling from conditional distributions in belief networks with high connectivity is stochastic simulation, described by Pearl [10, 11]. <p> It appears that the only plausible method of sampling from conditional distributions in belief networks with high connectivity is stochastic simulation, described by Pearl <ref> [10, 11] </ref>. As with Boltzmann machines, a step in the simulation requires selecting a new value for unit i from its distribution conditional on the values of the other units. <p> Even if some of the preceding units are not connected to unit i, more compact specifications will generally be necessary. One method, termed the "noisy-OR" model <ref> [11, 5] </ref>, views the units as 0=1 valued OR-gates with the preceding units as inputs. An input of 1 does not invariably force a unit to take on the value 1, however.
Reference: [12] <author> Rumelhart, D. E., Hinton, G. E., and Williams, R. J. </author> <title> (1986) Learning representations by back-propagating errors, </title> <journal> Nature, </journal> <volume> vol. 323, </volume> <pages> pp. 533-536. </pages>
Reference-contexts: The preferred output for such classification problems is a probability distribution over possible classes, conditional on the attributes presented as input. A deterministic feedforward network, trained by a method such as backpropagation <ref> [12] </ref>, can represent a distribution over two classes by simply producing the probability of one of the classes as its output.
Reference: [13] <author> Shachter, R. D. </author> <title> (1988) Probabilistic inference and influence diagrams, </title> <journal> Operations Research, </journal> <volume> vol. 36, no. 4, </volume> <pages> pp. 589-604. </pages>
Reference-contexts: One can also easily generate a sample from the distribution for S. However, computing conditional probabilities and sampling from conditional distributions are in general difficult problems. Various methods for computing exact conditional probabilities in belief networks have been proposed <ref> [11, 13, 8] </ref>, but all are either restricted to special forms of network or have exponential time complexity in the worst case. It appears that the only plausible method of sampling from conditional distributions in belief networks with high connectivity is stochastic simulation, described by Pearl [10, 11]. <p> Noisy-OR and sigmoid units can also be mixed in the same network, and for that matter, encorporating a Boltzmann machine as a sub-network is not impossible. Making decisions. Stochastic feedforward networks are compatible with the "influence diagrams" used to formulate decision problems. An algorithm of Shachter <ref> [13] </ref> exploits the structure of these diagrams to find decisions that maximize expected utility. Unfortunately, this algorithm can sometimes take exponential time. I will describe here a method of making simple decisions using stochastic simulation that also exploits the feedforward structure.
Reference: [14] <author> Stone, M. </author> <title> (1974) Cross-validatory choice and assessment of statistical predictions (with discussion), </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> vol. 36, </volume> <pages> pp. 111-147. </pages>
Reference-contexts: Generalization performance for all these networks might well be improved by stopping learning before convergence using a cross-validation criterion <ref> [14] </ref>.
Reference: [15] <author> Titterington, D. M., Smith, A. F. M., and Makov, U. E. </author> <title> (1985) Statistical Analysis of 33 Finite Mixture Distributions, </title> <address> Chichester, New York: </address> <publisher> Wiley. </publisher> <pages> 34 </pages>
Reference-contexts: Each component produces its own distribution for V , and these component distributions are then combined in the proportions P (M ). Mixture distributions are commonly encountered and much studied <ref> [15] </ref>. To represent a mixture distribution in a network, we need first to represent the mixture variable, M . For a mixture of n components, one way to do this is via a cluster of n units, exactly one of which is on at any time. <p> For comparison, results from a maximum-likelihood fit of a mixture model with six components to the training data using the EM algorithm <ref> [3, 15] </ref> are given as well, evaluated on a test sample of 5000 items.
References-found: 15

