URL: http://www.cs.duke.edu/~pankaj/spring97/term/magda.ps.gz
Refering-URL: http://www.cs.duke.edu/~pankaj/spring97/cps234.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Applications of Clustering Problems  
Author: Cecilia M. Procopiuc 
Date: April 30, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Agrawal, A. Ghosh, T. Imielinski, B. Iyer, and A. Swami, </author> <title> An interval classifier for database mining applications, </title> <booktitle> Proceedings of the 18th Conference on Very Large Databases, </booktitle> <publisher> Morgan Kauffman, </publisher> <month> August </month> <year> 1992. </year>
Reference-contexts: After that, classification algorithms are employed in order to find a classification function for each group, that would allow efficient retrieval of all objects in the database that belong to that group. See <ref> [1, 37] </ref> for more information on classification algorithms. One of the most common operations that database systems want to support efficiently is called the merge/purge problem. The task is to correlate information from different databases by identifying individuals that appear in a number of them.
Reference: [2] <author> M. R. Anderberg, </author> <title> Cluster Analysis for Applications, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: The various heuristics currently used can be classified into two categories: hierarchical clustering and partitional clustering. The next two subsections present a summary of these categories, which is largely based on [23] and <ref> [2] </ref>. 3.1 Hierarchical Clustering Heuristics If C and C 0 are two partitions (clusterings) of the input, we say that C is nested into C 0 if every component of C is a proper subset of C 0 .
Reference: [3] <author> M. Berger and I. Rigoutsos, </author> <title> An algorithm for point clustering and grid generation, </title> <journal> IEEE Trans. Systems, Man and Cybernetics., </journal> <volume> 21 (1991), </volume> <pages> 1278-1286. </pages>
Reference-contexts: There is also a cost determined by boundary conditions for each rectangular subgrid, thus making it necessary to use as few rectangles as possible. Two approaches are studied in <ref> [3] </ref>: a partitioning heuristic that chooses k initial points as cluster centers (k is the number of clusters), determines the clusters corresponding to them and then iteratively refines the cluster centers and the clusters (the general form of this method is detailed in the next section); and a divisive heuristic that
Reference: [4] <author> A. Bookstein, S. T. Klein, and T. Raita, </author> <title> Detecting content-bearing words by serial clustering, </title> <booktitle> Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1995, </year> <pages> pp. 319-327. </pages> <note> Extended Abstract. </note>
Reference-contexts: When such a word is encountered, it is simply ignored, and no position is assigned for it in the vector. We mention here a related idea proposed by Bookstein et al. <ref> [4] </ref>: they argue that whether a word is relevant or not for a set of documents may depend on the documents themselves (i.e. some words may be relevant for a corpus, and irrelevant for another one).
Reference: [5] <author> R. A. Botafogo, </author> <title> Cluster analysis for hypertext systems, </title> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1993, </year> <pages> pp. 116-125. </pages>
Reference-contexts: For example, in the life sciences, the data to be clustered consists of life forms and the clusters themselves are species, or subspecies of a given species. The need for using clustering alghorithms is determined by the scientists' wish to study various characteristics of the life forms. <ref> [5] </ref> mentions a situation where mammals are clustered by similarities in the proportion of three chemicals in their milk. The "natural association" of the animals depends on the percentages of these chemicals in their milk. <p> In particular, hypertext links are clustered according to similarities in the information they contain. In <ref> [5] </ref>, the hypertext is seen as a directed graph, which is then transformed into an undirected graph.
Reference: [6] <author> T. Brinkhoff and H.-P. Kriegel, </author> <title> The impact of global clusterings on spatial database systems, </title> <booktitle> Proceedings of the International Conference on Very Large Databases, </booktitle> <publisher> Morgan Kauffman, </publisher> <month> September </month> <year> 1994. </year> <month> 17 </month>
Reference-contexts: Another approach to improving the disk layout of the data is taken in <ref> [6] </ref>. Here, clustering relies heavily on the spatial access method used in the database, which is usually an R fl -tree. The objects are approximated by their minimum bounding rectangle (MBR), and a tree is constructed on these MBRs.
Reference: [7] <author> G. Coleman and H. Andrews, </author> <title> Image segmentation by clustering, </title> <booktitle> Proceedings of the IEEE., </booktitle> <year> 1979, </year> <pages> pp. 773-785. </pages>
Reference-contexts: The problem becomes more complex, due to the fact that clusters of the feature vectors are not necessarily connected in the xy plane. Various methods for finding an initial clustering and refining it to observe the spatial constraints have been studied <ref> [7, 24, 38, 36] </ref>. Jain and Dubes [23] discuss three types of images for which segmentation algorithms are employed, each of which determines a distinct feature vector. In the case of textured images, the vector of a pixel must reflect textural qualities such as coarseness or regularity.
Reference: [8] <author> D. R. Cutting, D. R. Karger, and J. O. Pedersen, </author> <title> Constant interaction-time scatter/gather browsing of very large document collections, </title> <booktitle> Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1993, </year> <pages> pp. 126-134. </pages>
Reference-contexts: The slower, more precise algortihms are used off-line to organize the documents, while faster algorithms are used online for reclustering at user's request <ref> [9, 8, 19] </ref>. Two problems are central for implementing such a clustering algorithm: 1. How to represent a document as a d dimensional object? 2. What should the distance between two documents be? The answer to the first question is the vector space representation of documents.
Reference: [9] <author> D. R. Cutting, D. R. Karger, J. O. Pedersen, and J. W. Tukey, Scatter/gather: </author> <title> A cluster-based approach to browsing large document collections, </title> <booktitle> Proceedings of the Fifteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1992, </year> <pages> pp. 318-329. </pages>
Reference-contexts: The slower, more precise algortihms are used off-line to organize the documents, while faster algorithms are used online for reclustering at user's request <ref> [9, 8, 19] </ref>. Two problems are central for implementing such a clustering algorithm: 1. How to represent a document as a d dimensional object? 2. What should the distance between two documents be? The answer to the first question is the vector space representation of documents.
Reference: [10] <author> A. A. Diwan, S. Rane, S. Seshadri, and S. Sudarshan, </author> <title> Clustering techniques for minimizing external path length., </title> <booktitle> Proceedings of the International Conference on Very Large Databases, </booktitle> <publisher> Morgan Kauffman, </publisher> <year> 1996. </year>
Reference-contexts: We also refer the reader to <ref> [10] </ref>, for a different clustering algorithm that minimizes the number of I/O's on the path from the root to the leaf in the R fl -tree. 2.4 Image Processing Applications An image processing system transforms continuous images taken from a camera into digital data, and then processes that data to determine
Reference: [11] <author> T. Feder and D. H. Greene, </author> <title> Optimal algorithms for approximate clustering, </title> <booktitle> Proc. 20th Annu. ACM Sympos. Theory Comput., </booktitle> <year> 1988, </year> <pages> pp. 434-444. </pages>
Reference-contexts: In this case, we will call the problem clustering on graph. This is the approach taken by the applications we describe in the next section. Most of the clustering problems are NP-complete [13, 33], even when an approximate solution is sought <ref> [11, 17, 26] </ref>. However, approximation algorithms exist for many of the geometric clustering problems, and for some clustering on graph problems, when the edge weights satisfy the triangle inequality.
Reference: [12] <author> M. Flickner, H. Sawhney, W. Niblack, J. Ashley, Q. Huang, B. Dom, M. Gorkani, J. Hafner, D. Lee, D. Petkovic, D. Steele, and P. Yanker, </author> <title> Query by image and video content: </title> <booktitle> The QBIC system, Computer, 28 (1995), </booktitle> <pages> 23-32. </pages>
Reference-contexts: Although in most of the cases it is considered that the collection consists of text documents, recent trends try to address the problem of multimedia collections <ref> [12, 32, 18] </ref>.
Reference: [13] <author> R. J. Fowler, M. S. Paterson, and S. L. Tanimoto, </author> <title> Optimal packing and covering in the plane are NP-complete, </title> <journal> Inform. Process. Lett., </journal> <volume> 12 (1981), </volume> <pages> 133-137. </pages>
Reference-contexts: In this case, we will call the problem clustering on graph. This is the approach taken by the applications we describe in the next section. Most of the clustering problems are NP-complete <ref> [13, 33] </ref>, even when an approximate solution is sought [11, 17, 26]. However, approximation algorithms exist for many of the geometric clustering problems, and for some clustering on graph problems, when the edge weights satisfy the triangle inequality.
Reference: [14] <author> C. A. Gerlhof, A. Kemper, C. Kilger, and G. Moerkotte, </author> <title> Clustering in object bases, </title> <type> Tech. Rep. </type> <institution> D-76050, University of Karlsruhe, </institution> <year> 1992. </year>
Reference-contexts: Then, a heurisitic clustering algorithm is run on this graph. The authors implemented Probability Ranking [39], Best First Traversal [21], and Greedy Graph Partitioning <ref> [14, 15] </ref>. The last method achieves the best tradeoff between running time and performance.
Reference: [15] <author> C. A. Gerlhof, A. Kemper, C. Kilger, and G. Moerkotte, </author> <title> Partition-based clustering in object bases: from theory to practice, </title> <booktitle> Proceedings of the International Conference on Foundations of Data Organization and Algorithms, </booktitle> <year> 1993, </year> <pages> pp. 301-316. </pages>
Reference-contexts: Then, a heurisitic clustering algorithm is run on this graph. The authors implemented Probability Ranking [39], Best First Traversal [21], and Greedy Graph Partitioning <ref> [14, 15] </ref>. The last method achieves the best tradeoff between running time and performance.
Reference: [16] <author> C. A. Gerlhof, A. Kemper, and G. Moerkotte, </author> <title> On the cost of monitoring and reorganization of object bases for clustering, </title> <booktitle> SIGMOD Record, 25 (1996), </booktitle> <pages> 22-27. </pages>
Reference-contexts: Thus, clustering the objects into pages, and the pages into larger consecutive disk pages can significantly improve the performance of the system. The approach in <ref> [16] </ref> is to monitor the access pattern of the database, and cluster the data according to this pattern.
Reference: [17] <author> T. Gonzalez, </author> <title> Clustering to minimize the maximum intercluster distance, </title> <type> Theoret. </type> <institution> Comput. Sci., </institution> <month> 38 </month> <year> (1985), </year> <pages> 293-306. </pages>
Reference-contexts: In this case, we will call the problem clustering on graph. This is the approach taken by the applications we describe in the next section. Most of the clustering problems are NP-complete [13, 33], even when an approximate solution is sought <ref> [11, 17, 26] </ref>. However, approximation algorithms exist for many of the geometric clustering problems, and for some clustering on graph problems, when the edge weights satisfy the triangle inequality. <p> This is the min-sum problem for S and k with the square-error distance function. Adapting the argument of <ref> [17] </ref>, Lin and Storer [27] proved that this problem is NP-complete. The problem was already known to be NP-complete for the Euclidian and the rectiliniar metrics [33], when d 2. We are not aware of any approximation algorithm for the min-sum problem with the square-error metric. <p> The current approach to solving this problem is by using heuristics (see Section 3). However, [27] proves that solutions obtained by the best known heuristic are not within any constant factor of the optimal. The authors suggest using the Greedy Algorithm of Gonzalez <ref> [17] </ref> for the min-max problem, starting from the observation that the min-max objective function upperbounds the min-sum objective function. The Greedy Algorithm is a theoretical approximation algorithm, guaranteed to achieve an approximation factor of 2 only when the distance satisfies the triangle inequality. <p> When a cluster becomes too large to fit into a disk page, the cluster is split into two, and the split is propagated upwards in the tree. The strategy to split a cluster is in fact Gonzalez's method <ref> [17] </ref>, but applied locally, rather than globally (choose the two points in the cluster that are farthest apart and split the cluster around them). Refining methods are proposed to improve the quality of the clustering obtained, at the cost of increased running time and multiple passes through data.
Reference: [18] <author> K.-A. Han and S.-H. Myaeng, </author> <title> Image organization and retrieval with automatically constructed feature vectors, </title> <booktitle> Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval 18 (H.-P. </booktitle> <editor> Frei, D. Harman, P. Schauble, and R. Wilkinson, eds.), </editor> <publisher> ACM Press, </publisher> <month> August </month> <year> 1996, </year> <pages> pp. 157-165. </pages>
Reference-contexts: Although in most of the cases it is considered that the collection consists of text documents, recent trends try to address the problem of multimedia collections <ref> [12, 32, 18] </ref>.
Reference: [19] <author> M. A. Hearst and J. O. Pedersen, </author> <title> Reexamining the cluster hypothesis: </title> <booktitle> Scatter/gather on retrieval results, Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (H.-P. </booktitle> <editor> Frei, D. Harman, P. Schauble, and R. Wilkinson, eds.), </editor> <publisher> ACM Press, </publisher> <month> August </month> <year> 1996, </year> <pages> pp. 76-84. </pages>
Reference-contexts: The slower, more precise algortihms are used off-line to organize the documents, while faster algorithms are used online for reclustering at user's request <ref> [9, 8, 19] </ref>. Two problems are central for implementing such a clustering algorithm: 1. How to represent a document as a d dimensional object? 2. What should the distance between two documents be? The answer to the first question is the vector space representation of documents.
Reference: [20] <author> M. A. Hernandez and S. J. Stolfo, </author> <title> The merge/purge problem for large databases, </title> <booktitle> Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1995, </year> <pages> pp. 127-138. </pages>
Reference-contexts: One approach, called the sorted neighbourhood method, is to append all files, sort them by the most significant key, and then scan the resulting file and compare all items in a small window to find the matches. To speed up this process, <ref> [20] </ref> proposes applying a clustering algorithm prior to sorting the file, and then sorting the clusters separately. This has the double advantage of reducing the number of operations during sorting, and allowing a parallelization of the process.
Reference: [21] <author> S. E. Hudson and R. King, Cactis: </author> <title> A self-adaptive, concurrent implementation of an object-oriented database management system, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 14 (1989), </volume> <pages> 291-321. </pages>
Reference-contexts: Then, a heurisitic clustering algorithm is run on this graph. The authors implemented Probability Ranking [39], Best First Traversal <ref> [21] </ref>, and Greedy Graph Partitioning [14, 15]. The last method achieves the best tradeoff between running time and performance.
Reference: [22] <author> M. Iwayama and T. Tokunaga, </author> <title> Cluster-based text categorization: A comparison of category search strategies, </title> <booktitle> Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1995, </year> <pages> pp. 273-280. </pages>
Reference-contexts: are assigned the same category into a cluster labeled by that category; see the documents as vectors (in the sense presented above) and cluster them using the Euclidian distance as criterion of similarity; use a probabilistic algorithm, that estimates the most likely set of clusters from the given training data <ref> [22] </ref>. 6 An interesting and recent application of clustering is identifying nodes of information on the Internet that are highly related to each other. In particular, hypertext links are clustered according to similarities in the information they contain.
Reference: [23] <author> A. K. Jain and R. C. Dubes, </author> <title> Algorithms for Clustering Data, </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: The problem becomes more complex, due to the fact that clusters of the feature vectors are not necessarily connected in the xy plane. Various methods for finding an initial clustering and refining it to observe the spatial constraints have been studied [7, 24, 38, 36]. Jain and Dubes <ref> [23] </ref> discuss three types of images for which segmentation algorithms are employed, each of which determines a distinct feature vector. In the case of textured images, the vector of a pixel must reflect textural qualities such as coarseness or regularity. <p> The various heuristics currently used can be classified into two categories: hierarchical clustering and partitional clustering. The next two subsections present a summary of these categories, which is largely based on <ref> [23] </ref> and [2]. 3.1 Hierarchical Clustering Heuristics If C and C 0 are two partitions (clusterings) of the input, we say that C is nested into C 0 if every component of C is a proper subset of C 0 .
Reference: [24] <author> J. Jolion, P. Meer, and S. Batauche, </author> <title> Robust clustering with applications in computer vision, </title> <journal> IEEE Trans. Pattern Analysis Mach. Intell., </journal> <volume> 13 (1991), </volume> <pages> 791-802. </pages>
Reference-contexts: The problem becomes more complex, due to the fact that clusters of the feature vectors are not necessarily connected in the xy plane. Various methods for finding an initial clustering and refining it to observe the spatial constraints have been studied <ref> [7, 24, 38, 36] </ref>. Jain and Dubes [23] discuss three types of images for which segmentation algorithms are employed, each of which determines a distinct feature vector. In the case of textured images, the vector of a pixel must reflect textural qualities such as coarseness or regularity.
Reference: [25] <author> L. Kaufman and P. J. Rousseeuw, </author> <title> Finding Groups in Data: An Introduction to Cluster Analysis, </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: Various experiments presented in the paper show a significant speed-up using clustering, at the cost of a very small loss (less than one percent) of precision. 7 Recently, the advent of spatial databases has triggered studies in using clustering algorithms on the spatial attributes of the data <ref> [34, 25] </ref>. In a spatial database, objects of more complex types are allowed, such as points, lines, polygons. The user may want to receive as answer to a query all objects that are spatially close to each other.
Reference: [26] <author> M. T. Ko, R. C. T. Lee, and J. S. Chang, </author> <title> An optimal approximation algorithm for the rectilinear m-center problem, </title> <journal> Algorithmica, </journal> <volume> 5 (1990), </volume> <pages> 341-352. </pages>
Reference-contexts: In this case, we will call the problem clustering on graph. This is the approach taken by the applications we describe in the next section. Most of the clustering problems are NP-complete [13, 33], even when an approximate solution is sought <ref> [11, 17, 26] </ref>. However, approximation algorithms exist for many of the geometric clustering problems, and for some clustering on graph problems, when the edge weights satisfy the triangle inequality.
Reference: [27] <author> J. Lin and J. A. Storer, </author> <title> Geometric clustering to minimize the mean-square error, </title> <type> Unpublished Manuscript, </type> <year> (1997). </year>
Reference-contexts: This is the min-sum problem for S and k with the square-error distance function. Adapting the argument of [17], Lin and Storer <ref> [27] </ref> proved that this problem is NP-complete. The problem was already known to be NP-complete for the Euclidian and the rectiliniar metrics [33], when d 2. We are not aware of any approximation algorithm for the min-sum problem with the square-error metric. <p> We are not aware of any approximation algorithm for the min-sum problem with the square-error metric. The current approach to solving this problem is by using heuristics (see Section 3). However, <ref> [27] </ref> proves that solutions obtained by the best known heuristic are not within any constant factor of the optimal. The authors suggest using the Greedy Algorithm of Gonzalez [17] for the min-max problem, starting from the observation that the min-max objective function upperbounds the min-sum objective function.
Reference: [28] <author> Y. Linde, A. Buzo, and R. M. Gray, </author> <title> An algorithm for vector quantiser design, </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-28 (1980), </volume> <pages> 84-95. </pages>
Reference-contexts: D (q) = E [d (X; q (X)]: The dissimilarity distance d (X; q (X)) is usually defined as the square-error d (X; q (X)) = i=1 although other distances such as the Euclidian or the L 1 distance have also been con sidered <ref> [28] </ref>. When the distribution of X is known, D (q) can be computed as D (q) = i=1 Many times, however, nothing is known about the distribution law of the random variable X.
Reference: [29] <author> R. Lupton, F. M. Maley, and N. Young, </author> <title> Data collection for the sloan digital sky survey: A network-flow heuristic, </title> <booktitle> Proceedings of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <address> ACM/SIAM, </address> <month> January </month> <year> 1996, </year> <pages> pp. 296-303. 19 </pages>
Reference-contexts: is not very high, we think that some of the geometric approximation algorithms could also be used in this context. 2.5 Other Applications A recent project of the Astrophysical Research Consortium and the Sloan Foundation is aimed to provide a much better map of the universe than is currently available <ref> [29] </ref>. 11 A telescope containing 660 optical fibers will take a series of "snapshots" from different regions of the sky. The maximum number of galaxies for which data can be gathered in a single snapshot is 660. <p> This is the capacitated clustering problem, for which the best known approximation algorithm by Bar-Ilan et al. achieves an approximation factor of log n. In this case, however, n is too large and the algorithm is not practical. The approach in <ref> [29] </ref> is heuristical, and it takes into account the fact that the points are distributed densely and somewhat uniformly in the plane. The plane is first covered by disks, so that the cover has (almost) minimum density.
Reference: [30] <author> J. MacQueen, </author> <title> Some methods for classification and analysis of multivariate obser-vations, </title> <booktitle> Proceedings of the Fifth Berkeley Symposium on Math., Stat. and Prob., </booktitle> <year> 1967, </year> <pages> pp. 281-296. </pages>
Reference-contexts: of them, we discuss to what extent the theoretical approximation algorithms are useful, and what are the problems that arise in practice. 2.1 Data Compression Applications The min-sum center clustering has one important application in vector quantization, a method used for compression of digitized data such as images or speech <ref> [31, 30] </ref>. The problem consists in coding a continuous-value random vector by a vector from a finite set of code vectors.
Reference: [31] <author> J. Makhoul, S. Roucos, and H. Gish, </author> <title> Vector quantization in speech coding, </title> <booktitle> Proceedings of the IEEE, 73 (1985), </booktitle> <pages> 1551-1588. </pages>
Reference-contexts: of them, we discuss to what extent the theoretical approximation algorithms are useful, and what are the problems that arise in practice. 2.1 Data Compression Applications The min-sum center clustering has one important application in vector quantization, a method used for compression of digitized data such as images or speech <ref> [31, 30] </ref>. The problem consists in coding a continuous-value random vector by a vector from a finite set of code vectors.
Reference: [32] <author> C. Meghini, </author> <title> An image retrieval model based on classical logic, </title> <booktitle> Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1995, </year> <pages> pp. 300-308. </pages>
Reference-contexts: Although in most of the cases it is considered that the collection consists of text documents, recent trends try to address the problem of multimedia collections <ref> [12, 32, 18] </ref>.
Reference: [33] <author> N. Megiddo and K. J. Supowit, </author> <title> On the complexity of some common geometric location problems, </title> <journal> SIAM J. Comput., </journal> <volume> 13 (1984), </volume> <pages> 182-196. </pages>
Reference-contexts: In this case, we will call the problem clustering on graph. This is the approach taken by the applications we describe in the next section. Most of the clustering problems are NP-complete <ref> [13, 33] </ref>, even when an approximate solution is sought [11, 17, 26]. However, approximation algorithms exist for many of the geometric clustering problems, and for some clustering on graph problems, when the edge weights satisfy the triangle inequality. <p> This is the min-sum problem for S and k with the square-error distance function. Adapting the argument of [17], Lin and Storer [27] proved that this problem is NP-complete. The problem was already known to be NP-complete for the Euclidian and the rectiliniar metrics <ref> [33] </ref>, when d 2. We are not aware of any approximation algorithm for the min-sum problem with the square-error metric. The current approach to solving this problem is by using heuristics (see Section 3).
Reference: [34] <author> R. T. Ng and J. Han, </author> <title> Efficient and Effective Clustering Methods for Spatial Data Mining, </title> <booktitle> Proceedings of the Twentieth International Conference on Very Large Databases, </booktitle> <year> 1994, </year> <pages> pp. 144-155. </pages>
Reference-contexts: Various experiments presented in the paper show a significant speed-up using clustering, at the cost of a very small loss (less than one percent) of precision. 7 Recently, the advent of spatial databases has triggered studies in using clustering algorithms on the spatial attributes of the data <ref> [34, 25] </ref>. In a spatial database, objects of more complex types are allowed, such as points, lines, polygons. The user may want to receive as answer to a query all objects that are spatially close to each other. <p> The user may want to receive as answer to a query all objects that are spatially close to each other. The answer can be farther used for a spatial join with different maps (i.e. the answer is overlaid with maps depicting various information on the same terrain). <ref> [34] </ref> discusses two clustering algorithms that can be used on objects with both spatial and nonspatial attributes. The spatial attributes are considered to be the x and y coordinates (each object is a point in space), and the metric is either the Euclidian or the L 1 metric.
Reference: [35] <author> P. Raghavan, </author> <title> Information retrieval algorithms: A survey, </title> <booktitle> Proceedings of the Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <month> January </month> <year> 1997, </year> <pages> pp. 11-18. </pages>
Reference-contexts: Document clustering has been used in order to reduce the query time, by matching the query against the clusters, rather than all the documents in the corpus. The intuition is that closely related documents will be relevant to the same queries (see <ref> [35] </ref> for a comprehensive survey). When a browsing method is used, the system provides some general information about the corpus, organized in a small number of topics that are considered representative for the entire collection.
Reference: [36] <author> P. Schroeter and J. Bigun, </author> <title> Hierarchical image segmentation by multi-dimensional clustering and orientation-adaptive boundary refinement, </title> <journal> Pattern Recognition., </journal> <volume> 28 (1995), </volume> <pages> 695-709. </pages>
Reference-contexts: The problem becomes more complex, due to the fact that clusters of the feature vectors are not necessarily connected in the xy plane. Various methods for finding an initial clustering and refining it to observe the spatial constraints have been studied <ref> [7, 24, 38, 36] </ref>. Jain and Dubes [23] discuss three types of images for which segmentation algorithms are employed, each of which determines a distinct feature vector. In the case of textured images, the vector of a pixel must reflect textural qualities such as coarseness or regularity.
Reference: [37] <author> J. Shafer, R. Agrawal, and M. Mehta, Sprint: </author> <title> A scalable parallel classifier for data mining., </title> <booktitle> Proceedings of the International Conference on Very Large Databases, </booktitle> <publisher> Morgan Kauffman, </publisher> <year> 1996. </year>
Reference-contexts: After that, classification algorithms are employed in order to find a classification function for each group, that would allow efficient retrieval of all objects in the database that belong to that group. See <ref> [1, 37] </ref> for more information on classification algorithms. One of the most common operations that database systems want to support efficiently is called the merge/purge problem. The task is to correlate information from different databases by identifying individuals that appear in a number of them.
Reference: [38] <author> M. Spann and R. Wilson, </author> <title> Quadtree approach to image segmentation which statistical and spatial information, </title> <journal> Pattern Recognition, </journal> <volume> 18 (1985), </volume> <pages> 257-269. </pages>
Reference-contexts: The problem becomes more complex, due to the fact that clusters of the feature vectors are not necessarily connected in the xy plane. Various methods for finding an initial clustering and refining it to observe the spatial constraints have been studied <ref> [7, 24, 38, 36] </ref>. Jain and Dubes [23] discuss three types of images for which segmentation algorithms are employed, each of which determines a distinct feature vector. In the case of textured images, the vector of a pixel must reflect textural qualities such as coarseness or regularity.
Reference: [39] <author> P. C. Yue and C. K. Wong, </author> <title> On the optimality of the probability ranking cheme in storage applications, </title> <journal> Journal of the ACM, </journal> <volume> 20 (1973), </volume> <pages> 624-633. </pages>
Reference-contexts: Then, a heurisitic clustering algorithm is run on this graph. The authors implemented Probability Ranking <ref> [39] </ref>, Best First Traversal [21], and Greedy Graph Partitioning [14, 15]. The last method achieves the best tradeoff between running time and performance.
Reference: [40] <author> T. Zhang, R. Ramakrishnan, and M. Livny, </author> <title> Birch: An efficient data clustering method for very large databases, </title> <booktitle> Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1996, </year> <pages> pp. 103-115. 20 </pages>
Reference-contexts: However, the quality of the solution is estimated only from empirical results, on an input data that has a simple natural clustering. A different approach to the same problem is proposed in <ref> [40] </ref>. The method, called BIRCH, is claimed to obtain significantly better results. An important contribution of the paper is that it takes into consideration the size of the physical pages, so that a cluster can fit into a disk page.
References-found: 40

