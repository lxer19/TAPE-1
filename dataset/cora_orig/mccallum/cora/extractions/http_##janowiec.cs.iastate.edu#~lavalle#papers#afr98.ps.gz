URL: http://janowiec.cs.iastate.edu/~lavalle/papers/afr98.ps.gz
Refering-URL: http://janowiec.cs.iastate.edu/~lavalle/
Root-URL: http://www.cs.iastate.edu
Email: lavalle@cs.iastate.edu  
Title: Robot Motion Planning: A Game-Theoretic Foundation  
Author: Steven M. LaValle 
Address: Ames, IA 50011 USA  
Affiliation: Department of Computer Science Iowa State University  
Abstract: Analysis techniques and algorithms for basic path planning have become quite valuable in a variety of applications such as robotics, virtual prototyping, computer graphics, and computational biology. Yet, basic path planning represents a very restricted version of general motion planning problems often encountered in robotics. Many problems can involve complications such as sensing and model uncertainties, non-holonomy, dynamics, multiple robots and goals, optimality criteria, unpredictability, and nonstationarity, in addition to standard geometric workspace constraints. This paper proposes a unified, game-theoretic mathematical foundation upon which analysis and algorithms can be developed for this broader class of problems, and is inspired by the similar benefits that were obtained by using unified configuration-space concepts for basic path planning. By taking this approach, a general algorithm has been obtained for computing approximate optimal solutions to a broad class of motion planning problems, including those involving uncertainty in sensing and control, environment uncertainties, and the coordination of multiple robots. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. M. Amato and Y. Wu. </author> <title> A randomized roadmap method for path and manipulation planning. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 113-120, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction Two decades of development has led to many successful analysis techniques and algorithms for planning collision-free paths of rigid or articulated robots in a known, cluttered environment. These algorithms, such as the randomized potential field method [9] or probabilistic roadmaps <ref> [1, 58, 101] </ref>, have enjoyed great success across many different kinds of robotic platforms in both research and industrial applications, and in applications beyond robotics, such as virtual prototyping, graphical animation, architecture, and computational biology. <p> In general, however, the state space could incorporate additional information. For instance, dynamics can 10 Problem State Space Motion Model Sensing Model Strategy Basic MP C _x = u (t) y (t) = x (t) <ref> [0; 1] </ref> ! C free [9, 86, 95] x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f [10, 20, 68, 77] x k+1 = f (x k <p> The dimensionality of this composite space has previously prompted many approaches that decouple the problem. Motion strategies are more or less constructed for each robot independently, and then combined to coordinate the robots. For fixed-path coordination, it is assumed that a collision-free path t i : <ref> [0; 1] </ref> ! C i free is given for each robot, and the state space is defined as the Cartesian product [0; 1] N . Instead of a single collision-free path, suppose that each robot is given a network of collision-free paths, referred to as a roadmap. <p> For fixed-path coordination, it is assumed that a collision-free path t i : <ref> [0; 1] </ref> ! C i free is given for each robot, and the state space is defined as the Cartesian product [0; 1] N . Instead of a single collision-free path, suppose that each robot is given a network of collision-free paths, referred to as a roadmap. Let R i denote a space that is formed by combining the domains of the roadmap paths for the i th robot. <p> Such results have turned efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [88] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 9, 57, 101] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes. <p> In the case of basic path planning, randomized search algorithms have been developed that perform well in practice for many high degree-of-freedom problems by relying on the notion of probabilistic completeness <ref> [1, 9, 57, 101] </ref>. These planners are formulated for problems in which path optimality is not a central concern and in which there is perfect configuration predictability (i.e., the solutions are open-loop paths in the configuration space).
Reference: [2] <author> B. D. Anderson and J. B. Moore. </author> <title> Optimal Control: Linear-Quadratic Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., [16, 29, 28]), optimal control theory (e.g., <ref> [2, 18, 62] </ref>), dynamic noncooperative game theory (e.g., [5, 54]). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. <p> In both control theory and dynamic game theory, the classic set of problems that can be solved are those with a linear state transition equation and quadratic loss functional <ref> [2, 5, 18, 62] </ref>. Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts.
Reference: [3] <author> M. D. Ardema and J. M. Skowronski. </author> <title> Dynamic game applied to coordination control of two arm robotic system. </title> <editor> In R. P. Hamalainen and H. K. Ehtamo, editors, </editor> <booktitle> Differential Games Developments in Modelling and Computation, </booktitle> <pages> pages 118-130. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories [15, 19, 39, 78]) or centralized planning (planning occurs in a composite configuration space <ref> [3, 8, 96] </ref>). For example, the decoupled planning representations constructed in [66, 85] can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot.
Reference: [4] <author> T. Ba~sar and P. R. Kumar. </author> <title> On worst case design strategies. </title> <institution> Comput. Math. Applic., 13(1-3):239-245, </institution> <year> 1987. </year>
Reference-contexts: If this uncertainty is represented probabilistically, the game against nature becomes a problem of stochastic optimal control theory [13, 62]. If the uncertainty is represented nondeterministically and worst case analysis is performed, then the game against nature can be considered as a form of robust controller design <ref> [4] </ref>. Before considering a formulation of the general motion strategy problem, first consider making small extensions to the basic path planning problem.
Reference: [5] <author> T. Ba~sar and G. J. Olsder. </author> <title> Dynamic Noncooperative Game Theory. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1982. </year>
Reference-contexts: In some applications, the state space might encode information that represents the status of the environment [76]. In general, if there is sensing uncertainty (i.e., the current state is unknown during execution), the state space can be replaced by an information space <ref> [5] </ref>. This space is generally spanned by the history of previous sensor data and motion commands during execution, and can usually be transformed into either a space of probability density functions or subsets of the state space. <p> In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., [16, 29, 28]), optimal control theory (e.g., [2, 18, 62]), dynamic noncooperative game theory (e.g., <ref> [5, 54] </ref>). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained [50, 94, 108]. <p> Next, consider moving to a mathematical structure for the general motion strategy problem, which is based on concepts from dynamic noncooperative game theory <ref> [5] </ref> and stochastic optimal control [62]. This structure will be formulated in discrete time to ease the specification of uncertainty aspects; however, continuous time can alternatively be used with some minor modifications. Thirteen components are first listed, and a discussion of how each relates to the motion strategy problem follows. <p> For instance, in a cooperative game in which there is a certain amount of trust, Pareto optimality may be appropriate [87]. In a noncooperative setting, a Nash equilibrium condition might be appropriate <ref> [5] </ref>. <p> In both control theory and dynamic game theory, the classic set of problems that can be solved are those with a linear state transition equation and quadratic loss functional <ref> [2, 5, 18, 62] </ref>. Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts.
Reference: [6] <author> J. Barraquand and P. Ferbach. </author> <title> A penalty function method for constrained motion planning. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1235-1242, </pages> <year> 1994. </year>
Reference-contexts: Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications <ref> [6, 53, 84, 100] </ref>. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies.
Reference: [7] <author> J. Barraquand and P. Ferbach. </author> <title> Motion planning with uncertainty: The information space approach. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1341-1348, </pages> <year> 1995. </year>
Reference-contexts: When there is perfect state information, decisions can be made on the basis of state. However, with imperfect state information, the decisions are conditioned on information states. The information state concept is similar to the definition of knowledge states, considered in [37], and has also recently been proposed in <ref> [7] </ref>. The information space can be considered as a replacement for the state space in the case of imperfect state information (i.e., planning occurs in the information space instead of the state space).
Reference: [8] <author> J. Barraquand, B. Langlois, and J. C. Latombe. </author> <title> Numerical potential field techniques for robot path planning. </title> <journal> IEEE Trans. Syst., Man, Cybern., </journal> <volume> 22(2) </volume> <pages> 224-241, </pages> <year> 1992. </year>
Reference-contexts: Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories [15, 19, 39, 78]) or centralized planning (planning occurs in a composite configuration space <ref> [3, 8, 96] </ref>). For example, the decoupled planning representations constructed in [66, 85] can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot. <p> Approaches to multiple-robot motion coordination are often categorized as centralized or decou-pled. A centralized approach typically constructs a path in a composite configuration space, which is formed by combining the configuration spaces of the individual robots (e.g., <ref> [8, 96] </ref>). A decoupled approach typically generates paths for each robot independently, and then considers the interactions between the robots (e.g., [40, 56, 85]). <p> In basic path planning, a single algorithm can be often applied with only minor modification to a variety of specific problems. For example, the randomized path planner in <ref> [8] </ref> has been applied to many examples including manipulator systems and rigid robots. Part of the ease of this applicability is due to the common configuration space representation. To make the game-theoretic ideas convincing, algorithms developed within the broader mathematical foundation should have similar portability.
Reference: [9] <author> J. Barraquand and J.-C. Latombe. </author> <title> A Monte-Carlo algorithm for path planning with many degrees of freedom. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1712-1717, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Two decades of development has led to many successful analysis techniques and algorithms for planning collision-free paths of rigid or articulated robots in a known, cluttered environment. These algorithms, such as the randomized potential field method <ref> [9] </ref> or probabilistic roadmaps [1, 58, 101], have enjoyed great success across many different kinds of robotic platforms in both research and industrial applications, and in applications beyond robotics, such as virtual prototyping, graphical animation, architecture, and computational biology. <p> In general, however, the state space could incorporate additional information. For instance, dynamics can 10 Problem State Space Motion Model Sensing Model Strategy Basic MP C _x = u (t) y (t) = x (t) [0; 1] ! C free <ref> [9, 86, 95] </ref> x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f [10, 20, 68, 77] x k+1 = f (x k ; u k ) y <p> This concept additionally relates closely to navigation functions <ref> [9, 93] </ref> and progress measures [38]. Assume that a strategy encodes a termination condition in addition to motion control, and that there is only a single decision maker (other than nature). Suppose that there is nondeterministic uncertainty, which is standard in preimage planning research. <p> Such results have turned efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [88] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 9, 57, 101] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes. <p> Artificial potential functions have often been constructed very efficiently in 27 path planning approaches; however, these approaches heuristically estimate the cost-to-go and are typically prone to have local minima <ref> [9, 60] </ref>. Suppose there are no uncertainties, and an optimal state-feedback strategy is sought using (30). Assume that the problem is stationary, which implies that no model components are time varying. The first step is to construct a representation of L fl K+1 . <p> Note that although the approach to 29 select the action is local (and efficient), the global information is still taken into account (it is encoded in the cost-to-go function). This concept is similar to the use of a numerical navigation function in previous motion planning literature <ref> [9, 93] </ref>, and the cost-to-go is a form of progress measure, as considered in [38]. When considering the cost-to-go as a navigation function, it is important to note that it does not contain local minima because it is constructed as a by product of determining the optimal solution. <p> In the case of basic path planning, randomized search algorithms have been developed that perform well in practice for many high degree-of-freedom problems by relying on the notion of probabilistic completeness <ref> [1, 9, 57, 101] </ref>. These planners are formulated for problems in which path optimality is not a central concern and in which there is perfect configuration predictability (i.e., the solutions are open-loop paths in the configuration space). <p> For example, a randomized potential field method could be developed that is similar to <ref> [9] </ref>, by defining an artificial potential function on the state space. Actions can be deterministically chosen that attempt to minimize the potential function, or actions can be chosen randomly to escape local extrema.
Reference: [10] <author> J. Barraquand and J.-C. Latombe. </author> <title> Nonholonomic multibody mobile robots: Controllability and motion planning in the presence of obstacles. </title> <journal> Algorithmica, </journal> <volume> 10 </volume> <pages> 121-155, </pages> <year> 1993. </year>
Reference-contexts: _x = u (t) y (t) = x (t) [0; 1] ! C free [9, 86, 95] x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f <ref> [10, 20, 68, 77] </ref> x k+1 = f (x k ; u k ) y k = x k Dynamics T (C) _x = f (x (t); u (t)) y (t) = h (x (t)) u (t); 0 t t f [21, 34] x k+1 = f (x k ; u
Reference: [11] <author> R. E. Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1957. </year>
Reference-contexts: By using the state transition equation, the next state is represented by a pdf, p (x k+1 jx k ; u 1 k ; : : : ; u N Note that the discrete-time formulation can be considered as an approximation to a continuous-time system <ref> [11, 12] </ref>. For example, suppose a system of the form _x = f (x (t); u 1 (t); : : : ; u N (t)) is given. <p> The second min does not affect the l k term; thus, it can be removed to obtain L fl u k l k (x k ; u k ) + min ( i=k+1 )# The second portion of the min represents the cost-to-go function for stage k + 1, yielding <ref> [11] </ref> L fl u k l k (x k ; u k (x k )) + L fl This final form represents a powerful constraint on the set of optimal strategies. The optimal strategy at stage k and state x depends only cost-to-go values at stage k + 1. <p> Other schemes, such as quadratic interpolation, can be used to improve numerical accuracy at the expense of computation time [64]. Convergence properties of the quantization and interpolation are discussed in <ref> [11, 12] </ref>. For a motion planning problem, the obstacle constraints must additionally be taken into account.
Reference: [12] <author> D. P. Bertsekas. </author> <title> Convergence in discretization procedures in dynamic programming. </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 20(3) </volume> <pages> 415-419, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: By using the state transition equation, the next state is represented by a pdf, p (x k+1 jx k ; u 1 k ; : : : ; u N Note that the discrete-time formulation can be considered as an approximation to a continuous-time system <ref> [11, 12] </ref>. For example, suppose a system of the form _x = f (x (t); u 1 (t); : : : ; u N (t)) is given. <p> Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures <ref> [12, 13, 63, 64] </ref>, particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies. <p> Using this model, a probability density function can be derived for next states of the form p (x k+1 jx k ; u k ). The task is to design a strategy that is optimal in the expected sense. In this case the cost-to-go is defined as <ref> [12] </ref> k (x k ) = E K X l i (x i ; u i ) + l K+1 (x K+1 ) ; (31) in which Efg denotes expectation taken over the actions of nature. <p> Other schemes, such as quadratic interpolation, can be used to improve numerical accuracy at the expense of computation time [64]. Convergence properties of the quantization and interpolation are discussed in <ref> [11, 12] </ref>. For a motion planning problem, the obstacle constraints must additionally be taken into account.
Reference: [13] <author> D. P. Bertsekas. </author> <title> Dynamic Programming: Deterministic and Stochastic Models. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1987. </year>
Reference-contexts: As will be discussed shortly, such problems can be viewed as a game against nature [16, 89]. If this uncertainty is represented probabilistically, the game against nature becomes a problem of stochastic optimal control theory <ref> [13, 62] </ref>. If the uncertainty is represented nondeterministically and worst case analysis is performed, then the game against nature can be considered as a form of robust controller design [4]. <p> This termination condition, in the determination of an optimal strategy, is equivalent to an optimal stopping rule, which has been studied for problems such as deciding when to stop gambling <ref> [13] </ref>. The termination condition represents a special action that can be considered by a robot, and can be applied in a variety of contexts for designing motion strategies. Performance preimages One concept that is complementary in many ways to the forward projection is the preimage [41, 67, 80]. <p> Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures <ref> [12, 13, 63, 64] </ref>, particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies.
Reference: [14] <author> W. F. Bialas. </author> <title> Cooperative n-person Stackelberg games. </title> <booktitle> In IEEE Conf. Decision & Control, </booktitle> <pages> pages 2439-2444, </pages> <address> Tampa, FL, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: A cooperative game refers to the case in which some subsets of the decision makers can choose their actions in unison, so that a mutually beneficial outcome can be obtained <ref> [14, 87] </ref>. Without cooperation the decision makers choose actions that take into account interests that conflict with the other decision makers. This is referred to as a noncooperative game. The most extreme case of conflicting interest is a zero-sum game, in which two decision makers are diametrically opposed.
Reference: [15] <author> Z. Bien and J. Lee. </author> <title> A minimum-time trajectory planning method for two robots. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 8(3) </volume> <pages> 414-418, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Specialized techniques that have been developed for the coordination of multiple robots that have independent goals can also be unified. Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories <ref> [15, 19, 39, 78] </ref>) or centralized planning (planning occurs in a composite configuration space [3, 8, 96]). For example, the decoupled planning representations constructed in [66, 85] can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot. <p> Multiple-robot optimality Little concern has been given in previous research to optimality for multiple-robot coordination problems. Previous approaches that consider optimality project the vector of individual losses onto a scalar loss <ref> [15, 98, 103] </ref>. As a result, these methods can fail to find many potentially useful motion strategies. There are many well-studied optimality concepts from game-theory and multiobjective optimization literature that can be applied in this case.
Reference: [16] <author> D. Blackwell and M. A. Girshik. </author> <title> Theory of Games and Statistical Decisions. </title> <publisher> Dover Publications, </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., <ref> [16, 29, 28] </ref>), optimal control theory (e.g., [2, 18, 62]), dynamic noncooperative game theory (e.g., [5, 54]). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. <p> Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature <ref> [16, 89] </ref>. If this uncertainty is represented probabilistically, the game against nature becomes a problem of stochastic optimal control theory [13, 62]. If the uncertainty is represented nondeterministically and worst case analysis is performed, then the game against nature can be considered as a form of robust controller design [4].
Reference: [17] <author> R. C. Brost and A. D. Christiansen. </author> <title> Probabilistic analysis of manipulation tasks: A computational framework. </title> <journal> Int. J. Robot. Res., </journal> <volume> 15(1) </volume> <pages> 1-23, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: i (t)) y i (t) = x (t) fl i : X ! U i [19, 85, 101] x i k ; u i k = x k CP uncertainty C _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U <ref> [17, 31, 41] </ref> x k+1 = f (x k ; u k ; a EP uncertainty C fi E _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U [27, 76, 107] x k+1 = f (x k ; u k ; <p> A motion strategy is then generated that is based on worst-case analysis (e.g., [23, 41, 67, 80]). With a probabilistic representation the parameter uncertainties are characterized with a probability density function (pdf). This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., <ref> [17, 46, 47] </ref>). One key aspect of the proposed mathematical foundation is a general capacity to model uncertainties by defining a nature player. This view of uncertainty was advocated for manipulation planning in [102]. <p> If R = frg for some point r 0, then places in X are obtained in which equal expected performance will be obtained. With a 0-1 loss functional and ignoring the termination condition, the performance preimages can give isoprobability curves which are equivalent to the probabilistic backprojections in <ref> [17] </ref>. Some examples of preimages are shown in Figure 4 (see also [73]). Figure 4 (a) shows a performance preimage under nondeterministic uncertainty and a loss functional that returns 0 when the goal is achieved, and 1 otherwise. <p> The curve shown in Figure 4 (a) corresponds closely to the classical preimage that has been determined for this problem in previous manipulation planning research (e.g., [41, 66]). Figure 4 (b) assumes probabilistic uncertainty, and shows probabilistic backprojections that are quite similar to those that appear in <ref> [17] </ref>. Figure 4 (c) shows performance preimages for a case in which a Gaussian error model is used to represent the uncertainty in control, as opposed to a bounded uniform pdf as in [17]. Figure 4 (d) shows performance preimages of a computed optimal strategy. <p> (b) assumes probabilistic uncertainty, and shows probabilistic backprojections that are quite similar to those that appear in <ref> [17] </ref>. Figure 4 (c) shows performance preimages for a case in which a Gaussian error model is used to represent the uncertainty in control, as opposed to a bounded uniform pdf as in [17]. Figure 4 (d) shows performance preimages of a computed optimal strategy. These results were all computed using variants of the algorithm discussed in Section 4. Performance preimages can also be defined on the information space to account for sensing uncertainty, and for multiple decision makers [70].
Reference: [18] <author> A. E. Bryson and Y.-C. Ho. </author> <title> Applied Optimal Control. </title> <publisher> Hemisphere Publishing Corp., </publisher> <address> New York, NY, </address> <year> 1975. </year>
Reference-contexts: For example, with a car-like robot we might want to specify the best steering angle to choose from any possible configuration that the robot might be confronted with during execution (this is equivalent to a feedback control law <ref> [18] </ref>). <p> In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., [16, 29, 28]), optimal control theory (e.g., <ref> [2, 18, 62] </ref>), dynamic noncooperative game theory (e.g., [5, 54]). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. <p> In both control theory and dynamic game theory, the classic set of problems that can be solved are those with a linear state transition equation and quadratic loss functional <ref> [2, 5, 18, 62] </ref>. Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts.
Reference: [19] <author> S. J. Buckley. </author> <title> Fast motion planning for multiple moving robots. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 322-326, </pages> <year> 1989. </year>
Reference-contexts: Specialized techniques that have been developed for the coordination of multiple robots that have independent goals can also be unified. Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories <ref> [15, 19, 39, 78] </ref>) or centralized planning (planning occurs in a composite configuration space [3, 8, 96]). For example, the decoupled planning representations constructed in [66, 85] can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot. <p> X ! U [92] x k+1 = f (x k ; u 1 k ) y i Multiple robots C 1 fi fi C N _ x i = f i (x i (t); u i (t)) y i (t) = x (t) fl i : X ! U i <ref> [19, 85, 101] </ref> x i k ; u i k = x k CP uncertainty C _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U [17, 31, 41] x k+1 = f (x k ; u k ; a EP uncertainty
Reference: [20] <author> L. G. Bushnell, D. M. Tilbury, and S. S. Sastry. </author> <title> Steering three-input nonholonomic systems: the fire truck example. </title> <journal> Int. J. Robot. Res., </journal> <volume> 14(4) </volume> <pages> 366-381, </pages> <year> 1995. </year>
Reference-contexts: _x = u (t) y (t) = x (t) [0; 1] ! C free [9, 86, 95] x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f <ref> [10, 20, 68, 77] </ref> x k+1 = f (x k ; u k ) y k = x k Dynamics T (C) _x = f (x (t); u (t)) y (t) = h (x (t)) u (t); 0 t t f [21, 34] x k+1 = f (x k ; u
Reference: [21] <author> J. Canny, A. Rege, and J. Reif. </author> <title> An exact algorithm for kinodynamic planning in the plane. </title> <journal> Discrete and Computational Geometry, </journal> <volume> 6 </volume> <pages> 461-484, </pages> <year> 1991. </year>
Reference-contexts: = x (t) u (t); 0 t t f [10, 20, 68, 77] x k+1 = f (x k ; u k ) y k = x k Dynamics T (C) _x = f (x (t); u (t)) y (t) = h (x (t)) u (t); 0 t t f <ref> [21, 34] </ref> x k+1 = f (x k ; u k ) y k = h (x k ) Moving obstacles C (t) _x = f (x (t); u (t); t) y (t) = x (t) u (t); 0 t t f [40, 56] x k+1 = f k (x k
Reference: [22] <author> J. Canny and J. Reif. </author> <title> New lower bound techniques for robot motion planning problems. </title> <booktitle> In Proc. IEEE Conf. on Foundations of Computer Science, </booktitle> <pages> pages 49-60, </pages> <year> 1987. </year>
Reference-contexts: The computational hardness results have curbed many efforts to find efficient, complete algorithms to general motion strategy problems. In [90] the basic path planning problem was shown to be PSPACE-hard for polyhedral robots with n links. In <ref> [22] </ref> is was shown that computing minimum-distance paths in a 3-D workspace is NP-hard. It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard.
Reference: [23] <author> J. F. Canny. </author> <title> On computability of fine motion plans. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 177-182, </pages> <year> 1989. </year>
Reference-contexts: Two common representations of uncertainty have been applied to motion strategy problems. With a nondeterministic (or bounded-set) representation parameter uncertainties are restricted to lie within a specified set. A motion strategy is then generated that is based on worst-case analysis (e.g., <ref> [23, 41, 67, 80] </ref>). With a probabilistic representation the parameter uncertainties are characterized with a probability density function (pdf). This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., [17, 46, 47]).
Reference: [24] <author> C.-T. Chen. </author> <title> Linear System Theory and Design. </title> <publisher> Holt, Rinehart, and Winston, </publisher> <address> New York, NY, </address> <year> 1984. </year>
Reference-contexts: For example, if we would like to compute a motion strategy for a car-like robot that reaches a goal region in minimum time, the state space should include both configuration parameters and velocities. This kind of state space representation is common in modern control theory <ref> [24] </ref>. In some applications, the state space might encode information that represents the status of the environment [76]. In general, if there is sensing uncertainty (i.e., the current state is unknown during execution), the state space can be replaced by an information space [5].
Reference: [25] <author> K.-C. Chu. </author> <title> Team decision theory and information structures in optimal control problems-part II. </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 17(1) </volume> <pages> 22-28, </pages> <month> February </month> <year> 1972. </year>
Reference-contexts: If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained [50, 94, 108]. In a situation in which there is a common loss functional and all decision makers wish to act cooperatively, team theory is obtained <ref> [25, 51, 61] </ref>. A cooperative game refers to the case in which some subsets of the decision makers can choose their actions in unison, so that a mutually beneficial outcome can be obtained [14, 87].
Reference: [26] <author> H. W. Corley. </author> <title> Some multiple objective dynamic programs. </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 30(12) </volume> <pages> 1221-1222, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: These solutions can be generated using algorithms that are based on the dynamic programming principle. For other applications this was observed in <ref> [26] </ref>. For the criterion (19) it is shown that minimal solutions are consistent with other well-established forms of optimality from optimization literature [70]. The minimal game strategies are equivalent to the nondominated strategies used in multiobjective optimization and Pareto optimal game strategies used in cooperative game theory.
Reference: [27] <author> J. Gil de Lamadrid and J. Zimmerman. </author> <title> Avoidance of obstacles with unknown trajectories: locally optimal paths and path complexity, part I. </title> <journal> Robotica, </journal> <volume> 11 </volume> <pages> 299-308, </pages> <year> 1993. </year>
Reference-contexts: a (t)) y (t) = x (t) fl : X ! U [17, 31, 41] x k+1 = f (x k ; u k ; a EP uncertainty C fi E _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U <ref> [27, 76, 107] </ref> x k+1 = f (x k ; u k ; a CS and CP unc.
Reference: [28] <author> M. H. </author> <title> DeGroot. Optimal Statistical Decisions. </title> <publisher> McGraw Hill, </publisher> <address> New York, NY, </address> <year> 1970. </year>
Reference-contexts: In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., <ref> [16, 29, 28] </ref>), optimal control theory (e.g., [2, 18, 62]), dynamic noncooperative game theory (e.g., [5, 54]). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature.
Reference: [29] <author> P. A. Devijver and J. Kittler. </author> <title> Pattern Recognition: A Statistical Approach. </title> <publisher> Prentice-Hall Publications, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., <ref> [16, 29, 28] </ref>), optimal control theory (e.g., [2, 18, 62]), dynamic noncooperative game theory (e.g., [5, 54]). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature.
Reference: [30] <author> B. R. Donald. </author> <title> Error Detection and Recovery for Robot Motion Planning with Uncertainty. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: (t); a (t)) y (t) = h (x (t); s (t)) fl : I k ! U k ) y k = h (x k ; s ES uncertainty C fi E _x = u (t) y (t) = h (x (t); s (t)) fl : I k ! U <ref> [30, 33, 81] </ref> x k+1 = x k + u k y k = h (x k ; s have received previous attention. For each case, the state space is identified. Both continuous-time and discrete-time models are given for motions and for sensing. <p> If the current environment is unknown, then there is uncertainty in environment sensing, which is a problem that has been considered in robotics from several different perspectives (e.g., <ref> [30, 35, 52, 65, 99] </ref>). This can be modeled by defining y k = h k (x k ; s k ), in which x k = [q k e k ]. In general, sensing and predictability uncertainties can be defined for any state space, including those that include dynamics.
Reference: [31] <author> B. R. Donald. </author> <title> Planning multi-step error detection and recovery strategies. </title> <journal> Int. J. Robot. Res., </journal> <volume> 9(1) </volume> <pages> 3-60, </pages> <year> 1990. </year>
Reference-contexts: i (t)) y i (t) = x (t) fl i : X ! U i [19, 85, 101] x i k ; u i k = x k CP uncertainty C _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U <ref> [17, 31, 41] </ref> x k+1 = f (x k ; u k ; a EP uncertainty C fi E _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U [27, 76, 107] x k+1 = f (x k ; u k ;
Reference: [32] <author> B. R. Donald. </author> <booktitle> On information invariants in robotics. Artif. Intell., </booktitle> <volume> 72 </volume> <pages> 217-304, </pages> <year> 1995. </year>
Reference-contexts: The relationship given by h i k is used in optimal control theory to define system outputs, and has also been 12 considered in robot sensing problems (see, for instance, <ref> [32, 33] </ref>). In addition to a projection from the state space to the sensor space, this information is potentially corrupted by a sensing action, s;i k , of nature, which is chosen from fi s;i k .
Reference: [33] <author> B. R. Donald and J. Jennings. </author> <title> Sensor interpretation and task-directed planning using perceptual equivalence classes. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 190-197, </pages> <address> Sacramento, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: (t); a (t)) y (t) = h (x (t); s (t)) fl : I k ! U k ) y k = h (x k ; s ES uncertainty C fi E _x = u (t) y (t) = h (x (t); s (t)) fl : I k ! U <ref> [30, 33, 81] </ref> x k+1 = x k + u k y k = h (x k ; s have received previous attention. For each case, the state space is identified. Both continuous-time and discrete-time models are given for motions and for sensing. <p> The relationship given by h i k is used in optimal control theory to define system outputs, and has also been 12 considered in robot sensing problems (see, for instance, <ref> [32, 33] </ref>). In addition to a projection from the state space to the sensor space, this information is potentially corrupted by a sensing action, s;i k , of nature, which is chosen from fi s;i k .
Reference: [34] <author> B. R. Donald and P. G. Xavier. </author> <title> Provably good approximation algorithms for optimal kinodynamic planning for Cartesian robots and open-chain manipulators. </title> <journal> Algorithmica, </journal> <volume> 14(6) </volume> <pages> 480-530, </pages> <year> 1995. </year>
Reference-contexts: = x (t) u (t); 0 t t f [10, 20, 68, 77] x k+1 = f (x k ; u k ) y k = x k Dynamics T (C) _x = f (x (t); u (t)) y (t) = h (x (t)) u (t); 0 t t f <ref> [21, 34] </ref> x k+1 = f (x k ; u k ) y k = h (x k ) Moving obstacles C (t) _x = f (x (t); u (t); t) y (t) = x (t) u (t); 0 t t f [40, 56] x k+1 = f k (x k
Reference: [35] <author> A. Elfes. </author> <title> Using occupancy grids for mobile robot perception and navigation. </title> <journal> IEEE Computer, </journal> <volume> 22(6) </volume> <pages> 46-57, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: If the current environment is unknown, then there is uncertainty in environment sensing, which is a problem that has been considered in robotics from several different perspectives (e.g., <ref> [30, 35, 52, 65, 99] </ref>). This can be modeled by defining y k = h k (x k ; s k ), in which x k = [q k e k ]. In general, sensing and predictability uncertainties can be defined for any state space, including those that include dynamics.
Reference: [36] <author> M. Erdmann. </author> <title> Randomization in robot tasks. </title> <journal> Int. J. Robot. Res., </journal> <volume> 11(5) </volume> <pages> 399-436, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: In this case a pdf of the form p (u i k j i k ) is specified as the strategy, and actions are chosen by sampling. Randomized have been particularly useful for improving robustness in manipulation tasks <ref> [36] </ref>. Encoding preferences Item 13 defines a loss functional, which guides the selection of strategies, for each of the decision makers. The loss can generally be based on actions taken by any decision maker at any stage, on the state trajectory, and on nature.
Reference: [37] <author> M. Erdmann. </author> <title> Randomization for robot tasks: Using dynamic programming in the space of knowledge states. </title> <journal> Algorithmica, </journal> <volume> 10 </volume> <pages> 248-291, </pages> <year> 1993. </year>
Reference-contexts: When there is perfect state information, decisions can be made on the basis of state. However, with imperfect state information, the decisions are conditioned on information states. The information state concept is similar to the definition of knowledge states, considered in <ref> [37] </ref>, and has also recently been proposed in [7]. The information space can be considered as a replacement for the state space in the case of imperfect state information (i.e., planning occurs in the information space instead of the state space).
Reference: [38] <author> M. Erdmann. </author> <title> Understanding action and sensing by designing action-based sensors. </title> <journal> Int. J. Robot. Res., </journal> <volume> 14(5) </volume> <pages> 483-509, </pages> <year> 1995. </year>
Reference-contexts: This concept additionally relates closely to navigation functions [9, 93] and progress measures <ref> [38] </ref>. Assume that a strategy encodes a termination condition in addition to motion control, and that there is only a single decision maker (other than nature). Suppose that there is nondeterministic uncertainty, which is standard in preimage planning research. Consider some subset of the reals, R &lt;. <p> This concept is similar to the use of a numerical navigation function in previous motion planning literature [9, 93], and the cost-to-go is a form of progress measure, as considered in <ref> [38] </ref>. When considering the cost-to-go as a navigation function, it is important to note that it does not contain local minima because it is constructed as a by product of determining the optimal solution. Once the optimal action is determined, an exact next state is obtained.
Reference: [39] <author> M. Erdmann and T. Lozano-Perez. </author> <title> On multiple moving objects. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1419-1424, </pages> <year> 1986. </year>
Reference-contexts: Specialized techniques that have been developed for the coordination of multiple robots that have independent goals can also be unified. Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories <ref> [15, 19, 39, 78] </ref>) or centralized planning (planning occurs in a composite configuration space [3, 8, 96]). For example, the decoupled planning representations constructed in [66, 85] can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot.
Reference: [40] <author> M. Erdmann and T. Lozano-Perez. </author> <title> On multiple moving objects. </title> <journal> Algorithmica, </journal> <volume> 2 </volume> <pages> 477-521, </pages> <year> 1987. </year>
Reference-contexts: (x (t)) u (t); 0 t t f [21, 34] x k+1 = f (x k ; u k ) y k = h (x k ) Moving obstacles C (t) _x = f (x (t); u (t); t) y (t) = x (t) u (t); 0 t t f <ref> [40, 56] </ref> x k+1 = f k (x k ; u k ) y k = x k Pursuit-evasion C 1 fi C 2 _x = f (x (t); u 1 (t); u 2 (t)) y i (t) = h i (x (t)) fl 1 ; fl 2 : X ! <p> A centralized approach typically constructs a path in a composite configuration space, which is formed by combining the configuration spaces of the individual robots (e.g., [8, 96]). A decoupled approach typically generates paths for each robot independently, and then considers the interactions between the robots (e.g., <ref> [40, 56, 85] </ref>). The suitability of one approach over the other is usually determined by the tradeoff between computational complexity associated with a given problem and the amount of completeness that is lost. A variety of multiple-robot coordination problems can be formulated by defining appropriate state spaces [70].
Reference: [41] <author> M. A. Erdmann. </author> <title> On motion planning with uncertainty. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> August </month> <year> 1984. </year> <month> 35 </month>
Reference-contexts: In the area of motion planning under uncertainty in sensing and prediction, many interesting concepts have been developed, such as preimages and forward projections <ref> [41, 67, 80, 83] </ref>); however, they are often tied to a particular set of uncertainty models that are based on crisp, geometric constructions (e.g., uncertainty cones and disks). <p> i (t)) y i (t) = x (t) fl i : X ! U i [19, 85, 101] x i k ; u i k = x k CP uncertainty C _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U <ref> [17, 31, 41] </ref> x k+1 = f (x k ; u k ; a EP uncertainty C fi E _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U [27, 76, 107] x k+1 = f (x k ; u k ; <p> Two common representations of uncertainty have been applied to motion strategy problems. With a nondeterministic (or bounded-set) representation parameter uncertainties are restricted to lie within a specified set. A motion strategy is then generated that is based on worst-case analysis (e.g., <ref> [23, 41, 67, 80] </ref>). With a probabilistic representation the parameter uncertainties are characterized with a probability density function (pdf). This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., [17, 46, 47]). <p> The relationship between sensor and action history and decision making has long been considered important in planning under uncertainty (e.g., <ref> [41, 80] </ref>). Generally one would like to optimize the performance of a robot, while directly taking into account the complications due to limited sensing. By using the concept of information state, as considered in stochastic control and dynamic game theory, a useful characterization of this relationship is provided. <p> An example of uncertainty in configuration predictability A variety of motion models with uncertainty can be specified. As an example, consider characterizing the uncertainty model that is used for motion control in preimage planning research (e.g., <ref> [41, 67, 80] </ref>). Suppose there is a single decision maker that is a polygonal robot translating in the plane amidst polygonal obstacles. The action space defines commanded velocity directions, which can be specified by an orientation, yielding U = [0; 2). <p> Under nondeterministic uncertainty, the set of all possible environments that are consistent with y k can be inferred. An information state corresponds to the set of possible environments after some history of sensor observations and actions. Forward projections In preimage planning research <ref> [41, 80] </ref>, the useful notion of a forward projection was introduced for characterizing robot execution when there is uncertainty in configuration predictability 17 (a) (b) (c) interpretation of the data: Discontinuities correspond to portions of the environment that are unknown; c) One possible environment that is consistent with the data. <p> A motion strategy might bring the robot into a goal region (reachability), but the robot may not halt if it does not realize that it is in the goal region (recognizability) <ref> [41] </ref>. The notion of a termination condition has been quite useful for formulating robot plans that tell the robot when to halt, based on its current, partial information [41, 67, 80]. <p> The notion of a termination condition has been quite useful for formulating robot plans that tell the robot when to halt, based on its current, partial information <ref> [41, 67, 80] </ref>. <p> The termination condition represents a special action that can be considered by a robot, and can be applied in a variety of contexts for designing motion strategies. Performance preimages One concept that is complementary in many ways to the forward projection is the preimage <ref> [41, 67, 80] </ref>. A preimage is classically defined as the set of all configurations from which a robot is guaranteed to halt in the goal region under a constant motion command. <p> If the termination condition is neglected, then (fl; f0g) yields a backprojection similar to that in <ref> [41] </ref>. Suppose probabilistic uncertainty is considered instead of nondeterministic uncertainty. <p> The curve shown in Figure 4 (a) corresponds closely to the classical preimage that has been determined for this problem in previous manipulation planning research (e.g., <ref> [41, 66] </ref>). Figure 4 (b) assumes probabilistic uncertainty, and shows probabilistic backprojections that are quite similar to those that appear in [17].
Reference: [42] <author> P. Ferbach. </author> <title> A method of progressive constraints for nonholonomic motion planning. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 2949-2955, </pages> <year> 1996. </year>
Reference-contexts: Using this approach, a method that computes solutions for a sufficiently broad class of non-holonomic planning problems can be directly applied to problems involving dynamics (this observation was exploited to immediately obtain a kinodynamic plan using a nonholonomic planner in <ref> [42] </ref>).
Reference: [43] <author> E. G. Gilbert and D. W. Johnson. </author> <title> Distance functions and their application to robot path planning in the presence of obstacles. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 1(1) </volume> <pages> 21-30, </pages> <month> March </month> <year> 1985. </year>
Reference-contexts: The final term Q (x (t f )) can indicate the importance of achieving the goal. The basic problem can be considered as a special form of optimal control <ref> [43] </ref>. Suppose l (x (t); u (t)) 0, and Q (x (t f )) = 0 if x (t f ) = q goal and Q (x (t f )) = 1 otherwise. This corresponds to the original case in which optimality is not important.
Reference: [44] <author> T. N. Gillespie. </author> <title> Fundamentals of Vehicle Dynamics. </title> <booktitle> Society of Automotive Engineers, </booktitle> <address> Warrendale, PA, </address> <year> 1992. </year>
Reference-contexts: This could be encoded by changing the set of possible steering angles, U (x 4 ), on the basis of the speed, x 4 . This dynamical model is quite simple, and a variety of other, more sophisticated models <ref> [44] </ref> could be formulated in state-space terms. In general, robot dynamics can be expressed in terms of q, _q, and q. If the state vector, x, is defined as x = [q _q], the dynamics can be written in the form _x = f (x (t); u (t)).
Reference: [45] <author> P. J. Gmytrasiewicz, E. H. Durfee, and D. K. Wehe. </author> <title> A decision-theoretic approach to coordinating multi-agent interations. </title> <booktitle> In Proc. Int. Joint Conf. on Artif. Intell., </booktitle> <pages> pages 62-68, </pages> <year> 1991. </year>
Reference-contexts: Another sensing model could be introduced that reflects imperfect information that each decision maker has about the game itself. Problems of this type are quite realistic, yet are very difficult to model <ref> [45, 49] </ref>. The information of each decision maker could be represented, for example, as a pdf over a set of possible games. To make appropriate decisions, each decision maker must speculate about the knowledge that other decision makers have regarding the game.
Reference: [46] <author> K. Y. Goldberg. </author> <title> Orienting polygonal parts without sensors. </title> <journal> Algorithmica, </journal> <volume> 10 </volume> <pages> 201-225, </pages> <year> 1993. </year>
Reference-contexts: A motion strategy is then generated that is based on worst-case analysis (e.g., [23, 41, 67, 80]). With a probabilistic representation the parameter uncertainties are characterized with a probability density function (pdf). This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., <ref> [17, 46, 47] </ref>). One key aspect of the proposed mathematical foundation is a general capacity to model uncertainties by defining a nature player. This view of uncertainty was advocated for manipulation planning in [102].
Reference: [47] <author> K. Y. Goldberg and M. T. Mason. </author> <title> Bayesian grasping. </title> <booktitle> In IEEE Int. Conf. </booktitle> <institution> Robot. & Autom., </institution> <year> 1990. </year>
Reference-contexts: A motion strategy is then generated that is based on worst-case analysis (e.g., [23, 41, 67, 80]). With a probabilistic representation the parameter uncertainties are characterized with a probability density function (pdf). This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., <ref> [17, 46, 47] </ref>). One key aspect of the proposed mathematical foundation is a general capacity to model uncertainties by defining a nature player. This view of uncertainty was advocated for manipulation planning in [102].
Reference: [48] <author> O. Hajek. </author> <title> Pursuit Games. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: A "solution" to a game of the noncooperative type is referred to as an equilibrium because it provides a balance between the independent interests of the decision makers. One well-studied branch of noncooperative game theory involves problems of pursuit and evasion <ref> [48, 54, 92, 104, 105, 106] </ref>. Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature [16, 89].
Reference: [49] <author> J. C. Harsanyi. </author> <title> Games with incomplete information played by Bayesian players. </title> <journal> Management Science, </journal> <volume> 14(3) </volume> <pages> 159-182, </pages> <month> November </month> <year> 1967. </year>
Reference-contexts: Another sensing model could be introduced that reflects imperfect information that each decision maker has about the game itself. Problems of this type are quite realistic, yet are very difficult to model <ref> [45, 49] </ref>. The information of each decision maker could be represented, for example, as a pdf over a set of possible games. To make appropriate decisions, each decision maker must speculate about the knowledge that other decision makers have regarding the game.
Reference: [50] <author> K. W. Hipel, K. J. Radford, and L. Fang. </author> <title> Multiple participant-multiple criteria decision making. </title> <journal> IEEE Trans. Syst., Man, Cybern., </journal> <volume> 23(4) </volume> <pages> 1184-1189, </pages> <year> 1993. </year>
Reference-contexts: The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained <ref> [50, 94, 108] </ref>. In a situation in which there is a common loss functional and all decision makers wish to act cooperatively, team theory is obtained [25, 51, 61].
Reference: [51] <author> Y.-C. Ho and K.-C. Chu. </author> <title> Team decision theory and information structures in optimal control problems-part I. </title> <journal> In IEEE Trans. Autom. Control, </journal> <pages> pages 15-22, </pages> <year> 1972. </year>
Reference-contexts: If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained [50, 94, 108]. In a situation in which there is a common loss functional and all decision makers wish to act cooperatively, team theory is obtained <ref> [25, 51, 61] </ref>. A cooperative game refers to the case in which some subsets of the decision makers can choose their actions in unison, so that a mutually beneficial outcome can be obtained [14, 87].
Reference: [52] <author> H. Hu and M. Brady. </author> <title> A Bayesian approach to real-time obstacle avoidance for a mobile robot. </title> <booktitle> Autonomous Robots, </booktitle> <volume> 1(1) </volume> <pages> 69-92, </pages> <year> 1994. </year>
Reference-contexts: If the current environment is unknown, then there is uncertainty in environment sensing, which is a problem that has been considered in robotics from several different perspectives (e.g., <ref> [30, 35, 52, 65, 99] </ref>). This can be modeled by defining y k = h k (x k ; s k ), in which x k = [q k e k ]. In general, sensing and predictability uncertainties can be defined for any state space, including those that include dynamics.
Reference: [53] <author> H. Hu, M. Brady, and P. Probert. </author> <title> Coping with uncertainty in control and planning for a mobile robot. </title> <booktitle> In IEEE/RSJ Int. Workshop on Intelligent Robots and Systems, </booktitle> <pages> pages 1025-1030, </pages> <address> Osaka, Japan, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications <ref> [6, 53, 84, 100] </ref>. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies.
Reference: [54] <author> R. Isaacs. </author> <title> Differential Games. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1965. </year>
Reference-contexts: In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., [16, 29, 28]), optimal control theory (e.g., [2, 18, 62]), dynamic noncooperative game theory (e.g., <ref> [5, 54] </ref>). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained [50, 94, 108]. <p> A "solution" to a game of the noncooperative type is referred to as an equilibrium because it provides a balance between the independent interests of the decision makers. One well-studied branch of noncooperative game theory involves problems of pursuit and evasion <ref> [48, 54, 92, 104, 105, 106] </ref>. Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature [16, 89].
Reference: [55] <author> A. Isidori. </author> <title> Nonlinear Control Systems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: To facilitate upcoming concepts, let C free be renamed as a generic state space, X = C free . It is well known that the nonholonomic constraints can be expressed as 8 _x = f (x (t); u (t)), which constrains the allowable vector fields on X <ref> [55] </ref>. Instead of directly choosing x (t), one is forced to interact with the system using the input (or action) u (t). This occurs, for example, when manipulating an object through pushing [82].
Reference: [56] <author> K. Kant and S. W. Zucker. </author> <title> Toward efficient trajectory planning: The path-velocity decomposition. </title> <journal> Int. J. Robot. Res., </journal> <volume> 5(3) </volume> <pages> 72-89, </pages> <year> 1986. </year>
Reference-contexts: (x (t)) u (t); 0 t t f [21, 34] x k+1 = f (x k ; u k ) y k = h (x k ) Moving obstacles C (t) _x = f (x (t); u (t); t) y (t) = x (t) u (t); 0 t t f <ref> [40, 56] </ref> x k+1 = f k (x k ; u k ) y k = x k Pursuit-evasion C 1 fi C 2 _x = f (x (t); u 1 (t); u 2 (t)) y i (t) = h i (x (t)) fl 1 ; fl 2 : X ! <p> A centralized approach typically constructs a path in a composite configuration space, which is formed by combining the configuration spaces of the individual robots (e.g., [8, 96]). A decoupled approach typically generates paths for each robot independently, and then considers the interactions between the robots (e.g., <ref> [40, 56, 85] </ref>). The suitability of one approach over the other is usually determined by the tradeoff between computational complexity associated with a given problem and the amount of completeness that is lost. A variety of multiple-robot coordination problems can be formulated by defining appropriate state spaces [70].
Reference: [57] <author> L. Kavraki and J.-C. Latombe. </author> <title> Randomized preprocessing of configuration space for path planning. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 2138-2139, </pages> <year> 1994. </year>
Reference-contexts: Such results have turned efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [88] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 9, 57, 101] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes. <p> In the case of basic path planning, randomized search algorithms have been developed that perform well in practice for many high degree-of-freedom problems by relying on the notion of probabilistic completeness <ref> [1, 9, 57, 101] </ref>. These planners are formulated for problems in which path optimality is not a central concern and in which there is perfect configuration predictability (i.e., the solutions are open-loop paths in the configuration space).
Reference: [58] <author> L. E. Kavraki. </author> <title> Random Networks in Configuration Space for Fast Path Planning. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1994. </year>
Reference-contexts: 1 Introduction Two decades of development has led to many successful analysis techniques and algorithms for planning collision-free paths of rigid or articulated robots in a known, cluttered environment. These algorithms, such as the randomized potential field method [9] or probabilistic roadmaps <ref> [1, 58, 101] </ref>, have enjoyed great success across many different kinds of robotic platforms in both research and industrial applications, and in applications beyond robotics, such as virtual prototyping, graphical animation, architecture, and computational biology.
Reference: [59] <author> L. E. Kavraki. </author> <title> Computation of configuration-space obstacles using the Fast Fourier Transform. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 11(3) </volume> <pages> 408-413, </pages> <year> 1995. </year>
Reference-contexts: The constraints can be directly evaluated each time to determine whether each x k+1 lies in the free space, or a bitmap representation of the configuration space can be used for quick evaluations (an efficient algorithm for building a bitmap representation of C free is given in <ref> [59] </ref>). Note that L fl K represents the cost of the optimal one-stage strategy from each state x K . More generally, L fl Ki represents the cost of the optimal (i + 1)-stage strategy from each state x Ki .
Reference: [60] <author> O. Khatib. </author> <title> Real-time obstacle avoidance for manipulators and mobile robots. </title> <journal> Int. J. Robot. Res., </journal> <volume> 5(1) </volume> <pages> 90-98, </pages> <year> 1986. </year>
Reference-contexts: Artificial potential functions have often been constructed very efficiently in 27 path planning approaches; however, these approaches heuristically estimate the cost-to-go and are typically prone to have local minima <ref> [9, 60] </ref>. Suppose there are no uncertainties, and an optimal state-feedback strategy is sought using (30). Assume that the problem is stationary, which implies that no model components are time varying. The first step is to construct a representation of L fl K+1 .
Reference: [61] <author> K. H. Kim and F. W. Roush. </author> <title> Team Theory. </title> <publisher> Ellis Horwood Limited, </publisher> <address> Chichester, England, </address> <year> 1987. </year>
Reference-contexts: If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained [50, 94, 108]. In a situation in which there is a common loss functional and all decision makers wish to act cooperatively, team theory is obtained <ref> [25, 51, 61] </ref>. A cooperative game refers to the case in which some subsets of the decision makers can choose their actions in unison, so that a mutually beneficial outcome can be obtained [14, 87].
Reference: [62] <author> P. R. Kumar and P. Varaiya. </author> <title> Stochastic Systems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1986. </year>
Reference-contexts: In this case, its use is much more general than a "game" in the intuitive sense. The formulation presented in this section share similarities with concepts from statistical decision theory (e.g., [16, 29, 28]), optimal control theory (e.g., <ref> [2, 18, 62] </ref>), dynamic noncooperative game theory (e.g., [5, 54]). The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. <p> As will be discussed shortly, such problems can be viewed as a game against nature [16, 89]. If this uncertainty is represented probabilistically, the game against nature becomes a problem of stochastic optimal control theory <ref> [13, 62] </ref>. If the uncertainty is represented nondeterministically and worst case analysis is performed, then the game against nature can be considered as a form of robust controller design [4]. <p> Next, consider moving to a mathematical structure for the general motion strategy problem, which is based on concepts from dynamic noncooperative game theory [5] and stochastic optimal control <ref> [62] </ref>. This structure will be formulated in discrete time to ease the specification of uncertainty aspects; however, continuous time can alternatively be used with some minor modifications. Thirteen components are first listed, and a discussion of how each relates to the motion strategy problem follows. <p> In both control theory and dynamic game theory, the classic set of problems that can be solved are those with a linear state transition equation and quadratic loss functional <ref> [2, 5, 18, 62] </ref>. Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts. <p> In optimal control theory, the dynamic programming principle is represented as a differential equation (or difference equation in discrete time) that can be used to directly solve a problem such as the linear-quadratic Gaussian regulator <ref> [62] </ref>, or can be used for computing numerical approximations of optimal strategies [63]. In the general case, the differential equation is expressed in terms of time-dependent cost-to-go functions.
Reference: [63] <author> R. E. Larson. </author> <title> A survey of dynamic programming computational procedures. </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 12(6) </volume> <pages> 767-774, </pages> <month> December </month> <year> 1967. </year>
Reference-contexts: Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures <ref> [12, 13, 63, 64] </ref>, particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies. <p> In optimal control theory, the dynamic programming principle is represented as a differential equation (or difference equation in discrete time) that can be used to directly solve a problem such as the linear-quadratic Gaussian regulator [62], or can be used for computing numerical approximations of optimal strategies <ref> [63] </ref>. In the general case, the differential equation is expressed in terms of time-dependent cost-to-go functions. <p> Note that no choice of K is necessary. Also, only the representation of L fl k+1 is retained while constructing L fl k ; earlier representations can be discarded to save storage space. The general applicability of these kinds of computations was noted long ago in <ref> [63] </ref>: 1) extremely general types of system equations, performance criteria, and constraints can be handled; 2) particular questions of existence and uniqueness are avoided; 3) a true feedback solution is directly generated. These same advantages apply to motion strategy problems that are formulated in this paper.
Reference: [64] <author> R. E. Larson and J. L. Casti. </author> <title> Principles of Dynamic Programming, Part II. </title> <publisher> Dekker, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference-contexts: Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures <ref> [12, 13, 63, 64] </ref>, particularly in robotics applications [6, 53, 84, 100]. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies. <p> Linear interpolation between neighboring quantized states can be used, however, to obtain the appropriate loss value without restricting the motions to the grid (see Figure 6.a). Other schemes, such as quadratic interpolation, can be used to improve numerical accuracy at the expense of computation time <ref> [64] </ref>. Convergence properties of the quantization and interpolation are discussed in [11, 12]. For a motion planning problem, the obstacle constraints must additionally be taken into account.
Reference: [65] <author> R. E. Larson and W. G. Keckler. </author> <title> Optimum adaptive control in an unknown environment. </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 13(4) </volume> <pages> 438-439, </pages> <month> August </month> <year> 1968. </year> <month> 36 </month>
Reference-contexts: If the current environment is unknown, then there is uncertainty in environment sensing, which is a problem that has been considered in robotics from several different perspectives (e.g., <ref> [30, 35, 52, 65, 99] </ref>). This can be modeled by defining y k = h k (x k ; s k ), in which x k = [q k e k ]. In general, sensing and predictability uncertainties can be defined for any state space, including those that include dynamics.
Reference: [66] <author> J.-C. Latombe. </author> <title> Robot Motion Planning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1991. </year>
Reference-contexts: Configuration space concepts served as a powerful representational tool for both the development and analysis of path planning algorithms <ref> [66, 79] </ref>. For example, the comparison of seemingly disparate approaches, such as cell decomposition methods, roadmap methods, and artificial potential field methods, was greatly facilitated [66], which increased our ability to measure progress in this area. <p> Configuration space concepts served as a powerful representational tool for both the development and analysis of path planning algorithms [66, 79]. For example, the comparison of seemingly disparate approaches, such as cell decomposition methods, roadmap methods, and artificial potential field methods, was greatly facilitated <ref> [66] </ref>, which increased our ability to measure progress in this area. Once the configuration space framework was in place, it became possible to develop algorithms that were generalizable to adaptable to a wide variety of applications. <p> Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories [15, 19, 39, 78]) or centralized planning (planning occurs in a composite configuration space [3, 8, 96]). For example, the decoupled planning representations constructed in <ref> [66, 85] </ref> can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot. <p> The game-theoretic mathematical foundation leads to the following spaces and their relationships: W ! C ! X ! I World or Configuration State Information Workspace Space Space Space The first step of transforming the world or workspace into the configuration space has already been achieved by the path planning framework <ref> [66, 79] </ref>. In many problems, however, we might want to use a state space that encodes additional information. <p> The basic problem is to find a continuous path x : [0; t f ] ! C free such that x (0) = q init and x (t f ) = q goal . Here, C free refers to the set of collision-free robot configurations as defined in <ref> [66] </ref>. Recall that C free implicitly incorporates all of the constraints due to the robot geometry and static obstacles in the workspace. Suppose that there are nonholonomic constraints. To facilitate upcoming concepts, let C free be renamed as a generic state space, X = C free . <p> The curve shown in Figure 4 (a) corresponds closely to the classical preimage that has been determined for this problem in previous manipulation planning research (e.g., <ref> [41, 66] </ref>). Figure 4 (b) assumes probabilistic uncertainty, and shows probabilistic backprojections that are quite similar to those that appear in [17]. <p> By allowing time-varying models, many interesting motion strategy problems can be defined. Suppose, for instance, that several moving obstacles exist in the workspace. For a single-robot problem, this leads to a time-varying free configuration space X (t) C free (t) <ref> [66] </ref>, which can be approximated in discrete time as X [k] = t2 [(k1)t;kt) In general, many game items from Section 2 can encode time-dependent models. In these cases, the motion strategies fl i k and fl i k+1 will generally be different due to changes in the model.
Reference: [67] <author> J.-C. Latombe, A. Lazanas, and S. Shekhar. </author> <title> Robot motion planning with uncertainty in control and sensing. </title> <journal> Artif. Intell., </journal> <volume> 52 </volume> <pages> 1-47, </pages> <year> 1991. </year>
Reference-contexts: In the area of motion planning under uncertainty in sensing and prediction, many interesting concepts have been developed, such as preimages and forward projections <ref> [41, 67, 80, 83] </ref>); however, they are often tied to a particular set of uncertainty models that are based on crisp, geometric constructions (e.g., uncertainty cones and disks). <p> Two common representations of uncertainty have been applied to motion strategy problems. With a nondeterministic (or bounded-set) representation parameter uncertainties are restricted to lie within a specified set. A motion strategy is then generated that is based on worst-case analysis (e.g., <ref> [23, 41, 67, 80] </ref>). With a probabilistic representation the parameter uncertainties are characterized with a probability density function (pdf). This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., [17, 46, 47]). <p> An example of uncertainty in configuration predictability A variety of motion models with uncertainty can be specified. As an example, consider characterizing the uncertainty model that is used for motion control in preimage planning research (e.g., <ref> [41, 67, 80] </ref>). Suppose there is a single decision maker that is a polygonal robot translating in the plane amidst polygonal obstacles. The action space defines commanded velocity directions, which can be specified by an orientation, yielding U = [0; 2). <p> The notion of a termination condition has been quite useful for formulating robot plans that tell the robot when to halt, based on its current, partial information <ref> [41, 67, 80] </ref>. <p> The termination condition represents a special action that can be considered by a robot, and can be applied in a variety of contexts for designing motion strategies. Performance preimages One concept that is complementary in many ways to the forward projection is the preimage <ref> [41, 67, 80] </ref>. A preimage is classically defined as the set of all configurations from which a robot is guaranteed to halt in the goal region under a constant motion command.
Reference: [68] <author> J.-P. Laumond. </author> <title> Singularities and topological aspects in nonholonomic motion planning. </title> <editor> In Z. Li and J. F. Canny, editors, </editor> <booktitle> Nonholonomic Motion Planning, </booktitle> <pages> pages 149-200. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1993. </year>
Reference-contexts: _x = u (t) y (t) = x (t) [0; 1] ! C free [9, 86, 95] x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f <ref> [10, 20, 68, 77] </ref> x k+1 = f (x k ; u k ) y k = x k Dynamics T (C) _x = f (x (t); u (t)) y (t) = h (x (t)) u (t); 0 t t f [21, 34] x k+1 = f (x k ; u
Reference: [69] <author> S. M. LaValle. </author> <title> Numerical computation of optimal navigation functions on a simplicial complex. </title> <booktitle> To appear in Proc. 1998 Workshop on the Algorithmic Foundations of Robotics. </booktitle>
Reference-contexts: A similar idea can be 31 applied for continuous-state dynamic programming by identifying the "frontier" in the state space at which the loss values become stabilized <ref> [69] </ref>. For problems that involve uncertainty, this region of interest could be quite narrow or potentially large enough to span the entire space, depending on the problem.
Reference: [70] <author> S. M. LaValle. </author> <title> A Game-Theoretic Framework for Robot Motion Planning. </title> <type> PhD thesis, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: We propose the development of motion strategy algorithms that are built on a game-theoretic framework <ref> [70, 73, 76] </ref>, which will hopefully lead to some of the same benefits enjoyed by current path planning algorithms, but instead apply to a broader class of problems that are of interest to the robotics community. <p> In [73] it is shown how these concepts can be generalized to a broad class of problems that involve a variety of models and assumptions, and in <ref> [70, 76] </ref> the concepts are transported to other types of uncertainty problems. There are generally two forms of uncertainty that appear in motion planning and are addressed in this paper: uncertainty in predictability and uncertainty in sensing. <p> In general, the pdfs do not admit a low-dimensional parameterization; however, moments of the distributions can be considered as an approximate representation <ref> [70] </ref>. For practical purposes, one might have to consider low-dimensional transformations of the history, such as limiting the number of stages included in the history, or estimate some portion of the state vector. 13 The strategy concept Item 12 defines a strategy for each decision maker. <p> on general motion strategy aspects; however, by using the game-theoretic formulation as a representational tool, particular models, analysis, algorithms, and computed solutions have so far been obtained for four particular classes of problems: (1) motion strategies under uncertainty in sensing and control [73, 71]; (2) motion strategies under environment uncertainties <ref> [70, 76] </ref>; (3) multiple-robot motion strategies [70, 72]; and (4) maintaining visibility of a predictable target in a cluttered workspace [75]. For the first problem class, a general method for determining feedback strategies is developed by blending ideas from dynamic game theory with traditional preimage planning concepts. <p> by using the game-theoretic formulation as a representational tool, particular models, analysis, algorithms, and computed solutions have so far been obtained for four particular classes of problems: (1) motion strategies under uncertainty in sensing and control [73, 71]; (2) motion strategies under environment uncertainties [70, 76]; (3) multiple-robot motion strategies <ref> [70, 72] </ref>; and (4) maintaining visibility of a predictable target in a cluttered workspace [75]. For the first problem class, a general method for determining feedback strategies is developed by blending ideas from dynamic game theory with traditional preimage planning concepts. <p> Figure 4 (d) shows performance preimages of a computed optimal strategy. These results were all computed using variants of the algorithm discussed in Section 4. Performance preimages can also be defined on the information space to account for sensing uncertainty, and for multiple decision makers <ref> [70] </ref>. Decoupling multiple robots Consider the problem of coordinating multiple robots that have independent goals. Approaches to multiple-robot motion coordination are often categorized as centralized or decou-pled. <p> The suitability of one approach over the other is usually determined by the tradeoff between computational complexity associated with a given problem and the amount of completeness that is lost. A variety of multiple-robot coordination problems can be formulated by defining appropriate state spaces <ref> [70] </ref>. <p> The minimal game strategies with respect to are better 22 than or equal to all other game strategies in , and it is shown in <ref> [70] </ref> that very few minimal game strategies typically exist (ignoring those that produce equivalent losses). These solutions can be generated using algorithms that are based on the dynamic programming principle. For other applications this was observed in [26]. <p> These solutions can be generated using algorithms that are based on the dynamic programming principle. For other applications this was observed in [26]. For the criterion (19) it is shown that minimal solutions are consistent with other well-established forms of optimality from optimization literature <ref> [70] </ref>. The minimal game strategies are equivalent to the nondominated strategies used in multiobjective optimization and Pareto optimal game strategies used in cooperative game theory. <p> The velocity constraints can be specified in the form _x = f (x; u): _x = s 4 sin (x 3 ) 3 23 in which L is the distance between the front and rear axles, and s is the vehicle speed. A discrete-time representation is straightforward to obtain <ref> [70] </ref>. In this formulation, the car is only allowed to drive forward. Suppose that some dynamic constraints must additionally be satisfied, such as a realistic acceleration bound _s a for some maximum acceleration, a &gt; 0. <p> Related details and dozens of computed examples for a variety of motion strategy problems are presented in <ref> [70] </ref>. <p> Other variations include finding multiple Nash equilibria, worst-case strategies, and determining cost-to-go functions directly on the information space when there is uncertainty in sensing <ref> [70] </ref>. Iteratively approximating cost-to-go functions An optimal strategy can be computed by successively building approximate representations of the cost-to-go functions. One straightforward way to represent a cost-to-go function is to specify its values at each location in a discretized representation of the state space. <p> One might want to compute the set of Nash equilibria, as discussed in Section 3. Instead of storing a scalar loss, the cost-to-go at a state can be expanded to include a set of alternative strategies and corresponding vectors of losses. Several variations are discussed in further detail in <ref> [70] </ref>. In all of these cases, feedback strategies are determined that can respond quickly to online changes, without necessarily making the traditional assumption that the motion strategy and on-line control are decoupled. <p> Execution times for practical examples vary dramatically depending on the resolutions, but computation times typically range from a few seconds for a basic 2-D problem up to several hours for a challenging 3-D or 4-D problem with uncertainties, on a typical workstation <ref> [70] </ref>. It is important to note, however, that this algorithm is not competing with known algorithms that apply to the basic path planning problem, since the algorithm described in this paper computes a state-feedback strategy. <p> Figures 7.e and 7.f show two simulated executions under the implementation of the strategy that minimizes the expected time to reach the goal region while there are no outstanding requests. Other examples, which illustrate the breadth of the approach, appear in <ref> [70] </ref>. Algorithm improvements By making some restrictions of the problems considered, several improvements can be made to the dynamic programming algorithm.
Reference: [71] <author> S. M. LaValle and S. A. Hutchinson. </author> <title> An objective-based stochastic framework for manipulation planning. </title> <booktitle> In Proc. IEEE/RSJ/GI Int'l Conf. on Intelligent Robots and Systems, </booktitle> <pages> pages 1772-1779, </pages> <month> Septem-ber </month> <year> 1994. </year>
Reference-contexts: The emphasis is placed on general motion strategy aspects; however, by using the game-theoretic formulation as a representational tool, particular models, analysis, algorithms, and computed solutions have so far been obtained for four particular classes of problems: (1) motion strategies under uncertainty in sensing and control <ref> [73, 71] </ref>; (2) motion strategies under environment uncertainties [70, 76]; (3) multiple-robot motion strategies [70, 72]; and (4) maintaining visibility of a predictable target in a cluttered workspace [75].
Reference: [72] <author> S. M. LaValle and S. A. Hutchinson. </author> <title> Optimal motion planning for multiple robots having independent goals. </title> <booktitle> In Proc. IEEE Int'l Conf. Robot. & and Autom., </booktitle> <pages> pages 2847-2852, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Also, by recognizing the fact that the fixed-path coordination problem is equivalent to a simple form of planar nonholonomic planning, a straightforward Dijkstra-like algorithm can be adapted to quickly compute optimal coordination strategies <ref> [72] </ref>. In 4 general, feedback motion strategies can be determined that optimize one or more criteria in an appropri-ate game-theoretic sense (such as Pareto optimality or a Nash equilibrium), applying to a wide variety of multiple-robot coordination problems. <p> by using the game-theoretic formulation as a representational tool, particular models, analysis, algorithms, and computed solutions have so far been obtained for four particular classes of problems: (1) motion strategies under uncertainty in sensing and control [73, 71]; (2) motion strategies under environment uncertainties [70, 76]; (3) multiple-robot motion strategies <ref> [70, 72] </ref>; and (4) maintaining visibility of a predictable target in a cluttered workspace [75]. For the first problem class, a general method for determining feedback strategies is developed by blending ideas from dynamic game theory with traditional preimage planning concepts. <p> In some problems, multiple "optimal" solutions are possible. This occurs, for instance, in the coordination of multiple robots that have independent goals <ref> [72] </ref>. One might want to compute the set of Nash equilibria, as discussed in Section 3. Instead of storing a scalar loss, the cost-to-go at a state can be expanded to include a set of alternative strategies and corresponding vectors of losses.
Reference: [73] <author> S. M. LaValle and S. A. Hutchinson. </author> <title> An objective-based framework for motion planning under sensing and control uncertainties. </title> <journal> International Journal of Robotics Research, </journal> <volume> 17(1) </volume> <pages> 19-42, </pages> <month> January </month> <year> 1998. </year>
Reference-contexts: We propose the development of motion strategy algorithms that are built on a game-theoretic framework <ref> [70, 73, 76] </ref>, which will hopefully lead to some of the same benefits enjoyed by current path planning algorithms, but instead apply to a broader class of problems that are of interest to the robotics community. <p> In <ref> [73] </ref> it is shown how these concepts can be generalized to a broad class of problems that involve a variety of models and assumptions, and in [70, 76] the concepts are transported to other types of uncertainty problems. <p> The emphasis is placed on general motion strategy aspects; however, by using the game-theoretic formulation as a representational tool, particular models, analysis, algorithms, and computed solutions have so far been obtained for four particular classes of problems: (1) motion strategies under uncertainty in sensing and control <ref> [73, 71] </ref>; (2) motion strategies under environment uncertainties [70, 76]; (3) multiple-robot motion strategies [70, 72]; and (4) maintaining visibility of a predictable target in a cluttered workspace [75]. <p> With a 0-1 loss functional and ignoring the termination condition, the performance preimages can give isoprobability curves which are equivalent to the probabilistic backprojections in [17]. Some examples of preimages are shown in Figure 4 (see also <ref> [73] </ref>). Figure 4 (a) shows a performance preimage under nondeterministic uncertainty and a loss functional that returns 0 when the goal is achieved, and 1 otherwise.
Reference: [74] <author> S. M. LaValle, D. Lin, L. J. Guibas, J.-C. Latombe, and R. Motwani. </author> <title> Finding an unpredictable target in a workspace with obstacles. </title> <booktitle> In Proc. IEEE Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 737-742, </pages> <year> 1997. </year>
Reference-contexts: Thus for each possible action and sensing history, a set of possible current states can be identified. For example, in pursuit-evasion problems for which the evader position is unknown, the information state can represent possible locations of the evader, given the initial conditions and history of pursuer motions <ref> [74] </ref>. With probabilistic uncertainty, the information space can be alternatively represented as a pdf on X that is obtained through the repeated application of Bayes' rule. <p> For many particular problems that fall within the game-theoretic framework, it might be possible to exploit special properties to develop an algorithm that is far superior to the general methods stated here. For example, in <ref> [74] </ref>, a combinatorial representation of the information space led to a complete algorithm for computing a motion strategy for a pursuer in a 2D environment, which is guaranteed to lead to line-of-sight visibility of an evading target.
Reference: [75] <author> S. M. LaValle, H. H. Gonzalez-Ba nos, C. Becker, and J.-C. Latombe. </author> <title> Motion strategies for maintaining visibility of a moving target. </title> <booktitle> In Proc. IEEE Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 731-736, </pages> <year> 1997. </year>
Reference-contexts: computed solutions have so far been obtained for four particular classes of problems: (1) motion strategies under uncertainty in sensing and control [73, 71]; (2) motion strategies under environment uncertainties [70, 76]; (3) multiple-robot motion strategies [70, 72]; and (4) maintaining visibility of a predictable target in a cluttered workspace <ref> [75] </ref>. For the first problem class, a general method for determining feedback strategies is developed by blending ideas from dynamic game theory with traditional preimage planning concepts. This generalizes classical preimages to performance preimages and preimage plans to motion strategies with information feedback. <p> Some problems involve nonstationary information, such as tracking a predictable target in a cluttered environment; in this case optimal solutions can be computed by retaining all cost-to-go functions from stages 1 to K + 1 <ref> [75] </ref>. In some problems, multiple "optimal" solutions are possible. This occurs, for instance, in the coordination of multiple robots that have independent goals [72]. One might want to compute the set of Nash equilibria, as discussed in Section 3.
Reference: [76] <author> S. M. LaValle and R. Sharma. </author> <title> On motion planning in changing, partially-predictable environments. </title> <journal> International Journal of Robotics Research, </journal> <volume> 16(6) </volume> <pages> 775-805, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: We propose the development of motion strategy algorithms that are built on a game-theoretic framework <ref> [70, 73, 76] </ref>, which will hopefully lead to some of the same benefits enjoyed by current path planning algorithms, but instead apply to a broader class of problems that are of interest to the robotics community. <p> In [73] it is shown how these concepts can be generalized to a broad class of problems that involve a variety of models and assumptions, and in <ref> [70, 76] </ref> the concepts are transported to other types of uncertainty problems. There are generally two forms of uncertainty that appear in motion planning and are addressed in this paper: uncertainty in predictability and uncertainty in sensing. <p> This kind of state space representation is common in modern control theory [24]. In some applications, the state space might encode information that represents the status of the environment <ref> [76] </ref>. In general, if there is sensing uncertainty (i.e., the current state is unknown during execution), the state space can be replaced by an information space [5]. <p> a (t)) y (t) = x (t) fl : X ! U [17, 31, 41] x k+1 = f (x k ; u k ; a EP uncertainty C fi E _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U <ref> [27, 76, 107] </ref> x k+1 = f (x k ; u k ; a CS and CP unc. <p> This corresponds to the standard use of state space representations in optimal control theory. The state space can also include any parameters that can be completely or partially controlled through the operation of the robot (s). In <ref> [76] </ref> the state space includes environment modes that characterize varying conditions in the environment that potentially affect the robot. Item 4 defines the set of actions that are available to each decision maker at each stage. Item 5 is used to model sources of uncertainty. <p> on general motion strategy aspects; however, by using the game-theoretic formulation as a representational tool, particular models, analysis, algorithms, and computed solutions have so far been obtained for four particular classes of problems: (1) motion strategies under uncertainty in sensing and control [73, 71]; (2) motion strategies under environment uncertainties <ref> [70, 76] </ref>; (3) multiple-robot motion strategies [70, 72]; and (4) maintaining visibility of a predictable target in a cluttered workspace [75]. For the first problem class, a general method for determining feedback strategies is developed by blending ideas from dynamic game theory with traditional preimage planning concepts. <p> In this case there is uncertainty in the robot's environment. A set E can be used to index the alternatives, and a state space is defined as some subset X C fi E <ref> [76] </ref>. Thus, for every e 2 E, a different free configuration space can be obtained. Let [q k e k ] represent the state at stage k. A state transition equation can be defined in two portions. <p> Computed examples To indicate the level of difficulty that can be handled by the dynamic programming approach described in this section, examples of two motion planning problems that can be solved appear in predictable (more details appear in <ref> [76] </ref>). Figure 7.a shows a problem for which there is a single rigid robot that can rotate in place or translate along its major axis.
Reference: [77] <author> Z. Li and J. F. Canny. </author> <title> Nonholonomic Motion Planning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1993. </year>
Reference-contexts: _x = u (t) y (t) = x (t) [0; 1] ! C free [9, 86, 95] x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f <ref> [10, 20, 68, 77] </ref> x k+1 = f (x k ; u k ) y k = x k Dynamics T (C) _x = f (x (t); u (t)) y (t) = h (x (t)) u (t); 0 t t f [21, 34] x k+1 = f (x k ; u
Reference: [78] <author> C.-F. Lin and W.-H. Tsai. </author> <title> Motion planning for multiple robots with multi-mode operations via disjunctive graphs. </title> <journal> Robotica, </journal> <volume> 9 </volume> <pages> 393-408, </pages> <year> 1990. </year>
Reference-contexts: Specialized techniques that have been developed for the coordination of multiple robots that have independent goals can also be unified. Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories <ref> [15, 19, 39, 78] </ref>) or centralized planning (planning occurs in a composite configuration space [3, 8, 96]). For example, the decoupled planning representations constructed in [66, 85] can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot.
Reference: [79] <author> T. Lozano-Perez. </author> <title> Spatial planning: A configuration space approach. </title> <journal> IEEE Trans. on Comput., </journal> <volume> C-32(2):108-120, </volume> <year> 1983. </year>
Reference-contexts: Configuration space concepts served as a powerful representational tool for both the development and analysis of path planning algorithms <ref> [66, 79] </ref>. For example, the comparison of seemingly disparate approaches, such as cell decomposition methods, roadmap methods, and artificial potential field methods, was greatly facilitated [66], which increased our ability to measure progress in this area. <p> The game-theoretic mathematical foundation leads to the following spaces and their relationships: W ! C ! X ! I World or Configuration State Information Workspace Space Space Space The first step of transforming the world or workspace into the configuration space has already been achieved by the path planning framework <ref> [66, 79] </ref>. In many problems, however, we might want to use a state space that encodes additional information.
Reference: [80] <author> T. Lozano-Perez, M. T. Mason, and R. H. Taylor. </author> <title> Automatic systhesis of fine-motion strategies for robots. </title> <journal> Int. J. Robot. Res., </journal> <volume> 3(1) </volume> <pages> 3-24, </pages> <year> 1984. </year>
Reference-contexts: In the area of motion planning under uncertainty in sensing and prediction, many interesting concepts have been developed, such as preimages and forward projections <ref> [41, 67, 80, 83] </ref>); however, they are often tied to a particular set of uncertainty models that are based on crisp, geometric constructions (e.g., uncertainty cones and disks). <p> Two common representations of uncertainty have been applied to motion strategy problems. With a nondeterministic (or bounded-set) representation parameter uncertainties are restricted to lie within a specified set. A motion strategy is then generated that is based on worst-case analysis (e.g., <ref> [23, 41, 67, 80] </ref>). With a probabilistic representation the parameter uncertainties are characterized with a probability density function (pdf). This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., [17, 46, 47]). <p> The relationship between sensor and action history and decision making has long been considered important in planning under uncertainty (e.g., <ref> [41, 80] </ref>). Generally one would like to optimize the performance of a robot, while directly taking into account the complications due to limited sensing. By using the concept of information state, as considered in stochastic control and dynamic game theory, a useful characterization of this relationship is provided. <p> An example of uncertainty in configuration predictability A variety of motion models with uncertainty can be specified. As an example, consider characterizing the uncertainty model that is used for motion control in preimage planning research (e.g., <ref> [41, 67, 80] </ref>). Suppose there is a single decision maker that is a polygonal robot translating in the plane amidst polygonal obstacles. The action space defines commanded velocity directions, which can be specified by an orientation, yielding U = [0; 2). <p> Under nondeterministic uncertainty, the set of all possible environments that are consistent with y k can be inferred. An information state corresponds to the set of possible environments after some history of sensor observations and actions. Forward projections In preimage planning research <ref> [41, 80] </ref>, the useful notion of a forward projection was introduced for characterizing robot execution when there is uncertainty in configuration predictability 17 (a) (b) (c) interpretation of the data: Discontinuities correspond to portions of the environment that are unknown; c) One possible environment that is consistent with the data. <p> The notion of a termination condition has been quite useful for formulating robot plans that tell the robot when to halt, based on its current, partial information <ref> [41, 67, 80] </ref>. <p> The termination condition represents a special action that can be considered by a robot, and can be applied in a variety of contexts for designing motion strategies. Performance preimages One concept that is complementary in many ways to the forward projection is the preimage <ref> [41, 67, 80] </ref>. A preimage is classically defined as the set of all configurations from which a robot is guaranteed to halt in the goal region under a constant motion command.
Reference: [81] <author> V. J. Lumelsky and A. A. Stepanov. </author> <title> Path planning strategies for a point mobile automaton moving amidst unknown obstacles of arbitrary shape. </title> <journal> Algorithmica, </journal> <volume> 2 </volume> <pages> 403-430, </pages> <year> 1987. </year>
Reference-contexts: (t); a (t)) y (t) = h (x (t); s (t)) fl : I k ! U k ) y k = h (x k ; s ES uncertainty C fi E _x = u (t) y (t) = h (x (t); s (t)) fl : I k ! U <ref> [30, 33, 81] </ref> x k+1 = x k + u k y k = h (x k ; s have received previous attention. For each case, the state space is identified. Both continuous-time and discrete-time models are given for motions and for sensing.
Reference: [82] <author> K. M. Lynch and M. T. Mason. </author> <title> Pulling by pushing, slip with infinite friction, and perfectly rough surfaces. </title> <journal> Int. J. Robot. Res., </journal> <volume> 14(2) </volume> <pages> 174-183, </pages> <year> 1995. </year>
Reference-contexts: Instead of directly choosing x (t), one is forced to interact with the system using the input (or action) u (t). This occurs, for example, when manipulating an object through pushing <ref> [82] </ref>. If f (x (t); u (t)) = u (t) for ku (t)k 1, the original holonomic, path planning problem is obtained since any desired, collision-free path in the state space can be obtained by selecting an appropriate input.
Reference: [83] <author> M. T. Mason. </author> <title> Automatic planning of fine motions: Correctness and completeness. </title> <booktitle> In Proc. IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 492-503, </pages> <year> 1984. </year>
Reference-contexts: In the area of motion planning under uncertainty in sensing and prediction, many interesting concepts have been developed, such as preimages and forward projections <ref> [41, 67, 80, 83] </ref>); however, they are often tied to a particular set of uncertainty models that are based on crisp, geometric constructions (e.g., uncertainty cones and disks).
Reference: [84] <author> J. Miura and Y. Shirai. </author> <title> Planning of vision and motion for a mobile robot using a probabilistic model of uncertainty. </title> <booktitle> In IEEE/RSJ Int. Workshop on Intelligent Robots and Systems, </booktitle> <pages> pages 403-408, </pages> <address> Osaka, Japan, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications <ref> [6, 53, 84, 100] </ref>. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies.
Reference: [85] <author> P. A. O'Donnell and T. Lozano-Perez. </author> <title> Deadlock-free and collision-free coordination of two robot manipulators. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 484-489, </pages> <year> 1989. </year> <month> 37 </month>
Reference-contexts: Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories [15, 19, 39, 78]) or centralized planning (planning occurs in a composite configuration space [3, 8, 96]). For example, the decoupled planning representations constructed in <ref> [66, 85] </ref> can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot. <p> X ! U [92] x k+1 = f (x k ; u 1 k ) y i Multiple robots C 1 fi fi C N _ x i = f i (x i (t); u i (t)) y i (t) = x (t) fl i : X ! U i <ref> [19, 85, 101] </ref> x i k ; u i k = x k CP uncertainty C _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U [17, 31, 41] x k+1 = f (x k ; u k ; a EP uncertainty <p> A centralized approach typically constructs a path in a composite configuration space, which is formed by combining the configuration spaces of the individual robots (e.g., [8, 96]). A decoupled approach typically generates paths for each robot independently, and then considers the interactions between the robots (e.g., <ref> [40, 56, 85] </ref>). The suitability of one approach over the other is usually determined by the tradeoff between computational complexity associated with a given problem and the amount of completeness that is lost. A variety of multiple-robot coordination problems can be formulated by defining appropriate state spaces [70].
Reference: [86] <author> C. O'Dunlaing and C. K. Yap. </author> <title> A retraction method for planning the motion of a disc. </title> <journal> Journal of Algorithms, </journal> <volume> 6 </volume> <pages> 104-111, </pages> <year> 1982. </year>
Reference-contexts: In general, however, the state space could incorporate additional information. For instance, dynamics can 10 Problem State Space Motion Model Sensing Model Strategy Basic MP C _x = u (t) y (t) = x (t) [0; 1] ! C free <ref> [9, 86, 95] </ref> x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f [10, 20, 68, 77] x k+1 = f (x k ; u k ) y
Reference: [87] <author> G. Owen. </author> <title> Game Theory. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference-contexts: A cooperative game refers to the case in which some subsets of the decision makers can choose their actions in unison, so that a mutually beneficial outcome can be obtained <ref> [14, 87] </ref>. Without cooperation the decision makers choose actions that take into account interests that conflict with the other decision makers. This is referred to as a noncooperative game. The most extreme case of conflicting interest is a zero-sum game, in which two decision makers are diametrically opposed. <p> For cases in which there are multiple, independent decision makers, a number of different concepts may be appropriate. For instance, in a cooperative game in which there is a certain amount of trust, Pareto optimality may be appropriate <ref> [87] </ref>. In a noncooperative setting, a Nash equilibrium condition might be appropriate [5].
Reference: [88] <author> C. H. Papadimitriou. </author> <title> An algorithm for shortest-path planning in three dimensions. </title> <journal> Information Processing Letters, </journal> <volume> 20(5) </volume> <pages> 259-263, </pages> <year> 1985. </year>
Reference-contexts: In [92], a 3-D pursuit-evasion problem is shown to be exponential time hard, even though there is perfect sensing information. Such results have turned efforts toward approximate techniques. For example, a polynomial-time algorithm is given in <ref> [88] </ref> for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods [1, 9, 57, 101].
Reference: [89] <author> C. H. Papadimitriou. </author> <title> Games against nature. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 31 </volume> <pages> 288-301, </pages> <year> 1985. </year>
Reference-contexts: Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature <ref> [16, 89] </ref>. If this uncertainty is represented probabilistically, the game against nature becomes a problem of stochastic optimal control theory [13, 62]. If the uncertainty is represented nondeterministically and worst case analysis is performed, then the game against nature can be considered as a form of robust controller design [4].
Reference: [90] <author> J. H. Reif. </author> <title> Complexity of the mover's problem and generalizations. </title> <booktitle> In Proc. of IEEE Symp. on Foundat. of Comp. Sci., </booktitle> <pages> pages 421-427, </pages> <year> 1979. </year>
Reference-contexts: If the following was available, all of our problems would be solved: A practical algorithm that computes an optimal feedback motion strategy on any information space. It appears impractical to work toward this ideal; even the basic path planning problem is PSPACE-hard <ref> [90] </ref> (the information space is generally infinite dimensional). Nevertheless, we now have practical algorithms for path planning that have been very successful in practice, even though they fall short of the ideal of being complete, general algorithms. <p> The computational hardness results have curbed many efforts to find efficient, complete algorithms to general motion strategy problems. In <ref> [90] </ref> the basic path planning problem was shown to be PSPACE-hard for polyhedral robots with n links. In [22] is was shown that computing minimum-distance paths in a 3-D workspace is NP-hard. It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard.
Reference: [91] <author> J. H. Reif and M. Sharir. </author> <title> Motion planning in the presence of moving obstacles. </title> <booktitle> In Proc. of IEEE Symp. on Foundat. of Comp. Sci., </booktitle> <pages> pages 144-154, </pages> <year> 1985. </year>
Reference-contexts: In [22] is was shown that computing minimum-distance paths in a 3-D workspace is NP-hard. It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard. In <ref> [91] </ref> it was shown that planning the motion of a disk in a 3-D environment with rotating obstacles is PSPACE-hard. In [92], a 3-D pursuit-evasion problem is shown to be exponential time hard, even though there is perfect sensing information. Such results have turned efforts toward approximate techniques.
Reference: [92] <author> J. H. Reif and S. R. Tate. </author> <title> Continuous alternation: The complexity of pursuit in continuous domains. </title> <journal> Algorithmica, </journal> <volume> 10 </volume> <pages> 157-181, </pages> <year> 1993. </year>
Reference-contexts: In this case, path planning is generally insufficient because a motion strategy must cause the robot (s) to respond appropriately to these unknown future states. As stated in <ref> [92] </ref>, "...it remains a fundamental problem to develop dynamic movement planning algorithms," which motivated that research and lends support to the strategy concepts presented in this paper. <p> A "solution" to a game of the noncooperative type is referred to as an equilibrium because it provides a balance between the independent interests of the decision makers. One well-studied branch of noncooperative game theory involves problems of pursuit and evasion <ref> [48, 54, 92, 104, 105, 106] </ref>. Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature [16, 89]. <p> x k+1 = f k (x k ; u k ) y k = x k Pursuit-evasion C 1 fi C 2 _x = f (x (t); u 1 (t); u 2 (t)) y i (t) = h i (x (t)) fl 1 ; fl 2 : X ! U <ref> [92] </ref> x k+1 = f (x k ; u 1 k ) y i Multiple robots C 1 fi fi C N _ x i = f i (x i (t); u i (t)) y i (t) = x (t) fl i : X ! U i [19, 85, 101] x <p> It was also shown that the compliant motion control problem with sensing uncertainty is nondeterministic exponential time hard. In [91] it was shown that planning the motion of a disk in a 3-D environment with rotating obstacles is PSPACE-hard. In <ref> [92] </ref>, a 3-D pursuit-evasion problem is shown to be exponential time hard, even though there is perfect sensing information. Such results have turned efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [88] for computing epsilon approximations of minimum-distance paths in a 3-D environment.
Reference: [93] <author> E. Rimon and D. E. Koditschek. </author> <title> Exact robot navigation using artificial potential fields. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 8(5) </volume> <pages> 501-518, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This concept additionally relates closely to navigation functions <ref> [9, 93] </ref> and progress measures [38]. Assume that a strategy encodes a termination condition in addition to motion control, and that there is only a single decision maker (other than nature). Suppose that there is nondeterministic uncertainty, which is standard in preimage planning research. <p> Note that although the approach to 29 select the action is local (and efficient), the global information is still taken into account (it is encoded in the cost-to-go function). This concept is similar to the use of a numerical navigation function in previous motion planning literature <ref> [9, 93] </ref>, and the cost-to-go is a form of progress measure, as considered in [38]. When considering the cost-to-go as a navigation function, it is important to note that it does not contain local minima because it is constructed as a by product of determining the optimal solution.
Reference: [94] <author> Y. Sawaragi, H. Nakayama, and T. Tanino. </author> <title> Theory of Multiobjective Optimization. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference-contexts: The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained <ref> [50, 94, 108] </ref>. In a situation in which there is a common loss functional and all decision makers wish to act cooperatively, team theory is obtained [25, 51, 61].
Reference: [95] <author> J. T. Schwartz and M. Sharir. </author> <title> On the piano movers' problem: II. General techniqies for computing topological properties of algebraic manifolds. </title> <journal> Communications on Pure and Applied Mathematics, </journal> <volume> 36 </volume> <pages> 345-398, </pages> <year> 1983. </year>
Reference-contexts: In general, however, the state space could incorporate additional information. For instance, dynamics can 10 Problem State Space Motion Model Sensing Model Strategy Basic MP C _x = u (t) y (t) = x (t) [0; 1] ! C free <ref> [9, 86, 95] </ref> x k+1 = x k + u k y k = x k Nonholonomic C _x = f (x (t); u (t)) y (t) = x (t) u (t); 0 t t f [10, 20, 68, 77] x k+1 = f (x k ; u k ) y
Reference: [96] <author> J. T. Schwartz and M. Sharir. </author> <title> On the piano movers' problem: III. Coordinating the motion of several independent bodies. </title> <journal> Int. J. Robot. Res., </journal> <volume> 2(3) </volume> <pages> 97-140, </pages> <year> 1983. </year>
Reference-contexts: Methods often vary significantly based on the use of decoupled planning (planning the paths independently and then coordinating the robot trajectories [15, 19, 39, 78]) or centralized planning (planning occurs in a composite configuration space <ref> [3, 8, 96] </ref>). For example, the decoupled planning representations constructed in [66, 85] can be generalized to a broad class of state spaces, including coordination along a configuration-space roadmap for each robot. <p> Approaches to multiple-robot motion coordination are often categorized as centralized or decou-pled. A centralized approach typically constructs a path in a composite configuration space, which is formed by combining the configuration spaces of the individual robots (e.g., <ref> [8, 96] </ref>). A decoupled approach typically generates paths for each robot independently, and then considers the interactions between the robots (e.g., [40, 56, 85]).
Reference: [97] <author> R. Sharma, S. M. LaValle, and S. A. Hutchinson. </author> <title> Optimizing robot motion strategies for assembly with stochastic models of the assembly process. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 12(2) </volume> <pages> 160-174, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: The limiting case of K = 1 can be defined. In general, decision making at regular intervals is not required. Suppose, for instance, that the decisions correspond to very high-level operations which may have unpredictable completion times. This case is discussed in more detail in <ref> [97] </ref>, for modeling the completion of a fine-motion operation. The state space is defined in Item 3. At the very least, the state space can be used to represent the free configuration space, C free .
Reference: [98] <author> K. G. Shin and Q. Zheng. </author> <title> Minimum-time collision-free trajectory planning for dual-robot systems. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 8(5) </volume> <pages> 641-644, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Multiple-robot optimality Little concern has been given in previous research to optimality for multiple-robot coordination problems. Previous approaches that consider optimality project the vector of individual losses onto a scalar loss <ref> [15, 98, 103] </ref>. As a result, these methods can fail to find many potentially useful motion strategies. There are many well-studied optimality concepts from game-theory and multiobjective optimization literature that can be applied in this case.
Reference: [99] <author> A. Stentz. </author> <title> Optimal and efficient path planning for partially-known environments. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 3310-3317, </pages> <year> 1994. </year>
Reference-contexts: If the current environment is unknown, then there is uncertainty in environment sensing, which is a problem that has been considered in robotics from several different perspectives (e.g., <ref> [30, 35, 52, 65, 99] </ref>). This can be modeled by defining y k = h k (x k ; s k ), in which x k = [q k e k ]. In general, sensing and predictability uncertainties can be defined for any state space, including those that include dynamics.
Reference: [100] <author> S.-H. Suh and K. G. Shin. </author> <title> A variational dynamic programming approach to robot-path planning with a distance-safety criterion. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 4(3) </volume> <pages> 334-349, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Because few problems can be solved analytically, there has been a large focus on numerical dynamic optimization procedures [12, 13, 63, 64], particularly in robotics applications <ref> [6, 53, 84, 100] </ref>. The algorithm description is organized into three parts. First, the general principle of optimality is described, which greatly reduces the amount of effort that is required to compute optimal strategies.
Reference: [101] <author> P. Svestka and M. H. Overmars. </author> <title> Coordinated motion planning for multiple car-like robots using probabilistic roadmaps. </title> <booktitle> In IEEE Int. Conf. Robot. & Autom., </booktitle> <pages> pages 1631-1636, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Two decades of development has led to many successful analysis techniques and algorithms for planning collision-free paths of rigid or articulated robots in a known, cluttered environment. These algorithms, such as the randomized potential field method [9] or probabilistic roadmaps <ref> [1, 58, 101] </ref>, have enjoyed great success across many different kinds of robotic platforms in both research and industrial applications, and in applications beyond robotics, such as virtual prototyping, graphical animation, architecture, and computational biology. <p> X ! U [92] x k+1 = f (x k ; u 1 k ) y i Multiple robots C 1 fi fi C N _ x i = f i (x i (t); u i (t)) y i (t) = x (t) fl i : X ! U i <ref> [19, 85, 101] </ref> x i k ; u i k = x k CP uncertainty C _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U [17, 31, 41] x k+1 = f (x k ; u k ; a EP uncertainty <p> Such results have turned efforts toward approximate techniques. For example, a polynomial-time algorithm is given in [88] for computing epsilon approximations of minimum-distance paths in a 3-D environment. Also, randomized techniques are used to compute solutions for high degree-of-freedom problems that are unapproachable by complete methods <ref> [1, 9, 57, 101] </ref>. The second motivation for considering approximate solutions is to avoid specialized analysis of particular cases, with the intent of allowing the algorithms to be adaptable to other problem classes. <p> In the case of basic path planning, randomized search algorithms have been developed that perform well in practice for many high degree-of-freedom problems by relying on the notion of probabilistic completeness <ref> [1, 9, 57, 101] </ref>. These planners are formulated for problems in which path optimality is not a central concern and in which there is perfect configuration predictability (i.e., the solutions are open-loop paths in the configuration space).
Reference: [102] <author> R. H. Taylor, M. T. Mason, and K. Y. Goldberg. </author> <title> Sensor-based manipulation planning as a game with nature. </title> <booktitle> In Fourth International Symposium on Robotics Research, </booktitle> <pages> pages 421-429, </pages> <year> 1987. </year>
Reference-contexts: This often leads to the construction of motion strategies through average-case or expected-case analysis (e.g., [17, 46, 47]). One key aspect of the proposed mathematical foundation is a general capacity to model uncertainties by defining a nature player. This view of uncertainty was advocated for manipulation planning in <ref> [102] </ref>. It will be assumed that no decision maker has control over actions that are chosen by nature; however, models can 11 be constructed to partially predict nature's actions. Nature can introduce nondeterministic or probabilistic uncertainties into the game by applying either control actions or sensing actions.
Reference: [103] <author> F.-Y. Wang and P. J. A. Lever. </author> <title> A cell mapping method for general optimum trajectory planning of multiple robotic arms. </title> <booktitle> Robots and Autonomous Systems, </booktitle> <volume> 12 </volume> <pages> 15-27, </pages> <year> 1994. </year>
Reference-contexts: Multiple-robot optimality Little concern has been given in previous research to optimality for multiple-robot coordination problems. Previous approaches that consider optimality project the vector of individual losses onto a scalar loss <ref> [15, 98, 103] </ref>. As a result, these methods can fail to find many potentially useful motion strategies. There are many well-studied optimality concepts from game-theory and multiobjective optimization literature that can be applied in this case.
Reference: [104] <author> Y. Yavin and M. Pachter. </author> <title> Pursuit-Evasion Differential Games. </title> <publisher> Pergamon Press, Oxford, </publisher> <address> England, </address> <year> 1987. </year>
Reference-contexts: A "solution" to a game of the noncooperative type is referred to as an equilibrium because it provides a balance between the independent interests of the decision makers. One well-studied branch of noncooperative game theory involves problems of pursuit and evasion <ref> [48, 54, 92, 104, 105, 106] </ref>. Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature [16, 89].
Reference: [105] <author> J. Yong. </author> <title> On differential evasion games. </title> <journal> SIAM J. Control & Optimization, </journal> <volume> 26(1) </volume> <pages> 1-22, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: A "solution" to a game of the noncooperative type is referred to as an equilibrium because it provides a balance between the independent interests of the decision makers. One well-studied branch of noncooperative game theory involves problems of pursuit and evasion <ref> [48, 54, 92, 104, 105, 106] </ref>. Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature [16, 89].
Reference: [106] <author> J. Yong. </author> <title> On differential pursuit games. </title> <journal> SIAM J. Control & Optimization, </journal> <volume> 26(2) </volume> <pages> 478-495, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: A "solution" to a game of the noncooperative type is referred to as an equilibrium because it provides a balance between the independent interests of the decision makers. One well-studied branch of noncooperative game theory involves problems of pursuit and evasion <ref> [48, 54, 92, 104, 105, 106] </ref>. Game theory can also model a situation in which some decision makers represent disturbances that must be overcome by the other decision makers. As will be discussed shortly, such problems can be viewed as a game against nature [16, 89].
Reference: [107] <author> Q. Zhu. </author> <title> Hidden Markov model for dynamic obstacle avoidance of mobile robot navigation. </title> <journal> IEEE Trans. Robot. & Autom., </journal> <volume> 7(3) </volume> <pages> 390-397, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: a (t)) y (t) = x (t) fl : X ! U [17, 31, 41] x k+1 = f (x k ; u k ; a EP uncertainty C fi E _x = f (x (t); u (t); a (t)) y (t) = x (t) fl : X ! U <ref> [27, 76, 107] </ref> x k+1 = f (x k ; u k ; a CS and CP unc.
Reference: [108] <author> S. Zionts. </author> <title> Multiple criteria mathematical programming: An overview and several approaches. </title> <editor> In P. Ser-afini, editor, </editor> <booktitle> Mathematics of Multi-Objective Optimization, </booktitle> <pages> pages 227-273. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: The amount of cooperation that occurs between decision makers in a game is one of the key differences between different branches of game theory literature. If the decision makers act in unison but each has different loss functionals, the multiobjective optimization problem is obtained <ref> [50, 94, 108] </ref>. In a situation in which there is a common loss functional and all decision makers wish to act cooperatively, team theory is obtained [25, 51, 61].
References-found: 108

