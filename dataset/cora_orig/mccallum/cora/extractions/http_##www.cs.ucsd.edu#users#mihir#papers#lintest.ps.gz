URL: http://www.cs.ucsd.edu/users/mihir/papers/lintest.ps.gz
Refering-URL: http://www.cs.ucsd.edu/users/mihir/papers/complexity-papers.html
Root-URL: http://www.cs.ucsd.edu
Email: mihir@cs.ucsd.edu.  copper@watson.ibm.com.  johanh@nada.kth.se.  madhu@watson.ibm.com.  
Title: Linearity Testing in Characteristic Two  
Author: M. Bellare D. Coppersmith J. H -astad M. Kiwi M. Sudan k 
Keyword: Index Terms Probabilistically checkable proofs, approximation, program testing, Hadamard codes, error detection, linearity testing, MaxSNP.  
Note: Part of this work was done while the author was visiting MIT.  
Address: San Diego, 9500 Gilman Drive, La Jolla, California 92093.  P.O. Box 218, Yorktown Heights, NY 10598, USA.  10044 Stockholm, Sweden.  P.O. Box 218, Yorktown Heights, NY 10598, USA.  
Affiliation: Department of Computer Science Engineering, Mail Code 0114, University of California at  Research Division, IBM T.J. Watson Research Center,  Department of Computer Science, Royal Institute of Technology,  k Research Division, IBM T.J. Watson Research Center,  
Abstract: Let Dist(f; g) = Pr u [ f(u) 6= g(u) ] denote the relative distance between functions f; g mapping from a group G to a group H, and let Dist(f) denote the minimum, over all linear functions (homomorphisms) g, of Dist(f; g). Given a function f : G ! H we let Err(f) = Pr u;v [ f(u) + f(v) 6= f(u + v) ] denote the rejection probability of the BLR (Blum-Luby-Rubinfeld) linearity test. Linearity testing is the study of the relationship between Err(f) and Dist(f), and in particular the study of lower bounds on Err(f) in terms of Dist(f). The case we are interested in is when the underlying groups are G = GF(2) n and H = GF(2). In this case the collection of linear functions describe a Hadamard code of block length 2 n and for an arbitrary function f mapping GF(2) n to GF(2) the distance Dist(f ) measures its distance to a Hadamard code (normalized so as to be a real number between 0 and 1). The quantity Err(f ) is a parameter that is "easy to measure" and linearity testing studies the relationship of this parameter to the distance of f. The code and corresponding test are used in the construction of efficient probabilistically checkable proofs and thence in the derivation of hardness of approximation results. In this context, improved analyses translate into better non-approximability results. However, while several analyses of the relation of Err(f ) to Dist(f) are known, none is tight. We present a description of the relationship between Err(f ) and Dist(f) which is nearly complete in all its aspects, and entirely complete (i.e. tight) in some. In particular we present functions L; U : [0; 1] ! [0; 1] such that for all x 2 [0; 1] we have L(x) Err(f ) U (x) whenever Dist(f ) = x, with the upper bound being tight on the whole range, and the lower bound tight on a large part of the range and close on the rest. Part of our strengthening is obtained by showing a new connection between the linearity testing problem and Fourier analysis, a connection which may be of independent interest. Our results are used by Bellare, Goldreich and Sudan to present the best known hardness results for Max-3SAT and other MaxSNP problems [7]. fl A preliminary version of this paper appeared in Proceedings of the 36th Symposium on Foundations of Computer Science, IEEE, 1995. - Depto. de Ingeniera Matematica, Fac. de Cs. Fsicas y Matematicas, U. de Chile. mkiwi@dim.uchile.cl. This work was done while the author was at the Dept. of Applied Mathematics, Massachusetts Institute of Technology. Supported by AT&T Bell Laboratories PhD Scholarship, NSF Grant CCR-9503322, FONDECYT grant No. 1960849, and Fundacion Andes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon and J. H. Spencer. </author> <title> The probabilistic method. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1992. </year>
Reference-contexts: In particular, one would like to derive good lower bounds on Err (f ) as a function of x. Rej (). A convenient way to capture the above issues is via the rejection probability function Rej G;H : <ref> [0; 1] </ref> ! [0; 1] of the test. It associates to any number x the minimum value of Err (f ), taken over all functions f of distance x from the space of linear functions. <p> In particular, one would like to derive good lower bounds on Err (f ) as a function of x. Rej (). A convenient way to capture the above issues is via the rejection probability function Rej G;H : <ref> [0; 1] </ref> ! [0; 1] of the test. It associates to any number x the minimum value of Err (f ), taken over all functions f of distance x from the space of linear functions. Thus, Rej G;H (x) = minf Err (f ) : f : G ! H s.t. <p> A simple algebraic manipulation concludes the proof. Tightness Discussion. We now discuss how tight the results of this section are. Throughout the rest of this discussion let x 2 <ref> [0; 1] </ref> be such that x jF j n is an integer. Case 1: x &gt; 1 2 . <p> Randomly choose f so f (u) = X u , where X u is a random variable distributed according to a Bernoulli distribution with parameter p 2 <ref> [ 1 2 ; 1] </ref>. 7 A Chernoff bound (see [1, Appendix A]) shows that with overwhelming probability 0 x Dist (f ) = o (1). <p> Randomly choose f so f (u) = X u , where X u is a random variable distributed according to a Bernoulli distribution with parameter p 2 [ 1 2 ; 1]. 7 A Chernoff bound (see <ref> [1, Appendix A] </ref>) shows that with overwhelming probability 0 x Dist (f ) = o (1). Moreover, Chebyschev's inequality (see [1, Ch. 4]) implies that with high probability jErr (f ) (3 p (1 p) 2 + p 3 ) j = o (1). <p> Moreover, Chebyschev's inequality (see <ref> [1, Ch. 4] </ref>) implies that with high probability jErr (f ) (3 p (1 p) 2 + p 3 ) j = o (1). Thus, if p = 1 2 , Theorem 1.2 is almost tight in the sense that Rej (x) is almost x. <p> f (w + x); f (w + y); f (w + x + y)] : We partition the elements w of F n according to the values that the trace of f at w takes, H 0 = f w : tr f (w) equals [0; 0; 0; 0] or <ref> [1; 1; 1; 1] </ref> g H x = f w : tr f (w) equals [0; 0; 1; 1] or [1; 1; 0; 0] g H y = f w : tr f (w) equals [0; 1; 0; 1] or [1; 0; 1; 0] g H x+y = f w : <p> We partition the elements w of F n according to the values that the trace of f at w takes, H 0 = f w : tr f (w) equals [0; 0; 0; 0] or [1; 1; 1; 1] g H x = f w : tr f (w) equals <ref> [0; 0; 1; 1] </ref> or [1; 1; 0; 0] g H y = f w : tr f (w) equals [0; 1; 0; 1] or [1; 0; 1; 0] g H x+y = f w : tr f (w) equals [0; 1; 1; 0] or [1; 0; 0; 1] g H <p> of F n according to the values that the trace of f at w takes, H 0 = f w : tr f (w) equals [0; 0; 0; 0] or [1; 1; 1; 1] g H x = f w : tr f (w) equals [0; 0; 1; 1] or <ref> [1; 1; 0; 0] </ref> g H y = f w : tr f (w) equals [0; 1; 0; 1] or [1; 0; 1; 0] g H x+y = f w : tr f (w) equals [0; 1; 1; 0] or [1; 0; 0; 1] g H odd = f w : <p> H 0 = f w : tr f (w) equals [0; 0; 0; 0] or [1; 1; 1; 1] g H x = f w : tr f (w) equals [0; 0; 1; 1] or [1; 1; 0; 0] g H y = f w : tr f (w) equals <ref> [0; 1; 0; 1] </ref> or [1; 0; 1; 0] g H x+y = f w : tr f (w) equals [0; 1; 1; 0] or [1; 0; 0; 1] g H odd = f w : tr f (w) has an odd number of 1's g ; and define their relative <p> : tr f (w) equals [0; 0; 0; 0] or [1; 1; 1; 1] g H x = f w : tr f (w) equals [0; 0; 1; 1] or [1; 1; 0; 0] g H y = f w : tr f (w) equals [0; 1; 0; 1] or <ref> [1; 0; 1; 0] </ref> g H x+y = f w : tr f (w) equals [0; 1; 1; 0] or [1; 0; 0; 1] g H odd = f w : tr f (w) has an odd number of 1's g ; and define their relative measures h 0 = jH <p> H x = f w : tr f (w) equals [0; 0; 1; 1] or [1; 1; 0; 0] g H y = f w : tr f (w) equals [0; 1; 0; 1] or [1; 0; 1; 0] g H x+y = f w : tr f (w) equals <ref> [0; 1; 1; 0] </ref> or [1; 0; 0; 1] g H odd = f w : tr f (w) has an odd number of 1's g ; and define their relative measures h 0 = jH 0 j=jF j n , h x = jH x j=jF j n , h <p> : tr f (w) equals [0; 0; 1; 1] or [1; 1; 0; 0] g H y = f w : tr f (w) equals [0; 1; 0; 1] or [1; 0; 1; 0] g H x+y = f w : tr f (w) equals [0; 1; 1; 0] or <ref> [1; 0; 0; 1] </ref> g H odd = f w : tr f (w) has an odd number of 1's g ; and define their relative measures h 0 = jH 0 j=jF j n , h x = jH x j=jF j n , h y = jH y j=jF <p> Indeed, observe that if (s; t) is in B, then p s;t is at least 1 4 . (We calculate an example: suppose s and s + t are both in H x , with tr f (s) = <ref> [0; 0; 1; 1] </ref> and tr f (s + t) = [1; 1; 0; 0], while t is in H odd , with tr f (t) = [1; 1; 0; 1]. <p> Indeed, observe that if (s; t) is in B, then p s;t is at least 1 4 . (We calculate an example: suppose s and s + t are both in H x , with tr f (s) = [0; 0; 1; 1] and tr f (s + t) = <ref> [1; 1; 0; 0] </ref>, while t is in H odd , with tr f (t) = [1; 1; 0; 1]. <p> 4 . (We calculate an example: suppose s and s + t are both in H x , with tr f (s) = [0; 0; 1; 1] and tr f (s + t) = [1; 1; 0; 0], while t is in H odd , with tr f (t) = <ref> [1; 1; 0; 1] </ref>. <p> If f were linear on the cosets s + S; t + S; s + t + S, and tr f (s), tr f (s + t) were as given, then tr f (t) would necessarily be <ref> [1; 1; 0; 0] </ref>, and t would be in H x . The value tr f (t) differs from [1; 1; 0; 0] in the last position, corresponding to x + y. <p> cosets s + S; t + S; s + t + S, and tr f (s), tr f (s + t) were as given, then tr f (t) would necessarily be <ref> [1; 1; 0; 0] </ref>, and t would be in H x . The value tr f (t) differs from [1; 1; 0; 0] in the last position, corresponding to x + y. Thus whenever v = x + y we will have f (s + u) + f (t + v) 6= f (s + t + u + v).
Reference: [2] <author> S. Arora, C. Lund, R. Motwani, M. Sudan and M. Szegedy. </author> <title> Proof verification and intractability of approximation problems. </title> <booktitle> Proceedings of the 33rd Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: The threshold of x = 1 4 turns out to be significant in this example and an important parameter that emerges in the study of linearity testing is how low Rej G;H (x) can be for x 1 4 . In this paper we call this parameter, identified in <ref> [2, 6, 7, 8] </ref>, the knee of the curve. <p> Err (f ) = 2 This leads into our research. We note that the problem to which linearity testing is applied in the proof system constructions of <ref> [2, 6, 7, 8] </ref> is that of testing Hadamard codes (in the first three works) and the long code (in the last work). <p> A subsequent result, due to Arora, Lund, Motwani, Sudan and Szegedy <ref> [2] </ref> managed to use a similar idea to show that an analogous result holds for a large collection of problems called MaxSNP hard problems. <p> Usage of the linearity test in the construction of efficient PCPs, and thence in the derivation of hardness of approximability results for MaxSNP problems, begins in <ref> [2] </ref> and continues in [6, 8, 7]. In the first three cases, it is used to test the Hadamard code; in the last case, to test a different code called the long code. <p> Low individual degree tests were studied by [3, 5, 12, 19]. Total degree tests were studied by <ref> [2, 13, 14, 20] </ref>. What we are looking at, namely linearity testing over GF (2), is a variant of the total degree testing problem in which the degree is d = 1, F is set to GF (2), and the constant term of the polynomial p is forced to 0. <p> Hadamard code in <ref> [2] </ref>. The proof systems of [7] use all these different testers, but, as we explained, the final non-approximability factors obtained can be expressed only in terms of the shape of the linearity testing curve. Recent work. Kiwi [16] provides improved analysis for the linearity testing problem over all finite fields.
Reference: [3] <author> S. Arora and S. Safra. </author> <title> Probabilistic checking of proofs: a new characterization of NP. </title> <booktitle> Proceedings of the 33rd Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: In the low total degree testing problem we are asked to determine whether f is close to some polynomial p of total degree d in its n variables. 5 Multi-linearity tests were studied by [4, 11]. Low individual degree tests were studied by <ref> [3, 5, 12, 19] </ref>. Total degree tests were studied by [2, 13, 14, 20]. <p> In fact the tightness of the result obtained here raises the hope that similar techniques can be used to improve the analysis in the above testers. The role of testing in PCP systems. An important tool in the construction of proof systems is a tool referred to as recursion <ref> [3] </ref>. Roughly, the tool provides an analog of the process of construction of concatenated error-correcting codes, to the realm of PCPs. A PCP proof system constructed by recursion consists of several levels of different atomic PCPs.
Reference: [4] <author> L. Babai, L. Fortnow and C. Lund. </author> <title> Non-deterministic exponential time has two-prover interactive protocols. </title> <journal> Computational Complexity, </journal> <volume> Vol. 1, </volume> <pages> 3-40, </pages> <year> 1991. </year>
Reference-contexts: In the low total degree testing problem we are asked to determine whether f is close to some polynomial p of total degree d in its n variables. 5 Multi-linearity tests were studied by <ref> [4, 11] </ref>. Low individual degree tests were studied by [3, 5, 12, 19]. Total degree tests were studied by [2, 13, 14, 20]. <p> A PCP proof system constructed by recursion consists of several levels of different atomic PCPs. The PCP at each level of recursion typically uses some form of low-degree testing, the kind differing from level to level. The use of multi-linearity testing was initiated by Babai, Fortnow and Lund <ref> [4] </ref>. For efficiency reasons, researchers beginning with Babai, Fortnow, Levin and Szegedy [5] then turned to low individual degree testing. This testing is used in the "higher" levels of the recursion.
Reference: [5] <author> L. Babai, L. Fortnow, L. Levin and M. Szegedy. </author> <title> Checking computations in polyloga-rithmic time. </title> <booktitle> Proceedings of the 23rd Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: In the low total degree testing problem we are asked to determine whether f is close to some polynomial p of total degree d in its n variables. 5 Multi-linearity tests were studied by [4, 11]. Low individual degree tests were studied by <ref> [3, 5, 12, 19] </ref>. Total degree tests were studied by [2, 13, 14, 20]. <p> The PCP at each level of recursion typically uses some form of low-degree testing, the kind differing from level to level. The use of multi-linearity testing was initiated by Babai, Fortnow and Lund [4]. For efficiency reasons, researchers beginning with Babai, Fortnow, Levin and Szegedy <ref> [5] </ref> then turned to low individual degree testing. This testing is used in the "higher" levels of the recursion.
Reference: [6] <author> M. Bellare, S. Goldwasser, C. Lund and A. Russell. </author> <title> Efficient probabilistically checkable proofs and applications to approximation. </title> <booktitle> Proceedings of the 25th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1993. </year>
Reference-contexts: The threshold of x = 1 4 turns out to be significant in this example and an important parameter that emerges in the study of linearity testing is how low Rej G;H (x) can be for x 1 4 . In this paper we call this parameter, identified in <ref> [2, 6, 7, 8] </ref>, the knee of the curve. <p> Their analysis showed that Rej G;H (x) 2 9 x [9]. (They indicate that this is an improvement of their original analysis obtained jointly with Coppersmith.) Interest in the tightness of the analysis begins with Bellare, Goldwasser, Lund and Russell <ref> [6] </ref> in the context of improving the performance of PCP systems. They showed that Rej G;H (x) 3 x 6 x 2 . <p> This claim appears in Bellare and Sudan [8], without proof. A proof is included in the appendix of this paper, for the sake of completeness. Of the three bounds above, the last two bounds supercede the first, so that the following theorem captures the state of knowledge. Theorem 1.1 <ref> [6, 9, 10] </ref> Let G; H be arbitrary finite groups. Then: (1) Rej G;H (x) 3x 6x 2 . (2) Knee G;H 2 9 . As indicated above, an improved lower bound for the knee would lead to better PCP systems. <p> Err (f ) = 2 This leads into our research. We note that the problem to which linearity testing is applied in the proof system constructions of <ref> [2, 6, 7, 8] </ref> is that of testing Hadamard codes (in the first three works) and the long code (in the last work). <p> Furthermore the upper bound is tight. The second graph indicates lower bounds on Rej (x). The line 2 9 x represents the result of [9]. The parabola is the curve 3 x 6 x 2 representing the result of <ref> [6] </ref>. The curve 2 3 x when x 1 3 and 2 when x &gt; 1 3 represents the result of [8]. <p> A subsequent series of works, initiated by Bellare, Goldwasser, Lund and Russell <ref> [6] </ref>, have improved the above results by constructing more efficient PCP systems and thereby showing stronger hardness of approximation results for MaxSNP hard problems. <p> Usage of the linearity test in the construction of efficient PCPs, and thence in the derivation of hardness of approximability results for MaxSNP problems, begins in [2] and continues in <ref> [6, 8, 7] </ref>. In the first three cases, it is used to test the Hadamard code; in the last case, to test a different code called the long code. <p> In all cases the underlying problem is the one we have considered above, namely linearity testing with G = GF (2) n and H = GF (2). The MaxSNP hardness result of <ref> [6] </ref> used only two things: The lower bound Rej (x) 3 x 6 x 2 of Theorem 1.1, and the best available lower bound k on the knee. They were able to express the non-approximability factor for Max-3SAT as an increasing function g 1 (k) depending solely on k. <p> They used Knee 2 9 to show that approximating Max-3SAT within 74 73 1:014 is NP-hard. Theorem 1.3 would yield direct improvements to the results of <ref> [6, 8] </ref> with no change in the underlying proof systems or construction. However, better proof systems are now known, namely the long code based ones of [7]. The analysis in the latter uses both our results (namely Theorem 1.3 and Theorem 1.2). <p> They show that approximating Max-3SAT within 1:038 is NP-hard. They also exploit our analyses to derive strong non-approximability results for other MaxSNP problems (like Max-2SAT and Max-Cut) and for Vertex Cover. Thus, the applications of <ref> [6, 8] </ref> motivated our consideration of the linearity testing problem. In the process we proved more than these works needed. <p> This lemma is a slightly more refined version of the bound Rej (x) 3 x 6 x 2 derived in <ref> [6] </ref>.
Reference: [7] <author> M. Bellare, O. Goldreich and M. Sudan. </author> <title> Free bits and non-approximability. </title> <booktitle> Proceedings of the 36th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1995. </year>
Reference-contexts: The threshold of x = 1 4 turns out to be significant in this example and an important parameter that emerges in the study of linearity testing is how low Rej G;H (x) can be for x 1 4 . In this paper we call this parameter, identified in <ref> [2, 6, 7, 8] </ref>, the knee of the curve. <p> Err (f ) = 2 This leads into our research. We note that the problem to which linearity testing is applied in the proof system constructions of <ref> [2, 6, 7, 8] </ref> is that of testing Hadamard codes (in the first three works) and the long code (in the last work). <p> Usage of the linearity test in the construction of efficient PCPs, and thence in the derivation of hardness of approximability results for MaxSNP problems, begins in [2] and continues in <ref> [6, 8, 7] </ref>. In the first three cases, it is used to test the Hadamard code; in the last case, to test a different code called the long code. <p> Theorem 1.3 would yield direct improvements to the results of [6, 8] with no change in the underlying proof systems or construction. However, better proof systems are now known, namely the long code based ones of <ref> [7] </ref>. The analysis in the latter uses both our results (namely Theorem 1.3 and Theorem 1.2). They show that approximating Max-3SAT within 1:038 is NP-hard. They also exploit our analyses to derive strong non-approximability results for other MaxSNP problems (like Max-2SAT and Max-Cut) and for Vertex Cover. <p> They also exploit our analyses to derive strong non-approximability results for other MaxSNP problems (like Max-2SAT and Max-Cut) and for Vertex Cover. Thus, the applications of [6, 8] motivated our consideration of the linearity testing problem. In the process we proved more than these works needed. Interestingly, later <ref> [7] </ref> found our results useful in the same context. 1.6 Relationship to other work As mentioned earlier, there are a variety of problems which are studied under the label of testing. In particular, a variety of tasks address the issue of testing variants of Reed-Solomon codes. <p> Hadamard code in [2]. The proof systems of <ref> [7] </ref> use all these different testers, but, as we explained, the final non-approximability factors obtained can be expressed only in terms of the shape of the linearity testing curve. Recent work. Kiwi [16] provides improved analysis for the linearity testing problem over all finite fields. <p> H-astad [15] has shown a tester for a different code, namely the "long code" of <ref> [7] </ref>, and an analysis for the test is again based on a Fourier Transform based approach.
Reference: [8] <author> M. Bellare and M. Sudan. </author> <title> Improved non-approximability results. </title> <booktitle> Proceedings of the 26th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: The threshold of x = 1 4 turns out to be significant in this example and an important parameter that emerges in the study of linearity testing is how low Rej G;H (x) can be for x 1 4 . In this paper we call this parameter, identified in <ref> [2, 6, 7, 8] </ref>, the knee of the curve. <p> They showed that Rej G;H (x) 3 x 6 x 2 . It turns out that, with very little effort, the result of [9] can be used to show that Rej G;H (x) 2 9 for x 1 3 . This claim appears in Bellare and Sudan <ref> [8] </ref>, without proof. A proof is included in the appendix of this paper, for the sake of completeness. Of the three bounds above, the last two bounds supercede the first, so that the following theorem captures the state of knowledge. <p> Err (f ) = 2 This leads into our research. We note that the problem to which linearity testing is applied in the proof system constructions of <ref> [2, 6, 7, 8] </ref> is that of testing Hadamard codes (in the first three works) and the long code (in the last work). <p> The line 2 9 x represents the result of [9]. The parabola is the curve 3 x 6 x 2 representing the result of [6]. The curve 2 3 x when x 1 3 and 2 when x &gt; 1 3 represents the result of <ref> [8] </ref>. <p> Usage of the linearity test in the construction of efficient PCPs, and thence in the derivation of hardness of approximability results for MaxSNP problems, begins in [2] and continues in <ref> [6, 8, 7] </ref>. In the first three cases, it is used to test the Hadamard code; in the last case, to test a different code called the long code. <p> The lower bound on the knee that they used was Knee 1 6 derived from Part (1) of Theorem 1.1 and [9]. Their final result was that approximating Max-3SAT within 113 112 1:009 is NP-hard. Improved proof systems were built by <ref> [8] </ref>. Again, their non-approximability factor had the form g 2 (k) for some function g 2 depending only on the best available lower bound k on the knee. They used Knee 2 9 to show that approximating Max-3SAT within 74 73 1:014 is NP-hard. <p> They used Knee 2 9 to show that approximating Max-3SAT within 74 73 1:014 is NP-hard. Theorem 1.3 would yield direct improvements to the results of <ref> [6, 8] </ref> with no change in the underlying proof systems or construction. However, better proof systems are now known, namely the long code based ones of [7]. The analysis in the latter uses both our results (namely Theorem 1.3 and Theorem 1.2). <p> They show that approximating Max-3SAT within 1:038 is NP-hard. They also exploit our analyses to derive strong non-approximability results for other MaxSNP problems (like Max-2SAT and Max-Cut) and for Vertex Cover. Thus, the applications of <ref> [6, 8] </ref> motivated our consideration of the linearity testing problem. In the process we proved more than these works needed.
Reference: [9] <author> M. Blum, M. Luby and R. Rubinfeld. </author> <title> Self-testing/correcting with applications to numerical problems. </title> <journal> Journal of Computer and System Sciences Vol. </journal> <volume> 47, </volume> <pages> 549-595, </pages> <year> 1993. </year>
Reference-contexts: The BLR Test. Blum, Luby and Rubinfeld <ref> [9] </ref> suggest a probabilistic method to "test" if a function f is really a linear function. This test, henceforth referred to as the BLR test, is the following [9]| Given a function f : G ! H , pick u; v 2 G at random and reject if f (u) + <p> The BLR Test. Blum, Luby and Rubinfeld <ref> [9] </ref> suggest a probabilistic method to "test" if a function f is really a linear function. This test, henceforth referred to as the BLR test, is the following [9]| Given a function f : G ! H , pick u; v 2 G at random and reject if f (u) + f (v) 6= f (u + v). Let def u;v R G denote the probability that the BLR test rejects f . <p> This is the ingredient which makes this test useful in the applications to PCPs and motivates our study. 1.3 Previous work The first investigation of the shape of the linearity testing curve, by Blum, Luby and Rubinfeld <ref> [9] </ref>, was in the general context where G; H are arbitrary finite groups. Their analysis showed that Rej G;H (x) 2 9 x [9]. (They indicate that this is an improvement of their original analysis obtained jointly with Coppersmith.) Interest in the tightness of the analysis begins with Bellare, Goldwasser, Lund <p> the applications to PCPs and motivates our study. 1.3 Previous work The first investigation of the shape of the linearity testing curve, by Blum, Luby and Rubinfeld <ref> [9] </ref>, was in the general context where G; H are arbitrary finite groups. Their analysis showed that Rej G;H (x) 2 9 x [9]. (They indicate that this is an improvement of their original analysis obtained jointly with Coppersmith.) Interest in the tightness of the analysis begins with Bellare, Goldwasser, Lund and Russell [6] in the context of improving the performance of PCP systems. <p> They showed that Rej G;H (x) 3 x 6 x 2 . It turns out that, with very little effort, the result of <ref> [9] </ref> can be used to show that Rej G;H (x) 2 9 for x 1 3 . This claim appears in Bellare and Sudan [8], without proof. A proof is included in the appendix of this paper, for the sake of completeness. <p> This claim appears in Bellare and Sudan [8], without proof. A proof is included in the appendix of this paper, for the sake of completeness. Of the three bounds above, the last two bounds supercede the first, so that the following theorem captures the state of knowledge. Theorem 1.1 <ref> [6, 9, 10] </ref> Let G; H be arbitrary finite groups. Then: (1) Rej G;H (x) 3x 6x 2 . (2) Knee G;H 2 9 . As indicated above, an improved lower bound for the knee would lead to better PCP systems. <p> Furthermore the upper bound is tight. The second graph indicates lower bounds on Rej (x). The line 2 9 x represents the result of <ref> [9] </ref>. The parabola is the curve 3 x 6 x 2 representing the result of [6]. The curve 2 3 x when x 1 3 and 2 when x &gt; 1 3 represents the result of [8]. <p> They were able to express the non-approximability factor for Max-3SAT as an increasing function g 1 (k) depending solely on k. The lower bound on the knee that they used was Knee 1 6 derived from Part (1) of Theorem 1.1 and <ref> [9] </ref>. Their final result was that approximating Max-3SAT within 113 112 1:009 is NP-hard. Improved proof systems were built by [8]. Again, their non-approximability factor had the form g 2 (k) for some function g 2 depending only on the best available lower bound k on the knee. <p> The analysis once again provides significant improvements to non-approximability results for the clique problem. 1.7 Discussion The main argument behind the analysis of the BLR test given in <ref> [9] </ref> is the following: given f taking values from one finite group G into another finite group, start by defining a function g f whose value at u is Pluralityf f (u + v) f (v) : v 2 G g. 6 Then, show that if Err (f ) is sufficiently <p> This argument was first used in <ref> [9] </ref> while studying linearity testing over finite groups. We will show how this argument can be tightened in the case of linearity testing over GF (2).
Reference: [10] <author> D. Coppersmith. </author> <booktitle> Notes, </booktitle> <month> summer </month> <year> 1990. </year>
Reference-contexts: This claim appears in Bellare and Sudan [8], without proof. A proof is included in the appendix of this paper, for the sake of completeness. Of the three bounds above, the last two bounds supercede the first, so that the following theorem captures the state of knowledge. Theorem 1.1 <ref> [6, 9, 10] </ref> Let G; H be arbitrary finite groups. Then: (1) Rej G;H (x) 3x 6x 2 . (2) Knee G;H 2 9 . As indicated above, an improved lower bound for the knee would lead to better PCP systems. <p> Then: (1) Rej G;H (x) 3x 6x 2 . (2) Knee G;H 2 9 . As indicated above, an improved lower bound for the knee would lead to better PCP systems. But in this general setting, we can do no better. The following example of Coppersmith <ref> [10] </ref> shows that the above value is in fact tight in the case of general groups. Let m be divisible by three. Let f be a function from Z n m to Z m such that f (u) = 3k, if u 1 2 f3k 1; 3k; 3k + 1g.
Reference: [11] <author> U. Feige, S. Goldwasser, L. Lov asz, S. Safra and M. Szegedy. </author> <title> Approximating clique is almost NP-complete. </title> <booktitle> Proceedings of the 32nd Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: This surprising connection, initiated by Feige, Goldwasser, Lovasz, Safra and Szegedy <ref> [11] </ref>, showed how to turn the results on constructions of efficient PCP systems into results which showed that for certain combinatorial optimization problems finding an * approximate solution is also an NP-hard task. <p> In the low total degree testing problem we are asked to determine whether f is close to some polynomial p of total degree d in its n variables. 5 Multi-linearity tests were studied by <ref> [4, 11] </ref>. Low individual degree tests were studied by [3, 5, 12, 19]. Total degree tests were studied by [2, 13, 14, 20].
Reference: [12] <author> K. Friedl, Zs. H ats agi and A. Shen. </author> <title> Low-degree testing. </title> <booktitle> Proceedings of the 5th Annual Symposium on Discrete Algorithms, ACM-SIAM, </booktitle> <year> 1994. </year>
Reference-contexts: In the low total degree testing problem we are asked to determine whether f is close to some polynomial p of total degree d in its n variables. 5 Multi-linearity tests were studied by [4, 11]. Low individual degree tests were studied by <ref> [3, 5, 12, 19] </ref>. Total degree tests were studied by [2, 13, 14, 20].
Reference: [13] <author> K. Friedl and M. Sudan. </author> <title> Some Improvements to Total Degree Tests. </title> <booktitle> Proceedings of the Third Israel Symposium on Theory and Computing Systems, IEEE, </booktitle> <year> 1995. </year>
Reference-contexts: Low individual degree tests were studied by [3, 5, 12, 19]. Total degree tests were studied by <ref> [2, 13, 14, 20] </ref>. What we are looking at, namely linearity testing over GF (2), is a variant of the total degree testing problem in which the degree is d = 1, F is set to GF (2), and the constant term of the polynomial p is forced to 0.
Reference: [14] <author> P. Gemmell, R. Lipton, R. Rubinfeld, M. Sudan and A. Wigderson. </author> <title> Self-testing/correcting for polynomials and for approximate functions. </title> <booktitle> Proceedings of the 23rd Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: Low individual degree tests were studied by [3, 5, 12, 19]. Total degree tests were studied by <ref> [2, 13, 14, 20] </ref>. What we are looking at, namely linearity testing over GF (2), is a variant of the total degree testing problem in which the degree is d = 1, F is set to GF (2), and the constant term of the polynomial p is forced to 0. <p> Hence, Knee = 45 128 as we wanted to prove. The rest of this section is dedicated to proving Lemmas 4.1 through 4.3. The proofs of Lemmas 4.1 and 4.2 are based on an observation which is implicit in <ref> [14] </ref>. This observation crucially depends on the fact that f takes values over F = GF (2).
Reference: [15] <author> J. H -astad. </author> <title> Testing of the long code and hardness for clique. </title> <booktitle> To appear in Proceedings of the 28th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1996. </year>
Reference-contexts: He obtains this result by providing another new interpretation of the linearity testing problem, this time by relating it to a weight enumeration problem of a linear code studied as a function of the minimum distance of its dual code. H-astad <ref> [15] </ref> has shown a tester for a different code, namely the "long code" of [7], and an analysis for the test is again based on a Fourier Transform based approach.
Reference: [16] <author> M. Kiwi. </author> <title> Probabilistically checkable proofs and the testing of Hadamard-like codes. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: Hadamard code in [2]. The proof systems of [7] use all these different testers, but, as we explained, the final non-approximability factors obtained can be expressed only in terms of the shape of the linearity testing curve. Recent work. Kiwi <ref> [16] </ref> provides improved analysis for the linearity testing problem over all finite fields. <p> Our discrete Fourier analysis approach does not exhibit the properties discussed above, and this may be one of the reasons for its success. Our approach was somewhat inspired by the coding theoretic statement of the linearity testing problem; however the final analysis does not bring this out clearly. Kiwi's <ref> [16] </ref> approach brings the connection out much more explicitly and suggests that further exploration of the relationship to coding theory may prove fruitful. 2 Fourier Analysis of the Linearity Test In this section we prove Theorem 1.2 and discuss how tight it is. Conventions.
Reference: [17] <author> D. J. Kleitman. </author> <title> Private communication, </title> <month> October </month> <year> 1995. </year>
Reference-contexts: The following lemma, independently proved by D. J. Kleitman <ref> [17] </ref>, gives a precise statement of the above discussed fact.
Reference: [18] <author> F. J. MacWilliams and N. J. A. Sloane. </author> <title> The Theory of Error-Correcting Codes. </title> <publisher> North-Holland, </publisher> <year> 1977. </year>
Reference-contexts: Any two distinct codewords differ in exactly 2 n1 positions, making this a (2 n ; 2 n ; 2 n1 )-code. For further details see MacWilliams and Sloane <ref> [18, pages 48-49] </ref>. For an arbitrary function f , the parameter Dist (f ) simply measures its distance to the above mentioned Hadamard code, normalized by 2 n . Estimating Dist (f ) is thus related to the classical task of error-detection.
Reference: [19] <author> A. Polishchuk and D. Spielman. </author> <title> Nearly Linear Size Holographic Proofs. </title> <booktitle> Proceedings of the 26th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: In the low total degree testing problem we are asked to determine whether f is close to some polynomial p of total degree d in its n variables. 5 Multi-linearity tests were studied by [4, 11]. Low individual degree tests were studied by <ref> [3, 5, 12, 19] </ref>. Total degree tests were studied by [2, 13, 14, 20].
Reference: [20] <author> R. Rubinfeld and M. Sudan. </author> <title> Robust characterizations of polynomials and their applications to program testing. </title> <type> IBM Technical Report RC 19156, </type> <year> 1993. </year> <note> To appear in SIAM Journal on Computing. </note>
Reference-contexts: Low individual degree tests were studied by [3, 5, 12, 19]. Total degree tests were studied by <ref> [2, 13, 14, 20] </ref>. What we are looking at, namely linearity testing over GF (2), is a variant of the total degree testing problem in which the degree is d = 1, F is set to GF (2), and the constant term of the polynomial p is forced to 0.
References-found: 20

