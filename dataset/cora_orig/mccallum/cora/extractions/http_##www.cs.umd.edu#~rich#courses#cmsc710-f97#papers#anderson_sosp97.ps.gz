URL: http://www.cs.umd.edu/~rich/courses/cmsc710-f97/papers/anderson_sosp97.ps.gz
Refering-URL: http://www.cs.umd.edu/~rich/courses/cmsc710-f97/resources.html
Root-URL: 
Title: Continuous Profiling: Where Have All the Cycles Gone?  
Author: Jennifer M. Anderson Lance M. Berc Jeffrey Dean Sanjay Ghemawat Monika R. Henzinger Shun-Tak A. Leung Richard L. Sites Mark T. Vandevoorde Carl A. Waldspurger William E. Weihl 
Abstract: This paper describes the DIGITAL Continuous Profiling Infrastructure, a sampling-based profiling system designed to run continuously on production systems. The system supports multiprocessors, works on unmodified executables, and collects profiles for entire systems, including user programs, shared libraries, and the operating system kernel. Samples are collected at a high rate (over 5200 samples/sec per 333-MHz processor), yet with low overhead (13% slowdown for most workloads). Analysis tools supplied with the profiling system use the sample data to produce an accurate accounting, down to the level of pipeline stalls incurred by individual instructions, of where time is being spent. When instructions incur stalls, the tools identify possible reasons, such as cache misses, branch mispredictions, and functional unit contention. The fine-grained instruction-level analysis guides users and automated optimizers to the causes of performance problems and provides important insights for fixing them. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. E. Anderson and E. D. Lazowska. Quartz: </author> <title> A tool for tuning parallel program performance. </title> <booktitle> Proceedings of the ACM SIGMETRICS 1990 Conference on Measurement & Modeling of Computer Systems, </booktitle> <address> 18(1):115125, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: The first includes pixie [17], gprof [11], jprof [19], quartz <ref> [1] </ref>, MTOOL [10], SimOS [20], part of SGI's SpeedShop [25], and Intel's Vtune dynamic analyzer [24]. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention.
Reference: [2] <author> T. Ball and J. Larus. </author> <title> Optimally profiling and tracing programs. </title> <journal> ACM TOPLAS, </journal> <volume> 16(4):13191360, </volume> <month> July </month> <year> 1994. </year>
Reference-contexts: These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention. The slowdown is too large for continuous measurements during production use, despite techniques that reduce instrumentation overhead substantially <ref> [2] </ref>. In addition, only the simulation-based systems provide accurate information about the locations and causes of stalls. The systems in the second group use statistical sampling to collect fine-grained information on program or system behavior.
Reference: [3] <author> D. Blickstein et al. </author> <title> The GEM optimizing compiler system. </title> <journal> Digital Technical Journal, </journal> <volume> 4(4), </volume> <year> 1992. </year>
Reference-contexts: The profiling system is freely available on the Web [7]; it has been running on DIGITAL Alpha processors under DIGITAL Unix since September 1996, and ports are in progress to Alpha/NT and OpenVMS. Work is underway to feed the output of our tools into DIGITAL's optimizing backend <ref> [3] </ref> and into the Spike/OM post-linker optimization framework [5, 6]. We are also studying new kinds of profile-driven optimizations made possible by the fine-grained instruction-level profile information provided by our system. Section 2 discusses other profiling systems. Section 3 illustrates the use of our system.
Reference: [4] <author> D. Carta. </author> <title> Two fast implementations of the `minimal standard' random number generator. </title> <journal> CACM, </journal> <volume> 33(1):8788, </volume> <month> January </month> <year> 1990. </year>
Reference-contexts: To minimize any systematic correlation between the timing of the interrupts and the code being run, we randomize the length of the sampling period by writing a pseudo-random value <ref> [4] </ref> into the performance counter at the end of each interrupt. The default sampling period is distributed uniformly between 60K and 64K when monitoring CYCLES. 4.1.2 Attributing Events to PCs To accurately interpret samples, it is important to understand the PC delivered to the interrupt handler.
Reference: [5] <author> R. Cohn, D. Goodwin, P. G. Lowney, and N. Rubin. Spike: </author> <title> An optimizer for Alpha/NT executables. </title> <booktitle> In USENIX Windows NT Workshop, </booktitle> <address> Seattle, </address> <month> Aug </month> <year> 1997. </year>
Reference-contexts: Work is underway to feed the output of our tools into DIGITAL's optimizing backend [3] and into the Spike/OM post-linker optimization framework <ref> [5, 6] </ref>. We are also studying new kinds of profile-driven optimizations made possible by the fine-grained instruction-level profile information provided by our system. Section 2 discusses other profiling systems. Section 3 illustrates the use of our system.
Reference: [6] <author> R. Cohn and P. G. Lowney. </author> <title> Hot cold optimization of large Windows/NT applications. </title> <booktitle> In 29th Annual International Symposium on Microarchitecture (Micro-29), </booktitle> <address> Paris, France, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: Work is underway to feed the output of our tools into DIGITAL's optimizing backend [3] and into the Spike/OM post-linker optimization framework <ref> [5, 6] </ref>. We are also studying new kinds of profile-driven optimizations made possible by the fine-grained instruction-level profile information provided by our system. Section 2 discusses other profiling systems. Section 3 illustrates the use of our system.
Reference: [7] <institution> DIGITAL Continuous Profiling Infrastructure project. </institution> <note> http://www.research.digital.com/SRC/dcpi/. </note>
Reference-contexts: These insights have been used to improve the performance of several major commercial applications. The output of the analysis tools can be used directly by programmers; it can also be fed into compilers, linkers, post-linkers, and run-time optimization tools. The profiling system is freely available on the Web <ref> [7] </ref>; it has been running on DIGITAL Alpha processors under DIGITAL Unix since September 1996, and ports are in progress to Alpha/NT and OpenVMS. Work is underway to feed the output of our tools into DIGITAL's optimizing backend [3] and into the Spike/OM post-linker optimization framework [5, 6]. <p> The processor-pipeline model explains static stalls; dynamic stalls are explained using a guilty until proven innocent approach that reports each possible cause not eliminated through careful analysis. Our profiling system is freely available via the Web <ref> [7] </ref>. Dozens of users have already successfully used our system to optimize a wide range of production software, including databases, compilers, graphics accelerators, and operating systems.
Reference: [8] <author> Digital Equipment Corporation. </author> <title> Alpha 21164 Microprocessor Hardware Reference Manual. </title> <address> Maynard, MA, </address> <year> 1995. </year> <title> Order Number EC-QAEQB-TE. </title>
Reference-contexts: The rest of this section describes these pieces in more detail, beginning with the hardware performance counters. 4.1 Alpha Performance Counters Alpha processors <ref> [9, 8] </ref> provide a small set of hardware performance counters that can each be configured to count a specified event. The precise number of counters, set of supported events, and other interface details vary across Alpha processor implementations. <p> When a performance counter overflows, it generates a high-priority interrupt that delivers the PC of the next instruction to be executed <ref> [21, 8] </ref> and the identity of the overflowing counter. When the device driver handles this interrupt, it records the process identifier (PID) of the interrupted process, the PC delivered by the interrupt, and the event type that caused the interrupt.
Reference: [9] <author> Digital Equipment Corporation. </author> <title> DECchip 21064 and DECchip 21064A Alpha AXP Microprocessors Hardware Reference Manual. </title> <address> Maynard, MA, </address> <year> 1995. </year> <title> Order Number EC-Q9ZUA-TE. </title>
Reference-contexts: The rest of this section describes these pieces in more detail, beginning with the hardware performance counters. 4.1 Alpha Performance Counters Alpha processors <ref> [9, 8] </ref> provide a small set of hardware performance counters that can each be configured to count a specified event. The precise number of counters, set of supported events, and other interface details vary across Alpha processor implementations.
Reference: [10] <author> Aaron J. Goldberg and John L. Hennessy. </author> <title> MTOOL: An Integrated System for Performance Debugging Shared Memory Multiprocessor Applications. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <pages> pages 2840, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The first includes pixie [17], gprof [11], jprof [19], quartz [1], MTOOL <ref> [10] </ref>, SimOS [20], part of SGI's SpeedShop [25], and Intel's Vtune dynamic analyzer [24]. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention.
Reference: [11] <author> S. Graham, P. Kessler, and M. McKusick. </author> <title> gprof: A call graph execution profiler. </title> <journal> SIGPLAN Notices, </journal> <volume> 17(6):120126, </volume> <month> June </month> <year> 1982. </year>
Reference-contexts: The first includes pixie [17], gprof <ref> [11] </ref>, jprof [19], quartz [1], MTOOL [10], SimOS [20], part of SGI's SpeedShop [25], and Intel's Vtune dynamic analyzer [24]. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention.
Reference: [12] <author> M. Hall et al. </author> <title> Maximizing multiprocessor performance with the SUIF compiler. </title> <journal> IEEE Computer, </journal> <volume> 29(12):8489, </volume> <month> December </month> <year> 1996. </year>
Reference-contexts: The system was driven so as to maintain 8 outstanding queries. DSS 2786 35 300 MHz 8-CPU ALPHASERVER 8400 A decision-support system (DSS) query based upon the TPC-D specification [23]. parallel SPECfp 2777 168 300 MHz 4-CPU ALPHASERVER 4100 The SPECfp95 programs, parallelized by the Stanford SUIF com piler <ref> [12] </ref>. timesharing 7 days 300 MHz 4-CPU ALPHASERVER 4100 A timeshared server used for office and technical applications, running the default configuration of our system. We used this work load to gather statistics for a long-running profile session.
Reference: [13] <author> Iprobe. </author> <title> Digital internal tool. </title>
Reference-contexts: By using hardware performance counters and randomizing the interval between samples, we are able to sample activity within essen tially the entire system (except for our interrupt handler itself) and to avoid correlations with any other activity. Other systems that use performance counters, including iprobe <ref> [13] </ref>, the Vtune sampler [24], and part of SpeedShop, share some of the characteristics of our system. However, iprobe and Vtune cannot be used for continuous profiling, mostly because they need a lot of memory for sample data.
Reference: [14] <author> R. Johnson, D. Pearson, and K. Pingali. </author> <title> The program structure tree: Computing control regions in linear time. </title> <booktitle> In ACM PLDI, </booktitle> <pages> pages 171 185, </pages> <year> 1994. </year>
Reference-contexts: Otherwise, we use an extended version of the cycle equivalence algorithm in <ref> [14] </ref> to identify sets of blocks and edges that are guaranteed to be executed the same number of times. Each such set constitutes one equivalence class. Our extension to the algorithm is for handling CFG's with infinite loops, e.g., the idle loop of an operating system.
Reference: [15] <author> J. D. McCalpin. </author> <title> Memory bandwidth and machine balance in high performance computers. </title> <journal> IEEE Technical Committee on Computer Architecture Newsletter, </journal> <month> December </month> <year> 1995. </year> <note> http://www.cs.virginia.edu/stream. </note>
Reference-contexts: Figure 2 illustrates the output of dcpicalc for the key basic block in a McCalpin-like copy benchmark <ref> [15] </ref>, running on an AlphaStation 500 5/333. <p> The tests chosen are representative of CPU-bound tests [16]. McCalpin N/A 333 MHz ALPHASTATION 500 The McCalpin STREAMS benchmark, consisting of four loops that measure memory-system bandwidth <ref> [15] </ref>. Multiprocessor workloads AltaVista 319 2 300 MHz 4-CPU ALPHASERVER 4100 A trace of 28622 queries made to the 3.5 GB AltaVista news index. The system was driven so as to maintain 8 outstanding queries.
Reference: [16] <author> J. McCormack, P. Karlton, S. Angebranndt, and C. Kent. x11perf. </author> <note> http://www.specbench.org/gpc/xpc.static/index.html. </note>
Reference-contexts: The tests chosen are representative of CPU-bound tests <ref> [16] </ref>. McCalpin N/A 333 MHz ALPHASTATION 500 The McCalpin STREAMS benchmark, consisting of four loops that measure memory-system bandwidth [15]. Multiprocessor workloads AltaVista 319 2 300 MHz 4-CPU ALPHASERVER 4100 A trace of 28622 queries made to the 3.5 GB AltaVista news index.
Reference: [17] <institution> MIPS Computer Systems. UMIPS-V Reference Manual (pixie and pixstats). </institution> <address> Sunnyvale, CA, </address> <year> 1990. </year> <title> [18] prof. Digital Unix man page. </title>
Reference-contexts: The first includes pixie <ref> [17] </ref>, gprof [11], jprof [19], quartz [1], MTOOL [10], SimOS [20], part of SGI's SpeedShop [25], and Intel's Vtune dynamic analyzer [24]. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention.
Reference: [19] <author> J. F. Reiser and J. P. Skudlarek. </author> <title> Program profiling problems, and a solution via machine language rewriting. </title> <journal> SIGPLAN Notices, </journal> <volume> 29(1):37 45, </volume> <month> January </month> <year> 1994. </year>
Reference-contexts: The first includes pixie [17], gprof [11], jprof <ref> [19] </ref>, quartz [1], MTOOL [10], SimOS [20], part of SGI's SpeedShop [25], and Intel's Vtune dynamic analyzer [24]. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention.
Reference: [20] <author> M. Rosenblum, S. Herrod, E. Witchel, and A. Gupta. </author> <title> Complete computer simulation: The SimOS approach. </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <month> Fall </month> <year> 1995. </year>
Reference-contexts: The first includes pixie [17], gprof [11], jprof [19], quartz [1], MTOOL [10], SimOS <ref> [20] </ref>, part of SGI's SpeedShop [25], and Intel's Vtune dynamic analyzer [24]. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention.
Reference: [21] <author> R. Sites and R. Witek. </author> <title> Alpha AXP Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <address> Newton, MA, </address> <year> 1995. </year>
Reference-contexts: When a performance counter overflows, it generates a high-priority interrupt that delivers the PC of the next instruction to be executed <ref> [21, 8] </ref> and the identity of the overflowing counter. When the device driver handles this interrupt, it records the process identifier (PID) of the interrupted process, the PC delivered by the interrupt, and the event type that caused the interrupt. <p> In general, samples for events other than CYCLES and IMISS are helpful in tracking down performance problems, but less useful for detailed analysis. 4.1.3 Blind Spots: Deferred Interrupts Performance-counter interrupts execute at the highest kernel priority level (spldevrt), but are deferred while running non-interruptible PALcode <ref> [21] </ref> or system code at the highest priority level. 2 Events in PALcode and high-priority interrupt code are still counted, but samples for those events will be associated with the instruction that runs after the PALcode finishes or the interrupt level drops below spldevrt. <p> Therefore these accesses do not generate any more cache misses. 4.2.3 Reducing Synchronization Synchronization is eliminated between interrupt handlers on different processors in a multiprocessor, and minimized between the handlers and other driver routines. Synchronization operations (in particular, memory barriers <ref> [21] </ref>) are expensive, costing on the order of 100 cycles, so even a small number of them in the interrupt handler would result in unacceptable overhead.
Reference: [22] <institution> The Standard Performance Evaluation Corporation. </institution> <note> http://www.specbench.org/osg/spec95. </note>
Reference-contexts: The notification Workload Mean base Platform Description runtime (secs) Uniprocessor workloads SPECint95 13226 258 333 MHz ALPHASTATION 500 The SPEC benchmark suite compiled using both the BASE and SPECfp95 17238 106 333 MHz ALPHASTATION 500 PEAK compilation flags and run with the runspec driver <ref> [22] </ref>. x11perf N/A 333 MHz ALPHASTATION 500 Several tests from the x11perf X server performance testing program. The tests chosen are representative of CPU-bound tests [16]. McCalpin N/A 333 MHz ALPHASTATION 500 The McCalpin STREAMS benchmark, consisting of four loops that measure memory-system bandwidth [15].
Reference: [23] <institution> Transaction Processing Performance Council. </institution> <note> http://www.tpc.org/bench.descrip.html. </note>
Reference-contexts: The system was driven so as to maintain 8 outstanding queries. DSS 2786 35 300 MHz 8-CPU ALPHASERVER 8400 A decision-support system (DSS) query based upon the TPC-D specification <ref> [23] </ref>. parallel SPECfp 2777 168 300 MHz 4-CPU ALPHASERVER 4100 The SPECfp95 programs, parallelized by the Stanford SUIF com piler [12]. timesharing 7 days 300 MHz 4-CPU ALPHASERVER 4100 A timeshared server used for office and technical applications, running the default configuration of our system.
Reference: [24] <author> Vtune: </author> <title> Intel's visual tuning environment. </title> <address> http://developer.intel.com/design/perftool/vtune. </address>
Reference-contexts: The first includes pixie [17], gprof [11], jprof [19], quartz [1], MTOOL [10], SimOS [20], part of SGI's SpeedShop [25], and Intel's Vtune dynamic analyzer <ref> [24] </ref>. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention. The slowdown is too large for continuous measurements during production use, despite techniques that reduce instrumentation overhead substantially [2]. <p> By using hardware performance counters and randomizing the interval between samples, we are able to sample activity within essen tially the entire system (except for our interrupt handler itself) and to avoid correlations with any other activity. Other systems that use performance counters, including iprobe [13], the Vtune sampler <ref> [24] </ref>, and part of SpeedShop, share some of the characteristics of our system. However, iprobe and Vtune cannot be used for continuous profiling, mostly because they need a lot of memory for sample data.
Reference: [25] <author> M. Zagha et al. </author> <title> Performance analysis using the MIPS R10000 performance counters. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: The first includes pixie [17], gprof [11], jprof [19], quartz [1], MTOOL [10], SimOS [20], part of SGI's SpeedShop <ref> [25] </ref>, and Intel's Vtune dynamic analyzer [24]. These systems use binary modification, compiler support, or direct simulation of programs to gather measurements. They all have high overhead and usually require significant user intervention. <p> Since only a limited number of events can be monitored simultaneously (2 on the 21064 and 3 on the 21164), our system also supports time-multiplexing among different events at a very fine grain. (SGI's Speedshop <ref> [25] </ref> provides a similar multiplexing capability.) 4.1.1 Sampling Period Performance counters can be configured to overflow at different values; legal settings vary on different Alpha processors. When monitoring CYCLES on the Alpha 21064, interrupts can be generated every 64K events or every 4K events.
Reference: [26] <author> X. Zhang et al. </author> <title> Operating system support for automated profiling & optimization. </title> <booktitle> In Proceedings of the 16th ACM Symposium on Operating Systems Principles, </booktitle> <address> St. Malo, France, </address> <month> Oct </month> <year> 1997. </year>
Reference-contexts: Finally, Section 7 discusses future work and Section 8 summarizes our results. 2 Related Work Few other profiling systems can monitor complete system activity with high-frequency sampling and low overhead; only ours and Morph <ref> [26] </ref> are designed to run continuously for long periods on production systems, something that is essential for obtaining useful profiles of large complex applications such as databases. <p> In addition, only the simulation-based systems provide accurate information about the locations and causes of stalls. The systems in the second group use statistical sampling to collect fine-grained information on program or system behavior. Some sampling systems, including Morph <ref> [26] </ref>, prof [18], and part of SpeedShop, rely on an existing source of interrupts (e.g., timer interrupts) to generate program-counter samples. This prevents them from sampling within those interrupt routines, and can also result in correlations between the sampling and other system activity.
References-found: 25

