URL: http://www.isi.edu/isd/rickel/aaij98.ps
Refering-URL: http://www.isi.edu/isd/rickel/index.html
Root-URL: http://www.isi.edu
Email: rickel@isi.edu, johnson@isi.edu  
Title: Animated Agents for Procedural Training in Virtual Reality: Perception, Cognition, and Motor Control  
Author: Jeff Rickel and W. Lewis Johnson 
Date: May 4, 1998  
Web: http://www.isi.edu/isd/VET/vet.html  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292-6695  
Affiliation: Information Sciences Institute Computer Science Department University of Southern California  
Note: To appear in Applied Artificial Intelligence  
Abstract: This paper describes Steve, an animated agent that helps students learn to perform physical, procedural tasks. The student and Steve cohabit a three-dimensional, simulated mock-up of the student's work environment. Steve can demonstrate how to perform tasks and can also monitor students while they practice tasks, providing assistance when needed. This paper describes Steve's architecture in detail, including perception, cognition, and motor control. The perception module monitors the state of the virtual world, maintains a coherent representation of it, and provides this information to the cognition and motor control modules. The cognition module interprets its perceptual input, chooses appropriate goals, constructs and executes plans to achieve those goals, and sends out motor commands. The motor control module implements these motor commands, controlling Steve's voice, locomotion, gaze, and gestures, and allowing Steve to manipulate objects in the virtual world.
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. F.; Miller, B. W.; Ringger, E. K.; and Sikorski, T. </author> <year> 1996. </year> <title> Robust understanding in a dialogue system. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 62-70. </pages>
Reference: <author> Anderson, J. R.; Corbett, A. T.; Koedinger, K. R.; and Pelletier, R. </author> <year> 1995. </year> <title> Cognitive tutors: Lessons learned. </title> <journal> Journal of the Learning Sciences 4(2) </journal> <pages> 167-207. </pages>
Reference-contexts: Some, notably those of Anderson and his colleagues <ref> (Anderson et al. 1995) </ref>, use detailed cognitive models built from production rules. Such systems perform domain tasks by directly executing the rules. Other systems use a declarative representation of the knowledge, usually some variant of a procedural network representation (Sacerdoti 1977) specifying the steps in the procedure and their ordering.
Reference: <author> Andre, E., and Rist, T. </author> <year> 1996. </year> <title> Coping with temporal constraints in multimedia presentation planning. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <pages> 142-147. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference: <author> Andre, E.; Rist, T.; and Mueller, J. </author> <year> 1998. </year> <title> Employing AI methods to control the behavior of animated interface agents. </title> <journal> Applied Artificial Intelligence. </journal> <note> This issue. </note>
Reference: <author> Badler, N. I.; Phillips, C. B.; and Webber, B. L. </author> <year> 1993. </year> <title> Simulating Humans. </title> <address> New York: </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: We have experimented with several bodies for Steve. At the simple end of the spectrum, we tried a hand alone and then a hand and head. At the complex end, we tried a full human figure, using the Jack software <ref> (Badler, Phillips, & Webber 1993) </ref> developed at the University of Pennsylvania. In the long run, Jack is an exciting prospect. However, our use of Jack was limited, since Jack comes with its own visual interface, and cannot run in others. <p> Another agent, Presenter Jack (Noma & Badler 1997), is a full human figure that uses speech, gestures, and short-range locomotion to give presentations. The human figure animation is provided by the Jack software <ref> (Badler, Phillips, & Webber 1993) </ref>. Unlike Steve, the presentations are not interactive; they are scripted by a human. The work is notable for its use of a full human figure and its analysis of how gestures and gaze are used in presentations.
Reference: <author> Billinghurst, M., and Savage, J. </author> <year> 1996. </year> <title> Adding intelligence to the interface. </title> <booktitle> In Proceedings of the IEEE Virtual Reality Annual International Symposium (VRAIS '96), </booktitle> <pages> 168-175. </pages> <address> Los Alamitos, CA: </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Billinghurst, M.; Savage, J.; Oppenheimer, P.; and Edmond, C. </author> <year> 1996. </year> <title> The expert surgical assistant: An intelligent virtual environment with multimodal input. </title> <booktitle> In Proceedings of Medicine Meets Virtual Reality IV. </booktitle>
Reference: <author> Burton, R. R. </author> <year> 1982. </year> <title> Diagnosing bugs in a simple procedural skill. </title> <editor> In Sleeman, D., and Brown, J., eds., </editor> <booktitle> Intelligent Tutoring Systems. </booktitle> <address> Cambridge, MA: </address> <publisher> Academic Press. </publisher> <pages> 157-183. </pages>
Reference: <author> Cassell, J., and Thorisson, K. R. </author> <year> 1998. </year> <title> The power of a nod and a glance: Envelope vs. emotion in animated conversational agents. </title> <journal> Applied Artificial Intelligence. </journal> <note> This issue. </note>
Reference: <author> Cassell, J.; Pelachaud, C.; Badler, N.; Steedman, M.; Achorn, B.; Becket, T.; Douville, B.; Prevost, S.; and Stone, M. </author> <year> 1994. </year> <title> Animated conversation: Rule-based generation of facial expression, gesture and spoken intonation for multiple conversational agents. </title> <booktitle> In Proceedings of ACM SIGGRAPH '94. </booktitle>
Reference: <author> Cormen, T. H.; Leiserson, C. E.; and Rivest, R. L. </author> <year> 1989. </year> <title> Introduction to Algorithms. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: An edge between two objects in the graph indicates that Steve can move from one to the other without colliding with other objects (e.g., a wall). Given Steve's current location (one object) and his specified destination (another object), the motor control module uses Dijkstra's shortest path algorithm <ref> (Cormen, Leiserson, & Rivest 1989) </ref> to compute a path. Next, the motor control module moves Steve along this path, one leg at a time. For each leg of the path (i.e., movement from one object to the next), it does the following: 1.
Reference: <author> Douville, B.; Levison, L.; and Badler, N. I. </author> <year> 1996. </year> <title> Task-level object grasping for simulated agents. Presence 5(4) </title> <type> 416-430. </type> <note> 33 Ferguson, </note> <author> G.; Allen, J.; and Miller, B. </author> <year> 1996. </year> <title> Trains-95: Towards a mixed-initiative planning assistant. </title> <booktitle> In Proceedings of the Third Conference on AI Planning Systems. </booktitle>
Reference: <author> Geib, C.; Levison, L.; and Moore, M. B. </author> <year> 1994. </year> <title> Sodajack: An architecture for agents that search and manipulate objects. </title> <type> Technical Report MS-CIS-94-16/LINC LAB 265, </type> <institution> Department of Computer and Information Science, University of Pennsylvania. </institution>
Reference: <author> Grosz, B. J., and Sidner, C. L. </author> <year> 1986. </year> <title> Attention, intentions, and the structure of discourse. </title> <booktitle> Computational Liguistics 12(3) </booktitle> <pages> 175-204. </pages>
Reference: <author> Johnson, W. L.; Rickel, J.; Stiles, R.; and Munro, A. </author> <year> 1998. </year> <title> Integrating pedagogical agents into virtual environments. Presence. </title> <publisher> Forthcoming. </publisher>
Reference-contexts: First, Section 2 illustrates Steve's capabilities via an example of Steve and a student working together on a task. Next, as background, Section 3 briefly describes the larger software architecture for virtual worlds of which Steve is a part; more detail is available in an earlier paper <ref> (Johnson et al. 1998) </ref>. Finally, Section 4 gives an overview of Steve's architecture, and the remainder of the paper provides the details. 2 Steve's Capabilities To illustrate Steve's capabilities, suppose Steve is demonstrating how to inspect a high-pressure air compressor aboard a ship. <p> With our colleagues from Lockheed Martin Corporation and the USC Behavioral Technologies Laboratory, we have designed and implemented such an architecture <ref> (Johnson et al. 1998) </ref>. For purposes of modularity and efficiency, the architecture consists of separate components running in parallel as separate processes, possibly on different machines. The components communicate by exchanging messages.
Reference: <author> Johnson, W. L.; Marsella, S.; and Rickel, J. </author> <year> 1998. </year> <title> Pedagogical agents in virtual team training. </title> <booktitle> In Proceedings of the Virtual Worlds and Simulation Conference, volume 30 of Simulation Series. </booktitle> <address> San Diego, CA: </address> <booktitle> Society for Computer Simulation International. </booktitle>
Reference-contexts: First, Section 2 illustrates Steve's capabilities via an example of Steve and a student working together on a task. Next, as background, Section 3 briefly describes the larger software architecture for virtual worlds of which Steve is a part; more detail is available in an earlier paper <ref> (Johnson et al. 1998) </ref>. Finally, Section 4 gives an overview of Steve's architecture, and the remainder of the paper provides the details. 2 Steve's Capabilities To illustrate Steve's capabilities, suppose Steve is demonstrating how to inspect a high-pressure air compressor aboard a ship. <p> With our colleagues from Lockheed Martin Corporation and the USC Behavioral Technologies Laboratory, we have designed and implemented such an architecture <ref> (Johnson et al. 1998) </ref>. For purposes of modularity and efficiency, the architecture consists of separate components running in parallel as separate processes, possibly on different machines. The components communicate by exchanging messages.
Reference: <author> Johnson, W. L. </author> <year> 1994. </year> <title> Agents that learn to explain themselves. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> 1257-1263. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: To answer such questions, Steve cannot rely on his current plan, since the task is already complete and the step in question is no longer relevant. To support such questions, Steve employs the episodic memory capability of the Debrief system <ref> (Johnson 1994) </ref>. Debrief includes a set of production rules that enable Soar agents to remember their actions and the situations in which they occurred. It uses Soar's chunking capability (Laird, Newell, & Rosenbloom 1987) to represent and recall situations efficiently.
Reference: <author> Korth, H. F., and Silberschatz, A. </author> <year> 1986. </year> <title> Database System Concepts. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: If the perception module were to update the simulation snapshot after each message, the cognition module might ask for a snapshot before both messages have been received and processed, and hence it could receive an inconsistent state of the world. This situation is analogous to a database transaction <ref> (Korth & Silberschatz 1986) </ref>; either the cognition module should see the effects of all the simultaneous changes, or it should not see the effects of any of them. To avoid this possibility, the simulator must use start and end messages to delimit messages representing simultaneous changes.
Reference: <author> Labrou, Y., and Finin, T. </author> <year> 1994. </year> <title> A semantics approach for KQML a general purpose communication language for software agents. </title> <booktitle> In Proceedings of the Third International Conference on Information and Knowledge Management. </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: Currently, these messages do not include a semantic token, like their corresponding messages representing human speech. Instead, agents send separate messages representing the semantic content of their speech; these messages are loosely based on speech acts, much like KQML <ref> (Labrou & Finin 1994) </ref>. 13 6 Cognition 6.1 The Layers of Steve's Cognition The cognition module is organized into three main layers: * Domain-specific task knowledge * Domain-independent pedagogical capabilities * Soar Steve is built on top of the Soar architecture (Laird, Newell, & Rosenbloom 1987; Newell 1990).
Reference: <author> Laird, J. E.; Newell, A.; and Rosenbloom, P. S. </author> <year> 1987. </year> <title> Soar: An architecture for general intelligence. </title> <booktitle> Artificial Intelligence 33(1) </booktitle> <pages> 1-64. </pages>
Reference-contexts: To support such questions, Steve employs the episodic memory capability of the Debrief system (Johnson 1994). Debrief includes a set of production rules that enable Soar agents to remember their actions and the situations in which they occurred. It uses Soar's chunking capability <ref> (Laird, Newell, & Rosenbloom 1987) </ref> to represent and recall situations efficiently. When the student asks why Steve performed an action, Steve triggers the Debrief productions to recall the situation in which the action was performed (i.e., Steve's perception snapshot and mental state).
Reference: <author> Lester, J. C.; Voerman, J. L.; Towns, S. G.; and Callaway, C. B. </author> <year> 1998. </year> <title> Deictic believability: Coordinating gesture, locomotion, and speech in lifelike pedagogical agents. </title> <journal> Applied Artificial Intelligence. </journal> <note> This issue. </note>
Reference-contexts: Lester and his colleagues are developing two animated pedagogical agents, Herman the Bug (Stone & Lester 1996) and Cosmo <ref> (Lester et al. 1998) </ref>. These agents do not inhabit three-dimensional virtual worlds; they appear as two-dimensional characters floating on top of a two-dimensional image of a simulated world.
Reference: <author> McAllester, D., and Rosenblitt, D. </author> <year> 1991. </year> <title> Systematic nonlinear planning. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> 634-639. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Finally, the role of the steps in the task is represented by a set of causal links <ref> (McAllester & Rosenblitt 1991) </ref>. Each causal link specifies that one step achieves a goal that is a precondition for another step (or for termination of the task).
Reference: <author> Moore, J. D. </author> <year> 1993. </year> <booktitle> What makes human explanations effective? In Proceedings of the 15th Annual Conference of the Cognitive Science Society, </booktitle> <pages> 131-136. </pages>
Reference: <author> Munro, A., and Surmon, D. </author> <year> 1997. </year> <title> Primitive simulation-centered tutor services. </title> <booktitle> In Proceedings of the AI-ED Workshop on Architectures for Intelligent Simulation-Based Learning Environments. </booktitle>
Reference-contexts: The components communicate by exchanging messages. Our current architecture includes the following types of components: Simulator The behavior of the virtual world is controlled by a simulator. Our current implementation uses the VIVIDS simulation engine <ref> (Munro & Surmon 1997) </ref>, developed at the USC Behavioral Technologies Laboratory. 2 Visual Interface Each human participant has a visual interface component that allows them to view and manipulate the virtual world.
Reference: <author> Munro, A.; Johnson, M.; Surmon, D.; and Wogulis, J. </author> <year> 1993. </year> <title> Attribute-centered simulation authoring for instruction. </title> <booktitle> In Proceedings of the World Conference on Artificial Intelligence in Education (AI-ED '93), </booktitle> <pages> 82-89. </pages> <booktitle> Association for the Advancement of Computing in Education. </booktitle>
Reference: <author> Newell, A. </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <address> Cambridge, MA: </address> <publisher> Harvard University Press. </publisher>
Reference: <author> Noma, T., and Badler, N. I. </author> <year> 1997. </year> <title> A virtual human presenter. </title> <booktitle> In Proceedings of the IJCAI Workshop on Animated Interface Agents: Making Them Intelligent, </booktitle> <pages> 45-51. </pages> <note> 34 Rickel, J. </note> <year> 1988. </year> <title> An intelligent tutoring framework for task-oriented domains. </title> <booktitle> In Proceedings of the International Conference on Intelligent Tutoring Systems. </booktitle>
Reference-contexts: The agent cannot interact with a simulation, and it has no pedagogical capabilities except the ability to describe a procedure. However, it is notable for its ability to plan and schedule a sequence of presentation acts (e.g., speech and gestures). Another agent, Presenter Jack <ref> (Noma & Badler 1997) </ref>, is a full human figure that uses speech, gestures, and short-range locomotion to give presentations. The human figure animation is provided by the Jack software (Badler, Phillips, & Webber 1993). Unlike Steve, the presentations are not interactive; they are scripted by a human.
Reference: <author> Russell, S., and Norvig, P. </author> <year> 1995. </year> <title> Artificial Intelligence: A Modern Approach. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: For these reasons, Steve uses a procedural network (plan) representation of domain tasks. Steve represents domain tasks as hierarchical plans, using a relatively standard representation <ref> (Russell & Norvig 1995) </ref>. First, each task consists of a set of steps, each of which is either a primitive action (e.g., press a button) or a composite action (i.e., itself a task). Composite actions give tasks a hierarchical structure. <p> The goal is satisfied when that attribute-value pair is part of Steve's current perceptual snapshot. For the latter, the attribute is one that will appear in Steve's mental state. Such attributes are stored as the result of certain primitive actions that Steve executes, namely sensing actions <ref> (Russell & Norvig 1995) </ref>. Sensing actions are used to record the state of some attribute of the virtual world at a particular point during a task. <p> To handle dynamic environments containing people and other agents, Steve must be able to adapt procedures to unexpected events. This argues against a rote execution of domain procedures, in favor of a general planning and replanning capability. Thus, we might encode domain actions as STRIPS operators <ref> (Russell & Norvig 1995) </ref> and use a standard partial-order planner (Weld 1994) to construct plans. However, we also want Steve to follow standard procedures whenever possible. Thus, we would have to augment the partial-order planner with substantial control knowledge to discourage unusual plans.
Reference: <author> Sacerdoti, E. </author> <year> 1977. </year> <title> A Structure for Plans and Behavior. </title> <address> New York: </address> <publisher> Elsevier North-Holland. </publisher>
Reference-contexts: Some, notably those of Anderson and his colleagues (Anderson et al. 1995), use detailed cognitive models built from production rules. Such systems perform domain tasks by directly executing the rules. Other systems use a declarative representation of the knowledge, usually some variant of a procedural network representation <ref> (Sacerdoti 1977) </ref> specifying the steps in the procedure and their ordering. Such systems perform tasks by using a domain-independent interpreter to "execute" the procedural network (i.e., walk through the steps). Production rule models provide a more flexible ontology at a price: they are laborious to build. <p> The central purpose of Steve's task knowledge is to allow him to create a task model when he is required to demonstrate a task or monitor the student performing the task. He creates the task model by simple top-down task decomposition <ref> (Sacerdoti 1977) </ref>. First, he initializes the task model to contain the name of the task. Next, he adds the task representation (steps, ordering constraints, and causal links) for that task.
Reference: <author> Schank, R., and Abelson, R. </author> <year> 1977. </year> <title> Scripts, Plans, Goals and Understanding. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Unlike Steve, their agent is also capable of natural language understanding and gesture recognition. Their agent represents domain tasks as hierarchical scripts <ref> (Schank & Abelson 1977) </ref>, which are similar to Steve's hierarchical plans.
Reference: <author> Stiles, R.; McCarthy, L.; and Pontecorvo, M. </author> <year> 1995. </year> <title> Training studio: A virtual environment for training. </title> <booktitle> In Workshop on Simulation and Interaction in Virtual Environments (SIVE-95). </booktitle> <address> Iowa City, IW: </address> <publisher> ACM Press. </publisher>
Reference-contexts: Our current implementation uses Lockheed Martin's Vista Viewer <ref> (Stiles, McCarthy, & Pontecorvo 1995) </ref> as the visual interface component. Audio Each human participant has an audio component. This component receives messages from the simulator describing the location and audible radius of various sounds, and it broadcasts appropriate sounds to the headphones on the person's head-mounted display.
Reference: <author> Stone, B. A., and Lester, J. C. </author> <year> 1996. </year> <title> Dynamically sequencing an animated pedagogical agent. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <pages> 424-431. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: Lester and his colleagues are developing two animated pedagogical agents, Herman the Bug <ref> (Stone & Lester 1996) </ref> and Cosmo (Lester et al. 1998). These agents do not inhabit three-dimensional virtual worlds; they appear as two-dimensional characters floating on top of a two-dimensional image of a simulated world.
Reference: <author> Thorisson, K. R. </author> <year> 1996. </year> <title> Communicative Humanoids: A Computational Model of Psychoso-cial Dialogue Skills. </title> <type> Ph.D. Dissertation, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference: <author> Trias, T. S.; Chopra, S.; Reich, B. D.; Moore, M. B.; Badler, N. I.; Webber, B. L.; and Geib, C. W. </author> <year> 1996. </year> <title> Decision networks for integrating the behaviors of virtual agents and avatars. </title> <booktitle> In Proceedings of the IEEE Virtual Reality Annual International Symposium (VRAIS '96), </booktitle> <pages> 156-162. </pages> <address> Los Alamitos, CA: </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: <author> Weld, D. S. </author> <year> 1994. </year> <title> An introduction to least commitment planning. </title> <journal> AI Magazine 15(4) </journal> <pages> 27-61. </pages>
Reference-contexts: This argues against a rote execution of domain procedures, in favor of a general planning and replanning capability. Thus, we might encode domain actions as STRIPS operators (Russell & Norvig 1995) and use a standard partial-order planner <ref> (Weld 1994) </ref> to construct plans. However, we also want Steve to follow standard procedures whenever possible. Thus, we would have to augment the partial-order planner with substantial control knowledge to discourage unusual plans.
References-found: 35

