URL: http://www.isi.edu/soar/hill/papers/IAAI.ps
Refering-URL: http://www.isi.edu/soar/hill/publications.html
Root-URL: http://www.isi.edu
Email: tambe-@isi.edu  
Title: Intelligent Agents for the Synthetic Battlefield: A Company of Rotary Wing Aircraft  
Author: Randall W. Hill, Jr., Johnny Chen, Jonathan Gratch, Paul Rosenbloom, Milind Tambe -hill, chen, gratch, rosenbloom, 
Keyword: Task Description Background  
Address: 4676 Admiralty Way Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: 1 We have constructed a team of intelligent agents that perform the tasks of an attack helicopter company for a synthetic battlefield environment used for running large-scale military exercises. We have used the Soar integrated architecture to develop: (1) pilot agents for a company of helicopters, (2) a command agent that makes decisions and plans for the helicopter company, and (3) an approach to teamwork that enables the pilot agents to coordinate their activities in accomplishing the goals of the company. This case study describes the task domain and architecture of our application, as well as the benefits and lessons learned from applying AI technology to this domain. Since 1983 the Defense Advanced Research Projects Agency (DARPA) has exerted a significant effort to develop a realistic, distributed, synthetic battlefield that could be used for training, mission planning and rehearsal, tactics and doctrine development, and weaponsystem concept evaluation. The underlying distributed interactive simulation (DIS) technology builds large-scale simulations from a set of independent simulators linked together in a network (DIS Steering Committee 1994). It is envisioned that a synthetic battlefield will make it cheaper and safer to conduct large scale military exercises than would be possible with live field units. One of the goals of DARPAs Synthetic Theater of War 97 (STOW-97) project is to field several thousand entities during one exercise, using a DIS environment called ModSAF (Modular Semi-Automated Forces)(Calder et al., 1993). Simulation in DIS is high-fidelity: actions in ModSAF are represented and resolved at the level of individual combatants and vehicles, which we hereafter refer to as entities. The synthetic environment includes terrain, 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ambros-Ingerson, J.A. and S. Steel, </author> <year> 1988. </year> <title> Integrating Planning, Execution, and Monitoring. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <year> 1988, </year> <pages> pp. 83-88. </pages>
Reference: <author> Calder, R.B., J.E. Smith, A.J. Courtemanche, </author> <month> J.M.F. </month>
Reference: <author> Mar, A.Z. Ceranowicz, </author> <year> 1993. </year> <title> ModSAF Behavior Simulation and Control. </title> <booktitle> In Proceedings of the Second Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <address> STRICOM-DMSO, </address> <month> July, </month> <year> 1993, </year> <pages> pp. 347-356. </pages>
Reference: <author> Cohen, P. R. and Levesque, H. J., </author> <year> 1991. </year> <title> Confirmation and Joint Action. </title> <booktitle> In Proceedings of International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: In our work, we have integrated a set of teamwork capabilities within Soar; the combined system is called STEAM (Tambe, 1996a; Tambe, 1997). STEAM is founded on the joint intentions theory <ref> (Cohen and Levesque, 1991) </ref>. It enables explicit representation of team goals that expand out into goals and plans for individuals' roles in the team goal.
Reference: <author> DeJong, G, and Mooney, R, </author> <year> 1986. </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning 1, </journal> <volume> 2, </volume> <year> 1986, </year> <pages> pp. 145-176. </pages> <institution> DIS Steering Committee. </institution> <year> 1994. </year> <title> The DIS Vision: A Map to the Future of Distributed Simulations. </title> <type> Technical Report, </type> <institution> IST-SP-94-01, Institute for Simulation and Training, University of Central Florida. </institution>
Reference: <author> Erol, K., Hendler, J., and Nau, D.S.., </author> <year> 1994. </year> <title> HTN Planning: complexity and expressivity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <year> 1994, </year> <pages> pp. 1123-1128. </pages>
Reference: <author> Fikes, R. E., and Nilsson, N. J., </author> <year> 1971. </year> <title> STRIPS: a new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 2 (3/4), </volume> <year> 1971. </year>
Reference-contexts: In the command agent, plans are represented by a graph structure known as a hierarchical task network (HTN). Nodes in the network correspond to tasks, and are represented as STRIPS-style action descriptions <ref> (Fikes, 1971) </ref>. Tasks may be abstract or primitive. Abstract tasks may be decomposed into a partially ordered set of more specific tasks. Primitive tasks are those that may be directly executed without further decomposition. Tasks in the network are connected by a variety of relations between them.
Reference: <author> Firby, J., </author> <year> 1987. </year> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of National Conference. on Artificial Intelligence. </booktitle>
Reference-contexts: Second, given domain specificity, reusability suffers coordination has to be redesigned for each new domain. A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar (Tambe et. al, 1995), RAP <ref> (Firby, 1987) </ref>, IRMA (Pollack, 1992), BB1 (Hayes-Roth et. al, 1995), and PRS (Rao et. al, 1993) facilitate an individual agent's flexible behaviors via mechanisms such as commitments and reactive plans. However, flexible individual behaviors, even if simultaneous and coordinated, do not sum up to teamwork.
Reference: <author> Gratch, J.A., </author> <year> 1996. </year> <title> Task-decomposition planning for command decision making. </title> <booktitle> In Proceedings of the Sixth Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <address> STRICOM-DMSO, </address> <month> July, </month> <year> 1996, </year> <pages> pp. 37-45. </pages>
Reference-contexts: At USC-ISI we shifted our focus to the helicopter domain, while also adding new techniques to facilitate teamwork (Tambe, 1996a) and command-level decision making <ref> (Gratch, 1996) </ref>. Here we describe how these new approaches help address the challenge of 2 We wish to acknowledge the UM team for their role with USC-ISI in developing the FWA agent architecture: Karen Coulter, Randy Jones, Frank Koss, John Laird, and Paul Nielsen. constructing intelligent synthetic forces.
Reference: <author> Grosz, B., </author> <year> 1996. </year> <journal> Collaborating systems. AI Magazine, </journal> <volume> vol. </volume> <pages> 17. </pages>
Reference: <author> Hartzog, S. M., Salisbury, </author> <title> M.R., 1996. Command Forces (CFOR) Program Status Report. </title> <booktitle> In Proceedings of the Sixth Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <address> Orlando, Florida, </address> <month> July, </month> <year> 1996. </year>
Reference-contexts: The agents control their aircraft, manipulate simulated lasers and weapons, sense the terrain, and communicate by radio via the SMI. Besides using ModSAF radios to communicate, the Soar helicopter pilot agents and the company commander agent also communicate via the Command and Control Communications Interface Language (CCSIL), <ref> (Hartzog and Salisbury, 1996) </ref>, a structured language that enables the agents to send standard military messages (e.g., operations orders or situation reports) to one another.
Reference: <author> Hayes, P. J., </author> <year> 1975. </year> <title> A representation for robot plans. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> 181-188, </pages> <year> 1975. </year>
Reference: <author> Hayes-Roth, B., Brownston, L. and Gen, R.V., </author> <year> 1995. </year> <title> Multiagent collaboration in directed improvisation. </title> <booktitle> In Proceedings of International Conference on Multi-Agent Systems. </booktitle>
Reference: <author> Jennings, N., </author> <year> 1995. </year> <title> Controlling cooperative problem solving in industrial multi-agent systems using joint intentions. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 75, </volume> <pages> pp. 195-240. </pages>
Reference-contexts: Unfortunately, implemented multi-agent systems often rely on preplanned, domain-specific coordination that fails to provide such flexibility <ref> (Jennings, 1995) </ref>. First, it is difficult to anticipate and preplan for all possible coordination failures, given the complexity of the domain. Second, given domain specificity, reusability suffers coordination has to be redesigned for each new domain. A fundamental reason for these teamwork limitations is the current agent architectures.
Reference: <author> Jones, R.M., Laird, J.E., and Nielsen, P.E., </author> <year> 1996. </year> <title> Moving intelligent automated forces into theater-level scenarios. </title> <booktitle> In Proceedings of the Sixth Conference on Computer Ge nerate d Force s a nd Beha viora l Representation, </booktitle> <address> STRICOM-DMSO, </address> <month> July, </month> <year> 1996, </year> <pages> pp. 113-117. </pages>
Reference: <author> Kambhampati, S., </author> <year> 1992. </year> <journal> A validationstructure-based theory of plan modification and reuse . Artificial Intelligence Journal 55: </journal> <pages> 193-258. </pages>
Reference: <author> Laird, J.E., Johnson, W.L., Jones, R.M., Koss, F., Lehman, J.F., Nielsen, P.E., Rosenbloom, P.S., Rubinoff, R., Schwamb, K., Tambe, M., Van Dyke, J., van Lent, M., Wray, R.E., III, </author> <year> 1995. </year> <title> "Simulated Intelligent Forces for Air: </title> <booktitle> The Soar/IFOR Project 1995," Proceedings of the Fifth Conference on Computer Generated Forces and Behavioral Representation, STRICOM-DMSO, </booktitle> <pages> pp. 27-36. </pages>
Reference: <author> Laird, J.E. and Rosenbloom, P.S., </author> <year> 1990. </year> <title> Integrating execution, planning, and learning in Soar for external environments. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <address> Menlo Park, California: </address> <publisher> The AAAI Press, </publisher> <month> July, </month> <year> 1990. </year>
Reference: <author> Mitchell, T. M., Keller R. M., and Kedar-Cabelli, </author> <title> S. </title>
Reference: <author> T., </author> <year> 1986. </year> <title> Explanation-based generalization: A unifying View. </title> <booktitle> Machine Learning 1 (1): </booktitle> <year> 1986, </year> <pages> pp. 47-80. </pages>
Reference: <author> Newell, A., </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference: <author> Pearson, D.J., Huffman, S.B., Willis, M.B., Laird, J.E., and Jones, R.M., </author> <year> 1993. </year> <title> A symbolic solution to intelligent real-time control. </title> <journal> IEEE Robotics and Autonomous Systems, </journal> <volume> 11 </volume> <pages> 279-291. </pages>
Reference: <author> Penberthy, J., Weld, D., </author> <year> 1992. </year> <title> UCPOP: A sound, complete, partial order planner for ADL. </title> <booktitle> In Proceedings of the 3rd International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> 103-114. </pages>
Reference: <author> Pollack, M., </author> <year> 1992. </year> <journal> The uses of plans . Artificial Intelligence Journal, </journal> <volume> volume 57. </volume>
Reference-contexts: Second, given domain specificity, reusability suffers coordination has to be redesigned for each new domain. A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar (Tambe et. al, 1995), RAP (Firby, 1987), IRMA <ref> (Pollack, 1992) </ref>, BB1 (Hayes-Roth et. al, 1995), and PRS (Rao et. al, 1993) facilitate an individual agent's flexible behaviors via mechanisms such as commitments and reactive plans. However, flexible individual behaviors, even if simultaneous and coordinated, do not sum up to teamwork.
Reference: <author> Rao, A. S., Lucas, A., Morley, D. Selvestrel, M. and Murray, G., </author> <year> 1993. </year> <title> Agent-oriented architecture for air-combat simulation. </title> <type> Technical Report 42, </type> <institution> Australian AI Institute. </institution>
Reference-contexts: Second, given domain specificity, reusability suffers coordination has to be redesigned for each new domain. A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar (Tambe et. al, 1995), RAP (Firby, 1987), IRMA (Pollack, 1992), BB1 (Hayes-Roth et. al, 1995), and PRS <ref> (Rao et. al, 1993) </ref> facilitate an individual agent's flexible behaviors via mechanisms such as commitments and reactive plans. However, flexible individual behaviors, even if simultaneous and coordinated, do not sum up to teamwork.
Reference: <author> Rosenbloom, P.S., Laird, J.E., Newell, A., (Eds.) </author> <year> 1993. </year> <title> The Soar Papers: </title> <booktitle> Research on Integrated Intelligence. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <editor> Salisbury, M.R., Booker, L.B., Seidel, D.W., Dahmann, J.S., </editor> <booktitle> 1995. Implementation of command forces (CFOR) simulation. In Proceedings of the Fifth Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <pages> 423-430, </pages> <address> Orlando, Florida, </address> <month> May, </month> <year> 1995. </year>
Reference-contexts: CCSIL messages are delivered using the Command Forces (CFOR) Infrastructure software <ref> (Salisbury, 1995) </ref>, which uses remote procedure calls to enable agents outside of ModSAF to communicate with agents in ModSAF vehicles.
Reference: <author> Tambe, M., Johnson, W.L., Jones, R.M., Koss, F., Laird, J.E., Rosenbloom, P.S., and Schwamb, K., </author> <year> 1995. </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine, </journal> <volume> 16(1) </volume> <pages> 15-39, </pages> <address> Spring, 1995, </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Second, given domain specificity, reusability suffers coordination has to be redesigned for each new domain. A fundamental reason for these teamwork limitations is the current agent architectures. Architectures such as Soar <ref> (Tambe et. al, 1995) </ref>, RAP (Firby, 1987), IRMA (Pollack, 1992), BB1 (Hayes-Roth et. al, 1995), and PRS (Rao et. al, 1993) facilitate an individual agent's flexible behaviors via mechanisms such as commitments and reactive plans. However, flexible individual behaviors, even if simultaneous and coordinated, do not sum up to teamwork. <p> Development Effort Required The original Soar/IFOR project focused on the FWA domain, and there is an ongoing development effort to continue this effort <ref> (e.g., see Tambe et al., 1995 and Jones et al., 1996) </ref>. We began working on the Soar/IFOR AHC application in July, 1994. We were able to build on top of a considerable amount of the original Soar/IFOR FWA infrastructure code, which included the interface between Soar and ModSAF.
Reference: <author> Tambe, M., </author> <year> 1996a. </year> <title> Teamwork in real-world, dynamic environments. </title> <booktitle> In Proceedings of the International Conference on Multi-Agent Systems. </booktitle>
Reference-contexts: At USC-ISI we shifted our focus to the helicopter domain, while also adding new techniques to facilitate teamwork <ref> (Tambe, 1996a) </ref> and command-level decision making (Gratch, 1996).
Reference: <author> Tambe, M., </author> <year> 1996b. </year> <title> Tracking dynamic team activity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Tambe, M., </author> <year> 1997. </year> <title> Agent architectures for flexible, practical teamwork. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: STEAM has been reapplied in the context of Marine transport helicopter simulation, where a team of escorts and transports transport synthetic troops from sea to land. STEAM is also in the process of being applied in the RoboCup soccer simulation. Evaluations of STEAM's flexibility and reusability are presented in <ref> (Tambe, 1997) </ref>. Planning The demands of command-level decision making require a greater focus on deliberation than required by pilot agents. The commander must be proactive rather than reactive, anticipating the possible outcomes of future actions as well as potential interactions that might arise between actions.
Reference: <author> Tate, A., </author> <year> 1990. </year> <title> Generating project networks. </title> <editor> In Allen, J.; Hendler, J; and Tate, A., editors, </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Morgan Kaufman. </publisher> <pages> 162-170. </pages>
Reference-contexts: The greater focus on deliberation has led us to draw substantially from the classical planning literature in the course of command entity development. The command entity incorporates a hybrid of planning styles, incorporating hierarchical task-decomposition techniques <ref> (as in Tate, 1990) </ref> as well as partial-order planning approaches (as in Penberthy and Weld, 1992; Gratch, 1996). In this respect it closely resembles the IPEM planning architecture of Ambros-Ingerson and Steel (1988), with some significant enhancements.
References-found: 32

