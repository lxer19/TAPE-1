URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1997/umsi-97-142.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1997/
Root-URL: http://www.cs.umn.edu
Title: Preconditioning the Matrix Exponential Operator with Applications  
Author: Paul Castillo and Yousef Saad 
Keyword: exponential operator, preconditioner, generalized Runge Kutta methods  
Date: November 24, 1997  
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science and Engineering, University of Minnesota,  
Abstract: The idea of preconditioning is usually associated with solution techniques for solving linear systems or eigenvalue problems. It refers to a general method by which the original system is transformed into one which admits the same solution but which is easier to solve. Following this principle we consider in this paper techniques for preconditioning the matrix exponential operator, e A y 0 , using different approximations of the matrix A. These techniques are based on using generalized Runge Kutta type methods. Preconditioners based on the sparsity structure of the matrix, such as diagonal, block diagonal, and least-squares tensor sum approximations are presented. Numerical experiments are reported to compare the quality of the schemes introduced. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Castillo and Y. Saad, </author> <title> Tensor sum approximation preconditioners, </title> <booktitle> Proc. Eighth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> Minneapolis, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: tensor products, A = L y I + I L x where L x and L y are discretizations of the original operator in the x and y directions respectively, We have recently proposed a preconditioner for linear systems whose matrix can be approximated by a sum of tensor products, <ref> [1] </ref>. This approximation is attractive mainly for two reasons. First, the tensor sum approximation captures the sparsity pattern of the discretization matrix, better than the block diagonal approximation. <p> The diagonal preconditioner we have used consists of the main diagonal and the block diagonal consists of a tridiagonal matrix formed by the diagonals of offsets -1,0 and 1. We have integrated the differential system on the interval <ref> [0; 1] </ref>, using several number of uniform steps, 10; 50; 100; 250; 500; 750; 1000; 1250; 1500; 2000; 4000; 8000; 16000: The code was run until the norm of the difference between the computed solution at time t = 1 and the "true" solution was less than a tolerance TOL, usually
Reference: [2] <author> P. Chartier and B. Philippe, </author> <title> Solution of Markov processes by waveform relaxation methods, </title> <type> Tech. Report, </type> <institution> IRISA, University of Rennes, France, </institution> <year> 1997, </year> <note> In preparation. </note>
Reference-contexts: In order to exploit preconditioning operations we will be particularly interested in methods which can take advantage of operations of the form exp (M )x or of the form (M )x with (z) = (exp (z) 1)=z, see <ref> [2] </ref>. 2 2 Algorithms Integration schemes based on an arbitrary approximation of matrix A will now be presented. The `preconditioning' matrix B will denote any approximation of A, and E = A B (5) the error of the approximation. We consider two approaches.
Reference: [3] <author> B.L. Ehle and J.D. Lawson, </author> <title> Generalized Runge-Kutta processes for stiff initial-value problems. </title> <journal> J. Inst. Maths. Applics. </journal> <volume> 16 1975, </volume> <pages> pp. 11-21. </pages>
Reference-contexts: an error of order O (h 3 kE 2 k) + O (h 4 kEk). 5 2.2 Runge Kutta methods It is possible to develop generalized Runge Kutta type schemes by applying Runge Kutta methods to a modified system as was first suggested by Lawson in a series of paper <ref> [3, 10, 11, 12, 13] </ref>. Consider the change of variable, z (t) = e (tt 0 )B y (t); (12) in the interval [t 0 ; t 1 ].
Reference: [4] <author> R. A. Friesner, L. S. Tuckerman, B. C. Dornblaser, and T. V. Russo, </author> <title> A method for exponential propagation of large systems of stiff nonlinear differential equations. </title> <journal> J. Sci. Comput., </journal> <volume> 4, </volume> <year> 1989, </year> <pages> pp. 327-354. </pages>
Reference-contexts: Krylov subspace fl This work was supported by NSF under grant CCR-9618827 and by the Minnesota Supercomputer Institute. 1 algorithms of this type have been considered in recent years, see <ref> [4, 5, 7, 8, 9, 14, 16] </ref>. <p> h) = e (t+h)B y 0 0 ! Z t+h e (s (t+h))B Ey (s)ds Z h e (sh)B Ey (t + s)ds In order to avoid the computation of the exponential term e hB y (t), of the previous expression, at each integration step, we can proceed as in <ref> [4] </ref> to further simplify the last equation by using the identity e hB = I B 0 Hence, the following general expression is obtained y (t + h) = y (t) 0 where v (s) = Ey (t + s) + By (t) = E (y (t + s) y (t))
Reference: [5] <author> E. Gallopoulos and Y. Saad, </author> <title> Efficient solution of parabolic equations by Krylov approximation methods. </title> <journal> SIAM J. Sci Stat. Comput. </journal> <volume> Vol 13, No. 5, </volume> <year> 1992, </year> <pages> pp. 1236-1264. </pages>
Reference-contexts: Krylov subspace fl This work was supported by NSF under grant CCR-9618827 and by the Minnesota Supercomputer Institute. 1 algorithms of this type have been considered in recent years, see <ref> [4, 5, 7, 8, 9, 14, 16] </ref>. <p> Again, we assume that v (s) is constant in the interval [0; h] and equal to the new value of v ( 1 2 h) = Ey (t + h Define the operator h (A) = 0 which has been used in Krylov subspace methods to approximate the exponential operator, <ref> [5, 7, 8, 16] </ref>. <p> With such techniques, the computations of the exponentiations is reduced to two block-exponential calculations for both algorithms. Further, an interesting observation can be made. In <ref> [5] </ref>, subspaces Krylov subspaces used for a certain vector were effectively used to compute matrix-exponentials with other vectors.
Reference: [6] <author> E. Hairer, S. P. Norsett and G. Wanner, </author> <title> Solving Ordinary Differential Equations I. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, 2nd edition, </address> <year> 1993. </year>
Reference-contexts: 1 = y 0 3. q = e hB EY 1 5. y 1 = w + h Only two matrix exponential evaluations per time step are required by the algorithm. 6 2.2.2 Runge Kutta 3 The Heun algorithm is a well known Runge Kutta type method of order 3, <ref> [6] </ref>. It is derived from the two point Radau quadrature formula, t 1 Z f (t)dt = 4 f (t 0 ) + 3f t 0 + 3 One step of the Heun scheme in the z variable is as follows, [6]: 8 &gt; &gt; &gt; &gt; : Z 2 = <p> well known Runge Kutta type method of order 3, <ref> [6] </ref>. It is derived from the two point Radau quadrature formula, t 1 Z f (t)dt = 4 f (t 0 ) + 3f t 0 + 3 One step of the Heun scheme in the z variable is as follows, [6]: 8 &gt; &gt; &gt; &gt; : Z 2 = z 0 + 1 Z 3 = z 0 + 2 3 h; Z 2 ) z 1 = z 0 + 1 3 h; Z 3 ) The corresponding algorithm translated into the y variable reads 8 &gt; &gt; &gt; <p> 3 h; Z 2 ) z 1 = z 0 + h 3 h; Z 3 ) It can easily bee seen that this Runge Kutta algorithm is of order three by showing that the coefficients of its Butcher tableau satisfy the order conditions of theorem 2.1 pp. 145, in <ref> [6] </ref> The Butcher tableau of a general three stage Runge Kutta method is of the form c 1 a 11 a 12 a 13 c 3 a 31 a 32 a 33 The corresponding Butcher tableau of the above modified Heun scheme is 0 0 0 0 2=3 1=3 1=3 0 <p> The corresponding Butcher tableau of the above modified Heun scheme is 0 0 0 0 2=3 1=3 1=3 0 Simple calculations show that these coefficients satisfy P b j = 1 j;k 2 j;k;l 3 j;k;l 6 which are the conditions required for the scheme to be of order three <ref> [6] </ref>. <p> In order to compare the accuracy of the solution given by our algorithms, we have used the routine DOPRI5 <ref> [6] </ref> to generate the "true" solution. The error norm is the norm of the difference between the computed solution and the solution given by the DOPRI5 routine.
Reference: [7] <author> M. Hochbruck and C. Lubich, </author> <title> On Krylov subspace approximations to the matrix exponential operator. </title> <note> To appear in SIAM J. Numer. Anal. </note>
Reference-contexts: Krylov subspace fl This work was supported by NSF under grant CCR-9618827 and by the Minnesota Supercomputer Institute. 1 algorithms of this type have been considered in recent years, see <ref> [4, 5, 7, 8, 9, 14, 16] </ref>. <p> Again, we assume that v (s) is constant in the interval [0; h] and equal to the new value of v ( 1 2 h) = Ey (t + h Define the operator h (A) = 0 which has been used in Krylov subspace methods to approximate the exponential operator, <ref> [5, 7, 8, 16] </ref>.
Reference: [8] <author> M. Hochbruck, C. Lubich and H. Selhofer, </author> <title> Exponential integrators for large systems of differential equations. </title> <note> To appear in SIAM J. Sci. Comp. </note>
Reference-contexts: Krylov subspace fl This work was supported by NSF under grant CCR-9618827 and by the Minnesota Supercomputer Institute. 1 algorithms of this type have been considered in recent years, see <ref> [4, 5, 7, 8, 9, 14, 16] </ref>. <p> Again, we assume that v (s) is constant in the interval [0; h] and equal to the new value of v ( 1 2 h) = Ey (t + h Define the operator h (A) = 0 which has been used in Krylov subspace methods to approximate the exponential operator, <ref> [5, 7, 8, 16] </ref>.
Reference: [9] <author> L.A. Knizhnerman, </author> <title> Computations of functions of unsymmetric matrices by means of Arnoldi's method. </title> <journal> J. Comput. Math. and Math. Phys. </journal> <volume> Vol 31, No. 1, </volume> <year> 1991, </year> <pages> pp. 5-16. </pages>
Reference-contexts: Krylov subspace fl This work was supported by NSF under grant CCR-9618827 and by the Minnesota Supercomputer Institute. 1 algorithms of this type have been considered in recent years, see <ref> [4, 5, 7, 8, 9, 14, 16] </ref>.
Reference: [10] <author> J.D. Lawson, </author> <title> Generalized Runge-Kutta processes for stable systems with large Lipschitz constants. </title> <journal> SIAM J. Numer. Anal. </journal> <volume> Vol 4, No 3, </volume> <year> 1967, </year> <pages> pp. 372-380. </pages>
Reference-contexts: We consider two approaches. The first approach consists of writing the ODE system (2) as a new linear ODE system and solving this new system by using simple quadrature rules. The second approach consists of transforming the linear system into a new one via the Lawson transformation <ref> [10] </ref>, and solving the system by using generalized Runge Kutta methods. <p> an error of order O (h 3 kE 2 k) + O (h 4 kEk). 5 2.2 Runge Kutta methods It is possible to develop generalized Runge Kutta type schemes by applying Runge Kutta methods to a modified system as was first suggested by Lawson in a series of paper <ref> [3, 10, 11, 12, 13] </ref>. Consider the change of variable, z (t) = e (tt 0 )B y (t); (12) in the interval [t 0 ; t 1 ]. <p> Consider the change of variable, z (t) = e (tt 0 )B y (t); (12) in the interval [t 0 ; t 1 ]. The essential idea of `generalized Runge-Kutta methods' as given in <ref> [10] </ref> consists of performing a local transformation of the problem in order to reduce the magnitude of the eigenvalues.
Reference: [11] <author> J.D. Lawson, </author> <title> Some numerical methods for stiff ordinary and partial differential equations. </title> <booktitle> Proc. Second Manitoba Conference on Numerical Mathematics., </booktitle> <year> 1972, </year> <pages> pp. 27-34. </pages>
Reference-contexts: an error of order O (h 3 kE 2 k) + O (h 4 kEk). 5 2.2 Runge Kutta methods It is possible to develop generalized Runge Kutta type schemes by applying Runge Kutta methods to a modified system as was first suggested by Lawson in a series of paper <ref> [3, 10, 11, 12, 13] </ref>. Consider the change of variable, z (t) = e (tt 0 )B y (t); (12) in the interval [t 0 ; t 1 ].
Reference: [12] <author> J.D. Lawson and D.A. Swayne, </author> <title> High-order near best uniform approximations to the solution of heat conduction problems. </title> <booktitle> Proc. IFIP Congress 80, </booktitle> <year> 1980, </year> <pages> pp. 741-746. </pages>
Reference-contexts: an error of order O (h 3 kE 2 k) + O (h 4 kEk). 5 2.2 Runge Kutta methods It is possible to develop generalized Runge Kutta type schemes by applying Runge Kutta methods to a modified system as was first suggested by Lawson in a series of paper <ref> [3, 10, 11, 12, 13] </ref>. Consider the change of variable, z (t) = e (tt 0 )B y (t); (12) in the interval [t 0 ; t 1 ].
Reference: [13] <author> J.D. Lawson and D.A. Swayne, </author> <title> Reduction of matrix factorizations in solvers for stiff ordinary differential equations. </title> <type> Congressus Numerantium 52, </type> <year> 1986, </year> <pages> pp. 147-152. </pages>
Reference-contexts: an error of order O (h 3 kE 2 k) + O (h 4 kEk). 5 2.2 Runge Kutta methods It is possible to develop generalized Runge Kutta type schemes by applying Runge Kutta methods to a modified system as was first suggested by Lawson in a series of paper <ref> [3, 10, 11, 12, 13] </ref>. Consider the change of variable, z (t) = e (tt 0 )B y (t); (12) in the interval [t 0 ; t 1 ].
Reference: [14] <author> B. Nour-Omid, </author> <title> Applications of the Lanczos algorithm. </title> <journal> Comput. Phys. Comm., </journal> <volume> 53, </volume> <year> 1989, </year> <pages> pp. 153-168. </pages>
Reference-contexts: Krylov subspace fl This work was supported by NSF under grant CCR-9618827 and by the Minnesota Supercomputer Institute. 1 algorithms of this type have been considered in recent years, see <ref> [4, 5, 7, 8, 9, 14, 16] </ref>.
Reference: [15] <author> C.B. Moler and C.F. VanLoan, </author> <title> Nineteen dubious ways to compute the exponential of a matrix. </title> <journal> SIAM Review, </journal> <volume> Vol 20, No. 4, </volume> <year> 1978, </year> <pages> pp. 801-836. </pages>
Reference-contexts: In such situations efficient and stable methods for computing matrix exponentials can be found in the literature, see for example the classical paper of Moler and Van Loan, <ref> [15] </ref>. In this case, it is 10 important to note that since most of the approximations are expressed in terms of powers of e ffhB we can compute this matrix only once. For example in Algorithm 2.4, all such products are expressed in terms of exp ( h 2 B).
Reference: [16] <author> Y. Saad, </author> <title> Analysis of some Krylov subspace approximations to the matrix exponential operator. </title> <journal> SIAM J. Numer. Anal. </journal> <volume> Vol 29, No. 1, </volume> <year> 1992, </year> <pages> pp. 209-228. 19 </pages>
Reference-contexts: Krylov subspace fl This work was supported by NSF under grant CCR-9618827 and by the Minnesota Supercomputer Institute. 1 algorithms of this type have been considered in recent years, see <ref> [4, 5, 7, 8, 9, 14, 16] </ref>. <p> Again, we assume that v (s) is constant in the interval [0; h] and equal to the new value of v ( 1 2 h) = Ey (t + h Define the operator h (A) = 0 which has been used in Krylov subspace methods to approximate the exponential operator, <ref> [5, 7, 8, 16] </ref>.
Reference: [17] <author> Y. Saad, SPARSKIT: </author> <title> A basic tool kit for sparse matrix computations. </title> <type> Technical Report 90-20, </type> <institution> Research Institute for Advanced Computer Science, NASA Ames Research Center, Moffet Field, </institution> <address> CA, </address> <year> 1990. </year> <month> 20 </month>
Reference-contexts: Matrices comes from the discretization of a PDE using a centered finite difference scheme. We have discretized the unit square using a uniform, 34 fi 34 grid. The order of the test matrices is 1024, using Dirichlet boundary conditions. The matrices were generated by SPARSKIT2 <ref> [17] </ref> and have been stored using the diagonal format. The diagonal preconditioner we have used consists of the main diagonal and the block diagonal consists of a tridiagonal matrix formed by the diagonals of offsets -1,0 and 1.
References-found: 17

