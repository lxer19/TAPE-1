URL: ftp://ftp.cs.wisc.edu/computer-vision/pami93-eggert.ps
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Email: goldgof@csee.usf.edu  dyer@cs.wisc.edu  hic@vision.auc.dk  
Title: The Scale Space Aspect Graph  
Author: David W. Eggert Kevin W. Bowyer Charles R. Dyer Henrik I. Christensen Dmitry B. Goldgof 
Keyword: Index terms: aspect graph, scale space, viewpoint space partition, image resolution, dynamic shape, Gaussian smoothing.  
Address: Tampa, Florida 33620 eggertd, kwb or  Madison, Wisconsin 53706  DK-9220 Aalborg East  
Affiliation: Department of Computer Science and Engineering University of South Florida  Department of Computer Science University of Wisconsin  Institute of Electronic Systems Aalborg University  
Abstract: Currently the aspect graph is computed from the theoretical standpoint of perfect resolution in object shape, the viewpoint and the projected image. This means that the aspect graph may include details that an observer could never see in practice. Introducing the notion of scale into the aspect graph framework provides a mechanism for selecting a level of detail that is "large enough" to merit explicit representation. This effectively allows control over the number of nodes retained in the aspect graph. This paper introduces the concept of the scale space aspect graph, defines three different interpretations of the scale dimension, and presents a detailed example for a simple class of objects, with scale defined in terms of the spatial extent of features in the image. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Babaud, J., Witkin, A. P., Baudin, M. and Duda, R. O. </author> <year> 1986. </year> <title> "Uniqueness of the Gaussian kernel for scale-space filtering", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 8, </volume> <pages> pp. 26-33, </pages> <year> 1986. </year>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves [23], the 2-D intensity map <ref> [1, 15, 20, 40] </ref> and 3-D object shape [16, 17]. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept. To better explain the approach we review the basics of Witkin's 1-D signal analysis.
Reference: [2] <author> Ben-Arie, J. </author> <title> "Probabilistic models of observed features and aspects with application to weighted aspect graphs", </title> <journal> Pattern Recognition Letters, </journal> <volume> vol. 11, </volume> <pages> pp. 421-427, </pages> <year> 1990. </year>
Reference-contexts: This is an important topic, and has been addressed in part by other researchers using concepts such as equivalence [34] and probability <ref> [2, 8, 13, 36, 37] </ref>. While the work presented here will be of aid in addressing this difficulty, it is not proposed as a solution by itself. As such, this issue will not be addressed further in this paper. <p> In the past researchers have considered the probability of certain views based on relative cell volumes <ref> [2, 8, 13, 36, 37] </ref>. There are a few problems with this approach. First, volume of a cell, without regard to shape, is perhaps not a proper indication of the likelihood that a given view is seen.
Reference: [3] <author> Bowyer, K. W., Sallam, M. Y., Eggert, D. W. and Stewman, J. S. </author> <title> "Computing the generalized aspect graph for objects with moving parts", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> to appear, </note> <year> 1993. </year>
Reference-contexts: Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies <ref> [3] </ref>. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. The actual labeling of contours and junctions varies slightly among researchers. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model. <p> In part (a) of Figure 3, it is depicted as an explicit sequence of conventional aspect graphs, each element representing a range of over which the aspect graph has a constant qualitative structure. This form bears considerable resemblance to the visual potential of articulated assemblies developed in <ref> [3] </ref>. In their representation separate instances of the aspect graph are recorded for varying articulation parameter values of an object (for instance, the angle of rotation on a hinge). <p> If one constructs the parcellation of the 3-D scale space using a sampling of the scale parameter similar to that used for articulated assemblies <ref> [3] </ref>, a total of fifty aspects is determined.
Reference: [4] <author> Chen, S. and Freeman, H. </author> <title> "On the characteristic views of quadric-surfaced solids", </title> <booktitle> Proceedings of the IEEE Workshop on Directions in Automated CAD-Based Vision, </booktitle> <pages> pp. 34-43, </pages> <year> 1991. </year>
Reference-contexts: Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects <ref> [4, 26, 27, 28, 29, 31] </ref>, to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. The actual labeling of contours and junctions varies slightly among researchers. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model.
Reference: [5] <author> Clark, J. J. </author> <title> "Singularity theory and phantom edges in scale space", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 10, </volume> <pages> pp. 720-727, </pages> <year> 1987. </year>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves <ref> [5, 22] </ref> and 3-D curves [23], the 2-D intensity map [1, 15, 20, 40] and 3-D object shape [16, 17]. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept.
Reference: [6] <author> Cowan, C. K. </author> <title> "Automatic camera and light-source placement using CAD models", </title> <booktitle> Proceedings of the IEEE Workshop on Directions in Automated CAD-Based Vision, </booktitle> <pages> pp. 22-31, </pages> <year> 1991. </year>
Reference-contexts: Implicit in this method is the fact that we will account for changes in size due to viewing distance. These ideas are similar in nature to those used by researchers determining visibility constraints for automatic sensor placement <ref> [6] </ref>. First one must determine which features should be measured. In order to be measured, a feature must have some spatial extent in the image. This means that a junction, which occurs at a single point, should not be one of the features we now concentrate on.
Reference: [7] <author> Eggert, D. and Bowyer, K. </author> <title> "Computing the orthographic projection aspect graph for solids of revolution", </title> <journal> Pattern Recognition Letters, </journal> <volume> vol. 11, </volume> <pages> pp. 751-763, </pages> <year> 1990. </year>
Reference-contexts: The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution <ref> [7, 8, 18] </ref>, to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [8] <author> Eggert, D. and Bowyer, K. </author> <title> "Computing the perspective projection aspect graph of solids of revolution", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> to appear, 1993. (See also Eggert, </note> <author> D. </author> <title> "Aspect graphs of solids of revolution", </title> <type> Doctoral Dissertation, </type> <institution> Department of Computer Science and Engineering, University of South Florida, </institution> <year> 1991.) </year>
Reference-contexts: This is an important topic, and has been addressed in part by other researchers using concepts such as equivalence [34] and probability <ref> [2, 8, 13, 36, 37] </ref>. While the work presented here will be of aid in addressing this difficulty, it is not proposed as a solution by itself. As such, this issue will not be addressed further in this paper. <p> The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution <ref> [7, 8, 18] </ref>, to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model. <p> In the past researchers have considered the probability of certain views based on relative cell volumes <ref> [2, 8, 13, 36, 37] </ref>. There are a few problems with this approach. First, volume of a cell, without regard to shape, is perhaps not a proper indication of the likelihood that a given view is seen.
Reference: [9] <author> Eggert, D. W., Bowyer, K. W., Dyer, C. R. </author> <title> "Aspect graphs: </title> <booktitle> state-of-the-art and applications in digital photogrammetry", Proceedings of the ISPRS 17th Congress: International Archives of Photogrammetry and Remote Sensing, Part B5, </booktitle> <pages> pp. 633-645, </pages> <year> 1992. </year>
Reference-contexts: The other is 3-D space, in which each point is the focal point for a perspective projection [4, 8, 25, 3, 30, 32, 33, 36, 37]. (For greater detail on categorization and comparison of these algorithms, see <ref> [9] </ref>.) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model. Most algorithms for computing the aspect graph follow the same basic high-level approach: Step 1.
Reference: [10] <author> Faugeras, O., Mundy, J., Ahuja, N., Dyer, C., Pentland, A., Jain, R., Ikeuchi, K. and Bowyer, K. </author> <title> "Panel theme: Why aspect graphs are not (yet) practical for computer vision", </title> <booktitle> Proceedings of the IEEE Workshop on Directions in Automated CAD-Based Vision, </booktitle> <pages> pp. 98-104, </pages> <year> 1991. </year> <month> 38 </month>
Reference-contexts: However, the practical utility of the aspect graph has been questioned. A recent panel discussion on the theme "Why aspect graphs are not (yet) practical for computer vision" was held at the 1991 IEEE Workshop on Directions in Automated CAD-Based Vision <ref> [10] </ref>.
Reference: [11] <author> Gigus, Z., Canny, J. and Seidel, R. </author> <title> "Efficiently computing and representing aspect graphs of polyhedral objects", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 13, </volume> <pages> pp. 542-551, </pages> <year> 1991. </year>
Reference-contexts: The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra <ref> [11, 25, 30, 32, 33, 36, 37] </ref>, to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [12] <author> Gualtieri, J. A., Baugher, S. and Werman, M. </author> <title> "The visual potential: One convex polygon", Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> vol. 46, </volume> <pages> pp. 96-130, </pages> <year> 1989. </year>
Reference-contexts: The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons <ref> [12] </ref>, to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3].
Reference: [13] <author> Kender, J. R. and Freudenstein, D. G. </author> <title> "What is a `degenerate' view?", </title> <booktitle> Proceedings of the ARPA Image Understanding Workshop, </booktitle> <pages> pp. 589-598, </pages> <year> 1987. </year>
Reference-contexts: This is an important topic, and has been addressed in part by other researchers using concepts such as equivalence [34] and probability <ref> [2, 8, 13, 36, 37] </ref>. While the work presented here will be of aid in addressing this difficulty, it is not proposed as a solution by itself. As such, this issue will not be addressed further in this paper. <p> In the past researchers have considered the probability of certain views based on relative cell volumes <ref> [2, 8, 13, 36, 37] </ref>. There are a few problems with this approach. First, volume of a cell, without regard to shape, is perhaps not a proper indication of the likelihood that a given view is seen.
Reference: [14] <author> Koenderink, J. J. and van Doorn, A. J. </author> <title> "The internal representation of solid shape with respect to vision", </title> <journal> Biological Cybernetics, </journal> <volume> vol. 32, </volume> <pages> pp. 211-216, </pages> <year> 1979. </year>
Reference-contexts: 1 Introduction The aspect graph <ref> [14] </ref> is considered important because it provides a complete view-centered representation of an object. Considerable research has been performed in recent years on algorithms that compute the aspect graph and its related representations [4, 7, 8, 11, 12, 18, 25, 26, 28, 30, 31, 32, 33, 36, 37].
Reference: [15] <author> Koenderink, J. J. </author> <title> "The structure of images", </title> <journal> Biological Cybernetics, </journal> <volume> vol. 50, </volume> <pages> pp. 363-370, </pages> <year> 1984. </year>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves [23], the 2-D intensity map <ref> [1, 15, 20, 40] </ref> and 3-D object shape [16, 17]. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept. To better explain the approach we review the basics of Witkin's 1-D signal analysis. <p> Previous scale space representations have been applied to 1-D, 2-D and 3-D intensity functions by interpreting the scale parameter in terms of the solution to the diffusion equation <ref> [15] </ref> (or more specifically, as the variance of a Gaussian kernel used to blur the function). It has been proven that only under this interpretation will the qualitative features of the function disappear and not be created as the scale value is increased [15]. <p> of the solution to the diffusion equation <ref> [15] </ref> (or more specifically, as the variance of a Gaussian kernel used to blur the function). It has been proven that only under this interpretation will the qualitative features of the function disappear and not be created as the scale value is increased [15]. Unfortunately, the entities on which the aspect graph concept is based (such as visual events, projected line drawings, and 3-D shape) are not intensity functions. As such, it is hard to define what one means by "blurring" the parcellation of viewpoint space. <p> Thus "weaker" edges would disappear first, meaning the strength of an edge defines its importance. An alternative is to describe the image according to the surface topology of the intensity function, e.g., the "hills and dales" representation <ref> [15] </ref>. A study has been made of the changes that occur for a given image under Gaussian smoothing, such as the annihilation of saddle regions and merging of small hills or dales into one.
Reference: [16] <author> Koenderink, J. J. and van Doorn, A. J. </author> <title> "Dynamic shape", </title> <journal> Biological Cybernetics, </journal> <volume> vol. 53, </volume> <pages> pp. 383-396, </pages> <year> 1986. </year>
Reference-contexts: was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves [23], the 2-D intensity map [1, 15, 20, 40] and 3-D object shape <ref> [16, 17] </ref>. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept. To better explain the approach we review the basics of Witkin's 1-D signal analysis. <p> Intuitively, one wants to smooth the object surface until a featureless blob is achieved, while examining the structure of the parcellation along the way. The question is how to perform the smoothing operation. A technique which initially seems appealing is the "dynamic shape" concept <ref> [16, 17] </ref>. This is a form of 3-D volumetric blurring in which the surface is marked as the level set of the resulting distribution. The volume over which averaging occurs is a function of the scale parameter, while the determination of the surface level is a constant threshold.
Reference: [17] <author> Koenderink, J. J. </author> <title> Solid Shape, </title> <publisher> (MIT Press, </publisher> <address> Cambridge, Mass.), </address> <year> 1990. </year>
Reference-contexts: was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves [23], the 2-D intensity map [1, 15, 20, 40] and 3-D object shape <ref> [16, 17] </ref>. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept. To better explain the approach we review the basics of Witkin's 1-D signal analysis. <p> Intuitively, one wants to smooth the object surface until a featureless blob is achieved, while examining the structure of the parcellation along the way. The question is how to perform the smoothing operation. A technique which initially seems appealing is the "dynamic shape" concept <ref> [16, 17] </ref>. This is a form of 3-D volumetric blurring in which the surface is marked as the level set of the resulting distribution. The volume over which averaging occurs is a function of the scale parameter, while the determination of the surface level is a constant threshold.
Reference: [18] <author> Kriegman, D. and Ponce, J. </author> <title> "Computing exact aspect graphs of curved objects: Solids of revolution", </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 5, </volume> <pages> pp. 119-135, </pages> <year> 1990. </year>
Reference-contexts: The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution <ref> [7, 8, 18] </ref>, to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [19] <author> Levitt, T. S. and Lawton, D. T. </author> <title> "Qualitative navigation for mobile robots", </title> <journal> Artificial Intelligence, </journal> <volume> vol. 44, </volume> <pages> pp. 305-360, </pages> <year> 1990. </year>
Reference-contexts: This curve is merely a circular arc segment <ref> [19] </ref>, the size and center of which vary with for a particular edge as shown in Figure 9.a. The shape of the surface in scale space can be seen in Figure 9.b. <p> For polyhedra, the visibility surface for an edge feature is the toroidal shape generated by rotating the circular curves about the edge in question <ref> [19] </ref>. Similar to the pseudo edges in 2-D, the visibility of chains of edges around the boundary of a face must be examined, as the nature of the face's shape changes. The visibility of a face as a whole is governed by the size of its projected area.
Reference: [20] <author> Lindeberg, T. and Eklundh, J. </author> <title> "Scale detection and region extraction from a scale-space primal sketch", </title> <booktitle> Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pp. 416-426, </pages> <year> 1990. </year>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves [23], the 2-D intensity map <ref> [1, 15, 20, 40] </ref> and 3-D object shape [16, 17]. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept. To better explain the approach we review the basics of Witkin's 1-D signal analysis. <p> This is essentially the conversion process used to generate a particular entry in the sequence of aspect graphs in the first representation in Figure 3.a from the second scale space form. Other representations, such as extensions of the interval tree concept <ref> [20, 39] </ref> may exist depending on the interpretation of the scale parameter, which is the topic of the next section. 5 Interpretations of the Scale Parameter Weaknesses in the aspect graph representation arise from certain implicit and explicit assumptions.
Reference: [21] <author> Malik, J. </author> <title> "Interpreting line drawings of curved objects", </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 1, </volume> <pages> pp. 73-103, </pages> <year> 1987. </year>
Reference-contexts: Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) <ref> [21] </ref>. The actual labeling of contours and junctions varies slightly among researchers. Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used.
Reference: [22] <author> Mokhtarian, F. and Mackworth, A. K. </author> <title> "Scale-based description and recognition of planar curves and two-dimensional shapes", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 8, </volume> <pages> pp. 34-43, </pages> <year> 1986. </year>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves <ref> [5, 22] </ref> and 3-D curves [23], the 2-D intensity map [1, 15, 20, 40] and 3-D object shape [16, 17]. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept.
Reference: [23] <author> Mokhtarian, F. and Mackworth, A. K. </author> <title> "A theory of multiscale, curvature-based shape representation for planar curves", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 14, </volume> <pages> pp. 789-805, </pages> <year> 1992. </year>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves <ref> [23] </ref>, the 2-D intensity map [1, 15, 20, 40] and 3-D object shape [16, 17]. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept.
Reference: [24] <author> Nalwa, V. S. </author> <title> "Line-drawing interpretation: A mathematical framework", </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 2, </volume> <pages> pp. 103-124, </pages> <year> 1988. </year>
Reference-contexts: is easier to first explore the concepts using a single-dimension scale space.) An alternative measurement, used commonly by psychologists and biologists, is the angle of visual arc , or field of view, occupied by the feature. (See Figure 7.) Furthermore, if this is combined with the natural perspective viewing model <ref> [24] </ref> implicitly used by many aspect graph researchers, every feature's size can be described by only one parameter value in the range 0 ffi 360 ffi .
Reference: [25] <author> Plantinga, H. and Dyer, C. R. </author> <title> "Visibility, occlusion and the aspect graph", </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 5, </volume> <pages> pp. 137-160, </pages> <year> 1990. </year>
Reference-contexts: Each of these factors contributes to a rather large overall size of the aspect graph representation. (For example, the worst-case node complexity is O (N 9 ) for an N-faced polyhedron assuming a 3-D viewpoint space <ref> [25, 33] </ref>.) By introducing the concept of scale one hopes to reduce this large set of theoretical aspects to a smaller set of the "most important" aspects. 2 This problem relates to another issue raised about the aspect graph, namely, the problem of indexing during object recognition. <p> The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra <ref> [11, 25, 30, 32, 33, 36, 37] </ref>, to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model. <p> Each node represents a "volume" of the scale space in which the same general view exists. Each arc again represents a visual event, but the underlying event surface is now parameterized by the scale dimension. This form corresponds most closely to the asp representation developed in <ref> [25] </ref>. In their representation features are represented in a higher-dimensional space according to their location on the image plane as a function of viewpoint position (direction). "Volumes" in this space represent particular feature configurations. The aspect graph is formed as the projection of these "volumes" into viewpoint space.
Reference: [26] <author> Ponce, J. and Kriegman, D. </author> <title> "Computing exact aspect graphs of curved objects: Parametric surfaces", </title> <booktitle> Proceedings of the 8th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 340-350, </pages> <year> 1987. </year>
Reference-contexts: Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects <ref> [4, 26, 27, 28, 29, 31] </ref>, to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. The actual labeling of contours and junctions varies slightly among researchers. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [27] <author> Ponce, J., Petitjean, S. and Kriegman, D. </author> <title> "Computing exact aspect graphs of curved objects: Algebraic surfaces", </title> <booktitle> Proceedings of the European Conference on Computer Vision, </booktitle> <pages> pp. 599-614, </pages> <year> 1992. </year>
Reference-contexts: Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects <ref> [4, 26, 27, 28, 29, 31] </ref>, to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. The actual labeling of contours and junctions varies slightly among researchers. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [28] <author> Rieger, J. </author> <title> "The geometry of view space of opaque objects bounded by smooth surfaces", </title> <journal> Artificial Intelligence, </journal> <volume> vol. 44, </volume> <pages> pp. 1-40, </pages> <year> 1990. </year>
Reference-contexts: Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects <ref> [4, 26, 27, 28, 29, 31] </ref>, to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. The actual labeling of contours and junctions varies slightly among researchers. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [29] <author> Rieger, J. </author> <title> "Global bifurcation sets and stable projections of nonsingular algebraic surfaces", </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 7, </volume> <pages> pp. 171-194, </pages> <year> 1992. </year>
Reference-contexts: Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects <ref> [4, 26, 27, 28, 29, 31] </ref>, to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. The actual labeling of contours and junctions varies slightly among researchers. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [30] <author> Seales, W. B. and Dyer, C. R. </author> <title> "Modeling the Rim Appearance", </title> <booktitle> Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pp. 698-701, </pages> <year> 1990. </year>
Reference-contexts: The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra <ref> [11, 25, 30, 32, 33, 36, 37] </ref>, to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model.
Reference: [31] <author> Sripradisvarakul, T. and Jain, R. </author> <title> "Generating aspect graphs for curved objects", </title> <booktitle> Proceedings of the IEEE Workshop on Interpretation of 3D Scenes, </booktitle> <pages> pp. 109-115, </pages> <year> 1989. </year>
Reference-contexts: Object domains have 3 evolved from polygons [12], to polyhedra [11, 25, 30, 32, 33, 36, 37], to solids of revolution [7, 8, 18], to piecewise-smooth objects <ref> [4, 26, 27, 28, 29, 31] </ref>, to articulated assemblies [3]. Almost without exception, a view of the object is represented using a qualitative description of the line drawing, such as the image structure graph (ISG) [21]. The actual labeling of contours and junctions varies slightly among researchers. <p> Distinctions between general and accidental views are usually based on isomorphism of the ISG. Lastly, two viewpoint space models are commonly used. The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection <ref> [7, 11, 18, 25, 26, 27, 28, 29, 31] </ref>.
Reference: [32] <author> Stewman, J. and Bowyer, K.W. </author> <title> "Direct construction of perspective projection aspect graphs for planar-face convex objects", Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> vol. 51, </volume> <pages> pp. 20-37, </pages> <year> 1990. </year>
Reference-contexts: The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra <ref> [11, 25, 30, 32, 33, 36, 37] </ref>, to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model.
Reference: [33] <author> Stewman, J. H. and Bowyer, K. W. </author> <title> "Creating the perspective projection aspect graph of convex polyhedra", </title> <booktitle> Proceedings of the 2nd International Conference on Computer Vision, </booktitle> <pages> pp. 494-500, </pages> <year> 1988. </year>
Reference-contexts: Each of these factors contributes to a rather large overall size of the aspect graph representation. (For example, the worst-case node complexity is O (N 9 ) for an N-faced polyhedron assuming a 3-D viewpoint space <ref> [25, 33] </ref>.) By introducing the concept of scale one hopes to reduce this large set of theoretical aspects to a smaller set of the "most important" aspects. 2 This problem relates to another issue raised about the aspect graph, namely, the problem of indexing during object recognition. <p> The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra <ref> [11, 25, 30, 32, 33, 36, 37] </ref>, to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model. <p> We now examine how the scale space theory can be applied to compute the structure of the scale space aspect graph. In principle, the equations of each event surface can be used to calculate a data structure such as the geometric incidence lattice, used in previous aspect graph algorithms <ref> [33] </ref>, to represent the subdivision of the 3-D scale space. However, since these surfaces are not ruled, the necessary intersection calculations can be very difficult.
Reference: [34] <author> Stewman, J. H., Stark, L. and Bowyer, K. W. </author> <title> "Restructuring aspect graphs into aspect-and cell-equivalence classes for use in computer vision", </title> <booktitle> Proceedings of the 13th International Workshop on Graph-Theoretic Concepts in Computer Science, </booktitle> <pages> pp. 230-241, </pages> <year> 1987. </year>
Reference-contexts: This is an important topic, and has been addressed in part by other researchers using concepts such as equivalence <ref> [34] </ref> and probability [2, 8, 13, 36, 37]. While the work presented here will be of aid in addressing this difficulty, it is not proposed as a solution by itself. As such, this issue will not be addressed further in this paper.
Reference: [35] <author> Waldon, S. and Dyer, C. </author> <title> "Towards an Aspect Graph for Photometric Imaging", </title> <type> Technical Report, </type> <institution> Computer Science Department, University of Wisconsin, </institution> <year> 1991. </year>
Reference-contexts: A study has been made of the changes that occur for a given image under Gaussian smoothing, such as the annihilation of saddle regions and merging of small hills or dales into one. Others are beginning to explore the types of visual events that exist for this view representation <ref> [35] </ref>. However, one difficulty is that much of the current theory that predicts changes in the ISG is not applicable under this representation.
Reference: [36] <author> Wang, R. and Freeman, H. </author> <title> "Object recognition based on characteristic view classes", </title> <booktitle> Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <pages> pp. 8-12, </pages> <year> 1990. </year>
Reference-contexts: This is an important topic, and has been addressed in part by other researchers using concepts such as equivalence [34] and probability <ref> [2, 8, 13, 36, 37] </ref>. While the work presented here will be of aid in addressing this difficulty, it is not proposed as a solution by itself. As such, this issue will not be addressed further in this paper. <p> The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra <ref> [11, 25, 30, 32, 33, 36, 37] </ref>, to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model. <p> In the past researchers have considered the probability of certain views based on relative cell volumes <ref> [2, 8, 13, 36, 37] </ref>. There are a few problems with this approach. First, volume of a cell, without regard to shape, is perhaps not a proper indication of the likelihood that a given view is seen.
Reference: [37] <author> Watts, N. </author> <title> "Calculating the principal views of a polyhedron", </title> <booktitle> Proceedings of the 9th International Conference on Pattern Recognition, </booktitle> <pages> pp. 316-322, </pages> <year> 1988. </year>
Reference-contexts: This is an important topic, and has been addressed in part by other researchers using concepts such as equivalence [34] and probability <ref> [2, 8, 13, 36, 37] </ref>. While the work presented here will be of aid in addressing this difficulty, it is not proposed as a solution by itself. As such, this issue will not be addressed further in this paper. <p> The various algorithms that have been developed may be classified using three properties; the object domain, the view representation and the model of viewpoint space. Object domains have 3 evolved from polygons [12], to polyhedra <ref> [11, 25, 30, 32, 33, 36, 37] </ref>, to solids of revolution [7, 8, 18], to piecewise-smooth objects [4, 26, 27, 28, 29, 31], to articulated assemblies [3]. <p> The first is the 2-D viewing sphere, on which each point defines a viewing direction for orthographic projection [7, 11, 18, 25, 26, 27, 28, 29, 31]. The other is 3-D space, in which each point is the focal point for a perspective projection <ref> [4, 8, 25, 3, 30, 32, 33, 36, 37] </ref>. (For greater detail on categorization and comparison of these algorithms, see [9].) Figure 1 depicts the aspect graph of a simple block, as found using each viewpoint space model. <p> In the past researchers have considered the probability of certain views based on relative cell volumes <ref> [2, 8, 13, 36, 37] </ref>. There are a few problems with this approach. First, volume of a cell, without regard to shape, is perhaps not a proper indication of the likelihood that a given view is seen.
Reference: [38] <author> Welford, W. T. </author> <title> Geometrical Optics: Optical Instrumentation, </title> <publisher> (North Holland Pub., </publisher> <address> Amster-dam), </address> <year> 1962. </year>
Reference-contexts: For those viewpoints from which the sphere overlaps the cell boundary, a composite view exists consisting of those views from the cell, the accidental boundary, and the neighboring cell. The nature of this composite view depends on the type of accidental boundary. 2 Under the assumptions of geometric optics <ref> [38] </ref>, a thin lens will focus all impinging light rays onto its optical axis. However, not all rays will be focused to the same point.
Reference: [39] <author> Witkin, A. P. </author> <title> "Scale-space filtering", in From Pixels to Predicates, </title> <publisher> (Ablex Publishing Corp., </publisher> <address> Norwood, NJ), </address> <pages> pp. 5-19, </pages> <year> 1986. </year>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal <ref> [39] </ref>. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves [23], the 2-D intensity map [1, 15, 20, 40] and 3-D object shape [16, 17]. <p> This is essentially the conversion process used to generate a particular entry in the sequence of aspect graphs in the first representation in Figure 3.a from the second scale space form. Other representations, such as extensions of the interval tree concept <ref> [20, 39] </ref> may exist depending on the interpretation of the scale parameter, which is the topic of the next section. 5 Interpretations of the Scale Parameter Weaknesses in the aspect graph representation arise from certain implicit and explicit assumptions.
Reference: [40] <author> Yuille A. and Poggio, T. </author> <title> "Scaling theorems for zero crossings", </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 8, </volume> <pages> pp. 15-25, </pages> <year> 1986. </year> <month> 40 </month>
Reference-contexts: Research in this area was popularized by Witkin's scale space analysis of the inflections of a 1-D signal [39]. 5 Since that time the scale space concept has been applied to the curvature of 2-D curves [5, 22] and 3-D curves [23], the 2-D intensity map <ref> [1, 15, 20, 40] </ref> and 3-D object shape [16, 17]. In addition, a number of other researchers have described other "hierarchical" or "multi-resolution" representations, such as pyramids, that are similar to the scale space concept. To better explain the approach we review the basics of Witkin's 1-D signal analysis.
References-found: 40

