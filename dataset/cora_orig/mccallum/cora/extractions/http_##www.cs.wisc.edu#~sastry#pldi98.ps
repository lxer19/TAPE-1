URL: http://www.cs.wisc.edu/~sastry/pldi98.ps
Refering-URL: 
Root-URL: 
Email: sastry@cs.wisc.edu  subbarao@cs.wisc.edu  jes@ece.wisc.edu  
Title: Exploiting Idle Floating-Point Resources For Integer Execution  
Author: S.Subramanya Sastry Subbarao Palacharla James E. Smith 
Affiliation: Computer Sciences Dept. University of Wisconsin-Madison  Computer Sciences Dept. University of Wisconsin-Madison  Dept. of ECE University of Wisconsin-Madison  
Abstract: To exploit these idle floating resources, the compiler must identify integer code that can be profitably offloaded to the augmented floating-point subsystem. In this paper, we present two compiler algorithms to do this. The basic scheme offloads integer computation to the floating-point subsystem using existing program loads/stores for inter-partition communication. For the SPECINT95 benchmarks, we show that this scheme offloads from 5% to 29% of the total dynamic instructions to the floating-point subsystem. The advanced scheme inserts copy instructions and duplicates some instructions to further offload computation. We evaluate the effectiveness of the two schemes using timing simulation. We show that the advanced scheme can offload from 9% to 41% of the total dynamic instructions to the floating-point subsystem. In doing so, speedups from 3% to 23% are achieved over a conventional microarchitecture. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alex Peleg, Sam Wilkie, and Uri Weiser. </author> <title> How Intel Built MMX Technology. </title> <journal> Communications of the ACM, </journal> <volume> 40(1):2538, </volume> <month> January </month> <year> 1997. </year>
Reference-contexts: Again, code duplication is not used to eliminate some of this communication, though it is recognized as a possible improvement to their algorithms. The MMX extensions to the IA-32 instruction set <ref> [1] </ref> are aimed at speeding up multimedia programs by performing multiple bit, byte, or word operations in parallel like a SIMD processor.
Reference: [2] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers : Principles, Techniques and Tools. </booktitle> <publisher> Addison Wesley, </publisher> <year> 1988. </year>
Reference-contexts: There is an edge from node v i to node v j if instruction i produces a value that could be consumed by instruction j. These edges are determined by solving the reaching-definitions dataflow problem <ref> [2] </ref>. Load and store instructions are special-cased in the RDG to simplify the partitioning algorithms. Each load instruction is split into two nodes one representing the load address and the other representing the loaded value. <p> Further, this keeps the hardware cost to a minimum since integer multiply and divide operations tend to be expensive (in terms of die area) to implement. Code partitioning is performed on the intermediate representation of the program after all the initial machine-independent optimizations <ref> [2] </ref> are complete. Register allocation is performed after code partitioning. Operands of instructions assigned to the FP a partition are allocated floating-point registers. We used a cycle-based timing simulator derived from the Sim-pleScalar tool set [7].
Reference: [3] <author> Andrea Capitanio, Nikil Dutt, and Alexandru Nicolau. </author> <title> Partitioned Register Files for VLIWs: A Preliminary Analysis of Tradeoffs. </title> <booktitle> In Proceedings of the 25th Annual International Symposium on Microar-chitecture, </booktitle> <pages> pages 292300, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: the floating-point resources are nearly idle even when executing floating-point code! This is not uncommon, and the techniques proposed in this paper can probably be effective with floating-point code. 2 In the context of VLIW machines (ELI, Multiflow TRACE, LC--VLIW), there has been prior work to partition code across clusters <ref> [14, 23, 5, 3, 11] </ref>. Ellis' BUG (bottom-up greedy) assignment algorithm in the Bulldog compiler [14] assigns instructions to functional units in all clusters. The algorithm is based on the assumption that functional units are the only limiting resource in the machine. <p> Inter-cluster communication bandwidth is not considered a limiting resource. In his thesis [5], Banerjia shows that when inter-cluster communication resources are scarce, the excessive copies introduced by BUG can hurt performance. Capitanio, Dutt, and Nicolau <ref> [3] </ref> present compiler schemes to achieve balanced code partitions while minimizing inter-cluster communication. However, this study applied the code partitioning techniques only to straight-line loop bodies of floating-point codes. Unlike the BUG algorithm, the partitioning algorithms presented by Banerjia [5], Capitanio et al. [3], and Desoli [11] attempt to maximize utilization <p> Capitanio, Dutt, and Nicolau <ref> [3] </ref> present compiler schemes to achieve balanced code partitions while minimizing inter-cluster communication. However, this study applied the code partitioning techniques only to straight-line loop bodies of floating-point codes. Unlike the BUG algorithm, the partitioning algorithms presented by Banerjia [5], Capitanio et al. [3], and Desoli [11] attempt to maximize utilization of hardware resources in all clusters while minimizing inter-cluster communication. In this respect, these algorithms are similar in spirit to our partitioning algorithms.
Reference: [4] <author> Ashok Kumar. </author> <title> The HP-PA8000 RISC CPU: A High Performance Out-of-Order Processor. </title> <booktitle> In Proceedings of the Hot Chips VIII, </booktitle> <pages> pages 920, </pages> <month> August </month> <year> 1996. </year> <month> 11 </month>
Reference-contexts: 1 Introduction Most current superscalar processors <ref> [17, 18, 16, 4] </ref> are based on the microarchitecture shown in Figure 1. The instruction fetch unit reads multiple instructions from the instruction cache, decodes them, and places them in instruction buffers for execution by the integer and floating-point subsystems.
Reference: [5] <author> Sanjeev Banerjia. </author> <title> Instruction Scheduling And Fetch Mechanisms For Clustered VLIW Processors. </title> <type> PhD thesis, </type> <institution> Dept. of Electrical and Computer Engineering, North Carolina State University, </institution> <year> 1998. </year>
Reference-contexts: the floating-point resources are nearly idle even when executing floating-point code! This is not uncommon, and the techniques proposed in this paper can probably be effective with floating-point code. 2 In the context of VLIW machines (ELI, Multiflow TRACE, LC--VLIW), there has been prior work to partition code across clusters <ref> [14, 23, 5, 3, 11] </ref>. Ellis' BUG (bottom-up greedy) assignment algorithm in the Bulldog compiler [14] assigns instructions to functional units in all clusters. The algorithm is based on the assumption that functional units are the only limiting resource in the machine. <p> Ellis' BUG (bottom-up greedy) assignment algorithm in the Bulldog compiler [14] assigns instructions to functional units in all clusters. The algorithm is based on the assumption that functional units are the only limiting resource in the machine. Inter-cluster communication bandwidth is not considered a limiting resource. In his thesis <ref> [5] </ref>, Banerjia shows that when inter-cluster communication resources are scarce, the excessive copies introduced by BUG can hurt performance. Capitanio, Dutt, and Nicolau [3] present compiler schemes to achieve balanced code partitions while minimizing inter-cluster communication. <p> Capitanio, Dutt, and Nicolau [3] present compiler schemes to achieve balanced code partitions while minimizing inter-cluster communication. However, this study applied the code partitioning techniques only to straight-line loop bodies of floating-point codes. Unlike the BUG algorithm, the partitioning algorithms presented by Banerjia <ref> [5] </ref>, Capitanio et al. [3], and Desoli [11] attempt to maximize utilization of hardware resources in all clusters while minimizing inter-cluster communication. In this respect, these algorithms are similar in spirit to our partitioning algorithms.
Reference: [6] <author> Digital Equipment Corporation. </author> <title> Alpha Architecture Handbook, </title> <type> Version 3, </type> <month> October </month> <year> 1996. </year>
Reference-contexts: For this example, code duplication can be used to achieve the same partitioning as realized by inserting copy instructions. In the 3 Linear in the number of nodes and edges of the RDG. 4 Such instructions are present in a number of instruction sets (e.g. MIPS [10] and Alpha <ref> [6] </ref>). C code fragment of our example shown in Figure 3, the loop induction variable regno is used both for address computation as well as for branch computation.
Reference: [7] <author> Doug Burger, Todd M. Austin, and Steve Bennett. </author> <title> Evaluating Future Microprocessors: The SimpleScalar Tool Set. </title> <note> Technical Report CS-TR-96-1308 (Available from http://www.cs.wisc.edu/trs.html), University of Wisconsin-Madison, </note> <month> July </month> <year> 1996. </year>
Reference-contexts: We then present results for the effectiveness of the two partitioning schemes and the net performance improvement over a conventional microarchitecture. 7.1 Evaluation Methodology We used gcc-2.7.1 as the base compiler for our work. The compiler was modified to generate code for the extended SimpleScalar <ref> [7] </ref> instruction set which is based on the MIPS instruction set. The SimpleScalar instruction set was extended by using new opcodes to encode integer instructions executing in the floating-point subsystem. We used 22 new opcodes for our study. <p> Register allocation is performed after code partitioning. Operands of instructions assigned to the FP a partition are allocated floating-point registers. We used a cycle-based timing simulator derived from the Sim-pleScalar tool set <ref> [7] </ref>. The timing simulator models both a conventional microarchitecture as well as a microarchitecture with the augmented floating-point subsystem. Both microarchitectures are identical in all other respects. The machine parameters we used in our simulations are presented in Table 1.
Reference: [8] <author> Eric Rotenberg, Quinn Jacobson, Yiannakis Sazeides, and Jim Smith. </author> <title> Trace Processors. </title> <booktitle> In Proceedings of the 30th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 138148, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures for exploiting fine grain instruction level parallelism have been proposed in the literature <ref> [24, 15, 13, 12, 27, 8, 9] </ref>. All of these architectures attempt to reduce hardware complexity to obtain a faster clock cycle. In all these architectures, the hardware resources are uniformly partitioned across multiple clusters resulting in homogeneous clusters.
Reference: [9] <author> G. S. Sohi, S. E. Breach, and T. N. Vijaykumar. </author> <title> Multiscalar Processors. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 414425, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures for exploiting fine grain instruction level parallelism have been proposed in the literature <ref> [24, 15, 13, 12, 27, 8, 9] </ref>. All of these architectures attempt to reduce hardware complexity to obtain a faster clock cycle. In all these architectures, the hardware resources are uniformly partitioned across multiple clusters resulting in homogeneous clusters.
Reference: [10] <author> Gerry Kane and Joe Heinrich. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: For this example, code duplication can be used to achieve the same partitioning as realized by inserting copy instructions. In the 3 Linear in the number of nodes and edges of the RDG. 4 Such instructions are present in a number of instruction sets (e.g. MIPS <ref> [10] </ref> and Alpha [6]). C code fragment of our example shown in Figure 3, the loop induction variable regno is used both for address computation as well as for branch computation.
Reference: [11] <author> Giuseppe Desoli. </author> <title> Instruction Assignment For Clustered VLIW DSP Compilers: A New Approach. </title> <type> Technical Report HPL-98-13, </type> <institution> HP Labs, </institution> <month> January </month> <year> 1998. </year>
Reference-contexts: the floating-point resources are nearly idle even when executing floating-point code! This is not uncommon, and the techniques proposed in this paper can probably be effective with floating-point code. 2 In the context of VLIW machines (ELI, Multiflow TRACE, LC--VLIW), there has been prior work to partition code across clusters <ref> [14, 23, 5, 3, 11] </ref>. Ellis' BUG (bottom-up greedy) assignment algorithm in the Bulldog compiler [14] assigns instructions to functional units in all clusters. The algorithm is based on the assumption that functional units are the only limiting resource in the machine. <p> However, this study applied the code partitioning techniques only to straight-line loop bodies of floating-point codes. Unlike the BUG algorithm, the partitioning algorithms presented by Banerjia [5], Capitanio et al. [3], and Desoli <ref> [11] </ref> attempt to maximize utilization of hardware resources in all clusters while minimizing inter-cluster communication. In this respect, these algorithms are similar in spirit to our partitioning algorithms.
Reference: [12] <author> Gregory A. Kemp and Manoj Franklin. PEWS: </author> <title> A Decentralized Dynamic Scheduler for ILP Processing. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <volume> volume I, </volume> <pages> pages 239246, </pages> <year> 1996. </year>
Reference-contexts: We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures for exploiting fine grain instruction level parallelism have been proposed in the literature <ref> [24, 15, 13, 12, 27, 8, 9] </ref>. All of these architectures attempt to reduce hardware complexity to obtain a faster clock cycle. In all these architectures, the hardware resources are uniformly partitioned across multiple clusters resulting in homogeneous clusters.
Reference: [13] <author> J.A.Fisher. </author> <title> Very Long Instruction Word Architectures and ELI-512. </title> <booktitle> In Proceedings of the 10th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 140150, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures for exploiting fine grain instruction level parallelism have been proposed in the literature <ref> [24, 15, 13, 12, 27, 8, 9] </ref>. All of these architectures attempt to reduce hardware complexity to obtain a faster clock cycle. In all these architectures, the hardware resources are uniformly partitioned across multiple clusters resulting in homogeneous clusters.
Reference: [14] <author> John R. Ellis. Bulldog: </author> <title> A Compiler for VLIW Architectures. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1985. </year>
Reference-contexts: the floating-point resources are nearly idle even when executing floating-point code! This is not uncommon, and the techniques proposed in this paper can probably be effective with floating-point code. 2 In the context of VLIW machines (ELI, Multiflow TRACE, LC--VLIW), there has been prior work to partition code across clusters <ref> [14, 23, 5, 3, 11] </ref>. Ellis' BUG (bottom-up greedy) assignment algorithm in the Bulldog compiler [14] assigns instructions to functional units in all clusters. The algorithm is based on the assumption that functional units are the only limiting resource in the machine. <p> Ellis' BUG (bottom-up greedy) assignment algorithm in the Bulldog compiler <ref> [14] </ref> assigns instructions to functional units in all clusters. The algorithm is based on the assumption that functional units are the only limiting resource in the machine. Inter-cluster communication bandwidth is not considered a limiting resource.
Reference: [15] <author> Keith I. Farkas, Paul Chow, Norman P. Jouppi, and Zvonko Vranesic. </author> <title> The Multicluster Architecture: Reducing Cycle Time Through Partitioning. </title> <booktitle> In Proceedings of the 30th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 149159, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures for exploiting fine grain instruction level parallelism have been proposed in the literature <ref> [24, 15, 13, 12, 27, 8, 9] </ref>. All of these architectures attempt to reduce hardware complexity to obtain a faster clock cycle. In all these architectures, the hardware resources are uniformly partitioned across multiple clusters resulting in homogeneous clusters. <p> This simplifies the problem since it is not necessary to schedule for individual issue slots. A further difference between our approaches is that these earlier algorithms do not consider code duplication as a means of eliminating inter-cluster communication. In the Multicluster architecture <ref> [15] </ref>, the hardware takes care of inter-cluster communication automatically. The compiler does not insert explicit copy instructions. The hardware performs inter-cluster copying based on the architectural registers used by the operands of an instruction. The compiler performs code partitioning by assigning registers to instruction operands.
Reference: [16] <author> Jim Keller. </author> <title> The 21264: A Superscalar Alpha Processor with Out-of-Order Execution, October 1996. </title> <booktitle> 9th Annual Microprocessor Forum, </booktitle> <address> San Jose, California. </address>
Reference-contexts: 1 Introduction Most current superscalar processors <ref> [17, 18, 16, 4] </ref> are based on the microarchitecture shown in Figure 1. The instruction fetch unit reads multiple instructions from the instruction cache, decodes them, and places them in instruction buffers for execution by the integer and floating-point subsystems.
Reference: [17] <author> Linley Gwennap. </author> <title> MIPS R10000 Uses Decoupled Architecture. </title> <type> Microprocessor Report, 8(14), </type> <month> October </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Most current superscalar processors <ref> [17, 18, 16, 4] </ref> are based on the microarchitecture shown in Figure 1. The instruction fetch unit reads multiple instructions from the instruction cache, decodes them, and places them in instruction buffers for execution by the integer and floating-point subsystems.
Reference: [18] <author> Linley Gwennap. </author> <title> UltraSparc Unleashes SPARC Performance. </title> <type> Microprocessor Report, 8(13), </type> <month> October </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Most current superscalar processors <ref> [17, 18, 16, 4] </ref> are based on the microarchitecture shown in Figure 1. The instruction fetch unit reads multiple instructions from the instruction cache, decodes them, and places them in instruction buffers for execution by the integer and floating-point subsystems.
Reference: [19] <author> Linley Gwennap. </author> <title> UltraSparc Adds Multimedia Instructions. </title> <type> Microprocessor Report, 8(16), </type> <month> December </month> <year> 1995. </year>
Reference-contexts: The hardware modifications required of existing architectures are minimal and are similar in spirit to the Intel MMX extensions to the IA-32 instruction set [20] and the Sun SPARC Visual Instruction Set (VIS) extensions <ref> [19] </ref>. * The floating-point functional units are augmented to support simple integer and logical operations. The more complex operations, integer multiplication and division, are fairly rare and do not have to be included.
Reference: [20] <author> Linley Gwennap. </author> <title> Intel's MMX Speeds Multimedia. </title> <type> Microprocessor Report, 10(3), </type> <month> March </month> <year> 1996. </year>
Reference-contexts: Palacharla and Smith [26] addressed this drawback and proposed a more general microarchitecture in which the floating-point subsystem can also execute integer instructions. The hardware modifications required of existing architectures are minimal and are similar in spirit to the Intel MMX extensions to the IA-32 instruction set <ref> [20] </ref> and the Sun SPARC Visual Instruction Set (VIS) extensions [19]. * The floating-point functional units are augmented to support simple integer and logical operations. The more complex operations, integer multiplication and division, are fairly rare and do not have to be included.
Reference: [21] <author> Mark Weiser. </author> <title> Program Slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 10(4):352357, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: Note that backward slices, as defined, do not go past load-value nodes. Similarly, forward slices do not go past address nodes. This is the primary difference from the traditional definition of slices <ref> [21] </ref>. Given this definition of a forward slice, all forward slices in a RDG terminate at memory addresses, call arguments, return values, branch outcomes, or store values. Using these terminal nodes, we define various computational slices as follows.
Reference: [22] <author> Ann Marie Grizzaffi Maynard, Colette M. Donnelly, and Bret R. Ol-szewski. </author> <title> Contrasting Characteristics and Cache Performance of Technical and Multi-User Commercial Workloads. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 145156, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: The main disadvantage of the partitioned approach is that it can lead to an imbalance in resource usage. In particular, it leads to idle floating-point resources (instruction buffers, issue logic, and functional units) during execution of integer programs. A large number of common programs (compilers, editors, databases, operating systems) <ref> [28, 22] </ref> are integer programs that execute very few (if any) 1 floating-point operations. Palacharla and Smith [26] addressed this drawback and proposed a more general microarchitecture in which the floating-point subsystem can also execute integer instructions.
Reference: [23] <author> P.Geoffrey Lowney, Stefan Freudenberger, Thomas Karzes, W.D.Lichtenstein, Robert P. Nix, John S. O'Donnel, and John C.Ruttenberg. </author> <title> The Multiflow Trace Scheduling Compiler. </title> <journal> The Journal of Supercomputing, </journal> <volume> 7(1):51142, </volume> <month> May </month> <year> 1993. </year>
Reference-contexts: the floating-point resources are nearly idle even when executing floating-point code! This is not uncommon, and the techniques proposed in this paper can probably be effective with floating-point code. 2 In the context of VLIW machines (ELI, Multiflow TRACE, LC--VLIW), there has been prior work to partition code across clusters <ref> [14, 23, 5, 3, 11] </ref>. Ellis' BUG (bottom-up greedy) assignment algorithm in the Bulldog compiler [14] assigns instructions to functional units in all clusters. The algorithm is based on the assumption that functional units are the only limiting resource in the machine.
Reference: [24] <author> Robert P. Colwell, Robert P. Nix, John J. O'Donnell, David B. Pa-pworth, and Paul K. Rodman. </author> <title> A VLIW Architecture for a Trace Scheduling Compiler. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(8), </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures for exploiting fine grain instruction level parallelism have been proposed in the literature <ref> [24, 15, 13, 12, 27, 8, 9] </ref>. All of these architectures attempt to reduce hardware complexity to obtain a faster clock cycle. In all these architectures, the hardware resources are uniformly partitioned across multiple clusters resulting in homogeneous clusters.
Reference: [25] <author> Scott McFarling. </author> <title> Combining Branch Predictors. </title> <note> Technical Report DEC WRL Technical Note TN-36, </note> <institution> DEC Western Research Laboratory, </institution> <year> 1993. </year>
Reference-contexts: of computation o*oaded to FP a graph shows the size of the FP a partition for both the basic and the 9 Parameter 4-way 8-way Fetch width any 4 instructions any 8 instructions I-cache 64KB, 2-way set-associative 128 byte lines,1 cycle hit time,6 cycle miss penalty Branch Predictor McFarling's gshare <ref> [25] </ref> with 32K 2-bit counters, 15 bit global history Unconditional control flow instructions predicted perfectly Decode/Rename width any 4 instructions any 8 instructions Issue window size 16 int/16 fp 32 int/32 fp Max. in-flight instructions 32 64 Retire width 4 8 Functional Units 2 Int + 2 Fp units 4 Int
Reference: [26] <author> Subbarao Palacharla and J. E. Smith. </author> <title> Decoupling Integer Execution in Superscalar Processors. </title> <booktitle> In Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 285290, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: In particular, it leads to idle floating-point resources (instruction buffers, issue logic, and functional units) during execution of integer programs. A large number of common programs (compilers, editors, databases, operating systems) [28, 22] are integer programs that execute very few (if any) 1 floating-point operations. Palacharla and Smith <ref> [26] </ref> addressed this drawback and proposed a more general microarchitecture in which the floating-point subsystem can also execute integer instructions. <p> The remaining computational slices, branch slices and store-value slices, are potential candidates for assignment to the FP a partition. Some of these slices can be assigned to the FP a partition without requiring any inter-partition communication. It is shown by Palacharla and Smith <ref> [26] </ref> (and is borne out by our simulations) that the LdSt slices of integer programs account for close to 50% of all dynamic instructions executed. This puts an upper bound on the size of the FP a partition that our algorithms can identify.
Reference: [27] <author> Subbarao Palacharla, Norman P. Jouppi, and J. E. Smith. </author> <title> Complexity-Effective Superscalar Processors. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures for exploiting fine grain instruction level parallelism have been proposed in the literature <ref> [24, 15, 13, 12, 27, 8, 9] </ref>. All of these architectures attempt to reduce hardware complexity to obtain a faster clock cycle. In all these architectures, the hardware resources are uniformly partitioned across multiple clusters resulting in homogeneous clusters.
Reference: [28] <author> Zarka Cvetanovic and Dileep Bhandarkar. </author> <title> Characterization of Alpha AXP Performance Using TP and SPEC Workloads. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year> <month> 12 </month>
Reference-contexts: The main disadvantage of the partitioned approach is that it can lead to an imbalance in resource usage. In particular, it leads to idle floating-point resources (instruction buffers, issue logic, and functional units) during execution of integer programs. A large number of common programs (compilers, editors, databases, operating systems) <ref> [28, 22] </ref> are integer programs that execute very few (if any) 1 floating-point operations. Palacharla and Smith [26] addressed this drawback and proposed a more general microarchitecture in which the floating-point subsystem can also execute integer instructions.
References-found: 28

