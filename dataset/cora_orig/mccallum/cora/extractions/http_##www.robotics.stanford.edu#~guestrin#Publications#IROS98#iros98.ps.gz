URL: http://www.robotics.stanford.edu/~guestrin/Publications/IROS98/iros98.ps.gz
Refering-URL: http://www.robotics.stanford.edu/~guestrin/
Root-URL: http://www.robotics.stanford.edu
Email: fguestrin,fgcozman,epkg@cs.cmu.edu  
Title: Fast Software Image Stabilization with Color Registration  
Author: Carlos Guestrin Fabio Cozman Eric Krotkov 
Affiliation: Robotics Institute, Carnegie Mellon University  
Abstract: We present the formulation and implementation of an image stabilization system capable of stabilizing video with very large displacements between frames. A coarse-to-fine technique is applied in resolution and in model spaces. The registration algorithm uses phase correlation to obtain an initial estimate for translation between images; then Levenberg-Marquardt method for non-linear optimization is applied to refine the solution. Registration is performed in color space, using a subset of the pixels selected by a gradient-based sub-sampling criteria. This software implementation runs at 5Hz on non-dedicated hardware (Silicon Graphics R10000 workstation). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Brown. </author> <title> A survey of image registration techniques. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(4) </volume> <pages> 325-376, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: The registration algorithm presented in this paper is also applicable to mosaicing. A similar methodology was formulated and used for image mosaicing by Szeliski [12]. Work on image registration is extensive, Brown presents a survey of this field <ref> [1] </ref>. 3 Registration Algorithms In our system, image registration is used to estimate camera motion between consecutive frames of the video sequence. The effects of camera motion in the sequence are modeled by the camera motion model. In the literature, there are many models for camera motion [7, 9, 12].
Reference: [2] <author> P. Burt and P. Anandan. </author> <title> Image stabilization by registration to a reference mosaic. </title> <booktitle> DARPA Image Understanding Workshop, </booktitle> <month> november </month> <year> 1994. </year>
Reference-contexts: In applications such as stabilizing a home video, on the other hand, a high frame-rate is fundamental, but displacements between frames tend to be of a smaller magnitude. 2 Related Work There has been extensive work on image stabilization, <ref> [2, 5, 7, 9] </ref> are some examples available in the literature. Most of these, including our system, use the same general framework for image stabilization: the motion between consecutive frames of the video sequence is estimated (except for [2]) and compensated for. <p> Most of these, including our system, use the same general framework for image stabilization: the motion between consecutive frames of the video sequence is estimated (except for <ref> [2] </ref>) and compensated for. The main differences are in the motion estimation algorithm used, the type of motion compensation applied, the hardware and the final goal application. Morimoto and Chellappa developed a system that performs motion estimation by tracking a set of feature points [9]. <p> Irani et al. formulate a method for determining 3D ego-motion from the 2D motion obtained from stabilization [7]. Burt and Anandan demonstrate registration of a frame in the video sequence to a mosaic, rather than to the previous frame <ref> [2] </ref>. The registration algorithm presented in this paper is also applicable to mosaicing. A similar methodology was formulated and used for image mosaicing by Szeliski [12].
Reference: [3] <author> F. Cozman and E. Krotkov. </author> <title> Automatic mountain detection and pose estimation for teleoperation of lunar rovers. </title> <booktitle> Int. Conference on Robotics and Automation, </booktitle> <year> 1997. </year>
Reference-contexts: Bottom, resulting images from positions 1 and 2. to select the pixels to be used in the registration step. This system was integrated with a visual position estimator <ref> [3] </ref>. The position estimator was developed for space robotics applications, where the video frame-rate is low. Thus, the most important factor for the image stabilization algorithm is to deal with large displacement between frames, a high frame-rate is not fundamental. <p> This estimate can then be refined using a local method. 6 Implementation and Results We implemented an image stabilization system using the formulation presented previously. This system was integrated into a Visual Position Estimator designed to aid operators of teleoperated rovers <ref> [3] </ref>. This system was able to stabilize a live video stream at 5Hz, using a software-only implementation on a Silicon Graphics R10000 workstation. This frame-rate is adequate for a space robotics application, such as that of the visual position estimation system.
Reference: [4] <author> C. Guestrin, F. Cozman, and E. Krotkov. </author> <title> Image stabilization for feature tracking and generation of stable video overlays. </title> <type> Technical Report CMU-RI-TR-97-42, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <month> November </month> <year> 1997. </year>
Reference-contexts: The effects of camera motion in the sequence are modeled by the camera motion model. In the literature, there are many models for camera motion [7, 9, 12]. The most common models are: translation, rigid, affine and projective <ref> [4] </ref>. In this Section, we present two methods used in our image stabilization system: phase correlation and minimization of image difference. 3.1 Phase Correlation An estimate of image translation can be obtained by using the phase difference of the Fourier transform. This algorithm was proposed by Kuglin and Hines [8]. <p> Again, the problem is defined as finding the values of the parameters of T that minimize E 2 . 4 Motion Compensation In this Section, we present an overview of some motion compensation techniques. <ref> [4] </ref> * overlays on raw video: an application of this work is creating stable graphical overlays on video so that they appear to "stick" to world features as the camera moves. <p> The low-frequency component of the camera motion, such as that caused by a rover turning, should not be altered. A possible approach is to remove the low-frequency component from the motion compensation. <ref> [4] </ref> 5 Feature Tracking Feature tracking is used in many computer vision applications. The motion of the camera and of objects in the scene are the main causes of feature motion. Image stabilization can be used estimate the camera motion component. <p> Therefore, it is possible to use image stabilization to track features. This is achieved by applying the transformation [T ] to the original position of the feature, thus, obtaining a new estimate of feature location. <ref> [4] </ref> The advantage of using a global method is that it is not affected by local effects. This allows us, for example, to track a region with no texture. However, the motion of the feature may not be perfectly estimated with a global motion model. <p> The position of the flag was estimated using the global motion estimation calculated by the registration algorithm. Experiments were also performed in smoothing camera motion and motion coding, obtaining successful results (see <ref> [4] </ref>). During our tests, we compared the visual result of smoothed camera motion to that of just using the raw video. We found that, for low frame-rates, the improvement is minimal. <p> First, the global motion calculated in the stabilization step presented previously is used to estimate the position of the feature in the current frame. Then, a local tracking algorithm is applied to refine this estimate. <ref> [4] </ref> Using this feature tracking improved, visually, the accuracy of the positioning of overlays over long video sequences. ... ... ... ... ... ... ... ... ... ... ... ... 7 Conclusion In this paper, we have presented the formulation and implementation of an image stabilization system.
Reference: [5] <author> M. Hansen, P. Anandan, K. Dana, G. Van der Wal, and P. Burt. </author> <title> Real-time scene atabilization and mosaic construction. </title> <booktitle> DARPA Image Understanding Workshop, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: In applications such as stabilizing a home video, on the other hand, a high frame-rate is fundamental, but displacements between frames tend to be of a smaller magnitude. 2 Related Work There has been extensive work on image stabilization, <ref> [2, 5, 7, 9] </ref> are some examples available in the literature. Most of these, including our system, use the same general framework for image stabilization: the motion between consecutive frames of the video sequence is estimated (except for [2]) and compensated for. <p> Morimoto and Chellappa developed a system that performs motion estimation by tracking a set of feature points [9]. The system of Hansen et al. fits a global motion model to the optical flow <ref> [5] </ref>. These implementations achieved higher frame-rates (between 10 and 28Hz) using specialized hardware. These approaches use tracking or flow to stabilize video. Our approach stabilizes the video by directly estimating a global transformation by applying an image registration algorithm. This result could then be used for tracking or flow estimation.
Reference: [6] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Computing occluding and transparent motions. </title> <journal> International Journal of Computer Vision, </journal> <volume> 12(1) </volume> <pages> 5-16, </pages> <month> January 94. </month>
Reference-contexts: These methods are prone to fall into local minima, instead of the desired global minima. To circumvent this problem, the method can be performed in a coarse-to-fine fashion, for example, using a Gaussian image pyramid [11]. Another interesting technique is to also perform a coarse-to-fine approach on model space. <ref> [6] </ref>. 3.3 Optimizing in Color Space When using grayscale images, a blue sky could be incorrectly registered to a brown mountain, if they have similar intensities.
Reference: [7] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Recovery of ego-motion using image stabilization. </title> <booktitle> In International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 454-460, </pages> <month> March 94. </month>
Reference-contexts: In applications such as stabilizing a home video, on the other hand, a high frame-rate is fundamental, but displacements between frames tend to be of a smaller magnitude. 2 Related Work There has been extensive work on image stabilization, <ref> [2, 5, 7, 9] </ref> are some examples available in the literature. Most of these, including our system, use the same general framework for image stabilization: the motion between consecutive frames of the video sequence is estimated (except for [2]) and compensated for. <p> Irani et al. formulate a method for determining 3D ego-motion from the 2D motion obtained from stabilization <ref> [7] </ref>. Burt and Anandan demonstrate registration of a frame in the video sequence to a mosaic, rather than to the previous frame [2]. The registration algorithm presented in this paper is also applicable to mosaicing. A similar methodology was formulated and used for image mosaicing by Szeliski [12]. <p> The effects of camera motion in the sequence are modeled by the camera motion model. In the literature, there are many models for camera motion <ref> [7, 9, 12] </ref>. The most common models are: translation, rigid, affine and projective [4].
Reference: [8] <author> C. Kuglin and D. Hines. </author> <title> The phase correlation image alignment method. </title> <booktitle> IEEE Conference on Cybernetics and Society, </booktitle> <month> September </month> <year> 1975. </year>
Reference-contexts: In this Section, we present two methods used in our image stabilization system: phase correlation and minimization of image difference. 3.1 Phase Correlation An estimate of image translation can be obtained by using the phase difference of the Fourier transform. This algorithm was proposed by Kuglin and Hines <ref> [8] </ref>. We will introduce this algorithm by analyzing the continuous one dimensional case.
Reference: [9] <author> C. H. Morimoto and R. Chellappa. </author> <title> Automatic digital image stabilization. </title> <booktitle> IEEE International Conference on Pattern Recognition, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: In applications such as stabilizing a home video, on the other hand, a high frame-rate is fundamental, but displacements between frames tend to be of a smaller magnitude. 2 Related Work There has been extensive work on image stabilization, <ref> [2, 5, 7, 9] </ref> are some examples available in the literature. Most of these, including our system, use the same general framework for image stabilization: the motion between consecutive frames of the video sequence is estimated (except for [2]) and compensated for. <p> The main differences are in the motion estimation algorithm used, the type of motion compensation applied, the hardware and the final goal application. Morimoto and Chellappa developed a system that performs motion estimation by tracking a set of feature points <ref> [9] </ref>. The system of Hansen et al. fits a global motion model to the optical flow [5]. These implementations achieved higher frame-rates (between 10 and 28Hz) using specialized hardware. These approaches use tracking or flow to stabilize video. <p> The effects of camera motion in the sequence are modeled by the camera motion model. In the literature, there are many models for camera motion <ref> [7, 9, 12] </ref>. The most common models are: translation, rigid, affine and projective [4].
Reference: [10] <author> W. Press, W. Vetterling, and S. Teukolsky snd B. Flannery. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge Press, </publisher> <year> 1992. </year>
Reference-contexts: As expected theoretically, the phase correlation method was able to detect translations of up to 50% of the image size (in this implementation, up to 128 pixels horizontally and 64 vertically). 6.2.2 Minimizing Image Difference To perform this minimization, the Levenberg-Marquardt method for non-linear optimization was chosen <ref> [10] </ref>. Using this iterative optimization method, sub-pixel accuracy can be achieved. In our implementation, optimization is carried out in a coarse-to-fine approach in image space, using a Gaussian pyramid.
Reference: [11] <author> A. Rosenfeld. </author> <title> Multiresolution Image Processing and Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: An iterative numerical optimization method is used to minimize E 2 [12]. These methods are prone to fall into local minima, instead of the desired global minima. To circumvent this problem, the method can be performed in a coarse-to-fine fashion, for example, using a Gaussian image pyramid <ref> [11] </ref>. Another interesting technique is to also perform a coarse-to-fine approach on model space. [6]. 3.3 Optimizing in Color Space When using grayscale images, a blue sky could be incorrectly registered to a brown mountain, if they have similar intensities.
Reference: [12] <author> R. Szeliski. </author> <title> Image mosaicing for tele-reality applications. </title> <type> Technical Report CRL 94/2, </type> <institution> Digital Equipment Corporation, Cambridge Research Lab, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Burt and Anandan demonstrate registration of a frame in the video sequence to a mosaic, rather than to the previous frame [2]. The registration algorithm presented in this paper is also applicable to mosaicing. A similar methodology was formulated and used for image mosaicing by Szeliski <ref> [12] </ref>. Work on image registration is extensive, Brown presents a survey of this field [1]. 3 Registration Algorithms In our system, image registration is used to estimate camera motion between consecutive frames of the video sequence. <p> The effects of camera motion in the sequence are modeled by the camera motion model. In the literature, there are many models for camera motion <ref> [7, 9, 12] </ref>. The most common models are: translation, rigid, affine and projective [4]. <p> The phase correlation algorithm is capable of dealing with translations of up to 50% of the image size. 3.2 Minimizing Image Difference The registration problem can also be modelled as the minimization of the intensity difference between the images <ref> [12] </ref>. <p> This transformation is usually a parametric model of the effect on the images of the camera mo-tion. Thus, the problem can be defined as finding the values of the parameters of T that minimize E 2 . An iterative numerical optimization method is used to minimize E 2 <ref> [12] </ref>. These methods are prone to fall into local minima, instead of the desired global minima. To circumvent this problem, the method can be performed in a coarse-to-fine fashion, for example, using a Gaussian image pyramid [11].
References-found: 12

