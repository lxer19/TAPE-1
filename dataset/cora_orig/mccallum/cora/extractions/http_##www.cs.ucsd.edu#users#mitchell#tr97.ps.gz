URL: http://www.cs.ucsd.edu/users/mitchell/tr97.ps.gz
Refering-URL: http://www.cs.ucsd.edu/users/mitchell/papers.html
Root-URL: http://www.cs.ucsd.edu
Title: Quantifying the Multi-Level Nature of Tiling Interactions  
Author: Nicholas Mitchell Larry Carter, Jeanne Ferrante, Karin Hogstedt 
Address: La Jolla CA 92093-0114  
Affiliation: Computer Science and Engineering Department, UCSD,  
Abstract: Current trends in architecture are towards a hierarchy of memory and parallelism. Optimizations such as tiling are often aimed towards improvement at a single level of this hierarchy, e.g., cache. Such optimizations are usually performed separately for each level, guided by a cost function using information only about a single level, even though it is widely acknowledged that optimization using global information can lead to better results. In this paper, for three different common architectural scenarios, we quantify the extent to which performance of a single tiling choice can be improved by the use of information about multiple levels in concert. We give both analysis and simulation results to support our point. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, D. Krantz, and V. Natarajan. </author> <title> Automatic partitioning of parallel loops and data arrays for distributed shared memory multiprocessors. </title> <booktitle> In Proc. of International Conference on Parallel Computing, </booktitle> <year> 1993. </year>
Reference-contexts: Kennedy and McKinley [22] study the extent to which loop fusion and distribution affect both parallelism and locality. However, these latter two works do not directly address tiling or the nature of the interactions themselves. Related works such as <ref> [23, 1, 13] </ref> give methods for choosing tile size in a nested loop; [23] uses a "fits-in" constraint based only on memory capacity (not block size), [13]'s "fits-in" constraint does not fully utilize block size information, and [1] limits block size to 1. <p> Related works such as [23, 1, 13] give methods for choosing tile size in a nested loop; [23] uses a "fits-in" constraint based only on memory capacity (not block size), [13]'s "fits-in" constraint does not fully utilize block size information, and <ref> [1] </ref> limits block size to 1. In contrast to these and other approaches to tiling size selection, our multi-level approach uses the block size at each level in a multi-level cost function. <p> In contrast to these and other approaches to tiling size selection, our multi-level approach uses the block size at each level in a multi-level cost function. We employ counting arguments similar to <ref> [23, 15, 13, 1, 17] </ref> to estimate the number of misses in a module. Some of this work [15, 17] does not apply their results to determine tile size.
Reference: [2] <author> Bowen Alpern, Larry Carter, and Kang-Su Gatlin. </author> <title> Mi-croparallelism and high-performance string matching. </title> <booktitle> In Proc. of Supercomputing, </booktitle> <year> 1995. </year>
Reference-contexts: For this scenario, the best optimization strategy must balance data locality and ILP as a function of the program and details of the target machine. The Protein String Matching problem (PSM) <ref> [2, 12] </ref> provides an interesting study in shared memory parallelism tiling interactions. Given a query string q and a set R of reference strings, the protein string matching problem finds the reference string r 2 R with maximal similarity to the query string. <p> This way, little padding is needed. 15 A typical instance of protein string matching has 10; 000 reference strings with average length 20; 000, and each point of the ISG requires 16 bytes of storage. <ref> [2] </ref>. 8 matching: a series of independent planes, each constrained as indicated. optimizes for good cache usage without considering instruction level parallelism, the other first considers ILP without considering cache.

Reference: [4] <author> D. F. Bacon, S. L. Graham, and O. J. Sharp. </author> <title> Compiler transformations for high-performance computing. </title> <journal> Com puting Surveys, </journal> <volume> 26(4) </volume> <pages> 345-420, </pages> <year> 1994. </year>
Reference-contexts: We express block size in units of problem elements (for example, elements of the matrices in matrix multiply), rather than bytes. The block count, C k , is the number of blocks contained in module k. 2.2 Related Work As noted in <ref> [4] </ref>, optimizations interact, and choosing the order of their application is problematical. <p> Some of this work [15, 17] does not apply their results to determine tile size. No previous work has applied these arguments to show the extent to which optimization decisions made independently can lead to performance degradation. With respect to optimization, Bacon, Graham and Sharp <ref> [4] </ref> observe: "There is no single best order of application; one transformation can permit or prevent a second from being applied, or it can change the effectiveness of subsequent changes." Understanding the nature of the interactions between optimizations allows us to explain why certain codes behave badly on certain architectures, or
Reference: [5] <author> Utpal Banerjee. </author> <title> Unimodular transformations of double loops. </title> <booktitle> In Proc. of the 3rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [6] <author> Steve Carr. </author> <title> Combining optimization for cache and instruction-level parallelism. </title> <booktitle> In PACT '96, </booktitle> <pages> pages 238 247, </pages> <year> 1996. </year>
Reference-contexts: Unimodular transformations provide a means to guide loop transformations for parallelism [30] and locality [29]. However, this work seeks to unify only improvement-enabling transformations such as skewing, interchange, and reversal, and does not consider locality and parallelism in concert. Carr <ref> [6] </ref> studies criteria to guide locality and instruction level parallelism in concert via unroll-and-jam. Kennedy and McKinley [22] study the extent to which loop fusion and distribution affect both parallelism and locality. However, these latter two works do not directly address tiling or the nature of the interactions themselves.
Reference: [7] <author> Steve Carr and Ken Kennedy. </author> <title> Compiler blockability of numerical algorithms. </title> <journal> The Journal of Supercomputing, </journal> <pages> pages 114-124, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: In addition, current machines often include several levels of parallelism: instruction-level, multiple processors on a chip, and so forth. Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations <ref> [29, 7, 9, 8] </ref> may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism [3, 30, 14, 20, 24] are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors.
Reference: [8] <author> Steve Carr and Ken Kennedy. </author> <title> Improving the ratio of memory operations to floatingpoint operations in loops. </title> <journal> Transactions on Programming Languages and Systems, </journal> <volume> 16(6) </volume> <pages> 1768-1810, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: In addition, current machines often include several levels of parallelism: instruction-level, multiple processors on a chip, and so forth. Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations <ref> [29, 7, 9, 8] </ref> may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism [3, 30, 14, 20, 24] are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors.
Reference: [9] <author> Steve Carr, Kathryn S. McKinley, and Chau-Wen Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: In addition, current machines often include several levels of parallelism: instruction-level, multiple processors on a chip, and so forth. Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations <ref> [29, 7, 9, 8] </ref> may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism [3, 30, 14, 20, 24] are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors.
Reference: [10] <author> Larry Carter, Jeanne Ferrante, and S. Flynn Hummel. </author> <title> Efficient parallelism via hierarchical tiling. </title> <booktitle> In Proc. of SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <month> February </month> <year> 1995. </year>
Reference-contexts: Our current work on automating hierarchical tiling <ref> [10, 11, 12] </ref> follows this latter approach. In Section 3, we consider abstractions of several real application codes, such as Protein String Matching. We also consider three different architectural scenarios (summarized in Figure 1) involving multiple levels of memory or parallelism.
Reference: [11] <author> Larry Carter, Jeanne Ferrante, and S. Flynn Hummel. </author> <title> Hierarchical tiling for improved superscalar perfomance. </title> <booktitle> In Proc. of International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Our current work on automating hierarchical tiling <ref> [10, 11, 12] </ref> follows this latter approach. In Section 3, we consider abstractions of several real application codes, such as Protein String Matching. We also consider three different architectural scenarios (summarized in Figure 1) involving multiple levels of memory or parallelism.
Reference: [12] <author> Larry Carter, Jeanne Ferrante, Susan Flynn Hummel, Bowen Alpern, and Kang-Su Gatlin. </author> <title> Hierarchical tiling: A methodology for high performance. </title> <type> Technical Report CS96-508, UCSD, </type> <institution> Department of Computer Science and Engineering, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Our current work on automating hierarchical tiling <ref> [10, 11, 12] </ref> follows this latter approach. In Section 3, we consider abstractions of several real application codes, such as Protein String Matching. We also consider three different architectural scenarios (summarized in Figure 1) involving multiple levels of memory or parallelism. <p> For this scenario, the best optimization strategy must balance data locality and ILP as a function of the program and details of the target machine. The Protein String Matching problem (PSM) <ref> [2, 12] </ref> provides an interesting study in shared memory parallelism tiling interactions. Given a query string q and a set R of reference strings, the protein string matching problem finds the reference string r 2 R with maximal similarity to the query string. <p> The (k; j; i) schedule gives the worst performance as it thrashes cache when there are more reference strings than cache lines. Which is best? Table 4 summarizes some experimental results from <ref> [12] </ref>. These experiments used very short reference strings, so the effect of cache misses was negligible. The table shows that using two independent reference strings greatly improved the IBM Power2 processor's performance, and made a much smaller improvement on the DEC Alpha 21064.
Reference: [13] <author> S. Coleman and K. S. McKinley. </author> <title> Tile size selection using cache organization and data layout. </title> <booktitle> In Proc. of Program ming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: In current practice, only the parameters from a single architectural level are included as parameters of the cost function. For instance, in tiling for cache, only cache size, cache line size, and cache associativity may be considered <ref> [13] </ref>. This is despite the fact that it is common knowledge that using more information can lead to better optimization. A cost function is level-specific if its parameters only include information from one specific level of the hierarchy; otherwise the cost function is multi-level. <p> Kennedy and McKinley [22] study the extent to which loop fusion and distribution affect both parallelism and locality. However, these latter two works do not directly address tiling or the nature of the interactions themselves. Related works such as <ref> [23, 1, 13] </ref> give methods for choosing tile size in a nested loop; [23] uses a "fits-in" constraint based only on memory capacity (not block size), [13]'s "fits-in" constraint does not fully utilize block size information, and [1] limits block size to 1. <p> In contrast to these and other approaches to tiling size selection, our multi-level approach uses the block size at each level in a multi-level cost function. We employ counting arguments similar to <ref> [23, 15, 13, 1, 17] </ref> to estimate the number of misses in a module. Some of this work [15, 17] does not apply their results to determine tile size. <p> As the length of the longest dependent chain is a function of the shape of the iteration space, a hierarchical strategy may define shorter dependence chains. So, in choosing tile shapes and sizes for each level independently, previous work such as <ref> [29, 13] </ref> misses out on an opportunity for performance gains. Our preliminary findings indicate that tiling for multiple levels of parallelism can indeed improve performance; for PDE-like codes on an SGI Cray Origin one can achieve a speedup of 10% over level-at-a-time parallelization.
Reference: [14] <author> Paul Feautrier. </author> <title> Some efficient solutions to the affine scheduling problem, Part I, one-dimensional time. </title> <journal> International Journal of Parallel Programming, </journal> <note> 21(5), Oc tober 1992. </note>
Reference-contexts: Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations [29, 7, 9, 8] may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism <ref> [3, 30, 14, 20, 24] </ref> are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors.
Reference: [15] <author> Jeanne Ferrante, Vivek Sarkar, and Wendy Thrash. </author> <title> On estimating and enhancing cache effectiveness. </title> <booktitle> (589), 1991. Proceedings of the Fourth International Workshop on Languages and Compilers for Parallel Computing. </booktitle>
Reference-contexts: In contrast to these and other approaches to tiling size selection, our multi-level approach uses the block size at each level in a multi-level cost function. We employ counting arguments similar to <ref> [23, 15, 13, 1, 17] </ref> to estimate the number of misses in a module. Some of this work [15, 17] does not apply their results to determine tile size. <p> We employ counting arguments similar to [23, 15, 13, 1, 17] to estimate the number of misses in a module. Some of this work <ref> [15, 17] </ref> does not apply their results to determine tile size. No previous work has applied these arguments to show the extent to which optimization decisions made independently can lead to performance degradation.
Reference: [16] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> In Journal of Parallel and Distributed Computing, </journal> <volume> volume 5, </volume> <month> October </month> <year> 1988. </year>
Reference-contexts: Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [17] <author> G. Gao, V. Sarkar, and S. Han. </author> <title> Locality analysis for distributed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Fourth International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <year> 1996. </year>
Reference-contexts: In contrast to these and other approaches to tiling size selection, our multi-level approach uses the block size at each level in a multi-level cost function. We employ counting arguments similar to <ref> [23, 15, 13, 1, 17] </ref> to estimate the number of misses in a module. Some of this work [15, 17] does not apply their results to determine tile size. <p> We employ counting arguments similar to [23, 15, 13, 1, 17] to estimate the number of misses in a module. Some of this work <ref> [15, 17] </ref> does not apply their results to determine tile size. No previous work has applied these arguments to show the extent to which optimization decisions made independently can lead to performance degradation.
Reference: [18] <author> Karin Hogstedt, Larry Carter, and Jeanne Ferrante. </author> <title> Calculating the idle time of a tiling. </title> <booktitle> In Proc. of Principles of Programming Languages, </booktitle> <year> 1997. </year>
Reference-contexts: The theoretical basis for this work appears in <ref> [18] </ref>. Figure 1c portrays a system with two levels of parallelism, such as a distributed symmetric multiprocessor. Due to data dependences, the features of a tiling determine the time spent waiting for data or synchronization (idle time). <p> Choosing the tile to include the extreme (outermost) vectors of the stencil insures no dependence cycles between the tiles, and is thus a legal tiling. 18 Choosing the tile to include the smallest such angle including the extreme vectors will minimize the idle time <ref> [18] </ref>. Rectangular tiles have the smallest angle that includes the given dependences in this example. The tiles at the second level won't be further divided so we choose rectangular tiles, the locally optimal tile shape at this level. <p> Note, however, that the tile at the top level is the iteration space at the second level. Since the idle time of a tiling at a given level is determined by the relation between the shape of the tiles and the shape of the iteration space <ref> [18] </ref>, choosing a tile shape at the top level might result in poor idle time at the middle level. We now show it is more advantageous to choose a tile shape at the top level which is suboptimal to get a better overall execution time. <p> zero and C 2;1 as L 2;1 + h 2 +w 2 +h 2 w 2 B 2;1 , where L 2;1 and B 2;1 are the latency and bandwidth respectively between the second and first level. (For an explanation of these formulas and the notion of rise, please see <ref> [18] </ref>.) The different formulas for idle time that are being used in the different cases are discussed below. In Table 5 we show the calculated execution times for three different cases.
Reference: [19] <author> F. Irigoin and R. Triolet. </author> <title> Supernode partitioning. </title> <booktitle> In Proc. 15th ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 319-328, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular. <p> formula is only used to explain the process of choosing the tile parameters; in the calculations we take the number of bytes required to calculate one iteration into account. 18 Including the extreme vectors in the tile angle is a (suffi cient but) not necessary condition for a legal tiling <ref> [19] </ref>. 12 where IT i is the idle time at level i, C i;i1 is the communication time of the necessary data from level i to level i 1, and t i is the number of tiles (not necessarily an integer) in each stack at level i. 19 For the base
Reference: [20] <author> Wayne Kelly and William Pugh. </author> <title> A unifying framework for iteration reordering transformations. </title> <booktitle> In Proc. of IEEE 14 First International Conference on Algorithms and Archi--tectures for Parallel Processing, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations [29, 7, 9, 8] may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism <ref> [3, 30, 14, 20, 24] </ref> are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors.
Reference: [21] <author> Ken Kennedy and Kathryn S. McKinley. </author> <title> Optimizing for parallelism and data locality. </title> <booktitle> In Proc. International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [22] <author> Ken Kennedy and Kathryn S. McKinley. </author> <title> Maximizing loop parallelism and improving data locality via loop fusion and distribution. </title> <booktitle> (768), 1993. Proceedings of the Fourth International Workshop on Languages and Compilers for Parallel Computing. </booktitle>
Reference-contexts: However, this work seeks to unify only improvement-enabling transformations such as skewing, interchange, and reversal, and does not consider locality and parallelism in concert. Carr [6] studies criteria to guide locality and instruction level parallelism in concert via unroll-and-jam. Kennedy and McKinley <ref> [22] </ref> study the extent to which loop fusion and distribution affect both parallelism and locality. However, these latter two works do not directly address tiling or the nature of the interactions themselves.
Reference: [23] <author> Monica S. Lam, Edward E. Rothberg, and Michael E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In ASPLOS-IV, </booktitle> <address> Palo Alto, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> Kennedy and McKinley [22] study the extent to which loop fusion and distribution affect both parallelism and locality. However, these latter two works do not directly address tiling or the nature of the interactions themselves. Related works such as <ref> [23, 1, 13] </ref> give methods for choosing tile size in a nested loop; [23] uses a "fits-in" constraint based only on memory capacity (not block size), [13]'s "fits-in" constraint does not fully utilize block size information, and [1] limits block size to 1. <p> However, these latter two works do not directly address tiling or the nature of the interactions themselves. Related works such as [23, 1, 13] give methods for choosing tile size in a nested loop; <ref> [23] </ref> uses a "fits-in" constraint based only on memory capacity (not block size), [13]'s "fits-in" constraint does not fully utilize block size information, and [1] limits block size to 1. <p> In contrast to these and other approaches to tiling size selection, our multi-level approach uses the block size at each level in a multi-level cost function. We employ counting arguments similar to <ref> [23, 15, 13, 1, 17] </ref> to estimate the number of misses in a module. Some of this work [15, 17] does not apply their results to determine tile size. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [24] <author> Daniel Lavery and Wen mei Hwu. </author> <title> Unrolling-based optimizations for modulo scheduling. </title> <booktitle> In Proceedings of the 28th International Symposium on Microarchitecture, </booktitle> <month> De-cember </month> <year> 1995. </year>
Reference-contexts: Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations [29, 7, 9, 8] may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism <ref> [3, 30, 14, 20, 24] </ref> are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors.
Reference: [25] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> In Communications of the ACM, </journal> <volume> volume 29, </volume> <pages> pages 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: different scenarios to quantify the difference in results using level-specific and multi-level cost functions. 2 Background Given a loop nest, the Iteration Space Graph (ISG) [26] is a directed acyclic graph whose nodes represent the initial values and computations in the loop body, and whose edges represent data 1 dependences <ref> [25] </ref>. Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG.
Reference: [26] <author> J. Ramanujam and P. Sadayappan. </author> <title> Tiling multidimensional iteration spaces for nonshared memory machines. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <month> November </month> <year> 1991. </year>
Reference-contexts: We also consider three different architectural scenarios (summarized in Figure 1) involving multiple levels of memory or parallelism. We use these codes in the different scenarios to quantify the difference in results using level-specific and multi-level cost functions. 2 Background Given a loop nest, the Iteration Space Graph (ISG) <ref> [26] </ref> is a directed acyclic graph whose nodes represent the initial values and computations in the loop body, and whose edges represent data 1 dependences [25]. Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. <p> Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [27] <author> Rafael H. Saavedra, Weihua Mao, Daeyeon Park, Jacque-line Chame, and Sungo Moon. </author> <title> The combined effectiveness of unimodular transformations, tiling, and software prefetching. </title> <booktitle> In Proc. of International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: TLB considerations have already chosen the tile width to be W = 20, is obtained by choosing the largest value 9 These equations apply to any level k of the memory hierarchy for which we have only considered the characteristics of that level in isolation. 10 Note that Saavedra's observations <ref> [27] </ref> that multiple levels of tiling can have excessive overhead do not apply to our approach, since he used a nine-deep loop nest. 6 of H that satisfies the "fits-in" constraint for cache, E c (H; W ) = :75C c .
Reference: [28] <author> K. Wang and D. Gannon. </author> <title> Applying ai techniques to program optimization for parallel computers. 1989. chapter 12, </title> <publisher> Mc Graw Hill Co. </publisher>
Reference-contexts: The block count, C k , is the number of blocks contained in module k. 2.2 Related Work As noted in [4], optimizations interact, and choosing the order of their application is problematical. One approach to controlling the interactions different from ours is that of Wang and Gannon <ref> [28] </ref>, who use AI search techniques on a decision tree of possible optimizations to find a good sequence of transformations to parallelize a given program. The work in [31] acknowledges that optimizations are interdependent, and give a pruned search procedure through the possible transformation space.
Reference: [29] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proc. of Programming Language Design and Implementation, </booktitle> <year> 1991. </year>
Reference-contexts: In addition, current machines often include several levels of parallelism: instruction-level, multiple processors on a chip, and so forth. Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations <ref> [29, 7, 9, 8] </ref> may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism [3, 30, 14, 20, 24] are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors. <p> However, there is no assurance that the locally optimal choices will be globally optimal. In this paper, we present evidence to support the case that * Level-specific cost functions may not lead to the globally optimal choice. We show that for the tiling transformation <ref> [32, 29] </ref>, a level-specific tiling at a single level can lead to a globally suboptimal choice. <p> Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> We show in this paper that a cache-specific cost function and ILP-specific cost function to determine tiling do not lead to as good performance as considering both levels in concert. Unimodular transformations provide a means to guide loop transformations for parallelism [30] and locality <ref> [29] </ref>. However, this work seeks to unify only improvement-enabling transformations such as skewing, interchange, and reversal, and does not consider locality and parallelism in concert. Carr [6] studies criteria to guide locality and instruction level parallelism in concert via unroll-and-jam. <p> As the length of the longest dependent chain is a function of the shape of the iteration space, a hierarchical strategy may define shorter dependence chains. So, in choosing tile shapes and sizes for each level independently, previous work such as <ref> [29, 13] </ref> misses out on an opportunity for performance gains. Our preliminary findings indicate that tiling for multiple levels of parallelism can indeed improve performance; for PDE-like codes on an SGI Cray Origin one can achieve a speedup of 10% over level-at-a-time parallelization. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [30] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-471, </pages> <year> 1991. </year>
Reference-contexts: Optimizations are often aimed towards the improved performance of a given level of this processor-memory hierarchy. For example, data locality optimizations [29, 7, 9, 8] may be directed to a specific level of memory, such as registers, or a specific level of cache. Transformations to enhance parallelism <ref> [3, 30, 14, 20, 24] </ref> are directed towards a specific level of parallelism such as multiple functional units, or multiprocessors. <p> Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> We show in this paper that a cache-specific cost function and ILP-specific cost function to determine tiling do not lead to as good performance as considering both levels in concert. Unimodular transformations provide a means to guide loop transformations for parallelism <ref> [30] </ref> and locality [29]. However, this work seeks to unify only improvement-enabling transformations such as skewing, interchange, and reversal, and does not consider locality and parallelism in concert. Carr [6] studies criteria to guide locality and instruction level parallelism in concert via unroll-and-jam. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [31] <author> Michael E. Wolf, Dror Maydan, and Ding kai Chen. </author> <title> Combining loop transformations considering caches and scheduling. </title> <booktitle> In Proceedings of the 29th International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: One approach to controlling the interactions different from ours is that of Wang and Gannon [28], who use AI search techniques on a decision tree of possible optimizations to find a good sequence of transformations to parallelize a given program. The work in <ref> [31] </ref> acknowledges that optimizations are interdependent, and give a pruned search procedure through the possible transformation space. However, they argue it is reasonable to separate cache-level optimization with 2 We consider tiling for the faster levels of the memory hierarchy, those at or below main memory. <p> Factors such as the associativity of the TLB and the alignment of the matrix can influence whether A remains resident; the determination of these factors is beyond the scope of this paper. Instead, like <ref> [31] </ref>, we use the estimated effective cache size. In this case we assume that the A submatrix will reside in the TLB with the assumption E t (H; W ) :75C t .
Reference: [32] <author> Michael J. Wolfe. </author> <title> Iteration space tiling for memory hierarchies. </title> <booktitle> In Parallel Processing for Scientific Computing, </booktitle> <pages> pages 357-361, </pages> <year> 1987. </year>
Reference-contexts: However, there is no assurance that the locally optimal choices will be globally optimal. In this paper, we present evidence to support the case that * Level-specific cost functions may not lead to the globally optimal choice. We show that for the tiling transformation <ref> [32, 29] </ref>, a level-specific tiling at a single level can lead to a globally suboptimal choice. <p> Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
Reference: [33] <author> Michael J. Wolfe. </author> <title> More iteration space tiling. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <pages> pages 655-664, </pages> <year> 1989. </year> <month> 15 </month>
Reference-contexts: Figure 2 shows the ISG for naive three-loop matrix multiplication and Figure 3 shows the loop nest for the tiled program. The loop nest gives an order for executing the nodes of the ISG. Tiling <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref> can improve both data locality and parallel execution time. <p> However, on the uppermost level of the memory hierarchy we let the tile height, h 3 , vary while minimizing the total idle time, and, as we show, the total execution time. Next we need to decide the shape of the tile. Standard tiling approaches <ref> [16, 19, 32, 33, 23, 26, 29, 30, 5, 21] </ref>, when tiling at two levels, consider the information at each level separately and ignore potential interactions between the levels. Using these approaches, the locally optimal tile shapes and iteration space shapes in this example would be rectangular.
References-found: 32

