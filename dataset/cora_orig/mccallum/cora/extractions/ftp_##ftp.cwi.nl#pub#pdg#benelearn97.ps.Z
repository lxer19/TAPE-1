URL: ftp://ftp.cwi.nl/pub/pdg/benelearn97.ps.Z
Refering-URL: http://www.cwi.nl/~pdg/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Phone: 26,  
Title: On Predictive Distributions and Bayesian Networks  
Author: Petri Kontkanen, Petri Myllymaki, Tomi Silander, Henry Tirri Peter Grunwald 
Address: P.O.Box  FIN-00014 University of Helsinki, Finland  P.O. Box 94079, NL-1090 GB Amsterdam, The Netherlands  
Affiliation: Complex Systems Computation Group (CoSCo)  Department of Computer Science  CWI, Department of Algorithms and Architectures  
Abstract: We study discrete prediction problems for a decision-theoretic setting, where the task is to compute the predictive distribution for a finite set of possible alternatives. We consider two Bayesian and two information-theoretic approaches for arriving at a predictive distribution on the basis of a parametric model class. The information theoretic approaches are based on Rissanen's renewed definition of stochastic complexity. We describe how the four predictive inference methods can be realized in the case of Bayesian networks, which involves computing Jeffrey's prior for Bayesian Networks. We experimentally compare the four approaches on the restricted Naive Bayes model. Our experiments on several public domain classification datasets show that the two most sophisticated approaches perform surprisingly well even if only a very small amount of training data is available.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.O. Berger. </author> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Here P evj is just P ev as defined in eq. 4 with the prior instantiated to Jeffrey's Prior (fi) which is defined as (fi) = jI (fi)j 1=2 = R jI ()j 1=2 d. jI (fi)j is the determinant of the Fisher information matrix <ref> [1] </ref> I (fi). <p> Furthermore, all the conditional distributions of the variables given their parents are assumed to be multinomial, i.e., X ijq i ~ Multi (1; i q i 1 ; : : : ; i q i n i ). Since the family of Dirichlet densities is conjugate (see e.g. <ref> [1] </ref>) to the family of multinomials, i.e. the functional form of parameter distribution remains invariant in the prior-to-posterior transformation, we assume that the prior distributions of the parameters are from this family.
Reference: [2] <author> G. Cooper and E. Herskovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347, </pages> <year> 1992. </year>
Reference-contexts: In section 3 we instantiate our four methods for the case that the model class M consists of all Bayesian networks of a certain arbitrary but fixed structure. For the two Bayesian approaches, this instantiation has been done before <ref> [2, 4] </ref>. Our own contribution in this section is to derive explicit formulas for the information-theoretic approaches when applied to Bayesian networks. This involves computing the Fisher (expected) information matrix for Bayesian networks. <p> Having now defined the prior distribution, we can derive explicit formulas for the predictive distributions P map (3) and P ev (4). Since this has been done before <ref> [2, 4] </ref> we will omit this here and focus on our own contribution: we will first give an explicit formula for the Bayesian Network instantiation of P sc (6). We will then show how to compute Jeffrey's prior as needed for P evj .
Reference: [3] <author> G.F. Cooper. </author> <title> The computational complexity of probabilistic inference using Bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):393-405, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Unfortunately, for multi-connected Bayesian networks, this problem is known to be NP-hard <ref> [3] </ref>.
Reference: [4] <author> D. Heckerman, D. Geiger, </author> <title> and D.M. Chickering. Learning Bayesian networks: The combination of knowledge and statistical data. </title> <journal> Machine Learning, </journal> <volume> 20(3) </volume> <pages> 197-243, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: In section 3 we instantiate our four methods for the case that the model class M consists of all Bayesian networks of a certain arbitrary but fixed structure. For the two Bayesian approaches, this instantiation has been done before <ref> [2, 4] </ref>. Our own contribution in this section is to derive explicit formulas for the information-theoretic approaches when applied to Bayesian networks. This involves computing the Fisher (expected) information matrix for Bayesian networks. <p> Having now defined the prior distribution, we can derive explicit formulas for the predictive distributions P map (3) and P ev (4). Since this has been done before <ref> [2, 4] </ref> we will omit this here and focus on our own contribution: we will first give an explicit formula for the Bayesian Network instantiation of P sc (6). We will then show how to compute Jeffrey's prior as needed for P evj .
Reference: [5] <author> P. Kontkanen, P. Myllymaki, T. Silander, H. Tirri, and P. Grunwald. </author> <title> Predictive distributions and bayesian networks. </title> <type> Technical Report NC-TR-97-032, Neurocolt Technical Report Series, </type> <year> 1997. </year> <note> Available at www.cs.rhbnc.ac.uk/ research/ compint/ neurocolt/. </note>
Reference-contexts: We can use P sc to arrive at a predictive distribution in two ways: Using P sc directly In <ref> [5] </ref> we show that by manipulating (5) one obtains: P sc ( ~ d j D) = P i.i.d P ( ~ d j ~ fi ( ~ d; D))P (D j ~ fi ( ~ d; D)) ~ d 0 P ( ~ d 0 j ~ fi ( ~ <p> We do not have this equality for P sc 1 . In <ref> [5] </ref> we discuss in detail how this may lead to potential problems when using P sc for prediction. <p> This suggests using P evj instead of P sc as a predictive distribution if the regularity conditions referred to above hold. In <ref> [5] </ref> we show that the conditions are satisfied for the subset of Bayesian network models used in our experiments (section 4). 3 Predictive Distributions for Bayesian Networks A Bayesian (belief) network [7, 10] is a representation of a probability distribution over a set of discrete variables, consisting of an acyclic directed <p> The P sc predictive distribution for Bayesian Networks We want to compute (2) for P sc . From (6) we see that it is proportional to the likelihood of the combined data set D + = D [ ~ d t at the maximum likelihood point. It follows <ref> [5] </ref> from (8) that we can write: P sc ( ~ d t j D) / P (D + j ~ fi (D + )) = i=1 q i =1 x i =1 q i x i ) ; where ~ i q i x i = (f i P n <p> Let us consider the element [I (fi)] r;s where (r; s) is the entry corresponding to i 1 q i 2 l 2 ). By deriving an explicit expression for log P ( ~ Xjfi) one can show that <ref> [5] </ref> if either the variable indices i 1 ; i 2 or the parent configurations q i 1 ; q i 2 are different, then [I (fi)] r;s = 0. If q i 1 = q i 2 and i 1 = i 2 one obtains after some calculations [5]: E <p> that <ref> [5] </ref> if either the variable indices i 1 ; i 2 or the parent configurations q i 1 ; q i 2 are different, then [I (fi)] r;s = 0. If q i 1 = q i 2 and i 1 = i 2 one obtains after some calculations [5]: E fi @ 2 log P ( ~ d j j fi) q i l ) 2 = i + I (l 1 ; l 2 ) i We now have an expression for each element of I (fi). <p> This allows us to calculate p jI (fi)j using a combination of several standard methods for calculating determinants <ref> [5] </ref>. <p> In this case, the Jeffrey's prior formula (9) can be written as a product of Dirichlet distributions <ref> [5] </ref>: reduces to fi ~ Di ( 2 m1 X (n i 1) + 1); : : : ; 2 m1 X (n i 1) + 1)) i=1 k=1 1 ; : : : ; 2 For our experiments with the Naive Bayes classifier, eight public domain classification data sets of <p> On the other hand, the MAP and SC methods appear to be much more sensitive to the amount of data available. In <ref> [5] </ref> we give a detailed discussion of the various reasons for the weak performance of the MAP and SC methods with small amounts of data. 5 Conclusion and Future Work We have described how to obtain predictive distributions by using different approximations for the problem domain probability distribution.
Reference: [6] <editor> D. Michie, D.J. Spiegelhalter, and C.C. Taylor, editors. </editor> <title> Machine Learning, Neural and Statistical Classification. </title> <publisher> Ellis Horwood, </publisher> <address> London, </address> <year> 1994. </year>
Reference-contexts: The prediction methods used are MAP (denoted here by M), EVU (E), EVJ (J), and SC (S). 4.1 Crossvalidation results In our crossvalidation experiments, we initially used with each of the datasets the same number of folds as in the major experimental comparison performed by the Statlog project <ref> [6] </ref> (the number of folds used in each case can be found in Table 1).
Reference: [7] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: In [5] we show that the conditions are satisfied for the subset of Bayesian network models used in our experiments (section 4). 3 Predictive Distributions for Bayesian Networks A Bayesian (belief) network <ref> [7, 10] </ref> is a representation of a probability distribution over a set of discrete variables, consisting of an acyclic directed graph, where the nodes correspond to domain variables X 1 ; : : : ; X m .
Reference: [8] <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific Publishing Company, </publisher> <address> New Jersey, </address> <year> 1989. </year>
Reference-contexts: In section 2 we consider four different ways of arriving at a P: two Bayesian approaches and two approaches based on the information theoretic notion of stochastic complexity (SC) <ref> [8, 9] </ref>. In section 3 we instantiate our four methods for the case that the model class M consists of all Bayesian networks of a certain arbitrary but fixed structure. For the two Bayesian approaches, this instantiation has been done before [2, 4]. <p> In this case, the predictive distribution (2) becomes P ev ( ~ d j D) = P ( ~ d j D; fi)P (fi)dfi: (4) 2.2 Information Theoretic Approaches: P sc and P evj Stochastic Complexity is a central notion in the theory of Minimum Description Length Inference <ref> [8, 9] </ref>. It is defined as follows [8]: the stochastic complexity S of a data set D relative to a class of models M is the code length of D when it is encoded using the shortest code obtainable with the help of the class M. <p> It is defined as follows <ref> [8] </ref>: the stochastic complexity S of a data set D relative to a class of models M is the code length of D when it is encoded using the shortest code obtainable with the help of the class M. <p> Here by `shortest code' one means the code that gives as short as possible a code length to all possible data sets D. It follows from the Kraft Inequality (see for example <ref> [8] </ref>) that the stochastic complexity S can be written as S = log P sc where P sc is some probability distribution. The definition above gives no explicit formula for the stochastic complexity. There are several reasons [8] of why log P ev (D) is a good candidate for the stochastic <p> It follows from the Kraft Inequality (see for example <ref> [8] </ref>) that the stochastic complexity S can be written as S = log P sc where P sc is some probability distribution. The definition above gives no explicit formula for the stochastic complexity. There are several reasons [8] of why log P ev (D) is a good candidate for the stochastic complexity. Therefore, Rissanen originally proposed it as its mathematical definition: S (D) = log P ev (D). <p> ~ fi ( ~ d 0 ; D)) P sc is defined with an emphasis on compression and not prediction; Indeed, in itself P sc is not well-suited for prediction, since it does not define a random process: each random process P must satisfy the compatibility condition (see for example <ref> [8] </ref>) P ~ d P ( ~ d; D) = P (D). We do not have this equality for P sc 1 . In [5] we discuss in detail how this may lead to potential problems when using P sc for prediction. <p> Approximating P sc by P evj On the other hand, we know from the theory of MDL estimation (e.g. the theorem in <ref> [8] </ref>) that for any distribution P that does define a random process, we have that the more it compresses, the better it predicts. This implies that in order to find a good predictive distribution, we should look for the random process that best approximates P sc .
Reference: [9] <author> J. Rissanen. </author> <title> Fisher information and stochastic complexity. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 42(1) </volume> <pages> 40-47, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: In section 2 we consider four different ways of arriving at a P: two Bayesian approaches and two approaches based on the information theoretic notion of stochastic complexity (SC) <ref> [8, 9] </ref>. In section 3 we instantiate our four methods for the case that the model class M consists of all Bayesian networks of a certain arbitrary but fixed structure. For the two Bayesian approaches, this instantiation has been done before [2, 4]. <p> In this case, the predictive distribution (2) becomes P ev ( ~ d j D) = P ( ~ d j D; fi)P (fi)dfi: (4) 2.2 Information Theoretic Approaches: P sc and P evj Stochastic Complexity is a central notion in the theory of Minimum Description Length Inference <ref> [8, 9] </ref>. It is defined as follows [8]: the stochastic complexity S of a data set D relative to a class of models M is the code length of D when it is encoded using the shortest code obtainable with the help of the class M. <p> The definition above gives no explicit formula for the stochastic complexity. There are several reasons [8] of why log P ev (D) is a good candidate for the stochastic complexity. Therefore, Rissanen originally proposed it as its mathematical definition: S (D) = log P ev (D). Recently, however, Rissanen <ref> [9] </ref> has shown that there exists a code that is itself not dependent on any prior distributions of parameters and which in general yields even shorter codelengths than the code with lengths log P ev (D). <p> This implies that in order to find a good predictive distribution, we should look for the random process that best approximates P sc . Now it can be shown (using some complicated mathematics) <ref> [9] </ref> that, under some regularity conditions on the model class M, for each fi 2 M, we have that with fi-probability one, log P sc (D) is equal to log P evj (D) to within 2 o (1). <p> The special thing about Jeffrey's prior is the o (1) in stead of the O (1). For small sample behaviour, this difference can be very relevant! <ref> [9] </ref> the following, we denote by I () the indicator function, i.e. I (a; b) = 1 if a = b and 0 otherwise.
Reference: [10] <author> R.D. Shachter. </author> <title> Probabilistic inference and influence diagrams. </title> <journal> Operations Research, </journal> <volume> 36(4) </volume> <pages> 589-604, </pages> <month> July-August </month> <year> 1988. </year>
Reference-contexts: In [5] we show that the conditions are satisfied for the subset of Bayesian network models used in our experiments (section 4). 3 Predictive Distributions for Bayesian Networks A Bayesian (belief) network <ref> [7, 10] </ref> is a representation of a probability distribution over a set of discrete variables, consisting of an acyclic directed graph, where the nodes correspond to domain variables X 1 ; : : : ; X m .
Reference: [11] <author> H. Tirri, P. Kontkanen, and P. Myllymaki. </author> <title> Probabilistic instance-based learning. </title> <editor> In L. Saitta, editor, </editor> <booktitle> Machine Learning: Proceedings of the Thirteenth International Conference, </booktitle> <pages> pages 507-515. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1996. </year>
Reference-contexts: In addition to comparison purposes between the different predictive distributions, the results in compared to the results reported in the machine learning literature (for references, see e.g., <ref> [11] </ref>).
References-found: 11

