URL: http://www.cs.princeton.edu/prism/papers-ps/jiang-sigmetrics98.ps
Refering-URL: http://www.cs.princeton.edu/prism/html/all-papers.html
Root-URL: http://www.cs.princeton.edu
Email: fdj, jpsg@cs.princeton.edu  
Title: A Methodology and an Evaluation of the SGI Origin2000  
Author: Dongming Jiang and Jaswinder Pal Singh 
Address: Princeton, NJ 08544  
Affiliation: Department of Computer Science Princeton University  
Abstract: As hardware-coherent, distributed shared memory (DSM) multiprocessing becomes popular commercially, it is important to evaluate modern realizations to understand how they perform and scale for a range of interesting applications and to identify the nature of the key bottlenecks. This paper evaluates the SGI Origin2000|the machine that perhaps has the most aggressive communication architecture of the recent cache-coherent offerings|and, in doing so, articulates a sound methodology for evaluating real systems. We examine data access and synchronization microbenchmarks; speedups for different application classes, problem sizes and scaling models; detailed interactions and time breakdowns using performance tools; and the impact of special hardware support. We find that overall the Origin appears to deliver on the promise of cache-coherent shared address space multiprocessing, at least at the 32-processor scale we examine. The machine is quite easy to program for performance and has fewer organizational problems than previous systems we have examined. However, some important trouble spots are also identified, especially related to contention that is apparently caused by engineering decisions to share resources among processors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal and et al. </author> <title> The mit alewife machine: Architecture and performance. </title> <booktitle> In Proceedings of the 22th International Symposium on Computer Architecuture, </booktitle> <pages> pages 2-13, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Research prototypes of hardware cache-coherent shared address space multiprocessors have been shown to deliver good performance on many applications at small to moderate scale <ref> [10, 15, 1, 4] </ref>. However, these studies were largely done either on simulated systems or on systems with slow processors that are quite dated.
Reference: [2] <author> G. Blelloch, C. Leiserson, and B. Maggs. </author> <title> A comparison of sorting algorithms for the connection machine cm-2. </title> <booktitle> In Sym posium on Parallel Algorithms and Architectures, </booktitle> <year> 1991. </year>
Reference-contexts: This is because other bottlenecks coexist that are not alleviated: e.g. TLB misses and contention at memory banks due to both local and incoming accesses in the large problems. Sample Sort: We also examine another sorting algorithm, sample sorting <ref> [2] </ref>, which alleviates the scattered writing pattern in Radix, but introduces extra computational complexity (more local sorting). Communication is still all-to-all, but it is performed through remote reads of contiguously allocated keys from other processors rather than scattered remote writes; spatial locality is much better, and TLB misses are alleviated.
Reference: [3] <author> C. C. Chen, J. P. Singh, W. Poland, and R. Altman. </author> <title> Paral lel protein structure determination in the presence of uncer tainty. </title> <booktitle> In Proceedings of Supercomputing'94, </booktitle> <year> 1994. </year>
Reference-contexts: In addition to several applications from SPLASH-2, we also examine a shear-warp volume renderer [7], a probabilistic inference method applied to disease diagnosis in medical networks [8] and a protein structure prediction application <ref> [3] </ref>. The last two are shown together in a single graph (Figure 10 (g)), with only single problem size of a real medical Bayesian network for the former. The problem sizes we choose are based on the methodology described in Section 4.1.2.
Reference: [4] <author> C. Holt, J. Singh, and J. Hennessy. </author> <title> Application and archi tectural bottlenecks in large scale distributed shared memory machines. </title> <booktitle> In Proceedings of the 23th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 134-145, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Research prototypes of hardware cache-coherent shared address space multiprocessors have been shown to deliver good performance on many applications at small to moderate scale <ref> [10, 15, 1, 4] </ref>. However, these studies were largely done either on simulated systems or on systems with slow processors that are quite dated. <p> The performance robustness of a machine to lack of optimization is important. In particular, three important levels of optimization are important to consider: algorithmic (partitioning), data structuring, and data layout, distribution and alignment <ref> [4, 6] </ref>. While our standard set consists of well-optimized applications, we discuss the impact of other versions as well. 4.1.2 Choosing Problem Sizes Having chosen a workload or parallel program, we have to choose a problem size. <p> FFT: FFT is more interesting. Figure 7 (a) shows that FFT does not scale well beyond 16 processors, even though it scaled very well to large processor counts in the previous simulation study of cache-coherent DSM machines <ref> [4] </ref>. Increasing problem size improves performance but not very quickly. Figure 7 (b) and (c) indicate that as expected it is the all-to-all matrix transpose phases that are the problem. <p> The remote to local latency ratio is aggressive (more so than in the simulation study), the Hub itself is hardwired and has relatively low occupancy <ref> [4] </ref>, and the network bandwidth (even bisection bandwidth for this size system) is very high. The tools and time breakdowns show that memory stall time is very imbalanced across processors while the frequency of cache misses is balanced, indicating that contention is the problem. <p> Prefetching helps more with silencing than without. The performance improvements obtained by silencing are very substantial and this "false" FFT finally achieves a very good speedup on 32 processors for this data set, especially when prefetching is used (much like the simulation results in <ref> [4] </ref> where processors did not share these resources). Performance improves with greater silencing, which indicates that the sharing of both Hubs and routers is a problem despite their aggressive bandwidth. <p> The all-to-all scattered communication also causes contention at the network interfaces, controller, and memory, exacerbated by the simultaneous bursty propagation of coherence messages like invalidations and acknowledgments. Prefetching does not have a noticeable impact on performance, since it does not help the permutation phase <ref> [4] </ref>. We use similar silencing experiments to those in FFT (Figure 8) for the permutation phase The resulting speedup (relative to the full uniprocessor sort) improves due to alleviation of contention at Hubs and routers, but not so much as in FFT (about 20% in the best case). <p> Most generally, of course, we would like to understand whether the promise of cache-coherent multiprocessing at larger scale shown through simulation <ref> [4] </ref> holds in aggressive, real machines as well. In general, evaluations that use simulation are much more difficult to be confident about (especially at larger scale where contention becomes even more significant).
Reference: [5] <author> C. Hristea. </author> <type> Personal communication. </type>
Reference-contexts: Both measure latency from processor issue till the first word of the block is returned to the processor. Similar results are reported independently in a recent microbenchmarking paper by other researchers <ref> [5] </ref>.
Reference: [6] <author> D. Jiang, H. Shan, and J. Singh. </author> <title> Application restructuring and performance portability on shared virtual memory and hardware-coherent multiprocessors. </title> <booktitle> In Proceedings of the 1997 ACM SIGPLAN Symposium on Principles and Prac tice of Parallel Programming, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: The performance robustness of a machine to lack of optimization is important. In particular, three important levels of optimization are important to consider: algorithmic (partitioning), data structuring, and data layout, distribution and alignment <ref> [4, 6] </ref>. While our standard set consists of well-optimized applications, we discuss the impact of other versions as well. 4.1.2 Choosing Problem Sizes Having chosen a workload or parallel program, we have to choose a problem size. <p> We also examined the impact of further optimizations to some of our applications, starting from our regular set, that were developed in the context of page-based software shared memory systems and are described in <ref> [6] </ref>. They were designed to combat systems with slow communication and large granularities, and their impact on this aggressive architecture are small at this scale. 5 Performance Under Time- and Memory-Constrained Scaling Now let us examine the impact of time-constrained and memory-constrained scaling for some applications on Ori-gin2000.
Reference: [7] <author> D. Jiang and J. Singh. </author> <title> Parallel shear-warp volume render ing on shared address space multiprocessors. </title> <booktitle> In Proceedings of the 1997 ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: In addition to several applications from SPLASH-2, we also examine a shear-warp volume renderer <ref> [7] </ref>, a probabilistic inference method applied to disease diagnosis in medical networks [8] and a protein structure prediction application [3]. The last two are shown together in a single graph (Figure 10 (g)), with only single problem size of a real medical Bayesian network for the former.
Reference: [8] <author> A. Kozlov and J. P. Singh. </author> <title> Parallel probabilistic inference on cache-coherent multiprocessors. Speical Issue of IEEE Com puters on Applications for Shared-Memory Multiprocessors, </title> <year> 1996. </year>
Reference-contexts: In addition to several applications from SPLASH-2, we also examine a shear-warp volume renderer [7], a probabilistic inference method applied to disease diagnosis in medical networks <ref> [8] </ref> and a protein structure prediction application [3]. The last two are shown together in a single graph (Figure 10 (g)), with only single problem size of a real medical Bayesian network for the former. The problem sizes we choose are based on the methodology described in Section 4.1.2.
Reference: [9] <author> J. Laudon and D. Lenoski. </author> <title> The sgi origin: A ccnuma highly scalable server. </title> <booktitle> In Proceedings of the 24th Annual Interna tional Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: As this style of multiprocessing becomes more popular commercially, it is important to evaluate modern realizations of these systems and to understand how they perform and scale for a range of interesting applications. The SGI Origin2000 <ref> [9] </ref> is a commercial CC-NUMA machine with fast, MIPS R10000 processors and an aggressive, scalable distributed shared memory (DSM) architecture. The question we are interested in here is whether a real modern system like the Origin2000 delivers on the promise of cache-coherent multiprocessing, even at moderate (here 32-processor) scale. <p> Finally, fairly simple synchronization algorithms seem to perform and scale quite well using the primitives provided, although evaluating synchronization raises interesting methodological questions. 2 SGI Origin2000 The SGI Origin2000 <ref> [9] </ref> is a scalable shared-memory multiprocessing architecture, as shown in Figure 1 (a). It provides global address spaces not only for memory, but also for the IO subsystem. <p> The two processors within a node do not function as a snoopy SMP cluster, but operate separately over the single multiplexed physical bus and are governed by the same, one-level directory protocol. Less snooping keeps both absolute memory latency and the ratio of remote to local latency low <ref> [9, 10] </ref>, and provides remote memory bandwidth equal to local memory bandwidth (780MB/s each) [9, 10, 11]. The two processors within a node share a hardwired coherence controller called the Hub that implements the directory based cache coherence protocol. <p> Less snooping keeps both absolute memory latency and the ratio of remote to local latency low [9, 10], and provides remote memory bandwidth equal to local memory bandwidth (780MB/s each) <ref> [9, 10, 11] </ref>. The two processors within a node share a hardwired coherence controller called the Hub that implements the directory based cache coherence protocol. <p> These are not described here <ref> [9] </ref>. processors) are connected to each router, and routers are connected by CrayLinks. With this configuration, the maximum number of hops between any two processors is three. <p> To alleviate the TLB shoot-down normally needed when migrating a page, Origin2000 incorporates hardware support in its protocol that allows it to delay invalidating the TLBs of processors from the time of the page migration itself until the time that processor accesses a cache line on that page again <ref> [9] </ref> 3 . As discussed 3 To migrate a page, the block transfer engine reads cache blocks earlier, it was difficult to find an application among our set in which data distribution was very important, given the large caches and aggressive communication architecture.
Reference: [10] <author> D. Lenoski, J. Laudon, T. Joe, D. Nakahira, L. Stevens, A. Gupta, and J. Hennessy. </author> <title> The DASH prototype: Imple mentation and performance. </title> <booktitle> In Proceedings of the 19th An nual International Symposium on Computer Architecture, </booktitle> <pages> pages 92-103, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Research prototypes of hardware cache-coherent shared address space multiprocessors have been shown to deliver good performance on many applications at small to moderate scale <ref> [10, 15, 1, 4] </ref>. However, these studies were largely done either on simulated systems or on systems with slow processors that are quite dated. <p> The two processors within a node do not function as a snoopy SMP cluster, but operate separately over the single multiplexed physical bus and are governed by the same, one-level directory protocol. Less snooping keeps both absolute memory latency and the ratio of remote to local latency low <ref> [9, 10] </ref>, and provides remote memory bandwidth equal to local memory bandwidth (780MB/s each) [9, 10, 11]. The two processors within a node share a hardwired coherence controller called the Hub that implements the directory based cache coherence protocol. <p> Less snooping keeps both absolute memory latency and the ratio of remote to local latency low [9, 10], and provides remote memory bandwidth equal to local memory bandwidth (780MB/s each) <ref> [9, 10, 11] </ref>. The two processors within a node share a hardwired coherence controller called the Hub that implements the directory based cache coherence protocol. <p> However, with this representation, the square-shaped (sub-block) partition of each processor is not allocated contiguously in memory (the row-wise partition is naturally contiguous even with a 2-d array [15]). The 4-d array is a more optimized alternative to make square-shaped partition contiguous <ref> [10] </ref>, but is much more difficult to code for near-neighbor calculations. Figure 5 shows the speedups for SOR with different combinations of partition shapes, data structures, problem sizes, and page placement policies. refer to 2-d and 4-d array grid implementation. ROW refers to row-wise partitioning method in 2-d grid implementation.
Reference: [11] <author> T. Lovertt and R. Clapp. Sting: </author> <title> A cc-numa computer sys tem for the commercial marketplace. </title> <booktitle> In Proceedings of the 23rd Annual International Symposium on Computer Archi tecture, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Less snooping keeps both absolute memory latency and the ratio of remote to local latency low [9, 10], and provides remote memory bandwidth equal to local memory bandwidth (780MB/s each) <ref> [9, 10, 11] </ref>. The two processors within a node share a hardwired coherence controller called the Hub that implements the directory based cache coherence protocol.
Reference: [12] <author> J. M. Mellor-Crummey and M. L. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiproces sors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: We implement well-known lock and barrier algorithms (see for example <ref> [12] </ref>) using both fetch-and-op and LL/SC, and measure their performance on this machine. The measurements here are on a much more modern system with quite different communication to processing ratios than previously reported [12], the primitives used are newer and different, and this is perhaps the first time results are reported <p> We implement well-known lock and barrier algorithms (see for example <ref> [12] </ref>) using both fetch-and-op and LL/SC, and measure their performance on this machine. The measurements here are on a much more modern system with quite different communication to processing ratios than previously reported [12], the primitives used are newer and different, and this is perhaps the first time results are reported for a cache-coherent machine with physically distributed memory. <p> Fop-uncached-spin spins on an uncached location while Fop-cached-spin spins on a cacheable variable, but they both try to access the lock using a fetch-and-op. All others are implemented using the LL/SC primitive. The lock algorithms are well known <ref> [12] </ref>, so we do not explain them. In particular, the queuing locks are the software MCS locks, and Exp and Prop refer to exponential and proportional backoff respectively.
Reference: [13] <author> E. Rothberg, J. P. Singh, and A. Gupta. </author> <title> Working sets, cache sizes, and node granularity issues for large-scale multiproces sors. </title> <booktitle> In Proceedings of the 20th Annual International Sym posium on Computer Architecture, </booktitle> <pages> pages 14-25, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: While data distribution made a big difference for this application on the Stanford DASH machine [15] where caches were smaller and four processors shared a coherent bus, it is not important here even for a 16M-point FFT because the caches are big enough to hold the important working set (see <ref> [13] </ref> for working set sizes) and inherent communication dominates. The transpose in FFT is blocked to obtain reuse of remotely fetched cache blocks.
Reference: [14] <author> J. Singh, A. Gupta, and J. Hennessy. </author> <title> Scaling parallel programs for multiprocessors: Methodology and examples. </title> <booktitle> IEEE Computer, </booktitle> <year> 1994. </year>
Reference-contexts: Origin has a fast enough processor and node, and our goal is not to compare with the absolute performance of other processors. As the number of processors changes, we need a scaling model under which to scale the problem size <ref> [17, 14] </ref>. We use the three major models, which may each be applicable in different circumstances: problem constrained (PC) or constant problem size scaling, time constrained (TC) scaling, and memory constrained (MC) scaling. <p> From (1), speedup can be measured as the increase in the useful work done during that fixed ex ecution time Speedup (p) = Work (p) / Work (1). * Memory-constrained scaling (MC) Here neither work nor time remains fixed (in fact, both can increase dramatically as discussed in <ref> [14] </ref>). We must therefore resort to the full expression in (1), so Speedup (p) = In crease in Work Done / Increase in Time Taken. <p> size of main memory (8GB) constrains the TC and MC experiments to 16 processors but not beyond. "Naive" TC and MC refers to scaling on the number of particles (n) without changing other application parameters, while TC and MC refers to scaling with changing all application parameters that matter realistically <ref> [14] </ref>. <p> computation radio and load balance, we expect speedups to be best under MC scaling, since these properties usually depend mostly on data set size per processor which remains about constant under this model. (Note that MC scaling is often unrealistic in its execution time requirements, including for Barnes and Ocean <ref> [14] </ref>). Interactions with page and cache line granular-ities (spatial locality) also do not degrade with scaling in this case.
Reference: [15] <author> J. Singh, T. Joe, J. Hennessy, and A. Gupta. </author> <title> An empirical comparison of the ksr-1 allcache and stanford dash multipro cessors. </title> <booktitle> In Supercomputing '93, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Research prototypes of hardware cache-coherent shared address space multiprocessors have been shown to deliver good performance on many applications at small to moderate scale <ref> [10, 15, 1, 4] </ref>. However, these studies were largely done either on simulated systems or on systems with slow processors that are quite dated. <p> The grid is naturally implemented as a 2-d array. However, with this representation, the square-shaped (sub-block) partition of each processor is not allocated contiguously in memory (the row-wise partition is naturally contiguous even with a 2-d array <ref> [15] </ref>). The 4-d array is a more optimized alternative to make square-shaped partition contiguous [10], but is much more difficult to code for near-neighbor calculations. <p> Since capacity misses also decrease on more processors, the 4-d and row-wise versions with data distribution yield super-linear speedups beyond 8 processors. More interestingly, however, the benefits of data distribution are not nearly so large as in some previous machines studied <ref> [15] </ref>. This is because of the large caches, the very low-latency communication archi-tecture, and the fact that contention does not occur in this case. <p> While data distribution made a big difference for this application on the Stanford DASH machine <ref> [15] </ref> where caches were smaller and four processors shared a coherent bus, it is not important here even for a 16M-point FFT because the caches are big enough to hold the important working set (see [13] for working set sizes) and inherent communication dominates. <p> This is fortunate, because it can often be difficult to perform data distribution well at 16KB page granularity, especially for irregular applications. Even in the examples where data distribution is important (e.g. a very large SOR), unlike on previously studies machines <ref> [15] </ref> not distributing data does not destroy performance. The aggressive communication architecture is a great help here: there is little contention in this case, and the problem is simply remote access latency which is kept very low relative to local latency as discussed earlier.
Reference: [16] <author> J. P. Singh, C. Holt, T. Totsuka, A. Gupta, and J. Hennessy. </author> <title> Load balancing and data locality in adaptive hierarhcical n body methods: Barnes-hut, fast multipole, and radiosity. </title> <booktitle> Parallel and Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: Two major optimization levels, algorithmic and data structuring, are examined. The static algorithm in Barnes (Figure 11 (a)) simply assigns particles to processors round-robin rather than computing good partitions dynamically <ref> [16] </ref>. Load balance works out okay due to randomization, but the big impact is on communication. Nonetheless, communication volume is still small, the machine is good at low-latency fine-grained communication, and there is little contention, so the difference between versions is not very large at this scale.
Reference: [17] <author> X. Sun and L. Ni. </author> <title> Scalable problems and memory-bounded speedup. </title> <journal> Parallel and Distributed Computing, </journal> <volume> 19 </volume> <pages> 27-37, </pages> <year> 1993. </year>
Reference-contexts: Origin has a fast enough processor and node, and our goal is not to compare with the absolute performance of other processors. As the number of processors changes, we need a scaling model under which to scale the problem size <ref> [17, 14] </ref>. We use the three major models, which may each be applicable in different circumstances: problem constrained (PC) or constant problem size scaling, time constrained (TC) scaling, and memory constrained (MC) scaling.
Reference: [18] <author> S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. </author> <title> The splash-2 programs: Characterization and methodologi cal considerations. </title> <booktitle> In Proceedings of the 22th Annual Inter national Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: In the course of performing our evaluation in this paper, we also articulate a methodology for evaluating a real system and illustrate some of the important issues. Some key issues in the complementary problem|choosing machine parameters given a set of application parameters for a simulation study|were discussed in <ref> [18] </ref>. We begin by briefly describing the memory and communication architecture of the Origin2000 in Section 2. We then isolate the basic performance characteristics of data access and synchronization in the machine, using microbench-marks, including comparing different synchronization algorithms and primitives (Section 3). <p> applications, most of which are from the SPLASH-2 suite, which were chosen to cover a wide range of behavioral properties for cache-coherent DSMs: regular and irregular access patterns, local and remote memory accesses, static and dynamic load balancing, localized and long-range communication patterns, and small and large working sets (see <ref> [18] </ref> for details on most of the applications). Even the three kernels we choose range from localized near-neighbor communication (SOR) to all-to-all regular communication (FFT) to all-to-all irregular communication (Radix sorting). <p> The algorithmic (PRAM) speedups with some small problem sizes for most of our programs can be found in <ref> [18] </ref> and are adequate (they assume data access and communication are free, and measure only computational load imbalance and serialization as well as extra work done in the parallel program). <p> We do so in this paper, based on known application characteristics as in <ref> [18] </ref>. <p> One general reason is the larger parameter space since both application and machine parameters (organization and performance) may be variable. Some guidelines for dealing with the space can be found in <ref> [18] </ref>, and several are fundamentally similar or complementary to the ones articulated here.
Reference: [19] <author> M. Zagha, B. Larson, S. Turner, and M. Itzkowitz. </author> <title> Perfor mance analysis using the mips r10000 performance counters. </title> <booktitle> In Supercomputing'96, </booktitle> <year> 1996. </year>
Reference-contexts: We use various types of per-process in strumentation and the hardware performance (frequency) counters <ref> [19] </ref> to obtain insights into runtime behavior. 4.3.1 Computational Kernels We first examine computational kernels, since they have relatively clean access patterns and are easier to understand. SOR: The SOR kernel iterates over a two-dimensional grid, and computes every grid point as the average of its nearest neighbors.
References-found: 19

