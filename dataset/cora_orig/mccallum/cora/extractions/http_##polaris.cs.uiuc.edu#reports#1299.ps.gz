URL: http://polaris.cs.uiuc.edu/reports/1299.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Generalized Iteration Space and the Parallelization of Symbolic Programs (Extended Abstract)  
Author: Luddy Harrison 
Date: October 15, 1991  
Abstract: A large body of literature has developed concerning the automatic parallelization of numerical programs, and a quite separate literature has developed concerning the parallelization of symbolic programs. Because many symbolic programs make heavy use of array data and iterative constructs, in addition to more "symbolic" language features like pointers and recursion, it is desirable to fuse these bodies of work so that results developed for numerical programs can be applied to symbolic ones, and generalized so that they apply to the variety of language constructs encountered in symbolic computations. In this paper is described a framework, called generalized iteration space, that allows one to unify dependence analysis of array computations with dependence analysis of pointer computations. It is shown that subscripted array accesses as well as pointer dereferences can be seen as linear functions of generalized iteration space. We are applying this framework to the automatic parallelization of C and Lisp programs in two parallelizing compilers at CSRD, called Parcel [Har89] and Miprac [HA89]. 
Abstract-found: 1
Intro-found: 1
Reference: [Ban79] <author> Uptal D. Banerjee. </author> <title> Speedup of Ordinary Programs. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1979. </year>
Reference-contexts: If this is unacceptably expensive, then an approximation to linear programming, like Banerjee's test <ref> [Ban79] </ref>, can be applied instead (at the cost of some precision). This has been a most dreadful compression of a very lively area of research.
Reference: [Ban86] <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1986. </year>
Reference-contexts: If this is unacceptably expensive, then an approximation to linear programming, like Banerjee's test [Ban79], can be applied instead (at the cost of some precision). This has been a most dreadful compression of a very lively area of research. For a complete treatment, the reader is urged to see <ref> [Ban86] </ref>, [ZC90], [PW86], [TIF86], [Wol82]. 2 Iteration Space = Time Consider a program that consists of a single nest of n do loops.
Reference: [CWZ90] <author> David R. Chase, Mark Wegman, and F. Kenneth Zadeck. </author> <title> Analysis of pointers and structures. </title> <booktitle> In ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310, </pages> <year> 1990. </year>
Reference: [Gua87] <author> Vincent Antony Guarna. </author> <title> Analysis of c programs for parallelization in the presence of pointers. </title> <type> Technical Report 695, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1987. </year>
Reference: [HA89] <author> W.L. Harrison III and Z. Ammarguellat. </author> <title> The design of parallelizers for symbolic and numeric programs. </title> <editor> In Takayasu Ito and Robert Halstead, editors, </editor> <booktitle> Parallel Lisp: Languages and Systems (US/Japan Workshop on Parallel Lisp, Sendai, </booktitle> <address> Japan, </address> <month> June </month> <year> 1989), </year> <pages> pages 235-253. </pages> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1989. </year> <note> Lecture Notes in Computer Science #441. </note>
Reference: [Har89] <author> W.L. Harrison III. </author> <title> The interprocedural analysis and automatic par-allelization of scheme programs. Lisp and Symbolic Computation: </title> <journal> an International Journal, </journal> 2(3/4):179-396, 1989. Generalized Iteration Space <volume> 12 </volume>
Reference-contexts: This is not a problem, as long as we are mindful of the fact, but it is also easy to remedy this by using call sites rather than procedures as the control flow points that represented by elements of the iteration vector j. See also <ref> [Har89] </ref> for a different notion of interprocedural time, that gives rise to unique names for points during the execution. Generalized Iteration Space 7 5 Generalized Induction Variables A do loop has two aspects: repetitive control flow and an index variable that is a linear function of the control flow.
Reference: [Har91] <author> W.L. Harrison III. </author> <title> Pointers, procedures and parallelization. Technical Report (Work In Progress), </title> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> Oc-tober </month> <year> 1991. </year>
Reference-contexts: A complete comparison of the dependence analysis used in Miprac to other methods for analyzing symbolic programs (e.g., [LH88],[HN90],[Gua87],[CWZ90]) can't be given here since the dependence analysis algorithm used in Miprac has not been presented completely here. The interested reader may obtain <ref> [Har91] </ref> which contains a lengthy comparison of Miprac's methods to other research in the parallelization of symbolic programs. Generalized Iteration Space 11 10 Conclusion It is possible to generalize the notion of iteration space and linear memory access so that they apply usefully to the dependence testing of symbolic programs.
Reference: [HN90] <author> L. Hendren and A. Nicolau. </author> <title> Parallelizing programs with recursive data structures. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <month> January </month> <year> 1990. </year>
Reference: [LH88] <author> J. Larus and P. N. Hilfinger. </author> <title> Restructuring lisp programs for concurrent execution (summary). </title> <booktitle> In Conference Record of the ACM SIGPLAN Symposium on Parallel Programming, </booktitle> <year> 1988. </year>
Reference: [PW86] <author> D.A. Padua and M. J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM, </journal> <volume> 29(12), </volume> <month> December </month> <year> 1986. </year>
Reference-contexts: This has been a most dreadful compression of a very lively area of research. For a complete treatment, the reader is urged to see [Ban86], [ZC90], <ref> [PW86] </ref>, [TIF86], [Wol82]. 2 Iteration Space = Time Consider a program that consists of a single nest of n do loops. A vector i that denotes a particular setting of the index variables of the loops, defines a point in a multidimensional space (n dimensions), called the iteration space.
Reference: [TIF86] <author> Remi J. Triolet, Francois Irigoin, and Paul Feautrier. </author> <title> Direct par-allelization of call statements. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <pages> pages 176-185, </pages> <year> 1986. </year>
Reference-contexts: This has been a most dreadful compression of a very lively area of research. For a complete treatment, the reader is urged to see [Ban86], [ZC90], [PW86], <ref> [TIF86] </ref>, [Wol82]. 2 Iteration Space = Time Consider a program that consists of a single nest of n do loops. A vector i that denotes a particular setting of the index variables of the loops, defines a point in a multidimensional space (n dimensions), called the iteration space.
Reference: [Wol82] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1982. </year>
Reference-contexts: This has been a most dreadful compression of a very lively area of research. For a complete treatment, the reader is urged to see [Ban86], [ZC90], [PW86], [TIF86], <ref> [Wol82] </ref>. 2 Iteration Space = Time Consider a program that consists of a single nest of n do loops. A vector i that denotes a particular setting of the index variables of the loops, defines a point in a multidimensional space (n dimensions), called the iteration space.
Reference: [ZC90] <author> Hans Zima and Barbara Chapman. </author> <title> Supercompilers for Parallel and Vector Supercomputers. Frontier Series. </title> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference-contexts: This has been a most dreadful compression of a very lively area of research. For a complete treatment, the reader is urged to see [Ban86], <ref> [ZC90] </ref>, [PW86], [TIF86], [Wol82]. 2 Iteration Space = Time Consider a program that consists of a single nest of n do loops. A vector i that denotes a particular setting of the index variables of the loops, defines a point in a multidimensional space (n dimensions), called the iteration space.
References-found: 13

