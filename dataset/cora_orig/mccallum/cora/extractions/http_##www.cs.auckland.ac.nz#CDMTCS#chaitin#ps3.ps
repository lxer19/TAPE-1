URL: http://www.cs.auckland.ac.nz/CDMTCS/chaitin/ps3.ps
Refering-URL: http://www.cs.auckland.ac.nz/CDMTCS/chaitin/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: chaitin@watson.ibm.com  
Title: INFORMATION- THEORETIC INCOMPLETENESS  
Author: G. J. Chaitin 
Note: Published 1992 by World Scientific, Singapore  
Address: O Box 704 Yorktown Heights, NY 10598  
Affiliation: IBM, P  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> G. J. Chaitin, </author> <title> "On the length of programs for computing finite binary sequences," </title> <journal> Journal of the ACM 13 (1966), </journal> <pages> 547-569. </pages>
Reference-contexts: We also construct a Turing machine "halting probability" tm with the property that the initial segments of its base-two expansion asymptotically have the maximum possible Turing machine complexity H tm . 1. Turing Machine Complexity H tm Following <ref> [1] </ref>, consider Turing machines with a single one-way infinite tape (infinite to the right), a single read-write scanner, and a tape-symbol alphabet consisting of blank, 0 and 1. Such an n-state 3-tape-symbol Turing machine is defined by a 3 fi n table. <p> the smallest n-state 3-tape-symbol Turing machine that starts with the scanner at the beginning of a blank tape and halts with s written at the beginning of the tape, with the rest of the tape blank, and with the scanner on the first blank square of the tape. 1 In <ref> [1] </ref> it is shown that the maximum possible Turing machine complexity H tm (s) of an n-bit string s is asymptotic to n=2 log 2 n. Furthermore, most n-bit strings s have Turing machine complexity close to n=2 log 2 n. <p> Furthermore, most n-bit strings s have Turing machine complexity close to n=2 log 2 n. Equivalently, most 2n log 2 n bit strings have Turing machine complexity close to n. Moreover, it is proposed in <ref> [1] </ref> that such strings are "random"; for example, it is shown that in the limit of large n such s have exactly the same relative frequency of 0's and 1's.
Reference: [2] <author> G. J. Chaitin, </author> <title> "On the length of programs for computing finite binary sequences: statistical considerations," </title> <journal> Journal of the ACM 16 (1969), </journal> <pages> 145-159. </pages>
Reference-contexts: Moreover, it is proposed in [1] that such strings are "random"; for example, it is shown that in the limit of large n such s have exactly the same relative frequency of 0's and 1's. The sequel <ref> [2] </ref> considers random infinite bit strings and laboriously constructs an example, i.e., a specific infinite string whose initial n-bit segments have Turing machine complexity close to the maximum possible, which is n=2 log 2 n. <p> Thus tm is a Turing-machine-random bit string and therefore a normal real number in Borel's sense. The construction of a complex infinite string presented in this section is much better than our original approach in <ref> [2, Section 7] </ref>. The description in this section is very concise. For more details, see the analogous discussion for LISP in [3, Sections 4, 7 and 9]. 3.
Reference: [3] <author> G. J. Chaitin, </author> <title> "LISP program-size complexity II," </title> <journal> Applied Mathematics and Computation, </journal> <note> in press. </note>
Reference-contexts: The construction of a complex infinite string presented in this section is much better than our original approach in [2, Section 7]. The description in this section is very concise. For more details, see the analogous discussion for LISP in <ref> [3, Sections 4, 7 and 9] </ref>. 3. Proving Lower Bounds on H tm We will measure the complexity of a formal system by the number of states needed for a proof-checker. <p> Thus an n-state formal system cannot establish that a specific bit string has complexity &gt; n + c 0 + blog 2 (n + c 0 )c + c = n + O (log n): Q.E.D. It is much easier to formulate this information-theoretic incompleteness theorem in LISP <ref> [3, Section 3] </ref>. The LISP result is also much sharper.
Reference: [4] <author> G. J. Chaitin, </author> <title> "Computational complexity and Godel's incompleteness theorem," Abstract 70T-E35, </title> <journal> AMS Notices 17 (1970), </journal> <volume> 672. </volume>
Reference-contexts: At most one bit is added to its size in the unlikely event that overflow occurs (i.e., a carry out of the left-most non-zero bit position). History: This was my very first information-theoretic incompleteness theorem <ref> [4, 5] </ref>. The only difference is that here I spell out all the inequalities. 4. Proving Lower Bounds II Here is an arrangement of the proof that avoids the messy inequalities. Proof (Improved Version): Suppose we are given an n-state Turing machine for checking purported proofs in a formal system.

Reference: [1] <author> G. J. Chaitin, </author> <title> "Information-theoretic computational complexity," </title> <journal> IEEE Transactions on Information Theory IT-20 (1974), </journal> <pages> 10-15. </pages>
Reference-contexts: We also construct a Turing machine "halting probability" tm with the property that the initial segments of its base-two expansion asymptotically have the maximum possible Turing machine complexity H tm . 1. Turing Machine Complexity H tm Following <ref> [1] </ref>, consider Turing machines with a single one-way infinite tape (infinite to the right), a single read-write scanner, and a tape-symbol alphabet consisting of blank, 0 and 1. Such an n-state 3-tape-symbol Turing machine is defined by a 3 fi n table. <p> the smallest n-state 3-tape-symbol Turing machine that starts with the scanner at the beginning of a blank tape and halts with s written at the beginning of the tape, with the rest of the tape blank, and with the scanner on the first blank square of the tape. 1 In <ref> [1] </ref> it is shown that the maximum possible Turing machine complexity H tm (s) of an n-bit string s is asymptotic to n=2 log 2 n. Furthermore, most n-bit strings s have Turing machine complexity close to n=2 log 2 n. <p> Furthermore, most n-bit strings s have Turing machine complexity close to n=2 log 2 n. Equivalently, most 2n log 2 n bit strings have Turing machine complexity close to n. Moreover, it is proposed in <ref> [1] </ref> that such strings are "random"; for example, it is shown that in the limit of large n such s have exactly the same relative frequency of 0's and 1's.
Reference: [2] <author> G. J. Chaitin, </author> <title> "LISP program-size complexity II," </title> <journal> Applied Mathematics and Computation, </journal> <note> in press. </note>
Reference-contexts: Moreover, it is proposed in [1] that such strings are "random"; for example, it is shown that in the limit of large n such s have exactly the same relative frequency of 0's and 1's. The sequel <ref> [2] </ref> considers random infinite bit strings and laboriously constructs an example, i.e., a specific infinite string whose initial n-bit segments have Turing machine complexity close to the maximum possible, which is n=2 log 2 n. <p> Thus tm is a Turing-machine-random bit string and therefore a normal real number in Borel's sense. The construction of a complex infinite string presented in this section is much better than our original approach in <ref> [2, Section 7] </ref>. The description in this section is very concise. For more details, see the analogous discussion for LISP in [3, Sections 4, 7 and 9]. 3.
Reference: [3] <author> G. J. Chaitin, </author> <title> "Information-theoretic limitations of formal systems," </title> <journal> Journal of the ACM 21 (1974), </journal> <month> 403-424. </month> <title> 2 This view is strongly supported by the incompleteness theorems in [5], which use self-delimiting e-complexity instead of blank-endmarker e-complexity. Blank-Endmarker Programs 35 </title>
Reference-contexts: The construction of a complex infinite string presented in this section is much better than our original approach in [2, Section 7]. The description in this section is very concise. For more details, see the analogous discussion for LISP in <ref> [3, Sections 4, 7 and 9] </ref>. 3. Proving Lower Bounds on H tm We will measure the complexity of a formal system by the number of states needed for a proof-checker. <p> Thus an n-state formal system cannot establish that a specific bit string has complexity &gt; n + c 0 + blog 2 (n + c 0 )c + c = n + O (log n): Q.E.D. It is much easier to formulate this information-theoretic incompleteness theorem in LISP <ref> [3, Section 3] </ref>. The LISP result is also much sharper.
Reference: [4] <author> G. J. Chaitin, </author> <title> "Program size, oracles, and the jump operation," </title> <journal> Osaka Journal of Mathematics 14 (1977), </journal> <pages> 139-149. </pages>
Reference-contexts: At most one bit is added to its size in the unlikely event that overflow occurs (i.e., a carry out of the left-most non-zero bit position). History: This was my very first information-theoretic incompleteness theorem <ref> [4, 5] </ref>. The only difference is that here I spell out all the inequalities. 4. Proving Lower Bounds II Here is an arrangement of the proof that avoids the messy inequalities. Proof (Improved Version): Suppose we are given an n-state Turing machine for checking purported proofs in a formal system.

References-found: 8

