URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-319.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: Email: sourabh@media.mit.edu  
Title: Kinetic Occlusion  
Author: Sourabh A. Niyogi 
Address: Room E15-384,  20 Ames St., Cambridge, MA 02139  
Affiliation: Department of Electrical Engineering and Computer Science  The Media Laboratory Massachusetts Institute of Technology  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 319 S.M./E.E. Thesis, Department of Electrical Engineering and Computer Science Abstract Visual motion boundaries provide a powerful cue for perceptual organization of scenes. Motion boundaries are present when surfaces in motion occlude one another. Conventional approaches to motion analysis have relied on assumptions of data conservation and smoothness, which has made analysis of motion boundaries difficult. We show that a common source of motion boundary, kinetic occlusion, can be detected using spatiotemporal junction analysis. Junction analysis is accomplished by modeling kinetic occlusion as the multiplication of spatiotemporally oriented patterns. Using this model, we show that kinetic occlusion appears as locally oriented power in the frequency domain. Detecting kinetic occlusion is possible by detecting and isolating this locally oriented power. We provide an analysis of kinetic occlusion in one and two dimensional spatiotem-poral stimuli, and develop algorithms to detect it. Our algorithms are applied successfully on spatiotemporal stimuli containing occluding surfaces in motion.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. H. Adelson and J. R. Bergen. </author> <title> Spatiotemporal energy models for the perception of motion. </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 2 </volume> <pages> 284-299, </pages> <year> 1985. </year>
Reference-contexts: Spatiotemporally oriented filters allow one to selectively extract portions of the frequency domain so as to accomplish this task <ref> [1, 13, 36] </ref>. <p> Spatiotemporally oriented filters allow one to selectively extract portions of the frequency domain so as to accomplish this task [1, 13, 36]. Phase-invariant energy extraction is possible through usage of a quadrature pair of filters G (x) and H (x) tuned to orientation : <ref> [1, 10] </ref> E (x) = (I (x) fl G (x)) + (I (x) fl H (x)) (9) Multiple motions at each point in space-time x can be found by finding local peaks in E (x) as is varied. <p> In the spatial domain, a rightward moving plaid (i 1 (x; y) = sin (w x1a x + w y1a y + w t1a ) + sin (w x1b x + w y1b y + w t1b ), ~v 1 = <ref> [1; 0] </ref> T ) is occluded by another plaid moving leftward (i 2 (x; y) = sin (w x2a x + w y2a y + w t2a ) + sin (w x2b x + w y2b y + w t2b ), m = ~v 2 = [1; 0] T ). <p> ), ~v 1 = <ref> [1; 0] </ref> T ) is occluded by another plaid moving leftward (i 2 (x; y) = sin (w x2a x + w y2a y + w t2a ) + sin (w x2b x + w y2b y + w t2b ), m = ~v 2 = [1; 0] T ). Each plaid is composed of two sinu-soids whose normal motions are consistent with rightward and leftward motion respectively. <p> An example image sequence with two occluding surfaces is shown as a sliced XYT volume in Figure 18 (a); the occluded surface is moving to the left (~v 1 = <ref> [1; 0] </ref> T ) and the occluding surface is moving to the right (~v 2 = [1; 0] T ). The first order motion energy extracted for the two motions present, E ~v 1 (x) and E ~v 2 (x), are shown in Figure 18 (b,c). <p> An example image sequence with two occluding surfaces is shown as a sliced XYT volume in Figure 18 (a); the occluded surface is moving to the left (~v 1 = <ref> [1; 0] </ref> T ) and the occluding surface is moving to the right (~v 2 = [1; 0] T ). The first order motion energy extracted for the two motions present, E ~v 1 (x) and E ~v 2 (x), are shown in Figure 18 (b,c). <p> This is easily done by filtering local measures of first order orientation E ~v (x) with a linear filter Q ~v (x) via: R ~v (x) = E ~v (x) fl Q ~v (x) (25) where ^ Q ~v (w) = 0 for every ~w such that ~w <ref> [v x ; v y ; 1] </ref> T = 0, i.e. zero frequency response along the plane v x w x + v y w y + w t = 0. <p> Here, there are two dominant motions, ~v 1 = <ref> [1; 0] </ref> T and ~v 2 = [1; 0] T . (b) Two frames and an (x; t) slice of the stimulus. (c,d,e) First and second order orientation extracted for the occluded surface's velocity, ~v 1 . (f,g,h) First and second order orientation extracted for the occluding surface's velocity ~v 2 <p> Here, there are two dominant motions, ~v 1 = <ref> [1; 0] </ref> T and ~v 2 = [1; 0] T . (b) Two frames and an (x; t) slice of the stimulus. (c,d,e) First and second order orientation extracted for the occluded surface's velocity, ~v 1 . (f,g,h) First and second order orientation extracted for the occluding surface's velocity ~v 2 . (i) Response R (x) pooled across
Reference: [2] <author> J. R. Bergen, P. J. Burt, K. Hanna, R. Hingorani, and S. Peleg. </author> <title> A three-frame algorithm for estimating two-component image motion. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 14 </volume> <pages> 886-896, </pages> <year> 1992. </year>
Reference-contexts: Motion registra tion techniques where multiple transparent motions are estimated using global parametrized motion mod els have also been developed <ref> [2] </ref>. All of the above approaches pursue the goal of flow field estimation. Few have attempted to analyze kinetic occlusion directly. <p> Other recently developed global multiple motion estimation algorithms, e.g. <ref> [2, 18] </ref>, yield similar representations. We illustrate our approach on a simple example containing two moving surfaces. Figure 20 (a) depicts a random-dot stimulus where a rightward moving square occludes a leftward moving background.
Reference: [3] <author> M. J. Black and P. Anandan. </author> <title> Constraints for the early detection of discontinuity from motion. </title> <booktitle> In Proc. National Conf. on Artificial Intelligence, AAAI-90, </booktitle> <pages> pages 1060-1066, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: Motion estimation methods have been modified to be less sensitive to violations of underlying assumptions of smoothness and data conservation <ref> [3, 4, 31] </ref>. By discounting deviations from underlying assumptions, occlusions are viewed as an anomalous process that should be ignored. * Multiple motions globally.
Reference: [4] <author> M. J. Black and P. Anandan. </author> <title> A framework for the robust estimation of optical flow. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 231-236, </pages> <address> Berlin, Germany, </address> <year> 1993. </year>
Reference-contexts: Motion estimation methods have been modified to be less sensitive to violations of underlying assumptions of smoothness and data conservation <ref> [3, 4, 31] </ref>. By discounting deviations from underlying assumptions, occlusions are viewed as an anomalous process that should be ignored. * Multiple motions globally.
Reference: [5] <author> R. C. Bolles and H. H. Baker. </author> <title> Epipolar-plane image analysis: An approach to determining structure from motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(1) </volume> <pages> 7-56, </pages> <year> 1987. </year>
Reference-contexts: Motion registra tion techniques where multiple transparent motions are estimated using global parametrized motion mod els have also been developed [2]. All of the above approaches pursue the goal of flow field estimation. Few have attempted to analyze kinetic occlusion directly. Exceptions are Bolles and Baker <ref> [5] </ref>, who apply 3-d spatiotemporal edge detection to image sequences in order to link edges across space-time, and Zetsche et al [38], who suggest that occlusion can be detected via application of generic 3-d curvature operators directly to image sequences.
Reference: [6] <author> L. H. Finkel and P. Sajda. </author> <title> Object discrimination based on depth-from-occlusion. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 901-921, </pages> <year> 1992. </year>
Reference-contexts: And, by detecting motion boundaries, other visual modules may be aided: Motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis [14, 28], our module can be used for surface segregation processes <ref> [6, 7, 12, 15, 25] </ref>. In section 4, we analyze one-dimensional kinetic occlusion and develop techniques to analyze one-dimensional spatiotemporal stimuli. <p> With a detected ordinal cue to depth, we can determine the depth ordering of surfaces locally. Our detected occlusion can be used to activate direction of figure representations, as is done in the models of <ref> [6, 7, 15] </ref>. A global depth ordering of surfaces can also be attempted from these local cues (c.f. [35]). Furthermore, by discontinuing use of optical flow upon occlusion detection, and continuing use of optical flow upon disocclusion detection, we can potentially track surfaces through occlusion. <p> Multiplicative transparency, most commonly appearing as shadows, naturally fits into the model we adopt, and could be analyzed by similar or identical mechanisms. Most importantly, our current analysis is purely local; no spatiotemporal propagation has been attempted. Solutions to spatial contour completion <ref> [6, 12, 15, 25, 7, 37] </ref> are likely to be extendable to spatiotemporal surface completion. 8 Conclusion Motion estimation algorithms, relying on "constant intensity" and "single velocity" assumptions, have always had difficulty near motion boundaries. Providing a better model of motion boundaries is of paramount importance to two-dimensional motion analysis.
Reference: [7] <author> L. H. Finkel and P. Sajda. </author> <title> Constructing visual perception artificial vision systems reveal the rules of human visual processing. </title> <journal> American Scientist, </journal> <volume> 82(3) </volume> <pages> 224-237, </pages> <year> 1994. </year>
Reference-contexts: And, by detecting motion boundaries, other visual modules may be aided: Motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis [14, 28], our module can be used for surface segregation processes <ref> [6, 7, 12, 15, 25] </ref>. In section 4, we analyze one-dimensional kinetic occlusion and develop techniques to analyze one-dimensional spatiotemporal stimuli. <p> With a detected ordinal cue to depth, we can determine the depth ordering of surfaces locally. Our detected occlusion can be used to activate direction of figure representations, as is done in the models of <ref> [6, 7, 15] </ref>. A global depth ordering of surfaces can also be attempted from these local cues (c.f. [35]). Furthermore, by discontinuing use of optical flow upon occlusion detection, and continuing use of optical flow upon disocclusion detection, we can potentially track surfaces through occlusion. <p> Multiplicative transparency, most commonly appearing as shadows, naturally fits into the model we adopt, and could be analyzed by similar or identical mechanisms. Most importantly, our current analysis is purely local; no spatiotemporal propagation has been attempted. Solutions to spatial contour completion <ref> [6, 12, 15, 25, 7, 37] </ref> are likely to be extendable to spatiotemporal surface completion. 8 Conclusion Motion estimation algorithms, relying on "constant intensity" and "single velocity" assumptions, have always had difficulty near motion boundaries. Providing a better model of motion boundaries is of paramount importance to two-dimensional motion analysis.
Reference: [8] <author> D. Fleet and A. Jepson. </author> <title> Measurement of image velocity by phase information. </title> <journal> International Journal of Computer Vision, </journal> <year> 1990. </year>
Reference-contexts: In motion analysis, this involves estimation of surface velocities ~v n (x). This is a well understood problem, and there are now numerous motion estimation algorithms available. First order motion analysis in two dimensions involves determining the plane (s) which contain the most energy <ref> [8, 11, 13] </ref>. The task of second order motion analysis is to deduce as much information as possible about M (x).
Reference: [9] <author> D. Fleet and K. Langley. </author> <title> Computational analysis of non-Fourier motion. </title> <type> Technical report, </type> <institution> Queens University, </institution> <year> 1994. </year>
Reference-contexts: By exploiting the characteristic structure in the spa-tiotemporal domain and in the frequency domain, we show that the above image formation process involves modulation of information about the mask M (x), and that for purposes of analysis it is natural to demodulate it. Recently, Fleet and Langley <ref> [9] </ref> have shown that many "second-order" motion stimuli, including kinetic occlusion, possess locally oriented power in the frequency domain. We specialize the analysis to kinetic occlusion in this paper, and consider both one-dimensional and two-dimensional kinetic occlusion. <p> Beats, theta motion, multiplicative transparency, and drift-balanced stimuli also contain locally oriented power <ref> [9] </ref>.
Reference: [10] <author> W. T. Freeman and E. H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <year> 1991. </year> <title> 19 (a) I(x) (b) R(x) Shown here are three sample frames from the sequence, and an (x; t)-slice. (b) Detected occlusion R(x) extracted for the three sample frames shown, and the same (x; t)-slice. </title>
Reference-contexts: Spatiotemporally oriented filters allow one to selectively extract portions of the frequency domain so as to accomplish this task [1, 13, 36]. Phase-invariant energy extraction is possible through usage of a quadrature pair of filters G (x) and H (x) tuned to orientation : <ref> [1, 10] </ref> E (x) = (I (x) fl G (x)) + (I (x) fl H (x)) (9) Multiple motions at each point in space-time x can be found by finding local peaks in E (x) as is varied. <p> Gabor functions and derivatives of Gaussians are particularly convenient forms that are popularly used for orientation analysis. Gabor functions may be preferred because they form a natural quadrature pair and exactly "demodulate" portions of the frequency domain; we use derivatives of Gaussians in our experiments because they are steerable <ref> [10] </ref>. 4.2.2 Second order orientation analysis The key idea behind our method of second order orientation analysis is as follows. <p> Here we used the steerability property of derivatives of Gaussians <ref> [10] </ref> to filter orthogonally to the direction of spatiotemporal orientation. 3 With first order orientation removed, only second order information remains in R (x). In principle, methods to estimate first order motion can now be applied to R (x) to estimate v m . <p> See <ref> [10] </ref> for details. lar orientation and scale around ~w = ~w 0 in the frequency domain. Successful kinetic occlusion detection depends crucially on whether second order orientation is demodulated successfully. This in turn depends on the accuracy of first order orientation extraction. <p> Simoncelli [32] has recently developed methods of doing so using tools of steerable filtering <ref> [10, 21] </ref>. We summarize the method below.
Reference: [11] <author> N. M. Grzywacz and A. L. Yuille. </author> <title> A model for the estimate of local image velocity by cells in the visual cortex. </title> <journal> Proceedings Royal Society London B, </journal> <volume> 239 </volume> <pages> 129-61, </pages> <year> 1990. </year>
Reference-contexts: Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction <ref> [11, 13, 32] </ref>. Observing that translation in space-time appears as a plane passing through the origin in the frequency domain, these models construct distributed representations of motion via a two-stage process, as suggested by [23]. The first stage involves filtering image sequences with spatiotemporally oriented filters. <p> In motion analysis, this involves estimation of surface velocities ~v n (x). This is a well understood problem, and there are now numerous motion estimation algorithms available. First order motion analysis in two dimensions involves determining the plane (s) which contain the most energy <ref> [8, 11, 13] </ref>. The task of second order motion analysis is to deduce as much information as possible about M (x). <p> y ] T that contains power along the plane v x w x + v y w y + w t = 0, extracting first or der motion E ~v (x) is possible through linear filtering of the stimulus I (x) with banks of spatiotemporal filters centered on the plane <ref> [11, 13] </ref>. Simoncelli [32] has recently developed methods of doing so using tools of steerable filtering [10, 21]. We summarize the method below.
Reference: [12] <author> G. Guy and G. Medioni. </author> <title> Inferring global perceptual contours from local features. </title> <type> Technical report, </type> <institution> University of Southern California, </institution> <year> 1994. </year>
Reference-contexts: And, by detecting motion boundaries, other visual modules may be aided: Motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis [14, 28], our module can be used for surface segregation processes <ref> [6, 7, 12, 15, 25] </ref>. In section 4, we analyze one-dimensional kinetic occlusion and develop techniques to analyze one-dimensional spatiotemporal stimuli. <p> Multiplicative transparency, most commonly appearing as shadows, naturally fits into the model we adopt, and could be analyzed by similar or identical mechanisms. Most importantly, our current analysis is purely local; no spatiotemporal propagation has been attempted. Solutions to spatial contour completion <ref> [6, 12, 15, 25, 7, 37] </ref> are likely to be extendable to spatiotemporal surface completion. 8 Conclusion Motion estimation algorithms, relying on "constant intensity" and "single velocity" assumptions, have always had difficulty near motion boundaries. Providing a better model of motion boundaries is of paramount importance to two-dimensional motion analysis.
Reference: [13] <author> D. Heeger. </author> <title> Model for the extraction of image flow. </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 4 </volume> <pages> 1455-1471, </pages> <year> 1987. </year>
Reference-contexts: Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction <ref> [11, 13, 32] </ref>. Observing that translation in space-time appears as a plane passing through the origin in the frequency domain, these models construct distributed representations of motion via a two-stage process, as suggested by [23]. The first stage involves filtering image sequences with spatiotemporally oriented filters. <p> Spatiotemporally oriented filters allow one to selectively extract portions of the frequency domain so as to accomplish this task <ref> [1, 13, 36] </ref>. <p> i n (x; y) which move with velocity ~v n = [v xn ; v yn ] T : I n (x) = i n (x + v xn t; y + v yn t) (18) Unambiguously translating surfaces have power constrained to lie along planes in the frequency domain <ref> [13] </ref>: ^ I n (w) = ^ i n (w x ; w y )ffi (w x v xn + w y v yn + w t ) (19) 5.1 XYT Kinetic occlusion: Model Kinetic occlusion is modeled with a spatially oriented step edge u m (x; y) translating with speed <p> In motion analysis, this involves estimation of surface velocities ~v n (x). This is a well understood problem, and there are now numerous motion estimation algorithms available. First order motion analysis in two dimensions involves determining the plane (s) which contain the most energy <ref> [8, 11, 13] </ref>. The task of second order motion analysis is to deduce as much information as possible about M (x). <p> y ] T that contains power along the plane v x w x + v y w y + w t = 0, extracting first or der motion E ~v (x) is possible through linear filtering of the stimulus I (x) with banks of spatiotemporal filters centered on the plane <ref> [11, 13] </ref>. Simoncelli [32] has recently developed methods of doing so using tools of steerable filtering [10, 21]. We summarize the method below.
Reference: [14] <author> F. Heitger, L. Rosenthaler, R. von der Heydt, E. Pe-terhans, and O. Kubler. </author> <title> Simulation of neural contour mechanisms: From simple to end-stopped cells. </title> <journal> Vision Research, </journal> <volume> 32(5) </volume> <pages> 963-981, </pages> <year> 1992. </year>
Reference-contexts: And, by detecting motion boundaries, other visual modules may be aided: Motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis <ref> [14, 28] </ref>, our module can be used for surface segregation processes [6, 7, 12, 15, 25]. In section 4, we analyze one-dimensional kinetic occlusion and develop techniques to analyze one-dimensional spatiotemporal stimuli. <p> We should be aware that significant deviations from the dominant motion will result in false responses. The systematic nature of these false responses can be taken advantage of, as some spatial junction analysis schemes have done <ref> [14, 28] </ref>, but we do not pursue this possibility here. Our overall block diagram for processing one-dimensional stimuli is shown in Figure 11. <p> There are a variety of additional directions that can be taken based on this work. First, considerable improvements can be made on our detection methods alone. The systematic nature of "false responses" has been taken advantage of in two-dimensional spatial occlusion analysis <ref> [14, 28] </ref>; it should be possible to extend the basic idea to spatiotemporal occlusion analysis. We can also combine spatial junction analysis and our spatiotemporal junction analysis in unified framework. Second, we are currently using non-causal operations.
Reference: [15] <author> F. Heitger and R. von der Heydt. </author> <title> A computational model of neural contour processing: Figure-ground segregation and illusory contours. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 32-40, </pages> <address> Berlin, Germany, </address> <year> 1993. </year>
Reference-contexts: And, by detecting motion boundaries, other visual modules may be aided: Motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis [14, 28], our module can be used for surface segregation processes <ref> [6, 7, 12, 15, 25] </ref>. In section 4, we analyze one-dimensional kinetic occlusion and develop techniques to analyze one-dimensional spatiotemporal stimuli. <p> With a detected ordinal cue to depth, we can determine the depth ordering of surfaces locally. Our detected occlusion can be used to activate direction of figure representations, as is done in the models of <ref> [6, 7, 15] </ref>. A global depth ordering of surfaces can also be attempted from these local cues (c.f. [35]). Furthermore, by discontinuing use of optical flow upon occlusion detection, and continuing use of optical flow upon disocclusion detection, we can potentially track surfaces through occlusion. <p> Multiplicative transparency, most commonly appearing as shadows, naturally fits into the model we adopt, and could be analyzed by similar or identical mechanisms. Most importantly, our current analysis is purely local; no spatiotemporal propagation has been attempted. Solutions to spatial contour completion <ref> [6, 12, 15, 25, 7, 37] </ref> are likely to be extendable to spatiotemporal surface completion. 8 Conclusion Motion estimation algorithms, relying on "constant intensity" and "single velocity" assumptions, have always had difficulty near motion boundaries. Providing a better model of motion boundaries is of paramount importance to two-dimensional motion analysis.
Reference: [16] <author> F. Heitz and P. Bouthemy. </author> <title> Multimodal motion estimation and segmentation using Markov random fields. </title> <booktitle> In Proceedings IEEE International Conference on Pattern Recognition, </booktitle> <pages> pages 378-383, </pages> <year> 1990. </year>
Reference-contexts: Recently, many have proposed algorithms with more relaxed assumptions, thus yielding significantly improved velocity estimates near motion boundaries: * Regularization/line processes. If significant velocity gradients are detected during motion estimation, then line processes can be activated <ref> [16, 17, 24, 27, 33] </ref>; subsequent smoothing of motion is prevented across these line processes. * Multiple motions locally.
Reference: [17] <author> J. Hutchinson, C. Koch, J. Luo, and C. Mead. </author> <title> Computing motion using analog and binary resistive networks. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 52-63, </pages> <year> 1988. </year>
Reference-contexts: Recently, many have proposed algorithms with more relaxed assumptions, thus yielding significantly improved velocity estimates near motion boundaries: * Regularization/line processes. If significant velocity gradients are detected during motion estimation, then line processes can be activated <ref> [16, 17, 24, 27, 33] </ref>; subsequent smoothing of motion is prevented across these line processes. * Multiple motions locally.
Reference: [18] <author> A. Jepson and M. J. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> In Proceedings of Computer Vision and Pattern Recognition, </booktitle> <pages> pages 760-761, </pages> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: t Texture of the posterior surface, the flowerbed, is accreted and deleted as the anterior surface, the tree, moves over it. (b) An (x; t) slice of the spatiotemporal stimulus of (a) reveals that when an orientation stops in space-time, there is a strong cue to occlusion. surface motions effectively <ref> [18, 35] </ref>. Motion registra tion techniques where multiple transparent motions are estimated using global parametrized motion mod els have also been developed [2]. All of the above approaches pursue the goal of flow field estimation. Few have attempted to analyze kinetic occlusion directly. <p> While all orientations can be extracted with the 7 above operations, simulations may be simplified by only extracting second order orientation at k dominant orientations. We can utilize mechanisms which find the dominant orientations for one-dimensional stimuli [26] or which find the dominant motions in two-dimensional stimuli <ref> [18, 35] </ref>. We should be aware that significant deviations from the dominant motion will result in false responses. The systematic nature of these false responses can be taken advantage of, as some spatial junction analysis schemes have done [14, 28], but we do not pursue this possibility here. <p> Other recently developed global multiple motion estimation algorithms, e.g. <ref> [2, 18] </ref>, yield similar representations. We illustrate our approach on a simple example containing two moving surfaces. Figure 20 (a) depicts a random-dot stimulus where a rightward moving square occludes a leftward moving background.
Reference: [19] <author> G. A. Kaplan. </author> <title> Kinetic disruption of optical texture: The perception of depth at an edge. </title> <journal> Perception and Psychophysics, </journal> <volume> 6(4) </volume> <pages> 193-198, </pages> <year> 1969. </year>
Reference-contexts: 1 Introduction With motion boundaries as the sole cue, surfaces can easily be segmented, recognized, and perceived as having a distinct ordering in depth <ref> [19, 29] </ref>. Under natural conditions, motion boundaries are formed by occluding surfaces in motion. Relative motion of occluding surfaces generically results in accretion or deletion of surface texture of the occluded surface by the occluding surface. This basic phenomena, which we will call kinetic occlusion, is illustrated in Figure 1.
Reference: [20] <author> M. Kass, A. Witkin, and D. Terzopoulos. Snakes: </author> <title> Active contour models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(1):1, </volume> <year> 1987. </year>
Reference-contexts: Detecting edges in velocity fields [34] is difficult due to erroneous velocity estimates at motion boundaries; we offer an alternate possibility. Tools such as de-formable contours <ref> [20] </ref> may also use our detected motion boundaries as an image potential. With a detected ordinal cue to depth, we can determine the depth ordering of surfaces locally. Our detected occlusion can be used to activate direction of figure representations, as is done in the models of [6, 7, 15].
Reference: [21] <author> J. Koenderink. </author> <title> Generic neighborhood operators. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 14(6) </volume> <pages> 597-605, </pages> <year> 1992. </year>
Reference-contexts: Simoncelli [32] has recently developed methods of doing so using tools of steerable filtering <ref> [10, 21] </ref>. We summarize the method below.
Reference: [22] <author> K. Langley, D. Fleet, and T. Atherton. </author> <title> Multiple motions from instantaneous frequency. </title> <booktitle> In Proceedings of Computer Vision and Pattern Recognition, </booktitle> <pages> pages 846-849, </pages> <year> 1992. </year>
Reference-contexts: If significant velocity gradients are detected during motion estimation, then line processes can be activated [16, 17, 24, 27, 33]; subsequent smoothing of motion is prevented across these line processes. * Multiple motions locally. Flow constraints have been generalized to estimate multiple motions directly <ref> [22, 30] </ref>, assuming a stimulus is a linear superposition of independent motion signals; kinetic occlusion cannot be considered as such. * Robust estimation. Motion estimation methods have been modified to be less sensitive to violations of underlying assumptions of smoothness and data conservation [3, 4, 31].
Reference: [23] <author> A. J. Movshon, E. H. Adelson, M. S. Gizzi, and W. T. Newsome. </author> <title> The analysis of moving visual patterns. </title> <journal> Experimental Brain Research, </journal> <volume> 11 </volume> <pages> 117-152, </pages> <year> 1986. </year>
Reference-contexts: Observing that translation in space-time appears as a plane passing through the origin in the frequency domain, these models construct distributed representations of motion via a two-stage process, as suggested by <ref> [23] </ref>. The first stage involves filtering image sequences with spatiotemporally oriented filters. The second stage pools the squared responses of these filters to construct units tuned to velocity.
Reference: [24] <author> D. W. Murray and B. F. Buxton. </author> <title> Scene segmentation from visual motion using global optimization. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 9(2) </volume> <pages> 220-228, </pages> <year> 1987. </year>
Reference-contexts: Recently, many have proposed algorithms with more relaxed assumptions, thus yielding significantly improved velocity estimates near motion boundaries: * Regularization/line processes. If significant velocity gradients are detected during motion estimation, then line processes can be activated <ref> [16, 17, 24, 27, 33] </ref>; subsequent smoothing of motion is prevented across these line processes. * Multiple motions locally.
Reference: [25] <author> M. Nitzberg, D. Mumford, and S. Shiota. </author> <booktitle> Lecture Notes in Computer Science: Filtering, Segmentation and Depth, </booktitle> <volume> volume 622. </volume> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: And, by detecting motion boundaries, other visual modules may be aided: Motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis [14, 28], our module can be used for surface segregation processes <ref> [6, 7, 12, 15, 25] </ref>. In section 4, we analyze one-dimensional kinetic occlusion and develop techniques to analyze one-dimensional spatiotemporal stimuli. <p> Multiplicative transparency, most commonly appearing as shadows, naturally fits into the model we adopt, and could be analyzed by similar or identical mechanisms. Most importantly, our current analysis is purely local; no spatiotemporal propagation has been attempted. Solutions to spatial contour completion <ref> [6, 12, 15, 25, 7, 37] </ref> are likely to be extendable to spatiotemporal surface completion. 8 Conclusion Motion estimation algorithms, relying on "constant intensity" and "single velocity" assumptions, have always had difficulty near motion boundaries. Providing a better model of motion boundaries is of paramount importance to two-dimensional motion analysis.
Reference: [26] <author> R. Picard and M. Gorkani. </author> <title> Finding perceptually dominant orientations in natural textures. Spatial Vision, </title> <booktitle> 8(2) </booktitle> <pages> 221-253, </pages> <year> 1993. </year>
Reference-contexts: The above operation can be performed at every orientation . While all orientations can be extracted with the 7 above operations, simulations may be simplified by only extracting second order orientation at k dominant orientations. We can utilize mechanisms which find the dominant orientations for one-dimensional stimuli <ref> [26] </ref> or which find the dominant motions in two-dimensional stimuli [18, 35]. We should be aware that significant deviations from the dominant motion will result in false responses.
Reference: [27] <author> T. Poggio, V. Torre, and C. Koch. </author> <title> Computational vision and regularization theory. </title> <journal> Nature, </journal> <volume> 317(26) </volume> <pages> 314-319, </pages> <year> 1985. </year>
Reference-contexts: Recently, many have proposed algorithms with more relaxed assumptions, thus yielding significantly improved velocity estimates near motion boundaries: * Regularization/line processes. If significant velocity gradients are detected during motion estimation, then line processes can be activated <ref> [16, 17, 24, 27, 33] </ref>; subsequent smoothing of motion is prevented across these line processes. * Multiple motions locally. <p> This is commonly attempted in feature tracking approaches in a brittle fashion; we offer an alternate approach. Finally, the detection of motion boundaries allows for better motion estimates. In addition to activating line processes (c.f. <ref> [27] </ref>) due to velocity gradients, we can activate them through the detection of kinetic occlusion. Preventing smoothing across detected motion boundaries can yield better estimates of optical flow. There are a variety of additional directions that can be taken based on this work.
Reference: [28] <author> L. Rosenthaler, F. Heitger, O. Kubler, and R. von der Heydt. </author> <title> Detection of general edges and keypoints. </title> <booktitle> In Proceedings of the European Conference on Computer Vision, </booktitle> <pages> pages 78-86, </pages> <year> 1992. </year>
Reference-contexts: And, by detecting motion boundaries, other visual modules may be aided: Motion estimation can be improved by indicating where smoothing of motion estimates should not occur; and, as spatiotemporal junction analysis yields information similar to spatial junction analysis <ref> [14, 28] </ref>, our module can be used for surface segregation processes [6, 7, 12, 15, 25]. In section 4, we analyze one-dimensional kinetic occlusion and develop techniques to analyze one-dimensional spatiotemporal stimuli. <p> We should be aware that significant deviations from the dominant motion will result in false responses. The systematic nature of these false responses can be taken advantage of, as some spatial junction analysis schemes have done <ref> [14, 28] </ref>, but we do not pursue this possibility here. Our overall block diagram for processing one-dimensional stimuli is shown in Figure 11. <p> There are a variety of additional directions that can be taken based on this work. First, considerable improvements can be made on our detection methods alone. The systematic nature of "false responses" has been taken advantage of in two-dimensional spatial occlusion analysis <ref> [14, 28] </ref>; it should be possible to extend the basic idea to spatiotemporal occlusion analysis. We can also combine spatial junction analysis and our spatiotemporal junction analysis in unified framework. Second, we are currently using non-causal operations.
Reference: [29] <author> C. S. Royden, J. F. Baker, and J. Allman. </author> <title> Perceptions of depth elicited by occluded and shearing motions of random dots. </title> <journal> Perception, </journal> <volume> 17 </volume> <pages> 289-296, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction With motion boundaries as the sole cue, surfaces can easily be segmented, recognized, and perceived as having a distinct ordering in depth <ref> [19, 29] </ref>. Under natural conditions, motion boundaries are formed by occluding surfaces in motion. Relative motion of occluding surfaces generically results in accretion or deletion of surface texture of the occluded surface by the occluding surface. This basic phenomena, which we will call kinetic occlusion, is illustrated in Figure 1.
Reference: [30] <author> M. Shizawa and K. Mase. </author> <title> A unified computational theory for motion transparency and motion boundaries based on eigenenergy analysis. </title> <booktitle> In IEEE Computer Vision and Pattern Recognition, </booktitle> <year> 1991. </year>
Reference-contexts: If significant velocity gradients are detected during motion estimation, then line processes can be activated [16, 17, 24, 27, 33]; subsequent smoothing of motion is prevented across these line processes. * Multiple motions locally. Flow constraints have been generalized to estimate multiple motions directly <ref> [22, 30] </ref>, assuming a stimulus is a linear superposition of independent motion signals; kinetic occlusion cannot be considered as such. * Robust estimation. Motion estimation methods have been modified to be less sensitive to violations of underlying assumptions of smoothness and data conservation [3, 4, 31].
Reference: [31] <author> D. Shulman and J. Herve. </author> <title> Regularization of discontinuous flow fields. </title> <booktitle> In Proceedings of Workshop on Visual Motion, </booktitle> <pages> pages 81-85, </pages> <address> Irvine, CA, 1989. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Motion estimation methods have been modified to be less sensitive to violations of underlying assumptions of smoothness and data conservation <ref> [3, 4, 31] </ref>. By discounting deviations from underlying assumptions, occlusions are viewed as an anomalous process that should be ignored. * Multiple motions globally.
Reference: [32] <author> E. Simoncelli. </author> <title> Distributed Representations of Motion. </title> <type> PhD thesis, </type> <institution> MIT Dept. Electrical Engineering and Computer Science, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction <ref> [11, 13, 32] </ref>. Observing that translation in space-time appears as a plane passing through the origin in the frequency domain, these models construct distributed representations of motion via a two-stage process, as suggested by [23]. The first stage involves filtering image sequences with spatiotemporally oriented filters. <p> Simoncelli <ref> [32] </ref> has recently developed methods of doing so using tools of steerable filtering [10, 21]. We summarize the method below. <p> Idealized level surfaces of the power spectra of two such derivative filters are shown here. The level surfaces of the sum of the two will form a smooth ring bisecting the plane. From <ref> [32] </ref>, with permission. Second order orientation that may be contained in this ring is demodulated to the origin ~w = 0. occlusion detection signals R ~v n (x).
Reference: [33] <author> D. Terzopoulos. </author> <title> Regularization of inverse problems involving discontinuities. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 413-424, </pages> <year> 1986. </year>
Reference-contexts: Recently, many have proposed algorithms with more relaxed assumptions, thus yielding significantly improved velocity estimates near motion boundaries: * Regularization/line processes. If significant velocity gradients are detected during motion estimation, then line processes can be activated <ref> [16, 17, 24, 27, 33] </ref>; subsequent smoothing of motion is prevented across these line processes. * Multiple motions locally.
Reference: [34] <author> W. B. Thompson, K. M. Mutch, and V. A. Berzins. </author> <title> Dynamic occlusion analysis in optical flow fields. </title> <journal> IEEE Pattern Analysis and Machine Intelligence, </journal> <volume> 7(4) </volume> <pages> 374-383, </pages> <year> 1985. </year>
Reference-contexts: By analyzing this spatiotempo-ral structure, we develop methods to detect and analyze kinetic occlusion. 2 Background With a detected motion boundary, interpretation of kinetic occlusion is straightforward: if the motion boundary moves consistently with either of the surfaces that define it, then that surface is the occluding surface <ref> [34] </ref>. If motion could be estimated accurately near motion boundaries, then edges could be detected in the velocity field. By deducing which side of the moving edge possessed motion consistent with the motion boundary, the ordinal depth relationship between two surfaces could be determined. <p> First, surfaces can be segregated on the basis of kinetic occlusion. In contrast to the large number of vision algorithms using luminance-based edge detection as a base representation, there are very few that utilize motion boundaries. Detecting edges in velocity fields <ref> [34] </ref> is difficult due to erroneous velocity estimates at motion boundaries; we offer an alternate possibility. Tools such as de-formable contours [20] may also use our detected motion boundaries as an image potential. With a detected ordinal cue to depth, we can determine the depth ordering of surfaces locally.
Reference: [35] <author> J. Y. A. Wang and E. H. Adelson. </author> <title> Representing moving images with layers. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 625-638, </pages> <year> 1994. </year>
Reference-contexts: t Texture of the posterior surface, the flowerbed, is accreted and deleted as the anterior surface, the tree, moves over it. (b) An (x; t) slice of the spatiotemporal stimulus of (a) reveals that when an orientation stops in space-time, there is a strong cue to occlusion. surface motions effectively <ref> [18, 35] </ref>. Motion registra tion techniques where multiple transparent motions are estimated using global parametrized motion mod els have also been developed [2]. All of the above approaches pursue the goal of flow field estimation. Few have attempted to analyze kinetic occlusion directly. <p> By con structing mechanisms which observe how distributed rep resentations of motion change over time, we can detect kinetic occlusion. 3 Approach We model the local structure present in occlusions directly, using the "layers" model of <ref> [35] </ref>. Layers I 1 (x) through I n (x) may attenuate the luminance of the layer beneath it by a factor ff (x) (0 ff (x) 1), and may contribute its own emission e n (x). <p> While all orientations can be extracted with the 7 above operations, simulations may be simplified by only extracting second order orientation at k dominant orientations. We can utilize mechanisms which find the dominant orientations for one-dimensional stimuli [26] or which find the dominant motions in two-dimensional stimuli <ref> [18, 35] </ref>. We should be aware that significant deviations from the dominant motion will result in false responses. The systematic nature of these false responses can be taken advantage of, as some spatial junction analysis schemes have done [14, 28], but we do not pursue this possibility here. <p> If desired, we can pool responses over all k dominant motions with simple summation: R (x) = n=1 to summarize the occlusion detected in the spatiotemporal stimulus. In our experiments, dominant motions ~v n (x) are extracted via the clustering technique used in <ref> [35] </ref>; the technique uses a k-means clustering algorithm on local affine parameter fits of optical flow to yield k dominant motions described by: ~v n (x; y; t) = a x (t) + a xx (t)x + a xy (t)y where the vector ~a n (t) = [a x (t); a <p> For our synthetic stimuli, we impose perfect estimated first order motions on the stimulus for controlled experimentation. For real stimuli, we use the dominant motion extraction scheme of <ref> [35] </ref>. Vertical Bars. A three-motion stimulus with non-ideal spatiotemporal junctions is shown in Figure 21 (a,b). Here, two bars, moving rightward and leftward, respectively, occlude a static background. Figure 21 (c,d,e) show kinetic occlusion extraction steps for static motion; kinetic occlusion is reliably detected at the edges of the bars. <p> Garden sequence. Figure 26 shows the same steps applied to a real image sequence, where a tree occludes a flowerbed. The motion of the tree and flowerbed is represented accurately by the affine model we have adopted. Affine motion estimates were obtained from the k-means clustering algorithm used in <ref> [35] </ref>. Second order motion is detected in regions where the tree occludes the flowerbed; as before, the sign of R (x) differentiates accretion from deletion. At the right side of the tree, the tree disoccludes the flowerbed, so R (x) responds positively at the motion boundary. <p> Our detected occlusion can be used to activate direction of figure representations, as is done in the models of [6, 7, 15]. A global depth ordering of surfaces can also be attempted from these local cues (c.f. <ref> [35] </ref>). Furthermore, by discontinuing use of optical flow upon occlusion detection, and continuing use of optical flow upon disocclusion detection, we can potentially track surfaces through occlusion. This is commonly attempted in feature tracking approaches in a brittle fashion; we offer an alternate approach.
Reference: [36] <author> A. B. Watson and A. J. Ahumada. </author> <title> Model of human visual motion sensing. </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 2 </volume> <pages> 322-341, </pages> <year> 1985. </year>
Reference-contexts: Spatiotemporally oriented filters allow one to selectively extract portions of the frequency domain so as to accomplish this task <ref> [1, 13, 36] </ref>.
Reference: [37] <author> L. R. Williams and D. W. Jacobs. </author> <title> Stochastic completion fields: A neural model of illusory contour shape and salience. </title> <booktitle> In Fifth International Conference on Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Multiplicative transparency, most commonly appearing as shadows, naturally fits into the model we adopt, and could be analyzed by similar or identical mechanisms. Most importantly, our current analysis is purely local; no spatiotemporal propagation has been attempted. Solutions to spatial contour completion <ref> [6, 12, 15, 25, 7, 37] </ref> are likely to be extendable to spatiotemporal surface completion. 8 Conclusion Motion estimation algorithms, relying on "constant intensity" and "single velocity" assumptions, have always had difficulty near motion boundaries. Providing a better model of motion boundaries is of paramount importance to two-dimensional motion analysis.
Reference: [38] <author> C. Zetzsche, E. Barth, and J. Berkmann. </author> <title> Spatiotem-poral curvature measures for flow field analysis. </title> <booktitle> In SPIE Geometric Methods in Computer Vision, </booktitle> <volume> volume 1570, </volume> <pages> pages 337-350, </pages> <year> 1991. </year> <month> 21 </month>
Reference-contexts: All of the above approaches pursue the goal of flow field estimation. Few have attempted to analyze kinetic occlusion directly. Exceptions are Bolles and Baker [5], who apply 3-d spatiotemporal edge detection to image sequences in order to link edges across space-time, and Zetsche et al <ref> [38] </ref>, who suggest that occlusion can be detected via application of generic 3-d curvature operators directly to image sequences. Distributed representations of motion, as used by biological visual systems, do not suffer from the problems of explicit velocity field construction [11, 13, 32].
References-found: 38

