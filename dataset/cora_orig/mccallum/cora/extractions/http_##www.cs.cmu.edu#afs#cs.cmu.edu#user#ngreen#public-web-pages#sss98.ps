URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/ngreen/public-web-pages/sss98.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/ngreen/public-web-pages/sss98-sched2.html
Root-URL: 
Email: nancy.green@cs.cmu.edu  
Title: An Application of Explanation-Based Learning to Discourse Generation and Interpretation  
Author: Nancy Green and Jill Fain Lehman 
Address: Pittsburgh, PA 15231 USA  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: This paper presents a brief description of Explanation-Based Learning (EBL), and argues that it is an approach to machine learning with significant potential for use in discourse processing. More specifically, EBL can be used by systems that model discourse generation as goal-driven behavior, and that model discourse interpretation as recognizing the speaker's discourse goals. As evidence, we describe the discourse architecture of the NL-Soar dialogue system. The architecture uses the EBL capabilities of Soar to compile discourse recipes during discourse planning. The recipes can be reused to speed up discourse generation and as a knowledge source during discourse interpretation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alexandersson, J.; Reithinger, N.; and Maier, E. </author> <year> 1997. </year> <title> Insights into the dialogue processing of VERB-MOBIL. </title> <booktitle> In Proceedings of ANLP-97. </booktitle>
Reference-contexts: Related Work We are not aware of prior work to perform recipe acquisition during discourse planning. There has been some work, however, on using discourse recipes acquired automatically from a manually-annotated corpus <ref> (Alexandersson, Reithinger, & Maier 1997) </ref> for discourse plan recognition. Although EBL has been applied to optimizing performance during sentence parsing (Neumann 1997) and sentence generation (Samuelsson & Rayner 1991), there has been very little work in applying it to problems in discourse.
Reference: <author> Allen, J. F., and Perrault, C. R. </author> <year> 1980. </year> <title> Analyzing intention in utterances. </title> <booktitle> Artificial Intelligence 15 </booktitle> <pages> 143-178. </pages>
Reference-contexts: EBL has been used to learn rules for interpreting indirect speech acts (Schulenburg & Pazzani 1989). Given a representation of the surface speech act of an utterance used as an indirect speech act, the system uses the plan inference technique of <ref> (Allen & Perrault 1980) </ref> to interpret the utterance. EBL techniques are then used to compile the chain of inference into rules for use in future cases. Also, as described above, EBL has been used to recognize narrative schemata (Dejong & Mooney 1986).
Reference: <author> Carberry, S. </author> <year> 1990. </year> <title> Plan Recognition in Natural Language Dialogue. </title> <address> Cambridge, Massachusetts: </address> <publisher> MIT Press. </publisher>
Reference: <author> Cawsey, A. </author> <year> 1992. </year> <title> Explanation and Interaction: The Computer Generation of Explanatory Dialogues. </title> <address> Cambridge, Massachusetts: </address> <publisher> MIT Press. </publisher>
Reference: <author> Clark, H. H., and Schaefer, E. F. </author> <year> 1989. </year> <title> Contributing to discourse. </title> <booktitle> Cognitive Science 13 </booktitle> <pages> 259-294. </pages>
Reference: <author> Dejong, G., and Mooney, R. </author> <year> 1986. </year> <title> Explanation-based generalization: An alternative view. </title> <booktitle> Machine Learning 1 </booktitle> <pages> 145-176. </pages>
Reference-contexts: In other words, the explanation is used to find sufficient conditions for recognizing new instances of the concept. Dejong and Mooney propose a different characterization of explanation-based approaches, which they term Explanation-Based Learning (EBL) <ref> (Dejong & Mooney 1986) </ref> to reflect a broader range of phenomena than considered by Mitchell et al. <p> EBL techniques are then used to compile the chain of inference into rules for use in future cases. Also, as described above, EBL has been used to recognize narrative schemata <ref> (Dejong & Mooney 1986) </ref>. Conclusions We argue that EBL has potential for use in dialogue systems that model discourse generation as goal-driven behavior, and that model discourse interpretation as recognizing the speaker's discourse goals. As evidence, we describe the discourse architecture of NL-Soar.
Reference: <author> Gibbon, D. </author> <year> 1985. </year> <title> Context and variation in two-way radio discourse. </title> <booktitle> Discourse Processes 8 </booktitle> <pages> 395-419. </pages>
Reference-contexts: The goal of the current implementation is for NL-Soar to enable a human trainee to communicate with an automated pilot agent playing the role of the other participant. As in other domains involving two-way radio discourse <ref> (Gibbon 1985) </ref>, a large portion of each turn in the dialogues is devoted to discourse acts for managing the turn (Sacks, Schegloff, & Jefferson 1974) (summons, self-introduction, end-turn) and grounding (Clark & UTTERANCE DISCOURSE ACT A2: Parrot101. summons This is Parrot102. self-introduction I have a contact inform-description-of bearing 260.
Reference: <author> Green, N., and Lehman, J. F. </author> <title> in preparation. An integrated architecture for discourse: Generation, interpretation and recipe acquisition. </title>
Reference: <author> Grosz, B., and Sidner, C. </author> <year> 1986. </year> <title> Attention, intention, and the structure of discourse. </title> <booktitle> Computational Linguistics 12(3) </booktitle> <pages> 175-204. </pages>
Reference-contexts: Over. end-turn A2: Parrot101. summons This is Parrot102. self-introduction Roger. acknowledge That is your bogey. inform-same-object Over. end-turn Schaefer 1989) (acknowledge). Most of the task-related dialogue can be described using three discourse segment purposes (DSPs) <ref> (Grosz & Sidner 1986) </ref>. Seven primitive illocutionary act types and a small set of discourse expectations are sufficient to describe those dialogue segments. For example, Figure 3 shows a dialogue segment constructed to illustrate a variety of discourse acts in this domain.
Reference: <author> Hovy, E. H. </author> <year> 1988. </year> <title> Planning coherent multisentential text. </title> <booktitle> In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 163-169. </pages>
Reference: <author> Huffman, S. B. </author> <year> 1993. </year> <title> Instructable Autonomous Agents. </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan. </institution>
Reference: <author> Johnson, T. R.; Krems, J.; and Amra, N. K. </author> <year> 1994. </year> <title> A computational model of human abductive skill and its acquisition. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 463-468. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Laird, J. E., and Rosenbloom, P. S. </author> <year> 1990. </year> <title> Integrating execution, planning, and learning in Soar for external environments. </title> <booktitle> In Proceedings of AAAI-90. </booktitle>
Reference: <author> Lambert, L., and Carberry, S. </author> <year> 1991. </year> <title> A tripartite plan-based model of dialogue. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 47-54. </pages>
Reference: <author> Lehman, J. F.; Dyke, J. V.; Lonsdale, D.; Green, N.; and Smith, M. </author> <title> in preparation. A building block approach to a unified language capability. </title>
Reference: <author> Lehman, J. F.; Laird, J. E.; and Rosenbloom, P. S. </author> <year> 1996. </year> <title> A gentle introduction to Soar, an architecture for human cognition. </title> <editor> In Sternberg, S., and Scarbor-ough, D., eds., </editor> <booktitle> Invitation to Cognitive Science, </booktitle> <volume> volume 4. </volume> <publisher> MIT Press. </publisher>
Reference: <author> Litman, D., and Allen, J. </author> <year> 1987. </year> <title> A plan recognition model for subdialogues in conversation. </title> <booktitle> Cognitive Science 11 </booktitle> <pages> 163-200. </pages>
Reference: <author> Maybury, M. T. </author> <year> 1992. </year> <title> Communicative acts for explanation generation. </title> <journal> International Journal of Man-Machine Studies 37 </journal> <pages> 135-172. </pages>
Reference: <author> Miller, C. S., and Laird, J. E. </author> <year> 1996. </year> <title> Accounting for graded performance within a discrete search framework. </title> <booktitle> Cognitive Science 4(1) </booktitle> <pages> 499-537. </pages>
Reference: <author> Miller, C.; Lehman, J. F.; and Koedinger, K. </author> <note> submitted. Goal-directed learning in microworld interaction. </note> <institution> Cognitive Science. </institution>
Reference: <author> Minton, S.; Carbonell, J. G.; Knoblock, C. A.; Kuokka, D. R.; Etzioni, O.; and Gil, Y. </author> <year> 1989. </year> <title> Explanation-based learning: A problem solving perspective. </title> <booktitle> Artificial Intelligence 40 </booktitle> <pages> 63-118. </pages>
Reference-contexts: This search control knowledge would be used by the discourse planner in the future to make discourse planning more efficient. For example in PRODIGY, EBL is integrated with a means-end problem-solver to acquire domain-specific search control rules to improve future problem-solving performance in domains such as machine-shop scheduling <ref> (Minton et al. 1989) </ref>. These search control rules help select operators during the planning process reducing the amount of search performed by the planner. Similarly, during discourse planning search control rules could be learned to avoid exploring discourse strategies which would be ineffective.
Reference: <author> Mitchell, T. M.; Kellar, R. M.; and Kedar-Cabelli, S. T. </author> <year> 1986. </year> <title> Explanation-based generalization: A unifying view. </title> <booktitle> Machine Learning 1 </booktitle> <pages> 47-80. </pages>
Reference-contexts: In contrast to corpus-based approaches, EBL can make meaningful generalizations from a single example. In one of the first articles to survey and attempt to unify previous work on explanation-based approaches, Mitchell et al. provide a definition of and method for constructing an explanation-based generalization (EBG) <ref> (Mitchell, Kellar, & Kedar-Cabelli 1986) </ref>. Knowledge about the training example and domain is encoded as logical propositions and the process of finding an explanation is characterized as finding a proof that the training example satisfies a (nonoperational) concept definition.
Reference: <author> Moore, J. D. </author> <year> 1995. </year> <title> Participating in Explanatory Dialogues. </title> <publisher> MIT Press. </publisher>
Reference: <author> Neumann, G. </author> <year> 1997. </year> <title> Applying explanation-based learning to control and speeding-up natural language generation. </title> <booktitle> In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <pages> 214-221. </pages>
Reference-contexts: There has been some work, however, on using discourse recipes acquired automatically from a manually-annotated corpus (Alexandersson, Reithinger, & Maier 1997) for discourse plan recognition. Although EBL has been applied to optimizing performance during sentence parsing <ref> (Neumann 1997) </ref> and sentence generation (Samuelsson & Rayner 1991), there has been very little work in applying it to problems in discourse. EBL has been used to learn rules for interpreting indirect speech acts (Schulenburg & Pazzani 1989).
Reference: <author> Newell, A. </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <address> Cam-bridge, Massachusetts: </address> <publisher> Harvard University Press. </publisher>
Reference: <author> Rosenbloom, P. S., and Laird, J. E. </author> <year> 1986. </year> <title> Mapping explanation-based generalization onto Soar. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> 561-567. </pages>
Reference-contexts: Chunking can be regarded as a type of EBL, where the productions that were applied during subgoaling constitute the explanation <ref> (Rosenbloom & Laird 1986) </ref>. The conversion of this explanation to chunks results in operational knowledge which can be applied to future problem-solving.
Reference: <author> Sacks, H.; Schegloff, E. A.; and Jefferson, G. </author> <year> 1974. </year> <title> A simplest systematics for the organization of turntak-ing for conversation. </title> <booktitle> Language 50 </booktitle> <pages> 696-735. </pages>
Reference-contexts: As in other domains involving two-way radio discourse (Gibbon 1985), a large portion of each turn in the dialogues is devoted to discourse acts for managing the turn <ref> (Sacks, Schegloff, & Jefferson 1974) </ref> (summons, self-introduction, end-turn) and grounding (Clark & UTTERANCE DISCOURSE ACT A2: Parrot101. summons This is Parrot102. self-introduction I have a contact inform-description-of bearing 260. Over. end-turn A1: Parrot102. summons This is Parrot101. self-introduction Roger. acknowledge I have a contact inform-description-of bearing 270.
Reference: <author> Samuelsson, C., and Rayner, M. </author> <year> 1991. </year> <title> Quantitative evaluation of explanation-based learning as an optimization tool for a large-scale natural language system. </title> <booktitle> In Proceedings, </booktitle> <pages> 609-615. </pages> <booktitle> International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: There has been some work, however, on using discourse recipes acquired automatically from a manually-annotated corpus (Alexandersson, Reithinger, & Maier 1997) for discourse plan recognition. Although EBL has been applied to optimizing performance during sentence parsing (Neumann 1997) and sentence generation <ref> (Samuelsson & Rayner 1991) </ref>, there has been very little work in applying it to problems in discourse. EBL has been used to learn rules for interpreting indirect speech acts (Schulenburg & Pazzani 1989).
Reference: <author> Schulenburg, D., and Pazzani, M. J. </author> <year> 1989. </year> <title> Explanation-based learning of indirect speech act rules. </title> <type> Technical Report Technical Report 89-11, </type> <institution> Dept. of Information and Computer Science, University of California, Irvine. </institution>
Reference-contexts: Although EBL has been applied to optimizing performance during sentence parsing (Neumann 1997) and sentence generation (Samuelsson & Rayner 1991), there has been very little work in applying it to problems in discourse. EBL has been used to learn rules for interpreting indirect speech acts <ref> (Schulenburg & Pazzani 1989) </ref>. Given a representation of the surface speech act of an utterance used as an indirect speech act, the system uses the plan inference technique of (Allen & Perrault 1980) to interpret the utterance.
Reference: <author> Tambe, M., and Rosenbloom, P. S. </author> <year> 1995. </year> <title> RESC: An approach for real-time, dynamic agent tracking. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: If the simulated updates to the HMOS are consistent with what has been heard, the Monitor updates the hearer's version of the conversational record. We decided to investigate this approach to plan recognition, which is similar to earlier work on event tracking in Soar <ref> (Tambe & Rosen-bloom 1995) </ref> (but which is quite different from most prior approaches to discourse plan recognition (Car-berry 1990)) because it permits much of the processing to be performed automatically by the underlying Soar architecture. Discourse Recipes NL-Soar acquires recipes by use of Soar's built-in chunking mechanism.
Reference: <author> Thomason, R. H. </author> <year> 1990. </year> <title> Accommodation, meaning, and implicature: Interdisciplinary foundations for pragmatics. </title> <editor> In Cohen, P.; Morgan, J.; and Pollack, M., eds., </editor> <booktitle> Intentions in Communication. </booktitle> <address> Cambridge, Massachusetts: </address> <publisher> MIT Press. </publisher> <pages> 325-363. </pages>
Reference-contexts: uses in other systems built in Soar, e.g., (Miller & Laird 1996; Miller, Lehman, & Koedinger submitted; Huffman 1993; Johnson, Krems, & Amra 1994).) Discourse Architecture Components As shown in Figure 1, the input to discourse generation in NL-Soar is the shared state of the dialogue, termed the conversational record <ref> (Thomason 1990) </ref>, and the speaker's salient non-shared beliefs and desires. The output is a sequence of primitive discourse actions to be realized by the sentence generator, and their anticipated effects (e.g., updates to the conversational record). In NL-Soar, discourse generation is modeled as goal-driven behavior.
References-found: 31

