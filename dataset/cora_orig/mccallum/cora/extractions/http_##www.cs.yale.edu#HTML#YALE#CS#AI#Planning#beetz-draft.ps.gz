URL: http://www.cs.yale.edu/HTML/YALE/CS/AI/Planning/beetz-draft.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/AI/Planning/
Root-URL: http://www.cs.yale.edu
Title: Anticipating and Forestalling Execution Failures in Structured Reactive Plans  
Author: Michael K. Beetz 
Affiliation: YALEU/CSD/RR  
Abstract-found: 0
Intro-found: 1
Reference: [Agre and Chapman, 1987] <author> P. Agre and D. Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proc. of AAAI-87, </booktitle> <pages> pages 268-272, </pages> <address> Seattle, WA, </address> <year> 1987. </year>
Reference-contexts: This approach requires correct and complete world models and has a tendency to cause relatively simple problems to become computationally intractable. To avoid the problems of classical controllers in coping with real environments in real-time, several researchers developed a different approach, often called situated robot control <ref> [Brooks, 1991a, Agre and Chapman, 1987, Rosenschein and Kaelbling, 1995] </ref>. In the situated control paradigm controllers are organized into interacting concurrent control processes. These processes continuously sense their environment and map the resulting sensor data into effector commands without deliberation and without maintaining large data structures. <p> This approach works only well if the right action can always be selected almost solely on the sensor data. CHAPTER 8. EVALUATION 182 Robots with reactive control systems (Allen [Brooks, 1986b], Pengi <ref> [Agre and Chapman, 1987] </ref>, Herbert [Connell, 1990]) work robustly in dynamic and unknown environments because they respond fast to sensor input. Disadvantages of reactive architectures are that they can usually handle only a small set of fixed jobs of limited complexity.
Reference: [Agre and Horswill, 1992] <author> P. Agre and I. Horswill. </author> <booktitle> Cultural support for improvisation. </booktitle> <pages> pages 363-368, </pages> <year> 1992. </year>
Reference-contexts: It is unrealistic to expect one kind of robot controller to work well in such different jobs and environments. Moreover, many difficult robot control and perception problems can be solved more easily in specific habitats [Horswill, 1995, Horswill, 1993], especially when the habitats are designed to facilitate jobs <ref> [Agre and Horswill, 1992] </ref>. To summarize, the desirable features of a robot controller are to a large degree determined by the capabilities of the robot and the features of its jobs and environment. <p> In HACKER skill is a set of canned answer procedures indexed by problems. HACKER acquires and improves its skills by solving a sequence of increasingly difficult problems and 1 Other work on designing routine plans: <ref> [Agre, 1991, Chapman, 1990, Agre and Horswill, 1992] </ref>. CHAPTER 8. EVALUATION 165 generalizing its solutions to these problems.
Reference: [Agre, 1991] <author> Philip E. Agre. </author> <title> The Dynamic Structure of Everyday Life. </title> <address> Cam-bridge, UK, </address> <year> 1991. </year>
Reference-contexts: In addition, he has regular daily and weekly errands, like cleaning his office. Since an office courier does his daily activities over and over again and is confronted with the same kinds of situations many times, he learns [Sussman, 1977] and uses <ref> [Agre, 1991] </ref> reliable and efficient routines for carrying out his daily jobs. Performing his daily activities usually does not require a lot of thought because routines are general. This generality is necessary since jobs come in many variations and require the courier to cope with whatever situations he encounters. <p> In HACKER skill is a set of canned answer procedures indexed by problems. HACKER acquires and improves its skills by solving a sequence of increasingly difficult problems and 1 Other work on designing routine plans: <ref> [Agre, 1991, Chapman, 1990, Agre and Horswill, 1992] </ref>. CHAPTER 8. EVALUATION 165 generalizing its solutions to these problems.
Reference: [Agre, 1995] <author> P. </author> <title> Agre. </title> <journal> Special issue: Computational research on interaction and agency. Artificial Intelligence 72, </journal> <year> 1995. </year>
Reference-contexts: A good overview on this research effort can be found in <ref> [Agre, 1995] </ref>. 2.1.2 Commands and Jobs The properties of the commands and jobs given to the robot also determine desiderata for the robot controllers to be used.
Reference: [Allen et al., 1990] <editor> J. Allen, J. Hendler, and A. Tate, editors. </editor> <booktitle> Readings in Planning. </booktitle> <publisher> Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: [Aloimonos et al., 1988] <author> J. Aloimonos, A. Bandopadhay, and I. Weiss. </author> <title> Active vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 333-356, </pages> <year> 1988. </year>
Reference-contexts: Vision is limited to the area within sensor range. Since even this area is complex the robot does not try to perceive whole scenes but actively looks for the information needed for executing its routines <ref> [Aloimonos et al., 1988, Bajcsy, 1988, Ballard, 1991] </ref>. Thus, when activating a vision routine, the robot controller parameterizes the routine with the information it wants to extract from an image. For instance, the routine LOOK-FOR can be called with red balls as parameters.
Reference: [Ambros-Ingerson and Steel, 1988] <author> J. Ambros-Ingerson and S. Steel. </author> <title> Integrating planning, execution, and monitoring. </title> <booktitle> In Proc. of AAAI-88, </booktitle> <pages> pages 735-740, </pages> <address> St. Paul, MN, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Planning and action are performed in separate phases. We have sketched the RPL code for a simplified PLANEX system on page 151. NASL [McDermott, 1978] and IPEM <ref> [Ambros-Ingerson and Steel, 1988] </ref> interleave planning and execution in order to exploit the information acquired during plan execution. NASL uses planning to execute complex actions and IPEM integrates partial-order planning and plan execution. These kinds of interactions between planning and action can be expressed in extended RPL.
Reference: [Arkin, 1991] <author> R. Arkin. </author> <title> Motor schema based navigation for a mobile robot: An approach to programming by behavior. </title> <editor> In S. S. Iyengar and A. Elfes, editors, </editor> <booktitle> Autonomous Mobile Robots: Control, Planning, and Architecture (Vol. </booktitle> <volume> 2), </volume> <pages> pages 162-169. </pages> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: Timely action is guaranteed because important reactions have high priority. The 3T [Bonasso et al., 1992], ANIMATE AGENT ARCHITECTURE [Firby et al., 1995], and AT-LANTIS [Gat, 1992] are hybrid layered control architectures that that are based on RAP system. Other hybrid layered systems include <ref> [Arkin, 1991] </ref> and SSS [Connell, 1992]. Structured reactive controllers can avoid flaws in the behavior of the robot that hybrid layered controllers cannot.
Reference: [Bajcsy, 1988] <author> R. </author> <title> Bajcsy. Active perception. </title> <booktitle> Proceedings of IEEE, </booktitle> <volume> 76 </volume> <pages> 996-1005, </pages> <year> 1988. </year>
Reference-contexts: Vision is limited to the area within sensor range. Since even this area is complex the robot does not try to perceive whole scenes but actively looks for the information needed for executing its routines <ref> [Aloimonos et al., 1988, Bajcsy, 1988, Ballard, 1991] </ref>. Thus, when activating a vision routine, the robot controller parameterizes the routine with the information it wants to extract from an image. For instance, the routine LOOK-FOR can be called with red balls as parameters.
Reference: [Ballard, 1991] <author> D. Ballard. </author> <title> Animate vision. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 57-86, </pages> <year> 1991. </year> <note> 196 BIBLIOGRAPHY 197 </note>
Reference-contexts: Vision is limited to the area within sensor range. Since even this area is complex the robot does not try to perceive whole scenes but actively looks for the information needed for executing its routines <ref> [Aloimonos et al., 1988, Bajcsy, 1988, Ballard, 1991] </ref>. Thus, when activating a vision routine, the robot controller parameterizes the routine with the information it wants to extract from an image. For instance, the routine LOOK-FOR can be called with red balls as parameters.
Reference: [Beetz and McDermott, 1992] <author> M. Beetz and D. McDermott. </author> <title> Declarative goals in reactive plans. </title> <editor> In J. Hendler, editor, </editor> <booktitle> AIPS-92, </booktitle> <pages> pages 3-12, </pages> <publisher> Morgan Kauf-mann, </publisher> <year> 1992. </year>
Reference-contexts: We use these constructs to make structured reactive plans transparent to automated planning algorithms. In other words, we represent the structure of plans and the purpose of subplans explicitly. To accomplish transparency we represent goals, perceptions, and beliefs as logical expressions <ref> [Beetz and McDermott, 1992] </ref>. Goals like (ACHIEVE P) or (MAINTAIN P) describe states of the world the robot has to achieve or maintain. Perception statements, like (PERCEIVE D), take a perceptual description D and return designators that describe objects satisfying D and thereby acquire new information. <p> We represent a plan p for getting an object described by the data structure des to the location hx,yi as (REDUCE (ACHIEVE (LOC des h0,10i)) p) <ref> [Beetz and McDermott, 1992] </ref>. When the plan interpreter executes this statement it generates two subtasks, T A for (ACHIEVE (LOC des h0,10i)) and T R for p, and performs T A by performing T R .
Reference: [Beetz and McDermott, 1994] <author> M. Beetz and D. McDermott. </author> <title> Improving robot plans during their execution. </title> <editor> In Kris Hammond, editor, </editor> <booktitle> AIPS-94, </booktitle> <pages> pages 3-12, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: Those tools make it possible to * project what might happen when a robot controller gets executed and return it as an execution scenarios [McDermott, 1994a, McDermott, 1992b]; * infer what might be wrong with a robot controller given an execution scenario <ref> [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995] </ref>; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans as Syntactic Objects For the purpose of planning RPL plans are internally represented as parse or code trees. <p> robot controller gets executed and return it as an execution scenarios [McDermott, 1994a, McDermott, 1992b]; * infer what might be wrong with a robot controller given an execution scenario <ref> [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995] </ref>; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans as Syntactic Objects For the purpose of planning RPL plans are internally represented as parse or code trees. <p> The bug CHAPTER 3. PLANNING 57 description provides the information required by the corresponding bug eliminator to produce new candidate plans. 3.4 Anticipation and Forestalling of Execution Failures Forestalling behavior flaws is implemented as a specialized planner in the XFRM framework <ref> [Beetz and McDermott, 1994] </ref>. <p> It has been studied for a long time, but still remains an open research issue. We investigate the problem within a particular framework for planning and action: the XFRM framework <ref> [McDermott, 1992b, Beetz and McDermott, 1994] </ref>, which is based on the following principles: * Action: the course of action is specified by structured reactive plans. Structured reactive plans specify how the robot is to respond to sensory input in order to accomplish its jobs. <p> Several algorithms satisfying this property have been proposed for real-time robot planning [McDermott, 1992b, Drummond and Bresina, 1990, Dean et al., 1993, Lyons and Hendriks, 1992]. CHAPTER 7. PLANNING ONGOING ACTIVITIES 144 For our implementation of local planning, we have used the variant of the XFRM planning algorithm <ref> [McDermott, 1992b, Beetz and McDermott, 1994] </ref> that we have described in chapter 3. In XFRM planning is implemented as a search in plan space. A node in the space is a proposed plan; the initial node is a plan that represents the local planning problem.
Reference: [Beetz and McDermott, 1995] <author> M. Beetz and D. McDermott. </author> <title> A notation for expressing transformations of structured reactive plans. </title> <note> Submitted for Publication, </note> <year> 1995. </year>
Reference-contexts: Those tools make it possible to * project what might happen when a robot controller gets executed and return it as an execution scenarios [McDermott, 1994a, McDermott, 1992b]; * infer what might be wrong with a robot controller given an execution scenario <ref> [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995] </ref>; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans as Syntactic Objects For the purpose of planning RPL plans are internally represented as parse or code trees. <p> robot controller gets executed and return it as an execution scenarios [McDermott, 1994a, McDermott, 1992b]; * infer what might be wrong with a robot controller given an execution scenario <ref> [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995] </ref>; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans as Syntactic Objects For the purpose of planning RPL plans are internally represented as parse or code trees.
Reference: [Biundo et al., 1992] <author> S. Biundo, D. Dengler, and J. Koehler. </author> <title> Deductive planning and plan reuse in a command language environment. </title> <booktitle> In ECAI-92, </booktitle> <pages> pages 628-632, </pages> <publisher> Wiley, </publisher> <year> 1992. </year>
Reference-contexts: valuable information to guide the heuristic search for better plans. 3 The average complexity of transformational planning can also be reduced by applying efficient heuristic plan revision methods and testing the resulting plans [Newell, Langley et al., 1987] instead of relying on revision methods that guarantee improvements of the plan <ref> [Broy and Pepper, 1986, Biundo et al., 1992] </ref>. This technique often works because checking the correctness of a solution is computationally less complex than generating correct solutions [Kannan and Blum, 1989]. 1.6 Contributions To put this dissertation into context we have to review briefly other approaches to autonomous robot control. <p> Related Work Related works in AI planning include works on representations for planning [Lehrer, 1993] and formalizations of plan interpretation [Davis, 1992], which reason either about plans and their (physical) effects or plan interpretation processes. Another line of planning research <ref> [Biundo et al., 1992] </ref> focuses on meaning-preserving plan transformations, which assume perfect world models and unlimited computational resources. In addition, our approach contrasts with representations of engineered physical devices as considered in model-based troubleshooting [Hamscher, 1991].
Reference: [Boddy and Dean, 1989] <author> M. Boddy and T. Dean. </author> <title> Solving time-dependent planning problems. </title> <booktitle> In Proc. of the 11 th IJCAI, </booktitle> <pages> pages 979-984, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: EVALUATION 191 Time-dependent Planning A robot planning system has to treat planning time as a limited resource; i.e., it has to return plans for any allocation of computation time and has to reason about whether the expected gains from further planning will outweigh the costs of spending more planning time <ref> [Dean and Boddy, 1988, Boddy and Dean, 1989, Hanks, 1990a] </ref>. <p> for any allocation of computation time, and are expected to return better answers when more time is given (for example, iterative deepening [Korf, 1985] is an anytime search algorithm) The reasoning technique which copes with problems of assigning time ressources to subproblems in a problem-solving process is called deliberation scheduling <ref> [Boddy and Dean, 1989, Horvitz, 1988] </ref>. The goal of deliberation scheduling is to find an assignment of time resources to computation problems and planning efforts such that running the algorithms as specified in the schedule will produce a plan with maximal expected quality.
Reference: [Bonasso et al., 1992] <author> P. Bonasso, H. Antonisse, and M. Slack. </author> <title> A reactive robot system for find and fetch tasks in an outdoor environment. </title> <year> 1992. </year>
Reference-contexts: It has also the ability to evaporate and revise partially executed steps but only in the context of a highly repetitive task. We have seen that variants of this kind of interaction can be implemented in RPL (see section 7.2.1). Hybrid-layered control systems <ref> [Connell, 1992, Gat, 1992, Bonasso et al., 1992] </ref> can plan and execute in parallel by decoupling planning and execution with a sequencing layer which manages a queue of tasks. <p> The actions in the queue have priorities and ordering constraints. Both, the reactive and planning layer can add actions to the queue. The planning layer can also implement ordering constraints on the queue. Timely action is guaranteed because important reactions have high priority. The 3T <ref> [Bonasso et al., 1992] </ref>, ANIMATE AGENT ARCHITECTURE [Firby et al., 1995], and AT-LANTIS [Gat, 1992] are hybrid layered control architectures that that are based on RAP system. Other hybrid layered systems include [Arkin, 1991] and SSS [Connell, 1992].
Reference: [Bratman, 1987] <author> M. Bratman. </author> <title> Intention, Plans, and Practical Reason. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: PRS [Georgeff and Ingrand, 1989] action is determined by the interaction between an intended plan and the environmental contingencies. Rational agency as the result of beliefs, intentions, and desires of the agent (BDI architectures <ref> [Georgeff and Ingrand, 1989, Bratman, 1987] </ref>. Blackboard architectures [Hayes-Roth, 1989] are data-driven control systems that use meta-level reasoning to choose between different applicable courses of action. PRS and blackboard architectures do not provide the kinds of control abstractions for various kinds of synchronizations that are provided by RPL. <p> The methods, decision-theoretic, goal-based, action utility, and condition-action, require different types of information and time resources. An arbitrator chooses which method to use for determining the next action based on the constraints in the environment and the information available. IRMA <ref> [Bratman, 1987] </ref> is another architecture for controlling a resource-bounded autonomous agent.
Reference: [Breese and Fehling, 1988] <author> J. Breese and M. Fehling. </author> <title> Decision-theoretic control of problem solving: </title> <booktitle> Principles and architecture. In Proceedings of the 1988 Workshop on Uncertainty and Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference: [Brooks and Stein, 1994] <author> R. Brooks and L. Stein. </author> <title> Building brains for bodies. </title> <booktitle> Autonomous Robots, </booktitle> <volume> 1 </volume> <pages> 7-25, </pages> <year> 1994. </year>
Reference-contexts: Robot controllers that are organized in a subsumption architecture can be specified in the BEHAVIOR LANGUAGE [Brooks, 1990] and are compiled into networks of augmented finite state machines. The subsumption approach is targeted to equip autonomous robots with the behavioral repertoire typical for insects. The COG project <ref> [Brooks and Stein, 1994] </ref> is the biggest application of reactive and behavior-based control methods. The goal of the project is to build an integrated physical humanoid robot.
Reference: [Brooks, 1986a] <author> R. Brooks. </author> <title> Achieving artificial intelligence through building robots. </title> <institution> MIT AI LAB Memo 899, Massachussetts Institute of Technology, </institution> <month> May </month> <year> 1986. </year>
Reference-contexts: Of course, autonomous robot controllers already exist (although only for carefully engineered environments [Nilsson, 1984] or for a few fixed and specific tasks <ref> [Brooks, 1986a] </ref>). It is also not a new idea that robot controllers equipped with AI planning techniques can be more effective than fixed robot controllers (it has been implemented in order to control several robots [Nilsson, 1984, Winston, 1972, Giralt et al., 1979]).
Reference: [Brooks, 1986b] <author> R. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <pages> pages 14-23, </pages> <year> 1986. </year>
Reference-contexts: Other processes that are not part of the delivery such as watching out for opportunities and risks should also be active. The specification of robot behavior using concurrent control processes with different priorities is a powerful technique to deal with partly unknown and changing situations <ref> [Brooks, 1986b] </ref>. <p> This approach works only well if the right action can always be selected almost solely on the sensor data. CHAPTER 8. EVALUATION 182 Robots with reactive control systems (Allen <ref> [Brooks, 1986b] </ref>, Pengi [Agre and Chapman, 1987], Herbert [Connell, 1990]) work robustly in dynamic and unknown environments because they respond fast to sensor input. Disadvantages of reactive architectures are that they can usually handle only a small set of fixed jobs of limited complexity. <p> Also the information that can be sensed at any time has to be sufficient for selecting the right actions. While reactive approaches are characterized by fast response time to environmental events they are unable to deal with multiple and varying goals in a sophisticated manner. Behavior-based Architectures <ref> [Brooks, 1986b, Mataric, 1992, Steels, 1994] </ref>. Behavior-based architectures decompose the problem of autonomous control into special-purpose task-achieving modules that are connected directly to sensors and effectors. <p> Behavior-based systems have a fast sense/act cycle. The difficult problem is task arbitration, i.e., the resolution of conflicts when multiple control processes try to control the same effector simultaneously in different ways. CHAPTER 8. EVALUATION 183 Subsumption architecture <ref> [Brooks, 1986b] </ref>. The subsumption architecture is the most prominent architecture for reactive and behavior-based robot control. The main characteristics of the architecture are distributed, reflexive control and no explicit representation. The control system is organized in concurrent layers that interact (see figure 8.4). <p> It also provides a real time operating system. Behavior Language [Brooks, 1990]. The BEHAVIOR LANGUAGE is a rule-based real-time parallel robot programming language. It compiles into a an extended version of the sub-sumption architecture (or Augmented Finite State Machines) <ref> [Brooks, 1986b] </ref>. Behaviors CHAPTER 8. EVALUATION 186 are groups of rules. All rules are assumed to run in parallel and asynchronously. ALFA [Gat, 1992] is another language for the implementation of subsumption architectures. GAPPS and REX [Kaelbling, 1988].
Reference: [Brooks, 1990] <author> R. Brooks. </author> <title> The behavior language; user's guide. A.I. </title> <type> Memo 1227, </type> <institution> MIT AI Lab, </institution> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: The lower levels are simple, vital behaviors like avoiding obstacles or running away; the higher levels are more complex and task-directed, like map learning. Robot controllers that are organized in a subsumption architecture can be specified in the BEHAVIOR LANGUAGE <ref> [Brooks, 1990] </ref> and are compiled into networks of augmented finite state machines. The subsumption approach is targeted to equip autonomous robots with the behavioral repertoire typical for insects. The COG project [Brooks and Stein, 1994] is the biggest application of reactive and behavior-based control methods. <p> The L system provides a series of L functions and macros which simplify the creation of large numbers of threads which can communicate via a message passing paradigm. It also provides a real time operating system. Behavior Language <ref> [Brooks, 1990] </ref>. The BEHAVIOR LANGUAGE is a rule-based real-time parallel robot programming language. It compiles into a an extended version of the sub-sumption architecture (or Augmented Finite State Machines) [Brooks, 1986b]. Behaviors CHAPTER 8. EVALUATION 186 are groups of rules. All rules are assumed to run in parallel and asynchronously.
Reference: [Brooks, 1991a] <author> R. Brooks. </author> <title> Intelligence without reason. </title> <booktitle> In Proc. of the 12 th IJCAI, </booktitle> <pages> pages 569-595, </pages> <address> Sidney, Australia, </address> <year> 1991. </year>
Reference-contexts: Such robots act in partly unknown and changing worlds, have imperfect control over their effectors, and have only limited CHAPTER 1. INTRODUCTION 3 computational resources. Where the assumed conditions do not hold, robot controllers that compute optimal sequences of actions and execute them afterwards are only of limited use <ref> [Brooks, 1991a] </ref>. We advocate to accomplish reliability and efficiency through structured reactive controllers, collections of concurrent control routines that specify routine activities and can adapt themselves to non-standard situations by means of planning. <p> This approach requires correct and complete world models and has a tendency to cause relatively simple problems to become computationally intractable. To avoid the problems of classical controllers in coping with real environments in real-time, several researchers developed a different approach, often called situated robot control <ref> [Brooks, 1991a, Agre and Chapman, 1987, Rosenschein and Kaelbling, 1995] </ref>. In the situated control paradigm controllers are organized into interacting concurrent control processes. These processes continuously sense their environment and map the resulting sensor data into effector commands without deliberation and without maintaining large data structures.
Reference: [Brooks, 1991b] <author> R. Brooks. </author> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-159, </pages> <year> 1991. </year> <note> BIBLIOGRAPHY 198 </note>
Reference-contexts: Reactive control usually means two things. First, the controller has a very fast decision cycle (sense/act cycle). Second, the robot controller minimizes the use of internal state. The motto of reactive architectures is that the world is its own best model <ref> [Brooks, 1991b] </ref>. Having minimal state and in particular no symbolic world models avoids the efforts necessary for their construction and maintenance. Also the algorithms that use these symbolic models are often computationally very expensive.
Reference: [Brooks, 1993] <author> R. Brooks. </author> <title> L: A subset of common lisp. </title> <institution> Technical Report ???, MIT AI Lab, </institution> <year> 1993. </year>
Reference-contexts: We will start with the L system which is a dialect of Common Lisp and can be used to implement higher-level robot control languages, in particular using Lisp's macro facility. The remaining languages are more closely tight to specific robot control architectures. L System. The L system <ref> [Brooks, 1993] </ref> is a development system for a highly efficient dialect of Common Lisp which includes multi-threading extensions. The L system provides a series of L functions and macros which simplify the creation of large numbers of threads which can communicate via a message passing paradigm.
Reference: [Broy and Pepper, 1986] <author> M. Broy and P. Pepper. </author> <title> Program development as a formal activity. </title> <editor> In C. Rich and R. C. Waters, editors, </editor> <booktitle> Artificial Intelligence and Software Engineering, </booktitle> <pages> pages 123-131. </pages> <year> 1986. </year>
Reference-contexts: valuable information to guide the heuristic search for better plans. 3 The average complexity of transformational planning can also be reduced by applying efficient heuristic plan revision methods and testing the resulting plans [Newell, Langley et al., 1987] instead of relying on revision methods that guarantee improvements of the plan <ref> [Broy and Pepper, 1986, Biundo et al., 1992] </ref>. This technique often works because checking the correctness of a solution is computationally less complex than generating correct solutions [Kannan and Blum, 1989]. 1.6 Contributions To put this dissertation into context we have to review briefly other approaches to autonomous robot control.
Reference: [Bylander, 1991] <author> T. Bylander. </author> <title> Complexity results for planning. </title> <booktitle> In Proc. of the 12 th IJCAI, </booktitle> <pages> pages 274-279, </pages> <address> Sidney, Australia, </address> <year> 1991. </year>
Reference-contexts: The first is that causing the kind of behavior that people exhibit in their everyday activities requires sophisticated synchronization of concurrent control processes, monitoring of the execution, adequate reaction to unpredicted events, and recovery from 1 see <ref> [Erol et al., 1992, Bylander, 1991] </ref>, for some complexity results for propositional planning. 2 see [Zilberstein, 1995] for an discussion of the utility of planning. CHAPTER 1. INTRODUCTION 5 local execution failures. <p> But even if we restrict ourselves to simple plans and describe the behavior of control routines in a very simple propositional language, the planning problem quickly becomes intractable <ref> [Bylander, 1991] </ref>. Evaluating existing partial-order planning systems shows the effects of this intractability for typical planning problems. These planners often have to explore hundreds of partial plans in order to find plans that only require a handful of plan steps (e.g., [McDermott, 1994b]).
Reference: [Carbonell et al., 1992] <author> J. Carbonell, J. Blythe, O. Etzioni, Y. Gil, R. Joseph, D. Kahn, C. Knoblock, S. Minton, A. Perez, S. Reilly, M. Veloso, and X. Wang. </author> <title> Prodigy 4.0: the manual and tutorial. </title> <type> Technical Report, </type> <institution> Carnegie Mellon, </institution> <year> 1992. </year>
Reference-contexts: In addition, our approach contrasts with representations of engineered physical devices as considered in model-based troubleshooting [Hamscher, 1991]. XFRM-PRL reflects that reactive plans are not just connected components, or subplans, but contain control structures which coordinate subplans and recover from their failures. PRODIGY <ref> [Carbonell et al., 1992] </ref> and other partial-order planners use meta-languages for plans to implement search control rules. Khambhampati [Kambhampati, 1990] describes the structure of plans explicitly to facilitate plan adaptation. Chapter 6 Forestalling Behavior Flaws So far, we have described the tools for forestalling failures in structured reactive plans.
Reference: [Chapman, 1987] <author> D. Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: A plan is typically found by proposing an operator to solve part of the goal, then embedding that operator in a plan for the rest of the goal [McDermott, 1991b]. Unfortunately, the choice of operators and embeddings is not obvious, so we quickly get an intractable search problem <ref> [Chapman, 1987] </ref>. The best approach we see to reactive goal decomposition is to assume that for every goal G there is a routine plan for the job (ACHIEVE G) that can always be executed (and will, in benign circumstances, actually cause G to become true).
Reference: [Chapman, 1990] <author> D. Chapman. </author> <title> Vision, instruction, and action. </title> <type> Technical Report 1204, </type> <year> 1990. </year>
Reference-contexts: In HACKER skill is a set of canned answer procedures indexed by problems. HACKER acquires and improves its skills by solving a sequence of increasingly difficult problems and 1 Other work on designing routine plans: <ref> [Agre, 1991, Chapman, 1990, Agre and Horswill, 1992] </ref>. CHAPTER 8. EVALUATION 165 generalizing its solutions to these problems.
Reference: [Cohen and Howe, 1988] <author> P. Cohen and A. Howe. </author> <title> How evaluation guides ai research. </title> <journal> AI Magazine, </journal> <pages> pages 35-44, </pages> <year> 1988. </year>
Reference-contexts: In this chapter, we will demonstrate that taken together these techniques can improve the performance of autonomous robots considerably. Our evaluation of structured reactive controllers consists of three steps (see, for example, <ref> [Cohen and Howe, 1988] </ref>). First, we will argue that the computational problem that we seek to solve is an important specialization of the robot control/planning problem. We will explain how and under which circumstances programs that solve this computational problem can improve the performance of autonomous robots.
Reference: [Cohen et al., 1989] <author> P. Cohen, M. Greenberg, D. Hart, and A. Howe. </author> <title> Trial by fire: Understanding the design requirements for agents in complex environments. </title> <journal> AI Magazine, </journal> <pages> pages 32-48, </pages> <year> 1989. </year>
Reference-contexts: A good metric for evaluating the practical usefulness of structured reactive controllers is the amount by which they can improve the performance of the robots they control <ref> [Zilberstein, 1995, Cohen et al., 1989, Pollack and Ringuette, 1990] </ref>. The overall performance summarizes several measures such as the quality of the plan revisions, the time resources needed to compute these revisions, how robust plan revision is, and so on.
Reference: [Connell, 1987] <author> J. Connell. </author> <title> Creature design with the subsumption architecture. </title> <booktitle> In Proc. of the 10 th IJCAI, </booktitle> <pages> pages 1124-1126, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference-contexts: The condition-action rules select the appropriate actions for each sensor reading without deliberation. Consider, for example, the behavior required for following another robot, which has to maintain the distance and relative orientation to the other robot continuously CHAPTER 2. REACTIVITY 32 <ref> [Connell, 1987] </ref>. The desired state is to be behind the other robot at a certain distance. The behavior has to read the sensor data frequently and the robot drive has to adapt its speed and heading frequently.
Reference: [Connell, 1990] <author> J. Connell. </author> <title> Minimalist Mobile Robotics: A Colony-style Architecture for a Mobile Robot. </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: This approach works only well if the right action can always be selected almost solely on the sensor data. CHAPTER 8. EVALUATION 182 Robots with reactive control systems (Allen [Brooks, 1986b], Pengi [Agre and Chapman, 1987], Herbert <ref> [Connell, 1990] </ref>) work robustly in dynamic and unknown environments because they respond fast to sensor input. Disadvantages of reactive architectures are that they can usually handle only a small set of fixed jobs of limited complexity.
Reference: [Connell, 1992] <author> J. Connell. </author> <title> Sss: A hybrid architecture applied to robot navigation. </title> <booktitle> In Proceedings IEEE International Conference on Robotics and Automation, </booktitle> <year> 1992. </year>
Reference-contexts: It has also the ability to evaporate and revise partially executed steps but only in the context of a highly repetitive task. We have seen that variants of this kind of interaction can be implemented in RPL (see section 7.2.1). Hybrid-layered control systems <ref> [Connell, 1992, Gat, 1992, Bonasso et al., 1992] </ref> can plan and execute in parallel by decoupling planning and execution with a sequencing layer which manages a queue of tasks. <p> Timely action is guaranteed because important reactions have high priority. The 3T [Bonasso et al., 1992], ANIMATE AGENT ARCHITECTURE [Firby et al., 1995], and AT-LANTIS [Gat, 1992] are hybrid layered control architectures that that are based on RAP system. Other hybrid layered systems include [Arkin, 1991] and SSS <ref> [Connell, 1992] </ref>. Structured reactive controllers can avoid flaws in the behavior of the robot that hybrid layered controllers cannot.
Reference: [Davis and Hamscher, 1988] <author> R. Davis and W. Hamscher. </author> <title> Model-based reasoning: Troubleshooting. </title> <editor> In H. E. Shrobe, editor, </editor> <booktitle> Exploring Artificial Intelligence, </booktitle> <pages> pages 297-346. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: A plan failure diagnosis consists of a reference to the subplan that should be revised, a failure model, and the instantiation of the failure model that explains the failure. CHAPTER 6. FORESTALLING BEHAVIOR FLAWS 118 FAUST's diagnosis step performs model-based diagnosis <ref> [Davis et al., 1982, Davis and Hamscher, 1988, Davis, 1985] </ref>. In this step the plan is viewed as a device that has been constructed to accomplish the top-level commands. The declarative subplans and the subplan relationship are the planner's model of the internal structure of the device.
Reference: [Davis et al., 1982] <author> R. Davis, H. Shrobe, W. Hamscher, K. Wieckert, M. Shirley, and S. Polit. </author> <title> Diagnosis based on description of structure and function. </title> <booktitle> In Proc. of AAAI-82, </booktitle> <pages> pages 137-142, </pages> <address> Pittsburgh, PA, </address> <year> 1982. </year> <note> BIBLIOGRAPHY 199 </note>
Reference-contexts: A plan failure diagnosis consists of a reference to the subplan that should be revised, a failure model, and the instantiation of the failure model that explains the failure. CHAPTER 6. FORESTALLING BEHAVIOR FLAWS 118 FAUST's diagnosis step performs model-based diagnosis <ref> [Davis et al., 1982, Davis and Hamscher, 1988, Davis, 1985] </ref>. In this step the plan is viewed as a device that has been constructed to accomplish the top-level commands. The declarative subplans and the subplan relationship are the planner's model of the internal structure of the device.
Reference: [Davis, 1985] <author> R. Davis. </author> <title> Diagnostic reasoning based on structure and behavior. </title> <editor> In D. G. Bobrow, editor, </editor> <booktitle> Qualitative Reasoning about Physical Systems, </booktitle> <pages> pages 347-410. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: A plan failure diagnosis consists of a reference to the subplan that should be revised, a failure model, and the instantiation of the failure model that explains the failure. CHAPTER 6. FORESTALLING BEHAVIOR FLAWS 118 FAUST's diagnosis step performs model-based diagnosis <ref> [Davis et al., 1982, Davis and Hamscher, 1988, Davis, 1985] </ref>. In this step the plan is viewed as a device that has been constructed to accomplish the top-level commands. The declarative subplans and the subplan relationship are the planner's model of the internal structure of the device.
Reference: [Davis, 1992] <author> E. Davis. </author> <title> Semantics for tasks that can be interrupted or abandoned. </title> <editor> In J. Hendler, editor, </editor> <booktitle> AIPS-92, </booktitle> <pages> pages 37-44, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: It only introduces an additional task ((REDUCE G P)) that always has the same status as P. The interpretation of the REDUCE-statement introduces a small overhead but we can neglect this overhead if we assume the interpreter to be infinitely fast <ref> [Davis, 1992] </ref>. This assumption is reasonable because the time for setting or testing the value of a program variable is negligible compared to the time needed for moving the robot's arm or going to another location. Restartability Restartability is another important property of structured reactive plans. <p> Related Work Related works in AI planning include works on representations for planning [Lehrer, 1993] and formalizations of plan interpretation <ref> [Davis, 1992] </ref>, which reason either about plans and their (physical) effects or plan interpretation processes. Another line of planning research [Biundo et al., 1992] focuses on meaning-preserving plan transformations, which assume perfect world models and unlimited computational resources.
Reference: [Dean and Boddy, 1988] <author> T. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proc. of AAAI-88, </booktitle> <pages> pages 49-54, </pages> <address> St. Paul, MN, </address> <year> 1988. </year>
Reference-contexts: EVALUATION 191 Time-dependent Planning A robot planning system has to treat planning time as a limited resource; i.e., it has to return plans for any allocation of computation time and has to reason about whether the expected gains from further planning will outweigh the costs of spending more planning time <ref> [Dean and Boddy, 1988, Boddy and Dean, 1989, Hanks, 1990a] </ref>.
Reference: [Dean and Bonasso, 1993] <author> T. Dean and P. Bonasso. </author> <title> The 1992 aaai robot exhibition and competition. </title> <journal> AI Magazine, </journal> <volume> 14(1) </volume> <pages> 35-48, </pages> <year> 1993. </year>
Reference-contexts: Finally, the research presents novel and more powerful plan representation and inference techniques for planning research. 1.4.1 Relevance for Autonomous Robot Control Accomplishing everyday activities in our world simulator poses problems for a simulated robot that resembles those addressed by current robotic research <ref> [Dean and Bonasso, 1993, Konolige, 1994, Simmons, 1995] </ref>. In some respects our world simulator challenges robot controllers in ways that real environments challenge real robots: the simulated environment is complex, it changes, and time in the simulator passes at a realistic speed. <p> After discussing the indi 19 CHAPTER 2. REACTIVITY 20 vidual control concepts we show how the different concepts can be effectively combined within a structured reactive controller, which serves as a programming framework to realize the robot's routine activities. 2.1 The DELIVERYWORLD Although technology is progressing rapidly <ref> [Dean and Bonasso, 1993, Konolige, 1994, Simmons, 1995] </ref>, we still cannot equip robots with the repertoire of robust routines that they need to accomplish daily activities reliably and time-effectively. Perceiving the necessary and relevant information in real time is another serious obstacle.
Reference: [Dean and Wellmann, 1991] <author> T. Dean and M. Wellmann. </author> <title> Planning and Control. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Figure 8.3 shows different types of control architectures ordered along this dimension. At the left end of the spectrum are control systems, which try to model the environment at a very detailed level using complex mathematical models like differential equations <ref> [Passino and Antsaklis, 1989, Dean and Wellmann, 1991] </ref>. At the right end of the spectrum are classical planning architectures, which make strong simplifying assumptions about the environment but reason CHAPTER 8. EVALUATION 181 very carefully about how jobs can be accomplished. In between are reactive, behavior-based, and hybrid deliberative systems.
Reference: [Dean et al., 1993] <author> T. Dean, L. Kaelbling, J. Kirman, and A. Nicholson. </author> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proc. of AAAI-93, </booktitle> <pages> pages 574-579, </pages> <year> 1993. </year>
Reference: [Dechter and Pearl, 1985] <author> R. Dechter and J. Pearl. </author> <title> Generalized best-first search strategies and the optimality of A*. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 32(3) </volume> <pages> 505-536, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: This typically overestimates the severity because most plans resulting from plan revisions are slower. However, by CHAPTER 6. FORESTALLING BEHAVIOR FLAWS 127 making plan failures look more severe than they are we can make sure that the planner tries to eliminate them <ref> [Dechter and Pearl, 1985] </ref>. 6.1.5 The Elimination of Behavior Flaws The algorithm for producing new candidate plans is straightforward. It takes a plan and a diagnosed plan failure as its argument and returns a set of new plans.
Reference: [DeJong and Bennett, 1995] <author> G. DeJong and S. Bennett. </author> <title> Extending classical planning to real-world execution with machine learning. </title> <booktitle> In Proc. of the 14 th IJCAI, </booktitle> <pages> pages 1153-1161, </pages> <address> Montreal, Canada, </address> <year> 1995. </year>
Reference-contexts: More recently, Mitchell [1990, 1990] and DeJong and Bennet <ref> [DeJong and Bennett, 1995] </ref> have proposed novel algorithms for learning routines for real robots. * Another costly procedure in the development of structured reactive controllers is the specification of models of typical flaws and plan revision methods that forestall these flaws that have to be provided by a programmer.
Reference: [Donald, 1990] <author> B. Donald. </author> <title> Planning multi-step error detection and recovery strategies. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 9(1) </volume> <pages> 3-60, </pages> <year> 1990. </year>
Reference-contexts: In many cases, plan failures cannot be detected from the robot's sensors and therefore, the interpreter does not signal the plan failures. A plan-generated failure, also called cognizant plan failure <ref> [Donald, 1990] </ref>, is signalled by the plan itself during execution or projection, by use of the RPL FAIL construct. Plan failures that CHAPTER 6. FORESTALLING BEHAVIOR FLAWS 112 have not been detected by the structured reactive controller have to be treated differently from those that have been detected.
Reference: [Doyle et al., 1986] <author> R. Doyle, D. Atkinson, and R. Doshi. </author> <title> Generating perception requests and expectations to verify the execution of plans. </title> <booktitle> In Proc. of AAAI-86, </booktitle> <pages> pages 268-272, </pages> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: Several planners can automatically add steps for verifying the executability of subsequent parts of the plan by analyzing the causal dependency between the steps in the plan <ref> [Doyle et al., 1986] </ref>. However, adding verification steps based only on the causal structure is too simplistic. Our delivery robot in the DELIVERYWORLD cannot and should not verify that BALL-23 is at location h10,10i while going from h0,0i to h0,3i.
Reference: [Draper et al., 1994] <author> D. Draper, S. Hanks, and D. Weld. </author> <title> Probabilistic planning with information gathering and contingent execution. </title> <editor> In K. Hammond, editor, </editor> <booktitle> Proc. 2nd. Int. Conf. on AI Planning Systems. </booktitle> <publisher> Morgan Kauf-mann, </publisher> <year> 1994. </year>
Reference: [Drummond and Bresina, 1990] <author> M. Drummond and J. Bresina. </author> <title> Anytime synthetic projection: Maximizing the probability of goal satisfaction. </title> <booktitle> In Proc. of AAAI-90, </booktitle> <pages> pages 138-144, </pages> <year> 1990. </year>
Reference-contexts: Sensitivity to protection violations is achieved by adding the statement (PROTECT ...) as a policy for the reducer. A top-level command (ACHIEVE g) has the same meaning as (GOAL tag g). CHAPTER 4. TRANSPARENT REACTIVE PLANS 86 GAPPS [Kaelbling, 1988] and ERE <ref> [Drummond and Bresina, 1990] </ref> also have declarative achievement and maintenance statements for specifying top-level commands. In GAPPS these statements are used as abstract programming constructs. <p> CHAPTER 8. EVALUATION 190 Planning Reactive Behavior Robot planners have to synthesize plans that implement any problem-solving behavior necessary to solve complex tasks in its environment not just sequences of primitive robot actions [McDermott, 1990]. ERE (Entropy Reduction Engine) contains a synthetic projection algorithm <ref> [Drummond and Bresina, 1990] </ref>. Given given a behavioral constraint and a probabilistic causal theory of the robot actions, ERE attempts to find a directed acyclic graph of situation control rules [Drummond, 1989] that maximizes the probability of successful task performance. The planning algorithm consists of two steps: traverse and robustify.
Reference: [Drummond et al., 1993] <author> M. Drummond, K. Swanson, J. Bresina, and R. Levinson. </author> <title> Reaction-first search. 1993. BIBLIOGRAPHY 200 </title>
Reference-contexts: In contrast, XFRM computes plans that are represented in RPL, a more complex plan representation language. Dean et al. [1993] propose a planning algorithm with the same purpose as ERE based on the theory of Markov decision problems. Another successor of the ERE planning algorithm is the reaction-first algorithm <ref> [Drummond et al., 1993] </ref> that computes plan prefixes that can be substituted for the default plan to increase the probability of goal satisfaction.
Reference: [Drummond, 1989] <author> M. Drummond. </author> <title> Situated control rules. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> KR'89: Proc. of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 103-113. </pages> <publisher> Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: The goal of the project is to build an integrated physical humanoid robot. Other approaches to the implementation of reactive and behavior-based control systems include situated automata [Rosenschein, 1985, Rosenschein and Kaelbling, 1995], the ALFA language [Gat, 1991], Situated Control Rules <ref> [Drummond, 1989] </ref>. Structured reactive controllers add to behavior-based systems the capability to make control decisions that require foresight and a change in the intended course of action. Hybrid Deliberative Robot Control Hybrid architectures [Hanks and Firby, 1990] integrate deliberation and action. They expand and schedule tasks before executing them. <p> ERE (Entropy Reduction Engine) contains a synthetic projection algorithm [Drummond and Bresina, 1990]. Given given a behavioral constraint and a probabilistic causal theory of the robot actions, ERE attempts to find a directed acyclic graph of situation control rules <ref> [Drummond, 1989] </ref> that maximizes the probability of successful task performance. The planning algorithm consists of two steps: traverse and robustify. The traverse step constructs a sequence of steps that achieves the given goals efficiently and with relatively high probability.
Reference: [Engelson, 1994] <author> S. Engelson. </author> <title> Passive Map Learning and Visual Place Recognition. </title> <type> Technical report 1032, </type> <institution> Yale University, Department of Computer Science, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: To do this world simulators have to be designed carefully so that they challenge robot controllers in the same way as real environments and robots would [Hanks et al., 1993, Hanks and Badr, 1991] and that they are justified with respect to the current state of robotic research <ref> [Engelson, 1994] </ref>. On the upside, world simulators allow researchers to run, debug, and test robot controllers for thousands of hours, a process necessary for the development and evaluation of software of this complexity. <p> Despite the simplicity we can generate place recognition problems by defining as noisy the logical sensor LOOK-FOR-SIGNPOST. A more realistic model of place recognition and navigation is described in <ref> [Engelson, 1994] </ref>. Besides cameras, hand force sensors that measure the force applied by the robot's grippers are the only other sensors the robot uses. If the hand is holding an object this force measure is high otherwise it is low.
Reference: [Erol et al., 1992] <author> K. Erol, D. S. Nau, and V. S. Subrahmanian. </author> <booktitle> On the complexity of domain-independent planning. </booktitle> <pages> pages 381-386, </pages> <year> 1992. </year>
Reference-contexts: The first is that causing the kind of behavior that people exhibit in their everyday activities requires sophisticated synchronization of concurrent control processes, monitoring of the execution, adequate reaction to unpredicted events, and recovery from 1 see <ref> [Erol et al., 1992, Bylander, 1991] </ref>, for some complexity results for propositional planning. 2 see [Zilberstein, 1995] for an discussion of the utility of planning. CHAPTER 1. INTRODUCTION 5 local execution failures.
Reference: [Etzioni, 1989] <author> O. Etzioni. </author> <title> Tractable decision-analytic control. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> KR'89: Proc. of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 114-125. </pages> <publisher> Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: In general, methods for measuring the benefit a robot obtains from accomplishing a job g work according to the following pattern. First, they determine what is to be achieved and when. Second, they compute the intrinsic value of accomplishing the job g <ref> [Etzioni, 1989] </ref>. For instance, the intrinsic value of a delivery could depend on the weight and size of the object to be delivered and the distance from the current location of the object to its destination.
Reference: [Fikes and Nilsson, 1971] <author> R. E. Fikes and N. J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: Shakey's robot control system manages a global symbolic world model that is assumed to be correct and complete. The system works as follows: given a conjunctive goal GOAL, the planning system STRIPS <ref> [Fikes and Nilsson, 1971] </ref> computes a sequence of plan steps (s 1 , ... s n ) that achieves GOAL CHAPTER 7. PLANNING ONGOING ACTIVITIES 151 when executed in the current situation, which is then executed.
Reference: [Fikes et al., 1972] <author> R. Fikes, P. Hart, and N. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3(4) </volume> <pages> 189-208, </pages> <year> 1972. </year>
Reference-contexts: this kind of planned iterative behavior have been implemented for the kitting robot [Lyons and Hendriks, 1992] and for controlling the walking behavior of Ambler [Simmons, 1990]. 7.2.2 Plan Execution a la Shakey The following RPL code piece specifies a simplified version of Shakey's [Nilsson, 1984] plan execution system PLANEX <ref> [Fikes et al., 1972] </ref>. Shakey's robot control system manages a global symbolic world model that is assumed to be correct and complete. <p> SIPE [Wilkins, 1988] and PLANEX <ref> [Fikes et al., 1972] </ref> are examples of planning systems that replan after the detection of irrecoverable plan failures. 7.2.5 Some Robot Control Architectures Since RPL is a single high-level language to coordinate planning and physical actions, we can implement a variety of robot control architectures in RPL. <p> Most systems implement a particular type of coordination between planning and execution. Others leave the coordination flexible. Our approch proposes to specify the interaction between planning and execution as part of the robot controllers and provides the necessary language primitives to support this. PLANEX <ref> [Fikes et al., 1972] </ref> and SIPE [Wilkins, 1988] reason to recover from execution failures. The systems first generate a complete plan and execute it afterwards.
Reference: [Firby et al., 1995] <author> J. Firby, R. Kahn, P. Prokopowitz, and M. Swain. </author> <title> An architecture for vision and action. </title> <editor> In C. Mellish, editor, </editor> <booktitle> Proc. of the 14 th IJCAI, </booktitle> <pages> pages 72-79, </pages> <year> 1995. </year>
Reference-contexts: It must also be able to recover locally from detected plan failures. 4. Many assumptions can be justified by current robotic research. The primitive control routines that drive our robot are implemented in the same way as the skills used by a real robot for trash collection <ref> [Firby et al., 1995] </ref>. This robot uses skills like finding a small (large) object on the floor, turning the pan tilt head to track the target location, and moving to the target while avoiding obstacles. <p> The plan resulting from this revision is shown below. 6.3 Some Failure Types and their Revisions Many autonomonous robots use special purpose planning capabilities such as motion planning [Latombe, 1991], navigation planning, or revising cleaning plans to direct the robot into areas with high expected concentration of trash <ref> [Firby et al., 1995] </ref>. FAUST can be tailored to particular robots, jobs, and environments by defining failure mod els and plan revision methods for avoiding the failures. For example, because the delivery robot in the DELIVERYWORLD should perform its deliveries in time and deliver objects CHAPTER 6. <p> Both, the reactive and planning layer can add actions to the queue. The planning layer can also implement ordering constraints on the queue. Timely action is guaranteed because important reactions have high priority. The 3T [Bonasso et al., 1992], ANIMATE AGENT ARCHITECTURE <ref> [Firby et al., 1995] </ref>, and AT-LANTIS [Gat, 1992] are hybrid layered control architectures that that are based on RAP system. Other hybrid layered systems include [Arkin, 1991] and SSS [Connell, 1992]. Structured reactive controllers can avoid flaws in the behavior of the robot that hybrid layered controllers cannot.
Reference: [Firby, 1989] <author> J. Firby. </author> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> Technical report 672, </type> <institution> Yale University, Department of Computer Science, </institution> <year> 1989. </year>
Reference-contexts: An algorithm different from Firby's memory update algorithm was required because Firby's does not need to provide a single consistent view of a location <ref> [Firby, 1989] </ref>. 2.2.8 The Structure of Routine Activities There are several features of everyday activity for which we have not yet discussed any implementation methods. First, we have said that routine activities are skills associated with the problems they solve [Sussman, 1977]. <p> If the plan tries the conjunctive goal at least three times, the plan would not fail because of interactions between the two subgoals. Trying plan steps repeatedly and monitoring the success is one of the basic methods used in RAP to make the reactive plans robust <ref> [Firby, 1989] </ref>. An alternative revision is to introduce an additional subgoal (ON C TABLE) and add ordering constraints on the subgoals. The revised plan requires the minimal number of physical actions to achieve the task. <p> This way the planner can still have the illusion of plans being sequences of plan steps and many existing planning techniques carry over to robot control more or less the way they are. The RAP interpreter <ref> [Firby, 1989, Firby, 1992] </ref> is a plan interpreter that allows a planner to keep this illusion. The planner can generate partially ordered sets of actions (goal steps) and pass them to the RAP interpreter. <p> These explicit representations allow XFRM to revise and specialize reactive plans if the robot acquires more information about the environment or if it changes its preferences, for instance, when it changes from a slow and robust execution mode to a fast and less reliable one. RAP (Reactive Action Packages) <ref> [Firby, 1989, Firby, 1995] </ref>. RAP is a language for specifying situation-driven interpretation of sketchy plans, plans that contain steps that are not immediately executable or underspecified. The RAP system uses reactive action packages to perform sketchy plan steps. Reactive action packages contain situation-specific methods for achieving a particular goal.
Reference: [Firby, 1992] <author> J. Firby. </author> <title> Building symbolic primitives with continuous control routines. </title> <editor> In J. Hendler, editor, </editor> <booktitle> AIPS-92, </booktitle> <pages> pages 62-69, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: A failed grasp can be detected if fingers have minimal distance to each other while the hand force is still zero. Detecting the termination of actions boils down to discretizing continuous processes <ref> [Firby, 1992] </ref>. The last issue in the implementation of behavior modules that must be discussed here is the way the control processes communicate with the RPL control routines. RPL distinguishes between two kinds of communication: one within a thread of control and the other between different threads of control. <p> This way the planner can still have the illusion of plans being sequences of plan steps and many existing planning techniques carry over to robot control more or less the way they are. The RAP interpreter <ref> [Firby, 1989, Firby, 1992] </ref> is a plan interpreter that allows a planner to keep this illusion. The planner can generate partially ordered sets of actions (goal steps) and pass them to the RAP interpreter.
Reference: [Firby, 1994] <author> J. Firby. </author> <title> Task networks for controlling continuous processes. </title> <editor> In Kris Hammond, editor, </editor> <booktitle> AIPS-94, </booktitle> <pages> pages 49-54, </pages> <publisher> Morgan Kauf-mann, </publisher> <year> 1994. </year>
Reference-contexts: RPL provides a construct (EVAP-PROTECT a b) that blocks the evaporation of a control process until all critical stretches of behavior b are completed. The control processes recognize simultaneously that the desired behavior is completed and whether it has been completed successfully or unsuccessfully <ref> [McDermott, 1992b, Firby, 1994] </ref>. For instance, the successful completion of a grasp is detected if the force measured by the hand force sensor exceeds a certain threshold. A failed grasp can be detected if fingers have minimal distance to each other while the hand force is still zero.
Reference: [Firby, 1995] <author> J. Firby. </author> <title> The RAP language manual. Animate Agent Project Working Note AAP-6, </title> <institution> University of Chicago, </institution> <year> 1995. </year>
Reference-contexts: These explicit representations allow XFRM to revise and specialize reactive plans if the robot acquires more information about the environment or if it changes its preferences, for instance, when it changes from a slow and robust execution mode to a fast and less reliable one. RAP (Reactive Action Packages) <ref> [Firby, 1989, Firby, 1995] </ref>. RAP is a language for specifying situation-driven interpretation of sketchy plans, plans that contain steps that are not immediately executable or underspecified. The RAP system uses reactive action packages to perform sketchy plan steps. Reactive action packages contain situation-specific methods for achieving a particular goal.
Reference: [Gat, 1991] <author> E. Gat. Alfa: </author> <title> A language for programming reactive robotic control systems. </title> <booktitle> In Proceedings IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1116-1121, </pages> <year> 1991. </year> <note> BIBLIOGRAPHY 201 </note>
Reference-contexts: The goal of the project is to build an integrated physical humanoid robot. Other approaches to the implementation of reactive and behavior-based control systems include situated automata [Rosenschein, 1985, Rosenschein and Kaelbling, 1995], the ALFA language <ref> [Gat, 1991] </ref>, Situated Control Rules [Drummond, 1989]. Structured reactive controllers add to behavior-based systems the capability to make control decisions that require foresight and a change in the intended course of action. Hybrid Deliberative Robot Control Hybrid architectures [Hanks and Firby, 1990] integrate deliberation and action.
Reference: [Gat, 1992] <author> E. Gat. </author> <title> Integrating planning and reacting in a heterogeneous asynchronous architecture for controlling real-world mobile robots. </title> <year> 1992. </year>
Reference-contexts: It has also the ability to evaporate and revise partially executed steps but only in the context of a highly repetitive task. We have seen that variants of this kind of interaction can be implemented in RPL (see section 7.2.1). Hybrid-layered control systems <ref> [Connell, 1992, Gat, 1992, Bonasso et al., 1992] </ref> can plan and execute in parallel by decoupling planning and execution with a sequencing layer which manages a queue of tasks. <p> Both, the reactive and planning layer can add actions to the queue. The planning layer can also implement ordering constraints on the queue. Timely action is guaranteed because important reactions have high priority. The 3T [Bonasso et al., 1992], ANIMATE AGENT ARCHITECTURE [Firby et al., 1995], and AT-LANTIS <ref> [Gat, 1992] </ref> are hybrid layered control architectures that that are based on RAP system. Other hybrid layered systems include [Arkin, 1991] and SSS [Connell, 1992]. Structured reactive controllers can avoid flaws in the behavior of the robot that hybrid layered controllers cannot. <p> The BEHAVIOR LANGUAGE is a rule-based real-time parallel robot programming language. It compiles into a an extended version of the sub-sumption architecture (or Augmented Finite State Machines) [Brooks, 1986b]. Behaviors CHAPTER 8. EVALUATION 186 are groups of rules. All rules are assumed to run in parallel and asynchronously. ALFA <ref> [Gat, 1992] </ref> is another language for the implementation of subsumption architectures. GAPPS and REX [Kaelbling, 1988]. GAPPS allows for the specification of reactive plans in terms of declarative tasks.
Reference: [Georgeff and Ingrand, 1989] <author> M. Georgeff and F. Ingrand. </author> <title> Decision making in an embedded reasing system. </title> <booktitle> In Proc. of the 11 th IJCAI, </booktitle> <pages> pages 972-978, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: The vital behavior are global policies are always active. The difference is that in RPL the task queue is not manipulated explicitly but implicitly as specified by the semantics of RPL constructs. PRS <ref> [Georgeff and Ingrand, 1989] </ref> action is determined by the interaction between an intended plan and the environmental contingencies. Rational agency as the result of beliefs, intentions, and desires of the agent (BDI architectures [Georgeff and Ingrand, 1989, Bratman, 1987]. <p> PRS [Georgeff and Ingrand, 1989] action is determined by the interaction between an intended plan and the environmental contingencies. Rational agency as the result of beliefs, intentions, and desires of the agent (BDI architectures <ref> [Georgeff and Ingrand, 1989, Bratman, 1987] </ref>. Blackboard architectures [Hayes-Roth, 1989] are data-driven control systems that use meta-level reasoning to choose between different applicable courses of action. PRS and blackboard architectures do not provide the kinds of control abstractions for various kinds of synchronizations that are provided by RPL. <p> The agent achieves its goals by choosing actions that bring it from the belief worlds to the intention worlds. BDI architectures represent incomplete knowledge as multiple possible worlds and alternative actions as branches within a possible world. PRS (Procedural Reasoning System) <ref> [Georgeff and Ingrand, 1989, Georgeff and Lansky, 1987] </ref> is an agent control system based on a BDI architecture.
Reference: [Georgeff and Lansky, 1987] <author> M. Georgeff and A. Lansky. </author> <title> Reactive reasoning and planning. </title> <booktitle> In Proc. of AAAI-87, </booktitle> <pages> pages 677-682, </pages> <address> Seattle, WA, </address> <year> 1987. </year>
Reference-contexts: The agent achieves its goals by choosing actions that bring it from the belief worlds to the intention worlds. BDI architectures represent incomplete knowledge as multiple possible worlds and alternative actions as branches within a possible world. PRS (Procedural Reasoning System) <ref> [Georgeff and Ingrand, 1989, Georgeff and Lansky, 1987] </ref> is an agent control system based on a BDI architecture.
Reference: [Giralt et al., 1979] <author> G. Giralt, R. Sobek, and R. Chatila. </author> <title> A multi-level planning and navigation system for a mobile robot: A first approach to hilare. </title> <booktitle> In Proc. of the 6 th IJCAI, </booktitle> <pages> pages 335-337, </pages> <address> Tokio, </address> <year> 1979. </year>
Reference-contexts: It is also not a new idea that robot controllers equipped with AI planning techniques can be more effective than fixed robot controllers (it has been implemented in order to control several robots <ref> [Nilsson, 1984, Winston, 1972, Giralt et al., 1979] </ref>). The main characteristic of such deliberative robot controllers is that they carefully reason through all actions before they execute them. Deliberative robot controllers sense their environments in order to maintain a symbolic representation of the relevant aspects of their environments.
Reference: [Haddawy and Hanks, 1990] <author> P. Haddawy and S. Hanks. </author> <title> Issues in decision-theoretic planning: Symbolic goals and utilities. </title> <editor> In K. Sycara, editor, </editor> <booktitle> Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pages 48-58, </pages> <year> 1990. </year>
Reference-contexts: Benefit models that are specific to declarative statements combine the results of the first three steps into a number that summarizes the benefit the robot gains from accomplishing g. The benefits a robot obtains in a particular execution scenario is the sum of the benefits over all top-level command <ref> [Haddawy and Hanks, 1990, Haddawy and Hanks, 1995] </ref>. Hanks and Haddawy [1995] describe a utility model for a robot that includes concepts like temporally scoped goals, partial goal satisfaction, and the cost of resource consumption. Many of their ideas are incorporated here. <p> We have restricted ourselves to these aspects, because so far these are the ones that can be checked by the plan simulator. A thorough discussion of more expressive utility models for plans, including resources other than time, partial goal satisfaction, etc., can be found in <ref> [Haddawy and Hanks, 1990] </ref>. Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan.
Reference: [Haddawy and Hanks, 1995] <author> P. Haddawy and S. Hanks. </author> <title> Utility models for goal-directed decision-theoretic planning. </title> <note> Submitted for publication, AI Journal, </note> <year> 1995. </year>
Reference-contexts: Benefit models that are specific to declarative statements combine the results of the first three steps into a number that summarizes the benefit the robot gains from accomplishing g. The benefits a robot obtains in a particular execution scenario is the sum of the benefits over all top-level command <ref> [Haddawy and Hanks, 1990, Haddawy and Hanks, 1995] </ref>. Hanks and Haddawy [1995] describe a utility model for a robot that includes concepts like temporally scoped goals, partial goal satisfaction, and the cost of resource consumption. Many of their ideas are incorporated here.
Reference: [Haddawy and Rendell, 1990] <author> P. Haddawy and L. Rendell. </author> <title> Planning and decision theory. </title> <journal> The Knowledge Engineering Review, </journal> <volume> 5 </volume> <pages> 15-33, </pages> <year> 1990. </year>
Reference: [Hallam and Hayes, 1994] <author> B. Hallam and G. Hayes. </author> <title> Comparing robot and animal behavior. </title> <type> DAI Research Report 598, </type> <institution> University of Edinburgh, </institution> <year> 1994. </year>
Reference-contexts: One kind of exceptional state are other robots acting in the neighborhood of the robot. Again the same kind of behavior can be found in animals: even when occupied with a particular activity, animals generally notice and orient towards new features in their surrounding environment <ref> [Hallam and Hayes, 1994] </ref>. The time that is needed to move around and manipulate objects often gives the robot enough computation time to adjust to the exceptional states by means of planning.
Reference: [Hammond et al., 1995] <author> K. Hammond, T. Converse, and J. Grass. </author> <title> The stabilization of environments. </title> <journal> Artificial Intelligence, </journal> <volume> 73, </volume> <year> 1995. </year>
Reference-contexts: An RPL plan for achieving this behavior could ask the robot to stop going whenever the hand force sensor drops to zero, pick up the lost object, and continue on to hX,Yi. CHAPTER 4. TRANSPARENT REACTIVE PLANS 73 Another important class of declarative goals are stabilization goals. Stabilization goals <ref> [Hammond et al., 1995] </ref> make routine activities more robust and efficient by actively stabilizing aspects of the environment. An example of a stabilization goal is putting glasses back in the cupboard after using them.
Reference: [Hammond, 1989] <author> K. Hammond. </author> <title> Case-Based Planning. </title> <publisher> Academic Press, Inc., </publisher> <year> 1989. </year>
Reference-contexts: Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan. The transformational planning systems that are most closely related to XFRM are HACKER [Sussman, 1977, Sussman, 1990], CHEF <ref> [Hammond, 1989, Hammond, 1990] </ref>, and GORDIUS [Simmons, 1988a, Simmons, 1988b, Simmons, 1992]. Given a set of tasks, transformational planners generate a plan hypothesis that can be projected and revise the plan hypothesis until it is good enough.
Reference: [Hammond, 1990] <author> K. Hammond. </author> <title> Explaining and repairing plans that fail. </title> <journal> Artificial Intelligence, </journal> <volume> 45(1) </volume> <pages> 173-228, </pages> <year> 1990. </year>
Reference-contexts: Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan. The transformational planning systems that are most closely related to XFRM are HACKER [Sussman, 1977, Sussman, 1990], CHEF <ref> [Hammond, 1989, Hammond, 1990] </ref>, and GORDIUS [Simmons, 1988a, Simmons, 1988b, Simmons, 1992]. Given a set of tasks, transformational planners generate a plan hypothesis that can be projected and revise the plan hypothesis until it is good enough. <p> This step is implemented in GORDIUS [Simmons, 1988b] as the localization of faulty assumptions made by the planner or projector. In the CHEF planner a detailed explanation for bugs is generated by executing questioning scripts <ref> [Hammond, 1990] </ref>. The transformations for plan repair are indexed either by the faulty assumptions (GORDIUS) or by explanations (CHEF).
Reference: [Hamscher, 1991] <author> W. Hamscher. </author> <title> Modeling digital circuits for troubleshooting. </title> <journal> Artificial Intelligence, </journal> <volume> 51 </volume> <pages> 223-271, </pages> <year> 1991. </year>
Reference-contexts: Another line of planning research [Biundo et al., 1992] focuses on meaning-preserving plan transformations, which assume perfect world models and unlimited computational resources. In addition, our approach contrasts with representations of engineered physical devices as considered in model-based troubleshooting <ref> [Hamscher, 1991] </ref>. XFRM-PRL reflects that reactive plans are not just connected components, or subplans, but contain control structures which coordinate subplans and recover from their failures. PRODIGY [Carbonell et al., 1992] and other partial-order planners use meta-languages for plans to implement search control rules.
Reference: [Hanks and Badr, 1991] <author> S. Hanks and A. Badr. </author> <title> Critiquing the TILEWORLD: Agent architectures, planning benchmarks, and experimental methodology. </title> <type> Technical Report 91-10-31, </type> <institution> Dept. of Computer Science and Engineering, Univ. of Washington, </institution> <year> 1991. </year> <note> BIBLIOGRAPHY 202 </note>
Reference-contexts: Therefore, it is important to minimize the risk that the results obtained are irrelevant. To do this world simulators have to be designed carefully so that they challenge robot controllers in the same way as real environments and robots would <ref> [Hanks et al., 1993, Hanks and Badr, 1991] </ref> and that they are justified with respect to the current state of robotic research [Engelson, 1994].
Reference: [Hanks and Firby, 1990] <author> S. Hanks and R. J. Firby. </author> <title> Issues and architectures for planning and execution. </title> <booktitle> In Proc. of the Workshop on Innovative Approaches to Planning, </booktitle> <pages> pages 59-70, </pages> <booktitle> Scheduling and Control, </booktitle> <address> San Diego, CA, </address> <year> 1990. </year>
Reference-contexts: Structured reactive controllers add to behavior-based systems the capability to make control decisions that require foresight and a change in the intended course of action. Hybrid Deliberative Robot Control Hybrid architectures <ref> [Hanks and Firby, 1990] </ref> integrate deliberation and action. They expand and schedule tasks before executing them. We will differentiate here between three types of hybrid control systems: hybrid layered control systems, bounded rationality architectures, and Belief/Desire/Intention architectures. Hybrid layered control architectures.
Reference: [Hanks et al., 1993] <author> S. Hanks, M. Pollack, and P. Cohen. </author> <title> Benchmarks, test beds, controlled experimentation, and the design of agent architectures. </title> <journal> AI Magazine, </journal> <volume> 14(4) </volume> <pages> 17-42, </pages> <year> 1993. </year>
Reference-contexts: Therefore, it is important to minimize the risk that the results obtained are irrelevant. To do this world simulators have to be designed carefully so that they challenge robot controllers in the same way as real environments and robots would <ref> [Hanks et al., 1993, Hanks and Badr, 1991] </ref> and that they are justified with respect to the current state of robotic research [Engelson, 1994]. <p> An extensive discussion of the role of testbeds and empirical evaluation of agent architectures can be found in <ref> [Hanks et al., 1993] </ref>. 2.2 The Implementation of Routine Activities This section analyzes implementation strategies for delivery routines and describe how these strategies can be implemented in RPL [McDermott, 1991a]. RPL programs look very much like LISP programs that make use of control abstractions typical of structured concurrent programming languages.
Reference: [Hanks, 1990a] <author> S. Hanks. </author> <title> Controlling inference in planning systems: Who, what, when, why, and how. </title> <type> Technical Report #90-04-01, </type> <institution> Department of Computer Science, University of Washington, </institution> <year> 1990. </year>
Reference-contexts: EVALUATION 191 Time-dependent Planning A robot planning system has to treat planning time as a limited resource; i.e., it has to return plans for any allocation of computation time and has to reason about whether the expected gains from further planning will outweigh the costs of spending more planning time <ref> [Dean and Boddy, 1988, Boddy and Dean, 1989, Hanks, 1990a] </ref>.
Reference: [Hanks, 1990b] <author> S. Hanks. </author> <title> Practical temporal projection. </title> <booktitle> In Proc. of AAAI-90, </booktitle> <pages> pages 158-163, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: Therefore, our projector performs lazy temporal projection. It projects whatever is necessary to decide what events occur. But it projects how the environment changes only if these changes have to be known to predict the subsequent events (cf. <ref> [Hanks, 1990b] </ref>). Timeline initializers are pattern-directed procedures that guess the current situation of the environment. If there is a query about the state in which the plan projection starts then CHAPTER 3. PLANNING 53 timeline initializers first look up whether the global variables contain information concerning the query.
Reference: [Hayes-Roth, 1989] <author> B. Hayes-Roth. </author> <title> Intelligent monitoring and control. </title> <booktitle> In Proc. of the 11 th IJCAI, </booktitle> <pages> pages 243-249, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: PRS [Georgeff and Ingrand, 1989] action is determined by the interaction between an intended plan and the environmental contingencies. Rational agency as the result of beliefs, intentions, and desires of the agent (BDI architectures [Georgeff and Ingrand, 1989, Bratman, 1987]. Blackboard architectures <ref> [Hayes-Roth, 1989] </ref> are data-driven control systems that use meta-level reasoning to choose between different applicable courses of action. PRS and blackboard architectures do not provide the kinds of control abstractions for various kinds of synchronizations that are provided by RPL.
Reference: [Hendler et al., 1990] <editor> J. Hendler, A. Tate, and M. </editor> <title> Drummond. Ai planning: Systems and techniques. </title> <journal> AI Magazine, </journal> <volume> 11(3) </volume> <pages> 61-77, </pages> <year> 1990. </year>
Reference: [Horswill, 1993] <author> I. Horswill. Polly: </author> <title> A vision-based artificial agent. </title> <year> 1993. </year>
Reference-contexts: It is unrealistic to expect one kind of robot controller to work well in such different jobs and environments. Moreover, many difficult robot control and perception problems can be solved more easily in specific habitats <ref> [Horswill, 1995, Horswill, 1993] </ref>, especially when the habitats are designed to facilitate jobs [Agre and Horswill, 1992]. To summarize, the desirable features of a robot controller are to a large degree determined by the capabilities of the robot and the features of its jobs and environment.
Reference: [Horswill, 1995] <author> I. Horswill. </author> <title> Analysis of adaptation and environment. </title> <journal> Artificial Intelligence, </journal> <volume> 73 </volume> <pages> 1-30, </pages> <year> 1995. </year>
Reference-contexts: It is unrealistic to expect one kind of robot controller to work well in such different jobs and environments. Moreover, many difficult robot control and perception problems can be solved more easily in specific habitats <ref> [Horswill, 1995, Horswill, 1993] </ref>, especially when the habitats are designed to facilitate jobs [Agre and Horswill, 1992]. To summarize, the desirable features of a robot controller are to a large degree determined by the capabilities of the robot and the features of its jobs and environment.
Reference: [Horvitz, 1988] <author> E. Horvitz. </author> <title> Reasoning under varying and uncertain resource constraints. </title> <booktitle> In Proc. of AAAI-88, </booktitle> <pages> pages 111-116, </pages> <address> St. Paul, MN, </address> <year> 1988. </year>
Reference-contexts: for any allocation of computation time, and are expected to return better answers when more time is given (for example, iterative deepening [Korf, 1985] is an anytime search algorithm) The reasoning technique which copes with problems of assigning time ressources to subproblems in a problem-solving process is called deliberation scheduling <ref> [Boddy and Dean, 1989, Horvitz, 1988] </ref>. The goal of deliberation scheduling is to find an assignment of time resources to computation problems and planning efforts such that running the algorithms as specified in the schedule will produce a plan with maximal expected quality.
Reference: [Kaelbling, 1987] <author> L. Kaelbling. Rex: </author> <title> A symbolic language for the design and parallel implementation of embedded systems. </title> <booktitle> In Proceedings of AIAA Conference on Computers in Aerospace, </booktitle> <address> Wakefield, MA, </address> <year> 1987. </year>
Reference-contexts: Goals and plans in GAPPS are implicit in the compiled circuit. The circuits are specified in REX <ref> [Kaelbling, 1987] </ref>. Rather than synthesizing executable plans from abstract specifications XFRM improves plans during their execution and therefore has to represent goals and reactive plans in an explicit way.
Reference: [Kaelbling, 1988] <author> L. Kaelbling. </author> <title> Goals as parallel program specifications. </title> <booktitle> In Proc. of AAAI-88, </booktitle> <pages> pages 60-65, </pages> <address> St. Paul, MN, </address> <year> 1988. </year>
Reference-contexts: Abstract goals are represented as reducees, more detailed plans as reducers. Sensitivity to protection violations is achieved by adding the statement (PROTECT ...) as a policy for the reducer. A top-level command (ACHIEVE g) has the same meaning as (GOAL tag g). CHAPTER 4. TRANSPARENT REACTIVE PLANS 86 GAPPS <ref> [Kaelbling, 1988] </ref> and ERE [Drummond and Bresina, 1990] also have declarative achievement and maintenance statements for specifying top-level commands. In GAPPS these statements are used as abstract programming constructs. <p> Behaviors CHAPTER 8. EVALUATION 186 are groups of rules. All rules are assumed to run in parallel and asynchronously. ALFA [Gat, 1992] is another language for the implementation of subsumption architectures. GAPPS and REX <ref> [Kaelbling, 1988] </ref>. GAPPS allows for the specification of reactive plans in terms of declarative tasks. Given declarative tasks (goals) of the form do (?a), achieve (?g), or maintain (?p), and a set of goal reduction rules, the system compiles the tasks into a synchronous digital circuit that achieves the tasks.
Reference: [Kambhampati, 1990] <author> S. Kambhampati. </author> <title> A theory of plan modification. </title> <booktitle> In Proc. of AAAI-90, </booktitle> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: XFRM-PRL reflects that reactive plans are not just connected components, or subplans, but contain control structures which coordinate subplans and recover from their failures. PRODIGY [Carbonell et al., 1992] and other partial-order planners use meta-languages for plans to implement search control rules. Khambhampati <ref> [Kambhampati, 1990] </ref> describes the structure of plans explicitly to facilitate plan adaptation. Chapter 6 Forestalling Behavior Flaws So far, we have described the tools for forestalling failures in structured reactive plans. In this chapter, we will explain how these tools are used.
Reference: [Kannan and Blum, 1989] <author> S. Kannan and M. Blum. </author> <title> Designing programs that check their work. </title> <booktitle> In Proceedings of the 1989 Symposium on Theory of Computing, </booktitle> <year> 1989. </year>
Reference-contexts: This technique often works because checking the correctness of a solution is computationally less complex than generating correct solutions <ref> [Kannan and Blum, 1989] </ref>. 1.6 Contributions To put this dissertation into context we have to review briefly other approaches to autonomous robot control. We have already discussed the classical/deliberative approach in which the planner computes optimal courses of actions described in terms of plan steps.
Reference: [Konolige, 1994] <author> K. Konolige. </author> <title> Designing the 1993 robot competition. </title> <journal> AI Magazine, </journal> <volume> 15(1) </volume> <pages> 57-62, </pages> <year> 1994. </year> <note> BIBLIOGRAPHY 203 </note>
Reference-contexts: Finally, the research presents novel and more powerful plan representation and inference techniques for planning research. 1.4.1 Relevance for Autonomous Robot Control Accomplishing everyday activities in our world simulator poses problems for a simulated robot that resembles those addressed by current robotic research <ref> [Dean and Bonasso, 1993, Konolige, 1994, Simmons, 1995] </ref>. In some respects our world simulator challenges robot controllers in ways that real environments challenge real robots: the simulated environment is complex, it changes, and time in the simulator passes at a realistic speed. <p> After discussing the indi 19 CHAPTER 2. REACTIVITY 20 vidual control concepts we show how the different concepts can be effectively combined within a structured reactive controller, which serves as a programming framework to realize the robot's routine activities. 2.1 The DELIVERYWORLD Although technology is progressing rapidly <ref> [Dean and Bonasso, 1993, Konolige, 1994, Simmons, 1995] </ref>, we still cannot equip robots with the repertoire of robust routines that they need to accomplish daily activities reliably and time-effectively. Perceiving the necessary and relevant information in real time is another serious obstacle.
Reference: [Korf, 1985] <author> R. Korf. </author> <title> Depth-first iterative deepening: an optimal admissible tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 27(1) </volume> <pages> 97-109, </pages> <year> 1985. </year>
Reference-contexts: Anytime algorithms are algorithms that return answers for any allocation of computation time, and are expected to return better answers when more time is given (for example, iterative deepening <ref> [Korf, 1985] </ref> is an anytime search algorithm) The reasoning technique which copes with problems of assigning time ressources to subproblems in a problem-solving process is called deliberation scheduling [Boddy and Dean, 1989, Horvitz, 1988].
Reference: [Kushmerick et al., 1995] <author> N. Kushmerick, S. Hanks, and D. Weld. </author> <title> An algorithm for probabilistic planning. </title> <journal> Artificial Intelligence, </journal> <volume> 76 </volume> <pages> 239-286, </pages> <year> 1995. </year>
Reference: [Laird et al., 1991] <author> P. Laird, E. Yager, M. Hucka, and M. Tuck. Robo-soar: </author> <title> an integration of external interaction, planning, </title> <booktitle> and learning in soar. Robotics and Autonomous Systems, </booktitle> <volume> 8 </volume> <pages> 113-129, </pages> <year> 1991. </year>
Reference-contexts: The difference between PROPEL and XFRM is that PROPEL replaces choice points in a plan by more informed decisions while XFRM revises a course of action to avoid flawed behavior. ROBOSOAR <ref> [Laird et al., 1991] </ref> controls a robot with a set of production rules that map sensor data into effector commands. In routine situations exactly one rule fires; in exceptional states multiple rules may be applicable. To resolve such impasses, the planner is called and chooses the best rule to apply.
Reference: [Langley et al., 1987] <author> P. Langley, H. Simon, G. Bradshaw, and J. Zytkow. </author> <title> Scientific Discovery: Computational Explorations of the Creative Processes. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: In addition, diagnosing the causes of the flaws provides valuable information to guide the heuristic search for better plans. 3 The average complexity of transformational planning can also be reduced by applying efficient heuristic plan revision methods and testing the resulting plans <ref> [Newell, Langley et al., 1987] </ref> instead of relying on revision methods that guarantee improvements of the plan [Broy and Pepper, 1986, Biundo et al., 1992].
Reference: [Langlotz et al., 1985] <author> C. Langlotz, L. Fagan, S. Tu, J. Williams, and B. Sikic. Onyx: </author> <title> An architecture for planning in uncertain environments. </title> <booktitle> In Proc. of the 9 th IJCAI, </booktitle> <pages> pages 447-449, </pages> <address> Los Angeles, CA, </address> <year> 1985. </year>
Reference: [Latombe, 1991] <author> J.-C. Latombe. </author> <title> Robot Motion Planning. </title> <publisher> Kluwer, </publisher> <address> Dordrecht, The Netherlands, </address> <year> 1991. </year>
Reference-contexts: The plan resulting from this revision is shown below. 6.3 Some Failure Types and their Revisions Many autonomonous robots use special purpose planning capabilities such as motion planning <ref> [Latombe, 1991] </ref>, navigation planning, or revising cleaning plans to direct the robot into areas with high expected concentration of trash [Firby et al., 1995]. FAUST can be tailored to particular robots, jobs, and environments by defining failure mod els and plan revision methods for avoiding the failures.
Reference: [Lehrer, 1993] <author> N. Lehrer. </author> <title> Krsl specification language. </title> <type> Technical Report Technical Report 2.0.2, </type> <institution> ISX Corporation, </institution> <year> 1993. </year>
Reference-contexts: In chapter 8 we conduct an experiment that suggests that XFRM-PRL is fast enough to improve the problem-solving behavior of a simple simulated robot while the robot performs its tasks. Related Work Related works in AI planning include works on representations for planning <ref> [Lehrer, 1993] </ref> and formalizations of plan interpretation [Davis, 1992], which reason either about plans and their (physical) effects or plan interpretation processes. Another line of planning research [Biundo et al., 1992] focuses on meaning-preserving plan transformations, which assume perfect world models and unlimited computational resources.
Reference: [Levinson, 1995] <author> R. Levinson. </author> <title> A general programming language for unified planning and control. </title> <journal> Artificial Intelligence, </journal> <volume> 76 </volume> <pages> 319-375, </pages> <year> 1995. </year>
Reference-contexts: Another successor of the ERE planning algorithm is the reaction-first algorithm [Drummond et al., 1993] that computes plan prefixes that can be substituted for the default plan to increase the probability of goal satisfaction. PROPEL <ref> [Levinson, 1995] </ref> is a planning system that reasons about plans written in a nondeterministic plan language with loops, conditionals, and a CHOOSE-operator for variable instantiations and selecting procedures to be executed. PROPEL starts with a plan that contains choices that are to be made by simple heuristics.
Reference: [Lumelski and Stepanov, 1986] <author> V. Lumelski and A. Stepanov. </author> <title> Dynamic path planning for a mobile automaton with limited information on the environment. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 31(11) </volume> <pages> 1058-1063, </pages> <year> 1986. </year>
Reference-contexts: Going to a particular location could then be the result of two concurrent control processes: the first causes the robot to go towards the destination until it has arrived there and the second causes it to circumnavigate blocked locations whenever it runs into them <ref> [Lumelski and Stepanov, 1986] </ref>. Opportunities like passing the location where an object has to be painted can be exploited if the go to destination process can be interrupted and resumed afterwards. <p> If some obstacles are concave a robust navigation algorithm has to get the robot to a location next to the obstacle that is closest to the destination <ref> [Lumelski and Stepanov, 1986] </ref>, which, depending on the available sensors, might require the robot to go around the whole obstacle.
Reference: [Lyons and Arbib, 1989] <author> D. Lyons and M. Arbib. </author> <title> A formal model of computation for sensory-based robotics. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 5(3) </volume> <pages> 280-293, </pages> <year> 1989. </year>
Reference-contexts: The Reactor-Planner Architecture <ref> [Lyons and Arbib, 1989] </ref>. The kitting robot uses a control system that consists of two concurrent processes: the planner and the reactor. The planner perceives aspects of the performance of the reactor and adapts the reactors incrementally to increase the reactor's reliability of achieving a given set of goals. <p> IRMA [Bratman, 1987] is another architecture for controlling a resource-bounded autonomous agent. It uses a filtering process to avoid wasting computational resources. 8.4.2 Control Languages for Reactive Control A robot control language provides the control and data abstractions that support the implementation of autonomous robot controllers (see <ref> [Lyons and Arbib, 1989] </ref> for a good discussion). In the following we will briefly describe the characteristics of different robot control languages.
Reference: [Lyons and Hendriks, 1992] <author> D. Lyons and A. Hendriks. </author> <title> A practical approach to integrating reaction and deliberation. </title> <editor> In J. Hendler, editor, </editor> <booktitle> AIPS-92, </booktitle> <pages> pages 153-162, </pages> <year> 1992. </year>
Reference-contexts: BETTER-PLAN ... BEST-PLAN) (WAIT-FOR BETTER-PLAN?) (WAIT-FOR (TASK-END AN-ITER))) (IF BETTER-PLAN? (SWAP-PLAN BEST-PLAN NEXT-ITER))))))) Variants of this kind of planned iterative behavior have been implemented for the kitting robot <ref> [Lyons and Hendriks, 1992] </ref> and for controlling the walking behavior of Ambler [Simmons, 1990]. 7.2.2 Plan Execution a la Shakey The following RPL code piece specifies a simplified version of Shakey's [Nilsson, 1984] plan execution system PLANEX [Fikes et al., 1972]. <p> NASL uses planning to execute complex actions and IPEM integrates partial-order planning and plan execution. These kinds of interactions between planning and action can be expressed in extended RPL. RS <ref> [Lyons and Hendriks, 1992] </ref> plans and acts in parallel but is constrained to highly repetitive tasks. It has also the ability to evaporate and revise partially executed steps but only in the context of a highly repetitive task.
Reference: [Maes, 1990] <editor> P. Maes, editor. </editor> <title> Designing Autonomous Agents: Theory and Practice from Biology and Back. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [Mataric, 1992] <author> M. Mataric. </author> <title> Behavior-based systems: Main properties and implications. </title> <booktitle> In Proceedings IEEE International Conference on Robotics and Automation, Workshop on Intelligent Control Systems, </booktitle> <pages> pages 46-54, </pages> <year> 1992. </year> <note> BIBLIOGRAPHY 204 </note>
Reference-contexts: Routine activities are behavior-based control systems that are composed from sets of concurrent behaviors without a centralized control <ref> [Mataric, 1992] </ref>. Also, program units in routine activities are supposed to accomplish a particular task as, for instance, avoiding obstacles or delivering an object and do all the necessary sensing, effector control, and failure recovery themselves. <p> Fortunately, this requirement is the same as one of the basic design principles for behavior-based control systems (see Section 2.2.8 and <ref> [Mataric, 1992] </ref>): behavior-based control systems are composed of control processes that try to achieve and maintain certain states of the robot and its environment. Another kind of subplan in structured reactive plans senses aspects of the environment in order to acquire information about the state of the world. <p> Also the information that can be sensed at any time has to be sufficient for selecting the right actions. While reactive approaches are characterized by fast response time to environmental events they are unable to deal with multiple and varying goals in a sophisticated manner. Behavior-based Architectures <ref> [Brooks, 1986b, Mataric, 1992, Steels, 1994] </ref>. Behavior-based architectures decompose the problem of autonomous control into special-purpose task-achieving modules that are connected directly to sensors and effectors.
Reference: [McAllester and Rosenblitt, 1991] <author> D. McAllester and D. Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. of AAAI-91, </booktitle> <pages> pages 634-639, </pages> <year> 1991. </year>
Reference-contexts: A protection represents an effect of a plan step that is needed by some later step, and therefore this effect has to be maintained until the later step is executed [Sussman, 1977]. Many classical partial-order planners work by adding ordering constraints until no protection is violated <ref> [McAllester and Rosenblitt, 1991] </ref>. RPL provides the statement (PROTECTION rigidity proposition fluent repair). <p> However, for this revision to apply, the planner has to know that the a goal was clobbered by the robot's own action. Knowing the failure was caused by a task interference, the planner can apply a goal achievement procedure of a partial-order planning system (e.g. <ref> [McAllester and Rosenblitt, 1991] </ref>) to resolve the problem. Whenever possible, the planner should apply the most specific or informed plan revisions. The second revision for the Sussman anomaly failure is better because the revision deals with failures due to task interferences instead of failures in general. <p> :UNTIL are event specifications of different kinds: the passing of a deadline (:BY (TIME 14:00)), a certain state of plan interpretation (:BY (TASK-END t)), or an event caused by another robot (:BY (*BEGIN* (DOES ROBOT3 PICK-UP DESIG)). :UNTIL parameters can be used to represent protections [Sussman, 1977] and causal links <ref> [McAllester and Rosenblitt, 1991] </ref> that are well-known in classical planning. For instance, we can represent a plan for achieving a conjunctive goal in RPL as follows: (REDUCE (ACHIEVE (AND (G 1 G 2 ))) (:TAG CG (PLAN (ACHIEVE G 1 :UNTIL (TASK-END CG)) (ACHIEVE G 2 :UNTIL (TASK-END CG))))). <p> CHAPTER 5. REPRESENTING PLAN REVISIONS 107 We can also express planning operations performed by classical planning systems such as means-end analysis [Newell and Simon, 1961] or the operations of the SNLP planning algorithm can <ref> [McAllester and Rosenblitt, 1991] </ref>. However, additional techniques are nec essary to make a classical planning algorithm, such as SNLP, work in a reactive setting. The real test of our claims about XFRM-PRL depends on how many rules can be expressed in it without significant extension.
Reference: [McDermott, 1978] <author> D. McDermott. </author> <title> Planning and acting. </title> <journal> Cognitive Science, </journal> <volume> 2(2) </volume> <pages> 71-109, </pages> <year> 1978. </year>
Reference-contexts: Planning and action are performed in separate phases. We have sketched the RPL code for a simplified PLANEX system on page 151. NASL <ref> [McDermott, 1978] </ref> and IPEM [Ambros-Ingerson and Steel, 1988] interleave planning and execution in order to exploit the information acquired during plan execution. NASL uses planning to execute complex actions and IPEM integrates partial-order planning and plan execution.
Reference: [McDermott, 1981] <author> D. McDermott. </author> <booktitle> Artificial intelligence meets natural stupidity. </booktitle> <editor> In J. Haugeland, editor, </editor> <booktitle> Mind Design: Philosophy, Psychology, Artificial Intelligence, </booktitle> <pages> pages 143-160. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1981. </year>
Reference-contexts: That is, the planning system can infer the purpose of a declarative plan based on a syntactic analysis of its name. So far we have used declarative statements only as a naming convention for subplans <ref> [McDermott, 1981] </ref>. What differentiates declarative RPL statements like (ACHIEVE (LOC DESIG h0,10i)) from other calls to subplans like (GET-OB-TO-LOC DESIG h0,10i), however, is that declarative statements satisfy additional conditions: namely that they have routine plans, behavior specifications, and benefit models.
Reference: [McDermott, 1985] <author> D. McDermott. </author> <title> Reasoning about plans. </title> <editor> In J. R. Hobbs and R. C. Moore, editors, </editor> <booktitle> Formal Theories of the Commonsense World, </booktitle> <pages> pages 269-317. </pages> <publisher> Ablex, </publisher> <address> Norwood, NJ, </address> <year> 1985. </year>
Reference: [McDermott, 1990] <author> D. McDermott. </author> <title> Planning reactive behavior: A progress report. </title> <editor> In K. Sycara, editor, </editor> <title> Innovative Approaches to Planning, </title> <journal> Scheduling and Control, </journal> <pages> pages 450-458, </pages> <address> San Mateo, CA, 1990. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: Also, by making use of the control structures provided, we can make plans more robust in ways that traditional planners cannot. Planning the situated control of a robot is the goal of a research effort called transformational planning of reactive behavior, of which this dissertation is part <ref> [McDermott, 1990, McDermott, 1992b] </ref>. <p> CHAPTER 8. EVALUATION 190 Planning Reactive Behavior Robot planners have to synthesize plans that implement any problem-solving behavior necessary to solve complex tasks in its environment not just sequences of primitive robot actions <ref> [McDermott, 1990] </ref>. ERE (Entropy Reduction Engine) contains a synthetic projection algorithm [Drummond and Bresina, 1990].
Reference: [McDermott, 1991a] <author> D. McDermott. </author> <title> A reactive plan language. </title> <institution> Research Report YALEU/DCS/RR-864, Yale University, </institution> <year> 1991. </year>
Reference-contexts: CHAPTER 1. INTRODUCTION 5 local execution failures. Unfortunately, plans that are partially ordered sets of actions cannot describe behaviors as complex and flexible as routine activities concisely, because they lack suitable control abstractions. Therefore, we use RPL (Reactive Plan Language <ref> [McDermott, 1991a] </ref>), a structured plan language, which provides control abstractions that help to structure the complex everyday activities and make them reactive and adaptive. The concepts and control structures provided by RPL include conditionals, loops, program variables, processes, and subroutines. <p> Reacting appropriately requires the robot to deal with unknown and changing aspects of the environment, respond to asynchronous events, and carry out different threads of control concurrently. Furthermore, the chapter demonstrates how these concepts can be realized in RPL (Reactive Plan Language) <ref> [McDermott, 1991a] </ref>, the programming language used to implement the robot controllers described in this dissertation. After discussing the indi 19 CHAPTER 2. <p> An extensive discussion of the role of testbeds and empirical evaluation of agent architectures can be found in [Hanks et al., 1993]. 2.2 The Implementation of Routine Activities This section analyzes implementation strategies for delivery routines and describe how these strategies can be implemented in RPL <ref> [McDermott, 1991a] </ref>. RPL programs look very much like LISP programs that make use of control abstractions typical of structured concurrent programming languages. Such abstractions include those for sequencing, concurrent execution, conditionals, loops, assignments of values to program variables, and subroutine calls. <p> The plan library improves the performance of the robot by speeding up the construction of robust routine plans. The general, aspects of structured reactive controllers are their organization and the tools that we have used to implement them. In particular the RPL system <ref> [McDermott, 1991a] </ref>, CHAPTER 2. REACTIVITY 42 consisting of the RPL language, its interpreter, and the runtime system is a very powerful and general tool for the implementation of controllers for autonomous robots.
Reference: [McDermott, 1991b] <author> D. McDermott. </author> <title> Regression planning. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 6 </volume> <pages> 357-416, </pages> <year> 1991. </year>
Reference-contexts: An operator is relevant to a goal if it adds propositions involving the predicates mentioned in the goal. A plan is typically found by proposing an operator to solve part of the goal, then embedding that operator in a plan for the rest of the goal <ref> [McDermott, 1991b] </ref>. Unfortunately, the choice of operators and embeddings is not obvious, so we quickly get an intractable search problem [Chapman, 1987].
Reference: [McDermott, 1992a] <author> D. McDermott. </author> <title> Robot planning. </title> <journal> AI Magazine, </journal> <volume> 13(2) </volume> <pages> 55-79, </pages> <year> 1992. </year>
Reference-contexts: EVALUATION 160 Since we use a planning system to solve the robot control problem, we refine the problem as follows. Given an abstract plan P, and a description of the current situation, find an executable realization Q that maximizes some objective function V and execute it <ref> [McDermott, 1992a] </ref>. Planning is feasible only if the planning system is equipped with the information necessary to compute (more or less precise) predictions of what will happen when the robot carries out its control program. <p> As part of our research effort we try to compile RPL programs into control programs for TCA. CHAPTER 8. EVALUATION 187 8.4.3 Robot Planning Robot planning is the automatic generation, debugging, and optimization of robot plans, the parts of the robot controllers that planning systems reason about and manipulate <ref> [McDermott, 1992a] </ref>.
Reference: [McDermott, 1992b] <author> D. McDermott. </author> <title> Transformational planning of reactive behavior. </title> <institution> Research Report YALEU/DCS/RR-941, Yale University, </institution> <year> 1992. </year>
Reference-contexts: Also, by making use of the control structures provided, we can make plans more robust in ways that traditional planners cannot. Planning the situated control of a robot is the goal of a research effort called transformational planning of reactive behavior, of which this dissertation is part <ref> [McDermott, 1990, McDermott, 1992b] </ref>. <p> Currently, XFRM does errand planning in a simulated world of discrete locations developed by McDermott and briefly described in <ref> [McDermott, 1992b] </ref>. The world is a grid of locations; each location has an infinite number of positions and at each position there is at most one object. A signpost (the object at position 4 in Figure 2.1) gives the coordinates of each location. <p> RPL provides a construct (EVAP-PROTECT a b) that blocks the evaporation of a control process until all critical stretches of behavior b are completed. The control processes recognize simultaneously that the desired behavior is completed and whether it has been completed successfully or unsuccessfully <ref> [McDermott, 1992b, Firby, 1994] </ref>. For instance, the successful completion of a grasp is detected if the force measured by the hand force sensor exceeds a certain threshold. A failed grasp can be detected if fingers have minimal distance to each other while the hand force is still zero. <p> The interpretation of the subsequent steps are then blocked until the robot has arrived at l (i.e., till the move behavior signals its completion). The architecture is an adapted version of the XFRM architecture <ref> [McDermott, 1992b] </ref>. The main difference is that in XFRM there is a planning system that communicates with the user and swaps plans. The architecture proposed here does not contain a planning system. <p> Since planning processes install additional synchronizations and ordering constraints automatically, it often happens that these constraints are inconsistent and that two different threads of control block each other. Therefore, an important mechanism in the CPU of a structured reactive plan is deadlock breaking <ref> [McDermott, 1992b] </ref>. The RPL interpreter works as follows: it picks a thread, which specifies what to do and how to continue, from the enabled queue and interprets it. What has to be done is specified by the RPL code c contained in the thread. <p> Thus what turns RPL into a language for representing structured reactive plans is the set of tools RPL comes with. Those tools make it possible to * project what might happen when a robot controller gets executed and return it as an execution scenarios <ref> [McDermott, 1994a, McDermott, 1992b] </ref>; * infer what might be wrong with a robot controller given an execution scenario [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans <p> Those tools make it possible to * project what might happen when a robot controller gets executed and return it as an execution scenarios [McDermott, 1994a, McDermott, 1992b]; * infer what might be wrong with a robot controller given an execution scenario <ref> [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995] </ref>; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans as Syntactic Objects For the purpose of planning RPL plans are internally represented as parse or code trees. <p> robot controller gets executed and return it as an execution scenarios [McDermott, 1994a, McDermott, 1992b]; * infer what might be wrong with a robot controller given an execution scenario <ref> [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995] </ref>; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans as Syntactic Objects For the purpose of planning RPL plans are internally represented as parse or code trees. <p> The input for the criticize step is a structured reactive plan and the computational state of the currently executed structured reactive controller. Plan Projection Plan projection <ref> [McDermott, 1992b, McDermott, 1994a] </ref> is the single most important inference technique applied by XFRM planning processes. 1 The plan projection process takes the current world model, a reactive plan, rules for randomly generating exogenous events, rules for probabilistically guessing missing pieces of the world model, probabilistic causal models of basic control <p> In addition, the update of the belief B can be realized by adding the statement (PERCEIVE B) to the plan. The basic mechanisms necessary to reconstruct beliefs at any time instant during a projection are discussed in <ref> [McDermott, 1992b] </ref>. 4.1.5 Other Declarative Statements We have not yet mentioned maintenance and stabilization goals, two other declarative statements used for controlling the delivery robot. As subroutines, maintenance goals are often used in the context of policies. <p> The XFRM scheduler uses this declarative statement to find out where the robot has to go to perform a certain task and to place ordering constraints on structured reactive plans <ref> [McDermott, 1992b] </ref>. The plan writer has to decide which plans in the plan library are essential for plan revision and should thus be implemented transparently using declarative statements. She can add new declarative statements to the plan language by specifying RPL construct descriptions for them. <p> Again, the low-level plans used in this dissertation are variants of the ones originally described in <ref> [McDermott, 1992b] </ref>. CHAPTER 4. TRANSPARENT REACTIVE PLANS 81 Plan Behavior (MOVE dir) Move to the next location in direction dir (east, west, south, north). (LOOK-FOR pl) Look for an object that satisfies the list of properties pl. <p> For example, the protection-violation avoidance transformation [Sussman, 1977] is, in the classical framework, a matter of inserting a link. In a structured reactive plan, it is a complex editing operation that must respect the semantics of RPL. In the past <ref> [McDermott, 1992b] </ref> we have expressed such transformations as Lisp procedures, but the resulting codes are unintelligible and error-prone. In this chapter we will describe XFRM-PRL (XFRM Plan Revision Language), the transformation language of the planning system XFRM. <p> Therefore, in an execution scenario, the projected plan is represented as a structure, called a code tree, which essentially duplicates the structure of the plan text, augmented with some further syntactic information. (For CHAPTER 5. REPRESENTING PLAN REVISIONS 93 details, see <ref> [McDermott, 1992b] </ref>.) The if parts of transformation rules need to access that tree, and the then parts need to rearrange it. <p> These data structures are described in <ref> [McDermott, 1992b] </ref>, although a few new ones have been added since that report. For example, because TASK-GOAL is such a ubiquitous predicate, XFRM's projector constructs a table during plan projection that maps goals to the tasks that are intended to achieve them. <p> It has been studied for a long time, but still remains an open research issue. We investigate the problem within a particular framework for planning and action: the XFRM framework <ref> [McDermott, 1992b, Beetz and McDermott, 1994] </ref>, which is based on the following principles: * Action: the course of action is specified by structured reactive plans. Structured reactive plans specify how the robot is to respond to sensory input in order to accomplish its jobs. <p> Several algorithms satisfying this property have been proposed for real-time robot planning [McDermott, 1992b, Drummond and Bresina, 1990, Dean et al., 1993, Lyons and Hendriks, 1992]. CHAPTER 7. PLANNING ONGOING ACTIVITIES 144 For our implementation of local planning, we have used the variant of the XFRM planning algorithm <ref> [McDermott, 1992b, Beetz and McDermott, 1994] </ref> that we have described in chapter 3. In XFRM planning is implemented as a search in plan space. A node in the space is a proposed plan; the initial node is a plan that represents the local planning problem.
Reference: [McDermott, 1994a] <author> D. McDermott. </author> <title> An algorithm for probabilistic, totally-ordered temporal projection. </title> <institution> Research Report YALEU/DCS/RR-1014, Yale University, </institution> <year> 1994. </year>
Reference-contexts: Thus what turns RPL into a language for representing structured reactive plans is the set of tools RPL comes with. Those tools make it possible to * project what might happen when a robot controller gets executed and return it as an execution scenarios <ref> [McDermott, 1994a, McDermott, 1992b] </ref>; * infer what might be wrong with a robot controller given an execution scenario [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]; and * perform complex and meaningful revisions of the robot controller [McDermott, 1992b, Beetz and McDermott, 1994, Beetz and McDermott, 1995]. 3.1.1 Plans <p> The input for the criticize step is a structured reactive plan and the computational state of the currently executed structured reactive controller. Plan Projection Plan projection <ref> [McDermott, 1992b, McDermott, 1994a] </ref> is the single most important inference technique applied by XFRM planning processes. 1 The plan projection process takes the current world model, a reactive plan, rules for randomly generating exogenous events, rules for probabilistically guessing missing pieces of the world model, probabilistic causal models of basic control <p> The probabilistic temporal projection algorithm is described in <ref> [McDermott, 1994a] </ref>. McDermott [1994a] gives a formal semantics for the rule language introduced above, shows that a consistent set of rules has a unique model, and proves the algorithms for building and retrieving from the timeline to be correct. CHAPTER 3. PLANNING 51 Execution scenario. <p> The timeline is a linear sequence of events and their results, synchronized with the task network. Timelines represent how the world changes during the execution of a plan in terms of time instants, occasions, and events <ref> [McDermott, 1994a] </ref>. Time instants are points in time at which the world changes due to an action of the robot or an exogenous event. Each time instant has a date which holds the time on the global clock at that particular time instant occurred. <p> REPRESENTING PLAN REVISIONS 99 (?-VAR ?CMDS (SETOF ?TLC-CMD (AND (TLC-TASK ?TLC-CMD ?TLC-TASK) (TASK-OUTCOME ?TLC-TASK FAIL)) ?CMDS)) 5.2.3 Predicates on Timelines The purpose of plans is to change the world. XFRM represents how the world changes during the execution of a plan in terms of time instants, occasions, and events <ref> [McDermott, 1994a] </ref>. Time instants are points in time at which the world changes due to an action of the robot or an exogenous event. Each time instant has a date which holds the time at that particular time instant occurred. <p> If the planning processes produce plan revisions after the corresponding parts of the plan are executed, these revisions will not affect the course of action taken by the robot. 2 The projection algorithm, described in <ref> [McDermott, 1994a] </ref>, computes in the limit the correct distribution of execution scenarios. CHAPTER 8. EVALUATION 167 Sometimes the revisions performed by structured reactive controllers make the behavior of the robot worse. Suppose the robot has to get the blue ball at location h2,2i.
Reference: [McDermott, 1994b] <author> D. McDermott. </author> <title> The other problem with classical planning. Invited Talk at the AIPS-94, </title> <year> 1994. </year>
Reference-contexts: Evaluating existing partial-order planning systems shows the effects of this intractability for typical planning problems. These planners often have to explore hundreds of partial plans in order to find plans that only require a handful of plan steps (e.g., <ref> [McDermott, 1994b] </ref>). Worse still, problems with linear complexity (as, for instance, graph searches) can become intractable by simply being restated as general planning problems [McDermott, 1994b]. One of the biggest hurdles in the realization of planning techniques for improving robot behavior is overcoming the computational complexity of AI planning methods. <p> These planners often have to explore hundreds of partial plans in order to find plans that only require a handful of plan steps (e.g., <ref> [McDermott, 1994b] </ref>). Worse still, problems with linear complexity (as, for instance, graph searches) can become intractable by simply being restated as general planning problems [McDermott, 1994b]. One of the biggest hurdles in the realization of planning techniques for improving robot behavior is overcoming the computational complexity of AI planning methods. To reduce the computational complexity we simplify the planning problem in various ways.
Reference: [McFarland and Boesser, 1993] <author> D. McFarland and T. Boesser. </author> <title> Intelligent Behavior in Animals and Robots. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: We describe how these extensions are implemented and how different models of interaction between planning and execution can be realized in extended RPL. Chapter 8 describes our experiments and the Conclusion concludes. Chapter 2 Reactivity Robots, like animals, have particular roles in particular environments <ref> [McFarland and Boesser, 1993] </ref>. The current and future roles of robots include nuclear waste removal, office and hospital courier service, carpet cleaning in buildings, household tasks, spraypainting in automatic factories, and planetary exploration.
Reference: [Mitchell et al., 1990] <author> T. Mitchell, J. Allen, P. Chalasani, J. Cheng, O. Etzioni, M. Ringuette, and J. Schlimmer. Theo: </author> <title> a framework for self-improving systems. </title> <editor> In K. VanLehn, editor, </editor> <booktitle> Architectures for Intelligence. </booktitle> <publisher> Erlbaum, </publisher> <year> 1990. </year>
Reference: [Mitchell, 1990] <author> T. Mitchell. </author> <title> Becoming increasingly reactive. </title> <editor> In K. Sycara, editor, </editor> <booktitle> Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pages 459-467, </pages> <year> 1990. </year> <note> BIBLIOGRAPHY 205 </note>
Reference: [Nebel and Koehler, 1995] <author> B. Nebel and J. Koehler. </author> <title> Plan reuse versus plan generation: A theoretical and empirical analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 76 </volume> <pages> 427-454, </pages> <year> 1995. </year>
Reference-contexts: In order to exploit the structure of everyday activity we employ a transformational planning technique that generates approximately competent plans and then revises these plans in order to eliminate their flaws. Despite having the same worst-case complexity as planning from first principles <ref> [Nebel and Koehler, 1995] </ref>, transformational planning is much more attractive for robot planning for several reasons. For one reason, a transformational planner can generate executable (although not necessarily successful) plans very fast.
Reference: [Newell] <author> A. Newell. </author> <title> Artificial intelligence and the concept of mind. </title> <booktitle> In Computer Models of Language and Thought. </booktitle>
Reference-contexts: In addition, diagnosing the causes of the flaws provides valuable information to guide the heuristic search for better plans. 3 The average complexity of transformational planning can also be reduced by applying efficient heuristic plan revision methods and testing the resulting plans <ref> [Newell, Langley et al., 1987] </ref> instead of relying on revision methods that guarantee improvements of the plan [Broy and Pepper, 1986, Biundo et al., 1992].
Reference: [Newell and Simon, 1961] <author> A. Newell and H. Simon. </author> <title> GPS, a program that simulates human thought. </title> <editor> In Heinz Billing, editor, </editor> <booktitle> Lernende Automaten, </booktitle> <pages> pages 109-124. </pages> <editor> R. </editor> <publisher> Oldenbourg, </publisher> <address> Munich, Germany, </address> <year> 1961. </year>
Reference-contexts: No other notation for reasoning about plans and their projections we know of covers all these aspects of plan execution. CHAPTER 5. REPRESENTING PLAN REVISIONS 107 We can also express planning operations performed by classical planning systems such as means-end analysis <ref> [Newell and Simon, 1961] </ref> or the operations of the SNLP planning algorithm can [McAllester and Rosenblitt, 1991]. However, additional techniques are nec essary to make a classical planning algorithm, such as SNLP, work in a reactive setting.
Reference: [Nilsson, 1984] <author> N. Nilsson. </author> <title> Shakey the robot. </title> <type> Technical Note 323, </type> <institution> SRI AI Center, </institution> <year> 1984. </year>
Reference-contexts: An important goal in the design and implementation of autonomous robot controllers is to understand and build controllers that can carry out daily jobs in offices and factories with a reliablity and efficiency comparable to people. Of course, autonomous robot controllers already exist (although only for carefully engineered environments <ref> [Nilsson, 1984] </ref> or for a few fixed and specific tasks [Brooks, 1986a]). <p> It is also not a new idea that robot controllers equipped with AI planning techniques can be more effective than fixed robot controllers (it has been implemented in order to control several robots <ref> [Nilsson, 1984, Winston, 1972, Giralt et al., 1979] </ref>). The main characteristic of such deliberative robot controllers is that they carefully reason through all actions before they execute them. Deliberative robot controllers sense their environments in order to maintain a symbolic representation of the relevant aspects of their environments. <p> We have tried to demonstrate the usefulness of concepts that were introduced using concrete examples from the delivery application. Compared to the classical Sense/Model/Plan/Act control architecture <ref> [Nilsson, 1984] </ref> the structured reactive controllers require an additional library of reliable routine plans whereas, in the classical architecture, the plans for particular jobs are constructed from first principles. The plan library used by the robot is specific to the robot's jobs, its environment, and its capabilities. <p> BETTER-PLAN? (SWAP-PLAN BEST-PLAN NEXT-ITER))))))) Variants of this kind of planned iterative behavior have been implemented for the kitting robot [Lyons and Hendriks, 1992] and for controlling the walking behavior of Ambler [Simmons, 1990]. 7.2.2 Plan Execution a la Shakey The following RPL code piece specifies a simplified version of Shakey's <ref> [Nilsson, 1984] </ref> plan execution system PLANEX [Fikes et al., 1972]. Shakey's robot control system manages a global symbolic world model that is assumed to be correct and complete. <p> The implementation of the CHAPTER 7. PLANNING ONGOING ACTIVITIES 154 classical robot control architecture SMPA <ref> [Nilsson, 1984] </ref> is straightforward. It consists of a sequence of four steps. In the sense step the robot perceives all objects at its current location. The perception subplan updates the global variable KNOWN-THINGS* that contains designators for all objects the robot has seen so far (see chapter 2.3).
Reference: [Passino and Antsaklis, 1989] <author> K. Passino and P. </author> <title> Antsaklis. </title> <journal> A system and control-theoretic perspective on artificial intelligence planning systems. Applied Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 1-32, </pages> <year> 1989. </year>
Reference-contexts: Figure 8.3 shows different types of control architectures ordered along this dimension. At the left end of the spectrum are control systems, which try to model the environment at a very detailed level using complex mathematical models like differential equations <ref> [Passino and Antsaklis, 1989, Dean and Wellmann, 1991] </ref>. At the right end of the spectrum are classical planning architectures, which make strong simplifying assumptions about the environment but reason CHAPTER 8. EVALUATION 181 very carefully about how jobs can be accomplished. In between are reactive, behavior-based, and hybrid deliberative systems.
Reference: [Pollack and Ringuette, 1990] <author> M. Pollack and M. Ringuette. </author> <title> Introducing the tileworld: Experimentally evaluating agent architectures. </title> <booktitle> In Proc. of AAAI-90, </booktitle> <pages> pages 183-189, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: A good metric for evaluating the practical usefulness of structured reactive controllers is the amount by which they can improve the performance of the robots they control <ref> [Zilberstein, 1995, Cohen et al., 1989, Pollack and Ringuette, 1990] </ref>. The overall performance summarizes several measures such as the quality of the plan revisions, the time resources needed to compute these revisions, how robust plan revision is, and so on.
Reference: [Rao and Georgeff, 1991] <author> A. Rao and M. Georgeff. </author> <title> Modeling rational agents within a bdi-architecture. </title> <editor> In J. Allen, R. Fikes, and E. Sandewall, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. of the Second International Conference (KR'91), </booktitle> <pages> pages 473-484, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: The main difference between Lyons' reactor-planner architecture and structured reactive controllers is that Lyons' control architecture is tailored towards highly repetitive jobs, while structured reactive controllers are designed for non-recurring sets of routine jobs. BDI Architectures <ref> [Rao and Georgeff, 1991, Rao and Georgeff, 1992] </ref>. The basic concepts in BDI architectures are beliefs, goals, intentions, actions and the relationships between them. BDI architectures can be formalized using a branching-time possible-worlds logic, where each world has a branching time future and a single past.
Reference: [Rao and Georgeff, 1992] <author> A. Rao and M. Georgeff. </author> <title> An abstract architecture for rational agents. </title> <editor> In B. Nebel, C. Rich, and W. Swartout, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. of the Third International Conference (KR'92), </booktitle> <pages> pages 439-449, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: The main difference between Lyons' reactor-planner architecture and structured reactive controllers is that Lyons' control architecture is tailored towards highly repetitive jobs, while structured reactive controllers are designed for non-recurring sets of routine jobs. BDI Architectures <ref> [Rao and Georgeff, 1991, Rao and Georgeff, 1992] </ref>. The basic concepts in BDI architectures are beliefs, goals, intentions, actions and the relationships between them. BDI architectures can be formalized using a branching-time possible-worlds logic, where each world has a branching time future and a single past.
Reference: [Rosenschein and Kaelbling, 1986] <author> S. Rosenschein and L. Kaelbling. </author> <title> The synthesis of digital machines with provable epistemic properties. </title> <booktitle> In Proc. of the 1986 Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 83-98, </pages> <address> Monterey, CA, </address> <year> 1986. </year>
Reference-contexts: In the corresponding conditional branch the robot acts as if it believed that the object designated by DESIG is at hX,Yi (see <ref> [Rosenschein and Kaelbling, 1986] </ref>). The meaning of the expression can therefore be represented explicitly as (BELIEF (LOC DESIG hX,Yi)). CHAPTER 4. <p> In this case we say that at any time the robot believes it is at location hX,Yi if in the current computational state, the value of X-POS is X and the value of Y-POS is Y (see <ref> [Rosenschein and Kaelbling, 1986] </ref>). We take the relation (BELIEF-AT state n begin-task (tsk) end-task (tsk) o ) to mean that the robot believes state holds in the world. The programmer specifies axioms that define under which conditions the robot believes in state.
Reference: [Rosenschein and Kaelbling, 1995] <author> S. Rosenschein and L. Kaelbling. </author> <title> A situated view of representation and control. </title> <journal> Artificial Intelligence, </journal> <volume> 73 </volume> <pages> 149-173, </pages> <year> 1995. </year>
Reference-contexts: This approach requires correct and complete world models and has a tendency to cause relatively simple problems to become computationally intractable. To avoid the problems of classical controllers in coping with real environments in real-time, several researchers developed a different approach, often called situated robot control <ref> [Brooks, 1991a, Agre and Chapman, 1987, Rosenschein and Kaelbling, 1995] </ref>. In the situated control paradigm controllers are organized into interacting concurrent control processes. These processes continuously sense their environment and map the resulting sensor data into effector commands without deliberation and without maintaining large data structures. <p> The COG project [Brooks and Stein, 1994] is the biggest application of reactive and behavior-based control methods. The goal of the project is to build an integrated physical humanoid robot. Other approaches to the implementation of reactive and behavior-based control systems include situated automata <ref> [Rosenschein, 1985, Rosenschein and Kaelbling, 1995] </ref>, the ALFA language [Gat, 1991], Situated Control Rules [Drummond, 1989]. Structured reactive controllers add to behavior-based systems the capability to make control decisions that require foresight and a change in the intended course of action.
Reference: [Rosenschein, 1985] <author> S. Rosenschein. </author> <title> Formal theories of knowledge in AI and robotics. </title> <journal> New Generation Computing, </journal> <volume> 3 </volume> <pages> 345-357, </pages> <year> 1985. </year> <note> BIBLIOGRAPHY 206 </note>
Reference-contexts: The COG project [Brooks and Stein, 1994] is the biggest application of reactive and behavior-based control methods. The goal of the project is to build an integrated physical humanoid robot. Other approaches to the implementation of reactive and behavior-based control systems include situated automata <ref> [Rosenschein, 1985, Rosenschein and Kaelbling, 1995] </ref>, the ALFA language [Gat, 1991], Situated Control Rules [Drummond, 1989]. Structured reactive controllers add to behavior-based systems the capability to make control decisions that require foresight and a change in the intended course of action.
Reference: [Russell and Subramanian, 1995] <author> S. Russell and D. Subramanian. </author> <title> Provably bounded-optimal agents. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 3, </volume> <year> 1995. </year>
Reference: [Russell and Wefald, 1991] <author> S. Russell and E. Wefald. </author> <title> Do the right thing: studies in limited rationality. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference: [Russell, 1991] <author> S. Russell. </author> <title> An architecture for bounded rationality. </title> <journal> SIGART Bulletin 2, </journal> <year> 1991. </year>
Reference-contexts: Bounded Rationality Architectures. A bounded optimal agent behaves as well as possible given its computational resources. Bounded optimality specifies optimal programs rather than optimal actions or optimal computation sequences. RALPH-MEA "An architecture for bounded rationality" <ref> [Russell, 1991] </ref> runs in parallel different methods for selecting the best actions. The methods, decision-theoretic, goal-based, action utility, and condition-action, require different types of information and time resources.
Reference: [Schoppers, 1987] <author> M. Schoppers. </author> <title> Universal plans for reactive robots in unpredictable environments. </title> <booktitle> In Proc. of the 10 th IJCAI, </booktitle> <pages> pages 1039-1046, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference-contexts: We call these kinds of reactive plans universal because they are designed to achieve their tasks no matter what the initial situation looks like and despite hindrances <ref> [Schoppers, 1987] </ref>. They do so by assessing the current situation based on sensor readings and internal data structures and selecting subplans based on this assessment. Universal plans are not described adequately by causal models with preconditions and effects. They are designed CHAPTER 2.
Reference: [Simmons, 1988a] <author> R. Simmons. </author> <title> Combining Associational and Causal Reasoning to Solve Interpretation and Planning Problems. </title> <type> Technical report 1048, </type> <institution> MIT AI Lab, </institution> <year> 1988. </year>
Reference-contexts: Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan. The transformational planning systems that are most closely related to XFRM are HACKER [Sussman, 1977, Sussman, 1990], CHEF [Hammond, 1989, Hammond, 1990], and GORDIUS <ref> [Simmons, 1988a, Simmons, 1988b, Simmons, 1992] </ref>. Given a set of tasks, transformational planners generate a plan hypothesis that can be projected and revise the plan hypothesis until it is good enough.
Reference: [Simmons, 1988b] <author> R. Simmons. </author> <title> A theory of debugging plans and interpretations. </title> <booktitle> In Proc. of AAAI-88, </booktitle> <pages> pages 94-99, </pages> <address> St. Paul, MN, </address> <year> 1988. </year>
Reference-contexts: Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan. The transformational planning systems that are most closely related to XFRM are HACKER [Sussman, 1977, Sussman, 1990], CHEF [Hammond, 1989, Hammond, 1990], and GORDIUS <ref> [Simmons, 1988a, Simmons, 1988b, Simmons, 1992] </ref>. Given a set of tasks, transformational planners generate a plan hypothesis that can be projected and revise the plan hypothesis until it is good enough. <p> Once a plan failure is detected the planners have to find out why and where in order to revise the plan appropriately. This step is implemented in GORDIUS <ref> [Simmons, 1988b] </ref> as the localization of faulty assumptions made by the planner or projector. In the CHEF planner a detailed explanation for bugs is generated by executing questioning scripts [Hammond, 1990]. The transformations for plan repair are indexed either by the faulty assumptions (GORDIUS) or by explanations (CHEF).
Reference: [Simmons, 1990] <author> R. Simmons. </author> <title> An architecture for coordinating planning, sensing, and action. </title> <editor> In K. Sycara, editor, </editor> <title> Innovative Approaches to Planning, </title> <journal> Scheduling and Control, </journal> <pages> pages 292-297, </pages> <address> San Mateo, CA, 1990. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: BETTER-PLAN ... BEST-PLAN) (WAIT-FOR BETTER-PLAN?) (WAIT-FOR (TASK-END AN-ITER))) (IF BETTER-PLAN? (SWAP-PLAN BEST-PLAN NEXT-ITER))))))) Variants of this kind of planned iterative behavior have been implemented for the kitting robot [Lyons and Hendriks, 1992] and for controlling the walking behavior of Ambler <ref> [Simmons, 1990] </ref>. 7.2.2 Plan Execution a la Shakey The following RPL code piece specifies a simplified version of Shakey's [Nilsson, 1984] plan execution system PLANEX [Fikes et al., 1972]. Shakey's robot control system manages a global symbolic world model that is assumed to be correct and complete. <p> PRS and blackboard architectures do not provide the kinds of control abstractions for various kinds of synchronizations that are provided by RPL. Our work is closely related to Simmons' TCA (Task Control Architecture) <ref> [Simmons, 1990] </ref>, which provides control concepts to synchronize different threads of control, interleave planning and execution, recover from execution failures, and monitor the environment continuously. RPL provides control structures for the same purposes at a higher level of abstraction. <p> The RAP language is a predecessor of RPL, the robot control language used in this dissertation. We have shown on page 34 how reactive action packages can be implemented in RPL. RPL provides a larger set of control structures and more tools for planning. TCA (Task Control Architecture) <ref> [Simmons, 1990] </ref> is a specialized real-time operating system for managing the task-specific processes of a robot controller. The purpose of TCA is the handling of multiple, complex tasks in dynamic and uncertain environments by combining reactive and planning behaviors. The task-specific coomunicate via a centrol control module.
Reference: [Simmons, 1992] <author> R. Simmons. </author> <title> The roles of associational and causal reasoning in problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 53 </volume> <pages> 159-207, </pages> <year> 1992. </year>
Reference-contexts: The search strategy applied by planning modules is best-first search. The nodes in the search space are plans and the root node is the plan the planning module was activated with. The criticize/revise cycle is a variant of the generate/test/debug control strategy <ref> [Simmons, 1992] </ref>. The generate/test/debug control strategy eliminates all bugs in a plan to obtain a correct plan. The criticize/revise control strategy tries to compute plans with optimal scores. Bugs give the planner hints about how to improve the plan. <p> We have implemented models for about twenty five types of execution failures and about forty transformation rules. Another test would be to see how XFRM-PRL would have to be extended to express the rules used by other transformational planners, such as those described in <ref> [Sussman, 1977, Simmons, 1992] </ref>. <p> Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan. The transformational planning systems that are most closely related to XFRM are HACKER [Sussman, 1977, Sussman, 1990], CHEF [Hammond, 1989, Hammond, 1990], and GORDIUS <ref> [Simmons, 1988a, Simmons, 1988b, Simmons, 1992] </ref>. Given a set of tasks, transformational planners generate a plan hypothesis that can be projected and revise the plan hypothesis until it is good enough.
Reference: [Simmons, 1995] <author> R. Simmons. </author> <title> The 1994 aaai robot competition and exhibition. </title> <journal> AI Magazine, </journal> <volume> 16(2) </volume> <pages> 19-30, </pages> <year> 1995. </year>
Reference-contexts: Finally, the research presents novel and more powerful plan representation and inference techniques for planning research. 1.4.1 Relevance for Autonomous Robot Control Accomplishing everyday activities in our world simulator poses problems for a simulated robot that resembles those addressed by current robotic research <ref> [Dean and Bonasso, 1993, Konolige, 1994, Simmons, 1995] </ref>. In some respects our world simulator challenges robot controllers in ways that real environments challenge real robots: the simulated environment is complex, it changes, and time in the simulator passes at a realistic speed. <p> After discussing the indi 19 CHAPTER 2. REACTIVITY 20 vidual control concepts we show how the different concepts can be effectively combined within a structured reactive controller, which serves as a programming framework to realize the robot's routine activities. 2.1 The DELIVERYWORLD Although technology is progressing rapidly <ref> [Dean and Bonasso, 1993, Konolige, 1994, Simmons, 1995] </ref>, we still cannot equip robots with the repertoire of robust routines that they need to accomplish daily activities reliably and time-effectively. Perceiving the necessary and relevant information in real time is another serious obstacle.
Reference: [Steels, 1994] <author> L. Steels. </author> <title> Building agents out of behavior systems. </title> <editor> In L. Steels and R. Brooks, editors, </editor> <title> The Artificial Life Route to Artificial Intelligence. Building Situated Embodied Agents. </title> <publisher> Lawrence Erlbaum Ass., </publisher> <year> 1994. </year>
Reference-contexts: Also the information that can be sensed at any time has to be sufficient for selecting the right actions. While reactive approaches are characterized by fast response time to environmental events they are unable to deal with multiple and varying goals in a sophisticated manner. Behavior-based Architectures <ref> [Brooks, 1986b, Mataric, 1992, Steels, 1994] </ref>. Behavior-based architectures decompose the problem of autonomous control into special-purpose task-achieving modules that are connected directly to sensors and effectors.
Reference: [Sussman, 1977] <author> G. Sussman. </author> <title> A Computer Model of Skill Acquisition, </title> <booktitle> volume 1 of Aritficial Intelligence Series. </booktitle> <publisher> American Elsevier, </publisher> <address> New York, NY, </address> <year> 1977. </year>
Reference-contexts: In addition, he has regular daily and weekly errands, like cleaning his office. Since an office courier does his daily activities over and over again and is confronted with the same kinds of situations many times, he learns <ref> [Sussman, 1977] </ref> and uses [Agre, 1991] reliable and efficient routines for carrying out his daily jobs. Performing his daily activities usually does not require a lot of thought because routines are general. <p> First, we have said that routine activities are skills associated with the problems they solve <ref> [Sussman, 1977] </ref>. We have added the statement (DEF-ROUTINE-ACTIVITY pattern body) that can be used to specify pattern-directed routine activities. Defining a routine activity generates an entry in the plan library that can be indexed by pattern. The picture below shows a typical RPL procedure for a routine activity. <p> An important concept in classical planning is the notion of protections (or causal links) and protection violations (or threads). A protection represents an effect of a plan step that is needed by some later step, and therefore this effect has to be maintained until the later step is executed <ref> [Sussman, 1977] </ref>. Many classical partial-order planners work by adding ordering constraints until no protection is violated [McAllester and Rosenblitt, 1991]. RPL provides the statement (PROTECTION rigidity proposition fluent repair). <p> Thus, a good strategy is narrowing down the failures to more and more specific types of failures. Instead of hardwiring a questioning strategy <ref> [Sussman, 1977] </ref> into the critic we define a taxonomy of failure models where each model describes a particular class of failures and a classification algorithm that takes a failure description and computes the set of most specialized refinements with respect to the given failure taxonomy. <p> The arguments for :BY and :UNTIL are event specifications of different kinds: the passing of a deadline (:BY (TIME 14:00)), a certain state of plan interpretation (:BY (TASK-END t)), or an event caused by another robot (:BY (*BEGIN* (DOES ROBOT3 PICK-UP DESIG)). :UNTIL parameters can be used to represent protections <ref> [Sussman, 1977] </ref> and causal links [McAllester and Rosenblitt, 1991] that are well-known in classical planning. <p> We will show that transparent structured reactive plans are successful along the second dimensions in the chapters 6 and 8. The idea of making programs more transparent to facilitate planning is not new. HACKER <ref> [Sussman, 1977] </ref> uses annotations to make its plans more transparent. The following example shows an entry in HACKER's plan library for the task (ACHIEVE (ON ?A ?B)). <p> Over and above the difficult substantive issues about what plan transformations should be carried out, we must deal with formal issues about how to specify transformations on structured reactive plans. For example, the protection-violation avoidance transformation <ref> [Sussman, 1977] </ref> is, in the classical framework, a matter of inserting a link. In a structured reactive plan, it is a complex editing operation that must respect the semantics of RPL. <p> The planner views T A as an annotation for T R that represents the purpose of T R <ref> [Sussman, 1977] </ref>. We promised on page 96 to show how to test whether a task's purpose was to get a particular object, say BALL-5, to location h0,10i. Here's how: (AND (TASK-GOAL ?TSK (ACHIEVE (LOC ?DES h0,10i))) (HOLDS (TRACK ?DES BALL-5) (DURING ?TSK))). CHAPTER 5. <p> We have implemented models for about twenty five types of execution failures and about forty transformation rules. Another test would be to see how XFRM-PRL would have to be extended to express the rules used by other transformational planners, such as those described in <ref> [Sussman, 1977, Simmons, 1992] </ref>. <p> We have implemented models for about twenty five types of execution failures and about forty transformation rules. Another test would be to see how XFRM-PRL would have to be extended to express the rules used by other transformational planners, such as those described in [Sussman, 1977, Simmons, 1992]. HACKER's <ref> [Sussman, 1977] </ref> plan revision methods can be expressed easily. ?CODE # (PLAN ?STEPS ((:ORDER ?T2 ?T1) !?RELAXED-CONSTRAINTS)) 2 6 6 (AND (BUG PREREQUISITE-CLOBBERS-BROTHERS ?CODE ?T1 ?T2) (== ?CODE (PLAN ?STEPS ?CONSTRAINTS)) (MEMBER (:ORDER ?T1 ?T2) ?CONSTRAINTS) (DELETE (:ORDER ?T1 ?T2) ?CONSTRAINTS ?RELAXED-CONSTRAINTS)) The transformation rule above is a reconstruction of a <p> The XFRM framework facilitates the implementations by providing a plan language with very powerful control abstractions and declarative statements for making plans transparent. 1 In the long run we hope to learn libraries of routine plans automatically. Sussman's HACKER <ref> [Sussman, 1977] </ref> is an early computer program that learns plans, called skills, for accomplishing simple block stacking problems in the blocks world. In HACKER skill is a set of canned answer procedures indexed by problems. <p> Again, we would like the robot to learn procedures for detecting obvious flaws by just looking at the plan and the situation description without projecting and carefully analyzing the flaws. Such procedures could, for instance, detect obvious interferences between top-level commands. HACKER <ref> [Sussman, 1977] </ref> is able to learn methods for detecting flaws in plans. However, all these flaws are caused by violations of the linearity assumption, the assumption that the order in which subgoals of a conjunctive goal are accomplished does not matter. <p> Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan. The transformational planning systems that are most closely related to XFRM are HACKER <ref> [Sussman, 1977, Sussman, 1990] </ref>, CHEF [Hammond, 1989, Hammond, 1990], and GORDIUS [Simmons, 1988a, Simmons, 1988b, Simmons, 1992]. Given a set of tasks, transformational planners generate a plan hypothesis that can be projected and revise the plan hypothesis until it is good enough.
Reference: [Sussman, 1990] <author> G. Sussman. </author> <title> The virtuous nature of bugs. </title> <editor> In J. Allen, J. Hendler, and A. Tate, editors, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 111-117. </pages> <address> Kauf-mann, San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: An advantage of situated controllers is that they are robust against asynchronous events and sensor noise because they sense their environment at a high frequency. Situated approaches are appropriate for robots that have 3 Sussman <ref> [Sussman, 1990] </ref>: Has it ever occurred to you that bugs are manifestations of powerful strategies of creative thinking. That, perhaps, creating and removing bugs are necessary steps in the normal process of solving a problem? CHAPTER 1. INTRODUCTION 15 a small set of fixed goals. <p> The second observation is important in the context of planning reactive behavior because sometimes parts of reactive plans are opaque to the planner, or the plan interpreter requires revisions before failure analysis is completed. These two characteristics of revising structured reactive plans can be illustrated using the Sussmann anomaly <ref> [Sussman, 1990] </ref>. So let us leave the DELIVERYWORLD for a moment and CHAPTER 3. PLANNING 58 consider the following problem in the blocks world. <p> The number of transformations that can be CHAPTER 6. FORESTALLING BEHAVIOR FLAWS 113 applied to a structured reactive plan is huge. One heuristic to deal with the huge search space for better plans is to exploit the information why the plan failed to guide the search for better plans <ref> [Sussman, 1990] </ref>. Applying this idea, the failure detection step does not merely check whether a plan is predicted to be successful but predicts what could go wrong and summarizes the detected flaws as plan failures. <p> Transformational Planning Transformational planning is a planning technique which modifies a single plan instance instead of refining an abstract plan. The transformational planning systems that are most closely related to XFRM are HACKER <ref> [Sussman, 1977, Sussman, 1990] </ref>, CHEF [Hammond, 1989, Hammond, 1990], and GORDIUS [Simmons, 1988a, Simmons, 1988b, Simmons, 1992]. Given a set of tasks, transformational planners generate a plan hypothesis that can be projected and revise the plan hypothesis until it is good enough. <p> The transformational planning approach is very promising in applications where we have good heuristics that can generate almost correct plans, methods for finding all flaws in a plans, and good knowledge about how to debug plans. Sussman <ref> [Sussman, 1990] </ref> was the first one who suggested that constructing almost correct solutions and debugging them later is a powerful problem solving strategy. Once a plan failure is detected the planners have to find out why and where in order to revise the plan appropriately.
Reference: [Terzopoulos et al., 1994] <author> D. Terzopoulos, X. Tu, and R. Grzeszczuk. </author> <title> Artificial fishes: Autonomous locomotion, perception, behavior, and learning in a simulated physical world. </title> <journal> Artificial Life, </journal> <volume> 1(4) </volume> <pages> 327-351, </pages> <year> 1994. </year> <note> BIBLIOGRAPHY 207 </note>
Reference-contexts: In spite of such realism the world and the robot presented by the world simulator are much simpler than their real counterparts <ref> [Terzopoulos et al., 1994] </ref> (Our world simulator is described and justified in chapter 2.1). This simplicity allows us to investigate issues in intelligent robot control that cannot yet be explored using real robots. <p> The objects include all types of objects that are to be delivered, boxes, other robots, and locations. States include those that indicate exogenous events, unreliability of vision routines, and exceptional states for manipulations. These characteristics correspond to results obtained in the computational modelling of the behavior of fish <ref> [Terzopoulos et al., 1994] </ref>. In order to generate realistic behaviors of fish, fish only have to distinguish very few categories of objects: fish of its own species, predators, food, and obstacles although underwater worlds are very rich.
Reference: [Thrun, 1995] <author> S. </author> <title> Thrun. </title> <type> "personal communication", </type> <year> 1995. </year>
Reference-contexts: In the XFRM framework the implementation of these monitoring processes is supported by the powerful control abstractions provided by RPL. Recent work in the area of robot learning has started to develop methods for learning what to monitor to keep the robot from running into trouble <ref> [Thrun, 1995] </ref>. These learning methods take advantage of the robots' general sensors that are always active and detect when the robots are in trouble (for example, bump sensors).
Reference: [Ullman, 1984] <author> S. Ullman. </author> <title> Visual routines. </title> <journal> Cognition, </journal> <volume> 18 </volume> <pages> 97-160, </pages> <year> 1984. </year>
Reference-contexts: Also, we assume that the robot has visual routines to distinguish between objects that are relevant for its jobs <ref> [Ullman, 1984] </ref>. Firby et al. [1995] describe vision routines for trash collection, which detect and discriminate floor objects. The routines work under the assumption that small objects are trash and large objects are waste baskets.
Reference: [Wellmann, 1990] <author> M. Wellmann. </author> <title> Formulation of Tradeoffs in Planning under Uncertainty. </title> <publisher> Pitman and Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference: [Wilkins, 1988] <author> D. Wilkins. </author> <title> Practical Planning: Extending the AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: SIPE <ref> [Wilkins, 1988] </ref> and PLANEX [Fikes et al., 1972] are examples of planning systems that replan after the detection of irrecoverable plan failures. 7.2.5 Some Robot Control Architectures Since RPL is a single high-level language to coordinate planning and physical actions, we can implement a variety of robot control architectures in RPL. <p> Others leave the coordination flexible. Our approch proposes to specify the interaction between planning and execution as part of the robot controllers and provides the necessary language primitives to support this. PLANEX [Fikes et al., 1972] and SIPE <ref> [Wilkins, 1988] </ref> reason to recover from execution failures. The systems first generate a complete plan and execute it afterwards. If an execution failure is detected that the execution module cannot recover from, a new plan is generated or the current plan is adapted to the new situation.
Reference: [Williamson and Hanks, 1995] <author> M. Williamson and S. Hanks. </author> <note> Utility-directed planning. page 1498, </note> <year> 1995. </year>
Reference: [Winston, 1972] <author> P. Winston. </author> <title> The mit robot. </title> <editor> In Bernard Meltzer and Donald Mitchie, editors, </editor> <booktitle> Machine Intelligence 7, </booktitle> <pages> pages 431-463. </pages> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1972. </year>
Reference-contexts: It is also not a new idea that robot controllers equipped with AI planning techniques can be more effective than fixed robot controllers (it has been implemented in order to control several robots <ref> [Nilsson, 1984, Winston, 1972, Giralt et al., 1979] </ref>). The main characteristic of such deliberative robot controllers is that they carefully reason through all actions before they execute them. Deliberative robot controllers sense their environments in order to maintain a symbolic representation of the relevant aspects of their environments.
Reference: [Yampratoom, 1994] <author> E. Yampratoom. </author> <title> Using simulation-based projection to plan in an uncertain and temporally complex world. </title> <type> Technical Report 531, </type> <institution> University of Rochester, CS Deptartment, </institution> <year> 1994. </year>
Reference-contexts: CHAPTER 8. EVALUATION 189 of XFRM's Monte Carlo projection method is that it is much faster than other methods for probabilistic temporal projection <ref> [Yampratoom, 1994] </ref>. The utility models used by XFRM describe the quality of structured reactive plans in terms of their robustness (probability of complete goal satisfaction), the estimated execution time, and their completeness and are a limited model of plan utility.
Reference: [Zilberstein and Russell, 1993] <author> S. Zilberstein and S. Russell. </author> <title> Anytime sensing, planning and action: A practical model for robot control. </title> <address> pages 1402-1407, </address> <year> 1993. </year>
Reference: [Zilberstein and Russell, 1995] <author> S. Zilberstein and S. Russell. </author> <title> Optimal composition of real-time systems. </title> <journal> Artificial Intelligence, </journal> <volume> 79(2), </volume> <year> 1995. </year>
Reference: [Zilberstein, 1995] <author> S. Zilberstein. </author> <title> On the utility of planning. </title> <editor> In M. Pollack, </editor> <title> editor, </title> <journal> SIGART Bulletin Special Issue on Evaluating Plans, Planners, and Planning Systems, </journal> <volume> volume 6. </volume> <publisher> ACM, </publisher> <year> 1995. </year>
Reference-contexts: is that causing the kind of behavior that people exhibit in their everyday activities requires sophisticated synchronization of concurrent control processes, monitoring of the execution, adequate reaction to unpredicted events, and recovery from 1 see [Erol et al., 1992, Bylander, 1991], for some complexity results for propositional planning. 2 see <ref> [Zilberstein, 1995] </ref> for an discussion of the utility of planning. CHAPTER 1. INTRODUCTION 5 local execution failures. Unfortunately, plans that are partially ordered sets of actions cannot describe behaviors as complex and flexible as routine activities concisely, because they lack suitable control abstractions. <p> A good metric for evaluating the practical usefulness of structured reactive controllers is the amount by which they can improve the performance of the robots they control <ref> [Zilberstein, 1995, Cohen et al., 1989, Pollack and Ringuette, 1990] </ref>. The overall performance summarizes several measures such as the quality of the plan revisions, the time resources needed to compute these revisions, how robust plan revision is, and so on.
References-found: 150

