URL: http://www-cse.ucsd.edu/users/gary/pubs/m.ps
Refering-URL: http://www.cse.ucsd.edu/users/gary/
Root-URL: 
Email: mnguyen@cs.ucsd.edu  
Title: Tau Net: A Neural Network for Modeling Temporal Variability  
Author: Mai H. Nguyen Garrison W. Cottrell 
Keyword: recurrent neural networks, predictive neural networks, temporal processing, speech recognition  
Date: November 1996  
Address: La Jolla, CA 92093-0114  
Affiliation: Department of Computer Science Engineering Institute for Neural Computation University of California, San Diego  
Abstract: The ability to handle temporal variation is important when dealing with real-world dynamic signals. In many applications, inputs do not come in as fixed-rate sequences, but rather as signals with time scales that can vary from one instance to the next; thus, modeling dynamic signals requires not only the ability to recognize sequences but also the ability to handle temporal changes in the signal. This paper discusses "Tau Net," a neural network for modeling dynamic signals, and its application to speech. In Tau Net, sequence learning is accomplished using a combination of prediction, recurrence and time-delay connections. Temporal variability is modeled by having adaptable time constants in the network, which are adjusted with respect to the prediction error. Adapting the time constants changes the time scale of the network, and the adapted value of the network's time constant provides a measure of temporal variation in the signal. Tau Net has been applied to several simple signals: sets of sine waves differing in frequency and in phase [2], a multidimensional signal representing the walking gait of children [3], and the energy contour of a simple speech utterance [11]. Tau Net has also been shown to work on a voicing distinction task using synthetic speech data [12]. In this paper, Tau Net is applied to two speaker-independent tasks, vowel recognition (of f/ae/,/iy/,/ux/g) and consonant recognition (of f/p/,/t/,/k/g) using speech data taken from the TIMIT database. It is shown that Tau Nets, trained on medium-rate tokens, achieved about the same performance as networks without time constants trained on tokens at all rates, and performed better than networks without time constants trained on medium-rate tokens. Our results demonstrate Tau Net's ability to identify vowels and consonants at variable speech rates by extrapolating to rates not represented in the training set. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Beth Carlson, </author> <year> 1994. </year> <title> Center for Computer Aids in Industrial Productivity (CAIP) Speech Workshop, </title> <type> personal communication. </type>
Reference-contexts: These vowels were chosen because they are among the most elastic phonemes in the TIMIT database; their durations have standard deviations of 0:0442, 0:0357, and 0:0528 seconds, respectively, compared to the average standard deviation of 0:0316 seconds for all phonemes in TIMIT <ref> [1] </ref>. These vowels would therefore make a good test for temporal variability. Training and test vowel tokens were extracted from the following contexts: had,greasy,suit for /ae/,/iy/,/ux/, respectively. Contexts were constrained to reduce variations in the speech signal due to coarticulation. The TIMIT database is divided into 8 different dialect regions.
Reference: [2] <author> Garrison W. Cottrell, Mai H. Nguyen, and Fu-Sheng Tsung. </author> <title> Dynamic rate adaptation. </title> <journal> Artificial Intelligence Review, </journal> <volume> 7 </volume> <pages> 271-283, </pages> <year> 1993. </year>
Reference-contexts: However, none of this work investigated the adaptation of time constants to dynamically adjust the processing rate of a neural network. 5 4 Experimental Results In previous work, we have tested Tau Net on sine waves of different phases and frequencies [3], a 24-dimensional signal representing gait motion in children <ref> [2] </ref>, the energy contour of a simple speech utterance [11], and on a voicing task using synthetic speech data [12]. In all these experiments, Tau Net is trained on signals at the medium rate and tested on signals at all rates (or time scales). <p> This one-dimensional minimization was performed using a line search method. This procedure made use of the segmentation information (endpoints of a token), which was readily available for TIMIT data. It is possible to adapt the time constant online as well. In previous work ([3] <ref> [2] </ref> [11]), we have used online adaptation of the time constant using backpropagation with momentum. To quantify the benefits of adaptable time constants, a comparison was made with networks with the same architecture but without time constants.
Reference: [3] <author> Garrison W. Cottrell, Mai H. Nguyen, and Fu-Sheng Tsung. </author> <title> Tau net: The way to do is to be. </title> <booktitle> Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 365-370, </pages> <year> 1993. </year>
Reference-contexts: However, none of this work investigated the adaptation of time constants to dynamically adjust the processing rate of a neural network. 5 4 Experimental Results In previous work, we have tested Tau Net on sine waves of different phases and frequencies <ref> [3] </ref>, a 24-dimensional signal representing gait motion in children [2], the energy contour of a simple speech utterance [11], and on a voicing task using synthetic speech data [12].
Reference: [4] <author> Ken ichi Iso and Takao Watanabe. </author> <title> Speaker-independent word recognition using a neural prediction model. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 441-444, </pages> <year> 1990. </year>
Reference-contexts: In the NPM, a word is modeled by a sequence of predictive networks. The NPM has been applied to a speaker-independent isolated Japanese digit word recognition task <ref> [4] </ref>. A similar approach is taken in the LPNN: A word is modeled by a sequence of predictive networks, and a phoneme, in turn, is modeled by a sequence of three predictive networks.
Reference: [5] <author> Peter Ladefoged. </author> <title> A course in phonetics. </title> <publisher> Harcourt Brace Jovanovich, </publisher> <address> 2 edition, </address> <year> 1982. </year>
Reference-contexts: In addition, since acoustic features of consonants are very subtle, and because of their brief and transient nature, consonants are often characterized by their effects on the adjacent vowel rather than by their acoustic features <ref> [5] </ref>. The fact that token segments contained only the consonant and excludes the following vowel context (since phone endpoints provided in TIMIT were used to extract tokens) makes the identification of these consonant tokens extremely difficult.
Reference: [6] <author> Lori F. Lamel, Robert H. Kassel, and Stephanie Seneff. </author> <title> Speech database development: Design and analysis of the acoustic-phonetic corpus. </title> <booktitle> Procceedings of the DARPA Speech Recognition Workshop, </booktitle> <pages> pages 26-32, </pages> <year> 1987. </year>
Reference-contexts: Consequently, we expect to encounter variable rates in the speech data, thus, providing a good test for Tau Net's ability to model temporal variation. 4.1 Speech Data The data used for these experiments were taken from TIMIT, a large speech database with over 600 speakers <ref> [6] </ref>. TIMIT was designed for developing speaker-independent phoneme-based speech recognition systems and is widely used. A Hamming window of width 256 samples was applied to the speech waveform every 10 msec.
Reference: [7] <author> Kevin J. Lang, Alex H. Waibel, and Geoff E. Hinton. </author> <title> A time-delay neural network architecture for isolated word recognition. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 23-43, </pages> <year> 1990. </year>
Reference-contexts: TDNNs have been applied to a speaker-dependent phoneme recognition task [21] and a multi-speaker isolated word recognition task of the difficult E-set (BDEV) <ref> [7] </ref>. 2.3 Recurrent Neural Networks A third approach is to use recurrent connections to enable the network to develop internal states. This allows the network to keep a history of its responses to previous inputs, and to use that information in processing the current input.
Reference: [8] <author> Esther Levin. </author> <title> Hidden control neural architecture modeling of nonlinear time varying systems and its applications. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4(1) </volume> <pages> 109-116, </pages> <year> 1993. </year>
Reference-contexts: The current state of the HCNN is determined by a control input, which is separate from the acoustic input. The HCNN has been tested on a speaker-independent connected digit recognition task <ref> [8] </ref>. 2.5 Temporal Variability As discussed earlier, modeling real-world dynamic signals such as speech requires sequence recognition and the ability to handle temporal variability.
Reference: [9] <author> A. Mellouk and P. Gallinari. </author> <title> A discriminative neural prediction system for speech recognition. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 533-536, </pages> <year> 1993. </year>
Reference-contexts: Discriminant training allows for negative examples to be used, thus providing better region boundaries between the classes and should yield better classification, especially for classes with few clearly distinct features such as consonants. Mellouk & Gallinari <ref> [9] </ref> have investigated the use of discriminant training in the predictive framework. In this approach, the output of the network is converted into a scalar that represents the prediction error.
Reference: [10] <author> Michael Mozer. </author> <title> Induction of multiscale temporal structure. </title> <editor> In Richard P. Lippmann, John E. Moody, and David S. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 3. </volume> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: With our approach, the network automatically determines its processing rate in the process of minimizing its prediction error. Other researchers have used time constants in neural networks (e.g., <ref> [10] </ref> [13] [14]).
Reference: [11] <author> Mai H. Nguyen and Garrison W. Cottrell. </author> <title> A technique for adapting to speech rate. </title> <booktitle> IEEE Workshop on Neural Networks for Signal Processing, </booktitle> <pages> pages 382-391, </pages> <year> 1993. </year>
Reference-contexts: time constants to dynamically adjust the processing rate of a neural network. 5 4 Experimental Results In previous work, we have tested Tau Net on sine waves of different phases and frequencies [3], a 24-dimensional signal representing gait motion in children [2], the energy contour of a simple speech utterance <ref> [11] </ref>, and on a voicing task using synthetic speech data [12]. In all these experiments, Tau Net is trained on signals at the medium rate and tested on signals at all rates (or time scales). <p> This one-dimensional minimization was performed using a line search method. This procedure made use of the segmentation information (endpoints of a token), which was readily available for TIMIT data. It is possible to adapt the time constant online as well. In previous work ([3] [2] <ref> [11] </ref>), we have used online adaptation of the time constant using backpropagation with momentum. To quantify the benefits of adaptable time constants, a comparison was made with networks with the same architecture but without time constants.
Reference: [12] <author> Mai H. Nguyen and Garrison W. Cottrell. </author> <title> A connectionist approach to rate adaptation. </title> <journal> SigArt, </journal> <volume> 5(3), </volume> <year> 1994. </year> <title> special issue on "Time and Neural Networks". </title>
Reference-contexts: neural network. 5 4 Experimental Results In previous work, we have tested Tau Net on sine waves of different phases and frequencies [3], a 24-dimensional signal representing gait motion in children [2], the energy contour of a simple speech utterance [11], and on a voicing task using synthetic speech data <ref> [12] </ref>. In all these experiments, Tau Net is trained on signals at the medium rate and tested on signals at all rates (or time scales).
Reference: [13] <author> Barak A. Pearlmutter. </author> <title> Learning state space trajectories in recurrent neural networks. </title> <booktitle> IJCNN, </booktitle> <pages> pages 365-372, </pages> <year> 1989. </year>
Reference-contexts: With our approach, the network automatically determines its processing rate in the process of minimizing its prediction error. Other researchers have used time constants in neural networks (e.g., [10] <ref> [13] </ref> [14]).
Reference: [14] <author> F. Pineda. </author> <title> Generalization of back propagation to recurrent neural networks. </title> <journal> In Physical Review Letters, </journal> <volume> volume 19, </volume> <pages> pages 2229-2232, </pages> <year> 1987. </year>
Reference-contexts: With our approach, the network automatically determines its processing rate in the process of minimizing its prediction error. Other researchers have used time constants in neural networks (e.g., [10] [13] <ref> [14] </ref>).
Reference: [15] <author> Steve Renals, Nelson Morgan, Herve Bourlard, Michael Cohen, and Horacio Franco. </author> <title> Connectionist probability estimators in hmm speech recognition. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> 2(1) </volume> <pages> 161-174, </pages> <year> 1994. </year>
Reference-contexts: Most current hybrid approaches use neural networks to perform recognition at the frame level and HMMs on top to concatenate sequences of frame-level results to perform phoneme- and word-level recognition. Hybrid neural network-HMM systems have been used for large-vocabulary, speaker-independent, continuous speech recognition tasks (e.g., see <ref> [15] </ref>). 2.2 Time Delay Neural Networks Another approach is to use time delay neural networks (TDNNs). A TDNN is a multi-layer feed-forward network in which time is modeled as space.
Reference: [16] <author> Tony Robinson. </author> <title> An application of recurrent nets to phone probability estimation. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(2) </volume> <pages> 298-305, </pages> <year> 1994. </year> <month> 22 </month>
Reference-contexts: The REPN can also be considered a hybrid system since frame-level classifications determined by the network are processed by an HMM to produce phone-level classifications. The REPN has been shown to work quite well on a speaker-independent phoneme recognition task using data from TIMIT, a large standard speech corpus <ref> [16] </ref>. 2.4 Predictive Neural Networks Yet another way to model time-dependent speech signals with neural networks is to use a predictive approach.
Reference: [17] <author> Joe Tebelskis and Alex Waibel. </author> <title> Large vocabulary recognition using linked predictive neural networks. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 437-440, </pages> <year> 1990. </year>
Reference-contexts: Networks that correspond to the same phoneme (but in different words or in different parts of the same word) have their weights linked together, to allow for modeling phonemes in different contexts. The LPNN has been applied to a single-speaker Japanese isolated word task <ref> [17] </ref> and a continuous speech recognition task [18]. In the HCNN, sequencing is modeled in a manner similar to HMMs: the current state of the model is explicitly determined, and the output of the model is dependent on the current state.
Reference: [18] <author> Joe Tebelskis, Alex Waibel, Bojan Petek, and Otto Schmidbauer. </author> <title> Continuous speech recognition using linked predictive neural networks. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 61-64, </pages> <year> 1991. </year>
Reference-contexts: The LPNN has been applied to a single-speaker Japanese isolated word task [17] and a continuous speech recognition task <ref> [18] </ref>. In the HCNN, sequencing is modeled in a manner similar to HMMs: the current state of the model is explicitly determined, and the output of the model is dependent on the current state.
Reference: [19] <author> Fu-Sheng Tsung. </author> <title> Learning in recurrent finite difference networks. </title> <editor> In D. S. Touretzky, J. L. Elman, T. J. Sejnowski, and G. E. Hinton, editors, </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Compensating for temporal variability is then accomplished by adapting the time constant of the network with respect to the prediction error, which adjusts the time scale of the network, as explained below. Following Tsung <ref> [19] </ref>, the set of equations we use for Tau Net is a finite-difference approximation to a continuous-time network. <p> = (1 t k t f (s k (t)) (2) X w kj y j (t): One advantage of using the discretized version of a continuous network is that the learning algorithm is simpler than the continuous versions, but the network still retains some essential characteristics of the continuous network <ref> [19] </ref>. Equation 2 may lead to instabilities, however, since the gradient @E=@t i contains a 1=t 2 i term. This is, of course, undesirable since @E=@t i ! 1 as t 2 i ! 0. In addition, Equation 2 makes sense only if 0 t=t k 1.
Reference: [20] <author> Drew van Camp, Tony Plate, and Geoff Hinton. </author> <title> Xerion neural network simulator. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: The range of these features is [0,1]. For the consonant data, the log power was also extracted for each frame, resulting in 15 speech parameters per input vector. 4.2 Training and Testing Methodology The Xerion simulator <ref> [20] </ref> was used to implement the networks used in these experiments. The hyperbolic tangent was used for the unit activation function, the networks were trained with the real-time recurrent learning (RTRL) algorithm [23].
Reference: [21] <author> A. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K. Lang. </author> <title> Phoneme recognition using time-delay neural networks. </title> <type> Technical report, </type> <institution> ATR Interpreting Telephony Research Laboratories, </institution> <year> 1987. </year>
Reference-contexts: Temporal relationships between acoustic events are captured via time delay connections and successively larger receptive fields from layer to layer, and shift invariance is achieved by imposing local receptive fields and weight sharing on units within the same layer. TDNNs have been applied to a speaker-dependent phoneme recognition task <ref> [21] </ref> and a multi-speaker isolated word recognition task of the difficult E-set (BDEV) [7]. 2.3 Recurrent Neural Networks A third approach is to use recurrent connections to enable the network to develop internal states.
Reference: [22] <author> Raymond L. Watrous. </author> <title> Phoneme discrimination using connectionist networks. </title> <journal> The Journal of the Acoustical Society of America, </journal> <volume> 87(4) </volume> <pages> 1753-1772, </pages> <year> 1990. </year>
Reference-contexts: In the temporal flow model, each hidden and output unit has a self-recurrent weight, and connections between successive layers are time-delayed. The temporal flow model has been applied to several single-speaker phonetic 2 discrimination tasks involving place of articulation, voicing, etc <ref> [22] </ref>. The REPN has a fully recur-rent hidden layer, and each weight in this network has a separate learning rate. The REPN can also be considered a hybrid system since frame-level classifications determined by the network are processed by an HMM to produce phone-level classifications.
Reference: [23] <author> Ron Williams and Dave Zipser. </author> <title> A learning algorithm for continually running fully recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 270-280, </pages> <year> 1989. </year> <month> 23 </month>
Reference-contexts: The hyperbolic tangent was used for the unit activation function, the networks were trained with the real-time recurrent learning (RTRL) algorithm <ref> [23] </ref>. Optimization was performed using the conjugate gradient method; for the following experiments, the default settings for conjugate gradient in Xerion were used. Since TIMIT was designed for speaker-independent recognition (as opposed to multi-speaker recognition), speech data for training and testing were taken from two separate sets of speakers.
References-found: 23

