URL: http://robotics.eecs.berkeley.edu/~mayi/psfile/EECS226/midterm296soln.ps.gz
Refering-URL: http://robotics.eecs.berkeley.edu/~mayi/EECS226.html
Root-URL: http://www.cs.berkeley.edu
Title: a bit more mathematical, the log likelihood ratio is L() (ba) T 1 for I
Author: &lt; P n P n i= P fS i g n fi (=n) . Similarly, j&lt;i fS j j S i g Y (n) j N (t) E[mN (t)] mt h h N(t) X Y (n)) j N (t) 
Date: 2  2  
Address: i=1  
Affiliation: E(N 2 E  
Note: EECS 226A Midterm 2 Solutions To try to be  eigenvalues of (I vv T are 1  1 n(n 1)P fS i gP  so varN 2 1 1. 3. X(t) is not stationary, as the distribution of (X(1=4); X(3=4)) is not the same as the  3 X Y (1=3) (b) The LLSE is given by X(Y cov(X; Y )[var(Y 1 Y g 4 g 6 Y (c) (2Z 1 Z 2 )=3  is possible and the MMSE of X is X. (d) E(X j V v) 1 2 (v 2 0, so E(X j V 0, which is the same as the estimate with no information at all, namely E(X). So knowing V does not help us in the MMSE sense. 5. (b)  
Pubnum: 1 2:  
Abstract: 1. Intuitively it is clear that (for n 2) we should take a to be orthogonal to v, with kak = 1, b = a, to make the signal as large as possible and the problem of distinguishing between the hypothesis orthogonal to as much of the noise as possible (the rest of the noise is white, so unaffected by direction). N 2 we can choose (b a) 1 orthogonal to v which will minimise the component of the noise in the direction of the test statistic. This is the same as choosing (b a) orthogonal to v since the 
Abstract-found: 1
Intro-found: 1
References-found: 0

