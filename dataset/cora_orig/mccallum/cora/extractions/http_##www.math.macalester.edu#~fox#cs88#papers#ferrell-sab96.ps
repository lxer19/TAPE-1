URL: http://www.math.macalester.edu/~fox/cs88/papers/ferrell-sab96.ps
Refering-URL: http://www.math.macalester.edu/~fox/cs88/readings.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: ferrell@ai.mit.edu  
Phone: voice: (617) 253-7007 fax: (617) 253-0039  
Title: Orientation Behavior Using Registered Topographic Maps  
Author: Cynthia Ferrell 
Address: 545 Technology Square, Room 819 Cambridge, MA 02139 USA  
Affiliation: Massachusetts Institute of Technology Artificial Intelligence Laboratory  
Abstract: The ability to orient toward visual, auditory, or tactile stimuli is an important skill for systems intended to interact with and explore their environment. In the brain of mammalian vertebrates, the Superior Colliculus is specialized for integrating multi-modal sensory information, and for using this information to orient the animal to the source sensory stimuli, such as noisy, moving objects. Within the Superior Colliculus, this ability appears to be implemented using layers of registered, multi-modal, topographic maps. Inspired by the structure, function, and plasticity of the Superior Colliculus, we are in the process of implementing multi-modal orientation behaviors on our humanoid robot using registered topographic maps. In this paper, we explore integrating visual motion and oculomotor maps to study experience-based map registration mechanisms. Continuing work includes incorporating self-organizing feature maps, including more sensory modalities such as auditory and somatorsensory maps, and extending the motor repertoire to include the neck and body degrees of freedom for full-body orien tation.
Abstract-found: 1
Intro-found: 1
Reference: <author> Bauer, H. & Pawelzik, K. </author> <year> (1992), </year> <title> `Quantifying the Neighborhood Preservation of Self-Organizing Feature Maps', </title> <journal> IEEE Transactions on Neural Networks 3(4), </journal> <pages> 570-579. </pages>
Reference-contexts: This phenomena has been seen in other perceptual areas of the cortex and is typical of self-organizing feature maps (SOFMs). A number of people have modeled this phenomena using neural networks (Kohonen 1982), <ref> (Bauer & Pawelzik 1992) </ref>, (Durbin & Mitchison 1990). It has also been found that the registration between maps is malleable over the developmental period.
Reference: <author> Brainard, M. & Knudsen, E. </author> <year> (1993), </year> <title> `Experience-dependent Plasticity in the Inferior Colliculus: A Site for Visual Calibration of the Neural Representation of Auditory Space in the Barn Owl', </title> <journal> The Journal of Neuroscience 13(11), </journal> <pages> 4589-4608. </pages>
Reference-contexts: The same is true for social skills where the robot should position itself so that the person is easy to interact with. Our approach to implementing orientation behavior on Cog is heavily inspired by relevant work in neuroscience (Stein & Meredith 1993), <ref> (Brainard & Knudsen 1993) </ref>. In the brain of mammalian vertebrates, the Superior Colliculus is an organ specialized for producing orientation behavior. In non-mammalian vertebrates (birds, amphibians, etc.), the optic tectum is the analogous organ. The structure of the Superior Colliculus is characterized by layers of topographically organized maps. <p> It has also been found that the registration between maps is malleable over the developmental period. This phenomena has been studied in the inferior and superior colliculus of young barnyard owls, where the registration of the auditory map to the visual map shifts according to experience. <ref> (Brainard & Knudsen 1993) </ref>, (Brainard & Knudsen 1995) found that the visual map is used to train the auditory map so that the auditory map shares the same coordinates as the visual map.
Reference: <author> Brainard, M. & Knudsen, E. </author> <year> (1995), </year> <title> `Dynamics of Visually Guided Auditory Plasticity in the Optic Tec-tum of the Barn Owl', </title> <journal> Journal of Neurophysiology 73(2), </journal> <pages> 595-614. </pages>
Reference-contexts: This phenomena has been studied in the inferior and superior colliculus of young barnyard owls, where the registration of the auditory map to the visual map shifts according to experience. (Brainard & Knudsen 1993), <ref> (Brainard & Knudsen 1995) </ref> found that the visual map is used to train the auditory map so that the auditory map shares the same coordinates as the visual map.
Reference: <author> Brooks, R. </author> <year> (1990), </year> <title> AIM 1227: The Behavior Language User's Guide, </title> <type> Technical report, </type> <institution> MIT Artificial Intelligence Lab Internal Document. </institution>
Reference-contexts: MARS, like the Behavior Language <ref> (Brooks 1990) </ref>, is a language for building networks of concurrently running processes. The processes can communicate either locally by passing messages over virtual wires, or globally through a process inspired by hormonal mechanisms.
Reference: <author> Brooks, R. </author> <year> (1994a), </year> <title> L, </title> <type> Technical report, </type> <note> IS Robotics Internal Document. </note>
Reference-contexts: Position and velocity commands are sent to the motor controller boards from the MIMD computer described above. 3.4 The Software Environment Each processor has an operating system; L, a compact, downwardly compatible version of Common Lisp that supports real-time multi-processing <ref> (Brooks 1994a) </ref>; and MARS, which is a front end to L that supports com munication between multiple processes on a single pro-cessor as well as communication between processes running on separate processors (Brooks 1994b).
Reference: <author> Brooks, R. </author> <year> (1994b), </year> <title> MARS, </title> <type> Technical report, </type> <note> IS Robotics Internal Document. </note>
Reference-contexts: processor has an operating system; L, a compact, downwardly compatible version of Common Lisp that supports real-time multi-processing (Brooks 1994a); and MARS, which is a front end to L that supports com munication between multiple processes on a single pro-cessor as well as communication between processes running on separate processors <ref> (Brooks 1994b) </ref>. MARS, like the Behavior Language (Brooks 1990), is a language for building networks of concurrently running processes. The processes can communicate either locally by passing messages over virtual wires, or globally through a process inspired by hormonal mechanisms.
Reference: <author> Brooks, R. & Stein, L. A. </author> <year> (1994), </year> <title> `Building Brains for Bodies', </title> <booktitle> Autonomous Robots 1:1, </booktitle> <pages> 7-25. </pages>
Reference-contexts: Hence, orientation behavior is performed frequently and repeatedly by agents that are tightly coupled with their environment, where perception guides action and behavior assists in more effective perception. Certainly, orientation behavior is a basic skill we would like to implement on Cog, our humanoid robot <ref> (Brooks & Stein 1994) </ref>. We would like Cog to perform a variety of tasks, many of which fall under two broad behavioral themes: exploratory behavior and social skills.
Reference: <author> Durbin, R. & Mitchison, G. </author> <year> (1990), </year> <title> `A Dimension Reduction Framework for Understanding Cortical Maps', </title> <booktitle> Nature 343(6259), </booktitle> <pages> 644-647. </pages>
Reference-contexts: This phenomena has been seen in other perceptual areas of the cortex and is typical of self-organizing feature maps (SOFMs). A number of people have modeled this phenomena using neural networks (Kohonen 1982), (Bauer & Pawelzik 1992), <ref> (Durbin & Mitchison 1990) </ref>. It has also been found that the registration between maps is malleable over the developmental period.
Reference: <author> Irie, R. </author> <year> (1995), </year> <title> Robust Sound Localization: an Application of an Auditory System for a Humanoid Robot, </title> <type> Master's thesis, </type> <institution> MIT. </institution>
Reference-contexts: In addition to the visual system described above, Cog has several other perceptual systems under concurrent development. To date, we have developed an auditory system <ref> (Irie 1995) </ref>, a vestibular system, and a variety of force resistive sensors to give Cog a tactile sense. These systems are in the process of being ported to the Cog platform. 3.3 The Computational Platform This section summarizes the computational system we developed to meet Cog's requirements.
Reference: <author> Kohonen, T. </author> <year> (1982), </year> <title> `Self-Organized Formation of Topologically Correct Feature Maps', </title> <booktitle> Biological Cybernetics 43, </booktitle> <pages> 59-69. </pages>
Reference-contexts: This figure illustrates registered visual, auditory, and soma-torsensory spatial representations. Adapted from (Stein & Meredith 1993). Subsequently, cortical maps have garnered a lot of attention, and a variety of work has explored the phenomena of self-organizing feature maps, <ref> (Kohonen 1982) </ref>, (Ritter & Schulten 1988), (Obermayer, Ritter, & Schulten 1990). Through implementing something like the Superior Colliculus on Cog, this paper explores how topographically organized maps develop and interact to produce a unified observable behavior. There are a variety of topics this paper explores in relation to this endeavor. <p> This phenomena has been seen in other perceptual areas of the cortex and is typical of self-organizing feature maps (SOFMs). A number of people have modeled this phenomena using neural networks <ref> (Kohonen 1982) </ref>, (Bauer & Pawelzik 1992), (Durbin & Mitchison 1990). It has also been found that the registration between maps is malleable over the developmental period. <p> Several mechanisms and models have been proposed to account for this organizational process. The mechanisms we use for map organization and alignment on Cog are inspired by similar mechanisms <ref> (Kohonen 1982) </ref>. However, different combinations of mechanisms are used depending on what is being learned: i.e. tuning the organization within a map, registering different sensory maps, or registering sensory maps and motor maps. A variety of mechanisms determine how map connections are established.
Reference: <author> Marjanovic, M., Scassellati, B., & Williamson, M. </author> <year> (1996), </year> <title> Self-Taught Visually-Guided Pointing for a Humanoid Robot, </title> <booktitle> in `Proceedings of the 4th Intl. Conference on Simulation of Adatpive Behavior', </booktitle> <address> Cape Cod, MA. </address>
Reference-contexts: For example, orienting the body to an object of interest assists manipulation tasks by putting the object where it is most accessible to sensory and motor systems. Eventually the work presented in this paper will be integrated with the ability to reach for visual targets <ref> (Marjanovic, Scassel-lati, & Williamson 1996) </ref>. The same is true for social skills where the robot should position itself so that the person is easy to interact with. <p> We would like to integrate the full orientation behavior with reaching and manipulation tasks currently under parallel development by other members of the group <ref> (Marjanovic et al. 1996) </ref>. 8 Conclusions This paper describes an implementation of orientation behavior on Cog using registered topographic maps. We have presented biological evidence that this is an effective method for orienting to multi-modal stimuli in animals.
Reference: <author> Obermayer, K., Ritter, H., & Schulten, K. </author> <year> (1990), </year> <title> `A Principle for the Formation of the Spatial Structure of Cortical Feature Maps', </title> <booktitle> Proceedings of the National Academy of Science USA 87, </booktitle> <pages> 8345-8349. </pages>
Reference-contexts: This figure illustrates registered visual, auditory, and soma-torsensory spatial representations. Adapted from (Stein & Meredith 1993). Subsequently, cortical maps have garnered a lot of attention, and a variety of work has explored the phenomena of self-organizing feature maps, (Kohonen 1982), (Ritter & Schulten 1988), <ref> (Obermayer, Ritter, & Schulten 1990) </ref>. Through implementing something like the Superior Colliculus on Cog, this paper explores how topographically organized maps develop and interact to produce a unified observable behavior. There are a variety of topics this paper explores in relation to this endeavor.
Reference: <author> Ritter, H. & Schulten, K. </author> <year> (1988), </year> <title> Kohonen's Self-Organizing Maps: Exploring their Computational Capabilites, </title> <booktitle> in `Proceedings of the IEEE International Conference on Neural Networks', </booktitle> <volume> Vol. </volume> <pages> 1, </pages> <address> San Diego, CA, </address> <pages> pp. 109-116. </pages>
Reference-contexts: This figure illustrates registered visual, auditory, and soma-torsensory spatial representations. Adapted from (Stein & Meredith 1993). Subsequently, cortical maps have garnered a lot of attention, and a variety of work has explored the phenomena of self-organizing feature maps, (Kohonen 1982), <ref> (Ritter & Schulten 1988) </ref>, (Obermayer, Ritter, & Schulten 1990). Through implementing something like the Superior Colliculus on Cog, this paper explores how topographically organized maps develop and interact to produce a unified observable behavior. There are a variety of topics this paper explores in relation to this endeavor.
Reference: <author> Stein, B. & Meredith, M. </author> <year> (1993), </year> <title> The Merging of the Senses, A Bradford Book, </title> <address> Cambridge, MA. </address>
Reference-contexts: The same is true for social skills where the robot should position itself so that the person is easy to interact with. Our approach to implementing orientation behavior on Cog is heavily inspired by relevant work in neuroscience <ref> (Stein & Meredith 1993) </ref>, (Brainard & Knudsen 1993). In the brain of mammalian vertebrates, the Superior Colliculus is an organ specialized for producing orientation behavior. In non-mammalian vertebrates (birds, amphibians, etc.), the optic tectum is the analogous organ. <p> These maps are registered with one another to share a common multisensory coordinate system. This figure illustrates registered visual, auditory, and soma-torsensory spatial representations. Adapted from <ref> (Stein & Meredith 1993) </ref>. Subsequently, cortical maps have garnered a lot of attention, and a variety of work has explored the phenomena of self-organizing feature maps, (Kohonen 1982), (Ritter & Schulten 1988), (Obermayer, Ritter, & Schulten 1990). <p> Experiments have shown that the size of the map region corresponding to a particular cutaneous region on the hand is correlated to how much stimulation that part of the hand receives over time. Furthermore, adjacent regions of the map correspond to regions on the hand that are temporally adjacent <ref> (Stein & Meredith 1993) </ref>. This phenomena has been seen in other perceptual areas of the cortex and is typical of self-organizing feature maps (SOFMs). A number of people have modeled this phenomena using neural networks (Kohonen 1982), (Bauer & Pawelzik 1992), (Durbin & Mitchison 1990).
References-found: 14

