URL: ftp://ftp.cs.colorado.edu/users/mozer/papers/branch-prediction.ps
Refering-URL: http://www.cs.colorado.edu/~mozer/papers/branch-prediction.html
Root-URL: http://www.cs.colorado.edu
Title: Evidence-based Static Branch Prediction using Machine Learning  
Author: Brad Calder Dirk Grunwald, Michael Jones, Donald Lindsay, James Martin, Michael Mozer, and Benjamin Zorn 
Date: September 19, 1996  
Address: Campus Box 430  Boulder, CO 80309-0430 USA  
Affiliation: Department of Computer Science  University of Colorado  
Abstract: Correctly predicting the direction that branches will take is increasingly important in today's wide-issue computer architectures. The name program-based branch prediction is given to static branch prediction techniques that base their prediction on a program's structure. In this paper, we investigate a new approach to program-based branch prediction that uses a body of existing programs to predict the branch behavior in a new program. We call this approach to program-based branch prediction evidence-based static prediction, or ESP. The main idea of ESP is that the behavior of a corpus of programs can be used to infer the behavior of new programs. In this paper, we use neural networks and decision trees to map static features associated with each branch to a prediction that the branch will be taken. ESP shows significant advantages over other prediction mechanisms. Specifically, it is a program-based technique, it is effective across a range of programming languages and programming styles, and it does not rely on the use of expert-defined heuristics. In this paper, we describe the application of ESP to the problem of static branch prediction and compare our results to existing program-based branch predictors. We also investigate the applicability of ESP across computer architectures, programming languages, compilers, and run-time systems. We provide results showing how sensitive ESP is to the number and type of static features and programs included in the ESP training sets, and compare the efficacy of static branch prediction for subroutine libraries. Averaging over a body of 43 C and Fortran programs, ESP branch prediction results in a miss rate of 20%, as compared with the 25% miss rate obtained using the best existing program-based heuristics.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Alverson, D. Callahan, D. Cummings, B. Koblenz, A. Porterfield, and B. Smith. </author> <title> The tera computer system. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 1-6, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: To facilitate program-based methods for branch prediction, some modern architectures provide a branch-likely bit in each branch instruction <ref> [1] </ref>. In these architectures, compilers can employ either profile-based [13] or program-based techniques to determine what branches are likely to be taken. <p> The tanh function is normalized to achieve an activity range of <ref> [0; 1] </ref> for the output unit. 18 The input-output behavior of the neural network is determined by its free parameters, the weights w and v and biases b and a. These parameters are set by an algorithm known as back propagation [21].
Reference: [2] <author> C. N. Arnold. </author> <title> Performance evaluation of three automatic vectorizer packages. </title> <booktitle> Proceedings of the 1982 International Conference on Parallel Processing, </booktitle> <pages> pages 235-242, </pages> <year> 1982. </year>
Reference-contexts: The difference caused by loop-unrolling is significant if we want to use branch probabilities after traditional optimizations have been applied. However, many programmers unroll loops by hand and other programmers use source-to-source restructuring tools, such as KAP [16] or VAST <ref> [2] </ref>. The differences evinced by these applications may render the fixed ordering of heuristics ineffective for some programs. 4 Evidence-based Branch Prediction In this section, we propose a general framework for program-based prediction. Our method, ESP, is generally described as follows.
Reference: [3] <author> Vasanth Balasundaram, Geoffrey Fox, Ken Kennedy, and Ulrich Kremer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Third ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, </booktitle> <pages> pages 213-223, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: There is little other work in compiler optimization that has taken this approach. We summarize the work we are aware of here. In <ref> [3] </ref>, Balasundaram et al. address a somewhat different program-based estimation problem. The authors wanted to make compile-time decisions about data partitioning across a parallel computer. They report on the idea of using profile data to train an estimator.
Reference: [4] <author> Thomas Ball and James R. Larus. </author> <title> Branch prediction for free. </title> <booktitle> In Proceedings of the SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 300-313, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware [6, 28] while others involve software <ref> [4, 7, 13] </ref>. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler. <p> Some of these techniques use heuristics based on local knowledge that can be encoded in the architecture [18, 23]. Other techniques rely on applying heuristics based on less local program structure in an effort to predict branch behavior <ref> [4] </ref>. In [15], Hank et al. showed that these program-based heuristics can be used to accurately guide profile-based compiler optimizations achieving performance improvements close to what is achieved if real profiles were used. <p> To facilitate program-based methods for branch prediction, some modern architectures provide a branch-likely bit in each branch instruction [1]. In these architectures, compilers can employ either profile-based [13] or program-based techniques to determine what branches are likely to be taken. In recent work, Ball and Larus <ref> [4] </ref> showed that applying a number of simple program-based heuristics can significantly improve the branch prediction miss rate over BTFNT on tests based on the conditional branch operation. A complete summary of the Ball and Larus heuristics is given in Table 1 (as described in [27]). <p> First, an important question is which heuristics should be used. In their paper, they describe seven heuristics that they considered successful, but also noted that We tried many heuristics that were unsuccessful. <ref> [4] </ref> A second issue that arises with heuristic methods is how to decide what to do when more than one heuristic applies to a given branch. This problem has existed in the artificial intelligence community for many years and is commonly known as the evidence combination problem. <p> The probabilities that Wu and Larus use are taken directly from the paper of Ball and Larus <ref> [4] </ref>. We refer to a DSHC algorithm based on this data as DSHC (B&L). Because the goal of Wu and Larus was to perform program-based profile estimation, they give no results about how the DSHC method works for program-based branch prediction. <p> In addition, our results show that this general approach of knowledge-based training can be used to enhance a wide class of optimizations based on program behavior estimation. 7 3 Problems with Apriori Program Estimation In the paper by Ball and Larus <ref> [4] </ref>, a number of prediction heuristics were described. These heuristics were the foundation for the prediction scheme in both the study by Ball and Larus and the study by Wu and Larus. In the study by Wu and Larus, the values given in [4] were used for the Dempster-Shafer combination method, <p> In the paper by Ball and Larus <ref> [4] </ref>, a number of prediction heuristics were described. These heuristics were the foundation for the prediction scheme in both the study by Ball and Larus and the study by Wu and Larus. In the study by Wu and Larus, the values given in [4] were used for the Dempster-Shafer combination method, even though the study by Wu and Larus used a different architecture, compiler and run-time system. In this section, we show that the apriori heuristics described in [4] are sensitive to differences in architecture, compiler, run-time system and selection of programs. <p> In the study by Wu and Larus, the values given in <ref> [4] </ref> were used for the Dempster-Shafer combination method, even though the study by Wu and Larus used a different architecture, compiler and run-time system. In this section, we show that the apriori heuristics described in [4] are sensitive to differences in architecture, compiler, run-time system and selection of programs. This sensitivity implies that it is important to develop automatic techniques for branch estimation, and an understanding of the sensitivity of those automatic techniques. <p> This sensitivity implies that it is important to develop automatic techniques for branch estimation, and an understanding of the sensitivity of those automatic techniques. We use the CFG, dominator, post-dominator and loop information to implement the same heuristics used in <ref> [4] </ref>, summarized in Table 1. Our implementation results for these heuristics are shown in Table 2. This table shows detailed information about how the branch heuristics performed for each program. Some of the programs in our suite were also used in the earlier study by Ball [4], and the values in <p> same heuristics used in <ref> [4] </ref>, summarized in Table 1. Our implementation results for these heuristics are shown in Table 2. This table shows detailed information about how the branch heuristics performed for each program. Some of the programs in our suite were also used in the earlier study by Ball [4], and the values in parenthesis show the equivalent metrics recorded in that study. In general, the values are quite similar, but there are some small differences that we believe arise from different run-time libraries. <p> For example, the Alpha has a conditional move that avoids the need for many short conditional branches, reducing the number of conditional branches that are executed. Table 2 further demonstrates that our implementation of the heuristics listed in <ref> [4] </ref> appear to be correctly implemented. <p> Clearly, determining this information at compile time would simplify the analysis, since more program information would be available. Both Ball and Larus <ref> [4] </ref> and our study used binary instrumentation, so we felt that other 11 factors must also contribute to the prediction differences. <p> Using the control flow graph, we computed the dominator and post-dominator trees. Following this, we determined the natural loop headers and applied the same definition of natural loops used by Ball and Larus to determine the loop bodies <ref> [4] </ref>. As the instrumentation program runs, it can also add procedure calls to the executable that allow information about the executing program to be collected. <p> We did the same for Fortran programs feeding into the neural net and decision tree the feature sets for 19 of the 20 programs in order to predict branches for the 20th program. 26 6 Results We now compare the prediction accuracy of a priori heuristic combination (APHC) branch prediction <ref> [4] </ref>, the Dempster-Shafer heuristic combination (DSHC) proposed by Wu and Larus [27], and our ESP techniques. <p> In implementing DSHC, we use both the original prediction rates specified in <ref> [4] </ref>, DSHC (B&L), and the prediction rates produced by our implementation, DSHC (Ours). Later, we compare the similarity between these two sets of prediction heuristics as seen in Table 3.
Reference: [5] <author> M. Berry. </author> <title> The Perfect Club Benchmarks: Effective performance evaluation of supercomputers. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: During our study, we instrumented the programs from the SPEC92 benchmark suite and other programs, including many from the Perfect Club <ref> [5] </ref> suite. We used ATOM [25] to instrument the programs. Due to the structure of ATOM, we did not need to record traces and could trace very long-running programs. The programs were compiled on a DEC 3000-400 using the Alpha AXP-21064 processor using either the DEC C or Fortran compilers.
Reference: [6] <author> Brad Calder and Dirk Grunwald. </author> <title> Fast & accurate instruction fetch and branch prediction. </title> <booktitle> In 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-11. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware <ref> [6, 28] </ref> while others involve software [4, 7, 13]. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler.
Reference: [7] <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing branch costs via branch alignment. </title> <booktitle> In Six International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 242-251. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware [6, 28] while others involve software <ref> [4, 7, 13] </ref>. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler. <p> Most of the previous work in program-based branch prediction uses the final program binary to determine the outcome of branches; following those decisions, the program can be reorganized <ref> [19, 7] </ref> to take advantage of the program-based branch prediction information. 2.1 Program-Based Branch Prediction Methods One of the simplest program-based methods for branch prediction is called backward-taken/forward-not-taken (BTFNT). This technique relies on the heuristic that backward branches are usually loop branches, and as such are likely to be taken.
Reference: [8] <author> Brad Calder, Dirk Grunwald, and Amitabh Srivastava. </author> <title> The predictability of branches in libraries. </title> <booktitle> In 28th International Symposium on Microarchitecture, </booktitle> <pages> pages 24-34, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: This difference is largest for the branches occurring in Fortran library routines. This decrease in miss rate for the library branches most likely comes from the library branches having very similar behavior between different programs. In a related study <ref> [8] </ref>, we found this to be the case.
Reference: [9] <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Quantifying behavioral differences between C and C++ programs. </title> <journal> Journal of Programming Languages, </journal> <volume> 2(4), </volume> <year> 1994. </year> <note> Also available as University of Colorado Technical Report CU-CS-698-94. </note>
Reference-contexts: For example, the mispredict penalty is 4 cycles on the Digital Alpha AXP 21064 processor and 5 cycles in the Alpha AXP 21164 processor. In previous studies, we found that conditional branches in C programs were executed approximately every 8 instructions on the Alpha architecture <ref> [9] </ref>. Current wide-issue architectures can execute four or more instructions per cycle. As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important.
Reference: [10] <author> P. P. Chang and W. W. Hwu. </author> <title> Profile-guided automatic inline expansion for C programs. </title> <journal> Software Practice and Experience, </journal> <volume> 22(5) </volume> <pages> 349-376, </pages> <year> 1992. </year> <month> 42 </month>
Reference-contexts: Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling [15, 14, 17] and other profile-based optimizations <ref> [10, 11] </ref>. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [11] <author> P. P. Chang, S. A. Mahlke, and W. W. Hwu. </author> <title> Using profile information to assist classic compiler code optimizations. </title> <journal> Software Practice and Experience, </journal> <volume> 21(12) </volume> <pages> 1301-1321, </pages> <year> 1991. </year>
Reference-contexts: Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling [15, 14, 17] and other profile-based optimizations <ref> [10, 11] </ref>. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [12] <author> A. P. Dempster. </author> <title> A generalization of bayesian inference. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 30 </volume> <pages> 205-247, </pages> <year> 1968. </year>
Reference-contexts: With branch probabilities, the goal is to determine the numeric probability that a branch is taken or not taken. Wu and Larus abandoned the simplistic evidence combination function of APHC in favor of an evidence combination function borrowed from Dempster-Shafer theory <ref> [12, 22] </ref>. We call this form of evidence combination Dempster-Shafer Heuristic Combination (DSHC). By making some fairly strong assumptions concerning the independence of different attributes, the Dempster-Shafer evidence combination function can produce an estimate of the branch probability from any number of sources of evidence. <p> indicates that a branch is likely to be taken with probability X%, while another says it is likely to be taken with probability Y%, then DSHC allows these two probabilities to be combined. 6 Unless it is shown that the data is truly independent, and that other restrictions described in <ref> [12, 22] </ref> are observed, the Dempster-Shafer mechanism may not provide any useful information. The probabilities that Wu and Larus use are taken directly from the paper of Ball and Larus [4]. We refer to a DSHC algorithm based on this data as DSHC (B&L).
Reference: [13] <author> J. A. Fisher and S. M. Freudenberger. </author> <title> Predicting conditional branch directions from previous runs of a program. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-V), </booktitle> <pages> pages 85-95, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware [6, 28] while others involve software <ref> [4, 7, 13] </ref>. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler. <p> Profile-based methods use program profiles to determine the frequency that branch paths are executed. Fisher and Freudenberger showed that profile-based branch prediction can be extremely successful at predicting the future behavior of branches <ref> [13] </ref>. The main drawback of profile-based methods is that additional work is required on the part of the programmer to generate the program profiles. Program-based branch prediction methods attempt to predict branch behavior 2 in the absence of profile information and are based only on a program's structure. <p> To facilitate program-based methods for branch prediction, some modern architectures provide a branch-likely bit in each branch instruction [1]. In these architectures, compilers can employ either profile-based <ref> [13] </ref> or program-based techniques to determine what branches are likely to be taken. In recent work, Ball and Larus [4] showed that applying a number of simple program-based heuristics can significantly improve the branch prediction miss rate over BTFNT on tests based on the conditional branch operation.
Reference: [14] <author> Joseph A. Fisher. </author> <title> Trace scheduling: A technique for global microcode compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(7):478-490, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: Branch prediction is the process of correctly predicting whether branches will be taken or not before they are actually executed. Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling <ref> [15, 14, 17] </ref> and other profile-based optimizations [10, 11]. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [15] <author> Richard Hank, Scott Mahlke, Roger Bringmann, John Gyllenhaal, and Wen mei Hwu. </author> <title> Superblock formation using static program analysis. </title> <booktitle> In 26th International Symposium on Microarchitecture, </booktitle> <pages> pages 247-256. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: Branch prediction is the process of correctly predicting whether branches will be taken or not before they are actually executed. Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling <ref> [15, 14, 17] </ref> and other profile-based optimizations [10, 11]. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long. <p> Some of these techniques use heuristics based on local knowledge that can be encoded in the architecture [18, 23]. Other techniques rely on applying heuristics based on less local program structure in an effort to predict branch behavior [4]. In <ref> [15] </ref>, Hank et al. showed that these program-based heuristics can be used to accurately guide profile-based compiler optimizations achieving performance improvements close to what is achieved if real profiles were used. In this paper, we describe a new approach to program-based branch prediction that does not rely on such heuristics. <p> In this paper, we investigate methods for static program-based branch prediction. Such methods are important since they can be used to estimate branch behavior at compile-time when performing compiler optimizations <ref> [15] </ref>. We propose a new, general approach to program-based behavior estimation called evidence-based static prediction (ESP). We then show how our general approach can be applied specifically to the problem of program-based branch prediction.
Reference: [16] <author> C. Huson, T. Macke, J. Davies, M. Wolfe, and B. Leasure. </author> <title> The kap/205: An advanced source-to-source vectorizer for the Cyber 205 supercomputer. </title> <booktitle> In Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 827-835, </pages> <year> 1986. </year>
Reference-contexts: The difference caused by loop-unrolling is significant if we want to use branch probabilities after traditional optimizations have been applied. However, many programmers unroll loops by hand and other programmers use source-to-source restructuring tools, such as KAP <ref> [16] </ref> or VAST [2]. The differences evinced by these applications may render the fixed ordering of heuristics ineffective for some programs. 4 Evidence-based Branch Prediction In this section, we propose a general framework for program-based prediction. Our method, ESP, is generally described as follows.
Reference: [17] <author> Wen-mei W. Hwu and Pohua P. Chang. </author> <title> Achieving high instruction cache performance with an optimizing compiler. </title> <booktitle> In 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 242-251. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Branch prediction is the process of correctly predicting whether branches will be taken or not before they are actually executed. Branch prediction is important, both for computer architectures and compilers. Compilers rely on branch prediction and execution estimation to implement optimizations such as trace-scheduling <ref> [15, 14, 17] </ref> and other profile-based optimizations [10, 11]. Wide-issue computer architectures rely on predictable control flow, and failure to correctly predict a branch results in delays for fetching and decoding the instructions along the incorrect path of execution. The penalty for a mispredicted branch may be several cycles long.
Reference: [18] <author> Scott McFarling and John Hennessy. </author> <title> Reducing the cost of branches. </title> <booktitle> In 13th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 396-403. </pages> <institution> Association for Computing Machinery, </institution> <year> 1986. </year>
Reference-contexts: Program-based branch prediction methods attempt to predict branch behavior 2 in the absence of profile information and are based only on a program's structure. Some of these techniques use heuristics based on local knowledge that can be encoded in the architecture <ref> [18, 23] </ref>. Other techniques rely on applying heuristics based on less local program structure in an effort to predict branch behavior [4].
Reference: [19] <author> Karl Pettis and Robert C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> In Proceedings of the SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 16-27. </pages> <publisher> ACM, ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Most of the previous work in program-based branch prediction uses the final program binary to determine the outcome of branches; following those decisions, the program can be reorganized <ref> [19, 7] </ref> to take advantage of the program-based branch prediction information. 2.1 Program-Based Branch Prediction Methods One of the simplest program-based methods for branch prediction is called backward-taken/forward-not-taken (BTFNT). This technique relies on the heuristic that backward branches are usually loop branches, and as such are likely to be taken.
Reference: [20] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: This direct interpretability was one of our primary motivations for investigating the use of decision trees. Fortunately, there are effective and efficient algorithms for learning decision trees directly from a corpus of data represented as feature vectors with assigned categories (See Quinlan <ref> [20] </ref> for a survey of such methods.) There are two key notions underlying all of these algorithms. The first is the notion that any diverse collection of objects can be assigned a value based on the heterogeneity of the collection. <p> The decision tree induction experiments reported here were performed using the well-studied, and widely distributed, C4.5 system <ref> [20] </ref>. The results reported here were achieved using C4.5's default training settings, along with its standard tree pruning mechanism. To be more specific, C4.5 requires a training set made up of individual feature vectors labeled with correct classifications and outputs a decision tree capable of classifying such vectors.
Reference: [21] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Parallel distributed processing: Explorations in the mi-crostructure of cognition. Volume I: Foundations, chapter Learning internal representations by error propagation, </title> <address> pages 318-362. </address> <publisher> MIT Press/Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <editor> D. E. Rumelhart and J. L. McClelland, </editor> <publisher> editors. </publisher>
Reference-contexts: These parameters are set by an algorithm known as back propagation <ref> [21] </ref>. This is a gradient descent procedure for adjusting the parameters such that performance of the network on a training corpus is optimized.
Reference: [22] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1976. </year>
Reference-contexts: With branch probabilities, the goal is to determine the numeric probability that a branch is taken or not taken. Wu and Larus abandoned the simplistic evidence combination function of APHC in favor of an evidence combination function borrowed from Dempster-Shafer theory <ref> [12, 22] </ref>. We call this form of evidence combination Dempster-Shafer Heuristic Combination (DSHC). By making some fairly strong assumptions concerning the independence of different attributes, the Dempster-Shafer evidence combination function can produce an estimate of the branch probability from any number of sources of evidence. <p> indicates that a branch is likely to be taken with probability X%, while another says it is likely to be taken with probability Y%, then DSHC allows these two probabilities to be combined. 6 Unless it is shown that the data is truly independent, and that other restrictions described in <ref> [12, 22] </ref> are observed, the Dempster-Shafer mechanism may not provide any useful information. The probabilities that Wu and Larus use are taken directly from the paper of Ball and Larus [4]. We refer to a DSHC algorithm based on this data as DSHC (B&L).
Reference: [23] <author> J. E. Smith. </author> <title> A study of branch prediction strategies. </title> <booktitle> In 8th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 135-148. </pages> <publisher> ACM, </publisher> <year> 1981. </year>
Reference-contexts: Program-based branch prediction methods attempt to predict branch behavior 2 in the absence of profile information and are based only on a program's structure. Some of these techniques use heuristics based on local knowledge that can be encoded in the architecture <ref> [18, 23] </ref>. Other techniques rely on applying heuristics based on less local program structure in an effort to predict branch behavior [4]. <p> First, because the technique generates predictions automatically, the predictions can be specialized based on specific languages, compilers, and computer architectures. Existing techniques rely on heuristics defined by compiler writers that are based on intuition and empirical studies (e.g., <ref> [23] </ref>) about common programming idioms. Second, given a large amount of static information about each branch, the technique automatically determines what parts of that information are useful. Thus, it does not rely on trial-and-error on the part of the compiler writer searching for good heuristics.
Reference: [24] <author> P. Smolensky, M. C. Mozer, and D. E. Rumelhart, </author> <title> editors. Mathematical perspectives on neural networks. </title> <publisher> Erlbaum, </publisher> <year> 1994. </year> <note> In press. </note>
Reference-contexts: This system should accurately predict not just for the programs in the corpus, but also for previously unseen programs. One way of doing such prediction is via a feedforward neural network <ref> [24] </ref>. A feedforward neural network maps a numerical input vector to a numerical output. Here, the input vector consists of the feature values in the static feature set, and the output is a scalar indicating whether the branch will be taken. units, depicted in the Figure by circles.
Reference: [25] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the SIGPLAN'94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 196-205. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: During our study, we instrumented the programs from the SPEC92 benchmark suite and other programs, including many from the Perfect Club [5] suite. We used ATOM <ref> [25] </ref> to instrument the programs. Due to the structure of ATOM, we did not need to record traces and could trace very long-running programs. The programs were compiled on a DEC 3000-400 using the Alpha AXP-21064 processor using either the DEC C or Fortran compilers.
Reference: [26] <author> Tim A. Wagner, Vance Maverick, Susan Graham, and Michael Harrison. </author> <title> Accurate static estimators for program optimization. </title> <booktitle> In Proceedings of the SIGPLAN'94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 85-96, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: One of the contributions of our paper is that we quantify the effectiveness of the DSHC method for branch prediction. As we show later, the DSHC method provides worse prediction than the simple APHC method. Wagner et al. <ref> [26] </ref> also used heuristics similar to those of Ball and Larus to perform program-based profile estimation. They also applied the heuristics in a fixed order.
Reference: [27] <author> Youfeng Wu and James R. Larus. </author> <title> Static branch frequency and program profile analysis. </title> <booktitle> In 27th International Symposium on Microarchitecture, </booktitle> <address> San Jose, Ca, </address> <month> November </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: A complete summary of the Ball and Larus heuristics is given in Table 1 (as described in <ref> [27] </ref>). Their heuristics use information about the branch opcode, operands, and characteristics of the branch successor blocks, and encode knowledge about common programming idioms. 5 Two questions arise when employing an approach like that taken by Ball and Larus. First, an important question is which heuristics should be used. <p> Using APHC, Ball and Larus report an average overall miss rate on the MIPS architecture of 20%; when their technique is applied to the DEC Alpha architecture, the prediction accuracy worsens, becoming 25%. In a related paper, Wu and Larus refined the APHC method of Ball and Larus <ref> [27] </ref>. In that paper, their goal was to determine branch probabilities instead of simple branch prediction. With branch prediction, the goal is to determine a single bit of information per branch (likely versus unlikely). <p> net and decision tree the feature sets for 19 of the 20 programs in order to predict branches for the 20th program. 26 6 Results We now compare the prediction accuracy of a priori heuristic combination (APHC) branch prediction [4], the Dempster-Shafer heuristic combination (DSHC) proposed by Wu and Larus <ref> [27] </ref>, and our ESP techniques. Following this, we show that the APHC and DSHC techniques are sensitive to differences in system architecture and compilers. 6.1 Comparison: APHC, DSHC and ESP Table 7 shows the branch misprediction rate for the methods we implemented. <p> Table 7 reveals several interesting points. First, the overall average shows that the Dempster-Shafer method performs no better than the fixed order of heuristics. Wu and Larus <ref> [27] </ref> said When more than one heuristic applies to a branch, combining the probabilities estimated by the applicable heuristics should produce an overall branch probability that is more accurate than the individual probabilities. 27 Branch Prediction Miss Rates Program BTFNT APHC DSHC DSHC ESP ESP ESP Perfect (B&L's) (B&L's) (Ours) NN <p> In 6 cases (flex, sort, mdljsp2, CSS, NAS, TFS), the Dempster-Shafer's miss rate is more than 5% higher (worse) than the simple APHC ordering, while the APHC ordering method is 5% worse in only three cases (wdiff, SDS, LWS). The intuition in <ref> [27] </ref> was correct; however, the Dempster-Shafer theory does not combine the evidence well enough to improve branch prediction. The ESP techniques perform significantly better than the Dempster-Shafer and the APHC methods for most of the programs.
Reference: [28] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 257-266, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <journal> ACM. </journal> <volume> 43 </volume>
Reference-contexts: As a result, such architectures are likely to execute branch instructions every two cycles or less and effective branch prediction on such architectures is extremely important. Many approaches have been taken to branch prediction, some of which involve hardware <ref> [6, 28] </ref> while others involve software [4, 7, 13]. Software methods usually work in tandem with hardware methods. For example, some architectures have a likely bit that can be set by a compiler if a branch is determined to be likely taken by a compiler.
References-found: 28

