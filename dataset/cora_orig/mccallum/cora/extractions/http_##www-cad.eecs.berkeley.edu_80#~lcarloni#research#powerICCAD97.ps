URL: http://www-cad.eecs.berkeley.edu:80/~lcarloni/research/powerICCAD97.ps
Refering-URL: http://www-cad.eecs.berkeley.edu:80/~lcarloni/research/papersIndex.html
Root-URL: 
Email: flcarloni,albertog@ic.eecs.berkeley.edu  fmcgeer,saldanhag@cadence.com  
Title: Trace Driven Logic Synthesis Application to Power Minimization  
Author: Luca P. Carloni Patrick C. McGeer Alexander Saldanha Alberto L. Sangiovanni-Vincentelli 
Address: Berkeley, CA 94720  Berkeley, CA 94704-1103  
Affiliation: University of California at Berkeley  Cadence Berkeley Laboratories  
Abstract: A trace driven methodology for logic synthesis and optimization is proposed. Given a logic description of a digital circuit C and an expected trace of input vectors T , an implementation of C that optimizes a cost function under application of T is derived. This approach is effective in capturing and utilizing the correlations that exist between input signals on an application specific design. The idea is novel since it propose synthesis and optimization at the logic level where the goal is to optimize the average case rather than the worst case for a chosen cost metric. This paper focuses on the development of algorithms for trace driven optimization to minimize the switching power in multi-level networks. The average net power reduction (internal plus I/O power) obtained on a set of benchmark FSMs is 14%, while the average reduction in internal power is 25%. We also demonstrate that the I/O transition activity provides an upper bound on the power reduction that can be achieved by combinational logic synthesis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. K. Brayton, G. D. Hachtel, C. T. McMullen, and A. L. Sangiovanni-Vincentelli. </author> <title> Logic Minimization Algorithms for VLSI Synthesis. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1984. </year>
Reference-contexts: A minimum cover is denoted Q ? T . Following <ref> [1, 13] </ref>, a minimum-weight unate covering problem (UCP) is solved using W T (q) as the cost of each implicant q. In the case of trace driven two-level power minimization a minimum cover may contain an implicant which is not a prime. <p> Even extending the classical branch-and-bound based covering algorithm with lower-bound computation techniques recently presented in [2] do not provide much improvement. As an alternative, we have adapted the two-level heuristic minimization program espresso <ref> [1] </ref> to perform trace driven two-level minimization.
Reference: [2] <author> O. Coudert. </author> <title> On Solving Covering Problems. </title> <booktitle> In Proc. of the Design Automation Conf., </booktitle> <pages> pages 197-202, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Although the approach of enumerating only candidate implicants and early discarding of dominated implicants performs efficiently in practice, the final step of finding a minimum cost unate covering problem is often a bottleneck. Even extending the classical branch-and-bound based covering algorithm with lower-bound computation techniques recently presented in <ref> [2] </ref> do not provide much improvement. As an alternative, we have adapted the two-level heuristic minimization program espresso [1] to perform trace driven two-level minimization.
Reference: [3] <author> O. Coudert and R. Haddad. </author> <title> Integrated Resynthesis for Low Power. </title> <booktitle> In ISLPED Digest of Technical Papers, </booktitle> <pages> pages 169-174, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: The idea has been applied to the minimization of the switching activity in the combinational logic portion of finite state machines. In this paper we have focussed on technology independent optimizations. The extension to technology mapping, based on applying trace driven optimization to the methods proposed in <ref> [3] </ref> remains for the future. Our results have also indicated that additional gains can only be realized by changing the sequential behavior of the FSMs to impact the I/O switching activity. The application of encoding and re-encoding techniques [4] to reduce I/O activity is a promising avenue for exploration.
Reference: [4] <author> G. D. Hachel, M. Hermida, A. Pardo, M. Poncino, and F. Somenzi. </author> <title> Re-Encoding Sequential Circuits to Reduce Power Dissipation. </title> <booktitle> In Proceedings of the Design Automation Conference, </booktitle> <pages> pages 70-73, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Our results have also indicated that additional gains can only be realized by changing the sequential behavior of the FSMs to impact the I/O switching activity. The application of encoding and re-encoding techniques <ref> [4] </ref> to reduce I/O activity is a promising avenue for exploration. Acknowledgments The authors would like to thank Alberto Ferrari and Tiziano Villa for their support and useful discussions.
Reference: [5] <author> S. Iman and M. Pedram. </author> <title> Logic Extraction and Factorization for Low Power. </title> <booktitle> In Proceedings of the Design Automation Conference, </booktitle> <pages> pages 248-253, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: A potential weakness of this approach is that the initial factored forms are not altered, leading to sub-optimum extractions. In <ref> [5] </ref> an alternate approach is proposed to solve this problem: the power values of the common sub-expressions are computed using the power cost of a node represented using a sum-of-products representation. <p> This operation is generally time consuming and is sped-up by using an approximation for the signal probabilities on the immediate fanin of a node <ref> [5] </ref>. Our technique is similar to the previous approaches in that a value is associated with each sub-expression to denote the power saving obtained if the logic extraction is performed. On the other hand, it differs from the previous approaches in three aspects.

Reference: [7] <author> R. Marculescu, D. Marculescu, and M. Pedram. </author> <title> Efficient Power Estimation for Higly Correlated Input Streams. </title> <booktitle> In Proceedings of the Design Automation Conference, </booktitle> <pages> pages 628-634, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The main reason behind this conclusion is the inaccuracy of the estimated power using probabilistic or statistical techniques. Specifically the correlations between the values on input signals within a vector as well as across vectors cannot be captured by existing probabilistic and statistical methods <ref> [9, 7] </ref>. Our approach extends the use of the actual vectors employed in power estimation to logic synthesis and optimization as well, thus narrowing the discrepancy in estimated power between analysis and synthesis tools while providing room for reduction in the power dissipation due to trace driven optimization.
Reference: [8] <author> R. Murgai, R. K. Brayton, and A. L. Sangiovanni-Vincentelli. </author> <title> Decomposition for Minimum Transition Activity. </title> <booktitle> In Proceedings of the Low Power Workshop - Napa Valley, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: For our purposes the decomposition of a complex gate is also used to guide the estimation of the internal switching activity during the logic extraction step (Section 4.3). Murgai, et al. <ref> [8] </ref> analyze the problem of decomposing a large-fanin gate for minimum switching activity using input transition probabilities (assuming independence between the input signals) and demonstrate that it is equivalent to the problem of finding a minimum weighted binary tree, where the weight of each node is its 1-controllability.
Reference: [9] <author> F. N. Najm. </author> <title> A Survey of Power Estimation Techniques in VLSI Circuits. </title> <journal> IEEE Transactions on VLSI Systems, </journal> <volume> 2 </volume> <pages> 446-455, </pages> <year> 1994. </year>
Reference-contexts: The main reason behind this conclusion is the inaccuracy of the estimated power using probabilistic or statistical techniques. Specifically the correlations between the values on input signals within a vector as well as across vectors cannot be captured by existing probabilistic and statistical methods <ref> [9, 7] </ref>. Our approach extends the use of the actual vectors employed in power estimation to logic synthesis and optimization as well, thus narrowing the discrepancy in estimated power between analysis and synthesis tools while providing room for reduction in the power dissipation due to trace driven optimization.
Reference: [10] <author> F. N. Najm. </author> <title> Feedback, Correlation, and Delay Concerns in the Power Estimation of VLSI Circuits. </title> <booktitle> In Proceedings of the 32 th Design Automation Conference, </booktitle> <pages> pages 612-617, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The first implementation generates 41 switches while the second yields 37 switches under trace T 1 . On the trace T 2 the first circuit generates 30 switches while the second yields 35. Now, assuming the input signals are uncorrelated, the transition probabilities <ref> [10] </ref> for both traces are identical, i.e., p (x 1 ) = 0:5, p (x 2 ) = 1:0, p (x 3 ) = 1:0. Thus, previous approaches described by Najm [10] or Iman and Pe-dram [6] using signal and/or transition probabilities cannot distinguish between the two traces. <p> Now, assuming the input signals are uncorrelated, the transition probabilities <ref> [10] </ref> for both traces are identical, i.e., p (x 1 ) = 0:5, p (x 2 ) = 1:0, p (x 3 ) = 1:0. Thus, previous approaches described by Najm [10] or Iman and Pe-dram [6] using signal and/or transition probabilities cannot distinguish between the two traces. Hence, the same implementation is selected for both traces. Our approach, in contrast, differentiates between the two traces and always selects the desirable implementation.
Reference: [11] <author> J. Rajski and J. Vasudevamurthy. </author> <title> The Testability-Preserving Concurrent Decomposition and Factorization of Boolean Espression. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 11 </volume> <pages> 778-793, </pages> <year> 1992. </year>
Reference-contexts: Instead, each node is decomposed on the fly into gates with fanin two, by using the procedure outlined in Section 4.2. This represents a structure that is better correlated to the final network after technology mapping. Finally, our algorithm derives directly from the algorithm of Rajski and Vasudevamurthy <ref> [11] </ref> which is widely considered the most efficient method for Boolean extraction. The basic objects used in extraction are single-cube divisors having exactly two literals, double cube divisors and their complements. <p> The complete definitions of double-cube divisor, set and subset of double-cube divisors, base of a double-cube divisor, single-cube divisor and its coincidence are found in <ref> [11] </ref>. We illustrate some of the terms for the benefit of the reader. <p> The greedy algorithm we propose is an extension of the Rajski and Vasudevamurthy extraction algorithm <ref> [11] </ref>, modified to use cost values denoting the power dissipation due to single-cube and double-cube divisors. <p> 2 . f 1 = x 1 x 4 x 5 + x 1 x 6 + x 2 x 3 x 4 x 5 + x 2 x 3 x 6 + x 7 Performing extraction using the area minimal option described in the algorithm of Rajski and Vasudevamurthy <ref> [11] </ref>, followed by decomposition into 2-input AN D and OR gates yields N 1 in Figure 3. Now, suppose that we want to perform the best extraction for low power on N with respect to the input trace T specified in the same Figure.
Reference: [12] <author> K. Roy and S.C. Prasad. </author> <title> Circuit Activity Based Logic Synthesis for Low Power Reliable Operations. </title> <journal> IEEE Transactions on VLSI Systems, </journal> <volume> 1 </volume> <pages> 503-513, </pages> <year> 1993. </year>
Reference-contexts: The unmodified Huffman algorithm yields a decomposition with 11 switches. 4.3 Trace driven extraction The problem of logic extraction for low power has been previously addressed in two ways. Roy and Prasad <ref> [12] </ref> present a kernel extraction algorithm to reduce power dissipation by common sub-expression extraction guided by power values for nodes computed on the given factored form expressions for the nodes. A potential weakness of this approach is that the initial factored forms are not altered, leading to sub-optimum extractions.
Reference: [13] <author> Richard L. Rudell. </author> <title> Logic Synthesis for VLSI Design. </title> <type> PhD thesis, </type> <institution> University of California Berkeley, Electronics Research Laboratory, College of Engineering, University of California, Berkeley, </institution> <address> CA 94720, </address> <month> April </month> <year> 1989. </year> <note> Memorandum No. UCB/ERL M89/49. </note>
Reference-contexts: A minimum cover is denoted Q ? T . Following <ref> [1, 13] </ref>, a minimum-weight unate covering problem (UCP) is solved using W T (q) as the cost of each implicant q. In the case of trace driven two-level power minimization a minimum cover may contain an implicant which is not a prime. <p> In [5] an alternate approach is proposed to solve this problem: the power values of the common sub-expressions are computed using the power cost of a node represented using a sum-of-products representation. Since this conforms to the underlying assumptions for traditional algebraic extraction and decomposition algorithms <ref> [13, 17] </ref>, the authors can rely on these algorithms to extract the set of all single cube intersections and kernel intersections among the network nodes in order to choose the sub-expression having the maximum power reduction.
Reference: [14] <author> C-Y. Tsui, R. Marculescu, D. Marculescu, and M. Pedram. </author> <title> Improving the Efficiency of Power Simulators by Input Vector Compaction. </title> <booktitle> In Proceedings of the Design Automation Conference, </booktitle> <pages> pages 165-168, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Most of these simulations are performed in a pre-processing step and the running time can be improved by employing state-of-the-art logic simulation techniques. Nonetheless, trace driven synthesis can be performed with traces which are produced by vector compaction tools: for example, Tsui et al. <ref> [14] </ref> propose a technique with a compaction ratio of 100X while preserving most correlations. 2 Trace driven logic optimization problem The problem of trace driven logic optimization for minimum switching activity is: Given a logic circuit represented as a set of Boolean functions and a sequence of input vectors, synthesize a
Reference: [15] <author> C-Y. Tsui, M. Pedram, and A. M. Despain. </author> <title> Efficient Estimation of Dynamic Power Consumption under a Real Delay Model. </title> <booktitle> In Proceedings of the International Conference on Computer-Aided Design, </booktitle> <pages> pages 224-228, </pages> <month> Nov </month> <year> 1993. </year>
Reference-contexts: Past approaches have suggested techniques to account for the effects of correlated inputs. One approach to approximating transition probabilities in the presence of correlated inputs is suggested in <ref> [15] </ref>. Another approach relevant to FSMs is the derivation of the steady state probabilities (e.g. using the Chapman-Kolmogorov equations [16]).
Reference: [16] <author> C-Y. Tsui, M. Pedram, and A. M. Despain. </author> <title> Exact and Approximate Methods for Calculating Signal and Transition Probabilities in FSMs. </title> <booktitle> In Proceedings of the 29 th Design Automation Conference, </booktitle> <pages> pages 18-23, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Past approaches have suggested techniques to account for the effects of correlated inputs. One approach to approximating transition probabilities in the presence of correlated inputs is suggested in [15]. Another approach relevant to FSMs is the derivation of the steady state probabilities (e.g. using the Chapman-Kolmogorov equations <ref> [16] </ref>). However, capturing accurate transition probabilities on the inputs of a combinational network (even augmented with correlation values between pairs of inputs) still does not easily allow the derivation of accurate transition probabilities (and correlations between signals) on internal nodes of the network.
Reference: [17] <author> A. Wang. </author> <title> Algorithms for Multi-Level Logic Optimization. </title> <type> PhD thesis, </type> <institution> University of California Berkeley, Electronics Research Laboratory, College of Engineering, University of California, Berkeley, </institution> <address> CA 94720, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: We simply adopt the logic simplification strategy already existing for area minimization, modified to use the procedure described for heuristic power minimization; alternatives to this naive approach remain an interesting problem for future work. To attempt to climb out of a local minimum, a trace-driven elimination command <ref> [17] </ref> has been developed using as the figure of merit the change in switching activity under the given trace. <p> In [5] an alternate approach is proposed to solve this problem: the power values of the common sub-expressions are computed using the power cost of a node represented using a sum-of-products representation. Since this conforms to the underlying assumptions for traditional algebraic extraction and decomposition algorithms <ref> [13, 17] </ref>, the authors can rely on these algorithms to extract the set of all single cube intersections and kernel intersections among the network nodes in order to choose the sub-expression having the maximum power reduction.
References-found: 16

