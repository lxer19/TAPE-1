URL: http://www.cs.colorado.edu/~suvas/papers/LCPC96.ps
Refering-URL: http://www.cs.colorado.edu/~suvas/Papers.html
Root-URL: http://www.cs.colorado.edu
Email: fsuvas,grunwaldg@cs.colorado.edu  
Title: Dependence Driven Execution for Data Parallelism  
Author: Suvas Vajracharya Dirk Grunwald 
Address: Campus Box 430 Boulder, Colorado 80309  
Affiliation: Department of Computer Science University of Colorado  
Abstract: This paper proposes an efficient run-time system to schedule general nested loops on multiprocessors. The work extends existing one-dimensional loop scheduling strategies such as static scheduling, affinity scheduling and various dynamic scheduling methods. The extensions are twofold. First, multiple independent loops as found in different branches of parbegin/parend constructs can be scheduled simultaneously. Secondly, multidimensional loops with dependencies and conditions can be aggressively scheduled. The ability to schedule multidimensional loops with dependencies is made possible by providing a dependence vector as an input to the scheduler. Based on this application-specific input, a continuation-passing run-time system using non-blocking threads efficiently orchestrates the parallelism on shared memory MIMD and DSM mul-ticomputers. The run-time system uses a dependence-driven execution which is similar to data-driven and message-driven executions in that it is asynchronous. This asynchrony allows high degree of parallelism. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Allen, M. Burke, J. Ferrante, W. Hsieh, and V. Sarkar. </author> <title> A framework for determining useful parallelism. </title> <booktitle> In ACM Int. Conf. Supercomputing, </booktitle> <pages> pages 207-215, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: In a parallel program, three types of loops may be distinguished: doser, doall <ref> [1] </ref> and doacross [10]. Doser loops must be executed serially while iterations in a doall loop are completely independent and therefore can run in any order or in parallel. In a doacross loop, values assigned in one iterations are used in another iteration and therefore only partial parallelism is possible.
Reference: [2] <author> J.R. Allen and K. Kennedy. </author> <title> Automatic loop interchange. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 19(6) </volume> <pages> 233-246, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: This transformation then allows the application of the methods described in the previous section. A hybrid loop consisting of doser and doall can be transformed such that all doalls are nested within the doser loop by loop interchange <ref> [2, 33] </ref>. Other compiler transformations attempt to organize loops such that the loop with maximum parallelism is the outer loop. Compiler transformations such as loop normalization and loop fusion can also be used to collapse a multi-dimensional iteration space to a single dimensional iteration space.
Reference: [3] <author> Vasanth Balasundaram. </author> <title> A mechanism for keeping useful internal information in parallel programming tools: The data access descriptor. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 154-170, </pages> <year> 1990. </year> <note> size 1024x1024 </note>
Reference-contexts: To achieve this, it is necessary to describe regions of computations (such as the non-intersecting regions) using data descriptors. In this paper, data descriptors consist of simple rectangles although more sophisticated and exact methods available from compiler literature <ref> [3, 8, 4] </ref> could be used. DUDE is a run-time system that can take advantage of such patterns recognized by the compiler.
Reference: [4] <author> Vasanth Balasundaram and Ken Kennedy. </author> <title> A technique for summarizing data access and its use in parallelism enhancing transformations. </title> <booktitle> In Proceedings of teh ACM SIGPLAN Symposium on Compiler Construction, </booktitle> <pages> pages 41-53, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: To achieve this, it is necessary to describe regions of computations (such as the non-intersecting regions) using data descriptors. In this paper, data descriptors consist of simple rectangles although more sophisticated and exact methods available from compiler literature <ref> [3, 8, 4] </ref> could be used. DUDE is a run-time system that can take advantage of such patterns recognized by the compiler.
Reference: [5] <author> U. Banerjee. </author> <title> An introduction to a formal theory of dependence analysis. </title> <journal> J. Supercomp., </journal> <volume> 2(2) </volume> <pages> 133-149, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: General loop scheduling is possible if the programmer or the compiler passes application-specific dependencies to the scheduler. Parallelizing compilers can make some of this information available in the form of dependence vectors <ref> [33, 5] </ref>. By passing this information to the run-time layer, a dependence-driven run-time system can exploit application-specific parallelism in a general, portable manner. The compiler describes the parallelism declaratively in the form of dependence vectors. All the procedural details of synchronization and scheduling are handled by the run-time system. <p> Each vector in the set represents an arc from the source of the to the target of the dependency. How these vectors are computed is beyond the scope of this paper but a good description can be found in [33] <ref> [5] </ref>. Line 15 specifies the dependencs for stencil computation. A compiler can compute this vector by taking the difference between the iteration vectors of the source and target iterations. Data Parallel Operation Data parallel operation and dependence satisfaction is handled by the runtime system.
Reference: [6] <author> B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> PRESTO: A System for Object-Oriented Parallel Programming. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 713-732, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Doall loops with large number of iterations are divided into pieces (usually two) and the piece are run in a interleaved fashion. 3.2 Data-driven Runtime Systems The Chores system [11] is implemented on top of Presto <ref> [6] </ref> and runs on the Sequent Symmetry. A per-processor worker (a user-level thread) grab chunks of work from a central queue using the guided self-scheduling method.
Reference: [7] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kuszmaul, Charles E. Leiserson, Keith H. Randall, and Yuli Zhou. Cilk: </author> <title> An efficient multithreaded runtime system. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Barbara, California, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Programmers need to lock the user-defined data structures to atomically decrement the counters that keep track of the number of unsatisfied precedence arcs. The add-atom () library call provides the means to schedule new enabled work. Dynamic Chores has the same benefits of flexibility and generality as Cilk <ref> [7] </ref>, Mentat [17, 16] and Tam [9], but also suffers from the problem of using a low-level abstractions. 2. Indexed Chores: Indexed chores are significantly easier to use than dynamic chores since the users need only provide the body of the loop, the range of loop iterations, and a de-pendencespecification.
Reference: [8] <author> David Callahan. </author> <title> A Global Approach to Detection of Parallelism. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> April </month> <year> 1987. </year>
Reference-contexts: To achieve this, it is necessary to describe regions of computations (such as the non-intersecting regions) using data descriptors. In this paper, data descriptors consist of simple rectangles although more sophisticated and exact methods available from compiler literature <ref> [3, 8, 4] </ref> could be used. DUDE is a run-time system that can take advantage of such patterns recognized by the compiler.
Reference: [9] <author> D.E. Culler, A. Sah, K.E. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain parallelism with minimal hardware support: a compiler-controlled threaded abstract machine. </title> <booktitle> In Proceedings of the 4th Symposium on Architectural Support for ProgrammingLanguagesand Operating Systems, </booktitle> <pages> pages 164-175, </pages> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The add-atom () library call provides the means to schedule new enabled work. Dynamic Chores has the same benefits of flexibility and generality as Cilk [7], Mentat [17, 16] and Tam <ref> [9] </ref>, but also suffers from the problem of using a low-level abstractions. 2. Indexed Chores: Indexed chores are significantly easier to use than dynamic chores since the users need only provide the body of the loop, the range of loop iterations, and a de-pendencespecification.
Reference: [10] <author> R. Cytron. </author> <title> Doacross: Beyond vectorization for multiprocessors. </title> <booktitle> In Int. Conf. Parallel Procesing, </booktitle> <pages> pages 836-834, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: In a parallel program, three types of loops may be distinguished: doser, doall [1] and doacross <ref> [10] </ref>. Doser loops must be executed serially while iterations in a doall loop are completely independent and therefore can run in any order or in parallel. In a doacross loop, values assigned in one iterations are used in another iteration and therefore only partial parallelism is possible.
Reference: [11] <author> Derek L. Eager and John Zahorjan. Chores: </author> <title> Enhanced run-time support fo shared memory parallel computing. </title> <journal> ACM. Trans on Computer Systems, </journal> <volume> 11(1) </volume> <pages> 1-32, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Doall loops with large number of iterations are divided into pieces (usually two) and the piece are run in a interleaved fashion. 3.2 Data-driven Runtime Systems The Chores system <ref> [11] </ref> is implemented on top of Presto [6] and runs on the Sequent Symmetry. A per-processor worker (a user-level thread) grab chunks of work from a central queue using the guided self-scheduling method.
Reference: [12] <author> Dawson R. Engler, Gregory R. Andrews, and David K. Lowenthal. </author> <title> Efficient support for fine-grain parallelism. </title> <type> TR 93-13, </type> <institution> Univ. Arizona, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: One of the consequence of using a shared-memory model together with the use of high-level application-specific dependence information is that run-time system can direct communication at a higher-level than would be possible. The Filaments work <ref> [12] </ref> makes the case that extremely fine grain threads are not as expensive as previously thought.
Reference: [13] <author> Zhixi Fang, Peiyi Tang, Pen chung Yew, and Chuan qi Zhu. </author> <title> Dynamic processor self-scheduling for general parallel nested loops. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 919-929, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: In contrast, we proposes the use of tree-like recursive data structures (presented later) to represent multidimensional iteration space. The iterations spaces are manipulated during run-time. This allows the proposed run-time system to schedule multi-dimensional loops with dependencies across iterations and across dimensions. Runtime Methods: Fang et. al. <ref> [13] </ref> described a two-level scheduling scheme for general arbitrarily nested parallel loops. Each loop doser, doall or doacross is termed a task. An extremely large-grain data-flow graph, where each node is an entire loop, is created.
Reference: [14] <author> D. Gannon and J.K. Lee. </author> <title> Object oriented parallelism. </title> <booktitle> In Proceedings of 1991 Japan Society for Parallel Processing, </booktitle> <pages> pages 13-23, </pages> <year> 1991. </year>
Reference-contexts: In the absence of hints from the user, the runtime will decompose the data using a default method. The decomposition methods are similar to the data decomposition and distribution utilities available in HPF [19] and pC++ <ref> [14] </ref>. One important difference, however, is that in the process of data decomposition, DUDE takes flat data and creates objects called Iterates which is a tuple consisting of both data and operation. Iterates defines the granularity of parallelism in DUDE.
Reference: [15] <author> Susan Graham, Steven Lucco, and Oliver Sharp. </author> <title> Orchestrating interactions among parallel computations. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> April </month> <year> 1993. </year> <note> ACM, ACM. </note>
Reference-contexts: The current size of the batch is exactly half of the previous batch. Other methods in this model include adaptive guided self-scheduling, trapezoidal self-scheduling [31], tapering <ref> [15, 25] </ref>, and safe self-scheduling [24]. A distributed version of tapering has also been proposed by Graham and Lucco.
Reference: [16] <author> A. S. Grimshaw. </author> <title> Easy to use object-oriented parallel programming with mentat. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 39-51, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The add-atom () library call provides the means to schedule new enabled work. Dynamic Chores has the same benefits of flexibility and generality as Cilk [7], Mentat <ref> [17, 16] </ref> and Tam [9], but also suffers from the problem of using a low-level abstractions. 2. Indexed Chores: Indexed chores are significantly easier to use than dynamic chores since the users need only provide the body of the loop, the range of loop iterations, and a de-pendencespecification.
Reference: [17] <author> A. S. Grimshaw, W. T. Strayer, and P. Narayan. </author> <title> Dynamic object-oriented parallel processing. </title> <booktitle> IEEE Parallel and Distributed Technology: Systems and Applications, </booktitle> <pages> pages 33-47, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The add-atom () library call provides the means to schedule new enabled work. Dynamic Chores has the same benefits of flexibility and generality as Cilk [7], Mentat <ref> [17, 16] </ref> and Tam [9], but also suffers from the problem of using a low-level abstractions. 2. Indexed Chores: Indexed chores are significantly easier to use than dynamic chores since the users need only provide the body of the loop, the range of loop iterations, and a de-pendencespecification.
Reference: [18] <author> Dirk Grunwald. </author> <title> A users guide to awesime: An object oriented parallel programming and simulation system. </title> <type> Technical Report CU-CS-552-91, </type> <institution> University of Colorado, Boulder, </institution> <year> 1991. </year>
Reference-contexts: Finally, DUDE directs communcation by using prefetching and in the case of DSM systems, by relaxing memory coherence protocols. 4 The DUDE Run-time System The DUDE runtime system is built on the top of an existing thread library, AWESIME <ref> [18] </ref>, a thread library implemented in C++. Together they provide a powerful way to take advantage of both task and data parallelism in applications. In this paper, we concentrate on DUDE's data parallelism since this is the most novel aspect of the runtime system.
Reference: [19] <author> High Performance Fortran Forum HPFF. </author> <title> Draft high performance fortran specificition, </title> <note> version 0.4. In Proceedings of 1991 Japan Society for Parallel Processing, page Available from anonymous ftp site titan.cs.rice.edu, </note> <year> 1992. </year>
Reference-contexts: A programmer or compiler chooses the decomposition method such as by BLOCK or CYCLIC. In the absence of hints from the user, the runtime will decompose the data using a default method. The decomposition methods are similar to the data decomposition and distribution utilities available in HPF <ref> [19] </ref> and pC++ [14]. One important difference, however, is that in the process of data decomposition, DUDE takes flat data and creates objects called Iterates which is a tuple consisting of both data and operation. Iterates defines the granularity of parallelism in DUDE.
Reference: [20] <author> S. F. Hummel, Edith Schonberg, and L. E. Flynn. </author> <title> Factoring, a method for scheduling parallel loops. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 90-101, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The size of the ith chunk, C i , is selected using the following rule: R 0 = N; C i = d p where R i is the number of remaining iterations. A variation on this method is factoring <ref> [20] </ref> where at each scheduling operation the scheduler computes the size of a batch of chunks with the motivation to reduce the number of scheduling operations. The current size of the batch is exactly half of the previous batch.
Reference: [21] <author> Scott R. Kohn. </author> <title> A Parallel Software Infrastructure for Dynamic Block-Irregular Scientific Calculations. </title> <type> PhD thesis, </type> <institution> UCSD CSE Dept., </institution> <month> June </month> <year> 1995. </year> <note> Tech. Report CS95-429. </note>
Reference-contexts: Furthermore, DUDE is more appropriate for NUMA multiprocessors and DSM multicomputers since the run-time system reduces communication by using affinity information and by directing the DSM layer. Chores was designed with the assumption that memory accesses are uniform such as in the Sequent Symmetry. 3.3 Control-Driven Thread Packages LPARX <ref> [21, 22] </ref> is a library designed specifically for dynamic irregular scientific calculations. The most interesting part of the software infrastructure is the grid hierarchy management facilities for adaptive mesh refinements. The grid hierarchy routines provide data structures, error estimation, grid generation, workload balancing, processor assignment, and communication.
Reference: [22] <author> S.R. Kohn and S.B. Baden. </author> <title> A parallel software infrastructure for structured adaptive mesh methods. </title> <booktitle> In Supercomputing '95, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: Furthermore, DUDE is more appropriate for NUMA multiprocessors and DSM multicomputers since the run-time system reduces communication by using affinity information and by directing the DSM layer. Chores was designed with the assumption that memory accesses are uniform such as in the Sequent Symmetry. 3.3 Control-Driven Thread Packages LPARX <ref> [21, 22] </ref> is a library designed specifically for dynamic irregular scientific calculations. The most interesting part of the software infrastructure is the grid hierarchy management facilities for adaptive mesh refinements. The grid hierarchy routines provide data structures, error estimation, grid generation, workload balancing, processor assignment, and communication.
Reference: [23] <author> C. Kruskal and A. Weiss. </author> <title> Allocating independent subtasks on parallel processors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 11 </volume> <pages> 1001-10016, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: The simplest dynamic method is self-scheduling [30] where each processor grabs one iteration from the central data structure and executes that iteration. To alleviate the high cost of N synchronizations for N iterations in this approach, fixed-size chunking <ref> [23] </ref> was proposed, where each process grabs chunks of K iterations instead of one iteration. If the processors do not start simultaneously or if one processor gets an expensive chunk, the potential for load imbalance still exists.
Reference: [24] <author> Liu and et al. </author> <title> Scheduling parallel loops with variable length iteration execution times on parallel computers. </title> <booktitle> In Proc. 5th Intl. Conf. Parallel and Distributed Computing and System, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: The current size of the batch is exactly half of the previous batch. Other methods in this model include adaptive guided self-scheduling, trapezoidal self-scheduling [31], tapering [15, 25], and safe self-scheduling <ref> [24] </ref>. A distributed version of tapering has also been proposed by Graham and Lucco. Hybrid Methods: A compromise between purely static scheduling, which has the potential for poor load balance on irregular problems, and dynamic scheduling, is affinity loop scheduling [26], which takes affinity of data to processors into account.
Reference: [25] <author> Steven Lucco. </author> <title> A dynamic scheduling method for irregular parallel programs. </title> <booktitle> In Proceedings of ACM SIGPLAN '92 Conference on Porgramming Language Design and Implementation, </booktitle> <pages> pages 200-211. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: The current size of the batch is exactly half of the previous batch. Other methods in this model include adaptive guided self-scheduling, trapezoidal self-scheduling [31], tapering <ref> [15, 25] </ref>, and safe self-scheduling [24]. A distributed version of tapering has also been proposed by Graham and Lucco.
Reference: [26] <author> E.P Markatos and T. J. LeBlanc. </author> <title> Load Balancing vs Locality Management in Shared Memory Multiprocessors. </title> <booktitle> In Intl. Conference on Parallel Processing, </booktitle> <pages> pages 258-257, </pages> <address> St. Charles, Illinois, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: A distributed version of tapering has also been proposed by Graham and Lucco. Hybrid Methods: A compromise between purely static scheduling, which has the potential for poor load balance on irregular problems, and dynamic scheduling, is affinity loop scheduling <ref> [26] </ref>, which takes affinity of data to processors into account. This scheme is most like fixed-sized chunking except that chunks have an affinity to a particular processor which is remembered for subsequent scheduling to promote data locality.
Reference: [27] <author> C. D. Polochronopoulous and D. Kuck. </author> <title> Guided self-scheduling: A practical scheduling scheme for parallel supercomputers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(12) </volume> <pages> 1425-1439, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: If the processors do not start simultaneously or if one processor gets an expensive chunk, the potential for load imbalance still exists. In guided-self scheduling <ref> [27] </ref>, a variable chunk size as determined during runtime is used. The size of the ith chunk, C i , is selected using the following rule: R 0 = N; C i = d p where R i is the number of remaining iterations.
Reference: [28] <author> C. D. Polychronopoulos. </author> <title> Loop coalescing: A compiler transformation for parallel machines. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: Static Methods: A special case of multiply-nested loops are the one-way (or perfectly) nested doall loops in which there exists exactly one loop at each nest level. Given a one-way nested doall loop, a compile time transformation, loop coalescing, <ref> [28] </ref> can be used to coalesce m doall loops into a single doall with N = Q m iterations. This transformation then allows the application of the methods described in the previous section.
Reference: [29] <author> Hanan Samet. </author> <title> The Design and Analysis of Spatial Data Structures. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: In the quadtree decomposition, each subdivision is a block divided into four equal-sized parts. Alternatively, at each subdivision, the block could be divided into two parts as in bintree shown in be found in <ref> [29] </ref>. These structures solve the problem of inefficient indexing into the pools of Iterates because the chunk sizes are uniform at any given level. Given the level and the index, Iterates from a pool can be retrieved by simply using random access.
Reference: [30] <author> P. Tang and P.C. Yew. </author> <title> Processor self-scheduling for multiple nested parallel loops. </title> <booktitle> In Proc. Int. Conf. on Parallel Processing, </booktitle> <pages> pages 528-535. </pages> <publisher> IEEE, </publisher> <month> August </month> <year> 1986. </year>
Reference-contexts: This scheme is simple and there is no runtime scheduling overhead. The disadvantage, however, is that the method cannot adapt to dynamic fluctuation of the load in the system. Dynamic Scheduling: Dynamic assignment of iterations to processors can achieve better load balance. The simplest dynamic method is self-scheduling <ref> [30] </ref> where each processor grabs one iteration from the central data structure and executes that iteration. To alleviate the high cost of N synchronizations for N iterations in this approach, fixed-size chunking [23] was proposed, where each process grabs chunks of K iterations instead of one iteration.
Reference: [31] <author> T.H. Tzen and L.M. Ni. </author> <title> Trapezoid self-scheduling: A practical scheduling scheme for parallel computers. </title> <journal> IEEE Transactions Parrallel Distributed Systems, </journal> <volume> 4 </volume> <pages> 87-98, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The current size of the batch is exactly half of the previous batch. Other methods in this model include adaptive guided self-scheduling, trapezoidal self-scheduling <ref> [31] </ref>, tapering [15, 25], and safe self-scheduling [24]. A distributed version of tapering has also been proposed by Graham and Lucco.
Reference: [32] <author> Chien-Min Wang and Sheng-De Wang. </author> <title> A hybrid scheme for efficiently executing loops on multiprocessors. </title> <journal> Parallel Computing, </journal> <volume> 18 </volume> <pages> 625-637, </pages> <year> 1992. </year>
Reference-contexts: Iterations from different loops cannot be overlapped since the low-level scheduler must schedule a loop in its entirety before beginning a different loop. Hybrid Methods: A optimized compile/run-time version of loop interchange and loop distribution called IGSS and MGSS was proposed in <ref> [32] </ref>. These schemes also allowed the scheduling of hybrid loops consisting of doser and doalls. This method is useful in cases where the number of iterations of a doall loop is much larger than the number of processors involved.
Reference: [33] <author> M.J. Wolfe. </author> <title> Optimizing supercompilers for supercomputers. </title> <type> PhD thesis, </type> <institution> Univ. Illinois, Urbana, </institution> <month> April </month> <year> 1987. </year> <type> Rep. 329. </type>
Reference-contexts: General loop scheduling is possible if the programmer or the compiler passes application-specific dependencies to the scheduler. Parallelizing compilers can make some of this information available in the form of dependence vectors <ref> [33, 5] </ref>. By passing this information to the run-time layer, a dependence-driven run-time system can exploit application-specific parallelism in a general, portable manner. The compiler describes the parallelism declaratively in the form of dependence vectors. All the procedural details of synchronization and scheduling are handled by the run-time system. <p> This transformation then allows the application of the methods described in the previous section. A hybrid loop consisting of doser and doall can be transformed such that all doalls are nested within the doser loop by loop interchange <ref> [2, 33] </ref>. Other compiler transformations attempt to organize loops such that the loop with maximum parallelism is the outer loop. Compiler transformations such as loop normalization and loop fusion can also be used to collapse a multi-dimensional iteration space to a single dimensional iteration space. <p> Each vector in the set represents an arc from the source of the to the target of the dependency. How these vectors are computed is beyond the scope of this paper but a good description can be found in <ref> [33] </ref> [5]. Line 15 specifies the dependencs for stencil computation. A compiler can compute this vector by taking the difference between the iteration vectors of the source and target iterations. Data Parallel Operation Data parallel operation and dependence satisfaction is handled by the runtime system.
References-found: 33

