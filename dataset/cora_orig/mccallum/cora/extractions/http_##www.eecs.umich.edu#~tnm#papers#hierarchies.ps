URL: http://www.eecs.umich.edu/~tnm/papers/hierarchies.ps
Refering-URL: http://www.eecs.umich.edu/~tnm/papers.html
Root-URL: http://www.cs.umich.edu
Title: An Analytical Model for Designing Memory Hierarchies  
Author: Bruce L. Jacob, Student Member, IEEE, Peter M. Chen, Member, IEEE, Seth R. Silverman, and Trevor N. Mudge, Fellow, IEEE 
Keyword: cache, memory, and storage hierarchies; trace-driven simulations; optimization of cache configurations.  
Date: 10, OCTOBER 1996  
Note: 100 IEEE TRANSACTIONS ON COMPUTERS, VOL. 45, NO.  
Abstract: Memory hierarchies have long been studied by many means: system building, trace-driven simulation, and mathematical analysis. Yet little help is available for the system designer wishing to quickly size the different levels in a memory hierarchy to a first-order approximation. In this paper, we present a simple analysis for providing this practical help and some unexpected results and intuition that come out of the analysis. By applying a specific, parameterized model of workload locality, we are able to derive a closed-form solution for the optimal size of each hierarchy level. We verify the accuracy of this solution against exhaustive simulation with two case studies: a three-level I/O storage hierarchy and a three-level processor-cache hierarchy. In all but one case, the configuration recommended by the model performs within 5% of optimal. One result of our analysis is that the first place to spend money is the cheapest (rather than the fastest) cache level, particularly with small system budgets. Another is that money spent on an n-level hierarchy is spent in a fixed proportion until another level is added. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Blumson, P. Honeyman, T. E. Ragland, and M. T. Stolarchuk. </author> <title> "AFS server logging." </title> <type> Tech. Rep. </type> <institution> CITI-93-10, University of Michi-gan, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: B.1 Workload The data that was used for the workload in the I/O hierarchy simulations was collected by a logging AFS server <ref> [1] </ref>. The server sees all requests not serviced from the client's local AFS disk cache 6 . We used one month's worth of trace 6 This client cache was found to capture only a few MB of data for this server.
Reference: [2] <author> C. H. Edwards, Jr. and D. E. Penney. </author> <title> Calculus and Analytic Geometry. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: Specifically, we solve for the size of each hierarchy level (s i ), given the access time (t i ) and unit cost (c i ) of each technology; parameters describing workload locality; and the total system budget. Our solution proceeds through the following steps: 1) use Lagrange multipliers <ref> [2] </ref> to get a general solution without constraining the sizes to be non-negative; 2) apply a specific, parameterized model of workload locality to derive a closed-form solution, again allowing negative sizes; 3) refine the solution to account for the additional constraint that all sizes be non-negative.
Reference: [3] <author> C. K. Chow. </author> <title> "On optimization of storage hierarchies." </title> <journal> IBM Journal of Research and Development, </journal> <pages> pp. 194-203, </pages> <month> May </month> <year> 1974. </year> <title> [4] |. "Determination of cache's capacity and its matching storage hierarchy." </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 25, no. 2, </volume> <pages> pp. 157-164, </pages> <month> February </month> <year> 1976. </year>
Reference-contexts: Many researchers have analyzed memory hierarchies in the past. Chow showed that the optimum number of cache levels scales with the logarithm of the capacity of the cache hierarchy <ref> [3, 4] </ref>. Garcia-Molina and Rege demonstrated that it is often better to have more of a slower device than less of a faster device [7, 15]. Welch showed that the optimal speed of each level should be proportional to the amount of time spent servicing requests at that level [20].
Reference: [5] <author> E. G. Coffman and P. J. Denning. </author> <title> Operating System Theory. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1973. </year>
Reference-contexts: The effects of these assumptions are discussed at the end of this section. To compute the probability of a reference hitting at a cache level, we use stack distance curves, measurements taken directly from address streams <ref> [5] </ref>. The stack distance curves describe how many unique bytes of data separate two references to the same item.
Reference: [6] <author> A. L. Drapeau and R. H. Katz. </author> <title> "Striped tape arrays." </title> <booktitle> In Proceedings of the 1993 IEEE Symposium on Mass Storage Systems, </booktitle> <year> 1993, </year> <pages> pp. 257-265. </pages>
Reference-contexts: Table I describes the specifications used in the simulator and analytical calculations for the constant values of the various c i and t i (specifications taken from <ref> [6, 14] </ref>). B.1 Workload The data that was used for the workload in the I/O hierarchy simulations was collected by a logging AFS server [1]. The server sees all requests not serviced from the client's local AFS disk cache 6 .
Reference: [7] <author> H. Garcia-Molina, A. Park, and L. R. Rogers. </author> <title> "Performance through memory." </title> <booktitle> In Proceedings of the 1987 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <year> 1987, </year> <pages> pp. 122-131. </pages>
Reference-contexts: Chow showed that the optimum number of cache levels scales with the logarithm of the capacity of the cache hierarchy [3, 4]. Garcia-Molina and Rege demonstrated that it is often better to have more of a slower device than less of a faster device <ref> [7, 15] </ref>. Welch showed that the optimal speed of each level should be proportional to the amount of time spent servicing requests at that level [20].
Reference: [8] <author> B. L. Jacob. </author> <title> "Optimization of mass storage hierarchies." </title> <type> Tech. Rep. </type> <institution> CSE-TR-228-95, University of Michigan, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: This follows from the 30% Rule 2 . It is also consistent with our workload traces in Section V. Thus we assume polynomial forms for P (x) and p (x) in this paper; we have also used an exponential form with similar results <ref> [8] </ref>. It is easiest to start at the cumulative probability graph P (x). As mentioned before, P (x) is related to a cache's hit ratio|an LRU-managed cache of size x would have a hit rate of P (x), given the input stream that generated P (x).
Reference: [9] <author> N. P. Jouppi and S. J. E. Wilton. </author> <title> "Tradeoffs in two-level on-chip caching." </title> <booktitle> In Proc. 21st International Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: This is described more in the discussion of the analysis (Section IV). II. Previous Work Countless articles have been written about memory hierarchies ([17, 18] provide excellent overviews of CPU and disk caches), generally focusing on a two-level hierarchy <ref> [9] </ref>. Most papers in recent years have used trace-driven simulation to investigate such aspects of cache performance as multiprocessor cache coherence and replacement strategies. Trace-driven studies are valuable for understanding cache behavior on specific workloads, but they are not easily applied to other workloads [17].
Reference: [10] <author> J. E. MacDonald and K. L. Sigworth. </author> <title> "Storage hierarchy optimization procedure." </title> <journal> IBM Journal of Research and Development, </journal> <pages> pp. 133-140, </pages> <month> March </month> <year> 1975. </year>
Reference-contexts: Exhaustive simulation takes far too long, particularly as hierarchies become more complex [16]; trial and error on running systems is usually impossible; and prior mathematical analyses have stopped short of providing much-needed, intuitive insight into cache sizing <ref> [10] </ref> or have assumed the availability of memory technologies with B. Jacob, P. Chen, and T. Mudge are with the Advanced Computer Architecture Laboratory, Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI 48109-2122. e-mail: blj@eecs.umich.edu; pmchen@eecs.umich.edu; tnm@eecs.umich.edu. S. <p> Failing to apply a specific model of workload locality makes it impossible to provide an easily used, closed-form solution for the optimal cache configuration <ref> [10] </ref>, and so results from these papers have contained dependencies on the cache configuration|the number of levels, or the sizes and hit rates of the levels.
Reference: [11] <author> R. Pike, D. Presotto, K. Thompson, and H. Trickey. </author> <title> "Plan 9 from Bell Labs." </title> <booktitle> In Proc. Summer 1990 UKUUG Conference, </booktitle> <pages> pp. 1-9, </pages> <address> London, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: We simulate different ways to allocate money, where the quantum of money was $256 for the storage hierarchy simulation and $64 for the processor-cache hierarchy simulation. B. Storage Hierarchy Simulations We simulated a storage hierarchy similar to that of Plan 9 <ref> [11, 13] </ref>, where the file system lives entirely on an optical disk jukebox and is cached by DRAM and magnetic disk. Table I describes the specifications used in the simulator and analytical calculations for the constant values of the various c i and t i (specifications taken from [6, 14]).
Reference: [12] <author> S. Przybylski. </author> <title> Cache and Memory Hierarchy Design: A Performance-Directed Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Since the model takes only a moment to recommend a configuration, we can easily use it to choose a subset of devices from a larger pool of technologies. This is similar to Przybylski's dynamic programming approach to hierarchy optimization <ref> [12] </ref>, but it is much simpler because we can quickly search through all possible subsets. This process will find the best organization of the best subset of technologies at a given budget point. V.
Reference: [13] <author> S. Quinlan. </author> <title> "A cached WORM file system." </title> <journal> Software-Practice and Experience, </journal> <volume> vol. 21, no. 12, </volume> <pages> pp. 1289-1299, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: We simulate different ways to allocate money, where the quantum of money was $256 for the storage hierarchy simulation and $64 for the processor-cache hierarchy simulation. B. Storage Hierarchy Simulations We simulated a storage hierarchy similar to that of Plan 9 <ref> [11, 13] </ref>, where the file system lives entirely on an optical disk jukebox and is cached by DRAM and magnetic disk. Table I describes the specifications used in the simulator and analytical calculations for the constant values of the various c i and t i (specifications taken from [6, 14]).
Reference: [14] <author> S. Ranade. </author> <title> Mass Storage Technologies. </title> <publisher> Meckler Publishing, </publisher> <address> Westport, CT, </address> <year> 1991. </year>
Reference-contexts: Table I describes the specifications used in the simulator and analytical calculations for the constant values of the various c i and t i (specifications taken from <ref> [6, 14] </ref>). B.1 Workload The data that was used for the workload in the I/O hierarchy simulations was collected by a logging AFS server [1]. The server sees all requests not serviced from the client's local AFS disk cache 6 .
Reference: [15] <author> S. L. </author> <title> Rege. "Cost, performance and size trade-offs for different levels in a memory hierarchy." </title> <journal> IEEE Computer, </journal> <volume> vol. 19, </volume> <pages> pp. 43-51, </pages> <month> April </month> <year> 1976. </year>
Reference-contexts: Chow showed that the optimum number of cache levels scales with the logarithm of the capacity of the cache hierarchy [3, 4]. Garcia-Molina and Rege demonstrated that it is often better to have more of a slower device than less of a faster device <ref> [7, 15] </ref>. Welch showed that the optimal speed of each level should be proportional to the amount of time spent servicing requests at that level [20].
Reference: [16] <author> A. J. Smith. </author> <title> "Two methods for the efficient analysis of memory address trace data." </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 3, no. 1, </volume> <pages> pp. 94-101, </pages> <month> January </month> <year> 1977. </year> <title> [17] |. "Cache memories." </title> <journal> Computing Surveys, </journal> <volume> vol. 14, no. 3, </volume> <pages> pp. 473-530, </pages> <month> September </month> <year> 1982. </year> <title> [18] |. "Disk cache-miss ratio analysis and design considerations." </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 161-203, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Unfortunately, little practical help exists for system designers and administrators seeking to optimize their cache hierarchies. Exhaustive simulation takes far too long, particularly as hierarchies become more complex <ref> [16] </ref>; trial and error on running systems is usually impossible; and prior mathematical analyses have stopped short of providing much-needed, intuitive insight into cache sizing [10] or have assumed the availability of memory technologies with B. Jacob, P. Chen, and T.
Reference: [19] <author> H. S. Stone. </author> <title> High Performance Computer Architecture. </title> <publisher> Addison Wesley, </publisher> <year> 1993. </year>

References-found: 16

