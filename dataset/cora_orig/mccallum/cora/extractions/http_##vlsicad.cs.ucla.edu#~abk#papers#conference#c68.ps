URL: http://vlsicad.cs.ucla.edu/~abk/papers/conference/c68.ps
Refering-URL: http://vlsicad.cs.ucla.edu/~abk/publications.html
Root-URL: http://www.cs.ucla.edu
Title: Multilevel Circuit Partitioning  
Author: Charles J. Alpert Jen-Hsin Huang and Andrew B. Kahng 
Address: Los Angeles, CA 90095-1596  Austin, TX 78758 Synopsys, Inc., Mountain View, CA 94043  San Jose, CA 95134  
Affiliation: UCLA Computer Science Department,  IBM Austin Research Laboratory,  Cadence Design Systems, Inc.,  
Abstract: Recent work [2] [5] [11] [12] [14] has illustrated the promise of multilevel approaches for partitioning large circuits. Multilevel partitioning recursively clusters the instance until its size is smaller than a given threshold, then unclusters the instance while applying a partitioning refinement algorithm. Our multilevel partitioner uses a new technique to control the number of levels in the matching-based clustering phase and also exploits recent innovations in classic iterative partitioning [7] [10]. Our heuristic outperforms numerous existing bipartitioning heuristics, with improvements ranging from 6.9 to 27.9% for 100 runs and 3.0 to 20.6% for just 10 runs (while also using less CPU time). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. J. Alpert. </author> <type> Multi-way Graph and Hypergraph Partitioning PhD Thesis, </type> <institution> UCLA, </institution> <year> 1996. </year>
Reference-contexts: Our first experiments study the effects of varying the matching ratio parameter R: we ran ML 100 times for each test case with R values 1:0, 0:5 and 0:33. Due to space limitations, Table 1 includes only the data for the 12 largest test cases (see <ref> [1] </ref>, or our website http://vlsicad.cs.ucla.edu/ , for the entire data set). For all the benchmarks, the difference among minimum cuts for various values of R is less than 2%, except for the largest benchmarks. <p> We choose to use ML C with R = 0:5 for comparing with other algorithms since the gains of CLIP over FM and R = 0:5 over R = 1:0 are significant, while reducing R to 0:33 does not seem worth the extra runtime <ref> [1] </ref>. <p> More complete comparisons with other algorithms whose results are subsumed by these works can be found in <ref> [1] </ref> or our website. The last two rows of the table respectively give the percent improvements of ML C with 100 runs, and ML C with 10 runs, over the other algorithms in terms of cut size.
Reference: [2] <author> C. J. Alpert, L. W. Hagen, and A. B. Kahng. </author> <title> A Hybrid Multilevel/ Genetic Approach for Circuit Partitioning. </title> <booktitle> Physical Design Workshop, </booktitle> <pages> pp. 100105, </pages> <year> 1996. </year>
Reference-contexts: One of the Metis coarsening schemes uses a greedy weighted matching algorithm, upon which our coarsening scheme is based. In the VLSI CAD community, previous multilevel works include <ref> [2] </ref> [5] [11]. The authors of [2] adapt Metis to partition netlist hypergraphs and use a genetic algorithm to obtain more stable solution quality. The authors of [5] apply clique-finding clustering as the coarsening step for multilevel bipartitioning. <p> One of the Metis coarsening schemes uses a greedy weighted matching algorithm, upon which our coarsening scheme is based. In the VLSI CAD community, previous multilevel works include <ref> [2] </ref> [5] [11]. The authors of [2] adapt Metis to partition netlist hypergraphs and use a genetic algorithm to obtain more stable solution quality. The authors of [5] apply clique-finding clustering as the coarsening step for multilevel bipartitioning. <p> The characteristics for these test cases can be found in e.g., <ref> [2] </ref> [7]. We report bipartitioning results for unit module areas with r = 0:1. The FM- and CLIP-based implementations for our ML algorithm are denoted by ML F and ML C respectively. For all experiments, the coarsening threshold was set to T = 35 modules. <p> Many works which present bipartitioning results for unit module areas and size constraints corresponding to r = 0:1. Table 2 compares the cuts and obtained by ML C with R = 0:5 for 100 and 10 runs to seven such algorithms in the literature. GM <ref> [2] </ref> and HB [11] are multilevel approaches, PARABOLI (PB) [19] uses linear placement techniques, GFM t is a two-phase gradient FM approach [16], and CL-LA3 f (CLIP with lookahead level 3), CD-LA3 f (CDIP with lookahead level 3) and CL-PR f (CLIP with PROP gain calculation) [7] are three modifications to
Reference: [3] <author> C. J. Alpert and A. B. Kahng. </author> <title> Recent Directions in Netlist Partitioning: A Survey. Integration, </title> <journal> the VLSI Journal, </journal> <year> 1995. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] [12] [11] [14] (see <ref> [3] </ref> for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community.
Reference: [4] <author> T. Bui, C. Heigham, C. Jones, and T. Leighton. </author> <title> Improving the Performance of the Kernighan-Lin and Simulated Annealing Graph Bisection Algorithms. </title> <booktitle> DAC, </booktitle> <pages> pp. 775778, </pages> <year> 1989. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering <ref> [4] </ref> or multilevel clustering [5] [12] [11] [14] (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> Work in multilevel partitioning [12] [14] [18] has been especially prominent in the scientific computing literature for partitioning finite-element graphs. Hendrickson and Leland [12] developed a very efficient multilevel partitioning algorithm, included in their Chaco package. They use random matching <ref> [4] </ref> to perform clustering and multi-way FM to do refinement, with several modifications to reduce runtime: (i) the algorithm can terminate before a pass is completed if further improvement appears unlikely; (ii) gains are saved after a pass is completed so that only moved modules and their neighbors need to have <p> If no unmatched w exists (i.e., all of the neighbors of v are matched), then v is assigned to its own cluster. When computing the conn function, we ignore nets with more than ten modules to reduce runtimes. The matching algorithms of <ref> [4] </ref> [12] [14] seek maximal match-ings, which generally forces the ratio of jV i+1 j to jV i j to be 1 2 . We believe that maximal matching can result in too few levels; a slower coarsening gives the refinement algorithm more opportunities to construct better solutions.
Reference: [5] <author> J. Cong and M'L. Smith. </author> <title> A Parallel Bottom-Up Clustering Algorithm with Applications to Circuit Partitioning in VLSI Design. </title> <booktitle> DAC, </booktitle> <pages> pp. 755760, </pages> <year> 1993. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering <ref> [5] </ref> [12] [11] [14] (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> One of the Metis coarsening schemes uses a greedy weighted matching algorithm, upon which our coarsening scheme is based. In the VLSI CAD community, previous multilevel works include [2] <ref> [5] </ref> [11]. The authors of [2] adapt Metis to partition netlist hypergraphs and use a genetic algorithm to obtain more stable solution quality. The authors of [5] apply clique-finding clustering as the coarsening step for multilevel bipartitioning. <p> In the VLSI CAD community, previous multilevel works include [2] <ref> [5] </ref> [11]. The authors of [2] adapt Metis to partition netlist hypergraphs and use a genetic algorithm to obtain more stable solution quality. The authors of [5] apply clique-finding clustering as the coarsening step for multilevel bipartitioning. Finally, the authors of [11] give a detailed study of multilevel FPGA partitioning, exploring various schemes for technology mapping, clustering, partitioning the coarsest graph, and uncoarsening in one or multiple steps.
Reference: [6] <author> S. Dutt and W. Deng. </author> <title> A Probability-Based Approach to VLSI Circuit Partitioning. </title> <booktitle> DAC, </booktitle> <pages> pp. 100105, </pages> <year> 1996. </year>
Reference: [7] <author> S. Dutt and W. Deng. </author> <title> VLSI Circuit Partitioning by Cluster-Removal Using Iterative Improvement Techniques. </title> <booktitle> ICCAD, </booktitle> <pages> pp. </pages> <address> 194200, </address> <year> 1996. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm <ref> [7] </ref> [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] [12] [11] [14] (see [3] for a survey on partitioning and clustering techniques). <p> This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. We have added two key ingredients to the functionality of our partitioner, which significantly improve performance: (i) we use the CLIP algorithm of <ref> [7] </ref> within our FM implementation, and (ii) we use a matching based clustering that halts prematurely so that more than n 2 clusters are generated. <p> If the initial partitioning passed in is NU LL, as in Step 5 of Figure 1, then a random starting solution is constructed. Our partitioner uses FM with a LIFO bucket scheme [10] and may also use CLIP <ref> [7] </ref> if desired. CLIP uses the idea of infinite weight tie-breaking, e.g., suppose that moving module v i increases the gain of v j by one. Instead of increasing the gain by just one, it could be increased by two, five, ten, etc. The authors of [7] actually propose to increase <p> may also use CLIP <ref> [7] </ref> if desired. CLIP uses the idea of infinite weight tie-breaking, e.g., suppose that moving module v i increases the gain of v j by one. Instead of increasing the gain by just one, it could be increased by two, five, ten, etc. The authors of [7] actually propose to increase the gain by an infinite factor and accomplish this by initializing all cells to the zero gain bucket in order of their true gains. Experiments in [7] show that CLIP averages 18% improvement over FM (both using a LIFO bucket scheme). 4 Experimental Results We ran <p> The authors of <ref> [7] </ref> actually propose to increase the gain by an infinite factor and accomplish this by initializing all cells to the zero gain bucket in order of their true gains. Experiments in [7] show that CLIP averages 18% improvement over FM (both using a LIFO bucket scheme). 4 Experimental Results We ran our partitioner on 23 of the standard benchmarks from the CAD Benchmarking Laboratory (ftp.cbl.ncsu.edu or visit our web site at http://vlsicad.cs.ucla.edu/). <p> The characteristics for these test cases can be found in e.g., [2] <ref> [7] </ref>. We report bipartitioning results for unit module areas with r = 0:1. The FM- and CLIP-based implementations for our ML algorithm are denoted by ML F and ML C respectively. For all experiments, the coarsening threshold was set to T = 35 modules. <p> GM [2] and HB [11] are multilevel approaches, PARABOLI (PB) [19] uses linear placement techniques, GFM t is a two-phase gradient FM approach [16], and CL-LA3 f (CLIP with lookahead level 3), CD-LA3 f (CDIP with lookahead level 3) and CL-PR f (CLIP with PROP gain calculation) <ref> [7] </ref> are three modifications to the FM engine. More complete comparisons with other algorithms whose results are subsumed by these works can be found in [1] or our website.
Reference: [8] <author> C. M. Fiduccia and R. M. Mattheyses. </author> <title> A Linear Time Heuristic for Improving Network Partitions. </title> <booktitle> DAC, </booktitle> <pages> pp. 175181, </pages> <year> 1982. </year>
Reference-contexts: The standard bipartitioning approach is iterative improvement based on the Kernighan-Lin algorithm, which was later improved by Fiduccia-Mattheyses (FM) <ref> [8] </ref>. The FM algorithm begins with some initial solution fX ;Y g and proceeds in a series of passes. During a pass, modules are successively moved between X and Y until each module has been moved exactly once.
Reference: [9] <author> A. S. Fukunaga, J.-H. Huang, and A. B. Kahng. </author> <title> Large-Step Markov Chain Variants for VLSI Netlist Partitioning. </title> <booktitle> Proc. of the IEEE Intl. Symp. on Circuits and Systems, </booktitle> <volume> vol. IV, </volume> <pages> pp. 496499, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains <ref> [9] </ref>, two-phase clustering [4] or multilevel clustering [5] [12] [11] [14] (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> The table also reports the total time required for 10 runs of 1 For 10 and 100 runs of ML C , we respectively averaged 19.1% and 21.9% improvement over our implementation of LSMC <ref> [9] </ref> (22 test cases), 6.5% and 11.1% improvement over GFM [16] (13 test cases), and -1.7% and 2.4% improvement over PANZA [17] (9 test cases).
Reference: [10] <author> L. W. Hagen, D. J.-H. Huang, and A. B. Kahng. </author> <title> On Implementation Choices for Iterative Improvement Partitioning Algorithms. </title> <journal> IEEE Trans. </journal> <note> CAD (to appear), </note> <year> 1997. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] <ref> [10] </ref> [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] [12] [11] [14] (see [3] for a survey on partitioning and clustering techniques). <p> If the initial partitioning passed in is NU LL, as in Step 5 of Figure 1, then a random starting solution is constructed. Our partitioner uses FM with a LIFO bucket scheme <ref> [10] </ref> and may also use CLIP [7] if desired. CLIP uses the idea of infinite weight tie-breaking, e.g., suppose that moving module v i increases the gain of v j by one. Instead of increasing the gain by just one, it could be increased by two, five, ten, etc.
Reference: [11] <author> S. Hauck and G. Borriello. </author> <title> An Evaluation of Bipartitioning Techniques. </title> <booktitle> Proc. of the 16th Conf. on Advanced Research in VLSI, </booktitle> <pages> pp. 383402, </pages> <year> 1995. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] [12] <ref> [11] </ref> [14] (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> One of the Metis coarsening schemes uses a greedy weighted matching algorithm, upon which our coarsening scheme is based. In the VLSI CAD community, previous multilevel works include [2] [5] <ref> [11] </ref>. The authors of [2] adapt Metis to partition netlist hypergraphs and use a genetic algorithm to obtain more stable solution quality. The authors of [5] apply clique-finding clustering as the coarsening step for multilevel bipartitioning. Finally, the authors of [11] give a detailed study of multilevel FPGA partitioning, exploring various <p> the VLSI CAD community, previous multilevel works include [2] [5] <ref> [11] </ref>. The authors of [2] adapt Metis to partition netlist hypergraphs and use a genetic algorithm to obtain more stable solution quality. The authors of [5] apply clique-finding clustering as the coarsening step for multilevel bipartitioning. Finally, the authors of [11] give a detailed study of multilevel FPGA partitioning, exploring various schemes for technology mapping, clustering, partitioning the coarsest graph, and uncoarsening in one or multiple steps. <p> Many works which present bipartitioning results for unit module areas and size constraints corresponding to r = 0:1. Table 2 compares the cuts and obtained by ML C with R = 0:5 for 100 and 10 runs to seven such algorithms in the literature. GM [2] and HB <ref> [11] </ref> are multilevel approaches, PARABOLI (PB) [19] uses linear placement techniques, GFM t is a two-phase gradient FM approach [16], and CL-LA3 f (CLIP with lookahead level 3), CD-LA3 f (CDIP with lookahead level 3) and CL-PR f (CLIP with PROP gain calculation) [7] are three modifications to the FM engine.
Reference: [12] <author> B. Hendrickson and R. Leland. </author> <title> A Multilevel Algorithm for Partitioning Graphs. </title> <booktitle> Proc. Supercomputing, </booktitle> <year> 1995. </year> <note> Also see, </note> <institution> Tech. </institution> <type> Rep. </type> <institution> SAND93-1301, Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] <ref> [12] </ref> [11] [14] (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] <ref> [12] </ref> [11] [14] (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> This permits the refinement algorithm to avoid bad local minima via big steps at high levels, while still being able to find a good final solution via detailed refinement at low levels. Work in multilevel partitioning <ref> [12] </ref> [14] [18] has been especially prominent in the scientific computing literature for partitioning finite-element graphs. Hendrickson and Leland [12] developed a very efficient multilevel partitioning algorithm, included in their Chaco package. <p> Work in multilevel partitioning <ref> [12] </ref> [14] [18] has been especially prominent in the scientific computing literature for partitioning finite-element graphs. Hendrickson and Leland [12] developed a very efficient multilevel partitioning algorithm, included in their Chaco package. <p> Metis, another multilevel partitioning package targeted to finite-element graphs, was developed by Karypis and Kumar [14]. As in <ref> [12] </ref>, boundary schemes and early pass termination are used, along with many different algorithms for clustering, initial partitioning and refinement which allow experiments with various combinations of options. One of the Metis coarsening schemes uses a greedy weighted matching algorithm, upon which our coarsening scheme is based. <p> If no unmatched w exists (i.e., all of the neighbors of v are matched), then v is assigned to its own cluster. When computing the conn function, we ignore nets with more than ten modules to reduce runtimes. The matching algorithms of [4] <ref> [12] </ref> [14] seek maximal match-ings, which generally forces the ratio of jV i+1 j to jV i j to be 1 2 . We believe that maximal matching can result in too few levels; a slower coarsening gives the refinement algorithm more opportunities to construct better solutions. <p> Our current efforts seek to speed up our approach (e.g., via boundary refinement schemes and propagation of gain data down the hierarchy <ref> [12] </ref> [14]) while maintaining high solution quality. We have also integrated a 4-way partitioning version of ML C to yield an excellent quadrisection-based placement tool [13].
Reference: [13] <author> D. J.-H. Huang and A. B. </author> <title> Kahng Partitioning-Based Standard-Cell Global Placement with An Exact Objective. </title> <booktitle> Proc. Intl. Symp. on Physical Design, </booktitle> <pages> pp. 1825, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Our current efforts seek to speed up our approach (e.g., via boundary refinement schemes and propagation of gain data down the hierarchy [12] [14]) while maintaining high solution quality. We have also integrated a 4-way partitioning version of ML C to yield an excellent quadrisection-based placement tool <ref> [13] </ref>.
Reference: [14] <author> G. Karypis and V. Kumar. </author> <title> Multilevel Graph Partitioning Schemes. </title> <editor> P. Banerjee and P. Boca, editors, </editor> <booktitle> Proc. of the 1995 Intl. Conf. on Parallel Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 113122, </pages> <year> 1995. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] [15]. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] [12] [11] <ref> [14] </ref> (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] [12] [11] <ref> [14] </ref> (see [3] for a survey on partitioning and clustering techniques). This paper proposes a new multilevel circuit partitioning algorithm that is motivated by the success of multilevel partitioners [12] [14] in the scientific computing community. <p> This permits the refinement algorithm to avoid bad local minima via big steps at high levels, while still being able to find a good final solution via detailed refinement at low levels. Work in multilevel partitioning [12] <ref> [14] </ref> [18] has been especially prominent in the scientific computing literature for partitioning finite-element graphs. Hendrickson and Leland [12] developed a very efficient multilevel partitioning algorithm, included in their Chaco package. <p> Metis, another multilevel partitioning package targeted to finite-element graphs, was developed by Karypis and Kumar <ref> [14] </ref>. As in [12], boundary schemes and early pass termination are used, along with many different algorithms for clustering, initial partitioning and refinement which allow experiments with various combinations of options. One of the Metis coarsening schemes uses a greedy weighted matching algorithm, upon which our coarsening scheme is based. <p> We now discuss the procedures Match and FMPartition in more detail. We coarsen via a linear time heavy-edge matching similar in spirit to <ref> [14] </ref>. The Match algorithm starts by randomly permuting the modules and then visits each in turn. <p> If no unmatched w exists (i.e., all of the neighbors of v are matched), then v is assigned to its own cluster. When computing the conn function, we ignore nets with more than ten modules to reduce runtimes. The matching algorithms of [4] [12] <ref> [14] </ref> seek maximal match-ings, which generally forces the ratio of jV i+1 j to jV i j to be 1 2 . We believe that maximal matching can result in too few levels; a slower coarsening gives the refinement algorithm more opportunities to construct better solutions. <p> Our current efforts seek to speed up our approach (e.g., via boundary refinement schemes and propagation of gain data down the hierarchy [12] <ref> [14] </ref>) while maintaining high solution quality. We have also integrated a 4-way partitioning version of ML C to yield an excellent quadrisection-based placement tool [13].
Reference: [15] <author> B. Krishnamurthy. </author> <title> An Improved Min-Cut Algorithm for Partitioning VLSI Networks. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 33(5):438446, </volume> <year> 1984. </year>
Reference-contexts: Hence, much work has sought to improve upon the classic FM algorithm [7] [10] <ref> [15] </ref>. Other works attempt to use iterative improvement as an engine inside other algorithmic approaches such as large-scale Markov chains [9], two-phase clustering [4] or multilevel clustering [5] [12] [11] [14] (see [3] for a survey on partitioning and clustering techniques).
Reference: [16] <author> L. T. Liu, M. T. Kuo, S.-C. Huang, and C.-K. Cheng. </author> <title> A Gradient Method on the Initial Partition of Fiduccia-Mattheyses Algorithm. </title> <booktitle> ICCAD, </booktitle> <pages> pp. 229234, </pages> <year> 1995. </year>
Reference-contexts: Table 2 compares the cuts and obtained by ML C with R = 0:5 for 100 and 10 runs to seven such algorithms in the literature. GM [2] and HB [11] are multilevel approaches, PARABOLI (PB) [19] uses linear placement techniques, GFM t is a two-phase gradient FM approach <ref> [16] </ref>, and CL-LA3 f (CLIP with lookahead level 3), CD-LA3 f (CDIP with lookahead level 3) and CL-PR f (CLIP with PROP gain calculation) [7] are three modifications to the FM engine. <p> The table also reports the total time required for 10 runs of 1 For 10 and 100 runs of ML C , we respectively averaged 19.1% and 21.9% improvement over our implementation of LSMC [9] (22 test cases), 6.5% and 11.1% improvement over GFM <ref> [16] </ref> (13 test cases), and -1.7% and 2.4% improvement over PANZA [17] (9 test cases). Note that PANZA does not report results some of the largest benchmarks (e.g., industry2, avqsmall, avqlarge, and golem3) for which our approach has been particularly successful.
Reference: [17] <author> J. Li, J. Lillis, and C.-K. Cheng. </author> <title> Linear Decomposition Algorithm for VLSI Design Applications. </title> <booktitle> ICCAD, </booktitle> <pages> pp. 223228, </pages> <year> 1995. </year>
Reference-contexts: total time required for 10 runs of 1 For 10 and 100 runs of ML C , we respectively averaged 19.1% and 21.9% improvement over our implementation of LSMC [9] (22 test cases), 6.5% and 11.1% improvement over GFM [16] (13 test cases), and -1.7% and 2.4% improvement over PANZA <ref> [17] </ref> (9 test cases). Note that PANZA does not report results some of the largest benchmarks (e.g., industry2, avqsmall, avqlarge, and golem3) for which our approach has been particularly successful.
Reference: [18] <author> R. Ponnusamy, N. Mansour, A. Choudhary, and G. C. Fox. </author> <title> Graph Contraction for Mapping Data on Parallel Computers: A Quality-Cost Tradeoff. </title> <booktitle> Scientific Programming, </booktitle> <address> 3(1):7382, </address> <month> Spring </month> <year> 1994. </year>
Reference-contexts: This permits the refinement algorithm to avoid bad local minima via big steps at high levels, while still being able to find a good final solution via detailed refinement at low levels. Work in multilevel partitioning [12] [14] <ref> [18] </ref> has been especially prominent in the scientific computing literature for partitioning finite-element graphs. Hendrickson and Leland [12] developed a very efficient multilevel partitioning algorithm, included in their Chaco package.
Reference: [19] <author> B. M. Riess, K. Doll, and F. M. Johannes. </author> <title> Partitioning Very Large Circuits Using Analytical Placement Techniques. </title> <journal> DAC, pp. </journal> <volume> 646 651, </volume> <year> 1994. </year>
Reference-contexts: Table 2 compares the cuts and obtained by ML C with R = 0:5 for 100 and 10 runs to seven such algorithms in the literature. GM [2] and HB [11] are multilevel approaches, PARABOLI (PB) <ref> [19] </ref> uses linear placement techniques, GFM t is a two-phase gradient FM approach [16], and CL-LA3 f (CLIP with lookahead level 3), CD-LA3 f (CDIP with lookahead level 3) and CL-PR f (CLIP with PROP gain calculation) [7] are three modifications to the FM engine.
References-found: 19

