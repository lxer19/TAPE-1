URL: http://www.cs.indiana.edu/scicomp/html/mpi2/mpi2short.ps
Refering-URL: http://www.cs.indiana.edu/scicomp/html/mpi2/dir.html
Root-URL: http://www.cs.indiana.edu
Title: MPI Performance on the SGI Power Challenge  
Author: Tom Loos and Randall Bramley 
Note: Work supported by NSF grants NSF CDA-9309746, CDA-9303189, and ASC-9502292.  
Abstract: The widely implemented [5] MPI Standard defines primitives for point-to-point and collective inter-processor communication (IPC), and synchronization based on message passing. The main reason to use a message passing standard is to ease the development, porting, and execution of applications on the variety of parallel computers that can support the paradigm, including shared memory, distributed memory, and shared memory array multiprocessors. This paper concentrates on the SGI Power Challenge, a shared memory multiprocessor, with comparison results provided for the distributed memory Intel Paragon. Memory and communications tests written in C++ using messages of double precision arrays show both memory and MPI blocking IPC performance on the Power Challenge degrade once total message sizes grow larger than the second level cache. Comparing the MPI and memory performance curves indicate Power Challenge native MPI point-to-point communication is implemented using memory copying. A model of blocking IPC for the SGI Power Challenge was developed and validated with performance results for use as part of a cost function in a graph partitioning algorithm. A new measure of communications efficiency and overhead, the ratio of IPC time to memory copy time, is used to compare relative IPC performance. Comparison between the Power Challenge and the Paragon show that the Paragon is more efficient for small messages, but the Power Challenge is better on large messages. Power Challenge observations do not correspond well with Paragon results, indicating shared memory multiprocessor results should not be used to predict distributed memory multiprocessor performance. This suggests that relative performance of parallel algorithms should not judged based on one type of machine. A longer version of this paper is available at http://www.cs.indiana.edu/scicomp/html/mpi2/dir.html. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> CENTER FOR INNOVATIVE 3 COMPUTER APPLICATIONS, INDIANA UNIVERSITY, </institution>
Reference-contexts: This pipelined operation model is only suited for large message sizes since n 1=2 is negative. 2 Comparison with the Intel Paragon The Intel Paragon is a distributed memory multiprocessor with the processors or nodes arranged in a two-dimensional mesh and no global memory <ref> [1] </ref>. The studied Paragon is a model XP/S-A7 with 92 general purpose and 4 I/O and service nodes connected in a 12 fi 8 mesh.
References-found: 1

