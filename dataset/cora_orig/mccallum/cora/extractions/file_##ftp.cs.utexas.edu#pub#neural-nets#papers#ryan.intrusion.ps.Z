URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/ryan.intrusion.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: 
Email: raven@cs.utexas.edu  mj@orac.ece.utexas.edu  risto@cs.utexas.edu  
Title: Intrusion Detection with Neural Networks  
Author: Jake Ryan Meng-Jang Lin Risto Miikkulainen 
Address: Austin, TX 78712  Austin, TX 78712  Austin, TX 78712  
Affiliation: Department of Computer Sciences The University of Texas at Austin  Department of Electrical and Computer Engineering The University of Texas at Austin  Department of Computer Sciences The University of Texas at Austin  
Abstract: With the rapid expansion of computer networks during the past few years, security has become a crucial issue for modern computer systems. A good way to detect illegitimate use is through monitoring unusual user activity. Methods of intrusion detection based on hand-coded rule sets or predicting commands on-line are laborous to build or not very reliable. This paper proposes a new way of applying neural networks to detect intrusions. We believe that a user leaves a `print' when using the system; a neural network can be used to learn this print and identify each user much like detectives use thumbprints to place people at crime scenes. If a user's behavior does not match his/her print, the system administrator can be alerted of a possible security breech. A backpropagation neural network called NNID (Neural Network Intrusion Detector) was trained in the identification task and tested experimentally on a system of 10 users. The system was 96% accurate in detecting unusual activity, with 7% false alarm rate. These results suggest that learning user profiles is an effective way for detecting intrusions.
Abstract-found: 1
Intro-found: 1
Reference: <author> Debar, H., Becker, M., and Siboni, D. </author> <year> (1992). </year> <title> A neural network component for an intrusion detection system. </title> <booktitle> In Proceedings of the 1992 IEEE Computer Society Symposium on Research in Computer Security and Privacy, </booktitle> <pages> 240250. </pages>
Reference-contexts: The size of the window is an important parameter: If w is too small, there will be many false positives; if it is too big, the network may not generalize well to novel sequences. The most recent of such systems <ref> (Debar et al. 1992) </ref> can predict the next command correctly around 80% of the time, and accept a command as predictable (among the three most likely next commands) 90% of the time.
Reference: <author> Denning, D. E. </author> <year> (1987). </year> <title> An intrusion detection model. </title> <journal> IEEE Transactions on Software Engineering, SE-13:222232. </journal>
Reference: <author> Fox, K. L., Henning, R. R., Reed, J. H., and Simonian, R. </author> <year> (1990). </year> <title> A neural network approach towards intrusion detection. </title> <booktitle> In Proceedings of the 13th National Computer Security Conference, </booktitle> <pages> 125134. </pages>
Reference: <author> Frank, J. </author> <year> (1994). </year> <title> Artificial intelligence and intrusion detection: Current and future directions. </title> <booktitle> In Proceedings of the National 17th Computer Security Conference. </booktitle>
Reference: <author> Garvey, T. D., and Lunt, T. F. </author> <year> (1991). </year> <title> Model-based intrusion detection. </title> <booktitle> In Proceedings of the 14th National Computer Security Conference. </booktitle>
Reference-contexts: Often statistical methods are used to measure how anomalous the behavior is, that is, how different e.g. the commands used are from normal behavior. Such approaches require that the distribution of subjects' behavior is known. The behavior can be represented as a rule-based model <ref> (Garvey and Lunt 1991) </ref>, in terms of predictive pattern generation (Teng et al. 1990), or using state transition analysis (Porras 2 et al. 1995).
Reference: <author> Miyata, Y. </author> <year> (1991). </year> <title> A User's Guide to PlaNet Version 5.6 A Tool for Constructing, Running, and Looking in to a PDP Network. </title> <institution> Computer Science Department, University of Colorado, Boulder, Boulder, CO. </institution>
Reference-contexts: The input layer consisted of 100 units, representing the user vector; the hidden layer had 30 units and the output layer 10 units, one for each user. The network was implemented in the PlaNet Neural Network simulator <ref> (Miyata 1991) </ref>. 5 RESULTS To avoid overtraining, several training sessions were run prior to the actual experiments to see how many training cycles would give the highest performance.
Reference: <author> Mukherjee, B., Heberlein, L. T., and Levitt, K. N. </author> <year> (1994). </year> <title> Network intrusion detection. </title> <journal> IEEE Network, </journal> <volume> 2641. </volume>
Reference: <author> Porras, P. A., Ilgun, K., and Kemmerer, R. A. </author> <year> (1995). </year> <title> State transition analysis: A rule-based intrusion detection approach. </title> <journal> IEEE Transactions on Software Engineering, SE-21:181199. </journal>
Reference-contexts: Such approaches require that the distribution of subjects' behavior is known. The behavior can be represented as a rule-based model (Garvey and Lunt 1991), in terms of predictive pattern generation (Teng et al. 1990), or using state transition analysis <ref> (Porras 2 et al. 1995) </ref>. Pattern matching techniques are then used to determine whether the sequence of events is part of normal behavior, constitutes an anomaly, or fits the description of a known attack. IDSs also differ in whether they are on-line or off-line.
Reference: <author> Teng, H. S., Chen, K., and Lu, S. C. </author> <year> (1990). </year> <title> Adaptive real-time anomaly detection using inductively generated sequential patterns. </title> <booktitle> In Proceedings of the 1990 IEEE Symposium on Research in Computer Security and Privacy, </booktitle> <volume> 278284. </volume> <pages> 7 </pages>
Reference-contexts: Such approaches require that the distribution of subjects' behavior is known. The behavior can be represented as a rule-based model (Garvey and Lunt 1991), in terms of predictive pattern generation <ref> (Teng et al. 1990) </ref>, or using state transition analysis (Porras 2 et al. 1995). Pattern matching techniques are then used to determine whether the sequence of events is part of normal behavior, constitutes an anomaly, or fits the description of a known attack.
References-found: 9

