URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P591.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts96.htm
Root-URL: http://www.mcs.anl.gov
Title: RESTARTING AN ARNOLDI REDUCTION an iteration by restarting the reduction with information in a length
Author: R. B. LEHOUCQ 
Keyword: Key words. Arnoldi reduction, Lanczos reduction, restarting, eigenvalues.  
Note: A popular alternative is to define  AMS subject classifications. 65F15, 65G05  
Abstract: The Arnoldi reduction is an efficient procedure for approximating a subset of the eigensystem of a large sparse matrix A of order n: At each step, a partial orthogonal reduction of A into an upper Hessenberg matrix is produced. The eigenvalues of this Hessenberg matrix are used to approximate a subset of the eigenvalues of the large matrix A. The approximation to the eigenvalues of A generally improves as the order of the Hessenberg matrix increases. Unfortunately, so do the cost and storage of the reduction. This paper considers the various approaches used to restart a reduction. Analysis and numerical examples are presented that explain and exhibit the generally superior properties of Sorensen's implicitly restarted Arnoldi iteration. The analysis exploits the fact that an IRA iteration is mathematically equivalent to a curtailed QR iteration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. D. Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen, </author> <title> LAPACK Users' Guide, </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <note> second ed., </note> <year> 1995. </year>
Reference-contexts: This decomposition is computed by the practical qr algorithm in the LAPACK <ref> [1] </ref> software library. <p> We present results for the two-dimensional model convection-diffusion problem u (x; y) + aer ru (x; y) = u (x; y); on the unit square <ref> [0; 1] </ref> fi [0; 1] with zero boundary data. Here, ae represents the convection and is a real number. The problem is discretized by using centered finite differences. The eigenvalues and eigenvectors of the resulting matrix are known explicitly. This feature allows us to check the accuracy of our results. <p> We present results for the two-dimensional model convection-diffusion problem u (x; y) + aer ru (x; y) = u (x; y); on the unit square <ref> [0; 1] </ref> fi [0; 1] with zero boundary data. Here, ae represents the convection and is a real number. The problem is discretized by using centered finite differences. The eigenvalues and eigenvectors of the resulting matrix are known explicitly. This feature allows us to check the accuracy of our results.
Reference: [2] <author> W. E. </author> <title> Arnoldi, The principle of minimized iterations in the solution of the matrix eigenvalue problem, </title> <journal> Quart. J. Applied Mathematics, </journal> <volume> 9 (1951), </volume> <pages> pp. 17-29. </pages>
Reference-contexts: 1. Introduction. The Arnoldi reduction <ref> [2] </ref> is an orthogonal projection method for approximating a subset of the eigensystem of a general square matrix.
Reference: [3] <author> J. Baglama, D. Calvetti, and L. Reichel, </author> <title> Iterative methods for the computation of a few eigenvalues of a large symmetric matrix, </title> <type> technical report, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1995. </year> <note> BIT (to appear). </note>
Reference-contexts: This is the subject of current research. We have examined one particular choice of polynomial, namely, one constructed from the unwanted Ritz values at every iteration. Other interesting strategies include the roots of Chebyshev polynomials [34], Harmonic Ritz values [24, 26, 28, 38], the roots of Leja polynomials <ref> [3, 5] </ref>, and the roots of least squares polynomials [35]. In particular, the Harmonic Ritz values have been used to estimate the interior eigenvalues of A: There also remains the interesting question of how many shifts p i to apply per iteration. <p> This approach differs from the ira iteration outlined in Table 6.1 in two ways. The first is that of deflation. The other difference is that a large-degree polynomial is applied at 16 R. B. LEHOUCQ every step. For symmetric A; Baglama, Calvetti, and Reichel <ref> [3] </ref> use Leja shifts, and this strategy outperforms ARPACK for small m: ARPACK uses a polynomial of degree at most m k as compared with the degree m j polynomial used by the deflated approach. Other polynomials and nonsymmetric A should be investigated. Acknowledgments.
Reference: [4] <author> T. Braconnier, </author> <title> The Arnoldi-Tchebycheff algorithm for solving large nonsymmetric eigen-problems, </title> <type> Technical Report TR/PA/93/25, </type> <institution> CERFACS, Toulouse, France, </institution> <year> 1993. </year>
Reference-contexts: Numerical Results. Lehoucq and Scott [17] presented a software survey of large-scale eigenvalue methods and comparative results. The Arnoldi-based software included the following three packages, which are available either in the public domain or under licence. These are the ARNCHEB package <ref> [4] </ref>, the ARPACK [19] software package, and the Harwell Subroutine Library code EB13 [37]. The ARNCHEB package provides the subroutine ARNOL, which implements an explicitly restarted Arnoldi iteration. The code is based on the algorithm given in Table 9.1 without the use of locking. It uses Chebyshev polynomial acceleration.
Reference: [5] <author> D. Calvetti, L. Reichel, and D. C. Sorensen, </author> <title> An implicitly restarted Lanczos method for large symmetric eigenvalue problems, </title> <journal> ETNA, </journal> <volume> 2 (1994), </volume> <pages> pp. 1-21. </pages>
Reference-contexts: This is the subject of current research. We have examined one particular choice of polynomial, namely, one constructed from the unwanted Ritz values at every iteration. Other interesting strategies include the roots of Chebyshev polynomials [34], Harmonic Ritz values [24, 26, 28, 38], the roots of Leja polynomials <ref> [3, 5] </ref>, and the roots of least squares polynomials [35]. In particular, the Harmonic Ritz values have been used to estimate the interior eigenvalues of A: There also remains the interesting question of how many shifts p i to apply per iteration.
Reference: [6] <author> F. Chatelin, </author> <title> Eigenvalues of Matrices, </title> <publisher> Wiley, </publisher> <year> 1993. </year>
Reference-contexts: Note that by the Implicit Q theorem (see x4) and equation (11.1), kf (l) (l) k+1 : The shifting strategy has the effect of replacing the starting vector, thereby restarting the reduction. Thus, the convergence of an ira iteration is established. The distance between the subspaces <ref> [6, 10] </ref> R (Z k ) and R (Z (l) k ) may be shown to be equal to q k Z k k 2 .
Reference: [7] <author> J. Cullum and W. E. Donath, </author> <title> A block Lanczos algorithm for computing the q algebraically largest eigenvalues and a corresponding eigenspace for large, sparse symmetric matrices, </title> <booktitle> in Proceedings of the 1974 IEEE Conference on Decision and Control, </booktitle> <address> New York, </address> <year> 1974, </year> <pages> pp. 505-509. </pages>
Reference-contexts: The explicitly restarted Arnoldi iteration (era iteration) was introduced by Saad [32] to overcome these difficulties, based on similar ideas developed for the Lanczos process by Paige [27], Cullum and Donath <ref> [7] </ref>, and Golub and Underwood [11]. Karush [14] proposes what appears to fl This work was supported in part by ARPA (U.S. Army ORA4466.01), by the U.S.
Reference: [8] <author> J. Cullum and R. A. Wilboughby, </author> <title> Lanczos algorithms for large symmetric eigenvalue computations, vol. 1, Theory, </title> <publisher> Birkhauser, </publisher> <address> Boston, MA., </address> <year> 1985. </year>
Reference-contexts: When the matrix A is symmetric, the Lanczos reduction [15] is recovered. More than a decade of research has been devoted to understanding and overcoming the numerical difficulties of the Lanczos reduction. The works of Parlett [30] and Cullum and Wiloughby <ref> [8] </ref> study in detail the many specifics of the Lanczos algorithm, while the paper by Grimes, Lewis, and Simon [13] discusses the design and development of high-quality software.
Reference: [9] <author> I. S. Duff and J. A. Scott, </author> <title> Computing selected eigenvalues of large sparse unsymmetric matrices using subspace iteration, </title> <journal> ACM Trans. on Math. Software, </journal> <volume> 19 (1993), </volume> <pages> pp. 137-159. </pages>
Reference-contexts: that fi (l) k+1 goes to zero with the convergence rate of j k+1 = k j: It is well known that performing subspace iteration on a subspace of dimension larger than the number of eigenvalues required typically leads to improved convergence rates; see the paper of Duff and Scott <ref> [9] </ref> for a discussion and further references. <p> I thank Chris Beattie for showing me the matrix identity in equation (6.1). I also thank Ron Morgan for some helpful discssions on his related work [25] and Jennifer Scott for answering many questions on her codes <ref> [9, 37] </ref>.
Reference: [10] <author> G. H. Golub and C. F. V. Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins, </publisher> <address> Baltimore, </address> <note> second ed., </note> <year> 1989. </year>
Reference-contexts: The blocks of order two contain the complex conjugate eigenvalues of A. The matrix T is said to be in upper quasi-triangular matrix form. Proof. See <ref> [10, page 362] </ref>. Let C be a quasi-diagonal orthogonal matrix with two by two blocks allowed only where T has them. <p> If the first columns of X m and V m are equal, then H m = G m , X m = V m and f m = r m : Proof. See <ref> [10, page 367] </ref>. Let (s j ; j ) for j = 1; : : : ; m be the eigenpairs of H m where all the s j are of unit length. <p> Note that by the Implicit Q theorem (see x4) and equation (11.1), kf (l) (l) k+1 : The shifting strategy has the effect of replacing the starting vector, thereby restarting the reduction. Thus, the convergence of an ira iteration is established. The distance between the subspaces <ref> [6, 10] </ref> R (Z k ) and R (Z (l) k ) may be shown to be equal to q k Z k k 2 .
Reference: [11] <author> G. H. Golub and R. Underwood, </author> <title> The block Lanczos method for computing eigenvalues, in Mathematical Software III, </title> <editor> J. R. Rice, ed., </editor> <year> 1977, </year> <pages> pp. 361-377. </pages>
Reference-contexts: The explicitly restarted Arnoldi iteration (era iteration) was introduced by Saad [32] to overcome these difficulties, based on similar ideas developed for the Lanczos process by Paige [27], Cullum and Donath [7], and Golub and Underwood <ref> [11] </ref>. Karush [14] proposes what appears to fl This work was supported in part by ARPA (U.S. Army ORA4466.01), by the U.S.
Reference: [12] <author> G. H. Golub and J. H. Wilkinson, </author> <title> Ill-conditioned eigensystems and the computation of the Jordan canonical form, </title> <journal> SIAM Review, </journal> <volume> 18 (1976), </volume> <pages> pp. 578-619. </pages>
Reference-contexts: On the other hand, using an expansion in terms of the Schur vectors of H m gives a "richer" starting vector. Theorem 8.1 gives that the ira iteration implicitly uses a Schur basis of H m . Golub and Wilkinson <ref> [12] </ref> examine the many practical difficulties involved when computing invariant subspaces. They conclude that working with Schur vectors is a better behaved numerical process. Within the context of subspace iteration, Stew-art [41] also arrives at the same conclusion. 8. Characterzing an IRA Iteration.
Reference: [13] <author> R. G. Grimes, J. G. Lewis, and H. D. Simon, </author> <title> A shifted block Lanczos algorithm for solving sparse symmetric generalized eigenproblems, </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <volume> 15 (1994), </volume> <pages> pp. 228-272. </pages>
Reference-contexts: More than a decade of research has been devoted to understanding and overcoming the numerical difficulties of the Lanczos reduction. The works of Parlett [30] and Cullum and Wiloughby [8] study in detail the many specifics of the Lanczos algorithm, while the paper by Grimes, Lewis, and Simon <ref> [13] </ref> discusses the design and development of high-quality software. Development of the Arnoldi reduction lagged behind because of the inordinate computational and storage requirements associated with the original method when a large number of steps are required for convergence.
Reference: [14] <author> W. Karush, </author> <title> An iterative method for finding characteristics vectors of a symmetric matrix, </title> <journal> Pacific J. Mathematics, </journal> <volume> 1 (1951), </volume> <pages> pp. 233-248. </pages>
Reference-contexts: The explicitly restarted Arnoldi iteration (era iteration) was introduced by Saad [32] to overcome these difficulties, based on similar ideas developed for the Lanczos process by Paige [27], Cullum and Donath [7], and Golub and Underwood [11]. Karush <ref> [14] </ref> proposes what appears to fl This work was supported in part by ARPA (U.S. Army ORA4466.01), by the U.S.
Reference: [15] <author> C. </author> <title> Lanczos, An iteration method for the solution of the eigenvalue problem of linear differential and integral operators, </title> <institution> J. Research of the National Bureau of Standards, </institution> <month> 45 </month> <year> (1950), </year> <pages> pp. 255-282. </pages> <note> Research Paper 2133. </note>
Reference-contexts: When the matrix A is symmetric, the Lanczos reduction <ref> [15] </ref> is recovered. More than a decade of research has been devoted to understanding and overcoming the numerical difficulties of the Lanczos reduction.
Reference: [16] <author> R. B. Lehoucq, </author> <title> Analysis and Implementation of an Implicitly Restarted Iteration, </title> <type> PhD thesis, </type> <institution> Rice University, Houston, Texas, </institution> <month> May </month> <year> 1995. </year> <note> Also available as Technical Report TR95-13, </note> <institution> Dept. of Computational and Applied Mathematics. </institution>
Reference-contexts: The residual vector f m is orthogonal to the columns of X m : In order to ensure that f m is orthogonal to the column space of X m in finite-precision arithmetic, some form of reorthogonalization is necessary at step 5. See Chapter 7 of <ref> [16] </ref>. 4 R. B. LEHOUCQ Table 4.1 Extending an Arnoldi Reduction * Let AX m = X m H m + f m e T m be a length m Arnoldi reduction. 1. fi m+1 = kf m k: 2. <p> Then f m = 0 if and only if x 1 2 R (Z m ), where AZ m = Z m T m is a partial real Schur decomposition. Proof. See Chapter 2 of <ref> [16] </ref> or [39] for a proof based on the Jordan canonical form. <p> Other polynomials and nonsymmetric A should be investigated. Acknowledgments. A large part of this research was carried out while the author was writing his dissertation <ref> [16] </ref> under the kind direction of Danny Sorensen. Theorem 8.2 is a joint result with Danny that also appears in [40]. I thank Chris Beattie for showing me the matrix identity in equation (6.1).
Reference: [17] <author> R. B. Lehoucq and J. A. Scott, </author> <title> An evaluation of software for computing eigenvalues of sparse nonsymmetric matrices, </title> <type> Preprint MCS-P547-1195, </type> <institution> Argonne National Laboratory, Argonne, IL, </institution> <year> 1995. </year>
Reference-contexts: In order to compute in real arithmetic, the procedure outlined in x2 is employed at line 2 if 1 is not a real number. 10. Numerical Results. Lehoucq and Scott <ref> [17] </ref> presented a software survey of large-scale eigenvalue methods and comparative results. The Arnoldi-based software included the following three packages, which are available either in the public domain or under licence. These are the ARNCHEB package [4], the ARPACK [19] software package, and the Harwell Subroutine Library code EB13 [37]. <p> For many large-scale eigenvalue problems, the dominant cost is that of performing the matrix-vector products. For these two examples, ARPACK reliably computed the multiplicities. Changing WHICH has the effect of modifying the restart parameters. For further information and other experiments, we refer the reader to <ref> [17] </ref>. 11. Convergence of an IRA Iteration. Sorensen gives a convergence theorem [39, pages 369-370] for an ira iteration where the polynomial applied at every restart is fixed.
Reference: [18] <author> R. B. Lehoucq and D. C. Sorensen, </author> <title> Deflation techniques for an implicitly restarted iteration, </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <note> (1996). To appear. </note>
Reference-contexts: They have contributed to the emergence of the practical qr algorithm as the method of choice for computing the eigensystem of dense matrices. In particular, the deflation rules allow the qr iteration to compute multiple and clustered eigenvalues. The reader is referred to <ref> [18] </ref> for a detailed study on deflation strategies for an ira iteration. The remainder of this section discusses shifting strategies. We remark that the shifting strategy of the practical qr algorithm cannot by employed because it requires the full reduction to upper Hessenberg form at every iteration.
Reference: [19] <author> R. B. Lehoucq, D. C. Sorensen, P. Vu, and C. Yang, ARPACK: </author> <title> An implementation of the implicitly re-started Arnoldi iteration that computes some of the eigenvalues and eigenvectors of a large sparse matrix, 1995. Available from netlib@ornl.gov under the RESTARTING AN ARNOLDI REDUCTION 17 directory scalapack. </title>
Reference-contexts: This viewpoint provides an alternate approach to study restarted Arnoldi/Lanczos reductions in which the power of the qr algorithm is used. The immediate effect is the improvement of the numerical accuracy and convergence properties of the ARPACK <ref> [19] </ref> software package. The paper is organized as follows. Some notation and the real Schur decomposition are introduced in x2. The eigenvalue problem and Arnoldi reduction along with more notation are the subject of xx3-4. <p> When i has a nonzero imaginary part, we set s i and s i+1 to be the real and imaginary portions of the complex eigenvector of H m associated with i : 6. An IRA Iteration. The ARPACK software package <ref> [19] </ref> implements an implicitly restarted Arnoldi method. Table 6.1 gives the basic algorithm as implemented by ARPACK. The scheme is called implicit because the starting vector is updated with an implicitly shifted qr algorithm on the Hessenberg matrix H m : The method is motivated by the following result. <p> Numerical Results. Lehoucq and Scott [17] presented a software survey of large-scale eigenvalue methods and comparative results. The Arnoldi-based software included the following three packages, which are available either in the public domain or under licence. These are the ARNCHEB package [4], the ARPACK <ref> [19] </ref> software package, and the Harwell Subroutine Library code EB13 [37]. The ARNCHEB package provides the subroutine ARNOL, which implements an explicitly restarted Arnoldi iteration. The code is based on the algorithm given in Table 9.1 without the use of locking. It uses Chebyshev polynomial acceleration.
Reference: [20] <author> T. A. Manteuffel, </author> <title> Adaptive procedure for estimating parameters for the nonsymmetric Tchebychev iteration, </title> <journal> Numerische Mathematik, </journal> <volume> 31 (1978), </volume> <pages> pp. 183-208. </pages>
Reference-contexts: The acceleration techniques and hybrid methods presented by Saad in Chapter 7 of [36] attempt to improve the era iteration introduced in x5 by approximately solving the min-max problem of equation (9.2). Motivated by Manteuffel's scheme <ref> [20] </ref>, Saad first proposed the use of Chebyshev polynomials in [34]. A Chebyshev polynomial (A) on an ellipse containing the unwanted Ritz values is applied to the restart vector in an attempt to accelerate convergence of the orginal era iteration.
Reference: [21] <author> R. S. Martin, G. Peters, and J. H. Wilkinson, </author> <title> The QR algorithm for real Hessenberg matrices, </title> <journal> Numerische Mathematik, </journal> <volume> 14 (1978), </volume> <pages> pp. 219-231. </pages>
Reference-contexts: RESTARTING AN ARNOLDI REDUCTION 15 12. Practical Considerations. We have shown a direct connection between the ira and qr iterations. With this connection, we believe that reliable general-purpose software for the large-scale eigenvalue problem is possible. The practical qr algorithm <ref> [21] </ref> resulted when deflation rules and practical shifting strategies were incorporated. These techniques are extremely important for the convergence and stability of the iteration. They have contributed to the emergence of the practical qr algorithm as the method of choice for computing the eigensystem of dense matrices.
Reference: [22] <author> K. Meerbergen and A. Spence, </author> <title> Implicitly restarted Arnoldi with purification for the shift-invert transformation, </title> <type> Technical Report TW225, </type> <institution> Katholieke Universitet Leuven, Leuven, Belguim, </institution> <month> April </month> <year> 1995. </year> <note> Submitted to Mathematics of Computation. </note>
Reference-contexts: Compute the qr factorization (H m ) fi fl = Q k R k : Equation (6.1) may then be rewritten as (A)X k = X m Q k R k , and the lemma is proved. This is a generalization of the special case () = shown in <ref> [22] </ref>. A similar result was proved by Paige, Parlett, and Van der Vorst in Lemma 1 of [28] for the Lanczos reduction. Restarting the iteration involves postmultiplying the length m Arnoldi factor ization with Q k and thus obtaining a length k factorization.
Reference: [23] <author> G. S. Miminis and C. C. Paige, </author> <title> Implicit shifting in the QR and related algorithms, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 12 (1991), </volume> <pages> pp. 385-400. </pages>
Reference-contexts: Proof. A result by Miminis and Paige <ref> [23, pages 391-395] </ref> proves equation (8.1). They prove that if m k qr steps are performed, the matrix equation (8.1) results if and only if the m k shifts are eigenvalues of H m , regardless of their multiplicity.
Reference: [24] <author> R. B. Morgan, </author> <title> Computing interior eigenvalues of large matrices, Linear Algebra and Its Applications, </title> <booktitle> 154/156 (1991), </booktitle> <pages> pp. </pages> <month> 289-309. </month> <title> [25] , On restarting the Arnoldi method for large nonsymmetric eigenvalue problems, </title> <journal> Mathematics of Computation, </journal> <note> (1995). To appear 1996. </note>
Reference-contexts: This is the subject of current research. We have examined one particular choice of polynomial, namely, one constructed from the unwanted Ritz values at every iteration. Other interesting strategies include the roots of Chebyshev polynomials [34], Harmonic Ritz values <ref> [24, 26, 28, 38] </ref>, the roots of Leja polynomials [3, 5], and the roots of least squares polynomials [35].
Reference: [26] <author> R. B. Morgan and M. Zeng, </author> <title> Estimates for interior eigenvalues of large nonsymmetric matrices, </title> <type> tech. rep., </type> <year> 1996. </year>
Reference-contexts: This is the subject of current research. We have examined one particular choice of polynomial, namely, one constructed from the unwanted Ritz values at every iteration. Other interesting strategies include the roots of Chebyshev polynomials [34], Harmonic Ritz values <ref> [24, 26, 28, 38] </ref>, the roots of Leja polynomials [3, 5], and the roots of least squares polynomials [35].
Reference: [27] <author> C. C. Paige, </author> <title> The computation of eigenvalues and eigenvectors of very large sparse matrices, </title> <type> PhD thesis, </type> <institution> University of London, </institution> <address> London, England, </address> <year> 1971. </year>
Reference-contexts: The explicitly restarted Arnoldi iteration (era iteration) was introduced by Saad [32] to overcome these difficulties, based on similar ideas developed for the Lanczos process by Paige <ref> [27] </ref>, Cullum and Donath [7], and Golub and Underwood [11]. Karush [14] proposes what appears to fl This work was supported in part by ARPA (U.S. Army ORA4466.01), by the U.S.
Reference: [28] <author> C. C. Paige, B. N. Parlett, and H. A. V. der Vorst, </author> <title> Approximate solutions and eigenvalue bounds from Krylov subspaces, Numerical Linear Algebra with Applications, </title> <booktitle> 2 (1995), </booktitle> <pages> pp. 115-134. </pages>
Reference-contexts: This is a generalization of the special case () = shown in [22]. A similar result was proved by Paige, Parlett, and Van der Vorst in Lemma 1 of <ref> [28] </ref> for the Lanczos reduction. Restarting the iteration involves postmultiplying the length m Arnoldi factor ization with Q k and thus obtaining a length k factorization. <p> This is the subject of current research. We have examined one particular choice of polynomial, namely, one constructed from the unwanted Ritz values at every iteration. Other interesting strategies include the roots of Chebyshev polynomials [34], Harmonic Ritz values <ref> [24, 26, 28, 38] </ref>, the roots of Leja polynomials [3, 5], and the roots of least squares polynomials [35].
Reference: [29] <author> B. N. Parlett, </author> <title> Global convergence of the basic QR algorithm on Hessenberg matrices, </title> <journal> Mathematics of Computation, </journal> <volume> 22 (1968), </volume> <pages> pp. </pages> <month> 803-817. </month> <title> [30] , The Symmetric Eigenvalue Problem, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1980. </year>
Reference-contexts: The theorems proved by Watkins and Elsner in [43] identify the convergence of the qr algorithm with that of simultaneous iteration, or subspace iteration. Parlett <ref> [29] </ref> presents the first set of comprehensive sufficient conditions for convergence of the qr iteration on Hessenberg matrices, while a portion of the paper by Parlett and Poole [31] considers a geometric convergence theory for Hessenberg matrices. RESTARTING AN ARNOLDI REDUCTION 15 12. Practical Considerations.
Reference: [31] <author> B. N. Parlett and W. G. Poole, </author> <title> A geometric theory for the QR, LU, and power iterations, </title> <journal> SIAM J. Numerical Analysis, </journal> <volume> 10 (1973), </volume> <pages> pp. 389-412. </pages>
Reference-contexts: Parlett [29] presents the first set of comprehensive sufficient conditions for convergence of the qr iteration on Hessenberg matrices, while a portion of the paper by Parlett and Poole <ref> [31] </ref> considers a geometric convergence theory for Hessenberg matrices. RESTARTING AN ARNOLDI REDUCTION 15 12. Practical Considerations. We have shown a direct connection between the ira and qr iterations. With this connection, we believe that reliable general-purpose software for the large-scale eigenvalue problem is possible.

Reference: [37] <author> J. A. Scott, </author> <title> An Arnoldi code for computing selected eigenvalues of sparse real unsymmetric matrices, </title> <journal> ACM Trans. Mathematical Software, </journal> <volume> 21 (1995), </volume> <pages> pp. 432-475. </pages>
Reference-contexts: Thus we may easily compute the norm of the residual of a Ritz pair and avoid the application of A: We remark that a tiny Ritz estimate does not imply an accurate approximation. We refer the reader to the work of Scott <ref> [37] </ref> for the many issues that must be considered for assessing the quality of Ritz pairs computed by the Arnoldi reduction. <p> The Arnoldi-based software included the following three packages, which are available either in the public domain or under licence. These are the ARNCHEB package [4], the ARPACK [19] software package, and the Harwell Subroutine Library code EB13 <ref> [37] </ref>. The ARNCHEB package provides the subroutine ARNOL, which implements an explicitly restarted Arnoldi iteration. The code is based on the algorithm given in Table 9.1 without the use of locking. It uses Chebyshev polynomial acceleration. <p> I thank Chris Beattie for showing me the matrix identity in equation (6.1). I also thank Ron Morgan for some helpful discssions on his related work [25] and Jennifer Scott for answering many questions on her codes <ref> [9, 37] </ref>.
Reference: [38] <author> G. L. G. Sleijpen and H. Van der Vorst, </author> <title> A Jacobi-Davidson iteration method for linear eigenvalue problems, </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <volume> 17, </volume> <pages> pp. 401-425. </pages>
Reference-contexts: This is the subject of current research. We have examined one particular choice of polynomial, namely, one constructed from the unwanted Ritz values at every iteration. Other interesting strategies include the roots of Chebyshev polynomials [34], Harmonic Ritz values <ref> [24, 26, 28, 38] </ref>, the roots of Leja polynomials [3, 5], and the roots of least squares polynomials [35].
Reference: [39] <author> D. C. Sorensen, </author> <title> Implicit application of polynomial filters in a k-step Arnoldi method, </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <volume> 13 (1992), </volume> <pages> pp. </pages> <month> 357-385. </month> <title> [40] , Implicitly restarted Arnoldi/Lanczos methods for large scale eigenvalue calculations, </title> <booktitle> in Proceedings of the ICASE/LaRC Workshop on Parallel Numerical Algorithms, </booktitle> <month> May 23-25, </month> <year> 1994, </year> <editor> D. E. Keyes, A. Sameh, and V. Venkatakrishnan, eds., </editor> <address> Norfolk, Va., </address> <year> 1995, </year> <note> Kluwer. To appear. </note>
Reference-contexts: From information available in this reduction, another reduction is computed. This defines the iteration and is deemed successful if improved estimates to the eigenvalues of A appear in the subsequent reductions. A relatively recent variant was developed by Sorensen <ref> [39] </ref> as a more efficient and numerically stable way to implement restarting. This technique, the implicitly restarted Arnoldi iteration (ira iteration), may be viewed as a truncation of the standard implicitly shifted qr-iteration. <p> Then f m = 0 if and only if x 1 2 R (Z m ), where AZ m = Z m T m is a partial real Schur decomposition. Proof. See Chapter 2 of [16] or <ref> [39] </ref> for a proof based on the Jordan canonical form. <p> Within the context of subspace iteration, Stew-art [41] also arrives at the same conclusion. 8. Characterzing an IRA Iteration. We present three theorems that explain the behavoir of an ira iteration in exact arithmetic. The first theorem is a generalization of Lemma 3.10 proved by Sorensen <ref> [39] </ref> and indicates what occurs when a certain choice of shifts is used during an ira iteration. There are two major differences. The first is that there is no assumption on the existence of a basis of eigenvectors for the desired invariant subspace. Only a Schur basis is used. <p> For these two examples, ARPACK reliably computed the multiplicities. Changing WHICH has the effect of modifying the restart parameters. For further information and other experiments, we refer the reader to [17]. 11. Convergence of an IRA Iteration. Sorensen gives a convergence theorem <ref> [39, pages 369-370] </ref> for an ira iteration where the polynomial applied at every restart is fixed.
Reference: [41] <author> G. W. Stewart, </author> <title> Simultaneous iteration for computing invariant subspaces of non-Hermitian matrices, </title> <journal> Numerische Mathematik, </journal> <volume> 25 (1976), </volume> <pages> pp. 123-136. </pages>
Reference-contexts: Golub and Wilkinson [12] examine the many practical difficulties involved when computing invariant subspaces. They conclude that working with Schur vectors is a better behaved numerical process. Within the context of subspace iteration, Stew-art <ref> [41] </ref> also arrives at the same conclusion. 8. Characterzing an IRA Iteration. We present three theorems that explain the behavoir of an ira iteration in exact arithmetic.
Reference: [42] <author> D. S. Watkins, </author> <title> Understanding the QR algorithm, </title> <journal> SIAM Review, </journal> <volume> 24 (1982), </volume> <pages> pp. 427-439. </pages>
Reference-contexts: Q k involves performing p steps of the qr algorithm on the current upper Hessenberg matrix, using the zeros of as shifts to obtain H m Q m = Q m H + m : This allows us to exploit the well-known connection between the qr algorithm and subspace iteration <ref> [42] </ref>.
Reference: [43] <author> D. S. Watkins and L. Elsner, </author> <title> Convergence of algorithms of decomposition type for the eigenvalue problem, Linear Algebra and Its Applications, </title> <booktitle> 143 (1991), </booktitle> <pages> pp. 19-47. </pages>
Reference-contexts: A convergence theory for the shifted qr iteration was presented by Watkins and Elsner <ref> [43] </ref> within the more general framework of generic GR algorithms. <p> See Theorems 5.4 and 6.2 of Watkins and Elsner <ref> [43] </ref>. If we partition the eigenvalues of A so that 1 ; : : :; k are the sought-after eigen values, then () = i=k+1 is an example of the polynomial used by the theorem. <p> The hypothesis on the product of the shifts ensures that if one is applied with a nonzero imaginary part, its complex conjugate is also a shift. The theorems proved by Watkins and Elsner in <ref> [43] </ref> identify the convergence of the qr algorithm with that of simultaneous iteration, or subspace iteration.
References-found: 35

