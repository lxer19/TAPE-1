URL: ftp://ftp.cse.unsw.edu.au/pub/doc/papers/UNSW/9406.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/research/tr.html
Root-URL: http://www.cse.unsw.edu.au
Title: Parallel Approach to High-Speed Protocol Processing  
Author: Toong Shoon Chan and Ian Gorton 
Affiliation: SCHOOL OF COMPUTER SCIENCE AND ENGINEERING THE UNIVERSITY OF NEW SOUTH WALES  
Note: A  
Abstract: SCS&E Report 9406 March, 1994 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> David D. Clark, Van Jacobson, John Romkey, Howard Salwen, </author> <title> "An Analysis of TCP Processing Overhead," </title> <journal> IEEE Commn. Magazine, </journal> <pages> pp. 23-29, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Consequently, several approaches to solve this communication bottleneck have been proposed. The first approach concerns with the optimal implementation of existing protocols, such as TCP and TP4. It has been shown in <ref> [1] </ref> that efficient implementations of TCP for Berkeley BSD Unix can still achieve a relatively high throughput performance. Although this is a feasible approach, careful examination reveals that several mechanisms employed in TCP to ensure reliable transport of data are not suitable for highspeed networks.
Reference: 2. <author> W. Doeringer, D. Dykeman, M. Kaiserswerth, B. Meiser, H. Rudin and R. Williamson, </author> <title> "A Survey of Lightweight Transport Protocols for Highspeed Networks," </title> <journal> IEEE Trans. Commn., </journal> <volume> vol 38, </volume> <pages> pp. 2057-2071, </pages> <month> Nov </month> <year> 1991. </year>
Reference-contexts: The next approach concerns new protocol designs that are suitable for highspeed operation. The key to such design is to minimise protocol processing requirements and consequently improve protocol processing speed. This has led to design of several lightweight protocols <ref> [2, 3] </ref> that are designed to provide highspeed processing by simplifying the protocol operation under normal data transfer phase, without compromising on the functionality to provide reliability of data transfer. Often, these lightweight protocols are designed for ease of implementation in hardware to further speed up in protocol processing.
Reference: 3. <author> A. N. Netravali, W. D. Roome, and K. Sabnani, </author> <title> "Design and Implementation of a High Speed Transport Protocol", </title> <journal> IEEE Trans. on Commn., </journal> <volume> vol. 38, no. 11, </volume> <pages> pp 2010-24, </pages> <month> Nov </month> <year> 1990. </year>
Reference-contexts: The next approach concerns new protocol designs that are suitable for highspeed operation. The key to such design is to minimise protocol processing requirements and consequently improve protocol processing speed. This has led to design of several lightweight protocols <ref> [2, 3] </ref> that are designed to provide highspeed processing by simplifying the protocol operation under normal data transfer phase, without compromising on the functionality to provide reliability of data transfer. Often, these lightweight protocols are designed for ease of implementation in hardware to further speed up in protocol processing.
Reference: 4. <author> G. Chesson, </author> <title> "The Protocol Engine Project," Unix Review, </title> <month> Sept </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: The next approach is concerned with the implementation of protocols on an outboard hardware protocol processor platform. Such implementations can come in the form of dedicated VLSI hardware for a specific protocol <ref> [4] </ref> or using a general multiprocessor platform. The main advantage of a dedicated VLSI hardware solution is the high processing speed achievable and consequently higher throughput performance. However, this advantage is offset by the high cost and difficulty in adapting to changing requirements.
Reference: 5. <author> D. C. Feldmeier, </author> <title> "A Framework of Architecture Concepts for HighSpeed Communication Systems", </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol 11, no. 4, </volume> <month> May </month> <year> 1993. </year>
Reference-contexts: In this 4 paper, we will focus on applying both functional and packet parallelism to protocol processing at transport and presentation layers, which are seen to be the processing bottleneck <ref> [5] </ref>. 3. PROCESSING REQUIREMENTS 3.1 Data and Control Processing Despite the complexity of protocol processing, the entire protocol operation can generally be grouped into two processing functions: data processing and control processing. Data processing is concerned with the transfer of data between communicating end points.
Reference: 6. <author> David D. Clark and David L. Tennenhouse, </author> <title> "Architectural Considerations for a New Generation of Protocols", </title> <booktitle> Proc. ACM SIGCOMM '90, </booktitle> <pages> pp. 200-8, </pages> <address> Philadelphia, PA, </address> <month> Sep </month> <year> 1990. </year>
Reference-contexts: of packet parallelism, since synchronisation between packet and control processors is less frequent. 1 In TCP, an acknowledgment is generated for each received data packet. 5 3.3 Data Ordering Constraints In order to apply packet parallelism to protocol processing, we need to employ the concept of Application Level Framing (ALF) <ref> [6] </ref>. In the OSI protocol layering, each protocol layer appends its own protocol header onto the front of the data unit received from the preceding layer. At the transport layer, data units from the session layer might be segmented into smaller data units suitable for transmission to the network.
Reference: 7. <author> D. C. Feldmeier, </author> <title> "A Survey of High Performance Protocol Implementation Techniques", in High Performance Networks - Technology and Protocols, Chapter 2, </title> <editor> Ahmed Tantawy editor, </editor> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Further, timers are also used to detect failures in communicating connections. On a processor that does not directly support the implementation of timers, the computational overheads in managing these timers can prove to be very high <ref> [7] </ref>. In contrast, the support in Occam for timers greatly simplifies the implementation of timing calculations and consequently results in higher computational efficiency. To protect against the corruption of data messages, cyclic redundancy checking (CRC) is often employed to check on the data integrity.
Reference: 8. <author> T. S. Chan and I. Gorton, </author> <title> "A Transputer-based Implementation of HTPNET: A Transport Protocol for Broadband Networks", </title> <booktitle> in Transputer Applications and Systems '93 Vol 2, Proc. of the 1993 World Transputer Congress, </booktitle> <address> Aachen, Germany, </address> <pages> pp. 889-910, </pages> <publisher> IOS Press, </publisher> <year> 1993. </year>
Reference-contexts: the simple token sequencing mechanism ensures the correct ordering of data is presented to the host, while requiring minimum overhead in synchronising between processors. 9 Transport Processing Presentation Processing Data Packet From Network Data To Host Token In Token Out Processor Node 5.3 State Synchronisation A high-performance transport protocol, HTPNET <ref> [8] </ref>, has been simulated on the proposed architecture. To support functional parallelism, HTPNET employs out-of-band signalling, in which peer-transport entities exchange data and state information using separate packets. A state information packet is exchanged frequently so that the state between the transmitter and receiver is synchronised.
Reference: 9. <author> J. R. </author> <title> Jump, "NETSIM Reference Manual", </title> <institution> Rice Univeristy, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Simulation A simulation of the proposed system has been implemented to evaluate the performance of the architecture. A simulation tool known as NETSIM <ref> [9] </ref> has been used for the simulation of the proposed system. The simulation program is written with the T9000 as the target processor. Before performing the actual simulation, the processes to be simulated on the proposed architecture were written in Occam.
Reference: 10. <author> M. D. May, R. M. Shepherd and P. W. Thompson, </author> <title> "The T9000 Communications Architecture", in Networks, Routers and Transputer, </title> <editor> M. D. May, P. W. Thompson and P. H. Welch (eds.), </editor> <publisher> IOS Press, </publisher> <year> 1993. </year>
Reference-contexts: Although, it is possible to test on a single T800 transputer, the architecture cannot be extended to run on multiple T800 transputers due to the limitation on the number of external links available. However, this limitation has been eliminated with the T9000 transputer and C104 router <ref> [10, 11] </ref>. After verifying the functionality of the program, the Occam processes were translated to equivalent C functions for execution in NETSIM. The C104 router is not simulated, instead, links between processors are connected directly.
Reference: 11. <author> M. Simpson and P. W. Thompson, "DS-Links and C104 Routers", </author> <title> in Networks, Routers and Transputer, </title> <editor> M. D. May, P. W. Thompson and P. H. Welch (eds.), </editor> <publisher> IOS Press, </publisher> <year> 1993. </year>
Reference-contexts: Although, it is possible to test on a single T800 transputer, the architecture cannot be extended to run on multiple T800 transputers due to the limitation on the number of external links available. However, this limitation has been eliminated with the T9000 transputer and C104 router <ref> [10, 11] </ref>. After verifying the functionality of the program, the Occam processes were translated to equivalent C functions for execution in NETSIM. The C104 router is not simulated, instead, links between processors are connected directly.
Reference: 12. <author> R. G. Covington, S. Dwarkadas, J. R. Jump, J. B. Sinclair and S. Madala, </author> <title> "The Efficient Simulation of Parallel Systems", </title> <journal> International Journal in Computer Simulation, </journal> <volume> vol 1, no. 1, </volume> <pages> pp. 31-58, </pages> <year> 1991. </year> <title> 13. "Transputer Reference Manual," </title> <publisher> Prentice Hall, INMOS Limited, </publisher> <year> 1988. </year>
Reference-contexts: Modelling the advancement of simulation time while executing the instructions is achieved by identifying the basic block within each process and applying the necessary delay to 3 The choice of a timeslice period of 5120 cycles is based on the design of T800 transputer [13]. 11 execute these blocks <ref> [12] </ref>. A basic block is defined as a sequence of instructions such that all instructions within that block are executed in sequence until a process interaction point is reached. Some examples of a basic block are shown in Figure 4.
Reference: 14. <author> SGS-THOMSON, </author> <title> "The T9000 Transputer Products Overview Manual", </title> <note> first edition 1991. </note>
Reference-contexts: As expected, due to the faster processor speed, the number of processors required to match the network speed is reduced to about 6 processors. 4 The number of machine cycles required to execute Occam programs is based on the performance figure obtained from <ref> [14] </ref>. 12 N o. of Proce ssors 0 40 80 120 160 200 0 0.2 0.4 0.6 0.8 1 Utilisation Throughput N o. of Proce ssors 0 40 80 120 160 200 0 0.2 0.4 0.6 0.8 1 Utilisation Throughput In the next configuration, the processor speed is set to 50
References-found: 13

