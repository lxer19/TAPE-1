URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-217.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Email: ganguly,leichter,noordewi@cs.rutgers.edu  
Title: Fast Search Methods for Biological Sequence Databases  
Author: Sumit Ganguly Jerry Leichter Michiel Noordewier 
Note: LCSR-TR-217  
Date: October 26, 1993  
Address: New Brunswick, NJ 08903  
Affiliation: Department of Computer Science Hill Center, Busch Campus Rutgers University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S.F. Altschul, W. Gish, W. Miller, E.W Myers, and D. J. Lipman. </author> <title> Basic local alignment search tool. </title> <journal> Journal of Molecular Biology, </journal> <volume> 215 </volume> <pages> 403-410, </pages> <year> 1990. </year>
Reference-contexts: Since the current size of the libraries precludes exhaustive pairwise comparison with a normal query sequence, approximate methods have been developed [24]. Two of the most widely used are FASTP [13], which utilizes a search based on identities but not gaps; and BLAST <ref> [1] </ref>, which employs a more realistic mutation model, but whose implementation requires a direct tradeoff between accuracy and speed. The use of such methods is less desirable than string-edit calculations, which corresponds to known biological mechanisms for the evolution of nucleic acid sequences.
Reference: [2] <author> J. Bentley. </author> <title> Multidimensional binary search trees used for associative searching. </title> <journal> Communications of the ACM, </journal> <volume> 18(9) </volume> <pages> 509-517, </pages> <year> 1975. </year>
Reference-contexts: The studies involve research on accompanying algorithms for storing multidimensional data and solving the nearest neighbor problem. K d trees were originally proposed by Bentley <ref> [2] </ref> and their applicability to nearest neighbor problems is described in another paper co-authored by him [4]. Generally speaking, the nearest neighbor problem is the search for the N nearest points to given a point with respect to a distance measure. The connection to our problem should be obvious.
Reference: [3] <editor> R.F. Doolittle et al. Simian sarcoma virus onc gene, V-sis, </editor> <title> is derived from the gene (or genes) encoding a platelet-derived growth factor. </title> <journal> Science, </journal> <volume> 221 </volume> <pages> 275-277, </pages> <year> 1983. </year>
Reference-contexts: An example of such a relationship was discovered in 1983, when Doolittle and colleagues reported that a newly discovered oncogene was similar to a normal gene for development and growth <ref> [3] </ref>. The idea of using databases to store biological information is not entirely new; they have been used for over 10 years [11]. The development of database concepts has been under way in the computer science community for much longer than a decade.
Reference: [4] <author> J. H. Friedman, J. Bentley, and R. Finkel. </author> <title> An algorithm for finding best matches in logarithmic expected time. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 3(3) </volume> <pages> 209-226, </pages> <year> 1977. </year>
Reference-contexts: The studies involve research on accompanying algorithms for storing multidimensional data and solving the nearest neighbor problem. K d trees were originally proposed by Bentley [2] and their applicability to nearest neighbor problems is described in another paper co-authored by him <ref> [4] </ref>. Generally speaking, the nearest neighbor problem is the search for the N nearest points to given a point with respect to a distance measure. The connection to our problem should be obvious.
Reference: [5] <author> G. H. Gonnet. </author> <title> Handbook of Algorithms and Data Structures. </title> <publisher> Addison-Wesley, </publisher> <address> London, </address> <year> 1984. </year>
Reference-contexts: Structuring the database requires additional work, since newly distributed data must be converted before it can be used, but it has the potential to greatly increase search speeds. An example of adding structure to a sequence database has been reported by Gonnet [6]. Here, patricia trees <ref> [5] </ref> were used to organize a protein sequence database. Patricia trees group data lexicographically, so similar sequences lie near each other in the tree.
Reference: [6] <author> G. H. Gonnet, M. A. Cohen, and S. A. Benner. </author> <title> Exhaustive matching of the entrie protein sequence database. </title> <journal> Science, </journal> <volume> 256 </volume> <pages> 1443-1445, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Structuring the database requires additional work, since newly distributed data must be converted before it can be used, but it has the potential to greatly increase search speeds. An example of adding structure to a sequence database has been reported by Gonnet <ref> [6] </ref>. Here, patricia trees [5] were used to organize a protein sequence database. Patricia trees group data lexicographically, so similar sequences lie near each other in the tree.
Reference: [7] <author> Greg Hamm. </author> <type> personal communication. </type>
Reference-contexts: The original intent of this simple format was to distribute the data in a platform-independent fashion, with the assumption that target systems would structure it accordingly <ref> [7] </ref>. The data collections are therefore more aptly termed data libraries, and are not well-suited for fast retrieval. For example, given a newly discovered sequence, the biologist must scan the entire file to determine whether the sequence string has been found previously.
Reference: [8] <author> P. Klier and R. J. Fateman. </author> <title> On finding the closest bitwise maches in a fixed set. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 17(1) </volume> <pages> 88-97, </pages> <year> 1991. </year>
Reference-contexts: There are several measures of similarity in current use for sequence comparison. One of the simplest is the Hamming distance, which is a count of the number of positions where two sequences differ <ref> [8] </ref>. The most rigorously investigated measure of similarity between two sequences, however, describes similarity in terms of a string edit problem: Find the minimum cost of editing one string into another using a specified set of operations, each of which is assigned an individual cost.
Reference: [9] <author> Donald E. Knuth. </author> <title> The Art of Computer Programming: Sorting and Searching, volume 3. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1973. </year>
Reference-contexts: In the following sections, we discuss each of the three components listed above, and indicate our approach to it. Theory The computer science literature is rich with theoretical studies of what can be included under the general rubric of search algorithms. Some traditional 27 references include <ref> [9] </ref> for a variety of techniques, and [10] for databases. There is active research in such areas as geometric databases [17], distributed databases, database-like languages [12], and many others. While some general principles are known, specific problems impose significant constraints on the set of algorithms which may be appropriate.
Reference: [10] <author> Henry F. Korth and Abraham Silberschatz. </author> <title> Database System Concepts. </title> <publisher> McGraw Hill, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Theory The computer science literature is rich with theoretical studies of what can be included under the general rubric of search algorithms. Some traditional 27 references include [9] for a variety of techniques, and <ref> [10] </ref> for databases. There is active research in such areas as geometric databases [17], distributed databases, database-like languages [12], and many others. While some general principles are known, specific problems impose significant constraints on the set of algorithms which may be appropriate.
Reference: [11] <author> E. S. Lander, R. Langridge, and D. M. Saccocio. </author> <title> Computing in molecular biology: Mapping and interpreting biological information. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 6-13, </pages> <month> November </month> <year> 1991. </year> <month> 31 </month>
Reference-contexts: Modern study of heritable traits is inevitably associated with determination of the DNA sequence by variants of these methods. Sequencing technology is rapidly improving, and by 1994 it is estimated that 1.6 billion base-pairs will be sequenced each year <ref> [11] </ref>. The existence of libraries of DNA sequences allows researchers to attempt to find genes that may be similar to a newly determined sequence. <p> The idea of using databases to store biological information is not entirely new; they have been used for over 10 years <ref> [11] </ref>. The development of database concepts has been under way in the computer science community for much longer than a decade. However, biological problems have not influenced database research until recently. Today, sequence data are collected by several organizations which compile the data and distribute it publicly. <p> At times this search has been performed using simple UNIX utilities such as grep. When one considers that in 1991 GenBank contained more than 44,000 separate sequence entries comprising a total of more than 66 million characters <ref> [11] </ref>, this method appears woefully inadequate. The problems with this simple approach are compounded when the biologist wants to extract not only exact matches, but also similar sequences. There are several measures of similarity in current use for sequence comparison. <p> It has been reported that the rate of discovery of sequence data is increasing 10-fold every 5 years (from 1.5 million nucleotides per year in 1989 to an expected 1.6 billion nucleotides per year in 1999) <ref> [11] </ref>. With this rapid increase in data volume, it is questionable whether advances in computer hardware and parallelization techniques will be able to keep pace. The fundamental problem with the application of more computing power is that nothing is being done to limit the amount of data to be searched.
Reference: [12] <author> Jerrold S. Leichter. </author> <title> Shared tuple memories, shared memories, buses and LAN's | Linda implementations across the spectrum of connectivity. </title> <type> Technical Report TR-714, </type> <institution> Yale University Department of Computer Science, </institution> <month> July </month> <year> 1989. </year> <note> Also a 1989 Yale University PhD thesis. </note>
Reference-contexts: Some traditional 27 references include [9] for a variety of techniques, and [10] for databases. There is active research in such areas as geometric databases [17], distributed databases, database-like languages <ref> [12] </ref>, and many others. While some general principles are known, specific problems impose significant constraints on the set of algorithms which may be appropriate.
Reference: [13] <author> D. J. Lipman and W. R. Pearson. </author> <title> Rapid and sensitive protein similarity searches. </title> <journal> Science, </journal> <volume> 227 </volume> <pages> 1435-1441, </pages> <year> 1985. </year>
Reference-contexts: Since the current size of the libraries precludes exhaustive pairwise comparison with a normal query sequence, approximate methods have been developed [24]. Two of the most widely used are FASTP <ref> [13] </ref>, which utilizes a search based on identities but not gaps; and BLAST [1], which employs a more realistic mutation model, but whose implementation requires a direct tradeoff between accuracy and speed.
Reference: [14] <author> A.M. Maxam and W. Gilbert. </author> <title> A new method of sequencing DNA. </title> <journal> Proc. Natl. Acad. Sci., </journal> <volume> 74 </volume> <pages> 560-564, </pages> <year> 1977. </year>
Reference-contexts: Knowledge of this structure allowed representation of genes as strings of characters corresponding to the arrangement of individual nucleotide bases. * In 1977, two separate laboratories developed methods for rapidly determining the sequence of DNA molecules <ref> [14, 18] </ref>. Modern study of heritable traits is inevitably associated with determination of the DNA sequence by variants of these methods. Sequencing technology is rapidly improving, and by 1994 it is estimated that 1.6 billion base-pairs will be sequenced each year [11].
Reference: [15] <author> P. L. Miller, P. M. Nadkarni, and N. M. Carriero. </author> <title> Parallel computation and FASTA: Confronting the problem of parallel database search for a fast sequence comparison algorithm. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 7(1) </volume> <pages> 71-78, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: More Computing Power Research in this area is most commonly focused on developing methods for running conventional sequence comparison algorithms in parallel. For example, Miller describes an implementation of the FASTA algorithm using the machine-independent parallel programming language, Linda <ref> [15] </ref>. In this parallelized version of FASTA, there are many worker processors, each of which is given a copy of the query sequence and which then compares this with assigned sequences from the database. A master processor oversees the assignment of sequences to processors.
Reference: [16] <author> S.B. Needleman and C.D. Wunsch. </author> <title> A general method applicable to the search for similarities in the amino acid sequences of two proteins. </title> <journal> Journal of Molecular Biology, </journal> <volume> 48:444, </volume> <year> 1970. </year>
Reference-contexts: Nonetheless, string-edit costs and various approximations are currently the most widely used measures for relating biological sequences. Calculating the string edit cost can quite be difficult. The problem has received significant attention, and has inspired the development of several algorithms <ref> [16, 19, 20, 25] </ref>. The existence of these algorithms would seem to satisfy the need for a method to compare and retrieve gene sequences from sequence databases.
Reference: [17] <author> Hanan Samet. </author> <title> Applications of Spatial Data Structures. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1989. </year>
Reference-contexts: Theory The computer science literature is rich with theoretical studies of what can be included under the general rubric of search algorithms. Some traditional 27 references include [9] for a variety of techniques, and [10] for databases. There is active research in such areas as geometric databases <ref> [17] </ref>, distributed databases, database-like languages [12], and many others. While some general principles are known, specific problems impose significant constraints on the set of algorithms which may be appropriate.
Reference: [18] <author> F.S. Sanger, S. Nicklen, and A.R. Couson. </author> <title> DNA sequencing with chain terminating inhibitors. </title> <journal> Proc. Natl. Acad. Sci., </journal> <volume> 74 </volume> <pages> 5463-5467, </pages> <year> 1977. </year>
Reference-contexts: Knowledge of this structure allowed representation of genes as strings of characters corresponding to the arrangement of individual nucleotide bases. * In 1977, two separate laboratories developed methods for rapidly determining the sequence of DNA molecules <ref> [14, 18] </ref>. Modern study of heritable traits is inevitably associated with determination of the DNA sequence by variants of these methods. Sequencing technology is rapidly improving, and by 1994 it is estimated that 1.6 billion base-pairs will be sequenced each year [11].
Reference: [19] <author> David Sankoff. </author> <title> Time warps, string edits, and macromolecules: The theory and practice of string comparison. </title> <year> 1983. </year>
Reference-contexts: Nonetheless, string-edit costs and various approximations are currently the most widely used measures for relating biological sequences. Calculating the string edit cost can quite be difficult. The problem has received significant attention, and has inspired the development of several algorithms <ref> [16, 19, 20, 25] </ref>. The existence of these algorithms would seem to satisfy the need for a method to compare and retrieve gene sequences from sequence databases.
Reference: [20] <author> P. Sellers. </author> <title> Theory and computation of evolutionary distances. </title> <journal> SIAM Journal of Applied Mathematics, </journal> <volume> 26:787, </volume> <year> 1974. </year>
Reference-contexts: Nonetheless, string-edit costs and various approximations are currently the most widely used measures for relating biological sequences. Calculating the string edit cost can quite be difficult. The problem has received significant attention, and has inspired the development of several algorithms <ref> [16, 19, 20, 25] </ref>. The existence of these algorithms would seem to satisfy the need for a method to compare and retrieve gene sequences from sequence databases.
Reference: [21] <author> J. Shavlik, G. Towell, and M. Noordewier. </author> <title> Using artificial neural networks to refine existing biological knowledge. </title> <journal> International Journal of Human Genome Research, </journal> <volume> 1 </volume> <pages> 81-107, </pages> <year> 1992. </year>
Reference: [22] <author> W. Taylor. </author> <title> Sequence analysis: Spinning in hyperspace. </title> <journal> Nature, </journal> <volume> 353 </volume> <pages> 388-389, </pages> <year> 1991. </year>
Reference-contexts: By using this method of database structuring, Gonnet was able to align 2 a database of 8,344,353 nucleotides. Without structuring the data, this had previously been thought impossible; it had been estimated to require more than 106 years of computational time <ref> [22] </ref>. Gonnet, et al were able to perform the computation using only 405 days of computational time without losing any rigor. It should be noted from Gonnet's efforts that structuring the database consumes enormous amounts of time.
Reference: [23] <author> G. Vogt and P. Argos. </author> <title> Profile sequence analysis and database searches on a transputer machine connected to a Macintosh computer. </title> <booktitle> Computer Applications in the Biosciences, </booktitle> <volume> 9(1) </volume> <pages> 25-28, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Several possible approaches to resolve the I/O bottleneck are discussed, such as preloading the database in memory. A similar example of applying more computing power is in work reported by Vogt <ref> [23] </ref>. Here, a personal computer served as a master and I/O server and was used to drive multiple transputers 1 which did the sequence comparison. <p> Substantially increasing I/O rates, given current and forseeable technology, is a more difficult and considerably more expensive undertaking than increasing CPU speed or parallelism. 1 Transputers are microprocessors designed to act as parallel function units in easily extensible computers of any size <ref> [23] </ref>. 7 Structuring the Database The basic idea of our approach is to structure sequence databases so that the data within the database should be stored in a manner which obviates the need to search the entire database.
Reference: [24] <author> M. S. Waterman. </author> <title> General methods of sequence comparison. </title> <journal> Bulletin of Mathematical Biology, </journal> <volume> 46(4) </volume> <pages> 473-500, </pages> <year> 1984. </year>
Reference-contexts: Since the current size of the libraries precludes exhaustive pairwise comparison with a normal query sequence, approximate methods have been developed <ref> [24] </ref>. Two of the most widely used are FASTP [13], which utilizes a search based on identities but not gaps; and BLAST [1], which employs a more realistic mutation model, but whose implementation requires a direct tradeoff between accuracy and speed. <p> As an example, the availability of separate indices for differing edit costs for basic string edit is particularly attractive. Waterman <ref> [24] </ref> cites the example of a search which misses the desired sequence because of an unfortunate 11 selection of gap and replacement weights in the basic alignment algorithm. Multiple indices for different selections of these parameters would reduce the chance of missing such biologically related examples. <p> In addition, indices may be constructed which facilitate the search for genes in uncharacterized sequence data now being produced by the various genome projects. In particular, indices could be constructed which correspond to the use of the "regions" method of comparing sequences <ref> [24] </ref>. This would allow conjunctive queries which quickly scanned a sequence database for the presence of multiple small regions. Such regions could be those which correspond to control regions required for gene expression. Schematically, we envision the final index scheme as depicted in Figure 3. <p> Only the remaining sequences need actually be compared to the query. Central to our approach is the observation that the most widely used comparison methods for genetic sequences, while often viewed as defining a similarity measure, can equivalently be used to defined distance measures, or metrics. (Waterman <ref> [24] </ref> discusses the equivalence of similarity measures and metrics.) Metrics satisfy the triangle inequality, which allows us to use reference strings 4 to partition the database: The triangle inequality says, in effect, that "closeness is preserved"; for example, if the query is "close" to 4 We use "string" when referring to
Reference: [25] <author> M.S. Waterman, T.F. Smith, </author> <title> and W.A. Beyer. Some biological sequence metrics. </title> <institution> Adv. Math., 20:367, </institution> <year> 1976. </year>
Reference-contexts: Nonetheless, string-edit costs and various approximations are currently the most widely used measures for relating biological sequences. Calculating the string edit cost can quite be difficult. The problem has received significant attention, and has inspired the development of several algorithms <ref> [16, 19, 20, 25] </ref>. The existence of these algorithms would seem to satisfy the need for a method to compare and retrieve gene sequences from sequence databases.
Reference: [26] <author> J.D. Watson and F.H.C. Crick. </author> <title> Molecular structure of nucleic acids: A structure for deoxyribose nucleic acid. </title> <journal> Nature, </journal> <volume> 171 </volume> <pages> 737-738, </pages> <year> 1953. </year> <month> 33 </month>
Reference-contexts: This follows from two landmark discoveries: * In 1953, Watson and Crick discovered the molecular structure of DNA, which explained the fine structure of genetic material <ref> [26] </ref>. Knowledge of this structure allowed representation of genes as strings of characters corresponding to the arrangement of individual nucleotide bases. * In 1977, two separate laboratories developed methods for rapidly determining the sequence of DNA molecules [14, 18].
References-found: 26

