URL: ftp://ftp.cs.toronto.edu/pub/kbms/cbr-ilp96.ps.Z
Refering-URL: http://www.cs.utoronto.ca/~juris/myp.html
Root-URL: 
Email: email: juris@ai.utoronto.ca  
Phone: Tel.: (416) 978-7589,  
Title: Inductive Learning and Case-Based Reasoning  
Author: Igor Jurisica 
Address: M5S 1A4  
Affiliation: Department of Computer Science University of Toronto, Toronto, ONT  
Abstract: This paper describes an application of an inductive learning techniques to case-based reasoning. We introduce two main forms of induction, define case-based reasoning and present a combination of both. The evaluation of the proposed system, called TA3, is carried out on a classification task, namely character recognition. We show how inductive knowledge improves knowledge representation and in turn flexibility of the system, its performance (in terms of classification accuracy) and its scalability. 
Abstract-found: 1
Intro-found: 1
Reference: [AB94] <author> Aha, D. W. and Bankert, R. L. </author> <title> Feature selection for case-based classification of cloud types: An empirical comparison. </title> <booktitle> In AAAI-94 Workshop on Case-Based Reasoning, </booktitle> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: There are several possible scenarios for creating the initial context. Their advantages/disadvantages depend on the actual implementation, as discussed in [JG96,JMG96]. Using context allows for diminishing the problem of instance-based learning algorithms <ref> [AB94] </ref>, namely performance degradation with increased number of irrelevant attributes. Pattern discovery in TA3 involves collecting cases sharing some features, for example using an IVF case [JS95], all women that have pregnancy with complications are in their third or fourth cycle.
Reference: [Aha92] <author> Aha, D. W. </author> <title> Generalizing from case studies: A case study. </title> <booktitle> In Proc. of the 9 th International Conference on Machine Learning, </booktitle> <pages> pages 1-10, </pages> <address> Aberdeen, Scotland, </address> <year> 1992. </year>
Reference: [AIS93] <author> Agrawal, R., Imielinski, T., and Swami, A. </author> <title> Database mining: A performance perspective. </title> <journal> IEEE Transactions on Knowledge and Data Engineering. Special issue on Learning and Discovery in Knowledge Based Databases, </journal> <volume> 5(6) </volume> <pages> 914-925, </pages> <year> 1993. </year>
Reference-contexts: T specifies the percentage of cases that have to be relevant in order to accept particular context. The task is to find the minimal context which satisfies the given threshold T. The algorithm uses factor analysis [Har76], discriminant analysis [Lac75] and is similar to the CDP algorithm <ref> [AIS93] </ref> as described in [JMGSC96]. The system uses factor analysis [Har76] to locate relevant attributes (characteristic features). Factor analysis is a statistical technique used to identify a reasonable small number of factors that can be used to represent relationships among sets of interrelated variables.
Reference: [FS91] <author> Frey, P. W. and Slate, D. J. </author> <title> Letter recognition using Holland-style adaptive classifiers. </title> <booktitle> Machine Learning,6(2), </booktitle> <year> 1991. </year>
Reference-contexts: If the system is supposed to generate classes then we use the term (conceptual) clustering [SM86]. Various techniques have been utilized for the classification task, including neural networks [SMT91], genetic algorithms <ref> [FS91] </ref>, inductive and instance-based learning [Tur95,SG95] and case-based reasoning [PBH90,AB94]. Individual approaches are comparable based on the method they deploy, the accuracy they achieve and the complexity of the algorithm used. Classification rules are usually extracted from training examples during a learning process.
Reference: [Gaa91] <author> Gaasterland, T. </author> <title> Restricting query relaxation through user constraints. </title> <booktitle> In Proc. on International Conference on Intelligent and Cooperative Information Systems, </booktitle> <pages> pages 359-366, </pages> <address> Rotterdam, The Netherlands, </address> <year> 1993. </year>
Reference: [GB95] <author> Griffiths, A. D. and Bridge, D. G. </author> <title> Inductive bias in case-based reasoning systems. </title> <type> Technical Report YCS 95/259, </type> <institution> University of York, </institution> <address> York, UK, </address> <year> 1995. </year>
Reference: [Har76] <author> Harman, H. </author> <title> Modern Factor Analysis. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, IL, </address> <year> 1976. </year> <month> 6 </month>
Reference-contexts: T specifies the percentage of cases that have to be relevant in order to accept particular context. The task is to find the minimal context which satisfies the given threshold T. The algorithm uses factor analysis <ref> [Har76] </ref>, discriminant analysis [Lac75] and is similar to the CDP algorithm [AIS93] as described in [JMGSC96]. The system uses factor analysis [Har76] to locate relevant attributes (characteristic features). <p> The task is to find the minimal context which satisfies the given threshold T. The algorithm uses factor analysis <ref> [Har76] </ref>, discriminant analysis [Lac75] and is similar to the CDP algorithm [AIS93] as described in [JMGSC96]. The system uses factor analysis [Har76] to locate relevant attributes (characteristic features). Factor analysis is a statistical technique used to identify a reasonable small number of factors that can be used to represent relationships among sets of interrelated variables.
Reference: [Jan94] <author> Jantke, K. P. </author> <title> Nonstandard concepts of similarity in case-based reasoning. </title> <booktitle> In Proc. of the 17 th Annual Conference of the Gesellschaft fur Klassifikation., </booktitle> <address> Kaiserslautern, </address> <publisher> Springer Verlag, </publisher> <year> 1994. </year>
Reference: [JG95] <author> Jurisica, I. and Glasgow, J. </author> <title> Applying case-based reasoning to control in robotics. </title> <booktitle> In 3 rd Robotics and Knowledge-Based Systems Workshop, </booktitle> <address> St. Hubert, Quebec, </address> <year> 1995. </year>
Reference-contexts: Similarly, in [JG95,JS95] we report on how TA3s representation scheme, context-based similarity assessment and inductive learning allow for flexible computation. By giving or limiting computational resources in <ref> [JG95] </ref> the precision of the results is controlled if enough time is available for computation, more accurate result can be returned.
Reference: [JG96] <author> Jurisica, I. and Glasgow, J. </author> <title> Case-based classification using relevance assessment in the TA3 system.1996. </title> <note> Submitted. </note>
Reference: [JMG96] <author> Jurisica, I., Mylopoulos, J. and Glasgow, J. </author> <title> Performance analysis of an incremental algorithm for the CBR system. </title> <note> 1996. Submitted. </note>
Reference: [JMGSC96] <author> Jurisica, I., Mylopoulos, J., Glasgow, J., Shapiro, H. and Casper, </author> <title> R.F. Case-based reasoning in IVF: Prediction and knowledge mining. </title> <journal> AI in Medicine. </journal> <note> Special issue on CBR in Medicine , 1996. Submitted. </note>
Reference-contexts: The task is to find the minimal context which satisfies the given threshold T. The algorithm uses factor analysis [Har76], discriminant analysis [Lac75] and is similar to the CDP algorithm [AIS93] as described in <ref> [JMGSC96] </ref>. The system uses factor analysis [Har76] to locate relevant attributes (characteristic features). Factor analysis is a statistical technique used to identify a reasonable small number of factors that can be used to represent relationships among sets of interrelated variables.
Reference: [JS95] <author> Jurisica, I. and Shapiro, H. </author> <title> A computer model for case-based reasoning in IVF. </title> <booktitle> In The 51 st Conference of the American Society for Reproductive Medicine , Seattle, </booktitle> <address> Washington, </address> <year> 1995. </year>
Reference-contexts: Their advantages/disadvantages depend on the actual implementation, as discussed in [JG96,JMG96]. Using context allows for diminishing the problem of instance-based learning algorithms [AB94], namely performance degradation with increased number of irrelevant attributes. Pattern discovery in TA3 involves collecting cases sharing some features, for example using an IVF case <ref> [JS95] </ref>, all women that have pregnancy with complications are in their third or fourth cycle. However, the pattern identification is not sufficient patterns need to be described: given a set of cases labeled by class.
Reference: [Jur94] <author> Jurisica, I. </author> <title> How to retrieve relevant information?. </title> <booktitle> In. Proc. of the AAAI Fall Symposium Series on Relevance., </booktitle> <address> New Orleans, </address> <publisher> Louisiana, </publisher> <pages> pp 101104, </pages> <year> 1994. </year> <note> Extended version available as the Technical Report, DKBS-TR 94-5, </note> <institution> University of Toronto, Department of Computer Science. </institution>
Reference-contexts: Cases in TA3 are represented as structured objects with relations [MBJK90]. Thus, a case is a finite set of attribute/value pairs with relations defined both between individual attributes and between cases. In addition, attributes can be grouped into one or more categories <ref> [Jur94] </ref>. This grouping allows for ascribing different constraints to different groups of attributes, based on their relevancy to a given problem. It allows for more flexible reasoning as well as for more comprehensible presentation of complex information.
Reference: [Jur95] <author> Jurisica, I. </author> <title> A similarity-based retrieval tool for software repositories. </title> <booktitle> In The 3 rd Workshop on AI and Software Engineering: Breaking the Mold. IJCAI-95 , Montreal, </booktitle> <address> Quebec, </address> <year> 1995. </year>
Reference: [Kok95] <author> Kokeny, T. </author> <title> Constraint satisfaction problems with ordersorted domains. </title> <journal> International Journal on Artificial Intelligence Tools. </journal> <volume> Vol. 4, </volume> <pages> Nos. 1-2, pp. </pages> <address> 55--72, </address> <year> 1995. </year>
Reference: [Kol93] <author> Kolodner, J. L. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Clustering problem arises when several objects or situations are presented to a learner and the task is to find classes that group objects usefully. A case-based reasoning <ref> [Kol93] </ref> relies on the idea that similar problems have similar solutions. Facing a new problem, a case-based system retrieves similar cases stored in a case base and adapts them to fit the problem at hand.
Reference: [Lac75] <author> Lachenbruch, P. </author> <title> Discriminant Analysis. </title> <publisher> Hafner Press, </publisher> <address> New York, NY, </address> <year> 1975. </year>
Reference-contexts: T specifies the percentage of cases that have to be relevant in order to accept particular context. The task is to find the minimal context which satisfies the given threshold T. The algorithm uses factor analysis [Har76], discriminant analysis <ref> [Lac75] </ref> and is similar to the CDP algorithm [AIS93] as described in [JMGSC96]. The system uses factor analysis [Har76] to locate relevant attributes (characteristic features).
Reference: [MBJK90] <author> Mylopoulos, J., Borgida, A., Jarke, M., and Koubarakis, M. </author> <title> Telos: Representing knowledge about information systems. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(4) </volume> <pages> 325-362, </pages> <year> 1990. </year>
Reference-contexts: In general, a case corresponds to a problem, solution and feedback. Cases in TA3 are represented as structured objects with relations <ref> [MBJK90] </ref>. Thus, a case is a finite set of attribute/value pairs with relations defined both between individual attributes and between cases. In addition, attributes can be grouped into one or more categories [Jur94].
Reference: [MCM86] <editor> Michalski, R., Carbonell, J., and Mitchell, T., editors. </editor> <booktitle> Machine Learning. An artificial intelligence approach, </booktitle> <volume> Volume 2. </volume> <publisher> Morgan Kaufmann Publishers, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: 1. Introduction Inductive learning is a process of generalizing specific facts or observations <ref> [MCM86] </ref>. It is a basic strategy by which one can acquire knowledge. There are two main forms associated with inductive learning: 1. Instance-to-class induction, where the learning system is presented with independent instances, representing class and the task is to induce a general description of the class. 2.
Reference: [Ort95] <author> Ortega, J. </author> <year> (1995). </year> <title> On the informativeness of the DNA promoter sequences domain theory. </title> <journal> Journal of Artificial Intelligence Research , 2 </journal> <pages> 361-367. </pages> <note> Research Note. </note>
Reference-contexts: However, the pattern identification is not sufficient patterns need to be described: given a set of cases labeled by class. In <ref> [Ort95] </ref> it was shown that m_of_n matches allow for improved performance if m is reasonably selected. Our approach of representing cases as sets of categories, each comprising a set of tuples, allows for multiple levels of m_of_n matching. <p> The data set consists of 20,000 instances, described by 17 attributes. Based on simple cross-validation, the basic TA3 system achieved comparable classification accuracy to other systems. Attributes were grouped into categories for selective cardinality relaxation/restriction, i.e., selective m_of_n matching <ref> [Ort95] </ref>. We have tested several relaxation strategies and attribute-grouping approaches that yielded various accuracy results, using 95% confidence intervals. We have also tested the effect of the case base size on the classification accuracy achieved for individual situations.
Reference: [PBH90] <author> Porter, B. W., Bareiss, E., and Holte, R.C. </author> <year> (1989). </year> <title> Knowledge acquisition and heuristic classification in weak-theory domains. </title> <type> Technical Report AI89-96, </type> <institution> AI Laboratory, University of Texas, Austin. </institution>
Reference: [SG95] <author> Schuurmans, D. and Greiner, R. </author> <title> Learning to classify incomplete examples. In Computational Learning Theory and Natural Learning Systems: </title> <publisher> Addressing Real World Tasks . MIT Press, </publisher> <year> 1995. </year>
Reference: [SM86] <author> Stepp, R. E., Michalski, </author> <title> R.S. Conceptual clustering: Inventing goal-oriented classifications of structured objects. </title> <booktitle> In [MCM-86], </booktitle> <pages> pp. 471-498, </pages> <year> 1986. </year>
Reference-contexts: If the system is supposed to generate classes then we use the term (conceptual) clustering <ref> [SM86] </ref>. Various techniques have been utilized for the classification task, including neural networks [SMT91], genetic algorithms [FS91], inductive and instance-based learning [Tur95,SG95] and case-based reasoning [PBH90,AB94]. Individual approaches are comparable based on the method they deploy, the accuracy they achieve and the complexity of the algorithm used.
Reference: [SMT91] <author> Shavlik, J., Mooney, R., and Towell, G. </author> <title> Symbolic and neural learning algorithms - An experimental comparison. </title> <journal> Machine Learning, </journal> <volume> 6(2) </volume> <pages> 111-143, </pages> <year> 1991. </year>
Reference-contexts: If the system is supposed to generate classes then we use the term (conceptual) clustering [SM86]. Various techniques have been utilized for the classification task, including neural networks <ref> [SMT91] </ref>, genetic algorithms [FS91], inductive and instance-based learning [Tur95,SG95] and case-based reasoning [PBH90,AB94]. Individual approaches are comparable based on the method they deploy, the accuracy they achieve and the complexity of the algorithm used. Classification rules are usually extracted from training examples during a learning process.
Reference: [THNG90] <author> Thagard, P. R., Holyoak, K. J., Nelson, G., and Gotchfeld, D. </author> <title> Analog retrieval by constraint satisfaction. </title> <booktitle> Artificial Intelligence , 46 </booktitle> <pages> 259-310, </pages> <year> 1990. </year>
Reference: [Tur95] <author> Turney, P. D. </author> <title> Costsensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm. </title> <journal> Journal of Artificial Intelligence Research , 2 </journal> <pages> 369-409, </pages> <year> 1995. </year>
References-found: 27

