URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-459.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Keyword: A Bayesian Computer Vision System for Modeling Human Interactions  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 459 Presented at CVPR'98, Workshop on Interpretation of Visual Motion To Appear in Proceedings of ICVS'99, January 99, Gran Canaria, Spain Abstract We describe a real-time computer vision and machine learning system for modeling and recognizing human behaviors in a visual surveillance task. The system is particularly concerned with detecting when interactions between people occur, and classifying the type of interaction. Examples of interesting interaction behaviors include following another person, altering one's path to meet another, and so forth. Our system combines top-down with bottom-up information in a closed feedback loop, with both components employing a statistical Bayesian approach. We propose and compare two different state-based learning architectures, namely HMMs and CHMMs, for modeling behaviors and interactions. The CHMM model is shown to work much more efficiently and accurately. Finally, to deal with the problem of limited training data, a synthetic `Alife-style' training system is used to develop flexible prior models for recognizing human interactions. We demonstrate the ability to use these a priori models to accurately classify real human behaviors and interactions with no additional tuning or training. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.K. </author> <title> Bajcsy. Active perception vs. passive perception. </title> <booktitle> In CVWS85, </booktitle> <pages> pages 55-62, </pages> <year> 1985. </year>
Reference-contexts: Finally a summary of the CHMM formulation is presented in the appendix. 2 System Overview Our system employs a static camera with wide field-of-view watching a dynamic outdoor scene (the extension to an active camera <ref> [1] </ref> is straightforward and planned for the next version). A real-time computer vision system segments moving objects from the learned scene.
Reference: [2] <author> A. Bobick and R. Bolles. </author> <title> The representation space paradigm of concurrent evolving object descriptions. </title> <journal> PAMI, </journal> <pages> pages 146-156, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: We use 2-D blob features for modeling each pedestrian. The notion of "blobs" as a representation for image features has a long history in computer vision <ref> [19, 15, 2, 25, 18] </ref>, and has had many different mathematical definitions. In our usage it is a compact set of pixels that share some visual properties that are not shared by the surrounding pixels.
Reference: [3] <author> A.F. Bobick. </author> <title> Computers seeing action. </title> <booktitle> In Proceedings of BMVC, </booktitle> <volume> volume 1, </volume> <pages> pages 13-22, </pages> <year> 1996. </year>
Reference: [4] <author> Matthew Brand. </author> <title> Coupled hidden markov models for modeling interacting processes. </title> <note> Submitted to Neural Computation, </note> <month> November </month> <year> 1996. </year>
Reference-contexts: Graphical models [6], such as Hidden Markov Models (HMMs) [21] and Coupled Hidden Markov Models (CHMMs) <ref> [5, 4] </ref>, seem most appropriate for modeling and classifying human behaviors because they offer dynamic time warping, a well-understood training algorithm, and a clear Bayesian semantics for both individual (HMMs) and interacting or coupled (CHMMs) generative processes. <p> In those cases approximation techniques are needed ([22, 12, 23, 24]). However, it is also known that there exists an exact solution for the case of 2 interacting chains, as it is our case <ref> [22, 4] </ref>. We therefore use two Coupled Hidden Markov Models (CHMMs) for modeling two interacting processes, in our case they correspond to individual humans. In this architecture state chains are coupled via matrices of conditional probabilities modeling causal (temporal) influences between their hidden state variables. <p> We direct the reader to <ref> [4] </ref> for a more detailed description of the MAP estimation in CHMMs. Coming back to our problem of modeling human behaviors, two persons (each modeled as a generative process) may interact without wholly determining each others' behavior. <p> This fact is specially important, given the limited amount of training data available. Acknowledgments We would like to sincerely thank Michael Jordan, Tony Jebara and Matthew Brand for their inestimable help and insightful comments. Appendix A: Forward (ff) and Backward (fi) expressions for CHMMs In <ref> [4] </ref> a deterministic approximation for maximum a posterior (MAP) state estimation is introduced.
Reference: [5] <author> Matthew Brand, Nuria Oliver, and Alex Pent-land. </author> <title> Coupled hidden markov models for complex action recognition. </title> <booktitle> In In Proceedings of IEEE CVPR97, </booktitle> <year> 1996. </year>
Reference-contexts: Graphical models [6], such as Hidden Markov Models (HMMs) [21] and Coupled Hidden Markov Models (CHMMs) <ref> [5, 4] </ref>, seem most appropriate for modeling and classifying human behaviors because they offer dynamic time warping, a well-understood training algorithm, and a clear Bayesian semantics for both individual (HMMs) and interacting or coupled (CHMMs) generative processes.
Reference: [6] <author> W.L. Buntine. </author> <title> Operations for learning with graphical models. </title> <journal> Journal of Artificial Intelligence Research, </journal> <year> 1994. </year>
Reference-contexts: We have pursued a Bayesian approach to modeling that includes both prior knowledge and evidence from data, believing that the Bayesian approach provides the best framework for coping with small data sets and novel behaviors. Graphical models <ref> [6] </ref>, such as Hidden Markov Models (HMMs) [21] and Coupled Hidden Markov Models (CHMMs) [5, 4], seem most appropriate for modeling and classifying human behaviors because they offer dynamic time warping, a well-understood training algorithm, and a clear Bayesian semantics for both individual (HMMs) and interacting or coupled (CHMMs) generative processes.
Reference: [7] <author> W.L. Buntine. </author> <title> A guide to the literature on learning probabilistic networks from data. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <year> 1996. </year>
Reference-contexts: Statistical directed acyclic graphs (DAGs) or probabilistic inference networks (PINs) <ref> [7, 13] </ref> can provide a computationally efficient solution to these problems. HMMs and their extensions, such as CHMMs, can be viewed as a particular, simple case of temporal PIN or DAG.
Reference: [8] <author> Hilary Buxton and Shaogang Gong. </author> <title> Advanced visual surveillance using bayesian networks. </title> <booktitle> In International Conference on Computer Vision, </booktitle> <address> Cambridge, Massachusetts, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The system is particularly concerned with detecting when interactions between people occur, and classifying the type of interaction. Over the last decade there has been growing interest within the computer vision and machine learning communities in the problem of analyzing human behavior in video ([10],[3],[20], <ref> [8] </ref>, [17], [14],[9], [11]).
Reference: [9] <author> C. Castel, L. Chaudron, and C. Tessier. </author> <title> What is going on? a high level interpretation of sequences of images. </title> <booktitle> In Proceedings of the workshop on conceptual descriptions from images, ECCV, </booktitle> <pages> pages 13-27, </pages> <year> 1996. </year>
Reference: [10] <author> T. Darrell and A. Pentland. </author> <title> Active gesture recognition using partially observable markov decision processes. </title> <note> In ICPR96, page C9E.5, </note> <year> 1996. </year>
Reference: [11] <author> J.H. Fernyhough, A.G. Cohn, </author> <title> and D.C. Hogg. Building qualitative event models automatically from visual input. </title> <booktitle> In ICCV98, </booktitle> <pages> pages 350-355, </pages> <year> 1998. </year>
Reference-contexts: The system is particularly concerned with detecting when interactions between people occur, and classifying the type of interaction. Over the last decade there has been growing interest within the computer vision and machine learning communities in the problem of analyzing human behavior in video ([10],[3],[20], [8], [17], [14],[9], <ref> [11] </ref>).
Reference: [12] <author> Zoubin Ghahramani and Michael I. Jordan. </author> <title> Factorial hidden Markov models. </title> <editor> In David S. Touret-zky, Michael C. Mozer, and M.E. Hasselmo, editors, </editor> <booktitle> NIPS, volume 8, </booktitle> <address> Cambridge, MA, </address> <year> 1996. </year> <month> MITP. </month>
Reference: [13] <author> David Heckerman. </author> <title> A tutorial on learning with bayesian networks. </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research, Redmond, Washing-ton, </institution> <year> 1995. </year> <note> Revised June 96. </note>
Reference-contexts: Statistical directed acyclic graphs (DAGs) or probabilistic inference networks (PINs) <ref> [7, 13] </ref> can provide a computationally efficient solution to these problems. HMMs and their extensions, such as CHMMs, can be viewed as a particular, simple case of temporal PIN or DAG.
Reference: [14] <author> T. Huang, D. Koller, J. Malik, G. Ogasawara, B. Rao, S. Russel, and J. Weber. </author> <title> Automatic symbolic traffic scene analysis using belief networks. </title> <booktitle> pages 966-972. Proceedings 12th National Conference in AI, </booktitle> <year> 1994. </year>
Reference: [15] <author> R. Kauth, A. Pentland, and G. Thomas. Blob: </author> <title> An unsupervised clustering approach to spatial preprocessing of mss imagery. </title> <booktitle> In 11th Int'l Symp. on Remote Sensing of the Environment, </booktitle> <address> Ann Harbor MI, </address> <year> 1977. </year>
Reference-contexts: We use 2-D blob features for modeling each pedestrian. The notion of "blobs" as a representation for image features has a long history in computer vision <ref> [19, 15, 2, 25, 18] </ref>, and has had many different mathematical definitions. In our usage it is a compact set of pixels that share some visual properties that are not shared by the surrounding pixels.
Reference: [16] <author> B. Moghaddam and A. Pentland. </author> <title> Probabilistic visual learning for object detection. </title> <booktitle> In ICCV95, </booktitle> <pages> pages 786-793, </pages> <year> 1995. </year>
Reference-contexts: Therefore, by comput image and input image with blob bounding boxes ing and thresholding the Euclidean distance (distance from feature space DFFS <ref> [16] </ref>) between the input image and the projected image we can detect the moving objects present in the scene: D i = jI i B i j &gt; t, where t is a given threshold.
Reference: [17] <author> H.H. Nagel. </author> <title> From image sequences towards conceptual descriptions. </title> <journal> IVC, </journal> <volume> 6(2) </volume> <pages> 59-74, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: The system is particularly concerned with detecting when interactions between people occur, and classifying the type of interaction. Over the last decade there has been growing interest within the computer vision and machine learning communities in the problem of analyzing human behavior in video ([10],[3],[20], [8], <ref> [17] </ref>, [14],[9], [11]).
Reference: [18] <author> N. Oliver, F. Berard, and A. Pentland. Lafter: </author> <title> Lips and face tracking. </title> <booktitle> In IEEE International Conference on Computer Vision and Pattern Recognition (CVPR97), </booktitle> <address> S.Juan, Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: We use 2-D blob features for modeling each pedestrian. The notion of "blobs" as a representation for image features has a long history in computer vision <ref> [19, 15, 2, 25, 18] </ref>, and has had many different mathematical definitions. In our usage it is a compact set of pixels that share some visual properties that are not shared by the surrounding pixels.
Reference: [19] <author> A. Pentland. </author> <title> Classification by clustering. </title> <booktitle> In IEEE Symp. on Machine Processing and Remotely Sensed Data, Purdue, IN, </booktitle> <year> 1976. </year>
Reference-contexts: We use 2-D blob features for modeling each pedestrian. The notion of "blobs" as a representation for image features has a long history in computer vision <ref> [19, 15, 2, 25, 18] </ref>, and has had many different mathematical definitions. In our usage it is a compact set of pixels that share some visual properties that are not shared by the surrounding pixels.
Reference: [20] <author> A. Pentland and A. Liu. </author> <title> Modeling and prediction of human behavior. </title> <booktitle> In DARPA97, </booktitle> <pages> page 201 206, </pages> <year> 1997. </year>
Reference: [21] <author> Lawrence R. Rabiner. </author> <title> A tutorial on hidden markov models and selected applications in speech recognition. </title> <journal> PIEEE, </journal> <volume> 77(2) </volume> <pages> 257-285, </pages> <year> 1989. </year>
Reference-contexts: We have pursued a Bayesian approach to modeling that includes both prior knowledge and evidence from data, believing that the Bayesian approach provides the best framework for coping with small data sets and novel behaviors. Graphical models [6], such as Hidden Markov Models (HMMs) <ref> [21] </ref> and Coupled Hidden Markov Models (CHMMs) [5, 4], seem most appropriate for modeling and classifying human behaviors because they offer dynamic time warping, a well-understood training algorithm, and a clear Bayesian semantics for both individual (HMMs) and interacting or coupled (CHMMs) generative processes.
Reference: [22] <author> Lawrence K. Saul and Michael I. Jordan. </author> <title> Boltzmann chains and hidden Markov models. </title> <editor> In Gary Tesauro, David S. Touretzky, and T.K. Leen, editors, </editor> <booktitle> NIPS, volume 7, </booktitle> <address> Cambridge, MA, </address> <year> 1995. </year> <month> MITP. </month>
Reference-contexts: In those cases approximation techniques are needed ([22, 12, 23, 24]). However, it is also known that there exists an exact solution for the case of 2 interacting chains, as it is our case <ref> [22, 4] </ref>. We therefore use two Coupled Hidden Markov Models (CHMMs) for modeling two interacting processes, in our case they correspond to individual humans. In this architecture state chains are coupled via matrices of conditional probabilities modeling causal (temporal) influences between their hidden state variables.
Reference: [23] <author> Padhraic Smyth, David Heckerman, and Michael Jordan. </author> <title> Probabilistic independence networks for hidden Markov probability models. AI memo 1565, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> Feb </month> <year> 1996. </year>
Reference: [24] <author> C. Williams and G. E. Hinton. </author> <title> Mean field networks that learn to discriminate temporally distorted strings. </title> <booktitle> In Proceedings, connectionist models summer school, </booktitle> <pages> pages 18-22, </pages> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [25] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <booktitle> In Photonics East, SPIE, </booktitle> <volume> volume 2615, </volume> <year> 1995. </year> <pages> Bellingham, </pages> <address> WA. </address>
Reference-contexts: We use 2-D blob features for modeling each pedestrian. The notion of "blobs" as a representation for image features has a long history in computer vision <ref> [19, 15, 2, 25, 18] </ref>, and has had many different mathematical definitions. In our usage it is a compact set of pixels that share some visual properties that are not shared by the surrounding pixels.
Reference: [26] <author> C.R. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 19(7) </volume> <pages> 780-785, </pages> <month> July </month> <year> 1997. </year>
Reference-contexts: This motion mask is the input to a connected component algorithm that produces blob descriptions that characterize each person's shape. We have also experimented with modeling the background by using a mixture of Gaussian distributions at each pixel, as in Pfinder <ref> [26] </ref>. However we finally opted for the eigenbackground method because it offered good re sults and less computational load. 3.2 Tracking The trajectories of each blob are computed and saved into a dynamic track memory.
References-found: 26

