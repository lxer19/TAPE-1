URL: ftp://iridia.ulb.ac.be/pub/dorigo/bookchapters/BC.03-WORLD98.ps.gz
Refering-URL: http://iridia.ulb.ac.be/dorigo/pub_x_subj.html
Root-URL: 
Email: colombet@elet.polimi.it  mdorigo@ulb.ac.be  
Title: EVOLUTIONARY COMPUTATION IN BEHAVIOR ENGINEERING  
Author: Marco Colombetti Marco Dorigo 
Address: Milano, Italy  Bruxelles, Belgium  
Affiliation: IRIDIA Universit Libre de Bruxelles  Progetto di intelligenza artificiale e robotica Dipartimento di elettronica e informazione Politecnico di Milano  IRIDIA Universit Libre de Bruxelles  
Note: To appear in: Evolutionary Computation: Theory and Applications, X. Yao (Ed.), World Scientific Publ. Co., Singapore, in press.  
Pubnum: TR/IRIDIA/1996-1  
Abstract: In the last few years we have used A LECSYS, a parallel learning classifier system based on the genetic algorithm, to develop behavioral modules for mobile robots, both simulated and real. In this paper we briefly report on our experience, and then reflect on various concepts stemming from the application of evolutionary computation to agent building. We propose a definition of agent, analyze the relationships holding between an agent and its external environment, and discuss some important similarities and differences between natural and artificial systems; in particular, we compare the concept of fitness of an organism with that of quality of an artifact. We then concentrate on adaptation, regarded as a basic process for the development of both biological organisms and artificial agents. We carry on our analysis trying to understand where and how Behavior Engineering (i.e., the discipline concerned with the development of artificial agents) might profit from the use of evolutionary strategies. We argue that an evolutionary approach might allow us to search the space of nonrational design, thus opening a whole new world of possibilities for the implementation of artificial systems.
Abstract-found: 1
Intro-found: 1
Reference: <author> Asimov, I. </author> <year> (1950). </year> <title> I, Robot. </title> <publisher> Gnome Press. </publisher>
Reference: <author> Brooks, R.A. </author> <year> (1991). </year> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 (1-3), </volume> <pages> 139159. </pages>
Reference-contexts: Though this divide et impera approach is not a new idea in software design, we were among the first (Dorigo & Sirtori, 1991; Mahadevan & Connell, 1992; Dorigo & Schnepf, 1993; Lin, 1993) to combine the behavioral decomposition approach <ref> (Brooks, 1991) </ref> with reinforcement learning techniques. We will discuss in the following Section 5 some of the limits of this approach and will suggest that evolutionary techniques could be better exploited to develop nonrational solutions to the problem of designing the control architecture of an autonomous agent.
Reference: <author> Brownston, L., F. Farrell, E. Kant & N. </author> <title> Martin (1985). Programming expert systems in OPS 5: An introduction to rule-based programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: Again, it is interesting to look at production systems which, as we have already remarked, have a low degree of modularity. Production systems of the OPS 5-type <ref> (Brownston et al., 1985) </ref> indeed deal with the problems we have pointed out.
Reference: <author> Colombetti, M., & M. </author> <title> Dorigo (1994). Training agents to perform sequential behavior. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 2 (3), </volume> <pages> 247275. </pages>
Reference: <author> Colombetti, M., M. Dorigo & G. </author> <month> Borghi </month> <year> (1996). </year> <title> Behavior Analysis and Training: A methodology for Behavior Engineering. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics-Part B, </journal> <volume> 26 (3), 365 380. </volume>
Reference-contexts: In fact, we believe that the attempt to establish a clear and rich terminology is of the greatest importance for a research area that still lacks universally accepted foundations an area that we propose to call Behavior Engineering (BE), given that producing behavior is the characteristic feature of agents <ref> (see also Colombetti, Dorigo & Borghi, 1996) </ref>. The plan of the article is the following. First, in Section 2, we shortly describe our past experience in developing agents through evolutionary methods. <p> This experiment showed that a fairly complex behavior can be achieved by directly training a real robot, without resorting to simulation. 2.3.2 HAMSTER HAMSTERs task was to hoard food bringing it to its nest 3 <ref> (Colombetti, Dorigo & Borghi, 1996) </ref>, Its chief features are that it combines innate (i.e., prewired) and learned behaviors, and that training was carried out in a simulated environment and then transferred to the physical robot. <p> In fact, we cannot forget that a robot is designed to carry out a predefined task, that we shall call its target behavior. Typically, the target behavior is part of the initial requirements that a robot designer has to fulfill <ref> (see Colombetti, Dorigo & Borghi, 1996) </ref>. So, it seems that we cannot immediately exploit the biological notion of fitness to formulate basic laws governing artificial agents. Not only scientists have been intrigued by the problems connected with the basic laws of artificial behavior.
Reference: <author> Dorigo, M. </author> <year> (1992). </year> <title> Using transputers to increase speed and flexibility of genetics-based machine learning systems. </title> <journal> Microprocessing and Microprogramming Journal, </journal> <volume> 34, </volume> <pages> 147152. </pages>
Reference: <author> Dorigo, M. </author> <year> (1993). </year> <title> Genetic and NonGenetic Operators in Alecsys, </title> <journal> Evolutionary Computation Journal, </journal> <volume> 1 (2), </volume> <pages> 151164. </pages>
Reference: <author> Dorigo, M., </author> <year> (1995). </year> <title> ALECSYS and the AutonoMouse: Learning to control a real robot by distributed classifier systems. </title> <journal> Machine Learning, </journal> <volume> 19 (3), </volume> <year> 209240. </year>
Reference-contexts: LeaveNest GetFood ReachNest Coordinator Avoid Obstacles Environment + 2.3.3 CRAB The experiment we have carried out with CRAB was intended to establish whether the light following task successfully learnt by AutonoMouse II could also be learned by a robot with a completely different geometry <ref> (Patel, Colombetti & Dorigo, 1995) </ref>. In fact, reaching for an object by a mobile robot or by a manipulator are two different behaviors, because they require the two agents to perform different actions to achieve similar results. Consider for example the two configurations, a and b, shown in Figure 2.14. <p> Robustness of behavior does not presuppose any change in the agents controller. For example, the AutonoMice trained to approach a steady light were still able to approach it if it started moving <ref> (see Dorigo, 1995) </ref>. This is a consequence of the insensitivity of the controller to the motion state of the light.
Reference: <author> Dorigo, M., & M. </author> <title> Colombetti (1994a). Robot shaping: developing autonomous agents through learning. </title> <journal> Artificial Intelligence, </journal> <volume> 71 (2), </volume> <pages> 321370. </pages>
Reference-contexts: In our approach to the development of control systems by LCSs, which we call robot shaping <ref> (Dorigo & Colombetti, 1994a) </ref>, the interaction between the agent controlled by the LCS and its environment is observed by a trainer which provides step-by-step (i.e., immediate) reinforcements: rewards when the agent does something correct, punishments when the agent does something wrong.
Reference: <author> Dorigo, M., & M. </author> <title> Colombetti (1994b). The role of the trainer in reinforcement learning. </title> <booktitle> Proceedings of MLC-COLT '94 Workshop on Robot Learning, </booktitle> <editor> S. Mahadevan et al. (Eds.), </editor> <address> New Brunswick, NJ, </address> <month> 3745. </month>
Reference: <author> Dorigo, M. & U. </author> <title> Schnepf (1993). Genetics-based machine learning and behavior based robotics: A new synthesis. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23 (1), </volume> <pages> 141153. </pages>
Reference: <author> Dorigo M. & E. </author> <title> Sirtori (1991). ALECSYS: A Parallel Laboratory for Learning Classifier Systems, </title> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <address> San Diego, California, </address> <publisher> R.K. </publisher> <editor> Belew & L.B. Booker (Eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <pages> 296302. </pages>
Reference: <author> M. Colombetti, M. </author> <title> Dorigo Evolutionary Computation in Behavior Engineering 29 Fodor, </title> <editor> J. </editor> <year> (1985). </year> <title> The modularity of mind. Focal article with commentary, </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 8, </volume> <pages> 142. </pages>
Reference: <author> Ghezzi, C., M. Jazayeri & D. </author> <title> Mandrioli (1991). Fundamentals of Software Engineering, </title> <publisher> Prentice - Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: Divide et impera is perhaps the most fundamental engineering motto. A system is modular when it is built up from modules , that is from subsystems that are both highly cohesive and loosely coupled <ref> (see for example Ghezzi, Yazayeri & Mandrioli, 1991) </ref>. High cohesion is an intramodular property: it means that the subsystem has a well - identified function, and contains only components that operate to realize such a function.
Reference: <author> Griffin, D.R. </author> <year> (1984). </year> <title> Animal thinking. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Holland, J.H. </author> <year> (1980). </year> <title> Adaptive algorithms for discovering and using general patterns in growing knowledge bases, </title> <journal> International Journal of Policy Analysis and Information Systems, </journal> <volume> 4 (2), 217 240. </volume>
Reference-contexts: A LCS is composed of three interacting systems: the performance system, a kind a production rule system which is in charge of directing the behavior of the controlled agent; the apportionment of credit system, which is in charge, by means of an algorithm called Bucket Brigade <ref> (Holland, 1980) </ref>, of evaluating the usefulness of rules used by the performance system; and the genetic algorithm, whose duty is to discover new useful rules to be added to the knowledge base used by the performance system 1 .
Reference: <author> Latombe, J.-C. </author> <year> (1991). </year> <title> Robot motion planning. </title> <publisher> Kluwer, </publisher> <address> Dordrecht, NE. </address>
Reference-contexts: We chose to program AvoidObstacles directly, implementing a potential-based avoidance mechanism exploiting Robuters sonars <ref> (see for example Latombe, 1991) </ref>. The 3 This robots name is mainly justified by its target behavior. It is also an acronym, namely Highly Autonomous Mobile System TrainEd by Reinforcements. M. Colombetti, M.
Reference: <author> Lin, L-J. </author> <year> (1993). </year> <title> Hierarchical learning of robot skills by reinforcement., </title> <booktitle> Proceedings of 1993 IEEE International Conference on Neural Networks, IEEE, </booktitle> <pages> 181186. </pages>
Reference: <author> Mahadevan, S., & J. </author> <title> Connell (1992). Automatic programming of behavior-based robots using reinforcement learning, </title> <journal> Artificial Intelligence, </journal> <volume> 55 (2), </volume> <pages> 311365. </pages>
Reference: <author> McFarland, D. (Ed.) </author> <year> (1981). </year> <title> The Oxford Companion to Animal Behaviour. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> UK. </address>
Reference-contexts: As far as it is genetically determined, an aspect of animal behavior should therefore be explained in terms of its adaptive value, defined as its contribution to the overall fitness of the organism. As shown by contemporary ethology <ref> (see for example McFarland, 1981) </ref>, this approach to the explanation of behavior is extremely powerful and productive. 4 Clearly, we cannot apply the same line of thought to the analysis of artificial agents: robots are the result of explicit design, not of natural selection. <p> An important difference between the natural and the artificial is that in animals learning is sharply different from evolution. Moreover, the capacity of individual learning in organisms 8 See for example the entry ADAPTATION in The Oxford Companion to Animal Behaviour <ref> (McFarland, 1981) </ref>. M. Colombetti, M. Dorigo Evolutionary Computation in Behavior Engineering 25 is itself a product of evolution; we must therefore expect to find such a capacity where it has adaptive value.
Reference: <author> Mondada F., E. Franzi & P. </author> <month> Ienne </month> <year> (1994). </year> <title> Mobile Robot Miniaturization: A Tool for Investigation in Control Algorithms. Experimental Robotics III: </title> <booktitle> Proceedings of the 3rd International Symposium on Experimental Robotics, </booktitle> <editor> T. Yoshikawa and F. Miyazaki (Eds.), SpringerVerlag, </editor> <volume> 501513. </volume>
Reference-contexts: There is certainly a metaphoric way of interpreting the fitness of an artifact in terms of its ability to maximize its offspring. Commercial robots as Robosofts Robuter (Robosoft SA, 1991) and Lausanne Polytechnics Khepera <ref> (Mondada, Franzi & Ienne, 1994) </ref> show high fitness, in that they are spreading through robotics labs. In a less metaphoric way, we would probably interpret this as a consequence of the overall quality of such robots.
Reference: <author> Patel, M.J., M. Colombetti & M. </author> <title> Dorigo (1995). Evolutionary learning for intelligent automation: A case study. </title> <journal> Intelligent Automation and Soft Computing, </journal> <volume> 1 (1), </volume> <pages> 2942. </pages>
Reference-contexts: LeaveNest GetFood ReachNest Coordinator Avoid Obstacles Environment + 2.3.3 CRAB The experiment we have carried out with CRAB was intended to establish whether the light following task successfully learnt by AutonoMouse II could also be learned by a robot with a completely different geometry <ref> (Patel, Colombetti & Dorigo, 1995) </ref>. In fact, reaching for an object by a mobile robot or by a manipulator are two different behaviors, because they require the two agents to perform different actions to achieve similar results. Consider for example the two configurations, a and b, shown in Figure 2.14.
Reference: <author> Prato Previde, E., M. Colombetti, M.D. Poli & E. </author> <month> Cenami Spada </month> <year> (1992). </year> <title> The mind of organisms: Some issues about animal cognition. Focal article with commentary, </title> <journal> International Journal of Comparative Psychology, </journal> <volume> 6 (2), </volume> <pages> 79119. </pages>
Reference: <institution> Robosoft SA (1991). </institution> <note> Robuter Users Manual V3.1, </note> <institution> Asnires, France. </institution>
Reference-contexts: There is certainly a metaphoric way of interpreting the fitness of an artifact in terms of its ability to maximize its offspring. Commercial robots as Robosofts Robuter <ref> (Robosoft SA, 1991) </ref> and Lausanne Polytechnics Khepera (Mondada, Franzi & Ienne, 1994) show high fitness, in that they are spreading through robotics labs. In a less metaphoric way, we would probably interpret this as a consequence of the overall quality of such robots.
Reference: <author> Searle, J.R. </author> <year> (1992). </year> <title> The rediscovery of the mind. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: However, it is likely that lower level animals do not have mental states properly so called, and this is certainly the case for current artificial systems <ref> (for a philosophical argument, see Searle, 1992) </ref>. Darwin has taught us how to avoid teleological arguments in the analysis of living systems: organisms that undergo natural selection show features that tend to maximize their fitness, that is, their capacity to spread their own genetic makeup.
Reference: <author> Wilson, S. </author> <year> (1987). </year> <title> Classifier systems and the Animat problem, </title> <journal> Machine Learning, </journal> <volume> 2 (3), </volume> <year> 199228. </year>
Reference-contexts: In the following we describe the types of agents, environments and behaviors we have considered, the development tool we have used, and the experiments we have run. 2.1 AutonoMice and other robots In our experiments, we have been inspired by Wilsons animat problem <ref> (Wilson, 1987) </ref>, that is, the problem of having an artificial agent survive in the real world. Therefore, our robot are somewhat zoomorphic, and inhabit environments containing preys, predators, nests, etc. <p> M. Colombetti, M. Dorigo Evolutionary Computation in Behavior Engineering 18 3.2 The functional characterization of environmental objects Our agents are animat-like robots <ref> (see Wilson, 1987) </ref> that carry out their activity in environments containing nests, obstacles, preys, hurting objects, etc. In most cases, the behavioral patterns exhibited by our agents are instances of tactic behavior, that is, they are directed at approaching, reaching, avoiding or fleeing from objects ( taxis).
References-found: 26

