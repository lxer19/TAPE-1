URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-99-3-1-callaway.ps.Z
Refering-URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-99-3-1.html
Root-URL: http://www.cs.man.ac.uk
Email: ndc93@aber.ac.uk  
Title: A Schema-Based Approach to Lifelong Learning  
Author: Neil Callaway and Mark Lee 
Keyword: lifelong learning, autonomous, agent, schema, mobile, robot  
Date: 26.3.99  
Address: Aberystwyth  
Affiliation: Department of Computer Science University of Wales  
Abstract: Learning systems in the field of mobile robotics are now quite commonplace and although they generally prove to be competent at the tasks set for them, their learning algorithms remain static rather than adapting through experience. Recently, "lifelong" learning systems have begun to appear that, over time, improve the way they learn, signifying the next generation of learning systems. This paper describes one such proposed system which is currently being developed. The chosen hardware and software components are discussed, including details of the schema-based learning system, and the expected behaviour of the agent is described. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baxter, J. </author> <year> 1997. </year> <title> A Bayesian information theoretic model of learning to learn via multiple task sampling. </title> <journal> Machine learning, </journal> <volume> 28, </volume> <pages> 7-39. </pages>
Reference-contexts: Multitask Learning (Caruana, 1997) improves the generalisation performance of a backpropagation neural network by extracting the "domain-specific information contained in the training signals of related tasks", which are undertaken in parallel. A Bayesian approach to the same idea is described in <ref> (Baxter, 1997) </ref>, where sampling from an environment of multiple related tasks creates hypothesis spaces that can be searched by a learner for one that is appropriate for learning all the tasks.
Reference: <author> Caruana, R. </author> <year> 1997. </year> <title> Multitask learning. </title> <journal> Machine learning, </journal> <volume> 28, </volume> <pages> 41-75. </pages>
Reference-contexts: Others exploit a learning bias provided by related learning experiences. Romaniuk's Trans-Dimensional Learning (Romaniuk, 1995) automatically adjusts the learning bias in a neural network while undertaking multiple pattern-matching tasks, leading to a faster learning system. Multitask Learning <ref> (Caruana, 1997) </ref> improves the generalisation performance of a backpropagation neural network by extracting the "domain-specific information contained in the training signals of related tasks", which are undertaken in parallel.
Reference: <author> Corbacho, F. J. </author> <year> 1995. </year> <title> Schema-based learning and learning to detour. </title> <booktitle> Lecture notes in computer science, </booktitle> <volume> 930, </volume> <pages> 412-418. </pages>
Reference-contexts: Schema-based systems for controlling mobile robots have been proposed before, e.g. <ref> (Corbacho, 1995) </ref>, but this is the first time that schemas have been used in a lifelong learning agent. Schemas are well-suited to the domain of mobile robotics because their context-action-result makeup matches the decision making process of an autonomous agent moving from one state to the next.
Reference: <author> Drescher, G. L. </author> <year> 1991. </year> <title> Made up minds: a constructivist approach to artificial intelligence. </title> <publisher> MIT Press. </publisher>
Reference-contexts: At the same time unused schemas are very novel and would be investigated by being selected for activation. 4.2 Schema Mechanism The basic learning system that forms most of the agent is largely based on the work of Drescher <ref> (Drescher, 1991) </ref>. Fundamental to the learning system is the concept of a schema. Conceptually, a schema is three things.
Reference: <author> Hughes, N., & Wilson, M. </author> <year> 1996. </year> <title> Appropriate reactions and planned responses. </title> <booktitle> Proceedings of the 4th international workshop advanced robotics and intelligent machines. </booktitle>
Reference-contexts: This mapping ability can be used to accomplish "navigation plus" tasks, which are defined in <ref> (Hughes & Wilson, 1996) </ref> as, "Tasks that involve navigating a complex environment in a variety of ways, performing some organi-sational activity at locations in that environment." This is the scenario that the authors wish to explore with the work described here. 2 Motivation It is the aim of the research work
Reference: <author> Ring, M. B. </author> <year> 1997. </year> <title> CHILD: A first step towards continual learning. </title> <journal> Machine Learning, </journal> <volume> 28, </volume> <pages> 77-104. </pages>
Reference-contexts: It can then start to move purposefully, exploring its surroundings and learning strategies for achieving its goals. Different techniques have been used to achieve lifelong learning. Ring <ref> (Ring, 1997) </ref> uses Q-learning with a constructive neural-network-based learning system to learn hierarchically and incrementally, allowing the navigation of simulation mazes of increasing complexity. Others exploit a learning bias provided by related learning experiences.
Reference: <author> Romaniuk, S. G. </author> <year> 1995. </year> <title> Learning to learn: automatic adaption of learning bias. </title> <booktitle> Neural Networks, </booktitle> <volume> 8, </volume> <pages> 871-876. </pages>
Reference-contexts: Different techniques have been used to achieve lifelong learning. Ring (Ring, 1997) uses Q-learning with a constructive neural-network-based learning system to learn hierarchically and incrementally, allowing the navigation of simulation mazes of increasing complexity. Others exploit a learning bias provided by related learning experiences. Romaniuk's Trans-Dimensional Learning <ref> (Romaniuk, 1995) </ref> automatically adjusts the learning bias in a neural network while undertaking multiple pattern-matching tasks, leading to a faster learning system.
Reference: <author> Taylor, C. J., & Kriegman, D. J. </author> <year> 1995. </year> <title> Vision-based motion planning and exploration algorithms for mobile robots. Pages 69-83 of: </title> <editor> Goldberg, K., Halperin, D., Latombe, J. C., & Wilson, R. (eds), </editor> <booktitle> Proceedings of the workshop on the algorithmic foundations of robotics (WAFR). </booktitle> <editor> A. K. </editor> <publisher> Peters. </publisher>
Reference-contexts: As software agents that control mobile robots become more sophisticated, the tasks that they are able to perform become more complex. Many learning agents are able to map and navigate around their environment, e.g. (Wesley, 1993) and <ref> (Taylor & Kriegman, 1995) </ref>, which both use qualitative mapping techniques based on observed landmarks to determine the location of the robot in its environment and to calculate the path to a desired location.
Reference: <author> Thrun, S. </author> <year> 1994. </year> <title> A lifelong learning perspective for mobile robot control. </title> <booktitle> IROS '94 intelligent robots and systems: advanced robotic systems and the real world, </booktitle> <pages> 1-3, 23-30. </pages>
Reference-contexts: Thrun concentrates on applying lifelong learning strategies to the control of mobile robots using explanation-based neural networks in <ref> (Thrun, 1994) </ref>, with the aim of learning to accomplish tasks with the minimum amount of initial knowledge and training time. In (Thrun & Mitchell, 1995) he considers lifelong learning by the invariance approach, that is transferring knowledge between tasks by learning a Proc.
Reference: <author> Thrun, S., & Mitchell, T. M. </author> <year> 1995. </year> <title> Learning one more thing. </title> <booktitle> Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI). </booktitle>
Reference-contexts: Thrun concentrates on applying lifelong learning strategies to the control of mobile robots using explanation-based neural networks in (Thrun, 1994), with the aim of learning to accomplish tasks with the minimum amount of initial knowledge and training time. In <ref> (Thrun & Mitchell, 1995) </ref> he considers lifelong learning by the invariance approach, that is transferring knowledge between tasks by learning a Proc. TIMR 99 "Towards Intelligent Mobile Robots", Bristol 1999. Technical Report Series, Department of Computer Science, Manchester University, ISSN 1361 - 6161.
Reference: <author> Wesley, L. P. </author> <year> 1993. </year> <title> Autonomous locative reasoning: an evidential approach. </title> <booktitle> Proceedings : IEEE international conference on robotics and automation, </booktitle> <volume> 1, </volume> <pages> 700-707. </pages>
Reference-contexts: As software agents that control mobile robots become more sophisticated, the tasks that they are able to perform become more complex. Many learning agents are able to map and navigate around their environment, e.g. <ref> (Wesley, 1993) </ref> and (Taylor & Kriegman, 1995), which both use qualitative mapping techniques based on observed landmarks to determine the location of the robot in its environment and to calculate the path to a desired location.
References-found: 11

