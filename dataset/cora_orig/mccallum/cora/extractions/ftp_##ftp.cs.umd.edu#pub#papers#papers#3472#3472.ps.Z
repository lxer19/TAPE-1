URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3472/3472.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: email: mahajan@cs.umd.edu, ben@cs.umd.edu  
Title: A Family of User Interface Consistency Checking Tools  
Author: Rohit Mahajan and Ben Shneiderman 
Address: College Park, MD 20742-3255 USA  
Affiliation: Human-Computer Interaction Laboratory Center for Automation Research 1 Department of Computer Science Institute for Systems Research University of Maryland,  
Date: April 1995  
Pubnum: CAR-TR-770  CS-TR-3472  
Abstract: Incorporating evaluation metrics with GUI development tools will help designers create consistent interfaces in the future. Complexity in design of interfaces makes efficient evaluation impossible by a single consistency checking evaluation tool. Our focus is on developing a family of evaluation tools in order to make the evaluation process less cumbersome. We have developed a dialog box typeface and color table to facilitate detection of anomalies in color, font, font size, and font style. Concordance tools have been developed to spot variant capitalization and abbreviations globally in the interface and specifically in the button widgets. As buttons are frequently used widgets, a button layout table has been created to spot any inconsistencies in height, width and relative position between a given group of buttons if present. Finally, a terminology basket tool has been created to identify unwanted synonyms of computer related terms used in the interface which may be misleading to the end user. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ashlund, S. and Hix, D. </author> <year> (1992), </year> <title> "IDEAL: A tool to Enable User Centred Design", </title> <booktitle> Proc. of CHI' 92 (Posters and short talk supplement to proceedings) , ACM, </booktitle> <address> New York, 119 120. </address>
Reference-contexts: Iterative refinement methods like Formative Evaluations can be used to design/redesign the interface from early development stages through completion stage ( Hix & Hartson, 1993). Interactive tools like IDEAL (Interface Design Environment Analysis Lattice) support procedures like Formative Evaluations <ref> (Ashlund & Hix, 1992) </ref>. Recent advances in powerful user interface development tools have expedited the interface development process helping both novice and experienced developers. However these expeditiously created designs may be clogged with spatial and textual inconsistencies that may have a subtle and negative impact on interface usability.
Reference: <author> Bodart, F., Hennebert, A.-M., Leheureux, J.-M., and Vanderdonckt, J. </author> <year> (1994), </year> <title> Towards a dynamic strategy for computer-aided visual placement, </title> <editor> In Catarci, T., Costabile, M., Levialdi, S., and Santucci, G. (Editors), </editor> <booktitle> Proc. Advanced Visual I nterfaces Conference 94, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <pages> 78-87. </pages>
Reference-contexts: These visual properties also include proportion, neutrality, singularity, repartion, grouping, sparing, simplicity etc. Dynamic strategies for automated evaluation using these visual techniques have been introduced. <ref> (Bodart, Hennebert, Leheureux and Vanderdonckt,1994) </ref>. Visual metrics introduced above for traditional layout grids and multimedia layout frames have not yet been tested. Sears (1993, 1994) has developed a first generation tool using automated metrics for both design and evaluation using Layout Appropriateness metrics.
Reference: <author> Chimera, R. and Shneiderman, B. </author> <year> (1993), </year> <title> User interface consistency: An evaluation of original and revised interfaces for a videodisk library, </title> <editor> In Shneiderman, B. (Editor), </editor> <title> Sparks of Innovation in Human-Computer Interaction , Ablex Publishers, </title> <address> Norwood, NJ, </address> <pages> 259-271. </pages>
Reference-contexts: Each designer may have different interpretation of terminology and uses his/her own style of abbreviations and computer terms. Furthermore designers personal preferences on fonts and colors add to the problem in group designs. Such anomalies in terminology and format lead to poor design, ultimately misleading and confusing the user <ref> (Chimera & Shneiderman, 1993) </ref>. Although many organizations are adopting more stringent usability testing standards to monitor quality and layout of the design, better automated evaluation tools are needed which would scan for inconsistencies in the interface layout at early design and development stages thereby decreasing the complexity of usability testing.
Reference: <author> Hix, D. and Hartson, H. R. </author> <year> (1993), </year> <title> Developing User Interfaces: Ensuring Usability Through Product & Process, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, NY. </address>
Reference-contexts: 1. INTRODUCTION AND PREVIOUS RELATED RESEARCH Creating user interfaces is a composite procedure involving iterative design, usability testing and evaluation processes (Shneiderman, 1992). Iterative refinement methods like Formative Evaluations can be used to design/redesign the interface from early development stages through completion stage <ref> ( Hix & Hartson, 1993) </ref>. Interactive tools like IDEAL (Interface Design Environment Analysis Lattice) support procedures like Formative Evaluations (Ashlund & Hix, 1992). Recent advances in powerful user interface development tools have expedited the interface development process helping both novice and experienced developers.
Reference: <author> Kim, W. and Foley, J. </author> <year> (1993), </year> <title> Providing high-level control and expert assistance in the user interface presentation design, </title> <booktitle> Proc. of CHI93, ACM, </booktitle> <address> New York, </address> <pages> 430-437. </pages>
Reference: <author> Nielsen, J. and Molich, R., </author> <title> (1990) "Heuristic evaluation of user interfaces", </title> <booktitle> Proc. of CHI'90 , ACM, </booktitle> <address> New York, </address> <pages> 249-256. </pages>
Reference-contexts: Usability testing is a highly beneficial but costly process when compared with automated evaluation. Prerequisites for these tests may include availability of developed working prototypes, test users and expert evaluators (Sears, 1994). These requirements are hindrances in this very powerful evaluation method. Alternative techniques like Heuristic Evaluations <ref> (Nielsen & Molich, 1990) </ref> can decrease but not eliminate these requirements. Furthermore usability testing works best for smaller applications. It is practically impossible to analyze every dialog box in an application with thousands of dialog boxes.
Reference: <author> Sears, A. </author> <year> (1993), </year> <title> Layout Appropriateness: A metric for evaluating user interface widget layouts, </title> <journal> IEEE Transactions on Software Engineering 19, </journal> <volume> 7, </volume> <pages> 707-719. </pages>
Reference: <author> Sears, A. </author> <year> (1994), </year> <title> Using automated metrics to design and evaluate user interfaces, </title> <institution> DePaul University Dept of Computer Science Technical Report #94-002, Chicago, IL. </institution>
Reference-contexts: Usability testing is a highly beneficial but costly process when compared with automated evaluation. Prerequisites for these tests may include availability of developed working prototypes, test users and expert evaluators <ref> (Sears, 1994) </ref>. These requirements are hindrances in this very powerful evaluation method. Alternative techniques like Heuristic Evaluations (Nielsen & Molich, 1990) can decrease but not eliminate these requirements. Furthermore usability testing works best for smaller applications.
Reference: <author> Shneiderman, B. </author> <year> (1992), </year> <title> Designing the User Interface: Strategies for Effective Human Computer Interaction: Second Edition, </title> <publisher> Addison-Wesley Publ. Co., </publisher> <address> Reading, MA. </address>
Reference-contexts: 1. INTRODUCTION AND PREVIOUS RELATED RESEARCH Creating user interfaces is a composite procedure involving iterative design, usability testing and evaluation processes <ref> (Shneiderman, 1992) </ref>. Iterative refinement methods like Formative Evaluations can be used to design/redesign the interface from early development stages through completion stage ( Hix & Hartson, 1993). Interactive tools like IDEAL (Interface Design Environment Analysis Lattice) support procedures like Formative Evaluations (Ashlund & Hix, 1992).
Reference: <author> Shneiderman, B., Chimera, R., Jog, N., Stimart, R. and White, D. </author> <year> (1995), </year> <title> "Evaluating spatial and textual style of displays", Proc. of Getting the Best from State-of the-Art Display Systems 95, </title> <publisher> London. </publisher>
Reference-contexts: So our evaluation programs are not specific to Visual Basic and can be used for evaluating interfaces developed by other tools. 7 2.1 Our Previous Method This research is an extension of previous work <ref> (Shneiderman, Chimera, Jog, Stimart and White, 1995) </ref> in which we developed spatial and textual evaluation tools. The spatial tool was a dialog box summary table which gave an overview of spatial and visual properties. Each dialog box corresponded to a distinct row and each column a metric.
Reference: <author> Streveler, D. and Wasserman, A. </author> <year> (1987), </year> <title> Quantitative measures of the spatial properties of screen designs, </title> <booktitle> Proc. of INTERACT 87, </booktitle> <publisher> Elsevier Science, Amsterdam, </publisher> <pages> 125-133. </pages>
Reference: <author> Tullis, T. S. </author> <year> (1988a), </year> <title> Screen design, </title> <editor> In Helander, M. (Editor), </editor> <booktitle> Handbook of Human Computer Interaction, </booktitle> <publisher> Elsevier Science, </publisher> <address> Amsterdam, The Netherlands, </address> <pages> 377-411. </pages>
Reference: <author> Tullis, T. S. </author> <year> (1988b), </year> <title> A system for evaluating screen formats: Research and application, </title> <editor> In Hartson, H. Rex and Hix, Hartson, </editor> <booktitle> Advances in Human-Computer Interaction: </booktitle> <volume> Volume 2, </volume> <publisher> Ablex Publishing Corp., </publisher> <address> Norwood, NJ, 214-286. </address> <note> 17 Vanderdonckt, </note> <author> J. and Gillo, X. </author> <year> (1994), </year> <title> Visual techniques for traditional and multimedia layouts, </title> <editor> In Catarci, T., Costabile, M., Levialdi, S. and Santucci, G. (Editors), </editor> <booktitle> Proc. Advanced Visual Interfaces Conference 94, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <pages> 95-104. </pages>
References-found: 13

