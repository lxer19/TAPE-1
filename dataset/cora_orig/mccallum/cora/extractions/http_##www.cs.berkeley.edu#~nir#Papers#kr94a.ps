URL: http://www.cs.berkeley.edu/~nir/Papers/kr94a.ps
Refering-URL: http://http.cs.berkeley.edu/~nir/publications.html
Root-URL: 
Email: nir@cs.stanford.edu  halpern@almaden.ibm.com  
Title: A Knowledge-Based Framework for Belief Change, Part II: Revision and Update  
Author: Nir Friedman Joseph Y. Halpern 
Address: Stanford, CA 94305-2140  650 Harry Road San Jose, CA 95120-6099  
Affiliation: Department of Computer Science Stanford University  IBM Almaden Research Center  
Abstract: The study of belief change has been an active area in philosophy and AI. In recent years two special cases of belief change, belief revision and belief update, have been studied in detail. In a companion paper [FH94b] we introduced a new framework to model belief change. This framework combines temporal and epistemic modalities with a notion of plausibility, allowing us to examine the changes of beliefs over time. In this paper we show how belief revision and belief update can be captured in our framework. This allows us to compare the assumptions made by each method and to better understand the principles underlying them. In particular, it allows us to understand the source of Gardenfors' triviality result for belief revision [Gar86] and suggests a way of mitigating the problem. It also shows that Katsuno and Mendelzon's notion of belief update [KM91a] depends on several strong assumptions that may limit its applicability in AI.
Abstract-found: 1
Intro-found: 1
Reference: [AGM85] <author> C. E. Alchourron, P. Gardenfors, and D. Makinson. </author> <title> On the logic of theory change: partial meet functions for contraction and revision. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-530, </pages> <year> 1985. </year>
Reference-contexts: The focus of this research is to understand how an agent should change his beliefs as a result of getting new information. Two instances of this general phenomenon have been studied in detail. Belief revision <ref> [AGM85, Gar88] </ref> focuses on how an agent revises his beliefs when he adopts a new belief. Belief update [KM91a], on the other hand, focuses on how an agent should change his beliefs when he realizes that the world has changed. <p> Essentially, it is appropriate if the agent always receives enough information to deduce the exact change in the state of the world, a condition unlikely to be met in most AI applications. We are certainly not the first to provide semantic models for belief revision and update. For example, <ref> [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] </ref> deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94]. <p> He must then discard some of his old beliefs in order to incorporate the new belief and remain con sistent. The question is which ones? The most widely accepted notion of belief revision is defined by the AGM theory <ref> [AGM85, Gar88] </ref>. The agent's epistemic state is represented as a belief set, that is, a set of formulas in L () closed under deduction. <p> Once we adopt the Ramsey test we can in fact discard postulates R1-R8 altogether, and simply define revision using Eq. (2). That is, we shift the focus from finding a set of postulates for belief revision, as done by previous researchers <ref> [AGM85, Gar88, Bou92, Fuh89, Rot89] </ref>, to that of finding a logical characterization of revision in terms of the properties of &gt;. <p> We hope that our framework will provide a useful basis for answering them. Finally, we note that our approach is quite different from the traditional approach to belief change <ref> [AGM85, Gar88, KM91a] </ref>. Traditionally, belief change was considered as an abstract process. Our framework, on the other hand, models the agent and the environment he is situated in, and how both change in time.
Reference: [Bou92] <author> C. Boutilier. Normative, </author> <title> subjective and autoepistemic defaults: Adopting the Ramsey test. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proc. Third International Conference (KR '92). </booktitle> <year> 1992. </year>
Reference-contexts: It should thus be no surprise that assuming persistence of such formulas leads to triviality. Indeed, this observation was essentially already made by Levi [Lev88]. Our solution to the triviality result is somewhat different from others that have been considered in the literature (e.g., <ref> [Rot89, Fuh89, LR92, Bou92] </ref>) in that it shifts the focus from postulates for the revision process to considerations of the appropriate logic of conditionals. We then turn our attention to belief update. Our treatment enables us to identify implicit assumptions made in the update process. <p> Essentially, it is appropriate if the agent always receives enough information to deduce the exact change in the state of the world, a condition unlikely to be met in most AI applications. We are certainly not the first to provide semantic models for belief revision and update. For example, <ref> [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] </ref> deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94]. <p> We would like '! to be true at (r; m) if the most plausible points in (r;m) that satisfy ' also satisfy . The actual definition that we use, which is standard in the literature (see <ref> [Lew73, Bur81, Bou92] </ref>), captures this desideratum if there are most plausible points that satisfy ' (in particular, if (r;m) is finite), and also deals with the more general case where there may be a sequence of increasingly more plausible points, with none being most plausible, i.e., : : : s 3 <p> Once we adopt the Ramsey test we can in fact discard postulates R1-R8 altogether, and simply define revision using Eq. (2). That is, we shift the focus from finding a set of postulates for belief revision, as done by previous researchers <ref> [AGM85, Gar88, Bou92, Fuh89, Rot89] </ref>, to that of finding a logical characterization of revision in terms of the properties of &gt;. <p> More precisely, after learning ', (r;m+1) = f (r; m + 15 Thus, we use &gt; rather than ! for belief revision, con trary to the suggestion implicit in <ref> [Bou92] </ref>. 10 1)j (r; m) 2 (r;m) ; (r; m) j= learn (') ^ fl'g, and (r 0 ; m + 1) (r;m+1) (r 00 ; m + 1) if and only if (r 0 ; m) (r;m) (r 00 ; m). (In the terminology of [FH94b], this means that the
Reference: [Bou93] <author> C. Boutilier. </author> <title> Revision sequences and nested conditionals. </title> <booktitle> In Proc. Thirteenth International Joint Conference on Artificial Intelligence (IJCAI '93), </booktitle> <pages> pages 519-525, </pages> <year> 1993. </year>
Reference-contexts: In this case, most observations that are not consistent with his beliefs will lead him to believe :'. These examples are two aspects of a bigger problem: The AGM postulates put very weak restrictions on the ordering that the agent has after a revision step (see <ref> [Bou93, DP94] </ref>). Essentialy, the only requirement is that after learning ', the most plausible worlds must be ones where ' is true. While this is an important and reasonable constraint on how beliefs should change, it does not capture all our intuitions regarding how beliefs change in many applications. <p> Thus, maps an ex tended belief set and a formula to an extended belief for similar reasons, in <ref> [Bou93, EG93] </ref>. 14 We might have defined Bel &gt; (I; s a ) as f' 2 L &gt; () j (I; s a ) j= B'g, which would have been even more in the spirit of our definition of Bel (I; s a ).
Reference: [Bou94] <author> C. Boutilier. </author> <title> An event-based abductive model of update. </title> <booktitle> In Proc. Tenth Biennial Canadian Conference on Artificial Intelligence (AI '94), </booktitle> <year> 1994. </year>
Reference-contexts: Some of the work has already been done for us by Katsuno and Mendelzon [KM91a], who identified three significant differences between revision and update: 1. Revision deals with static propositions, while up date allows propositions that are not static. As we 12 Similar observations were independently made by Boutilier <ref> [Bou94] </ref>, although his representation is quite dif ferent than ours. 8 noted in the introduction this difference is in the types of propositions that these notions deal with, rather than a difference in the type of situations that they deal with. 2. Revision and update treat inconsistent belief states differently.
Reference: [Bur81] <author> J. Burgess. </author> <title> Quick completeness proofs for some logics of conditionals. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 22 </volume> <pages> 76-84, </pages> <year> 1981. </year>
Reference-contexts: We would like '! to be true at (r; m) if the most plausible points in (r;m) that satisfy ' also satisfy . The actual definition that we use, which is standard in the literature (see <ref> [Lew73, Bur81, Bou92] </ref>), captures this desideratum if there are most plausible points that satisfy ' (in particular, if (r;m) is finite), and also deals with the more general case where there may be a sequence of increasingly more plausible points, with none being most plausible, i.e., : : : s 3
Reference: [DP94] <author> A. Darwiche and J. Pearl. </author> <title> On the logic of iterated belief revision. </title> <editor> In R. Fagin, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge: Proc. Fifth Conference, </booktitle> <pages> pages 5-23. </pages> <year> 1994. </year>
Reference-contexts: In this case, most observations that are not consistent with his beliefs will lead him to believe :'. These examples are two aspects of a bigger problem: The AGM postulates put very weak restrictions on the ordering that the agent has after a revision step (see <ref> [Bou93, DP94] </ref>). Essentialy, the only requirement is that after learning ', the most plausible worlds must be ones where ' is true. While this is an important and reasonable constraint on how beliefs should change, it does not capture all our intuitions regarding how beliefs change in many applications.
Reference: [dVS92] <author> A. del Val and Y. Shoham. </author> <title> Deriving properties of belief update from theories of action. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '92), </booktitle> <pages> pages 584-589, </pages> <year> 1992. </year>
Reference-contexts: We are certainly not the first to provide semantic models for belief revision and update. For example, [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] deal with revision and <ref> [KM91a, dVS92] </ref> deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94]. <p> How reasonable is the notion of update? As the definition of (r;m) given above suggests, it has a preference for deferring abnormal events. This makes it quite similar to Shoham's chronological ignorance [Sho88] (a point already noted by del Val and Shoham <ref> [dVS92, dVS93] </ref>), and it suffers from some of the same problems. Consider the following story, that we call the borrowed-car example. 11 (1) The agent leaves his car in a valet parking lot, (2) sits for an hour in a cafe, (3) returns to the car and starts driving home.
Reference: [dVS93] <author> A. del Val and Y. Shoham. </author> <title> Deriving properties of belief update from theories of action (II). </title> <booktitle> In Proc. Thirteenth International Joint Conference on Artificial Intelligence (IJCAI '93), </booktitle> <pages> pages 732-737, </pages> <year> 1993. </year>
Reference-contexts: How reasonable is the notion of update? As the definition of (r;m) given above suggests, it has a preference for deferring abnormal events. This makes it quite similar to Shoham's chronological ignorance [Sho88] (a point already noted by del Val and Shoham <ref> [dVS92, dVS93] </ref>), and it suffers from some of the same problems. Consider the following story, that we call the borrowed-car example. 11 (1) The agent leaves his car in a valet parking lot, (2) sits for an hour in a cafe, (3) returns to the car and starts driving home.
Reference: [dVS94] <author> A. del Val and Y. Shoham. </author> <title> A unified view of belief revision and update. </title> <journal> Journal of Logic and Computation, </journal> <note> Special issue on Actions and Processes, to appear, 1994. 11 </note>
Reference-contexts: For example, [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update <ref> [GMR92, dVS94] </ref>. Our approach is different from most in that we did not construct a specific framework to capture one or both belief change paradigms.
Reference: [EG93] <author> T. Eiter and Gottlob G. </author> <title> The complexity of nested counterfactuals and iterated knowledge base revisions. </title> <booktitle> In Proc. Thirteenth International Joint Conference on Artificial Intelligence (IJCAI '93), </booktitle> <pages> pages 526-531, </pages> <year> 1993. </year>
Reference-contexts: Thus, maps an ex tended belief set and a formula to an extended belief for similar reasons, in <ref> [Bou93, EG93] </ref>. 14 We might have defined Bel &gt; (I; s a ) as f' 2 L &gt; () j (I; s a ) j= B'g, which would have been even more in the spirit of our definition of Bel (I; s a ).
Reference: [FH94a] <author> N. Friedman and J. Y. Halpern. </author> <title> Conditional logics of belief change. </title> <type> Technical report, </type> <year> 1994. </year> <note> Submited to AAAI-94. </note>
Reference-contexts: That is, we shift the focus from finding a set of postulates for belief revision, as done by previous researchers [AGM85, Gar88, Bou92, Fuh89, Rot89], to that of finding a logical characterization of revision in terms of the properties of &gt;. In <ref> [FH94a] </ref>, it is shown that this general approach of characterizing belief change in terms of characterizing the behavior of the &gt; operator in a class of plausibility structures is relevant for all reasonable notions of belief change, not just belief revision. In particular, this is the case for belief update. <p> In particular, this is the case for belief update. The results of <ref> [FH94a] </ref> enable us to completely characterize the differences between revision and update axiomatically. <p> We refer the reader to <ref> [FH94a] </ref> for further details. Thinking in terms of &gt; helps us see connections between revision and update beyond those captured in our axioms. For one thing, it helps us make precise the intuition that both revision and update are characterized by the plausibility ordering at each state. <p> m + 1) if and only if (r 0 ; m) (r;m) (r 00 ; m). (In the terminology of [FH94b], this means that the plausibility space (r; m +1) can be understood as the result of conditioning on the plausibility space at (r; m).) These results, and those of <ref> [FH94a] </ref>, support the thesis that this language, which lets us reason about plausibility (and thus belief), belief change, time, and knowledge, is the right one with which to study belief change. 7 CONCLUSION We believe that our framework, with its natural representation of both time and belief, gives us a great
Reference: [FH94b] <author> N. Friedman and J. Y. Halpern. </author> <title> A knowledge-based framework for belief change. Part I: Foundations. </title> <editor> In R. Fa-gin, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge: Proc. Fifth Conference, </booktitle> <pages> pages 44-64. </pages> <year> 1994. </year>
Reference-contexts: The difference is that belief revision attempts to decide what beliefs should be discarded to accommodate a new belief, while belief update attempts to decide what changes in the world led to the new observation. In <ref> [FH94b] </ref> we introduce a general framework for modeling belief change. We start with the framework for analyzing knowledge in multi-agent systems, introduced in [HF89], and add to it a notion of plausibility ordering at each situation. We then define belief as truth in the most plausible situations. <p> approach|particularly in terms of the assumptions that each makes about how an agent's plausibility ordering changes over time|provide further justification as to the usefulness of having such a framework. 2 THE FRAMEWORK We now review the framework of [HF89] for modeling knowledge in multi-agent systems, and our extension of it <ref> [FH94b] </ref> for dealing with belief change. The key assumption in this framework is that we can characterize the system by describing it in terms of a state that changes over time. Formally, we assume that at each point in time, the agent is in some local state. <p> However, we can not talk about the agent's (possibly defeasible) beliefs at (r; m). To remedy this deficiency, in <ref> [FH94b] </ref> we added plausibility orderings to interpreted systems. We can then say that the agent believes ' if ' is true at all the most plausible worlds. <p> that is at least as plausible as (r 2 ; m 2 ) also satisfies . (I; r; m) j= '! if for every (r 1 ; m 1 ) 2 (r;m) such that (I; r 1 ; m 1 ) j= ', there is 2 The framework presented in <ref> [FH94b] </ref> is more general than this, dealing with multiple agents and allowing the agent to consider several plausibility spaces in each local state. <p> We now define a notion of belief. Intuitively, the agent believes ' if ' is true in all the worlds he considers most plausible. Formally, we define B' , true!'. In <ref> [FH94b] </ref> we prove that, in this framework, knowledge is an S5 operator, belief is a KD45 operator, and the interactions between knowledge and belief are captured by the axioms K' ) B' and B' ) KB'. <p> the suggestion implicit in [Bou92]. 10 1)j (r; m) 2 (r;m) ; (r; m) j= learn (') ^ fl'g, and (r 0 ; m + 1) (r;m+1) (r 00 ; m + 1) if and only if (r 0 ; m) (r;m) (r 00 ; m). (In the terminology of <ref> [FH94b] </ref>, this means that the plausibility space (r; m +1) can be understood as the result of conditioning on the plausibility space at (r; m).) These results, and those of [FH94a], support the thesis that this language, which lets us reason about plausibility (and thus belief), belief change, time, and knowledge, <p> Traditionally, belief change was considered as an abstract process. Our framework, on the other hand, models the agent and the environment he is situated in, and how both change in time. This allows us to model concrete agents in concrete settings (for example, diagnostic systems are analyzed in <ref> [FH94b] </ref>), and to reason about the beliefs and knowledge of such agents. We can then investigate what plausibility ordering induces beliefs that match our intuitions. By gaining a better understand ing of such concrete situations, we can better investigate more abstract notions of belief change.
Reference: [FHMV94] <author> R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. </author> <title> Reasoning about Knowledge. </title> <publisher> MIT Press, to appear, </publisher> <year> 1994. </year>
Reference-contexts: These definitions set the background for our presentation of belief revision and belief update. Our description is still missing a plausibility assignment function that describes the plausibility ordering of the agent at 5 We remark that P fl is similar to protocols used to model knowledge bases in <ref> [FHMV94] </ref>. each point. This function requires a different treatment for revision and update. Indeed, the plausibility function is the main source of difference between the two notions. 4 REVISION Belief revision attempts to describe how a rational agent incorporates new beliefs.
Reference: [Fuh89] <author> A. Fuhrmann. </author> <title> Reflective modalities and theory change. </title> <journal> Synthese, </journal> <volume> 81 </volume> <pages> 115-134, </pages> <year> 1989. </year>
Reference-contexts: It should thus be no surprise that assuming persistence of such formulas leads to triviality. Indeed, this observation was essentially already made by Levi [Lev88]. Our solution to the triviality result is somewhat different from others that have been considered in the literature (e.g., <ref> [Rot89, Fuh89, LR92, Bou92] </ref>) in that it shifts the focus from postulates for the revision process to considerations of the appropriate logic of conditionals. We then turn our attention to belief update. Our treatment enables us to identify implicit assumptions made in the update process. <p> Once we adopt the Ramsey test we can in fact discard postulates R1-R8 altogether, and simply define revision using Eq. (2). That is, we shift the focus from finding a set of postulates for belief revision, as done by previous researchers <ref> [AGM85, Gar88, Bou92, Fuh89, Rot89] </ref>, to that of finding a logical characterization of revision in terms of the properties of &gt;.
Reference: [Gar78] <author> P. Gardenfors. </author> <title> Conditionals and changes of belief. </title> <journal> Acta Philosophica Fennica, </journal> <volume> 20, </volume> <year> 1978. </year>
Reference-contexts: If we consider systems in S R , then extended belief sets, unlike belief sets, uniquely determine the outcome of revision. Our notion of extended belief sets is similar to a notion introduced by Gardenfors <ref> [Gar78, Gar86, Gar88] </ref>. He also considers revision of belief sets that contain conditionals of the form '&gt; .
Reference: [Gar86] <author> P. Gardenfors. </author> <title> Belief revision and the Ramsey test for conditionals. </title> <journal> Philosophical Review, </journal> <volume> 91 </volume> <pages> 81-93, </pages> <year> 1986. </year>
Reference-contexts: It allows any proposition to change its truth value, and treats this as a change in the world rather than as a change in the agent's beliefs about the world. This distinction allows us to better understand Gardenfors' triviality result <ref> [Gar86] </ref>. This result states that the belief revision postulates cannot be applied to belief states that contain Ramsey conditionals of the form '&gt; with the interpretation "revising by ' will lead to a state where is believed". <p> If we consider systems in S R , then extended belief sets, unlike belief sets, uniquely determine the outcome of revision. Our notion of extended belief sets is similar to a notion introduced by Gardenfors <ref> [Gar78, Gar86, Gar88] </ref>. He also considers revision of belief sets that contain conditionals of the form '&gt; .
Reference: [Gar88] <author> P. Gardenfors. </author> <title> Knowledge in Flux. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: The focus of this research is to understand how an agent should change his beliefs as a result of getting new information. Two instances of this general phenomenon have been studied in detail. Belief revision <ref> [AGM85, Gar88] </ref> focuses on how an agent revises his beliefs when he adopts a new belief. Belief update [KM91a], on the other hand, focuses on how an agent should change his beliefs when he realizes that the world has changed. <p> He must then discard some of his old beliefs in order to incorporate the new belief and remain con sistent. The question is which ones? The most widely accepted notion of belief revision is defined by the AGM theory <ref> [AGM85, Gar88] </ref>. The agent's epistemic state is represented as a belief set, that is, a set of formulas in L () closed under deduction. <p> We defer discussion of this approach to Section 6. Our representation brings out several issues. The revision literature usually does not address the relations between the agent's beliefs and the "real" world. (This point is explicitly discussed in <ref> [Gar88, pp 18-20] </ref>.) In fact, revision does not assume any correlation between what the agent learns and the state of the world. For example, revision allows the agent to learn (revise by) ' and then learn :'. <p> If we consider systems in S R , then extended belief sets, unlike belief sets, uniquely determine the outcome of revision. Our notion of extended belief sets is similar to a notion introduced by Gardenfors <ref> [Gar78, Gar86, Gar88] </ref>. He also considers revision of belief sets that contain conditionals of the form '&gt; . <p> Once we adopt the Ramsey test we can in fact discard postulates R1-R8 altogether, and simply define revision using Eq. (2). That is, we shift the focus from finding a set of postulates for belief revision, as done by previous researchers <ref> [AGM85, Gar88, Bou92, Fuh89, Rot89] </ref>, to that of finding a logical characterization of revision in terms of the properties of &gt;. <p> We hope that our framework will provide a useful basis for answering them. Finally, we note that our approach is quite different from the traditional approach to belief change <ref> [AGM85, Gar88, KM91a] </ref>. Traditionally, belief change was considered as an abstract process. Our framework, on the other hand, models the agent and the environment he is situated in, and how both change in time.
Reference: [GM88] <author> P. Gardenfors and D. Makinson. </author> <title> Revisions of knowledge systems using epis-temic entrenchment. </title> <editor> In M. Y. Vardi, editor, </editor> <booktitle> Proc. Second Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 83-95. </pages> <year> 1988. </year>
Reference-contexts: Essentially, it is appropriate if the agent always receives enough information to deduce the exact change in the state of the world, a condition unlikely to be met in most AI applications. We are certainly not the first to provide semantic models for belief revision and update. For example, <ref> [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] </ref> deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94].
Reference: [GMR92] <author> G. Grahne, A. Mendelzon, and R. Ri-eter. </author> <title> On the semantics of belief revision systems. </title> <editor> In Y. Moses, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge: Proc. Fourth Conference, </booktitle> <pages> pages 132-142. </pages> <year> 1992. </year>
Reference-contexts: For example, [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update <ref> [GMR92, dVS94] </ref>. Our approach is different from most in that we did not construct a specific framework to capture one or both belief change paradigms.
Reference: [GP92] <author> M. Goldszmidt and J. Pearl. </author> <title> Rank-based systems: A simple approach to belief revision, belief update and reasoning about evidence and actions. </title> <editor> In R. Parikh, editor, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proc. Third International Conference (KR '92), </booktitle> <pages> pages 661-672. </pages> <year> 1992. </year>
Reference-contexts: We are certainly not the first to provide semantic models for belief revision and update. For example, [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery <ref> [KS91, GP92] </ref> and others that simulate belief revision using belief update [GMR92, dVS94]. Our approach is different from most in that we did not construct a specific framework to capture one or both belief change paradigms.
Reference: [Gro88] <author> A. Grove. </author> <title> Two modelings for theory change. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 17 </volume> <pages> 157-170, </pages> <year> 1988. </year>
Reference-contexts: Essentially, it is appropriate if the agent always receives enough information to deduce the exact change in the state of the world, a condition unlikely to be met in most AI applications. We are certainly not the first to provide semantic models for belief revision and update. For example, <ref> [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] </ref> deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94]. <p> is coherent regarding the outcome of revision by similar formulas (e.g., ' and ' ^ ). 6 Cl (A) = f'jA ` L 'g is the deductive closure of a set of formulas A. 4 While there are several representation theorems for belief revision, the clearest is perhaps the following <ref> [Gro88, KM91b] </ref>: We associate with each belief set A a set W A of possible worlds. Intuitively, the worlds in W A are all those that are consistent with the agent's beliefs, in that W A consists of all those worlds in which all formulas in A are true. <p> The ranking prescribes how the agent revises his beliefs. When revising by ', the agent chooses the minimal worlds satisfying ' in the ranking and constructs a belief set from them. It is easy to see that this procedure for belief revision satisfies the AGM postulates. Moreover, in <ref> [Gro88, KM91b] </ref> it is shown that any belief revision operator can be described in terms of such a ranking. This representation suggests how we can capture belief revision in our framework. <p> Note that our assumptions correspond closely to those of <ref> [Gro88, KM91b] </ref>. The difference is that we have time explicitly in the picture and that our states have more structure. That is, in [Gro88, KM91b], a state is just a truth assignment. <p> Note that our assumptions correspond closely to those of <ref> [Gro88, KM91b] </ref>. The difference is that we have time explicitly in the picture and that our states have more structure. That is, in [Gro88, KM91b], a state is just a truth assignment. For us, the truth assignment is still there, as part of the environment's state, but we have also added the agent's local state.
Reference: [HF89] <author> J. Y. Halpern and R. Fagin. </author> <title> Modelling knowledge and action in distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 3(4) </volume> <pages> 159-179, </pages> <year> 1989. </year>
Reference-contexts: In [FH94b] we introduce a general framework for modeling belief change. We start with the framework for analyzing knowledge in multi-agent systems, introduced in <ref> [HF89] </ref>, and add to it a notion of plausibility ordering at each situation. We then define belief as truth in the most plausible situations. The resulting framework is very expressive; it captures both time and knowledge as well as beliefs. <p> Our approach is different from most in that we did not construct a specific framework to capture one or both belief change paradigms. Instead, we start from a natural framework to model how an agent's knowledge changes over time <ref> [HF89] </ref> and add to it machinery that captures a defeasible notion of belief. As we shall see, our framework allows us to clearly bring out the similarities and differences between update and revision. <p> We believe that the insights gained into revision and update using our approach|particularly in terms of the assumptions that each makes about how an agent's plausibility ordering changes over time|provide further justification as to the usefulness of having such a framework. 2 THE FRAMEWORK We now review the framework of <ref> [HF89] </ref> for modeling knowledge in multi-agent systems, and our extension of it [FH94b] for dealing with belief change. The key assumption in this framework is that we can characterize the system by describing it in terms of a state that changes over time.
Reference: [Kau86] <author> H. A. Kautz. </author> <title> Logic of persistence. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '86), </booktitle> <pages> pages 401-405, </pages> <year> 1986. </year>
Reference-contexts: The exact change assumed will depend on the distance 11 This example is based on Kautz's stolen car story <ref> [Kau86] </ref>, and is due to Boutilier, who independently observed this problem [private communication, 1993]. function embodied by the update operator. The key point is that update will not go back and revise the earlier beliefs about what happened between steps (1) and (2).
Reference: [KM91a] <author> H. Katsuno and A. Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proc. Second International Conference (KR '91), </booktitle> <pages> pages 387-394. </pages> <year> 1991. </year>
Reference-contexts: Two instances of this general phenomenon have been studied in detail. Belief revision [AGM85, Gar88] focuses on how an agent revises his beliefs when he adopts a new belief. Belief update <ref> [KM91a] </ref>, on the other hand, focuses on how an agent should change his beliefs when he realizes that the world has changed. Both approaches attempt to capture the intuition that an agent should fl To appear in Principles of Knowledge Representation and Reasoning: Proc. <p> Doing this allows us to compare the assumptions implicit in each method and to understand the principles underlying them. The explicit representation of time allows us to investigate some of the subtle differences between revision and update. For example, in the literature, belief revision has been described (in <ref> [KM91a] </ref>, for example) as a process of changing beliefs about a static world, but this is slightly misleading. <p> We are certainly not the first to provide semantic models for belief revision and update. For example, [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] deal with revision and <ref> [KM91a, dVS92] </ref> deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94]. <p> The problem is how a knowledge base should change when something is learned about world, such as "A table was moved from office 1 to office 2". Katsuno and Mendelzon <ref> [KM91a] </ref> suggest a set of postulates that any update operator should satisfy. The update postulates are expressed in terms of formulas, not belief sets. This is not unreasonable, since we 7 The only problematic postulate is R6. <p> We provided representation theorems for both notions and discussed issues that are specific to each notion. In this section we try to identify some common themes and points of difference. Some of the work has already been done for us by Katsuno and Mendelzon <ref> [KM91a] </ref>, who identified three significant differences between revision and update: 1. Revision deals with static propositions, while up date allows propositions that are not static. <p> We hope that our framework will provide a useful basis for answering them. Finally, we note that our approach is quite different from the traditional approach to belief change <ref> [AGM85, Gar88, KM91a] </ref>. Traditionally, belief change was considered as an abstract process. Our framework, on the other hand, models the agent and the environment he is situated in, and how both change in time.
Reference: [KM91b] <author> H. Katsuno and A. Mendelzon. </author> <title> Propositional knowledge base revision and minimal change. </title> <journal> Artificial Intelligence, </journal> <volume> 52(3) </volume> <pages> 263-294, </pages> <year> 1991. </year>
Reference-contexts: is coherent regarding the outcome of revision by similar formulas (e.g., ' and ' ^ ). 6 Cl (A) = f'jA ` L 'g is the deductive closure of a set of formulas A. 4 While there are several representation theorems for belief revision, the clearest is perhaps the following <ref> [Gro88, KM91b] </ref>: We associate with each belief set A a set W A of possible worlds. Intuitively, the worlds in W A are all those that are consistent with the agent's beliefs, in that W A consists of all those worlds in which all formulas in A are true. <p> The ranking prescribes how the agent revises his beliefs. When revising by ', the agent chooses the minimal worlds satisfying ' in the ranking and constructs a belief set from them. It is easy to see that this procedure for belief revision satisfies the AGM postulates. Moreover, in <ref> [Gro88, KM91b] </ref> it is shown that any belief revision operator can be described in terms of such a ranking. This representation suggests how we can capture belief revision in our framework. <p> Note that our assumptions correspond closely to those of <ref> [Gro88, KM91b] </ref>. The difference is that we have time explicitly in the picture and that our states have more structure. That is, in [Gro88, KM91b], a state is just a truth assignment. <p> Note that our assumptions correspond closely to those of <ref> [Gro88, KM91b] </ref>. The difference is that we have time explicitly in the picture and that our states have more structure. That is, in [Gro88, KM91b], a state is just a truth assignment. For us, the truth assignment is still there, as part of the environment's state, but we have also added the agent's local state.
Reference: [KS91] <author> H. Katsuno and K. Satoh. </author> <title> A unified view of consequence relation, belief revision and conditional logic. </title> <booktitle> In Proc. Twelfth International Joint Conference on Artificial Intelligence (IJCAI '91), </booktitle> <pages> pages 406-412, </pages> <year> 1991. </year>
Reference-contexts: We are certainly not the first to provide semantic models for belief revision and update. For example, [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery <ref> [KS91, GP92] </ref> and others that simulate belief revision using belief update [GMR92, dVS94]. Our approach is different from most in that we did not construct a specific framework to capture one or both belief change paradigms.
Reference: [KW85] <author> A. M. Keller and M. Winslett. </author> <title> On the use of an extended relational model to handle changing incomplete information. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11(7):620-633, </volume> <year> 1985. </year>
Reference-contexts: We believe that by introducing more structure it should be possible to derive reasonable constraints that will make revision a more useful tool. 5 UPDATE The notion of update originated in the database community <ref> [KW85, Win88] </ref>. The problem is how a knowledge base should change when something is learned about world, such as "A table was moved from office 1 to office 2". Katsuno and Mendelzon [KM91a] suggest a set of postulates that any update operator should satisfy.
Reference: [Lev88] <author> I. Levi. </author> <title> Iteration of conditionals and the Ramsey test. </title> <journal> Synthese, </journal> <volume> 76 </volume> <pages> 49-81, </pages> <year> 1988. </year>
Reference-contexts: It should thus be no surprise that assuming persistence of such formulas leads to triviality. Indeed, this observation was essentially already made by Levi <ref> [Lev88] </ref>. Our solution to the triviality result is somewhat different from others that have been considered in the literature (e.g., [Rot89, Fuh89, LR92, Bou92]) in that it shifts the focus from postulates for the revision process to considerations of the appropriate logic of conditionals.
Reference: [Lew73] <author> D. K. Lewis. </author> <title> Counterfactuals. </title> <publisher> Harvard University Press, </publisher> <year> 1973. </year>
Reference-contexts: We would like '! to be true at (r; m) if the most plausible points in (r;m) that satisfy ' also satisfy . The actual definition that we use, which is standard in the literature (see <ref> [Lew73, Bur81, Bou92] </ref>), captures this desideratum if there are most plausible points that satisfy ' (in particular, if (r;m) is finite), and also deals with the more general case where there may be a sequence of increasingly more plausible points, with none being most plausible, i.e., : : : s 3
Reference: [LR92] <author> S. Lindstrom and W. Rabinowicz. </author> <title> Belief revision, epistemic conditionals and the Ramsey test. </title> <journal> Synthese, </journal> <volume> 91 </volume> <pages> 195-237, </pages> <year> 1992. </year>
Reference-contexts: It should thus be no surprise that assuming persistence of such formulas leads to triviality. Indeed, this observation was essentially already made by Levi [Lev88]. Our solution to the triviality result is somewhat different from others that have been considered in the literature (e.g., <ref> [Rot89, Fuh89, LR92, Bou92] </ref>) in that it shifts the focus from postulates for the revision process to considerations of the appropriate logic of conditionals. We then turn our attention to belief update. Our treatment enables us to identify implicit assumptions made in the update process.
Reference: [Rij92] <author> M. de Rijke. </author> <title> Meeting some neighbors. </title> <institution> Research Report LP-92-10, University of Am-sterdam, </institution> <year> 1992. </year>
Reference-contexts: Essentially, it is appropriate if the agent always receives enough information to deduce the exact change in the state of the world, a condition unlikely to be met in most AI applications. We are certainly not the first to provide semantic models for belief revision and update. For example, <ref> [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] </ref> deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94].
Reference: [Rot89] <author> H. Rott. </author> <title> Conditionals and theory change: revision, expansions, and additions. </title> <journal> Syn-these, </journal> <volume> 81 </volume> <pages> 91-113, </pages> <year> 1989. </year>
Reference-contexts: It should thus be no surprise that assuming persistence of such formulas leads to triviality. Indeed, this observation was essentially already made by Levi [Lev88]. Our solution to the triviality result is somewhat different from others that have been considered in the literature (e.g., <ref> [Rot89, Fuh89, LR92, Bou92] </ref>) in that it shifts the focus from postulates for the revision process to considerations of the appropriate logic of conditionals. We then turn our attention to belief update. Our treatment enables us to identify implicit assumptions made in the update process. <p> Once we adopt the Ramsey test we can in fact discard postulates R1-R8 altogether, and simply define revision using Eq. (2). That is, we shift the focus from finding a set of postulates for belief revision, as done by previous researchers <ref> [AGM85, Gar88, Bou92, Fuh89, Rot89] </ref>, to that of finding a logical characterization of revision in terms of the properties of &gt;.
Reference: [Rot91] <author> H. Rott. </author> <title> Two methods of constructing contractions and revisions of knowledge systems. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 20 </volume> <pages> 149-173, </pages> <year> 1991. </year>
Reference-contexts: Essentially, it is appropriate if the agent always receives enough information to deduce the exact change in the state of the world, a condition unlikely to be met in most AI applications. We are certainly not the first to provide semantic models for belief revision and update. For example, <ref> [AGM85, Gro88, GM88, Rot91, Bou92, Rij92] </ref> deal with revision and [KM91a, dVS92] deal with update. In fact, there are several works in the literature that capture both using the same machinery [KS91, GP92] and others that simulate belief revision using belief update [GMR92, dVS94].
Reference: [Sho88] <author> Y. Shoham. </author> <title> Chronological ignorance: experiments in nonmonotonic temporal reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 271-331, </pages> <year> 1988. </year>
Reference-contexts: How reasonable is the notion of update? As the definition of (r;m) given above suggests, it has a preference for deferring abnormal events. This makes it quite similar to Shoham's chronological ignorance <ref> [Sho88] </ref> (a point already noted by del Val and Shoham [dVS92, dVS93]), and it suffers from some of the same problems.
Reference: [Win88] <author> M. Winslett. </author> <title> Reasoning about action using a possible models approach. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '88), </booktitle> <pages> pages 89-93, </pages> <year> 1988. </year> <month> 12 </month>
Reference-contexts: We believe that by introducing more structure it should be possible to derive reasonable constraints that will make revision a more useful tool. 5 UPDATE The notion of update originated in the database community <ref> [KW85, Win88] </ref>. The problem is how a knowledge base should change when something is learned about world, such as "A table was moved from office 1 to office 2". Katsuno and Mendelzon [KM91a] suggest a set of postulates that any update operator should satisfy.
References-found: 35

