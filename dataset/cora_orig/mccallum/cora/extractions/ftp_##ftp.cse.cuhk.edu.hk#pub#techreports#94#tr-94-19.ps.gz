URL: ftp://ftp.cse.cuhk.edu.hk/pub/techreports/94/tr-94-19.ps.gz
Refering-URL: ftp://ftp.cs.cuhk.hk/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Performance of a Data-Parallel Concurrent Constraint Programming System  
Author: Bo-Ming Tong and Ho-Fung Leung 
Keyword: performance evaluation, parallelism, finite domain constraints, concurrent constraint programming  
Address: Shatin, New Territories Hong Kong  
Affiliation: Department of Computer Science The Chinese University of Hong Kong  
Abstract: Firebird [12] is a data-parallel concurrent constraint programming system. It is shown that finite domain constraint languages can be implemented on massively parallel SIMD machines. Firebird has been further enhanced with parallel backtracking capability and the design of the Data-Parallel Abstract Machine, the basis of Firebird's implementation, has been presented in [13]. An almost complete implementation has been built on a DECmpp 12000 Sx-100 z massively parallel computer with 8,192 processor elements and some preliminary performance results are given in this paper. A speedup of 2 orders of magnitude is possible when we compare the performance using 8,192 processor elements and the performance using a single processor element of the same machine. Furthermore, the speedup is scalable, provided that the problem size is large enough for effective exploitation of or-parallelism. On the other hand, we measure the effects of several control strategies and optimizations on execution time and memory consumption in a data-parallel context. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. At-Kaci. </author> <title> Warren's Abstract Machine: A Tutorial Reconstruction. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The reader is referred to [13] for the details of parallel backtracking. 2.3 Data-Parallel Abstract Ma- chine The Data-Parallel Abstract Machine 3 (DPAM) is the basis of the implementation of Firebird. We assume the knowledge of Warren's Abstract Machine (WAM) <ref> [1] </ref>. 2.3.1 Hardware We assume that the implementation platform consists of a sequential front end called the host computer and a data-parallel back end called the processor element array. The host computer is responsible for dispatching instructions and broadcasting data to the processor element array.
Reference: [2] <author> B. Carlson, M. Carlsson, and D. Diaz. </author> <title> Entailment of finite domain constraints. </title> <booktitle> In Logic Programming: Proceedings of the Eleventh International Conference, S. </booktitle> <address> Margherita Lig-ure, Italy, 1994. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Except for the magic series problem, the results indicate that our implementation has very poor performance compared to CHIP. The magic series problem has good performance because Firebird is a concurrent language which allows a different formulation of the problem using entailment (ask) constraints <ref> [2, 8] </ref>. We attribute this to the deficiency of our implementation platform. We profile our execution and find that an average machine instruction requires about 10 machine cycles to execute on our 12.5 MHz DECmpp 12000 Sx-100.
Reference: [3] <author> D. Diaz and P. Codognet. </author> <title> A minimal extension of the WAM for clp(FD). </title> <editor> In D. S. Warren, editor, </editor> <booktitle> Logic Programming: Proceedings of the Tenth International Conference, </booktitle> <pages> pages 774-790, </pages> <address> Budapest, Hungary, 1993. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Table 5: Benchmark: on demand creation of bit vectors 3.3 Bit Vectors of Domain Vari ables The domain of a domain variable is represented by a bit vector. Many newer finite domain constraint programming systems, like clp (FD) <ref> [3] </ref> and cc (FD) [16], do not have bit vectors for continuous domains. A bit vector is created on demand only when the domain is broken into two parts because one of the invalid values is removed.
Reference: [4] <author> Y. Kanada, K. Kojima, and M. Sugaya. </author> <title> Vectorization techniques for Prolog. </title> <booktitle> In Proceedings of the ACM International Conference on Supercomputing, </booktitle> <pages> pages 539-549, </pages> <address> St. Malo, </address> <year> 1988. </year>
Reference-contexts: A new disj operator is introduced. Solutions to a disjunctive goal disj G are collected. The solutions form a disjunctive set of environments and goals appearing after G can be executed in these environments in parallel. No special language constructs are needed in Firebird. <ref> [4] </ref>, SIMD MultiLog and Firebird all execute goals over a disjunctive set of environments 7 , exploiting or-parallelism. [4] relies on a vectorizing compiler, Multi-Log uses solution aggregation and in Fire-bird the environments fall out of the labeling operation on domain variables naturally. <p> The solutions form a disjunctive set of environments and goals appearing after G can be executed in these environments in parallel. No special language constructs are needed in Firebird. <ref> [4] </ref>, SIMD MultiLog and Firebird all execute goals over a disjunctive set of environments 7 , exploiting or-parallelism. [4] relies on a vectorizing compiler, Multi-Log uses solution aggregation and in Fire-bird the environments fall out of the labeling operation on domain variables naturally. Like our approach, MultiLog has the advantage that traditional compilation techniques are applicable.
Reference: [5] <author> S. Kliger and E. Shapiro. </author> <title> From decision trees to decision graphs. </title> <editor> In S. Debray and M. Hermenegildo, editors, </editor> <booktitle> Proceedings of the 1990 North American Conference on Logic Programming, </booktitle> <pages> pages 97-116, </pages> <address> Austin, 1990. </address> <publisher> ALP, The MIT Press. </publisher>
Reference-contexts: The contingent bits are used to implement the mask bit vector (Section 2.2.3). 2.3.2 Implementation Overview A Firebird system consists of a compiler, either an emulator or a native code generator, a concurrent process scheduler and a runtime library. The compiler employs the decision graph <ref> [5] </ref> technique to compile a Firebird program to DPAM code. The instruction set is designed in such a way that the same compiler can be used for both sequential and data-parallel implementations.
Reference: [6] <author> M. J. Maher. </author> <title> Logic semantics for a class of committed-choice programs. </title> <editor> In J.- L. Lassez, editor, </editor> <booktitle> Logic Programming: Proceedings of the Fourth International Conference, </booktitle> <pages> pages 858-876, </pages> <address> Melbourne, 1987. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: In the next section, we give a brief review of [12, 13]. The reader is referred to [15] for an introduction to the use of finite domain constraints in logic programming, and to <ref> [6, 7, 8] </ref> for concurrent constraint programming. Section 3 is the performance data and section 4 is a compar-ison between SIMD MultiLog [9] and Fire-bird.
Reference: [7] <author> V. A. Saraswat. </author> <title> A somewhat logical formulation of CLP synchronisa-tion primitives. </title> <editor> In R. A. Kowalski and K. A. Bowen, editors, </editor> <booktitle> Logic Programming: Proceedings of the Fifth International Conference and Symposium, </booktitle> <pages> pages 1298-1314, </pages> <address> Seatle, 1988. </address> <publisher> ALP, IEEE, The MIT Press. </publisher>
Reference-contexts: In the next section, we give a brief review of [12, 13]. The reader is referred to [15] for an introduction to the use of finite domain constraints in logic programming, and to <ref> [6, 7, 8] </ref> for concurrent constraint programming. Section 3 is the performance data and section 4 is a compar-ison between SIMD MultiLog [9] and Fire-bird.
Reference: [8] <author> V. A. Saraswat and M. Rinard. </author> <title> Concurrent constraint programming. </title> <booktitle> In Proceedings of the 17th Symposium on Principles of Programming Languages, </booktitle> <pages> pages 232-244, </pages> <address> San Fransisco, </address> <year> 1990. </year>
Reference-contexts: In the next section, we give a brief review of [12, 13]. The reader is referred to [15] for an introduction to the use of finite domain constraints in logic programming, and to <ref> [6, 7, 8] </ref> for concurrent constraint programming. Section 3 is the performance data and section 4 is a compar-ison between SIMD MultiLog [9] and Fire-bird. <p> Except for the magic series problem, the results indicate that our implementation has very poor performance compared to CHIP. The magic series problem has good performance because Firebird is a concurrent language which allows a different formulation of the problem using entailment (ask) constraints <ref> [2, 8] </ref>. We attribute this to the deficiency of our implementation platform. We profile our execution and find that an average machine instruction requires about 10 machine cycles to execute on our 12.5 MHz DECmpp 12000 Sx-100.
Reference: [9] <author> D. A. Smith. MultiLog: </author> <title> Data or-parallel logic programming. </title> <editor> In D. S. Warren, editor, </editor> <booktitle> Logic Programming: Proceedings of the Tenth International Conference, </booktitle> <pages> pages 314-331, </pages> <address> Budapest, Hungary, 1993. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: The reader is referred to [15] for an introduction to the use of finite domain constraints in logic programming, and to [6, 7, 8] for concurrent constraint programming. Section 3 is the performance data and section 4 is a compar-ison between SIMD MultiLog <ref> [9] </ref> and Fire-bird. We conclude with section 5. 2 Firebird: A Review 2.1 The Firebird Computation Model In Firebird, the notions of committed-choice indeterminism and don't know nondetermin-ism are integrated using the Firebird Computation Model. <p> Since a processor-id is associated with each processor element, each processor element can compute which alternative it should take autonomously. Compared to SIMD MultiLog <ref> [9] </ref>, our model has the advantage that inter-processor communication is not necessary. We expect a performance gain in SIMD MultiLog if our mapping technique is ap plied. 2.2.3 Masks Consider the following example. p ([H|T]) :- H &gt; 0 | q (H), p (T). <p> For these reasons, we estimate that a single processor element of our implementation platform is about 50 times slower than an average workstation. The same result is observed in the implementation of SIMD MultiLog <ref> [9] </ref>. One could always enhance the speed of 5 For example, a conditional branch. One instruction is used to move each processor's flag to the contingent bit. The next instruction obtains the global or-ing of all contingent bits and stores the result in the carry flag of the host. <p> For the 8-queens problem, 64 processor elements are just enough for the first two nondeterministic derivation steps. The plot is shown in Figure 7. 4 A Comparison with SIMD MultiLog SIMD MultiLog <ref> [9] </ref> is another or-parallel system implemented on the MasPar MP-1 (equivalent to the DECmpp we are using). A new disj operator is introduced. Solutions to a disjunctive goal disj G are collected. <p> Automatic compilation of the engine/multi distinction is possible and there is no inherent technical difficulty to add it to Firebird. The current MasPar implementation of SIMD MultiLog has the overhead of environment copying which is not necessary in our Firebird implementation. <ref> [9] </ref> points out that environment copying is a performance bottleneck. However, there is no technical difficulty to incorporate our processor element mapping technique to SIMD Mul-tiLog, and we would expect a tremendous performance gain.
Reference: [10] <author> D. A. Smith, </author> <year> 1994. </year> <type> Personal communication. </type>
Reference-contexts: When the execution time of MultiLog using 8,192 processor elements and that of using a workstation are compared, 10 out of the 16 programs in a benchmark suite <ref> [10] </ref> (Path, Sat, Tri, WIM, 12-queens, Knight, Waltz, 11-Bratko, Cube, 11-queens) have a speedup at or below 3.5.
Reference: [11] <author> D. A. Smith. </author> <title> Why multi-SLD beats SLD (even on a uniprocessor). </title> <booktitle> In Proceedings of the Sixth International Symposium on Programming Language Implementation and Logic Programming, </booktitle> <address> Madrid, Spain, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Like our approach, MultiLog has the advantage that traditional compilation techniques are applicable. Furthermore, engine variables which reside on the host computer are distinguished manually from multi variables which reside on the processor elements. This leads to higher time and space efficiency. See <ref> [11] </ref> for a theoretical analysis of the resulting performance gain. Automatic compilation of the engine/multi distinction is possible and there is no inherent technical difficulty to add it to Firebird.
Reference: [12] <author> B. M. Tong and H. F. Leung. </author> <title> Concurrent constraint logic programming on Massively parallel SIMD computers. </title> <editor> In D. Miller, editor, </editor> <booktitle> Logic Programming: Proceedings of the 1993 International Symposium, </booktitle> <pages> pages 388-402, </pages> <address> Vancouver, Canada, October 1993. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: 1 Introduction To the best of our knowledge, Firebird <ref> [12] </ref> is the first data-parallel concurrent constraint programming system. It is shown that finite domain constraint languages [15] can be implemented efficiently on massively parallel SIMD computer systems. The syntax of Firebird is similar to mainstream concurrent logic programming languages, in particular, flat GHC [14]. <p> In this paper, we present some preliminary performance results of our implementation. we also measure the effects of several control strategies and optimizations on execution time and memory consumption in a data-parallel context. In the next section, we give a brief review of <ref> [12, 13] </ref>. The reader is referred to [15] for an introduction to the use of finite domain constraints in logic programming, and to [6, 7, 8] for concurrent constraint programming. Section 3 is the performance data and section 4 is a compar-ison between SIMD MultiLog [9] and Fire-bird. <p> Vector memory areas include the argument stack, the trail stack and the heap. The host computer is responsible for process scheduling and choice point management. Scalar memory areas include the choice point stack and the process stack. 3 Also known previously in <ref> [12] </ref> as the Firebird Abstract Machine. 2.3.3 Heap Frames On many data-parallel computers (e.g. MasPar MP-1, Connection Machine CM-2 and some vector supercomputers) local indirect addressing (each processor element accesses a different memory location) is slower than direct addressing (each processor element accesses the same memory location). <p> We test an earlier version of Firebird on a newer model, MasPar MP-2, which is binary compatible with the DECmpp 12000 Sx-100 we are currently using, and found that it is about 2 times faster on the n-queens problem 6 . See <ref> [12] </ref> for the benchmark. 3.2 Solitary Mode On our implementation platform, DECmpp, 16 processor elements form a cluster and share a single 8-bit memory port. We would 6 The manufacturer claims a speedup of up to 4.5, without any modifications to the program.
Reference: [13] <author> B. M. Tong and H. F. Leung. </author> <title> Implementation of a data-parallel concurrent constraint programming system. </title> <booktitle> In Proceedings of the First International Symposium on Parallel Symbolic Computation, </booktitle> <pages> pages 382-393, </pages> <address> Linz, Austria, </address> <month> September </month> <year> 1994. </year> <title> World Scientific. </title>
Reference-contexts: Alternatives of such choice points can be attempted in parallel on a data-parallel machine. We have enhanced Firebird with parallel backtracking capability and we have presented the Data-Parallel Abstract Machine which forms the basis of Firebird's implementation <ref> [13] </ref>. In this paper, we present some preliminary performance results of our implementation. we also measure the effects of several control strategies and optimizations on execution time and memory consumption in a data-parallel context. In the next section, we give a brief review of [12, 13]. <p> In this paper, we present some preliminary performance results of our implementation. we also measure the effects of several control strategies and optimizations on execution time and memory consumption in a data-parallel context. In the next section, we give a brief review of <ref> [12, 13] </ref>. The reader is referred to [15] for an introduction to the use of finite domain constraints in logic programming, and to [6, 7, 8] for concurrent constraint programming. Section 3 is the performance data and section 4 is a compar-ison between SIMD MultiLog [9] and Fire-bird. <p> We adopt the synchronous backtracking approach, in which the partitions which have finished wait until all partitions have finished before going back to the last choice point. The advantage of this approach is lower trail and choice-point management overhead. The reader is referred to <ref> [13] </ref> for the details of parallel backtracking. 2.3 Data-Parallel Abstract Ma- chine The Data-Parallel Abstract Machine 3 (DPAM) is the basis of the implementation of Firebird. <p> When a process is resumed, it is first moved to the resumption queue. The processes in the resumption queue are moved to the ready queue when the processes in the ready queue are exhausted. Please refer to <ref> [13] </ref> for a detailed description of DPAM's scheduling subsystem. 3 Performance Results The aim of this section is to evaluate the performance of our data-parallel implementation and to analyze the effects of a number of design decisions.
Reference: [14] <author> K. Ueda. </author> <title> Guarded horn clauses. </title> <editor> In E. Wada, editor, </editor> <booktitle> Logic Programming '85 | Proceedings of the 4th Conference, Lecture Notes in Computer Science 221, </booktitle> <pages> pages 168-179, </pages> <address> Tokyo, July 1985. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: It is shown that finite domain constraint languages [15] can be implemented efficiently on massively parallel SIMD computer systems. The syntax of Firebird is similar to mainstream concurrent logic programming languages, in particular, flat GHC <ref> [14] </ref>.
Reference: [15] <author> P. Van Hentenryck. </author> <title> Constraint Satisfaction in Logic Programming. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction To the best of our knowledge, Firebird [12] is the first data-parallel concurrent constraint programming system. It is shown that finite domain constraint languages <ref> [15] </ref> can be implemented efficiently on massively parallel SIMD computer systems. The syntax of Firebird is similar to mainstream concurrent logic programming languages, in particular, flat GHC [14]. <p> In the next section, we give a brief review of [12, 13]. The reader is referred to <ref> [15] </ref> for an introduction to the use of finite domain constraints in logic programming, and to [6, 7, 8] for concurrent constraint programming. Section 3 is the performance data and section 4 is a compar-ison between SIMD MultiLog [9] and Fire-bird. <p> In a nondeterministic derivation step, a choice point based on one of the domain variables in the system is set up and all possible values in its domain are attempted in an or-parallel manner. The domain variable used in a nondeterministic derivation step is said to be labeled 1 <ref> [15] </ref> and each or-parallel branch is called a partition.
Reference: [16] <author> P. Van Hentenryck, V. A. Saraswat, and Y. Deville. </author> <title> Design, implementation and evaluation of the constraint language cc(FD). </title> <type> Technical Report CS-93-02, </type> <institution> Department of Computer Science, Brown University, Providence, </institution> <year> 1993. </year>
Reference-contexts: Table 5: Benchmark: on demand creation of bit vectors 3.3 Bit Vectors of Domain Vari ables The domain of a domain variable is represented by a bit vector. Many newer finite domain constraint programming systems, like clp (FD) [3] and cc (FD) <ref> [16] </ref>, do not have bit vectors for continuous domains. A bit vector is created on demand only when the domain is broken into two parts because one of the invalid values is removed.
References-found: 16

