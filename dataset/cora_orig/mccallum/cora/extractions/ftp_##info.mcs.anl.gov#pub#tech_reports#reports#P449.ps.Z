URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P449.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Email: E-mail: kwong@mcs.anl.gov tang@mcs.anl.gov  
Title: W -Matrices, Nonorthogonal Multiresolution Analysis, and Finite Signals of Arbitrary Length  
Author: Man Kam Kwong and P. T. Peter Tang 
Address: Argonne, IL 60439-4844  
Affiliation: Mathematics and Computer Science Division Argonne National Laboratory  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Chui, C. K., </author> <title> An Introduction to Wavelets, </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: in the family have the form K = B B B B B B B B @ 2 3 1 1 3 3 1 1 3 3 1 1 3 2 1 C C C C C C C C : (3:1) The building blocks are the g- and h-vectors <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]. The top two rows and bottom two rows are obtained from the basic vectors by adding the number (s) that has (have) been cut off to the nearest neighborhood that is retained. <p> form K = B B B B B B B B @ 2 3 1 1 3 3 1 1 3 3 1 1 3 2 1 C C C C C C C C : (3:1) The building blocks are the g- and h-vectors <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]. The top two rows and bottom two rows are obtained from the basic vectors by adding the number (s) that has (have) been cut off to the nearest neighborhood that is retained. <p> Although the inverse matrix K 1 has a structure similar to that of K, it is more appropriate to think of K 1 as being built by columns instead of rows. The building blocks of K 1 are thus the g-vector and h-vector <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]: (3:3) They are dual to the g- and h-vectors of K, respectively. <p> Although the inverse matrix K 1 has a structure similar to that of K, it is more appropriate to think of K 1 as being built by columns instead of rows. The building blocks of K 1 are thus the g-vector and h-vector <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]: (3:3) They are dual to the g- and h-vectors of K, respectively. <p> The relative errors between the original and the restored approximation, measured using the Euclidean l 2 norm, are given. Our first example uses the signal x = sin ((1:100)=10) + 0:2 sin ((1:100)=2), where 1:100 denotes the vector <ref> [1; 2; 3; ; 100] </ref>. In Table 2, the first column gives the number of components in y 2 that are retained. The third and fourth columns give the relative l 2 error of the restored signal, for the QS and D 4 transforms, respectively. <p> Theorem 6 All orthogonal W -matrices of order 4 are generated by the pair of basic vectors (after being normalized to be of unit length) g = <ref> [1; ff; fffi; fi] </ref> (6:13) h = [1; ff; ff=fi; 1=fi] (6:14) for arbitrary real numbers ff and fi. <p> Theorem 6 All orthogonal W -matrices of order 4 are generated by the pair of basic vectors (after being normalized to be of unit length) g = [1; ff; fffi; fi] (6:13) h = <ref> [1; ff; ff=fi; 1=fi] </ref> (6:14) for arbitrary real numbers ff and fi. <p> The signal restored from y 1 is thus a linear combination of translates of some basic signal, which is the J times inverse transform of the (y 1 ) vector <ref> [0; 1; 0] </ref> 0 | by this, we mean that we take the J -th level y 1 vector to be [0; 1; 0] 0 , and y 2 at all levels to be zero, and we compute the original signal that gives this decomposition. <p> signal restored from y 1 is thus a linear combination of translates of some basic signal, which is the J times inverse transform of the (y 1 ) vector <ref> [0; 1; 0] </ref> 0 | by this, we mean that we take the J -th level y 1 vector to be [0; 1; 0] 0 , and y 2 at all levels to be zero, and we compute the original signal that gives this decomposition. We normalize this signal by multiplying it with a constant so that the maximum of the signal is 1. <p> In a similar way, the J -times-inverse transform of the (y 2 ) vector <ref> [0; 1; 0] </ref> 0 , after normalizing to have maximum 1, is the J -th wavelet signal. As J ! 1, the J -th wavelet signal may converge to a continuous wavelet. <p> Then OE satisfies the dilation equation OE (x) = P X where g = [g 1 ; ; g n ] is the first basic vector of the inverse W -matrix. In particular, the QS scaling function satisfies OE (x) = 4 It is well known (see, for example, <ref> [1] </ref>) that OE is the classical quadratic spline. The wavelet defined here coincides with the classical wavelet in the case where the multiresolution analysis is orthogonal. In the contrary case, we can consider our wavelet as a generalization of the classical wavelet.
Reference: [2] <author> Daubechies, </author> <title> I, Ten Lectures on Wavelets, </title> <journal> CBMS-NSF Series Appl. Math., SIAM, </journal> <year> 1991. </year>
Reference-contexts: (this can be adequately explained only by referring to the scaling function associated with the transform; see Section 7). 2.2 The Daubechies D 4 Transform Daubechies made a significant contribution when she constructed higher-order orthogonal wavelets of compact support that led to discrete wavelet transforms generalizing the classical Haar transform <ref> [2] </ref>. To fully understand the beauty of her wavelets and the motivation for imposing certain properties requires a fair amount of reading. However, her wavelet transforms can still be appreciated and applied without delving too much into the technical details of wavelet theory. <p> The relative errors between the original and the restored approximation, measured using the Euclidean l 2 norm, are given. Our first example uses the signal x = sin ((1:100)=10) + 0:2 sin ((1:100)=2), where 1:100 denotes the vector <ref> [1; 2; 3; ; 100] </ref>. In Table 2, the first column gives the number of components in y 2 that are retained. The third and fourth columns give the relative l 2 error of the restored signal, for the QS and D 4 transforms, respectively.
Reference: [3] <author> Mallat, S. G., </author> <title> A theory for multiresolution signal decomposition: The wavelet representation, </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence 11 (1989), </journal> <pages> 674-693. </pages>
Reference-contexts: in the family have the form K = B B B B B B B B @ 2 3 1 1 3 3 1 1 3 3 1 1 3 2 1 C C C C C C C C : (3:1) The building blocks are the g- and h-vectors <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]. The top two rows and bottom two rows are obtained from the basic vectors by adding the number (s) that has (have) been cut off to the nearest neighborhood that is retained. <p> form K = B B B B B B B B @ 2 3 1 1 3 3 1 1 3 3 1 1 3 2 1 C C C C C C C C : (3:1) The building blocks are the g- and h-vectors <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]. The top two rows and bottom two rows are obtained from the basic vectors by adding the number (s) that has (have) been cut off to the nearest neighborhood that is retained. <p> Although the inverse matrix K 1 has a structure similar to that of K, it is more appropriate to think of K 1 as being built by columns instead of rows. The building blocks of K 1 are thus the g-vector and h-vector <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]: (3:3) They are dual to the g- and h-vectors of K, respectively. <p> Although the inverse matrix K 1 has a structure similar to that of K, it is more appropriate to think of K 1 as being built by columns instead of rows. The building blocks of K 1 are thus the g-vector and h-vector <ref> [1; 3; 3; 1] </ref> and [1; 3; 3; 1]: (3:3) They are dual to the g- and h-vectors of K, respectively. <p> The relative errors between the original and the restored approximation, measured using the Euclidean l 2 norm, are given. Our first example uses the signal x = sin ((1:100)=10) + 0:2 sin ((1:100)=2), where 1:100 denotes the vector <ref> [1; 2; 3; ; 100] </ref>. In Table 2, the first column gives the number of components in y 2 that are retained. The third and fourth columns give the relative l 2 error of the restored signal, for the QS and D 4 transforms, respectively. <p> We can see that the scaling function we define here coincides with the classical scaling function defined as in <ref> [3] </ref> by the following theorem. Theorem 7 Let OE be the scaling function, if it exists, corresponding to a W -matrix.
Reference: [4] <author> Taswell, C. and McGill, K. C., </author> <title> Wavelet transform algorithms for finite-duration discrete-time signals, Numerical Analysis Project Manuscript NA-91-07, </title> <institution> Department of Computer Science, Stanford University, </institution> <year> 1991. </year>
Reference-contexts: This new approach allows us efficiently to handle signals of any length; thus, one is not restricted to work with signal or image sizes that are multiples of a power of 2. A different method for dealing with signals of arbitrary length was given earlier by Taswell and McGill <ref> [4] </ref>. Our method does not lengthen the output signal and does not require an additional bookkeeping vector. fl This is an abridged version of a forthcoming paper. This work was supported by the Office of Scientific Computing, U.S. Department of Energy, under Contract W-31-109-Eng-38. <p> Since the total number of components of the output signal is always the same as the length of x, the latter can be restored without additional information (other than the number of multiresolution analysis levels applied). See Taswell <ref> [4] </ref> for a different technique in dealing with signals of odd length.
Reference: [5] <author> Kwong, Man Kam, </author> <title> MATLAB Implementation of W -Matrix Multires-olution Analyses, </title> <institution> Argonne National Laboratory Preprint Series MCS-P462-0894, </institution> <year> 1994. </year>
Reference-contexts: The experiments mentioned in this article were carried out in Matlab; most of the formulas, especially those involving matrix inverses, were derived by using Maple. We acknowledge the usefulness of these excellent packages. A description of our Matlab implementation can be found in <ref> [5] </ref>. The paper and the Matlab toolbox can be obtained through ftp at info.mcs.anl.gov under the directory /pub/W-transform. 2 Motivation the Haar and Daubechies D 4 Transforms Our goal is signal compression, and we look at two well-known wavelet transforms in the light of this objective. We permit lossy compression.
References-found: 5

