URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/ADBIS97_dbsim/adbis97.ps
Refering-URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/tech_papers.html
Root-URL: 
Title: Concurrency Control in Distributed Object-Oriented Database Systems  
Author: Kjetil Nrvag, Olav Sandsta, and Kjell Bratbergsengen 
Address: Trondheim, Norway  
Affiliation: Department of Computer and Information Science Norwegian University of Science and Technology  
Abstract: Simulating distributed database systems is inherently difficult, as there are many factors that may influence the results. This includes architectural options as well as workload and data distribution. In this paper we present the DBsim simulator and some simulation results. The DBsim simulator architecture is extendible, and it is easy to change parameters and configuration. The simulation results in this paper is a comparison of performance and response times for two concurrency control algorithms, timestamp ordering and two-phase locking. The simulations have been run with different number of nodes, network types, data declustering and workloads. The results show that for a mix of small and long transactions, the throughput is significantly higher for a system with a timestamp ordering scheduler than for a system with a two-phase locking scheduler. With only short transactions, the performance of the two schedulers are almost identical. Long transactions are treated more fair by a two-phase locking scheduler, because a timestamp ordering scheduler has a very high abort rate for long transactions.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, M. J. Carey, and M. Livny. </author> <title> Concurrency Control Performance Modeling: Alternatives and Implications. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 12(4), </volume> <year> 1987. </year>
Reference-contexts: In Section 6 we discuss possible weaknesses and shortcomings in our model. Finally, in Section 7, we present future work and concludes the paper. 2 Related Work Much work has been done in studying characteristics of centralized schedulers. An interesting model and simulation results can be found in <ref> [1] </ref> by Agrawal, Carey and Livny. Less has been done in the area of distributed schedulers. The work that has been done has been mostly theoretical, but some interesting simulation models have been developed and simulated at the University of Wisconsin. <p> In our simulations we have used a warm-up phase consisting of 2000 transactions before we start collecting data. Size of Address Space. Number of elements (pages) in the address space is important. Agrawal et. al. <ref> [1] </ref> argues for setting this to a low value, to increase the number of conflicts. In our simulations we have set the address space to 20000 elements. Advances in Databases and Information Systems, 1997 6 Concurrency Control in Distributed Object-Oriented Database Systems Data Declustering.
Reference: [2] <author> N. S. Barghouti and G. E. Kaiser. </author> <title> Concurrency Control in Advanced Database Applications. </title> <journal> ACM Computer Surveys, </journal> <volume> 23(3), </volume> <year> 1991. </year>
Reference-contexts: If one wants to model the databases of the future, more modern transaction concepts could be evaluated, such concepts are described in [4] and <ref> [2] </ref>. 8 Acknowledgments We thank Rune Hjelsvold for contributing to the first version of the centralized database system simulator.
Reference: [3] <author> P. A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley Publishing Company Inc., </publisher> <year> 1987. </year>
Reference-contexts: In the simulation model we use the number of concurrent transactions as the main criteria for load on the system. In every simulation we have a fixed number of active transactions. This is a good approximation to a system with constant load. In <ref> [3] </ref>, this is called multiprogramming level (MPL). Every time a transaction finishes, a new one is started (after some random delay). Address Space The database contains a fixed number of data elements. Each data element is addressed by a number in the interval [0, max].
Reference: [4] <author> A. Biliris, S. Dar, N. Gehani, H. Jagadish, and K. Ramamritham. </author> <title> A Flexible Transaction Facility for an Object-Oriented Database. </title> <type> Technical report, </type> <institution> AT&T Bell Labs, </institution> <year> 1992. </year>
Reference-contexts: One particularly interesting scheduler strategy, is multi granularity locking, which is a) easy to implement and b) efficient, and able to give a considerable improved performance. If one wants to model the databases of the future, more modern transaction concepts could be evaluated, such concepts are described in <ref> [4] </ref> and [2]. 8 Acknowledgments We thank Rune Hjelsvold for contributing to the first version of the centralized database system simulator.
Reference: [5] <author> M. J. Carey, M. J. Franklin, and M. Zaharioudakis. </author> <title> Fine Grained Sharing in a Page Server OODBMS. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD, </booktitle> <year> 1994. </year>
Reference-contexts: That means, instead of sending the queries to the data, data is sent to the queries. The most popular data granularity is pages. This is the easiest to implement, the most common in todays object-oriented DBMS, and also the granularity that gives the best performance <ref> [5] </ref>. Well-known centralized concurrency control techniques can be extended to solve the problem of concurrency control in distributed databases, but not all concurrency control techniques are suitable for a distributed database.
Reference: [6] <author> M. J. Carey and M. Livny. </author> <title> Parallelism and Concurrency Control Performance in Distributed Database Machines. </title> <booktitle> In Proceedings of the 1989 ACM SIGMOD, </booktitle> <year> 1989. </year>
Reference-contexts: Less has been done in the area of distributed schedulers. The work that has been done has been mostly theoretical, but some interesting simulation models have been developed and simulated at the University of Wisconsin. In <ref> [6] </ref> Carey and Livny describes a distributed DBMS model, an extension to their centralized model. Different simulation parameters are examined through simulations. Several papers about concurrency control have also been written by Thomasian et. al. [7, 12].
Reference: [7] <author> P. A. Franaszek, J. T. Robinson, and A. Thomasian. </author> <title> Concurrency Control for High Contention Environments. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(2), </volume> <year> 1992. </year>
Reference-contexts: In [6] Carey and Livny describes a distributed DBMS model, an extension to their centralized model. Different simulation parameters are examined through simulations. Several papers about concurrency control have also been written by Thomasian et. al. <ref> [7, 12] </ref>. The most important difference between our approach and the earlier approaches, is that we focus on data-shipping page-server OODBs, while earlier approaches have been done in the context of query-shipping relational database systems.
Reference: [8] <author> M. Franklin. </author> <title> Caching and Memory Management in Client-Server Database Systems. </title> <type> PhD thesis, </type> <institution> University of Wisconsin-Madison, </institution> <year> 1993. </year>
Reference-contexts: In this section we will briefly present the most important parameters that are part of the simulation model. Determining reasonable values of the parameters are very important, as the final result is highly dependent of these values. Our parameters are mainly taken from <ref> [8] </ref> and [9], others are determined according to hardware specifications and previous work at our department. The parameters being constant for all simulations are summarized in Table 1 and 2. It should also be noticed that all transactions are strict.
Reference: [9] <author> J. Gray and A. Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference-contexts: The results we get from the simulation with this model should therefore be taken with a grain of salt. One of the problems here is: how much time will sending and receiving data packets typically take? Based on Gray and Reuter <ref> [9] </ref>, and measuring the networks in our department, we have used 1 ms for clusters, 5 ms for LANs and 840 ms for WANs. In our model, this time also includes overhead and time used for interprocess communication. <p> In this section we will briefly present the most important parameters that are part of the simulation model. Determining reasonable values of the parameters are very important, as the final result is highly dependent of these values. Our parameters are mainly taken from [8] and <ref> [9] </ref>, others are determined according to hardware specifications and previous work at our department. The parameters being constant for all simulations are summarized in Table 1 and 2. It should also be noticed that all transactions are strict.
Reference: [10] <author> D. B. Lomet. </author> <title> Consistent Timestamping for Transactions in Distributed Systems. </title> <type> Technical Report CRL 90/3, </type> <institution> Digital Equipment Corporation, Cambridge Research Lab, </institution> <year> 1990. </year>
Reference-contexts: Assigning monotonous increasing unique timestamps to transactions. In a real implementation this could be done by concatenating a local timestamp counter with the node number. Keeping the clocks synchro nized is not trivial, but one solution to this problem is discussed by Lomet in <ref> [10] </ref>. 3.5 Data Manager The data manager simulates the physical database storage manager. Each node has a data manager, which operates independently of the other data managers in the system.
Reference: [11] <author> M. T. Ozsu and P. Valduriez. </author> <title> Principles of Distributed Database Systems. </title> <publisher> Prentice-Hall, </publisher> <year> 1991. </year>
Reference-contexts: Because of this, a distributed commit protocol has to be used, to make sure that all participating schedulers reach the same result. Either all perform the commit, or all have to abort. Two well-known protocols are two-phase commit (2PC) and three-phase commit <ref> [11] </ref>. We have employed 2PC, which is the protocol used by most commercially available distributed database systems. 3.7 Book Keeper The book keeper is used for collecting statistics. Among other things, it counts the number of transactions completed and aborted, whether they are short or long, and average execution time.
Reference: [12] <author> A. Thomasian. </author> <title> Performance Limits of Two-Phase Locking. </title> <booktitle> In Proceedings of the IEEE International Conference on Data Engineering, 1991. Advances in Databases and Information Systems, </booktitle> <year> 1997 </year> <month> 14 </month>
Reference-contexts: In [6] Carey and Livny describes a distributed DBMS model, an extension to their centralized model. Different simulation parameters are examined through simulations. Several papers about concurrency control have also been written by Thomasian et. al. <ref> [7, 12] </ref>. The most important difference between our approach and the earlier approaches, is that we focus on data-shipping page-server OODBs, while earlier approaches have been done in the context of query-shipping relational database systems.
References-found: 12

