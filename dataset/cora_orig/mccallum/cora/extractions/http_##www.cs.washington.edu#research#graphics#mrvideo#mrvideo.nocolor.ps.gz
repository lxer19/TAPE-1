URL: http://www.cs.washington.edu/research/graphics/mrvideo/mrvideo.nocolor.ps.gz
Refering-URL: http://www.cs.washington.edu/research/graphics/mrvideo/
Root-URL: 
Title: Multiresolution Video  
Author: Adam Finkelstein Charles E. Jacobs David H. Salesin 
Keyword: CR Categories and Subject Descriptors: H.5.1 [Information Interfaces]: Multimedia Information Systemsvideo I.3.3 [Computer Graphics]: Picture/Image Generationdisplay algorithms I.4.10 [Image Processing]: Image Representationhierarchical Additional Keywords: clip-art, compositing, image pyramids, multigrid methods, multimedia, scientific visualization, video editing  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: We present a new representation for time-varying image data that allows for varyingand arbitrarily highspatial and temporal resolutions in different parts of a video sequence. The representation, called multiresolution video, is based on a sparse, hierarchical encoding of the video data. We describe a number of operations for creating, viewing, and editing multiresolution sequences. These operations support a variety of applications: multiresolution playback, including motion-blurred fast-forward and reverse; constant-speed display; enhanced video scrubbing; and video clip-art editing and compositing. The multiresolution representation requires little storage overhead, and the algorithms using the representation are both simple and efficient. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Adams, R. Garcia, B. Gross, J. Hack, D. Haidvogel, and V. Pizzo. </author> <title> Applications of multigrid software in the atmospheric sciences. </title> <journal> Monthly Weather Review, </journal> <volume> 120(7) </volume> <pages> 1447-1458, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The multigrid techniques used frequently for solving large-scale problems in physics [15], astronomy [16], meteorology <ref> [1] </ref>, and applied mathematics [8] are a common example of this kind of computation. In this paper, we present a new approach for representing the time-varying data produced by such algorithms, called multiresolution video.
Reference: [2] <author> Deborah F. Berman, Jason T. Bartell, and David H. Salesin. </author> <title> Multiresolution painting and compositing. </title> <booktitle> In Proceedings of SIGGRAPH '94, Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 85-90, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: It is also similar in spirit to the wavelet-based representations for images described by Berman et al. <ref> [2] </ref> and Perlin and Velho [11]. In particular, like these latter works, our representation is sparse, and it supports efficient compositing operations [12] for assembling complex frames from simpler elements. Several commercially available video editing systems support many of the operations described in this paper for uniresolution video. <p> The DrawImage () routine takes time proportional to the number of squares that are drawn, assuming that the time to draw a square is constant. Fractional-level zoom The DrawImage () routine as described displays multiresolution video at any power-of-two spatial resolution. Berman et al. <ref> [2] </ref> describe a simple method to allow users to view multiresolution images at any arbitrary scale. We have adapted their method to work for multiresolution video. <p> As in the multiresolution image work of Berman et al. <ref> [2] </ref>, there is an important user-interface issue to be addressed: How does the user know when there is more spatial or temporal detail present in some part of the video? We have considered changing the cursor in areas where there is more spatial detail present than is currently being displayed.
Reference: [3] <author> Shenchang Eric Chen. </author> <title> Quicktime VRan image-based approach to virtual environment navigation. </title> <booktitle> In Proceedings of SIGGRAPH 95, Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 29-38, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: However, the input and output from all of these systems is uniresolution video. Multiresolution video also allows the user to pan and zoom to explore a flat video environment. This style of interaction is similar in spirit to two image-based environments: Apple Computer's QuickTime flR VR <ref> [3] </ref> and the plenoptic modeling system of McMillan and Bishop [9]. These methods provide an image-based representation of an environment that surrounds the viewer. <p> Chen <ref> [3] </ref> proposes a potential augmentation of QTVR based on quadtrees that would provide two benefits. First, it would allow users to zoom into areas where there is more detail than in other areas. Second, it would reduce aliasing when the user zooms out.
Reference: [4] <author> James D. Foley, Andries van Dam, Steven K. Feiner, and John F. Hughes. </author> <title> Computer Graphics: </title> <booktitle> Principles and Practice. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1990. </year>
Reference-contexts: Julia set <ref> [4] </ref>. The data were generated procedurally, with higher spatial resolution in places of higher detail, as described in Section 3.1. <p> .child [i, j], p 0 .child [i, j], r, 2x + i, 2y + j, ` + 1) end for end procedure The above procedure recursively descends the result tree c 0 to find those nodes that are completely covered by the given rectangle, an approach reminiscent of Warnock's algorithm <ref> [4] </ref>. The function CoverageType (r, x, y, `) returns a code indicating whether rectangle r completely covers, partially covers, or does not cover pixel (x, y) at level `.
Reference: [5] <author> D. Le Gall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> CACM, </journal> <volume> 34(4) </volume> <pages> 46-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: While not the emphasis of this work, we also describe a simple form of lossy compression suitable for multiresolution video. Video compression is a heavily-studied area, with too many papers to adequately survey here. MPEG <ref> [5] </ref> and QuickTime [13] are two industry standards. Other techniques based on multiscale transforms [7, 10] might be adapted to work for multiresolution video. 1.2 Overview The rest of this paper is organized as follows.
Reference: [6] <author> Randy LeVeque and Marsha Berger. AMRCLAW: </author> <title> adaptive mesh refinement + CLAWPACK. </title> <address> http://www.amath.washington.edu/rjl/amrclaw/. </address>
Reference-contexts: The left side of Figure 10 shows a frame from a computational fluid dynamics simulation in which two fluids (one heavy, one light) interact in a closed tank. The simulation method <ref> [6] </ref> adaptively refines its sample grid in regions where the function is spatially complex, so the resolution of the data is higher at the interface between the two fluids than it is in the large, constant regions containing just one fluid.
Reference: [7] <author> A. S. Lewis and G. Knowles. </author> <title> Video compression using 3D wavelet transforms. </title> <journal> Electronics Letters, </journal> <volume> 26(6) </volume> <pages> 396-398, </pages> <month> 15 March </month> <year> 1990. </year>
Reference-contexts: While not the emphasis of this work, we also describe a simple form of lossy compression suitable for multiresolution video. Video compression is a heavily-studied area, with too many papers to adequately survey here. MPEG [5] and QuickTime [13] are two industry standards. Other techniques based on multiscale transforms <ref> [7, 10] </ref> might be adapted to work for multiresolution video. 1.2 Overview The rest of this paper is organized as follows. Section 2 describes our representation for multiresolution video, and Section 3 describes how it is created and displayed.
Reference: [8] <author> S. McCormick and U. Rude. </author> <title> A finite volume convergence theory for the fast adaptive composite grid methods. Applied Numerical Mathematics, </title> <address> 14(1-3):91-103, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The multigrid techniques used frequently for solving large-scale problems in physics [15], astronomy [16], meteorology [1], and applied mathematics <ref> [8] </ref> are a common example of this kind of computation. In this paper, we present a new approach for representing the time-varying data produced by such algorithms, called multiresolution video. The multiresolution video representation provides a means of capturing time-varying image data produced at multiple scales, both spatially and temporally.
Reference: [9] <author> Leonard McMillan and Gary Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In Proceedings of SIGGRAPH 95, Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 39-46, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Multiresolution video also allows the user to pan and zoom to explore a flat video environment. This style of interaction is similar in spirit to two image-based environments: Apple Computer's QuickTime flR VR [3] and the plenoptic modeling system of McMillan and Bishop <ref> [9] </ref>. These methods provide an image-based representation of an environment that surrounds the viewer.
Reference: [10] <author> Arun N. Netravali and Barry G. </author> <title> Haskell. Digital Pictures. </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: While not the emphasis of this work, we also describe a simple form of lossy compression suitable for multiresolution video. Video compression is a heavily-studied area, with too many papers to adequately survey here. MPEG [5] and QuickTime [13] are two industry standards. Other techniques based on multiscale transforms <ref> [7, 10] </ref> might be adapted to work for multiresolution video. 1.2 Overview The rest of this paper is organized as follows. Section 2 describes our representation for multiresolution video, and Section 3 describes how it is created and displayed.
Reference: [11] <author> Ken Perlin and Luiz Velho. </author> <title> Live paint: Painting with procedural multiscale textures. </title> <booktitle> In Proceedings of SIGGRAPH 95, Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 153-160, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: It is also similar in spirit to the wavelet-based representations for images described by Berman et al. [2] and Perlin and Velho <ref> [11] </ref>. In particular, like these latter works, our representation is sparse, and it supports efficient compositing operations [12] for assembling complex frames from simpler elements. Several commercially available video editing systems support many of the operations described in this paper for uniresolution video.
Reference: [12] <author> Thomas Porter and Tom Duff. </author> <title> Compositing digital images. </title> <editor> In Hank Christiansen, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '84 Proceedings), </booktitle> <volume> volume 18, </volume> <pages> pages 253-259, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: It is also similar in spirit to the wavelet-based representations for images described by Berman et al. [2] and Perlin and Velho [11]. In particular, like these latter works, our representation is sparse, and it supports efficient compositing operations <ref> [12] </ref> for assembling complex frames from simpler elements. Several commercially available video editing systems support many of the operations described in this paper for uniresolution video. <p> the final composite in that it performs compositing on the images currently being displayed rather than on the underlying video, which is potentially represented at a much higher resolution. (The degree to which the preview differs from the final composite corresponds exactly to the degree to which the compositing assumption <ref> [12] </ref> is violated.) When viewing the motion-blurred result of compositing two video sequences, there is a similar difference between the preview provided in our editor and the actual result of the compositing operation. <p> The time complexity of scaling is the same as translation: linear in the size of the input and output. A.3 Compositing two video clips The final operation addressed in this appendix is compositing two Time Trees A and B using the compositing operation op <ref> [12] </ref>: function CompositeTimeTrees (A, B, op): returns TimeTree for each Half 2 fHalf1, Half2g do if A.Half = NULL and B.Half = NULL then Result.Half NULL else Ahalf A.Half Bhalf B.Half if Ahalf = NULL then Ahalf NewUplinkNode (A) end if if Bhalf = NULL then Bhalf NewUplinkNode (B) end if
Reference: [13] <author> Steven Radecki. </author> <title> Multimedia With Quicktime. </title> <publisher> Academic Press, </publisher> <year> 1993. </year> <note> ISBN 0-12-574750-0. </note>
Reference-contexts: While not the emphasis of this work, we also describe a simple form of lossy compression suitable for multiresolution video. Video compression is a heavily-studied area, with too many papers to adequately survey here. MPEG [5] and QuickTime <ref> [13] </ref> are two industry standards. Other techniques based on multiscale transforms [7, 10] might be adapted to work for multiresolution video. 1.2 Overview The rest of this paper is organized as follows. Section 2 describes our representation for multiresolution video, and Section 3 describes how it is created and displayed.
Reference: [14] <author> Hanan Samet. </author> <title> Applications of Spatial Data Structures. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The rest of this section describes the multiresolution video format we chose and an analysis of the storage required. 2.1 The basic multiresolution video format Perhaps the most obvious choice for a multiresolution video format would be a sparse octree <ref> [14] </ref>, whose three dimensions were used to encode the two spatial directions and time. Indeed, such a representation was our first choice, but we found that it did not adequately address a number of the goals enumerated above. <p> A.1 Translating a video clip When combining video sequences, the various elements may need to be registered with respect to one another, requiring that they be translated and scaled within their own coordinate frames. The basic operations of translation and scaling are well-understood for quadtrees <ref> [14] </ref>. However, as with drawing frames, we want these operations to take advantage of the temporal coherence encoded in the up-links of our data structure. For example, suppose we wanted to translate the fan and lamp video of Figure 3 a bit to the left.
Reference: [15] <author> P. S. Sathyamurthy and S. V. Patankar. </author> <title> Block-correction-based multigrid method for fluid flow problems. Numerical Heat Transfer, </title> <journal> Part B (Fundamentals), </journal> <volume> 25(4) </volume> <pages> 375-94, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The multigrid techniques used frequently for solving large-scale problems in physics <ref> [15] </ref>, astronomy [16], meteorology [1], and applied mathematics [8] are a common example of this kind of computation. In this paper, we present a new approach for representing the time-varying data produced by such algorithms, called multiresolution video.
Reference: [16] <author> I. Suisalu and E. Saar. </author> <title> An adaptive multigrid solver for high-resolution cosmological simulations. </title> <journal> Monthly Notices of the Royal Astronomical Society, </journal> <volume> 274(1) </volume> <pages> 287-299, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: The multigrid techniques used frequently for solving large-scale problems in physics [15], astronomy <ref> [16] </ref>, meteorology [1], and applied mathematics [8] are a common example of this kind of computation. In this paper, we present a new approach for representing the time-varying data produced by such algorithms, called multiresolution video.
Reference: [17] <author> Jonathan Swartz and Brian C. Smith. </author> <title> A resolution independent video language. </title> <booktitle> In ACM Multimedia 95, </booktitle> <pages> pages 179-188. </pages> <publisher> ACM, Addison-Wesley, </publisher> <month> November </month> <year> 1995. </year>
Reference-contexts: Discrete Logic's Flame and Flint systems also provide digital video compositing and many other digital editing operations on videos of arbitrary resolution. Swartz and Smith <ref> [17] </ref> describe a language for manipulation of video segments in a resolution-independent fashion. However, the input and output from all of these systems is uniresolution video. Multiresolution video also allows the user to pan and zoom to explore a flat video environment.
Reference: [18] <author> S. L. Tanimoto and Theo Pavlidis. </author> <title> A hierarchical data structure for picture processing. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 4(2) </volume> <pages> 104-119, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: Finally, the representation supports the assembly of complex multiresolution videos from either uniresolu-tion or multiresolution video clip-art elements. 1.1 Related work The multiresolution video representation described in this paper generalizes some of the multiresolution representations that have previously been proposed for images, such as image pyramids <ref> [18] </ref> and MIP maps [19]. It is also similar in spirit to the wavelet-based representations for images described by Berman et al. [2] and Perlin and Velho [11].
Reference: [19] <author> Lance Williams. Pyramidal parametrics. </author> <booktitle> In Computer Graphics (SIGGRAPH '83 Proceedings), </booktitle> <volume> volume 17, </volume> <pages> pages 1-11, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: Finally, the representation supports the assembly of complex multiresolution videos from either uniresolu-tion or multiresolution video clip-art elements. 1.1 Related work The multiresolution video representation described in this paper generalizes some of the multiresolution representations that have previously been proposed for images, such as image pyramids [18] and MIP maps <ref> [19] </ref>. It is also similar in spirit to the wavelet-based representations for images described by Berman et al. [2] and Perlin and Velho [11]. In particular, like these latter works, our representation is sparse, and it supports efficient compositing operations [12] for assembling complex frames from simpler elements. <p> if a pixel would be drawn at location (x, y) in a 2 ` fi 2 ` image, then it would be drawn at location (x 0 , y 0 ) in an M fiM image, where x = bxM=2 c y = byM=2 c Furthermore, as with MIP maps <ref> [19] </ref>, we interpolate between the colors appearing at levels ` and ` 1 in the image tree in order to reduce point-sampling artifacts. Drawing at this fractional level is only slightly more expensive than drawing pixels at level `.
Reference: [20] <author> L. Ziv and A. Lempel. </author> <title> A universal algorithm for sequential data compression. </title> <journal> IEEE Trans. Inform.Theory, Vol.IT-23, </journal> <volume> (3), </volume> <month> May </month> <year> 1977. </year>
Reference-contexts: Table 1 reports information about the storage space for the examples in Figures 7-12. The Disk Size column gives the total amount of space required to store the entire structure on disk, with averages and pointers included, after it has been compressed without loss using a Lempel-Ziv compressor <ref> [20] </ref>. The next column, Memory Size gives the total space required in memory, including all averages, pointers, and flags.
References-found: 20

