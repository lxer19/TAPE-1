URL: http://www-sal.cs.uiuc.edu/~kamin/pubs/ilc-arrays.ps
Refering-URL: http://www-sal.cs.uiuc.edu/~kamin/pubs/index.html
Root-URL: http://www.cs.uiuc.edu
Email: fkamin,reddyg@cs.uiuc.edu  
Title: Arrays in Imperative Lambda Calculus  
Author: Sam Kamin Uday S. Reddy 
Date: June 15, 1992  
Address: Urbana, IL 61820  
Affiliation: Computer Science Dept. University of Illinois at Urbana-Champaign  
Abstract: In recent work, Swarup, Reddy, and Ireland defined a formal system called Imperative Lambda Calculus to provide clean integration of functional and imperative programming styles. In this paper, we study the issues of array manipulation in this framework. It is shown that the unique features of the calculus allow one to express array algorithms using high-level abstractions that are not available in purely functional languages.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Anderson and P. Hudak. </author> <title> Compilation of haskell array comprehensions for scientific computing. </title> <booktitle> In SIGPLAN Conference on Design and Implementation of Programming Languages, </booktitle> <year> 1990. </year>
Reference-contexts: It follows that none of these approaches admits programs like our LUD, whose tail-recursive structure is possible only because of destructive update. Implicit update. Much work has been directed at detecting single-threadedness in the absence of any information from the programmer. These efforts include <ref> [1, 6, 8, 12] </ref>. A serious practical problem is the unreliability of such methods. Sophisticated static analyses are easily fooled, so that a small change in a program can have an unexpectedly dramatic effect on its performance. Linear logic-inspired systems.
Reference: [2] <author> Arvind, R.S. Nikhil, and K.K. Pingali. I-structures: </author> <title> Data structures for parallel computing. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 598-632, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Two paradigms which go beyond the pure functional style are data flow languages <ref> [9, 2] </ref> and higher-order imperative languages, most notably, Reynolds's Forsythe [11]. I-structures [2] are an array-like data structure used in dataflow languages. They allow once-only assignment to each component. In [2], several problems are mentioned whose solution in a purely functional style is difficult. <p> Two paradigms which go beyond the pure functional style are data flow languages [9, 2] and higher-order imperative languages, most notably, Reynolds's Forsythe [11]. I-structures <ref> [2] </ref> are an array-like data structure used in dataflow languages. They allow once-only assignment to each component. In [2], several problems are mentioned whose solution in a purely functional style is difficult. These can be solved in ILC just as they are solved there. <p> Two paradigms which go beyond the pure functional style are data flow languages [9, 2] and higher-order imperative languages, most notably, Reynolds's Forsythe [11]. I-structures <ref> [2] </ref> are an array-like data structure used in dataflow languages. They allow once-only assignment to each component. In [2], several problems are mentioned whose solution in a purely functional style is difficult. These can be solved in ILC just as they are solved there. The problems mentioned there for which I-structures are not appropriate|histograms, for example|can also be solved in ILC.
Reference: [3] <author> P. S. Barth, R. S. Nikhil, and Arvind. M-structures: </author> <title> Extending a parallel, non-strict, functional language with state. </title> <editor> In R. J. M. Hughes, editor, </editor> <booktitle> Conf. on Functional Program. Lang. and Comput. Arch., </booktitle> <pages> pages 538-568. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year> <note> (LNCS Vol. 523). </note>
Reference-contexts: These can be solved in ILC just as they are solved there. The problems mentioned there for which I-structures are not appropriate|histograms, for example|can also be solved in ILC. Recently, the data flow paradigm has been extended with mutable data structures <ref> [3] </ref>. The resulting language has the expressive power of ILC, but it is nondeterministic and has the flavor of a "concurrent" programming language as opposed to a functional language. Reynolds's Forsythe [11], apart from its novel conjunctive type system, is very close in spirit to our work.
Reference: [4] <author> M. J. C. Gordon. </author> <title> The Denotational Description of programming languages. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: The notion of an "effect" is then as a modifier, i.e., a function, of observers. This is essentially the meaning of a "command" in the continuation semantics of imperative languages <ref> [4] </ref>. So, we define a new primitive type cmd with the (polymorphic) semantics: cmd = 8t .
Reference: [5] <author> J.C. Guzman and P. Hudak. </author> <title> Single-threaded polymorphic lambda calculus. </title> <booktitle> In Fifth Ann. Symp. on Logic in Comp. Science. IEEE Computer Society, </booktitle> <year> 1990. </year>
Reference-contexts: So, imperative programming in ILC is much richer than that in conventional imperative languages like Pascal. It is also richer than value-oriented (purely functional) solutions to in-place updates such as <ref> [5, 15, 16] </ref>. Our notion of arrays is the following. An array is an indexed collection of references. Since references are dynamic objects, an array becomes a dynamic structure. One can define and use various operations to manipulate arrays such as extracting subarrays, transposing matrices etc.. <p> However, the truer comparison is with a "single-threaded" functional language, like those in <ref> [5, 15, 16] </ref>. We take the single-threaded lambda calculus, st [5], as a typical example. There are two major differences between the treatment of LUD in st versus ILC. <p> However, the truer comparison is with a "single-threaded" functional language, like those in [5, 15, 16]. We take the single-threaded lambda calculus, st <ref> [5] </ref>, as a typical example. There are two major differences between the treatment of LUD in st versus ILC. First, there is no type "cmd" in st | only the normal functional types exist (sometimes decorated to indicate single-threadedness, but not essentially changed). <p> say to allow the definition of vector-update is: fun updatable-subVector-row m j k = fn i =&gt; fn x =&gt; update! m j (i+k) x But this can't be type-checked in st because "it [is not] permissible for a function to `capture' a mutation to one of its free variables" <ref> [5] </ref>. <p> In Guzman and Hudak's single-threaded -calculus ( st ) <ref> [5] </ref>, the programmer explicitly requests destructive update of an array by writing update! instead of update (and let* instead of let); the type checker checks that the use of these destructive operations is sensible. <p> More significantly, ILC allows computations which create and use state internally to be viewed as functional computations from the outside. This is an important requirement for a smooth integration of functional and imperative styles. 6 Conclusions The systems of Wadler [15, 16] and Guzman and Hudak <ref> [5] </ref> do one thing that ILC doesn't: they distinguish between reading from and writing to the state. In ILC, a state "observer" may do either, and no distinction is made. Thus, two dereferencing operations must be sequentialized, which obviously should not be necessary.
Reference: [6] <author> P. Hudak and A. Bloss. </author> <title> The aggregate update problem in functional programming systems. </title> <booktitle> In ACM Symp. on Princ. of Program. Lang., </booktitle> <pages> pages 300-314, </pages> <year> 1985. </year>
Reference-contexts: It follows that none of these approaches admits programs like our LUD, whose tail-recursive structure is possible only because of destructive update. Implicit update. Much work has been directed at detecting single-threadedness in the absence of any information from the programmer. These efforts include <ref> [1, 6, 8, 12] </ref>. A serious practical problem is the unreliability of such methods. Sophisticated static analyses are easily fooled, so that a small change in a program can have an unexpectedly dramatic effect on its performance. Linear logic-inspired systems.
Reference: [7] <editor> P. Hudak and P. Wadler (eds). </editor> <title> Report on programming language Haskell, A non-strict purely functional language (Version 1.0). </title> <type> Technical Report YALEU/DCS/RR777, </type> <institution> Yale University, </institution> <month> Apr </month> <year> 1990. </year>
Reference-contexts: Thus, functional programs are annotated, or type-checked, or statically analyzed, to reveal "single-threadedness," but the programs do not basically differ from what one would write in a language like Haskell <ref> [7] </ref>, with non-destructively updated arrays. It follows that none of these approaches admits programs like our LUD, whose tail-recursive structure is possible only because of destructive update. Implicit update. Much work has been directed at detecting single-threadedness in the absence of any information from the programmer.
Reference: [8] <author> Paul Hudak. </author> <title> A semantics model of reference counting and its abstraction. </title> <editor> In S. Abramsky and C. Hankin, editors, </editor> <booktitle> Abstract Interpretation of Declarative Languages, </booktitle> <pages> pages 45-62. </pages> <publisher> Ellis Horwood Ltd., </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: It follows that none of these approaches admits programs like our LUD, whose tail-recursive structure is possible only because of destructive update. Implicit update. Much work has been directed at detecting single-threadedness in the absence of any information from the programmer. These efforts include <ref> [1, 6, 8, 12] </ref>. A serious practical problem is the unreliability of such methods. Sophisticated static analyses are easily fooled, so that a small change in a program can have an unexpectedly dramatic effect on its performance. Linear logic-inspired systems.
Reference: [9] <author> R.S. Nikhil, K. Pingali, and Arvind. </author> <title> Id nouveau. </title> <type> Technical Report CSG 265, </type> <institution> MIT, </institution> <year> 1986. </year>
Reference-contexts: Two paradigms which go beyond the pure functional style are data flow languages <ref> [9, 2] </ref> and higher-order imperative languages, most notably, Reynolds's Forsythe [11]. I-structures [2] are an array-like data structure used in dataflow languages. They allow once-only assignment to each component. In [2], several problems are mentioned whose solution in a purely functional style is difficult.
Reference: [10] <author> W. V. O. Quine. </author> <title> Word and Object. </title> <publisher> MIT Press, </publisher> <year> 1960. </year>
Reference-contexts: Let us stipulate for purposes of this discussion that the term "referentially transparent" has the meaning given by Quine <ref> [10] </ref>: A language is referentially transparent if for all terms t and u, and all contexts C [], t u implies C [t] C [u].
Reference: [11] <author> J. C. Reynolds. </author> <title> Preliminary design of the programming language Forsythe. </title> <type> Technical Report CMU-CS-88-159, </type> <institution> Carnegie-Mellon University, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: Two paradigms which go beyond the pure functional style are data flow languages [9, 2] and higher-order imperative languages, most notably, Reynolds's Forsythe <ref> [11] </ref>. I-structures [2] are an array-like data structure used in dataflow languages. They allow once-only assignment to each component. In [2], several problems are mentioned whose solution in a purely functional style is difficult. These can be solved in ILC just as they are solved there. <p> Recently, the data flow paradigm has been extended with mutable data structures [3]. The resulting language has the expressive power of ILC, but it is nondeterministic and has the flavor of a "concurrent" programming language as opposed to a functional language. Reynolds's Forsythe <ref> [11] </ref>, apart from its novel conjunctive type system, is very close in spirit to our work. However, it seems that Forsythe is really meant to be an imperative language (with a functional "architecture") whereas ILC is meant to support both imperative and functional paradigms.
Reference: [12] <author> D. A. Schmidt. </author> <title> Detecting global variables in denotational specifications. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(2) </volume> <pages> 299-310, </pages> <month> Apr </month> <year> 1985. </year>
Reference-contexts: It follows that none of these approaches admits programs like our LUD, whose tail-recursive structure is possible only because of destructive update. Implicit update. Much work has been directed at detecting single-threadedness in the absence of any information from the programmer. These efforts include <ref> [1, 6, 8, 12] </ref>. A serious practical problem is the unreliability of such methods. Sophisticated static analyses are easily fooled, so that a small change in a program can have an unexpectedly dramatic effect on its performance. Linear logic-inspired systems.
Reference: [13] <author> V. Swarup, U. S. Reddy, and E. Ireland. </author> <title> Assignments for applicative languages. </title> <editor> In R. J. M. Hughes, editor, </editor> <booktitle> Conf. on Functional Program. Lang. and Comput. Arch., </booktitle> <pages> pages 192-214. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year> <note> (LNCS Vol. 523). </note>
Reference-contexts: This liberal view point allows us to extend functional programming with dynamic objects (called references) and state-dependent values (called observers) while preserving all the properties of functional programs mentioned above. A formal system called imperative lambda calculus (ILC) is presented in <ref> [13] </ref> along these lines. <p> The most important benefit of programming in ILC is that problem solutions can be decomposed into the two classes: structure-level manipulations and dynamic manipulations. This paper is in five sections: (1) an overview of ILC as presented in <ref> [13] </ref>; (2) explanation of the sugared version of ILC used in Section 3; (3) examples of ILC, showing the power, as well as limitations, of the language in its present state; (4) comparisons of ILC with related work; and (5) conclusions concerning the future of ILC, especially about our current research <p> ! := e in t) : Obs t Dereference ` l : Ref ! ; x : ! ` t : Obs t Assignment ` l : Ref ! ` e : ! ` t : Obs t The type system ensures that such potentially non-deterministic expressions are illegal. (In <ref> [13] </ref>, a confluent and strongly normalizing set of reduction rules is given.) We must first describe the set of types, which is divided into two parts 2 , applicative types (normal, applicative values) and observer types (values that depend on the state): Applicative types: t ::= fi j t 1 ! <p> r:Ref int): r:Ref int ` 1:int r:Ref int, x:int ` x+1:int r:Ref int ` get x&lt;=r in x+1:Obs int ` letref r:Ref int := 1 in (r:=2; get x &lt;= r in x+1):Obs int ` letref r:Ref int := 1 in (r:=2; get x &lt;= r in x+1):int 2 In <ref> [13] </ref>, there were three parts, but we've combined two of them here; in this version, the system does not have the strong normalization property, but it is still confluent. 2 ILC 4 Notice how this expression observes the state internally, but from the outside is not considered an observer. <p> Given an observer k, it swaps the ith and jth elements of the array a and invokes k. The effect of swapping is thus only observable inside k. In general, the effects of assignments are localized to specific observers. As discussed in <ref> [13] </ref>, this plays a large role in obtaining a semantically clean language. <p> The above equivalence holds in ILC just as all other equivalences of lambda calculus. Moreover, a new set of equivalences holds for state-dependent values, as documented in <ref> [13] </ref>. Thus, ILC is referentially transparent, not only in the trivial sense mentioned above, but also in that its equivalences are what one expects to see. 3 ILC IN PRACTICE 5 3 ILC in practice Pure ILC is somewhat cumbersome to use in practice. <p> Thus, single threading seems to compromise the very values function programming espouses, viz., functional abstraction and lazy evaluation, while ILC preserves them. 5 Related work Concerning the general problem of destructive update in functional languages, reference <ref> [13] </ref> contained a number of comparisons of ILC with previous work. Here we recapitulate those comparisons only briefly, while adding some observations specific to the problem of arrays. The phrase "adding arrays to a functional language" means different things to different people.
Reference: [14] <author> P. Wadler. </author> <title> Comprehending monads. </title> <booktitle> In ACM Symp. on LISP and Functional Programming, </booktitle> <year> 1990. </year> <note> REFERENCES 13 </note>
Reference-contexts: Thus, two dereferencing operations must be sequentialized, which obviously should not be necessary. If ILC were developed to include the notion of "pure observers," programming in it would be more convenient. The uses of monads, as advocated by Wadler <ref> [14] </ref>. are really orthogonal to the problem of side effects, as can be seen from the wide variety of applications displayed in [14]. They provide notational convenience, whereby an array can be implicitly manipulated by a program, or one can implicitly use continuation-passing style. <p> If ILC were developed to include the notion of "pure observers," programming in it would be more convenient. The uses of monads, as advocated by Wadler <ref> [14] </ref>. are really orthogonal to the problem of side effects, as can be seen from the wide variety of applications displayed in [14]. They provide notational convenience, whereby an array can be implicitly manipulated by a program, or one can implicitly use continuation-passing style. It is especially from this latter use that ILC might benefit.
Reference: [15] <author> P. Wadler. </author> <title> Linear types can change the world. </title> <editor> In M. Broy and C. B. Jones, editors, </editor> <booktitle> Programming Concepts and Methods. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1990. </year> <booktitle> (Proc. IFIP TC 2 Working Conf., Sea of Galilee, </booktitle> <address> Israel). </address>
Reference-contexts: So, imperative programming in ILC is much richer than that in conventional imperative languages like Pascal. It is also richer than value-oriented (purely functional) solutions to in-place updates such as <ref> [5, 15, 16] </ref>. Our notion of arrays is the following. An array is an indexed collection of references. Since references are dynamic objects, an array becomes a dynamic structure. One can define and use various operations to manipulate arrays such as extracting subarrays, transposing matrices etc.. <p> However, the truer comparison is with a "single-threaded" functional language, like those in <ref> [5, 15, 16] </ref>. We take the single-threaded lambda calculus, st [5], as a typical example. There are two major differences between the treatment of LUD in st versus ILC. <p> These efforts include [1, 6, 8, 12]. A serious practical problem is the unreliability of such methods. Sophisticated static analyses are easily fooled, so that a small change in a program can have an unexpectedly dramatic effect on its performance. Linear logic-inspired systems. Though Wadler <ref> [15, 16] </ref> does not specifically address arrays, his linear logic type system is obviously applicable to them. (It has been further explored by Wakeling and Runciman [17].) Here, the type checker guarantees single-threadedness. <p> However, the programmer never specifically requests a destructive update, so it is up to the compiler to determine when it is appropriate. For example, in Wadler's destructive append! example in <ref> [15] </ref>, both arguments of append! are single-threaded; it is "obvious" which one should actually be modified, but it is far from clear how intelligent a compiler would be needed to sort this out in general. <p> More significantly, ILC allows computations which create and use state internally to be viewed as functional computations from the outside. This is an important requirement for a smooth integration of functional and imperative styles. 6 Conclusions The systems of Wadler <ref> [15, 16] </ref> and Guzman and Hudak [5] do one thing that ILC doesn't: they distinguish between reading from and writing to the state. In ILC, a state "observer" may do either, and no distinction is made. Thus, two dereferencing operations must be sequentialized, which obviously should not be necessary.
Reference: [16] <author> P. Wadler. </author> <title> Is there a use for linear logic? In Proc. </title> <booktitle> ACM SIGPLAN Conf. on Partial Evaluation and Semantics-Based Program Manipulation. ACM, </booktitle> <year> 1991. </year> <journal> (SIGPLAN Notices, </journal> <note> to appear). </note>
Reference-contexts: So, imperative programming in ILC is much richer than that in conventional imperative languages like Pascal. It is also richer than value-oriented (purely functional) solutions to in-place updates such as <ref> [5, 15, 16] </ref>. Our notion of arrays is the following. An array is an indexed collection of references. Since references are dynamic objects, an array becomes a dynamic structure. One can define and use various operations to manipulate arrays such as extracting subarrays, transposing matrices etc.. <p> However, the truer comparison is with a "single-threaded" functional language, like those in <ref> [5, 15, 16] </ref>. We take the single-threaded lambda calculus, st [5], as a typical example. There are two major differences between the treatment of LUD in st versus ILC. <p> These efforts include [1, 6, 8, 12]. A serious practical problem is the unreliability of such methods. Sophisticated static analyses are easily fooled, so that a small change in a program can have an unexpectedly dramatic effect on its performance. Linear logic-inspired systems. Though Wadler <ref> [15, 16] </ref> does not specifically address arrays, his linear logic type system is obviously applicable to them. (It has been further explored by Wakeling and Runciman [17].) Here, the type checker guarantees single-threadedness. <p> More significantly, ILC allows computations which create and use state internally to be viewed as functional computations from the outside. This is an important requirement for a smooth integration of functional and imperative styles. 6 Conclusions The systems of Wadler <ref> [15, 16] </ref> and Guzman and Hudak [5] do one thing that ILC doesn't: they distinguish between reading from and writing to the state. In ILC, a state "observer" may do either, and no distinction is made. Thus, two dereferencing operations must be sequentialized, which obviously should not be necessary.
Reference: [17] <editor> D. Wakeling and C. Runciman. Linearity and laziness. In R. J. M. Hughes, editor, </editor> <booktitle> Conf. on Functional Program. Lang. and Comput. Arch., </booktitle> <pages> pages 215-240. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year> <note> (LNCS Vol. 523). </note>
Reference-contexts: Linear logic-inspired systems. Though Wadler [15, 16] does not specifically address arrays, his linear logic type system is obviously applicable to them. (It has been further explored by Wakeling and Runciman <ref> [17] </ref>.) Here, the type checker guarantees single-threadedness. However, the programmer never specifically requests a destructive update, so it is up to the compiler to determine when it is appropriate.
References-found: 17

