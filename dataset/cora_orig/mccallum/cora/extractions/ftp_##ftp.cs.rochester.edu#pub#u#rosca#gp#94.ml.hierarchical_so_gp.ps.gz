URL: ftp://ftp.cs.rochester.edu/pub/u/rosca/gp/94.ml.hierarchical_so_gp.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/rosca/papers.html
Root-URL: 
Email: rosca@cs.rochester.edu  dana@cs.rochester.edu  
Title: Hierarchical Self-Organization in Genetic Programming  
Author: Justinian P. Rosca Dana H. Ballard 
Address: Rochester, NY 14627  Rochester, NY 14627  
Affiliation: Computer Science Department University of Rochester  Computer Science Department University of Rochester  
Abstract: This paper presents an approach to automatic discovery of functions in Genetic Programming. The approach is based on discovery of useful building blocks by analyzing the evolution trace, generalizing blocks to define new functions, and finally adapting the problem representation on-the-fly. Adaptating the representation determines a hierarchical organization of the extended function set which enables a restructuring of the search space so that solutions can be found more easily. Measures of complexity of solution trees are defined for an adaptive representation framework. The minimum description length principle is applied to justify the feasibility of approaches based on a hierarchy of discovered functions and to suggest alternative ways of defining a problem's fitness function. Preliminary empirical results are presented.
Abstract-found: 1
Intro-found: 1
Reference: [ Angeline and Pollack, 1994 ] <author> Peter J. Angeline and Jor-dan B. Pollack. </author> <title> Coevolving high level representations. </title> <booktitle> In The Proceedings of Artificial Life III (to appear), </booktitle> <year> 1994. </year>
Reference-contexts: We define blocks as entire subtrees of a given maximum height from population individuals. This represents the bottom-up approach in figure 1. (In contrast the module approach <ref> [ Angeline and Pollack, 1994 ] </ref> starts with subtrees of any depth and chops off all branches at a given depth.) We will show that this bottom-up approach enables the definition of blocks whose usefulness can be evaluated.
Reference: [ Angeline, 1994 ] <author> Peter J. Angeline. </author> <title> Genetic programming and emergent intelligence. </title> <editor> In Kim Kinnear, editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: GAs work best when the internal representation encourages the emergence of useful building blocks that can subsequently be combined with each other to improve performance. In GP no precise definition of a schema exists, and no corresponding schemata theorem has been proven. One more difficulty is outlined in <ref> [ Angeline, 1994 ] </ref> : Since GP individuals represent code, as opposed to GA strings which are collections of data, there exists a complicated many-to-many mapping between genotypic and phenotypic features. module approach. <p> The problem is that the converse of the GA schemata theorem is not true. Poor blocks, i.e. blocks that are identities or add no functionality, may be frequent and should not be considered as candidates, although they may have a role of preserving recessive features (introns in <ref> [ Angeline, 1994 ] </ref> ). Some conclusions obtained by monitoring frequent blocks indicate their unsuitability in estimating block usefulness [ Rosca and Ballard, 1994 ] . Blocks that appear in a final solution may be discovered very late in the search process. <p> For example crossover can only be performed between components of the same type. Although the hierarchy of components is fixed, it boosts the power of solution discovery especially for problems with regular solutions or decomposable into smaller subproblems. The module acquisition approach <ref> [ Angeline, 1994 ] </ref> is based on the creation and administration of a library of modules which extend the problem representation and on the use of two new genetic operators, compress and expand, that control the process of modifying population individuals.
Reference: [ Beckenbach and Bellman, 1965 ] <author> Edwin F. Beckenbach and Richard Bellman. </author> <title> Inequalities. </title> <publisher> Springer Verlag, </publisher> <year> 1965. </year>
Reference-contexts: We can prove this by applying Jensen's inequality <ref> [ Beckenbach and Bellman, 1965 ] </ref> to the convex function (logx + logA). The case n 0 = n and n i = 0 for all 1 i m represents the situation when no (automatically discovered) subfunc-tions are used. DC (T ) is maximum in this case.
Reference: [ Goldberg, 1989 ] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: We conclude by analyzing an example, mentioning related work and considering directions for future work. 2 BUILDING BLOCKS IN GP In Genetic Algorithms (GA), the schemata theorem [ Hol-land, 1992 ] , <ref> [ Goldberg, 1989 ] </ref> summarizes the effect of fitness-proportionate reproduction, crossover and mutation. Schemata are template strings representing sets of individuals in the search space. Schemata are defined by strings over the (usually binary) alphabet extended with a don't care symbol.
Reference: [ Hillis, 1990 ] <author> W. Daniel Hillis. </author> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <editor> In Stephanie Forrest, editor, </editor> <booktitle> Proceedings of the Ninth Annual International Conference of the Center for Nonlinear Studies on Self-organizing, Collective, and Cooperative Phenomena in Natural and Artificial Computing Networks, </booktitle> <pages> pages 228-234. </pages> <publisher> North Holland, </publisher> <year> 1990. </year>
Reference-contexts: Each of the block fitness functions exerts environmental pressure for the selection of viable blocks. In a co-evolutionary framework such pressure could come from co-evolving species <ref> [ Hillis, 1990 ] </ref> . As expected fit blocks are very useful in dynamically extending the problem representation by means of definition of new global functions. A highly fit block generated in the initial population spreads in the population very easily.
Reference: [ Hinton and Nowlan, 1987 ] <author> Geoffrey E. Hinton and Steven J. Nowlan. </author> <title> How learning can guide evolution. </title> <journal> Complex Systems, </journal> <pages> pages 495-502, </pages> <year> 1987. </year>
Reference-contexts: The effect of our approach is a dynamical reshaping of the search space and exemplifies the effect learning, in the form of acquisition of new functions, has in the evolutionary process <ref> [ Hinton and Nowlan, 1987 ] </ref> . Extraordinary improvements of the effort needed to find a solution have been observed for problems with regularity in their solutions. Developing robust criteria for discovering useful building blocks in general could help in the design of GP applications for complex problems.
Reference: [ Holland, 1992 ] <author> John H. Holland. </author> <title> Adaptation in Natural and Artificial Systems, An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference: [ Iba et al., 1994 ] <author> Hitoshi Iba, Hugo de Garis, and Taisuke Sato. </author> <title> Genetic programming using a minimum description length principle. </title> <editor> In Kim Kinnear, editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The idea that frequent subtrees in one individual correspond to synthesized features suggests the conclusion that those subtrees comprise building blocks. The minimum description length principle has been recently used in an application of Genetic Programming to pattern recognition <ref> [ Iba et al., 1994 ] </ref> . The standard GP representation of individuals is transformed into a decision tree representation. The fitness function used relies on the formulas derived in [ Quinlan and Rivest, 1989 ] .
Reference: [ Kinnear, 1994 ] <author> Kim Kinnear. </author> <title> Alternatives in automatic function definition. </title> <editor> In Kim Kinnear, editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The power of GP using automatically discovered functions to solve problems is significantly increased too ( [ Koza, 1992 ] , [ Rosca and Ballard, 1994 ] , [ Koza, 1994 ] , <ref> [ Kinnear, 1994 ] </ref> ). Moreover, the descriptional complexity can be used as a measure for the fitness of an individual T that would drive GP towards discovering solutions with a smaller descrip-tional complexity. <p> A performance comparison of ADF and module acquisition is presented in a recent paper <ref> [ Kinnear, 1994 ] </ref> . The author analyzes the performance of the two methods and many other variations of the methods and attributes the better performance of ADF to the repeated use of calls to automatically defined functions and to the multiple use of parameters.
Reference: [ Koza, 1992 ] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: For such an organization, the size of individuals and discovered functions is kept within reasonable bounds while the structural complexity of individuals is much bigger. The power of GP using automatically discovered functions to solve problems is significantly increased too ( <ref> [ Koza, 1992 ] </ref> , [ Rosca and Ballard, 1994 ] , [ Koza, 1994 ] , [ Kinnear, 1994 ] ). <p> The main parameters were population size M = 4000, number of generations G = 50. Selection is done by running tournaments of size 7. The epoch-replacement-fraction parameter was 1 2 . Other GP parameters have typical values as reported in <ref> [ Koza, 1992 ] </ref> . <p> A similar problem would appear if the new functions created by AR did not correspond to good building blocks. 7 RELATED WORK The Automatic Definition of Functions (ADF) approach <ref> [ Koza, 1992 ] </ref> has opened this line of research in GP. In ADF-based GP each individual has a fixed number of components: functions to be automatically evolved (having a fixed number of parameters) and result producing branches.
Reference: [ Koza, 1994 ] <editor> John R. Koza. </editor> <booktitle> Genetic Programming II. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1994. </year>
Reference-contexts: This has been done mostly in an empirical way. For example, individuals with too big a size, number of state-changing operations (as in the LAWN MOWER or ARTIFICIAL ANT problems described in <ref> [ Koza, 1994 ] </ref> ) or running time are penalized. <p> The power of GP using automatically discovered functions to solve problems is significantly increased too ( [ Koza, 1992 ] , [ Rosca and Ballard, 1994 ] , <ref> [ Koza, 1994 ] </ref> , [ Kinnear, 1994 ] ). Moreover, the descriptional complexity can be used as a measure for the fitness of an individual T that would drive GP towards discovering solutions with a smaller descrip-tional complexity. <p> Rows 2 and 3 present some comparative results taken from <ref> [ Koza, 1994 ] </ref> for sample runs of GP with similar parameter values, but M = 16000. of both the best of generation individual and on average over the entire population. The structural complexity values are bounded from below and above by Size and EC respectively.
Reference: [ Li and Vitanyi, 1993 ] <author> Ming Li and Paul Vitanyi. </author> <title> An Introduction to Kolmogorov Complexity and its Applications. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: tree that best explains a set of examples [ Quinlan and Rivest, 1989 ] , the construction of a finite automaton or the inference of a boolean function that satisfies a set of constraints are all problems that match the described pattern and can be solved using the MDL principle <ref> [ Li and Vitanyi, 1993 ] </ref> . MDL is also called stochastic complexity. The MDL principle advocates a hierarchical representation of evolved programs (see appendix A). A more complex behavior can be obtained based on a more complex, hierarchical organization.
Reference: [ Michalski, 1983 ] <author> Ryszard S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, editors, </editor> <booktitle> Machine Learning, An Artificial Intelligence Approach, </booktitle> <pages> pages 83-129. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1983. </year>
Reference-contexts: However useful blocks tend to be small and the process can be applied recursively to discover more and more complex useful blocks. A block can be generalized by substituting each occurrence of a terminal of the block by a variable (descriptive generalization in <ref> [ Michalski, 1983 ] </ref> ). This process transforms a block into a parameterized function whose parameters are given by the block variables. Figure 1 presents an example of a function F b generated in this approach.
Reference: [ Quinlan and Rivest, 1989 ] <author> J. Ross Quinlan and Ronald L. Rivest. </author> <title> Inferring decision trees using the minimum description length principle. </title> <booktitle> Information and Computation, </booktitle> <pages> pages 227-248, </pages> <year> 1989. </year>
Reference-contexts: It states that the best theory to explain a set of data is one which minimizes the length of the data description together with the hypothesis description. In general, problems such as the inference of a decision tree that best explains a set of examples <ref> [ Quinlan and Rivest, 1989 ] </ref> , the construction of a finite automaton or the inference of a boolean function that satisfies a set of constraints are all problems that match the described pattern and can be solved using the MDL principle [ Li and Vitanyi, 1993 ] . <p> The minimum description length principle has been recently used in an application of Genetic Programming to pattern recognition [ Iba et al., 1994 ] . The standard GP representation of individuals is transformed into a decision tree representation. The fitness function used relies on the formulas derived in <ref> [ Quinlan and Rivest, 1989 ] </ref> .
Reference: [ Rosca and Ballard, 1994 ] <author> Justinian P. Rosca and Dana H. Ballard. </author> <title> Learning by Adapting Representations in Genetic Programming. </title> <booktitle> To appear in the proceedings of the IEEE World Congress on Computational Intelligence, </booktitle> <address> Orlando, Florida, </address> <year> 1994. </year>
Reference-contexts: Some conclusions obtained by monitoring frequent blocks indicate their unsuitability in estimating block usefulness <ref> [ Rosca and Ballard, 1994 ] </ref> . Blocks that appear in a final solution may be discovered very late in the search process. They are not necessarily responsible for the evolution process, usually having a low frequency count. Frequent blocks in early generations may become rare in late generations. <p> For such an organization, the size of individuals and discovered functions is kept within reasonable bounds while the structural complexity of individuals is much bigger. The power of GP using automatically discovered functions to solve problems is significantly increased too ( [ Koza, 1992 ] , <ref> [ Rosca and Ballard, 1994 ] </ref> , [ Koza, 1994 ] , [ Kinnear, 1994 ] ). Moreover, the descriptional complexity can be used as a measure for the fitness of an individual T that would drive GP towards discovering solutions with a smaller descrip-tional complexity. <p> is true to certain degree even with simple fitness measures incorporating rewards for hits and penalties for misses as well as a size pressure component, that have been empirically used so far in GP applications. 6 EXPERIMENTAL RESULTS The results discussed herein are based on runs with the AR-GP kernel <ref> [ Rosca and Ballard, 1994 ] </ref> . The main parameters were population size M = 4000, number of generations G = 50. Selection is done by running tournaments of size 7. The epoch-replacement-fraction parameter was 1 2 .
Reference: [ Rosca and Ballard, February 1994 ] <author> Justinian P. Rosca and Dana H. Ballard. </author> <title> Genetic programming with adaptive representations. </title> <type> Technical Report 489, </type> <institution> University of Rochester, Computer Science Department, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: All new blocks can be discovered efficiently (O (M ) time, where M is the population size) by marking the program-tree paths actually affected by a GP operator and by examining only those paths while searching for new blocks <ref> [ Rosca and Ballard, February 1994 ] </ref> . The skeleton of the GP algorithm that incorporates the AR component is presented in figure 2.
Reference: [ Simon, 1973 ] <author> Herbert A. Simon. </author> <title> The organization of complex systems. </title> <editor> In G. Braziller Howard H. Pattee, editor, </editor> <booktitle> Hierarchy Theory; The Challenge of Complex Systems, </booktitle> <pages> pages 3-27. </pages> <address> New York, </address> <year> 1973. </year>
Reference-contexts: The discovery of stable components when solving a problem could speed the search process, as the time needed for the complex system to evolve based on its subsystems is much shorter than if the system evolves from its elementary parts <ref> [ Simon, 1973 ] </ref> . We claim that in GP building blocks emerge that correspond to such stable components. They can be discovered in the population using a process of generalization of substructures (blocks) already incorporated in the individuals.
Reference: [ Tackett, 1993 ] <author> Walter Alden Tackett. </author> <title> Genetic programming for feature discovery and image discrimination. </title> <booktitle> In Proceedings of the Fifth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <year> 1993. </year>
Reference-contexts: An attempt to explain the course of evolution in GP based on an understanding of what building blocks are appears in <ref> [ Tackett, 1993 ] </ref> . The idea that frequent subtrees in one individual correspond to synthesized features suggests the conclusion that those subtrees comprise building blocks.
References-found: 18

