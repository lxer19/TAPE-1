URL: http://www.medg.lcs.mit.edu/ftp/doyle/rbr90.ps
Refering-URL: http://www.medg.lcs.mit.edu/ftp/doyle/
Root-URL: 
Title: Rational Belief Revision (Preliminary Report)  
Author: Jon Doyle 
Keyword: Belief revision, reason maintenance, rationality postulates, social choice theory, default reasoning, limited rationality, preference change.  
Address: 545 Technology Square Cambridge, Massachusetts 02139, USA  
Affiliation: Massachusetts Institute of Technology Laboratory for Computer Science  
Note: Reset reproduction of preprint distributed at the Third International Workshop on Nonmonotonic Reasoning, South Lake Tahoe, California, June 1990. Reprinted July 1994. Reprinting c Copyright 1990, 1994 by Jon Doyle.  
Abstract: Theories of rational belief revision recently proposed by Gardenfors and Nebel illuminate many important issues but impose unnecessarily strong standards for correct revisions and make strong assumptions about what information is available to guide revisions. We reconstruct these theories according to an economic standard of rationality in which preferences are used to select among alternative possible revisions. By permitting multiple partial specifications of preferences in ways closely related to preference-based nonmonotonic logics, the reconstructed theory employs information closer to that available in practice and offers more flexible ways of selecting revisions. We formally compare this notion of rational belief revision with those of Gardenfors and Nebel, adapt results about universal default theories to prove that there is no universal method of rational belief revision, and examine formally how different limitations on rationality affect belief revision. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Alchourron, P. Gardenfors, and D. Makinson. </author> <title> On the logic of theory change: Partial meet contraction functions and their associated revision functions. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-530, </pages> <year> 1985. </year>
Reference-contexts: One of the best developed formal theories of belief revision is that expounded by Gardenfors [14], based on work with Alchourron and Makinson <ref> [1] </ref>. Gardenfors models belief states with deductively closed sets of propositions (logical theories) and develops, motivates, and studies a small set of axioms that characterize how a rational agent should change its belief states when new beliefs are added, subtracted, or changed.
Reference: [2] <author> C. Alchourron and D. Makinson. </author> <title> The logic of theory change: Contraction functions and their associated revision functions. </title> <journal> Theoria, </journal> <volume> 48 </volume> <pages> 14-37, </pages> <year> 1982. </year>
Reference-contexts: Specifically, if : 4 is a revision operation defined by (4) and (10) and if :x 2 A and 6` :x, then A + x = Cn (fxg): (11) (See <ref> [2] </ref> or [32, Corollary 3].) Taken together, these results about maxichoice and full meet contraction indicate that the notion of rational contraction captured by axioms ( : : 8) and (4) is really very weak. 2.3.3 Partial meet contraction If the extremes of defining the contraction A : the propositions in
Reference: [3] <author> K. J. </author> <title> Arrow. Social Choice and Individual Values. </title> <publisher> Yale University Press, </publisher> <address> second edition, </address> <year> 1963. </year>
Reference-contexts: We then present the formal theory of rational revision guided by multiple partial preferences, which is based on several principles for rationally aggregating partial preferences. This theory is formally similar to Doyle and Wellman's [12] theory of rational default reasoning and to the economic theory of social choice <ref> [3] </ref>. We prove that no method for belief revision based on partial preferences satisfies all the rationality conditions on preference aggregation. We examine how irrationalities in preference aggregation lead to violations of Gardenfors's rationality axioms. Section 6 expands the theory further to cover rational revision of preferences. <p> The principled design of an aggregation policy for partial preference criteria begins with a consideration of properties we think a reasonable policy should exhibit. The properties we propose are analogs of Arrow's <ref> [3] </ref> desiderata for social choice. 3 3 Consult sources on social choice theory [3, 38] for somewhat more rigorous versions of these desiderata, though for the case of total orders. 1. Collective rationality. <p> The principled design of an aggregation policy for partial preference criteria begins with a consideration of properties we think a reasonable policy should exhibit. The properties we propose are analogs of Arrow's [3] desiderata for social choice. 3 3 Consult sources on social choice theory <ref> [3, 38] </ref> for somewhat more rigorous versions of these desiderata, though for the case of total orders. 1. Collective rationality. The global order ~ is a function of the individual orders ~ i , which are unre stricted, possibly partial, preorders.
Reference: [4] <author> K. J. </author> <title> Arrow. Values and collective decision-making. </title> <editor> In P. Laslett and W. G. Runciman, editors, </editor> <booktitle> Philosophy, Politics and Society, Third, </booktitle> <pages> pages 215-232. </pages> <publisher> Basil Blackwell Oxford, </publisher> <year> 1967. </year>
Reference-contexts: Proof: With the restriction to total orders, this is exactly Arrow's theorem. For a proof of the original result see <ref> [4] </ref> or [38, Chapter 7]. 2 There is no problem finding good aggregation policies for choices among only two alternatives: majority rule works fine, for example. But for the case of belief revision, there are typically several possible alternatives to choose from.
Reference: [5] <author> J. A. K. </author> <title> Cave. Learning to agree. </title> <journal> Economics Letters, </journal> <volume> 12 </volume> <pages> 147-152, </pages> <year> 1983. </year>
Reference-contexts: The general pattern here is that believing something may be worse than not believing it, even though not believing it is worse than believing it for good reason. (See <ref> [5, 11] </ref> for more examples.) 4.6 Economic vs. Gardenfors rationality Are economically rational contractions rational in Gardenfors's sense? The obvious answer is no: rational contraction is of a different type than Gardenfors's contraction, a nondeterministic relation rather than a functional relation, and this nondeterminism can cause big differences.
Reference: [6] <author> M. Dalal. </author> <title> Investigations into a theory of knowledge base revision: Preliminary report. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> pages 475-479, </pages> <address> San Mateo, CA, </address> <month> August </month> <year> 1988. </year> <booktitle> AAAI, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Recently these studies have been complemented by detailed studies by philosophers (e.g., [36, 28, 42, 20, 14]) and artificial intelligence researchers (e.g., <ref> [9, 17, 44, 6, 29, 32, 37] </ref>) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of believed propositions.
Reference: [7] <author> J. de Kleer. </author> <title> An assumption-based tms. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 127-162, </pages> <year> 1986. </year>
Reference-contexts: Numerous practical systems for belief revision called reason maintenance or truth fl Copyright c fl 1990 by Jon Doyle. maintenance systems have also been developed in artificial intelligence (see <ref> [41, 8, 30, 7, 19] </ref>), and even some philosophers have implemented systems corresponding to their theories [34]. One of the best developed formal theories of belief revision is that expounded by Gardenfors [14], based on work with Alchourron and Makinson [1].
Reference: [8] <author> J. Doyle. </author> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12(2) </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference-contexts: Numerous practical systems for belief revision called reason maintenance or truth fl Copyright c fl 1990 by Jon Doyle. maintenance systems have also been developed in artificial intelligence (see <ref> [41, 8, 30, 7, 19] </ref>), and even some philosophers have implemented systems corresponding to their theories [34]. One of the best developed formal theories of belief revision is that expounded by Gardenfors [14], based on work with Alchourron and Makinson [1].
Reference: [9] <author> J. Doyle. </author> <title> Some theories of reasoned assumptions: An essay in rational psychology. </title> <type> Technical Report 83-125, </type> <institution> Department of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1983. </year>
Reference-contexts: Recently these studies have been complemented by detailed studies by philosophers (e.g., [36, 28, 42, 20, 14]) and artificial intelligence researchers (e.g., <ref> [9, 17, 44, 6, 29, 32, 37] </ref>) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of believed propositions.
Reference: [10] <author> J. Doyle. </author> <title> Artificial intelligence and rational self-government. </title> <type> Technical Report CS-88-124, </type> <institution> Carnegie-Mellon University Computer Science Department, </institution> <year> 1988. </year>
Reference-contexts: It is not clear that this assumption is necessary, or that the definitions here are the best possible. How to deal with the case in which no alternatives are maximally preferred is an interesting question for future study. It would appear that the notion of rational representation <ref> [10, 11] </ref>, in which consistent subsets of inconsistent preferences are chosen to temporarily represent the inconsistent sets, should play a role here. The generality exhibited in the definitions of rational contraction and revision goes against the usual presupposition of epistemologists that knowing more is always better.
Reference: [11] <author> J. Doyle. </author> <title> Constructive belief and rational representation. </title> <journal> Computational Intelligence, </journal> <volume> 5(1) </volume> <pages> 1-11, </pages> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: We examine how irrationalities in preference aggregation lead to violations of Gardenfors's rationality axioms. Section 6 expands the theory further to cover rational revision of preferences. This final expansion, which is related to our earlier theory of constructive attitudes <ref> [11] </ref>, introduces further ways in which rational belief revision can diverge from Gardenfors's notion. 2 Revising belief states Gardenfors's formalization of belief revision may be summarized as follows, using an adaptation of Nebel's notation. <p> It is not clear that this assumption is necessary, or that the definitions here are the best possible. How to deal with the case in which no alternatives are maximally preferred is an interesting question for future study. It would appear that the notion of rational representation <ref> [10, 11] </ref>, in which consistent subsets of inconsistent preferences are chosen to temporarily represent the inconsistent sets, should play a role here. The generality exhibited in the definitions of rational contraction and revision goes against the usual presupposition of epistemologists that knowing more is always better. <p> The general pattern here is that believing something may be worse than not believing it, even though not believing it is worse than believing it for good reason. (See <ref> [5, 11] </ref> for more examples.) 4.6 Economic vs. Gardenfors rationality Are economically rational contractions rational in Gardenfors's sense? The obvious answer is no: rational contraction is of a different type than Gardenfors's contraction, a nondeterministic relation rather than a functional relation, and this nondeterminism can cause big differences. <p> In Nebel's theory, belief states are just the deductive closures of belief bases. This follows a long tradition of deductive representation. But as argued elsewhere <ref> [11] </ref>, the representation relation between belief bases and belief states should be viewed instead as rational selection of sets of consequential beliefs and preferences given an initial set of beliefs and preferences. That is, the meaning of finite belief representations will depend on preferences in practical approaches to representation.
Reference: [12] <author> J. Doyle and M. P. Wellman. </author> <title> Impediments to universal preference-based default theories. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR'89), </booktitle> <pages> pages 94-102, </pages> <address> San Mateo, CA, May 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We then present the formal theory of rational revision guided by multiple partial preferences, which is based on several principles for rationally aggregating partial preferences. This theory is formally similar to Doyle and Wellman's <ref> [12] </ref> theory of rational default reasoning and to the economic theory of social choice [3]. We prove that no method for belief revision based on partial preferences satisfies all the rationality conditions on preference aggregation. We examine how irrationalities in preference aggregation lead to violations of Gardenfors's rationality axioms. <p> These preferences can conflict on cases like that of Nixon, and a preferences for more specific rules does not help since "Quaker" and "Republican" are incomparable categories. Indeed, as argued in <ref> [12] </ref>, other preference criteria can conflict as well, including very specific criteria corresponding to individual default rules. Constructing a global ordering thus means resolving the conflicts among the preference criteria being combined. In addition to flexibility, we seek a revision method which is potentially mechanizable. <p> Thus we seek conflict resolution mechanisms based on general, modular rules of combination that apply even as the criteria used evolve. 5.1 Constructing global preference orders To analyze the problem of modular construction of orderings, we follow the formal approach elaborated in <ref> [12] </ref> for analyzing the related problem for preference-based nonmonotonic logics. We say that an aggregation policy is a function that specifies the global order corresponding to any given set of partial preference orders. <p> But like Nebel's orderings, these linear orderings are not very flexible, and can be expected to require ongoing manual revision to achieve satisfactory performance. (See <ref> [12] </ref> for more discussion of ways around theorem 5 in the context of nonmono-tonic logic.) 5.2 Revision rationality and aggregation rationality Some irrationalities in preference aggregation do not affect the formal rationality of belief revision.
Reference: [13] <author> R. Fagin, J. D. Ullman, and M. Y. Vardi. </author> <title> On the semantics of updates in databases. </title> <booktitle> In Proceed 15 ings of the Second ACM SIGACT-SIGMOD Con--ference, </booktitle> <pages> pages 352-365, </pages> <year> 1983. </year>
Reference-contexts: if :x were now believed. 2.2 Epistemic entrenchment Though Gardenfors first characterizes rational revisions by means of the preceding axioms, he views the behaviors these axioms describe as arising from a more fundamental notion, that of epistemic entrenchment [14, 16], which is related to the notion of database priorities in <ref> [13] </ref>. Epistemic entrenchment is characterized by a complete preorder (a reflexive and transitive relation) over propositions which indicates which propositions are more valuable than others.
Reference: [14] <author> P. Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1988. </year>
Reference-contexts: Many of these studies view knowledge in probabilistic terms, phrasing the problem as one of revision of probability assessments, with Bayes's rule the central method (see, for example, [39, 21]). Recently these studies have been complemented by detailed studies by philosophers (e.g., <ref> [36, 28, 42, 20, 14] </ref>) and artificial intelligence researchers (e.g., [9, 17, 44, 6, 29, 32, 37]) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of <p> One of the best developed formal theories of belief revision is that expounded by Gardenfors <ref> [14] </ref>, based on work with Alchourron and Makinson [1]. Gardenfors models belief states with deductively closed sets of propositions (logical theories) and develops, motivates, and studies a small set of axioms that characterize how a rational agent should change its belief states when new beliefs are added, subtracted, or changed. <p> If contraction satisfies ( : : 6), then ( : and ( 8) taken together are equivalent to the "factor ing" condition (3). A (x ^ y) = (A x) " (A y) or : A y Gardenfors <ref> [14] </ref> also develops a parallel set of axioms for revisions and proves that they are logically equiva lent to the contraction postulates if the revision A : is defined by means of the Levi identity (after [27]) A + x = (A :x) + x; (4) so that revision by x <p> by x is equivalent to taking those beliefs that would be preserved if :x were now believed. 2.2 Epistemic entrenchment Though Gardenfors first characterizes rational revisions by means of the preceding axioms, he views the behaviors these axioms describe as arising from a more fundamental notion, that of epistemic entrenchment <ref> [14, 16] </ref>, which is related to the notion of database priorities in [13]. Epistemic entrenchment is characterized by a complete preorder (a reflexive and transitive relation) over propositions which indicates which propositions are more valuable than others. <p> Formally, we assume the existence of a choice function C which selects one of the elements of A # x and define the full meet contraction operation m A x = C (A # x) if 6` x A otherwise. (9) Gardenfors <ref> [14, Lemma 4.1] </ref> shows that this operation satisfies ( : : 6), but not necessarily ( : : However, failure to satisfy these last axioms is the least of the problems with maxichoice contraction, for one may prove that using maxichoice contraction to effect the revision A : + x via <p> : However, failure to satisfy these last axioms is the least of the problems with maxichoice contraction, for one may prove that using maxichoice contraction to effect the revision A : + x via (4) makes A : + x a complete belief set as long as :x 2 A <ref> [14, Corollary 4.6] </ref>. That is, A + x in this case contains either y or :y for each proposition y. <p> the operation of partial meet contraction A p by p def T A otherwise. (12) Partial meet contraction satisfies the basic rationality postulates ( : : 6), and in fact is equivalent to them in the sense that any operation satisfying these axioms is a partial meet contraction operation (see <ref> [14, Theorem 4.13] </ref>). 2.3.4 Relational contraction Some partial meet contractions, namely those derived from orderings of belief states are fully rational, satisfying ( 1)-( 8). <p> The most important case is that when v is a transitive relation. Gardenfors <ref> [14, Theorem 4.16] </ref> proves that if v is transitive, the contraction function defined by (12) and (13) satisfies ( : ( 8). <p> Since rational contraction functions may be constructed from either epistemic entrenchment order-ings of propositions or from transitive relations v over substates of belief states, it is natural to ask if there is some special connection between these orders. Gardenfors <ref> [14] </ref> views v as comparing the epistemic entrenchment of sets of propositions, but makes no explicit connection between the two notions. <p> One obvious difference is that is a total order, while v may be partial; but this difference need not be important, since Gardenfors also proves that for each transitive relation v there is a transitive total order v 0 which yields the same contraction function as v <ref> [14, Theorem 4.17] </ref>. <p> Gardenfors <ref> [14, Lemma 4.3] </ref> shows that any orderly maxichoice contraction operation satisfies all the contraction axioms, and to apply this result, we need only consider the partial order v defined so that X v Y iff either X = Y or X Y . 2 Another way of avoiding the complications of
Reference: [15] <author> P. Gardenfors. </author> <title> The dynamics of belief systems: Foundations vs. coherence theories. </title> <journal> Revue Inter-nationale de Philosophie, </journal> <volume> 172 </volume> <pages> 24-46, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: In the end, Nebel leaves unsolved the practical problem of how to represent general belief base contractions. 3.2 Epistemic relevance While one may apply the notion of epistemic entrenchment in the foundational view of belief revision, this approach is not always practical (but see <ref> [15] </ref>). <p> In particular, the whole motivation for conserving as many beliefs as possible seems entirely nonlogical. Conservatism has nothing to do with the consistency or completeness of beliefs or the soundness of inferences, which are the only characteristics of concern to logic. As Gardenfors <ref> [15] </ref> acknowledges, the motivations for conservatism are instead economic: beliefs are valuable (useful in acting, costly to infer or acquire), so getting rid of beliefs unnecessarily is irrational.
Reference: [16] <author> P. Gardenfors and D. Makinson. </author> <title> Revisions of knowledge systems using epistemic entrenchment. </title> <editor> In M. Y. Vardi, editor, </editor> <booktitle> Proceedings of the Second Conference on Theoretical Aspects of Reasoning About Knowledge, </booktitle> <pages> pages 83-95, </pages> <address> Los Altos, CA, March 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: by x is equivalent to taking those beliefs that would be preserved if :x were now believed. 2.2 Epistemic entrenchment Though Gardenfors first characterizes rational revisions by means of the preceding axioms, he views the behaviors these axioms describe as arising from a more fundamental notion, that of epistemic entrenchment <ref> [14, 16] </ref>, which is related to the notion of database priorities in [13]. Epistemic entrenchment is characterized by a complete preorder (a reflexive and transitive relation) over propositions which indicates which propositions are more valuable than others. <p> The main result of the theory of epistemic entrenchment is that this notion is essentially equivalent to the previously axiomatized notion of rational revision. Gardenfors and Makinson <ref> [16] </ref> prove this equivalence in two parts. They first prove that rational contraction functions may be constructed from orderings of epistemic entrenchment, specifically, that if an ordering satisfies (1)-(5), then the contraction function uniquely determined by the contraction condition (6) satisfies ( : : 8) as well as (7). <p> Moreover, this form of belief base contraction is fully rational, and corresponds to maxichoice contraction [32, Lemma 17ff]. Epistemic entrenchment is not entirely impractical, as Gardenfors and Makinson <ref> [16] </ref> show that epistemic entrenchment orders can be efficiently represented by information linear in the number of atomic propositions. But pure representation is only half the problem, and they leave the problem of logical dependencies unaddressed.
Reference: [17] <author> M. L. Ginsberg. </author> <title> Counterfactuals. </title> <journal> Artificial Intelligence, </journal> <volume> 30(1) </volume> <pages> 35-79, </pages> <year> 1986. </year>
Reference-contexts: Recently these studies have been complemented by detailed studies by philosophers (e.g., [36, 28, 42, 20, 14]) and artificial intelligence researchers (e.g., <ref> [9, 17, 44, 6, 29, 32, 37] </ref>) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of believed propositions.
Reference: [18] <author> I. J. </author> <title> Good. On the principle of total evidence. In Good Thinking: The Foundations of Probability and Its Applications. </title> <publisher> University of Minnesota Press, </publisher> <year> 1983. </year> <journal> Originally appeared in British Journal of Philosophy of Science, </journal> <volume> 17 </volume> <pages> 319-321, </pages> <year> 1967. </year>
Reference-contexts: The generality exhibited in the definitions of rational contraction and revision goes against the usual presupposition of epistemologists that knowing more is always better. Indeed, one can even prove that knowing more is better in some standard theories (see <ref> [18] </ref>). But this presupposition (or theorem) is not always justified when beliefs incur costs to the agent. For example, the set A # x need not be computable, or if computable, may take too long to compute.
Reference: [19] <author> J. W. Goodwin. </author> <title> A Theory and System for Non-Monotonic Reasoning. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, Linkoping University, Linkoping, Sweden, </institution> <year> 1987. </year> <booktitle> Linkoping Studies in Science and Technology, </booktitle> <volume> No. </volume> <pages> 165. </pages>
Reference-contexts: Numerous practical systems for belief revision called reason maintenance or truth fl Copyright c fl 1990 by Jon Doyle. maintenance systems have also been developed in artificial intelligence (see <ref> [41, 8, 30, 7, 19] </ref>), and even some philosophers have implemented systems corresponding to their theories [34]. One of the best developed formal theories of belief revision is that expounded by Gardenfors [14], based on work with Alchourron and Makinson [1].
Reference: [20] <author> G. Harman. </author> <title> Change in View: </title> <booktitle> Principles of Reasoning. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Many of these studies view knowledge in probabilistic terms, phrasing the problem as one of revision of probability assessments, with Bayes's rule the central method (see, for example, [39, 21]). Recently these studies have been complemented by detailed studies by philosophers (e.g., <ref> [36, 28, 42, 20, 14] </ref>) and artificial intelligence researchers (e.g., [9, 17, 44, 6, 29, 32, 37]) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of <p> See [25, 26].) In Harman's <ref> [20] </ref> terminology, Gardenfors's theory is a coherence theory as it requires only that belief states be internally coherent. <p> A + x = Cn (A [ fxg) (2) Contraction and revision, on the other hand, have no single natural definitions, only the standard requirement that the change made be as small as possible so as to minimize unnecessary loss of knowledge. (Quine [35] calls this requirement "minimum mutilation;" Har-man <ref> [20] </ref> calls it "conservativity.") This requirement does not define these operations since there are usually several ways to get rid of some belief. In the case of contraction, for example, there is generally no largest belief set B A such that B 6` x.
Reference: [21] <author> W. L. Harper. </author> <title> Rational belief change, Popper functions, and counterfactuals. </title> <editor> In W. L. Harper and C. A. Hooker, editors, </editor> <title> Foundations of Probability Theory, Statistical Inference, </title> <journal> and Statistical Theories of Science, </journal> <volume> volume 1, </volume> <pages> pages 73-115. </pages> <publisher> Reidel, </publisher> <address> Dordrecht, </address> <year> 1976. </year>
Reference-contexts: Many of these studies view knowledge in probabilistic terms, phrasing the problem as one of revision of probability assessments, with Bayes's rule the central method (see, for example, <ref> [39, 21] </ref>).
Reference: [22] <author> W. L. Harper. </author> <title> Rational conceptual change. </title> <booktitle> In PSA 1976, </booktitle> <volume> volume 2, </volume> <pages> pages 462-494, </pages> <address> East Lansing, MI, </address> <year> 1976. </year> <institution> Philosophy of Science Association. </institution>
Reference-contexts: One can also define contractions in terms of revisions by means of the Harper identity (after <ref> [22] </ref>) A x = (A + :x) " A; (5) so that the contraction by x is equivalent to taking those beliefs that would be preserved if :x were now believed. 2.2 Epistemic entrenchment Though Gardenfors first characterizes rational revisions by means of the preceding axioms, he views the behaviors these
Reference: [23] <author> J. F. Horty, R. H. Thomason, and D. S. Touretzky. </author> <title> A skeptical theory of inheritance in nonmonotonic semantic networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):311-348, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: The skepticism of partial meet contraction is similar to the skepticism of certain theories of inheritance and default reasoning, in which the conclusions of a theory are defined to be those which hold in every maximally preferred interpretation (see <ref> [23, 40] </ref>). 2 The difficulty is that skepticism is not always rational. The agent cannot always rationally choose to remain skeptical about questions concerning actions that are very important to an agent's prosperity.
Reference: [24] <author> R. C. Jeffrey. </author> <title> The Logic of Decision. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <note> second edition, </note> <year> 1983. </year>
Reference-contexts: In particular, the optimal revision according to the preferences held prior to a revision may not be optimal according to the preferences obtaining after the revision. Paraphrasing Jeffrey <ref> [24] </ref>, we may say that a ratified revision or contraction is one that is rational according to the preferences that result from the revision or contraction. 6.2 Belief-dependent preferences This picture leaves preferences completely independent of beliefs.
Reference: [25] <author> K. Konolige. </author> <title> Belief and incompleteness. </title> <editor> In J. R. Hobbs and R. C. Moore, editors, </editor> <booktitle> Formal Theories of the Common-Sense World, </booktitle> <pages> pages 359-403. </pages> <publisher> Ablex, </publisher> <address> Norwood, </address> <year> 1985. </year>
Reference-contexts: See <ref> [25, 26] </ref>.) In Harman's [20] terminology, Gardenfors's theory is a coherence theory as it requires only that belief states be internally coherent.
Reference: [26] <author> H. J. Levesque. </author> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 198-202. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1984. </year>
Reference-contexts: See <ref> [25, 26] </ref>.) In Harman's [20] terminology, Gardenfors's theory is a coherence theory as it requires only that belief states be internally coherent. <p> The whole notion of belief state idealizes far beyond what seems reasonable for agents of limited cognitive abilities, whose explicit beliefs (in the sense of Levesque <ref> [26] </ref>) might not be closed or consistent, calling ( : 1) into question.
Reference: [27] <editor> I. Levi. Subjunctives, dispositions and chances. Synthese, </editor> <volume> 34 </volume> <pages> 423-455, </pages> <year> 1977. </year>
Reference-contexts: (x ^ y) = (A x) " (A y) or : A y Gardenfors [14] also develops a parallel set of axioms for revisions and proves that they are logically equiva lent to the contraction postulates if the revision A : is defined by means of the Levi identity (after <ref> [27] </ref>) A + x = (A :x) + x; (4) so that revision by x is equivalent to contracting by :x to remove any inconsistent beliefs and then expanding with x.
Reference: [28] <author> D. Lewis. </author> <title> Counterfactuals. </title> <publisher> Blackwell, Oxford, </publisher> <year> 1973. </year>
Reference-contexts: Many of these studies view knowledge in probabilistic terms, phrasing the problem as one of revision of probability assessments, with Bayes's rule the central method (see, for example, [39, 21]). Recently these studies have been complemented by detailed studies by philosophers (e.g., <ref> [36, 28, 42, 20, 14] </ref>) and artificial intelligence researchers (e.g., [9, 17, 44, 6, 29, 32, 37]) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of
Reference: [29] <author> J. a. P. Martins and S. C. Shapiro. </author> <title> A model for belief revision. </title> <journal> Artificial Intelligence, </journal> <volume> 35(1) </volume> <pages> 25-79, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Recently these studies have been complemented by detailed studies by philosophers (e.g., [36, 28, 42, 20, 14]) and artificial intelligence researchers (e.g., <ref> [9, 17, 44, 6, 29, 32, 37] </ref>) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of believed propositions.
Reference: [30] <author> D. A. McAllester. </author> <title> A three valued truth maintenance system. </title> <type> AIM 473, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, 545 Technology Square, </institution> <address> Cambridge, MA, 02139, </address> <year> 1978. </year>
Reference-contexts: Numerous practical systems for belief revision called reason maintenance or truth fl Copyright c fl 1990 by Jon Doyle. maintenance systems have also been developed in artificial intelligence (see <ref> [41, 8, 30, 7, 19] </ref>), and even some philosophers have implemented systems corresponding to their theories [34]. One of the best developed formal theories of belief revision is that expounded by Gardenfors [14], based on work with Alchourron and Makinson [1].
Reference: [31] <author> D. A. McAllester. </author> <title> Reasoning Utility Package user's manual. </title> <type> AIM 667, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, 545 Technology Square, </institution> <address> Cambridge, MA, 02139, </address> <year> 1982. </year>
Reference-contexts: Moreover, maxichoice base contraction is just as rational as the more complicated base contraction. Since it can be iterated easily and does not introduce complicated disjunctions, it is to be preferred in practice. He points to McAllester's <ref> [31] </ref> rup system as an implemen tation of just this sort of rational belief base revision (ignoring the issue of rup's deductive incompleteness). 3.3 Epistemic relevance vs. epistemic entrenchment The orders of epistemic relevance and epistemic entrenchment are superficially different in that epistemic entrenchment orders all propositions in L while may <p> In the second place, linear epistemic relevance orderings of the propositions in a belief base make belief base contraction easy to implement (as in rup <ref> [31] </ref>) by simply dropping the lowest ranked propo sitions in any conflicting set. Moreover, this form of belief base contraction is fully rational, and corresponds to maxichoice contraction [32, Lemma 17ff].
Reference: [32] <author> B. Nebel. </author> <title> A knowledge level analysis of belief revision. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR'89), </booktitle> <pages> pages 301-311, </pages> <address> San Mateo, CA, </address> <month> May </month> <year> 1989. </year> <note> Morgan Kauf-mann. </note>
Reference-contexts: Recently these studies have been complemented by detailed studies by philosophers (e.g., [36, 28, 42, 20, 14]) and artificial intelligence researchers (e.g., <ref> [9, 17, 44, 6, 29, 32, 37] </ref>) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of believed propositions. <p> But this "maxichoice" method has highly undesirable properties in the coherence theory, as it often produces complete sets of beliefs, even if the original set took no position on many questions. To better model AI practice, Nebel <ref> [32] </ref> adapted Gardenfors's theory so that finite sets of representing propositions mediate revisions. He then shows that the resulting revisions satisfy most of Gardenfors's rationality axioms. <p> Specifically, if : 4 is a revision operation defined by (4) and (10) and if :x 2 A and 6` :x, then A + x = Cn (fxg): (11) (See [2] or <ref> [32, Corollary 3] </ref>.) Taken together, these results about maxichoice and full meet contraction indicate that the notion of rational contraction captured by axioms ( : : 8) and (4) is really very weak. 2.3.3 Partial meet contraction If the extremes of defining the contraction A : the propositions in one or <p> Nebel <ref> [32] </ref> modified Gardenfors's theory by modeling finite representations of belief states as finite sets of propositions, called belief bases, with each belief base B L representing the belief set Cn (B). (Of course, not all belief sets are finitely repre sentable, and the representation is never unique.) 3.1 Belief base contraction <p> That is, we may use the contraction postulates to judge base contraction by identifying A with Cn (B) and identifying A : with Cn (B x). With these identifications, Nebel <ref> [32, Lemma 11] </ref> proves that belief base contraction satisfies ( 1)-( 6). Nebel proceeds to show that belief base contraction is a form of partial meet contraction when lifted to belief states. <p> Let S B be a selection function corresponding to belief set B and defined by S B (Cn (B) # x) = (16) C 0 " B 6 C " Bg: Nebel <ref> [32, Theorem 14] </ref> then proves that contraction of finite premise sets B using is identical (with respect to `) to a partial meet contraction p defined by the selection function S B , that is, Cn (B x) = Cn (B) x: (17) This guarantees that the lifted version of satisfies <p> By defining the order v by X v Y iff X " B 6 Y " B, (18) Nebel proves that partial meet contraction using S B satisfies ( : 7) as well <ref> [32, Theorem 15] </ref>. <p> Nebel then defines a new selection function S B; in terms of v by S B; (A # x) = (20) C 0 " B v C " Bg and proves <ref> [32, Theorem 16] </ref> that partial meet contraction defined by this selection function gives rise to a fully rational contraction function satisfying ( : : If is a linear ordering (no ties allowed), then every finite set of beliefs has a most relevant element, and we may rewrite the definition of v <p> the definition of v as X v Y iff max (X Y ) max (Y X). (21) In this case, v always singles out the greatest element of (B # x), and the partial meet contraction function defined using S B; resembles a maxichoice contraction on the belief base (see <ref> [32, Lemma 17] </ref>). Nebel concludes from this that maxichoice contraction on belief bases does not have the undesirable completion behavior exhibited by maxichoice contraction of belief states. Moreover, maxichoice base contraction is just as rational as the more complicated base contraction. <p> Moreover, this form of belief base contraction is fully rational, and corresponds to maxichoice contraction <ref> [32, Lemma 17ff] </ref>. Epistemic entrenchment is not entirely impractical, as Gardenfors and Makinson [16] show that epistemic entrenchment orders can be efficiently represented by information linear in the number of atomic propositions. But pure representation is only half the problem, and they leave the problem of logical dependencies unaddressed.
Reference: [33] <author> B. Nebel. </author> <title> Representation and Reasoning in Hybrid Representation Systems. </title> <booktitle> Number 422 in Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: Nebel <ref> [33, pp. 162-166] </ref> introduces the notion of epistemic relevance as an analogue of epis-temic entrenchment more suited to the needs of computational belief revision.
Reference: [34] <author> J. L. Pollock. </author> <title> Defeasible reasoning. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 481-518, </pages> <year> 1987. </year>
Reference-contexts: Numerous practical systems for belief revision called reason maintenance or truth fl Copyright c fl 1990 by Jon Doyle. maintenance systems have also been developed in artificial intelligence (see [41, 8, 30, 7, 19]), and even some philosophers have implemented systems corresponding to their theories <ref> [34] </ref>. One of the best developed formal theories of belief revision is that expounded by Gardenfors [14], based on work with Alchourron and Makinson [1].
Reference: [35] <author> W. V. Quine. </author> <title> Philosophy of Logic. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1970. </year>
Reference-contexts: the belief set and the new proposition: A + x = Cn (A [ fxg) (2) Contraction and revision, on the other hand, have no single natural definitions, only the standard requirement that the change made be as small as possible so as to minimize unnecessary loss of knowledge. (Quine <ref> [35] </ref> calls this requirement "minimum mutilation;" Har-man [20] calls it "conservativity.") This requirement does not define these operations since there are usually several ways to get rid of some belief.
Reference: [36] <author> W. V. Quine and J. S. Ullian. </author> <title> The Web of Belief. Random House, </title> <address> New York, </address> <note> second edition, </note> <year> 1978. </year>
Reference-contexts: Many of these studies view knowledge in probabilistic terms, phrasing the problem as one of revision of probability assessments, with Bayes's rule the central method (see, for example, [39, 21]). Recently these studies have been complemented by detailed studies by philosophers (e.g., <ref> [36, 28, 42, 20, 14] </ref>) and artificial intelligence researchers (e.g., [9, 17, 44, 6, 29, 32, 37]) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of <p> It would be valuable to have some more flexible way of specifying preferences for guiding contraction and revision. If we look to the usual explanations of why one revision is selected over another (such as those in <ref> [36] </ref>), we see that many different properties of propositions influence whether one proposition is preferred to another.
Reference: [37] <author> A. S. Rao and N. Y. Foo. </author> <title> Formal theories of belief revision. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR'89), </booktitle> <pages> pages 369-380, </pages> <address> San Mateo, CA, </address> <month> May </month> <year> 1989. </year> <note> Morgan Kauf-mann. </note>
Reference-contexts: Recently these studies have been complemented by detailed studies by philosophers (e.g., [36, 28, 42, 20, 14]) and artificial intelligence researchers (e.g., <ref> [9, 17, 44, 6, 29, 32, 37] </ref>) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of believed propositions.
Reference: [38] <author> F. S. Roberts. </author> <title> Discrete Mathematical Models. </title> <publisher> Prentice-Hall Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1976. </year>
Reference-contexts: The principled design of an aggregation policy for partial preference criteria begins with a consideration of properties we think a reasonable policy should exhibit. The properties we propose are analogs of Arrow's [3] desiderata for social choice. 3 3 Consult sources on social choice theory <ref> [3, 38] </ref> for somewhat more rigorous versions of these desiderata, though for the case of total orders. 1. Collective rationality. The global order ~ is a function of the individual orders ~ i , which are unre stricted, possibly partial, preorders. <p> Proof: With the restriction to total orders, this is exactly Arrow's theorem. For a proof of the original result see [4] or <ref> [38, Chapter 7] </ref>. 2 There is no problem finding good aggregation policies for choices among only two alternatives: majority rule works fine, for example. But for the case of belief revision, there are typically several possible alternatives to choose from.
Reference: [39] <author> L. J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1972. </year>
Reference-contexts: Many of these studies view knowledge in probabilistic terms, phrasing the problem as one of revision of probability assessments, with Bayes's rule the central method (see, for example, <ref> [39, 21] </ref>).
Reference: [40] <author> Y. Shoham. </author> <title> Reasoning about Change: Time and Causation from the Standpoint of Artificial Intelligence. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: The skepticism of partial meet contraction is similar to the skepticism of certain theories of inheritance and default reasoning, in which the conclusions of a theory are defined to be those which hold in every maximally preferred interpretation (see <ref> [23, 40] </ref>). 2 The difficulty is that skepticism is not always rational. The agent cannot always rationally choose to remain skeptical about questions concerning actions that are very important to an agent's prosperity.
Reference: [41] <author> R. M. Stallman and G. J. Sussman. </author> <title> Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9(2) </volume> <pages> 135-196, </pages> <year> 1977. </year>
Reference-contexts: Numerous practical systems for belief revision called reason maintenance or truth fl Copyright c fl 1990 by Jon Doyle. maintenance systems have also been developed in artificial intelligence (see <ref> [41, 8, 30, 7, 19] </ref>), and even some philosophers have implemented systems corresponding to their theories [34]. One of the best developed formal theories of belief revision is that expounded by Gardenfors [14], based on work with Alchourron and Makinson [1].
Reference: [42] <author> R. C. Stalnaker. </author> <title> Inquiry. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1984. </year>
Reference-contexts: Many of these studies view knowledge in probabilistic terms, phrasing the problem as one of revision of probability assessments, with Bayes's rule the central method (see, for example, [39, 21]). Recently these studies have been complemented by detailed studies by philosophers (e.g., <ref> [36, 28, 42, 20, 14] </ref>) and artificial intelligence researchers (e.g., [9, 17, 44, 6, 29, 32, 37]) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of
Reference: [43] <author> R. H. Thomason. </author> <title> The context-sensitivity of be-lief and desire. </title> <editor> In M. P. Georgeff and A. L. Lan-sky, editors, </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <pages> pages 341-360. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: In this setting, revision of preferences may be viewed as entirely analogous to revision of beliefs, guided by principles like the Gardenfors axioms, but subject to ` P 4 Thomason <ref> [43] </ref> raises doubts about whether beliefs and preferences are really determined by mental states, but we will not address this issue here. instead of `. But a new issue arises if we seek to make preference revision rational by using preferences about preferences.
Reference: [44] <author> M. Winslett. </author> <booktitle> Is belief revision harder than you thought? In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <volume> volume 1, </volume> <pages> pages 421-427, </pages> <month> August </month> <year> 1986. </year> <month> 17 </month>
Reference-contexts: Recently these studies have been complemented by detailed studies by philosophers (e.g., [36, 28, 42, 20, 14]) and artificial intelligence researchers (e.g., <ref> [9, 17, 44, 6, 29, 32, 37] </ref>) of belief revision in a nonprobabilistic setting, in which one views the beliefs of an agent as a set of propositions and seeks to describe how a rational agent should change its set of believed propositions.
References-found: 44

