URL: http://www.cs.bu.edu/techreports/98-007-tracking-multiple-humans.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Title: Pattern Recognition. Workshop on the Interpretation of Visual Motion, Santa Barbara, CA, 1998. Improved Tracking
Author: R omer Rosales and Stan Sclaroff 
Address: Boston, MA 02215  
Affiliation: Image and Video Computing Group Computer Science Department Boston University  
Note: To appear in Proceedings IEEE Conf. on Computer Vision and  
Abstract: A combined 2D, 3D approach is presented that allows for robust tracking of moving bodies in a given environment as observed via a single, uncalibrated video camera. Low-level features are often insufficient for detection, segmentation, and tracking of non-rigid moving objects. Therefore, an improved mechanism is proposed that combines low-level (image processing) and mid-level (recursive trajectory estimation) information obtained during the tracking process. The resulting system can segment and maintain the tracking of moving objects before, during, and after occlusion. At each frame, the system also extracts a stabilized coordinate frame of the moving objects. This stabilized frame can be used as input to motion recognition modules. The approach enables robust tracking without constraining the system to know the shape of the objects being tracked beforehand; although, some assumptions are made about the characteristics of the shape of the objects, and how they evolve with time. Experiments in tracking moving people are described. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Azarbayejani and A. Pentland. </author> <title> Recursive estimation of motion, structure, </title> <journal> and focal lenght. PAMI, </journal> <volume> 17(6), </volume> <year> 1995. </year>
Reference-contexts: For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision <ref> [8, 28, 1, 22, 26, 6, 9] </ref>. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34]. <p> For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision [8, 28, 1, 22, 26, 6, 9]. Another important set of approaches is based on [16]. Our formulation has some similarities to <ref> [1] </ref>. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34]. The system is initialized by acquiring statistical measurements of the empty scene over a number of video frames. <p> The parameterization and selection of the state vector is in part related to the work of <ref> [1] </ref>, who used it in a structure from motion problem. However, they tested their approach with rigid structures with the assumption that enough number of feature points are tracked during the sequence. The problem of feature correspondence and tracking was not addressed directly. <p> However, when analyzing basic human locomotion, we believe that these assumptions are a fair approximation. 5.2 Camera Model For our representation a 3D central projection model similar to <ref> [32, 1] </ref> is used: v = x 1 + zfi where (x; y; z) is the real 3D feature location in the camera reference frame, (u; v) is the projection of it to the camera plane, and fi = 1 f is the inverse focal length. <p> The origin of the coordinate system is fixed at the image plane. This model has proven to be useful when estimating focal length and structure in the structure from motion problem <ref> [1] </ref>. One important property of this model is that it is numerically well defined even in the case of orthographic projection. 5.3 3D Representation of Feature Points One of the novel techniques here introduced is the use of a convenient parameterization of the feature points. <p> This formulation only allows for recovery of depth up to a scale factor. For our tracking application, there is no need to recover the true 3D position of the feature point. The noise sensitivity of a similar formulation has been analyzed in <ref> [1] </ref>. Without the effect of registration inaccuracies, the sensitivity in _x and _y is directly dependent on the object depth. This is because objects that are farther away from the camera tend to project to fewer image pixels. The sensitivity of _z depends on camera focal length.
Reference: [2] <author> A. Azarbayejani and A. Pentland. </author> <title> Real-time 3d tracking of the human body. In Image Com, </title> <year> 1996. </year>
Reference-contexts: The basic detection and registration technique used in our approach, based on background segmentation, is related to the work of Baumberg and Hogg [3] and Bich-sel [5]. Using similar differencing techniques are <ref> [34, 2] </ref>, whose likelihood measurement approach is closely related to ours; however, they used it in the simpler problem of detecting a single moving object. Nonetheless, these works showed how this information can be used as input for more sophisticated techniques.
Reference: [3] <author> A. Baumberg and D. Hogg. </author> <title> Learning flexible models from image sequences. </title> <booktitle> In ECCV, </booktitle> <year> 1994. </year>
Reference-contexts: Perhaps one of the first approaches related with walking people in real environments is due to Hogg [14]. The basic detection and registration technique used in our approach, based on background segmentation, is related to the work of Baumberg and Hogg <ref> [3] </ref> and Bich-sel [5]. Using similar differencing techniques are [34, 2], whose likelihood measurement approach is closely related to ours; however, they used it in the simpler problem of detecting a single moving object. Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. <p> The use of a fixed camera makes background-foreground segmentation methods well suited for this task <ref> [34, 3, 5, 15, 29] </ref>. If controlled with a feedback approach, such methods can achieve a good level of accuracy [34]. More importantly, this approach is efficient enough to allow real-time tracking. Finally, these techniques also allow detection of foreground objects even when they are not moving.
Reference: [4] <author> D. Beymer, P. McLauchlan, B Coifman, and J. Malik. </author> <title> A real-time computer vision system for measuring traffic parameters. </title> <booktitle> In CVPR, </booktitle> <year> 1997. </year>
Reference-contexts: Most of the techniques mentioned have not been tested in areas where multiple non-rigid objects interact and/or the object paths undergo the projective effect of image formation. Rigidity of objects has been explicitly exploited by <ref> [20, 12, 8, 4] </ref>. Our approach is related more to these because in some situations we use the idea of a global rigid body when fixing the feature points. For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31].
Reference: [5] <author> M. Bichsel. </author> <title> Segmenting simply connected moving objects in a static scene. </title> <journal> PAMI, </journal> <volume> 16 </volume> (11):1138-1142, 1994. 
Reference-contexts: Perhaps one of the first approaches related with walking people in real environments is due to Hogg [14]. The basic detection and registration technique used in our approach, based on background segmentation, is related to the work of Baumberg and Hogg [3] and Bich-sel <ref> [5] </ref>. Using similar differencing techniques are [34, 2], whose likelihood measurement approach is closely related to ours; however, they used it in the simpler problem of detecting a single moving object. Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. <p> The use of a fixed camera makes background-foreground segmentation methods well suited for this task <ref> [34, 3, 5, 15, 29] </ref>. If controlled with a feedback approach, such methods can achieve a good level of accuracy [34]. More importantly, this approach is efficient enough to allow real-time tracking. Finally, these techniques also allow detection of foreground objects even when they are not moving.
Reference: [6] <author> A. Blake, R. Curwen, , and A. Zisserman. </author> <title> A framework for spatiotemporal control in the tracking of visual contours. </title> <journal> IJCV, </journal> <volume> 11(2) </volume> <pages> 127-145, </pages> <year> 1991. </year>
Reference-contexts: For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision <ref> [8, 28, 1, 22, 26, 6, 9] </ref>. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34].
Reference: [7] <author> H. Blom. </author> <title> An efficient filter for abruptly changing systems. </title> <booktitle> In Proc. Conf. on Decision Control, </booktitle> <year> 1984. </year>
Reference-contexts: The experimental system averaged 5 fps. For convergence, the EKF needed about 40 frames on average in our experiments. The performance and generality of the system can be improved by using an Interacting Multiple Model approach (IMM) <ref> [8, 7] </ref>. In this approach, n EKF's with different dynamics properties are run together direction during occlusion. and the system determines which one better describes the observations. This could allow for the estimation of positions when we want to consider different model dynamics.
Reference: [8] <author> K. Bradshaw, I. Reid, and D. Murray. </author> <title> The active recovery of 3d motion trajectories and their use in prediction. </title> <journal> PAMI, </journal> <volume> 19(3), </volume> <year> 1997. </year>
Reference-contexts: Most of the techniques mentioned have not been tested in areas where multiple non-rigid objects interact and/or the object paths undergo the projective effect of image formation. Rigidity of objects has been explicitly exploited by <ref> [20, 12, 8, 4] </ref>. Our approach is related more to these because in some situations we use the idea of a global rigid body when fixing the feature points. For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. <p> For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision <ref> [8, 28, 1, 22, 26, 6, 9] </ref>. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34]. <p> The problem of feature correspondence and tracking was not addressed directly. Furthermore, their method could not handle the appearance (or disappearance) of new features. Our approach is also related to the ideas of <ref> [8] </ref> in the use of an EKF to predict and recover object trajectories. 5.1 Features To reduce the complexity of the tracking problem, two feature points are selected: two opposite corners in the object bounding box. <p> The experimental system averaged 5 fps. For convergence, the EKF needed about 40 frames on average in our experiments. The performance and generality of the system can be improved by using an Interacting Multiple Model approach (IMM) <ref> [8, 7] </ref>. In this approach, n EKF's with different dynamics properties are run together direction during occlusion. and the system determines which one better describes the observations. This could allow for the estimation of positions when we want to consider different model dynamics.
Reference: [9] <author> C. Bregler. </author> <title> Learning and recognizing human dynamics in video sequences. </title> <booktitle> In CVPR97, </booktitle> <year> 1997. </year>
Reference-contexts: Effective solutions to these problems would lead to breakthroughs in areas such as video surveillance, motion analysis, virtual reality interfaces, robot navigation and recognition. Low-level image processing methods have been shown to work surprisingly well in restricted domains despite the lack of high-level models; e.g., <ref> [11, 10, 21, 34, 9] </ref>. Unfortunately, most of these techniques assume a simplified version of the general problem; e.g., there is only one moving object, objects do not occlude each other, or objects appear at a limited range of scales and orientations. <p> For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision <ref> [8, 28, 1, 22, 26, 6, 9] </ref>. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34].
Reference: [10] <author> T. Darrell and A. Pentland. </author> <title> Classifying hand gestures with a view-based distributed representation. </title> <booktitle> In NIPS, </booktitle> <year> 1994. </year>
Reference-contexts: Effective solutions to these problems would lead to breakthroughs in areas such as video surveillance, motion analysis, virtual reality interfaces, robot navigation and recognition. Low-level image processing methods have been shown to work surprisingly well in restricted domains despite the lack of high-level models; e.g., <ref> [11, 10, 21, 34, 9] </ref>. Unfortunately, most of these techniques assume a simplified version of the general problem; e.g., there is only one moving object, objects do not occlude each other, or objects appear at a limited range of scales and orientations.
Reference: [11] <author> J. Davis and A. F. Bobick. </author> <title> The representation and recognition of human movement using temporal templates. </title> <booktitle> In CVPR, </booktitle> <year> 1997. </year>
Reference-contexts: Effective solutions to these problems would lead to breakthroughs in areas such as video surveillance, motion analysis, virtual reality interfaces, robot navigation and recognition. Low-level image processing methods have been shown to work surprisingly well in restricted domains despite the lack of high-level models; e.g., <ref> [11, 10, 21, 34, 9] </ref>. Unfortunately, most of these techniques assume a simplified version of the general problem; e.g., there is only one moving object, objects do not occlude each other, or objects appear at a limited range of scales and orientations. <p> Many techniques developed for these purposes have had the problem that registration of useful, filtered information is a hard labor by itself <ref> [11, 23, 25, 35] </ref>.
Reference: [12] <author> N. Ferrier, S. Rowe, and A. Blake. </author> <title> Real-time traffic monitoring. </title> <type> Technical report, </type> <institution> Robotics Research Group, Oxford U., </institution> <year> 1996. </year>
Reference-contexts: Most of the techniques mentioned have not been tested in areas where multiple non-rigid objects interact and/or the object paths undergo the projective effect of image formation. Rigidity of objects has been explicitly exploited by <ref> [20, 12, 8, 4] </ref>. Our approach is related more to these because in some situations we use the idea of a global rigid body when fixing the feature points. For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31].
Reference: [13] <author> D. Gavrila and L. Davis. </author> <title> Tracking of humans in action: a 3-d model-based approac. </title> <booktitle> In Proc. ARPA Image Understanding Workshop, </booktitle> <address> Palm Springs, </address> <year> 1996. </year>
Reference-contexts: Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. These detection and registration methods have also been tested as the basis of more complicated representations like <ref> [19, 13, 24, 29, 18, 27] </ref>, who used model-based techniques, generally articulated models comprised of 2D or 3D solid primitives. Others have used multiple but rigid structures.
Reference: [14] <author> D. Hogg. </author> <title> Interpreting Images of a Known Moving Object. </title> <type> PhD thesis, </type> <institution> University of Sussex, </institution> <year> 1984. </year>
Reference-contexts: Perhaps one of the first approaches related with walking people in real environments is due to Hogg <ref> [14] </ref>. The basic detection and registration technique used in our approach, based on background segmentation, is related to the work of Baumberg and Hogg [3] and Bich-sel [5].
Reference: [15] <author> S. Intille and A. F. Bobick. </author> <title> Real time close world tracking. </title> <booktitle> In CVPR, </booktitle> <year> 1997. </year>
Reference-contexts: Others have used multiple but rigid structures. For instance [20], who used it for tracking cars. <ref> [15] </ref> uses it for tracking multiple objects, in which the projective effect is avoided through the use of a top view. Most of the techniques mentioned have not been tested in areas where multiple non-rigid objects interact and/or the object paths undergo the projective effect of image formation. <p> The use of a fixed camera makes background-foreground segmentation methods well suited for this task <ref> [34, 3, 5, 15, 29] </ref>. If controlled with a feedback approach, such methods can achieve a good level of accuracy [34]. More importantly, this approach is efficient enough to allow real-time tracking. Finally, these techniques also allow detection of foreground objects even when they are not moving. <p> For this initial map, con-nected regions are labeled using a connected component analysis algorithm and their bounding boxes are computed. Initially different connected regions are merged <ref> [15] </ref>. As opposed to previous approaches, our method includes two additional steps. First, bounding boxes are tested for collision and merged if so. Second, information from the object segmentation obtained in the previous frame is used.
Reference: [16] <author> M. Isard and A. Blake. </author> <title> Contour tracking by stochastic propagation of conditional density. </title> <booktitle> In ECCV, </booktitle> <year> 1996. </year>
Reference-contexts: For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision [8, 28, 1, 22, 26, 6, 9]. Another important set of approaches is based on <ref> [16] </ref>. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34].
Reference: [17] <author> G. Johansson. </author> <title> Visual perception of biological motion and a model for its analysis. </title> <journal> Perception and Psychophysics, </journal> <volume> 14(2): </volume> <pages> 210-211, </pages> <year> 1973. </year>
Reference-contexts: From these points of view, our system can be a functional front-end that would support these tasks. 2 Related Work One of the fundamental ideas in motion perception is the work of Johansson's moving light displays <ref> [17] </ref>, where it was demonstrated that relatively little information is needed (in theory) to perform motion recognition. Perhaps one of the first approaches related with walking people in real environments is due to Hogg [14].
Reference: [18] <author> S. Ju, M. Black, and Y. Yacoob. </author> <title> Cardboard people: A parameterized model of articulated image motion. </title> <booktitle> In Proc. Gesture Recognition, </booktitle> <year> 1996. </year>
Reference-contexts: Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. These detection and registration methods have also been tested as the basis of more complicated representations like <ref> [19, 13, 24, 29, 18, 27] </ref>, who used model-based techniques, generally articulated models comprised of 2D or 3D solid primitives. Others have used multiple but rigid structures.
Reference: [19] <author> I. Kakadiaris, D. Metaxas, and R. </author> <title> Bajcsy. Active part-decomposition, shape and motion estimation of articulated objects: A physics-based approach. </title> <booktitle> In CVPR, </booktitle> <year> 1994. </year>
Reference-contexts: Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. These detection and registration methods have also been tested as the basis of more complicated representations like <ref> [19, 13, 24, 29, 18, 27] </ref>, who used model-based techniques, generally articulated models comprised of 2D or 3D solid primitives. Others have used multiple but rigid structures.
Reference: [20] <author> D. Koller, J. Weber, and J. Malik. </author> <title> Robust multiple car tracking with occlusion reasoning. </title> <type> Technical report, </type> <address> U. C. Berkeley, </address> <year> 1994. </year>
Reference-contexts: These detection and registration methods have also been tested as the basis of more complicated representations like [19, 13, 24, 29, 18, 27], who used model-based techniques, generally articulated models comprised of 2D or 3D solid primitives. Others have used multiple but rigid structures. For instance <ref> [20] </ref>, who used it for tracking cars. [15] uses it for tracking multiple objects, in which the projective effect is avoided through the use of a top view. <p> Most of the techniques mentioned have not been tested in areas where multiple non-rigid objects interact and/or the object paths undergo the projective effect of image formation. Rigidity of objects has been explicitly exploited by <ref> [20, 12, 8, 4] </ref>. Our approach is related more to these because in some situations we use the idea of a global rigid body when fixing the feature points. For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31].
Reference: [21] <author> M.W. Krueger. </author> <title> Virtual Reality II. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Effective solutions to these problems would lead to breakthroughs in areas such as video surveillance, motion analysis, virtual reality interfaces, robot navigation and recognition. Low-level image processing methods have been shown to work surprisingly well in restricted domains despite the lack of high-level models; e.g., <ref> [11, 10, 21, 34, 9] </ref>. Unfortunately, most of these techniques assume a simplified version of the general problem; e.g., there is only one moving object, objects do not occlude each other, or objects appear at a limited range of scales and orientations.
Reference: [22] <author> L. Matthies, T. Kanade, and R. Szeliski. </author> <title> Kalman filter based algorithms for estimating depth from image sequences. </title> <journal> IJCV, </journal> <volume> 3(3) </volume> <pages> 209-236, </pages> <year> 1989. </year>
Reference-contexts: For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision <ref> [8, 28, 1, 22, 26, 6, 9] </ref>. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34].
Reference: [23] <author> S. Niyogi and E. H. Adelson. </author> <title> Analyzing and recognizing walking figures in xyt. </title> <booktitle> In CVPR, </booktitle> <year> 1994. </year>
Reference-contexts: Many techniques developed for these purposes have had the problem that registration of useful, filtered information is a hard labor by itself <ref> [11, 23, 25, 35] </ref>.
Reference: [24] <author> A. Pentland and B. Horowitz. </author> <title> Recovery of non-rigid motion and structure. </title> <journal> PAMI, </journal> <volume> 13(7):730742, </volume> <year> 1991. </year>
Reference-contexts: Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. These detection and registration methods have also been tested as the basis of more complicated representations like <ref> [19, 13, 24, 29, 18, 27] </ref>, who used model-based techniques, generally articulated models comprised of 2D or 3D solid primitives. Others have used multiple but rigid structures.
Reference: [25] <author> R. Polana and R. Nelson. </author> <title> Low level recognition of human motion. </title> <booktitle> In Proc. IEEE Workshop on Nonrigid and Articulate Motion, </booktitle> <year> 1994. </year>
Reference-contexts: Many techniques developed for these purposes have had the problem that registration of useful, filtered information is a hard labor by itself <ref> [11, 23, 25, 35] </ref>.
Reference: [26] <author> B. Rao, H. Durrant-Whyte, , and J. Sheen. </author> <title> A fully decentralized multi-sensor system for tracking and surveillance. </title> <journal> Int. J. of Robotics Research, </journal> <volume> 12(1), </volume> <year> 1993. </year>
Reference-contexts: For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision <ref> [8, 28, 1, 22, 26, 6, 9] </ref>. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34].
Reference: [27] <author> J. M. Regh and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. These detection and registration methods have also been tested as the basis of more complicated representations like <ref> [19, 13, 24, 29, 18, 27] </ref>, who used model-based techniques, generally articulated models comprised of 2D or 3D solid primitives. Others have used multiple but rigid structures.
Reference: [28] <author> D. Reynard, A. Wildenberg, A. Blake, and J. Marchant. </author> <title> Learning dynamics of complex motions from image sequences. </title> <booktitle> In ECCV, </booktitle> <year> 1996. </year>
Reference-contexts: For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see [31]. The EKF has been extensively used in computer vision <ref> [8, 28, 1, 22, 26, 6, 9] </ref>. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of [34]. <p> If additional prior information on dynamics is available, then A can be changed to better describe the system evolution <ref> [28] </ref>. In our case, we use the assumption that trajectories are locally linear in 3D.
Reference: [29] <author> K. Rohr. </author> <title> Towards model-based recognition of human movements in image sequences. </title> <address> CVGIP:IU, 59(1):94115, </address> <year> 1994. </year>
Reference-contexts: Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. These detection and registration methods have also been tested as the basis of more complicated representations like <ref> [19, 13, 24, 29, 18, 27] </ref>, who used model-based techniques, generally articulated models comprised of 2D or 3D solid primitives. Others have used multiple but rigid structures. <p> The use of a fixed camera makes background-foreground segmentation methods well suited for this task <ref> [34, 3, 5, 15, 29] </ref>. If controlled with a feedback approach, such methods can achieve a good level of accuracy [34]. More importantly, this approach is efficient enough to allow real-time tracking. Finally, these techniques also allow detection of foreground objects even when they are not moving.
Reference: [30] <author> M. Shah and R. Jain. </author> <title> Motion-Based Recognition. </title> <publisher> Kluwer Academic, </publisher> <year> 1997. </year>
Reference-contexts: 1 Introduction Tracking non-rigid objects and classifying their motion is a challenging problem. Many of the key obstacles are not solved yet. The importance of tracking and motion recognition problems is evidenced by the increasing attention they have received in recent years <ref> [30] </ref>. Effective solutions to these problems would lead to breakthroughs in areas such as video surveillance, motion analysis, virtual reality interfaces, robot navigation and recognition.
Reference: [31] <author> H.W. Sorenson. </author> <title> Least-squares estimation: From gauss to kalman. </title> <journal> IEEE Spectrum, </journal> <volume> Vol. 7, </volume> <pages> pp. 63-68, </pages> <year> 1970. </year>
Reference-contexts: Our approach is related more to these because in some situations we use the idea of a global rigid body when fixing the feature points. For estimating motion trajectories, we use the Extended Kalman Filter (EKF). For a good review, see <ref> [31] </ref>. The EKF has been extensively used in computer vision [8, 28, 1, 22, 26, 6, 9]. Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. <p> In this formulation, the general assumptions are: w is a Gaussian random vector with p (w k ) N (0; W Q k W T ), and v is also Gaussian p (v k ) N (0; V R k V T ). For more detail, see <ref> [31, 33] </ref>. 6 Occlusion Detection and Reasoning The majority of tracking systems for non-rigid objects handle only isolated objects. Occlusions present a major problem. Researchers have tried to address this problem by using multi-camera tracking, range, stereo, etc.
Reference: [32] <author> R. Szeliski and S. Bing Kang. </author> <title> Recovering 3d shape and motion from image streams using non-linear least squares. </title> <booktitle> In CVPR, </booktitle> <year> 1993. </year>
Reference-contexts: However, when analyzing basic human locomotion, we believe that these assumptions are a fair approximation. 5.2 Camera Model For our representation a 3D central projection model similar to <ref> [32, 1] </ref> is used: v = x 1 + zfi where (x; y; z) is the real 3D feature location in the camera reference frame, (u; v) is the projection of it to the camera plane, and fi = 1 f is the inverse focal length.
Reference: [33] <author> G. Welch and G. Bishop. </author> <title> An introduction to the kalman filter,. </title> <type> Technical Report TR 95-041, </type> <institution> Computer Science, UNC Chapel Hill, </institution> <year> 1995. </year>
Reference-contexts: In this formulation, the general assumptions are: w is a Gaussian random vector with p (w k ) N (0; W Q k W T ), and v is also Gaussian p (v k ) N (0; V R k V T ). For more detail, see <ref> [31, 33] </ref>. 6 Occlusion Detection and Reasoning The majority of tracking systems for non-rigid objects handle only isolated objects. Occlusions present a major problem. Researchers have tried to address this problem by using multi-camera tracking, range, stereo, etc.
Reference: [34] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: </author> <title> Real time tracking of the human body. </title> <type> Technical Report TR 353, </type> <institution> MIT Media Lab, </institution> <year> 1996. </year>
Reference-contexts: Effective solutions to these problems would lead to breakthroughs in areas such as video surveillance, motion analysis, virtual reality interfaces, robot navigation and recognition. Low-level image processing methods have been shown to work surprisingly well in restricted domains despite the lack of high-level models; e.g., <ref> [11, 10, 21, 34, 9] </ref>. Unfortunately, most of these techniques assume a simplified version of the general problem; e.g., there is only one moving object, objects do not occlude each other, or objects appear at a limited range of scales and orientations. <p> The basic detection and registration technique used in our approach, based on background segmentation, is related to the work of Baumberg and Hogg [3] and Bich-sel [5]. Using similar differencing techniques are <ref> [34, 2] </ref>, whose likelihood measurement approach is closely related to ours; however, they used it in the simpler problem of detecting a single moving object. Nonetheless, these works showed how this information can be used as input for more sophisticated techniques. <p> Another important set of approaches is based on [16]. Our formulation has some similarities to [1]. 3 Approach An overview of our approach is illustrated in Fig. 1. The first stage of the algorithm is based on the background subtraction methods of <ref> [34] </ref>. The system is initialized by acquiring statistical measurements of the empty scene over a number of video frames. The statistics acquired are the mean and covariance of image pixels in 3D color space. <p> The use of a fixed camera makes background-foreground segmentation methods well suited for this task <ref> [34, 3, 5, 15, 29] </ref>. If controlled with a feedback approach, such methods can achieve a good level of accuracy [34]. More importantly, this approach is efficient enough to allow real-time tracking. Finally, these techniques also allow detection of foreground objects even when they are not moving. <p> The use of a fixed camera makes background-foreground segmentation methods well suited for this task [34, 3, 5, 15, 29]. If controlled with a feedback approach, such methods can achieve a good level of accuracy <ref> [34] </ref>. More importantly, this approach is efficient enough to allow real-time tracking. Finally, these techniques also allow detection of foreground objects even when they are not moving. Another possible approach is to measure the optical flow and use it to guide registration and/or segmentation. <p> Occlusions due to multiple moving objects further complicate this process. 4.1 Scene Initialization Our two initial steps are based on the results of <ref> [34] </ref>. We first build a representation of the background. This is done by capturing the environment without interesting objects (those we want to track). For the empty scene to be learned, it is necessary to capture about 2 seconds (approx. 60 frames) of video.
Reference: [35] <author> J. Yamato, J. Ohya, and K. Isii. </author> <title> Recognizing human action in time sequential images using hidden markov models. </title> <booktitle> In CVPR, </booktitle> <year> 1993. </year>
Reference-contexts: Many techniques developed for these purposes have had the problem that registration of useful, filtered information is a hard labor by itself <ref> [11, 23, 25, 35] </ref>.
References-found: 35

