URL: http://www.research.att.com/~mkearns/papers/klpv-ml.ps.Z
Refering-URL: http://www.research.att.com/~mkearns/
Root-URL: 
Author: Ming Li Leonard Pitt Leslie Valiant 
Affiliation: Harvard University  Harvard University and Ohio State University  University of Illinois at Urbana-Champaign  Harvard University  
Note: Michael Kearns  
Abstract: Recent Results on Boolean Concept Learning Abstract Recently, a new formal model of learnability was introduced [23]. The model is applicable to practical learning systems because it requires the learning algorithm to be feasibly computable, yet at the same time demands only that the algorithm find an approximation to the unknown rule. We survey recent results in this new area of theoretical induction, giving both positive (learnability) and negative (non-learnability) results, as well as outlining useful techniques for proving learnability. Our main focus is the application of the model to the problem of learning boolean formulae.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Angluin. </author> <title> Finding Patterns Common to a Set of Strings. </title> <journal> JCSS 21, </journal> <pages> 46-62, </pages> <year> 1980. </year>
Reference-contexts: There are far fewer results if we insist that the convergence occur within a feasible amount of time, i.e. that the learning algorithm find a correct rule within time polynomial in the size of the examples seen and of the rule to be learned. The work of <ref> [1, 2, 8, 20, 21] </ref> stand as notable exceptions to a number of NP-completeness results which point out that this type of "exact" learning is too difficult to achieve in polynomial time when the rule may be any one of a large (exponential) class of possible rules.
Reference: [2] <author> D. Angluin. </author> <title> Inference of Reversible Languages. </title> <journal> JACM 29(3), </journal> <pages> 741-765, </pages> <year> 1982. </year>
Reference-contexts: There are far fewer results if we insist that the convergence occur within a feasible amount of time, i.e. that the learning algorithm find a correct rule within time polynomial in the size of the examples seen and of the rule to be learned. The work of <ref> [1, 2, 8, 20, 21] </ref> stand as notable exceptions to a number of NP-completeness results which point out that this type of "exact" learning is too difficult to achieve in polynomial time when the rule may be any one of a large (exponential) class of possible rules.
Reference: [3] <author> D. Angluin. </author> <title> Learning Regular Sets From Queries and Counter-examples. </title> <type> Tech. </type> <institution> Rept. TR-464, Yale U. Comp. Sci. Dept., </institution> <year> 1986. </year>
Reference-contexts: This method essentially tells us when it is safe to keep a particular hypoth esis while guaranteeing that the conditions of learnability have been met. This technique was first used in <ref> [3, 5] </ref>. <p> An extensive study of various oracles for concept learning can be found in [5]; see also <ref> [3, 23] </ref>. In the context of algorithms that learn in polynomial time, there is the related issue whether the algorithms can be made to converge even faster by a carefully chosen set of examples [26]. <p> Clearly, an important line of research in the learnability model is the investigation of other types of representations for concepts. As a start in this direction, various representations of continuous concepts have been studied [6, 13], as well as representations of languages using finite automata <ref> [3] </ref>. Also, it has been observed that relations, in the sense of predicate calculus, can be added to the propositional case in certain very restricted ways while maintaining learnability [24]. The representation issue, more generally, has been addressed also in the context of "bias" [13, 22].
Reference: [4] <author> D. Angluin and P.D. Laird. </author> <title> Identifying k-CNF Formulas From Noisy Examples. </title> <type> Tech. </type> <institution> Rept. TR-478, Yale U. Comp. Sci. Dept., </institution> <year> 1986. </year>
Reference-contexts: The two types of errors studied thus far are "random" errors and "malicious" errors. In the random error model, there is some probability that the source POS will draw from the distribution D , yet still report the example as being positive (similarly for the source NEG). In <ref> [4] </ref> it is shown that kDNF can be learned in this model even with rather high error rates.
Reference: [5] <author> D. Angluin. </author> <title> Types of Queries for Concept Learning. </title> <type> Tech. </type> <institution> Rept. TR-479, Yale U. Comp. Sci. Dept., </institution> <year> 1986. </year>
Reference-contexts: Learning in a Shallow Hypothesis Space The following method allows us to prove that certain types of algorithms learn as required by definition 1 without having to resort to detailed probabilistic arguments for each new case. Theorem 8 follows from a combination of ideas from <ref> [5, 14, 18] </ref>. It is easy to show that to be (1 ffi) confident that a given hypothesis is (1 *) accurate, it suffices to test it against 1 * ln 1 ffi randomly generated examples. <p> This method essentially tells us when it is safe to keep a particular hypoth esis while guaranteeing that the conditions of learnability have been met. This technique was first used in <ref> [3, 5] </ref>. <p> An extensive study of various oracles for concept learning can be found in <ref> [5] </ref>; see also [3, 23]. In the context of algorithms that learn in polynomial time, there is the related issue whether the algorithms can be made to converge even faster by a carefully chosen set of examples [26].
Reference: [6] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. </author> <title> Classifying Learnable Geometric Concepts With the Vapnik-Chervonenkis Dimension. </title> <booktitle> In Proc. of the 18 th Annual ACM STOC, </booktitle> <pages> pp 273-282, </pages> <year> 1986. </year>
Reference-contexts: Thus the formula found by the algorithm cannot be exponentially larger than the unknown formula, and the amount of time required for increased accuracy or confidence should not be exponential. We refer the reader to <ref> [6, 23, 24, 25] </ref> for further discussion and justification of this model. If there is an algorithm L as above which never asks for any negative (respectively positive) examples, then we'll say that A is learnable from positive (negative) examples only. <p> For example, for each number k, any kDNF formula of n variables can be written using at most (2n) k bits. A polynomial time recognition algorithm <ref> [6] </ref> for a class of representations A is an algorithm which, given any collection of examples, can find (in polynomial time) an element of A which is consistent with all examples in the given collection (assuming one exists). Theorem 6 ([6]) Let A be a class of representations such that every <p> On the other hand, every k-term-DNF formula can be expressed with a polynomial number of bits, but there is no polynomial recognition algorithm unless P = NP [17]. In either of these cases, the approach suggested in <ref> [6, 7] </ref> is that of an "Occam algorithm", which for the boolean domain is easier to describe in terms of data compression: Theorem 7 ([7]) Let ff &lt; 1, and c 1. <p> The proofs of the theorems rely on techniques using theorems 6 and 7. In addition to the positive results for representations of boolean functions presented here, there have also been learning algorithms given for continuous representations, such as linear separators and geometric regions in Euclidean space <ref> [6] </ref>. 5 Negative Results This section summarizes negative results which indicate that certain classes cannot be learned in the distribution-free sense required by the learnability model. Recall that all negative results here rely on the complexity-theoretic assumption that RP 6= NP. <p> Clearly, an important line of research in the learnability model is the investigation of other types of representations for concepts. As a start in this direction, various representations of continuous concepts have been studied <ref> [6, 13] </ref>, as well as representations of languages using finite automata [3]. Also, it has been observed that relations, in the sense of predicate calculus, can be added to the propositional case in certain very restricted ways while maintaining learnability [24].
Reference: [7] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. </author> <title> Occam's Razor. </title> <type> Tech. </type> <institution> Rept. UCSC-CRL-86-2, UC Santa Cruz, </institution> <year> 1986. </year>
Reference-contexts: On the other hand, every k-term-DNF formula can be expressed with a polynomial number of bits, but there is no polynomial recognition algorithm unless P = NP [17]. In either of these cases, the approach suggested in <ref> [6, 7] </ref> is that of an "Occam algorithm", which for the boolean domain is easier to describe in terms of data compression: Theorem 7 ([7]) Let ff &lt; 1, and c 1.
Reference: [8] <author> S. Crespi-Reghizzi. </author> <title> An Effective Model for Grammar Inference. </title> <journal> In Inform. Process. </journal> <volume> 71, </volume> <editor> B. Gilchrist, Ed. </editor> <publisher> North Holland, </publisher> <address> NY, </address> <year> 1972. </year> <month> 16 </month>
Reference-contexts: There are far fewer results if we insist that the convergence occur within a feasible amount of time, i.e. that the learning algorithm find a correct rule within time polynomial in the size of the examples seen and of the rule to be learned. The work of <ref> [1, 2, 8, 20, 21] </ref> stand as notable exceptions to a number of NP-completeness results which point out that this type of "exact" learning is too difficult to achieve in polynomial time when the rule may be any one of a large (exponential) class of possible rules.
Reference: [9] <institution> Duda Hart </institution>
Reference-contexts: By assuming certain particular input distributions, many techniques of statistical pattern recognition are capable of finding such approximate rules <ref> [9] </ref>. One problem with this approach, however, is that the input distributions assumed are not necessarily representative of nature.
Reference: [10] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: It would be just as startling if this stronger hypothesis were false. The reader is referred to <ref> [10] </ref> for further details concerning these classes. 2 An Example In this section, we illustrate how the learnability model works in the very basic case of monomials. In later sections we discuss larger learnable classes that are better suited to the real world.
Reference: [11] <author> O. Goldriech, S. Goldwasser, and S. Micali. </author> <title> How to Construct Random Functions. </title> <booktitle> In Proc. of the 25th Annual Symposium on Foundations of Computer Science, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1984. </year>
Reference-contexts: Finally, we point out the results of <ref> [11] </ref>, indicating that, assuming the existence of certain types of cryptographic functions, there are families of easy to compute functions which must appear totally random in a very strong sense to any polynomial time learning algorithm. 6 Extensions and Restrictions In addition to the basic learnability model, there are several realistic
Reference: [12] <author> E. M. Gold. </author> <title> Language Identification in the Limit. </title> <journal> Inf. Contr. </journal> <volume> 10, </volume> <pages> 447-474, </pages> <year> 1967. </year>
Reference-contexts: We motivate these properties by briefly discussing some previous definitions of learning. A main problem for defining learning from a never-ending stream of examples is that at any point in the learning process, the very next datum may contradict the current hypothesis. Gold <ref> [12] </ref> (in the context of learning of formal languages) effectively dealt with this issue by introducing the notion of convergence in the limit to a correct rule for the data.
Reference: [13] <author> D. Haussler. </author> <title> Quantifying the Inductive Bias in Concept Learning. </title> <type> Tech. </type> <institution> Rept. UCSC-CRL-86-25, UC Santa Cruz, </institution> <year> 1986. </year>
Reference-contexts: For the purposes of this paper, we assume that the attributes are boolean (0-1) valued, although many of the results have extensions in the case of certain types of multi-valued attributes <ref> [13] </ref>. Each object in our world W consists of a vector ~v of length n, the i th position of the vector being either "1" or "0", indicating that the i th attribute is (respectively is not) present. <p> In [15] it is shown that 7 there is no algorithm for monomials requiring only negative examples. Such an impossibility result, however, does not preclude the usefulness of negative examples in learning monomials. In fact, it is shown in <ref> [13] </ref> that if a short monomial is to be learned, the number of examples required if both positive and negative examples are available is only logarithmic in n, the number of attributes. <p> Theorem 11 ([23]) For each k 1, kCNF is learnable from positive examples only. By duality, we also have that kDNF is learnable from negative examples alone. However, as in the case of monomials, it is shown in <ref> [13] </ref> that there is an algorithm using both types of examples that requires fewer examples than algorithms using only one type, if the formula being learned is small compared to the number of attributes. <p> Clearly, an important line of research in the learnability model is the investigation of other types of representations for concepts. As a start in this direction, various representations of continuous concepts have been studied <ref> [6, 13] </ref>, as well as representations of languages using finite automata [3]. Also, it has been observed that relations, in the sense of predicate calculus, can be added to the propositional case in certain very restricted ways while maintaining learnability [24]. <p> Also, it has been observed that relations, in the sense of predicate calculus, can be added to the propositional case in certain very restricted ways while maintaining learnability [24]. The representation issue, more generally, has been addressed also in the context of "bias" <ref> [13, 22] </ref>. The results cited all serve to identify the limits of polynomial time learnability on universal computers. It is interesting also to ask where the limits lie if we restrict the model of computation, for example, to neural networks.
Reference: [14] <author> D. Haussler. </author> <title> Space Efficient Learning Algorithms. </title> <type> Unpublished manuscript, </type> <year> 1986. </year>
Reference-contexts: Learning in a Shallow Hypothesis Space The following method allows us to prove that certain types of algorithms learn as required by definition 1 without having to resort to detailed probabilistic arguments for each new case. Theorem 8 follows from a combination of ideas from <ref> [5, 14, 18] </ref>. It is easy to show that to be (1 ffi) confident that a given hypothesis is (1 *) accurate, it suffices to test it against 1 * ln 1 ffi randomly generated examples. <p> This method essentially tells us when it is safe to keep a particular hypoth esis while guaranteeing that the conditions of learnability have been met. This technique was first used in [3, 5]. Following <ref> [14] </ref>, define a learning algorithm to be conservative iff it discards the current hypothesis if and only if the hypothesis incorrectly classifies the next datum. acyclic iff the algorithm never conjectures any hypothesis more than once. poly-failure-bounded iff the algorithm never makes more than a polynomial number of incorrect hypotheses.
Reference: [15] <author> M. Kearns, M. Li, L. Pitt, and L. G. Valiant. </author> <title> On the Learnability of Boolean Formulae. </title> <booktitle> In Proc. of the 19 th Annual ACM STOC, </booktitle> <year> 1987. </year>
Reference-contexts: As mentioned above, algorithm L outputs a hypothesis that is accurate over both D + and D , but needs only positive examples to construct this hypothesis. In <ref> [15] </ref> it is shown that 7 there is no algorithm for monomials requiring only negative examples. Such an impossibility result, however, does not preclude the usefulness of negative examples in learning monomials. <p> For classes where learnability is either an unresolved problem or known to be intractable, it is reasonable to try to find learning algorithms that work for specific natural probability distributions on the examples. In <ref> [15] </ref> an algorithm is given for DNF and k-term-DNF when both D + and D are uniform. This contrasts with the fact that learning k-term-DNF is NP-hard [15]. <p> In <ref> [15] </ref> an algorithm is given for DNF and k-term-DNF when both D + and D are uniform. This contrasts with the fact that learning k-term-DNF is NP-hard [15]. It is also shown that monotone DNF is learnable, when both distributions are uniform, in the more general model of group learning, which appears to be of independent 15 interest.
Reference: [16] <institution> Michalski </institution>
Reference-contexts: The relevance of the class DNF was discussed in [24], and this class has been used in many systems as a natural representation for concepts <ref> [16] </ref>. A major goal of some of this research has been to determine whether this particular class is learnable. We indicate the implications of a number of results with respect to this tantalizing open problem in the following sections.
Reference: [17] <author> L. Pitt and L.G. Valiant. </author> <title> Computational Limitations on Learning From Examples. </title> <type> Tech. </type> <institution> Rept. TR-05-86, Harvard University, </institution> <year> 1986, </year> <note> submitted for publication. </note>
Reference-contexts: However, not all DNF formulae can be expressed with a polynomial number of bits. On the other hand, every k-term-DNF formula can be expressed with a polynomial number of bits, but there is no polynomial recognition algorithm unless P = NP <ref> [17] </ref>. In either of these cases, the approach suggested in [6, 7] is that of an "Occam algorithm", which for the boolean domain is easier to describe in terms of data compression: Theorem 7 ([7]) Let ff &lt; 1, and c 1. <p> In <ref> [17] </ref>, the notion of h (n)-heuristic learnability was formalized so that a class is h (n)-heuristically learnable iff a learning algorithm can produce a hypothesis which correctly classifies at least the fraction h (n) of the positive examples, while correctly classifying 1 * of the negative examples. Theorem 20 ([17]) For
Reference: [18] <author> L. Pitt. </author> <title> Unpublished course notes for Formal Models of Machine Inference, </title> <institution> taught at University of Illinois. </institution>
Reference-contexts: Learning in a Shallow Hypothesis Space The following method allows us to prove that certain types of algorithms learn as required by definition 1 without having to resort to detailed probabilistic arguments for each new case. Theorem 8 follows from a combination of ideas from <ref> [5, 14, 18] </ref>. It is easy to show that to be (1 ffi) confident that a given hypothesis is (1 *) accurate, it suffices to test it against 1 * ln 1 ffi randomly generated examples.
Reference: [19] <author> R. Rivest. </author> <title> Learning Decision-Lists. </title> <type> Unpublished manuscript, </type> <month> December, </month> <year> 1986. </year>
Reference: [20] <author> T. Shinohara. </author> <title> Polynomial Time Inference of Extended Pattern Languages. </title> <booktitle> In Proceedings, Software Sci. and Engineering, </booktitle> <address> Kyoto, Japan, </address> <year> 1982. </year>
Reference-contexts: There are far fewer results if we insist that the convergence occur within a feasible amount of time, i.e. that the learning algorithm find a correct rule within time polynomial in the size of the examples seen and of the rule to be learned. The work of <ref> [1, 2, 8, 20, 21] </ref> stand as notable exceptions to a number of NP-completeness results which point out that this type of "exact" learning is too difficult to achieve in polynomial time when the rule may be any one of a large (exponential) class of possible rules.
Reference: [21] <author> T. Shinohara. </author> <title> Polynomial Time Inference of Pattern Languages and its Application. </title> <booktitle> In Proc. of the 7th IBM Symposium on Math. Foundations of Comp. Sci., </booktitle> <year> 1982 </year>
Reference-contexts: There are far fewer results if we insist that the convergence occur within a feasible amount of time, i.e. that the learning algorithm find a correct rule within time polynomial in the size of the examples seen and of the rule to be learned. The work of <ref> [1, 2, 8, 20, 21] </ref> stand as notable exceptions to a number of NP-completeness results which point out that this type of "exact" learning is too difficult to achieve in polynomial time when the rule may be any one of a large (exponential) class of possible rules.
Reference: [22] <author> P. E. Utgoff and T. M. Mitchell. </author> <title> Acquisition of Appropriate Bias for Inductive Concept Learning. </title> <booktitle> In Proc. of AAAI-82, </booktitle> <address> Pittsburgh, PA, </address> <year> 1982. </year>
Reference-contexts: Also, it has been observed that relations, in the sense of predicate calculus, can be added to the propositional case in certain very restricted ways while maintaining learnability [24]. The representation issue, more generally, has been addressed also in the context of "bias" <ref> [13, 22] </ref>. The results cited all serve to identify the limits of polynomial time learnability on universal computers. It is interesting also to ask where the limits lie if we restrict the model of computation, for example, to neural networks.
Reference: [23] <author> L. G. Valiant. </author> <title> A Theory of the Learnable. </title> <journal> Comm. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: Another explanation is that the domains of investigation (e.g. the inductive inference of classes of recursive functions) have been significantly removed from the types of domains typically of interest, and few results can be transferred. Recently, in <ref> [23] </ref>, a new formal definition of concept learning from examples was introduced, which we will refer to as the "learnability model." In this paper we summarize subsequent work by the authors and others in this new area of induction. <p> Thus the formula found by the algorithm cannot be exponentially larger than the unknown formula, and the amount of time required for increased accuracy or confidence should not be exponential. We refer the reader to <ref> [6, 23, 24, 25] </ref> for further discussion and justification of this model. If there is an algorithm L as above which never asks for any negative (respectively positive) examples, then we'll say that A is learnable from positive (negative) examples only. <p> An extensive study of various oracles for concept learning can be found in [5]; see also <ref> [3, 23] </ref>. In the context of algorithms that learn in polynomial time, there is the related issue whether the algorithms can be made to converge even faster by a carefully chosen set of examples [26].
Reference: [24] <author> L. G. Valiant. </author> <title> Learning Disjunctions of Conjunctions. </title> <booktitle> In Proceedings of the 9 th IJCAI, </booktitle> <volume> vol. 1, </volume> <pages> pp 560-566, </pages> <address> Los Angeles, CA. </address> <month> August, </month> <year> 1985. </year>
Reference-contexts: Thus the formula found by the algorithm cannot be exponentially larger than the unknown formula, and the amount of time required for increased accuracy or confidence should not be exponential. We refer the reader to <ref> [6, 23, 24, 25] </ref> for further discussion and justification of this model. If there is an algorithm L as above which never asks for any negative (respectively positive) examples, then we'll say that A is learnable from positive (negative) examples only. <p> We also view as an operator applied to classes of formulae to get corresponding classes where each variable appears at most once; for example, DNF is the class of DNF formulae with at most one occurrence of each variable. The relevance of the class DNF was discussed in <ref> [24] </ref>, and this class has been used in many systems as a natural representation for concepts [16]. A major goal of some of this research has been to determine whether this particular class is learnable. <p> In [4] it is shown that kDNF can be learned in this model even with rather high error rates. In the malicious model, where there is some probability of an error about which we can make no assumptions (e.g., it may be chosen by our adversary), <ref> [24] </ref> gives an algorithm for kDNF tolerating a lower rate of error. For classes where learnability is either an unresolved problem or known to be intractable, it is reasonable to try to find learning algorithms that work for specific natural probability distributions on the examples. <p> Also, it has been observed that relations, in the sense of predicate calculus, can be added to the propositional case in certain very restricted ways while maintaining learnability <ref> [24] </ref>. The representation issue, more generally, has been addressed also in the context of "bias" [13, 22]. The results cited all serve to identify the limits of polynomial time learnability on universal computers. <p> The results cited all serve to identify the limits of polynomial time learnability on universal computers. It is interesting also to ask where the limits lie if we restrict the model of computation, for example, to neural networks. In <ref> [24] </ref> some results are given about the learning capabilities of networks of threshold elements. Acknowledgements This research was supported by grants NSF-DCR-8600379 and ONR-N00014-85-K-0445. The third author was also supported by the Computer Science Department, University of Illinois at Urbana-Champaign, and the fourth author by a Guggenheim Fellowship.
Reference: [25] <author> L. G. Valiant. </author> <title> Deductive Learning. </title> <journal> Phil. Trans. R. Soc. Lond. </journal> <volume> A 312, </volume> <pages> 441-446, </pages> <year> 1984. </year>
Reference-contexts: Thus the formula found by the algorithm cannot be exponentially larger than the unknown formula, and the amount of time required for increased accuracy or confidence should not be exponential. We refer the reader to <ref> [6, 23, 24, 25] </ref> for further discussion and justification of this model. If there is an algorithm L as above which never asks for any negative (respectively positive) examples, then we'll say that A is learnable from positive (negative) examples only.
Reference: [26] <author> P. H. Winston. </author> <title> Learning Structural Descriptions from Examples. </title> <booktitle> PhD thesis, in The Psychology of Computer Vision, </booktitle> <publisher> McGraw-Hill, </publisher> <address> NY, </address> <year> 1975. </year> <month> 17 </month>
Reference-contexts: In the context of algorithms that learn in polynomial time, there is the related issue whether the algorithms can be made to converge even faster by a carefully chosen set of examples <ref> [26] </ref>. The learnability model as presented assumes a perfect source of examples drawn from the unknown distributions, and in some practical situations, this assumption may be too strong. Thus, we are led to consider the case where there is some probability of error in the source.
References-found: 26

