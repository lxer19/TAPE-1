URL: http://www.cs.washington.edu/research/projects/lis/oetools/www/papers/burns-ucsc.ps
Refering-URL: http://www.cs.washington.edu/homes/burns/professional/pubs.html
Root-URL: 
Email: fsteveb,alaing@vlsi.cs.caltech.edu  
Title: Performance Analysis and Optimi- zation of Asynchronous Circuits 1  
Author: Steven M. Burns and Alain J. Martin 
Address: Pasadena, CA 91125 USA  
Affiliation: Computer Science Department California Institute of Technology  
Abstract: We present a method for analyzing the time performance of asynchronous circuits, in particular, those derived by program transformation from concurrent programs using the synthesis approach developed by the second author. The analysis method produces a performance metric (related to the time needed to perform an operation) in terms of the primitive gate delays of the circuit. Such a metric provides a quantitative means by which to compare competing designs. Because the gate delays are functions of transistor sizes, the performance metric can be optimized with respect to these sizes. For a large class of asynchronous circuits|including those produced by using our synthesis method|these techniques produce the global optimum of the performance metric. A CAD tool has been implemented to perform this optimization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Steven M. Burns. </author> <title> Performance Analysis and Optimization of Asynchronous Circuits. </title> <type> Ph.D. thesis, </type> <institution> California Institute of Technology, </institution> <year> 1991. </year> <month> CS-TR-91-1. </month>
Reference-contexts: The smallest timing function denotes the earliest time at which the events of E can execute, and thus corresponds to the observed execution times of real circuits. Any feasible ER system with a constraint graph containing cycles can be transformed into an equivalent acyclic system <ref> [1] </ref>. 3 Lemma 2.1 If the constraint graph G of an event-rule system hE; Ri is acyclic, then there exists a unique function ^ t 2 T such that for every t 2 T , ^ t (e) t (e) for every e 2 E: (2) We call ^ t the <p> We propose the following recursive definition for ^ t: ^ t (f ) = 0 if sources (f ) = ; maxf ^ t (e) + ff j e ff 7! f 2 Rg otherwise: (3) We can show, by contradiction, that ^ t is the smallest timing function. (See <ref> [1] </ref> for a complete proof.) Example 2.2 The ER system defined by the constraint graph: e ? y ff eb ff ab ! b ff cd ! d has the timing simulation: ^ t (a) = 0 ^ t (b) = max (ff ab ; ff eb ) ^ t (d) <p> Then, if y 0 is such that y T A 0 = 0 T , there exist scalars i 0, 0 i &lt; q such that y = 0 U 0 + 1 U 1 + : : : + q1 U q1 : (12) Proof: See <ref> [1] </ref> for complete proof. The proof uses induction on the number of simple cycles in the graph of A 0 . This lemma provides a straightforward means of determining the minimum cycle period p. <p> one that is too long, the algorithm uses binary search and a procedure to test|for a particular candidate cycle period|whether there is a negative cycle in the graph in order to determine the minimum cycle period in log B steps. (B is related to desired precision of the result.) In <ref> [1] </ref>, we provide an O (jN j jAj) algorithm to determine the minimum cycle period when the sum of the " values around each simple cycle is bounded. <p> While it is possible to extend repetitive ER systems to allow the analysis of 9 an unbounded linear array of identical processes <ref> [1] </ref>, we instead perform the analysis directly on small arrays. We leave it as an exercise to the reader to show that, in these two cases, instantiating additional processes in the array does not increase the cycle period. <p> Three stages of a four-phase lazy-active/passive (lap) FIFO (Example 2.4) with the datapath between the stages are shown in Figure 1. For a circuit level implementation of a lap stage, see <ref> [1] </ref> or [10]. The three critical cycles through the transitions of the middle process are represented by bold arcs in the collapsed-constraint graphs (Figure 2). <p> The bold arcs in the graph represent the critical cycle. Assuming all delays in the circuit are small compared to the datapath delay, we get that p = 2ff D . A more complete analysis is provided in <ref> [1] </ref> which compares several other designs for FIFOs. This example shows that the best existing two-phase and four-phase implementations of a FIFO have comparable cycle periods. <p> Example 3.2 The optimal value for the cycle period of Example 3.1 occurs when the width values are a positive scalar multiple of (w 0 ; w 1 ; w 2 ; w 3 ; w 4 ) = (1:0; 0:4782; 1:1632; 1:8002; 0:9209) : (See <ref> [1] </ref> for an explanation of how to achieve a unique minimum point by constraining the power consumption and/or the largest and smallest transistor width.) We have implemented a CAD tool for solving the resulting non-linear, non-differentiable, convex optimization problems based on the subgradient techniques described by Shor [15]. <p> With the addition of these techniques, we have a complete method combining synthesis and performance analysis. The performance analysis can be done early and at each level of the synthe sis procedure and can be used to guide the synthesis of efficient circuits. A complete description is given in <ref> [1] </ref>. Acknowledgments We wish to thank Nan Boden, Pieter Hazewindus, Marcel Van der Goot, Drazen Borkovic, Tony Lee, Jose Tierno, Mass Sivilotti, and Dian De Sha for their comments on this manuscript.
Reference: [2] <author> Steven M. Burns and Alain J. Martin. </author> <title> Syntax-directed translation of concurrent programs into self-timed circuits. </title> <editor> In J. Allen and F. Leighton, editors, </editor> <booktitle> Advanced Research in VLSI, Proceedings of the Fifth MIT Conference, </booktitle> <pages> pages 35-50. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: At each stage of the synthesis procedure, a variety of transformations can potentially be applied. In the automated compiler of <ref> [2] </ref>, these choices are made so that the same subcircuit template can be used to implement each instance of the same CSP language construct. Instances of these small templates are composed together to form a correct circuit that implements the original CSP program.
Reference: [3] <author> J.P. Fishburn and A.E. Dunlop. TILOS: </author> <title> A posynomial programming approach to transistor sizing. </title> <booktitle> In IEEE ICCAD, </booktitle> <pages> pages 326-328, </pages> <month> Novem-ber </month> <year> 1985. </year>
Reference-contexts: At the circuit level, the component delays are functions of transistor widths and, as such, the cycle period can be optimized with respect to these widths. Non-linear optimization methods (such as those used in TILOS <ref> [3] </ref> and COP [7]) can 2 be used to perform the optimization of this expression for the cycle period.
Reference: [4] <author> Joel Franklin. </author> <title> Methods of Mathematical Economics. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1980. </year>
Reference-contexts: The techniques of linear programming <ref> [4] </ref> can be used to find such a minimum-period linear timing function. 6 The constraints of a linear timing function, (8), are simple linear inequal- ities in the x v 's and p. <p> w 3 + 1 ff yu = 1 3.2 Convex Objective Function Every ff derived using this simple model (and also other more accurate ones) is a posynomial function (polynomial with positive coefficients and positive variables) of the transistor widths w's, and thus a convex function of the log w's <ref> [4] </ref>. Because both the sum and the maximum of two convex functions are convex functions, the resulting expression for p is a convex function of the log w's; and, thus, each minimum of p is global.
Reference: [5] <author> Eugene L. Lawler. </author> <title> Combinatorial Optimization: Networks and Ma-troids. </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: Lawler in <ref> [5] </ref> provides an O (jN j jAj log B) solution to the minimal cost-to-time ratio cycle problem, which is equivalent to (13).
Reference: [6] <author> Jan Magott. </author> <title> Performance evaluation of concurrent systems using Petri nets. </title> <journal> Information Processing Letters, </journal> <volume> 18 </volume> <pages> 7-13, </pages> <year> 1984. </year>
Reference-contexts: This paper discusses a framework for determining the time needed to perform computations using asynchronous systems, and applies especially to repetitive computations. Early work in the scheduling of concurrent computing elements [14] is closely related to our approach. Previous work in the area of timed Petri nets <ref> [13, 6] </ref> applies to this problem as well. The results we describe here are based on event-rule systems, a different formalism that is more closely connected to the methods we use to synthesize the asynchronous systems.
Reference: [7] <author> David P. Marple and Abbas El Gamal. </author> <title> Optimal selection of transistor sizes in digital VLSI circuits. </title> <editor> In Paul Losleben, editor, </editor> <booktitle> Advanced Research in VLSI, Proceedings of the 1987 Stanford Conference, </booktitle> <pages> pages 151-172. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: At the circuit level, the component delays are functions of transistor widths and, as such, the cycle period can be optimized with respect to these widths. Non-linear optimization methods (such as those used in TILOS [3] and COP <ref> [7] </ref>) can 2 be used to perform the optimization of this expression for the cycle period.
Reference: [8] <author> A.J. Martin, S.M. Burns, T.K. Lee, D. Borkovic, and P.J. Hazewindus. </author> <title> The design of an asynchronous microprocessor. </title> <editor> In C.L. Seitz, editor, </editor> <booktitle> Advanced Research in VLSI: Proceedings of the Decennial Caltech Conference on VLSI, </booktitle> <pages> pages 351-373, </pages> <address> Cambridge, MA, 1989. </address> <publisher> MIT Press. </publisher>
Reference-contexts: However, in order to produce high-performance circuits, these choices must be directed by performance concerns. We observed this potential benefit of performance-directed transformations during the design of the Caltech Asynchronous Microprocessor <ref> [8] </ref>. The decisions of what transformation to apply were based on performance goals and this accounts for its high performance. Event-rule (ER) systems can be used at each stage of the synthesis procedure to analyze the potential performance of the current refinement.
Reference: [9] <author> Alain J. Martin. </author> <title> Programming in VLSI: From communicating processes to delay-insensitive circuits. In C.A.R. Hoare, editor, </title> <booktitle> UT Year of Programming Institute on Concurrent Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference: [10] <author> Alain J. Martin. </author> <title> Synthesis of asynchronous VLSI circuits. </title> <editor> In J. Staunstrup, editor, </editor> <title> Formal Methods for VLSI Design. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: Three stages of a four-phase lazy-active/passive (lap) FIFO (Example 2.4) with the datapath between the stages are shown in Figure 1. For a circuit level implementation of a lap stage, see [1] or <ref> [10] </ref>. The three critical cycles through the transitions of the middle process are represented by bold arcs in the collapsed-constraint graphs (Figure 2).
Reference: [11] <author> J.K. Ousterhout. </author> <title> A switch-level timing verifier for digital MOS VLSI. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <volume> 4(3), </volume> <month> July </month> <year> 1985. </year>
Reference-contexts: No clear separation 1 to appear in the Advanced Research in VLSI Conference, Santa Cruz, CA, March 1991 1 is available in asynchronous systems. Analysis procedures must deal directly with cyclic critical paths; thus, existing critical-path analysis tools such as CRYSTAL <ref> [11] </ref> cannot be easily applied to this problem. This paper discusses a framework for determining the time needed to perform computations using asynchronous systems, and applies especially to repetitive computations. Early work in the scheduling of concurrent computing elements [14] is closely related to our approach.
Reference: [12] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year> <month> 16 </month>
Reference-contexts: This algorithm is based on a direct solution to the linear program (11) and its corresponding dual and uses a customization of the general primal-dual algorithm <ref> [12] </ref>. 2.6 Case Study: Comparison of Two FIFOs We now apply the performance analysis techniques of Section 2 to compare the performance of two implementations of a first-in/first-out (FIFO) queue.
Reference: [13] <author> C.V. Ramamoorthy and Gary S. Ho. </author> <title> Performance evaluation of asyn-chronous concurrent systems using Petri nets. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 6(5) </volume> <pages> 440-449, </pages> <month> September </month> <year> 1980. </year>
Reference-contexts: This paper discusses a framework for determining the time needed to perform computations using asynchronous systems, and applies especially to repetitive computations. Early work in the scheduling of concurrent computing elements [14] is closely related to our approach. Previous work in the area of timed Petri nets <ref> [13, 6] </ref> applies to this problem as well. The results we describe here are based on event-rule systems, a different formalism that is more closely connected to the methods we use to synthesize the asynchronous systems.
Reference: [14] <author> Raymond Reiter. </author> <title> Scheduling parallel computations. </title> <journal> Journal of the ACM, </journal> <volume> 15(4) </volume> <pages> 590-599, </pages> <month> October </month> <year> 1968. </year>
Reference-contexts: This paper discusses a framework for determining the time needed to perform computations using asynchronous systems, and applies especially to repetitive computations. Early work in the scheduling of concurrent computing elements <ref> [14] </ref> is closely related to our approach. Previous work in the area of timed Petri nets [13, 6] applies to this problem as well.
Reference: [15] <author> N.Z. Shor. </author> <title> Minimization Methods for Non-Differentiable Functions. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year> <note> Translated from Russian. </note>
Reference-contexts: 0:9209) : (See [1] for an explanation of how to achieve a unique minimum point by constraining the power consumption and/or the largest and smallest transistor width.) We have implemented a CAD tool for solving the resulting non-linear, non-differentiable, convex optimization problems based on the subgradient techniques described by Shor <ref> [15] </ref>. Table 1 lists the results of this program when applied to a variety of circuits. The column n trans denotes the number of transistors in the circuit, and thus the number of free variables in the optimization problem.
Reference: [16] <author> Ivan E. Sutherland. </author> <title> Micropipelines. </title> <journal> Communications of the ACM, </journal> <volume> 32(6) </volume> <pages> 720-738, </pages> <year> 1989. </year>
References-found: 16

