URL: http://www-sal.cs.uiuc.edu/~harrison/pubs/research/iccl98.ps.Z
Refering-URL: http://www-sal.cs.uiuc.edu/~harrison/pubs/research/research.html
Root-URL: http://www.cs.uiuc.edu
Email: fharrison,kaming@cs.uiuc.edu  
Title: Modular Compilers Based on Monad Transformers  
Author: William L. Harrison Samuel N. Kamin 
Address: Urbana, Illinois 61801-2987  
Affiliation: Department of Computer Science University of Illinois, Urbana-Champaign  
Abstract: The monadic style of language specification has the advantages of modularity and extensibility: it is simple to add or change features in an interpreter to reflect modifications in the source language. It has proven difficult to extend the method to compilation. We demonstrate that by introducing machine-like stores (code and data) into the monadic semantics and then partially evaluating the resulting semantic expressions, we can achieve many of the same advantages for a compiler as for an interpreter. A number of language constructs and features are compiled: expressions, CBV and CBN evaluation of -expressions, dynamic scop-ing, and various imperative features. The treatment of recursive procedures is outlined as well. The resulting method allows compilers to be constructed in a mix-and-match fashion just as in a monad-structured interpreter. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, R. Sethi, and J. D. </author> <title> Ullman Compilers: Principles, Techniques, and Tools, </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: ]] = rdEnv bind :inEnv [ 7! f ix (:[[c]])] [[c 0 ]] C [[letrec c : comm in c 0 ]] = rdEnv bind : currentFrame bind f:newlabel bind L c : C [[c]] bind : newSegment (L c ; inEnv [ 7! mkCall L c f ] (return <ref> [f + 1; 1] </ref>)) bind :(inEnv [ 7! mkCall L c f ] C [[c 0 ]]) mkCall L c f = newlabel bind L :unit: newSegment (L ; ) bind : updateSto ([f + 1; 1] 7! L ) bind :call L c rdSeg L = rdCode bind :l call <p> L c rdSeg L = rdCode bind :l call L c = rdSeg L c return [f; e] = rdloc [f; e] bind L :rdSegL currentFrame = updateA (a:a) bind &lt;f; d&gt;:unitf recursive bindings of type comm pairs &lt;f rame; disp&gt;, which may be thought of as a display address <ref> [1] </ref>, or alternatively, as a stack shape [17]. Intuitively, f rame points to an activation record and disp is an offset within that record. Following Reynolds [17], we assume each activation record has a call block where the labels of argument parameters are stored.
Reference: [2] <author> A. Appel, </author> <title> Modern Compiler Implementation in ML, </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1998. </year>
Reference-contexts: | Imp+Exp Id)))) Source Code: new g:intvar in let f = v: intvar: e: intexp: v := 1 + e ; v := (g + 1) + e in f g (g + 1) Target Code: 0 := 0; 2 := 1; 2 := [0]; 2 := [0]; 2 := <ref> [2] </ref> + [3]; 2 := [2] + [3]; 1 := [0]; halt; Espinosa [6] and Hudak, Liang, and Jones [12] use monad transformers to create modular, extensible interpreters. <p> new g:intvar in let f = v: intvar: e: intexp: v := 1 + e ; v := (g + 1) + e in f g (g + 1) Target Code: 0 := 0; 2 := 1; 2 := [0]; 2 := [0]; 2 := <ref> [2] </ref> + [3]; 2 := [2] + [3]; 1 := [0]; halt; Espinosa [6] and Hudak, Liang, and Jones [12] use monad transformers to create modular, extensible interpreters. This work shows how interpreters can be developed in a modular way, leaving open the question of whether compilers can be developed similarly. <p> For our compilation examples, we use the abstract machine language from Reynolds [17]. The details are 2 There is a considerable body of work using continuations to structure compilers <ref> [2, 17, 20] </ref>. <p> For boolean expressions, we use a dual completion "control-flow" semantics, reflecting common practice in compilers <ref> [2] </ref>.
Reference: [3] <author> Z. Benaissa, T. Sheard, and W. Taha, </author> <title> "Compilers as staged monadic interpreters," </title> <institution> Oregon Graduate Institute, </institution> <year> 1997. </year> <note> Submitted for publication. </note>
Reference-contexts: Id)))) Source Code: new g:intvar in let f = v: intvar: e: intexp: v := 1 + e ; v := (g + 1) + e in f g (g + 1) Target Code: 0 := 0; 2 := 1; 2 := [0]; 2 := [0]; 2 := [2] + <ref> [3] </ref>; 2 := [2] + [3]; 1 := [0]; halt; Espinosa [6] and Hudak, Liang, and Jones [12] use monad transformers to create modular, extensible interpreters. This work shows how interpreters can be developed in a modular way, leaving open the question of whether compilers can be developed similarly. <p> in let f = v: intvar: e: intexp: v := 1 + e ; v := (g + 1) + e in f g (g + 1) Target Code: 0 := 0; 2 := 1; 2 := [0]; 2 := [0]; 2 := [2] + <ref> [3] </ref>; 2 := [2] + [3]; 1 := [0]; halt; Espinosa [6] and Hudak, Liang, and Jones [12] use monad transformers to create modular, extensible interpreters. This work shows how interpreters can be developed in a modular way, leaving open the question of whether compilers can be developed similarly.
Reference: [4] <author> O. Danvy, </author> <title> "Type-Directed Partial Evaluation," </title> <booktitle> Proceedings of the ACM Conference on the Principles of Programming Languages, </booktitle> <year> 1996. </year>
Reference-contexts: The result of partial evaluation is as shown in Figure 8. This code generation technique is a monadic version of Danvy and Vestergaard's <ref> [4, 5] </ref>. 3 [a 7! v] : Sto ! Sto is the usual update function which changes the value of a store at a. n 2 N umeral c 2 Cmd ::= c 1 ;c 2 j Addr:=Exp j if Bool then c t 2 Exp ::= n b 2 Bool
Reference: [5] <author> O. Danvy and R. Vestergaard, </author> <title> "Semantics-Based Compiling: A Case Study in Type-Directed Partial Evaluation," </title> <booktitle> Eighth International Symposium on Programming Language Implementation and Logic Programming, </booktitle> <year> 1996, </year> <pages> pages 182-497. </pages>
Reference-contexts: It has been shown [6, 12] that modular interpreters may be constructed by applying the monad transformers associated with each feature in the language. Here, we extend that approach to compilers. To obtain compilers by partial evaluation of semantic definitions <ref> [5, 8, 10] </ref>, we must introduce data structures for pass separation [9]. This work demonstrates that, by exploiting the monadic structure of our language semantics, pass separation can be done in a modular way. <p> The resulting compiler translates a term into a monadic intermediate code. Our work differs from theirs in that our target language is more realistic (it includes jumps, labels, etc.), we compile considerably more language features, and modularity and extensibility are key features of our approach. Danvy and Vestergaard <ref> [5] </ref> show how to produce code that "looks like" machine language, by expressing the source language semantics in terms of machine language-like combinators (e.g., "popblock", "push"). <p> The result of partial evaluation is as shown in Figure 8. This code generation technique is a monadic version of Danvy and Vestergaard's <ref> [4, 5] </ref>. 3 [a 7! v] : Sto ! Sto is the usual update function which changes the value of a store at a. n 2 N umeral c 2 Cmd ::= c 1 ;c 2 j Addr:=Exp j if Bool then c t 2 Exp ::= n b 2 Bool
Reference: [6] <author> D. Espinosa, </author> <title> "Semantic Lego," </title> <type> Doctoral Dissertation, </type> <institution> Columbia University, </institution> <year> 1995. </year>
Reference-contexts: Modularity in our compilers comes from the fact that our language semantics is structured with monads [14, 19] and monad transformers <ref> [6, 12] </ref>. Mon-ads may be viewed as abstract data types whose operations may be used to give denotational definitions of programming languages. <p> Monad transformers create a new monad by extending an existing monad with addi tional operations, thereby allowing new programming language features to be defined while preserving any language definitions given for the original monad. It has been shown <ref> [6, 12] </ref> that modular interpreters may be constructed by applying the monad transformers associated with each feature in the language. Here, we extend that approach to compilers. To obtain compilers by partial evaluation of semantic definitions [5, 8, 10], we must introduce data structures for pass separation [9]. <p> e: intexp: v := 1 + e ; v := (g + 1) + e in f g (g + 1) Target Code: 0 := 0; 2 := 1; 2 := [0]; 2 := [0]; 2 := [2] + [3]; 2 := [2] + [3]; 1 := [0]; halt; Espinosa <ref> [6] </ref> and Hudak, Liang, and Jones [12] use monad transformers to create modular, extensible interpreters. This work shows how interpreters can be developed in a modular way, leaving open the question of whether compilers can be developed similarly. <p> In Section 4, our final example is the idealized Algol compiled by Reynolds in [17]. 2 Monads and Monad Transformers In this section, we review the theory of monads [14, 19] and monad transformers <ref> [6, 12] </ref>. Readers familiar with these topics may skip the section, except for the last paragraph. <p> Unfortunately, M St (M St t ) and M 2St t are very different types. This points to a difficulty with monads: they do not compose in this simple manner. The key contribution of the recent work <ref> [6, 12] </ref> on monad transformers is to solve this composition problem. When applied to a monad M, a monad transformer T creates a new monad M 0 . <p> Figure 19 contains the standard and compilation semantics for letrec and Figure 20 presents an example. 5 Conclusions and Further Work The main contribution of this work is the development a "mix-and-match" compilation method similar to the modular interpreter constructions of <ref> [6, 12, 19] </ref>. Using monads and monad transformers to structure semantics-directed compilers achieves much of the same flexibility and modularity that one associates with monadic interpreters. <p> Claims have been made <ref> [6, 11, 13] </ref> that proofs about monadic specifications retain some modularity as well, and a correctness proof of our method would be a good test of this. Another goal for future research is the compilation of language features such as exceptions and objects.
Reference: [7] <author> W. Harrison and S. Kamin, </author> <title> "Deriving Compilers from Monadic Semantics," </title> <note> Unpublished manuscript available at http://www-sal.cs.uiuc.edu/~harrison/pubs/proposal.ps.Z. </note>
Reference-contexts: For arithmetic expressions, we can give, following Reynolds, a more space-efficient compilation semantics than that presented in Figure 7, but space constraints prevent our describing it here. (Please refer to Harrison, et al. <ref> [7] </ref>).
Reference: [8] <author> N. D. Jones, C. K. Gomard, and P. Sestoft, </author> <title> Partial Evaluation and Automatic Program Generation, </title> <publisher> Prentice-Hall 1993. </publisher>
Reference-contexts: It has been shown [6, 12] that modular interpreters may be constructed by applying the monad transformers associated with each feature in the language. Here, we extend that approach to compilers. To obtain compilers by partial evaluation of semantic definitions <ref> [5, 8, 10] </ref>, we must introduce data structures for pass separation [9]. This work demonstrates that, by exploiting the monadic structure of our language semantics, pass separation can be done in a modular way. <p> They showed how compilers could be constructed by introducing intermediate data structures into an interpreter and then partially evaluating. Their interpreter had no monadic structure, so that each pass separation must be done by hand. Our work continues a long line of generating compilers from denotational semantics <ref> [8, 10, 20] </ref>. What primarily distinguishes our work is the use of monads and monad transformers to structure our semantics. Benaissa, et al.[3], transform an interpreter for the while language into a compiler using a sequence of explicit staging annotations.
Reference: [9] <author> U. Jorring and W. Scherlis, </author> <title> "Compilers and Staging Transformations," </title> <booktitle> Proceedings of the ACM Conference on the Principles of Programming Languages, </booktitle> <year> 1986. </year>
Reference-contexts: Here, we extend that approach to compilers. To obtain compilers by partial evaluation of semantic definitions [5, 8, 10], we must introduce data structures for pass separation <ref> [9] </ref>. This work demonstrates that, by exploiting the monadic structure of our language semantics, pass separation can be done in a modular way. Thus, language features can be combined easily, while retaining the ability to produce compiled code by partial evaluation. <p> He describes an experiment in [13] wherein the Glasgow Haskell compiler is retargeted to the SML/NJ back-end, and develops many examples of reasoning about monadic specifications. Since Liang does not compile to machine language, many of the issues we confront|especially pass separation|do not arise. Jorring and Scherlis <ref> [9] </ref> introduced the term "pass separation", which introduces intermediate data structure to pass values between two phases of computation, thus enabling separation of the two phases. They showed how compilers could be constructed by introducing intermediate data structures into an interpreter and then partially evaluating. <p> So, our first change to the standard semantics is to apply two state monad transformers adding addresses and value storage. Assuming that the standard semantics is written in terms of the monad M, we can add the intermediate data structure for pass separation <ref> [9] </ref> by applying T St twice: M c = T St Addr (T St Sto M) where Addr = int and Sto = Addr ! int. We will call the new combinators in M c : updateA, updateSto, rdAddr, rdSto.
Reference: [10] <author> P. Lee, </author> <title> Realistic Compiler Generation, </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: It has been shown [6, 12] that modular interpreters may be constructed by applying the monad transformers associated with each feature in the language. Here, we extend that approach to compilers. To obtain compilers by partial evaluation of semantic definitions <ref> [5, 8, 10] </ref>, we must introduce data structures for pass separation [9]. This work demonstrates that, by exploiting the monadic structure of our language semantics, pass separation can be done in a modular way. <p> They showed how compilers could be constructed by introducing intermediate data structures into an interpreter and then partially evaluating. Their interpreter had no monadic structure, so that each pass separation must be done by hand. Our work continues a long line of generating compilers from denotational semantics <ref> [8, 10, 20] </ref>. What primarily distinguishes our work is the use of monads and monad transformers to structure our semantics. Benaissa, et al.[3], transform an interpreter for the while language into a compiler using a sequence of explicit staging annotations. <p> The beauty of the monadic form is that the meaning of [[]] can be reinterpreted in a variety of monads. Monadic semantics separate the description of a language from its denotation. In this sense, it is similar to action semantics [15] and high-level semantics <ref> [10] </ref>. The simplest monad is the identity monad, shown in Figure 3. Given the identity monad, we can define add as ordinary addition. [[]] would have type Expression! int. <p> One of the advantages of the monadic approach is that the underlying denota-tional model can be made arbitrarily complex through application of monad transformers without complicating the denotational description unnecessarily. Because of this separability as Lee calls it <ref> [10] </ref>, monadic specifications are a natural setting for pass separation. The use of partial evaluation in the compiler clarifies the relationship between the compilation semantics and the machine language semantics.
Reference: [11] <author> S. Liang, </author> <title> "A Modular Semantics for Compiler Generation," </title> <institution> Yale University Department of Computer Science Technical Report TR-1067, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: This work shows how interpreters can be developed in a modular way, leaving open the question of whether compilers can be developed similarly. Liang <ref> [11, 13] </ref> addresses that question, proposing that monadic semantics constructed from monad transformers and monadic specifications provide a modular and extensible basis for semantics-directed compilation. <p> Claims have been made <ref> [6, 11, 13] </ref> that proofs about monadic specifications retain some modularity as well, and a correctness proof of our method would be a good test of this. Another goal for future research is the compilation of language features such as exceptions and objects.
Reference: [12] <author> S. Liang, P. Hudak, and M. Jones. </author> <title> Monad Transformers and Modular Interpreters. </title> <booktitle> Proceedings of the ACM Conference on the Principles of Programming Languages, </booktitle> <year> 1995. </year>
Reference-contexts: Modularity in our compilers comes from the fact that our language semantics is structured with monads [14, 19] and monad transformers <ref> [6, 12] </ref>. Mon-ads may be viewed as abstract data types whose operations may be used to give denotational definitions of programming languages. <p> Monad transformers create a new monad by extending an existing monad with addi tional operations, thereby allowing new programming language features to be defined while preserving any language definitions given for the original monad. It has been shown <ref> [6, 12] </ref> that modular interpreters may be constructed by applying the monad transformers associated with each feature in the language. Here, we extend that approach to compilers. To obtain compilers by partial evaluation of semantic definitions [5, 8, 10], we must introduce data structures for pass separation [9]. <p> e ; v := (g + 1) + e in f g (g + 1) Target Code: 0 := 0; 2 := 1; 2 := [0]; 2 := [0]; 2 := [2] + [3]; 2 := [2] + [3]; 1 := [0]; halt; Espinosa [6] and Hudak, Liang, and Jones <ref> [12] </ref> use monad transformers to create modular, extensible interpreters. This work shows how interpreters can be developed in a modular way, leaving open the question of whether compilers can be developed similarly. <p> In Section 4, our final example is the idealized Algol compiled by Reynolds in [17]. 2 Monads and Monad Transformers In this section, we review the theory of monads [14, 19] and monad transformers <ref> [6, 12] </ref>. Readers familiar with these topics may skip the section, except for the last paragraph. <p> Unfortunately, M St (M St t ) and M 2St t are very different types. This points to a difficulty with monads: they do not compose in this simple manner. The key contribution of the recent work <ref> [6, 12] </ref> on monad transformers is to solve this composition problem. When applied to a monad M, a monad transformer T creates a new monad M 0 . <p> However, it is quite simple to add address allocation and store using the state monad transformer <ref> [12, 19] </ref>. In the parlance of pass separation, the addresses and storage are intermediate data structures. So, our first change to the standard semantics is to apply two state monad transformers adding addresses and value storage. <p> We include abstractions for call-by-name (CBN) and call-by-value (CBV) functions. Semantically, this requires that environments be added to the underlying monad, and we accomplish this by applying the environment monad transformer T Env <ref> [12] </ref>. So, the monad for the compilation semantics has the form: M c = T Env Env (T St Addr (T St Sto M)). The Addr and Sto states are only necessary for CBV. For CBN procedures alone, M c = T Env Env M suffices. <p> Figure 19 contains the standard and compilation semantics for letrec and Figure 20 presents an example. 5 Conclusions and Further Work The main contribution of this work is the development a "mix-and-match" compilation method similar to the modular interpreter constructions of <ref> [6, 12, 19] </ref>. Using monads and monad transformers to structure semantics-directed compilers achieves much of the same flexibility and modularity that one associates with monadic interpreters.
Reference: [13] <author> S. Liang, </author> <title> "Modular Monadic Semantics and Compilation," </title> <type> Doctoral Thesis, </type> <institution> Yale University, </institution> <year> 1997. </year>
Reference-contexts: This work shows how interpreters can be developed in a modular way, leaving open the question of whether compilers can be developed similarly. Liang <ref> [11, 13] </ref> addresses that question, proposing that monadic semantics constructed from monad transformers and monadic specifications provide a modular and extensible basis for semantics-directed compilation. <p> Liang [11, 13] addresses that question, proposing that monadic semantics constructed from monad transformers and monadic specifications provide a modular and extensible basis for semantics-directed compilation. He describes an experiment in <ref> [13] </ref> wherein the Glasgow Haskell compiler is retargeted to the SML/NJ back-end, and develops many examples of reasoning about monadic specifications. Since Liang does not compile to machine language, many of the issues we confront|especially pass separation|do not arise. <p> Claims have been made <ref> [6, 11, 13] </ref> that proofs about monadic specifications retain some modularity as well, and a correctness proof of our method would be a good test of this. Another goal for future research is the compilation of language features such as exceptions and objects.
Reference: [14] <author> E. Moggi, </author> <title> "Notions of Computation and Mon-ads," </title> <booktitle> Information and Computation 93(1), </booktitle> <pages> pp. 55-92, </pages> <year> 1991. </year>
Reference-contexts: Compilers constructed in this manner are modular in that source language features may be added or deleted easily, allowing the compiler writer to develop compilers at a high level of abstraction. Modularity in our compilers comes from the fact that our language semantics is structured with monads <ref> [14, 19] </ref> and monad transformers [6, 12]. Mon-ads may be viewed as abstract data types whose operations may be used to give denotational definitions of programming languages. <p> In Section 4, our final example is the idealized Algol compiled by Reynolds in [17]. 2 Monads and Monad Transformers In this section, we review the theory of monads <ref> [14, 19] </ref> and monad transformers [6, 12]. Readers familiar with these topics may skip the section, except for the last paragraph.
Reference: [15] <author> P. Mosses, </author> <title> Action Semantics, </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: The beauty of the monadic form is that the meaning of [[]] can be reinterpreted in a variety of monads. Monadic semantics separate the description of a language from its denotation. In this sense, it is similar to action semantics <ref> [15] </ref> and high-level semantics [10]. The simplest monad is the identity monad, shown in Figure 3. Given the identity monad, we can define add as ordinary addition. [[]] would have type Expression! int.
Reference: [16] <author> J. Reynolds. </author> <title> "The Essence of Algol," </title> <booktitle> Algorithmic Languages, Proceedings of the International Symposium on Algorithmic Languages, </booktitle> <pages> pp. 345-372, </pages> <year> 1981. </year>
Reference-contexts: Its standard semantics is presented in Figure 18. A location S is allocated and the integer variable i is bound to an acceptor-expresser pair which writes and reads to and from S as in Reynolds <ref> [16] </ref>. deAlloc is used to deallocate S. The specification for assignment looks up the acceptor-expresser pair associated with i, and passes the appropriate continuation on to the integer expression e. The compilation semantics for new and assignment are identical to their standard semantics.
Reference: [17] <author> J. Reynolds, </author> <title> "Using Functor Categories to Generate Intermediate Code," </title> <booktitle> Proceedings of the ACM Conference on the Principles of Programming Languages, </booktitle> <pages> pages 25-36, </pages> <year> 1995. </year>
Reference-contexts: When the interpreter is closed over these combinators, partial evaluation of this closed term with respect to a program produces a completely dynamic term, composed of a sequence of combinators, looking very much like machine language. This approach is key to making the monadic structure useful for compilation. Reynolds' <ref> [17] </ref> demonstration of how to produce efficient code in a compiler derived from the functor category semantics of an Algol-like language was an original inspiration for this study. <p> We then define call-by-value and call-by-name procedures in Section 3.4, and dynamic binding in Section 3.5, as examples of the kinds of features that can be compiled in this modular fashion. In Section 4, our final example is the idealized Algol compiled by Reynolds in <ref> [17] </ref>. 2 Monads and Monad Transformers In this section, we review the theory of monads [14, 19] and monad transformers [6, 12]. Readers familiar with these topics may skip the section, except for the last paragraph. <p> In Figure 6, [[]] has type Exp ! [[intexp]]. Observe that the standard semantics uses only bind and unit, and so the standard semantics can be interpreted in any monad. For our compilation examples, we use the abstract machine language from Reynolds <ref> [17] </ref>. The details are 2 There is a considerable body of work using continuations to structure compilers [2, 17, 20]. <p> For our compilation examples, we use the abstract machine language from Reynolds [17]. The details are 2 There is a considerable body of work using continuations to structure compilers <ref> [2, 17, 20] </ref>. <p> The compilation semantics for if-then and or are shown in Figure 11; for all other features, the compilation and standard semantics are the same. The new equation for if-then is very similar to the informal 4 This is exactly what happens in Reynolds <ref> [17] </ref>. 0: jump 1; 1: 100 := 7; jump 2; 2: halt; 0: jump 1; 0 := [0]+[1]; 1: 0 := 1; 100 := -[0]; 1 := 2; jump 2; 0 := [0]+[1]; 2: halt; 1 := 3; code outline for the compilation of if-then above. <p> As in the first half of Reynolds <ref> [17] </ref>, this compilation semantics corresponds to treating -expressions as open procedures, that is, procedures that are expanded like macros. Observe that the CBN standard and compilation semantics are identical (as is the case in Reynolds [17]). <p> As in the first half of Reynolds <ref> [17] </ref>, this compilation semantics corresponds to treating -expressions as open procedures, that is, procedures that are expanded like macros. Observe that the CBN standard and compilation semantics are identical (as is the case in Reynolds [17]). The standard and compilation semantics for CBV -calculus are identical at higher type, but for arguments of type intexp, the value of the expression argument is stored in a temporary location a. An example compilation is presented in Figure 15. <p> The case of dynamic binding, when the body of f is evaluated, the most recent binding of s (i.e., 5) is stored in 1, rather than the value of s when f was defined (i.e., 10). 4 Compilation of Idealized Algol the language compiled by Reynolds in <ref> [17] </ref>, and the compiler we derive is essentially identical to that in [17] for the non-recursive fragment. <p> f is evaluated, the most recent binding of s (i.e., 5) is stored in 1, rather than the value of s when f was defined (i.e., 10). 4 Compilation of Idealized Algol the language compiled by Reynolds in <ref> [17] </ref>, and the compiler we derive is essentially identical to that in [17] for the non-recursive fragment. With the exception of the new operator, and the inclusion of integer variables, we have considered the compilation of each of these constructs in Section 3, and their compilation is treated identically for the imperative, -calculus, and boolean parts of the language. <p> :l call L c = rdSeg L c return [f; e] = rdloc [f; e] bind L :rdSegL currentFrame = updateA (a:a) bind &lt;f; d&gt;:unitf recursive bindings of type comm pairs &lt;f rame; disp&gt;, which may be thought of as a display address [1], or alternatively, as a stack shape <ref> [17] </ref>. Intuitively, f rame points to an activation record and disp is an offset within that record. Following Reynolds [17], we assume each activation record has a call block where the labels of argument parameters are stored. <p> = updateA (a:a) bind &lt;f; d&gt;:unitf recursive bindings of type comm pairs &lt;f rame; disp&gt;, which may be thought of as a display address [1], or alternatively, as a stack shape <ref> [17] </ref>. Intuitively, f rame points to an activation record and disp is an offset within that record. Following Reynolds [17], we assume each activation record has a call block where the labels of argument parameters are stored. Call block entries are denoted [frame; e] which points to the e-th argument in the activation pointed to by f rame. We replace the store Sto with an (unspecified) stack type Stack.
Reference: [18] <author> J. E. Stoy, </author> <title> Denotational Semantics: the Scott-Strachey Approach to Programming Language Theory, </title> <publisher> MIT Press, </publisher> <year> 1977. </year>
Reference-contexts: 1 ]] bind e 1 :[[t 2 ]] bind e 2 : unit fi:(e 1 (v 1 :e 2 (v 2 :fi (v 1 + v 2 )))) a monadic version of the usual continuation semantics 2 for the language as it might appear in a standard textbook like Stoy <ref> [18] </ref>. For example in a continuation semantics for expressions with no variables, the meaning of a constant is: [[n]] fi = fi n where [[n]] : (int ! Ans) ! Ans. <p> Its syntax is given in Figure 5 and its standard semantics is given in Figure 6. This is a monadic version of the usual continuation-based specification of arithmetic expressions <ref> [18] </ref>. In Figure 6, [[]] has type Exp ! [[intexp]]. Observe that the standard semantics uses only bind and unit, and so the standard semantics can be interpreted in any monad. For our compilation examples, we use the abstract machine language from Reynolds [17]. <p> Of course, an actual compiler would emit code once and then emit appropriate jumps. Here, a technique from denotational semantics <ref> [18] </ref> is applicable: when a command jumps to a label, it invokes the continuation stored at that label. We make this continuation store explicit, just as we made the value store explicit to compile the expression language. <p> The idea is that the continuation store contains segments of code that are not inherently connected, so that every segment is either the completion of the entire computation or ends by invoking another segment. (Again, this is a characteristic of continuation stores as used in Stoy <ref> [18] </ref>.) The most difficult part of the compilation semantics for CF is the definitions of the auxiliary operations. Define the static context to be the data structures added for pass separation, in this case the label and code store.
Reference: [19] <author> P. Wadler, </author> <title> "The essence of functional programming," </title> <booktitle> Proceedings of the ACM Conference on the Principles of Programming Languages, </booktitle> <pages> pages 1-14, </pages> <year> 1992. </year>
Reference-contexts: Compilers constructed in this manner are modular in that source language features may be added or deleted easily, allowing the compiler writer to develop compilers at a high level of abstraction. Modularity in our compilers comes from the fact that our language semantics is structured with monads <ref> [14, 19] </ref> and monad transformers [6, 12]. Mon-ads may be viewed as abstract data types whose operations may be used to give denotational definitions of programming languages. <p> In Section 4, our final example is the idealized Algol compiled by Reynolds in [17]. 2 Monads and Monad Transformers In this section, we review the theory of monads <ref> [14, 19] </ref> and monad transformers [6, 12]. Readers familiar with these topics may skip the section, except for the last paragraph. <p> However, it is quite simple to add address allocation and store using the state monad transformer <ref> [12, 19] </ref>. In the parlance of pass separation, the addresses and storage are intermediate data structures. So, our first change to the standard semantics is to apply two state monad transformers adding addresses and value storage. <p> Figure 19 contains the standard and compilation semantics for letrec and Figure 20 presents an example. 5 Conclusions and Further Work The main contribution of this work is the development a "mix-and-match" compilation method similar to the modular interpreter constructions of <ref> [6, 12, 19] </ref>. Using monads and monad transformers to structure semantics-directed compilers achieves much of the same flexibility and modularity that one associates with monadic interpreters.
Reference: [20] <author> M. Wand, </author> <title> "Deriving Target Code as a Representation of Continuation Semantics," </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 4, No. 3, </volume> <pages> pp. 496-517, </pages> <year> 1982. </year>
Reference-contexts: They showed how compilers could be constructed by introducing intermediate data structures into an interpreter and then partially evaluating. Their interpreter had no monadic structure, so that each pass separation must be done by hand. Our work continues a long line of generating compilers from denotational semantics <ref> [8, 10, 20] </ref>. What primarily distinguishes our work is the use of monads and monad transformers to structure our semantics. Benaissa, et al.[3], transform an interpreter for the while language into a compiler using a sequence of explicit staging annotations. <p> For our compilation examples, we use the abstract machine language from Reynolds [17]. The details are 2 There is a considerable body of work using continuations to structure compilers <ref> [2, 17, 20] </ref>.
References-found: 20

