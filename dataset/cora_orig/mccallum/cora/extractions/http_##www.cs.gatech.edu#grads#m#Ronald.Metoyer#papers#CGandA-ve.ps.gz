URL: http://www.cs.gatech.edu/grads/m/Ronald.Metoyer/papers/CGandA-ve.ps.gz
Refering-URL: http://www.cs.gatech.edu/grads/m/Ronald.Metoyer/res.html
Root-URL: 
Email: [dbroganjmetoyerjjkh]@cc.gatech.edu  
Title: Dynamically Simulated Characters in Virtual Environments  
Author: David C. Brogan, Ronald A. Metoyer, and Jessica K. Hodgins 
Address: Atlanta, GA 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: 1 Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bruce M. Blumberg and Tinsley A. Galyean. </author> <title> Multi-level direction of autonomous creatures for real-time virtual environments. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 47-54. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Single player video games, on the other hand, need fully autonomous characters to serve as opponents or companions. Blumberg developed autonomous creatures using a layered approach for behaviors, motor skills, and geometry <ref> [1] </ref>. Two additional layers provide some abstraction or generalization between creatures with different functionality. This architecture was used to create an animated responsive dog in the ALIVE system. Perlin and Goldberg developed the IMPROV system to facilitate the creation of autonomous interactive characters [2].
Reference: [2] <author> Ken Perlin and Athomas Goldberg. IMPROV: </author> <title> A system for scripting interactive actors in virtual worlds. </title> <editor> In Holly Rushmeier, editor, </editor> <booktitle> SIGGRAPH 96 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 205-216. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year>
Reference-contexts: Two additional layers provide some abstraction or generalization between creatures with different functionality. This architecture was used to create an animated responsive dog in the ALIVE system. Perlin and Goldberg developed the IMPROV system to facilitate the creation of autonomous interactive characters <ref> [2] </ref>. Like Blumberg's system, IMPROV utilizes a layered architecture with a behavior engine for selecting among higher-level behaviors, an animation engine that uses high-level descriptions to move the characters, and a geometry layer.
Reference: [3] <author> John P. Granieri, Welton Becket, Barry D. Reich, Jonathan Crabtree, and Norman L. Badler. </author> <title> Behavioral control for real-time simulated human agents. </title> <editor> In Pat Hanrahan and Jim Winget, editors, </editor> <booktitle> 1995 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 173-180. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> April </month> <year> 1995. </year>
Reference-contexts: The Jack system developed at the University of Pennsylvania facilitates the animation of human characters in virtual environments by providing autonomous walks and other behaviors <ref> [3] </ref>. A real-time behavioral controller generates paths through an environment that guide Jack while reactive navigation controllers avoid obstacles and compute footstep placements. In this environment, Jack is able to walk through city streets and sidewalks while observing pedestrian crossing signals.
Reference: [4] <author> S.R. Musse and D. Thalmann. </author> <title> A model of human crowd behavior. In Computer Animation and Simulation '97, </title> <booktitle> Eurographics workshop, Budapest, </booktitle> <pages> pages 39-51. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Recently, researchers in those labs have focused on the development of synthetic humans for use in virtual environments. In particular, they have explored the control of avatars with many degrees of freedom, the generation of autonomous walking and grasping motions, and the control of animated crowds <ref> [4] </ref>. They have also developed systems to facilitate the creation of networked virtual environments [5]. Multi-agent Behavioral Control. Reynolds was one of the first graphics researchers to explore the animation of group behaviors [6].
Reference: [5] <author> Tolga K. Capin, Hansrudi Noser, Daniel Thalmann, Igor Sunday Pandzic, and Nadia Mag-nenat Thalmann. </author> <title> Virtual human representation and communication in VLNet. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 17(2) </volume> <pages> 42-54, </pages> <month> March-April </month> <year> 1997. </year>
Reference-contexts: In particular, they have explored the control of avatars with many degrees of freedom, the generation of autonomous walking and grasping motions, and the control of animated crowds [4]. They have also developed systems to facilitate the creation of networked virtual environments <ref> [5] </ref>. Multi-agent Behavioral Control. Reynolds was one of the first graphics researchers to explore the animation of group behaviors [6].
Reference: [6] <author> Craig W. Reynolds. </author> <title> Flocks, herds, and schools: A distributed behavioral model. </title> <editor> In Maureen C. Stone, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '87 Proceedings), </booktitle> <volume> volume 21, </volume> <pages> pages 25-34, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: They have also developed systems to facilitate the creation of networked virtual environments [5]. Multi-agent Behavioral Control. Reynolds was one of the first graphics researchers to explore the animation of group behaviors <ref> [6] </ref>. Actors in his system are bird-like objects and are similar to the point masses used in particle systems except that each bird has an orientation and the model includes important dynamic features such as gravity, lift, and banking.
Reference: [7] <author> D. C. Brogan and J. K. Hodgins. </author> <title> Group behaviors for systems with significant dynamics. </title> <booktitle> Autonomous Robots, </booktitle> <volume> 4 </volume> <pages> 137-153, </pages> <year> 1997. </year> <month> 25 </month>
Reference-contexts: Reynolds' work convincingly demonstrates that realistic animations of group formations can be created by applying simple rules to determine the behaviors of the individuals in the flock. Brogan and Hodgins expanded on Reynolds' work by applying similar control algorithms to characters that are dynamically simulated <ref> [7] </ref>. They explored the performance of this algorithm with a herd of 105 hopping robots and a group of 18 bicyclists for a test suite of three problems: steady-state motion, turning, and avoiding obstacles. <p> When every robot in a group exhibits this behavior, the robots settle into a circular pattern with roughly equal spacing <ref> [7] </ref>. To make the autonomous behavior of the robots more interesting, the group wanders randomly through the environment. The behavioral control algorithm calculates the centroid of the robot group and computes a vector between this centroid and a random goal position on the terrain.
Reference: [8] <author> Xiaoyuan Tu and Demetri Terzopoulos. </author> <title> Artificial fishes: Physics, locomotion, perception, behavior. </title> <booktitle> In Proceedings of SIGGRAPH '94 (Orlando, FL), Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 43-50. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: Tu and Terzopoulos populated a virtual marine world with fish that hunt, flee, mate, and wander <ref> [8] </ref>. To create fully autonomous artificial creatures, they modeled the physics of the animal and environment, locomotion style, perception, and higher-level behaviors. To make the interactions more interesting, they modeled fish that differed not only in shape and color but also in behavior by including predators, prey, and pacifists.
Reference: [9] <author> Qinxin Yu and Demetri Terzopoulos. </author> <title> Synthetic motion capture for interactive virtual worlds. </title> <booktitle> In Proceedings of Computer Animation (Philadelphia, </booktitle> <address> PA). </address> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1998. </year>
Reference-contexts: Yu and Terzopoulos adapted this system for real-time performance by replacing the simulated motion of the fishes with kinematic motion derived from a prerecorded database of systematically simulated fish maneuvers <ref> [9] </ref>. Virtual Environment Interfaces. Researchers have explored many different navigational interfaces for virtual environments. Flying with a six degree-of-freedom input device and loco-moting with a two-dimensional treadmill or a stationary bicycle are among the most common.
Reference: [10] <author> H. Distler and H. H. Bulthoff. </author> <title> Psychophysical experiments and virtual environments. In Virtual Reality '96, </title> <publisher> Stuttgart, </publisher> <address> Germany, </address> <year> 1996. </year>
Reference-contexts: Bulthoff and Distler created a virtual environment to investigate cognition and visual perception in complex environments <ref> [10] </ref>. The user navigates by riding a stationary bicycle while looking at a flat screen display. This system allowed them to conduct experiments in visual attention, effects of cognitive load on peripheral vision, object recognition in three-dimensional scenes, navigation, and optical flow and time-to-collision in virtual environments.
Reference: [11] <author> J. Robert Ensor and Gianpaolo U. Carraro. Peloton: </author> <title> A vrml-based bicycling simulator. </title> <booktitle> In Visual Proceedings of SIGGRAPH '97, Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> page 198. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <year> 1997. </year>
Reference-contexts: Researchers at Bell Laboratories created a virtual Peloton to explore virtual reality systems for interaction and collaboration over the World Wide Web <ref> [11] </ref>. Users navigate by riding a stationary bicycle as the system applies resistive torques to the wheel to simulate hill riding. Several commercially available systems for sports training use bicycling as an interface. The Computrainer provides a load generator to simulate pedaling resistance on hills and monitors energy expenditure.
Reference: [12] <author> R. Waters, D. Anderson, J. Barrus, D. Brogan, M. Casey, S. McKeown, T. Nitta, I. Sterns, and W. Yerazunis. </author> <title> Diamond park and spline: Social virtual reality with 3d animation, spoken interaction, and runtime extendability. In Presence: </title> <booktitle> Teleoperators and Virtual Environments, </booktitle> <pages> pages 461-481, </pages> <year> 1997. </year>
Reference-contexts: System Design. Virtual environments are often supported by a network of computers that provide the graphics processing power for multiple users and the computational power for calculating the motion of synthetic actors. One such network-based system is SPLINE (Scalable Platform for Large Interactive Networked Environments) <ref> [12] </ref>. This system provides a framework for the creation of networked virtual environments that allows multiple users in an environment, spoken interaction, three-dimensional sound, and many forms of motion generation. <p> The computation of the sixteen robots is distributed across a cluster of workstations that communicate the position of each robot via distributed shared memory. The Border Collie Environment is set in the flat, oval infield of the polygonal velodrome model extracted from Diamond Park <ref> [12] </ref>. At one end of the infield is a 10 meter square corral with a 6 meter opening in one side (figure 3). The environment consisting of 11,000 polygons and the robots consisting of 500 polygons are rendered using the IRIS Performer Graphics API at 30 frames per second.
Reference: [13] <author> M. R. Macedonia, D. P. Brutzmann, M. J. Zyda, D. R. Pratt, P. T. Barham, J. Falby, and J. Locke. NPSNET: </author> <title> A multi-player 3D virtual environment over the internet. </title> <editor> In Pat Hanrahan and Jim Winget, editors, </editor> <booktitle> 1995 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 93-94. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> April </month> <year> 1995. </year>
Reference-contexts: The park was populated with vehicle simulations, autonomous characters, and figures driven by motion capture data. NPSNET-IV is a three-dimensional virtual environment for multi-player participation over the Internet <ref> [13] </ref>. The system is designed to be used for networked virtual environments that include large scale communication, networked multimedia for sound and video, and autonomous agents.
Reference: [14] <author> Marc H. Raibert. </author> <title> Legged Robots That Balance. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference-contexts: The control system for hopping takes a desired velocity as input, and computes the foot position at touchdown that will achieve this desired velocity by the next liftoff <ref> [14] </ref>. Flight duration is controlled by extending the telescoping leg during stance to make up for losses in the system. Body attitude is controlled by exerting a torque between the body and the leg during stance.
Reference: [15] <author> A. Singla, U. Ramachandran, and J. K. Hodgins. </author> <title> Temporal notions of synchronization and consistency in beehive. </title> <booktitle> In Proceedings of the 9th Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA) (Newport, </booktitle> <address> RI), </address> <year> 1997. </year>
Reference-contexts: We use a system called Beehive to provide synchronization protocols for the cluster of networked Sun UltraSparcs that execute the simulations <ref> [15] </ref>. Beehive provides a software barrier to enforce global time synchronization between the simulations. The software barrier also triggers a process that obtains the body geometry transformations from each simulation and transmits a UDP datagram stream containing the data to the computer rendering the user's view of the graphical world.
Reference: [16] <author> Jessica K. Hodgins, Wayne L. Wooten, David C. Brogan, and James F. O'Brien. </author> <title> Animating human athletics. </title> <editor> In Robert Cook, editor, </editor> <booktitle> Proceedings of SIGGRAPH '95 (Los Angeles, </booktitle> <address> CA, </address> <month> August 6-11, </month> <year> 1995), </year> <booktitle> Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 71-78. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: The connecting springs are two-sided, and the bicyclist is able to pull up on the pedals as if the bicycle were equipped with toe-clips. The details of the bicycling control system were presented in Hodgins et al. <ref> [16] </ref>. The motion of the dynamically simulated bicyclist exhibits some of the subtle details present in real bicycling. For example, to complete a right turn the simulated bicyclist must first steer to the left slightly and shift its center of mass to the right side of the bicycle.
Reference: [17] <author> Edmund R. Burke. </author> <title> Serious Cycling. Human Kinetics, </title> <address> Champaign, IL, </address> <year> 1995. </year> <month> 26 </month>
Reference-contexts: Bicyclists routinely ride in groups because the middle and rear riders expend 30-40% less energy than the leading edge of the pack <ref> [17] </ref>. The behavioral controller achieves similar grouping behaviors by computing a goal position relative to the bicyclist that moves it closer to distant neighbors and further from close neighbors.
References-found: 17

