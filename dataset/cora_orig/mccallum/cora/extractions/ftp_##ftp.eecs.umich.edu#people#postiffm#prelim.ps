URL: ftp://ftp.eecs.umich.edu/people/postiffm/prelim.ps
Refering-URL: http://www.eecs.umich.edu/~postiffm/papers/class.papers.html
Root-URL: http://www.cs.umich.edu
Email: postiffm@eecs.umich.edu  
Title: Function Unit Clustering in Wide-Issue Superscalar Processors  
Author: Matt Postiff 
Keyword: instruction level parallelism, function unit clusters, forwarding paths.  
Address: 1301 Beal Avenue Ann Arbor, MI 48109-2122, USA  
Affiliation: Electrical Engineering and Computer Science Department University of Michigan  
Abstract: Directed Study and Preliminary Examination Report September 17, 1997 Abstract As more function units are integrated into wide-issue superscalar processors and as cycle times decrease, result-forwarding delays will become worse relative to processor cycle time. Physical distance and capacitive effects of smaller geometry wires are the main reason for this increase in delay. Thus, a full bypass network, able to forward results from any function unit to any other function unit, cannot be realized without increasing the cycle time. Since increasing the cycle time is undesirable, this paper examines clustering of function units as an approximation to an ideal design where there is no inter-function unit communication delay. A cluster of function units is simply a grouping of neighboring function units with fast intra-cluster communication delay. Communication between clusters is assessed a higher penalty because of the distance between the clusters. This complicates function unit selection over the ideal case where there is no delay between function units. The goal of this work is to examine the performance of a clustered microengine compared with an ideal one with the same function unit resources but no communication delay between function units. The results presented in this paper show that clustered configurations of function units can perform competitively with an ideal non-clustered configuration. It is also shown that the steering heuristic makes a significant difference in performance in some cases, particularly when the inter-cluster bypass delay is high. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Ahuja, D. Clark, and A. Rogers, </author> <title> The Performance of Incomplete Bypassing in Processor Pipelines, </title> <booktitle> in The 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pp. 36 45, </pages> <year> 1995. </year>
Reference-contexts: Completion refers to the out-of-order result becoming available. Retirement is when an instructions results are committed to architected state. 2. Related Work This section outlines related research in the design of bypass networks and configurations of function units. Ahuja et. al. <ref> [1] </ref> showed that bypassing is required for scalar processors by noting that in the SPEC92 benchmarks, half of the executed instructions use a bypass value in a generic 5-stage pipeline. However, a full set of bypass paths is not necessary to obtain near full performance.
Reference: [2] <author> D. H. Friendly, S. J. Patel, and Y. N. Patt, </author> <title> The Impact of Data Forwarding Delay in a Dynamically Scheduled Superscalar Processor. </title> <type> Draft Copy. </type>
Reference-contexts: The compiler can swap the operands of commutative operators and rearrange instructions within basic blocks to avoid performance degradation due to the removed bypass paths. Such transformations can obtain most of the performance of a complete set of bypass paths. Friendly et. al. <ref> [2] </ref> show that in terms of forwarding paths, about 40% of the source operands require the use of a forwarding bus in an 8-issue superscalar processor.
Reference: [3] <author> L. Gwenapp, </author> <title> Digital 21264 Sets New Standard, </title> <type> Microprocessor Report, </type> <month> October 28, </month> <year> 1996. </year> <pages> pp. 11-16. </pages>
Reference: [4] <author> J. Keller, </author> <title> The 21264: A Superscalar Alpha Processor with Out-of-Order Execution, </title> <booktitle> Presentation at the 9th Annual Microprocessor Forum, </booktitle> <address> San Jose, California. </address> <month> October </month> <year> 1996. </year>
Reference-contexts: This can be considered a form of clustering where a cluster (one of the pipelines) receives a unit of work based on the ISA macro instructions. The importance of function unit clustering is evident in new microprocessors. In particular, the recently-announced Digital 21264 ([3], <ref> [4] </ref>) implements two integer clusters, each with its own register file, integer logic, and address calculation unit. The architects estimated a 1% performance degradation due to a one-cycle communication delay between clusters. The decrease in cycle time attributable to the clustered design has not been published. 3.
Reference: [5] <author> Subbarao Palacharla, Norman P. Jouppi, and J.E. Smith, </author> <title> Complexity-Effective Superscalar Processors, </title> <booktitle> Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 206-218, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: They concluded that the latency-hiding techniques of an out-of-order processor help mask the delay on the slow bypass paths. Palacharla et. al. <ref> [5] </ref> examine clustering in light of technology constraints. They identify wakeup and selection logic as having the greatest delay in their 0.18um technology, followed by register rename and bypass logic, with bypass logic becoming a critical path in their 8-issue model. <p> We propose heuristics similar to the one presented in <ref> [5] </ref> to approximate the optimal cluster assignment for an instruction. The following paragraphs describe the heuristics. It is also important to note that these are simply heuristics: they do not need to produce correct steering decisions. <p> The RPT is used in conjunction with a mask indicating whether the cluster has the hardware to perform a dependent instruction. When it is determined where the current instruction will be executed, the function unit number is written into the RPT. The SRC_FIFO in <ref> [5] </ref> serves a similar function as the RPT in this paper. We chose a different name because our architecture uses general reservation stations for the instruction window instead of FIFOs. Note that the RPT is not indexed by physical register number. <p> For the present experiment, we selected the cluster configuration shown in Figure 1. The selection of this configuration was ad hoc: it was selected to try to take advantage of 2- or 3-instruction chains within basic blocks. Previous work, particularly <ref> [5] </ref>, uses universal, unit-latency function units 4 whereas we use limited function units within the clusters. This additional restriction means that we must determine what mixture of function units are good to put in the clusters. Section 6 of this paper presents initial results in this area. 4. <p> It means that less penalty is being paid for inter-cluster bypasses in the steered configuration. We see that random steering of instructions (H0) to function units performs worse than the other heuristics. Though our results are not as dramatic as those shown in <ref> [5] </ref> for the same kind of steering heuristic, we agree with the authors of that paper in that we feel that it is essential to base instruction steering on dependence information. 5.4 Overall Performance of the Configurations configurations described in Section 5.1.
Reference: [6] <author> S. Palacharla, N. P. Jouppi, and J. E. Smith, </author> <title> Quantifying the Complexity of Superscalar Processors, </title> <note> University of Wisconsin-Madison Technical Report available at http://www.cs.wisc.edu/trs.html. </note>
Reference: [7] <author> Unknown, </author> <title> Improving Instruction Dispatch and Issue for Superscalar Processors Running Ordinary Programs, </title> <booktitle> Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. </pages> <address> X-Y, </address> <month> June </month> <year> 1997. </year>
Reference: [8] <author> E. Rotenberg, S. Bennet, and J. Smith, </author> <title> Trace Cache: a Low Latency Approach to High Bandwidth Instruction Fetching. </title> <note> University of Wisconsin-Madison Technical Report CS-TR-96 1310. Available at http://www.cs.wisc.edu/trs.html. </note>
Reference-contexts: We examine what happens when the processor dynamically decides the instruction-to-cluster mapping. This approach is a natural extension of current 4-issue superscalar approaches. It continues to rely on sophisticated branch prediction and instruction-caching techniques <ref> [21, 8] </ref> to supply the processor with lots of instructions. <p> TraceSim models a dynamically scheduled out-of-order processor. It uses checkpointing to maintain in-order state at branch mispredictions and exceptions. The trace cache in the simulator is loosely derived from work first done by Melvin, et. al. [16], proposed in detail by Rotenberg and Smith in <ref> [8] </ref>, and extended by Patel, et. al. in [12] and [13] 5 . It allows the microengine to execute multiple basic blocks per cycle. Instructions are fetched from the trace cache or the instruction cache (if a miss occurs in the trace cache).
Reference: [9] <author> Y. N. Patt, W. Hwu, and M. Shebanow, HPS, </author> <title> a New Microarchitecture: Rationale and Introduction, </title> <booktitle> in Proceedings of the 18th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pp. 103-107, </pages> <year> 1985. </year>
Reference-contexts: This additional restriction means that we must determine what mixture of function units are good to put in the clusters. Section 6 of this paper presents initial results in this area. 4. Experimental Setup 4.1 Simulator Experiments are based on a variation of the HPS <ref> [9] </ref> Trace Cache simulator called TraceSim, an executable-driven simulator which generates and consumes traces from MC88100 COFF binaries. TraceSim models a dynamically scheduled out-of-order processor. It uses checkpointing to maintain in-order state at branch mispredictions and exceptions.
Reference: [10] <author> Y. N. Patt, S. W. Melvin, W. Hwu, and M. C. Shebanow, </author> <title> Critical Issues Regarding HPS, A High Performance Microarchitecture, </title> <booktitle> in Proceedings of the 18th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <pages> pp. 109-116, </pages> <year> 1985. </year>
Reference: [11] <author> S. J. Patel, D. H. Friendly, and Y. N. Patt, </author> <title> Critical Issues Regarding the Trace Cache Fetch Mechanism, </title> <type> Draft Technical Report, </type> <institution> Advanced Computer Architecture Laboratory, University of Michigan. </institution> <month> March 25, </month> <year> 1997. </year>
Reference-contexts: Examine the information that can be collected at the trace cache fill unit and used to simplify later issues of the packet. Patels work in <ref> [11] </ref> indicates that machine performance is not significantly impacted by large fill unit latencies and so the fill unit can be used to gather and collate rather complex information.
Reference: [12] <author> S. J. Patel, S.W. Kim, D. H. Friendly, and Y. N. Patt, </author> <title> Enhancing the Trace Cache Fetch Mechanism, </title> <note> Draft paper submitted to ISCA 97. </note>
Reference-contexts: It uses checkpointing to maintain in-order state at branch mispredictions and exceptions. The trace cache in the simulator is loosely derived from work first done by Melvin, et. al. [16], proposed in detail by Rotenberg and Smith in [8], and extended by Patel, et. al. in <ref> [12] </ref> and [13] 5 . It allows the microengine to execute multiple basic blocks per cycle. Instructions are fetched from the trace cache or the instruction cache (if a miss occurs in the trace cache). The instruction cache can provide up to one basic block.
Reference: [13] <author> S. J. Patel, </author> <title> A Pipelined Implementation of a Trace Cache, </title> <type> Oral Qualifying Examination, </type> <institution> University of Michigan, </institution> <month> September 19, </month> <year> 1996. </year>
Reference-contexts: It uses checkpointing to maintain in-order state at branch mispredictions and exceptions. The trace cache in the simulator is loosely derived from work first done by Melvin, et. al. [16], proposed in detail by Rotenberg and Smith in [8], and extended by Patel, et. al. in [12] and <ref> [13] </ref> 5 . It allows the microengine to execute multiple basic blocks per cycle. Instructions are fetched from the trace cache or the instruction cache (if a miss occurs in the trace cache). The instruction cache can provide up to one basic block.
Reference: [14] <author> R. M. Tomasulo, </author> <title> An efficient algorithm for exploiting multiple arithmetic units, </title> <journal> IBM Journal of Research and Development, </journal> <volume> vol. 11, </volume> <pages> pp. 25-33, </pages> <month> January </month> <year> 1967. </year>
Reference: [15] <author> Stephan Jourdan, Pascal Sainrat, and Daniel Litaize. </author> <title> Exploring Configurations of Functional Units in an Out-of-Order Superscalar Processor. </title> <booktitle> In Proceedings of the 22nd ACM International Symposium on Computer Architecture, </booktitle> <pages> pages 117-125, </pages> <address> Italy, </address> <month> June 22-24 </month> <year> 1995. </year>
Reference-contexts: The paper shows that a clustered microarchitecture performs only slightly worse than a traditionally-designed 8-way superscalar processor 1 , and that the shorter critical paths in their design would allow for a higher clock rate than the traditional design. In <ref> [15] </ref>, Jourdan examines different numbers and types of function units with regard to the width of issue and the size of the instruction window. Their results show that for a 4-way processor, about 6 function units and 2 data cache ports would be necessary to sustain maximum performance.
Reference: [16] <author> S. Melvin, M. Shebanow, and Y. Patt. </author> <title> Hardware support for large atomic units in dynamically scheduled machines. </title> <booktitle> 21st Intl. Symp. on Microarchitecture, </booktitle> <pages> pp. 60-66, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: TraceSim models a dynamically scheduled out-of-order processor. It uses checkpointing to maintain in-order state at branch mispredictions and exceptions. The trace cache in the simulator is loosely derived from work first done by Melvin, et. al. <ref> [16] </ref>, proposed in detail by Rotenberg and Smith in [8], and extended by Patel, et. al. in [12] and [13] 5 . It allows the microengine to execute multiple basic blocks per cycle.
Reference: [17] <author> Unknown Authors. </author> <title> Complexity Effective PEWS Architecture. </title> <booktitle> Micro 30 Submission #65. </booktitle>
Reference-contexts: We examine what happens when the processor dynamically decides the instruction-to-cluster mapping. This approach is a natural extension of current 4-issue superscalar approaches. It continues to rely on sophisticated branch prediction and instruction-caching techniques [21, 8] to supply the processor with lots of instructions. In the taxonomy of <ref> [17] </ref>, our approach is classified as decentralizing the microarchitecture based on data dependencies, rather than on function unit dependencies or control dependencies. 3.2 Inter-cluster Delay Inter-cluster delay is perhaps the most obvious parameter to study in a clustered configuration of function units. <p> Further increases in the number of clusters will require a ring or other kind of network to connect clusters <ref> [MULTISCALAR, 17] </ref>, where the delay between two clusters is a direct function of distance. This study considers inter-cluster delays of 0 to 3 cycles, but does not model what happens when inter-cluster buses are limited (i.e. where there is contention for the buses).
Reference: [18] <author> R. Uhlig, D. Nagle, T. Mudge, S. Sechrest, and J. Emer, </author> <title> Instruction Fetching: Coping with Code Bloat. </title> <booktitle> 22nd Int. Symp. on Computer Architecture, </booktitle> <address> Santa Margherita Ligure, Italy, </address> <month> June 18-24, </month> <year> 1995, </year> <pages> pp. 345-356. </pages>
Reference-contexts: These results are then collated and sorted by frequency. Table 6 shows the result for the real_gcc benchmark from IBS <ref> [18] </ref>. real_gcc was run for 107 million instructions. Of 98 combinations of function units used, we show the most common 12.
Reference: [19] <author> Kenneth C. Yeager, </author> <title> The MIPS R10000 Superscalar Microprocessor. </title> <booktitle> IEEE Micro, </booktitle> <month> April </month> <year> 1996, </year> <pages> pp. 28-40. </pages>
Reference-contexts: The model is based on the R10000 pipeline. The key hardware components of the R10000 model, and thus the simulator, include the active list, free list, busy bit table, and tag table. The reader is referred to <ref> [19] </ref> for detailed information about how these structures are combined to provide precise exception handling with out-of-order execution. 6.3 Simulation Results For the initial clustering experiments, clustersim was configured as shown in Table 5.
Reference: [20] <author> John L. Hennessy and David A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: In the last four rows of the table, we see that memory operations correspond to half of the operations requested. Qualitatively, at least, the mixture of function units agrees with dynamic instruction frequencies counted by clustersim and published elsewhere <ref> [20] </ref>. 8 Of course, function units will need to be present for each type of instruction so that execution time is not dominated by a small percentage of the instruction stream. We are more interested here in the common case.
Reference: [21] <author> T-Y Yeh and Yale N. Patt, </author> <title> Alternative Implementations of Two-Level Adaptive Branch Prediction, </title> <booktitle> Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: We examine what happens when the processor dynamically decides the instruction-to-cluster mapping. This approach is a natural extension of current 4-issue superscalar approaches. It continues to rely on sophisticated branch prediction and instruction-caching techniques <ref> [21, 8] </ref> to supply the processor with lots of instructions.
Reference: [22] <author> Basem A. Nayfeh, Lance Hammond, and Kunle Olukotun, </author> <title> Evaluation of Design Alternatives for a Multiprocessor Microprocessor. </title> <booktitle> Proceedings of the 23rd International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Squashing of the path that eventually is determined to be the wrong path could then be restricted to a single cluster. Finally, we recognize that the clustering approach begins to look like recent multiprocessor-on-a-chip and multithreading proposals <ref> [22, 23] </ref>. The multiprocessor floating point clusters. Function units within a cluster can communicate with no delay. Communication that uses the inter-cluster buses (show in bold below the clusters) require some bypass delay (0 to 3 cycles for this study).
Reference: [23] <author> Susan J. Eggers, Joel Emer, Henry M. Levy, Lack L. Lo, Rebecca Stamm, and Dean M Tullsen, </author> <title> Simultaneous Multithreading: A Platform for Next-generation Processors. Source=? </title>
Reference-contexts: Squashing of the path that eventually is determined to be the wrong path could then be restricted to a single cluster. Finally, we recognize that the clustering approach begins to look like recent multiprocessor-on-a-chip and multithreading proposals <ref> [22, 23] </ref>. The multiprocessor floating point clusters. Function units within a cluster can communicate with no delay. Communication that uses the inter-cluster buses (show in bold below the clusters) require some bypass delay (0 to 3 cycles for this study).
Reference: [24] <author> Alexander Peleg and Uri Weiser, </author> <type> United States Patent 5381533. </type> <institution> Intel Corporation. </institution> <year> 1994. </year>
Reference-contexts: See <ref> [24] </ref>. 6 Ideally, the trace cache would also contain decode and route information to ease decode and issue for packets which are already in the trace cache.
Reference: [25] <author> Steve C. McMahan, Mark Bluhm, and Raul A. Garibay, Jr. 6x86: </author> <title> The Cyrix Solution to Executing x86 Binaries on a High Performance Microprocessor. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 83, No. 12, </volume> <month> December </month> <year> 1995. </year>
Reference-contexts: Finally, their paper showed that it was futile to increase the window size without selecting the right combination of function units and memory ports. The authors in <ref> [25] </ref> describe Cyrixs approach to building the 6x86, which uses two pipelines, each capable of executing a complete x86 instruction. This can be considered a form of clustering where a cluster (one of the pipelines) receives a unit of work based on the ISA macro instructions.
References-found: 25

