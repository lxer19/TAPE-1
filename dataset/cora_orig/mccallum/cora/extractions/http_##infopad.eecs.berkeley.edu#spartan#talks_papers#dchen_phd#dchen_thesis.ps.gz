URL: http://infopad.eecs.berkeley.edu/spartan/talks_papers/dchen_phd/dchen_thesis.ps.gz
Refering-URL: http://infopad.eecs.berkeley.edu/spartan/talks_papers/
Root-URL: http://www.cs.berkeley.edu
Title: Programmable Arithmetic Devices for High Speed Digital Signal Processing  
Author: Devereaux C. Chen Jan M Rabaey 
Degree: Thesis Committee Chairman  
Note: Prof.  
Affiliation: University of California Department of Electrical Engineering Berkeley, California and Computer Science  
Abstract: The high throughput computation requirements of real-time digital signal processing (dsp) systems usually dictate hardware intensive solutions. Often attendant to hardware approaches are problems of high development costs, slow turnaround, susceptibility to errors, and difficulty in testing and debugging, all of which tend to inhibit the rapid implementation of such systems. Research is underway into the synthesis of application specific hardware to aid the system designer by automatically generating hardware that is "correct by construction". The creation of configurable, pre-fabricated hardware that has been designed for high speed computations forms part of this research and is the main topic of this thesis. This work contains a survey of some typical real-time dsp algorithms drawn from video and speech processing and summarizes the particular computation challenges posed by this class of algorithms. Currently available hardware choices and their trade-offs and limitations are discussed. A multiprocessor architecture consisting of programmable arithmetic devices is presented as a novel platform for supporting high speed digital signal processing. The vlsi realization of the architecture and an accompanying software development environment are presented as a proof of concept. The main conclusion of this work is that software-configurable hardware approaches to high speed digital signal processing problems form viable alternatives to existing approaches, for systems designers interested in rapidly prototyping or implementing their ideas. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> "IEEE Micro: </institution> <note> Special Issue on Digital Signal Processors", Dec. 1986. [2] "IEEE Micro: Special Issue on Digital Signal Processors", </note> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: Since then, they have established themselves as being first choice for general purpose digital signal processing. These processors are surveyed in <ref> [1, 2, 65, 66, 18] </ref>. If there is a definitive feature of these dsps, it is the multiply-accumulate time (mac). Since their introduction, the mac time has been steadily decreasing from several hundreds of nanoseconds to the 50 - 100 nanoseconds that they now exhibit. Fig 4.1 shows the trend. <p> in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L <ref> [1] </ref> 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd <p> 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L <ref> [1] </ref> 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 <p> in I2L <ref> [1] </ref> 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] <p> PIN LIST 155 Pin Type Name Pin Type Name Pin Type Name 36 bo phso 105 vdd Vdd 174 in I1L [4] 37 vdd Vdd 106 out O2H [3] 175 in I1L [3] 38 in start1 107 out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H <ref> [1] </ref> 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L <p> O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L <ref> [1] </ref> 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd GND 204 gnd GND 68 gnd GND 137 <p> [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L <ref> [1] </ref> 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd GND 204 gnd GND 68 gnd GND 137 in FI1L 206 in I2L [13] 208 vdd <p> out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L <ref> [1] </ref> 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd GND 204 gnd GND 68 gnd GND 137 in FI1L 206 in I2L [13] 208 vdd Vdd Table E.3: PADDI Pin List (contd.) Appendix F Assembler Manual Page F.1 Introduction PAS (1) USER
Reference: [3] <author> Advanced Micro Devices Inc. </author> <title> Array Processing and Digital Signal Processing Handbook, </title> <year> 1986. </year>
Reference-contexts: Prefabricated generic ics include ttl chips, ttl bit-slices [78], and ecl and cmos byte-slices <ref> [3] </ref>. The major disadvantages of using these approaches are high power, low speed, and large board area, drawbacks which are related to the low level of integration of the parts. <p> 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L <ref> [3] </ref> 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND <p> 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L <ref> [3] </ref> 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 <p> PIN LIST 155 Pin Type Name Pin Type Name Pin Type Name 36 bo phso 105 vdd Vdd 174 in I1L [4] 37 vdd Vdd 106 out O2H <ref> [3] </ref> 175 in I1L [3] 38 in start1 107 out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out <p> PIN LIST 155 Pin Type Name Pin Type Name Pin Type Name 36 bo phso 105 vdd Vdd 174 in I1L [4] 37 vdd Vdd 106 out O2H <ref> [3] </ref> 175 in I1L [3] 38 in start1 107 out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd <p> out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L <ref> [3] </ref> 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out <p> vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L <ref> [3] </ref> 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd GND 204 gnd GND <p> [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L <ref> [3] </ref> 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd GND 204 gnd GND 68 gnd GND 137 in FI1L 206 in I2L [13] 208 vdd Vdd Table E.3: PADDI Pin List (contd.)
Reference: [4] <author> M. Ahrens, A. EL Gammal, D. Gailbraith, J. Greene, S. Kaptanoglu, K.R. Dharmara-jan, L. Hutchings, S. Ku, P. McGibney, K. Shaw, N. Stiawalt, T. Whitney, T. Wong, W. Wong, and B. Wu. </author> <title> "An FPGA Family Optimized for High Densities and Reduced Routing Delay". </title> <booktitle> In Proc. CICC'90: 1990 Custom Integrated Circuits Conference, </booktitle> <pages> pages 31.5.1-4, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: With these devices, the chip count can be dramatically reduced. In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx [52, 51, 130], Actel <ref> [4] </ref>, Algotronix (Cal) [45], Plessey [46], att [48], and Plus Logic [94]. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect. <p> 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H <ref> [4] </ref> 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 <p> PIN LIST 155 Pin Type Name Pin Type Name Pin Type Name 36 bo phso 105 vdd Vdd 174 in I1L <ref> [4] </ref> 37 vdd Vdd 106 out O2H [3] 175 in I1L [3] 38 in start1 107 out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd <p> vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L <ref> [4] </ref> 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out <p> in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L <ref> [4] </ref> 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in <p> Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L <ref> [4] </ref> 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd GND 204 gnd GND 68 gnd GND 137 in FI1L 206 in
Reference: [5] <author> Altera Corp. </author> <title> User-Configurable Logic Data Handbook, </title> <month> July </month> <year> 1988. </year>
Reference-contexts: are not as high as the applications that we consider, this processor is an good example of the effective use of software-configurable techniques to its application domain to provide flexibility and high performance. 4.4.8 Field Programmable Gate Arrays Programmable or restructurable devices known as programmable logic devices (PLD's) (such as <ref> [5] </ref>) are able to implement random logic and simple fsms rather well. Prior to these devices, any glue logic or simple controllers would typically require several or many ttl parts depending on the complexity. With these devices, the chip count can be dramatically reduced. <p> Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L <ref> [5] </ref> 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H <p> I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H <ref> [5] </ref> 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin List APPENDIX E. <p> lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H <ref> [5] </ref> 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin List APPENDIX E.
Reference: [6] <author> D. Amrany, S. Gadot, and M. Dimyan. </author> <title> "A Programmable DSP Engine for High-Rate Modems". </title> <booktitle> In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 222-223, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: This vsp has the advantage of having a very high data memory bandwidth and is attractive for specific video processing such as video codecs. 4.4.7 Software Reconfigurable Transceiver A programmable dsp engine for high-rate modems is was presented in <ref> [6] </ref>. The architecture contains a fir processor for signal processing applications and a binary processor for data manipulation. The fir processor contains three fir engines in a multiprocessor simd architecture with a 32b instruction set dedicated for dsp tasks. <p> CHAPTER 8. CONCLUSIONS AND FUTURE WORK 134 We expect to see many novel multiprocessor architectures for digital signal processing. Accompanying innovations will be required in the software arena to fully exploit the power of these architectures. Investigations into this domain, such as here and in <ref> [127, 35, 34, 107, 6] </ref>, have begun, and will continue to expand. For example star Semiconductor has recently introduced a complete development system, the Sproclab. It uses the sproc1400 processor which contains four general signal processors with on-board shared memory and serial and parallel i/o [114, 19]. <p> testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L <ref> [6] </ref> 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd <p> 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L <ref> [6] </ref> 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 <p> I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H <ref> [6] </ref> 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin List APPENDIX E. <p> lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H <ref> [6] </ref> 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin List APPENDIX E. <p> 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L <ref> [6] </ref> 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] <p> in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L <ref> [6] </ref> 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in <p> out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L <ref> [6] </ref> 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd
Reference: [7] <author> W. Andrews. </author> <title> "Distinctions Blur Between DSP Solutions". </title> <booktitle> Computer Design, </booktitle> <pages> pages 86-99, </pages> <month> May. </month> <year> 1989. </year>
Reference-contexts: Chapter 4 Rapid Prototyping Platforms "A wide variety of chips move to higher levels of integration, making previous distinctions ambiguous and heralding a new generation of dsp technology", | W Andrews, Computer Design Magazine <ref> [7] </ref> 4.1 Introduction In real-time dsp applications the emphasis is on performance. Because of their distinctive advantages in achieving high performance, hard-wired pipelined data paths are used in many designs (Chapters 2 and 3). Currently, these data paths are implemented as ASIC s. <p> O1L [10] 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L <ref> [7] </ref> 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H <p> I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L <ref> [7] </ref> 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo <p> 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L <ref> [7] </ref> 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in <p> I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H <ref> [7] </ref> 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin <p> ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H <ref> [7] </ref> 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin List APPENDIX E.
Reference: [8] <author> P.J. Berkhout and L.D.J. Eggermont. </author> <title> Digital Audio Systems. </title> <journal> IEEE ASSP Magazine, </journal> <pages> pages 45-67, </pages> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: A particular thrust of this overall cad effort targets high performance real-time systems. Examples of such systems can be found in the field of digital signal processing (dsp) which has become a dominant force in signal processing and communications [31]. Typical application domains include digital audio <ref> [75, 8] </ref>, speech recognition and synthesis [10], mobile communications [44], personal communications systems [14, 47], robotics 1 CHAPTER 1. <p> PIN LIST 154 Pin Type Name Pin Type Name Pin Type Name 1 gnd GND 70 out O1L [10] 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L <ref> [8] </ref> 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 <p> Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H <ref> [8] </ref> 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L <p> [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H <ref> [8] </ref> 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 in I1L [6] 35 Bin gl0 104 <p> out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H <ref> [8] </ref> 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin List APPENDIX E. <p> 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H <ref> [8] </ref> 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197
Reference: [9] <author> P. Bertin, D. Roncin, and J. Vuillemin. </author> <title> "Programmable Active Memories". </title> <booktitle> presented at the 1992 ACM International Workshop on Field- Programmable Gate Arrays, </booktitle> <pages> pages 57-59, </pages> <month> Feb. </month> <year> 1992. </year> <note> 164 BIBLIOGRAPHY 165 </note>
Reference-contexts: A field programmable mcm architecture utilizing an a array of modified fpgas is proposed. Interconnections are provided by a fixed routing network on the mcm, and by programmable interconnection frames on each fpga. Quickturn Systems reports an emulation machine based on xilinx fpgas. In <ref> [9] </ref>, a programmable active memory (pam) card which consists of a large array of xilinx fpgas is connected to the system bus of a host computer, in this case, a dec work-station. <p> PIN LIST 154 Pin Type Name Pin Type Name Pin Type Name 1 gnd GND 70 out O1L [10] 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L <ref> [9] </ref> 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 <p> ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L <ref> [9] </ref> 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 in I1L [6] 35 Bin gl0 104 Bin sci 173 in I1L [5] Table E.2: PADDI Pin List APPENDIX E. <p> 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L <ref> [9] </ref> 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out <p> 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L <ref> [9] </ref> 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132
Reference: [10] <author> R. Bisiani. </author> <title> "System Implementation Strategies". </title> <booktitle> In Speech And Natural Language Workshop, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Examples of such systems can be found in the field of digital signal processing (dsp) which has become a dominant force in signal processing and communications [31]. Typical application domains include digital audio [75, 8], speech recognition and synthesis <ref> [10] </ref>, mobile communications [44], personal communications systems [14, 47], robotics 1 CHAPTER 1. <p> PIN LIST 154 Pin Type Name Pin Type Name Pin Type Name 1 gnd GND 70 out O1L <ref> [10] </ref> 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 <p> PIN LIST 154 Pin Type Name Pin Type Name Pin Type Name 1 gnd GND 70 out O1L <ref> [10] </ref> 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 <p> I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H <ref> [10] </ref> 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd Vdd 152 vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L <p> [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H <ref> [10] </ref> 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 <p> GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H <ref> [10] </ref> 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in
Reference: [11] <author> W. E. Blanz, D. Petkovic, and J. L. C. Sanz. </author> <title> "Algorithms and Architectures for Machine Vision (chapter)". </title> <editor> In C. H. Chen, editor, </editor> <booktitle> Handbook of Signal Processing. Marcell Decker, </booktitle> <year> 1988. </year>
Reference-contexts: Typical application domains include digital audio [75, 8], speech recognition and synthesis [10], mobile communications [44], personal communications systems [14, 47], robotics 1 CHAPTER 1. INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision <ref> [11] </ref>, digital television [30], high definition television [56], sonar [84], ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking [71, 76]. In signal processing applications, the computation involves a set of operations which operate on an infinite data stream (the signal). <p> I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H <ref> [11] </ref> 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L [6] 150 in I1H [7] 14 in I2L [1] 83 vdd <p> 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L <ref> [11] </ref> 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 in I1L [7] 33 Bin gl2 102 out O2H [5] 171 <p> 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L <ref> [11] </ref> 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out <p> 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L <ref> [11] </ref> 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1]
Reference: [12] <author> R.K. Brayton. </author> <title> "SRC Center Of Excellence In CAD/IC". </title> <booktitle> 1990 Research Planning Report, </booktitle> <pages> pages 1-45, </pages> <year> 1990. </year>
Reference-contexts: Berkeley, many resources are being directed to establishing an Integrated System Design Environment for the rapid design of all levels of electronic systems <ref> [29, 12] </ref>. The result will be the creation of efficient, high performance systems which will compete with present manual design approaches by incorporating the very best of algorithms and by using advanced implementation technologies. Top priority is being placed on performance optimization, and reducing the time and cost of implementation. <p> gnd GND 70 out O1L [10] 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H <ref> [12] </ref> 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 in I1H [8] 12 in I2L [3] 81 out O1L <p> out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H <ref> [12] </ref> 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H
Reference: [13] <author> R.K. Brayton, R. Rudell, A. Sangiovanni-Vincentelli, and A. Wang. </author> <title> "MIS: A Multiple Level Logic Optimization System". </title> <journal> IEEE Transactions on Computer Aided Design, </journal> <volume> CAD-6(6):1062-1081, </volume> <month> Nov. </month> <year> 1987. </year>
Reference-contexts: Logic synthesis is the translation of a register-transfer level (rtl) description of a circuit into combinational logic and registers that implement this register transfer. An example of a successful logic synthesis system is reported in <ref> [13] </ref>. By creating designs that are "correct by construction", the designer can reduce the number of iterations through the design, fabrication, and test cycle. High level synthesis is one approach to this problem and its advantages are discussed in [74]. <p> Pin Type Name Pin Type Name Pin Type Name 1 gnd GND 70 out O1L [10] 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H [14] 5 in I2L [8] 74 ininv ph1 143 in I1H <ref> [13] </ref> 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 in I1H [10] 11 substrate GND 80 out O1L [7] 149 <p> I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H <ref> [13] </ref> 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 <p> verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H <ref> [13] </ref> 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in I1L [8] 32 Bin lctr0 101 out O2H [6] 170 <p> in I1L [3] 38 in start1 107 out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H [14] 113 out O2L <ref> [13] </ref> 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND <p> in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L <ref> [13] </ref> 135 gnd GND 204 gnd GND 68 gnd GND 137 in FI1L 206 in I2L [13] 208 vdd Vdd Table E.3: PADDI Pin List (contd.) Appendix F Assembler Manual Page F.1 Introduction PAS (1) USER COMMANDS PAS (1) NAME pas - PADDI assembler SYNOPSIS pas [ -ENPWsv ] [ -T <p> out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L [15] 133 out FO2H 202 in I2H [0] 66 out O1L <ref> [13] </ref> 135 gnd GND 204 gnd GND 68 gnd GND 137 in FI1L 206 in I2L [13] 208 vdd Vdd Table E.3: PADDI Pin List (contd.) Appendix F Assembler Manual Page F.1 Introduction PAS (1) USER COMMANDS PAS (1) NAME pas - PADDI assembler SYNOPSIS pas [ -ENPWsv ] [ -T type ] [ -e errors ] [ -i instruction ] [ -o objfile ] filename DESCRIPTION
Reference: [14] <author> R.W. Brodersen, A. Chandrakasan, and S. Sheng. </author> <title> "Technologies for Personal Communications". </title> <booktitle> VLSI Symposium, </booktitle> <year> 1991. </year>
Reference-contexts: Examples of such systems can be found in the field of digital signal processing (dsp) which has become a dominant force in signal processing and communications [31]. Typical application domains include digital audio [75, 8], speech recognition and synthesis [10], mobile communications [44], personal communications systems <ref> [14, 47] </ref>, robotics 1 CHAPTER 1. INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision [11], digital television [30], high definition television [56], sonar [84], ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking [71, 76]. <p> PIN LIST 154 Pin Type Name Pin Type Name Pin Type Name 1 gnd GND 70 out O1L [10] 139 in FI2L 3 in I2L [10] 72 ininv testi 141 vdd Vdd 4 in I2L [9] 73 vdd Vdd 142 in I1H <ref> [14] </ref> 5 in I2L [8] 74 ininv ph1 143 in I1H [13] 6 vdd Vdd 75 gnd GND 144 in I1H [12] 7 in I2L [7] 76 ininv teste 145 in I1H [11] 8 in I2L [6] 77 ininv scant 146 gnd GND 9 in I2L [5] 78 gnd GND 147 <p> I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H <ref> [14] </ref> 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 <p> read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H [15] 159 in I1H [0] 22 bo phmo 91 out O2H <ref> [14] </ref> 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 in I1L [9] 31 gnd GND 100 gnd GND 169 in <p> out O2H [3] 175 in I1L [3] 38 in start1 107 out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H <ref> [14] </ref> 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H <p> Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L [15] 180 vdd Vdd 44 out O1H <ref> [14] </ref> 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out O2L [4] 193 gnd GND 57 out O1H [4] 126 out
Reference: [15] <author> R.W. Brodersen and J. Rabaey. </author> <title> "Evolution of Microsystem Design". </title> <booktitle> In ESSCIRC'89: Proceedings of the 15th European Solid State Circuits Conference, </booktitle> <pages> pages 208-217, </pages> <month> Sept. </month> <year> 1989. </year>
Reference-contexts: discussed: a) the nec vspm system [121] b) the Matsushita ismp chip [73] c) the Philips vsp chip [127] The rough trade-offs of asynchronous vs synchronous schemes are mentioned. 3.2.5 Digital Signal Processors A general classification for dsp architectures, based on the control/arithmetic ratio, was suggested by Brodersen and Rabaey <ref> [15] </ref>. It is based on the amount of operation sharing on an arithmetic unit (hardware multiplexing), a concept developed further in [20]. <p> This classification does not explicitly consider node granularity. However, it is included implicitly since it is closely related to the control/arithmetic ratio, as is apparent in Fig. 3.9. The authors in <ref> [15] </ref> explained their classification as follows: Architectures can be classified in many different ways. One way of classification is based on the amount of operation sharing on an arithmetic unit, as shown in Fig. 3.9. <p> CHAPTER 3. ARCHITECTURAL CLASSIFICATION 24 Systolic Bit-Serial Data Path Clusters Micro-Processor HARDWIRED ASSEMBLY CODE General Purpose Signal Processor Dedicated DSP Dedicated Multi-Processors FULLY INTERMEDIATE PERFORMANCE FLEXIBILITY Reference should be made to <ref> [15] </ref> for any necessary clarification. 3.3 Architectures for High Speed DSP What architectural approaches satisfy the specific computation requirements of high speed dsp, that were outlined in Section 2.5 of Chapter 2? For a given algorithm, hard-wired approaches usually dominate in performance since they can be designed to fit the specific <p> Systolic architectures ( [62, 63]) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in [86, 55, 50]. Vector-pipelined architectures such as described in [123] (not classified in <ref> [15] </ref>) can achieve high throughput rates. However, due to the high branching penalty overhead associated with very deep pipelines, the use of conditional operations is very restricted. There have been recent investigations to alleviate this overhead [33], but this is still in the research phase. <p> However conditional operations will have severe overhead penalties due to the deep pipelines. On the topic of heterogeneous data path clusters, the authors in <ref> [15] </ref> stated: The control oriented processor approach tends to break down for applications with higher throughput ranges (such as required in speech recognition, video, and image processing), since the ratio between data rate and instruction rate tends to approach unity in these cases. <p> vdd Vdd 16 vdd Vdd 85 out O1L [3] 154 in I1H [4] 18 bo scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H <ref> [15] </ref> 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 <p> scanc 87 out O1L [1] 156 in I1H [2] 19 bo read 88 out O1L [0] 157 gnd GND 20 in verify 89 gnd GND 158 in I1H [1] 21 gnd GND 90 out O2H <ref> [15] </ref> 159 in I1H [0] 22 bo phmo 91 out O2H [14] 160 in I1L [15] 23 bo ce 92 out O2H [13] 161 in I1L [14] 25 out nop 94 vdd Vdd 163 in I1L [13] 27 bo ns0 96 out O2H [10] 165 in I1L [11] 29 Bin lctr2 98 out O2H [8] 167 substrate GND 30 Bin lctr1 99 out O2H [7] 168 <p> in I1L [4] 37 vdd Vdd 106 out O2H [3] 175 in I1L [3] 38 in start1 107 out O2H [2] 176 in I1L [2] 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L <ref> [15] </ref> 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H <p> 39 bo wr 108 out O2H [1] 177 vdd Vdd 41 Bin stop 110 gnd GND 179 ininv ph2 42 gnd GND 111 out O2L <ref> [15] </ref> 180 vdd Vdd 44 out O1H [14] 113 out O2L [13] 182 gnd GND 46 out O1H [12] 115 substrate GND 184 in I2H [15] 47 vdd Vdd 116 out O2L [11] 185 in I2H [14] 49 out O1H [10] 118 out O2L [9] 187 vdd Vdd 51 out O1H [8] 120 vdd Vdd 189 in I2H [11] 53 gnd GND 122 out O2L [6] 191 in I2H [9] 55 out O1H [6] 124 out <p> gnd GND 57 out O1H [4] 126 out O2L [3] 195 in I2H [6] 59 out O1H [3] 128 out O2L [1] 197 in I2H [4] 61 out O1H [1] 130 vdd Vdd 199 in I2H [3] 63 substrate GND 132 out FO1L 201 in I2H [1] 64 out O1L <ref> [15] </ref> 133 out FO2H 202 in I2H [0] 66 out O1L [13] 135 gnd GND 204 gnd GND 68 gnd GND 137 in FI1L 206 in I2L [13] 208 vdd Vdd Table E.3: PADDI Pin List (contd.) Appendix F Assembler Manual Page F.1 Introduction PAS (1) USER COMMANDS PAS (1) NAME
Reference: [16] <author> R. Budzinski, J. Linn, and S. Thatte. </author> <title> "A Restructurable Integrated Circuit for Implementing Programmable Digital Systems". </title> <booktitle> Computer, </booktitle> <pages> pages 11-21, </pages> <month> Mar. </month> <year> 1982. </year>
Reference-contexts: Overall, this paper contains several interesting ideas on configurable hardware at the processor level. It is not clear how many of these ideas have been implemented into hardware. 4.4.2 Texas Instrument RIC The Texas Instrument's ric <ref> [16] </ref>, is another early proposal for reconfigurable hardware, at the integrated circuit level. Essentially, "A Restructurable Integrated Circuit for Implementing Digital Systems" is proposed. The overt goal of the design was to create a semicustom ic that serves much the same purpose as gate arrays and master-slices.
Reference: [17] <author> D. Bursky. </author> <title> "Programmable Sequencer Hits 125-MHz Clock Speed". </title> <booktitle> Electronic Design, </booktitle> <pages> pages 43-46, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Time per Cycle (T): The time required to perform a single machine cycle is determined by such factors as: Instruction access time: Global instructions are generated by a fast commercially available external programmable logic sequencer e.g. <ref> [17, 119] </ref> and broadcast to each exu. For the prototype chip these are three bits long. Instruction decode time: At configuration time, the local controller for each exu is serially configured each with its own unique set of instructions.
Reference: [18] <author> D. Bursky. </author> <title> "DSP Expands Role As Cost Drops And Speed Increases". </title> <booktitle> Electronic Design, </booktitle> <pages> pages 53-81, </pages> <month> Oct </month> <year> 1991. </year>
Reference-contexts: Since then, they have established themselves as being first choice for general purpose digital signal processing. These processors are surveyed in <ref> [1, 2, 65, 66, 18] </ref>. If there is a definitive feature of these dsps, it is the multiply-accumulate time (mac). Since their introduction, the mac time has been steadily decreasing from several hundreds of nanoseconds to the 50 - 100 nanoseconds that they now exhibit. Fig 4.1 shows the trend. <p> In other words, they are currently found in many places, and are quickly becoming ubiquitous. To illustrate the pervasive nature of these chips we list some typical dedicated-function ones in Table 8.1 (from <ref> [18] </ref>). CHAPTER 8.
Reference: [19] <author> D. Bursky. </author> <title> "Parallel Processing DSP Chip Delivers Top Speed". </title> <booktitle> Electronic Design, </booktitle> <pages> pages 43-50, </pages> <month> Oct </month> <year> 1991. </year>
Reference-contexts: For example star Semiconductor has recently introduced a complete development system, the Sproclab. It uses the sproc1400 processor which contains four general signal processors with on-board shared memory and serial and parallel i/o <ref> [114, 19] </ref>. The objective of this system is to provide better performance than single chip dsps, together with a rapid prototyping environment.
Reference: [20] <author> F. Catthoor. </author> <title> "Microcoded Processor Architectures and Synthesis Methodologies for Real-Time Signal Processing". </title> <editor> In E.F. Depreterre and A-J. van der Veens, editors, </editor> <booktitle> Algorithms and Parallel VLSI Architectures, </booktitle> <pages> pages 403-429. </pages> <address> Elsvier Science, </address> <year> 1991. </year> <note> Vol. </note> <author> A. </author> <title> BIBLIOGRAPHY 166 </title>
Reference-contexts: It is based on the amount of operation sharing on an arithmetic unit (hardware multiplexing), a concept developed further in <ref> [20] </ref>. We will adopt this taxonomy since the concepts of control/arithmetic ratio and hardware multiplexing are closely related to the issue of high speed dsp computation which is our CHAPTER 3.
Reference: [21] <author> P.K. Chan, M. Schlag, and M. Martin. "BORG: </author> <title> A Reconfigurable Prototyping Board Using FPGAs". </title> <booktitle> presented at the 1992 ACM International Workshop on Field- Programmable Gate Arrays, </booktitle> <pages> pages 47-51, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: In the cases where the algorithms could be hard-wired into the pams, several orders of magnitude speed-ups were observed. Similar efforts at this level are reported in <ref> [21] </ref> We anticipate that the impact of these and similarly new technologies on logic design and system design methodology will be as follows: a. Software-configurable components such as fpgas, micro-controllers, plds, and multiprocessor architectures such as wavefront arrays and programmable arithmetic devices will gradually replace ssi components such as ttl.
Reference: [22] <author> D. C. Chen, R. Yu, R. W. Brodersen, and J. Rabaey. </author> <title> "A VLSI Grammar Processing Subsystem for a Real Time Large Vocabulary Continuous-Speech Recognition System". </title> <booktitle> In Proc. CICC'90: 1990 Custom Integrated Circuits Conference, </booktitle> <pages> pages 13.3.1-5, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Recently, this system has been upgraded to handle 60,000 words in real-time with 30 accesses per state which require in excess of 600 MB/sec of i/o bandwidth [115]. In this system, 520 Mops/sec are required. Let us discuss the grammar processing sub-system in some more detail ( <ref> [22] </ref>). The statistical grammar model allows any word to follow any other word. Associated with the ith word produced by the word processing sub-system is a probability P GO i , the probability that the word i ends at a particular point in time. <p> The evaluation of the ith word (equation (2.1)) is terminated when the probability falls below a programmable threshold and processing, and the i + 1th evaluation is begun. Assuming average of 17 successors per word ( <ref> [22] </ref>), the two cycle branch delay of the Grammar Processor leads to a 12 per cent performance branch penalty. The dynamically adjusted threshold will terminate successor updates before complete processing of all the successors of a word. <p> HIGH SPEED DIGITAL SIGNAL PROCESSING 10 YUV 3x3 WORD GRAMMAR CONV. CONV. PROC. PROC. MOPS 1674 170 225/520 200 IO (MB/sec) 213 20 85/600 265 Table 2.1: Computations and I/O Summary system ( <ref> [22] </ref>). <p> and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor [116, 115] * h) Grammar Processor <ref> [22] </ref> The basic features that must be supported by the architecture were listed in Sec tion 4.4.9. These were: CHAPTER 5.
Reference: [23] <author> D.C. Chen, L.M. Guerra, E.H. Ng, , M. Potkonjak, D.P. Schultz, and J.M. Rabaey. </author> <title> "An Integrated System for Rapid Prototyping of High Algorithmic Specific Data Paths". to be presented at the International Conference on Application-Specific Array Processors, </title> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: We will then describe the two approaches to compilation. In the first we will examine in detail a proposal for allocation and assignment problem using a hierarchical clustering scheme. We will also discuss the latter approach though somewhat briefly. The details of this approach will appear in <ref> [23] </ref>. 7.3.1 Architectural Constraints The goal is to identify computationally efficient means of compiling a high level behavioral specification of an algorithm into paddi, subject to its particular hardware constraints. A strong point of the architecture is the power of the cross-bar switch. <p> N) :: c (i) * In@i func fir (in:fix) Out: fix = Input: Flowgraph language of the compiler effort will be reported in <ref> [23] </ref>. 7.4 Conclusions We have described the low-level programming tools for the paddi architecture. We have also discussed the architectural features which directly affect the quality of software compilation from a high level language. A proposal was made for optimizing hardware allocation and assignment.
Reference: [24] <author> D.C. Chen, L.M. Guerra, E.H. Ng, D.P. Schultz, C.N. Yu, and J.M. Rabaey. </author> <title> "A Field Programmable Architecture for High Speed Digital Signal Processing Applications". </title> <booktitle> presented at the 1992 ACM International Workshop on Field- Programmable Gate Arrays, </booktitle> <pages> pages 117-122, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Appendix A Xilinx Case Study A.1 Introduction The results presented in this appendix were first presented in <ref> [24] </ref>. As mentioned in Section 4.4.8, the number of choices for fpgas are numerous. As part of this research, we made a detailed study of the applicability of fpgas to high speed data path prototyping. This Appendix will outline the results of that study.
Reference: [25] <author> D.C. Chen and J.M. Rabaey. "PADDI: </author> <title> Programmable Arithmetic Devices For DIgital Signal Processing". </title> <booktitle> In VLSI Signal Processing IV, </booktitle> <pages> pages 240-249. </pages> <publisher> IEEE Press, </publisher> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: In order to demonstrate concept feasibility, a prototype chip, dubbed paddi for Programmable Arithmetic Devices for Digital Signal Processing, was designed and fabricated <ref> [25] </ref>. Its vlsi implementation is described in Chapter 6. The supporting software environment necessary to program these devices is discussed in Chapter 7 along with compilation approaches, and Chapter 8 concludes the dissertation. Chapter 2 High Speed Digital Signal Processing Fallacy: There is such a thing as a typical program. <p> The basic concepts for such an engine, paddi, or Programmable Arithmetic Devices for High Speed Digital Signal processing, were first reported in <ref> [25] </ref>. The abstract architecture, shown in Fig. 4.21, is similar, but not identical to those of the software-configurable architectures presented in the previous sections. The set of exus are represented as data processors. The n x n switch provides flexible communication.
Reference: [26] <author> D.C. Chen and J.M. Rabaey. </author> <title> "A Reconfigurable Multiprocessor IC for Rapid Pro-totyping of Real Time Data Paths". </title> <booktitle> In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 74-75, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Design Een graficus heeft in zijn wezen iets van een troubador. (A graphic artist has something of the troubador within him.) | M Escher, Escher on Escher 6.1 Introduction As a proof of concept, a prototype of the the architecture described in Chapter 5 was implemented as a multiprocessor ic <ref> [26] </ref> using vlsi technology. This chapter will discuss the logic and vlsi implementation of the major units which comprise the chip. In order to maximize the probability of fabricating a functional chip, a conservative approach to circuit design was taken wherever possible.
Reference: [27] <author> W.L. Chen, P.Haskell, D. Messerschmitt, and L.Yun. </author> <title> "Structured Video: Concept and Display Architecture". sub. to IEEE Transactions on Circuits and Systems for Video Technology, </title> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision [11], digital television [30], high definition television [56], sonar [84], ultrasonic imaging, advanced video services <ref> [27] </ref>, smart weapons, and advanced fire control for target discrimination and tracking [71, 76]. In signal processing applications, the computation involves a set of operations which operate on an infinite data stream (the signal).
Reference: [28] <author> C. Chu, M. Potkonjak, M. Thaler, and J. Rabaey. </author> <title> "HYPER: An Interactive Synthesis Environment for High Performance Real Time Applications". </title> <booktitle> In IEEE International Conference on Computer Design, </booktitle> <month> October </month> <year> 1989. </year>
Reference-contexts: More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications. Examples of such systems are Lager IV [64] (actually more of a silicon compiler than a high level synthesis system), Cathedral-III [88, 87], hyper <ref> [28, 99] </ref>, and phideo [70]. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems [118, 113]. It extends the concepts of a vlsi silicon compiler to board level module generation.
Reference: [29] <author> J.B. Costello. </author> <title> 1991 Keynote Address. </title> <booktitle> In Proceedings 28th ACM/IEEE Design Automaton Conference, </booktitle> <month> June </month> <year> 1991. </year> <title> BIBLIOGRAPHY 167 [30] ed. C.P. Sandbank. In DIGITAL TELEVISION. </title> <publisher> John Wiley and Sons, </publisher> <year> 1990. </year> <note> [31] ed. </note> <editor> K. Feher. </editor> <booktitle> In Advanced Digital Communications: Systems and Signal Processing Techniques. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: Berkeley, many resources are being directed to establishing an Integrated System Design Environment for the rapid design of all levels of electronic systems <ref> [29, 12] </ref>. The result will be the creation of efficient, high performance systems which will compete with present manual design approaches by incorporating the very best of algorithms and by using advanced implementation technologies. Top priority is being placed on performance optimization, and reducing the time and cost of implementation.
Reference: [32] <author> A. ElGamal, I. Dobbelare, D. How, and B. Kleveland. </author> <title> "Field Programmable MCM Systems". </title> <booktitle> presented at the 1992 ACM International Workshop on Field- Programmable Gate Arrays, </booktitle> <pages> pages 52-56, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: The area of rapid prototyping and emulation of systems is, in itself, a fast growing area. For example, work is in progress by other researchers to provide programmability at mcm level <ref> [32] </ref>. A field programmable mcm architecture utilizing an a array of modified fpgas is proposed. Interconnections are provided by a fixed routing network on the mcm, and by programmable interconnection frames on each fpga. Quickturn Systems reports an emulation machine based on xilinx fpgas.
Reference: [33] <author> R. Ernst. </author> <title> "Long Pipelines in Single-Chip Digital Signal Processors-Concepts and Case Study". </title> <journal> IEEE Transactions on Circuits And Systems, </journal> <pages> pages 100-108, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: Vector-pipelined architectures such as described in [123] (not classified in [15]) can achieve high throughput rates. However, due to the high branching penalty overhead associated with very deep pipelines, the use of conditional operations is very restricted. There have been recent investigations to alleviate this overhead <ref> [33] </ref>, but this is still in the research phase. Moderate performance has been reported for architectures which have dedicated multi-processors. The control based nature of these architectures restricts the throughput range.
Reference: [34] <author> R.D. Fellman. </author> <title> Design Issues and an Architecture for the Monolithic Implementation of a Parallel Digital Signal Processor. </title> <journal> IEEE Transactions on Acoustics, Speech, And Signal Processing, </journal> <pages> pages 839-852, </pages> <month> May. </month> <year> 1990. </year>
Reference-contexts: CHAPTER 8. CONCLUSIONS AND FUTURE WORK 134 We expect to see many novel multiprocessor architectures for digital signal processing. Accompanying innovations will be required in the software arena to fully exploit the power of these architectures. Investigations into this domain, such as here and in <ref> [127, 35, 34, 107, 6] </ref>, have begun, and will continue to expand. For example star Semiconductor has recently introduced a complete development system, the Sproclab. It uses the sproc1400 processor which contains four general signal processors with on-board shared memory and serial and parallel i/o [114, 19].
Reference: [35] <author> A.L. Fisher, P.T. Highnam, and T.E. Rockoff. </author> <title> "A Four Processor Building Block for SIMD Processor Arrays". </title> <journal> IEEE Journal of Solid State Circuits, </journal> <pages> pages 369-375, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Many of these circuits are user-configurable, and their number keeps increasing every year. For example: a general purpose vsp is reported in [127], a four processor building block for simd image processing arrays is reported in <ref> [35] </ref>, a data-driven video signal array processor is reported in [107, 108, 109], a 300 mops video signal processor is reported in [79], and a data-flow processor for real-time low level image processing is reported in [96]. <p> CHAPTER 8. CONCLUSIONS AND FUTURE WORK 134 We expect to see many novel multiprocessor architectures for digital signal processing. Accompanying innovations will be required in the software arena to fully exploit the power of these architectures. Investigations into this domain, such as here and in <ref> [127, 35, 34, 107, 6] </ref>, have begun, and will continue to expand. For example star Semiconductor has recently introduced a complete development system, the Sproclab. It uses the sproc1400 processor which contains four general signal processors with on-board shared memory and serial and parallel i/o [114, 19].
Reference: [36] <author> S. Fiske and W. J. Dally. </author> <title> "The Reconfigurable Arithmetic Processor". </title> <booktitle> 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 30-36, </pages> <month> May. </month> <year> 1988. </year>
Reference-contexts: CHAPTER 4. RAPID PROTOTYPING PLATFORMS 39 Microinstruction register Microstore Microstore Address Downloader 4.4.4 MIT RAP The mit reconfigurable Arithmetic Processor (rap) is an arithmetic processing node for a message-passing, mimd concurrent computer <ref> [36] </ref>. It incorporates on one chip several serial 64b floating point arithmetic units connected by a switching network. rap calculates complete arithmetic formulas by sequencing the switch through different patterns.
Reference: [37] <author> M.J. Flynn. </author> <title> "Very High Speed Computing Systems". </title> <booktitle> In Proceedings of the IEEE, </booktitle> <volume> volume 54, </volume> <pages> pages 1901-1909, </pages> <year> 1966. </year>
Reference-contexts: They are discussed below in several different taxonomies. 3.2.1 Flynn The classical taxonomy for computer systems was presented by Flynn in <ref> [37, 38] </ref>. The classification (Fig. 3.1 and Fig. 3.2) is based on the parallelism within the instruction stream and parallelism within the data stream. Flynn observed that the methods for achieving parallel operation depended on replicating the instruction stream and the data stream.
Reference: [38] <author> M.J. Flynn. </author> <title> "Some Computer Organizations and Their Effectiveness". </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-21, </volume> <month> Sep. </month> <year> 1972. </year>
Reference-contexts: They are discussed below in several different taxonomies. 3.2.1 Flynn The classical taxonomy for computer systems was presented by Flynn in <ref> [37, 38] </ref>. The classification (Fig. 3.1 and Fig. 3.2) is based on the parallelism within the instruction stream and parallelism within the data stream. Flynn observed that the methods for achieving parallel operation depended on replicating the instruction stream and the data stream.
Reference: [39] <author> R.J. Francis, J. Rose, and Z. Vranesic. </author> <title> "Technology Mapping for Lookup Table-Based FPGAs fro Performance". </title> <booktitle> In IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pages 568-561, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Since many actual designs typically contain gates of this order of magnitude, fpgas have and will continue to be competitive with conventional gate-arrays for low to medium complexity designs. Active research is also currently being done in the field of logic synthesis for fpgas <ref> [81, 82, 39] </ref> and in incorporating them as hardware platforms into high level synthesis systems [132].
Reference: [40] <author> R. Freeman. </author> <title> "User-programmable Gate Arrays". </title> <journal> IEEE Spectrum, </journal> <pages> pages 32-35, </pages> <month> De-cember </month> <year> 1988. </year>
Reference-contexts: Prior to these devices, any glue logic or simple controllers would typically require several or many ttl parts depending on the complexity. With these devices, the chip count can be dramatically reduced. In recent years, the class of chips known as fpgas has seen rapid growth <ref> [40] </ref>. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx [52, 51, 130], Actel [4], Algotronix (Cal) [45], Plessey [46], att [48], and Plus Logic [94].
Reference: [41] <author> T. Fukushima. </author> <title> "A Survey of Image Processing LSIs in Japan". </title> <booktitle> In IEEE International Conference on Pattern Recognition, </booktitle> <volume> volume 2, </volume> <pages> pages 394-401, </pages> <year> 1990. </year> <note> BIBLIOGRAPHY 168 </note>
Reference-contexts: CHAPTER 3. ARCHITECTURAL CLASSIFICATION 22 3.2.4 Image and Video Processing Architectures The idea of node granularity is used in the classification of over forty image processing lsis made in Japan in the 1980's <ref> [41] </ref>. The author classifies the devices into five categories: the fully parallel processor (fpp), the partially parallel processor (ppp), the digital signal processor (dsp) specialized for image processing, the functional processor (fp), and the neural network processor (nnp). <p> Over forty image processing lsis made in Japan in the 1980's are surveyed in <ref> [41] </ref> There are too many of these processors to describe all of them, so we will restrict our discussion to a few representative specimens. CHAPTER 4.
Reference: [42] <author> W. Geurts and F. Catthoor. </author> <title> "DSP Applications suited for Lowly Multiplexed Architectures". </title> <booktitle> In ASICS Open Workshop on synthesis techniques for (lowly) multiplexed datapaths, </booktitle> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: The repetitive kernel in an (or in a part of an) algorithm is the smallest coherent part of the algorithm which is repeated again and again in time, and which covers all arithmetic operations <ref> [42] </ref>.
Reference: [43] <author> H. Gharavi, P. Pirsch, and H. Yasuda. </author> <title> Special Issue on VLSI Implementation For Digital Image And Video Processing Applications. </title> <journal> IEEE Transactions on Circuits And Systems, </journal> <pages> pages 1259-1365, </pages> <month> Oct. </month> <year> 1989. </year>
Reference-contexts: Typical application domains include digital audio [75, 8], speech recognition and synthesis [10], mobile communications [44], personal communications systems [14, 47], robotics 1 CHAPTER 1. INTRODUCTION 2 and electro-mechanical control, digital image and video processing <ref> [43] </ref>, machine vision [11], digital television [30], high definition television [56], sonar [84], ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking [71, 76].
Reference: [44] <author> D. Goodman. </author> <title> "Trends in Cellular and Cordless Communications". </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 31-40, </pages> <month> June. </month> <year> 1991. </year>
Reference-contexts: Examples of such systems can be found in the field of digital signal processing (dsp) which has become a dominant force in signal processing and communications [31]. Typical application domains include digital audio [75, 8], speech recognition and synthesis [10], mobile communications <ref> [44] </ref>, personal communications systems [14, 47], robotics 1 CHAPTER 1.
Reference: [45] <author> J.P. Gray and T.A. Kean. </author> <title> "Configurable Hardware: A New Paradigm for Computation". </title> <booktitle> In Advanced Research In VLSI, </booktitle> <pages> pages 279-295. </pages> <booktitle> Proceedings of the Decennial Caltech Conference on VLSI, </booktitle> <month> Mar. </month> <year> 1989. </year>
Reference-contexts: With these devices, the chip count can be dramatically reduced. In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx [52, 51, 130], Actel [4], Algotronix (Cal) <ref> [45] </ref>, Plessey [46], att [48], and Plus Logic [94]. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect. It would be impractical and unnecessary to discuss all members of this class.
Reference: [46] <author> N. Hastie and Richard Cliff. </author> <title> "The Implementation of Hardware Subroutines on Field Programmable Gate Arrays". </title> <booktitle> In Proc. CICC'90: 1990 Custom Integrated Circuits Conference, </booktitle> <pages> pages 31.4.1-4, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx [52, 51, 130], Actel [4], Algotronix (Cal) [45], Plessey <ref> [46] </ref>, att [48], and Plus Logic [94]. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect. It would be impractical and unnecessary to discuss all members of this class.
Reference: [47] <author> G. Heilmeir. </author> <title> "Personal Communications: </title> <booktitle> Quo Vadis". In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 24-26-123, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Examples of such systems can be found in the field of digital signal processing (dsp) which has become a dominant force in signal processing and communications [31]. Typical application domains include digital audio [75, 8], speech recognition and synthesis [10], mobile communications [44], personal communications systems <ref> [14, 47] </ref>, robotics 1 CHAPTER 1. INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision [11], digital television [30], high definition television [56], sonar [84], ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking [71, 76].
Reference: [48] <author> D. Hill and D. Cassiday. </author> <title> "Preliminary Description of Tabula Rosa: an electrically configurable hardware design". </title> <booktitle> In ICCD, </booktitle> <pages> pages 391-395, </pages> <month> Sep. </month> <year> 1990. </year>
Reference-contexts: In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx [52, 51, 130], Actel [4], Algotronix (Cal) [45], Plessey [46], att <ref> [48] </ref>, and Plus Logic [94]. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect. It would be impractical and unnecessary to discuss all members of this class.
Reference: [49] <author> P.D Hoang and J.M. Rabaey. "McDAS: </author> <title> A Compiler for Multiprocessor DSP Implementation". </title> <booktitle> In Proc. ICASSP 92: 1992 International Conference on Acoustics Speech and Signal Processing, </booktitle> <pages> pages V581-V584, </pages> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: This compiler is being developed as a part of the unified rapid prototyping framework environment, which also includes the hyper and mcdas <ref> [49] </ref> systems. The three systems share a common database structure, but each targets a different architecture: caddi targets programmable arithmetic devices, hyper, semicustom architectures, and mcdas, multiple programmable processor architectures. Besides the common data structure and several tools, caddi shares with mcdas and hyper the same fully modular software organization.
Reference: [50] <author> R. Hofer, W. Kamp, R. Kunemund, and H. Soldner. </author> <title> "Programmable 2D Linear Filter For Video Applications". </title> <booktitle> In ESSCIRC'89: Proceedings of the 15th European Solid State Circuits Conference, </booktitle> <pages> pages 276-279, </pages> <month> Sept. </month> <year> 1989. </year>
Reference-contexts: Systolic architectures ( [62, 63]) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in <ref> [86, 55, 50] </ref>. Vector-pipelined architectures such as described in [123] (not classified in [15]) can achieve high throughput rates. However, due to the high branching penalty overhead associated with very deep pipelines, the use of conditional operations is very restricted.
Reference: [51] <author> H.C. Hsieh, W. Carter, J. Ja, E. Cheung, S. Schreifels, C. Erikson, P. Freidin, L. Tin-key, and R. </author> <title> Kanazawa. "Third-Generation Architecture Boosts Speed And Density of Field-Programmable Gate Arrays". </title> <booktitle> In Proc. CICC'90: 1990 Custom Integrated Circuits Conference, </booktitle> <pages> pages 31.2.1-31.2.7, </pages> <month> May </month> <year> 1990. </year> <note> BIBLIOGRAPHY 169 </note>
Reference-contexts: With these devices, the chip count can be dramatically reduced. In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx <ref> [52, 51, 130] </ref>, Actel [4], Algotronix (Cal) [45], Plessey [46], att [48], and Plus Logic [94]. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect.
Reference: [52] <author> H.C. Hsieh, K. Dong, J. Ja, R. Kanazawa, L. Ngo, L. Tinkey, and W. Carter R. Freeman. </author> <title> "A Second Generation User-Programmable Gate Array". </title> <booktitle> In Proc. CICC'89: 1989 Custom Integrated Circuits Conference, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: With these devices, the chip count can be dramatically reduced. In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx <ref> [52, 51, 130] </ref>, Actel [4], Algotronix (Cal) [45], Plessey [46], att [48], and Plus Logic [94]. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect.
Reference: [53] <institution> IEEE Communications Society. </institution> <note> "HDTV: Special Issue", </note> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: The basic architectural features such as level of pipelining, functional requirements, control, and i/o bandwidth of each example will be examined. 4 CHAPTER 2. HIGH SPEED DIGITAL SIGNAL PROCESSING 5 2.2 Video High definition television, or hdtv, is rapidly on its way to becoming a commercial reality <ref> [53] </ref>. Let us consider a typical hdtv bit transfer rate.
Reference: [54] <author> R. Jain, P. A. Ruetz, and R. W. Brodersen. </author> <title> "Architectural Strategies For Digital Signal Processing Circuits". </title> <booktitle> In VLSI Signal Processing II, </booktitle> <pages> pages 361-372, </pages> <month> Nov. </month> <year> 1986. </year>
Reference-contexts: Section 4.2.1 will discuss these processors further. Bit-serial architectures do not lend themselves easily to hardware multiplexing and conditional operations which limits their application range. For high performance circuits, they are less area efficient and are slower than bit-parallel ones for the reasons outlined in <ref> [54] </ref>. Systolic architectures ( [62, 63]) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in [86, 55, 50].
Reference: [55] <author> C. Joanblanq and P. Senn. </author> <title> "A 54 MHz CMOS Programmable Video Signal Processor for HDTV Applications". </title> <booktitle> In ESSCIRC'89: Proceedings of the 15th European Solid State Circuits Conference, </booktitle> <pages> pages 7-10, </pages> <month> Sept. </month> <year> 1989. </year>
Reference-contexts: Systolic architectures ( [62, 63]) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in <ref> [86, 55, 50] </ref>. Vector-pipelined architectures such as described in [123] (not classified in [15]) can achieve high throughput rates. However, due to the high branching penalty overhead associated with very deep pipelines, the use of conditional operations is very restricted.
Reference: [56] <author> R. K. Jurgen. </author> <title> "The Challenges of Digital HDTV". </title> <booktitle> In IEEE Spectrum, </booktitle> <pages> page 28, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Typical application domains include digital audio [75, 8], speech recognition and synthesis [10], mobile communications [44], personal communications systems [14, 47], robotics 1 CHAPTER 1. INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision [11], digital television [30], high definition television <ref> [56] </ref>, sonar [84], ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking [71, 76]. In signal processing applications, the computation involves a set of operations which operate on an infinite data stream (the signal).
Reference: [57] <author> G. Kane. </author> <title> "Mips RISC Architecture". </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: We will now discuss the various techniques which we have applied to improving the performance. This work relies in part on the techniques used in the popular risc <ref> [57] </ref> approaches. If we can reduce any of the individual components which contribute to the overall time per task without increasing any of the other components in the process, we will have improved the performance.
Reference: [58] <author> R. Kavaler. </author> <title> "The Design And Evaluation Of A Speech Workstation". </title> <type> Technical Report Memo. </type> <institution> No. UCB/ERL M86/39, U.C. Berkeley, </institution> <year> 1986. </year>
Reference-contexts: The computational needs are exacerbated when the recognition is performed in real-time. A real-time isolated-word speech recognition system with a vocabulary of 1000 words was presented in <ref> [58] </ref>. It requires the computation of 1.25 M equations/sec or roughly 60 mips, where each equation is a dynamic programming recursion equation. The 3000 word, real-ime, hidden Markov model-based, continuous-speech recogni CHAPTER 2. <p> * a) biquad hardware multiplexed - direct-mapped pipelined [112, 92] Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp <ref> [58] </ref> * g) Word Processor [116, 115] * h) Grammar Processor [22] The basic features that must be supported by the architecture were listed in Sec tion 4.4.9. These were: CHAPTER 5.
Reference: [59] <author> K. Keutzer. </author> <title> "Three Competing Design Methodologies For ASIC's: Architectural Synthesis, Logic Synthesis and Module Generation". </title> <booktitle> In Proceedings 26th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 308-313, </pages> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: The classes defined span a broad range of computational elements. 3.2.3 Telecommunications ASICs In the paper by Keutzer <ref> [59] </ref>. the scope of the taxonomy is restricted to ic applications and architectures, specifically: microprocessors, digital signal processors, floating-point units, co-processors such as for graphics and memory management, protocol engines for communications applications, sequencers, and glue logic.
Reference: [60] <author> S. Kirkpatrick, C. Gelatt, and M. Vecchi. </author> <title> "Optimization by Simulated Annealing". </title> <booktitle> Science, </booktitle> <pages> pages 671-680, </pages> <year> 1983. </year>
Reference-contexts: This phase provides an initial solution which, although it is not guaranteed to have a successful schedule, does have a high probability of being scheduled by keeping the constraints hard. CHAPTER 7. PADDI: SOFTWARE ENVIRONMENT 127 Improvement Phase In the improvement phase, simulated annealing <ref> [60] </ref> is applied to improve the initial solution. One or more of the hard bounds are relaxed and even bad moves are probabilistically accepted.
Reference: [61] <author> K. Kornegay. </author> <title> "A Test Controller Board For TSS". </title> <type> Technical Report Memo. </type> <institution> No. UCB/ERL M91/4, U.C. Berkeley, </institution> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: In this mode, a word of the nanostores is read, and scanned out. This repeats for all nanostore words, thus enabling verification of the nanostore contents. 6.6.2 Test Support System A pre-existing Test Support System <ref> [61] </ref>, (Fig. 6.24), was retro-fitted to accommodate the specific requirements of the chip. The system allows the user to download scan-test vectors from a sun workstation to a Test Control Board (tcb) which is connected to the Device Under Test (dut).
Reference: [62] <author> H.T. Kung. </author> <title> "Why Systolic Architectures?". </title> <journal> IEEE Computer, </journal> <volume> 15:1:37-46, </volume> <year> 1982. </year>
Reference-contexts: Section 4.2.1 will discuss these processors further. Bit-serial architectures do not lend themselves easily to hardware multiplexing and conditional operations which limits their application range. For high performance circuits, they are less area efficient and are slower than bit-parallel ones for the reasons outlined in [54]. Systolic architectures ( <ref> [62, 63] </ref>) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in [86, 55, 50]. Vector-pipelined architectures such as described in [123] (not classified in [15]) can achieve high throughput rates.
Reference: [63] <author> S.Y. Kung. </author> <title> "VLSI Array Processors". </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: Section 4.2.1 will discuss these processors further. Bit-serial architectures do not lend themselves easily to hardware multiplexing and conditional operations which limits their application range. For high performance circuits, they are less area efficient and are slower than bit-parallel ones for the reasons outlined in [54]. Systolic architectures ( <ref> [62, 63] </ref>) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in [86, 55, 50]. Vector-pipelined architectures such as described in [123] (not classified in [15]) can achieve high throughput rates.
Reference: [64] <institution> Electronic Research Laboratory. LagerIV Distribution 1.0 Silicon Assembly System Manual. University of California at Berkeley, </institution> <month> June </month> <year> 1988. </year> <title> Distribution 1.0. </title>
Reference-contexts: More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications. Examples of such systems are Lager IV <ref> [64] </ref> (actually more of a silicon compiler than a high level synthesis system), Cathedral-III [88, 87], hyper [28, 99], and phideo [70]. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems [118, 113]. <p> This section will describe the implementation of its major parts. The adders were implemented using the carry-select-adder cells from the lageriv cell library <ref> [64] </ref>, the fastest available at the time. The adder consists of several stages that work in parallel to produce carry results for two cases: that of a zero carry input into the stage and that of a one carry input into the stage. <p> Fig. 6.26 shows how the clocks were routed from the input pads. Drivers were sized to maintain sharp edges. 6.7.1 Layout and Simulation Layout: Hand-crafted cells were laid out using the magic cad tool [90]. The carry-select adder cells were obtained from the Lager cell library <ref> [64] </ref>. A micro-photograph of the chip is shown in Fig. 6.27. Simulation: Circuit and behavioral simulation were performed using spice [83] and irsim [105] respectively, and the pas assembler was used to generate simulation test vectors and chip configuration files. <p> The configuration fsms were described in a high level behavioral language and their corresponding plas were automatically generated using the Berkeley oct tools <ref> [64] </ref>. spice simulations were performed to simulate the critical path of the chip. The respective load capacitances were estimated from the worst case ic process parameters and CHAPTER 6. PADDI: HARDWARE DESIGN 113 PHOTO CHIP CHAPTER 6.
Reference: [65] <author> E. A. Lee. </author> <title> Programmable DSP Architectures, Part I. </title> <journal> IEEE ASSP Magazine, </journal> <month> Oct. </month> <year> 1988. </year> <note> BIBLIOGRAPHY 170 </note>
Reference-contexts: Since then, they have established themselves as being first choice for general purpose digital signal processing. These processors are surveyed in <ref> [1, 2, 65, 66, 18] </ref>. If there is a definitive feature of these dsps, it is the multiply-accumulate time (mac). Since their introduction, the mac time has been steadily decreasing from several hundreds of nanoseconds to the 50 - 100 nanoseconds that they now exhibit. Fig 4.1 shows the trend.
Reference: [66] <author> E. A. Lee. </author> <title> Programmable DSP Architectures, Part II. </title> <journal> IEEE ASSP Magazine, </journal> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: Since then, they have established themselves as being first choice for general purpose digital signal processing. These processors are surveyed in <ref> [1, 2, 65, 66, 18] </ref>. If there is a definitive feature of these dsps, it is the multiply-accumulate time (mac). Since their introduction, the mac time has been steadily decreasing from several hundreds of nanoseconds to the 50 - 100 nanoseconds that they now exhibit. Fig 4.1 shows the trend.
Reference: [67] <author> E.A. Lee. </author> <title> "Introduction to Programmable DSPs". UCSB short Course on Signal Processing and Speech, </title> <month> July </month> <year> 1988. </year>
Reference-contexts: Fig 4.1 shows the trend. The data was drawn from the data sheets of several popular manufacturers such as Motorola, AT& T, Texas Instruments, Fujitsu, Hitachi, and Analog Devices. One possible way of deciding whether or not a dsp is appropriate for the task at hand <ref> [67] </ref> is described in the following steps: Step 1: Determine the application sample period. For example Table 4.1 shows the sample period for three applications. Step 2: Divide by the multiply-accumulate time of the machine.
Reference: [68] <author> C. Leiserson. </author> <title> "VLSI Theory and Parallel Supercomputing". </title> <booktitle> In Advanced Research In VLSI, </booktitle> <pages> pages 308-313. </pages> <booktitle> Proceedings of the Decennial Caltech Conference on VLSI, </booktitle> <month> Mar. </month> <year> 1989. </year>
Reference-contexts: A main criterion for the interconnect network is that it be fast, with no latency. The main design choices left to us was whether to adopt hierarchical approaches as fat-trees <ref> [69, 68] </ref> and discretionary interconnection matrices as in [128], or to adopt a full-crossbar. Full-crossbars are more expensive to implement than hierarchical ones, as the number of functional blocks grow. Ultimately, we adopted a combination of the hierarchical and cross-bar approaches. <p> It is the 3 x 3 linear convolver of Fig. 2.3 of Section 2.3. The coefficients. are powers-of-two and so the multiplications can be implemented as shifts and adds. This convolver is used in low level image processing [103] to implement various filtering operations. After retiming <ref> [68] </ref>, the signal flow diagram of Fig. B.1 results. Fig. B.2 and Fig. B.3 show how this can be mapped to two chips (excluding the line delays). (Note also that the pads of each chip are pipelined).
Reference: [69] <author> C. E. Leiserson and J. B. Saxe. </author> <title> "Optimizing Synchronous Systems". </title> <booktitle> Twenty-Second Annual Symposium on Foundations of Computer Science, </booktitle> <month> Oct. </month> <year> 1981. </year>
Reference-contexts: A main criterion for the interconnect network is that it be fast, with no latency. The main design choices left to us was whether to adopt hierarchical approaches as fat-trees <ref> [69, 68] </ref> and discretionary interconnection matrices as in [128], or to adopt a full-crossbar. Full-crossbars are more expensive to implement than hierarchical ones, as the number of functional blocks grow. Ultimately, we adopted a combination of the hierarchical and cross-bar approaches.
Reference: [70] <author> P. E. R. Lippens, J. van Meerbergen, A. van der Werf, W.F.J. Verhaegh, B.T. Mc-Sweeney, J.O. Huisken, and O.P. McArdle. "PHIDEO: </author> <title> A Silicon Compiler for High Speed Algorithms". </title> <booktitle> European Design Automation Conference, </booktitle> <pages> pages 436-41, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Examples of such systems are Lager IV [64] (actually more of a silicon compiler than a high level synthesis system), Cathedral-III [88, 87], hyper [28, 99], and phideo <ref> [70] </ref>. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems [118, 113]. It extends the concepts of a vlsi silicon compiler to board level module generation.
Reference: [71] <author> M. J. Little, M. L. Campbell, S. P. Laub, M. W. Yung, and J. Grinberg. </author> <title> "3-D Computer For Advanced Fire Control". </title> <booktitle> First Annual Fire Control Symposium (SDIO), </booktitle> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision [11], digital television [30], high definition television [56], sonar [84], ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking <ref> [71, 76] </ref>. In signal processing applications, the computation involves a set of operations which operate on an infinite data stream (the signal).
Reference: [72] <editor> LSI Logic Corp. </editor> <title> Application Note: DSP and Image Processing Family, </title> <year> 1987. </year>
Reference-contexts: The functions performed by these chips are 3x3 convolution, 7x7 logical convolution, 3x3 non-linear filtering based on sorting, image contour extraction, feature extraction, and line delays. Chips of these types are in commercial production <ref> [72] </ref>. As an example, consider the 3x3 linear convolver. A mask of fixed coefficients is dragged across an image (Fig. 2.2). At each point, the output y (i,j) is the sum of the products of the coefficients and their corresponding pixel intensities. <p> Thirteen of these devices are listed. Four nnps are listed for tasks such as character, text, voice, and image recognition. Similar classes of image processing ics as above are produced elsewhere e.g. <ref> [72] </ref>, to name just one. Another interesting classification for real time video architectures is contained in [126], where the author attempts a functional classification based on processing properties, memory properties, communication properties, and control properties.
Reference: [73] <author> M. Maruyama, H. Nakahira, T. Araki, S. Sakiyama, Y. Kitao, K. Aono, and H. Ya-mada. </author> <title> "A 200 MIPS Image Signal Multiprocessor on a Single Chip". </title> <booktitle> In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 122-123, </pages> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: Examples of different video architectures are presented: a) systolic arrays b) wavefront arrays c) self-timed language-driven architectures [125]. Specific chips are discussed: a) the nec vspm system [121] b) the Matsushita ismp chip <ref> [73] </ref> c) the Philips vsp chip [127] The rough trade-offs of asynchronous vs synchronous schemes are mentioned. 3.2.5 Digital Signal Processors A general classification for dsp architectures, based on the control/arithmetic ratio, was suggested by Brodersen and Rabaey [15].
Reference: [74] <author> M.C. McFarland, A.C. Parker, and R. Camposano. </author> <title> "Tutorial on High-Level Synthesis". </title> <booktitle> In Proceedings 25th ACM/IEEE Design Automaton Conference, </booktitle> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: By creating designs that are "correct by construction", the designer can reduce the number of iterations through the design, fabrication, and test cycle. High level synthesis is one approach to this problem and its advantages are discussed in <ref> [74] </ref>. Traditionally, high level synthesis is followed by automatic layout generation of an ic which implements the rtl description. However, one is still left with the time for fabrication and testing, and the still rather high nre costs associated with asic design and sophisticated cad tools. <p> high level synthesis, basic interdependent tasks which must be done include translation of the high level language into an internal representation (typically some variation of a graph with control flow and data flow constructs), transformations (at all levels of the process) [124, 102, 89] scheduling, allocation, assignment, as described in <ref> [74] </ref> Various approaches differ in manner and the order in which these basic tasks are attacked. In one approach, scheduling, allocation and assignment are performed separately and in separate phases.
Reference: [75] <author> G.W. McNally. </author> <title> "Digital Audio in Broadcasting". </title> <journal> IEEE ASSP Magazine, </journal> <pages> pages 26-44, </pages> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: A particular thrust of this overall cad effort targets high performance real-time systems. Examples of such systems can be found in the field of digital signal processing (dsp) which has become a dominant force in signal processing and communications [31]. Typical application domains include digital audio <ref> [75, 8] </ref>, speech recognition and synthesis [10], mobile communications [44], personal communications systems [14, 47], robotics 1 CHAPTER 1.
Reference: [76] <author> G. Melcher, G. Thomas, and D. Kaplan. </author> <title> "The Navy's New Standard Signal Processor, </title> <journal> the AN/UYS-2". Journal of VLSI Signal Processing, </journal> <pages> pages 103-109, </pages> <month> Oct </month> <year> 1990. </year> <note> BIBLIOGRAPHY 171 </note>
Reference-contexts: INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision [11], digital television [30], high definition television [56], sonar [84], ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking <ref> [71, 76] </ref>. In signal processing applications, the computation involves a set of operations which operate on an infinite data stream (the signal).
Reference: [77] <author> S. Melvin. </author> <title> "Performance Enhancement Through Dynamic Scheduling and Large Execution Atomic Units In Single Instruction Stream Processors". </title> <institution> U.C. Berkeley, </institution> <year> 1990. </year> <note> UCB CS Divsion. </note>
Reference-contexts: computation rate, was made early in the design process, based upon the analysis contained in the previous chapters, The next step was choice of the dynamic/static interface, which is described in the following section. 5.3 Dynamic/Static and Hardware/Software Interfaces In this section we adopt the interface model described by Melvin <ref> [77] </ref>. A computer can be thought of as a multi-level system with high level algorithms at the top and circuits at the bottom. In between are levels, or interfaces, which define sets of data structures and the operations allowed upon them.
Reference: [78] <author> J. Mick and J. </author> <title> Brick. In "Bit-slice Microprocessor Design". </title> <publisher> McGraw-Hill, </publisher> <year> 1980. </year>
Reference-contexts: Prefabricated generic ics include ttl chips, ttl bit-slices <ref> [78] </ref>, and ecl and cmos byte-slices [3]. The major disadvantages of using these approaches are high power, low speed, and large board area, drawbacks which are related to the low level of integration of the parts.
Reference: [79] <author> T. Minami, H. Yamaguchi, Y. Tashiro, R. Kasai, J. Takahasi, S. Hamaguchi, K. Endo, and T. Tajiri. </author> <title> "A 300 MOPS Video Signal Processor with a Parallel Architecture". </title> <booktitle> In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 252-253, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: For example: a general purpose vsp is reported in [127], a four processor building block for simd image processing arrays is reported in [35], a data-driven video signal array processor is reported in [107, 108, 109], a 300 mops video signal processor is reported in <ref> [79] </ref>, and a data-flow processor for real-time low level image processing is reported in [96]. <p> 16wx32b prog. mem. 512w x 32b Program Sequencer Program Bus 32b DP3DP2DP1 DP0 Program Local ADD/SUB ALU Cache 512w x 16b Memory Cache 512w x 16b MemoryMemory 512w x 16b Cache Memory 512w x 16b Cache 512w x 16b Memory Work Address Generation Unit 4.4.6 NTT VSP The ntt vsp <ref> [79, 80] </ref> contains four pipelined data processing units (dpus) and three parallel i/o ports (Fig. 4.16). Communication among the dpus and four sets of cache memories occurs via eight 16b buses. The dpus are pipelined to five levels. <p> In order to illustrate this point we have tabulated several vsps <ref> [79, 107, 127] </ref> together with the paddi chip in Table 6.2. The actual chip areas are listed. They are also normalized to account for the difference in design rules. Two layers of metal were used in the fabrication of all these processors.
Reference: [80] <author> T. Minami, H. Yamaguchi, Y. Tashiro, R. Kasai, J. Takahasi, S. Hamaguchi, K. Endo, and T. Tajiri. </author> <title> "A 300 MOPS Video Signal Processor with a Parallel Architecture". </title> <journal> In Journal of Solid-State Circuits, </journal> <pages> pages 1868-1875, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: 16wx32b prog. mem. 512w x 32b Program Sequencer Program Bus 32b DP3DP2DP1 DP0 Program Local ADD/SUB ALU Cache 512w x 16b Memory Cache 512w x 16b MemoryMemory 512w x 16b Cache Memory 512w x 16b Cache 512w x 16b Memory Work Address Generation Unit 4.4.6 NTT VSP The ntt vsp <ref> [79, 80] </ref> contains four pipelined data processing units (dpus) and three parallel i/o ports (Fig. 4.16). Communication among the dpus and four sets of cache memories occurs via eight 16b buses. The dpus are pipelined to five levels.
Reference: [81] <author> R. Murgai, Y. Nishizaki, N. Shenoy, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> "Logic Synthesis for Programmable Gate Arrays". </title> <booktitle> 27th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 620-625, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Since many actual designs typically contain gates of this order of magnitude, fpgas have and will continue to be competitive with conventional gate-arrays for low to medium complexity designs. Active research is also currently being done in the field of logic synthesis for fpgas <ref> [81, 82, 39] </ref> and in incorporating them as hardware platforms into high level synthesis systems [132].
Reference: [82] <author> R. Murgai, N. Shenoy, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> "Improved Logic Synthesis for Table Look Up Architectures". </title> <booktitle> In IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pages 564-567, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Since many actual designs typically contain gates of this order of magnitude, fpgas have and will continue to be competitive with conventional gate-arrays for low to medium complexity designs. Active research is also currently being done in the field of logic synthesis for fpgas <ref> [81, 82, 39] </ref> and in incorporating them as hardware platforms into high level synthesis systems [132].
Reference: [83] <author> L. W. Nagel and et al. </author> <title> "Simulation Program With Integrated Circuit Emphasis (SPICE)". </title> <booktitle> 16th Midwest Symp. Circuit Theory, </booktitle> <month> Feb. </month> <year> 1985. </year>
Reference-contexts: The carry-select adder cells were obtained from the Lager cell library [64]. A micro-photograph of the chip is shown in Fig. 6.27. Simulation: Circuit and behavioral simulation were performed using spice <ref> [83] </ref> and irsim [105] respectively, and the pas assembler was used to generate simulation test vectors and chip configuration files.
Reference: [84] <author> R.O. Nielsen. </author> <title> In Sonar Signal Processing. </title> <publisher> Artech House Inc., </publisher> <year> 1991. </year>
Reference-contexts: Typical application domains include digital audio [75, 8], speech recognition and synthesis [10], mobile communications [44], personal communications systems [14, 47], robotics 1 CHAPTER 1. INTRODUCTION 2 and electro-mechanical control, digital image and video processing [43], machine vision [11], digital television [30], high definition television [56], sonar <ref> [84] </ref>, ultrasonic imaging, advanced video services [27], smart weapons, and advanced fire control for target discrimination and tracking [71, 76]. In signal processing applications, the computation involves a set of operations which operate on an infinite data stream (the signal).
Reference: [85] <author> Y. Ninomiya. </author> <title> "HDTV Broadcasting Systems". </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 15-22, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: Typical signal processing requirements are yuv and rgb conversions, digital filtering, video compression, motion compensation, and sampling conversion <ref> [85] </ref>. If one makes the reasonable assumption that any of these algorithms can require several tens of operations, then the resulting computational requirements are in the billions of (byte) operations per second (gops).
Reference: [86] <author> T.G. Noll and S. Meier. </author> <title> "A 40 MHz Programmable Semi-Systolic Transversal Filter". </title> <booktitle> In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 180-181, </pages> <month> Feb. </month> <year> 1987. </year>
Reference-contexts: Systolic architectures ( [62, 63]) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in <ref> [86, 55, 50] </ref>. Vector-pipelined architectures such as described in [123] (not classified in [15]) can achieve high throughput rates. However, due to the high branching penalty overhead associated with very deep pipelines, the use of conditional operations is very restricted.
Reference: [87] <author> S. Note, W. Geurts, F. Catthoor, and H. De Man. "Cathedral III: </author> <title> Architecture-Driven High-level Synthesis for High Throughput DSP Applications". </title> <booktitle> 28th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 597-602, </pages> <month> June </month> <year> 1991. </year> <note> BIBLIOGRAPHY 172 </note>
Reference-contexts: More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications. Examples of such systems are Lager IV [64] (actually more of a silicon compiler than a high level synthesis system), Cathedral-III <ref> [88, 87] </ref>, hyper [28, 99], and phideo [70]. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems [118, 113]. It extends the concepts of a vlsi silicon compiler to board level module generation.
Reference: [88] <author> S. Note, J. Van Meerbergen, F. Catthoor, and H. De Man. </author> <title> "Hardwired Data Path Synthesis For High Speed DSP Systems With The Cathedral III Compilation Environment". </title> <booktitle> In Logic and Architecture Synthesis for Silicon Compilers, </booktitle> <pages> pages 243-254. </pages> <publisher> Elsevier Science Publishers B.V. (North-Holland), </publisher> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: For higher resolution screens and/or more complicated algorithms, this can increase by one or two orders of magnitude. As an example, consider the conversion of rgb to yuv <ref> [88] </ref>. Video sources generate three color signals, red (R), green (G), and blue (B). The three color signals are oversampled to 27 MHz and converted to eight bits. These signals are often converted to luminance (Y), and two chrominance (U,V) signals for further processing. <p> These signals are often converted to luminance (Y), and two chrominance (U,V) signals for further processing. This conversion is done by a video matrix according to the following three equations: Y = 256 44 fl R 87 fl G + 131 fl B V = 256 In <ref> [88] </ref>, various hard-wired data paths were constructed in an attempt to meet the high throughput requirements. Pipelining was found necessary to meet the the clocking rate specification. Fig. 2.1 shows a possible data path to perform the luminance conversion. <p> However, one is still left with the time for fabrication and testing, and the still rather high nre costs associated with asic design and sophisticated cad tools. Early synthesis systems which target the generation of dedicated multi-processors have been reported in the Lager-I [101], and the Cathedral-II <ref> [100, 88] </ref>. More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications. <p> More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications. Examples of such systems are Lager IV [64] (actually more of a silicon compiler than a high level synthesis system), Cathedral-III <ref> [88, 87] </ref>, hyper [28, 99], and phideo [70]. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems [118, 113]. It extends the concepts of a vlsi silicon compiler to board level module generation. <p> The architecture can support non-recursive filters but recursive biquadratic filters are more interesting because their feedback structure puts more of a burden on the architecture. Filtering * a) biquad hardware multiplexed - direct-mapped pipelined [112, 92] Video and Low Level Image Processing * b) Video Matrix Converter <ref> [88] </ref> * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor [116, 115] * h) Grammar Processor [22] The basic features that must be supported by the architecture
Reference: [89] <author> S. Note, J.V. Meerbergen, F. Catthoor, and H. De Man. </author> <title> "Automated Synthesis of a High Speed CORDIC Algorithm With The CATHEDRAL-III Compilation System". </title> <booktitle> ISCAS, </booktitle> <pages> pages 581-584, </pages> <year> 1988. </year>
Reference-contexts: CHAPTER 7. PADDI: SOFTWARE ENVIRONMENT 124 In high level synthesis, basic interdependent tasks which must be done include translation of the high level language into an internal representation (typically some variation of a graph with control flow and data flow constructs), transformations (at all levels of the process) <ref> [124, 102, 89] </ref> scheduling, allocation, assignment, as described in [74] Various approaches differ in manner and the order in which these basic tasks are attacked. In one approach, scheduling, allocation and assignment are performed separately and in separate phases.
Reference: [90] <author> J. Ousterhout and et al. </author> <title> "The Magic VLSI Layout System". </title> <booktitle> IEEE Design & Test of Computers, </booktitle> <pages> pages 19-30, </pages> <month> Feb </month> <year> 1985. </year>
Reference-contexts: Fig. 6.26 shows how the clocks were routed from the input pads. Drivers were sized to maintain sharp edges. 6.7.1 Layout and Simulation Layout: Hand-crafted cells were laid out using the magic cad tool <ref> [90] </ref>. The carry-select adder cells were obtained from the Lager cell library [64]. A micro-photograph of the chip is shown in Fig. 6.27.
Reference: [91] <author> P. Hilfinger. </author> <title> "A High Level Language and Silicon Compiler for Digital Signal Processing". </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pages 240-243. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1985. </year>
Reference-contexts: We will examine the specific features of the architecture which will affect the quality of the compilation. The cad environment and software tools being developed for automatic compilation from a high level language <ref> [91] </ref> will be discussed. 7.2 Low-level Programming Tools The low-level programming tools, the pas assembler and psim simulator, provide the foundation for the higher-level synthesis tools. 122 CHAPTER 7. <p> This makes it easy to add new tools or to modify existing tools. An overview of the envisioned system is shown in Fig. 7.1. An automated compilation path from a high level data flow language silage <ref> [91] </ref> to the paddi chip, which includes partitioning, scheduling, and code generation is forseen. caddi will be similar to the approach [95] taken in hyper and will contain all steps required for compilation namely allocation, assignment, and scheduling modules, followed by translation into assembly language and ultimately into a configuration file. <p> An assembler and simulator have been developed to facilitate programming and testing of the chip. A software compilation path from the high level data flow language silage <ref> [91] </ref> to paddi is currently under development, and handles partitioning, scheduling, and code generation. A 16 exu (400 mips) processor is currently under design, together with a multi-chip module approach which could support up to 32 exus (800 mips) in a single package.
Reference: [92] <author> K.K. Parhi and D.G. Messerschmitt. </author> <title> "Pipeline Interleaving and Parallelism in Recursive Digital Filters, I and II". </title> <journal> IEEE Transactions on Speech and Signal Processing, </journal> <pages> pages 1099-1134, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Biquadratic filters were a simple and convenient benchmark with which to get started. The architecture can support non-recursive filters but recursive biquadratic filters are more interesting because their feedback structure puts more of a burden on the architecture. Filtering * a) biquad hardware multiplexed - direct-mapped pipelined <ref> [112, 92] </ref> Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor [116, 115] * h) <p> PADDI: ARCHITECTURAL DESIGN 66 IO Statistics The i/o statistics are shown in Figure 5.10. In this figure we see the inclusion of two versions of the biquadratic filter. The first assumes that the filter runs at 4 MHz. The second assumes that transformations are made (using techniques described in <ref> [112, 92] </ref>) to pipeline the filter to achieve a sampling rate of 24 MHz. Both assume that the filters are 16 bits. For the linear convolver and the non-linear sorting filter (examples c and d), we assume that the line delays exist external to the system. <p> The final number will be even greater due to interchip delays. Similar results are shown for case B where the coefficients are assumed to have 4 non-zero bits (after canonic-signed-digit transformations). If we apply transformations to pipeline case B (using techniques described in <ref> [112, 92] </ref>), the critical path will continue to be dominated by the 16-bit ripple delays of the adders. paddi delivers equal or superior minimum sampling intervals for similar hardware costs.
Reference: [93] <author> Y.N. Patt and J.K. Ahlstrom. </author> <title> "Microcode and the Protection of Intellectual Effort". </title> <booktitle> Proceedings of the 18th Annual Workshop on Microprogramming, </booktitle> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: Melvin observes that Patt and Ahlstrom argue that microcode should be considered hard ware if it provided by the manufacturer and software if it written by the user <ref> [93] </ref>. The apparent conflict is discussed by him and is resolved as follows: the idea of builder/user interface is used to describe software-configurability and is considered a separate concept from that of hsi. The author discusses several examples of dsi placement as shown in Fig. 5.1. CHAPTER 5.
Reference: [94] <institution> Plus Logic. FPGA2040, </institution> <year> 1989. </year>
Reference-contexts: In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx [52, 51, 130], Actel [4], Algotronix (Cal) [45], Plessey [46], att [48], and Plus Logic <ref> [94] </ref>. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect. It would be impractical and unnecessary to discuss all members of this class.
Reference: [95] <author> M. Potkonjak and J. Rabaey. </author> <title> "A Scheduling and Resource Allocation Algorithm for Hierarchical Signal Flow Graphs". </title> <booktitle> In Proceedings 26th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 7-12, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: An overview of the envisioned system is shown in Fig. 7.1. An automated compilation path from a high level data flow language silage [91] to the paddi chip, which includes partitioning, scheduling, and code generation is forseen. caddi will be similar to the approach <ref> [95] </ref> taken in hyper and will contain all steps required for compilation namely allocation, assignment, and scheduling modules, followed by translation into assembly language and ultimately into a configuration file. In hyper the synthesis procedure is implemented as a search process. <p> The allocation and assignment approach differs from the approach presented above in that a modification of the rejectionless antivoter assignment algorithm of <ref> [95] </ref> is envisioned. The rapid prototyping framework will allow the designer to experiment and analyze the speed vs. cost trade-off for various implementations as well as the effects of quantization and transformations on system performance. Initial results and the on-going investigation CHAPTER 7.
Reference: [96] <author> G. Quenot and B. Zavidovique. </author> <title> "A Data-Flow Processor for Real-Time Low-Level Image Processing.". </title> <booktitle> In Proc. CICC'91: 1990 Custom Integrated Circuits Conference, </booktitle> <address> page 12.4, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: [127], a four processor building block for simd image processing arrays is reported in [35], a data-driven video signal array processor is reported in [107, 108, 109], a 300 mops video signal processor is reported in [79], and a data-flow processor for real-time low level image processing is reported in <ref> [96] </ref>. Over forty image processing lsis made in Japan in the 1980's are surveyed in [41] There are too many of these processors to describe all of them, so we will restrict our discussion to a few representative specimens. CHAPTER 4.
Reference: [97] <author> J. Rabaey, R. Brodersen, A. Stolzle, S. Narayanaswamy, D. Chen, R. Yu, P. Schrupp, H. Murveit, and A. Santos. </author> <title> "A Large Vocabulary Real Time Continuous Speech Recognition System". </title> <booktitle> In VLSI Signal Processing III, </booktitle> <pages> pages 61-74. </pages> <publisher> IEEE Press, </publisher> <year> 1988. </year>
Reference-contexts: HIGH SPEED DIGITAL SIGNAL PROCESSING 9 tion system described in <ref> [97] </ref> is another example. The word processing sub-system performs a Viterbi search over 50,000 states and computes 225 Mops/sec with 85 MB/sec of memory accesses [116]. Speech recognition accuracy is further enhanced when syntactic constraints are imposed on the concatenation of individual words in the vocabulary.
Reference: [98] <author> J. Rabaey and M. Potkonjak. </author> <title> "Resource Driven Synthesis in the HYPER System". </title> <address> ISCAS, </address> <year> 1990. </year> <note> BIBLIOGRAPHY 173 </note>
Reference-contexts: The disadvantage of the approach is that it could yield sub-optimal results since decisions chosen in one phase can have significant negative impact on the results obtained in another. In another approach, for example the approach taken in hyper <ref> [98, 99] </ref>, a global optimization routine simultaneously takes into consideration all these tasks. Here the problem is harder than the previous one.. A decision was made to adopt this type of approach mainly because of the availability of the installed hyper software base, and the potential for superior results.
Reference: [99] <author> J.M. Rabaey, C. Chu, P. Hoang, and M. Potkonjak. </author> <title> "Fast Prototyping of Datapath-Intensive Architectures". </title> <booktitle> IEEE Design & Test of Computers, </booktitle> <pages> pages 40-51, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications. Examples of such systems are Lager IV [64] (actually more of a silicon compiler than a high level synthesis system), Cathedral-III [88, 87], hyper <ref> [28, 99] </ref>, and phideo [70]. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems [118, 113]. It extends the concepts of a vlsi silicon compiler to board level module generation. <p> The disadvantage of the approach is that it could yield sub-optimal results since decisions chosen in one phase can have significant negative impact on the results obtained in another. In another approach, for example the approach taken in hyper <ref> [98, 99] </ref>, a global optimization routine simultaneously takes into consideration all these tasks. Here the problem is harder than the previous one.. A decision was made to adopt this type of approach mainly because of the availability of the installed hyper software base, and the potential for superior results.
Reference: [100] <author> J.M. Rabaey, H. De Man, J. Vannhoof, G. Goosens, and F. Catthoor. "CATHEDRAL-II: </author> <title> A Synthesis System for Multiprocessor DSP Systems". </title> <publisher> Addison Wesley, </publisher> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: However, one is still left with the time for fabrication and testing, and the still rather high nre costs associated with asic design and sophisticated cad tools. Early synthesis systems which target the generation of dedicated multi-processors have been reported in the Lager-I [101], and the Cathedral-II <ref> [100, 88] </ref>. More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications.
Reference: [101] <author> J.M. Rabaey, S. Pope, and R. Brodersen. </author> <title> "An Integrated Automatic Layout System for Multiprocessor DSP Systems". </title> <journal> IEEE Transactions on Computer Aided Design, </journal> <volume> CAD-4:285-296, </volume> <month> July. </month> <year> 1985. </year>
Reference-contexts: However, one is still left with the time for fabrication and testing, and the still rather high nre costs associated with asic design and sophisticated cad tools. Early synthesis systems which target the generation of dedicated multi-processors have been reported in the Lager-I <ref> [101] </ref>, and the Cathedral-II [100, 88]. More recent synthesis systems target the generation of dedicated data paths in order to achieve the much higher throughput demanded by real-time applications.
Reference: [102] <author> M. Roberts. </author> <title> "Optimizing Compilers". </title> <journal> BYTE Magazine, </journal> <pages> pages 165-170, </pages> <year> 1987. </year>
Reference-contexts: CHAPTER 7. PADDI: SOFTWARE ENVIRONMENT 124 In high level synthesis, basic interdependent tasks which must be done include translation of the high level language into an internal representation (typically some variation of a graph with control flow and data flow constructs), transformations (at all levels of the process) <ref> [124, 102, 89] </ref> scheduling, allocation, assignment, as described in [74] Various approaches differ in manner and the order in which these basic tasks are attacked. In one approach, scheduling, allocation and assignment are performed separately and in separate phases.
Reference: [103] <author> P. Ruetz and R. Brodersen. </author> <title> "A Realtime Image Processing Chip Set". </title> <booktitle> In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 148-149, </pages> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: The computational requirements of low level image processing are quite high, especially if done in real-time. The motivations of performing the processing in real-time are discussed in [104]. CHAPTER 2. HIGH SPEED DIGITAL SIGNAL PROCESSING 7 A real-time image processing chip set is described in <ref> [104, 103] </ref>. The functions performed by these chips are 3x3 convolution, 7x7 logical convolution, 3x3 non-linear filtering based on sorting, image contour extraction, feature extraction, and line delays. Chips of these types are in commercial production [72]. As an example, consider the 3x3 linear convolver. <p> It is the 3 x 3 linear convolver of Fig. 2.3 of Section 2.3. The coefficients. are powers-of-two and so the multiplications can be implemented as shifts and adds. This convolver is used in low level image processing <ref> [103] </ref> to implement various filtering operations. After retiming [68], the signal flow diagram of Fig. B.1 results. Fig. B.2 and Fig. B.3 show how this can be mapped to two chips (excluding the line delays). (Note also that the pads of each chip are pipelined).
Reference: [104] <author> P. A. Ruetz. </author> <title> "Architectures And Design Techniques For Real-Time Image Processing ICs". </title> <type> Technical Report Memo. </type> <institution> No. UCB/ERL M86/37, U.C. Berkeley, </institution> <year> 1986. </year>
Reference-contexts: The computational requirements of low level image processing are quite high, especially if done in real-time. The motivations of performing the processing in real-time are discussed in <ref> [104] </ref>. CHAPTER 2. HIGH SPEED DIGITAL SIGNAL PROCESSING 7 A real-time image processing chip set is described in [104, 103]. The functions performed by these chips are 3x3 convolution, 7x7 logical convolution, 3x3 non-linear filtering based on sorting, image contour extraction, feature extraction, and line delays. <p> The computational requirements of low level image processing are quite high, especially if done in real-time. The motivations of performing the processing in real-time are discussed in [104]. CHAPTER 2. HIGH SPEED DIGITAL SIGNAL PROCESSING 7 A real-time image processing chip set is described in <ref> [104, 103] </ref>. The functions performed by these chips are 3x3 convolution, 7x7 logical convolution, 3x3 non-linear filtering based on sorting, image contour extraction, feature extraction, and line delays. Chips of these types are in commercial production [72]. As an example, consider the 3x3 linear convolver. <p> The control logic requirements are minimal because of the highly pipelined nature of the design. The data i/o streams are 8b wide and require 20 MB/sec of i/o bandwidth excluding any synchronization signals. (The actual architecture used in <ref> [104] </ref> was a pipelined data path composed of multiply accumulate units with a somewhat different topology than the sfg). 2.4 Speech Recognition The computational requirements of speech recognition will vary depending on the type of recognition being performed (isolated word vs. connected speech), whether it is speaker dependent or independent, the <p> Filtering * a) biquad hardware multiplexed - direct-mapped pipelined [112, 92] Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver <ref> [104] </ref> * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor [116, 115] * h) Grammar Processor [22] The basic features that must be supported by the architecture were listed in Sec tion 4.4.9. <p> Filtering * a) biquad hardware multiplexed - direct-mapped pipelined [112, 92] Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver <ref> [104] </ref> * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor [116, 115] * h) Grammar Processor [22] The basic features that must be supported by the architecture were listed in Sec tion 4.4.9. These were: CHAPTER 5.
Reference: [105] <author> A. Salz and M. Horowitz. "IRSIM: </author> <title> An Incremental MOS Switch-Level Simulator". </title> <booktitle> In Proceedings 26th ACM/IEEE Design Automaton Conference, </booktitle> <pages> pages 173-178, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The carry-select adder cells were obtained from the Lager cell library [64]. A micro-photograph of the chip is shown in Fig. 6.27. Simulation: Circuit and behavioral simulation were performed using spice [83] and irsim <ref> [105] </ref> respectively, and the pas assembler was used to generate simulation test vectors and chip configuration files.
Reference: [106] <author> R. Schmidt. </author> <title> "A Memory Control Chip for Formatting Data into Blocks Suitable for Video Coding Applications". </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <pages> pages 249-258, </pages> <month> Oct. </month> <year> 1989. </year>
Reference-contexts: Therefore 213 MB/sec of i/o bandwidth are required for the rgb and yuv signals, excluding and synchronization signals. Flexible memory address generators are also required in video processing. A flexible memory control chip for formatting data into blocks suitable for video coding applications is described in <ref> [106] </ref>. <p> Filtering * a) biquad hardware multiplexed - direct-mapped pipelined [112, 92] Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding <ref> [106] </ref> Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor [116, 115] * h) Grammar Processor [22] The basic features that must be supported by the architecture were listed in Sec tion 4.4.9. These were: CHAPTER 5.
Reference: [107] <author> U. Schmidt. </author> <title> "Data Wave a Data Driven Video Signal Array Processor". In Hot Chips II : A Symposium on High Performance Chips, </title> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: Many of these circuits are user-configurable, and their number keeps increasing every year. For example: a general purpose vsp is reported in [127], a four processor building block for simd image processing arrays is reported in [35], a data-driven video signal array processor is reported in <ref> [107, 108, 109] </ref>, a 300 mops video signal processor is reported in [79], and a data-flow processor for real-time low level image processing is reported in [96]. <p> A fixed word width narrows its applicability to certain video applications. Its deep ale pipelines are not well suited to efficient calculation of recursive loops and conditional branch type instructions. ITT DataWave The itt DataWave is a so called "Wavefront Array Processor for Video Applications" <ref> [107, 108, 109] </ref>. The processor topology is an array of 16 individually programmable mesh-connected cells (Fig. 4.14). The processor executes statically scheduled data flow programs, propagating data through the array in a wavefront-like manner. <p> In order to illustrate this point we have tabulated several vsps <ref> [79, 107, 127] </ref> together with the paddi chip in Table 6.2. The actual chip areas are listed. They are also normalized to account for the difference in design rules. Two layers of metal were used in the fabrication of all these processors. <p> CHAPTER 8. CONCLUSIONS AND FUTURE WORK 134 We expect to see many novel multiprocessor architectures for digital signal processing. Accompanying innovations will be required in the software arena to fully exploit the power of these architectures. Investigations into this domain, such as here and in <ref> [127, 35, 34, 107, 6] </ref>, have begun, and will continue to expand. For example star Semiconductor has recently introduced a complete development system, the Sproclab. It uses the sproc1400 processor which contains four general signal processors with on-board shared memory and serial and parallel i/o [114, 19].
Reference: [108] <author> U. Schmidt and S. Mehgardt. </author> <title> "Wavefront Array Processor for Video Applications". </title> <booktitle> In ICCD, </booktitle> <year> 1990. </year>
Reference-contexts: Many of these circuits are user-configurable, and their number keeps increasing every year. For example: a general purpose vsp is reported in [127], a four processor building block for simd image processing arrays is reported in [35], a data-driven video signal array processor is reported in <ref> [107, 108, 109] </ref>, a 300 mops video signal processor is reported in [79], and a data-flow processor for real-time low level image processing is reported in [96]. <p> A fixed word width narrows its applicability to certain video applications. Its deep ale pipelines are not well suited to efficient calculation of recursive loops and conditional branch type instructions. ITT DataWave The itt DataWave is a so called "Wavefront Array Processor for Video Applications" <ref> [107, 108, 109] </ref>. The processor topology is an array of 16 individually programmable mesh-connected cells (Fig. 4.14). The processor executes statically scheduled data flow programs, propagating data through the array in a wavefront-like manner.
Reference: [109] <author> U. Schmidt, S. Mehgardt, K. Caesar, T. Himel, and S. Mehgardt. </author> <title> "Data-controlled array processor for video signal processing". </title> <booktitle> In Electronik, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Many of these circuits are user-configurable, and their number keeps increasing every year. For example: a general purpose vsp is reported in [127], a four processor building block for simd image processing arrays is reported in [35], a data-driven video signal array processor is reported in <ref> [107, 108, 109] </ref>, a 300 mops video signal processor is reported in [79], and a data-flow processor for real-time low level image processing is reported in [96]. <p> A fixed word width narrows its applicability to certain video applications. Its deep ale pipelines are not well suited to efficient calculation of recursive loops and conditional branch type instructions. ITT DataWave The itt DataWave is a so called "Wavefront Array Processor for Video Applications" <ref> [107, 108, 109] </ref>. The processor topology is an array of 16 individually programmable mesh-connected cells (Fig. 4.14). The processor executes statically scheduled data flow programs, propagating data through the array in a wavefront-like manner.
Reference: [110] <author> C.L. Seitz. </author> <title> "Concurrent VLSI Architectures". </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 1247-1265, </pages> <month> Dec. </month> <year> 1984. </year> <note> BIBLIOGRAPHY 174 </note>
Reference-contexts: Loosely coupled systems also have functional unit replication. The connection between data processors and data memories is n-to-n, and there is an n-by-n connection between the data processors. A loosely coupled multiprocessor abstract machine is shown in Fig. 3.8. Another classification is contained in the paper by Seitz <ref> [110] </ref> which presents a useful taxonomy for concurrent vlsi architectures that adhere to a basic structural model CHAPTER 3.
Reference: [111] <author> D.B. Skillicorn. </author> <title> "A Taxonomy for Computer Architectures". </title> <booktitle> IEEE Computer, </booktitle> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: Another is that it allows useful performance models to be built and used. A good classification scheme should reveal why a particular architecture is likely to provide a performance improvement <ref> [111] </ref>. In this chapter we will investigate ways of differentiating between the many architectural styles found in dsp. In order to establish a framework we will first consider taxonomies for general purpose computer architectures. We will also consider more specialized ones for ic applications such as telecommunications and image processing. <p> The two most interesting types for achieving high performance through parallelism of operation are simd and mimd [117]. 3.2.2 Extensions to Flynn's Taxonomy Since Flynn's original work there have been many suggestions on how to modify and/or extend it. The work by Skillicorn <ref> [111] </ref> is one such example. The classification method is shown if Fig. 3.3. At the highest level, the model of computation is considered, for example, von Neumann, dataflow, and graph reduction models.
Reference: [112] <author> M. A. Soderstrand and B. Sinha. </author> <title> "Comparison of Three New Techniques For Pipelin-ing IIR Digital Filters". </title> <booktitle> In Asilomar Conference on Circuits and Systems, </booktitle> <pages> pages 439-443, </pages> <year> 1985. </year>
Reference-contexts: Biquadratic filters were a simple and convenient benchmark with which to get started. The architecture can support non-recursive filters but recursive biquadratic filters are more interesting because their feedback structure puts more of a burden on the architecture. Filtering * a) biquad hardware multiplexed - direct-mapped pipelined <ref> [112, 92] </ref> Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor [116, 115] * h) <p> PADDI: ARCHITECTURAL DESIGN 66 IO Statistics The i/o statistics are shown in Figure 5.10. In this figure we see the inclusion of two versions of the biquadratic filter. The first assumes that the filter runs at 4 MHz. The second assumes that transformations are made (using techniques described in <ref> [112, 92] </ref>) to pipeline the filter to achieve a sampling rate of 24 MHz. Both assume that the filters are 16 bits. For the linear convolver and the non-linear sorting filter (examples c and d), we assume that the line delays exist external to the system. <p> The final number will be even greater due to interchip delays. Similar results are shown for case B where the coefficients are assumed to have 4 non-zero bits (after canonic-signed-digit transformations). If we apply transformations to pipeline case B (using techniques described in <ref> [112, 92] </ref>), the critical path will continue to be dominated by the 16-bit ripple delays of the adders. paddi delivers equal or superior minimum sampling intervals for similar hardware costs.
Reference: [113] <author> M.B. Srivastava and R.W. Brodersen. </author> <title> "Rapid-Prototyping of Hardware and Software in a Unified Framework". </title> <booktitle> In ICCAD, </booktitle> <pages> pages 152-155, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Examples of such systems are Lager IV [64] (actually more of a silicon compiler than a high level synthesis system), Cathedral-III [88, 87], hyper [28, 99], and phideo [70]. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems <ref> [118, 113] </ref>. It extends the concepts of a vlsi silicon compiler to board level module generation. Board level components are produced using a mix of module generators and a module library.
Reference: [114] <author> Star Semiconductor. </author> <title> SPROC Signal Processor Data Book, </title> <year> 1991. </year>
Reference-contexts: For example star Semiconductor has recently introduced a complete development system, the Sproclab. It uses the sproc1400 processor which contains four general signal processors with on-board shared memory and serial and parallel i/o <ref> [114, 19] </ref>. The objective of this system is to provide better performance than single chip dsps, together with a rapid prototyping environment.
Reference: [115] <author> A. Stolzle. </author> <title> "A Real Time Large Vocabulary Speech Recognition System". </title> <type> PhD thesis, </type> <institution> University of California, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Recently, this system has been upgraded to handle 60,000 words in real-time with 30 accesses per state which require in excess of 600 MB/sec of i/o bandwidth <ref> [115] </ref>. In this system, 520 Mops/sec are required. Let us discuss the grammar processing sub-system in some more detail ( [22]). The statistical grammar model allows any word to follow any other word. <p> - direct-mapped pipelined [112, 92] Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor <ref> [116, 115] </ref> * h) Grammar Processor [22] The basic features that must be supported by the architecture were listed in Sec tion 4.4.9. These were: CHAPTER 5. <p> As mentioned in Chapter 2, this system has been upgraded to handle 60,000 words in real-time with 30 accesses per state which require in excess of 600 MB/sec of i/o bandwidth <ref> [115] </ref>. This upgraded system is labeled as g3. The grammar processor section of the Grammar Processing Sub-system is labeled as h1, and the total requirements of the grammar processing sub-system is labeled as h2.
Reference: [116] <author> A. Stolzle, S. Narayanaswamy, K.Kornegay, R. W. Brodersen, and J. Rabaey. </author> <title> "A VLSI Wordprocessing Subsystem for a Real Time Large Vocabulary Speech Recognition System". </title> <booktitle> In Proc. CICC'89: 1989 Custom Integrated Circuits Conference, </booktitle> <pages> pages 20.7.1-5, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: HIGH SPEED DIGITAL SIGNAL PROCESSING 9 tion system described in [97] is another example. The word processing sub-system performs a Viterbi search over 50,000 states and computes 225 Mops/sec with 85 MB/sec of memory accesses <ref> [116] </ref>. Speech recognition accuracy is further enhanced when syntactic constraints are imposed on the concatenation of individual words in the vocabulary. This task is performed in the grammar processing sub-system which searches for the most probable word sequence given transition probabilities in speech model supported. <p> - direct-mapped pipelined [112, 92] Video and Low Level Image Processing * b) Video Matrix Converter [88] * c) 3x3 Linear Convolver [104] * d) 3x3 Nonlinear Sorting Filter [104] * e) Memory Controller For Video Coding [106] Speech Recognition * f) Dynamic Time Warp [58] * g) Word Processor <ref> [116, 115] </ref> * h) Grammar Processor [22] The basic features that must be supported by the architecture were listed in Sec tion 4.4.9. These were: CHAPTER 5.
Reference: [117] <author> H.S. Stone, T.C. Chen, M.J. Flynn, S.H. Fuller, W. G. Lane, H.H. Loomis Jr., W.M. McKeeman, Kay.B. Magleby, R.E. Matick, </author> <title> and T.M. Whitney. </title> <booktitle> Parallel Computers, </booktitle> <pages> pages 321-323. </pages> <institution> Science Research Associates, </institution> <year> 1975. </year>
Reference-contexts: A simd computer is essentially a vector processor. A misd computer is generally unrealistic for parallel computation while a mimd computer is the most general. The two most interesting types for achieving high performance through parallelism of operation are simd and mimd <ref> [117] </ref>. 3.2.2 Extensions to Flynn's Taxonomy Since Flynn's original work there have been many suggestions on how to modify and/or extend it. The work by Skillicorn [111] is one such example. The classification method is shown if Fig. 3.3.
Reference: [118] <author> J.S. Sun, M.B. Srivastava, and R.W. Brodersen. "SIERA: </author> <title> A CAD Environment for Real-Time Systems". 3rd IEEE/ACM Physical Design Workshop on Module Generation and Silicon Compilation, </title> <month> May. </month> <year> 1991. </year>
Reference-contexts: Examples of such systems are Lager IV [64] (actually more of a silicon compiler than a high level synthesis system), Cathedral-III [88, 87], hyper [28, 99], and phideo [70]. 4.3.2 Systems: Board Level siera (Fig. 4.2) is an integrated cad environment for the behavioral and physical design of dedicated systems <ref> [118, 113] </ref>. It extends the concepts of a vlsi silicon compiler to board level module generation. Board level components are produced using a mix of module generators and a module library.
Reference: [119] <author> C. Sung, P. Sasaki, R. Leung, Y.M. Chu, K.M. Le, G.W. Conner, R.H. Lane, J.L. DeJong, and R. Cline. </author> <title> "A 76-MHz BiCMOS Programmable Logic Sequencer". </title> <journal> IEEE Journal of Solid State Circuits, </journal> <pages> pages 1287-1294, </pages> <month> Oct. </month> <year> 1989. </year>
Reference-contexts: Time per Cycle (T): The time required to perform a single machine cycle is determined by such factors as: Instruction access time: Global instructions are generated by a fast commercially available external programmable logic sequencer e.g. <ref> [17, 119] </ref> and broadcast to each exu. For the prototype chip these are three bits long. Instruction decode time: At configuration time, the local controller for each exu is serially configured each with its own unique set of instructions.
Reference: [120] <author> L. Synder. </author> <title> "Introduction to the Configurable Highly Parallel Computer". </title> <booktitle> Computer, </booktitle> <pages> pages 47-57, </pages> <month> Jan. </month> <year> 1982. </year>
Reference-contexts: Each case study contains some important lessons and clues to reveal in their approaches to architectural and hardware configurability. 4.4.1 Purdue CHiP Early proposals for configurable architectures can be found in <ref> [120] </ref>.
Reference: [121] <author> I. Tamitani, H. Harasaki, T. Nishitani, Y. Endo, M. Yanshina, and T. Enomoto. </author> <title> "A Real-Time Video Signal Processor Suitable for Motion Picture Coding Applications". </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <pages> pages 1259-1266, </pages> <month> Oct. </month> <year> 1989. </year> <note> BIBLIOGRAPHY 175 </note>
Reference-contexts: Examples of different video architectures are presented: a) systolic arrays b) wavefront arrays c) self-timed language-driven architectures [125]. Specific chips are discussed: a) the nec vspm system <ref> [121] </ref> b) the Matsushita ismp chip [73] c) the Philips vsp chip [127] The rough trade-offs of asynchronous vs synchronous schemes are mentioned. 3.2.5 Digital Signal Processors A general classification for dsp architectures, based on the control/arithmetic ratio, was suggested by Brodersen and Rabaey [15].
Reference: [122] <author> D.E. Thomas and E.D. Lagnese. </author> <title> "Architectural Partitioning for System Level Design". </title> <booktitle> In Proceedings 26th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 62-67, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Similar closeness measures for a different clustering scheme have been done in the aparty architectural partitioner used in a behavioral synthesis system under development at Carnegie Mellon University <ref> [122] </ref> Some rough scheduling might be necessary here in order to identify such operators. We will now discuss constraints particular to the paddi architecture. 1) Maximum number of available registers per exu: these will be incorporated into the closeness and cost functions.
Reference: [123] <author> M. Toyoukura, K. Okamoto, H. Kodama, A. Ohtani, T. Araki, and K. Aono. </author> <title> "A Video Signal Processor with a Vector-Pipeline Architecture". </title> <booktitle> In Proceedings International Solid State Circuit Conference, </booktitle> <pages> pages 72-73, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Systolic architectures ( [62, 63]) are generally restricted to algorithms which can be formulated in a regular fashion (such as filters). Examples of bit-serial, systolic, and semi-systolic programmable filters can be found in [86, 55, 50]. Vector-pipelined architectures such as described in <ref> [123] </ref> (not classified in [15]) can achieve high throughput rates. However, due to the high branching penalty overhead associated with very deep pipelines, the use of conditional operations is very restricted. There have been recent investigations to alleviate this overhead [33], but this is still in the research phase.
Reference: [124] <author> H. Trickey. "Flamel: </author> <title> A High-Level Hardware Compiler". </title> <journal> IEEE Transactions on Computer Aided Design, CAD-6:259-269, </journal> <volume> Mar.. </volume> <year> 1987. </year>
Reference-contexts: CHAPTER 7. PADDI: SOFTWARE ENVIRONMENT 124 In high level synthesis, basic interdependent tasks which must be done include translation of the high level language into an internal representation (typically some variation of a graph with control flow and data flow constructs), transformations (at all levels of the process) <ref> [124, 102, 89] </ref> scheduling, allocation, assignment, as described in [74] Various approaches differ in manner and the order in which these basic tasks are attacked. In one approach, scheduling, allocation and assignment are performed separately and in separate phases.
Reference: [125] <author> C. van Berkel, C. Niessen, M. Rem, and R.W.J. Saeijs. </author> <title> "VLSI Programming and Silicon Compilation". </title> <booktitle> In IEEE International Conference on Computer Design, </booktitle> <pages> pages 150-166, </pages> <year> 1988. </year>
Reference-contexts: Another interesting classification for real time video architectures is contained in [126], where the author attempts a functional classification based on processing properties, memory properties, communication properties, and control properties. Examples of different video architectures are presented: a) systolic arrays b) wavefront arrays c) self-timed language-driven architectures <ref> [125] </ref>.
Reference: [126] <author> A.H. van Roermund. </author> <title> "Architectures for Real-Time Video". </title> <editor> In E.F. Depreterre and A-J. van der Veens, editors, </editor> <booktitle> Algorithms and Parallel VLSI Architectures, </booktitle> <pages> pages 445-461. </pages> <address> Elsvier Science, </address> <year> 1991. </year> <note> Vol. A. </note>
Reference-contexts: Thirteen of these devices are listed. Four nnps are listed for tasks such as character, text, voice, and image recognition. Similar classes of image processing ics as above are produced elsewhere e.g. [72], to name just one. Another interesting classification for real time video architectures is contained in <ref> [126] </ref>, where the author attempts a functional classification based on processing properties, memory properties, communication properties, and control properties. Examples of different video architectures are presented: a) systolic arrays b) wavefront arrays c) self-timed language-driven architectures [125].
Reference: [127] <author> A.H. van Roermund, P.J. Snijder, H. Dijkstra, </author> <title> C.G. Hemeryck, C.M. Huzier, J.M.P. Schmitz, and R.J. Sluitjter. "A General Purpose Programmable Video Signal Processor". </title> <journal> IEEE Transactions on Consumer Electronics, </journal> <pages> pages 249-258, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Examples of different video architectures are presented: a) systolic arrays b) wavefront arrays c) self-timed language-driven architectures [125]. Specific chips are discussed: a) the nec vspm system [121] b) the Matsushita ismp chip [73] c) the Philips vsp chip <ref> [127] </ref> The rough trade-offs of asynchronous vs synchronous schemes are mentioned. 3.2.5 Digital Signal Processors A general classification for dsp architectures, based on the control/arithmetic ratio, was suggested by Brodersen and Rabaey [15]. <p> The control based nature of these architectures restricts the throughput range. In general, the performance of architectures with a restricted number of large granularity processing elements (as constrained by chip area say) can be improved by increasing the level of pipelining of the processors e.g <ref> [127] </ref>. However conditional operations will have severe overhead penalties due to the deep pipelines. <p> Many of these circuits are user-configurable, and their number keeps increasing every year. For example: a general purpose vsp is reported in <ref> [127] </ref>, a four processor building block for simd image processing arrays is reported in [35], a data-driven video signal array processor is reported in [107, 108, 109], a 300 mops video signal processor is reported in [79], and a data-flow processor for real-time low level image processing is reported in [96]. <p> CHAPTER 4. RAPID PROTOTYPING PLATFORMS 41 NetworkNetwork ToFrom Control Queue Input Buffer Template OutputSwitch Control Memory Control Input Interface Network Queue Input Register Switch Registers Output Units Arithmetic Switch Registers Input Philips VSP The Philips vsp chip targets real-time video signal processing <ref> [127] </ref>. Each chip contains three Arithmetic Logic Elements ales, and two Memory Elements mes, connected by a full crossbar switch (Fig. 4.12). Connections to the crossbar switch are made through so-called silos, which is a 32 word, two port ram which are used to provide algorithmic sample delays. <p> This provides one aspect of software-configurability i.e. the ability to change the contents of the control store with each CHAPTER 5. PADDI: ARCHITECTURAL DESIGN 77 new application and is similar to the approach taken in <ref> [127] </ref>. A control store with a finite set of instruction words, supports the execution of loops and hardware multiplexing. For speed considerations we aimed for single cycle execution of each instruction which led us to choose a horizontally encoded instruction word format. <p> In order to illustrate this point we have tabulated several vsps <ref> [79, 107, 127] </ref> together with the paddi chip in Table 6.2. The actual chip areas are listed. They are also normalized to account for the difference in design rules. Two layers of metal were used in the fabrication of all these processors. <p> CHAPTER 8. CONCLUSIONS AND FUTURE WORK 134 We expect to see many novel multiprocessor architectures for digital signal processing. Accompanying innovations will be required in the software arena to fully exploit the power of these architectures. Investigations into this domain, such as here and in <ref> [127, 35, 34, 107, 6] </ref>, have begun, and will continue to expand. For example star Semiconductor has recently introduced a complete development system, the Sproclab. It uses the sproc1400 processor which contains four general signal processors with on-board shared memory and serial and parallel i/o [114, 19]. <p> The XC4005 (14 x 14 clbs) is being sampled with the XC4010 (20 x 20) planned before going to 0.5 m technology. The difference in implementation technology will complicate the task of comparison. vsps <ref> [127] </ref> and commercial dsps are other programmable alternatives. In future comparisons, one must take into account the technology and architectural differences and also the on chip hardware multiplexing support of paddi which is not present in conventional fpgas. However, because of the features described above i.e. APPENDIX A. <p> As a further comparison, a Motorola dsp56000 can operate at 10.25 mips and has a data i/o bandwidth of 60 MByte/sec. vsps <ref> [127] </ref> can operate three 12-bit execution units at 27 MHz (81 mips) with a data i/o bandwidth of 405 MByte/sec, but typically operate at 13.5 MHz (40 mips) due to the latency of the long pipelines.
Reference: [128] <author> J. Wawrznyek. </author> <title> "A Reconfigurable Concurrent VLSI Architecture For Sound Synthesis". </title> <booktitle> In VLSI Signal Processing II, </booktitle> <pages> pages 385-396, </pages> <month> Nov. </month> <year> 1986. </year>
Reference-contexts: A main criterion for the interconnect network is that it be fast, with no latency. The main design choices left to us was whether to adopt hierarchical approaches as fat-trees [69, 68] and discretionary interconnection matrices as in <ref> [128] </ref>, or to adopt a full-crossbar. Full-crossbars are more expensive to implement than hierarchical ones, as the number of functional blocks grow. Ultimately, we adopted a combination of the hierarchical and cross-bar approaches. As mentioned previously each benchmark was analyzed for its communication and routing requirements.
Reference: [129] <author> A. Wolfe, M. Breternitz Jr., C. Stephens, A.L. Ling, D. B. Kirk, R. P. Bianchini Jr., and J. P. Shen. </author> <title> "The White Dwarf: A High-Performance Application-Specific Processor". </title> <booktitle> 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 212-222, </pages> <month> May. </month> <year> 1988. </year>
Reference-contexts: CHAPTER 4. RAPID PROTOTYPING PLATFORMS 36 RAM M SS M S M MEMORY INTERFACE EXTERNAL INTERFACE MEMORY ALU, DECODER REGISTER SEQUENCER MICROCONTROL MANAGER INTERRUPT INTERFACE INTERRUPT EXTERNAL ROM MANAGER ROM 4.4.3 CMU White Dwarf The cmu White Dwarf <ref> [129] </ref> was designed specifically to solve finite element algorithms and other algorithms employing similar sparse matrix techniques. It employs a wide instruction word architecture in which the application algorithm is directly implemented in microcode. An overview of the processor is given in Fig. 4.6.
Reference: [130] <author> Xilinx Corp. </author> <title> The Programmable Gate Array Data Book, </title> <year> 1989. </year>
Reference-contexts: With these devices, the chip count can be dramatically reduced. In recent years, the class of chips known as fpgas has seen rapid growth [40]. Examples are numerous and new ones are continually being reported. Among the many popular ones are: Xilinx <ref> [52, 51, 130] </ref>, Actel [4], Algotronix (Cal) [45], Plessey [46], att [48], and Plus Logic [94]. These devices are of similar architecture and granularity in that they all consist of some form of configurable logic block clb connected by some form of programmable interconnect.
Reference: [131] <author> A. Yeung and J.M. Rabaey. </author> <title> "A Reconfigurable Data-driven Multiprocessor IC for Rapid Prototyping of High Performance DSP Algorithms". In VLSI Signal Processing V. </title> <publisher> IEEE Press, </publisher> <month> Oct. </month> <year> 1992. </year> <note> submitted. </note>
Reference-contexts: An asynchronous approach would not suffer from clock skew problems, but would incur overhead to support the necessary handshaking protocols. Which of these various approaches might yield better results still remains to be answered and is the subject of active research (e.g. <ref> [131] </ref>). CHAPTER 5. PADDI: ARCHITECTURAL DESIGN 82 5.5.4 IO The key requirement for i/o is that there should be wide i/o bandwidth (hundreds of MB/sec). Wide i/o bandwidth mainly refers to the communication of the processors with the external world.
Reference: [132] <author> R. Yu and J. Rabaey. </author> <title> "Techniques for Very Fast System Prototyping". Eecs/erl research summary, </title> <institution> U.C. Berkeley, </institution> <year> 1990. </year>
Reference-contexts: Active research is also currently being done in the field of logic synthesis for fpgas [81, 82, 39] and in incorporating them as hardware platforms into high level synthesis systems <ref> [132] </ref>.
References-found: 129

