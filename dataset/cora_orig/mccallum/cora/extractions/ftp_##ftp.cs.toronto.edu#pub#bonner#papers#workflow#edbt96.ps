URL: ftp://ftp.cs.toronto.edu/pub/bonner/papers/workflow/edbt96.ps
Refering-URL: http://www.cs.toronto.edu/DB/people/bonner/papers.html
Root-URL: 
Email: bonner@db.toronto.edu  shrufi@db.toronto.edu  steve@genome.wi.mit.edu  
Phone: 1  2  
Title: LabFlow-1: a Database Benchmark for High-Throughput Workflow Management  
Author: Anthony Bonner Adel Shrufi Steve Rozen 
Web: http://www.cs.toronto.edu/~bonner/papers.html#workflow  
Date: March 25-29, 1996, Avignon,  
Note: Appears in Proceedings of the Fifth International Conference on Extending Database Technology (EDBT),  France, pages 463-478. Springer-Verlag, Lecture Notes in Computer Science, volume 1057. This and related papers are available at the following web page:  This work was supported by funds from the U.S. National Institutes of Health, National Center for Human Genome Research, grant number P50 HG00098, and from the U.S. Department of Energy under contract DE-FG02-95ER62101.  
Address: Canada  Cambridge, MA, USA  
Affiliation: University of Toronto, Department of Computer Science, Toronto, ON,  Whitehead/MIT, Center for Genome Research,  
Abstract: Workflow management is a ubiquitous task faced by many organizations, and entails the coordination of various activities. This coordination is increasingly carried out by software systems called work-flow management systems (WFMS). An important component of many WFMSs is a DBMS for keeping track of workflow activity. This DBMS maintains an audit trail, or event history, that records the results of each activity. Like other data, the event history can be indexed and queried, and views can be defined on top of it. In addition, a WFMS must accommodate frequent workflow changes, which result from a rapidly evolving business environment. Since the database schema depends on the work-flow, the DBMS must also support dynamic schema evolution. These requirements are especially challenging in high-throughput WFMSs|i:e:, systems for managing high-volume, mission-critical workflows. Unfortunately, existing database benchmarks do not capture the combination of flexibility and performance required by these systems. To address this issue, we have developed LabFlow-1, the first version of a benchmark that concisely captures the DBMS requirements of high-throughput WFMSs. LabFlow-1 is based on the data and workflow management needs of a large genome-mapping laboratory, and reflects their real-world experience. In addition, we use LabFlow-1 to test the usability and performance of two object storage managers. These tests revealed substantial differences between these two systems, and highlighted the critical importance of being able to control locality of reference to persistent data. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> T.L. Anderson, A.J. Berre, M. Mallison, H.H. Porter, and B. Schneider. </author> <title> The hy-permodel benchmark. </title> <booktitle> In Proceedings of the International Conference on Extending Database Technology (EDBT), </booktitle> <pages> pages 317-331, </pages> <address> Venice, Italy, </address> <month> March </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks <ref> [5, 4, 1] </ref> are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark [19] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS).
Reference: 2. <author> A. Bonner, A. Shrufi, and S. Rozen. LabFlow-1: </author> <title> a database benchmark for high-throughput workflow management. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1995. </year> <pages> 53 pages. </pages> <note> Available at http:// www.db.toronto.edu:8020/people/bonner/bonner.html. </note>
Reference-contexts: Due to space limitations, this paper can provide only an informal description of the benchmark. A detailed description can be found in <ref> [2] </ref>. Benchmark software is available at the following web site: ftp://db.toronto.edu/pub/bonner/papers/workflow/software/ 2 Workflow in LabFlow-1 As noted above, an important component of many workflow management systems is a DBMS for tracking workflow. This DBMS maintains an audit trail, or event history, that records the results of each activity. <p> Usually, the most recent version is of greatest interest to scientists, since it represents the most up-to-date results. LabBase uses special-purpose storage and access structures to rapidly retrieve most-recent results from the event history of each material <ref> [2] </ref>. Notice that as described above, the database schema depends on the work-flow. For each kind of workflow step, there is a class in the database, and for each measurement made by the step, the class has an attribute. Consequently, workflow changes are reflected in the database as schema changes. <p> Thus, the attributes (or type) of a material depend on the history of the material, as well as its class. This rather dynamic feature reflects the flexibility demanded by workflow management. These issues are addressed in <ref> [2] </ref>, where we introduce structures that allow the view to be defined independently of the workflow, so that the view definition does not have to be changed each time the workflow changes. 3 Benchmark Database Schema Like the OO1 benchmark [5] and the Sequoia 2000 benchmark [19], our benchmark is independent <p> As shown in Figure 1, the EER diagram has two levels (separated by a dashed line). The top level is abstract, and is a partial specification of an event-history model <ref> [2] </ref>. The second level is concrete, and represents the workflow in particular 7 laboratory projects. The top-level is the same for all laboratory projects, while the bottom level changes from project to project. <p> Each kind of material and step may also define its own attributes. The lower level of the EER diagram can be fleshed out in many different ways depending on the particular workflows being modeled. The benchmark provides a specific schema for this lower level <ref> [2] </ref>. It is a simplified version of schema used in production at the Genome Center. <p> We decided against this option because the resulting benchmark would be complex, hard to understand, and difficult to scale. Instead, our benchmark is based on a relatively simple workflow simulation <ref> [2] </ref>. This simulation models many of the important features encountered in real workflows at the Genome Center. For instance, the workflow has cycles, it has success and failure states, and it models multiple, co-operating production lines. <p> Hence, they are not shown in Table 1. However, the complete set of test results can be found in <ref> [2] </ref>. Since much of the subsequent discussion applies to both Texas.3 and Texas.4, we often refer simply to Texas and its variants, Texas+TC and Texas-mm, without using version numbers. <p> Therefore a critical objective of our benchmark is to shed light on similarities and differences of such functional and operational characteristics. The interested reader is referred to <ref> [2] </ref> for a discussion of the similarities and differences between ObjectStore and the Texas Storage System. We compare the two systems along several dimensions: concurrency control, class libraries, tuning options, and database administration. To summarize, our benchmark revealed significant differences among different storage managers and implementations of LabBase.
Reference: 3. <author> M.J. Carey, D.J. DeWitt, M.J. Franklin, et al. </author> <title> Shoring up persistent applications. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 383-394, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: 0.5X main-memory size, all six versions of the LabBase data server consume similar resources, except for database-file size, which is greater in the Texas versions than in the OStore3 3 Thus, when based on the ObjectStore storage manager, the LabBase server is what Carey et al. term a "client-level server" <ref> [3] </ref>. 12 Database Server Version Persistent Transient Intvl Resource OStore3 Texas.4 Texas.3+TC Texas.3 Ostore3-mm Texas.4-mm 0.5X elapsed sec 1,424 1,474 1,469 1,402 1,384 1,471 user cpu sec 1,381 1,452 1,449 1,385 1,364 1,450 sys cpu sec 16 6 7 6 5 6 majflt 329 571 468 397 463 683 size (MB)
Reference: 4. <author> M.J. Carey, D.J. DeWitt, and J.F. Naughton. </author> <title> The OO7 benchmark. </title> <type> Technical report, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> January </month> <year> 1994. </year> <note> Available at ftp://ftp.cs.wisc.edu/oo7/techreport.ps. </note>
Reference-contexts: Existing database benchmarks do not capture the above requirements. This should not be surprising, as it has been observed by researchers working on OODBMS benchmarks that advanced applications are too complex and diverse to be captured by a single benchmark <ref> [4, 6] </ref>. A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks [5, 4, 1] are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. <p> A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks <ref> [5, 4, 1] </ref> are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark [19] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS).
Reference: 5. <author> R.G.G. Cattell. </author> <title> An engineering database benchmark. </title> <booktitle> In [10], chapter 6, </booktitle> <pages> pages 247-281. </pages>
Reference-contexts: A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks <ref> [5, 4, 1] </ref> are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark [19] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS). <p> These issues are addressed in [2], where we introduce structures that allow the view to be defined independently of the workflow, so that the view definition does not have to be changed each time the workflow changes. 3 Benchmark Database Schema Like the OO1 benchmark <ref> [5] </ref> and the Sequoia 2000 benchmark [19], our benchmark is independent of the data model provided by the DBMS. We therefore describe the database schema abstractly, using an extended entity relationship (EER) diagram [20]. An EER diagram is an ER diagram extended with is-a links.
Reference: 6. <author> A. Chaudhri. </author> <title> An Annotated Bibliography of Benchmarks for Object Databases. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 24(1) </volume> <pages> 50-57, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Existing database benchmarks do not capture the above requirements. This should not be surprising, as it has been observed by researchers working on OODBMS benchmarks that advanced applications are too complex and diverse to be captured by a single benchmark <ref> [4, 6] </ref>. A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks [5, 4, 1] are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications.
Reference: 7. <institution> Communications of the ACM, </institution> <month> 34(11), November </month> <year> 1991. </year> <title> Special issue on the Human Genome Project. </title>
Reference-contexts: Note that each workflow may involve many transactions. High-throughput workflows are also characteristic of large genome laboratories, like the Whitehead Institute/MIT Center for Genome Research (hereafter called "the Genome Center"). Workflow management is needed to support the Genome Center's large-scale genome-mapping projects <ref> [7] </ref>. Because of automation in instrumentation, data capture and workflow management, transaction rates at the Genome Center have increased dramatically in the last three years, from processing under 1,000 queries and updates per day in 1992 [9], to over 15,000 on many days in 1995. <p> These rates are expected to increase by another order of magnitude in the near future if the Genome Center begins large scale sequencing of the Human genome <ref> [7] </ref>. Moreover, unlike the simple banking debit/credit transactions of some TPC benchmarks [17], these transactions involve complex queries, and updates to complex objects, such as arrays, sequences, and nested sets. In this paper, we take a first step towards measuring the performance of work-flow management systems.
Reference: 8. <author> D. Georgakopoulos, M. Hornick, and A. Sheth. </author> <title> An overview of workflow management: From process modeling to infrastructure for automation. </title> <journal> Journal on Distributed and Parallel Database Systems, </journal> <volume> 3(2) </volume> <pages> 119-153, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: 1 Introduction 1.1 Overview Workflow management is a ubiquitous task faced by many organizations in a wide range of industries, from banking and insurance, to telecommunications and manufacturing, to pharmaceuticals and health care (e:g:, <ref> [8, 14] </ref>). The task is to coordinate the various activities involved in running an enterprise. Increasingly, this coordination is carried out by a software system called a workflow management system (WFMS). <p> Workflow management is needed to maintain throughput and control quality. Much of the research on workflow management in computer science has focussed on developing extended transaction models for specifying dependencies between workflow activities, especially in a heterogeneous environment (e:g:, 2 <ref> [11, 8] </ref>). However, the performance of WFMSs has so far received little atten-tion. The need to study performance arises because commercial products cannot support applications with high-throughput workflows. As stated in [8], Commercial workflow management systems typically support no more than a few hundred workflows a day. <p> However, the performance of WFMSs has so far received little atten-tion. The need to study performance arises because commercial products cannot support applications with high-throughput workflows. As stated in <ref> [8] </ref>, Commercial workflow management systems typically support no more than a few hundred workflows a day. Some processes require handling a larger number of workflows; perhaps a number comparable to the number of transactions TP systems are capable of handling. <p> We note that many commercial laboratories are legally bound to record event histories. Salient examples include clinical drug trials and environmental testing. Dynamic Schema Evolution. A hallmark of modern workflow management is that workflows change frequently, in response to rapidly changing business needs and circumstances <ref> [8] </ref>. Typically, a workflow will acquire new activities and existing activities will evolve. In both cases, the changed workflow generates new kinds of information, which must be recorded in the database. This requires changes to the database schema, preferably while the workflow is in operation (so-called dynamic workflow modification).
Reference: 9. <author> Nathan Goodman. </author> <title> An object oriented DBMS war story: Developing a genome mapping database in C++. </title> <editor> In Won Kim, editor, </editor> <title> Modern Database Management: Object-Oriented and Multidatabase Technologies. </title> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: Workflow management is needed to support the Genome Center's large-scale genome-mapping projects [7]. Because of automation in instrumentation, data capture and workflow management, transaction rates at the Genome Center have increased dramatically in the last three years, from processing under 1,000 queries and updates per day in 1992 <ref> [9] </ref>, to over 15,000 on many days in 1995. Of course, peak rates can be much higher, with a rate of 22.5 updates and queries per second recently observed over a 5-minute period.
Reference: 10. <author> Jim Gray, </author> <title> editor. The Benchmark Handbook for Database and Transaction Processing Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference: 11. <author> M. Hsu, Ed. </author> <title> Special issue on workflow and extended transaction systems. </title> <journal> Bulletin of the Technical Committee on Data Engineering (IEEE Computer Society), </journal> <volume> 16(2), </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: Workflow management is needed to maintain throughput and control quality. Much of the research on workflow management in computer science has focussed on developing extended transaction models for specifying dependencies between workflow activities, especially in a heterogeneous environment (e:g:, 2 <ref> [11, 8] </ref>). However, the performance of WFMSs has so far received little atten-tion. The need to study performance arises because commercial products cannot support applications with high-throughput workflows. As stated in [8], Commercial workflow management systems typically support no more than a few hundred workflows a day.
Reference: 12. <author> Setrag Khoshafian and Marek Buckiewicz. </author> <title> Introduction to Groupware, Workflow, and Workgroup Computing. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1995. </year>
Reference-contexts: LabFlow-1 is a benchmark that concisely describes the database requirements of a WFMS in a high-throughput genome laboratory. Although it is based on genome-laboratory workflow, we believe that LabFlow-1 captures the database requirements of a common class workflow management applications: those that require a production workflow system <ref> [12] </ref>. In production workflow, activities are organized into a kind of production line, involving a mix of human and computer activities. Examples in business include insurance-claim or loan-application processing.
Reference: 13. <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The ObjectStore database system. </title> <journal> Communications of the ACM, </journal> <volume> 34(10) </volume> <pages> 50-63, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Although LabFlow-1 is intended to be a general benchmark for DBMSs, this paper uses it to compare storage managers only. This is achieved by running the benchmark on versions of LabBase implemented on top of different storage managers, as described above. This paper compares ObjectStore (version 3.0) <ref> [13] </ref>. and Texas (versions 0.4 and 0.3) [18]. Compared to relational systems, these storage managers have been used in few production applications, so this analysis is interesting in its own right. <p> In the tests discussed here, we used several versions of the LabBase data server, which varied in storage management. The versions that we tested are: 1. OStore3|a version relying on ObjectStore (v3.0) <ref> [13] </ref> for storage manage ment. 2. Texas.3|a version relying on the Texas storage manager (v0.3) [18] for stor age management. 3. Texas.4|a version relying on the latest release (v0.4) of the Texas storage manager. 4.
Reference: 14. <author> Allen S. Nakagawa. LIMS: </author> <title> Implementation and Management. </title> <institution> Royal Society of Chemistry, Thomas Granham House, The Science Park, </institution> <address> Cambridge CB4 4WF, England, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction 1.1 Overview Workflow management is a ubiquitous task faced by many organizations in a wide range of industries, from banking and insurance, to telecommunications and manufacturing, to pharmaceuticals and health care (e:g:, <ref> [8, 14] </ref>). The task is to coordinate the various activities involved in running an enterprise. Increasingly, this coordination is carried out by a software system called a workflow management system (WFMS). <p> Examples of central materials include insurance claims, loan applications, and laboratory samples. As a central material is processed, workflow activities gather information about it. Production workflow systems include the class of Laboratory Information Management Systems, or LIMS (e:g:, <ref> [14] </ref>). LIMS are found in analytical laboratories in a wide range of industries, including pharmaceuticals, health care, environmental monitoring, food and drug testing, and water and soil management.
Reference: 15. <author> P. O'Neal. </author> <title> The set query benchmark. </title> <booktitle> In [10], chapter 5, </booktitle> <pages> pages 209-245. </pages>
Reference-contexts: In contrast, the SEQUOIA 2000 benchmark [19] is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS). The Set Query benchmark <ref> [15] </ref> is concerned with queries for decision support, including aggregation, multiple joins and report generation. (Such queries also arise in workflow management|for process re-engineering|but they are only part of the story.) Like these benchmarks, LabFlow-1 specifically targets a broad application area: workflow management.
Reference: 16. <author> Steve Rozen, Lincoln Stein, and Nathan Goodman. </author> <title> Constructing a domain-specific DBMS using a persistent object system. In M.P. </title> <editor> Atkinson, V. Benzaken, and D. Maier, editors, </editor> <booktitle> Persistent Object Systems, Workshops in Computing. </booktitle> <publisher> Springer-Verlag and British Computer Society, </publisher> <year> 1995. </year> <note> Presented at POS-VI, Sep. 1994. Available at ftp://genome.wi.mit.edu/pub/papers/Y1994/labbase-design.ps.Z. </note>
Reference-contexts: Fortunately, one can build a specialized DBMS that supports workflow on top of a storage manager that does not. This approach is taken at the Genome Center. Their specialized DBMS|called LabBase <ref> [16] </ref>| provides the needed support for event histories and schema evolution on top of 4 an object storage manager. LabBase provides a historical query language, as well as structures for rapid access into history lists.
Reference: 17. <author> O. </author> <title> Serlin. The history of debit credit and the TPC. </title> <booktitle> In [10], chapter 2, </booktitle> <pages> pages 19-117. </pages>
Reference-contexts: These rates are expected to increase by another order of magnitude in the near future if the Genome Center begins large scale sequencing of the Human genome [7]. Moreover, unlike the simple banking debit/credit transactions of some TPC benchmarks <ref> [17] </ref>, these transactions involve complex queries, and updates to complex objects, such as arrays, sequences, and nested sets. In this paper, we take a first step towards measuring the performance of work-flow management systems.
Reference: 18. <author> Vivek Singhal, Sheetal V. Kakkad, and Paul R. Wilson. </author> <title> Texas: an efficient, portable persistent store. </title> <booktitle> In Proceedings of the Fifth International Workshop on Persistent Object Systems (POS-V), </booktitle> <address> San Minato, Italy, </address> <month> September </month> <year> 1992. </year> <note> Available at ftp://cs.utexas.edu/pub/garbage/texaspstore.ps. </note>
Reference-contexts: This is achieved by running the benchmark on versions of LabBase implemented on top of different storage managers, as described above. This paper compares ObjectStore (version 3.0) [13]. and Texas (versions 0.4 and 0.3) <ref> [18] </ref>. Compared to relational systems, these storage managers have been used in few production applications, so this analysis is interesting in its own right. <p> In the tests discussed here, we used several versions of the LabBase data server, which varied in storage management. The versions that we tested are: 1. OStore3|a version relying on ObjectStore (v3.0) [13] for storage manage ment. 2. Texas.3|a version relying on the Texas storage manager (v0.3) <ref> [18] </ref> for stor age management. 3. Texas.4|a version relying on the latest release (v0.4) of the Texas storage manager. 4. Texas.3+TC and Texas.4+TC| versions almost identical to Texas.3 and Texas.4 respectively, which use the same storage manager, but with addi tional object clustering implemented in client code. 5. <p> The involves relation is implemented by keeping a (C++) pointer from each material instance to a list of pointers to those step instances that are related to the material by involves. ObjectStore and Texas also both rely on pointer swizzling at page-fault time, as described in <ref> [18] </ref>. However, internally they are rather different. ObjectStore offers concurrent access with lock-based concurrency control implemented in a page server that mediates all access to the database. 3 Texas does not support concurrent access, and Texas programs access their database files directly.
Reference: 19. <author> M. Stonebraker, J. Frew, K. Gardels, and J. Meredith. </author> <title> The Sequoia 2000 storage benchmark. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 2-11, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1993. </year> <month> 16 </month>
Reference-contexts: A quick glance at several recent benchmarks illustrates their diversity of characteristics and requirements. For instance, the OO1, OO7 and HyperModel benchmarks [5, 4, 1] are concerned with the traversal of large graphs, which is a requirement of engineering and hypertext applications. In contrast, the SEQUOIA 2000 benchmark <ref> [19] </ref> is concerned with the manipulation of large sets of spatial and image data, such as those found in geographic information systems (GIS). <p> issues are addressed in [2], where we introduce structures that allow the view to be defined independently of the workflow, so that the view definition does not have to be changed each time the workflow changes. 3 Benchmark Database Schema Like the OO1 benchmark [5] and the Sequoia 2000 benchmark <ref> [19] </ref>, our benchmark is independent of the data model provided by the DBMS. We therefore describe the database schema abstractly, using an extended entity relationship (EER) diagram [20]. An EER diagram is an ER diagram extended with is-a links.
Reference: 20. <author> T.J. Teorey, D. Yang, and J.P. Fry. </author> <title> A logical design methodology for relational databases using the extended entity-relationship model. </title> <journal> ACM Computing Surveys, </journal> <volume> 18 </volume> <pages> 197-222, </pages> <month> June </month> <year> 1986. </year> <title> This article was processed using the L a T E X macro package with LLNCS style 17 </title>
Reference-contexts: We therefore describe the database schema abstractly, using an extended entity relationship (EER) diagram <ref> [20] </ref>. An EER diagram is an ER diagram extended with is-a links. The database itself can be implemented in any number of ways, possibly as a relational database or as an object-oriented database. As shown in Figure 1, the EER diagram has two levels (separated by a dashed line).
References-found: 20

