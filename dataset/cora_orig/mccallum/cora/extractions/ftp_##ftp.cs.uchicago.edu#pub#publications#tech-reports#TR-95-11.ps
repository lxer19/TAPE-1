URL: ftp://ftp.cs.uchicago.edu/pub/publications/tech-reports/TR-95-11.ps
Refering-URL: http://cs-www.uchicago.edu/publications/tech-reports/
Root-URL: 
Title: Distinguishing Complexity and Symmetry of Information  
Author: Harry Buhrman Lance Fortnow 
Date: November 6, 1995  
Address: 1090 GB Amsterdam The Netherlands  1100 E. 58th St. Chicago, IL 60637  
Affiliation: CWI  University of Chicago Department of Computer Science  
Abstract: We describe how to use polynomial-time Kolmogorov distinguishing complexity to give an approximate measure of the size of sets. For any set S, we show that relative to S the polynomial time distinguishing complexity of every element of length n of S is bounded by 2 log jjS =n jj + O(log n). This lemma enables us to give a characterization of sparse sets using distinguishing complexity. We use this new lemma as a catalyst to study symmetry of information for polynomial-time distinguishing complexity. Longpre and Mocas and Longpre and Watanabe showed that if certain one-way functions exist then symmetry of information fails for the standard polynomial-time Kolmogorov complexity. We try to recover symmetry of information by studying Kolmogorov distinguishing complexity using our new approximating measure idea to avoid the problems with one-way functions and indexing of strings in (small) sets. We show problems with even formalizing the symmetry of information question for polynomial-time deterministic distinguishing complexity. Nondeterministic distinguishing complexity gives us more hope but we show that symmetry of information still seems unlikely due to the apparent inability of nondeterminism to approximately count. 
Abstract-found: 1
Intro-found: 1
Reference: [BDG88] <author> J. Balcazar, J. Daz, and J. Gabarro. </author> <title> Structural Complexity I. </title> <publisher> Springer, </publisher> <year> 1988. </year>
Reference-contexts: We then use these ideas to create a relativized world where nondeterministic distinguishing complexity fails. 2 Preliminaries We use basic concepts and notation from computational complexity theory texts like Balcazar, Daz and Gabarro <ref> [BDG88] </ref> and Kolmogorov complexity from the excellent book by Li and Vitanyi [LV93]. We use jxj to represent the length of a string x and jjAjj to represent the number of elements in the set A.
Reference: [FK95] <author> L. Fortnow and M. Kummer. </author> <title> Resource-bounded instance complexity. </title> <note> Theoretical Computer Science A, 1995. To appear. </note>
Reference-contexts: In distinguishing complexity we look at the smallest program that distinguishes the string from all others. Sipser [Sip83] used distinguishing complexity to help understand the computational complexity of randomized classes. More recently, distinguishing complexity has played an important role in resource-bounded instance complexity <ref> [FK95] </ref> and the complexity of small subsets of easily computable sets [For96]. To help us deal with the difficulties in symmetry of information inherent in these one-way functions we discover a powerful new lemma that approximately measures the sizes of sets using distinguishing complexity.
Reference: [For96] <author> L. Fortnow. </author> <title> Easy sets without easy small subsets. </title> <booktitle> In Proceedings of the 13th Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Sipser [Sip83] used distinguishing complexity to help understand the computational complexity of randomized classes. More recently, distinguishing complexity has played an important role in resource-bounded instance complexity [FK95] and the complexity of small subsets of easily computable sets <ref> [For96] </ref>. To help us deal with the difficulties in symmetry of information inherent in these one-way functions we discover a powerful new lemma that approximately measures the sizes of sets using distinguishing complexity. <p> Note that by the pigeonhole principle for any set S of strings of length n there exists some string in S with distinguishing complexity at least log jjSjj. This result improves earlier work by Sipser [Sip83] and Fortnow <ref> [For96] </ref>. Our proof uses polynomials over small finite fields to distinguish the strings. We can also use this lemma to characterize sparse sets. A polynomial-time computable set S is sparse if and only if every element in S has O (log n) polynomial-time distinguishing complexity. <p> For deterministic distinguishing complexity we run into other problems. We show that even formulating the symmetry of information question seems difficult for distinguishing complexity because concepts like conditional distinguishing complexity may not have the nice properties that we would expect. Instead we examine nondeterministic distinguishing complexity <ref> [For96] </ref> where we allow a nondeterministic machine to distinguish a particular string. Nondeterministic distinguishing complexity gives us a robust characterization of the symmetry of information question as well as defeating any problems with one-way one-one functions. <p> We can get around these definitional problems by looking at a nondeterministic variant of CD t complexity. Fix a universal nondeterministic Turing machine U n . Fortnow <ref> [For96] </ref> defined the nondeterministic distinguishing complexity CND t by CND t (xjy) = min 8 : (1) U n (p; x; y) accepts. jpj : (2) U n (p; z; y) rejects for all z 6= x. (3) U n (p; z; y) runs in at most t (jzj + jyj) <p> This result can be seen as a derandomized version of Sipser [Sip83] and improves the bound in Fortnow <ref> [For96] </ref>. Lemma 3.1 Let A be any set, such that jjA =n jj = d. For all strings x 2 A =n it holds that CD p;A =n (x) 2 log (d) + 2 log (n) + O (1) for some polynomial p.
Reference: [LM93] <author> L. Longpre and S. Mocas. </author> <title> Symmetry of information and one-way functions. </title> <journal> Information Processing Letters, </journal> <volume> 46(2) </volume> <pages> 95-100, </pages> <year> 1993. </year>
Reference-contexts: In particular, we would like to require that we have "efficient" access to information in a string, i.e. computation bounded by a polynomial in the length of the string whose information we are concerned about. Longpre and Mocas <ref> [LM93] </ref> and Longpre and Watanabe [LW95] have examined symmetry of information for resource-bounded Kolmogorov complexity. They show among other results that if certain kinds of one-way functions exist then symmetry of information fails in the polynomial-time case. fl E-mail: buhrman@cwi.nl. <p> Longpre and Mocas <ref> [LM93] </ref> and Longpre and Watanabe [LW95] show several results about these Hy potheses 4.3 and 4.5 including: 1. If P = NP then both hypothesis hold. 2. If certain kinds of one-way functions exist then Hypotheses 4.3 and 4.5 fail. (See [LM93] and [LW95] for details.) 3. <p> Longpre and Mocas <ref> [LM93] </ref> and Longpre and Watanabe [LW95] show several results about these Hy potheses 4.3 and 4.5 including: 1. If P = NP then both hypothesis hold. 2. If certain kinds of one-way functions exist then Hypotheses 4.3 and 4.5 fail. (See [LM93] and [LW95] for details.) 3. Both hypothesis hold for the polynomial-space and exponential-time variants of Kolmogorov complex ity. 4.2 Distinguishing Complexity Since computer scientists generally believe that one-way functions exist, this gives us strong evidence that symmetry of information does not hold for time-bounded Kolmogorov complexity.
Reference: [LV93] <author> M. Li and P. Vitanyi. </author> <title> An Introduction to Kolmogorov Complexity and Its Applications. Texts and Monographs in Computer Science. </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Though intuitively obvious that this "shared" information remains the same whether examined from x's or y's point of view, the proof requires a tricky set system argument (see <ref> [LV93] </ref>, pp. 143-144). As complexity theorists, we would like to understand this symmetry of information in the resource-bounded setting. <p> We then use these ideas to create a relativized world where nondeterministic distinguishing complexity fails. 2 Preliminaries We use basic concepts and notation from computational complexity theory texts like Balcazar, Daz and Gabarro [BDG88] and Kolmogorov complexity from the excellent book by Li and Vitanyi <ref> [LV93] </ref>. We use jxj to represent the length of a string x and jjAjj to represent the number of elements in the set A.
Reference: [LW95] <author> L. Longpre and O. Watanabe. </author> <title> On symmetry of information and polynomial time invertibility. </title> <journal> Information and Computation, </journal> <volume> 121(1) </volume> <pages> 14-22, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: In particular, we would like to require that we have "efficient" access to information in a string, i.e. computation bounded by a polynomial in the length of the string whose information we are concerned about. Longpre and Mocas [LM93] and Longpre and Watanabe <ref> [LW95] </ref> have examined symmetry of information for resource-bounded Kolmogorov complexity. They show among other results that if certain kinds of one-way functions exist then symmetry of information fails in the polynomial-time case. fl E-mail: buhrman@cwi.nl. Part of this research was done while visiting The University of Chicago. <p> Longpre and Mocas [LM93] and Longpre and Watanabe <ref> [LW95] </ref> show several results about these Hy potheses 4.3 and 4.5 including: 1. If P = NP then both hypothesis hold. 2. If certain kinds of one-way functions exist then Hypotheses 4.3 and 4.5 fail. (See [LM93] and [LW95] for details.) 3. <p> Longpre and Mocas [LM93] and Longpre and Watanabe <ref> [LW95] </ref> show several results about these Hy potheses 4.3 and 4.5 including: 1. If P = NP then both hypothesis hold. 2. If certain kinds of one-way functions exist then Hypotheses 4.3 and 4.5 fail. (See [LM93] and [LW95] for details.) 3. Both hypothesis hold for the polynomial-space and exponential-time variants of Kolmogorov complex ity. 4.2 Distinguishing Complexity Since computer scientists generally believe that one-way functions exist, this gives us strong evidence that symmetry of information does not hold for time-bounded Kolmogorov complexity. <p> Proof: Will be in the final version. 2 Note that Hypothesis 4.11 fails even if we replace the CND p with C p on the right hand side of the hypothesis since Equations 3 and 4 hold for C p complexity. Longpre and Watanabe <ref> [LW95] </ref> show that approximate counting suffices for symmetry of information. We had hoped to use the ideas from Section 3 to approximately count these subsets. But we see that even nondeterministic distinguishing complexity cannot apparently approximately count sets even with our new counting techniques.
Reference: [Sho90] <author> V. Shoup. </author> <title> New algorithms for finding irreducible polynomials over finite fields. </title> <journal> Mathematics of Computation, </journal> <volume> 54 </volume> <pages> 435-447, </pages> <year> 1990. </year>
Reference-contexts: This is 2 log (d) + 2 log (n) + O (1) as required. It remains to be shown that it runs in polynomial time. Shoup <ref> [Sho90] </ref> enables us to find an irreducible polynomial P 2 Z 2 [X] of degree m over Z 2 in time polynomial in m, and since m log d + log n + 1 n + log n + 1, in time polynomial in n.
Reference: [Sip83] <author> M. Sipser. </author> <title> A complexity theoretic approach to randomness. </title> <booktitle> In Proceedings of the 15th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 330-335. </pages> <publisher> ACM, </publisher> <address> New York, </address> <year> 1983. </year> <month> 8 </month>
Reference-contexts: The usual time-bounded Kolmogorov complexity looks at the smallest program that generates a string. In distinguishing complexity we look at the smallest program that distinguishes the string from all others. Sipser <ref> [Sip83] </ref> used distinguishing complexity to help understand the computational complexity of randomized classes. More recently, distinguishing complexity has played an important role in resource-bounded instance complexity [FK95] and the complexity of small subsets of easily computable sets [For96]. <p> Note that by the pigeonhole principle for any set S of strings of length n there exists some string in S with distinguishing complexity at least log jjSjj. This result improves earlier work by Sipser <ref> [Sip83] </ref> and Fortnow [For96]. Our proof uses polynomials over small finite fields to distinguish the strings. We can also use this lemma to characterize sparse sets. A polynomial-time computable set S is sparse if and only if every element in S has O (log n) polynomial-time distinguishing complexity. <p> While this difference only affects the unbounded Kolmogorov complexity by only a constant it can make a difference for the time-bounded case. Sipser <ref> [Sip83] </ref> defined the distinguishing complexity CD t by CD t (x) = min 8 : (1) U (p; x) accepts. jpj : (2) U (p; z) rejects for all z 6= x. (3) U (p; z) runs in at most t (jzj) steps for all z 2 fl . 9 ; <p> This result can be seen as a derandomized version of Sipser <ref> [Sip83] </ref> and improves the bound in Fortnow [For96]. Lemma 3.1 Let A be any set, such that jjA =n jj = d. For all strings x 2 A =n it holds that CD p;A =n (x) 2 log (d) + 2 log (n) + O (1) for some polynomial p. <p> On the other hand simple counting shows that for a set A with cardinality d there must be a string x 2 A such that CD (x) log (d). 2 Comparing our deterministic scheme with the randomized one of Sipser <ref> [Sip83] </ref> we note that our bound is slightly weaker. We need 2 log (d) + 2 log (n) bits to describe any x 2 A =n , whereas Sipser's bound is log (d)+log log (d)+O (1).
Reference: [ZL70] <author> A. Zvonkin and L. Levin. </author> <title> The complexity of finite objects and the devlopment of the concepts of information and randomness by means of the theory of algorithms. </title> <journal> Russian Mathematical Surveys, </journal> <volume> 25 </volume> <pages> 83-124, </pages> <year> 1970. </year>
Reference-contexts: 1 Introduction Kolmogorov and Levin (see <ref> [ZL70] </ref>) independently proved one of the most beautiful theorems in all of Kolmogorov complexity: "Symmetry of Information". <p> Formally we say I (y : x) = C (x) C (xjy) Informally one would expect that the amount of information of x contained in y would be roughly the same as the amount of information of y contained in x. Levin and Kolmogorov (see <ref> [ZL70] </ref>) prove this fact: Theorem 4.1 I (y : x) I (x : y) where by A B we mean jA Bj O (log (jxj + jyj)). Suppose we wanted to produce two strings x and y. <p> This yields the following identity: C (x; y) C (x) + C (yjx) + O (1) (1) One would think by the nature of symmetry of information that this would give us an efficient way to produce both x and y. Levin and Kolmogorov (see <ref> [ZL70] </ref>) actually prove this "equality". Theorem 4.2 C (x; y) C (x) + C (yjx) Note that Theorem 4.2 implies Theorem 4.1 since jC (x; y) C (y; x)j = O (1). In this paper we will look at polynomial-time bounded versions of the symmetry of information question.
References-found: 9

