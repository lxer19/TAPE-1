URL: http://www.cs.jhu.edu/~goodrich/pubs/inplace.ps
Refering-URL: http://www.cs.jhu.edu/~goodrich/pubs/index.html
Root-URL: http://www.cs.jhu.edu
Title: Fast Randomized Parallel Methods for Planar Convex Hull Construction  
Author: Mujtaba R. Ghouse Michael T. Goodrich 
Keyword: Key words: parallel algorithms, convex hulls, randomization, computational geom etry, CRCW PRAM.  
Address: 301 E. Evelyn Ave.  Mountain View, CA 94041 Baltimore, MD 21218-2694  
Affiliation: Quintus Corporation Dept. of Computer Science  Johns Hopkins University  
Abstract: We present a number of efficient parallel algorithms for constructing 2-dimensional convex hulls on a randomized CRCW PRAM. Specifically, we show how to build the convex hull of n pre-sorted points in the plane in O(1) time using O(n log n) work, with n-exponential probability, or, alternately, in O(log fl n) time using O(n) work, with n-exponential probability. We also show how to find the convex hull of n unsorted planar points in in O(log n) time using O(n log h) work, with n-exponential probability, where h is the number of edges in the convex hull (h is O(n), but can be as small as O(1)). Our algorithm for unsorted inputs depends on the use of new in-place procedures, that is, procedures that are defined on a subset of elements in the input and that work without re-ordering the input. In order to achieve our n-exponential confidence bounds we use a new parallel technique called failure sweeping. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, B. Chazelle, L. Guibas, C. O'Dunlaing, and C. Yap, </author> <title> "Parallel computational geometry," </title> <journal> Algorithmica, </journal> <volume> 3, </volume> <pages> 293-327, </pages> <year> 1988. </year>
Reference-contexts: The work performed by this algorithm, i.e., the total number of computations, is suboptimal, however, as it is O (n log 2 n). The running time using n processors was subsequently (and independently) improved to O (log n) time by Aggarwal et al. <ref> [1] </ref> and Atallah and Goodrich [3], thus achieving optimal-work parallel methods. Miller and Stout [24] show how to achieve the same result on an EREW PRAM, the parallel model where both reads and writes must be exclusive.
Reference: [2] <author> N. Alon and N. Megiddo, </author> <title> "Parallel linear programming in fixed dimension almost surely in constant time," </title> <booktitle> in Proc. 31st Annu. IEEE Sympos. </booktitle> <institution> Found. Comput. Sci., </institution> <month> 574-582, </month> <year> 1990. </year>
Reference-contexts: Our analysis does not depend on any assumptions about the input distribution. Our methods are also based on various adaptations of a method of Alon and Megiddo <ref> [2] </ref> for performing linear programming in fixed dimensions in O (1) time using O (n) processors, with n-exponential probability, in a randomized CRCW PRAM model. <p> Lemma 2.2 (Alon and Megiddo <ref> [2] </ref>): Given n half-space constraints in &lt; d , for fixed d, linear programming can be performed in O (1) time with n processors on a CRCW PRAM, with (n exponential) probability 1 2 cn 1 3 , where c &gt; 1 is a constant. <p> how to use this result to derive an optimal algorithm that runs in O (log fl n) time, with n-exponential probability. 2.4 Making Alon and Megiddo's Method Point-Hull Invariant Here we define the property of point-hull invariance and we show that our application of Alon and Megiddo's linear programming algorithm <ref> [2] </ref> is point-hull invariant. Suppose we are given n halfplane constraints defined by the duals to n points in the plane, and a linear objective function dual to the problem of finding the bridge passing through a given vertical line. The linear programming algorithm of Alon and Megiddo [2], applied to <p> programming algorithm <ref> [2] </ref> is point-hull invariant. Suppose we are given n halfplane constraints defined by the duals to n points in the plane, and a linear objective function dual to the problem of finding the bridge passing through a given vertical line. The linear programming algorithm of Alon and Megiddo [2], applied to this set, comprises repeatedly choosing a subset of the constraints, and finding the solution to this subset of constraints with respect to the given objective function. <p> In our algorithm for the unsorted input problem we must deal with many unrelated problems scattered through the input such that the processors of any one problem cannot be assumed to be contiguous, while Alon and Megiddo's linear programming algorithm <ref> [2] </ref> assumes contiguous input for one problem. In this subsection we show how to solve an m-constraint linear programming using m processors in-place in O (1)-time, with m-exponential probability. <p> This completes our procedure. Let us, therefore, analyze this procedure. First we review a useful result due to Alon and Megiddo: Lemma 3.4 (Upper bound on the survivors (Alon and Megiddo <ref> [2] </ref>)): The number of survivors, s, that violate the solution to the base problem, given that there were m 1 surviving points before the solution, is given by: Probability (s &gt; m 2 1 ) &lt; e (n * ) .
Reference: [3] <author> M. J. Atallah and M. T. Goodrich, </author> <title> "Efficient parallel solutions to some geometric problems," </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 3, </volume> <pages> 492-507, </pages> <year> 1986. </year>
Reference-contexts: The work performed by this algorithm, i.e., the total number of computations, is suboptimal, however, as it is O (n log 2 n). The running time using n processors was subsequently (and independently) improved to O (log n) time by Aggarwal et al. [1] and Atallah and Goodrich <ref> [3] </ref>, thus achieving optimal-work parallel methods. Miller and Stout [24] show how to achieve the same result on an EREW PRAM, the parallel model where both reads and writes must be exclusive.
Reference: [4] <author> M. J. Atallah and M. T. Goodrich, </author> <title> "Parallel algorithms for some functions of two convex polygons," </title> <journal> Algorithmica, </journal> <volume> 3, </volume> <pages> 535-548, </pages> <year> 1988. </year>
Reference-contexts: For each pair of groups, find the common tangent using a method of Atallah and Goodrich <ref> [4] </ref> that computes the common tangent of two upper hulls of n points each in O (1) time using n 1 processors (c = 1 will be sufficient here). This step can be implemented with n 2 k = n 1+ 1 processors. 3. <p> We define an algorithm on n points that would require only these operations to function with n upper hulls as input instead as point-hull invariant. Atallah and Goodrich <ref> [4] </ref> show that each of these upper hull problems can be solved in O (1) time with O (n 1 b ) processors, where b is a constant and n is the total number of edges in the upper hull. <p> q points, we can run the constant-time convex hull algorithm of Lemma 2.8, using a modification of (the dual of) Alon and Megiddo's algorithm such that in place of constant-time calls to the trivial operations on points, we call the constant-time operations on upper hulls due to Atallah and Goodrich <ref> [4] </ref>. <p> We begin Phase 2 by then using a parallel prefix sum computation (e.g., see [21]) to compact together all the remaining (active) points. We then apply an optimal (deterministic) parallel method of, say Atallah and Goodrich <ref> [4] </ref>, to compute the upper convex hull of the remaining points. By then merging this hull with the hull of edges found in Phase 1, we can complete the construction of the upper hull in O (log n) time using O (n) work (e.g., see [19]).
Reference: [5] <author> O. Berkman, B. Schieber, and U. Vishkin, </author> <title> "A fast parallel algorithm for finding the convex hull of a sorted point set," </title> <journal> International Journal on Computational Geometry & Applications, </journal> <note> to appear. </note>
Reference-contexts: If the input is presorted, Goodrich [15] shows how to achieve O (log n) time with an optimal O (n= log n) number of processors on a CREW PRAM, and Chen [7] shows how to achieve these same bounds in the EREW PRAM model. Recently, Berkman et al. <ref> [5] </ref> have shown how to achieve O (log log n) time with O (n= log log n) processors in the CRCW PRAM model, the synchronous parallel model where simultaneous concurrent reads and writes are allowed, with concurrent writes being resolved so that one succeeds arbitrarily 1 .
Reference: [6] <author> B. Chazelle and J. Matousek, </author> <title> "Derandomizing an output-sensitive convex hull algorithm in three dimensions," </title> <type> Technical report, </type> <institution> Dept. Comput. Sci., Princeton Univ., </institution> <year> 1992. </year>
Reference-contexts: Of course, to apply the above lemma to our convex hull algorithm, we must also know the value of W , which seems to require that we know the value of h. We can get around this seeming circular argument, however, by a well-known trick (e.g., see <ref> [6] </ref>).
Reference: [7] <author> D. Chen, </author> <title> "Efficient geometric algorithms on the EREW PRAM," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 6(1), </volume> <pages> 41-47, </pages> <year> 1995. </year>
Reference-contexts: If the input is presorted, Goodrich [15] shows how to achieve O (log n) time with an optimal O (n= log n) number of processors on a CREW PRAM, and Chen <ref> [7] </ref> shows how to achieve these same bounds in the EREW PRAM model.
Reference: [8] <author> H. Chernoff, </author> <title> "A measure of asymptotic efficiency for tests of a hypothesis based on the sum of the observations,," </title> <journal> Annals of Math. Stat., </journal> <volume> 23, </volume> <pages> 493-509, </pages> <year> 1952. </year>
Reference-contexts: Lemma 2.3 (Tail Estimation (Chernoff bound <ref> [8, 20] </ref>)): Let X 1 ; X 2 ; : : : ; X n 2 f0; 1g be n Bernoulli trials: independent trials with probability p i that X i = 1, where p i 2 (0; 1). Define X = n i=1 p i . <p> Each processor that did suffer a collision repeats steps 2-4 for a total of up to d attempts, where d is a constant. Note that all these steps can be performed in O (1) time with m processors, on the CRCW PRAM. By a Chernoff bound <ref> [8, 20] </ref> (Lemma 2.3), fewer than 4k processors will attempt a write, with probability 1 4 2k and more than k processors, with probability 1 e k Thus, given that m 0 processors attempt to write, with k m 0 4k, the probability of such a processor suffering a collision is
Reference: [9] <author> A. L. Chow, </author> <title> Parallel algorithms for geometric problems, </title> <type> Ph.D. thesis, </type> <institution> Dept. Comput. Sci., Univ. Illinois, Urbana, IL, </institution> <year> 1980. </year>
Reference-contexts: The running time in the (fully) sorted case is O (n), for example. Two-dimensional convex hull construction has also been well-studied in parallel. Chow <ref> [9, 10] </ref> is the first to study this problem, achieving O (log 2 n) time with n processors in the CREW PRAM model, the synchronous parallel shared-memory model that allows for simultaneous concurrent-reads but requires that all writes be exclusive.
Reference: [10] <author> A. L. Chow, </author> <title> "A parallel algorithm for determining convex hulls of sets of points in two dimensions," </title> <booktitle> in Proc. 19th Allerton Conf. Commun. Control Comput., </booktitle> <pages> 214-223, </pages> <year> 1981. </year>
Reference-contexts: The running time in the (fully) sorted case is O (n), for example. Two-dimensional convex hull construction has also been well-studied in parallel. Chow <ref> [9, 10] </ref> is the first to study this problem, achieving O (log 2 n) time with n processors in the CREW PRAM model, the synchronous parallel shared-memory model that allows for simultaneous concurrent-reads but requires that all writes be exclusive.
Reference: [11] <author> X. Deng, </author> <title> "An optimal parallel algorithm for linear programming in the plane," </title> <journal> Information Processing Letters, </journal> <volume> 35, </volume> <pages> 213-217, </pages> <year> 1990. </year>
Reference-contexts: None of these previous algorithms achieve the sequential output-sensitive work bounds described above, however. Nevertheless, using standard parallel techniques, one can use a parallel linear programming algorithm of Deng <ref> [11] </ref> to implement a parallel version of the algorithm of Kirkpatrick and Seidel [22] to run in O (log 2 n) time, using O (n log h) work. It is not clear how one could improve this time bound without the introduction of new techniques, however.
Reference: [12] <author> H. Edelsbrunner, </author> <title> Algorithms in Combinatorial Geometry, </title> <journal> EATCS Monographs on Theoretical Computer Science, </journal> <volume> vol. 10, </volume> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, West Germany, </address> <year> 1987. </year> <month> 17 </month>
Reference-contexts: The problem is generally defined as that of constructing the boundary of the smallest convex set containing all n points, and it can be solved sequentially in O (n log n) time. (See <ref> [12, 25, 26] </ref> for references.) This bound is, in fact, optimal, for Yao [29] shows that the identifying the points on the boundary of a 2-dimensional convex hull has an (n log n) lower bound in the algebraic computation tree model. <p> Kirkpatrick and Seidel [22] design a beautiful sequential algorithm upon the observation that, by a duality between points and lines (e.g., see <ref> [12] </ref>), the problem of finding a bridge for an n-point set is dual to an n-constraint 2-dimensional linear program. Our methods will also be based upon this observation. <p> In this base case, each processor is assigned O (log fl n) contiguous points, for which it finds the convex hull using a sequential, deterministic algorithm (e.g., see <ref> [12, 25, 26] </ref>). We call this hull of O (log fl n) points a mini-hull. Then, another array is set up, this time of size n=log fl n, such that the i-th element contains the extremal x coordinates of the ith mini-hull.
Reference: [13] <author> D. Eppstein and Z. Galil, </author> <title> "Parallel algorithmic techniques for combinatorial computation," </title> <booktitle> Annual Review of Computer Science, </booktitle> <volume> 3, </volume> <pages> 233-283, </pages> <year> 1988. </year>
Reference-contexts: The general approach of our 1 There are other possible conflict resolution methods, as well (e.g., see <ref> [13] </ref>), but we will be assuming this "arbi trary" resolution rule throughout this paper. 2 We say an event occurs with n-exponential probability if the probability that this will not occur is at most c n d , where c &gt; 1, d &gt; 0 are constants. 3 An upper hull <p> Lemma 2.5 (Eppstein and Galil <ref> [13] </ref>): The first non-zero element of an array of size n can be found in O (1) time on a CRCW PRAM with n processors.
Reference: [14] <author> M. Ghouse and M. T. Goodrich, </author> <title> "In-place techniques for parallel convex hull algorithms," </title> <booktitle> in Proc. 3rd ACM Sympos. Parallel Algorithms Architect., </booktitle> <pages> 192-203, </pages> <year> 1991. </year>
Reference-contexts: Incidentally, subsequent to the initial announcement of our results in <ref> [14] </ref> we have learned that this technique has been independently discovered by Matias and Vishkin [23], who call it the thinning-out principle.
Reference: [15] <author> M. T. Goodrich, </author> <title> "Finding the convex hull of a sorted point set in parallel," </title> <journal> Inform. Process. Lett., </journal> <volume> 26, </volume> <pages> 176-179, </pages> <year> 1987. </year>
Reference-contexts: Miller and Stout [24] show how to achieve the same result on an EREW PRAM, the parallel model where both reads and writes must be exclusive. If the input is presorted, Goodrich <ref> [15] </ref> shows how to achieve O (log n) time with an optimal O (n= log n) number of processors on a CREW PRAM, and Chen [7] shows how to achieve these same bounds in the EREW PRAM model.
Reference: [16] <author> M. T. Goodrich, </author> <title> "Constructing the convex hull of a partially sorted set of points," </title> <journal> Comput. Geom. Theory Appl., </journal> <volume> 2(5), </volume> <pages> 267-278, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: E-mail: goodrich@cs.jhu.edu. 1 the output size is linear. In addition, their method assumes that the input points are unsorted, whereas one can beat their bound for sorted [18, 25, 26] or even partially-sorted <ref> [16] </ref> inputs. The running time in the (fully) sorted case is O (n), for example. Two-dimensional convex hull construction has also been well-studied in parallel.
Reference: [17] <author> M. T. Goodrich, Y. Matias, and U. Vishkin, </author> <title> "Optimal parallel approximation for prefix sums and integer sorting," </title> <booktitle> in Proc. 5th ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> 241-250, </pages> <year> 1994. </year>
Reference-contexts: Sen [28] gives a randomized CRCW PRAM method for finding an approximate median in O (1) time using O (n) processors, with * = 1=4 with n-polynomial probability. As Goodrich et al. <ref> [17] </ref> observe, Sen's algorithm can be adapted to achieve an n-exponential success probability while remaining an O (1)-time computation using O (n) processors. We can easily convert this to an in-place median-finding method.
Reference: [18] <author> R. L. Graham, </author> <title> "An efficient algorithm for determining the convex hull of a finite planar set," </title> <journal> Inform. Process. Lett., </journal> <volume> 1, </volume> <pages> 132-133, </pages> <year> 1972. </year>
Reference-contexts: E-mail: goodrich@cs.jhu.edu. 1 the output size is linear. In addition, their method assumes that the input points are unsorted, whereas one can beat their bound for sorted <ref> [18, 25, 26] </ref> or even partially-sorted [16] inputs. The running time in the (fully) sorted case is O (n), for example. Two-dimensional convex hull construction has also been well-studied in parallel.
Reference: [19] <author> T. Hagerup and C. Rub, </author> <title> "Optimal merging and sorting on the erew pram," </title> <journal> Information Processing Letters, </journal> <volume> 33, </volume> <pages> 181-185, </pages> <year> 1989. </year>
Reference-contexts: By then merging this hull with the hull of edges found in Phase 1, we can complete the construction of the upper hull in O (log n) time using O (n) work (e.g., see <ref> [19] </ref>). Lemma 4.1: The total work required by the above algorithm is O (n log h), with n-exponential probability. Proof: Let W (n; h) denote the work required to find the convex hull of n points.
Reference: [20] <author> T. Hagerup and C. Rub, </author> <title> "A guided tour of Chernoff bounds," </title> <journal> Information Processing Letters, </journal> <volume> 33, </volume> <pages> 305-308, </pages> <year> 1989/90. </year>
Reference-contexts: Lemma 2.3 (Tail Estimation (Chernoff bound <ref> [8, 20] </ref>)): Let X 1 ; X 2 ; : : : ; X n 2 f0; 1g be n Bernoulli trials: independent trials with probability p i that X i = 1, where p i 2 (0; 1). Define X = n i=1 p i . <p> Each processor that did suffer a collision repeats steps 2-4 for a total of up to d attempts, where d is a constant. Note that all these steps can be performed in O (1) time with m processors, on the CRCW PRAM. By a Chernoff bound <ref> [8, 20] </ref> (Lemma 2.3), fewer than 4k processors will attempt a write, with probability 1 4 2k and more than k processors, with probability 1 e k Thus, given that m 0 processors attempt to write, with k m 0 4k, the probability of such a processor suffering a collision is
Reference: [21] <author> J. J Ja, </author> <title> An Introduction to Parallel Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1992. </year>
Reference-contexts: Thus, since there are at most 2 i+1 = O (n 3=4 ) subproblems in total, this implies that all the Phase 1 computations complete successfully with n-exponential probability. We begin Phase 2 by then using a parallel prefix sum computation (e.g., see <ref> [21] </ref>) to compact together all the remaining (active) points. We then apply an optimal (deterministic) parallel method of, say Atallah and Goodrich [4], to compute the upper convex hull of the remaining points.
Reference: [22] <author> D. G. Kirkpatrick and R. Seidel, </author> <title> "The ultimate planar convex hull algorithm?," </title> <journal> SIAM J. Comput., </journal> <volume> 15, </volume> <pages> 287-299, </pages> <year> 1986. </year>
Reference-contexts: Nevertheless, Kirkpatrick and Seidel <ref> [22] </ref> show that one can beat this lower bound in some cases, in that they give a 2-dimensional convex hull algorithm that runs in O (n log h) time, where h is the size of the output (which can be as small as 3 in some cases). <p> None of these previous algorithms achieve the sequential output-sensitive work bounds described above, however. Nevertheless, using standard parallel techniques, one can use a parallel linear programming algorithm of Deng [11] to implement a parallel version of the algorithm of Kirkpatrick and Seidel <ref> [22] </ref> to run in O (log 2 n) time, using O (n log h) work. It is not clear how one could improve this time bound without the introduction of new techniques, however. <p> occur is at most c n d , where c &gt; 1, d &gt; 0 are constants. 3 An upper hull is a convex chain monotone in x that "curves to the right" as one traverses it by increasing x. 2 methods is based on that of Kirkpatrick and Seidel <ref> [22] </ref>: namely, we use linear programming to "probe" the convex hull, either in parallel at many locations or in just a few places so as to split the problem and recurse. <p> For any node v in T define the bridge for v as the edge of the upper hull of S v intersected by a vertical line separating the points in the subtrees rooted at v's two children. Kirkpatrick and Seidel <ref> [22] </ref> design a beautiful sequential algorithm upon the observation that, by a duality between points and lines (e.g., see [12]), the problem of finding a bridge for an n-point set is dual to an n-constraint 2-dimensional linear program. Our methods will also be based upon this observation. <p> We wish to compute the upper convex hull of these points, ordered from left-to-right. At a very high level of abstraction, our algorithm is similar in structure to the sequential "marriage-before-conquest" algorithm of Kirkpatrick and Seidel <ref> [22] </ref>, which runs in O (n log h) time, where h is the number of hull points. Our method runs in O (log n) time using O (n log h) work with n-exponential probability. <p> Proof: Let W (n; h) denote the work required to find the convex hull of n points. Then, assuming every call returns without failing, the work for Phase 1 satisfies the following recurrence relation <ref> [22] </ref>: W (n; h) = cn + W (n 1 ; h 1 ) + W (n 2 ; h 2 ); where c is a constant, h 1 + h 2 = h, and n 1 + n 2 n (for we only count active points).
Reference: [23] <author> Y. Matias and U. Vishkin, </author> <title> "Converting high probability into nearly-constant time|with applications to parallel hashing," </title> <booktitle> in Proc. 23rd ACM Symp. on Theory of Computing, </booktitle> <pages> 307-316, </pages> <year> 1991. </year>
Reference-contexts: Incidentally, subsequent to the initial announcement of our results in [14] we have learned that this technique has been independently discovered by Matias and Vishkin <ref> [23] </ref>, who call it the thinning-out principle. Our method for the unsorted case also depends upon the use of new in-place techniques, whereby we mean methods that are defined on a subset S 0 of elements in the input and work without reordering the input. <p> Of course, this raises a significant issue regarding processor allocation in the PRAM model of computation, where we must simulate the work of these virtual processors using some given number, P , of processors. Fortunately, we can apply the following lemma of Matias and Vishkin <ref> [23] </ref> to resolve this issue. <p> There are several methods for performing linear approximate compaction (where the target array is proportional to the number of elements being compressed) in O (log fl n) time using O (n) processors, with n-exponential probability (e.g., see <ref> [23] </ref>). Of course, to apply the above lemma to our convex hull algorithm, we must also know the value of W , which seems to require that we know the value of h. We can get around this seeming circular argument, however, by a well-known trick (e.g., see [6]).
Reference: [24] <author> R. Miller and Q. F. Stout, </author> <title> "Efficient parallel convex hull algorithms," </title> <journal> IEEE Trans. Comput., </journal> <volume> C-37(12), </volume> <pages> 1605-1618, </pages> <year> 1988. </year>
Reference-contexts: The running time using n processors was subsequently (and independently) improved to O (log n) time by Aggarwal et al. [1] and Atallah and Goodrich [3], thus achieving optimal-work parallel methods. Miller and Stout <ref> [24] </ref> show how to achieve the same result on an EREW PRAM, the parallel model where both reads and writes must be exclusive.
Reference: [25] <author> J. O'Rourke, </author> <title> Computational Geometry in C, </title> <publisher> Cambridge University Press, </publisher> <address> 1994. ISBN 0 521-44592-2/Pb $24.95, ISBN 0-521-44034-3/Hc $49.95. Cambridge University Press 40 West 20th Street New York, NY 10011-4211 1-800-872-7423 346+xi pages, </address> <note> 228 exercises, 200 figures, 219 references. C code and errata available by anonymous ftp from grendel.csc.smith.edu (131.229.64.23), in the directory /pub/compgeom. </note>
Reference-contexts: The problem is generally defined as that of constructing the boundary of the smallest convex set containing all n points, and it can be solved sequentially in O (n log n) time. (See <ref> [12, 25, 26] </ref> for references.) This bound is, in fact, optimal, for Yao [29] shows that the identifying the points on the boundary of a 2-dimensional convex hull has an (n log n) lower bound in the algebraic computation tree model. <p> E-mail: goodrich@cs.jhu.edu. 1 the output size is linear. In addition, their method assumes that the input points are unsorted, whereas one can beat their bound for sorted <ref> [18, 25, 26] </ref> or even partially-sorted [16] inputs. The running time in the (fully) sorted case is O (n), for example. Two-dimensional convex hull construction has also been well-studied in parallel. <p> In this base case, each processor is assigned O (log fl n) contiguous points, for which it finds the convex hull using a sequential, deterministic algorithm (e.g., see <ref> [12, 25, 26] </ref>). We call this hull of O (log fl n) points a mini-hull. Then, another array is set up, this time of size n=log fl n, such that the i-th element contains the extremal x coordinates of the ith mini-hull.
Reference: [26] <author> F. P. Preparata and M. I. Shamos, </author> <title> Computational Geometry: an Introduction, </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1985. </year> <month> 18 </month>
Reference-contexts: The problem is generally defined as that of constructing the boundary of the smallest convex set containing all n points, and it can be solved sequentially in O (n log n) time. (See <ref> [12, 25, 26] </ref> for references.) This bound is, in fact, optimal, for Yao [29] shows that the identifying the points on the boundary of a 2-dimensional convex hull has an (n log n) lower bound in the algebraic computation tree model. <p> E-mail: goodrich@cs.jhu.edu. 1 the output size is linear. In addition, their method assumes that the input points are unsorted, whereas one can beat their bound for sorted <ref> [18, 25, 26] </ref> or even partially-sorted [16] inputs. The running time in the (fully) sorted case is O (n), for example. Two-dimensional convex hull construction has also been well-studied in parallel. <p> In this base case, each processor is assigned O (log fl n) contiguous points, for which it finds the convex hull using a sequential, deterministic algorithm (e.g., see <ref> [12, 25, 26] </ref>). We call this hull of O (log fl n) points a mini-hull. Then, another array is set up, this time of size n=log fl n, such that the i-th element contains the extremal x coordinates of the ith mini-hull.
Reference: [27] <author> P. Ragde, </author> <title> "The parallel simplicity of compaction and chaining,," </title> <booktitle> in Proc. 17th International Colloquium on Automata, Languages and Programming, </booktitle> <publisher> LNCS 443, Springer-Verlag, </publisher> <pages> 744-751, </pages> <year> 1990. </year>
Reference-contexts: Thus, one edge may occur in this list many times, as it will be stored by every point below it. 2.1 Preliminaries First, we review some elegant results that we use in our algorithm. Lemma 2.1 (The Approximate Compaction Lemma (Ragde <ref> [27] </ref>)): Given an array of size n containing at most k non-zero elements, then there is a method that will either conclude that k &gt; n 4 or compress these k elements into an area of size k 4 , in O (1) time on a CRCW PRAM (deterministically) with n <p> As described above, we then use Ragde's algorithm <ref> [27] </ref> which will succeed in compressing all the failures into an area of size n 1 4 , to be solved by brute force, if and only if the number of failures is n 1 16 (by Lemma 2.1), and, as the rest of the procedure will succeed with probability 1 <p> It uses fi (k) work space where it is uniformly random with k-exponential probability. 3.2 In-Place Approximate Compaction Lemma 2.1 describes the result of an elegant approximate compaction technique due to Ragde <ref> [27] </ref>. Unfortunately, this technique is not in itself in-place, so here we present an in-place approximate compaction technique that uses Ragde's method as a subroutine.
Reference: [28] <author> S. Sen, </author> <title> "Finding an approximate median with high probability in constant parallel time," </title> <journal> Information Processing Letters, </journal> <volume> 34, </volume> <pages> 77-80, </pages> <year> 1990. </year>
Reference-contexts: The approximate median-finding problem is to locate a number x such that the rank of x in X is between *n and (1 *)n, for some constant *. Sen <ref> [28] </ref> gives a randomized CRCW PRAM method for finding an approximate median in O (1) time using O (n) processors, with * = 1=4 with n-polynomial probability.
Reference: [29] <author> A. C. Yao, </author> <title> "A lower bound to finding convex hulls," </title> <journal> J. ACM, </journal> <volume> 28, </volume> <pages> 780-787, </pages> <year> 1981. </year> <month> 19 </month>
Reference-contexts: The problem is generally defined as that of constructing the boundary of the smallest convex set containing all n points, and it can be solved sequentially in O (n log n) time. (See [12, 25, 26] for references.) This bound is, in fact, optimal, for Yao <ref> [29] </ref> shows that the identifying the points on the boundary of a 2-dimensional convex hull has an (n log n) lower bound in the algebraic computation tree model.
References-found: 29

