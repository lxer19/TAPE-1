URL: ftp://grilled.cs.wisc.edu/naim/hpcn95.ps.gz
Refering-URL: http://www.cs.wisc.edu/~naim/publications.html
Root-URL: 
Email: E-mail: fand,efhg93r,on92r,ajgh,dang@ecs.soton.ac.uk  
Title: A Toolkit for Optimising Parallel Performance  
Author: Alistair Dunlop, Emilio Hernandez, Oscar Nam, Tony Hey, Denis Nicole 
Address: Southampton, Southampton S017 1BJ, UK  
Affiliation: Department of Electronics and Computer Science University of  
Abstract: Three interacting tools to assist distributed memory programmers in developing, optimising and understanding application performance have been developed. These tools perform automatic code generation from an initial workload specification, performance prediction using memory hierarchy simulation, and performance visualisation for distributed memory message passing applications. Their combination facilitates extensive performance tuning from initial workload specification through to completed message passing program codes.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Vasanth Balasundaram, Geoffrey Fox, Ken Kennedy, and Ulrich Kremer. </author> <title> A Static Performance Estimator in the Fortran D Programming System. </title> <booktitle> In Languages, Compilers and Run-Time Environments for Distributed Memory Machines, </booktitle> <pages> pages 119-138. </pages> <publisher> Elsevier Science Publishers B.V., </publisher> <year> 1992. </year> <editor> J. Saltz and P. </editor> <title> Mehrotra (Editors). </title>
Reference-contexts: The interaction with Lebep thus provided a test bed in order to verify the predictions of the Performance Estimator (a similar case study is presented in <ref> [1] </ref>). Furthermore, the Performance Estimator provided a good analysis of source code performance something that cannot be obtained by static analysis or profiling methods.
Reference: 2. <author> Alistair Dunlop, Emilio Hernandez, Oscar Nam, Tony Hey, and Denis Nicole. </author> <title> Collaborative Tools for Parallel Performance Optimization. </title> <type> Technical Report HPCC94-011, </type> <institution> Dept. of Electronics and Computer Science, University of Southamp-ton, Southampton S017 1BJ, UK, </institution> <month> November </month> <year> 1994. </year> <note> Submitted to Scientific Programming. </note>
Reference-contexts: The above three tools address the problem of improving application performance from different perspectives. Their combined use provides for performance tuning throughout the program development cycle (for more detailed information, please refer to <ref> [2] </ref>). The following section contains a case study showing how these tools were used to parallelise a sequential numerical method.
Reference: 3. <author> A.N. Dunlop, A.J.G. Hey, and D.A. Nicole. </author> <title> Parallel performance estimating using memory hierarchy simulation. </title> <type> Technical Report HPCC94-008, </type> <institution> Dept. of Electronics and Computer Science, University of Southampton, Southampton S017 1BJ, UK, </institution> <year> 1994. </year>
Reference-contexts: This tool does not require the target hardware platform, and is able to identify the workload placed on the system hardware components <ref> [3] </ref>. ? This work is supported in part by ESPRIT project P6643 (PPPE). The third performance tool is a visualisation system (Do-Loop-Surface dis-plays or DLS) for fine and coarse grain visualisation of massively parallel programs [5]. The above three tools address the problem of improving application performance from different perspectives.
Reference: 4. <author> C. Figueira and E. Hernandez. </author> <title> Benchmarks Specification and Generation for Performance Estimation on MIMD Machines. </title> <booktitle> In IFIP Transactions in Computer Science and Tecnology, </booktitle> <volume> volume 44, </volume> <year> 1994. </year>
Reference-contexts: There are three tools in the performance toolset: A parallel benchmark generator. A parallel performance estimator. A parallel performance visualiser. The parallel benchmark generator, Lebep, provides the user with a workload specification language with which to describe proposed algorithms <ref> [4] </ref>. Given an algorithm specification, the parallel benchmark generator produces a template program with the described workload characteristics. This facility allows for rapid performance prototyping of different solution strategies.
Reference: 5. <author> Oscar Nam and Tony Hey. Do-Loop-Surface: </author> <title> An Abstract Performance Data Visualization. </title> <booktitle> In HPCN Europe'94, </booktitle> <address> Munich, Germany, </address> <month> April </month> <year> 1994. </year> <title> Springer-Verlag Publishers. This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: The third performance tool is a visualisation system (Do-Loop-Surface dis-plays or DLS) for fine and coarse grain visualisation of massively parallel programs <ref> [5] </ref>. The above three tools address the problem of improving application performance from different perspectives. Their combined use provides for performance tuning throughout the program development cycle (for more detailed information, please refer to [2]).
References-found: 5

