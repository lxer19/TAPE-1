URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-94-38.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Dynamic Access Ordering: Bounds on Memory Bandwidth  
Author: Sally A. McKee 
Note: This work was supported in part by a grant from Intel Supercomputer Division and by NSF grants MIP-9114110 and MIP-9307626.  
Abstract: Computer Science Report No. CS-94-38 November 1, 1994 
Abstract-found: 1
Intro-found: 1
Reference: [Ben91] <author> Benitez, M.E., and Davidson, J.W., </author> <title> Code Generation for Streaming: An Access/Execute Mechanism, </title> <booktitle> Proc. Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April, </month> <year> 1991. </year>
Reference-contexts: These limitations motivate us to consider an implementation that reorders accesses dynamically. Benitez and Davidsons algorithm can be used to detect streams at compile Dynamic Access Ordering: Bounds on Memory Bandwidth 3 time <ref> [Ben91] </ref>, and the stream parameter can be transmitted to the reordering hardware at run time. What follows is an overview of the dynamic access ordering architecture proposed in the uniprocessor and SMP SMC reports [McK93a, McK93c, McK94c].
Reference: [Far92] <author> Farmwald, M., and Morring, D., </author> <title> A Fast Path to One Memory, </title> <booktitle> in [IEEE92], </booktitle> <pages> pp. 50-51, </pages> <month> October, </month> <year> 1992. </year>
Reference: [Har92] <author> Hart, C., </author> <title> Dynamic RAM as Secondary Cache, </title> <editor> in [IEEE92], p. </editor> <volume> 48, </volume> <month> October, </month> <year> 1992. </year>
Reference: [Hen90] <author> Hennessy, J., and Patterson, D., </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: 1. Introduction Memory speeds are increasing much more slowly than processor speeds <ref> [Kat89, Hen90] </ref>. As a result, memory bandwidth is rapidly becoming the limiting performance factor for many applications, particularly scientific computations.
Reference: [IEEE92] <author> High-speed DRAMs, </author> <title> Special Report, </title> <journal> IEEE Spectrum, </journal> <volume> vol. 29, no. 10, </volume> <month> October, </month> <year> 1992. </year>
Reference-contexts: Not only must we find ways to improve cache performance, but we must provide alternatives for computations for which caching is insufficient. For instance, most memory devices manufactured in the last decade provide special capabilities that make it possible to perform some access sequences faster than others <ref> [IEEE92, Ram92, Qui91] </ref>, and exploiting these component characteristics can dramatically improve effective bandwidth. For applications that perform vector-like memory accesses, bandwidth can be increased by reordering the requests to take advantage of device properties such as fast-page mode.
Reference: [Jon92] <author> Jones, F., </author> <title> A New Era of Fast Dynamic RAMs, </title> <booktitle> in [IEEE92], </booktitle> <pages> pp. 43-49, </pages> <month> October, </month> <year> 1992. </year>
Reference: [Kat89] <author> Katz, R., and Hennessy, J., </author> <title> High Performance Microprocessor Architectures, </title> <institution> University of California, Berkeley, </institution> <note> Report No. UCB/CSD 89/529, </note> <month> August, </month> <year> 1989. </year>
Reference-contexts: 1. Introduction Memory speeds are increasing much more slowly than processor speeds <ref> [Kat89, Hen90] </ref>. As a result, memory bandwidth is rapidly becoming the limiting performance factor for many applications, particularly scientific computations.
Reference: [McK93a] <author> McKee, S.A, </author> <title> Hardware Support for Access Ordering: Performance of Some Design Options, </title> <institution> University of Virginia, Department of Computer Science, </institution> <type> Technical Report CS-93-08, </type> <month> August, </month> <year> 1993. </year>
Reference-contexts: Section 4 discusses the assumptions underlying both the startup delay model presented in Section 5 and the asymptotic performance models of Section 6. Section 7 and Section 8 discuss the environment and benchmark kernels used in the simulation studies of SMC performance <ref> [McK93a, McK93c, McK94c] </ref>, and Section 9 correlates the performance curves generated by our analytic models with sample simulation results. 2. The SMC Moyer develops algorithms and analyzes the performance benefits and limitations of doing compile-time access ordering [Moy93]. <p> What follows is an overview of the dynamic access ordering architecture proposed in the uniprocessor and SMP SMC reports <ref> [McK93a, McK93c, McK94c] </ref>. Our discussion is based on the simplified architectures of Figure 1 and Figure 2. In these systems, memory is interfaced to the CPU or computational elements (CEs) through a controller labeled MSU for Memory Scheduling Unit. <p> Since performance on a single CE is relatively independent of access pattern <ref> [McK93a] </ref>, we model prescheduled computations by running the same benchmark on all CEs. Each vector is split into approximately equal-size chunks, and each CE processes a chunk. Figure 3 depicts this data distribution for a stride-one vector, along with the corresponding code for the inner loops on a 2-CE system. <p> Moreover, implementing such an algorithm might be expensive, both in the amount of hardware necessary and in the time required for it to run. Instead, we have developed a number of heuristics for dynamic access ordering; simulation results for these are presented elsewhere <ref> [McK93a, McK93c, McK94c] </ref>. Although we do not know precisely what the optimal ordering algorithm is, we can bound its performance. Taking advantage of the full bandwidth afforded by the memory system requires exploiting the page-mode capabilities of the memory components. <p> Complete uniprocessor results, including a detailed description of each access-ordering heuristic, can be found in <ref> [McK93a] </ref>; highlights of these results are presented in [McK94a, McK94b]. Complete shared-memory multiprocessor results can be found in [McK94c].
Reference: [McK93b] <author> McKee, S.A., </author> <title> An Analytic Model of SMC Performance, </title> <institution> University of Virginia, </institution> <type> Technical Report CS-93-54, </type> <month> November, </month> <year> 1993. </year>
Reference-contexts: The hardware part of this solution is the Stream Memory Controller (SMC). An analytical model to bound asymptotic SMC performance for unit-stride vectors has been developed and extended for non-unit stride vectors in <ref> [McK93b, McK93c] </ref>. Here we develop a model to bound SMC performance on short vectors, and we extend the asymptotic model to describe symmetric multiprocessor (SMP) SMC performance. <p> Given the overwhelming similarity of the performance trends for most benchmarks and system configurations, we only discuss highlights of our results here. Other results can be found in the Appendix, and a more detailed comparison of uniprocessor simulation and asymptotic model results can be found in <ref> [McK93b, McK93c] </ref>. curves for vaxpy, which involves three vectors: a vector a times a vector x, plus a vector y. For multiple-vector computations on short vectors, the startup-delay bound is the limiting performance factor, as evidenced by the curves in Figure 10 (a).
Reference: [McK93c] <author> McKee, S.A., </author> <title> Uniprocessor SMC Performance on Vectors with Non-unit Strides, </title> <institution> University of Virginia, </institution> <type> Technical Report CS-93-67, </type> <month> December, </month> <year> 1993. </year>
Reference-contexts: The hardware part of this solution is the Stream Memory Controller (SMC). An analytical model to bound asymptotic SMC performance for unit-stride vectors has been developed and extended for non-unit stride vectors in <ref> [McK93b, McK93c] </ref>. Here we develop a model to bound SMC performance on short vectors, and we extend the asymptotic model to describe symmetric multiprocessor (SMP) SMC performance. <p> Section 4 discusses the assumptions underlying both the startup delay model presented in Section 5 and the asymptotic performance models of Section 6. Section 7 and Section 8 discuss the environment and benchmark kernels used in the simulation studies of SMC performance <ref> [McK93a, McK93c, McK94c] </ref>, and Section 9 correlates the performance curves generated by our analytic models with sample simulation results. 2. The SMC Moyer develops algorithms and analyzes the performance benefits and limitations of doing compile-time access ordering [Moy93]. <p> What follows is an overview of the dynamic access ordering architecture proposed in the uniprocessor and SMP SMC reports <ref> [McK93a, McK93c, McK94c] </ref>. Our discussion is based on the simplified architectures of Figure 1 and Figure 2. In these systems, memory is interfaced to the CPU or computational elements (CEs) through a controller labeled MSU for Memory Scheduling Unit. <p> Moreover, implementing such an algorithm might be expensive, both in the amount of hardware necessary and in the time required for it to run. Instead, we have developed a number of heuristics for dynamic access ordering; simulation results for these are presented elsewhere <ref> [McK93a, McK93c, McK94c] </ref>. Although we do not know precisely what the optimal ordering algorithm is, we can bound its performance. Taking advantage of the full bandwidth afforded by the memory system requires exploiting the page-mode capabilities of the memory components. <p> Given the overwhelming similarity of the performance trends for most benchmarks and system configurations, we only discuss highlights of our results here. Other results can be found in the Appendix, and a more detailed comparison of uniprocessor simulation and asymptotic model results can be found in <ref> [McK93b, McK93c] </ref>. curves for vaxpy, which involves three vectors: a vector a times a vector x, plus a vector y. For multiple-vector computations on short vectors, the startup-delay bound is the limiting performance factor, as evidenced by the curves in Figure 10 (a).
Reference: [McK94a] <author> McKee, S.A., Klenke, R.H., Schwab, A.J., Wulf, Wm.A., Moyer, S.A., Hitchcock, C., Aylor, J.H., </author> <title> Experimental Implementation of Dynamic Access Ordering, </title> <booktitle> Proc. </booktitle> <address> HICSS-27, Maui, HI, </address> <note> January 1994; also University of Virginia, Technical Report CS-93-42, </note> <month> August, </month> <year> 1993. </year>
Reference-contexts: McKee, et. al., propose a combined hardware/ software scheme for implementing access ordering dynamically at run-time, and present Dynamic Access Ordering: Bounds on Memory Bandwidth 2 numerous simulation results demonstrating its effectiveness <ref> [McK94a] </ref>. The hardware part of this solution is the Stream Memory Controller (SMC). An analytical model to bound asymptotic SMC performance for unit-stride vectors has been developed and extended for non-unit stride vectors in [McK93b, McK93c]. <p> Complete uniprocessor results, including a detailed description of each access-ordering heuristic, can be found in [McK93a]; highlights of these results are presented in <ref> [McK94a, McK94b] </ref>. Complete shared-memory multiprocessor results can be found in [McK94c].
Reference: [McK94b] <author> McKee, S.A., Moyer, S.A., Wulf, Wm.A., Hitchcock, C., </author> <title> Increasing Memory Bandwidth for Vector Computations, </title> <booktitle> Proc. Conf. on Prog. Lang. and Sys. Arch., </booktitle> <address> Zurich, Switzerland, </address> <month> March, </month> <note> 1994; also University of Virginia, Technical Report CS-93-34. </note>
Reference-contexts: Complete uniprocessor results, including a detailed description of each access-ordering heuristic, can be found in [McK93a]; highlights of these results are presented in <ref> [McK94a, McK94b] </ref>. Complete shared-memory multiprocessor results can be found in [McK94c].
Reference: [McK94c] <author> McKee, S.A., </author> <title> Dynamic Access Ordering for Symmetric Shared-Memory Dynamic Access Ordering: Bounds on Memory Bandwidth 77 Multiprocessors, </title> <institution> University of Virginia, </institution> <type> Technical Report CS-94-14, </type> <month> April, </month> <year> 1994. </year>
Reference-contexts: Section 4 discusses the assumptions underlying both the startup delay model presented in Section 5 and the asymptotic performance models of Section 6. Section 7 and Section 8 discuss the environment and benchmark kernels used in the simulation studies of SMC performance <ref> [McK93a, McK93c, McK94c] </ref>, and Section 9 correlates the performance curves generated by our analytic models with sample simulation results. 2. The SMC Moyer develops algorithms and analyzes the performance benefits and limitations of doing compile-time access ordering [Moy93]. <p> What follows is an overview of the dynamic access ordering architecture proposed in the uniprocessor and SMP SMC reports <ref> [McK93a, McK93c, McK94c] </ref>. Our discussion is based on the simplified architectures of Figure 1 and Figure 2. In these systems, memory is interfaced to the CPU or computational elements (CEs) through a controller labeled MSU for Memory Scheduling Unit. <p> Moreover, implementing such an algorithm might be expensive, both in the amount of hardware necessary and in the time required for it to run. Instead, we have developed a number of heuristics for dynamic access ordering; simulation results for these are presented elsewhere <ref> [McK93a, McK93c, McK94c] </ref>. Although we do not know precisely what the optimal ordering algorithm is, we can bound its performance. Taking advantage of the full bandwidth afforded by the memory system requires exploiting the page-mode capabilities of the memory components. <p> Complete uniprocessor results, including a detailed description of each access-ordering heuristic, can be found in [McK93a]; highlights of these results are presented in [McK94a, McK94b]. Complete shared-memory multiprocessor results can be found in <ref> [McK94c] </ref>. <p> The erratic shape of the simulation performance curve in Figure 14 (b) results from using FIFO depths that are less than the number of memory banks; see the SMP SMC report for an explanation of the phenomenon <ref> [McK94c] </ref>. computations with 80,000-element vectors.
Reference: [McM86] <author> McMahon, F.H., </author> <title> The Livermore Fortran Kernels: A Computer Test of the Numerical Performance Range, </title> <institution> Lawrence Livermore National Laboratory, UCRL-53745, </institution> <month> December, </month> <year> 1986. </year>
Reference: [Moy93] <author> Moyer, S.A., </author> <title> Access Ordering and Effective Memory Bandwidth, </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, University of Virginia, </institution> <type> Technical Report CS-93-18, </type> <month> April, </month> <year> 1993. </year>
Reference-contexts: The SMC Moyer develops algorithms and analyzes the performance benefits and limitations of doing compile-time access ordering <ref> [Moy93] </ref>. His scheme involves unrolling loops and grouping accesses to each stream, so that the cost of each DRAM page-miss can be amortized over several accesses that hit the current page.
Reference: [Ost89] <author> Osterhaug, Anita, ed., </author> <title> Guide to Parallel Programming on Sequent Computer Systems, </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: On a 16-bank system, the vectors cross DRAM page boundaries at element 8192; on a 32-bank system, at element 16,384; and so on. Three general scheduling techniques are commonly used to parallelize workloads: prescheduling, static scheduling, and dynamic scheduling <ref> [Ost89] </ref>. Prescheduling requires that the programmer divide the workload among the CEs before compiling the program.
Reference: [Qui91] <author> Quinnell, R., </author> <title> High-speed DRAMs, </title> <type> EDN, </type> <month> May 23, </month> <year> 1991. </year>
Reference-contexts: Not only must we find ways to improve cache performance, but we must provide alternatives for computations for which caching is insufficient. For instance, most memory devices manufactured in the last decade provide special capabilities that make it possible to perform some access sequences faster than others <ref> [IEEE92, Ram92, Qui91] </ref>, and exploiting these component characteristics can dramatically improve effective bandwidth. For applications that perform vector-like memory accesses, bandwidth can be increased by reordering the requests to take advantage of device properties such as fast-page mode.
Reference: [Ram92] <institution> Architectural Overview, Rambus Inc., Mountain View, </institution> <address> CA, </address> <year> 1992. </year>
Reference-contexts: Not only must we find ways to improve cache performance, but we must provide alternatives for computations for which caching is insufficient. For instance, most memory devices manufactured in the last decade provide special capabilities that make it possible to perform some access sequences faster than others <ref> [IEEE92, Ram92, Qui91] </ref>, and exploiting these component characteristics can dramatically improve effective bandwidth. For applications that perform vector-like memory accesses, bandwidth can be increased by reordering the requests to take advantage of device properties such as fast-page mode.
References-found: 18

