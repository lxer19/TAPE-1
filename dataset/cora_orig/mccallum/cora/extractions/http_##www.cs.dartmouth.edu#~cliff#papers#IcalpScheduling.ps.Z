URL: http://www.cs.dartmouth.edu/~cliff/papers/IcalpScheduling.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~cliff/papers/
Root-URL: http://www.cs.dartmouth.edu
Title: Improved Scheduling Algorithms for Minsum Criteria (Extended Abstract)  
Author: Soumen Chakrabarti Cynthia A. Phillips Andreas S. Schulz David B. Shmoys Cliff Stein Joel Wein 
Abstract: We consider the problem of finding near-optimal solutions for a variety of N P-hard scheduling problems for which the objective is to minimize the total weighted completion time. Recent work has led to the development of several techniques that yield constant worst-case bounds in a number of settings. We continue this line of research by providing improved performance guarantees for several of the most basic scheduling models, and by giving the first constant performance guarantee for a number of more realistically constrained scheduling problems. For example, we give an improved performance guarantee for minimizing the total weighted completion time subject to release dates on a single machine, and subject to release dates and/or precedence constraints on identical parallel machines. We also give improved bounds on the power of preemption in scheduling jobs with release dates on parallel machines. We give improved on-line algorithms for many more realistic scheduling models, including environments with parallelizable jobs, jobs contending for shared resources, tree precedence-constrained jobs, as well as shop scheduling models. In several of these cases, we give the first constant performance guarantee achieved on-line. Finally, one of the consequences of our work is the surprising structural property that there are schedules that simultaneously approximate the optimal makespan and the optimal weighted completion time to within small constants. Not only do such schedules exist, but we can find approximations to them with an on-line algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Applegate and W. Cook. </author> <title> A computational study of the job-shop scheduling problem. </title> <journal> ORSA Journal of Computing, </journal> <volume> 3 </volume> <pages> 149-156, </pages> <year> 1991. </year>
Reference-contexts: Minimizing the makespan of job shops is perhaps the most notorious of difficult N P -hard scheduling problems; even small instances are difficult to solve to optimality <ref> [1] </ref> and the best approximation algorithms give polylogarithmic performance guarantees [19]. We give the first constant-factor approximations for min-sum shop scheduling with a fixed number of machines m.
Reference: 2. <editor> I. Barany and T. Fiala. Tobbgepes utemezesi problemak kozel optimalis megoldasa. Szigma-Mat.-Kozgazdasagi Folyoirat, </editor> <volume> 15 </volume> <pages> 177-191, </pages> <year> 1982. </year>
Reference-contexts: For an open shop instance a nonpreemptive schedule of length P max + max (2 + *)D, and a preemptive schedule of length max (P max ; max ) (1 + *)D can be constructed <ref> [9, 2] </ref>. For job shop scheduling we can adapt the known (2 + *)-approximation makespan algorithm for fixed m [19]. Theorem 10.
Reference: 3. <author> A. Blum, P. Chalasani, D. Coppersmith, B. Pulleyblank, P. Raghavan, and M. Sudan. </author> <title> The minimum latency problem. </title> <booktitle> In STOC 26, </booktitle> <pages> pages 163-172, </pages> <year> 1994. </year>
Reference-contexts: The result of Goemans & Kleinberg improves upon a result of Blum et al., who present a similar bicriteria result for traveling-salesman type problems <ref> [3] </ref>; we show that their approach applies to a very general class of scheduling problems.
Reference: 4. <author> J.L. Bruno, E.G. Coffman, and R. Sethi. </author> <title> Scheduling independent tasks to reduce mean finishing time. </title> <journal> Communications of the ACM, </journal> <volume> 17 </volume> <pages> 382-387, </pages> <year> 1974. </year>
Reference-contexts: Department of Computer Science, Polytechnic University, Brooklyn, NY, 11201. Research partially supported by NSF Research Initiation Award CCR-9211494 and a grant from the New York State Science and Technology Foundation, through its Center for Advanced Technology in Telecommunications. been known to be polynomial-time solvable <ref> [21, 4, 12] </ref>; when one adds release dates, precedence constraints, or weights, essentially all versions of the problem become N P-hard, and until [16, 11, 18] very little was known about approximation algorithms with good performance guarantees. Recent progress on these problems follows from two basic approaches.
Reference: 5. <author> S. Chakrabarti and S. Muthukrishnan. </author> <title> Resource scheduling for parallel database and scientific applications. </title> <note> To appear in SPAA 96, </note> <month> June </month> <year> 1996. </year>
Reference-contexts: and forest precedence on parallel machines, and a randomized on-line algorithm with expected performance within 5:78 of optimal. 4.3 Perfectly malleable jobs with tree precedence We shall consider perfectly malleable jobs, as in Feldmann et al [6], and out-tree precedence constraints. (A study of precedence and non-malleability is initiated in <ref> [5] </ref>.) Our DualPack routine is as follows.
Reference: 6. <author> A. Feldmann, M. Kao, J. Sgall, and S. Teng. </author> <title> Optimal online scheduline of parallel jobs with dependencies. </title> <booktitle> In STOC 25, </booktitle> <pages> pages 642-653, </pages> <year> 1993. </year>
Reference-contexts: algorithm to minimize the average weighted completion time of sequential jobs with release dates and forest precedence on parallel machines, and a randomized on-line algorithm with expected performance within 5:78 of optimal. 4.3 Perfectly malleable jobs with tree precedence We shall consider perfectly malleable jobs, as in Feldmann et al <ref> [6] </ref>, and out-tree precedence constraints. (A study of precedence and non-malleability is initiated in [5].) Our DualPack routine is as follows. We remove from J any j with PathToRoot (j) &gt; D, set J 0 = Knapsack (J ` ; mD), and list schedule J 0 as in [6]: let = <p> et al <ref> [6] </ref>, and out-tree precedence constraints. (A study of precedence and non-malleability is initiated in [5].) Our DualPack routine is as follows. We remove from J any j with PathToRoot (j) &gt; D, set J 0 = Knapsack (J ` ; mD), and list schedule J 0 as in [6]: let = ( 5 1)=2 be the golden ratio; whenever there is a job j with all of its predecessors completed and the number of busy processors is less than m, schedule the job on the minimum of m j and the number of free processors. Theorem 8.
Reference: 7. <author> M.R. Garey and R.L. Graham. </author> <title> Bounds for multiprocessor scheduling with resource constraints. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4 </volume> <pages> 187-200, </pages> <year> 1975. </year>
Reference-contexts: We set the weight and size of job j 2 J to be w j and m j p j , respectively, and then call Knapsack, setting J 0 = Knapsack (J; mD). Finally, we adapt the list scheduling algorithm of Garey & Graham <ref> [7] </ref> to schedule J 0 . Theorem 6. The above DualPack routine is a dual (3 + *)-approximation algorithm for the maximum scheduled weight problem. <p> This gives a deterministic on-line (12+*)-approximation algorithm for scheduling malleable jobs on parallel machines, and a randomized on-line algorithm with expected performance within 8:67 of optimal. Using the multidimensional knapsack routine in x4.4, together with adaptations of graph labeling results of <ref> [7] </ref>, we can also generalize non-malleable jobs to resource constrained jobs. In this model, each job j holds r ij 1 units of resource type i, i = 1; . . .; m, while it runs for duration p j .
Reference: 8. <author> M. Goemans and J. Kleinberg. </author> <title> An improved approximation ratio for the minimum latency problem. </title> <booktitle> In SODA 7, </booktitle> <pages> pages 152-157, </pages> <year> 1996. </year>
Reference-contexts: In the second part of the paper we give a framework for designing on-line algorithms that minimize the average weighted completion time, by improving and extending a result of Hall, Shmoys, & Wein [11]. By incorporating an idea of Goemans & Kleinberg <ref> [8] </ref> that exploits randomization in an elegant way, we can improve the performance guarantee of the resulting algorithms; the resulting bounds are quite strong, and in certain cases even improve upon off-line bounds achieved via the linear programming formulations previously discussed. <p> By incorporating an idea of Goemans & Kleinberg <ref> [8] </ref> that exploits randomization in an elegant way, we can improve the performance guarantee of the resulting algorithms. Furthermore, we show that this framework actually produces a schedule that is simultaneously near-optimal with respect to both the total weighted completion time objective, and the maximum completion time objective. <p> Coster [13] have given a family of unrelated parallel machine instances for which all minimum total completion time schedules have makespan that is an (log n) factor greater than the optimal makespan. 3.1 Applying randomization to other interval-based algorithms We can also use the randomized technique of Goemans and Kleinberg <ref> [8] </ref> to improve LP-based results of Hall, Schulz, Shmoys, & Wein [10]. In particular, we improve upon a 7-approximation algorithm for the problem of minimizing the total weighted completion time on scheduling parallel machines subject to precedence constraints and release dates.
Reference: 9. <author> T. Gonzalez and S. Sahni. </author> <title> Open shop scheduling to minimize finish time. </title> <journal> Journal of the ACM, </journal> <volume> 23 </volume> <pages> 665-679, </pages> <year> 1976. </year>
Reference-contexts: For an open shop instance a nonpreemptive schedule of length P max + max (2 + *)D, and a preemptive schedule of length max (P max ; max ) (1 + *)D can be constructed <ref> [9, 2] </ref>. For job shop scheduling we can adapt the known (2 + *)-approximation makespan algorithm for fixed m [19]. Theorem 10.
Reference: 10. <author> L.A. Hall, A.S. Schulz, D.B. Shmoys, and J. Wein. </author> <title> Scheduling to minimize average completion time: Off-line and on-line algorithms. </title> <note> Joint journal version of [11] and [18]; in preparation. </note>
Reference-contexts: This result yields the best known performance guarantee for minimizing the total weighted completion time subject to release date constraints in either a single-machine or a parallel-machine environment, improving results of <ref> [11, 18, 10] </ref>. Observe that in Corollary 4, we did not state that the two bounds could be achieved by the same schedule. <p> for which all minimum total completion time schedules have makespan that is an (log n) factor greater than the optimal makespan. 3.1 Applying randomization to other interval-based algorithms We can also use the randomized technique of Goemans and Kleinberg [8] to improve LP-based results of Hall, Schulz, Shmoys, & Wein <ref> [10] </ref>. In particular, we improve upon a 7-approximation algorithm for the problem of minimizing the total weighted completion time on scheduling parallel machines subject to precedence constraints and release dates. The algorithm of [10] first solves an LP relaxation of this problem to obtain an optimal solution e C j . <p> randomized technique of Goemans and Kleinberg [8] to improve LP-based results of Hall, Schulz, Shmoys, & Wein <ref> [10] </ref>. In particular, we improve upon a 7-approximation algorithm for the problem of minimizing the total weighted completion time on scheduling parallel machines subject to precedence constraints and release dates. The algorithm of [10] first solves an LP relaxation of this problem to obtain an optimal solution e C j . <p> Given this solution, the algorithm partitions the time horizon into intervals. Set t ` = ff2 ` , ` = 1; . . . ; L, where we will judiciously choose ff 2 [0:5; 1). (In <ref> [10] </ref>, this value was, in essence, 0.5.) We partition the time horizon into the intervals (t `1 ; t ` ], ` = 1; 2; . . .; L, where L is chosen so that each e C j value is contained in some interval. <p> For each j 2 J ` , we can bound the completion time of j in this schedule by fi j + 6t `1 , where fi j is the length of some chain that ends with job j. This yields the performance guarantee of 7 of <ref> [10] </ref>. Let B j = t `1 as in the on-line case. Thus, if ff is set equal to 2 X where X is selected uniformly from (0; 1], then the expected value of 6B j is equal to 3 ln 2 e C j . <p> Of course, we can derandomize the algorithm as well. Theorem 5. There is a 5:33-approximation algorithm for nonpreemptively scheduling on parallel machines with release dates and precedence constraints. Applying techniques used in <ref> [10] </ref>, it is also quite straightforward to generalize this theorem to the setting in which machine i runs at speed s i .
Reference: 11. <author> L.A. Hall, D.B. Shmoys, and J. Wein. </author> <title> Scheduling to minimize average completion time: Off-line and on-line algorithms. </title> <booktitle> In SODA 7, </booktitle> <pages> pages 142-151, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction Recently there has been significant progress in giving approximation algorithms to minimize average weighted completion time for a variety of N P -hard scheduling problems <ref> [16, 11, 18] </ref>. Constructing a schedule to minimize average completion time in a one-machine or parallel machine scheduling environment has long ? soumen@cs.berkeley.edu. Computer Science Division, U. C. Berkeley, CA 94720. Supported partly by ARPA/DOD (DABT63-92-C-0026), DOE (DE-FG03-94ER25206), and NSF (CCR-9210260, CDA-8722788 and CDA-9401156). <p> CCR-9211494 and a grant from the New York State Science and Technology Foundation, through its Center for Advanced Technology in Telecommunications. been known to be polynomial-time solvable [21, 4, 12]; when one adds release dates, precedence constraints, or weights, essentially all versions of the problem become N P-hard, and until <ref> [16, 11, 18] </ref> very little was known about approximation algorithms with good performance guarantees. Recent progress on these problems follows from two basic approaches. <p> In this paper we improve and extend these techniques. We develop new analytical tools that lead to improved off-line and on-line approximation algorithms for many of the problems considered in <ref> [16, 11, 18] </ref>. By on-line, we mean that the algorithm constructs the schedule in time, and that the existence of a job is known only at its release date. We also extend the on-line techniques to a number of different scheduling models. <p> This proved to be an important observation, for a generalization of this idea proved to be a powerful tool in rounding solutions to linear programming formulations of a number of scheduling problems <ref> [11, 18] </ref>. In this paper we give improved rounding techniques for these problems; specifically, we give an algorithm that takes a preemptive parallel machine schedule of average completion time C and converts it to a nonpreemptive schedule of average completion time 7 3 C. <p> In the second part of the paper we give a framework for designing on-line algorithms that minimize the average weighted completion time, by improving and extending a result of Hall, Shmoys, & Wein <ref> [11] </ref>. By incorporating an idea of Goemans & Kleinberg [8] that exploits randomization in an elegant way, we can improve the performance guarantee of the resulting algorithms; the resulting bounds are quite strong, and in certain cases even improve upon off-line bounds achieved via the linear programming formulations previously discussed. <p> In Section 3 we give different techniques that yield better randomized performance guarantees. 3 An on-line framework for bicriteria scheduling In this section, we will improve and extend a result of Hall, Shmoys, & Wein <ref> [11] </ref>, that gives a framework for designing on-line algorithms that minimize the total weighted completion time. By incorporating an idea of Goemans & Kleinberg [8] that exploits randomization in an elegant way, we can improve the performance guarantee of the resulting algorithms. <p> Hall, Shmoys, & Wein <ref> [11] </ref> show that Greedy-Interval finds a schedule of total weighted completion time at most 4 P n P n j : The value B j , for a particular j 2 f1; . . .; ng, is determined by the choice of ff and the value of C fl j . <p> This result yields the best known performance guarantee for minimizing the total weighted completion time subject to release date constraints in either a single-machine or a parallel-machine environment, improving results of <ref> [11, 18, 10] </ref>. Observe that in Corollary 4, we did not state that the two bounds could be achieved by the same schedule.
Reference: 12. <author> W. Horn. </author> <title> Minimizing average flow time with parallel machines. </title> <journal> Operations Research, </journal> <volume> 21 </volume> <pages> 846-847, </pages> <year> 1973. </year>
Reference-contexts: Department of Computer Science, Polytechnic University, Brooklyn, NY, 11201. Research partially supported by NSF Research Initiation Award CCR-9211494 and a grant from the New York State Science and Technology Foundation, through its Center for Advanced Technology in Telecommunications. been known to be polynomial-time solvable <ref> [21, 4, 12] </ref>; when one adds release dates, precedence constraints, or weights, essentially all versions of the problem become N P-hard, and until [16, 11, 18] very little was known about approximation algorithms with good performance guarantees. Recent progress on these problems follows from two basic approaches.
Reference: 13. <author> C.A.J. Hurkens and M.J. Coster. </author> <title> On the makespan of a schedule minimizing total completion time for unrelated parallel machines. </title> <type> Unpublished manuscript. </type>
Reference-contexts: Hence, C N j for each job j. This proof can be refined to yield somewhat better constants; the details will be given in the complete version of the paper. In contrast to this result, Hurkens & Coster <ref> [13] </ref> have given a family of unrelated parallel machine instances for which all minimum total completion time schedules have makespan that is an (log n) factor greater than the optimal makespan. 3.1 Applying randomization to other interval-based algorithms We can also use the randomized technique of Goemans and Kleinberg [8] to
Reference: 14. <author> D.S. Johnson and K.A. Niemi. </author> <title> On knapsacks, partitions, and a new dynamic programming technique for trees. </title> <journal> Mathematics of Operations Research, </journal> <volume> 8 </volume> <pages> 1-14, </pages> <year> 1983. </year>
Reference-contexts: To achieve this, we round down each s j by units of *S=n and then use dynamic programming as in <ref> [14] </ref>. In each of the following subsections, we will give an implementation of DualPack for a specific problem; throughout, we denote the deadline by D and the set of jobs from which we choose by J .
Reference: 15. <author> W. Ludwig and P. Tiwari. </author> <title> Scheduling malleable and nonmalleable parallel tasks. </title> <booktitle> in SODA 5, </booktitle> <pages> pages 167-176, </pages> <year> 1994. </year>
Reference-contexts: The best off-line performance guarantee known for the non-malleable special case, without release dates, is 8.53, due to Turek et al [22]; by applying an idea of Ludwig & Tiwari <ref> [15] </ref>, this can be extended to the malleable case. Our on-line min-sum algorithm with release dates has a performance guarantee of 12 + *, and if we allow randomization, a nearly identical guarantee of 8:67.
Reference: 16. <author> C. Phillips, C. Stein, and J. Wein. </author> <title> Scheduling jobs that arrive over time. </title> <booktitle> In WADS 4, </booktitle> <pages> pages 86-97, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction Recently there has been significant progress in giving approximation algorithms to minimize average weighted completion time for a variety of N P -hard scheduling problems <ref> [16, 11, 18] </ref>. Constructing a schedule to minimize average completion time in a one-machine or parallel machine scheduling environment has long ? soumen@cs.berkeley.edu. Computer Science Division, U. C. Berkeley, CA 94720. Supported partly by ARPA/DOD (DABT63-92-C-0026), DOE (DE-FG03-94ER25206), and NSF (CCR-9210260, CDA-8722788 and CDA-9401156). <p> CCR-9211494 and a grant from the New York State Science and Technology Foundation, through its Center for Advanced Technology in Telecommunications. been known to be polynomial-time solvable [21, 4, 12]; when one adds release dates, precedence constraints, or weights, essentially all versions of the problem become N P-hard, and until <ref> [16, 11, 18] </ref> very little was known about approximation algorithms with good performance guarantees. Recent progress on these problems follows from two basic approaches. <p> In this paper we improve and extend these techniques. We develop new analytical tools that lead to improved off-line and on-line approximation algorithms for many of the problems considered in <ref> [16, 11, 18] </ref>. By on-line, we mean that the algorithm constructs the schedule in time, and that the existence of a job is known only at its release date. We also extend the on-line techniques to a number of different scheduling models. <p> The first part of the paper has its roots in the observation that one may construct a nonpreemptive parallel machine schedule by list scheduling in order of the completion times of a preemptive schedule while at most losing a factor of (3 1 m ) in average weighted completion time <ref> [16] </ref>. This proved to be an important observation, for a generalization of this idea proved to be a powerful tool in rounding solutions to linear programming formulations of a number of scheduling problems [11, 18]. <p> This improves on the bound of (3 1 m ), given by Phillips, Stein and Wein <ref> [16] </ref>. We then use this technique to obtain a 3:5 approximation algorithm for P jr j j C j , improving upon the best previous bound of (4 1 m ) [18]. We use the algorithm Convert, introduced by [16], which takes a preemptive schedule P and list schedules the jobs <p> of (3 1 m ), given by Phillips, Stein and Wein <ref> [16] </ref>. We then use this technique to obtain a 3:5 approximation algorithm for P jr j j C j , improving upon the best previous bound of (4 1 m ) [18]. We use the algorithm Convert, introduced by [16], which takes a preemptive schedule P and list schedules the jobs nonpreemptively in the order of their completion times in P . Each job in turn is scheduled as early as possible without violating its release date, and without disturbing the jobs that have already been scheduled. <p> Next we show that given a preemptive schedule P for parallel machine scheduling with release dates, algorithm Convert produces a nonpreemptive schedule N in which C N 2C K + 3C L 1 + 2C L 2 . Phillips, Stein, and Wein <ref> [16] </ref> show that C N j 2C P j + p j . <p> Balancing the two cases proves the theorem. ut This theorem improves upon the previous best bound of (3 1 m ) for the ratio of average completion time in preemptive vs. nonpreemptive schedules; however, the best known preemptive algorithm is a 2-approximation algorithm <ref> [16] </ref>; therefore a direct application of this theorem does not give an approximation algorithm with an improved performance guarantee.
Reference: 17. <author> M. Queyranne and A.S. Schulz. </author> <title> Polyhedral approaches to machine scheduling. </title> <type> Preprint 408/1994, </type> <institution> Dept. of Mathematics, Technical University of Berlin, </institution> <year> 1994. </year>
Reference: 18. <author> A.S. Schulz. </author> <title> Scheduling to minimize total weighted completion time: Performance guarantees of LP-based heuristics and lower bounds. </title> <type> Preprint 474/1995, </type> <institution> Dept. of Mathematics, Technical University of Berlin. </institution> <note> To appear in IPCO V, </note> <month> June </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Recently there has been significant progress in giving approximation algorithms to minimize average weighted completion time for a variety of N P -hard scheduling problems <ref> [16, 11, 18] </ref>. Constructing a schedule to minimize average completion time in a one-machine or parallel machine scheduling environment has long ? soumen@cs.berkeley.edu. Computer Science Division, U. C. Berkeley, CA 94720. Supported partly by ARPA/DOD (DABT63-92-C-0026), DOE (DE-FG03-94ER25206), and NSF (CCR-9210260, CDA-8722788 and CDA-9401156). <p> CCR-9211494 and a grant from the New York State Science and Technology Foundation, through its Center for Advanced Technology in Telecommunications. been known to be polynomial-time solvable [21, 4, 12]; when one adds release dates, precedence constraints, or weights, essentially all versions of the problem become N P-hard, and until <ref> [16, 11, 18] </ref> very little was known about approximation algorithms with good performance guarantees. Recent progress on these problems follows from two basic approaches. <p> In this paper we improve and extend these techniques. We develop new analytical tools that lead to improved off-line and on-line approximation algorithms for many of the problems considered in <ref> [16, 11, 18] </ref>. By on-line, we mean that the algorithm constructs the schedule in time, and that the existence of a job is known only at its release date. We also extend the on-line techniques to a number of different scheduling models. <p> This proved to be an important observation, for a generalization of this idea proved to be a powerful tool in rounding solutions to linear programming formulations of a number of scheduling problems <ref> [11, 18] </ref>. In this paper we give improved rounding techniques for these problems; specifically, we give an algorithm that takes a preemptive parallel machine schedule of average completion time C and converts it to a nonpreemptive schedule of average completion time 7 3 C. <p> As a corollary, this gives the same bound on the power of preemption in this scheduling environment; allowing preemption improves the average completion time by at most a factor of 7 3 . When applied to the solution of a linear programming formulation considered by Schulz <ref> [18] </ref> and independently by Queyranne and by Hall, Shmoys & Wein, this technique yields a 3:5-approximation algorithm for the nonpreemptive scheduling of parallel machines subject to release dates to minimize average completion time; this improves on the previous best bound of (4 1 m ). <p> This improves on the bound of (3 1 m ), given by Phillips, Stein and Wein [16]. We then use this technique to obtain a 3:5 approximation algorithm for P jr j j C j , improving upon the best previous bound of (4 1 m ) <ref> [18] </ref>. We use the algorithm Convert, introduced by [16], which takes a preemptive schedule P and list schedules the jobs nonpreemptively in the order of their completion times in P . <p> We can, however, apply it to a different relaxation of the nonpreemptive schedule and obtain an improved ap proximation bound; we also believe that the ideas will prove useful in sharpening the analysis of other linear programming formulations for scheduling problems. Schulz <ref> [18] </ref>, and independently Queyranne and Hall, Shmoys and Wein, have given a (4 1 m )-approximation algorithm for nonpreemptively scheduling parallel machines with release dates to minimize average weighted completion time, which is based on the LP-relaxation of a formulation in completion time variables: with each job j is associated a <p> This result yields the best known performance guarantee for minimizing the total weighted completion time subject to release date constraints in either a single-machine or a parallel-machine environment, improving results of <ref> [11, 18, 10] </ref>. Observe that in Corollary 4, we did not state that the two bounds could be achieved by the same schedule. <p> No approximation algorithms were known for minimizing average completion time in shop scheduling, except for the recent results by Schulz that give an m-approximation algorithm for flow shop scheduling, the special case of job shop in which the order is the same for each job <ref> [18] </ref>. We assume for ease of presentation that each job has at most one operation on a machine; let p ij be the size of the operation of job j on machine i. We again give a version of DualPack for this problem.
Reference: 19. <author> D.B. Shmoys, C. Stein, and J. Wein. </author> <title> Improved approximation algorithms for shop scheduling problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 23 </volume> <pages> 617-632, </pages> <year> 1994. </year>
Reference-contexts: Minimizing the makespan of job shops is perhaps the most notorious of difficult N P -hard scheduling problems; even small instances are difficult to solve to optimality [1] and the best approximation algorithms give polylogarithmic performance guarantees <ref> [19] </ref>. We give the first constant-factor approximations for min-sum shop scheduling with a fixed number of machines m. <p> For job shop scheduling we can adapt the known (2 + *)-approximation makespan algorithm for fixed m <ref> [19] </ref>. Theorem 10.
Reference: 20. <author> D.B. Shmoys and E. Tardos. </author> <title> Scheduling parallel machines with costs. </title> <booktitle> In SODA 4, </booktitle> <pages> pages 448-455, </pages> <year> 1993. </year>
Reference: 21. <author> W.E. Smith. </author> <title> Various optimizers for single-stage production. </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 3 </volume> <pages> 59-66, </pages> <year> 1956. </year>
Reference-contexts: Department of Computer Science, Polytechnic University, Brooklyn, NY, 11201. Research partially supported by NSF Research Initiation Award CCR-9211494 and a grant from the New York State Science and Technology Foundation, through its Center for Advanced Technology in Telecommunications. been known to be polynomial-time solvable <ref> [21, 4, 12] </ref>; when one adds release dates, precedence constraints, or weights, essentially all versions of the problem become N P-hard, and until [16, 11, 18] very little was known about approximation algorithms with good performance guarantees. Recent progress on these problems follows from two basic approaches.
Reference: 22. <author> J. Turek, U. Schwiegelshohn, J. Wolf, and P. Yu. </author> <title> Scheduling parallel tasks to minimize average response time. </title> <booktitle> In SODA 5, </booktitle> <pages> pages 112-121, </pages> <year> 1994. </year> <title> This article was processed using the L a TLB.7exEX macro package with LLNCS style </title>
Reference-contexts: The best off-line performance guarantee known for the non-malleable special case, without release dates, is 8.53, due to Turek et al <ref> [22] </ref>; by applying an idea of Ludwig & Tiwari [15], this can be extended to the malleable case. Our on-line min-sum algorithm with release dates has a performance guarantee of 12 + *, and if we allow randomization, a nearly identical guarantee of 8:67.
References-found: 22

