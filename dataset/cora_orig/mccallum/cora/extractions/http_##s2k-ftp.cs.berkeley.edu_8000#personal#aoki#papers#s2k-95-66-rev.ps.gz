URL: http://s2k-ftp.cs.berkeley.edu:8000/personal/aoki/papers/s2k-95-66-rev.ps.gz
Refering-URL: http://s2k-ftp.cs.berkeley.edu:8000/mariposa/papers.html
Root-URL: 
Email: aoki@CS.Berkeley.EDU  
Title: Recycling Secondary Index Structures  
Author: Paul M. Aoki 
Address: Berkeley, CA 94720-1776  
Affiliation: Department of Electrical Engineering and Computer Sciences University of California  
Abstract: Many database reorganization techniques move tuples in a table from one location to another in a single pass. For example, distributed database systems move or copy tables between sites to optimize data placement. However, such systems typically drop and then rebuild the secondary indices defined over the table being moved. There are two primary reasons for this. First, moving a table invalidates any physical tuple pointers contained in its secondary indices (e.g., in the leaves of a tree). Second, changes in tuple or page size can cause index tuples on the remote site to be repacked onto pages in a way that degrades the clustering imposed by the structure (e.g., in the upper levels of an R-tree). The cost of rebuilding secondary indices is largely why table movement has been considered a expensive operation. This, in turn, means that data layout optimization has been considered expensive as well. In this paper, we present a simple, efficient mechanism for translating index pointers as well as an approach to preserving internal index clustering. By exploiting the structure of the original index, we can recycle its important properties and produce a usable index on the remote site without the expense of building one from scratch. We also demonstrate the effectiveness of these mechanisms using performance measurements of an implementation in the Mariposa distributed data manager. 
Abstract-found: 1
Intro-found: 1
Reference: [AOKI95] <author> P. M. Aoki, </author> <title> Recycling Secondary Index Structures, </title> <type> Sequoia 2000 Tech. Rep. 95/66, </type> <institution> Univ. of California, Berkeley, </institution> <address> CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Recall that tuples in S are copied into T in order. Hence, given the byte offset within a source TID, one can determine the exact t to which the corresponding target TID should point. A more detailed critique of the algorithm may be found in <ref> [AOKI95] </ref>; the main observation here is the fact that this method still does not allow the computation of the byte offset of the target TID. Like the Mariposa algorithm, this algorithm requires that the database fault in and search t in order to translate the byte offset. 5 3. <p> Reducing the 16 transmission delay due to index size and adding in the cost of an extra scan of the base table on the target machine results in the comp. slotted plot in Figure 5 (b). However, we cannot always apply this technique (see <ref> [AOKI95] </ref>). Under the characteristics described in this section, then, index recycling appears to be practical in local area (10-100 Mb/s) as well as metropolitan area ( 1 Mb/s) networks. However, below 100 Kb/s the scheme uses too much network bandwidth to be competitive. <p> Hence, index recycling appears to be an excellent way to put the table and an index on line quickly. 5. Future Work There are several interesting issues that arise in the implementation of index recycling. These are described in more detail in <ref> [AOKI95] </ref>. Lazy Translation: What are the performance tradeoffs of lazy and eager translation, given that the table and its indices may not be heavily used before the next time they are moved? Support for Additional Access Methods: Intelligent support for index types other than basic trees will require careful thought.
Reference: [CARE88] <author> M. J. Carey, D. J. DeWitt, G. Graefe, D. M. Haight, J. E. Richardson, D. T. Schuh, E. J. Shekita and S. L. Vandenberg, </author> <title> The EXODUS Extensible DBMS Project: An Overview, </title> <type> CS Tech. Rep. 808, </type> <institution> Univ. of Wisconsin, Madison, WI, </institution> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: A wide range of data managers use slotted pages, including relational and object-relational databases (e.g., nearly all IBM relational systems [MOHA93], Illustra [ILLU95], Oracle Rdb [HOBB91, p. 79]) as well as object data managers 3 (e.g., ESM <ref> [CARE88] </ref>, O 2 [DEUX90], Papyrus [CONN93], SHORE [CARE94]). The advantages of this scheme are discussed in more detail elsewhere [GRAY93, p. 755]. Item IDs have a critical property: unlike tuples, item IDs are fixed-size.
Reference: [CARE94] <author> M. J. Carey, D. J. DeWitt, M. J. Franklin, N. E. Hall, M. L. McAuliffe, J. F. Naughton, D. T. Schuh, M. H. Solomon, C. K. Tan, O. G. Tsatalos, S. J. White and M. J. Zwilling, </author> <title> Shoring Up Persistent Applications, </title> <booktitle> Proc. 1994 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994, </year> <pages> 383-394. </pages>
Reference-contexts: A wide range of data managers use slotted pages, including relational and object-relational databases (e.g., nearly all IBM relational systems [MOHA93], Illustra [ILLU95], Oracle Rdb [HOBB91, p. 79]) as well as object data managers 3 (e.g., ESM [CARE88], O 2 [DEUX90], Papyrus [CONN93], SHORE <ref> [CARE94] </ref>). The advantages of this scheme are discussed in more detail elsewhere [GRAY93, p. 755]. Item IDs have a critical property: unlike tuples, item IDs are fixed-size.
Reference: [COCK84] <author> W. P. Cockshot, M. P. Atkinson, K. J. Chisholm, P. J. Bailey and R. Morrison, </author> <title> Persistent Object Management System, </title> <journal> SoftwarePractice & Experience 14, </journal> <month> 1 (Jan. </month> <year> 1984), </year> <pages> 49-71. </pages>
Reference-contexts: This is discussed in more detail in [GRAY93, p. 760]. All are used in one system or another. For example, object systems (e.g., POMS <ref> [COCK84] </ref>) often use relative byte addresses, whereas relational systems (e.g., NonStop SQL) sometimes use primary keys as TIDs. In fact, most database systems use a particular kind of physiological TID instead of the physical TIDs discussed by Sun et al.
Reference: [CONN93] <author> T. Connors and M. Neimat, </author> <title> The Papyrus Object Library, </title> <booktitle> in Persistent Object Systems (Proc. 5th Int. Wksp. on Persistent Object Systems, </booktitle> <address> Pisa, Italy, </address> <month> Sep. </month> <year> 1992), </year> <editor> A. Albano and R. Morrison (ed.), </editor> <publisher> Springer Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1993, </year> <pages> 198-215. </pages>
Reference-contexts: A wide range of data managers use slotted pages, including relational and object-relational databases (e.g., nearly all IBM relational systems [MOHA93], Illustra [ILLU95], Oracle Rdb [HOBB91, p. 79]) as well as object data managers 3 (e.g., ESM [CARE88], O 2 [DEUX90], Papyrus <ref> [CONN93] </ref>, SHORE [CARE94]). The advantages of this scheme are discussed in more detail elsewhere [GRAY93, p. 755]. Item IDs have a critical property: unlike tuples, item IDs are fixed-size.
Reference: [DEWI91] <author> D. J. DeWitt, J. F. Naughton and D. A. Schneider, </author> <title> Parallel Sorting on a Shared-Nothing Architecture Using Probabilistic Splitting, </title> <booktitle> Proc. 1st Int. Conf. on Parallel and Dist. Info. Sys., </booktitle> <address> Miami Beach, FL, </address> <month> Dec. </month> <year> 1991, </year> <pages> 280-291. </pages>
Reference-contexts: Our external sorting routine follows the recent trend <ref> [DEWI91, GRAE92, NYBE94] </ref> toward quicksort-based run generation. 11 Index Base Table (Heap) Type Cardinality Size Distributions (tuples) (bytes) clustered unclustered B -tree 10 4 6 sorted random 10 10 sorted random 10 10 sorted random R-tree 1. 4 10 5 7 Hilbert (H 22 ) alphabetic 1. 4 10 1. 6
Reference: [DEUX90] <author> O. </author> <title> Deux et al., </title> <journal> The Story of O 2 , IEEE Trans. Knowledge and Data Eng. </journal> <volume> 2, </volume> <month> 1 (Mar. </month> <year> 1990), </year> <pages> 91-108. </pages>
Reference-contexts: A wide range of data managers use slotted pages, including relational and object-relational databases (e.g., nearly all IBM relational systems [MOHA93], Illustra [ILLU95], Oracle Rdb [HOBB91, p. 79]) as well as object data managers 3 (e.g., ESM [CARE88], O 2 <ref> [DEUX90] </ref>, Papyrus [CONN93], SHORE [CARE94]). The advantages of this scheme are discussed in more detail elsewhere [GRAY93, p. 755]. Item IDs have a critical property: unlike tuples, item IDs are fixed-size.
Reference: [EICK95] <author> A. Eickler, C. A. Gerlhof and D. Kossmann, </author> <title> A Performance Evaluation of OID Mapping Techniques, </title> <booktitle> Proc. 21st VLDB Conf., </booktitle> <address> Zurich, Switzerland, </address> <month> Sep. </month> <year> 1995, </year> <pages> 19-29. 20 </pages>
Reference-contexts: When main memory pointers are OIDs, the how (as opposed to the when) part of swizzling is known as the OID mapping problem. OID mapping mechanisms are generally more complex than arrays and include segmented mapping tables (e.g., ObServer [HORN87]), hash tables (e.g., Itasca <ref> [EICK95] </ref>) and B-trees (e.g., GemStone [MAIE87]). Mapping data structures that contain OID fi address entries work in the OODBMS environment because the database clusters and caches the mapping structure.
Reference: [GRAE92] <author> G. Graefe and S. S. Thakkar, </author> <title> Tuning a Parallel Database Algorithm on a Shared-Memory Multiprocessor, </title> <journal> SoftwarePractice & Experience 22, </journal> <month> 7 (July </month> <year> 1992), </year> <pages> 495-517. </pages>
Reference-contexts: Our external sorting routine follows the recent trend <ref> [DEWI91, GRAE92, NYBE94] </ref> toward quicksort-based run generation. 11 Index Base Table (Heap) Type Cardinality Size Distributions (tuples) (bytes) clustered unclustered B -tree 10 4 6 sorted random 10 10 sorted random 10 10 sorted random R-tree 1. 4 10 5 7 Hilbert (H 22 ) alphabetic 1. 4 10 1. 6
Reference: [GRAY93] <author> J. Gray and A. Reuter, </author> <title> Tr ansaction Processing: Concepts and Techniques, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Just as one can have physical, logical or physiological logging, one can have physical TIDs (e.g., relative byte addresses of the form -page,offset-), logical TIDs (e.g., primary key addresses of the form -key-), and any number of hybrid physiological TIDs (e.g., -page,key-). This is discussed in more detail in <ref> [GRAY93, p. 760] </ref>. All are used in one system or another. For example, object systems (e.g., POMS [COCK84]) often use relative byte addresses, whereas relational systems (e.g., NonStop SQL) sometimes use primary keys as TIDs. <p> The advantages of this scheme are discussed in more detail elsewhere <ref> [GRAY93, p. 755] </ref>. Item IDs have a critical property: unlike tuples, item IDs are fixed-size.
Reference: [HOBB91] <author> L. Hobbs and K. </author> <title> England, Rdb/VMS: A Comprehensive Guide, </title> <publisher> Digital Press, </publisher> <address> Bedford, MA, </address> <year> 1991. </year> <title> DEC Order Number EY-H873E-DP. </title>
Reference-contexts: A wide range of data managers use slotted pages, including relational and object-relational databases (e.g., nearly all IBM relational systems [MOHA93], Illustra [ILLU95], Oracle Rdb <ref> [HOBB91, p. 79] </ref>) as well as object data managers 3 (e.g., ESM [CARE88], O 2 [DEUX90], Papyrus [CONN93], SHORE [CARE94]). The advantages of this scheme are discussed in more detail elsewhere [GRAY93, p. 755]. Item IDs have a critical property: unlike tuples, item IDs are fixed-size.
Reference: [HORN87] <author> M. F. Hornick and S. B. Zdonik, </author> <title> A Shared, Segmented Memory System for an Object-Oriented Database, </title> <journal> Tr ans. on Office Info. Systems 5, </journal> <month> 1 (Jan. </month> <year> 1987), </year> <pages> 70-95. </pages>
Reference-contexts: When main memory pointers are OIDs, the how (as opposed to the when) part of swizzling is known as the OID mapping problem. OID mapping mechanisms are generally more complex than arrays and include segmented mapping tables (e.g., ObServer <ref> [HORN87] </ref>), hash tables (e.g., Itasca [EICK95]) and B-trees (e.g., GemStone [MAIE87]). Mapping data structures that contain OID fi address entries work in the OODBMS environment because the database clusters and caches the mapping structure.
Reference: [ILLU95] <institution> Illustra Information Technologies, </institution> <note> Illustra Server User's Guide, Version 3.2, </note> <institution> Illustra Information Technologies, Inc., </institution> <address> Oakland, CA, </address> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: A wide range of data managers use slotted pages, including relational and object-relational databases (e.g., nearly all IBM relational systems [MOHA93], Illustra <ref> [ILLU95] </ref>, Oracle Rdb [HOBB91, p. 79]) as well as object data managers 3 (e.g., ESM [CARE88], O 2 [DEUX90], Papyrus [CONN93], SHORE [CARE94]). The advantages of this scheme are discussed in more detail elsewhere [GRAY93, p. 755]. Item IDs have a critical property: unlike tuples, item IDs are fixed-size.
Reference: [KAME93] <author> I. Kamel and C. Faloutsos, </author> <title> On Packing R-trees, </title> <booktitle> Proc. 2nd Int. Conf. on Information and Knowledge Management, </booktitle> <address> Arlington, VA, </address> <month> Nov. </month> <year> 1993, </year> <pages> 490-499. </pages>
Reference-contexts: The base tables used in the B + -tree studies were loaded in both numerically sorted and random key order, whereas the base tables used in the R-tree studies were loaded in both least Hilbert value order <ref> [KAME93] </ref> and the alphabetic order in which the USGS distributes the data. The following conventions apply to all I/O measurements described hereafter. Page access counts include both reads and writes. <p> Retrieval Performance: Since we are concerned with the performance of actual index instances, we assess the goodness of an R-tree using the bounding box coverage metric of Kamel and Faloutsos <ref> [KAME93] </ref>: P ( q) = n=1 D P (x i,n + q i ) where fi fi q = (q 1 , . . . , q D ) are D-dimensional node bounding boxes and 17 query boxes with side length x i,n and q i , respectively, and P (
Reference: [KAME94] <author> I. Kamel and C. Faloutsos, Hilbert R-tree: </author> <title> An Improved R-tree Using Fractals, </title> <booktitle> Proc. 20th VLDB Conf., </booktitle> <address> Santiago, Chile, </address> <month> Sep. </month> <year> 1994, </year> <pages> 500-509. </pages>
Reference-contexts: Variations of the algorithms described can be applied to other structures (e.g., hash tables), but we restrict our discussion to those types of index for which we have implementations and benchmarks. There are two general types of hierarchical index structures: ordered (e.g., B + -trees, Hilbert R-trees <ref> [KAME94] </ref>) and unordered (e.g., R-trees). Generally speaking, a bottom-up recycling strategy similar to that described by Sun et al. should work for nearly any ordered structure. However, a bottom-up strategy may not necessarily work well for an unordered structure.
Reference: [MAIE87] <author> D. Maier and J. Stein, </author> <title> Development and Implementation of an Object-Oriented DBMS, in Research Directions in Object-Oriented Programming, </title> <editor> B. Shriver and P. Wegner (ed.), </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987, </year> <pages> 355-392. </pages> <note> Reprinted in: Readings in Object-Oriented Database Systems, </note> <editor> S. B. Zdonik and D. Maier (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: When main memory pointers are OIDs, the how (as opposed to the when) part of swizzling is known as the OID mapping problem. OID mapping mechanisms are generally more complex than arrays and include segmented mapping tables (e.g., ObServer [HORN87]), hash tables (e.g., Itasca [EICK95]) and B-trees (e.g., GemStone <ref> [MAIE87] </ref>). Mapping data structures that contain OID fi address entries work in the OODBMS environment because the database clusters and caches the mapping structure. However, when moving an index, we know we are processing all pointers contained in the index in a short period of time without locality guarantees.
Reference: [MOHA92] <author> C. Mohan and I. Narang, </author> <title> Algorithms for Creating Indexes for Very Large Tables Without Quiescing Updates, </title> <booktitle> Proc. 1992 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1992, </year> <pages> 361-370. </pages>
Reference-contexts: However, naive techniques of this kind are not concurrent; there are a variety of ways to improve reorganization concurrency while retaining recoverabil ity (e.g., <ref> [MOHA92, SRIN92] </ref>). 6. Conclusions While the ideas proposed in [SUN94] are useful, the algorithms described are not a good fit for implementation in existing systems. By adapting their algorithms for use with slotted pages, we have produced practical techniques for recycling secondary indices.
Reference: [MOHA93] <author> C. Mohan, </author> <title> IBM Relational DBMS Products: Features and Technologies, </title> <booktitle> Proc. 1993 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Washington, DC, </address> <month> May </month> <year> 1993, </year> <pages> 445-448. </pages>
Reference-contexts: A wide range of data managers use slotted pages, including relational and object-relational databases (e.g., nearly all IBM relational systems <ref> [MOHA93] </ref>, Illustra [ILLU95], Oracle Rdb [HOBB91, p. 79]) as well as object data managers 3 (e.g., ESM [CARE88], O 2 [DEUX90], Papyrus [CONN93], SHORE [CARE94]). The advantages of this scheme are discussed in more detail elsewhere [GRAY93, p. 755].
Reference: [NYBE94] <author> C. Nyberg, T. Barclay, Z. Cvetanovic, J. Gray and D. Lomet, AlphaSort: </author> <title> A RISC Machine Sort, </title> <booktitle> Proc. 1994 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994, </year> <pages> 233-242. </pages>
Reference-contexts: Our external sorting routine follows the recent trend <ref> [DEWI91, GRAE92, NYBE94] </ref> toward quicksort-based run generation. 11 Index Base Table (Heap) Type Cardinality Size Distributions (tuples) (bytes) clustered unclustered B -tree 10 4 6 sorted random 10 10 sorted random 10 10 sorted random R-tree 1. 4 10 5 7 Hilbert (H 22 ) alphabetic 1. 4 10 1. 6
Reference: [PEAR91] <author> C. Pearson, </author> <title> Moving Data in Parallel, </title> <booktitle> Digest of Papers, 36th IEEE Computer Society Int. Conf. (COMPCON Spring '91), </booktitle> <month> Feb. </month> <year> 1991, </year> <pages> 100-104. </pages>
Reference-contexts: Rebuilding indices from scratch has two major cost components. First, rebuilding is extremely time-consuming and resource-intensive. Time requirements can be reduced using parallel sorting and bulk-loading algorithms <ref> [PEAR91] </ref>, but resource requirements cannot. Second, proper indexing is critical to good performance and the table is likely to be useless while the table is being reindexed.
Reference: [SRIN92] <author> V. Srinivasan, </author> <title> On-Line Processing in Large-Scale Transaction Systems, </title> <type> Ph.D. thesis, </type> <institution> Univ. of Wisconsin, Madison, WI, </institution> <month> Jan. </month> <year> 1992. </year> <note> Also available as CS Tech. Rep. 1071. </note>
Reference-contexts: However, naive techniques of this kind are not concurrent; there are a variety of ways to improve reorganization concurrency while retaining recoverabil ity (e.g., <ref> [MOHA92, SRIN92] </ref>). 6. Conclusions While the ideas proposed in [SUN94] are useful, the algorithms described are not a good fit for implementation in existing systems. By adapting their algorithms for use with slotted pages, we have produced practical techniques for recycling secondary indices.
Reference: [STON87] <author> M. Stonebraker, </author> <title> The Design of the POSTGRES Storage System, </title> <booktitle> Proc. 13th VLDB Conf., </booktitle> <address> Brighton, England, </address> <month> Sep. </month> <year> 1987, </year> <pages> 289-300. </pages>
Reference-contexts: Such situations include moving a table to a different disk partition, changing a table's page size, defragmenting pages within a tablespace, and certain types of garbage collection (such as that performed by the POSTGRES vacuum cleaner <ref> [STON87] </ref>). Media interchange. Different storage devices may have different page sizes that are visible to the data manager. Our basic idea for making reindexing more efficient is that it is often cheaper to transmit a modified version of an index than to rebuild the index from scratch.
Reference: [STON93a] <author> M. Stonebraker, J. Frew, K. Gardels and J. Meredith, </author> <title> The Sequoia 2000 Storage Benchmark, </title> <booktitle> Proc. 1993 ACM-SIGMOD Conf. on Management of Data, </booktitle> <address> Washington, DC, </address> <month> May </month> <year> 1993, </year> <pages> 2-11. </pages>
Reference-contexts: The data sets for the R-tree tests consisted of geographic data obtained from the U. S. Geological Survey. The small data set was taken from the regional version of the Sequoia 2000 benchmark <ref> [STON93a] </ref> and contained 60,000 points and 80,000 polygons extracted from the USGS GNIS [USGS95] and Land Use 5 Our bulk-load routine uses the standard technique of extracting -key,TID- pairs from the base table, sorting the pairs into index leaf pages and then building the rest of the tree bottom-up.
Reference: [STON93b] <author> M. Stonebraker, P. M. Aoki, R. Devine, W. Litwin and M. Olson, Mariposa: </author> <title> A New Architecture for Distributed Data, </title> <type> Sequoia 2000 Tech. Rep. 93/31, </type> <institution> Univ. of California, Berkeley, </institution> <address> CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: However, all of them assume the use of physical -page,offset- TIDs. First, there have been a number of proposals that exploit (unrealistic) assumptions to provide precise translation of source TIDs to target TIDs. Second, the original Mariposa design <ref> [STON93b] </ref> provides an algorithm for mapping a source TID to a small range of potential target pages. Finally, Sun et al. give an algorithm that maps a source TID into the correct target page. 4 Under appropriate assumptions, we can map source TIDs directly into target TIDs. <p> This solution achieves our goal of storing only page-level mapping information, but the assumptions violate the conditions we stated in Section 1. [SUN94] and <ref> [STON93b] </ref> both contain a number of straw-man solutions similar to that just described. Unlike the above strawman proposal, Mariposa does assume that tuples can change size. Instead of using a constant expansion/contraction factor, the original Mariposa design proposes a simple page number translation table.
Reference: [STON94] <author> M. Stonebraker, P. M. Aoki, R. Devine, W. Litwin and M. Olson, Mariposa: </author> <title> A New Architecture for Distributed Data, </title> <booktitle> Proc. 10th IEEE Int. Conf. on Data Eng., </booktitle> <address> Houston, TX, </address> <month> Feb. </month> <year> 1994, </year> <pages> 54-65. </pages>
Reference-contexts: In the rest of the paper we discuss several implementation options, including some previously suggested in the literature, and present a comparative performance analysis based on an implementation of these options in the Mariposa distributed data manager <ref> [STON94] </ref>.
Reference: [SUN94] <author> W. Sun, W. Meng, C. Yu and W. Kim, </author> <title> An Efficient Way to Reestablish B + Trees in a Distributed Environment, </title> <booktitle> Information Sciences 77, </booktitle> <month> 3-4 (Mar. </month> <year> 1994), </year> <pages> 227-251. </pages>
Reference-contexts: Index bulk-load algorithms are also clearly relevant. However, there appears to be little work on reconstruction of indices based on the content and properties of existing indices. Sun et al. <ref> [SUN94] </ref> present an algorithm for reestablishing B + -tree indices in a distributed environment. Their algorithm makes no use of the overall tree structure; instead, it is a variation on the standard sort/build technique for bulk-loading B-trees. <p> This solution achieves our goal of storing only page-level mapping information, but the assumptions violate the conditions we stated in Section 1. <ref> [SUN94] </ref> and [STON93b] both contain a number of straw-man solutions similar to that just described. Unlike the above strawman proposal, Mariposa does assume that tuples can change size. Instead of using a constant expansion/contraction factor, the original Mariposa design proposes a simple page number translation table. <p> In that respect, our translation table is similar to the byte offset translation table from <ref> [SUN94] </ref>. The key difference is that each entry in our translation table stores the range of item ID array indices corresponding to the tuples that have been copied from s into t. <p> However, naive techniques of this kind are not concurrent; there are a variety of ways to improve reorganization concurrency while retaining recoverabil ity (e.g., [MOHA92, SRIN92]). 6. Conclusions While the ideas proposed in <ref> [SUN94] </ref> are useful, the algorithms described are not a good fit for implementation in existing systems. By adapting their algorithms for use with slotted pages, we have produced practical techniques for recycling secondary indices.
Reference: [USGS86] <author> U. S. </author> <title> Geological Survey, Land Use Land Cover Digital Data from 1:250,000 and 1:100,000-Scale Maps, Data Users Guide 4, </title> <editor> U. S. Geological Survey, U. S. </editor> <title> Department of the Interior, </title> <address> Reston, VA, </address> <year> 1986. </year>
Reference-contexts: Benchmark data sets. and Land Cover <ref> [USGS86] </ref> databases for the state of California. The large data set consisted of the contents of GNIS for the entire continental United States and contained nearly 1,400,000 points with their associated place names.
Reference: [USGS95] <author> U. S. </author> <title> Geological Survey, Geographic Names Information System, Data Users Guide 6 (4th printing, revised), </title> <editor> U. S. Geological Survey, U. S. </editor> <title> Department of the Interior, </title> <address> Reston, VA, </address> <year> 1995. </year> <month> 21 </month>
Reference-contexts: The data sets for the R-tree tests consisted of geographic data obtained from the U. S. Geological Survey. The small data set was taken from the regional version of the Sequoia 2000 benchmark [STON93a] and contained 60,000 points and 80,000 polygons extracted from the USGS GNIS <ref> [USGS95] </ref> and Land Use 5 Our bulk-load routine uses the standard technique of extracting -key,TID- pairs from the base table, sorting the pairs into index leaf pages and then building the rest of the tree bottom-up.
References-found: 28

