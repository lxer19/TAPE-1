URL: ftp://cse.ogi.edu/pub/dsrg/HOPE/cas92.ps.Z
Refering-URL: http://www.cse.ogi.edu/~crispin/
Root-URL: http://www.cse.ogi.edu
Email: crispin@csd.uwo.ca  
Title: Optimistic Replication in HOPE  
Author: Crispin Cowan 
Address: Middlesex College  Ontario London, Ontario N6A 5B7  
Affiliation: Computer Science Department  University of Western  
Abstract: The growing imbalance between network latency and throughput is causing nodes in distributed systems to appear to be moving farther apart. Many distributed systems are turning to replication as a mechanism to make resources appear closer. However, maintaining one-copy consistency in a system containing replicated elements has proven difficult. In particular, the checks required to make consistent updates can take as long or longer than the time that would be taken to update a single remote copy. Various optimistic concurrency control algorithms have been created to hide this latency. These systems hide latency by optimistically assuming that no conflict exists and performing the conflict check in parallel with the update. If the assumption proves correct, time has been saved. If the assumption proves incorrect, the update must be rolled back, along with any other computations that have become dependent on the results of this speculative update. Concurrency control algorithms are complex, and optimistic concurrency control is even more so. Optimistic algorithms in general tend to be complicated due to the need to perform dependency tracking and preserve sufficient state to be able to un-do speculative computations performed under an optimistic assumption. This paper describes a set of programming language constructs for the expression of optimistic algorithms known as HOPE. We present a description of the HOPE constructs, along with the programming language properties necessary to embed HOPE in a language. We then express several replication schemes from the literature in HOPE. The relative conceptual simplicity of the HOPE versions argues for the utility of HOPE in the construction of optimistic algorithms, particularly optimistic replication.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David F. Bacon and Robert E. Strom. </author> <title> Optimistic Parallelization of Communicating Sequential Processes. </title> <booktitle> In Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: The optimistic assumption is that the results of S1 do not influence S2, allowing S1 to be executed in parallel with S2. Strom and Yemini explored this notion, optimistic parallelization, in their 1987 paper [11], and Bacon and Strom elaborated on it in 1991 <ref> [1] </ref>. Optimistic assumptions can be made about causal ordering, consistency, atomicity, and even fault tolerance, yielding sophisticated optimistic algorithms. Optimistic algorithms have appeared in such disparate fields as caching, distributed discrete-event simulation, concur-rency control, and fault tolerance testifying to the versatility of optimistic techniques. <p> In [3] we present several algorithms for hiding latency through optimism expressed in HOPE, including Jefferson's Virtual Time [6], and Bacon and Strom's Call Streaming <ref> [1] </ref>. We begin this section by presenting Kung and Robinson's optimistic concurrency control algorithm, which is not replicated but does illustrate optimistic consistency.
Reference: [2] <author> P. Bernstein and N. Goodman. </author> <title> The Failure and Recovery Problem for Replicated Databases. </title> <booktitle> In Proc. of the 2nd ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 114-122, </pages> <month> August </month> <year> 1983. </year> <month> 19 </month>
Reference-contexts: However, most applica-tions are designed as if there is only a single copy of each object. A system which conforms to this view exhibits one copy serializability <ref> [2] </ref>. Maintaining this illusion requires a great deal of communication. Unfortunately, while replication sometimes reduces the latency of read operations, the increased communications overhead results in slower write operations. Optimism hides most forms of latency. Examples include caching, transaction processing, and in particular replication control.
Reference: [3] <author> Crispin Cowan. </author> <title> Language Constructs for Optimism. </title> <type> PhD Thesis Proposal. </type>
Reference-contexts: In <ref> [3] </ref> we present several algorithms for hiding latency through optimism expressed in HOPE, including Jefferson's Virtual Time [6], and Bacon and Strom's Call Streaming [1]. We begin this section by presenting Kung and Robinson's optimistic concurrency control algorithm, which is not replicated but does illustrate optimistic consistency. <p> Goldberg presents a mechanism layered on top of Jefferson's Virtual Time [6], another mechanism integrated with Virtual Time, and a third mechanism based loosely on the dependency tracking mechanisms of Strom and Yemini's Optimistic Recovery [9]. Because Virtual Time can be implemented in HOPE <ref> [3] </ref>, Goldberg's first two algorithms can be expressed in HOPE by simply composing the techniques. <p> One way to design such a preprocessor is to give it knowledge of various existing transformations. The preprocessor would search for suitable candidate sites to apply these transformations. Some highly amenable algorithms for this approach are those of Bacon and Strom (see <ref> [3] </ref>), Goldberg (see section 3.2), and Triantafillou (see section 3.3). Bacon and Strom's algorithms rely on good knowledge of the likely results of remote calls. Triantafillou's algorithms and Goldberg's algorithms rely on good knowledge of the data that will be frequently accessed at particular sites to obtain useful replica placement.
Reference: [4] <author> D. Gifford. </author> <title> Weighted Voting for Replicated Data. </title> <booktitle> In 7th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 150-162, </pages> <year> 1979. </year>
Reference-contexts: The third assumption is that a lock acquired only at the leader site will be granted at a quorum of other replica sites. Thus Triantafillou is using the conventional techniques of a location server and quorum consensus <ref> [4] </ref>, enhanced by using optimism to perform these functions asynchronously. The location-based algorithm proceeds as follows. Clients processing transactions begin by asking the location server for a list of up to date replicas of each object desired (the granularity of objects is not discussed).
Reference: [5] <author> Arthur P. Goldberg. </author> <title> Optimistic Algorithms for Distributed Transparent Process Replication. </title> <type> PhD thesis, </type> <institution> University of California at Los Angeles, </institution> <year> 1991. </year> <note> (UCLA Tech. Report CSD-910050). </note>
Reference-contexts: In this paper we illustrate that optimism applies to consistency by expressing Kung's early work in optimistic concurrency control [7] in HOPE. We then 3 examine two algorithms for optimistic replication, and express them in terms of HOPE. The first algorithm is Golberg's Optimistic Process Replication <ref> [5] </ref>, which presents a mechanism for transparently replicating entire processes, and focuses entirely on performance issues. The second algorithm is one of Triantafillou's algorithms for optimistic data replication [13, 15], which performs concurrency control in a replicated, optimistic fashion. Triantafillou's algorithms simultaneously address availability and performance issues. <p> Figure 7 shows the corresponding transaction expressed in HOPE. Most of the speculative power of HOPE is not exploited. Only the power to roll back a transaction due to operational or serialization failures is used. 3.2 Goldberg's Optimistic Process Replication Goldberg describes several mechanisms to transparently support process replication <ref> [5] </ref>. A replicated process appears to function identically to a single, non-replicated process, but has lower latency for read and non-conflicting write operations.
Reference: [6] <author> D. Jefferson. </author> <title> Virtual Time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 3(7) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: In [3] we present several algorithms for hiding latency through optimism expressed in HOPE, including Jefferson's Virtual Time <ref> [6] </ref>, and Bacon and Strom's Call Streaming [1]. We begin this section by presenting Kung and Robinson's optimistic concurrency control algorithm, which is not replicated but does illustrate optimistic consistency. <p> A replicated process appears to function identically to a single, non-replicated process, but has lower latency for read and non-conflicting write operations. Goldberg presents a mechanism layered on top of Jefferson's Virtual Time <ref> [6] </ref>, another mechanism integrated with Virtual Time, and a third mechanism based loosely on the dependency tracking mechanisms of Strom and Yemini's Optimistic Recovery [9]. Because Virtual Time can be implemented in HOPE [3], Goldberg's first two algorithms can be expressed in HOPE by simply composing the techniques.
Reference: [7] <author> H.T. Kung and John T. Robinson. </author> <title> On Optimistic Methods for Concurrency Control. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6(2) </volume> <pages> 213-226, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: Using a compiler that performs optimistic program transformations enables applications programmers to take advantage of optimistic algorithms without having to deal with the details of the algorithms. In this paper we illustrate that optimism applies to consistency by expressing Kung's early work in optimistic concurrency control <ref> [7] </ref> in HOPE. We then 3 examine two algorithms for optimistic replication, and express them in terms of HOPE. The first algorithm is Golberg's Optimistic Process Replication [5], which presents a mechanism for transparently replicating entire processes, and focuses entirely on performance issues. <p> % PIN to be authenticated . . . pin_ok = authorize_PIN (Pin); if pin_ok = 'OK' then commit (Guard); % assumption was correct else abort (Guard); % assumption was wrong, abort the guess end if; end process. 3.1 Kung and Robinson's Optimistic Concurrency Control Kung and Robinson's Optimistic Concurrency Control <ref> [7] </ref> is a conventional transaction-based concurrency control mechanism that makes the optimistic assumption that transactions usu ally don't conflict. The semantics presented are the conventional semantics for transaction processing.
Reference: [8] <author> Andy Lowry. </author> <title> Integrating Optimistic Systems. </title> <type> Personal Communications, </type> <month> April </month> <year> 1992. </year>
Reference-contexts: Any system supporting rollback of state changes is an optimistic system. Thus most database systems in use today are optimistic systems. In co-operation with Andy Lowry <ref> [8] </ref>, we hope to develop HOPE idioms that would allow HOPE programs to treat external optimistic systems as processes participating in optimistic algorithms. One way to achieve this is to place guard HOPE processes at the interface to the external optimistic system.
Reference: [9] <author> R.E. Strom and S. Yemini. </author> <title> Optimistic Recovery in Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 204-226, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Goldberg presents a mechanism layered on top of Jefferson's Virtual Time [6], another mechanism integrated with Virtual Time, and a third mechanism based loosely on the dependency tracking mechanisms of Strom and Yemini's Optimistic Recovery <ref> [9] </ref>. Because Virtual Time can be implemented in HOPE [3], Goldberg's first two algorithms can be expressed in HOPE by simply composing the techniques.
Reference: [10] <author> Rob Strom. </author> <title> The Need For Optimism in Hermes. </title> <type> Personal Communications, </type> <month> August </month> <year> 1991. </year>
Reference-contexts: Watson Research Center. Discussions with Rob Strom <ref> [10] </ref> on the need for optimism in Hermes gave a reason for HOPE. The language constructs themselves grew out of this discussion. Strom made many helpful suggestions as to the structure and content of this paper.
Reference: [11] <author> Rob Strom and Shaula Yemini. </author> <title> Synthesizing Distributed and Parallel Programs through Optimistic Transformations. </title> <editor> In Y. Yemini, editor, </editor> <booktitle> Current Advances in Distrubuted Computing and Communications, </booktitle> <pages> pages 234-256. </pages> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1987. </year>
Reference-contexts: The optimistic assumption is that the results of S1 do not influence S2, allowing S1 to be executed in parallel with S2. Strom and Yemini explored this notion, optimistic parallelization, in their 1987 paper <ref> [11] </ref>, and Bacon and Strom elaborated on it in 1991 [1]. Optimistic assumptions can be made about causal ordering, consistency, atomicity, and even fault tolerance, yielding sophisticated optimistic algorithms.
Reference: [12] <author> Robert E. Strom, David F. Bacon, Arthur Goldberg, Andy Lowry, Daniel Yellin, and Shaula Alexander Yemini. </author> <title> Hermes: A Language for Distributed Computing. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year>
Reference-contexts: Presenting program transformations as examples not only illustrates the transformation process, but also provides a clear definition of what the optimistic programs are supposed to be doing, due to the inclusion of the original, pessimistic programs. The examples are written in the Hermes distributed programming language <ref> [12] </ref> which has been extended with the HOPE constructs. Hermes was selected for its elegant ability to express distributed programs. The HOPE constructs can be applied to any programming language that provides concurrent sequential processes that communicate exclusively by message passing.
Reference: [13] <author> P. Triantafillou and D.J. Taylor. </author> <title> A New Paradigm for High Availability and Efficiency in Replicated and Distributed Databases. </title> <booktitle> In 2nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 136-143, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The first algorithm is Golberg's Optimistic Process Replication [5], which presents a mechanism for transparently replicating entire processes, and focuses entirely on performance issues. The second algorithm is one of Triantafillou's algorithms for optimistic data replication <ref> [13, 15] </ref>, which performs concurrency control in a replicated, optimistic fashion. Triantafillou's algorithms simultaneously address availability and performance issues. The next section of this paper presents the HOPE programming language constructs by illustrating how to express some simple optimistic algorithms in HOPE. <p> The cycle detection and correction is largely similar to Goldberg's, however since it is automated by HOPE, it omits his starvation-prevention protocol to avoid aborting the furthest-behind write. 3.3 Triantafillou's Optimistic Data Replication Triantafillou has presented three sophisticated consistency mechanisms for replicated data in transaction-based distributed systems <ref> [13, 14, 15, 16] </ref>. We focus on the Location Based Paradigm in [13], the simplest of Triantafillou's algorithms, to simplify demonstrating the applicability of HOPE to this style of algorithms. The algorithm is called "location-based" because it features an enhanced location server. <p> We focus on the Location Based Paradigm in <ref> [13] </ref>, the simplest of Triantafillou's algorithms, to simplify demonstrating the applicability of HOPE to this style of algorithms. The algorithm is called "location-based" because it features an enhanced location server.
Reference: [14] <author> P. Triantafillou and D.J. Taylor. </author> <title> Efficiently Maintaining Availability in the Presence of Partitionings in Distributed Systems. </title> <booktitle> In 7th IEEE International Conference on Data Engineering, </booktitle> <pages> pages 34-41, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: The cycle detection and correction is largely similar to Goldberg's, however since it is automated by HOPE, it omits his starvation-prevention protocol to avoid aborting the furthest-behind write. 3.3 Triantafillou's Optimistic Data Replication Triantafillou has presented three sophisticated consistency mechanisms for replicated data in transaction-based distributed systems <ref> [13, 14, 15, 16] </ref>. We focus on the Location Based Paradigm in [13], the simplest of Triantafillou's algorithms, to simplify demonstrating the applicability of HOPE to this style of algorithms. The algorithm is called "location-based" because it features an enhanced location server.
Reference: [15] <author> P. Triantafillou and D.J. Taylor. </author> <title> Using Multiple Replica Classes to Improve Performance in Distributed Systems. </title> <booktitle> In 11th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 420-428, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The first algorithm is Golberg's Optimistic Process Replication [5], which presents a mechanism for transparently replicating entire processes, and focuses entirely on performance issues. The second algorithm is one of Triantafillou's algorithms for optimistic data replication <ref> [13, 15] </ref>, which performs concurrency control in a replicated, optimistic fashion. Triantafillou's algorithms simultaneously address availability and performance issues. The next section of this paper presents the HOPE programming language constructs by illustrating how to express some simple optimistic algorithms in HOPE. <p> The cycle detection and correction is largely similar to Goldberg's, however since it is automated by HOPE, it omits his starvation-prevention protocol to avoid aborting the furthest-behind write. 3.3 Triantafillou's Optimistic Data Replication Triantafillou has presented three sophisticated consistency mechanisms for replicated data in transaction-based distributed systems <ref> [13, 14, 15, 16] </ref>. We focus on the Location Based Paradigm in [13], the simplest of Triantafillou's algorithms, to simplify demonstrating the applicability of HOPE to this style of algorithms. The algorithm is called "location-based" because it features an enhanced location server.

References-found: 15

