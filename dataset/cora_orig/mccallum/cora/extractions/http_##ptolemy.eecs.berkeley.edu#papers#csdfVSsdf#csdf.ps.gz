URL: http://ptolemy.eecs.berkeley.edu/papers/csdfVSsdf/csdf.ps.gz
Refering-URL: http://ptolemy.eecs.berkeley.edu/papers/csdfVSsdf/
Root-URL: 
Email: fparks,pino,ealg@EECS.Berkeley.EDU  
Title: A Comparison of Synchronous and Cyclo-Static Dataflow  
Author: Thomas M. Parks, Jose Luis Pino and Edward A. Lee 
Address: Berkeley  
Affiliation: Department of Electrical Engineering and Computer Sciences University of California,  
Date: October 1995  
Note: Presented at the Asilomar Conference on Signals, Systems and Computers  
Abstract: We compare synchronous dataflow (SDF) and cyclo-static dataflow (CSDF), which are each special cases of a model of computation we call dataflow process networks. In SDF, actors have static firing rules: they consume and produce a fixed number of data tokens in each firing. This model is well suited to multirate signal processing applications and lends itself to efficient, static scheduling, avoiding the run- time scheduling overhead incurred by general implementations of process networks. In CSDF, which is a generalization of SDF, actors have cyclicly changing firing rules. In some situations, the added generality of CSDF can unnecessarily complicate scheduling. We show how higher-order functions can be used to transform a CSDF graph into a SDF graph, simplifying the scheduling problem. In other situations, CSDF has a genuine advantage over SDF: simpler precedence constraints. We show how this makes it possible to eliminate unnecessary computations and expose additional parallelism. We use digital sample rate conversion as an example to illustrate these advantages of CSDF. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Bilsen, M. Engels, R. Lauwereins, and J. A. Peperstraete. </author> <title> Cyclo-static data flow. </title> <booktitle> In IEEE Int. Conf. ASSP, </booktitle> <pages> pages 32553258, </pages> <address> Detroit, Michigan, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: This property makes it possible to statically construct a finite schedule that can be periodically repeated to implement a process network that operates on infinite streams of data tokens. Cyclo-static dataflow (CSDF) <ref> [3, 1] </ref> generalizes SDF by allowing the number of tokens consumed and produced by an actor to vary from one firing to the next in 1 (a) (b) (c) static and state-dependent forms. a cyclic pattern. <p> Because these patterns are periodic and predictable, it is still possible to statically construct periodic schedules using techniques based on those developed for SDF <ref> [1] </ref>. CSDF has been extended to more general dynamic dataflow actors by allowing a data-dependent number of firings in a cycle [2]. <p> The first input token goes to the first output, the second input token goes to the second output, and so on. In this example, the token production parameters are: ~ g 11 = ~ g 12 = <ref> [1] </ref>, ~ g 21 = ~ g 22 = [1; 0] and ~ g 31 = ~ g 32 = [0; 1]. <p> The first input token goes to the first output, the second input token goes to the second output, and so on. In this example, the token production parameters are: ~ g 11 = ~ g 12 = [1], ~ g 21 = ~ g 22 = <ref> [1; 0] </ref> and ~ g 31 = ~ g 32 = [0; 1]. Let p i j = dim ( ~ g i j ) be the length or period of the token production pattern for the ith arc connected to the jth actor. <p> In this example, the token production parameters are: ~ g 11 = ~ g 12 = [1], ~ g 21 = ~ g 22 = [1; 0] and ~ g 31 = ~ g 32 = <ref> [0; 1] </ref>. Let p i j = dim ( ~ g i j ) be the length or period of the token production pattern for the ith arc connected to the jth actor. If there is no connection, then p i j = 1. <p> However, when an actor is part of a directed cycle, we might introduce deadlock as just demonstrated. In such cases, we must test the resulting CSDF graph for deadlock using more sophisticated methods <ref> [1] </ref>. This transformation from CSDF to SDF reduces the number of operations that must be scheduled, and allows us to use the many existing SDF scheduling techniques. But we have seen that transforming a CSDF graph into a SDF graph can introduce deadlock. <p> There are some genuine advantages that CSDF has over SDF. We showed how to eliminate dead code and how to expose additional parallelism. These advantages could be lost if we transformed every CSDF actor into an SDF actor, so this transformation is not always beneficial. Previous work on CSDF <ref> [3, 1] </ref> has made the restrictive assumption that all actors have internal state, effectively adding a self-loop in the dataflow graph, as in figure 1 (c), and additional dependencies in the precedence graph, as in figure 14.
Reference: [2] <author> J. T. Buck. </author> <title> Static scheduling and code generation from dy-namic dataflow graphs with integer valued control signals. </title> <booktitle> In Asilomar Conf. Sig. Sys. and Comp., </booktitle> <address> Pacific Grove, California, </address> <month> Oct. </month> <year> 1994. </year> <note> http://ptolemy.eecs.berkeley.edu/papers/IDF Asilomar.ps.Z. </note>
Reference-contexts: Because these patterns are periodic and predictable, it is still possible to statically construct periodic schedules using techniques based on those developed for SDF [1]. CSDF has been extended to more general dynamic dataflow actors by allowing a data-dependent number of firings in a cycle <ref> [2] </ref>. In this more general case, it is not always possible to construct a finite schedule that can be repeated, nor is it always possible to put bounds on the memory required to implement the communication channels.
Reference: [3] <author> M. Engels, G. Bilsen, R. Lauwereins, and J. Peperstraete. </author> <title> Cyclo-static dataflow: Model and implementation. </title> <booktitle> In Asilomar Conf. Sig. Sys. and Comp., </booktitle> <address> Pacific Grove, California, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: This property makes it possible to statically construct a finite schedule that can be periodically repeated to implement a process network that operates on infinite streams of data tokens. Cyclo-static dataflow (CSDF) <ref> [3, 1] </ref> generalizes SDF by allowing the number of tokens consumed and produced by an actor to vary from one firing to the next in 1 (a) (b) (c) static and state-dependent forms. a cyclic pattern. <p> be executed (i.e. there is no deadlock), then this firing sequence can be repeated infinitely in bounded memory. 3 Cyclo-static dataflow scheduling Unlike the scalar token consumption and production parameters G i j for SDF, these parameters are vectors ~ g i j for when transformed to SDF. 3 CSDF <ref> [3] </ref>. Figure 6 shows an example of a simple CSDF graph using a commutator and a distributor. The distributor is the counterpart to the commutator: it distributes tokens from its input stream to several output streams. <p> There are some genuine advantages that CSDF has over SDF. We showed how to eliminate dead code and how to expose additional parallelism. These advantages could be lost if we transformed every CSDF actor into an SDF actor, so this transformation is not always beneficial. Previous work on CSDF <ref> [3, 1] </ref> has made the restrictive assumption that all actors have internal state, effectively adding a self-loop in the dataflow graph, as in figure 1 (c), and additional dependencies in the precedence graph, as in figure 14.
Reference: [4] <author> G. Kahn. </author> <title> The semantics of a simple language for paral-lel programming. </title> <editor> In J. L. Rosenfeld, editor, </editor> <booktitle> Information Processing, </booktitle> <pages> pages 471-475, </pages> <address> Stockholm, </address> <month> Aug. </month> <year> 1974. </year> <booktitle> International Federation for Information Processing, </booktitle> <publisher> North-Holland Publishing Company. </publisher>
Reference-contexts: 1 Dataflow process networks In the process network model of computation <ref> [4, 5] </ref>, concurrent processes communicate through unidirectional FIFO channels. Communication channels are represented mathematically by streams (sequences of data elements or tokens), possibly infinite in length, and processes are functional mappings from a set of input streams to a set of output streams.
Reference: [5] <author> G. Kahn and D. B. MacQueen. </author> <title> Coroutines and networks of parallel processes. </title> <editor> In B. Gilchrist, editor, </editor> <booktitle> Information Processing, </booktitle> <pages> pages 993-998, </pages> <address> Toronto, </address> <month> Aug. </month> <year> 1977. </year> <booktitle> International Federation for Information Processing, </booktitle> <publisher> North-Holland Publishing Company. </publisher>
Reference-contexts: 1 Dataflow process networks In the process network model of computation <ref> [4, 5] </ref>, concurrent processes communicate through unidirectional FIFO channels. Communication channels are represented mathematically by streams (sequences of data elements or tokens), possibly infinite in length, and processes are functional mappings from a set of input streams to a set of output streams.
Reference: [6] <author> E. A. Lee and D. G. Messerschmitt. </author> <title> Static scheduling of synchronousdata flow programs for digital signal processing. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-36(1):24-35, </volume> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: Restricting the type of dataflow actors to those that have predictable token consumption and production patterns makes it possible to perform static, off-line scheduling and to bound the memory required to implement the communication channels. In synchronous dataflow (SDF) <ref> [6] </ref> the number of tokens consumed and produced by an actor is constant for each firing. This property makes it possible to statically construct a finite schedule that can be periodically repeated to implement a process network that operates on infinite streams of data tokens. <p> parallelism is lost and deadlock is not introduced, as in figure 4 (c). 2 Synchronous dataflow scheduling A SDF graph can be described by a topology matrix G, where the element G i j is defined as the number of tokens produced on the ith arc by the jth actor <ref> [6] </ref>. A negative value indicates that the actor consumes tokens on that arc.
Reference: [7] <author> E. A. Lee and T. M. Parks. </author> <title> Dataflow process networks. </title> <journal> Proc. IEEE, </journal> <volume> 83(5) </volume> <pages> 773-799, </pages> <month> May </month> <year> 1995. </year> <note> http://ptolemy.eecs.berkeley.edu/papers/processNets. </note>
Reference-contexts: A processes formed from repeated firings of a dataflow actor is called a dataflow process <ref> [7] </ref>. <p> head of a stream: map (f)[x 1 ; x 2 ; x 3 : : :] = cons (f (x 1 ); map (f)[x 2 ; x 3 : : :]) The use of map can be generalized so that f can consume and produce multiple tokens on multiple streams <ref> [7] </ref>. Breaking a process down into smaller units of execution, such as dataflow actor firings, makes efficient implementations of process networks possible.
Reference: [8] <author> J. L. Pino, S. S. Bhattacharyya, and E. A. Lee. </author> <title> A hierarchical multiprocessor scheduling framework for synchronous dataflow graphs. </title> <type> Technical Report UCB/ERL M95/36, </type> <institution> University of California, Berkeley, </institution> <month> May </month> <year> 1995. </year> <note> http://ptolemy.eecs.berkeley.edu/papers/erl-95-36. </note>
Reference-contexts: A new directed cycle is introduced in figure 4 (b) by combining actors A and B, and there is an insufficient number of tokens initially on the arcs of this cycle for any of the actors to be enabled. Composition can also introduce deadlock in other similar situations <ref> [8] </ref>. If instead we allow composite actors to follow the CSDF model, we can strike a balance between flexibility for the internal and external schedules. <p> The number of actor firings is r j P j . 4 Transforming CSDF to SDF The number of actor firings that must be scheduled can be exponential relative to the number of nodes in an SDF graph <ref> [8] </ref>. Figure 5 is an example of such a graph. If there are N nodes in the graph, then there are more than M N actor firings that must be scheduled. <p> It is counterproductive to expose hundreds or thousands of operations (a) (b) the precedence graph. that can execute in parallel when there are many fewer processors available. Incremental compilation heuristics have been developed to make parallel SDF scheduling tractable <ref> [8] </ref>. We would like to simplify CSDF scheduling and take advantage of all the scheduling techniques that already exist for SDF. To do this, we can transform a cycle of CSDF actor firings into a single SDF actor firing with a higher-order function.
Reference: [9] <author> J. L. Pino, S. Ha, E. A. Lee, and J. T. Buck. </author> <title> Software syn-thesis for DSP using Ptolemy. </title> <journal> J. VLSI Sig. Proc., </journal> <volume> 9(1) </volume> <pages> 7-21, </pages> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: However, this hides many of the advantages of the simpler precedence relationships of CSDF. None of the optimizations we have discussed are possible without knowing which actors have internal state and/or side effects. In the Ptolemy system <ref> [9] </ref>, our approach is to have the designer of an actor specify attributes for it. Thus the designer can assert whether or not an actor has internal state or side effects. Our loop transformation allows us to use existing SDF scheduling techniques for CSDF graphs.
Reference: [10] <author> S.-I. Shih. </author> <title> Code generation for VSP software tool in Ptolemy. </title> <type> Master's thesis, </type> <institution> University of California, Berkeley, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: But it also hides some important advantages of CSDF. Instead of developing schedulers that exploit the full generality of CSDF, we could extend existing SDF schedulers to treat certain multirate actors as special cases. In fact, we need only one multirate actor: the mixer <ref> [10] </ref>, shown in figure 15 (a). The mixer is a generalization of the distributor and commutator. It can have any number of inputs and outputs, and is functionally equivalent to a combination of a commutator and distributor, as shown in figure 15 (b).
Reference: [11] <author> P. P. Vaidyanathan. </author> <title> Multirate Systems and Filter Banks. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1993. </year> <month> 7 </month>
Reference-contexts: Only for CSDF can additional dead code be eliminated by examining the precedence graph. This is another example where the CSDF to SDF transformation may be undesirable. 6 Parallelism To overcome the limitations that SDF places on dead code elimination, we can use a polyphase filtering algorithm <ref> [11] </ref> for downsampling as shown in figure 10. This polyphase implementation is more efficient because it avoids the computation of unused results. There is no dead code to eliminate. Upsampling is a different problem and dead code elimination does not apply. <p> The mixer is a generalization of the distributor and commutator. It can have any number of inputs and outputs, and is functionally equivalent to a combination of a commutator and distributor, as shown in figure 15 (b). Because commutators and distributors are sufficient for building any multirate system <ref> [11] </ref>, we could use a simple dataflow model where the mixer is the only multirate actor. This would give us all the advantages of CSDF without the need to support its full generality.
References-found: 11

