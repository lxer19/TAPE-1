URL: ftp://theory.lcs.mit.edu/pub/tcryptol/98-14.ps
Refering-URL: http://theory.lcs.mit.edu/~tcryptol/1998/98-14.html
Root-URL: 
Title: Randomness versus Fault-Tolerance  
Author: Ran Canetti Eyal Kushilevitz Rafail Ostrovsky Adi Rosen 
Keyword: Secure multiparty protocols, Randomness, Limited independence, Composition of protocols.  
Date: April 30, 1998  
Abstract: We investigate the relations between two major requirements of multiparty protocols: fault tolerance (or resilience) and randomness. Fault-tolerance is measured in terms of the maximum number of col-luding faulty parties, t, that a protocol can withstand and still maintain the privacy of the inputs and the correctness of the outputs (of the honest parties). Randomness is measured in terms of the total number of random bits needed by the parties in order to execute the protocol. Previously, the upper bound on the amount of randomness required by general constructions for securely computing any non-trivial function f was polynomial both in n, the total number of parties, and the circuit-size C(f ). This was the state of knowledge even for the special case t = 1 (i.e., when there is at most one faulty party). In this paper, we show that for any linear-size circuit, and for any number t &lt; n=3 of faulty parties, O(poly(t)log n) randomness is sufficient. More generally, we show that for any function f with circuit-size C(f ), we need only O poly(t) log n + poly(t) C(f) n randomness in order to withstand any coalition of size at most t. Furthermore, in our protocol only t + 1 parties flip coins and the rest of the parties are deterministic. Our results generalize to the case of adaptive adversaries as well. fl A preliminary version of this paper appears in the proceedings of 16th PODC, 1997, 35-45. y IBM T.J. Watson Research Center. e-mail:canetti@watson.ibm.com z Dept. of Computer Science, Technion, Haifa, Israel. e-mail: eyalk@cs.technion.ac.il; Supported by MANLAM Fund. Part of this work was done while visiting Bellcore. URL: http://www.cs.technion.ac.il/~eyalk x Bell Communications Research, MCC-1C365B, Morristown, NJ 07960-6438, USA. e-mail:rafail@bellcore.com -Dept. of Computer Science, University of Toronto, Toronto, Canada. e-mail: adiro@cs.toronto.edu. Part of this work was done while visiting Bellcore. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, O. Goldreich, J. Hastad, and R. Peralta, </author> <title> "Simple Constructions of Almost k-wise Independent Random Variables", </title> <booktitle> FOCS 90 and Random Structures & Algorithms, </booktitle> <volume> Vol. 4, </volume> <year> 1993. </year>
Reference: [2] <author> J. Bar-Ilan, and D. Beaver, </author> <title> "Non-Cryptographic Fault-Tolerant Computing in a Constant Number of Rounds", </title> <booktitle> Proc. of 8th PODC, </booktitle> <pages> pp. 201-209, </pages> <year> 1989. </year>
Reference-contexts: S sets these values to be consistent with the data already known to the adversary; whenever a value is not determined it is chosen at random from 7 Both [50, 40] deal with the field GF <ref> [2] </ref> but can be extended to GF [p]. We note that the time-complexity of sampling in the sample space is poly (n; log n ; fi) but the complexity of the known algorithms that find such a space is poly ( n ).
Reference: [3] <author> D. Beaver, </author> <title> "Perfect Privacy for Two-Party Protocols", </title> <publisher> TR-11-89, Harvard University, </publisher> <year> 1989. </year>
Reference-contexts: The Protocols Composition Technique. To show the security of our protocols, we use general definitions of secure multiparty protocols. In particular, we use the formalization of [11], which allows modular composition of secure protocols. (This formalization is based on the <ref> [3] </ref> approach.) That is, in order to avoid re-proving the security of the [6] construction from scratch, we separately prove the security of the overall design of our protocol, assuming that the [6] modules for secret-sharing and for evaluating individual gates are secure. <p> Several definitions of multiparty secure computation have been proposed in the past (e.g., <ref> [45, 29, 3, 13, 11] </ref>). In this work we use the definition of [11] which, for self containment, we sketch below. We concentrate on the `secure channels' setting of [6, 16], where the adversary is computationally unbounded but has no access to the communication between non-faulty parties.
Reference: [4] <author> M. Bellare, O. Goldreich, and S. Goldwasser, </author> <title> "Randomness in Interactive Proofs", </title> <booktitle> FOCS, </booktitle> <year> 1990, </year> <pages> pp. 563-571. </pages>
Reference: [5] <author> M. Ben-Or, R. Canetti and O. Goldreich, </author> <title> "Asynchronous Secure Computations", </title> <booktitle> 25th STOC, </booktitle> <year> 1993, </year> <pages> pp. 52-61. </pages>
Reference-contexts: We then conclude that the composition of our "overall design" with the [6] modules is secure using the [11] composition theorem. We remark that a formal proof of security for [6] was never published. (It can be inferred, say, from the security proof of <ref> [5] </ref> as it appears in [12].) The modular proof technique used here can be applied also to proving the security of the [6] protocol itself. Organization. In Section 2 we provide some necessary definitions, including those of privacy and randomness. <p> Here a Verifiable Secret Sharing (VSS) scheme is used instead of Shamir's secret sharing. (VSS was introduced by [19]; different VSS schemes are described in <ref> [19, 28, 6, 23, 16, 5] </ref>.) Essentially, a VSS scheme makes sure that an honest dealer can successfully share a secret in a recoverable way, while guaranteeing that even if the dealer is corrupted, at the end of the sharing protocol the uncorrupted parties hold shares of a well defined and
Reference: [6] <author> M. Ben-or, S. Goldwasser, and A. Wigderson, </author> <title> "Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation", </title> <booktitle> STOC, </booktitle> <year> 1988, </year> <pages> pp. 1-10. </pages>
Reference-contexts: Secure multiparty computations has been extensively studied, in a variety of adversarial models. The following basic settings were considered. The adversary controlling the corrupted (i.e., faulty) parties can be either computationally unbounded (in which case the communication channels are assumed to be private) <ref> [6, 16] </ref>, or it can be limited to efficient (probabilistic polynomial time) computations [53, 28]. <p> Moreover, in the case of passive adversaries, any number t n of colluding parties is tolerable. In <ref> [6, 16] </ref> protocols for securely computing any function in the presence of computationally unbounded adversaries are presented. In the case of passive adversaries these protocols withstand up to t &lt; n=2 corrupted parties. In the case of active adversaries these protocols withstand up to t &lt; n=3 corrupted parties. <p> While these results do not substantially improve on <ref> [6, 16] </ref> for t = fi (n), they constitute big improvement for smaller values of t. In particular, for t = polylog (n), circuits with quasi-linear (i.e., m = O (n polylog (n))) number of gates can be securely evaluated using only polylog (n) random bits. <p> Our Constructions. Our results build on many previous ideas in the area of privacy as well as on limited independence distributions. In particular, we use the general framework of <ref> [6] </ref>, and combine it with ideas from [42] together with techniques for limited independence, in order to save in randomness. That is, the parties evaluate the given circuit gate by gate; each gate is computed in a manner similar to the construction of [6]. (In particular, we use the [6] modules <p> particular, we use the general framework of <ref> [6] </ref>, and combine it with ideas from [42] together with techniques for limited independence, in order to save in randomness. That is, the parties evaluate the given circuit gate by gate; each gate is computed in a manner similar to the construction of [6]. (In particular, we use the [6] modules for secret sharing and evaluating individual gates as building blocks.) However, as in [42], not all parties participate in evaluating each gate. Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. <p> of <ref> [6] </ref>, and combine it with ideas from [42] together with techniques for limited independence, in order to save in randomness. That is, the parties evaluate the given circuit gate by gate; each gate is computed in a manner similar to the construction of [6]. (In particular, we use the [6] modules for secret sharing and evaluating individual gates as building blocks.) However, as in [42], not all parties participate in evaluating each gate. Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. <p> To show the security of our protocols, we use general definitions of secure multiparty protocols. In particular, we use the formalization of [11], which allows modular composition of secure protocols. (This formalization is based on the [3] approach.) That is, in order to avoid re-proving the security of the <ref> [6] </ref> construction from scratch, we separately prove the security of the overall design of our protocol, assuming that the [6] modules for secret-sharing and for evaluating individual gates are secure. We then conclude that the composition of our "overall design" with the [6] modules is secure using the [11] composition theorem. <p> use the formalization of [11], which allows modular composition of secure protocols. (This formalization is based on the [3] approach.) That is, in order to avoid re-proving the security of the <ref> [6] </ref> construction from scratch, we separately prove the security of the overall design of our protocol, assuming that the [6] modules for secret-sharing and for evaluating individual gates are secure. We then conclude that the composition of our "overall design" with the [6] modules is secure using the [11] composition theorem. We remark that a formal proof of security for [6] was never published. (It can be inferred, say, from <p> order to avoid re-proving the security of the <ref> [6] </ref> construction from scratch, we separately prove the security of the overall design of our protocol, assuming that the [6] modules for secret-sharing and for evaluating individual gates are secure. We then conclude that the composition of our "overall design" with the [6] modules is secure using the [11] composition theorem. We remark that a formal proof of security for [6] was never published. (It can be inferred, say, from the security proof of [5] as it appears in [12].) The modular proof technique used here can be applied also to proving the <p> the overall design of our protocol, assuming that the <ref> [6] </ref> modules for secret-sharing and for evaluating individual gates are secure. We then conclude that the composition of our "overall design" with the [6] modules is secure using the [11] composition theorem. We remark that a formal proof of security for [6] was never published. (It can be inferred, say, from the security proof of [5] as it appears in [12].) The modular proof technique used here can be applied also to proving the security of the [6] protocol itself. Organization. <p> We remark that a formal proof of security for <ref> [6] </ref> was never published. (It can be inferred, say, from the security proof of [5] as it appears in [12].) The modular proof technique used here can be applied also to proving the security of the [6] protocol itself. Organization. In Section 2 we provide some necessary definitions, including those of privacy and randomness. In Section 3, we review the solution of [6] for the case of passive adversaries. In Section 4 we provide our solution for the same case. <p> proof of [5] as it appears in [12].) The modular proof technique used here can be applied also to proving the security of the <ref> [6] </ref> protocol itself. Organization. In Section 2 we provide some necessary definitions, including those of privacy and randomness. In Section 3, we review the solution of [6] for the case of passive adversaries. In Section 4 we provide our solution for the same case. In Section 5, we review the solution of [6] for the case of active (i.e., Byzantine) adversaries and in Section 6 we extend our solutions from the case of passive adversaries to the <p> Organization. In Section 2 we provide some necessary definitions, including those of privacy and randomness. In Section 3, we review the solution of <ref> [6] </ref> for the case of passive adversaries. In Section 4 we provide our solution for the same case. In Section 5, we review the solution of [6] for the case of active (i.e., Byzantine) adversaries and in Section 6 we extend our solutions from the case of passive adversaries to the case of active adversaries. <p> Several definitions of multiparty secure computation have been proposed in the past (e.g., [45, 29, 3, 13, 11]). In this work we use the definition of [11] which, for self containment, we sketch below. We concentrate on the `secure channels' setting of <ref> [6, 16] </ref>, where the adversary is computationally unbounded but has no access to the communication between non-faulty parties. Moreover, we concentrate on the case of strong adversaries; i.e., those which are both active and adaptive. The definition for weaker adversaries (passive, non-adaptive) can be inferred in a straightforward way. <p> For instance, consider the transformation not a ) (1 a); a and b ) a b; and a or b ) 1 ((1 a)(1 b)). 3 An Overview of the <ref> [6] </ref> Protocol for Passive Adversaries Our construction for passive adversaries, described in the next section, uses components used in the [6] general construction for t-securely computing any function in the presence of passive adversaries, for any t &lt; n=2. Therefore, we present in this section a brief overview of [6]. <p> For instance, consider the transformation not a ) (1 a); a and b ) a b; and a or b ) 1 ((1 a)(1 b)). 3 An Overview of the <ref> [6] </ref> Protocol for Passive Adversaries Our construction for passive adversaries, described in the next section, uses components used in the [6] general construction for t-securely computing any function in the presence of passive adversaries, for any t &lt; n=2. Therefore, we present in this section a brief overview of [6]. The construction (and proof) is presented in a modular way, using the composition theorem described in the previous section. <p> the <ref> [6] </ref> Protocol for Passive Adversaries Our construction for passive adversaries, described in the next section, uses components used in the [6] general construction for t-securely computing any function in the presence of passive adversaries, for any t &lt; n=2. Therefore, we present in this section a brief overview of [6]. The construction (and proof) is presented in a modular way, using the composition theorem described in the previous section. This form of presentation will enable us to use components of [6] without re-proving their security from scratch. For the [6] protocol, the parties agree on an arithmetic circuit for the <p> Therefore, we present in this section a brief overview of <ref> [6] </ref>. The construction (and proof) is presented in a modular way, using the composition theorem described in the previous section. This form of presentation will enable us to use components of [6] without re-proving their security from scratch. For the [6] protocol, the parties agree on an arithmetic circuit for the function f to be computed. (This involves agreeing on a prime p &gt; n; all the arithmetic in the sequel is done modulo p.) Each party holds values for some of <p> Therefore, we present in this section a brief overview of <ref> [6] </ref>. The construction (and proof) is presented in a modular way, using the composition theorem described in the previous section. This form of presentation will enable us to use components of [6] without re-proving their security from scratch. For the [6] protocol, the parties agree on an arithmetic circuit for the function f to be computed. (This involves agreeing on a prime p &gt; n; all the arithmetic in the sequel is done modulo p.) Each party holds values for some of the input wires. <p> Finally, the parties let each party reconstruct the values of the output gates assigned to it. More precisely, the <ref> [6] </ref> protocol consists of a `high-level' protocol for evaluating the circuit; this protocol uses as `subroutines' protocols for secure evaluation of the following n-argument functions: Secret Sharing. sec-shar n (F (); *; : : : ; *) = F (1); : : : ; F (n), where F () is an <p> In the high-level protocol the parties in W will interpolate a (degree t) polynomial A satisfying A (i) = a i for all i, and will output A (0). Theorem 2: <ref> [6] </ref>. Let t &lt; n=2. Then, there exist protocols for t-securely computing each of the above four functions, in the presence of passive adversaries, for all i 2 [n] and W [n]. 8 We do not prove this theorem here. <p> This protocol requires each participating party to choose O (t log p) random bits (hence total of O (nt log p) random bits in each invocation of multiplication protocol). For completeness, we also state the following theorem: Theorem 3: <ref> [6] </ref> Let t &lt; n=2. <p> Finally, the parties reconstruct the value of the output wire from their shares. Our approach can be applied to any protocol that follows this outline. For concreteness, however, we concentrate on the <ref> [6] </ref> construction (reviewed in the previous section). We develop a variation of the above outline. Instead of having the value of each wire shared among all parties, and having all parties participate in evaluating each gate, we use a different method. <p> We partition the parties into sets of size s = 2t + 1 which we call teams. The input of each party will be shared only among the members of its team (using the <ref> [49, 6] </ref> secret-sharing procedure). Each gate will be assigned a team, and will be evaluated only by the parties in that team. Consequently, the output wire of each gate will be shared among the parties in the corresponding team. <p> These shares are communicated by the parties of the teams that evaluated the gates leading to those wires. Now team T invokes the <ref> [6] </ref> procedure for evaluating gate g. (This can be done since s &gt; 2t.) At the end of this computation, the parties in T hold shares of the output wire of the gate. <p> The high-level protocol above is turned into a full-fledged protocol by replacing the ideal evaluation calls with subroutines that securely evaluate the corresponding functions; for concreteness, the <ref> [6] </ref> subroutines sketched in the previous section. We now turn to describe how the dealer distributes the random numbers (in GF [p]) to the parties. In the Input Sharing stage the dealer distributes coefficients of n polynomials (one polynomial to each party). <p> This is done in the same way as above. Theorem 1 and the trusted dealer version of Theorem 4 then imply that the modified protocol is t-secure in the real-life model as well. 5 An Overview of the <ref> [6] </ref> Protocol for Active Adversaries The general outline of the [6] construction for the case of active (Byzantine) adversaries is very similar to the case of passive adversaries. <p> This is done in the same way as above. Theorem 1 and the trusted dealer version of Theorem 4 then imply that the modified protocol is t-secure in the real-life model as well. 5 An Overview of the <ref> [6] </ref> Protocol for Active Adversaries The general outline of the [6] construction for the case of active (Byzantine) adversaries is very similar to the case of passive adversaries. Yet, the definitions of the four `building blocks', sec-shar; add; mult; recons, have to be modified to reflect the additional power of the adversary. <p> We introduce the c i 's in order to capture the fact that an active adversary may be able to fix (or influence) its own shares of the polynomial C. Yet, this capability of the adversary does not interfere with the secure evaluation of the function. (In particular, the <ref> [6] </ref> multiplication step allows the adversary to have such harmless influence.) Reconstruction. <p> In the high-level protocol the parties in W will interpolate a (degree t) polynomial A satisfying A (i) = a i for at least n t values i, and will output A (0). Theorem 5: <ref> [6] </ref>. Let t &lt; n=3. Then there exist protocols for t-securely computing the above four functions in the presence of active adversaries, for all i 2 [n], W [n]. We do not prove this theorem here. Yet we sketch below the [6] constructions for computing vss and act-mult. <p> Theorem 5: <ref> [6] </ref>. Let t &lt; n=3. Then there exist protocols for t-securely computing the above four functions in the presence of active adversaries, for all i 2 [n], W [n]. We do not prove this theorem here. Yet we sketch below the [6] constructions for computing vss and act-mult. For completeness, we state also the following theorem: Theorem 6: [6] Let t &lt; n=3. <p> We do not prove this theorem here. Yet we sketch below the <ref> [6] </ref> constructions for computing vss and act-mult. For completeness, we state also the following theorem: Theorem 6: [6] Let t &lt; n=3. <p> Using the composition theorem (Theorem 1), we get that there exist protocols for t-securely computing any n-argument function in the presence of active adversaries for any t &lt; n=3. 17 The <ref> [6] </ref> VSS protocol. <p> Here a Verifiable Secret Sharing (VSS) scheme is used instead of Shamir's secret sharing. (VSS was introduced by [19]; different VSS schemes are described in <ref> [19, 28, 6, 23, 16, 5] </ref>.) Essentially, a VSS scheme makes sure that an honest dealer can successfully share a secret in a recoverable way, while guaranteeing that even if the dealer is corrupted, at the end of the sharing protocol the uncorrupted parties hold shares of a well defined and <p> Several VSS schemes exist. We sketch one of the schemes described in <ref> [6] </ref>, that withstands t &lt; n=3 faults. The dealer, sharing a secret s, chooses a random bivariate polynomial H of degree t in each variable, whose free coefficient is s. <p> The reconstruction protocol (i.e., the protocol for computing recons) is simple: all parties broadcast their shares. It is guaranteed that if the sharing protocol completed successfully then a unique polynomial H (; ) will be reconstructed (using error correcting techniques of Generalized Reed-Solomon codes.) The <ref> [6] </ref> act-mult protocol. In the passive adversaries case evaluating a multiplication gate consisted of each party re-sharing a locally computed value, followed by local evaluation of a linear combination of the newly received shares. Here we follow this method, with two modifications. <p> The protocol for active adversaries is identical to the one for passive adversaries, with the exceptions that the size of teams is increased to s = 3t + 1, and that the various components of the <ref> [6] </ref> protocol are replaced by their Byzantine counterparts, for securely computing the functions vss; add; act-mult; recons described in the previous section. In addition, the trusted dealer now has to supply the parties with enough 18 random values to support the new protocols.
Reference: [7] <author> C. Blundo, A. De-Santis, G. Persiano, and U. Vaccaro, </author> <title> "On the Number of Random Bits in Totally Private Computations", </title> <note> ICALP, LNCS 944, </note> <year> 1995, </year> <pages> pp. 171-182. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages). <p> For the XOR function, (t) random bits are necessary for t-private computation, while O (t 2 log (n=t)) random bits are sufficient [40]. Additionally, for any function f with sensitivity n, if t n c for some constant c, then (n 2 ) random bits are required <ref> [7] </ref>. 2. For the special case of 1-privacy, any linear-size circuit can be computed 1-privately with constant number of random bits [42]. More generally, every circuit of m boolean gates can be computed 1-privately with O (m=n) random bits [42]. Our Results. We generalize both of the above results.
Reference: [8] <author> C. Blundo, A. De-Santis, and U. Vaccaro, </author> <title> "Randomness in Distribution Protocols", </title> <note> ICALP, LNCS 820, </note> <year> 1994, </year> <pages> pp. 568-579. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [9] <author> C. Blundo, A. Giorgio Gaggia, and D. R. Stinson, </author> <title> "On the Dealer's Randomness Required in Secret Sharing Schemes", </title> <journal> EuroCrypt94, </journal> <volume> LNCS 950, </volume> <year> 1995, </year> <pages> pp. 35-46. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [10] <author> M. Blum, and S. </author> <title> Micali "How to Generate Cryptographically Strong Sequences of Pseudo-Random Bits", </title> <journal> FOCS 82 and SIAM J. on Computing, </journal> <volume> Vol 13, </volume> <year> 1984, </year> <pages> pp. 850-864. </pages>
Reference-contexts: Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. We generalize 1 When the adversary is limited to probabilistic polynomial time and intractability assumptions are used, as in [53, 28], then by the results of <ref> [10, 30, 31] </ref> we may as well assume the existence of a pseudorandom generator. In this case parties can expand "small" seeds of truly random bits into "long" sequences of pseudo-random bits and use them.
Reference: [11] <author> R. Canetti, </author> <title> "Modular Composition of Multi-party Cryptographic Protocols", Available at the Theory of Cryptography Library, </title> <note> http://theory.lcs.mit.edu/~tcryptol, 1998. manuscript (available from the author), </note> <year> 1998. </year>
Reference-contexts: The Protocols Composition Technique. To show the security of our protocols, we use general definitions of secure multiparty protocols. In particular, we use the formalization of <ref> [11] </ref>, which allows modular composition of secure protocols. (This formalization is based on the [3] approach.) That is, in order to avoid re-proving the security of the [6] construction from scratch, we separately prove the security of the overall design of our protocol, assuming that the [6] modules for secret-sharing and <p> We then conclude that the composition of our "overall design" with the [6] modules is secure using the <ref> [11] </ref> composition theorem. <p> Several definitions of multiparty secure computation have been proposed in the past (e.g., <ref> [45, 29, 3, 13, 11] </ref>). In this work we use the definition of [11] which, for self containment, we sketch below. We concentrate on the `secure channels' setting of [6, 16], where the adversary is computationally unbounded but has no access to the communication between non-faulty parties. <p> Several definitions of multiparty secure computation have been proposed in the past (e.g., [45, 29, 3, 13, 11]). In this work we use the definition of <ref> [11] </ref> which, for self containment, we sketch below. We concentrate on the `secure channels' setting of [6, 16], where the adversary is computationally unbounded but has no access to the communication between non-faulty parties. <p> Composition of Secure Protocols. In the sequel we use the fact that secure protocols can be composed in a modular way while maintaining security. For a full exposition and a proof see <ref> [11] </ref>. Here we briefly review the set-up and state the theorem. <p> Yet, we remark that our protocols do enjoy this stronger security property. (See <ref> [11] </ref> for details.) To be able to state the composition theorem, we first formulate a model for computing a function g with the assistance of a trusted party for computing a function f , and define secure protocols in that model. <p> We assume that all parties terminate protocol at the same round. Let 1 ;:::; k denote protocol where each ideal evaluation call to f i is replaced by an invocation of protocol i . Theorem 1 : <ref> [11] </ref>. Let f 1 ; : : : ; f k and g be n-argument functions.
Reference: [12] <author> R. Canetti, </author> <title> "Studies in Secure Multi-Party Computation and Applications", </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science and Applied Math, Weizmann Institute of Science, Rehovot, Israel, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: We then conclude that the composition of our "overall design" with the [6] modules is secure using the [11] composition theorem. We remark that a formal proof of security for [6] was never published. (It can be inferred, say, from the security proof of [5] as it appears in <ref> [12] </ref>.) The modular proof technique used here can be applied also to proving the security of the [6] protocol itself. Organization. In Section 2 we provide some necessary definitions, including those of privacy and randomness. In Section 3, we review the solution of [6] for the case of passive adversaries.
Reference: [13] <author> R. Canetti, U. Feige, O. Goldreich, and M. Naor, </author> <title> "Adaptively Secure Multi-Party Computation", </title> <booktitle> Proc. of 28th STOC, </booktitle> <year> 1996, </year> <pages> pp. 639-648. </pages>
Reference-contexts: Several definitions of multiparty secure computation have been proposed in the past (e.g., <ref> [45, 29, 3, 13, 11] </ref>). In this work we use the definition of [11] which, for self containment, we sketch below. We concentrate on the `secure channels' setting of [6, 16], where the adversary is computationally unbounded but has no access to the communication between non-faulty parties.
Reference: [14] <author> R. Canetti, and O. Goldreich, </author> <title> "Bounds on Tradeoffs between Randomness and Communication Complexity", </title> <booktitle> FOCS 90 and Computational Complexity Vol. </booktitle> <volume> 3, </volume> <year> 1993, </year> <pages> 141-167. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [15] <author> S. Chari, R. Rogatgi, A. </author> <title> Srinivasan "Randomness-Optimal Unique Element Isolation, with Application to Perfect Matching and Related Problems, </title> <booktitle> STOC 1993, </booktitle> <pages> pp. 458-467. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [16] <author> D. Chaum, C. Crepeau, and I. Damgard, </author> <title> "Multiparty Unconditionally Secure Protocols", </title> <booktitle> STOC, </booktitle> <pages> pp. 11-19, </pages> <year> 1988. </year>
Reference-contexts: Secure multiparty computations has been extensively studied, in a variety of adversarial models. The following basic settings were considered. The adversary controlling the corrupted (i.e., faulty) parties can be either computationally unbounded (in which case the communication channels are assumed to be private) <ref> [6, 16] </ref>, or it can be limited to efficient (probabilistic polynomial time) computations [53, 28]. <p> Moreover, in the case of passive adversaries, any number t n of colluding parties is tolerable. In <ref> [6, 16] </ref> protocols for securely computing any function in the presence of computationally unbounded adversaries are presented. In the case of passive adversaries these protocols withstand up to t &lt; n=2 corrupted parties. In the case of active adversaries these protocols withstand up to t &lt; n=3 corrupted parties. <p> While these results do not substantially improve on <ref> [6, 16] </ref> for t = fi (n), they constitute big improvement for smaller values of t. In particular, for t = polylog (n), circuits with quasi-linear (i.e., m = O (n polylog (n))) number of gates can be securely evaluated using only polylog (n) random bits. <p> Several definitions of multiparty secure computation have been proposed in the past (e.g., [45, 29, 3, 13, 11]). In this work we use the definition of [11] which, for self containment, we sketch below. We concentrate on the `secure channels' setting of <ref> [6, 16] </ref>, where the adversary is computationally unbounded but has no access to the communication between non-faulty parties. Moreover, we concentrate on the case of strong adversaries; i.e., those which are both active and adaptive. The definition for weaker adversaries (passive, non-adaptive) can be inferred in a straightforward way. <p> Here a Verifiable Secret Sharing (VSS) scheme is used instead of Shamir's secret sharing. (VSS was introduced by [19]; different VSS schemes are described in <ref> [19, 28, 6, 23, 16, 5] </ref>.) Essentially, a VSS scheme makes sure that an honest dealer can successfully share a secret in a recoverable way, while guaranteeing that even if the dealer is corrupted, at the end of the sharing protocol the uncorrupted parties hold shares of a well defined and
Reference: [17] <author> B. Chor, and C. Dwork, </author> <title> "Randomization in Byzantine Agreement", </title> <booktitle> Advances in Computing Research, </booktitle> <volume> volume 5, </volume> <pages> 443-497, </pages> <year> 1989. </year>
Reference-contexts: Byzantine agreement with linear number of faults requires linear number of rounds deterministically [24] and constant number of rounds if randomization is allowed [23]; reaching a consensus in an asynchronous distributed system with faults is impossible with deterministic protocols [25], but is possible with the use of randomized protocols (see <ref> [17] </ref>).
Reference: [18] <author> B. Chor, and O. Goldreich, </author> <title> "Unbiased Bits from Sources of Weak Randomness and Probabilistic Communication Complexity", </title> <journal> FOCS 85 and SICOMP Vol. </journal> <volume> 17, </volume> <year> 1988, </year> <pages> 230-261. </pages>
Reference: [19] <author> B. Chor, S. Goldwasser, S. Micali and B. Awerbuch, </author> <title> "Verifiable Secret Sharing and Achieving Simultaneity in the Presence of Faults", </title> <booktitle> FOCS, </booktitle> <year> 1985, </year> <pages> pp. 383-395. </pages>
Reference-contexts: Here a Verifiable Secret Sharing (VSS) scheme is used instead of Shamir's secret sharing. (VSS was introduced by <ref> [19] </ref>; different VSS schemes are described in [19, 28, 6, 23, 16, 5].) Essentially, a VSS scheme makes sure that an honest dealer can successfully share a secret in a recoverable way, while guaranteeing that even if the dealer is corrupted, at the end of the sharing protocol the uncorrupted parties <p> Here a Verifiable Secret Sharing (VSS) scheme is used instead of Shamir's secret sharing. (VSS was introduced by [19]; different VSS schemes are described in <ref> [19, 28, 6, 23, 16, 5] </ref>.) Essentially, a VSS scheme makes sure that an honest dealer can successfully share a secret in a recoverable way, while guaranteeing that even if the dealer is corrupted, at the end of the sharing protocol the uncorrupted parties hold shares of a well defined and
Reference: [20] <author> B. Chor, and E. Kushilevitz, </author> <title> "A Zero-One Law for Boolean Privacy", </title> <journal> STOC 89 and SIDMA, </journal> <volume> Vol. 4, </volume> <pages> 36-47, </pages> <year> 1991. </year>
Reference: [21] <author> B. Chor, and E. Kushilevitz, </author> <title> "A Communication-Privacy Tradeoff for Modular Addition", </title> <journal> Information Processing Letters, </journal> <volume> Vol. 45, </volume> <year> 1993, </year> <pages> pp. 205-210. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [22] <author> U. Feige, J. Kilian, and M. Naor, </author> <title> "A Minimal Model for Secure Computation", </title> <booktitle> STOC, </booktitle> <pages> pp. 554-563, </pages> <year> 1994. </year>
Reference: [23] <author> P. Feldman, and S. Micali, </author> <title> "An Optimal Algorithm For Synchronous Byzantine Agreement", </title> <journal> STOC, 1988 and SIAM J. on Computing, </journal> <volume> Vol. 26, No. 4, </volume> <year> 1997, </year> <pages> pp. 873-933. </pages>
Reference-contexts: For instance, achieving Byzantine agreement with linear number of faults requires linear number of rounds deterministically [24] and constant number of rounds if randomization is allowed <ref> [23] </ref>; reaching a consensus in an asynchronous distributed system with faults is impossible with deterministic protocols [25], but is possible with the use of randomized protocols (see [17]). <p> Here a Verifiable Secret Sharing (VSS) scheme is used instead of Shamir's secret sharing. (VSS was introduced by [19]; different VSS schemes are described in <ref> [19, 28, 6, 23, 16, 5] </ref>.) Essentially, a VSS scheme makes sure that an honest dealer can successfully share a secret in a recoverable way, while guaranteeing that even if the dealer is corrupted, at the end of the sharing protocol the uncorrupted parties hold shares of a well defined and
Reference: [24] <author> M. Fischer and N. Lynch. </author> <title> "A Lower Bound for the Time to Assure Interactive Consistency", </title> <journal> IPL, </journal> <volume> 14(4), </volume> <pages> pp. 183-186, </pages> <year> 1982. </year>
Reference-contexts: In particular, in the context of distributed computing there are important examples of problems where there is a provable gap between the power of randomized algorithms and their deterministic counterparts. For instance, achieving Byzantine agreement with linear number of faults requires linear number of rounds deterministically <ref> [24] </ref> and constant number of rounds if randomization is allowed [23]; reaching a consensus in an asynchronous distributed system with faults is impossible with deterministic protocols [25], but is possible with the use of randomized protocols (see [17]).
Reference: [25] <author> M. J. Fischer, N. A. Lynch, and M. S. Paterson. </author> <title> "Impossibility of Distributed Consensus with One Faulty Process", </title> <journal> Journal of the ACM, </journal> <volume> 32(2), </volume> <pages> pp. 374-382, </pages> <year> 1985. </year>
Reference-contexts: For instance, achieving Byzantine agreement with linear number of faults requires linear number of rounds deterministically [24] and constant number of rounds if randomization is allowed [23]; reaching a consensus in an asynchronous distributed system with faults is impossible with deterministic protocols <ref> [25] </ref>, but is possible with the use of randomized protocols (see [17]).
Reference: [26] <author> M. Franklin, and M. Yung, </author> <title> "Communication Complexity of Secure Computation", </title> <booktitle> STOC, </booktitle> <pages> pp. 699-710, </pages> <year> 1992. </year>
Reference: [27] <author> R. Gennaro, T. Rabin, and M. Rabin, </author> <title> "VSS and Secure Multiparty Computations Made Simple", </title> <type> manuscript. </type>
Reference-contexts: The function add n can be computed by each partly locally summing its two inputs. Below we sketch Rabin's simplification of the protocol for securely computing mult n , as it appears in <ref> [27] </ref>. This protocol requires each participating party to choose O (t log p) random bits (hence total of O (nt log p) random bits in each invocation of multiplication protocol). For completeness, we also state the following theorem: Theorem 3: [6] Let t &lt; n=2. <p> Using the composition theorem (Theorem 1), we get that for any t &lt; n=2 there exist protocols for t-securely computing any n-argument function in the presence of passive adversaries. The <ref> [27] </ref> multiplication step. First, each party P i locally computes the value d i = a i b i . These values define a polynomial D (x) whose free coefficient is the value a b.
Reference: [28] <author> O. Goldreich, S. Micali, and A. Wigderson, </author> <title> "How to Play Any Mental Game", </title> <booktitle> Proc. of 19th STOC, </booktitle> <year> 1987, </year> <pages> pp. 218-229. </pages>
Reference-contexts: Over the past decade, both striving for stronger security and saving random bits received considerable amount of attention and yielded many interesting results. Secure protocols. Secure multiparty protocols (first studied in <ref> [53, 28] </ref>) are protocols that guarantee the privacy of the inputs and, at the same time, the correctness of the outputs of honest participants, even if some of the parties are maliciously faulty ("Byzantine"). Secure multiparty computations has been extensively studied, in a variety of adversarial models. <p> The following basic settings were considered. The adversary controlling the corrupted (i.e., faulty) parties can be either computationally unbounded (in which case the communication channels are assumed to be private) [6, 16], or it can be limited to efficient (probabilistic polynomial time) computations <ref> [53, 28] </ref>. In addition, the adversary can be either passive (in which case the corrupted parties are honest-but-curious; they follow their protocol and only collude to gather extra information), or active (in which case the corrupted parties may arbitrarily and maliciously deviate from their protocol). <p> In this work we consider adaptively secure protocols | that is, protocols secure against adaptive adversaries. We mention some known results: In <ref> [53, 28] </ref> it was shown that, if trapdoor permutations exist, every poly-time computable function f can be computed securely tolerating a computationally bounded, active adversary that controls up to t &lt; n=2 parties. Moreover, in the case of passive adversaries, any number t n of colluding parties is tolerable. <p> Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. We generalize 1 When the adversary is limited to probabilistic polynomial time and intractability assumptions are used, as in <ref> [53, 28] </ref>, then by the results of [10, 30, 31] we may as well assume the existence of a pseudorandom generator. In this case parties can expand "small" seeds of truly random bits into "long" sequences of pseudo-random bits and use them. <p> Here a Verifiable Secret Sharing (VSS) scheme is used instead of Shamir's secret sharing. (VSS was introduced by [19]; different VSS schemes are described in <ref> [19, 28, 6, 23, 16, 5] </ref>.) Essentially, a VSS scheme makes sure that an honest dealer can successfully share a secret in a recoverable way, while guaranteeing that even if the dealer is corrupted, at the end of the sharing protocol the uncorrupted parties hold shares of a well defined and
Reference: [29] <author> S. Goldwasser, and L. Levin, </author> <title> "Fair Computation of General Functions in Presence of Immoral Majority", </title> <booktitle> CRYPTO, </booktitle> <year> 1990. </year>
Reference-contexts: Several definitions of multiparty secure computation have been proposed in the past (e.g., <ref> [45, 29, 3, 13, 11] </ref>). In this work we use the definition of [11] which, for self containment, we sketch below. We concentrate on the `secure channels' setting of [6, 16], where the adversary is computationally unbounded but has no access to the communication between non-faulty parties.
Reference: [30] <author> J. Hastad, </author> <title> "Pseudo-Random Generators under Uniform Assumptions", </title> <note> STOC 90 </note> . 
Reference-contexts: Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. We generalize 1 When the adversary is limited to probabilistic polynomial time and intractability assumptions are used, as in [53, 28], then by the results of <ref> [10, 30, 31] </ref> we may as well assume the existence of a pseudorandom generator. In this case parties can expand "small" seeds of truly random bits into "long" sequences of pseudo-random bits and use them.
Reference: [31] <author> R. Impagliazzo, R., L. Levin, and M. </author> <title> Luby "Pseudo-Random Generation from One-Way Functions," </title> <note> STOC 89. </note>
Reference-contexts: Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. We generalize 1 When the adversary is limited to probabilistic polynomial time and intractability assumptions are used, as in [53, 28], then by the results of <ref> [10, 30, 31] </ref> we may as well assume the existence of a pseudorandom generator. In this case parties can expand "small" seeds of truly random bits into "long" sequences of pseudo-random bits and use them.
Reference: [32] <author> R. Impagliazzo, and D. Zuckerman, </author> <title> "How to Recycle Random Bits", </title> <booktitle> Proc. of 30th FOCS, </booktitle> <year> 1989, </year> <pages> pp. 248-253. </pages>
Reference: [33] <author> D. Karger, and D. Koller, </author> <title> "(De)randomized Construction of Small Sample Spaces in N C", </title> <booktitle> FOCS, </booktitle> <year> 1994, </year> <pages> pp. 252-263. </pages>
Reference: [34] <author> D. Karger, and R. Motwani, </author> <title> "Derandomization through Approximation: An N C Algorithm for Minimum Cuts", </title> <booktitle> Proc. of 26th STOC, </booktitle> <year> 1994, </year> <pages> pp. 497-506. 22 </pages>
Reference: [35] <author> H. Karloff, and Y. Mansour, </author> <title> "On Construction of k-wise Independent Random Variables", </title> <booktitle> STOC, </booktitle> <year> 1994, </year> <pages> pp. 564-573. </pages>
Reference: [36] <author> D. E. Knuth, and A. C. Yao, </author> <title> "The Complexity of Non-Uniform Random Number Generation", </title> <booktitle> Algorithms and Complexity, </booktitle> <pages> pp. 357-428, </pages> <editor> ed. J. Traub, </editor> <year> 1976. </year>
Reference: [37] <author> D. Koller, and N. Megiddo, </author> <title> "Constructing Small Sample Spaces Satisfying Given Constraints", </title> <journal> STOC 93 and SIAM J. Disc. Math. </journal> <volume> Vol. 7, </volume> <year> 1994. </year>
Reference: [38] <author> D. Krizanc, D. Peleg, and E. Upfal, </author> <title> "A Time-Randomness Tradeoff for Oblivious Routing", </title> <booktitle> STOC, </booktitle> <year> 1988, </year> <pages> pp. 93-102. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [39] <author> E. Kushilevitz, </author> <title> "Privacy and Communication Complexity", </title> <journal> FOCS 89, and SIAM Jour. on Disc. Math., </journal> <volume> Vol. 5, No. 2, </volume> <year> 1992, </year> <pages> pp. 273-284. </pages>
Reference: [40] <author> E. Kushilevitz, and Y. Mansour, </author> <title> "Randomness in Private Computations", </title> <journal> PODC 1996, and SIAM Jour. on Disc. Math., </journal> <volume> Vol. 10, No. 4, </volume> <year> 1997, </year> <pages> pp. 647-661. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages). <p> Furthermore, results were obtained either for a specific function (namely XOR) or for the special case t = 1: 1. For the XOR function, (t) random bits are necessary for t-private computation, while O (t 2 log (n=t)) random bits are sufficient <ref> [40] </ref>. Additionally, for any function f with sensitivity n, if t n c for some constant c, then (n 2 ) random bits are required [7]. 2. For the special case of 1-privacy, any linear-size circuit can be computed 1-privately with constant number of random bits [42]. <p> Interestingly, we show that not only we can use a small amount of randomness but also only t + 1 parties need to be randomized, and the rest of the parties can be deterministic. This is nearly optimal against coalitions of size t, since it was shown in <ref> [40] </ref> that t-private computations of simple functions require at least t parties to use randomness, and that in some cases, such as the XOR function, t is sufficient. The Protocols Composition Technique. To show the security of our protocols, we use general definitions of secure multiparty protocols. <p> In Section 5, we review the solution of [6] for the case of active (i.e., Byzantine) adversaries and in Section 6 we extend our solutions from the case of passive adversaries to the case of active adversaries. In the Appendix we describe an extension of the results of <ref> [50, 40] </ref> for sample spaces with limited independence; we use this extension in our constructions. 2 Preliminaries We start by specifying the requirements from a protocol for securely computing a function f whose inputs are partitioned among several parties. <p> However, we do not need all subsets of size fi to be uniformly distributed. It suffices that the n subsets of size fi, defined by the n subsets of t parties, be uniformly distributed. To take advantage of the relaxed requirement, we use an extension of the results of <ref> [50, 40] </ref> (which, for self containment, appears in Appendix A): Set p &gt; 2t + 1. The dealer will uniformly sample a space of M -tuples over GF [p], which is constructed to suit the specific n subsets. By [50, 40], there is a sample space of size n p fi <p> the relaxed requirement, we use an extension of the results of <ref> [50, 40] </ref> (which, for self containment, appears in Appendix A): Set p &gt; 2t + 1. The dealer will uniformly sample a space of M -tuples over GF [p], which is constructed to suit the specific n subsets. By [50, 40], there is a sample space of size n p fi such that if we sample the space uniformly, then the projection of the chosen vector on any of the n subsets is uniformly distributed. 7 To sample this space, the dealer will need randomness of O (t log (n=t) <p> S sets these values to be consistent with the data already known to the adversary; whenever a value is not determined it is chosen at random from 7 Both <ref> [50, 40] </ref> deal with the field GF [2] but can be extended to GF [p]. We note that the time-complexity of sampling in the sample space is poly (n; log n ; fi) but the complexity of the known algorithms that find such a space is poly ( n ). <p> Therefore, the simulator can pick a random degree fi polynomial consistent with the values handed to the adversary so far. 9 Finally, the simulator also has to give the 9 It can be shown that the <ref> [40] </ref> construction (see Appendix) also has the property that for a partial (legal) M -tuple one can find a random consistent M-tuple. 16 adversary values for the numbers that this dealer is supposed to receive from the other t dealers. This is done in the same way as above. <p> Since there are at most t corrupted parties altogether, and each corrupted party can give a bad share to at most one party in T i , it follows that at most t parties in T i are either corrupted or start off with an erroneous share. 20 by using <ref> [50, 40] </ref>.
Reference: [41] <author> E. Kushilevitz, S. Micali, and R. Ostrovsky, </author> <title> "Reducibility and Completeness in Multi-Party Private Computations", </title> <booktitle> Proc. of 35th FOCS, </booktitle> <pages> pp. 478-489, </pages> <year> 1994. </year>
Reference: [42] <author> E. Kushilevitz, R. Ostrovsky, and A. Rosen, </author> <title> "Characterizing Linear Size Circuits in Terms of Privacy", </title> <booktitle> STOC, </booktitle> <pages> pp. 541-550, </pages> <year> 1996. </year>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages). <p> Additionally, for any function f with sensitivity n, if t n c for some constant c, then (n 2 ) random bits are required [7]. 2. For the special case of 1-privacy, any linear-size circuit can be computed 1-privately with constant number of random bits <ref> [42] </ref>. More generally, every circuit of m boolean gates can be computed 1-privately with O (m=n) random bits [42]. Our Results. We generalize both of the above results. <p> For the special case of 1-privacy, any linear-size circuit can be computed 1-privately with constant number of random bits <ref> [42] </ref>. More generally, every circuit of m boolean gates can be computed 1-privately with O (m=n) random bits [42]. Our Results. We generalize both of the above results. <p> For t = 1, we are only O (log n) away from the specialized (to passive adversaries only) result of <ref> [42] </ref>. An Alternative Perspective. We suggest the following alternative perspective on our results. <p> Our Constructions. Our results build on many previous ideas in the area of privacy as well as on limited independence distributions. In particular, we use the general framework of [6], and combine it with ideas from <ref> [42] </ref> together with techniques for limited independence, in order to save in randomness. <p> That is, the parties evaluate the given circuit gate by gate; each gate is computed in a manner similar to the construction of [6]. (In particular, we use the [6] modules for secret sharing and evaluating individual gates as building blocks.) However, as in <ref> [42] </ref>, not all parties participate in evaluating each gate. Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. <p> Therefore, in this case the quantification of the "amount of randomness needed" is not meaningful. (In particular, the amount of randomness needed inherently depends on a security parameter.) 3 the technique of <ref> [42] </ref> in a way which allows us to use limited independence, and then show how this can be done in a secure and robust manner, building on previous work on both secure protocol design and de-randomization techniques.
Reference: [43] <author> E. Kushilevitz, R. Ostrovsky, and A. Rosen, </author> <title> "Amortizing Randomness in Private Multiparty Computations", </title> <booktitle> Proc. of 17th PODC, </booktitle> <year> 1998, </year> <note> to appear. </note>
Reference: [44] <author> E. Kushilevitz, and A. Rosen, </author> <title> "A Randomness-Rounds Tradeoff in Private Computation", </title> <journal> CRYPTO, </journal> <volume> LNCS 839, </volume> <pages> pp. 397-410, </pages> <year> 1994. </year>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [45] <author> S. Micali, and P. Rogaway, </author> <title> "Secure Computation", </title> <type> manuscript, </type> <year> 1992. </year> <note> Preliminary version in CRYPTO 91. </note>
Reference-contexts: Several definitions of multiparty secure computation have been proposed in the past (e.g., <ref> [45, 29, 3, 13, 11] </ref>). In this work we use the definition of [11] which, for self containment, we sketch below. We concentrate on the `secure channels' setting of [6, 16], where the adversary is computationally unbounded but has no access to the communication between non-faulty parties. <p> Then, the resulted protocol 1 ;:::; k securely computes g from scratch. We call this type of composition of protocols modular composition. (This notion was first suggested in <ref> [45] </ref>. There it is called reducibility of protocols.) In formalizing this theorem we concentrate on the case where at most one subroutine invocation is running at any computational round.
Reference: [46] <author> J. Naor, and M. Naor, </author> <title> "Small-Bias Probability Spaces: Efficient Constructions and Applications", </title> <journal> STOC 90, and SIAM J. on Computing, </journal> <volume> Vol 22, No. 4, </volume> <year> 1993, </year> <pages> pp. 838-856. </pages>
Reference: [47] <author> N. Nisan, </author> <title> "Pseudorandom Generator for Space Bounded Computation", </title> <booktitle> Proc. of 22nd STOC, </booktitle> <year> 1990, </year> <pages> pp. 204-212. </pages>
Reference: [48] <author> P. Raghavan, and M. Snir, </author> <title> "Memory vs. Randomization in On-Line Algorithms", </title> <booktitle> ICALP, </booktitle> <year> 1989, </year> <pages> pp. 687-703. </pages>
Reference-contexts: Various techniques to minimize the amount of randomness needed were extensively studied in computer science (e.g., [36, 52, 10, 47, 54, 18, 32, 4, 46, 1, 50, 35, 37, 40, 33, 34]) and tradeoffs between randomness and other resources were found (e.g., <ref> [14, 48, 38, 15, 21, 9, 8, 44, 7, 42, 40] </ref>). Security vs. Randomness. It is not hard to show that some randomness is essential to maintain security (if all parties are deterministic then the adversary can infer information on the parties' inputs from their messages).
Reference: [49] <author> A. Shamir. </author> <title> "How to Share a Secret", </title> <journal> Communications of the ACM, </journal> <volume> 22 </volume> <pages> 612-613, </pages> <year> 1979. </year>
Reference-contexts: Yet we note that the the protocols for computing sec-shar n;i and recons n;W are just Shamir's secret sharing and reconstruction protocols <ref> [49] </ref>. The sharing protocol requires the dealer to choose t random values in GF [p]; namely O (t log p) random bits. The function add n can be computed by each partly locally summing its two inputs. <p> We partition the parties into sets of size s = 2t + 1 which we call teams. The input of each party will be shared only among the members of its team (using the <ref> [49, 6] </ref> secret-sharing procedure). Each gate will be assigned a team, and will be evaluated only by the parties in that team. Consequently, the output wire of each gate will be shared among the parties in the corresponding team.
Reference: [50] <author> L. J. Schulman, </author> <title> "Sample Spaces Uniform on Neighborhoods", </title> <booktitle> Proc. of 24th STOC, </booktitle> <year> 1992, </year> <pages> pp. 17-25. </pages>
Reference-contexts: In Section 5, we review the solution of [6] for the case of active (i.e., Byzantine) adversaries and in Section 6 we extend our solutions from the case of passive adversaries to the case of active adversaries. In the Appendix we describe an extension of the results of <ref> [50, 40] </ref> for sample spaces with limited independence; we use this extension in our constructions. 2 Preliminaries We start by specifying the requirements from a protocol for securely computing a function f whose inputs are partitioned among several parties. <p> However, we do not need all subsets of size fi to be uniformly distributed. It suffices that the n subsets of size fi, defined by the n subsets of t parties, be uniformly distributed. To take advantage of the relaxed requirement, we use an extension of the results of <ref> [50, 40] </ref> (which, for self containment, appears in Appendix A): Set p &gt; 2t + 1. The dealer will uniformly sample a space of M -tuples over GF [p], which is constructed to suit the specific n subsets. By [50, 40], there is a sample space of size n p fi <p> the relaxed requirement, we use an extension of the results of <ref> [50, 40] </ref> (which, for self containment, appears in Appendix A): Set p &gt; 2t + 1. The dealer will uniformly sample a space of M -tuples over GF [p], which is constructed to suit the specific n subsets. By [50, 40], there is a sample space of size n p fi such that if we sample the space uniformly, then the projection of the chosen vector on any of the n subsets is uniformly distributed. 7 To sample this space, the dealer will need randomness of O (t log (n=t) <p> S sets these values to be consistent with the data already known to the adversary; whenever a value is not determined it is chosen at random from 7 Both <ref> [50, 40] </ref> deal with the field GF [2] but can be extended to GF [p]. We note that the time-complexity of sampling in the sample space is poly (n; log n ; fi) but the complexity of the known algorithms that find such a space is poly ( n ). <p> Since there are at most t corrupted parties altogether, and each corrupted party can give a bad share to at most one party in T i , it follows that at most t parties in T i are either corrupted or start off with an erroneous share. 20 by using <ref> [50, 40] </ref>.
Reference: [51] <author> J. H. van Lint, and R. M. Wilson, </author> <title> "A Course in Combinatorics", </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Also denote, ~ D = (D (1); D (2); : : :; D (2t + 1)). With this notation we get that ~ D = V ~ d. Since V is non-singular (see, e.g., <ref> [51] </ref>), we can write ~ d = V 1 ~ D and note that the value that we are interested in sharing is D (0) = d 0 , the first element of ~ d, which can therefore be written as D (0) = d 0 = P 2t+1 1;i D
Reference: [52] <author> A. C. Yao, </author> <title> "Theory and Applications of Trapdoor Functions", </title> <booktitle> Proc. of 23rd FOCS, </booktitle> <year> 1982, </year> <pages> pp. 80-91. </pages>
Reference: [53] <author> A. C. Yao, </author> <title> "How to Generate and Exchange Secrets", </title> <booktitle> Proc. of 27th FOCS, </booktitle> <year> 1986, </year> <pages> pp. 162-167. </pages>
Reference-contexts: Over the past decade, both striving for stronger security and saving random bits received considerable amount of attention and yielded many interesting results. Secure protocols. Secure multiparty protocols (first studied in <ref> [53, 28] </ref>) are protocols that guarantee the privacy of the inputs and, at the same time, the correctness of the outputs of honest participants, even if some of the parties are maliciously faulty ("Byzantine"). Secure multiparty computations has been extensively studied, in a variety of adversarial models. <p> The following basic settings were considered. The adversary controlling the corrupted (i.e., faulty) parties can be either computationally unbounded (in which case the communication channels are assumed to be private) [6, 16], or it can be limited to efficient (probabilistic polynomial time) computations <ref> [53, 28] </ref>. In addition, the adversary can be either passive (in which case the corrupted parties are honest-but-curious; they follow their protocol and only collude to gather extra information), or active (in which case the corrupted parties may arbitrarily and maliciously deviate from their protocol). <p> In this work we consider adaptively secure protocols | that is, protocols secure against adaptive adversaries. We mention some known results: In <ref> [53, 28] </ref> it was shown that, if trapdoor permutations exist, every poly-time computable function f can be computed securely tolerating a computationally bounded, active adversary that controls up to t &lt; n=2 parties. Moreover, in the case of passive adversaries, any number t n of colluding parties is tolerable. <p> Instead, the parties are partitioned into teams of small size, and each gate is evaluated by a single team. We generalize 1 When the adversary is limited to probabilistic polynomial time and intractability assumptions are used, as in <ref> [53, 28] </ref>, then by the results of [10, 30, 31] we may as well assume the existence of a pseudorandom generator. In this case parties can expand "small" seeds of truly random bits into "long" sequences of pseudo-random bits and use them.
Reference: [54] <author> D. Zuckerman, </author> <title> "Simulating BPP Using a General Weak Random Source", </title> <booktitle> Proc. of 32nd FOCS, </booktitle> <year> 1991, </year> <pages> pp. 79-89. </pages>
References-found: 54

