URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/ml-dpe92.ps.gz
Refering-URL: http://www.cs.purdue.edu/coast/archive/clife/GA/papers/
Root-URL: http://www.cs.purdue.edu
Email: nici@cs.ucsd.edu rik@cs.ucsd.edu  
Title: Dynamic Parameter Encoding for Genetic Algorithms  
Author: Nicol N. Schraudolph Richard K. Belew 
Note: revised for publication in Machine Learning  
Date: 90-2795  July 20, 1992  
Address: La Jolla, CA 92093-0114  
Affiliation: Computer Science Engineering Department University of California, San Diego  UCSD  
Pubnum: Technical Report CS 90-175 LANL Technical Report LAUR  
Abstract: The common use of static binary place-value codes for real-valued parameters of the phenotype in Holland's genetic algorithm (GA) forces either the sacrifice of representational precision for efficiency of search or vice versa. Dynamic Parameter Encoding (DPE) is a mechanism that avoids this dilemma by using convergence statistics derived from the GA population to adaptively control the mapping from fixed-length binary genes to real values. DPE is shown to be empirically effective and amenable to analysis; we explore the problem of premature convergence in GAs through two convergence models.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Richard A. Caruana and J. David Schaf-fer. </author> <title> Representation and hidden bias: Gray vs. binary coding for genetic algorithms. </title> <booktitle> In Proc. 5th Int. Conf. Machine Learning, </booktitle> <pages> pages 153-161, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Grefen-stette) here, and also follow their practice of Gray coding all genes <ref> [1] </ref>. <p> To avoid such undesirable complications the use of Gray code for DPE-mapped genes is highly recommended; it is also generally preferable as it reduces Hamming cliffs that could mislead the GA search <ref> [1] </ref>. 5.2 Genetic Hitchhiking In the previous section we showed that the DPE trigger threshold must not be set too high since this would make it impossible for DPE to eliminate slightly suboptimal areas of the search space from consideration.
Reference: [2] <author> Kenneth A. De Jong. </author> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> Dept. of Computer and Comm. Sciences, Univ. of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1975. </year> <journal> Univ. </journal> <volume> Microfilms No. </volume> <pages> 76-9381. </pages>
Reference-contexts: re-initialization of the gene's least significant bit. 5 This is achieved with a bit shift left plus some additional manipulations in the two most significant bit positions. 3 3 Empirical Results To verify the efficiency of the DPE algorithm we checked its performance on a classical GA test function suite <ref> [2] </ref>; see Table 1 for number of genes d, length l (in bits) of each gene, and the name of each test function to be minimized.
Reference: [3] <author> Kalyonmoy Deb. </author> <title> Binary and floating point optimization using messy genetic algorithms. </title> <type> Technical Report 91004 (dissertation), </type> <institution> The Clearinghouse for Genetic Algorithms, Univ. of Alabama, Tuscaloosa, AL, </institution> <year> 1991. </year>
Reference-contexts: by no means alone in suggesting that certain aspects of genetic encoding schemes in general, and those for real numbers in particular, should be under adaptive control of the GA itself | Deb for instance has investigated floating point optimization using a GA with "messy" representations as advocated by Goldberg <ref> [3] </ref>. Shaefer in particular has influenced our work with his GA-based function optimization strategy ARGOT [11], whose many heuristics include an operator very much like the zoom operator described here. However, ARGOT also features an "inverse zoom" operator that expands the search space if there is little convergence.
Reference: [4] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization & Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: While the common restriction to fixed-length genetic representations in GA experiments is rooted in convention and convenience, theoretical arguments have been made in support of binary alphabets <ref> [4, p. 80-82] </ref>. If the function to be optimized by the GA is defined over a continuous domain, its real-valued parameters can only have approximate genotypic representations as binary codes of a given length.
Reference: [5] <author> John J. Grefenstette. </author> <title> A user's guide to GENESIS. </title> <type> Technical Report CS-84-11, </type> <institution> Vanderbilt Univ., Nashville, TN, </institution> <year> 1984. </year>
Reference-contexts: 1 Motivation Genetic Algorithms (GAs) are capable of efficiently searching complex fitness landscapes utilizing methods inspired by biological evolution [7]. The work reported here used the GAucsd 1 software which implements a pop 1 GAucsd is our variant of the GENESIS package <ref> [5] </ref> supporting | among other enhancements | user ular form of the GA, applying the operators of selective reproduction, mutation and crossover to a fixed-length binary genome.
Reference: [6] <author> William E. Hart and Richard K. Belew. </author> <title> Optimizing an arbitrary function is hard for the genetic algorithm. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proc. 4th Intl. Conf. Genetic Algorithms, </booktitle> <pages> pages 190-195, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Returning to Figure 2, we note that with our default set of parameters DPE actually worsens the performance for f5, the only multimodal function in the test suite. However, this merely demonstrates that there is no universally optimal parameter setting for the GA <ref> [6] </ref>; in this case three bits per gene do not provide enough search resolution for DPE to evaluate which of f5's 25 optima is the best.
Reference: [7] <author> John H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> The Univ. of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: 1 Motivation Genetic Algorithms (GAs) are capable of efficiently searching complex fitness landscapes utilizing methods inspired by biological evolution <ref> [7] </ref>. The work reported here used the GAucsd 1 software which implements a pop 1 GAucsd is our variant of the GENESIS package [5] supporting | among other enhancements | user ular form of the GA, applying the operators of selective reproduction, mutation and crossover to a fixed-length binary genome. <p> This process could then be iterated until the result has the desired precision. In essence, this is what Dynamic Parameter Encoding (DPE) does autonomously and for each real-valued gene in 3 This implicit parallelism <ref> [7] </ref> occurs in the evaluation of low-order schemata, ie. exactly where it is not useful in case of a standard place-value representation. parallel.
Reference: [8] <author> Venkat R. Mandava, J. Michael Fitz-patrick, and David R. Pickens, III. </author> <title> Adaptive search space scaling in digital image registration. </title> <journal> IEEE Trans. Medical Imaging, </journal> <volume> 8(3) </volume> <pages> 251-262, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Two more approaches closely related to ARGOT and DPE have recently come to our attention: the Adaptive Search Space Scaling algorithm applied to medical image registration <ref> [8] </ref>, and the technique of Delta Coding [12]. Like ARGOT, these methods employ a form of inverse zoom that makes implicit assumptions (such as piecewise monotonicity) about the function being searched, thus sacrificing generality for performance.
Reference: [9] <author> J. David Schaffer, Richard A. Caruana, Larry J. Eshelman, and Rajarshi Das. </author> <title> A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <editor> In J. David Schaf-fer, editor, </editor> <booktitle> Proc. 3rd Intl. Conf. Genetic Algorithms, </booktitle> <pages> pages 51-60, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: 12 Rosenbrock's saddle f3 5 10 step function f4 30 8 x 4 with noise ( = 1) f5 2 17 Shekel's foxholes In a large empirical study Schaffer et al. have identified values for population size, crossover and mutation rate that produce good online performance on this test suite <ref> [9] </ref>; we are using their results (which are almost identical to earlier recommendations by John J. Grefen-stette) here, and also follow their practice of Gray coding all genes [1].
Reference: [10] <author> H. P. Schwefel. </author> <title> Numerical Optimization of Computer Models. </title> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1981. </year>
Reference-contexts: gained precision is thus bought at a high computational price. than tripled population size and crossover rate 9 no choice of mutation rate enables the plain GA to optimize the quadratic function 8 A more elaborate example of this approach is the adaptive control of mutation variances in evolutionary strategies <ref> [10] </ref>. 9 Population size 100, crossover rate 3.0 | that is, three independent two-point crossovers for each pair of parents. f m = trials various mutation rates, contrasted with DPE performance. f1 | trivial by optimization standards | to any high precision. <p> Since De Jong's test suite provides with f5 only one multimodal function, we performed additional tests on the following problem <ref> [10] </ref>: f 7 (~x) = i=1 p The best of the over 10 9 local optima of this function are located far from the global opti mum yet are almost as attractive (within 3% of optimal), making it especially hard for DPE to prune this search space.
Reference: [11] <author> Craig G. Shaefer. </author> <title> The ARGOT strategy: Adaptive representation genetic optimizer technique. </title> <editor> In John J. Grefenstette, editor, </editor> <booktitle> Genetic Algorithms and their Applications: Proc. 2nd Intl. Conf., </booktitle> <pages> pages 50-58, </pages> <address> Hillsdale, NJ, 1987. </address> <publisher> Lawrence Erl-baum Associates. </publisher>
Reference-contexts: The next two sections of this paper describe the DPE algorithm and demonstrate its effectiveness, respectively. We then contrast DPE with related approaches to the problem of real value representations in GAs, and the ARGOT strategy <ref> [11] </ref> in particular. <p> Shaefer in particular has influenced our work with his GA-based function optimization strategy ARGOT <ref> [11] </ref>, whose many heuristics include an operator very much like the zoom operator described here. However, ARGOT also features an "inverse zoom" operator that expands the search space if there is little convergence.
Reference: [12] <author> D. Whitley, K. Mathias, and P. Fitzhorn. </author> <title> Delta coding: An iterative search strategy for genetic algorithms. </title> <editor> In Richard K. Belew and Lashon B. Booker, editors, </editor> <booktitle> Proc. 4th Intl. Conf. Genetic Algorithms, </booktitle> <pages> pages 77-84, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Mor-gan Kaufmann. </publisher> <pages> 11 </pages>
Reference-contexts: Two more approaches closely related to ARGOT and DPE have recently come to our attention: the Adaptive Search Space Scaling algorithm applied to medical image registration [8], and the technique of Delta Coding <ref> [12] </ref>. Like ARGOT, these methods employ a form of inverse zoom that makes implicit assumptions (such as piecewise monotonicity) about the function being searched, thus sacrificing generality for performance.
References-found: 12

