URL: http://scotch.cs.yale.edu/saha/papers/cfa.ps
Refering-URL: http://scotch.cs.yale.edu/saha/papers/index.html
Root-URL: http://www.cs.yale.edu
Title: Subtransitive CFA using Types  
Author: Bratin Saha Nevin Heintze Dino Oliva 
Date: October 9, 1998  
Address: New Haven, CT Murray Hill, NJ Murray Hill, NJ  
Affiliation: Yale University Department of Computer Science  Yale University Bell Laboratories Bell Laboratories  
Pubnum: YALEU/DCS/TR-1166  
Abstract: The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the U.S. Government. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aiken and E. Wimmers, </author> <title> "Type Inclusion and Type Inference", </title> <booktitle> ACM Conference on Functional Programming and Computer Architecture, </booktitle> <year> 1993, </year> <pages> pp 31-41. </pages>
Reference-contexts: Starting from the early work by Jones [11, 12] and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. <ref> [2, 6, 1, 5, 10, 16, 4] </ref>. The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232.
Reference: [2] <author> A. Bondorf and J. Jorgensen, </author> <title> Journal of Functional Programming, "Efficient analysis for realistic off-line partial evaluation", </title> <journal> Vol. </journal> <volume> 3, No. 3, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: Starting from the early work by Jones [11, 12] and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. <ref> [2, 6, 1, 5, 10, 16, 4] </ref>. The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232.
Reference: [3] <author> G. DeFouw, D. Grove, and C. Chambers, </author> <title> "Fast Interprocedural Class Analysis", </title> <booktitle> Proc. 1998 ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pp. 222-236, </pages> <year> 1995. </year>
Reference-contexts: Other papers have dealt with making unification-based analyses more accurate. For example, <ref> [3] </ref> shows that by changing the way calls and returns are matched, one can improve the accuracy of the unification-based approach, so that for some benchmarks, the results are essentially as accurate as those obtained by using the cubic time algorithm.
Reference: [4] <author> M. Fahndrich, J. Foster, Z. Su, and A. Aiken, </author> <title> "Partial Online Cycle Elimination in Inclusion Constraint Graphs", </title> <booktitle> ACM Conference on Programming Language Design and Implementation, </booktitle> <year> 1998, </year> <pages> pp 85-96. </pages>
Reference-contexts: Starting from the early work by Jones [11, 12] and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. <ref> [2, 6, 1, 5, 10, 16, 4] </ref>. The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232. <p> Some papers have addressed methods for improving the scalability of 0CFA-style analyses by removing redundancies [5] and by recognizing "equivalent" nodes and collapsing them <ref> [4] </ref> (strictly speaking, [4] addresses points-to-analysis for C, but the techniques are directly applicable to 0CFA). Other papers have dealt with making unification-based analyses more accurate. <p> Some papers have addressed methods for improving the scalability of 0CFA-style analyses by removing redundancies [5] and by recognizing "equivalent" nodes and collapsing them <ref> [4] </ref> (strictly speaking, [4] addresses points-to-analysis for C, but the techniques are directly applicable to 0CFA). Other papers have dealt with making unification-based analyses more accurate.
Reference: [5] <author> C. Flanagan and M. Felleisen, </author> <title> "Componential Set-Base Analysis", </title> <booktitle> ACM Conference on Programming Language Design and Implementation, </booktitle> <year> 1997, </year> <pages> pp 235-248. </pages>
Reference-contexts: Starting from the early work by Jones [11, 12] and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. <ref> [2, 6, 1, 5, 10, 16, 4] </ref>. The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232. <p> In practice, it has been observed that analyses based on 0CFA rarely exhibit cubic behavior, but they often behave non-linearly, and this has discouraged their wider use in production compilers. Some papers have addressed methods for improving the scalability of 0CFA-style analyses by removing redundancies <ref> [5] </ref> and by recognizing "equivalent" nodes and collapsing them [4] (strictly speaking, [4] addresses points-to-analysis for C, but the techniques are directly applicable to 0CFA). Other papers have dealt with making unification-based analyses more accurate.
Reference: [6] <author> N. Heintze, </author> <title> "Set-Based Analysis of ML Programs", </title> <booktitle> ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pp 306-317, </pages> <year> 1994. </year>
Reference-contexts: Starting from the early work by Jones [11, 12] and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. <ref> [2, 6, 1, 5, 10, 16, 4] </ref>. The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232.
Reference: [7] <author> N. Heintze, </author> <title> "Control-Flow Analysis and Type Systems", Static Analysis Symposium, </title> <booktitle> 1995, </booktitle> <pages> pp 189-206. </pages>
Reference: [8] <author> N. Heintze and D. McAllester, </author> <booktitle> "On the Cubic-Bottleneck of Subtyping and Flow Analysis" IEEE Symposium on Logic in Computer Science, </booktitle> <year> 1997. </year>
Reference-contexts: When formulated as constraints, it uses inclusions. This algorithm has cubic time complexity (in the size of the input program) and recent work shows that, in the general case, we cannot hope to do better <ref> [8] </ref>. The other algorithm is based on unification, and involves a bi-directional flow of information - in essence, if one node can "flow" to another, then the two nodes are unified. When formulated as constraints, it uses equations.
Reference: [9] <author> N. Heintze and D. McAllester, </author> <booktitle> "Linear-Time Subtransitive Control Flow Analysis" ACM Conference on Programming Language Design and Implementation, </booktitle> <year> 1997, </year> <pages> pp 261-272. </pages>
Reference-contexts: For example, [3] shows that by changing the way calls and returns are matched, one can improve the accuracy of the unification-based approach, so that for some benchmarks, the results are essentially as accurate as those obtained by using the cubic time algorithm. In yet another approach, <ref> [9] </ref> develop a linear-time algorithm that computes the same information as the 0CFA for programs with bounded-type size. (Strictly speaking, their algorithm computes a graph whose transitive closure is identical to the results of 0CFA; they argue that many applications of CFA can be adapted to directly use this "subtransitive control-flow <p> As described in <ref> [9] </ref>, linear-time termination of the algorithm depends on the existence of a simple typing of the program such that the type tree at each node has a bounded size. A key question raised in [9] is: do programs have bounded type size in practice and how big is the bound? Early <p> As described in <ref> [9] </ref>, linear-time termination of the algorithm depends on the existence of a simple typing of the program such that the type tree at each node has a bounded size. A key question raised in [9] is: do programs have bounded type size in practice and how big is the bound? Early results in [9] for some small benchmarks (up to about 1000 lines of ML), and substantial folklore evidence suggest that most programs people write have bounded types and that the bound is quite small. <p> A key question raised in <ref> [9] </ref> is: do programs have bounded type size in practice and how big is the bound? Early results in [9] for some small benchmarks (up to about 1000 lines of ML), and substantial folklore evidence suggest that most programs people write have bounded types and that the bound is quite small. However, very recent work [14] suggests otherwise. <p> If the types of a program are used as templates to guide the application of the closure rules, (in phase two of the algorithm), then our results show that the approach is not scalable. <ref> [9] </ref> suggest that instead of using types to guide the closure rules, we can make the algorithm demand-driven. The idea here is that in the second phase of the algorithm, we apply the closure rules only when (and if) they are needed. <p> The intuition is that in many cases we need not explore the entire type tree for each node in the program. However, as we show in Section 4, the extension to polymorphically typed programs (described in <ref> [9] </ref>) interacts badly with the demand-driven approach. Specifically, the demand-driven approach does not always terminate on polymorphically typed bounded-type programs. <p> For example, in the CLOSE-DOM rule we add the precondition n 0 ! Dom (n 2 ) i.e. there is an edge from some random node n 0 to Dom (n 2 ). See <ref> [9] </ref> for further details and correctness arguments. 3 Type Size Type size is critical to the practicality of the LT-ST-CFA algorithm, particularly for the variant that uses types to control the application of the closure rules. <p> Functors often expose an input module via multiple access paths and this behavior is analogous to our pair function above. Furthermore, this programming style is often required to specify sharing constraints and occurs in large pieces of code like CM 4 The Demand-Driven Algorithm and Polymorphism <ref> [9] </ref> presents a demand driven variant of the LT-ST-CFA algorithm. Section 5 of [9] presents extensions for bounded-type polymorphic programs (a polymorphically typed program has type size bounded by k if the sum of the type tree sizes of the expressions in the let-expanded version of the program are bounded by <p> Furthermore, this programming style is often required to specify sharing constraints and occurs in large pieces of code like CM 4 The Demand-Driven Algorithm and Polymorphism <ref> [9] </ref> presents a demand driven variant of the LT-ST-CFA algorithm. Section 5 of [9] presents extensions for bounded-type polymorphic programs (a polymorphically typed program has type size bounded by k if the sum of the type tree sizes of the expressions in the let-expanded version of the program are bounded by k:n, where n is the size of the original program). <p> However our desire is to provide a more generic analysis for reasoning about functions, data constructors and arithmetic. Our results so far indicate that a straightforward adaptation of the data structure rules from <ref> [9] </ref> is not feasible on large benchmarks. We are currently investigating alternatives. Acknowledgement We thank Prof. Zhong Shao for helping us with many of the FLINT queries. We also thank Chris League for providing some of the code we used for measuring type sizes. 12
Reference: [10] <author> S. Jagannathan and S. Weeks, </author> <title> "A Unified Treatment of Flow Analysis in Higher-Order Languages", </title> <booktitle> Proc. 1995 ACM Symposium on the Principles of Programming Languages, </booktitle> <year> 1995. </year>
Reference-contexts: Starting from the early work by Jones [11, 12] and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. <ref> [2, 6, 1, 5, 10, 16, 4] </ref>. The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232.
Reference: [11] <author> N. Jones, </author> <title> "Flow Analysis of Lambda Expressions", </title> <booktitle> Symp. on Functional Languages and Computer Architecture, </booktitle> <pages> pp. 66-74, </pages> <year> 1981. </year>
Reference-contexts: However for programs that make significant use of higher-order features, this analysis is very crude, and may result in many lost opportunities for optimization. Over the last 20 years, a number of more aggressive approaches to control-flow analysis have been considered. Starting from the early work by Jones <ref> [11, 12] </ref> and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. [2, 6, 1, 5, 10, 16, 4].
Reference: [12] <author> N. Jones, </author> <title> "Flow Analysis of Lazy Higher-Order Functional Programs", in Abstract Interpretation of Declarative Languages, </title> <editor> S. Abramsky and C. Hankin (Eds.), </editor> <publisher> Ellis Horwood, </publisher> <year> 1987. </year>
Reference-contexts: However for programs that make significant use of higher-order features, this analysis is very crude, and may result in many lost opportunities for optimization. Over the last 20 years, a number of more aggressive approaches to control-flow analysis have been considered. Starting from the early work by Jones <ref> [11, 12] </ref> and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. [2, 6, 1, 5, 10, 16, 4].
Reference: [13] <author> R. Milner, M. Tofte and R. Harper, </author> <title> "The Definition of Standard ML", </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference: [14] <author> Z. Shao, C. League, and S. Monnier, </author> <title> "Implementing Typed Intermediate Languages", </title> <booktitle> ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pp. 313-323, </pages> <year> 1998. </year>
Reference-contexts: However, very recent work <ref> [14] </ref> suggests otherwise. In section 3, we present a detailed type-size study that includes more benchmarks and measures type size in a way that is directly applicable to the LT-ST-CFA algorithm. Although our results are not as negative as the ones in [14], they provide strong evidence that a naive type-based <p> However, very recent work <ref> [14] </ref> suggests otherwise. In section 3, we present a detailed type-size study that includes more benchmarks and measures type size in a way that is directly applicable to the LT-ST-CFA algorithm. Although our results are not as negative as the ones in [14], they provide strong evidence that a naive type-based approach to the LT-ST-CFA algorithm is not tenable. <p> So, when an administrative node is built from an already existing node, we check that this invariant is satisfied. Our algorithm is implemented in the SML/NJ compiler and is based on the FLINT <ref> [14] </ref> intermediate language. FLINT (Figure 5) is based upon a predicative variant of the Girard-Reynolds polymorphic - calculus [17, 18]. We use T () to denote the type corresponding to the constructor . <p> One disadvantage of FLINT is that it uses a De Bruijn index representation for types <ref> [14] </ref>; and as a result, some of the type operations required by our algorithm were not trivial to implement. robust than either the demand-driven or type-driven approaches. We use 1 to indicate benchmarks that did not terminate in two minutes.
Reference: [15] <author> O. Shivers, </author> <title> "Control Flow Analysis in Scheme", </title> <booktitle> Proc. 1988 ACM Conf. on Programming Language Design and Implementation, </booktitle> <pages> pp. 164-174, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: Over the last 20 years, a number of more aggressive approaches to control-flow analysis have been considered. Starting from the early work by Jones [11, 12] and then Shivers <ref> [15] </ref>, there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. [2, 6, 1, 5, 10, 16, 4].
Reference: [16] <author> B. Steensgaard, </author> <title> "Points-to Analysis in Almost Linear Time", </title> <booktitle> Proc. 1996 ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pp. 32-41, </pages> <year> 1996. </year>
Reference-contexts: Starting from the early work by Jones [11, 12] and then Shivers [15], there has been an explosion of interest in issues such as extending the basic analysis to data structures, references, arrays, implementation strategies and polyvariance, e.g. <ref> [2, 6, 1, 5, 10, 16, 4] </ref>. The first author was sponsored in part by a summer internship at Bell Laboratories and in part by the DARPA ITO under the title "Software Evolution using HOT Language Technology", DARPA Order No. D888, issued under Contract No. F30602-96-2-0232.
Reference: [17] <author> J. Y. Girard, </author> <title> "Interpretation Fonctionnelle et Elimination des Coupures dans l'Arithmetique d'Ordre Superieur", </title> <year> 1972. </year>
Reference-contexts: Our algorithm is implemented in the SML/NJ compiler and is based on the FLINT [14] intermediate language. FLINT (Figure 5) is based upon a predicative variant of the Girard-Reynolds polymorphic - calculus <ref> [17, 18] </ref>. We use T () to denote the type corresponding to the constructor . The terms are an explicitly typed -calculus (but in A-normal form) with explicit constructor abstraction (fl l t:e) and application (x [] l ).
Reference: [18] <author> John C. Reynolds, </author> <title> "Towards a theory of type structure", </title> <booktitle> Proceedings, Colloque sur la Programmation, Lecture Notes in Computer Science, </booktitle> <volume> volume 19, </volume> <pages> pp. 408-425, </pages> <year> 1974. </year> <month> 13 </month>
Reference-contexts: Our algorithm is implemented in the SML/NJ compiler and is based on the FLINT [14] intermediate language. FLINT (Figure 5) is based upon a predicative variant of the Girard-Reynolds polymorphic - calculus <ref> [17, 18] </ref>. We use T () to denote the type corresponding to the constructor . The terms are an explicitly typed -calculus (but in A-normal form) with explicit constructor abstraction (fl l t:e) and application (x [] l ).
References-found: 18

