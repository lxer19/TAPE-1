URL: ftp://ftp.physik.uni-wuerzburg.de/pub/preprint/1998/WUE-ITP-98-016.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00473.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Multilayer perceptrons may learn simple rules quickly  
Author: R. Urbanczik 
Date: November 27, 1997  
Address: Am Hubland D-97074 Wurzburg Germany  
Affiliation: Institut fur theoretische Physik Universitat Wurzburg  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Vapnik, </author> <title> Estimation of Dependences Based on Empirical Data (Springer, </title> <address> Berlin, </address> <year> 1982). </year>
Reference: [2] <author> S. Amari and S. Shinomoto, </author> <booktitle> Neural Computation 4, </booktitle> <month> 605 </month> <year> (1992). </year>
Reference: [3] <author> G. Mitchison and R. </author> <title> Durbin, </title> <booktitle> Biological Cybernetics 60, </booktitle> <month> 345 </month> <year> (1989). </year>
Reference: [4] <author> G. Gyorgyi, </author> <note> Phys. Rev. A 41, 7097 (1990). </note>
Reference: [5] <author> H. Sompolinsky, N. Tishby, and H. </author> <title> Seung, </title> <journal> Phys. Rev. Lett. </journal> <volume> 65, </volume> <month> 1683 </month> <year> (1990). </year>
Reference: [6] <author> H. Seung, H. Sompolinsky, and N. Tishby, </author> <note> Phys. Rev. A 45, 6056 (1992). </note>
Reference: [7] <author> G. Martin and J. </author> <title> Pittman, </title> <booktitle> Neural Computation 3, </booktitle> <month> 258 </month> <year> (1991). </year>
Reference: [8] <author> Y. LeCun et al., </author> <title> in Neural Networks: The Statistical Mechanics Perspective, edited by J. Oh, </title> <editor> C. Kwon, and S. </editor> <publisher> Cho (World Scientific, </publisher> <address> Singapore, </address> <year> 1995), </year> <pages> pp. 261-276. </pages>
Reference: [9] <author> H. Schwarze, M. Opper, and W. </author> <title> Kinzel, </title> <journal> Phys. </journal> <note> Rev. A 46, R6185 (1992). 10 </note>
Reference: [10] <author> D. Haussler, </author> <note> Information and Computation 100, 78 (1992). </note>
Reference: [11] <author> M. Opper and D. Haussler, </author> <title> Phys. </title> <journal> Rev. Lett. </journal> <volume> 66, </volume> <month> 2677 </month> <year> (1991). </year>
Reference: [12] <author> R. Urbanczik, J. </author> <note> Phys. A 28, 7097 (1995). </note>
Reference-contexts: For all the parametrizations of q and R we shall consider, one may show as in <ref> [12] </ref> that the joint distribution of Z a and Y is Gaussian in the limit K ! 1 when M is equal to 1 or when M is large as well.
Reference: [13] <author> M. Opper and D. Haussler, </author> <booktitle> in Proceedings of the fourth annual workshop on computational learning theory, </booktitle> <editor> edited by L. Valiant and M. </editor> <publisher> Warmuth (Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1991), </year> <pages> pp. 75-87. </pages>
Reference-contexts: As pointed out in <ref> [13] </ref>, it is thus easy to evaluate hF (r (~; ))i (~;) if F is, or can arbitrarily well be approximated by, a polynomial.
Reference: [14] <author> M. Opper and W. </author> <title> Kinzel, in Models of neural networks III, edited by E. </title> <editor> Domany, J. van Hemmen, and K. </editor> <publisher> Shulten (Springer, </publisher> <address> New York, </address> <year> 1995), </year> <pages> pp. </pages> <month> 151-207. </month> <title> Note that the authors measure the generalization performance against the noiseless teacher. If one compares with the noisy teacher, their result is as quoted above. </title>
Reference-contexts: The generalization error of the ensemble becomes minimal in all cases. For input noise, the 1= ~ff decay of the ensemble quite remarkably 6 equalizes the decay in the Bayesian algorithm which is optimized for this specific class of teachers <ref> [14] </ref>. The great difference between the ensemble and sampling may be explained quite simply: Let ^ B = K 1 P i J i be the (rescaled) average weight vector of a typical student in version space.
Reference: [15] <author> R. Urbanczik, J. </author> <note> Phys. A 30, L387 (1997). </note>
Reference: [16] <author> H. Schwarze, J. </author> <note> Phys. A 26, 5781 (1993). </note>
Reference-contexts: The generalization error is the same as for M = K in this unspecialized phase <ref> [16] </ref>. However above a critical sample size, ^ff 5:17, the value of increases from zero and it diverges with growing ^ff. The value of R s is close to one already at the transition.

References-found: 16

