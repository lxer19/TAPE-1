URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3115/3115.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: Space-Efficient Hot Spot Estimation  
Author: Kenneth Salem 
Note: This work was supported by CESDIS, NASA's Center of Excellence in Space Data and Information Sciences  
Address: College Park, Maryland, USA 20742  
Affiliation: Institute for Advanced Computer Studies and Department of Computer Science University of Maryland  
Abstract: This paper is concerned with the problem of identifying names which occur frequently in an ordered list of names. Such names are called hot spots. Hot spots can be identified easily by counting the occurrences of each name and then selecting those with large counts. However, this simple solution requires space proportional to the number of names that occur in the list. In this paper, we present and evaluate two hot spot estimation techniques. These techniques guess the frequently occurring names, while using less space than the simple solution. We have implemented and tested both techniques using several types of input traces. Our experiments show that very accurate guesses can be made using much less space than the simple solution would require. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sedat Akyurek and Kenneth Salem. </author> <title> Adaptive block rearrangement. </title> <booktitle> In Proceedings of the Interna tional Conference on Data Engineering, </booktitle> <pages> pages 182-189, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: We believe that each of these techniques has useful applications, and so we report them both here. Hot spot estimation has many applications. We have used it in an adaptive storage manager to determine which stored data are accessed frequently <ref> [1, 2] </ref>. In this application, the ordered list of names is the stream of data requests arriving at the storage manager. The storage manager can take advantage of detected hot spots in a variety of ways. <p> Names are reported as hot spots only if they fall into frequently referenced parititions under all of the partitionings. A pseudo-code implementation of RP is shown in Figure 2. Suppose that hash functions are available which map names to integers in the range <ref> [1; C] </ref>. Each such function defines a partitioning of the name space into C distinct subspaces. The RP algorithm uses K such functions to define K different partitionings of the name space. Every name is assigned to exactly K partitions, one for each of the K hash functions.
Reference: [2] <author> Sedat Akyurek and Kenneth Salem. </author> <title> Adaptive block rearrangement in unix. </title> <booktitle> In Proc. Usenix Summer Conference, </booktitle> <pages> pages 307-321, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: We believe that each of these techniques has useful applications, and so we report them both here. Hot spot estimation has many applications. We have used it in an adaptive storage manager to determine which stored data are accessed frequently <ref> [1, 2] </ref>. In this application, the ordered list of names is the stream of data requests arriving at the storage manager. The storage manager can take advantage of detected hot spots in a variety of ways.
Reference: [3] <author> J. Lawrence Carter and Mark N. Wegman. </author> <title> Universal classes of hash functions. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18 </volume> <pages> 143-154, </pages> <year> 1979. </year>
Reference-contexts: In other words, both x and y will be reported hot. To reduce the likelihood of this occurrence, RP's hash functions are randomly generated from a class of universal 2 hash functions <ref> [3] </ref>.
Reference: [4] <author> S. Christodoulakis. </author> <title> Implication of certain assumptions in data base performance evaluation. </title> <journal> ACM Transactions on Database Systems, </journal> <month> June </month> <year> 1984. </year>
Reference-contexts: However, since on-line techniques are fast and require relatively little memory, they may still be valuable when large volumes of data must be processed. Hot spots are a well-known phenomenom in both computer systems and natural systems. Numerous studies, e.g., <ref> [4, 13, 5, 7] </ref>. have reported the existence of skewed data or request distributions in file systems and database systems. Generally, these studies have used off-line analyses of reference traces to measure the complete distributions.
Reference: [5] <author> Christos Faloutsos and H. V. Jagadish. </author> <title> On B-tree indices for skewed distributions. </title> <booktitle> In Proceedings of the International Conference on Very Large Data Bases, </booktitle> <pages> pages 363-374, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: However, since on-line techniques are fast and require relatively little memory, they may still be valuable when large volumes of data must be processed. Hot spots are a well-known phenomenom in both computer systems and natural systems. Numerous studies, e.g., <ref> [4, 13, 5, 7] </ref>. have reported the existence of skewed data or request distributions in file systems and database systems. Generally, these studies have used off-line analyses of reference traces to measure the complete distributions. <p> In data processing systems, special concurrency controls [6, 11] and data structures <ref> [5] </ref> can be used. We are aware of one other paper [10] that addresses the hot spot detection problem. That paper presents two detection algorithms.
Reference: [6] <author> Dieter Gawlick and David Kinkade. </author> <title> Varieties of concurrency control in IMS/VS Fast Path. </title> <journal> Database Engineering, </journal> <volume> 8(2) </volume> <pages> 3-10, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: In data processing systems, special concurrency controls <ref> [6, 11] </ref> and data structures [5] can be used. We are aware of one other paper [10] that addresses the hot spot detection problem. That paper presents two detection algorithms.
Reference: [7] <author> David W. Jensen and Daniel A. Reed. </author> <title> File archive activity in a supercomputing environment. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: However, since on-line techniques are fast and require relatively little memory, they may still be valuable when large volumes of data must be processed. Hot spots are a well-known phenomenom in both computer systems and natural systems. Numerous studies, e.g., <ref> [4, 13, 5, 7] </ref>. have reported the existence of skewed data or request distributions in file systems and database systems. Generally, these studies have used off-line analyses of reference traces to measure the complete distributions.
Reference: [8] <author> Donald E. Knuth. </author> <title> Sorting and Searching, </title> <booktitle> volume 3 of The Art of Computer Programming. </booktitle> <publisher> Addison Wesley, </publisher> <year> 1973. </year>
Reference-contexts: Unfortunately, any names that collide under f conv can never be resolved by the RP algorithm. Several common, simple conversion functions produced significant numbers of collisions in our test traces. (For 7 example, combining character codes using exclusive-or to produce an integer key, as suggested in <ref> [8] </ref>, did not work well on the file names in our NCAR trace.) We were able to reduce this problem by using a different conversion function for each integer hash function h a;b .
Reference: [9] <author> Ethan L. Miller. </author> <title> File migration on the Cray Y-MP at the National Center for Atmospheric Research. </title> <type> Technical report, </type> <institution> Computer Science Division, Dept. of EECS, University of California at Berkeley, </institution> <month> June </month> <year> 1991. </year>
Reference-contexts: The sequence of file names from the trace is the input sequence used to drive the hot spot detection algorithms. Further information on the collection of these data and on the NCAR mass storage system itself can be found in <ref> [9] </ref>. The NASA trace is intended to be representative of an input sequence from a scientific data processing application. The trace consists of a list of pixel values taken from a multi-spectral image of the Wash-ington, DC metropolitan area.
Reference: [10] <author> J. Misra and D. Gries. </author> <title> Finding repeated elements. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 2(2) </volume> <pages> 143-152, </pages> <month> November </month> <year> 1982. </year>
Reference-contexts: In data processing systems, special concurrency controls [6, 11] and data structures [5] can be used. We are aware of one other paper <ref> [10] </ref> that addresses the hot spot detection problem. That paper presents two detection algorithms. Both detect hot spots with perfect accuracy, and one is known to have a space overhead proportional to 1=T , where T is the frequency threshold for hot spots. <p> However, both algorithms require two passes over the reference string, thus they cannot be used for on-line estimation. Although they were not designed for this purpose, the first pass (only) of either algorithm from <ref> [10] </ref> could be used as an on-line estimation technique. Used this way, either algorithm could produce false positives, but no false negatives (like the RP algorithm described here). However, neither algorithm allows a tradeoff between space overhead and accuracy.
Reference: [11] <author> Patrick E. O'Neil. </author> <title> The escrow transaction method. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(4) </volume> <pages> 405-430, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: In data processing systems, special concurrency controls <ref> [6, 11] </ref> and data structures [5] can be used. We are aware of one other paper [10] that addresses the hot spot detection problem. That paper presents two detection algorithms.
Reference: [12] <author> John A. Richards. </author> <title> Remote Sensing Digital Image Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: Second, clusters are associated with peaks in the histogram. Finally, individual data points are assigned to clusters based on their proximity to the peaks (clusters). (An application of this technique for clustering of pixels in multi-spectral images is described in <ref> [12] </ref>.) Clearly, the process of constructing a histogram to determine its peak values is hot spot detection. For data processing tasks such as this, it is not critical that on-line hot spot detection be used.
Reference: [13] <author> Carl Staelin and Hector Garcia-Molina. </author> <title> Clustering active disk data to improve disk performance. </title> <type> Technical Report CS-TR-283-90, </type> <institution> Department of Computer Science, Princeton University, Princeton, NJ, </institution> <month> September </month> <year> 1990. </year> <month> 20 </month>
Reference-contexts: However, since on-line techniques are fast and require relatively little memory, they may still be valuable when large volumes of data must be processed. Hot spots are a well-known phenomenom in both computer systems and natural systems. Numerous studies, e.g., <ref> [4, 13, 5, 7] </ref>. have reported the existence of skewed data or request distributions in file systems and database systems. Generally, these studies have used off-line analyses of reference traces to measure the complete distributions.
References-found: 13

