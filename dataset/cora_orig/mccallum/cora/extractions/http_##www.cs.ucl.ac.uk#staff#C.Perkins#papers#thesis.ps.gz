URL: http://www.cs.ucl.ac.uk/staff/C.Perkins/papers/thesis.ps.gz
Refering-URL: http://www.cs.ucl.ac.uk/staff/C.Perkins/papers/
Root-URL: http://www.cs.ucl.ac.uk
Title: Reliability Modelling and Analysis of Real-Time Systems  
Author: Colin Stanley Perkins 
Degree: Submission in partial fulfillment of the requirements for the degree of Doctor of Philosophy  
Date: September 1996  
Affiliation: University of York Department of Electronics  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> ACM Committee on Computers and Public Policy. </institution> <note> Forum on risks to the public in computers and related systems. Internet mailing list &lt;risks@csl.sri.com&gt;. Archived at http://catless.ncl.ac.uk/Risks/. </note>
Reference-contexts: A growing awareness of the increasing reliance of society on such unproven technology, together with a number of widely publicised failures (for numerous examples, see the discussion in <ref> [1] </ref>), has lead to much effort being expended in both areas. It is, however, the second method which forms the basis of this thesis: the modelling and reliability analysis of real-time embedded systems is considered, together with techniques for achieving reliability in the presence of faults.
Reference: [2] <author> T. Anderson and P. A. Lee. </author> <title> The provision of recoverable interfaces. </title> <booktitle> In Digest of papers : 9th International symposium on fault-tolerant computing. IEEE, </booktitle> <year> 1979. </year>
Reference-contexts: It is therefore seen that an unreliable, but replicated, hardware system (comprising off-the-shelf components) can be made reliable by using a layered software protocol <ref> [2] </ref>, that is, a protocol to make a reliable system at level n from an unreliable system at level (n-1). Hardware failures are masked using software techniques, resulting in a reliable system without the special purpose hardware.
Reference: [3] <author> T. Anderson and P. A. Lee. </author> <title> Fault tolerance | Principles and practice. </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: As an example of this, it is useful to discuss the differences between forward and backward error recovery techniques. Forward error recovery schemes must manipulate the current system state in order to perform error recovery <ref> [3] </ref>. This is typically implemented using exception handling techniques [13] and other application specific procedures. A forward error recovery scheme has the advantage of working from the current system state, and so it can be made very efficient in many cases. <p> However, it also has the problem that any recovery mechanism must necessarily be very application specific, and so forward error recovery cannot be used to recover from unanticipated errors. In contrast, backward error recovery schemes <ref> [3] </ref> rely on restoring a prior system state which will, hopefully, be free from error. <p> Atomic actions are the basis for a number of useful techniques, such as atomic transactions, recovery blocks and conversations. These are discussed in more detail in section 2.3. For a further discussion of atomic actions the reader is referred to <ref> [3] </ref>. 2.3 Advanced Techniques for Software Fault Tolerance The discussion in section 2.2 has focused on the basic building blocks for software fault tolerance. In many cases, these simple techniques are not sufficient, and must be extended to provide the required properties.
Reference: [4] <author> C. Andre. </author> <title> Synchronized elementary net systems. </title> <editor> In G. Rozenberg, editor, </editor> <booktitle> Advances in Petri nets 1989, volume 424 of Lecture notes in Computer Science, </booktitle> <pages> pages 51-76. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: CHAPTER 3. RELIABILITY MODELLING 25 A system such as this will allow the temporal properties of a system to be modelled, and indeed the use of such systems is noted a number of times in the literature (see, for example, <ref> [4, 15] </ref>).
Reference: [5] <author> J. Arlat, K. Kanoun, and J.-C. Laprie. </author> <title> Dependability modeling and evaluation of software fault-tolerant systems. </title> <journal> IEEE Transactions on computers, </journal> <volume> 39(4) </volume> <pages> 504-513, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: The remainder of this section discusses a number of Markovian reliability models, in order to provide some measure of the scope of applicability of these techniques. 3.1.2.1 Arlat et al. and Pucci The work of Arlat et al. <ref> [5] </ref> provides a good example of a Markovian model for a recovery block system. <p> Timing properties of the system are typically not modelled, except in the case of the mean number of executions of the system before failure. A similar class of model may be used to predict the behaviour of concurrent N-version programming systems, as is also discussed by Arlat et al. <ref> [5] </ref>. <p> Their model is, however, a significant source of inspiration for the model developed here, in particular for the application of a random fault model to a software based system. 6.4.5 Arlat et al. The model of Arlat et al. <ref> [5] </ref> is a basic Markov chain model, with three final states: completed, detected (benign) failure, and hidden (catastrophic) failure.
Reference: [6] <author> J. Arlat, L. Kanoun, and J.-C. Laprie. </author> <title> Dependability evaluation of software fault-tolerance. </title> <booktitle> In Proceedings 18th International Symposium on Fault- Tolerant Computing. IEEE, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: The reliability models which have been developed in the literature may be split into two broad groups: functional models which describe the system from a time-independent viewpoint, and dynamic models which describe the run-time behaviour of a system. Time-independent, functional, models <ref> [6, 38, 77, 81] </ref> are typically based around a Markov-chain or other stochastic process which is used to describe the behaviour of the system, either neglecting information about execution time or providing a partial ordering of events only.
Reference: [7] <author> N. C. Audsley, A. Burns, M. F. Richardson, and A. J. Wellings. </author> <title> Incorporating unbounded algorithms into predictable real-time systems. </title> <journal> Computer Systems Science & Engineering, </journal> <volume> 8(2) </volume> <pages> 80-89, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: APPLICATION TO SCHEDULING 100 The results presented in chapter 6 of this thesis show the same effects: systems typically have a long-tail to their execution time distribution, and the majority of systems complete in a much shorter time. These effects are further noted by Audsley et al. <ref> [7] </ref>, who note that they cause severe under utilisation of resources in many systems. They note that this under utilisation comes from: 1. Software components not taking worst case execution paths. 2. Hardware behaving better than expected due to gains from caching, pipelining or other facilities. 3.
Reference: [8] <author> A. Avizienis, M. Lyu, and W. Schutz. </author> <title> Multi-version software development: A UCLA/Honeywell joint project for fault-tolerant flight control systems. </title> <type> Technical Report CSD-880034, </type> <institution> Dept. Computer Science, University of California, </institution> <address> Los Angeles, </address> <year> 1988. </year>
Reference-contexts: In addition, it is often difficult to design multiple software systems which have the same specification, but use differing algorithms. As a consequence of this, common-mode failures can be frequent in N-version programming systems <ref> [8, 47, 52] </ref>. 2.2.2 N-Self Checking Programming N-Self Checking Programming, NSCP, is defined by Laprie [49] as follows: "...a self-checking program results from adding redundancy to a program so that it can check its own dynamic behaviour during execution.
Reference: [9] <author> S. Balaji, L. Jenkins, L. M. Patnaik, and P. S. Goel. </author> <title> Workload redistribution for fault-tolerance in a hard real-time distributed computing system. </title> <booktitle> In 19th International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 366-373. </pages> <publisher> IEEE, </publisher> <year> 1989. </year> <note> BIBLIOGRAPHY 154 </note>
Reference-contexts: Much of the research conducted with real-time systems has focused on scheduling problems <ref> [9, 35, 72, 82, 93] </ref>, and typically requires knowledge of the execution time bounds of a process CHAPTER 3. RELIABILITY MODELLING 18 to enable efficient schedules to be calculated. With the introduction of fault-tolerant procedures, the execution time bounds of the system will change.
Reference: [10] <author> M. Balakrishnan and C. S. Raghavendra. </author> <title> An analysis of a reliability model for repairable fault-tolerant systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(3) </volume> <pages> 327-339, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: In this case, the structure of the model allows for approximate solutions to be derived; other Markov models, such as that discussed by Balakrishnan & Ragavendra <ref> [10] </ref> have similar problems of state-space explosion, and various special techniques are employed to derive computationally feasible solutions.
Reference: [11] <author> Bell laboratories. </author> <title> The ESS No. 1A processor. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 56(2), </volume> <month> February </month> <year> 1977. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [12] <author> P. A. Bernstein. </author> <title> Sequoia: A fault-tolerant tightly coupled multiprocessor for Transaction Processing. </title> <journal> IEEE Computer, </journal> <volume> 21(2) </volume> <pages> 37-45, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [13] <author> A. Burns and A. J. Wellings. </author> <title> Real time systems and their programming languages. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: As an example of this, it is useful to discuss the differences between forward and backward error recovery techniques. Forward error recovery schemes must manipulate the current system state in order to perform error recovery [3]. This is typically implemented using exception handling techniques <ref> [13] </ref> and other application specific procedures. A forward error recovery scheme has the advantage of working from the current system state, and so it can be made very efficient in many cases. <p> CHAPTER 2. FAULT-TOLERANT EMBEDDED SYSTEMS 9 2.2.1 N-Version Programming N-Version programming is the software equivalent of N-Modular redundancy in hardware design <ref> [13, 49] </ref>. It requires the generation of N versions of a program block, each created independently of the others. The blocks are executed concurrently, with the same inputs, and a voter process compares results and passes the consensus result to the rest of the system. <p> The processes performing the action can detect no state change except that performed by themselves, and they do not reveal their state changes until the action is complete. There are a number of requirements for an action to be classed as atomic <ref> [13] </ref>: * The action must have well defined boundaries. * An atomic action must not allow the exchange of information between processes active in the action and those outside. * Only strict nesting of atomic actions should be allowed. * It should be possible to execute different atomic actions concurrently. * <p> It can therefore be seen that the recovery block as a whole performs as an atomic transaction, with the advantage of having design diversity as part of its structure. As described in <ref> [13] </ref> there are a number of features of recovery blocks which should be noted, these include * Overheads: In many cases it has been found that checkpointing can be expensive in both time and storage required. <p> The conversation as a whole exhibits failure atomicity. * Only strict nesting of conversations is allowed. The syntax for a single process taking part in a conversation is typically presented as follows <ref> [13] </ref>: action A with (P2, P3) do ensure &lt;acceptance test&gt; by &lt;primary module&gt; else by &lt;alternative module&gt; else by &lt;alternative module&gt; else by ... else error end The other processes involved in the conversation are declared similarly.
Reference: [14] <author> J. Campos and M. Silva. </author> <title> Structural techniques for performance bounds of stochastic Petri net models. </title> <editor> In G. Rozenberg, editor, </editor> <booktitle> Advances in Petri nets 1992, volume 609 of Lecture notes in computer science, </booktitle> <pages> pages 352 - 391. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: It is, however, noted in [57] that the timed Petri net model is effectively a sub-class of the stochastic Petri net model, and therefore, it will not be discussed further here. 3.2.3 Stochastic Petri Nets Stochastic Petri nets <ref> [14, 34, 57, 60] </ref> are an extension to the basic Petri net model where a firing delay is associated with each transition. Firing delays are random variables with negative exponential probability density function.
Reference: [15] <author> J. Carlier, Ph. Chretienne, and C. Girault. </author> <title> Modelling scheduling problems with timed Petri nets. </title> <booktitle> In Advances in Petri nets 1984, volume 188 of Lecture notes in computer science, </booktitle> <pages> pages 62-82. </pages> <publisher> Springer Verlag, </publisher> <year> 1984. </year>
Reference-contexts: CHAPTER 3. RELIABILITY MODELLING 25 A system such as this will allow the temporal properties of a system to be modelled, and indeed the use of such systems is noted a number of times in the literature (see, for example, <ref> [4, 15] </ref>).
Reference: [16] <author> T. L. Casavant and J. G. Kuhl. </author> <title> A taxonomy of scheduling in general purpose distributed computing systems. </title> <journal> IEEE Transactions on software engineering, </journal> <volume> 14(2), </volume> <month> February </month> <year> 1988. </year>
Reference-contexts: This has been a further motivation for the design of the model developed in this thesis: the belief that the coarse-grained timing metrics provided by many system reliability models lead to inefficient scheduling, and much waste of resources. 7.1 Problems in Real-Time Scheduling In the taxonomy of Casavant & Kuhl <ref> [16] </ref>, reproduced in figure 7.1, the range of scheduling possibilities for a distributed computer system is shown. <p> Examples of optimisation measures are minimising total process completion time, maximising utilisation of resources in the system, or maximising system throughput. In the event that these problems are computationally infeasible, suboptimal solutions may be tried." <ref> [16] </ref> In the case of safety critical embedded systems, the choice of optimal versus sub-optimal is less clear cut. In some areas, performance is of vital importance, and hence an optimal solution should be derived if at all possible.
Reference: [17] <author> G. Chiola, M. A. Marsan, G. Balbo, and G. Conte. </author> <title> Generalized stochastic petri nets: A definition at the net level and its implications. </title> <journal> IEEE Transaction on Software Engineering, </journal> <volume> 19(2) </volume> <pages> 89-107, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: It is noted that the limiting case of the discrete time stochastic Petri net, as o ! 0 is a continuous time stochastic Petri net. 3.2.5 Generalised Stochastic Petri Nets The generalised stochastic Petri net, GSPN, <ref> [17, 58] </ref> is a further extension of the basic Petri net model. Like the stochastic Petri nets discussed in section 3.2.3 the GSPN includes transitions with exponentially distributed firing delays. In addition, a GSPN CHAPTER 3. RELIABILITY MODELLING 27 allows immediate transition, which fire immediately when enabled.
Reference: [18] <author> K. L. Chung. </author> <title> Markov Chains with stationary transition probabilities. </title> <publisher> Springer-Verlag, </publisher> <address> second edition, </address> <year> 1967. </year>
Reference-contexts: A brief formal definition of the theory of Markov chains is provided below; for a more thorough description the reader is referred to the works of Chung <ref> [18] </ref> and Takacs [88]; for example. 3.1.1 Formal definition of a Markov chain The definition of a Markov chain builds from probability theory via a set of mutually exclusive and exhaustive events, E 1 ; E 2 ; ; E N .
Reference: [19] <author> G. F. Clement and R. D. Royer. </author> <title> Recovery from faults in the No. 1A processor. </title> <booktitle> In Digest of papers: 4th Annual International Symposium on Fault Tolerant Computing, </booktitle> <pages> pages 5.2-5.7, </pages> <month> January </month> <year> 1974. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [20] <author> F. Cristian. </author> <title> Understanding fault-tolerant distributed systems. </title> <journal> Communications of the ACM, </journal> <volume> 34(2), </volume> <month> February </month> <year> 1991. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [21] <author> A. Csenki. </author> <title> Reliability analysis of recovery blocks with nested clusters of failure points. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> 42(1) </volume> <pages> 34-43, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: The disadvantage with an approach such as this is the large increase in the size of the state-space caused. CHAPTER 3. RELIABILITY MODELLING 22 3.1.2.3 Csenki and Balakrishnan & Ragavendra The work of Csenki <ref> [21] </ref> provides a further example of the problem of state-space explosion inherent in the use of Markov models. Once again, a model for the reliability of a recovery block system is derived. <p> Similarly, the third alternate receives only those inputs for which the primary and secondary have failed, etc. This effect has been studied theoretically by Csenki <ref> [21] </ref>, who derives a model for the expected number of input points processed by a recovery block before failure: the failure probabilities for each alternate are parameters to this model, but the likely values of these parameters are, unfortunately, not discussed. <p> CHAPTER 6. APPLICATION TO SYSTEMS MODELLING 90 6.4.3 Csenki The work of Csenki <ref> [21] </ref> discusses the reliability of recovery block systems where failure points in the input space are assumed to be clustered together.
Reference: [22] <author> R. A. DeMillo, A. J. Offutt, and F. G. Sayward. </author> <title> Hints on test data selection: Help for the practicing programmer. </title> <journal> IEEE Computer, </journal> <volume> 11, </volume> <month> April </month> <year> 1978. </year> <note> BIBLIOGRAPHY 155 </note>
Reference-contexts: It is clear that a uniform probability profile is likely to be somewhat unrepresentative of the use environment of a system, and some technique must be employed to determine a more realistic probability profile. As an example of this, Geist et al.[30], propose the use of mutation analysis <ref> [22] </ref> to derive test cases. This is clearly not the only possible solution: techniques such as simulated annealing, genetic algorithms, monte-carlo simulation, etc. have also been proposed for this role. The selection of test cases is clearly an area worthy of further study.
Reference: [23] <author> B. Dimitrov, Z. Khalil, N. Kolev, and P. Petrov. </author> <title> On the optimal total processing time using checkpoints. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(5) </volume> <pages> 436-442, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The timing properties of a real-time system are as important as its functional properties in ensuring correct operation and, unfortunately, this class of model is not able to describe this with sufficient rigour. In contrast, time-dependent models are much less well developed <ref> [23, 33] </ref>. Although some work has been conducted into finding algorithms to derive the mean execution time of a set of processes in the presence of failure [79], there has been little work undertaken to determine the probability distribution of the system's execution time.
Reference: [24] <author> C. I. Dimmer. </author> <title> The Tandem Non-Stop system. </title> <editor> In T. Anderson, editor, </editor> <booktitle> Resilient Computer Systems, </booktitle> <pages> pages 178-196. </pages> <address> Collins, </address> <year> 1985. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [25] <author> D. E. Eckhardt and L. D. Lee. </author> <title> A theoretical basis for the analysis of multiversion software subject to coincident errors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11(12):1511-1517, </volume> <month> December </month> <year> 1985. </year>
Reference-contexts: In practice this is not a major limitation, since the majority of n-version systems deployed have a relatively small number of versions. In addition, it is unclear that large numbers of alternates increase a system's reliability in the general case. For example, the work of Eckhardt & Lee <ref> [25] </ref> illustrates a number of possible systems where increased numbers of alternates actually leads to reduced system reliability. <p> It has, however, been shown that this assumption is likely to be invalid. For example, the work of Eckhardt & Lee on N-version programming systems <ref> [25] </ref> states that "...recent experiments have demonstrated that programmers given the same task are prone to make mistakes that potentially reduce the effectiveness of a fault-tolerant approach.
Reference: [26] <author> E. N. Elnozahy and W. Zwaenepoel. Manetho: </author> <title> Transparent rollback-recovery with low overhead, limited rollback, and fast output commit. </title> <journal> IEEE Transactions on computers, </journal> <volume> 41(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: In contrast, backward error recovery schemes [3] rely on restoring a prior system state which will, hopefully, be free from error. Backward error recovery is typically implemented as some form of recovery block or atomic transaction scheme (See, for example, <ref> [26, 44] </ref> for a discussion of recovery blocks, and [91] for a discussion of transaction based techniques). The advantage of backward error recovery is that it is a generalised approach, and can recover from any software fault, anticipated or not, provided that the CHAPTER 2. <p> Examples include: aborting the firing of a missile, reversing a chemical reaction in a control plant, etc. There has been some work conducted which uses postponed execution schemes to reduce the effects of non-recoverable objects, and to allow limited rollback recovery in such cases <ref> [26, 80] </ref>; the problem is, however, a fundamental one for systems interacting with external devices, and there are no real solutions. CHAPTER 2. FAULT-TOLERANT EMBEDDED SYSTEMS 9 2.2.1 N-Version Programming N-Version programming is the software equivalent of N-Modular redundancy in hardware design [13, 49].
Reference: [27] <author> J. R. Elphick. </author> <title> Fault Tolerance in Rotorcraft Digital Flight Control Systems. </title> <type> PhD thesis, </type> <institution> Department of Electronics, University of York, </institution> <address> Heslington, York, YO1 5DD, UK., </address> <month> January </month> <year> 1996. </year>
Reference-contexts: The infallible acceptance tests studied in section 6.2 correspond to systems with parameters p ca = p ir = 1:0. Recent work into the effectiveness of acceptance tests in helicopter flight control systems <ref> [27] </ref>, classifies the results of an acceptance test in a similar fashion: false alarms, undetected faults, detected faults and stop faults. The results obtained in that work show that false alarms, corresponding to an acceptance test which rejects correct results, comprise less than 2% of the total detected faults.
Reference: [28] <author> Engineering Council. </author> <title> Guidelines on risk issues. </title> <address> 10 Maltravers Street, London, WC2R 3ER, UK, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: This is an engineering solution to the problem of designing reliable systems: produce a system which is fault free, to the extent that is reasonably CHAPTER 1. INTRODUCTION 2 practicable <ref> [28] </ref>. Once this is complete, an assessment must be made of the tolerability of risk from that system (for example, see [36]); and for this purpose some means of modelling the system's reliability must be employed. <p> Engineers must strive at all times to design a system which is safe to the extent that is reasonably practicable <ref> [28] </ref>. * The need for performance: In many embedded systems severe cost, space, and weight constraints apply. In cases such as these it may not practical to have a system operating with much spare capacity, and some increased risk may have to be accepted to meet other constraints.
Reference: [29] <author> European Space Agency. </author> <title> Software reliability modeling study, </title> <month> February </month> <year> 1988. </year> <note> Invitation to tender AO/1-2039/87/NL/IW. </note>
Reference-contexts: an a priori unrealistic hypothesis, turns out to be satisfactory." It is further noted that a study made of the reliability logs of Tandem systems [32] provides evidence for this claim, as indeed does the work of Musa at Bell Labs [64, 65], and that of the European Space Agency <ref> [29] </ref>, where it is noted that "Software failure is a process that appears to the observer to be random, therefore the term reliability is meaningful when applied to a system which includes software and the process can be modelled as stochastic." It can therefore be seen that the random-fault model as
Reference: [30] <author> R. Geist, A. J. Offutt, and F. C. Harris. </author> <title> Estimation and enhancement of real-time software reliability through mutation analysis. </title> <journal> IEEE Transactions of Computers, </journal> <volume> 41(5) </volume> <pages> 550-558, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: This can clearly not be an exhaustive survey: the range of Petri net models studied in the literature is huge. Rather, a sample of the Petri net techniques applied to reliability modelling is presented. CHAPTER 3. RELIABILITY MODELLING 28 3.2.6.1 Geist et al. The work of Geist et al. <ref> [30] </ref> uses a stochastic Petri net to model the synchronisation structure of N-version software. This model is illustrated in figure 3.1. In this figure, the thin bars represent instantaneous transitions, whilst the fat bars represent timed transitions.
Reference: [31] <author> J. N. Gray. </author> <title> The transaction concept: Virtues and limitations. </title> <booktitle> In Proceedings of the 7th International conference on very large databases. IEEE, </booktitle> <year> 1981. </year>
Reference-contexts: In many cases, these simple techniques are not sufficient, and must be extended to provide the required properties. A number of common extensions to these basic techniques will now be discussed, and their advantages and disadvantages highlighted. CHAPTER 2. FAULT-TOLERANT EMBEDDED SYSTEMS 11 2.3.1 Atomic Transactions An atomic transaction <ref> [31, 63] </ref> is an extension to the atomic action (section 2.2.3) which supports failure atomicity. An atomic transaction will either complete successfully or it will have no effect; it cannot partially complete and leave the system in an inconsistent state.
Reference: [32] <author> J. N. Gray. </author> <title> Why do computers stop and what can be done about it? In Proceedings 5th Symposium on Reliability in Distributed Software and Database Systems, </title> <address> pages 3-12, Los Angeles, </address> <month> January </month> <year> 1986. </year>
Reference-contexts: This conclusion is supported both by theoretical work, such as that of Littlewood [53], CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 34 and by experimental data <ref> [32, 66] </ref>. In addition, Laprie & Kanoun [50] note that: "In the case of software, the randomness comes at least from the trajectory in the input space which will activate the faults. <p> present in operation, after validation, are "soft" faults, in the sense that their activation conditions are extremely difficult to reproduce; hence the difficulty of diagnosing and removing them, which adds to the randomness." As an example of this, a study of the error logs from a number of Tandem systems <ref> [32] </ref> concluded that only one fault out of 132 was not a soft fault. From the above arguments, it seems reasonable to model a system's path through its inputs as a random-walk in a multi-dimensional space. <p> It is considered that such an assumption is not unrealistic, indeed it is the basis for a number of other models [50, 53, 64], and certain experimental data <ref> [32, 65] </ref> have been collected which appear to CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 35 confirm the validity of this approach. <p> The work conducted by Laprie [48] also lends support to this, when it is noted that "...the constancy of the hazard rates, although it is an a priori unrealistic hypothesis, turns out to be satisfactory." It is further noted that a study made of the reliability logs of Tandem systems <ref> [32] </ref> provides evidence for this claim, as indeed does the work of Musa at Bell Labs [64, 65], and that of the European Space Agency [29], where it is noted that "Software failure is a process that appears to the observer to be random, therefore the term reliability is meaningful when
Reference: [33] <author> A. Grnarov, J. Arlat, and A. Avizienis. </author> <title> On the performance of software fault-tolerance strategies. </title> <booktitle> In Proceedings of the 10th International Symposium on Fault-Tolerant Computing. IEEE, </booktitle> <year> 1980. </year>
Reference-contexts: The timing properties of a real-time system are as important as its functional properties in ensuring correct operation and, unfortunately, this class of model is not able to describe this with sufficient rigour. In contrast, time-dependent models are much less well developed <ref> [23, 33] </ref>. Although some work has been conducted into finding algorithms to derive the mean execution time of a set of processes in the presence of failure [79], there has been little work undertaken to determine the probability distribution of the system's execution time. <p> Finally, section 4.4 summarises the chapter. 4.1 Background A number of experimental studies have been conducted into the failure characteristics of software systems [46, 65]. These studies, together with theoretical results such as those presented in <ref> [33, 48, 50, 53, 64] </ref> indicate that it is possible to achieve an accurate prediction of the failure characteristics of a software system using very simple models, and indeed, it has often been proposed that a random-fault model will suffice.
Reference: [34] <author> P. J. Haas and G. S. Shedler. </author> <title> Stochastic Petri net representation of discrete event simulations. </title> <journal> IEEE Transaction on Software Engineering, </journal> <volume> 15(4) </volume> <pages> 381-393, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: It is, however, noted in [57] that the timed Petri net model is effectively a sub-class of the stochastic Petri net model, and therefore, it will not be discussed further here. 3.2.3 Stochastic Petri Nets Stochastic Petri nets <ref> [14, 34, 57, 60] </ref> are an extension to the basic Petri net model where a firing delay is associated with each transition. Firing delays are random variables with negative exponential probability density function.
Reference: [35] <author> D. Haban and K. G. Shin. </author> <title> Application of real-time monitoring to scheduling tasks with random execution times. </title> <journal> IEEE Transactions on software engineering, </journal> <volume> 16(12), </volume> <month> December </month> <year> 1990. </year> <note> BIBLIOGRAPHY 156 </note>
Reference-contexts: Much of the research conducted with real-time systems has focused on scheduling problems <ref> [9, 35, 72, 82, 93] </ref>, and typically requires knowledge of the execution time bounds of a process CHAPTER 3. RELIABILITY MODELLING 18 to enable efficient schedules to be calculated. With the introduction of fault-tolerant procedures, the execution time bounds of the system will change. <p> In certain cases, it is not possible to determine the worst case execution time, or if this worst case can be determined, it may be found to be much larger than the typical execution time. This is discussed by Haban & Shin <ref> [35] </ref> who state that: "Due to data-dependent loops and conditional branches in each program and resource sharing delay during execution, the [worst case execution time] is usually difficult to obtain and could be several orders of magnitude larger than the true execution time." CHAPTER 7.
Reference: [36] <editor> Health and Safety Executive. </editor> <title> The tolerability of risk from nuclear power stations, </title> <year> 1992. </year>
Reference-contexts: INTRODUCTION 2 practicable [28]. Once this is complete, an assessment must be made of the tolerability of risk from that system (for example, see <ref> [36] </ref>); and for this purpose some means of modelling the system's reliability must be employed. Following these considerations, a novel system reliability model is proposed, which provides greater expressive power in terms of derivation of the reliability and timing properties of a system, when compared with previously proposed models.
Reference: [37] <author> A. Hein and K. K. Goswami. </author> <title> Combined performance and dependability evaluation with conjoint simulation. </title> <booktitle> In Proceedings of the 7th European Simulation Symposium, </booktitle> <pages> pages 365-369, </pages> <address> Friedrich-Alexander-Universitat Erlangen-Nurnburg, </address> <month> October </month> <year> 1995. </year> <institution> Society for Computer Simulation. </institution>
Reference-contexts: Timed transitions are used within the model to illustrate various aspects of a system's behaviour, but only high-level metrics are derived from this. 3.2.6.3 Hein & Goswami The work of Hein & Goswami <ref> [37] </ref> provides an interesting example of the application of Petri net modelling combined with an event driven simulation. Named Conjoint Simulation, this technique splits a system model into two portions: a failure-repair model and an architecture workload model.
Reference: [38] <author> B. E. Helvik. </author> <title> Modelling the influence of unreliable software in distributed computer systems. </title> <booktitle> In Digest of papers : 18th International symposium on fault-tolerant computing, </booktitle> <pages> pages 136-141. </pages> <publisher> IEEE, </publisher> <year> 1988. </year>
Reference-contexts: The reliability models which have been developed in the literature may be split into two broad groups: functional models which describe the system from a time-independent viewpoint, and dynamic models which describe the run-time behaviour of a system. Time-independent, functional, models <ref> [6, 38, 77, 81] </ref> are typically based around a Markov-chain or other stochastic process which is used to describe the behaviour of the system, either neglecting information about execution time or providing a partial ordering of events only.
Reference: [39] <author> M. P. Herlihy and J. M. Wing. </author> <title> System-level primitives for Fault-Tolerant distributed computing. </title> <booktitle> In Digest of papers : 16th International symposium on fault-tolerant computing. IEEE, </booktitle> <year> 1986. </year>
Reference-contexts: The atomic transaction may sometimes be employed in these cases, when combined with a postponed execution scheme: failure atomicity is achieved by delaying certain actions until the remainder of the transaction is guaranteed to succeed. This is discussed further in <ref> [39, 67, 80, 91] </ref>. 2.3.2 Recovery Blocks The recovery block [78] is a technique which uses multiple versions of a program block to attempt to ensure success in the presence of system failures. The syntax of the recovery block is typically given as follows: CHAPTER 2.
Reference: [40] <author> P. G. Hoel. </author> <title> Elementary Statistics. </title> <publisher> John Wiley & Sons, Inc., 3rd edition, </publisher> <year> 1971. </year>
Reference-contexts: CHAPTER 5. GENERIC REAL TIME SYSTEM MODEL 56 5.3.3 Binomial Completion Profile A random variable, r, which has a binomial distribution will represent the total number of successes obtained in n repetitions of an experiment with probability, p, of success, this is defined by equation 5.22 <ref> [40, 42] </ref>. P (r) = n For the purposes of this work, n and p will be regarded simply as parameters to be adjusted to produce a curve of the required shape, and their interpretation in terms of probability theory will be neglected.
Reference: [41] <author> A. J. Hopkins and T. B. Smith. </author> <title> The architectural elements of a symmetric fault-tolerant multiprocessor. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C24(5):498-505, </volume> <month> May </month> <year> 1975. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [42] <author> A. Jeffrey. </author> <title> Mathematics for Engineers and Scientists. Van Nostrand Reinhold (International), </title> <booktitle> Fourth edition, 1989. </booktitle> <volume> ISBN 0 278 00083 5. </volume>
Reference-contexts: CHAPTER 5. GENERIC REAL TIME SYSTEM MODEL 56 5.3.3 Binomial Completion Profile A random variable, r, which has a binomial distribution will represent the total number of successes obtained in n repetitions of an experiment with probability, p, of success, this is defined by equation 5.22 <ref> [40, 42] </ref>. P (r) = n For the purposes of this work, n and p will be regarded simply as parameters to be adjusted to produce a curve of the required shape, and their interpretation in terms of probability theory will be neglected.
Reference: [43] <author> Z. Jelinski and P. B. Moranda. </author> <title> Software reliability research. </title> <editor> In W. Freiberger, editor, </editor> <booktitle> Statistical Computer Performance Evaluation, </booktitle> <pages> pages 465-484. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Indeed, many systems are of sufficient complexity that fault prevention can never be completely successful, and it must be assumed that some faults are present in the completed system. This process is highlighted by the many reliability growth models which have been developed <ref> [43, 53-55, 64, 87] </ref>; those wishing to produce systems which contain no faults are clearly fighting against the law of diminishing returns.
Reference: [44] <author> K. H. Kim and H. O. Welch. </author> <title> Distributed execution of recovery blocks: An approach for uniform treatment of hardware and software faults in real-time applications. </title> <journal> IEEE Transactions on computers, </journal> <volume> 38(5), </volume> <month> May </month> <year> 1989. </year>
Reference-contexts: In contrast, backward error recovery schemes [3] rely on restoring a prior system state which will, hopefully, be free from error. Backward error recovery is typically implemented as some form of recovery block or atomic transaction scheme (See, for example, <ref> [26, 44] </ref> for a discussion of recovery blocks, and [91] for a discussion of transaction based techniques). The advantage of backward error recovery is that it is a generalised approach, and can recover from any software fault, anticipated or not, provided that the CHAPTER 2. <p> If the primary fails its acceptance test it informs the first alternate, which passes its result out, provided that it has passed its acceptance test. This process is further described in <ref> [44, 45] </ref>. The distributed recovery block can be seen to provide a faster response to errors than the standard recovery block scheme, although this is bought at the expense of reduced performance in the absence of errors (since it requires multiple alternates to execute in parallel). <p> FAULT-TOLERANT EMBEDDED SYSTEMS 16 conversation has an advantage over the normal conversation because it is able to recover from processor (or other hardware) failure in a transparent manner, provided the acceptance tests include a timeout provision. The distributed conversation is discussed further in <ref> [44, 45, 68] </ref>. 2.4 Summary This chapter has discussed the basics of fault-tolerance for real-time embedded systems.
Reference: [45] <author> K. H. Kim and J. C. Yoon. </author> <title> Approaches to implementation of a repairable distributed recovery block scheme. </title> <booktitle> In Digest of papers : 18th International symposium on fault-tolerant computing. IEEE, </booktitle> <year> 1988. </year>
Reference-contexts: If the primary fails its acceptance test it informs the first alternate, which passes its result out, provided that it has passed its acceptance test. This process is further described in <ref> [44, 45] </ref>. The distributed recovery block can be seen to provide a faster response to errors than the standard recovery block scheme, although this is bought at the expense of reduced performance in the absence of errors (since it requires multiple alternates to execute in parallel). <p> FAULT-TOLERANT EMBEDDED SYSTEMS 16 conversation has an advantage over the normal conversation because it is able to recover from processor (or other hardware) failure in a transparent manner, provided the acceptance tests include a timeout provision. The distributed conversation is discussed further in <ref> [44, 45, 68] </ref>. 2.4 Summary This chapter has discussed the basics of fault-tolerance for real-time embedded systems.
Reference: [46] <author> J. C. Knight and N. G. Leveson. </author> <title> An experimental evaluation of the assumption of independence in multiversion programming. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(1):96-109, </volume> <month> January </month> <year> 1986. </year>
Reference-contexts: This is followed, in sections 4.2 and 4.3, by a formal definition of this model. Finally, section 4.4 summarises the chapter. 4.1 Background A number of experimental studies have been conducted into the failure characteristics of software systems <ref> [46, 65] </ref>. <p> An extension of Eckhardt & Lee's work by Tomek [90] has concluded that "...even independently developed modules are prone to exhibit the same types of errors when operating on the same input." In addition the oft-cited work of Knight and Leveson <ref> [46] </ref> indicates that the alternates in an N-version programming system (section 2.2.1) are likely to fail in a coincident manner. The recovery block has a number of features in common with N-version programming systems, and it is expected that the concerns expressed in the papers cited above are CHAPTER 6. <p> There have been a number of attempts to find acceptable intensity distributions to enable the application of this work. The most noteworthy of these is the work of Nicola & Goyal [69] who use a beta-binomial intensity distribution to fit the software reliability data of Knight & Leveson <ref> [46, 47] </ref>.
Reference: [47] <author> J. C. Knight, N. G. Leveson, and L. D. St.Jean. </author> <title> A large scale experiment in n-version programming. </title> <booktitle> In Digest of papers : 15th Annual International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 135-139, </pages> <year> 1985. </year> <note> BIBLIOGRAPHY 157 </note>
Reference-contexts: In addition, it is often difficult to design multiple software systems which have the same specification, but use differing algorithms. As a consequence of this, common-mode failures can be frequent in N-version programming systems <ref> [8, 47, 52] </ref>. 2.2.2 N-Self Checking Programming N-Self Checking Programming, NSCP, is defined by Laprie [49] as follows: "...a self-checking program results from adding redundancy to a program so that it can check its own dynamic behaviour during execution. <p> There have been a number of attempts to find acceptable intensity distributions to enable the application of this work. The most noteworthy of these is the work of Nicola & Goyal [69] who use a beta-binomial intensity distribution to fit the software reliability data of Knight & Leveson <ref> [46, 47] </ref>.
Reference: [48] <author> J.-C. Laprie. </author> <title> Dependability evaluation of software systems in operation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(4):701-714, </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: Finally, section 4.4 summarises the chapter. 4.1 Background A number of experimental studies have been conducted into the failure characteristics of software systems [46, 65]. These studies, together with theoretical results such as those presented in <ref> [33, 48, 50, 53, 64] </ref> indicate that it is possible to achieve an accurate prediction of the failure characteristics of a software system using very simple models, and indeed, it has often been proposed that a random-fault model will suffice. <p> A NEW SYSTEM RELIABILITY MODEL 35 confirm the validity of this approach. The work conducted by Laprie <ref> [48] </ref> also lends support to this, when it is noted that "...the constancy of the hazard rates, although it is an a priori unrealistic hypothesis, turns out to be satisfactory." It is further noted that a study made of the reliability logs of Tandem systems [32] provides evidence for this claim,
Reference: [49] <author> J.-C. Laprie, J. Arlat, C. Beounes, and K. Kanoun. </author> <title> Definition and analysis of hardware and software fault-tolerant architectures. </title> <booktitle> IEEE computer, </booktitle> <month> July </month> <year> 1990. </year>
Reference-contexts: CHAPTER 2. FAULT-TOLERANT EMBEDDED SYSTEMS 9 2.2.1 N-Version Programming N-Version programming is the software equivalent of N-Modular redundancy in hardware design <ref> [13, 49] </ref>. It requires the generation of N versions of a program block, each created independently of the others. The blocks are executed concurrently, with the same inputs, and a voter process compares results and passes the consensus result to the rest of the system. <p> In addition, it is often difficult to design multiple software systems which have the same specification, but use differing algorithms. As a consequence of this, common-mode failures can be frequent in N-version programming systems [8, 47, 52]. 2.2.2 N-Self Checking Programming N-Self Checking Programming, NSCP, is defined by Laprie <ref> [49] </ref> as follows: "...a self-checking program results from adding redundancy to a program so that it can check its own dynamic behaviour during execution.
Reference: [50] <author> J.-C. Laprie and K. Kanoun. </author> <title> X-Ware reliability and availability modeling. </title> <journal> IEEE Transactions of Software Engineering, </journal> <volume> 18(2) </volume> <pages> 130-147, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: Finally, section 4.4 summarises the chapter. 4.1 Background A number of experimental studies have been conducted into the failure characteristics of software systems [46, 65]. These studies, together with theoretical results such as those presented in <ref> [33, 48, 50, 53, 64] </ref> indicate that it is possible to achieve an accurate prediction of the failure characteristics of a software system using very simple models, and indeed, it has often been proposed that a random-fault model will suffice. <p> This conclusion is supported both by theoretical work, such as that of Littlewood [53], CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 34 and by experimental data [32, 66]. In addition, Laprie & Kanoun <ref> [50] </ref> note that: "In the case of software, the randomness comes at least from the trajectory in the input space which will activate the faults. <p> It is assumed that the system's input space is sufficiently large, and the tasks to be undertaken sufficiently complex, that a random-fault model such as this is applicable. It is considered that such an assumption is not unrealistic, indeed it is the basis for a number of other models <ref> [50, 53, 64] </ref>, and certain experimental data [32, 65] have been collected which appear to CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 35 confirm the validity of this approach. <p> The effects of these interactions between the alternates in a recovery block are further studied by Laprie and Kanoun <ref> [50] </ref> who state that "a distinction has to be made between the interface failures (characterising the failures occurring during interactions with other components) and the internal component failure rates." This work further suggests that the interface failure probabilities are at least as important as the internal component failures rates in determining <p> It does not, however, provide predictions amenable to analysis. 6.4.4 Laprie & Kanoun The work of Laprie & Kanoun <ref> [50] </ref> is based on the assumption that "...classical reliability theory can be extended in order to be interpreted from both hardware and software viewpoints..." and that "...even though the action mechanisms of the various classes of faults may be different from a physical viewpoint according to their causes, a single formulation <p> APPLICATION TO SYSTEMS MODELLING 91 The essential thesis of <ref> [50] </ref> is that, so far as is required for reliability modelling, the cause of a fault is unimportant, provided a statistical estimate of the failure distribution can be obtained.
Reference: [51] <author> J. Ledoux and G. Rubino. </author> <title> A counting model for software reliability analysis. </title> <type> Technical Report 750, </type> <institution> Institut de Recherche en Informatique et Systemes Aleatoires (IRISA), Campus Universitaire de Beaulieu, </institution> <address> 35042 Rennes Cedex, France, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: support for concurrency in Markov chain models is not a limiting factor for this class of model, since the concurrency of the underlying system is not represented directly in the model, but subsumed into the set of high-level failure events. 3.1.2.2 Ledoux & Rubino The work of Ledoux & Rubino <ref> [51] </ref> discusses the limitations of Markov models as applied to the structural modelling of software systems. <p> It is therefore possible to derive a stochastic process representing the transfer of control between the different modules of the system, and this process is typically assumed Markovian. Unfortunately, the memory-less Markovian assumption is found to be unrealistic in many cases; for example <ref> [51] </ref>: "...suppose that module M i receives the execution control sometimes from module M j , sometimes from module M k .
Reference: [52] <author> N. G. Leveson. </author> <title> Software safety: Why, what and how. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(2):125 - 163, </volume> <year> 1986. </year>
Reference-contexts: In addition, it is often difficult to design multiple software systems which have the same specification, but use differing algorithms. As a consequence of this, common-mode failures can be frequent in N-version programming systems <ref> [8, 47, 52] </ref>. 2.2.2 N-Self Checking Programming N-Self Checking Programming, NSCP, is defined by Laprie [49] as follows: "...a self-checking program results from adding redundancy to a program so that it can check its own dynamic behaviour during execution.
Reference: [53] <author> B. Littlewood. </author> <title> Stochastic reliability-growth: A model for fault-removal in computer programs and hardware designs. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> R-30(4):313-320, </volume> <month> October </month> <year> 1981. </year>
Reference-contexts: Finally, section 4.4 summarises the chapter. 4.1 Background A number of experimental studies have been conducted into the failure characteristics of software systems [46, 65]. These studies, together with theoretical results such as those presented in <ref> [33, 48, 50, 53, 64] </ref> indicate that it is possible to achieve an accurate prediction of the failure characteristics of a software system using very simple models, and indeed, it has often been proposed that a random-fault model will suffice. <p> This conclusion is supported both by theoretical work, such as that of Littlewood <ref> [53] </ref>, CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 34 and by experimental data [32, 66]. In addition, Laprie & Kanoun [50] note that: "In the case of software, the randomness comes at least from the trajectory in the input space which will activate the faults. <p> It is assumed that the system's input space is sufficiently large, and the tasks to be undertaken sufficiently complex, that a random-fault model such as this is applicable. It is considered that such an assumption is not unrealistic, indeed it is the basis for a number of other models <ref> [50, 53, 64] </ref>, and certain experimental data [32, 65] have been collected which appear to CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 35 confirm the validity of this approach.
Reference: [54] <author> B. Littlewood. </author> <title> Software reliability prediction. </title> <editor> In T. Anderson, editor, </editor> <booktitle> Resilient Computing Systems, chapter 8, </booktitle> <pages> pages 144-162. </pages> <address> Collins, </address> <year> 1985. </year>
Reference-contexts: Gathering this data can be difficult, especially if the alternates are complex, and there are problems inherent in obtaining a statistically valid sample of the system's state space. This difficulty has been noted a number of times in the literature, for example Littlewood <ref> [54] </ref> states that "Issues of data collection remain problamatical in this area.
Reference: [55] <author> B. Littlewood. </author> <title> Limits to evaluation of software dependability. </title> <editor> In N. Fenton and B. Littlewood, editors, </editor> <title> Software Reliability and Metrics, </title> <booktitle> chapter 6, </booktitle> <pages> pages 81-110. </pages> <publisher> Elsevier Science Publishers Ltd., </publisher> <year> 1991. </year>
Reference-contexts: This is, of course, a difficult and expensive process; and the validation of systems to such high levels of dependability is the subject of some controversy <ref> [55, 56] </ref>. Indeed, many systems are of sufficient complexity that fault prevention can never be completely successful, and it must be assumed that some faults are present in the completed system.
Reference: [56] <author> B. Littlewood and D. Wright. </author> <title> A bayesian model that combines disparate evidence for the quantitative assessment of system dependability. </title> <booktitle> In Digest of papers : 2nd Conference on the Mathematics of Dependable Systems, </booktitle> <institution> University of York, </institution> <month> September </month> <year> 1995. </year> <title> The Institute of Mathematics and it's Applications. </title> <type> Invited paper. </type>
Reference-contexts: This is, of course, a difficult and expensive process; and the validation of systems to such high levels of dependability is the subject of some controversy <ref> [55, 56] </ref>. Indeed, many systems are of sufficient complexity that fault prevention can never be completely successful, and it must be assumed that some faults are present in the completed system.
Reference: [57] <author> M. A. Marsan. </author> <title> Stochastic Petri nets: an elementary introduction. </title> <editor> In G. Rozenberg, editor, </editor> <booktitle> Advances in Petri nets 1989, volume 424 of Lecture Notes in Computer Science, </booktitle> <pages> pages 1-29. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: CHAPTER 3. RELIABILITY MODELLING 25 A system such as this will allow the temporal properties of a system to be modelled, and indeed the use of such systems is noted a number of times in the literature (see, for example, [4, 15]). It is, however, noted in <ref> [57] </ref> that the timed Petri net model is effectively a sub-class of the stochastic Petri net model, and therefore, it will not be discussed further here. 3.2.3 Stochastic Petri Nets Stochastic Petri nets [14, 34, 57, 60] are an extension to the basic Petri net model where a firing delay is <p> It is, however, noted in [57] that the timed Petri net model is effectively a sub-class of the stochastic Petri net model, and therefore, it will not be discussed further here. 3.2.3 Stochastic Petri Nets Stochastic Petri nets <ref> [14, 34, 57, 60] </ref> are an extension to the basic Petri net model where a firing delay is associated with each transition. Firing delays are random variables with negative exponential probability density function. <p> These values may be determined from the average firing delay, o i = 1= i . It is noted in <ref> [57, 60] </ref> that a stochastic Petri net model with this firing delay is equivalent to a continuous time Markov chain model. This opens up a new area of analysis, allowing performance measures to be calculated, based on an analysis of the underlying Markov model. <p> There are two reasons, however, why they are not a general solution to this problem: * There are certain classes of system which can be modelled simply using stochastic Petri nets, but which have an infinite number of states when converted into their corresponding Markovian form <ref> [57] </ref>. Analysis of systems such as these is difficult, using standard Markovian techniques. Further, the underlying Markov chain is typically much larger than the Petri net system: For some systems, analysis may be computationally infeasible. * Markovian analysis requires the "memoryless" property.
Reference: [58] <author> M. A. Marsan, G. Conte, and G. </author> <title> Balbo. A class of generalized stochastic petri nets for the performance evaluation of multiprocessor systems. </title> <journal> ACM Transactions of Computer Systems, </journal> <volume> 2(2) </volume> <pages> 93-122, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: It is noted that the limiting case of the discrete time stochastic Petri net, as o ! 0 is a continuous time stochastic Petri net. 3.2.5 Generalised Stochastic Petri Nets The generalised stochastic Petri net, GSPN, <ref> [17, 58] </ref> is a further extension of the basic Petri net model. Like the stochastic Petri nets discussed in section 3.2.3 the GSPN includes transitions with exponentially distributed firing delays. In addition, a GSPN CHAPTER 3. RELIABILITY MODELLING 27 allows immediate transition, which fire immediately when enabled.
Reference: [59] <author> P. Merlin. </author> <title> A Study of the recoverability of Computing Systems. </title> <type> PhD thesis, </type> <institution> Dept. Information and Computer Science, University of California, Irvine, </institution> <year> 1974. </year>
Reference-contexts: It is noted that coloured Petri nets are isomorphic to standard Petri net models: they are an optimisation only, and do not enable analysis of additional classes of system. For this reason, coloured Petri nets are not studied further here. 3.2.2 Timed Petri Nets Timed Petri nets <ref> [59] </ref> are an extension to the basic Petri net model in which a firing delay, which is assumed to take one of a set of discrete values [61], is associated with each transition. In such a system, transitions can be viewed as firing in three phases: 1.
Reference: [60] <author> M. K. Molloy. </author> <title> Performance analysis using stochastic Petri nets. </title> <journal> IEEE Transactions on computers, </journal> <volume> C-31(9):913-917, </volume> <month> September </month> <year> 1982. </year> <note> BIBLIOGRAPHY 158 </note>
Reference-contexts: It is, however, noted in [57] that the timed Petri net model is effectively a sub-class of the stochastic Petri net model, and therefore, it will not be discussed further here. 3.2.3 Stochastic Petri Nets Stochastic Petri nets <ref> [14, 34, 57, 60] </ref> are an extension to the basic Petri net model where a firing delay is associated with each transition. Firing delays are random variables with negative exponential probability density function. <p> These values may be determined from the average firing delay, o i = 1= i . It is noted in <ref> [57, 60] </ref> that a stochastic Petri net model with this firing delay is equivalent to a continuous time Markov chain model. This opens up a new area of analysis, allowing performance measures to be calculated, based on an analysis of the underlying Markov model.
Reference: [61] <author> M. K. Molloy. </author> <title> Discrete time stochastic petri nets. </title> <journal> IEEE Transactions on software engineering, </journal> <volume> SE-11(4):417-423, </volume> <month> April </month> <year> 1985. </year>
Reference-contexts: A Petri net model, Q, may be defined formally as a set of places, P, a set of transitions, T, input and output arcs, A, and an initial marking, M 0 <ref> [61] </ref>: Q = (P; T; A; M 0 ) (3.6) where P = fp 1 ; p 2 ; ; p n g (3.7) CHAPTER 3. <p> For this reason, coloured Petri nets are not studied further here. 3.2.2 Timed Petri Nets Timed Petri nets [59] are an extension to the basic Petri net model in which a firing delay, which is assumed to take one of a set of discrete values <ref> [61] </ref>, is associated with each transition. In such a system, transitions can be viewed as firing in three phases: 1. A start firing phase when tokens are removed from the input places. 2. <p> That is, if a transition fires to change the marking of the net, the distribution of the time remaining on the other enabled transitions is not affected <ref> [61] </ref>. For some systems this restriction is not acceptable. CHAPTER 3. <p> CHAPTER 3. RELIABILITY MODELLING 26 These restrictions are removed by the discrete time stochastic Petri nets, section 3.2.4, and by the so called generalised stochastic Petri net, as discussed in section 3.2.5. 3.2.4 Discrete Time Stochastic Petri Nets The discrete time stochastic Petri net <ref> [61] </ref>, bridges the gap between timed Petri nets and stochastic Petri nets. Unlike a continuous time stochastic Petri net, the discrete time stochastic Petri net only allows transitions to fire at certain times, hence opening the possibility of several transitions firing at once. As Molloy [61] notes: "Since multiple firings may <p> discrete time stochastic Petri net <ref> [61] </ref>, bridges the gap between timed Petri nets and stochastic Petri nets. Unlike a continuous time stochastic Petri net, the discrete time stochastic Petri net only allows transitions to fire at certain times, hence opening the possibility of several transitions firing at once. As Molloy [61] notes: "Since multiple firings may occur at any time step, the probabilities for each possible combination need to be determined. Requiring a designer to actually assign those probabilities is too difficult. The definition of discrete time stochastic Petri nets [...] takes a different approach.
Reference: [62] <author> P. Morrison and E. Morrison. </author> <title> Charles Babbage and his Calculating Engines. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1961. </year>
Reference-contexts: calculating engines could be checked: "The most certain and effectual check upon errors which arise in the process of calculation, is to cause the same computation to be made by separate and independent computers; and this check is rendered still more decisive if they make their computations by different methods." <ref> [62] </ref> The same technique is employed today, with the redundancy being implemented using some combination of hardware and software techniques. It is possible to create a system which only uses hardware fault-tolerant techniques, and of course a system which only employs software fault-tolerance is also feasible.
Reference: [63] <author> J. E. B. Moss. </author> <title> Nested Transactions | An approach to reliable distributed computing. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: In many cases, these simple techniques are not sufficient, and must be extended to provide the required properties. A number of common extensions to these basic techniques will now be discussed, and their advantages and disadvantages highlighted. CHAPTER 2. FAULT-TOLERANT EMBEDDED SYSTEMS 11 2.3.1 Atomic Transactions An atomic transaction <ref> [31, 63] </ref> is an extension to the atomic action (section 2.2.3) which supports failure atomicity. An atomic transaction will either complete successfully or it will have no effect; it cannot partially complete and leave the system in an inconsistent state.
Reference: [64] <author> J. D. Musa. </author> <title> Validity of execution-time theory of software reliability. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> R-28(3):181-191, </volume> <month> August </month> <year> 1979. </year>
Reference-contexts: Indeed, many systems are of sufficient complexity that fault prevention can never be completely successful, and it must be assumed that some faults are present in the completed system. This process is highlighted by the many reliability growth models which have been developed <ref> [43, 53-55, 64, 87] </ref>; those wishing to produce systems which contain no faults are clearly fighting against the law of diminishing returns. <p> Finally, section 4.4 summarises the chapter. 4.1 Background A number of experimental studies have been conducted into the failure characteristics of software systems [46, 65]. These studies, together with theoretical results such as those presented in <ref> [33, 48, 50, 53, 64] </ref> indicate that it is possible to achieve an accurate prediction of the failure characteristics of a software system using very simple models, and indeed, it has often been proposed that a random-fault model will suffice. <p> It is assumed that the system's input space is sufficiently large, and the tasks to be undertaken sufficiently complex, that a random-fault model such as this is applicable. It is considered that such an assumption is not unrealistic, indeed it is the basis for a number of other models <ref> [50, 53, 64] </ref>, and certain experimental data [32, 65] have been collected which appear to CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 35 confirm the validity of this approach. <p> "...the constancy of the hazard rates, although it is an a priori unrealistic hypothesis, turns out to be satisfactory." It is further noted that a study made of the reliability logs of Tandem systems [32] provides evidence for this claim, as indeed does the work of Musa at Bell Labs <ref> [64, 65] </ref>, and that of the European Space Agency [29], where it is noted that "Software failure is a process that appears to the observer to be random, therefore the term reliability is meaningful when applied to a system which includes software and the process can be modelled as stochastic." It
Reference: [65] <author> J. D. Musa. </author> <title> Software reliability data. </title> <type> Technical report, </type> <institution> Bell Telephone Laboratories, </institution> <month> January </month> <year> 1980. </year> <note> Report obtainable from DACS, </note> <institution> Rome Air Development Centre, Rome, </institution> <address> New York. </address>
Reference-contexts: This is followed, in sections 4.2 and 4.3, by a formal definition of this model. Finally, section 4.4 summarises the chapter. 4.1 Background A number of experimental studies have been conducted into the failure characteristics of software systems <ref> [46, 65] </ref>. <p> It is considered that such an assumption is not unrealistic, indeed it is the basis for a number of other models [50, 53, 64], and certain experimental data <ref> [32, 65] </ref> have been collected which appear to CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 35 confirm the validity of this approach. <p> "...the constancy of the hazard rates, although it is an a priori unrealistic hypothesis, turns out to be satisfactory." It is further noted that a study made of the reliability logs of Tandem systems [32] provides evidence for this claim, as indeed does the work of Musa at Bell Labs <ref> [64, 65] </ref>, and that of the European Space Agency [29], where it is noted that "Software failure is a process that appears to the observer to be random, therefore the term reliability is meaningful when applied to a system which includes software and the process can be modelled as stochastic." It
Reference: [66] <author> P. M. Nagel and J. A. Skrivan. </author> <title> Software reliability: Repetitive run experimentation and modeling. </title> <type> Technical Report CR-165836, </type> <institution> NASA, </institution> <address> Washington, DC, </address> <month> February </month> <year> 1982. </year>
Reference-contexts: This conclusion is supported both by theoretical work, such as that of Littlewood [53], CHAPTER 4. A NEW SYSTEM RELIABILITY MODEL 34 and by experimental data <ref> [32, 66] </ref>. In addition, Laprie & Kanoun [50] note that: "In the case of software, the randomness comes at least from the trajectory in the input space which will activate the faults.
Reference: [67] <author> E. Nett, R. Kroger, and J. Kaiser. </author> <title> Implementing a general error recovery mechanism in a distributed operating system. </title> <booktitle> In Digest of papers : 16th International symposium on fault-tolerant computing. IEEE, </booktitle> <year> 1986. </year>
Reference-contexts: The atomic transaction may sometimes be employed in these cases, when combined with a postponed execution scheme: failure atomicity is achieved by delaying certain actions until the remainder of the transaction is guaranteed to succeed. This is discussed further in <ref> [39, 67, 80, 91] </ref>. 2.3.2 Recovery Blocks The recovery block [78] is a technique which uses multiple versions of a program block to attempt to ensure success in the presence of system failures. The syntax of the recovery block is typically given as follows: CHAPTER 2.
Reference: [68] <author> E. Nett and R. Schumann. </author> <title> Supporting fault-tolerant distributed computations under real-time requirements. </title> <journal> Computer communications, </journal> <volume> 15(4), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: FAULT-TOLERANT EMBEDDED SYSTEMS 16 conversation has an advantage over the normal conversation because it is able to recover from processor (or other hardware) failure in a transparent manner, provided the acceptance tests include a timeout provision. The distributed conversation is discussed further in <ref> [44, 45, 68] </ref>. 2.4 Summary This chapter has discussed the basics of fault-tolerance for real-time embedded systems.
Reference: [69] <author> V. F. Nicola and A. Goyal. </author> <title> Modeling of correlated failures and community error recovery in multiversion software. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(3) </volume> <pages> 350-359, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: There have been a number of attempts to find acceptable intensity distributions to enable the application of this work. The most noteworthy of these is the work of Nicola & Goyal <ref> [69] </ref> who use a beta-binomial intensity distribution to fit the software reliability data of Knight & Leveson [46, 47]. <p> It is noted that these parameters may be directly estimated from experimental data, indeed if the mean, , and variance, oe 2 , of the number of alternates failing on a random input are known, then these parameters may be derived as in equations 6.4 and 6.5 <ref> [69] </ref>: = N (6.4) In a recovery block system, failure of the recovery block only occurs when all of the alternates fail for a single input. In the model of Nicola & Goyal, this corresponds to the case when i = N.
Reference: [70] <author> S. Omohundro and D. Stoutamire. </author> <title> The Sather 1.0 Specification. </title> <booktitle> International Computer Science Institute, </booktitle> <address> 1947 Center Street, Suite 600, Berkeley, California 94704, USA, </address> <month> December </month> <year> 1994. </year> <note> Available at http://www.icsi.berkeley.edu/~sather/. </note>
Reference-contexts: APPENDIX A. SIMULATION SOFTWARE 109 Appendix A Simulation Software The system reliability model presented in this thesis requires automated analysis. In this appendix the tools developed to enable this analysis are described. These tools have been written from scratch, in a mixture of the Sather <ref> [70] </ref> and Tcl [71] programming languages. Since these programming languages may be unfamiliar to some readers, a brief overview of their facilities is now provided. Sather is an object-oriented language which supports efficient computation, with powerful abstractions for encapsulation and code reuse, and constructs for improving code correctness.
Reference: [71] <author> J. K. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: APPENDIX A. SIMULATION SOFTWARE 109 Appendix A Simulation Software The system reliability model presented in this thesis requires automated analysis. In this appendix the tools developed to enable this analysis are described. These tools have been written from scratch, in a mixture of the Sather [70] and Tcl <ref> [71] </ref> programming languages. Since these programming languages may be unfamiliar to some readers, a brief overview of their facilities is now provided. Sather is an object-oriented language which supports efficient computation, with powerful abstractions for encapsulation and code reuse, and constructs for improving code correctness.
Reference: [72] <author> C. Y. Park. </author> <title> Predicting program execution times by analysing static and dynamic program paths. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 5 </volume> <pages> 31-62, </pages> <year> 1993. </year>
Reference-contexts: Much of the research conducted with real-time systems has focused on scheduling problems <ref> [9, 35, 72, 82, 93] </ref>, and typically requires knowledge of the execution time bounds of a process CHAPTER 3. RELIABILITY MODELLING 18 to enable efficient schedules to be calculated. With the introduction of fault-tolerant procedures, the execution time bounds of the system will change.
Reference: [73] <author> C. S. Perkins and A. M. Tyrrell. </author> <title> A new markov model for dependability and temporal evaluation of hard real-time systems. </title> <booktitle> In Proceedings of the 7th European Simulation Symposium, </booktitle> <pages> pages 388-392, </pages> <address> Friedrich-Alexander-Universitat Erlangen-Nurnburg, </address> <month> October </month> <year> 1995. </year> <title> Society for Computer Simulation. BIBLIOGRAPHY 159 </title>
Reference-contexts: INTRODUCTION 3 reliability characteristics are evaluated using the model derived in chapter 5 <ref> [73] </ref>.
Reference: [74] <author> C. S. Perkins and A. M. Tyrrell. </author> <title> Reliability models for hard real-time systems. </title> <booktitle> In Proceedings of the 2nd IMA Conference on the Mathematics of Dependable Systems, </booktitle> <institution> University of York, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: This model is based on the notion of random fault occurrence and provides a stochastic view of the execution of a system, allowing the state of the system to be derived for a particular point in its operation <ref> [74] </ref>. * Chapter 5 Generic Real Time System Model : The model developed in chapter 4, is used to derive a generic model for the behaviour of real time systems.
Reference: [75] <author> J. L. Peterson. </author> <title> Petri nets. </title> <journal> Computing Surveys, </journal> <volume> 9(3) </volume> <pages> 223-251, </pages> <month> September </month> <year> 1977. </year>
Reference-contexts: clear, from models such as these, that basic Markov techniques are limited by the problems of state space explosion, and that unless care is taken in the definition of the model, solution may become computationally infeasible for all apart from small systems. 3.2 Petri Net Models A Petri net model <ref> [75, 76] </ref> consists of a set of places, together with a set of transitions. These are interconnected by a series of directed arcs, which enable tokens to move from place-to-place by means of the transitions. Movement of the tokens is defined by the firing rules of the network. <p> The transition fires by removing the enabling tokens from their input places and generating new tokens which are deposited in the output places of the transition." <ref> [75] </ref> The placement of tokens in the network defines a marking which represents the state of the system modelled. <p> This reflects a philosophy of time which states that the only important property of time, from a logical point of view, is in defining a partial ordering of events." <ref> [75] </ref> That is, a Petri net system will allow the logical properties of a system to be described, but it cannot provide a model of the temporal properties of a system, except that it can define a partial ordering of events. 2.
Reference: [76] <author> J. L. Peterson. </author> <title> Petri net theory and the modeling of systems. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year> <note> ISBN 0-13-661983-5. </note>
Reference-contexts: clear, from models such as these, that basic Markov techniques are limited by the problems of state space explosion, and that unless care is taken in the definition of the model, solution may become computationally infeasible for all apart from small systems. 3.2 Petri Net Models A Petri net model <ref> [75, 76] </ref> consists of a set of places, together with a set of transitions. These are interconnected by a series of directed arcs, which enable tokens to move from place-to-place by means of the transitions. Movement of the tokens is defined by the firing rules of the network.
Reference: [77] <author> G. Pucci. </author> <title> A new approach to the modeling of recovery block structures. </title> <journal> IEEE Transactions on software engineering, </journal> <volume> 18(2) </volume> <pages> 159-167, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: The reliability models which have been developed in the literature may be split into two broad groups: functional models which describe the system from a time-independent viewpoint, and dynamic models which describe the run-time behaviour of a system. Time-independent, functional, models <ref> [6, 38, 77, 81] </ref> are typically based around a Markov-chain or other stochastic process which is used to describe the behaviour of the system, either neglecting information about execution time or providing a partial ordering of events only. <p> The number of states in the Markov chain is small, and the model derived is high-level, considering only the possible failure modes, and not their timing properties. The work of Arlat et al. is discussed further in section 6.4.5. The model of Pucci <ref> [77] </ref> is similar in scope, although the precise failure events chosen and the structure of the derived Markov chain differ. It is discussed further in section 6.4.2. CHAPTER 3. RELIABILITY MODELLING 21 Together, these models illustrate an important class of Markovian system reliability model. <p> The model illustrated in figure 5.1 is, of course, overly simplistic and must be extended in order to account for the presence of faults within the system. For example, Pucci <ref> [77] </ref> notes that "An important distinction is between errors whose manifestation is identified in the system (detected errors) and errors whose manifestations is not (undetected errors)." In particular, the effects of hidden faults are noted: "Undetected errors are the most insidious ones because of their effect on the future behaviour of <p> The second class of fault leads to a more complex model, requiring a parallel state chain to represent a system which is still functioning, but with a hidden fault <ref> [77] </ref>. These states mimic the function of the original state chain, and lead to the hidden fault and failed states (figure 5.3). <p> There are four possible outcomes of the execution of an acceptance test, each of which have an associated occurrence probability <ref> [77] </ref>: 1. A correct result is accepted, probability p ca . 2. A correct result is rejected, probability 1 - p ca . 3. An incorrect is result rejected, probability p ir . 4. An incorrect is result accepted, probability 1 - p ir . <p> The CHAPTER 6. APPLICATION TO SYSTEMS MODELLING 88 advantage gained by the Nicola & Goyal model as a result of this, is that the parameters of the model are easier to estimate than those required by the model developed in this thesis. 6.4.2 Pucci The model of Pucci <ref> [77] </ref> has a number of similarities to the recovery block model developed in this thesis, but also a significant set of differences. The essential similarities are the nature of the fault model employed, and the classification of faults. The differences are due to the timing properties of the models.
Reference: [78] <author> B. Randell. </author> <title> System structure for software fault tolerance. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1:220-231, </volume> <month> June </month> <year> 1975. </year>
Reference-contexts: This is discussed further in [39, 67, 80, 91]. 2.3.2 Recovery Blocks The recovery block <ref> [78] </ref> is a technique which uses multiple versions of a program block to attempt to ensure success in the presence of system failures. The syntax of the recovery block is typically given as follows: CHAPTER 2.
Reference: [79] <author> A. Ranganathan and S. Upadhyaya. </author> <title> Performance evaluation of rollback-recovery techniques in computer programs. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> 42(2) </volume> <pages> 220-226, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: In contrast, time-dependent models are much less well developed [23, 33]. Although some work has been conducted into finding algorithms to derive the mean execution time of a set of processes in the presence of failure <ref> [79] </ref>, there has been little work undertaken to determine the probability distribution of the system's execution time. Much of the research conducted with real-time systems has focused on scheduling problems [9, 35, 72, 82, 93], and typically requires knowledge of the execution time bounds of a process CHAPTER 3.
Reference: [80] <author> A. B. Romanovsky and I. V. Sturtz. </author> <title> Unplanned recovery for non-program object. </title> <booktitle> In Digest of papers : 12th International Distributed Computing Symposium, </booktitle> <address> Tampe, U.S.A., </address> <year> 1992. </year>
Reference-contexts: Examples include: aborting the firing of a missile, reversing a chemical reaction in a control plant, etc. There has been some work conducted which uses postponed execution schemes to reduce the effects of non-recoverable objects, and to allow limited rollback recovery in such cases <ref> [26, 80] </ref>; the problem is, however, a fundamental one for systems interacting with external devices, and there are no real solutions. CHAPTER 2. FAULT-TOLERANT EMBEDDED SYSTEMS 9 2.2.1 N-Version Programming N-Version programming is the software equivalent of N-Modular redundancy in hardware design [13, 49]. <p> The atomic transaction may sometimes be employed in these cases, when combined with a postponed execution scheme: failure atomicity is achieved by delaying certain actions until the remainder of the transaction is guaranteed to succeed. This is discussed further in <ref> [39, 67, 80, 91] </ref>. 2.3.2 Recovery Blocks The recovery block [78] is a technique which uses multiple versions of a program block to attempt to ensure success in the presence of system failures. The syntax of the recovery block is typically given as follows: CHAPTER 2.
Reference: [81] <author> R. K. Scott, J. W. Gault, and D. F. McAllister. </author> <title> Fault-tolerant software reliability modeling. </title> <journal> IEEE Transactions of Software Engineering, </journal> <volume> SE-13(5):582-592, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: The reliability models which have been developed in the literature may be split into two broad groups: functional models which describe the system from a time-independent viewpoint, and dynamic models which describe the run-time behaviour of a system. Time-independent, functional, models <ref> [6, 38, 77, 81] </ref> are typically based around a Markov-chain or other stochastic process which is used to describe the behaviour of the system, either neglecting information about execution time or providing a partial ordering of events only.
Reference: [82] <author> T. Shepard and J. A. M. Gagne. </author> <title> A pre-run-time scheduling algorithm for hard real-time systems. </title> <journal> IEEE Transactions on Software engineering, </journal> <volume> 17(7), </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: Much of the research conducted with real-time systems has focused on scheduling problems <ref> [9, 35, 72, 82, 93] </ref>, and typically requires knowledge of the execution time bounds of a process CHAPTER 3. RELIABILITY MODELLING 18 to enable efficient schedules to be calculated. With the introduction of fault-tolerant procedures, the execution time bounds of the system will change.
Reference: [83] <author> Y.-B. Shieh, D. Ghosal, P. R. Chintamaneni, and S. K. Tripathi. </author> <title> Modeling of hierarchical distributed systems with fault-tolerance. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(4) </volume> <pages> 444-457, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: CHAPTER 3. RELIABILITY MODELLING 29 3.2.6.2 Shieh et al. The work of Shieh et al. <ref> [83] </ref> models the process of rollback recovery and checkpointing using a stochastic Petri net. In this model, two basic primitives are derived: the fault transition unit, FTU, which manages the rollback of a process, and communicates this information to other communicating processes, causing them to stop executing.
Reference: [84] <author> D. P. Siewiorek. </author> <title> Fault tolerance in commercial computers. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 26-37, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [85] <author> A. Z. Spector, J. J. Bloch, D. S. Daniels, R. P. Draves, D. Dunchamp, J. L. Eppinger, S. G. Menees, and D. S. Thompson. </author> <title> The Camelot project. </title> <journal> Database Engineering, </journal> <volume> 9(3):149 - 160, </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: Many such systems have been implemented, for example, <ref> [85] </ref>, most involving database management or network file systems. The final class of object for which transactions could be required is the non-program object of a physical nature; that is, an external hardware device.
Reference: [86] <author> J. A. Stankovic and K. Ramamritham. </author> <title> What is predictability for real-time systems? Real-Time Systems, </title> <booktitle> 2(4) </booktitle> <pages> 247-254, </pages> <year> 1990. </year>
Reference-contexts: When coupled with the increasing drive towards greater use of software-based systems for embedded control, and the increasing functionality expected from those systems, it seems clear that the problem of scheduling such systems will not become easier. This problem has been summarised by Stankovic & Ramamritham <ref> [86] </ref>, who note that: "The next generation of real-time systems will be large, complex, distributed, adaptive, contain many types of timing constraints, need to operate in a CHAPTER 7.
Reference: [87] <author> J. Tain, P. Lu, and J. </author> <title> Palma. Test-execution-based reliability measurement and modeling for large commercial software. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(5) </volume> <pages> 405-414, </pages> <month> May </month> <year> 1995. </year> <note> BIBLIOGRAPHY 160 </note>
Reference-contexts: Indeed, many systems are of sufficient complexity that fault prevention can never be completely successful, and it must be assumed that some faults are present in the completed system. This process is highlighted by the many reliability growth models which have been developed <ref> [43, 53-55, 64, 87] </ref>; those wishing to produce systems which contain no faults are clearly fighting against the law of diminishing returns.
Reference: [88] <author> L. Takacs. </author> <title> Stochastic processes. </title> <publisher> Methuen, </publisher> <year> 1962. </year>
Reference-contexts: A brief formal definition of the theory of Markov chains is provided below; for a more thorough description the reader is referred to the works of Chung [18] and Takacs <ref> [88] </ref>; for example. 3.1.1 Formal definition of a Markov chain The definition of a Markov chain builds from probability theory via a set of mutually exclusive and exhaustive events, E 1 ; E 2 ; ; E N . These events are known as the states of the Markov chain.
Reference: [89] <editor> D. Taylor and G. Wilson. Stratus. In T. Anderson, editor, </editor> <title> Dependability of Resilient Computers, </title> <booktitle> chapter 10, </booktitle> <pages> pages 222 - 236. </pages> <address> BSP, </address> <year> 1989. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [90] <author> L. A. Tomek, J. K. Muppala, and K. S. Trivedi. </author> <title> Modeling correlation in software recovery blocks. </title> <journal> IEEE Transactions on Software Engineering, </journal> 19(11) 1071-1086, November 1993. 
Reference-contexts: Further, in many cases there exists an asymptotic limit to system reliability which is approached as the number of alternates is increased; this is illustrated in the work of Tomek et al. <ref> [90] </ref>. In order to illustrate this technique, the sample recovery block system used in section 6.2.1 has, once again, been used as a testbed. Since this comprises three alternates, there are a total of six possible orderings in which these alternates can be executed, as is illustrated in table 6.2. <p> An extension of Eckhardt & Lee's work by Tomek <ref> [90] </ref> has concluded that "...even independently developed modules are prone to exhibit the same types of errors when operating on the same input." In addition the oft-cited work of Knight and Leveson [46] indicates that the alternates in an N-version programming system (section 2.2.1) are likely to fail in a coincident
Reference: [91] <author> A. Tripathi and J. Silverman. </author> <title> System-level primitives for fault-tolerant distributed computing. </title> <booktitle> In Digest of papers : 16th International symposium on fault-tolerant computing. IEEE, </booktitle> <year> 1986. </year>
Reference-contexts: In contrast, backward error recovery schemes [3] rely on restoring a prior system state which will, hopefully, be free from error. Backward error recovery is typically implemented as some form of recovery block or atomic transaction scheme (See, for example, [26, 44] for a discussion of recovery blocks, and <ref> [91] </ref> for a discussion of transaction based techniques). The advantage of backward error recovery is that it is a generalised approach, and can recover from any software fault, anticipated or not, provided that the CHAPTER 2. FAULT-TOLERANT EMBEDDED SYSTEMS 8 software does not access unrecoverable external objects 1 . <p> The atomic transaction may sometimes be employed in these cases, when combined with a postponed execution scheme: failure atomicity is achieved by delaying certain actions until the remainder of the transaction is guaranteed to succeed. This is discussed further in <ref> [39, 67, 80, 91] </ref>. 2.3.2 Recovery Blocks The recovery block [78] is a technique which uses multiple versions of a program block to attempt to ensure success in the presence of system failures. The syntax of the recovery block is typically given as follows: CHAPTER 2. <p> For a further discussion of this the reader is referred to section 4.1 of <ref> [91] </ref>. A further problem is inherent in the multi-process nature of the conversation technique: the domino effect. This problem arises when multiple processes, which may be subject to rollback recovery, exchange information.
Reference: [92] <author> D. Wilson. </author> <title> The STRATUS computer system. </title> <editor> In T. Anderson, editor, </editor> <booktitle> Resilient Computer Systems, </booktitle> <pages> pages 208-231. </pages> <address> Collins, </address> <year> 1985. </year>
Reference-contexts: The potential for divergence in the results increases with the size of the replicated block, especially if the replicated blocks have differing designs in order to avoid common-mode failure. Despite these problems this technique, or variations on it, is widely used in many commercial systems <ref> [11, 12, 19, 20, 24, 41, 84, 89, 92] </ref>. This then is the basis of static hardware fault tolerance. Systems are replicated a number of times with voters used to detect failure and reconfigure the system so as to maintain correct operation.
Reference: [93] <author> J. Xu and D. L. Parnas. </author> <title> On satisfying timing constraints in hard-real-time systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(1) </volume> <pages> 70-84, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Much of the research conducted with real-time systems has focused on scheduling problems <ref> [9, 35, 72, 82, 93] </ref>, and typically requires knowledge of the execution time bounds of a process CHAPTER 3. RELIABILITY MODELLING 18 to enable efficient schedules to be calculated. With the introduction of fault-tolerant procedures, the execution time bounds of the system will change. <p> In the field of scheduling for safety critical, embedded systems, the usual choice is static scheduling. The potential for failure with dynamic scheduling schemes is usually considered too great. The work of Xu & Parnas <ref> [93] </ref> considers this in more detail, and strongly recommends the use of pre-run-time scheduling, possibly the strongest form of static scheduling.
References-found: 93

