URL: http://or.eng.tau.ac.il:7777/ai.ps.Z
Refering-URL: http://or.eng.tau.ac.il:7777/topics/ecobweb.html
Root-URL: 
Title: Constructive Induction by Incremental Concept Formation  
Author: Yoram Reich In Y. A. Feldman A. Bruckstein 
Note: (eds.), Artificial Intelligence and Computer Vision, 1991, pp. 191-204, Elsevier Science Publishers,  
Address: Pittsburgh, PA 15213, USA.  Amsterdam.  
Affiliation: Department of Civil Engineering and The Engineering Design Research Center, Carnegie Mel-lon University,  
Abstract: This paper describes a framework that generates constructive induction schemes for the concept formation system COBWEB. The basis of this framework|context-dependent bias of multi-valued properties|provides a way for allowing COBWEB to deal with continuous and hierarchical property types as a special case of constructive induction. The constructive induction scheme does not introduce learning bias and does not require major modification to the original concept-formation mechanisms. Bridger, a system that partially implements the constructive induction, as well as others extensions, is one of the first incremental concept formation programs with a general constructive induction ability. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J. </author> <year> (1984). </year> <title> Classification and Regression Trees, </title> <address> Belmont, Waldsworth, CA. </address>
Reference-contexts: This is in contrast to classification domains where only one property class is being predicted. We tested the system in a performance test using 10 runs of the 10-fold cross-validation experiment <ref> (Breiman et al, 1984) </ref>. The results were as follows. With all the properties as nominal values (continuous and ordinal values were discretized by an expert in the domain) the predictive accuracy summarized over the 5 properties was 64.6%.
Reference: <author> Fisher, D. H. </author> <year> (1987). </year> <title> "Knowledge acquisition via incremental conceptual clustering." </title> <journal> Machine Learning, </journal> <volume> 2(7) </volume> <pages> 139-172. </pages>
Reference-contexts: The importance of concept formation has resulted in the development of many concept formation programs that automatically generate clusterings or classifications of observations. A concept formation program that has been shown to be powerful in several diagnostic and classification domains is COBWEB <ref> (Fisher, 1987) </ref>. One of its descendants, Bridger, has been used in design domains for synthesizing artifacts from given specifications (Reich, 1990; Reich and Fenves, 1992b; Reich and Fenves, 1992a). COBWEB was designed to use observations described by a language restricted to lists of nominal property-value pairs. <p> Equation 8 can be used to substitute the corresponding terms in Equation 1 (or 7), thus allowing CU to handle continuous properties. 1 See <ref> (Fisher, 1987) </ref> for a detailed description of COBWEB's learning operators. AI & Comp. Vision, 1991, pp. 191-104 7 Reich (1991) The approach presented is very flexible, no assumption needs to be fixed when information implicit in examples suggests otherwise 2 . <p> BRIDGER Bridger is a domain-independent learning system for knowledge acquisition and performance improvement that is currently under development (Reich, 1991a; Reich, 1991b). Bridger is built on the foundations of the concept formation program COBWEB <ref> (Fisher, 1987) </ref>, but extends it along several dimensions. Bridger can handle entities described by a combination of nominal and continuous property types.
Reference: <author> Gennari, J. H., Langley, P., and Fisher, D. </author> <year> (1989). </year> <title> "Models of incremental concept formation." </title> <journal> Artificial Intelligence, 40(1-3):11-61. AI & Comp. Vision, </journal> <year> 1991, </year> <pages> pp. </pages> <note> 191-104 12 Reich (1991) Gluck, </note> <author> M. and Corter, J. </author> <year> (1985). </year> <title> "Information, uncertainty, and the utility of categories." </title> <booktitle> In Proceedings of the Seventh Annual Conference of the Cognitive Science Society, </booktitle> <address> Irvine, CA, </address> <pages> pages 283-287, </pages> <address> San Mateo, CA, </address> <publisher> Academic Press. </publisher>
Reference-contexts: One of its descendants, Bridger, has been used in design domains for synthesizing artifacts from given specifications (Reich, 1990; Reich and Fenves, 1992b; Reich and Fenves, 1992a). COBWEB was designed to use observations described by a language restricted to lists of nominal property-value pairs. Another recent descendant, CLASSIT <ref> (Gennari et al, 1989) </ref>, also uses a restricted language consisting of lists of continuous property-values assumed to be drawn Reich (1991) from a normal distribution. Such restricted languages are not appropriate for representing many real world domains such as design or medical diagnosis. <p> Bridger is built on the foundations of the concept formation program COBWEB (Fisher, 1987), but extends it along several dimensions. Bridger can handle entities described by a combination of nominal and continuous property types. It has a correcting-hierarchy module; it has a richer 2 In contrast, CLASSIT <ref> (Gennari et al, 1989) </ref>, a descendant of COBWEB, can use only continuous property-values that are drown from a normal distribution. AI & Comp.
Reference: <author> Langley, P., Simon, H. A., Bradshaw, G. L., and Zytkow, J. M. </author> <year> (1987). </year> <title> Scientific Discovery: Computational Explorations of the Creative Processes, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Examples AI & Comp. Vision, 1991, pp. 191-104 2 Reich (1991) include the creation of ranges of ordered values in CLUSTER, the creation of new terms in discovery systems such as BACON <ref> (Langley et al, 1987) </ref>, or the creation and use of intermediate concepts such as in RINCON (Wogulis and Langley, 1989). In general, these schemes were not supported by any analysis and were restricted to few types of term creation.
Reference: <author> Lebowitz, M. </author> <year> (1988). </year> <title> "Deferred commitment in unimem: waiting to learn." </title> <booktitle> In Proceedings of The International Conference on Machine Learning, </booktitle> <address> Ann Arbor, MI, </address> <pages> pages 80-86, </pages> <address> San Mateo, CA, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Another method that constrains the use of CI is the generation of features based on evidence accumulated from several examples. This strategy, for the concept learning program UNIMEM, has been termed deferred learning <ref> (Lebowitz, 1988) </ref>. Local versus global constructive induction. The current local scheme results in the creation of different features for different levels of the concept hierarchy. The traditional global view of CI is that new features are shared between all example descriptions.
Reference: <author> Michalski, R. S. and Stepp, R. </author> <year> (1983). </year> <title> "Learning from observation: Conceptual clustering." </title> <editor> In Michalski, R. S., Carbonell, J. G., and Mitchell, T. M., editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 331-363, </pages> <address> Palo Alto, CA, </address> <publisher> Tioga Press. </publisher>
Reference-contexts: The creation of a bias-free enriching mechanism requires a good understanding of the original behavior of the system. The manual enriching approach is usually pursued with the addition of property types and their ad-hoc generalization mechanisms. For example, the conceptual clustering program CLUSTER <ref> (Michalski and Stepp, 1983) </ref> uses several property types, each with its own generalizing operator, without analyzing whether an inherent bias is introduced by this combination. Usually, no such analysis is performed. One exception is Quinlan's (1985) analysis for the concept learning program ID3. <p> Another example is the use of explicit knowledge about the structure (i.e., partial ordering) of a property to allow Bridger to accommodate this property type into its mechanisms. In this case, the hierarchy-climbing operator of structured properties (e.g., see <ref> (Michalski, 1983) </ref>) can be implemented by allowing features to be generated only if their values correspond to the leaf nodes of a single intermediate node in the property hierarchy.
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> "A theory and methodology of inductive learning." </title> <journal> Artificial Intelligence, </journal> <volume> 20(2) </volume> <pages> 111-161. </pages>
Reference-contexts: The creation of a bias-free enriching mechanism requires a good understanding of the original behavior of the system. The manual enriching approach is usually pursued with the addition of property types and their ad-hoc generalization mechanisms. For example, the conceptual clustering program CLUSTER <ref> (Michalski and Stepp, 1983) </ref> uses several property types, each with its own generalizing operator, without analyzing whether an inherent bias is introduced by this combination. Usually, no such analysis is performed. One exception is Quinlan's (1985) analysis for the concept learning program ID3. <p> Another example is the use of explicit knowledge about the structure (i.e., partial ordering) of a property to allow Bridger to accommodate this property type into its mechanisms. In this case, the hierarchy-climbing operator of structured properties (e.g., see <ref> (Michalski, 1983) </ref>) can be implemented by allowing features to be generated only if their values correspond to the leaf nodes of a single intermediate node in the property hierarchy.
Reference: <author> Pagallo, G. and Haussler, D. </author> <year> (1990). </year> <title> "Boolean feature discovery in empirical learning." </title> <journal> Machine Learning, </journal> <volume> 5(1) </volume> <pages> 71-99. </pages>
Reference-contexts: This mechanism will treat values from different properties similarly. The size of the set that would serve as ground values is the summation of the number of values of all the properties. A simple instance of this will allow the performance of boolean feature discovery <ref> (Pagallo and Haussler, 1990) </ref>. With additional knowledge this scheme can be used to naturally learn from hierarchical description of objects. 10. SUMMARY We have described a general framework for designing constructive induction mechanisms for an incremental concept formation system.
Reference: <author> Quinlan, J. R. </author> <year> (1985). </year> <title> "Decision trees and multi-valued attributes." </title> <type> Technical Report 85.4, </type> <institution> New South Wales Institute of Technology, New South Wales. </institution>
Reference-contexts: We have shown that CU favors properties with more values depending on the contribution of these values to the classification. This constitutes a context dependent bias which is slightly different than the bias observed for ID3 <ref> (Quinlan, 1985) </ref>. The reason we are not concerned with this bias is that in our scheme decision nodes are polythetic, and a decision about which learning operator to apply is made on a relative basis.
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> "The effect of noise on concept learning." </title> <editor> In Michalski, R. S., Car-bonell, J. G., and Mitchell, T. M., editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. II, </volume> <pages> pages 149-166, </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference-contexts: Potentially, this value can be learned for each domain, but usually it is fixed to 0.75. 4 Available from the repository of learning databases at the University of California, Irvine. 5 This behavior is similar to the overfitting of noisy data by concept learning programs <ref> (Quinlan, 1986) </ref>. AI & Comp. Vision, 1991, pp. 191-104 10 Reich (1991) properties. Mushrooms domain. This domain is relatively easy to learn. The original Bridger achieves better than 99% predictive accuracy over various samples of the database. Essentially, there is no reason to use CI for this task.
Reference: <author> Reich, Y. and Fenves, S. J. </author> <year> (1992). </year> <title> "Inductive learning of bridge design knowledge." </title> <editor> In Arciszewski, T. and Rossman, L. A., editors, </editor> <booktitle> Knowledge Acquisition in Civil Engineering, </booktitle> <pages> pages 169-189, </pages> <publisher> American Society of Civil Engineers, </publisher> <address> New York, NY. </address>
Reference: <author> Reich, Y. and Fenves, S. J. </author> <year> (1992). </year> <title> "Inductive learning of synthesis knowledge." </title> <journal> International Journal of Expert Systems: Research and Applications, </journal> <volume> 5(4) </volume> <pages> 275-297. </pages>
Reference: <author> Reich, Y. </author> <year> (1989). </year> <title> "Combining nominal and continuous properties in an incremental learning system for design." </title> <type> Technical Report EDRC-12-33-89, </type> <institution> Engineering Design Research Center, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Reich, Y. </author> <year> (1990). </year> <title> "Converging to "Ideal" design knowledge by learning." </title> <editor> In Fitzhorn, P. A., editor, </editor> <booktitle> Proceedings of The First International Workshop on Formal Methods in Engineering Design, </booktitle> <pages> pages 330-349, </pages> <address> Colorado Springs, Colorado. </address>
Reference-contexts: Prediction progresses by assigning the partial description characteristic property-value pairs describing the nodes traversed 3 . This strategy, which differs from the original method employed by COBWEB, can be viewed as a least-commitment method <ref> (Reich, 1990) </ref>. 8. EXPERIMENTAL STUDIES The constructive induction scheme was tested in two domains: The domain of Pittsburgh bridges (Reich and Fenves, 1992b) and the mushrooms domain 4 . Pittsburgh bridge domain. This domain is a difficult design domain with 108 examples. Each example is described by twelve property-value pairs.
Reference: <author> Reich, Y. </author> <year> (1991). </year> <title> "Building and improving design systems: A machine learning approach." </title> <type> PhD thesis, </type> <institution> Department of Civil Engineering, Carnegie Mellon University, Pittsburgh, PA. </institution> <note> (Available as Technical Report EDRC 02-16-91). </note>
Reference: <author> Reich, Y. </author> <year> (1991). </year> <title> "Design knowledge acquisition: Task analysis and a partial implementation." </title> <journal> Knowledge Acquisition, </journal> <volume> 3(3) </volume> <pages> 237-254. </pages>
Reference: <author> Reich, Y. </author> <year> (1991). </year> <title> "Incremental clustering with mixed property types." </title> <type> Technical Report EDRC-12-??-91, </type> <institution> Engineering Design Research Center, Carnegie Mellon University, Pitts AI & Comp. Vision, </institution> <year> 1991, </year> <pages> pp. </pages> <address> 191-104 13 Reich (1991) burgh, PA. </address>
Reference: <author> Rendell, L. </author> <year> (1988). </year> <title> "Learning hard concepts through constructive induction: Framework and rationale." </title> <type> Technical Report UIUUCDCS-R-88-1426, </type> <institution> Department of Computer Science, University of Illinois as Urbana-Champaign, Urbana, Ill. </institution>
Reference-contexts: In contrast, decision nodes in ID3 are monothetic, thus it is important to divide the training set based on the best unbiased property. 4. CONSTRUCTIVE INDUCTION Constructive induction (CI) can be defined as the creation of useful features not existing in the original property-value description of examples <ref> (Rendell, 1988) </ref>. The original properties are called ground properties. The term useful means that the use of the new features should result in an improved leaning performance. This is a possible operationalization of the definition of the term naturally that was introduced before.
Reference: <author> Wogulis, J. and Langley, P. </author> <year> (1989). </year> <title> "Improving efficiency by learning intermediate concepts." </title> <booktitle> In Proceedings of The Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 657-662, </pages> <address> Detroit, MI, </address> <publisher> Morgan Kaufmann. </publisher> <address> AI & Comp. Vision, </address> <year> 1991, </year> <pages> pp. 191-104 14 </pages>
Reference-contexts: Examples AI & Comp. Vision, 1991, pp. 191-104 2 Reich (1991) include the creation of ranges of ordered values in CLUSTER, the creation of new terms in discovery systems such as BACON (Langley et al, 1987), or the creation and use of intermediate concepts such as in RINCON <ref> (Wogulis and Langley, 1989) </ref>. In general, these schemes were not supported by any analysis and were restricted to few types of term creation. In addition, only few of these schemes were related to incremental systems. This paper consolidates the two enriching activities into one framework.
References-found: 19

