URL: http://www.cs.cmu.edu/afs/cs/usr/pstone/public/papers/98hardware-challenge/hardware-challenge.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/usr/pstone/mosaic/pstone-papers.html
Root-URL: 
Title: The RoboCup Physical Agent Challenge: Phase I  
Author: Minoru Asada Peter Stone Hiroaki Kitano Barry Werger Yasuo Kuniyoshi Alexis Drogoul Dominique Duhaut Manuela Veloso Hajime Asama Sho'ji Suzuki 
Date: September 23, 1997  
Address: Japan CMU, USA Sony CSL, Japan Brandeis Univ., USA  Japan LAFORIA/CNRS, France LRP, France CMU, USA  Japan  
Affiliation: Osaka Univ.,  ETL,  Riken, Japan Osaka Univ.,  
Abstract: Traditional AI research has not given due attention to the important role that physical bodies play for agents as their interactions produce complex emergent behaviors to achieve goals in the dynamic real world. The RoboCup Physical Agent Challenge provides a good testbed for studying how physical bodies play a significant role in realizing intelligent behaviors using the RoboCup framework [ Kitano, et al., 95 ] . In order for the robots to play a soccer game reasonably well, a wide range of technologies needs to be integrated and a number of technical breakthroughs must be made. In this paper, we present three challenging tasks as the RoboCup Physical Agent Challenge Phase I: (1) moving the ball to the specified area (shooting, passing, and dribbling) with no, stationary, or moving obstacles, (2) catching the ball from an opponent or a teammate (receiving, goal-keeping, and intercepting), and (3) passing the ball between two players. The first two are concerned with single agent skills while the third one is related to a simple cooperative behavior. Motivation for these challenges and evaluation methodology are given.
Abstract-found: 1
Intro-found: 1
Reference: [ Asada et al., 1996a ] <author> M. Asada, S. Noda, and K. Hosoda. </author> <title> Action-based sensor space categorization for robot learning. </title> <booktitle> In Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems 1996 (IROS '96), </booktitle> <pages> pages 1502-1509, </pages> <year> 1996. </year>
Reference-contexts: structural (qualitative) knowledge (self calibration), (3) Subtask learning fit together in a layered fashion [ Stone and Veloso, 1997 ] (4) typical reinforcement learning such as Q-learning with almost no a priori knowledge, but given the state and action spaces, (5) action selection from the state and action space construction <ref> [ Asada et al., 1996a, Takahashi et al., 1996 ] </ref> , and (6) tabula rasa learning. These approaches should be evaluated in various kinds of viewpoints. 4.3.
Reference: [ Asada et al., 1996b ] <author> M. Asada, S. Noda, S. Tawaratumida, and K. Hosoda. </author> <title> Purposive behavior acquisition for a real robot by vision-based reinforcement learning. </title> <journal> Machine Learning, </journal> <volume> 23 </volume> <pages> 279-303, </pages> <year> 1996. </year>
Reference-contexts: In order to focus on skill acquisition, visual image processing should be drastically simplified. Discrimination by color information such as a red ball, a blue goal, a yellow opponent makes it easy to find and track objects in real-time <ref> [ Asada et al., 1996b ] </ref> . Nevertheless, robust color discrimination is a tough problem because digitized signals are so naive against the slight changes of lighting conditions. In the case of remote (wireless) processing, increased noise due to environmental factors causes fatal errors in image processing.
Reference: [ Asada, 1996 ] <author> Minoru Asada. </author> <title> An agent and an environment: A view on "having bodies" a case study on behavior learning for vision-based mobile robot -. In Proceedings of 1996 IROS Workshop on Towards Real Autonomy, </title> <address> pages 19-24, </address> <year> 1996. </year>
Reference-contexts: Once the robot succeeds in acquiring these skills, it can move anything to anywhere. In another aspect, these three challenges can be regarded as a sequence of one task which leads to an increase of the complexity of the internal representation according to the complexity of the environment <ref> [ Asada, 1996 ] </ref> . In the case of visual sensing, the agent can discriminate the static environment (and its own body if observed) from others by directly correlating the motor commands the agent sent and the visual information observed during the motor command executions.
Reference: [ Asama et al., 1996 ] <author> H. Asama, M. Sato, N. Goto, H. Kaetsu, A. Matsumoto, and I. Endo. </author> <title> Mutual transportation of cooperative mobile robots using forklift mechanisms. </title> <booktitle> In Proc. of IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1754-1759, </pages> <year> 1996. </year> <month> 9 </month>
Reference-contexts: To avoid these situations, the robot can quickly switch behaviors, which causes instability of the robot motion. One might use the omni-directionally movable vehicle based on a sophisticated mechanism <ref> [ Asama et al., 1996 ] </ref> . For example, the vehicle could move to any direction anytime. In addition to the motion control problem, there are more issues to be considered such as how to coordinate these two behaviors (switching conditions) [ Uchibe et al., 1996 ] . 4.2.4.
Reference: [ Brooks, 1991 ] <author> R. A. Brooks. </author> <title> Elephants don't play chess. </title> <editor> In P. Maes, editor, </editor> <booktitle> Designing Autonomous Agents, </booktitle> <pages> pages 3-15. </pages> <address> MIT/Elsevier, </address> <year> 1991. </year>
Reference-contexts: Traditional AI research has been mainly pursuing the methodology of symbol manipulations to be used in knowledge acquisition and representation and reasoning about it with little attention to intelligent behavior in dynamic real worlds <ref> [ Brooks, 1991 ] </ref> . On the other hand, in robotics much more emphasis has been put on the issues of designing and building hardware systems and their controls.
Reference: [ Inoue, et al., 92 ] <author> H. Inoue and T. Tachikawa and M. Inaba. </author> <title> Robot vision system with a correlation chip for real-time tracking, optical flow and depth map generation. </title> <booktitle> In Proc. of IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1621-1626, </pages> <year> 1992. </year>
Reference-contexts: Self calibration methods should be developed, which will be able to expand the general scope of image processing applications. Visual tracking hardware based on image intensity correlation inside a window region can be used to find and track objects from the complicated background by setting the initial windows <ref> [ Inoue, et al., 92 ] </ref> . Currently, a color tracking version is commercially available. As long as the initialized color pattern inside each window does not change much, tracking is almost successful.
Reference: [ Ishiguro, 96 ] <author> H. Ishiguro. </author> <note> http://www.lab7.kuis.kyoto-u.ac.jp/ vision/omni-sensor/omni-sensor.htl. </note>
Reference-contexts: This sort of lens seems very useful not only for acquiring the basic skills but also for realizing cooperative behaviors in multi agent environments. Currently this type of lens is commercially available as spherical and hyperboloidal ones <ref> [ Ishiguro, 96 ] </ref> . 4.2.2. Other perception In the case of other sensing strategies, the agent should find the ball, (in Level II and III, obstacles, too) and know what the target is.
Reference: [ Kitano, et al., 95 ] <author> Kitano, H., Asada, M., Kuniyoshi, Y., Noda, I. and Osawa, E., </author> <title> "RoboCup: The Robot World Cup Initiative", </title> <booktitle> IJCAI-95 Workshop on Entertainment and AI/Alife, </booktitle> <year> 1995 </year>
Reference-contexts: In other words, we need a standard problem which people regard as a new one that expose various various aspects of intelligent behaviors in real worlds. RoboCup (The World Cup Robot Soccer Games: <ref> [ Kitano, et al., 95, Kitano, et al., 97 ] </ref> ) is an attempt to promote AI and robotics research by providing a common task for evaluation of various theories, algorithms, and agent architectures, and was proposed as a new standard problem.
Reference: [ Kitano, et al., 97 ] <author> Kitano, H., Asada, M., Kuniyoshi, Y., Noda, I., Osawa, E., and Matsubara, H., </author> <title> "RoboCup: A Challenge AI Problem", </title> <journal> AI Magazine, </journal> <month> Spring, </month> <year> 1997. </year>
Reference-contexts: In other words, we need a standard problem which people regard as a new one that expose various various aspects of intelligent behaviors in real worlds. RoboCup (The World Cup Robot Soccer Games: <ref> [ Kitano, et al., 95, Kitano, et al., 97 ] </ref> ) is an attempt to promote AI and robotics research by providing a common task for evaluation of various theories, algorithms, and agent architectures, and was proposed as a new standard problem.
Reference: [ Kuniyoshi, 95 ] <author> Y. Kuniyoshi. </author> <title> Behavior Matching by Observation for Multi-Robot Cooperation. </title> <editor> In G. Giralt and G. Hirzinger (eds.) </editor> <booktitle> Robotics Research The Seventh International Symposium, </booktitle> <pages> pages 343-352, </pages> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: A primitive example of vision based interception of a static obstacle from another robot's trajectory has been demonstrated <ref> [ Kuniyoshi, 95 ] </ref> . However, a general interception in fully dynamic situations like soccer playing is an open problem. * Selection of passing direction depends on the motions of opponents. This introduces the opponent modeling issue which makes the cooperative behavior much harder to realize. 6.3.
Reference: [ Nakamura and Asada, 1995 ] <author> T. Nakamura and M. Asada. </author> <title> Motion sketch: Acquisition of visual motion guided behaviors. </title> <booktitle> In Proc. of International Joint Conference on Aritificial Intelligence, </booktitle> <pages> pages 126-132, </pages> <year> 1995. </year>
Reference-contexts: As long as the vision system can cope with the above issues, and capture the images of both the specified area (the target) and the ball, there might be no problem <ref> [ Nakamura and Asada, 1995, Nakamura and Asada, 1996 ] </ref> .
Reference: [ Nakamura and Asada, 1996 ] <author> T. Nakamura and M. Asada. </author> <title> Stereo sketch: Stereo vision-based target reaching behavior acquisition with occlusion detection and avoidance. </title> <booktitle> In Proc. of IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1314-1319, </pages> <year> 1996. </year>
Reference-contexts: As long as the vision system can cope with the above issues, and capture the images of both the specified area (the target) and the ball, there might be no problem <ref> [ Nakamura and Asada, 1995, Nakamura and Asada, 1996 ] </ref> .
Reference: [ Nakamura et al., 1996 ] <author> T. Nakamura, J. Morimoto, and M. Asada. </author> <title> Direct coupling of multisensor information and actions for mobile robot behavior acquisition. </title> <booktitle> In Proc. of 1996 IEEE/SICE/RSJ International Conference on Multisensor Fusion and Integration, </booktitle> <pages> pages 139-144, </pages> <year> 1996. </year>
Reference-contexts: One good strategy is assign the sensor roles in advance. For example, sonar and bumper sensors are used for obstacle avoidance while vision sensor is used for the target reaching. One can make the robot learn to assign the sensor roles <ref> [ Nakamura et al., 1996 ] </ref> . 5 4.2.3. Action As described in section 2, total balance of the whole system is a key issue to the robot design.
Reference: [ Stone and Veloso, 1997 ] <author> P. Stone, M. Veloso. </author> <title> Towards Collaborative and adversarial learning: A case study in robotic soccer . In International Journal of Human-Computer Systems (IJHCS), </title> <year> 1997. </year>
Reference-contexts: Between exist several variations with more or less knowledge. The approaches are summarized as follows: (1) complete hand-coding (no learning), (2) parameter tuning given the structural (qualitative) knowledge (self calibration), (3) Subtask learning fit together in a layered fashion <ref> [ Stone and Veloso, 1997 ] </ref> (4) typical reinforcement learning such as Q-learning with almost no a priori knowledge, but given the state and action spaces, (5) action selection from the state and action space construction [ Asada et al., 1996a, Takahashi et al., 1996 ] , and (6) tabula rasa <p> To receive the passed ball while moving, the relationship between the moving ball and the self motion should be made clear <ref> [ Stone and Veloso, 1997 ] </ref> . * Situation B: In addition to the above issue, goal protection is important. To estimate the goal position, the agent may have to watch the goal area lines and the penalty area line.
Reference: [ Stone and Veloso, 1997 ] <author> P. Stone, M. Veloso. </author> <title> A Layered Approach to Learning Client Behaviors in the RoboCup Soccer Server In Applied Artificial Intelligence (AAI) Journal), </title> <year> 1997. </year>
Reference-contexts: Between exist several variations with more or less knowledge. The approaches are summarized as follows: (1) complete hand-coding (no learning), (2) parameter tuning given the structural (qualitative) knowledge (self calibration), (3) Subtask learning fit together in a layered fashion <ref> [ Stone and Veloso, 1997 ] </ref> (4) typical reinforcement learning such as Q-learning with almost no a priori knowledge, but given the state and action spaces, (5) action selection from the state and action space construction [ Asada et al., 1996a, Takahashi et al., 1996 ] , and (6) tabula rasa <p> To receive the passed ball while moving, the relationship between the moving ball and the self motion should be made clear <ref> [ Stone and Veloso, 1997 ] </ref> . * Situation B: In addition to the above issue, goal protection is important. To estimate the goal position, the agent may have to watch the goal area lines and the penalty area line.
Reference: [ Takahashi et al., 1996 ] <author> Yasutake Takahashi, Minoru Asada, and Koh Hosoda. </author> <title> Reasonable performance in less learning time by real robot based on incremental state space segmentation. </title> <booktitle> In Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems 1996 (IROS '96), </booktitle> <pages> pages 1518-1524, </pages> <year> 1996. </year>
Reference-contexts: structural (qualitative) knowledge (self calibration), (3) Subtask learning fit together in a layered fashion [ Stone and Veloso, 1997 ] (4) typical reinforcement learning such as Q-learning with almost no a priori knowledge, but given the state and action spaces, (5) action selection from the state and action space construction <ref> [ Asada et al., 1996a, Takahashi et al., 1996 ] </ref> , and (6) tabula rasa learning. These approaches should be evaluated in various kinds of viewpoints. 4.3.
Reference: [ Uchibe et al., 1996 ] <author> Eiji Uchibe, Minoru Asada, and Koh Hosoda. </author> <title> Behavior coordination for a mobile robot using modular reinforcement learning. </title> <booktitle> In Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems 1996 (IROS '96), </booktitle> <pages> pages 1329-1336, </pages> <year> 1996. </year>
Reference-contexts: For example, the vehicle could move to any direction anytime. In addition to the motion control problem, there are more issues to be considered such as how to coordinate these two behaviors (switching conditions) <ref> [ Uchibe et al., 1996 ] </ref> . 4.2.4. Mapping from perception to action There are several approaches to implementing the control mechanisms which perform the given task.
Reference: [ Fujita and Kageyama, 1997 ] <author> Masahiro Fujita and Koji Kageyama. </author> <title> An Open Architecture for Robot Entertainment In Proc. </title> <booktitle> of First International Conference on Autonomous Agents, </booktitle> <pages> pages 435-442, </pages> <year> 1997. </year> <month> 10 </month>
Reference-contexts: As a middle ground, we would like to have a platform that allows us to easily reconfigure the physical structure by which we expect physical agents to develop complex behaviors. Recently, an open architecture called OPENR has been proposed as such a platform <ref> [ Fujita and Kageyama, 1997 ] </ref> . OPENR has 1) standard interfaces between physical and software components and a programming framework, 2) configurable physical components with a common interface and information exchangers of their function and configurations, and 3) is constructed as a layered architecture based on object-oriented robot OS.
References-found: 18

