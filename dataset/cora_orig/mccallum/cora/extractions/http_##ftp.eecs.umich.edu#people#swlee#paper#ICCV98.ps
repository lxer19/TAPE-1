URL: http://ftp.eecs.umich.edu/people/swlee/paper/ICCV98.ps
Refering-URL: http://ftp.eecs.umich.edu/people/swlee/paper/
Root-URL: http://www.eecs.umich.edu
Email: (dberwick@umich.edu and swlee@umich.edu)  
Title: A Chromaticity Space for Specularity, Illumination Color- and Illumination Pose-Invariant 3-D Object Recognition  
Author: Daniel Berwick and Sang Wook Lee 
Address: Ann Arbor, MI 48104  
Affiliation: Dept. of Electrical Enginnering and Computer Science University of Michigan  
Abstract: Most of the recent color recognition/indexing approaches concentrate on establishing invariance to illumination color to improve the utility of color recognition. However, other effects caused by illumination pose and specularity on three-dimensional object surfaces have not received notable attention. We present a chromaticity recognition method that discounts the effects of illumination pose, illumination color and specularity. It utilizes a chromaticity space based on log-ratio of sensor responses for illumination pose and color invariance. A model-based specularity detection/rejection algorithm can be used to improve the chromaticity recognition and illumination estimation for objects including specular reflections. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.R. Bach, C. Fuller, A. Gupta, A. Hampapur, R. Horowitz, R. Humphrey, R.C. Jain, and C. Shu. </author> <title> Virage image search engine: An open framework for image management. </title> <booktitle> In Proc. SPIE Storage and Retrieval of Still Image and Video Databases IV, </booktitle> <pages> pages 76-87, </pages> <address> San Jose, CA, </address> <year> 1996. </year> <month> 13 </month>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue [32] [26] [29] [14] [16] [30]. For image retrieval from an image database, color is one of the most effective cues [8] <ref> [1] </ref>. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32].
Reference: [2] <editor> R. Bajcsy, S.W. Lee, and A. Leonardis. </editor> <title> Detection of diffuse and specular interface reflections and inter-reflections by color image segmentation. </title> <journal> IJCV, </journal> <volume> 17, </volume> <year> 1996. </year>
Reference-contexts: Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] [15] [21] [3] [28] <ref> [2] </ref> [35] [27] [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. In summary, we propose a color-based object recognition algorithm invariant to: (1) illumination pose, (2) illumination color, and (3) specularity. <p> Finlayson, Drew, and Funt suggested methods for sharpening sensor functions and reported that the sensor sharpening improves the performance of color constancy algorithms based on diagonal transforms [12]. Under the diagonal transform condition, we suggest a chromaticity space = <ref> [ 1 ; 2 ] </ref> T that is invariant to illumination color up to translation: 1 = ln q G q B ; (9) In this space, the chromaticity distributions from an object under different illumination colors should appear identical up to translation, i.e., e = + j; where j = <p> In the chromaticity plane, specular reflections will appear as a cluster of points stretching from its underlying diffuse reflection chromaticity toward the chromaticity of the incident light ( Figure 2 (a)) <ref> [2] </ref>. To avoid deviations from an object's chromaticity signature of only diffuse reflections, specularities need to be detected and removed from the test image. The goal of specularity detection is to find image regions where s p s is nonzero. "Specularity rejection" excludes the detected regions from the chromaticity signature. <p> These constraints include restricted material types and piecewise uniform object colors. Extra physical cues include structured light, polarization sensors, and multiple-view image sensing [18] <ref> [2] </ref> [21] [28] [35] [27] [22]. These additional requirements sensing may be difficult to achieve, especially for test images. An additional source of information for specularity detection in lieu of extra sensing needs to be found.
Reference: [3] <author> G. Brelstaff and A. Blake. </author> <title> Detecting specular reflections using lambertain constraints. </title> <booktitle> In Proc. of IEEE Int. Conf. on Computer Vision, </booktitle> <pages> pages 297-302, </pages> <address> Tarpon Springs, FL, </address> <year> 1988. </year>
Reference-contexts: We also address the problem of specularity in object color appearances. Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] [15] [21] <ref> [3] </ref> [28] [2] [35] [27] [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. In summary, we propose a color-based object recognition algorithm invariant to: (1) illumination pose, (2) illumination color, and (3) specularity. <p> This chromaticity histogram comparison is motivated by histogram differencing techniques [21] [22]. Our approach to specularity rejection begins with conservative intensity-based processing of a test image, such as intensity thresholding, to eliminate sharp and intense specularity without any prior information <ref> [3] </ref>. From the resulting signature, a hypothesis for initial object identification and illumination estimation is generated. This signature is iteratively refined by chromaticity differencing. illumination estimation after thresholding, the chromaticity plane associated with the object and estimated illumination is used for coarse differencing with the test chromaticity diagram.
Reference: [4] <author> Q.S. Chen, M. Defrise, and F. Deconinck. </author> <title> Symmetric phase-only matched filtering of fourier-mellin transforms for image registration and recognition. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 16 </volume> <pages> 1156-1168, </pages> <year> 1994. </year>
Reference-contexts: An alternative fast and accurate method is to use the Fourier magnitude spectrum for similarity measure and the Fourier phase for estimating j <ref> [4] </ref>. Let f be a chromaticity distribution function in the new coordinate system .
Reference: [5] <author> R.T. Chin and C.R. Dyer. </author> <title> Model-based recognition in robot vision. </title> <journal> ACM Computing Surveys, </journal> <volume> 18, </volume> <year> 1986. </year>
Reference-contexts: Traditional object recognition and viewing condition estimation uses geometric cues such as 3-D object shape models and geometric relationships between object features, and recent appearance-based approaches describe an object by using relatively compact eigenspaces derived only from image appearances under various viewing conditions <ref> [5] </ref> [17] [33] [25]. Although color reflectance has been conceived as an obvious object descriptor and color matching has been a central focus of color science and engineering, only recently have a number of researchers begun to explore the use of color distributions as signatures for object recognition.
Reference: [6] <author> J. Cohen. </author> <title> Dependency of the spectral reflectance curves of the munsell color chips. </title> <journal> Psychon. Sci., </journal> <volume> 1 </volume> <pages> 369-370, </pages> <year> 1964. </year>
Reference-contexts: This is a consequence of surface normal variations on a 3-D object. The relationship between sensor responses under different illumination colors can be modelled as a linear transform [16] [30]. For three-dimensional approximation of surface 3 reflection <ref> [6] </ref> [24], s p () = i=0 i S i (): (2) where S i 's are basis functions and oe i 's are weighting coefficients (i = 0; 1; 2), the sensor responses q p = [q R ; q G ; q B ] T and reflectance coefficients oe
Reference: [7] <author> M. D'Zmura and P. Lennie. </author> <title> Mechanisms of color constancy. </title> <journal> JOSA, </journal> <volume> 3 </volume> <pages> 1662-1672, </pages> <year> 1986. </year>
Reference-contexts: Color constancy based on the diagonal matrix transformation and its impact are analyzed in detail by Finlayson, Drew and Funt, Worthey and Brill, West and Brill, and D'Zmura and Lennie [11] [12] [34] <ref> [7] </ref>. Finlayson, Drew and Funt showed that illumination change can be modelled as diagonal matrix transform under low-dimensional model constraints for illumination and reflectance [11]. Without the low-dimensional constraints on illumination and reflectance, the diagonal matrix transform can be approximated using very narrow color filters (ideally the Dirac delta function).
Reference: [8] <author> M. Flickner et al. </author> <title> Query by image and video content: The qbic system. </title> <journal> IEEE Computer, </journal> <volume> 28 </volume> <pages> 23-32, </pages> <year> 1995. </year>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue [32] [26] [29] [14] [16] [30]. For image retrieval from an image database, color is one of the most effective cues <ref> [8] </ref> [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32].
Reference: [9] <author> O.D. Faugeras. </author> <title> Digital color image processing within the framework of a human visual model. </title> <journal> IEEE Trans. ASSP, </journal> <volume> 27 </volume> <pages> 380-393, </pages> <year> 1979. </year>
Reference-contexts: Therefore, all the color pixels are used to form the distribution regardless of their spatial variation. It may be noted that the descriptors used in homomorphic image processing of opponent colors are similar to the logarithm of sensor ratios, e.g., ln (q R =q G ) <ref> [9] </ref> [19]. Sensor ratios are also used for the gamut mapping method by Finlayson [10].
Reference: [10] <author> G. D. Finlayson. </author> <title> Color in perspective. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 18(10) </volume> <pages> 1034-1038, </pages> <year> 1996. </year>
Reference-contexts: It may be noted that the CCCI method is relatively insensitive to illumination change for smooth surface shapes, and that the problem of illumination pose-invariance is recently gaining attention <ref> [10] </ref> [23]. We suggest the use of intensity-normalized color space, i.e., chromaticity space, to discount changes in color distributions due to illumination pose. The space is based on the logarithms of sensor-response ratios, and chromaticity deformation due to illumination color change is limited to translation. <p> It may be noted that the descriptors used in homomorphic image processing of opponent colors are similar to the logarithm of sensor ratios, e.g., ln (q R =q G ) [9] [19]. Sensor ratios are also used for the gamut mapping method by Finlayson <ref> [10] </ref>. Although basic cross-correlation in can be used for similarity measure, cross-correlation of test chromaticity distribution with all those of database objects would require high computational cost and estimation of j may be inaccurate if the correlation curve shows a broad peak.
Reference: [11] <author> G. D. Finlayson, M. S. Drew, and B. V. Funt. </author> <title> Color constancy: Generalized diagonal transforms suffice. </title> <journal> JOSA, </journal> <volume> 11 </volume> <pages> 3011-3019, </pages> <year> 1994. </year>
Reference-contexts: The problem of color constancy for discounting illumination color to obtain reflectance color has been the topic of much research in psychology and computer vision [20] [34] [24] [13] <ref> [11] </ref>. The knowledge gained through color constancy research is reflected in recent recognition/indexing methods that explore illumination-invariant descriptors from color distributions. Funt and Finlayson [14] developed color-constant color indexing (CCCI) to deal with scenes with variations in illumination color. <p> Color constancy based on the diagonal matrix transformation and its impact are analyzed in detail by Finlayson, Drew and Funt, Worthey and Brill, West and Brill, and D'Zmura and Lennie <ref> [11] </ref> [12] [34] [7]. Finlayson, Drew and Funt showed that illumination change can be modelled as diagonal matrix transform under low-dimensional model constraints for illumination and reflectance [11]. <p> transformation and its impact are analyzed in detail by Finlayson, Drew and Funt, Worthey and Brill, West and Brill, and D'Zmura and Lennie <ref> [11] </ref> [12] [34] [7]. Finlayson, Drew and Funt showed that illumination change can be modelled as diagonal matrix transform under low-dimensional model constraints for illumination and reflectance [11]. Without the low-dimensional constraints on illumination and reflectance, the diagonal matrix transform can be approximated using very narrow color filters (ideally the Dirac delta function).
Reference: [12] <author> G. D. Finlayson, M. S. Drew, and B. V. Funt. </author> <title> Spectral sharpening: Sensor transformations for improved color constancy. </title> <journal> JOSA, </journal> <volume> 11 </volume> <pages> 1553-1563, </pages> <year> 1994. </year>
Reference-contexts: Color constancy based on the diagonal matrix transformation and its impact are analyzed in detail by Finlayson, Drew and Funt, Worthey and Brill, West and Brill, and D'Zmura and Lennie [11] <ref> [12] </ref> [34] [7]. Finlayson, Drew and Funt showed that illumination change can be modelled as diagonal matrix transform under low-dimensional model constraints for illumination and reflectance [11]. <p> The narrow-band filters have been used successfully by Funt and Finlayson and by Nayar and Bolle [14] [29]. Finlayson, Drew, and Funt suggested methods for sharpening sensor functions and reported that the sensor sharpening improves the performance of color constancy algorithms based on diagonal transforms <ref> [12] </ref>.
Reference: [13] <author> D. A. Forsyth. </author> <title> A novel approach to colour constancy. </title> <journal> IJCV, </journal> <volume> 5 </volume> <pages> 5-36, </pages> <year> 1990. </year>
Reference-contexts: The problem of color constancy for discounting illumination color to obtain reflectance color has been the topic of much research in psychology and computer vision [20] [34] [24] <ref> [13] </ref> [11]. The knowledge gained through color constancy research is reflected in recent recognition/indexing methods that explore illumination-invariant descriptors from color distributions. Funt and Finlayson [14] developed color-constant color indexing (CCCI) to deal with scenes with variations in illumination color. <p> D 11 = e e ( 1 )=e ( 1 ); D 22 = e e ( 2 )=e ( 2 ): The diagonal matrix transform has been suggested as a base for many color constancy al-gorithms such as von Kries adaptation, retinex/lightness algorithms, and Forsyth's CRULE algorithm [34] [20] <ref> [13] </ref>. The narrow-band filters have been used successfully by Funt and Finlayson and by Nayar and Bolle [14] [29]. Finlayson, Drew, and Funt suggested methods for sharpening sensor functions and reported that the sensor sharpening improves the performance of color constancy algorithms based on diagonal transforms [12].
Reference: [14] <author> B. V. Funt and G. D. Finlayson. </author> <title> Color constant color indexing. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 17 </volume> <pages> 522-529, </pages> <year> 1995. </year>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue [32] [26] [29] <ref> [14] </ref> [16] [30]. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. <p> The knowledge gained through color constancy research is reflected in recent recognition/indexing methods that explore illumination-invariant descriptors from color distributions. Funt and Finlayson <ref> [14] </ref> developed color-constant color indexing (CCCI) to deal with scenes with variations in illumination color. By histogramming ratios of RGB values of adjacent pixels, they achieve a degree of color constancy that is relatively insensitive to illumination changes. Independently, Nayar and Bolle also used reflectance ratios for object recognition [29]. <p> The narrow-band filters have been used successfully by Funt and Finlayson and by Nayar and Bolle <ref> [14] </ref> [29]. Finlayson, Drew, and Funt suggested methods for sharpening sensor functions and reported that the sensor sharpening improves the performance of color constancy algorithms based on diagonal transforms [12]. <p> The relationship between the chromaticity space x in Equation 6 and is given as: 1 = ln x 2 1 x 1 x 2 ; The use of reflectance ratios has been suggested previously in <ref> [14] </ref> and [29]. The CCCI approach utilizes the distribution of ratios from spatially neighboring pixels, and thus only the image regions where color values spatially vary contribute to the distribution effectively. <p> The proposed log-sensor-ratio chromaticity space further provides illumination color invariance up to translation and our specularity rejection method reduce the influence of specular reflections on chromaticity distribution. Methods that are based on reflectance ratios and narrow-band filters have been suggested previously by Funt and Finlayson <ref> [14] </ref> and Nayar and Bolle [29]. The main difference is that the proposed log-sensor-ratio method creates the signature from the ratio of different color bands at the same pixel, while the previous ratio-based methods use ratios of different pixels in the same color band.
Reference: [15] <author> G.H. Healey. </author> <title> Using color for geometry-insensitive segmentation. </title> <journal> JOSA, </journal> <volume> 6, </volume> <year> 1989. </year>
Reference-contexts: We also address the problem of specularity in object color appearances. Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] <ref> [15] </ref> [21] [3] [28] [2] [35] [27] [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition.
Reference: [16] <author> G.H. Healey and D. Slater. </author> <title> Global color constancy: Recognition of objects by use of illumination-invariant properties of color distributions. </title> <journal> JOSA, </journal> <volume> 11, </volume> <year> 1994. </year>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue [32] [26] [29] [14] <ref> [16] </ref> [30]. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. <p> Healey et al. presented various methods mostly based on the affine property of color distribution change. By assuming a finite-dimensional linear surface reflectance model, changes in illumination color result in a linear transformation of global color pixel distributions in RGB space <ref> [16] </ref> [30] [31]. Their work has been extended to find local color features by restricting the spatial extent of regions in a color image. In this paper, we present an approach for increasing the utility of color distributions and the impact of color-based recognition. <p> The distribution of direct color sensor responses in a RGB space is affected by illumination pose. This is a consequence of surface normal variations on a 3-D object. The relationship between sensor responses under different illumination colors can be modelled as a linear transform <ref> [16] </ref> [30].
Reference: [17] <author> D.P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment. </title> <journal> IJCV, </journal> <volume> 5, </volume> <year> 1990. </year>
Reference-contexts: Traditional object recognition and viewing condition estimation uses geometric cues such as 3-D object shape models and geometric relationships between object features, and recent appearance-based approaches describe an object by using relatively compact eigenspaces derived only from image appearances under various viewing conditions [5] <ref> [17] </ref> [33] [25]. Although color reflectance has been conceived as an obvious object descriptor and color matching has been a central focus of color science and engineering, only recently have a number of researchers begun to explore the use of color distributions as signatures for object recognition.
Reference: [18] <author> G.J. Klinker, S.A. Shafer, and T. Kanade. </author> <title> A physical approach to color image understanding. </title> <journal> IJCV, </journal> <volume> 4, </volume> <year> 1990. </year>
Reference-contexts: We also address the problem of specularity in object color appearances. Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision <ref> [18] </ref> [15] [21] [3] [28] [2] [35] [27] [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. <p> These constraints include restricted material types and piecewise uniform object colors. Extra physical cues include structured light, polarization sensors, and multiple-view image sensing <ref> [18] </ref> [2] [21] [28] [35] [27] [22]. These additional requirements sensing may be difficult to achieve, especially for test images. An additional source of information for specularity detection in lieu of extra sensing needs to be found.
Reference: [19] <author> J.J. Koenderik, W.A. van de Grind, and M.A. Bouman. </author> <title> Opponent color coding: A mechanical model and a new metric for color space. </title> <journal> Kybernetik, </journal> <volume> 10 </volume> <pages> 78-98, </pages> <year> 1972. </year>
Reference-contexts: Therefore, all the color pixels are used to form the distribution regardless of their spatial variation. It may be noted that the descriptors used in homomorphic image processing of opponent colors are similar to the logarithm of sensor ratios, e.g., ln (q R =q G ) [9] <ref> [19] </ref>. Sensor ratios are also used for the gamut mapping method by Finlayson [10].
Reference: [20] <author> E.H. Land and J. J. </author> <title> McCann. </title> <journal> Lightness and retinex theory. JOSA, </journal> <volume> 61 </volume> <pages> 1-11, </pages> <year> 1971. </year> <month> 14 </month>
Reference-contexts: The problem of color constancy for discounting illumination color to obtain reflectance color has been the topic of much research in psychology and computer vision <ref> [20] </ref> [34] [24] [13] [11]. The knowledge gained through color constancy research is reflected in recent recognition/indexing methods that explore illumination-invariant descriptors from color distributions. Funt and Finlayson [14] developed color-constant color indexing (CCCI) to deal with scenes with variations in illumination color. <p> ); D 11 = e e ( 1 )=e ( 1 ); D 22 = e e ( 2 )=e ( 2 ): The diagonal matrix transform has been suggested as a base for many color constancy al-gorithms such as von Kries adaptation, retinex/lightness algorithms, and Forsyth's CRULE algorithm [34] <ref> [20] </ref> [13]. The narrow-band filters have been used successfully by Funt and Finlayson and by Nayar and Bolle [14] [29]. Finlayson, Drew, and Funt suggested methods for sharpening sensor functions and reported that the sensor sharpening improves the performance of color constancy algorithms based on diagonal transforms [12].
Reference: [21] <author> S.W. Lee and R. </author> <title> Bajcsy. Detection of specularity using color and multiple views. </title> <journal> Image and Vision Computing, </journal> <volume> 10 </volume> <pages> 643-653, </pages> <year> 1992. </year>
Reference-contexts: We also address the problem of specularity in object color appearances. Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] [15] <ref> [21] </ref> [3] [28] [2] [35] [27] [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. <p> These constraints include restricted material types and piecewise uniform object colors. Extra physical cues include structured light, polarization sensors, and multiple-view image sensing [18] [2] <ref> [21] </ref> [28] [35] [27] [22]. These additional requirements sensing may be difficult to achieve, especially for test images. An additional source of information for specularity detection in lieu of extra sensing needs to be found. <p> This chromaticity histogram comparison is motivated by histogram differencing techniques <ref> [21] </ref> [22]. Our approach to specularity rejection begins with conservative intensity-based processing of a test image, such as intensity thresholding, to eliminate sharp and intense specularity without any prior information [3]. From the resulting signature, a hypothesis for initial object identification and illumination estimation is generated. <p> The database images are taken with the illumination filtered by Lee Filter 201 (Full CT Blue) which moves the incandescent light towards a neutral color. Specularities in the model images are removed by intensity thresholding methods <ref> [21] </ref> or by hand before the chromaticity descriptors are created. Figure 3 (a), (b) and (c) show the database objects, their chromaticity diagrams in the x space, and in the space, respectively. The range of the chromaticity space is from -1 to 1 along the 1 and 2 axes.
Reference: [22] <author> S. Lin and S.W. Lee. </author> <title> Detection of specularity using stereo in color and polarization space. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <year> 1997. </year>
Reference-contexts: Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] [15] [21] [3] [28] [2] [35] [27] <ref> [22] </ref>. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. In summary, we propose a color-based object recognition algorithm invariant to: (1) illumination pose, (2) illumination color, and (3) specularity. <p> These constraints include restricted material types and piecewise uniform object colors. Extra physical cues include structured light, polarization sensors, and multiple-view image sensing [18] [2] [21] [28] [35] [27] <ref> [22] </ref>. These additional requirements sensing may be difficult to achieve, especially for test images. An additional source of information for specularity detection in lieu of extra sensing needs to be found. Our solution to this problem lies in the model images, from which we propose "model-based specularity detection/rejection". <p> This chromaticity histogram comparison is motivated by histogram differencing techniques [21] <ref> [22] </ref>. Our approach to specularity rejection begins with conservative intensity-based processing of a test image, such as intensity thresholding, to eliminate sharp and intense specularity without any prior information [3]. From the resulting signature, a hypothesis for initial object identification and illumination estimation is generated.
Reference: [23] <author> S. Lin and S.W. Lee. </author> <title> Using chromaticity distributions and eigenspace for pose-, illumination-, and specularity-invariant 3d object recognition. </title> <booktitle> In To Appear in Proc. IEEE Conf. Compt. Vision and Pattern Recog., </booktitle> <year> 1997. </year>
Reference-contexts: It may be noted that the CCCI method is relatively insensitive to illumination change for smooth surface shapes, and that the problem of illumination pose-invariance is recently gaining attention [10] <ref> [23] </ref>. We suggest the use of intensity-normalized color space, i.e., chromaticity space, to discount changes in color distributions due to illumination pose. The space is based on the logarithms of sensor-response ratios, and chromaticity deformation due to illumination color change is limited to translation.
Reference: [24] <author> L. T. Maloney and B. A. Wandell. </author> <title> A computational model of color constancy. </title> <journal> JOSA, </journal> <volume> 1 </volume> <pages> 29-33, </pages> <year> 1986. </year>
Reference-contexts: The problem of color constancy for discounting illumination color to obtain reflectance color has been the topic of much research in psychology and computer vision [20] [34] <ref> [24] </ref> [13] [11]. The knowledge gained through color constancy research is reflected in recent recognition/indexing methods that explore illumination-invariant descriptors from color distributions. Funt and Finlayson [14] developed color-constant color indexing (CCCI) to deal with scenes with variations in illumination color. <p> This is a consequence of surface normal variations on a 3-D object. The relationship between sensor responses under different illumination colors can be modelled as a linear transform [16] [30]. For three-dimensional approximation of surface 3 reflection [6] <ref> [24] </ref>, s p () = i=0 i S i (): (2) where S i 's are basis functions and oe i 's are weighting coefficients (i = 0; 1; 2), the sensor responses q p = [q R ; q G ; q B ] T and reflectance coefficients oe p
Reference: [25] <author> H. Murase and S.K. Nayar. </author> <title> Visual learning and recognition of 3-d objects from appearance. </title> <journal> IJCV, </journal> <volume> 14, </volume> <year> 1995. </year>
Reference-contexts: Traditional object recognition and viewing condition estimation uses geometric cues such as 3-D object shape models and geometric relationships between object features, and recent appearance-based approaches describe an object by using relatively compact eigenspaces derived only from image appearances under various viewing conditions [5] [17] [33] <ref> [25] </ref>. Although color reflectance has been conceived as an obvious object descriptor and color matching has been a central focus of color science and engineering, only recently have a number of researchers begun to explore the use of color distributions as signatures for object recognition.
Reference: [26] <author> M. Nagao, T. Matsuyama, and Y. Ikeda. </author> <title> Region extraction and shape analysis in aerial images. </title> <journal> CGIP, </journal> <volume> 10(3) </volume> <pages> 195-223, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue [32] <ref> [26] </ref> [29] [14] [16] [30]. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. <p> potentially be a strong cue [32] <ref> [26] </ref> [29] [14] [16] [30]. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. Although this initial work does not address the problems of changing viewing conditions such as illumination direction and color change, it introduced the usefulness of color in recognition and motivated work for illumination color-invariant recognition.
Reference: [27] <author> S. K. Nayar, X. S. Fang, and T. Boult. </author> <title> Separation of reflection components using color and polarization. </title> <booktitle> In Proc. DARPA IU Workshop, </booktitle> <pages> pages 1049-1060, </pages> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] [15] [21] [3] [28] [2] [35] <ref> [27] </ref> [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. In summary, we propose a color-based object recognition algorithm invariant to: (1) illumination pose, (2) illumination color, and (3) specularity. <p> These constraints include restricted material types and piecewise uniform object colors. Extra physical cues include structured light, polarization sensors, and multiple-view image sensing [18] [2] [21] [28] [35] <ref> [27] </ref> [22]. These additional requirements sensing may be difficult to achieve, especially for test images. An additional source of information for specularity detection in lieu of extra sensing needs to be found. Our solution to this problem lies in the model images, from which we propose "model-based specularity detection/rejection".
Reference: [28] <author> S. K. Nayar, K. Ikeuchi, and T. Kanade. </author> <title> Determining shape and reflectance of hybrid surfaces by photometric sampling. </title> <journal> IEEE Trans. Robo. Autom., </journal> <volume> 6 </volume> <pages> 418-431, </pages> <year> 1990. </year>
Reference-contexts: We also address the problem of specularity in object color appearances. Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] [15] [21] [3] <ref> [28] </ref> [2] [35] [27] [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. In summary, we propose a color-based object recognition algorithm invariant to: (1) illumination pose, (2) illumination color, and (3) specularity. <p> These constraints include restricted material types and piecewise uniform object colors. Extra physical cues include structured light, polarization sensors, and multiple-view image sensing [18] [2] [21] <ref> [28] </ref> [35] [27] [22]. These additional requirements sensing may be difficult to achieve, especially for test images. An additional source of information for specularity detection in lieu of extra sensing needs to be found.
Reference: [29] <author> S.K. Nayar and R.M. Bolle. </author> <title> Reflectance based object recognition. </title> <journal> IJCV, </journal> <volume> 17, </volume> <year> 1996. </year>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue [32] [26] <ref> [29] </ref> [14] [16] [30]. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. <p> By histogramming ratios of RGB values of adjacent pixels, they achieve a degree of color constancy that is relatively insensitive to illumination changes. Independently, Nayar and Bolle also used reflectance ratios for object recognition <ref> [29] </ref>. Healey et al. presented various methods mostly based on the affine property of color distribution change. By assuming a finite-dimensional linear surface reflectance model, changes in illumination color result in a linear transformation of global color pixel distributions in RGB space [16] [30] [31]. <p> The narrow-band filters have been used successfully by Funt and Finlayson and by Nayar and Bolle [14] <ref> [29] </ref>. Finlayson, Drew, and Funt suggested methods for sharpening sensor functions and reported that the sensor sharpening improves the performance of color constancy algorithms based on diagonal transforms [12]. <p> The relationship between the chromaticity space x in Equation 6 and is given as: 1 = ln x 2 1 x 1 x 2 ; The use of reflectance ratios has been suggested previously in [14] and <ref> [29] </ref>. The CCCI approach utilizes the distribution of ratios from spatially neighboring pixels, and thus only the image regions where color values spatially vary contribute to the distribution effectively. <p> Methods that are based on reflectance ratios and narrow-band filters have been suggested previously by Funt and Finlayson [14] and Nayar and Bolle <ref> [29] </ref>. The main difference is that the proposed log-sensor-ratio method creates the signature from the ratio of different color bands at the same pixel, while the previous ratio-based methods use ratios of different pixels in the same color band.
Reference: [30] <author> D. Slater and G.H. Healey. </author> <title> The illumination-invariant recognition of 3d objects using local color invariants. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 18(2), </volume> <year> 1996. </year>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue [32] [26] [29] [14] [16] <ref> [30] </ref>. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. <p> Healey et al. presented various methods mostly based on the affine property of color distribution change. By assuming a finite-dimensional linear surface reflectance model, changes in illumination color result in a linear transformation of global color pixel distributions in RGB space [16] <ref> [30] </ref> [31]. Their work has been extended to find local color features by restricting the spatial extent of regions in a color image. In this paper, we present an approach for increasing the utility of color distributions and the impact of color-based recognition. <p> The distribution of direct color sensor responses in a RGB space is affected by illumination pose. This is a consequence of surface normal variations on a 3-D object. The relationship between sensor responses under different illumination colors can be modelled as a linear transform [16] <ref> [30] </ref>.
Reference: [31] <author> D. Slater and G.H. Healey. </author> <title> Using spectral reflectance model for the illumination-invariant recognition of local image structure. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 770-775, </pages> <year> 1996. </year>
Reference-contexts: Healey et al. presented various methods mostly based on the affine property of color distribution change. By assuming a finite-dimensional linear surface reflectance model, changes in illumination color result in a linear transformation of global color pixel distributions in RGB space [16] [30] <ref> [31] </ref>. Their work has been extended to find local color features by restricting the spatial extent of regions in a color image. In this paper, we present an approach for increasing the utility of color distributions and the impact of color-based recognition.
Reference: [32] <author> M. J. Swain. </author> <title> Color indexing. </title> <journal> IJCV, </journal> <volume> 7 </volume> <pages> 11-32, </pages> <year> 1991. </year>
Reference-contexts: Their work has demonstrated that color can potentially be a strong cue <ref> [32] </ref> [26] [29] [14] [16] [30]. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. <p> be a strong cue <ref> [32] </ref> [26] [29] [14] [16] [30]. For image retrieval from an image database, color is one of the most effective cues [8] [1]. The early approaches for recognizing objects based on their color distributions were developed by Nagao et al. and by Swain and Ballard [26] [32]. Although this initial work does not address the problems of changing viewing conditions such as illumination direction and color change, it introduced the usefulness of color in recognition and motivated work for illumination color-invariant recognition.
Reference: [33] <author> M.A. Turk and A. Pentland. </author> <title> Face recognition using eigenfaces. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 586-591, </pages> <year> 1991. </year>
Reference-contexts: Traditional object recognition and viewing condition estimation uses geometric cues such as 3-D object shape models and geometric relationships between object features, and recent appearance-based approaches describe an object by using relatively compact eigenspaces derived only from image appearances under various viewing conditions [5] [17] <ref> [33] </ref> [25]. Although color reflectance has been conceived as an obvious object descriptor and color matching has been a central focus of color science and engineering, only recently have a number of researchers begun to explore the use of color distributions as signatures for object recognition.
Reference: [34] <author> G. West and M.H. Brill. </author> <title> Necessary and sufficient conditions for von kries chromatic adptation to give colour constancy. </title> <journal> J. Math. Biol., </journal> <volume> 15 </volume> <pages> 249-258, </pages> <year> 1982. </year>
Reference-contexts: The problem of color constancy for discounting illumination color to obtain reflectance color has been the topic of much research in psychology and computer vision [20] <ref> [34] </ref> [24] [13] [11]. The knowledge gained through color constancy research is reflected in recent recognition/indexing methods that explore illumination-invariant descriptors from color distributions. Funt and Finlayson [14] developed color-constant color indexing (CCCI) to deal with scenes with variations in illumination color. <p> Color constancy based on the diagonal matrix transformation and its impact are analyzed in detail by Finlayson, Drew and Funt, Worthey and Brill, West and Brill, and D'Zmura and Lennie [11] [12] <ref> [34] </ref> [7]. Finlayson, Drew and Funt showed that illumination change can be modelled as diagonal matrix transform under low-dimensional model constraints for illumination and reflectance [11]. <p> 0 ); D 11 = e e ( 1 )=e ( 1 ); D 22 = e e ( 2 )=e ( 2 ): The diagonal matrix transform has been suggested as a base for many color constancy al-gorithms such as von Kries adaptation, retinex/lightness algorithms, and Forsyth's CRULE algorithm <ref> [34] </ref> [20] [13]. The narrow-band filters have been used successfully by Funt and Finlayson and by Nayar and Bolle [14] [29]. Finlayson, Drew, and Funt suggested methods for sharpening sensor functions and reported that the sensor sharpening improves the performance of color constancy algorithms based on diagonal transforms [12].
Reference: [35] <author> L. B. Wolff. </author> <title> Using polarization to separate reflection components. </title> <booktitle> In Proc. of CVPR, </booktitle> <pages> pages 363-369, </pages> <address> San Diego, </address> <year> 1989. </year> <month> 15 </month>
Reference-contexts: Previous research in color recognition assumes the lack of strong specularity and its effects in the color distribution. Detection of specularity has been a topic of active research in the field of physics-based vision [18] [15] [21] [3] [28] [2] <ref> [35] </ref> [27] [22]. Most of this work deals with basic modeling and algorithm development. We present a systematic method that couples specularity detection with color-based object recognition. In summary, we propose a color-based object recognition algorithm invariant to: (1) illumination pose, (2) illumination color, and (3) specularity. <p> These constraints include restricted material types and piecewise uniform object colors. Extra physical cues include structured light, polarization sensors, and multiple-view image sensing [18] [2] [21] [28] <ref> [35] </ref> [27] [22]. These additional requirements sensing may be difficult to achieve, especially for test images. An additional source of information for specularity detection in lieu of extra sensing needs to be found. Our solution to this problem lies in the model images, from which we propose "model-based specularity detection/rejection".
References-found: 35

