URL: http://ftp.eecs.umich.edu/people/peter/aaai94.ps
Refering-URL: http://ftp.eecs.umich.edu/people/peter/
Root-URL: http://www.eecs.umich.edu
Email: peter@umich.edu  lytinen@cs.depaul.edu  
Phone: (313)763-9074  (312)362-6106  
Title: The Ups and Downs of Lexical Acquisition  
Author: Peter M. Hastings Steven L. Lytinen 
Address: 1101 Beal Avenue  Ann Arbor, MI 48109  243 South Wabash Avenue Chicago, IL 60604-2302  
Affiliation: Artificial Intelligence Laboratory  The University of Michigan  DePaul University Dept. of Computer Science and Info. Systems  
Abstract: We have implemented an incremental lexical acquisition mechanism that learns the meanings of previously unknown words from the context in which they appear, as a part of the process of parsing and semantically interpreting sentences. Implementation of this algorithm brought to light a fundamental difference between learning verbs and learning nouns. Specifically, because verbs typically play the predicate role in English sentences, whereas nouns typically function as arguments, we found that different mechanisms were required to learn verbs and nouns. Because of this difference in usage, our learning algorithm formulates the most specific hypotheses possible, consistent with the data, for verb meanings, but the most general hypotheses possible for nouns. Subsequent examples may falsify a current hypothesis, causing verb meanings to be generalized and noun meanings to be made more specific. This paper describes the two approaches used to learn verbs and nouns in the system, and reports on the system's performance in substantial empirical testing. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Behrend, D. </author> <year> 1990. </year> <title> The development of verb concepts: Children's use of verbs to label familiar and novel events. </title> <booktitle> Child Development 61 </booktitle> <pages> 681-696. </pages>
Reference: <author> Brent, M. </author> <year> 1993. </year> <title> Surface cues and robust inference as a basis for the early acquisition of subcategorization frames. Lingua. </title> <publisher> in press. </publisher>
Reference: <author> Cardie, C. </author> <year> 1993. </year> <title> A case-based approach to knowledge acquisition for domain-specific sentence analysis. </title> <booktitle> In Proceedings of the 11 th National Conference on Artificial Intelligence, </booktitle> <pages> 798-803. </pages>
Reference: <author> Church, K., and Hanks, P. </author> <year> 1990. </year> <title> Word association norms, mutual information, and lexicography. </title> <note> Computational Linguistics 16. </note>
Reference: <author> Cullingford, R. </author> <year> 1977. </year> <title> Organizing World Knowledge for Story Understanding by Computer. </title> <type> Ph.D. Dissertation, </type> <institution> Yale University, </institution> <address> New Haven, CT. </address>
Reference: <author> Fernald, A., and Morikawa, H. </author> <year> 1993. </year> <title> Common themes and cultural variations in Japanese and American mothers' speech to infants. </title> <booktitle> Child Development 64 </booktitle> <pages> 637-656. </pages>
Reference: <author> Gentner, D. </author> <year> 1978. </year> <title> On relational meaning: The acquisition of verb meaning. </title> <booktitle> Child Development 49 </booktitle> <pages> 988-998. </pages>
Reference: <author> Graesser, A.; Hopkinson, P.; and Schmid, C. </author> <year> 1987. </year> <title> Differences in interconcept organization between nouns and verbs. </title> <booktitle> Journal of Memory and Language 26 </booktitle> <pages> 242-253. </pages>
Reference: <author> Granger, R. </author> <year> 1977. </year> <title> Foul-up: A program that figures out meanings of words from context. </title> <booktitle> In Proceedings of Fifth International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Related Work Other systems have concentrated on the acquisition of specific kinds of words. Granger noted the importance and difficulty of acquiring verbs in his description of Foul-Up <ref> (Granger 1977) </ref> which used heuristic methods to learn verbs based on the prepositions in a sentence. Zernik's Rina (Zernik 1987) concentrated on learning verb-particle combinations using interactive training and extensive domain knowledge. Unfortunately, neither was evaluated on real-world data.
Reference: <author> Hastings, P. </author> <year> 1994. </year> <title> Automatic Acquisition of Word Meaning from Context. </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference-contexts: Introduction This paper describes the lexical acquisition system Camille (Contextual Acquisition Mechanism for Incremental Lexeme Learning <ref> (Hastings 1994) </ref>). Camille learns the lexical category and meaning of unknown words based on example sentences. Acquisition systems are crucial to NLP systems that process real-world text. Because the complete range of the text cannot be specified, gaps in lexical knowledge are bound to occur.
Reference: <author> Hindle, D. </author> <year> 1990. </year> <title> Noun classification from predicate-argument structures. </title> <booktitle> In Proceedings of the 28 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 268-275. </pages>
Reference: <author> Huttenlocher, J., and Lui, F. </author> <year> 1979. </year> <title> The semantic organization of some simple nouns and verbs. </title> <journal> Journal of verbal learning and verbal behavior 18 </journal> <pages> 141-162. </pages>
Reference: <author> Lytinen, S., and Roberts, S. </author> <year> 1989. </year> <title> Unifying linguistic knowledge. </title> <institution> AI Laboratory, Univ of Michigan, </institution> <address> Ann Arbor, MI 48109. </address>
Reference-contexts: Such an occasion can either be disruptive for the NLP system, preventing it from processing the rest of the text, or the system can take advantage of the situation and learn something about the unknown word. Camille is implemented as an extension of the LINK NLP system <ref> (Lytinen & Roberts 1989) </ref> which is a unification-based chart parser which integrates syntactic and semantic information. Unlike statistics-based acquisition mechanisms which require large corpora (Brent 1993; Church & Hanks 1990; Hindle 1990; Resnik 1992; Yarowsky 1992), Camille uses its domain knowledge when inferring the meaning of unknown words.
Reference: <author> Lytinen, S. </author> <year> 1988. </year> <title> Are vague words ambiguous? In Small, </title> <editor> S., and Cottrell, G., eds., </editor> <title> Lexical Ambiguity Resolution. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher> <pages> 109-128. </pages>
Reference: <author> Markman, E. </author> <year> 1991. </year> <title> The whole object, taxonomic, and mutual exclusivity assumptions as initial constraints on word meanings. </title> <editor> In Byrnes, J. P., and Gelman, S. A., eds., </editor> <booktitle> Perspectives on language and thought: Interrelations in development. </booktitle> <address> Cambridge: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Mitchell, T. </author> <year> 1977. </year> <title> Version spaces: A candidate elimination approach to rule learning. </title> <booktitle> In Proceedings of the Fifth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 305-309. </pages>
Reference-contexts: Then Mitchell's candidate-elimination approach <ref> (Mitchell 1977) </ref> to narrowing the hypothesis set might work. Unfortunately, negative examples are rare in human speech the concepts that are ruled out for an example sentence like "Terrorists froobled the headquarters." It is important to note that this is not just an artifact of LINK's knowledge representation structure.
Reference: <author> Resnik, P. </author> <year> 1992. </year> <title> A class-based approach to lexical discovery. </title> <booktitle> In Proceedings of the 30 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 327-329. </pages>
Reference: <author> Riloff, E. </author> <year> 1993. </year> <title> Automatically constructing a dictionary for information extraction tasks. </title> <booktitle> In Proceedings of the 11 th National Conference on Artificial Intelligence, </booktitle> <pages> 811-816. </pages>
Reference: <author> Salveter, S. </author> <year> 1979. </year> <title> Inferring conceptual graphs. </title> <booktitle> Cognitive Science 3 </booktitle> <pages> 141-166. </pages>
Reference: <author> Schank, R., and Abelson, R. </author> <year> 1977. </year> <title> Scripts, plans, goals, and understanding. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Selfridge, M. </author> <year> 1986. </year> <title> A computer model of child language learning. </title> <booktitle> Artificial Intelligence 29 </booktitle> <pages> 171-216. </pages>
Reference: <author> Siskind, J. </author> <year> 1990. </year> <title> Acquiring core meanings of words. </title> <booktitle> In Proceedings of the 28 th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 143-156. </pages>
Reference: <editor> Small, S., and Cottrell, G., eds. </editor> <year> 1988. </year> <title> Lexical Ambiguity Resolution. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: The following section describes the more difficult acquisition problem for verbs. Learning Ambiguous Nouns Word sense ambiguity has been a thorn in the side of NLP for a long time <ref> (Small & Cottrell 1988) </ref>. The majority of the research on this issue has targetted methods for selecting the appropriate sense of an ambiguous word.
Reference: <author> Sundheim, B. </author> <year> 1992. </year> <title> Overview of the fourth message understanding evaluation and conference. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Military Installation Utility Transport Route Transport Vehicle Building Energy Water Commun ications Church School Commercial Office-or-residence . . . Government official Political-figure Civilian . . . LINK's domain-specific object concepts from the Terrorism domain that served as the testing ground for ARPA's third and fourth Message Understanding Conferences <ref> (Sundheim 1992) </ref> (the shading will be explained later). The structure of the hierarchy forms an IS-A inheritance tree. Figure 2 shows some of the actions from the domain. Action concepts provide the relational structure that binds together the representation of the meaning of sentences.
Reference: <author> Yarowsky, D. </author> <year> 1992. </year> <title> Word-sense disambiguation using statistical models of roget's categories trained on large corpora. </title> <booktitle> In Proceedings, COLING-92. </booktitle>
Reference: <author> Zernik, U. </author> <year> 1987. </year> <title> Strategies in language acquisitions: Learning phrases from examples in context. </title> <type> Technical Report UCLA-AI-87-1, </type> <institution> UCLA. </institution>
Reference-contexts: Related Work Other systems have concentrated on the acquisition of specific kinds of words. Granger noted the importance and difficulty of acquiring verbs in his description of Foul-Up (Granger 1977) which used heuristic methods to learn verbs based on the prepositions in a sentence. Zernik's Rina <ref> (Zernik 1987) </ref> concentrated on learning verb-particle combinations using interactive training and extensive domain knowledge. Unfortunately, neither was evaluated on real-world data. The extent of special-purpose knowledge that these systems required would have made that extremely difficult to do.
References-found: 26

