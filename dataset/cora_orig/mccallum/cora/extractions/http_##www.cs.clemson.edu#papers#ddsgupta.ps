URL: http://www.cs.clemson.edu/papers/ddsgupta.ps
Refering-URL: http://www.cs.clemson.edu/html/research/studpapr.shtml
Root-URL: http://www.cs.clemson.edu
Email: ddsgupta@cs.clemson.edu  
Title: Scheduling Techniques for Improving Data Cache Performance  
Author: Devidas Gupta 
Date: May 4, 1994  
Address: Clemson, SC 29634  
Affiliation: Department of Computer Science Clemson University  
Abstract: We present techniques that can be applied to the assembly language output of a compiler for improving the data cache reference pattern. Previous techniques have addressed the problem of improving the instruction cache reference pattern but have not addressed the problem currently under study. We present an overview of the current literature including a taxonomy of improvement techniques for cache reference patterns. We present several heuristics for improving the data cache reference pattern including one heuristic for instructions containing a single memory reference and a second heuristic for instructions containing two memory references. 
Abstract-found: 1
Intro-found: 1
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers, Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference: [BCG + 76] <author> J. Bruno, E. G. Coffman, R. Graham, W. Kohler, R. Sethi, K. Steiglitz, and J. Ullman. </author> <title> Computing and Job-Shop Scheduling Theory. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, London, Sydney, Toronto, </address> <year> 1976. </year>
Reference-contexts: A sample dag for Figure 2 is shown in Figure 6 with ordered pairs attached to each node. The algorithm, BuildScheduleGraph, shown in Figure 5, is a version of list scheduling <ref> [BCG + 76] </ref>. BuildScheduleGraph maintains a ready list, R, where a node is inserted into R if it is ready to exe cute, that is, all of its predecessors are scheduled.
Reference: [Fer76] <author> Domenico Ferrari. </author> <title> The improvement of program behavior. </title> <journal> Computer, </journal> <volume> 9(11) </volume> <pages> 39-47, </pages> <month> November </month> <year> 1976. </year>
Reference-contexts: The unified approaches attempt to produce programs which require a lower memory bandwidth, without investigating the causative agents for a program's reference pattern. 3.3.1 Unified approaches based on profile information One of the earliest studies of program restructuring based on profile information is presented in <ref> [Fer76] </ref>. The technique presented uses memory references obtained from runs of the program to restructure the program. A program is divided into blocks and a restructuring graph is built from these blocks and the profile information.
Reference: [GC90] <author> Rajiv Gupta and Chi-Hung Chi. </author> <title> Improving instruction cache behaviour by reducing cache pollution. </title> <booktitle> Proceedings of Supercomputing'90, </booktitle> <pages> pages 82-91, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Such techniques generally rely on such programming constructs, as loops, conditionals and procedure calls to guide the optimization. Gupta and Chi <ref> [GC90] </ref> introduce the concept of cache pollutants. These are instructions which share a 5 cache line (in a multi-word cache) but are never executed. Code repositioning, duplication and propagation are used to reduce cache pollution.
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computer And Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman And Company, </publisher> <address> Reading, </address> <institution> Bell Laboratories, </institution> <year> 1979. </year>
Reference: [GJG88] <author> Dennis Gannon, William Jalby, and Kyle Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference: [GMM94] <author> Devidas Gupta, Alice McRae, and Brian Malloy. </author> <title> Scheduling techniques for improving data cache performance. </title> <type> Technical Report 94-106, </type> <institution> Department of Computer Science, Clemson University, Clemson, </institution> <address> SC 29634, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: We then provide a formal description of the problem that we consider followed by an examination of the complexity of the problem in Section 5. Since the problem is 1 NP-complete <ref> [GMM94] </ref>, we present heuristics in Section 6. Section 7 presents the experimental results and in Section 8 we draw some conclusions. 2 Background 2.1 The Impact of Cache Reference Pattern on Instruction Cost Most compilers accept a program as input and produce a sequence of assembly language statements as output. <p> We have investigated the complexity of the problem and the interested reader may consult <ref> [GMM94] </ref> for the proof of NP-completeness. 5.1 Problem definition The decision problem, we call it COP T for Cache Optimization, is presented as follows. 5.1.1 The COP T problem COPT INSTANCE A schedule graph, G (S,E p [ E s ) where E s = ;, a cache with n lines, <p> Hence, claim 1 holds. 5.2.2 X3C can be transformed to COP T Lemma 2 X3C p COP T Proof: The proof includes an interesting reduction from exact three cover constructed by Alice McRae. The reduction and proof are presented in <ref> [GMM94] </ref>. We are grateful to Dr. McRae for providing the reduction. Lemma 3 COP T is in NPc.
Reference: [HP90] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Reading, Stanford, </address> <year> 1990. </year>
Reference-contexts: data layout. 4 Cache misses can be attributed to one of three sources : Compulsory these are first reference misses, Capacity these occur due to insufficient cache lines to hold all the referenced data, and Conflict these occur due to different memory lines being mapped to the same cache line <ref> [HP90] </ref>. 6 3.3 Unified Approaches Most of the earlier work on program optimization that was motivated by memory reference patterns took a unified approach to tackle the problem. Separate caches for instructions and data have been introduced only in the past few years.
Reference: [JD91] <author> Y.-J. Ju and H. Dietz. </author> <title> Reduction of cache coherence overhead by compiler data layout and loop transformation. </title> <booktitle> Proceedings of Fourth International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 344-352, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: A mathematical formulation of data locality is presented. The algorithm applies a combination of loop transformations to improve the data locality of nested loops. Ju and Dietz <ref> [JD91] </ref> present a way to improve the data access patterns of a program. An interference graph is constructed to provide information about interactions between different potential data layouts and the loops which reference them.
Reference: [McF89] <author> Scott McFarling. </author> <title> Program optimization for instruction caches. </title> <booktitle> Proceedings of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 183-191, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Profile information is gathered from a profiler and the knowledge of the characteristics of the particular program being optimized helps the optimizer. These optimizations can be performed statically, at compile/optimization time, or dynamically, as the program executes. McFarling <ref> [McF89] </ref> presents an optimization algorithm for reducing instruction cache misses for a direct-mapped cache. Profile information from a program is used to reposition instructions, attempting to keep the most frequent instructions in the cache while excluding the less frequent instructions.
Reference: [McF91] <author> Scott McFarling. </author> <title> Procedure merging with instruction caches. </title> <booktitle> Proceedings of the ACM SIG-PLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 71-79, </pages> <month> June </month> <year> 1991. </year>
Reference: [McF92] <author> Scott McFarling. </author> <title> Cache replacement with dynamic exclusion. </title> <booktitle> Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 191-200, </pages> <month> May </month> <year> 1992. </year>
Reference: [MPS94] <author> Abraham Mendlson, Shlomit S. Pinter, and Ruth Shtokhamer. </author> <title> Compile time instruction cache optimizations. </title> <booktitle> Computer Architecture, </booktitle> <volume> 12(3) </volume> <pages> 177-886, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Code repositioning, duplication and propagation are used to reduce cache pollution. The techniques presented either use the Control Flow Graph or the Control Dependence Graph (of a Program Dependence Graph) for the optimizations. Mendlson, Pinter and Shtokhamer <ref> [MPS94] </ref> present an approach based on Nested Flow Graphs and their partitioning into Abstract Caches. The technique replicates code in order to minimize conflict misses 4 in loops. This expended code is then partitioned into abstract caches and replications if any within a single abstract cache are merged.
Reference: [mWHC89] <author> Wen mei W. Hwu and Pohua P. Chang. </author> <title> Achieving high instruction cache performance with an optimizing compiler. </title> <booktitle> Proceedings of the 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 242-251, </pages> <year> 1989. </year> <month> 22 </month>
Reference-contexts: McFarling's technique produces optimal results for programs without conditionals. For general purpose programs, the technique demonstrated good results for the set of programs tested. A five step approach to achieving a higher hit rate for instruction caches is presented in <ref> [mWHC89] </ref>. The program is represented by a weighted call graph and a weighted control flow graph. Dynamic profiling information is then used to record the weights on the edges of these graphs as the corresponding execution frequencies. Inline expansion is carried out using the weights.
Reference: [PH90] <author> Karl Pettis and Robert C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> Proceedings of the ACM SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 16-27, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Spatial locality is preserved by a careful layout of the function traces in sequential order. The final pass builds a global layout by placing functions which are executed close to each other in time into the same page. A closest is best strategy is presented in <ref> [PH90] </ref>, wherein two techniques are developed to guide code positioning using profile information. The first technique uses dynamic call graph information to place two procedures close to each another if one calls the other frequently. This technique is incorporated into the linker.
Reference: [Set75] <author> Ravi Sethi. </author> <title> Complete register allocation problems. </title> <journal> SIAM Journal of Computers, </journal> <volume> 4(3) </volume> <pages> 226-248, </pages> <month> September </month> <year> 1975. </year>
Reference: [SH88] <author> A. Dain Samples and Paul N. Hilfinger. </author> <title> Code reorganization for instruction caches. </title> <type> Technical report, </type> <institution> Computer Science Division - EECS, University of California at Berkeley, </institution> <month> October </month> <year> 1988. </year>
Reference-contexts: This technique is incorporated into the linker. The second technique works at the basic block level and tries to place blocks which have a high execution frequency close to one another. The Greedy Sewing algorithm presented in <ref> [SH88] </ref> uses profile information to build threads of stitched basic blocks. The algorithm uses arc counts in a Control Flow Graph to decide the configuration of the threads.
Reference: [Smi82] <author> Alan Jay Smith. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference: [TS87] <author> Dominique Thiebaut and Harold S. Stone. </author> <title> Footprints in the cache. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(4) </volume> <pages> 305-329, </pages> <month> November </month> <year> 1987. </year>
Reference: [Ull75] <author> J. D. Ullman. </author> <title> Np-complete scheduling problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 10 </volume> <pages> 384-393, </pages> <month> July </month> <year> 1975. </year>
Reference: [Wal91] <author> David W. Wall. </author> <title> Predicting program behavior using real or estimated profiles. </title> <booktitle> Proceedings of the ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 59-70, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The majority of these efforts have utilized static or dynamic knowledge of the behavior of the program, obtained by a profiler, to direct the instruction reordering. However, a recent study by Wall <ref> [Wal91] </ref> has shown that profile information can lead to inflated expectations of a profile-driven optimization. Furthermore, ignoring the possibility of improving the data cache reference pattern may result in a large number of data cache misses that can greatly affect program performance.
Reference: [WL91a] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> Proceedings of the ACM SIGPLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Techniques developed have largely concentrated on certain programming constructs such as loops and certain classes of algorithms such as numerical algorithms. Wolfe and Lam [WL91b], <ref> [WL91a] </ref> have addressed the problem of loop transformations such as interchange, skewing and reversal by presenting an algorithm to enhance data locality in numerical algorithms (that use matrices). A mathematical formulation of data locality is presented.
Reference: [WL91b] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-471, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Techniques developed have largely concentrated on certain programming constructs such as loops and certain classes of algorithms such as numerical algorithms. Wolfe and Lam <ref> [WL91b] </ref>, [WL91a] have addressed the problem of loop transformations such as interchange, skewing and reversal by presenting an algorithm to enhance data locality in numerical algorithms (that use matrices). A mathematical formulation of data locality is presented.

References-found: 23

