URL: http://www.cs.rochester.edu/research/trains/aaais98/SikorskiAAAIS98.ps.gz
Refering-URL: http://www.cs.rochester.edu/stats/oldmonths/1998.03/docs-name.html
Root-URL: 
Email: sikorski@cs.rochester.edu  
Title: Improving Dialogue Annotation Reliability  
Author: Teresa Sikorski 
Address: Rochester, New York 14627-0226  
Affiliation: Department of Computer Science University of Rochester  
Abstract: Data collection and annotation represent the most significant portion of the effort involved in building statistical models of dialogue. We must be able to annotate reliably if there is any hope of building predictive statistical models. This paper describes the annotation process being used to tag the TRAINS-93 corpus with dialogue acts, and measures we have taken to improve inter-annotator reliability. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J., and Core, M. </author> <title> Draft 1997. DAMSL: Dialog annotation markup in several layers. </title> <note> Available from http://www.cs.rochester.edu:80/ research/trains/annotation. </note>
Reference-contexts: The DAMSL Annotation Scheme The first step in the annotation process was to decide on an appropriate set of tags. DAMSL (Dialogue Act Markup in Several Layers) is a dialogue annotation scheme that provides tags for several characteristics of utterances that indicate their role in the dialogue <ref> (Allen & Core Draft 1997) </ref>.
Reference: <author> Carletta, J. </author> <year> 1996. </year> <title> Assessing agreement on classification tasks: The kappa statistic. </title> <note> Computational Linguistics 22(2). </note>
Reference-contexts: The reconciled version of the annotated dialogue is then used as the correctly tagged dialogue. The reliability of a dialogue tagging scheme such as DAMSL is generally evaluated with the kappa statistic, which measures agreement between annotators, while accounting for chance agreement <ref> (Carletta 1996) </ref>. The current rule of thumb applied is that kappa scores must be above 0.67 for tentative conclusions to be drawn, with above 0.8 considered reliable.
Reference: <author> Heeman, P., and Allen, J. </author> <year> 1995. </year> <title> The TRAINS-93 dialogues. </title> <type> TRAINS Technical Note 94-2, </type> <institution> Department of Computer Science, University of Rochester. </institution>
Reference: <author> Sikorski, T. </author> <year> 1998. </year> <title> Applying the DAMSL tagset in the TRAINS-93 domain. </title> <type> TRAINS Technical Note 98-1, </type> <institution> Department of Computer Science, University of Rochester. </institution>
Reference-contexts: inter annotator reliability to an acceptable level are: * The DAMSL manual was revised in an attempt to make crisper distinctions between tags. * An annotation manual specific to the TRAINS-93 corpus was written that explicitly sets out the "correct" tags for common and problematic phenomena within the TRAINS dialogues <ref> (Sikorski 1998) </ref>. * A feature was added to the annotation tool that causes warnings to be issued when unlikely tags are assigned. Domain-specific Annotation Instructions The DAMSL manual is fairly general, describing a tagging scheme appropriate for dialogues collected in various domains.
References-found: 4

