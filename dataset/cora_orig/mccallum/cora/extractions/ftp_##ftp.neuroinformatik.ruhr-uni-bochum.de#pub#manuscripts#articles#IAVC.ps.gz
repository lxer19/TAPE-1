URL: ftp://ftp.neuroinformatik.ruhr-uni-bochum.de/pub/manuscripts/articles/IAVC.ps.gz
Refering-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Root-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Title: Determination of face position and pose with a learned representation based on labelled graphs  
Author: N. Krugery, M. Potzschy, C. v.d. Malsburgyz Ruhr-Universitat Bochum, 
Degree: Accepted for  
Address: D-44780 Bochum, Germany  Los Angeles, CA 90089-2520, USA  
Affiliation: Institut fur Neuroinformatik,  University of Southern California, Dept. of Computer Science and Section for Neurobiology,  "Image and Vision Computing"  
Abstract: We present a new system for the automatic determination of the position, size and pose of the head of a human figure in a camera image. The system is an extension of the well-known face recognition system [15] to pose estimation. The pose estimation system is characterized by a certain reliability and speed. We improve this performance and speed with the help of statistical estimation methods. In order to make these applicable, we reduce the originally very high dimensionality of our system with the help of a number of a priori principles. We discuss a possible extension of the learning algorithm aiming an autonomous object recognition system at the end of the paper. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.J. Beymer. </author> <title> Face Recognition under Varying Pose. </title> <booktitle> Proceedings of the International Workshop on Automatic Face- and Gesture recognition. </booktitle> <address> Zurich 1995. </address>
Reference-contexts: In comparison to this system our representation is partially learned and deals with a much higher variability of the sizes and poses. The pose estimation system in <ref> [1] </ref> also deals with poses with a variation of 25 degrees differing from frontal faces without significant size differences. The face representation is based on a large amount of local templates based on the pixel values in local areas. <p> The face representation is based on a large amount of local templates based on the pixel values in local areas. The position of the local templates (eyes and nose) are defined by hand. Matching is accelerated by a coarse to fine strategy. But still the pose estimation in <ref> [1] </ref> is much slower and needs 10-15 minutes on a Sparc 2. 7 Outlook Currently we are working on a real-time face-spotting system based on the algorithm described here. This system shall extract a size-normalized frontal face from a sequence of images of a person moving towards a camera.
Reference: [2] <author> J. Buhmann, M. Lades, C vd. Malsburg. </author> <title> Size and Distortion Invariant Object Recognition by Hierarchical Graph Matching. </title> <booktitle> Proceedings of the IJCNN International Joint Conference on Neural Networks, </booktitle> <year> 1990. </year> <month> p:411-416. </month>
Reference-contexts: The total similarity between graphs is calculated as the sum of two terms, the average of individual node similarities just computed, and a (negatively taken) measure for relative graph distortion, for details see <ref> [2, 11] </ref>. The complete graph matching process used in this paper proceeds in four steps.
Reference: [3] <author> J.D. Daugman. </author> <title> Complete discrete 2-d Gabor transforms by neural networks for image analysis and compression. </title> <journal> IEEE Trans. Acoustics, Speech, and Signal Processing, </journal> <volume> 36 </volume> <pages> 1169-1179, </pages> <year> 1988. </year>
Reference-contexts: The total model for heads we call a collection of bunch graphs. Jets are derived from a set of linear filter operations in the form of convolutions of the image I (~x) with a set of Gabor wavelets 1 ~ k (cf. <ref> [3] </ref>), whose wavelength and orientation are parameterized by ~ k. The ~ k take the form of plane waves restricted by Gaussian envelopes function (see figure 2a).
Reference: [4] <author> D. </author> <title> Field. What is the Goal of Sensory Coding?. </title> <journal> Neural Computation, </journal> <volume> vol. 6, no. 4, </volume> <pages> pp. 561-601, </pages> <year> 1994. </year>
Reference-contexts: Therefore we assume that for this problem a clustering-like selection of jets is more appropriate than PCA. For a more detailed discussion of the problems and restriction of PCA we refer to <ref> [4] </ref>. 3.2 Principles for Selecting Nodes In this subsection we define a learning algorithm for a suitable subgraph which only contains the nodes important for head finding and pose identification. <p> Based on the idea of reduction of dimensionality by general a priori principles (as described in this paper) and the concept of sparse coding (discussed in <ref> [4] </ref>) we are currently working on features which are more flexible and able to express the "essence" of landmarks, representing for instance, an eye brow as a horizontal line which is slightly bending 9 downwards [9].
Reference: [5] <author> S.L.S. Jacoby, J.S. Kowalik, J.T. Pizzo. </author> <title> Iterative Methods for Nonlinear Optimization Problems. </title> <address> Englewood Cliffs, NJ, </address> <publisher> Prentice-Hall 1972. </publisher>
Reference: [6] <author> J.P. Jones and L.A. Palmer. </author> <title> An evaluation of the two-dimensional gabor filter model of simple receptive fields in cat striate cortex. </title> <journal> J. Neurophysiol., </journal> <volume> 58(6) </volume> <pages> 1233-1258, </pages> <year> 1987. </year>
Reference-contexts: As for the landmarks themselves there are two main differences: Firstly, the linear transformation based on Gabor filters as basis feature is more biologically plausible than those filters created by a PCA <ref> [6] </ref>. Secondly, PCA is exclusively data-driven, i.e., applied to instances of a certain landmark it leads to a special set of filters which is independent of the task to be solved (e.g., head finding and pose discrimination).
Reference: [7] <author> D. Koller, K. Daniilidis, , H.H. </author> <title> Nagel; Model-Based Tracking in Monocular Image Sequences of Road Traffic Scenes; International Journal of Computer Vision 10:3 (1993) 257-281. </title>
Reference-contexts: As basic local image features we use Gabor-based wavelets. As others before us, we treat the set of wavelets centered on one image point as a unit which we call a "jet". Like many other object recognition systems (e.g., <ref> [10, 7] </ref>), ours is based on object models (or rather, models for two-dimensional aspects of objects as they appear in the image).
Reference: [8] <author> N. Kruger. </author> <title> Learning Weights in Discrimination Functions using a priori Constraints, </title> <note> DAGM 1995. (See also WWW: http://www.neuroinformatik.ruhr-uni-bochum.de/ini/VDM/PUB-LIST/1995/html/pub95.html) </note>
Reference-contexts: These weights are learned by an algorithm introduced in <ref> [8] </ref> which also makes use of derived principles based on P1. 2 E.g., the number of possible subgrids is 2 N with N = P p;m N G (p; m), in our case this would be approximately 2 (3345) = 2 405 3.1 Selection of Jets In our bunch graph approach,
Reference: [9] <author> N. Kruger, G. Peters. </author> <title> Object Recognition with Banana Wavelets. </title> <note> Submitted to ESANN97. </note>
Reference-contexts: priori principles (as described in this paper) and the concept of sparse coding (discussed in [4]) we are currently working on features which are more flexible and able to express the "essence" of landmarks, representing for instance, an eye brow as a horizontal line which is slightly bending 9 downwards <ref> [9] </ref>. Such a representation will reduce memory requirements compared to our bunch--of-jets approach, may increase speed of matching, and could be more reliable, as the system could more narrowly focus on essential features. <p> We believe that with a more extensive application of the concepts introduced in this paper, a system could autonomously learn the necessary representations and mechanisms to deal with arbitrary objects in complex scenes. In <ref> [9] </ref> we already made one more step towards this demanding goal. Acknowledgement We wish to thank Laurenz Wiskott, Michael Lyons, Thomas Maurer, Ladan Shams, Jan Vorbruggen and Gabi Peters for fruitful disussions. We thank Michael Rinne for his great help during the implementation of the algorithms.
Reference: [10] <author> A. Lanitis, C.J. Taylor, T.F.Cootes, </author> <title> T.Ahmed; Automatic Interpretation of Human Faces and Hand Gestures Using Flexible Models. </title> <booktitle> Proceedings of the International Workshop on Automatic Face- and Gesture recognition. </booktitle> <address> Zurich 1995. </address>
Reference-contexts: As basic local image features we use Gabor-based wavelets. As others before us, we treat the set of wavelets centered on one image point as a unit which we call a "jet". Like many other object recognition systems (e.g., <ref> [10, 7] </ref>), ours is based on object models (or rather, models for two-dimensional aspects of objects as they appear in the image). <p> Besides, a quantitative comparison is hardly possible, because the cpu-time needed, the variability of sizes and poses considered, and the number of poses being separated in [13] remain unclear. The pose estimation system <ref> [10] </ref> determines the pose in a range of 25 degrees differing from frontal pose with slight variations in size. It is based on a manually defined grey-level model of a frontal face in which rotation is parameterized.
Reference: [11] <author> M. Lades, J.C. Vorbruggen, J. Buhmann, J. Lange, C. von der Malsburg, R.P. Wurtz, W. Konen. </author> <title> Distortion Invariant Object Recognition in the Dynamik Link Architecture. </title> <journal> IEEE Transactions on Computers 1993, </journal> <volume> 42(3) </volume> <pages> 300-311. </pages>
Reference-contexts: 1 Introduction In this paper we deal with two problems. Firstly, we describe a pose estimation algorithm based on Elastic Graph Matching (EGM) <ref> [11, 15] </ref>. The algorithm is an extension of the face representation introduced in [15] to the problem of pose estimation, in [15] the poses of faces is assumed to be known. Secondly, we improve the performance and speed of the pose estimation algorithm by learning. <p> to 5 frequencies and 8 orientations) rendered 1 We use the term "Gabor wavelets" or "set of Gabor wavelets" as a shorthand for "a set of wavelets derived from a Gabor filter as mother wavelet". 2 by all wavelets centered at a given position of the image (see figure 2b) <ref> [11] </ref>. Due to the spatial extent of the wavelets, jets describe a local area around their position. A bunch B of jets taken at the same landmark (that is, at corresponding positions) of different faces forms a generalized representation of this landmark. <p> Our notation for the various objects and collections of objects in our model domain is given in the upper part of table 1. The Algorithm for Pose Estimation A bunch graph is adapted to an image by Elastic Graph Matching (EGM) <ref> [11, 15] </ref>. For this, a graph is compared node by node to jet information extracted at the current node position from the image and the total similarity is optimized by shifting, scaling and deforming the graph. <p> To calculate graph similarities a similarity measure between two jets has to be defined. At different stages of the match procedure we use two different jet similarity measures, magnitude-similarity S mag (J ; J 0 ) <ref> [11] </ref> and phase-similarity S pha (J ; J 0 ) [15, 16]. The phase similarity is more sensitive to spatial displacements and gives, in addition to the similarity value, an estimate of the displacement ~ d which allows more precise matching of landmarks. <p> The total similarity between graphs is calculated as the sum of two terms, the average of individual node similarities just computed, and a (negatively taken) measure for relative graph distortion, for details see <ref> [2, 11] </ref>. The complete graph matching process used in this paper proceeds in four steps.
Reference: [12] <author> T. Maurer, C. von der Malsburg. </author> <title> Tracking and Learning Graphs and Pose on Image Sequences of Faces. </title> <booktitle> Proceedings of the 2d Int. Conf. on Automatic Face- and Gesture-Recognition 1996. </booktitle>
Reference-contexts: Here we made this system able to deal with arbitrary poses. A system which can determine an arbitrary pose more precisely in the context of image sequences within the very same framework of EGM and jets is described in <ref> [12] </ref>, where in contrast to our approach the faces have to be normalized according to size and the initial pose in the sequence has to be known. Therefore the pose estimation system described here can be used as an initial step of the system in [12]. In [12] head image sequences <p> and jets is described in <ref> [12] </ref>, where in contrast to our approach the faces have to be normalized according to size and the initial pose in the sequence has to be known. Therefore the pose estimation system described here can be used as an initial step of the system in [12]. In [12] head image sequences starting with the frontal face view the landmarks are placed automatically in the start frame similar to the algorithm described here and then tracked from frame to frame. The pose is determined simultaneously by integrating the motion of the landmarks. <p> is described in <ref> [12] </ref>, where in contrast to our approach the faces have to be normalized according to size and the initial pose in the sequence has to be known. Therefore the pose estimation system described here can be used as an initial step of the system in [12]. In [12] head image sequences starting with the frontal face view the landmarks are placed automatically in the start frame similar to the algorithm described here and then tracked from frame to frame. The pose is determined simultaneously by integrating the motion of the landmarks.
Reference: [13] <author> A. Pentland, B. Moghaddam, T. Starner. </author> <title> View-based and Modular Eigenspaces for Face Recognition. </title> <booktitle> IEEE Conference on Computer Vision and Pattern Recognition. </booktitle> <year> 1994. </year>
Reference-contexts: Doing so with different subjects leads to a bunch of face graphs of all possible poses, which can be sorted to build the bunch graphs for new pose classes. In this way our system can be extended to new poses automatically. In <ref> [13] </ref> PCA is used to discriminate poses. This system uses local Eigen-features. Manually selected landmarks, such as eyes and mouth, are used to apply a local PCA. In comparison to [13] we are able to learn the important landmarks for a certain task from a large set of landmarks. <p> In this way our system can be extended to new poses automatically. In <ref> [13] </ref> PCA is used to discriminate poses. This system uses local Eigen-features. Manually selected landmarks, such as eyes and mouth, are used to apply a local PCA. In comparison to [13] we are able to learn the important landmarks for a certain task from a large set of landmarks. <p> Besides, a quantitative comparison is hardly possible, because the cpu-time needed, the variability of sizes and poses considered, and the number of poses being separated in <ref> [13] </ref> remain unclear. The pose estimation system [10] determines the pose in a range of 25 degrees differing from frontal pose with slight variations in size. It is based on a manually defined grey-level model of a frontal face in which rotation is parameterized.
Reference: [14] <author> C. von der Malsburg. </author> <title> The correlation theory of brain function. </title> <type> Intern. Rep., 81-2, </type> <institution> MPI Bio-physikalische Chemie, Gottingen, </institution> <year> 1981. </year> <title> Repr. </title> <editor> in E. Domany, J.L. van Hemmen, and K. Schulten, eds, </editor> <booktitle> Models of Neural Networks II, </booktitle> <pages> pp. 95-119. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1994. </year>
Reference: [15] <author> L. Wiskott, J.-M. Fellous, N. Kruger, C. von der Malsburg. </author> <title> Face Recognition and Gender Determination. </title> <booktitle> Proceedings of the International Workshop on Automatic Face- and Gesture recognition. </booktitle> <address> Zurich 1995. </address> <month> 11 </month>
Reference-contexts: 1 Introduction In this paper we deal with two problems. Firstly, we describe a pose estimation algorithm based on Elastic Graph Matching (EGM) <ref> [11, 15] </ref>. The algorithm is an extension of the face representation introduced in [15] to the problem of pose estimation, in [15] the poses of faces is assumed to be known. Secondly, we improve the performance and speed of the pose estimation algorithm by learning. <p> 1 Introduction In this paper we deal with two problems. Firstly, we describe a pose estimation algorithm based on Elastic Graph Matching (EGM) [11, 15]. The algorithm is an extension of the face representation introduced in <ref> [15] </ref> to the problem of pose estimation, in [15] the poses of faces is assumed to be known. Secondly, we improve the performance and speed of the pose estimation algorithm by learning. <p> 1 Introduction In this paper we deal with two problems. Firstly, we describe a pose estimation algorithm based on Elastic Graph Matching (EGM) [11, 15]. The algorithm is an extension of the face representation introduced in <ref> [15] </ref> to the problem of pose estimation, in [15] the poses of faces is assumed to be known. Secondly, we improve the performance and speed of the pose estimation algorithm by learning. <p> This representation of objects applied to faces combined with EGM allows us to determine the pose and position of faces. Starting from this extension of the original face recognition system described in <ref> [15] </ref> to pose estimation we optimize the representation of faces by statistical methods. We want to achieve an optimal but fl Supported by EC grant ERBCHRX-CT-930097, an HFSPO grant and US Army Research Lab grant (01/93/K-0109). sparse representation of faces of different sizes and poses. <p> These labels are bunches of jets, each derived from the image of a different person, a bunch thus covering a variety of forms a single landmark may take. We call this structure a bunch graph, an idea first introduced in <ref> [15] </ref> (where, however, the term general face knowledge was used). The total model for heads we call a collection of bunch graphs. <p> Our notation for the various objects and collections of objects in our model domain is given in the upper part of table 1. The Algorithm for Pose Estimation A bunch graph is adapted to an image by Elastic Graph Matching (EGM) <ref> [11, 15] </ref>. For this, a graph is compared node by node to jet information extracted at the current node position from the image and the total similarity is optimized by shifting, scaling and deforming the graph. <p> To calculate graph similarities a similarity measure between two jets has to be defined. At different stages of the match procedure we use two different jet similarity measures, magnitude-similarity S mag (J ; J 0 ) [11] and phase-similarity S pha (J ; J 0 ) <ref> [15, 16] </ref>. The phase similarity is more sensitive to spatial displacements and gives, in addition to the similarity value, an estimate of the displacement ~ d which allows more precise matching of landmarks. <p> Since the fourth step is relatively fast, we are able to perform it on the full set of nodes and jets without significant increase of computational time. The output of the pose estimation system can be used as input to the face recognition system described in <ref> [15] </ref>, in which the pose of a face was assumed to be known. 3 Formalization of the Principles of Learning We now proceed to formalize the principles discussed in the introduction. For each pose and for each matching step we would like to have sparse but efficient bunch graphs. <p> In the past <ref> [15] </ref> we based the selection of suitable sample images on intuitive criteria such as balancing the data base in terms of gender or race, hoping to cover the space of eye jets, nose jets, etc. appropriately while avoiding redundancy. <p> The improvement of speed is caused from the sparseness of the learned representation. 6 Comparison to other Pose Estimation Systems We improved the representation of faces described in <ref> [15] </ref> by introducing our learning algorithm and we applied this representation to the problem of head finding, size normalization and pose estimation 8 over a wide range of sizes (three octaves) and poses (180 degree rotation in depth). In [15] the pose of a face is assumed to be known. <p> Pose Estimation Systems We improved the representation of faces described in <ref> [15] </ref> by introducing our learning algorithm and we applied this representation to the problem of head finding, size normalization and pose estimation 8 over a wide range of sizes (three octaves) and poses (180 degree rotation in depth). In [15] the pose of a face is assumed to be known. Here we made this system able to deal with arbitrary poses.

References-found: 15

