URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/FIAT-94.ps
Refering-URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/tech_papers.html
Root-URL: 
Email: rhj@idt.unit.no  
Title: Digital Television Archives Combining Computer Technology and Video  
Author: Rune Hjelsvold 
Date: November 25, 1994  
Affiliation: Department of Computer Systems and Telematics Norwegian Institute of Technology  
Abstract: Television archives play an important in giving their users easy access to the huge amount of video information that have been broadcast. In this paper we discuss some of the problems faced today, and we discuss how digital video and advances in computer technology can be used to overcome some of these problems. The paper also gives a short description of digital television archive prototype developed in a project between the Norwegian Institute of Technology and the Norwegian Broadcasting Corporation (NRK). 
Abstract-found: 1
Intro-found: 1
Reference: [Gal91] <author> D. Le Gall. </author> <title> MPEG: A Video Compression Standard for Multimedia Applications. </title> <journal> Communications of the ACM, </journal> <volume> 32(4), </volume> <year> 1991. </year>
Reference-contexts: second (fps) while the frame rate for the American NTSC standard is 30 fps. 2 Several digital video formats exist ranging from low quality formats such as the Quarter-CIF (QCIF) the one of the two video format used in teleconferencing [Lio91] to high-definition television (HDTV) standards which gives high-quality video <ref> [Gal91] </ref>. 3 JPEG, the ISO standard for still image compression [Wal91], takes advantage of spatial redundancy. 4 MPEG, the ISO standard for video compression [Gal91], and H.261, the CCITT standard for video compression [Lio91], take advantage of both spatial and temporal redundancies. 2 boxes and optical tape stations can be used <p> formats such as the Quarter-CIF (QCIF) the one of the two video format used in teleconferencing [Lio91] to high-definition television (HDTV) standards which gives high-quality video <ref> [Gal91] </ref>. 3 JPEG, the ISO standard for still image compression [Wal91], takes advantage of spatial redundancy. 4 MPEG, the ISO standard for video compression [Gal91], and H.261, the CCITT standard for video compression [Lio91], take advantage of both spatial and temporal redundancies. 2 boxes and optical tape stations can be used to store the least frequently used video information.
Reference: [Gra93] <author> Silicon Graphics. </author> <title> Challenge network resource servers data sheet, </title> <year> 1993. </year>
Reference-contexts: To handle all these data streaming through the system one has to introduce parallelism. Large scale video servers are appearing in the market today. Three different approaches have been introduced: * Parallel Servers, such as the Silicon Graphics Challenge <ref> [Gra93] </ref>, are homogeneous and tightly coupled servers with possibly several processors connected to each other via high-capacity internal busses.
Reference: [Her91] <author> R.G. Herrtwich, </author> <title> editor. Network and Operting System Support for Digital Audio and Video. </title> <booktitle> Second International Workshop, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: All components within a video information system should support this isochronity including the video database, the communications network and the viewing station. Much research is being performed regarding network and operating system support for video data - e.g. <ref> [Her91] </ref> and [VR92]. Less research has, however, been devoted to database support of video. Oracle is one of the first commercial database suppliers announcing support for video data in their Oracle Media Server [LL94].
Reference: [Hje94] <author> R. Hjelsvold. </author> <title> Video Information Contents and Architecture. </title> <booktitle> In Proceedings of the 4th International Conference on Extending Database Technology, </booktitle> <address> Cambridge, UK, </address> <month> March 28-31 </month> <year> 1994. </year>
Reference-contexts: Our model provides a generic framework that can be tailored to different application domains. 3.2 Video Indexing The structure of a video document captures some aspects of the video material but is not suited as a representation of every characteristic of the material. As discussed in [Smi92] and <ref> [Hje94] </ref> it should be possible to make detailed descriptions of the content of the video material which are not necessarily directly linked to structural components but more often to arbitrary frame sequences.
Reference: [KHT91] <author> W. Kameyama, T. Hanamura, and H. Tominaga. </author> <title> A Proposal of Multimedia Document Architecture and Video Document Architecture. </title> <booktitle> In Proceedings of ICC '91 The International Conference on Communication Conference Record, </booktitle> <address> Denver, USA, </address> <year> 1991. </year> <month> 7 </month>
Reference-contexts: This is because a single frame spans a very short interval of time and because there are so many individual frames even in a quite short video document (the Eu- ropean video standard, PAL, results for instance in 25 frames per second). [RD89] and <ref> [KHT91] </ref> strongly emphasize the need for some sort of structuring method. From our experiments [Mer93] we have learned that abstractions such as scenes and news items make it easier for the user to refer to some specific video information items and easier to comprehend its contents.
Reference: [KO93] <author> Y. Tonomura K. Otsuji. </author> <title> Projection detecting filter for video cut detection. </title> <booktitle> In Proceedings of the first ACM International Conference on Multimedia, </booktitle> <address> Anaheim, </address> <month> August 1-6 </month> <year> 1993. </year>
Reference-contexts: However, it seems clear that if all descriptions are to be made after the video material has been produced it would still be a rather time consuming process. Work has been done to try to automatically detect shot transitions, see for instance [ZKS93] or <ref> [KO93] </ref>. The methods proposed so far are not reliable, partly because of special effects used to smooth out transitions. This kind of information is precisely known some production stage and it would be a superior solution to preserve this information during the lifetime of the video material.
Reference: [Lio91] <author> M. Liou. </author> <title> Overview of the px64 kbit/s Video Coding Standard. </title> <journal> Communications of the ACM, </journal> <volume> 32(4), </volume> <year> 1991. </year>
Reference-contexts: The size of the video stream depends on the quality of the video format 2 that is used. The Common Intermediate Format (CIF) used in teleconferencing is a medium quality format that can be used as an illustrative example. The uncompressed bit rates for transmitting CIF is 36.45 Mbit/s <ref> [Lio91] </ref>. 1 GB disk space, which most users today find quite spacious, can only store three and a half minutes of such a video stream. The data volumes that uncompressed video generates cannot easily be handled in the computer systems. Fortunately, video data is redundant in two dimensions. <p> The analogue European video standard, PAL, specifies 25 frames per second (fps) while the frame rate for the American NTSC standard is 30 fps. 2 Several digital video formats exist ranging from low quality formats such as the Quarter-CIF (QCIF) the one of the two video format used in teleconferencing <ref> [Lio91] </ref> to high-definition television (HDTV) standards which gives high-quality video [Gal91]. 3 JPEG, the ISO standard for still image compression [Wal91], takes advantage of spatial redundancy. 4 MPEG, the ISO standard for video compression [Gal91], and H.261, the CCITT standard for video compression [Lio91], take advantage of both spatial and temporal <p> the two video format used in teleconferencing <ref> [Lio91] </ref> to high-definition television (HDTV) standards which gives high-quality video [Gal91]. 3 JPEG, the ISO standard for still image compression [Wal91], takes advantage of spatial redundancy. 4 MPEG, the ISO standard for video compression [Gal91], and H.261, the CCITT standard for video compression [Lio91], take advantage of both spatial and temporal redundancies. 2 boxes and optical tape stations can be used to store the least frequently used video information.
Reference: [LL94] <author> A. Laursen and B. Linder. </author> <title> Delivering Realtime Audio/Video with the Oracle Media Server. </title> <booktitle> In Proceedings of the EOUG Oracle User Forum 94, </booktitle> <address> Maastricth, Netherlands, </address> <month> April 17-20 </month> <year> 1994. </year>
Reference-contexts: Much research is being performed regarding network and operating system support for video data - e.g. [Her91] and [VR92]. Less research has, however, been devoted to database support of video. Oracle is one of the first commercial database suppliers announcing support for video data in their Oracle Media Server <ref> [LL94] </ref>. Even though Oracle Media Server is supported by the Oracle7 DBMS, it is not an integrated part of the DBMS. Much research and developments have to be done before DBMS's really manage video data.
Reference: [MD89] <author> W.E. Mackay and G. Davenport. </author> <title> Virtual Video Editing In Interactive Multimedia Applications. </title> <journal> Communications of the ACM, </journal> <volume> 32(7), </volume> <year> 1989. </year>
Reference-contexts: These annotations are independent from any structural components. Thus, the thematic indexes complement the structural description of VideoDocuments. 3.3 Sharing and Reuse of Video Mate <p>- rial As recognised in <ref> [MD89] </ref>, the same basic video material may be used in several different video documents.
Reference: [Mer93] <author> P. Merok. </author> <title> Data Models for Digital Film and Video Archives. </title> <type> Master's thesis, </type> <institution> Norwegian Institute of Technology, </institution> <year> 1993. </year> <note> In Norwegian. </note>
Reference-contexts: From our experiments <ref> [Mer93] </ref> we have learned that abstractions such as scenes and news items make it easier for the user to refer to some specific video information items and easier to comprehend its contents. Other researchers have shown that video information browsing is difficult (see [Ste91]).
Reference: [Mon81] <author> J. Monaco. </author> <title> How to Read a Film. The Art, Technology, Language, History and Theory of Film and Media. </title> <publisher> Oxford University Press, </publisher> <year> 1981. </year> <title> [nCU94] nCUBE. Video-on-demand, 1994. A two pages' information sheet from nCUBE Deutschland, </title> <address> Hanauer Strasse 56, D-80992 Munic, Germany. </address>
Reference-contexts: Other researchers have shown that video information browsing is difficult (see [Ste91]). Our experiments show that structural abstractions give valuable support to video browsers. The structure part of our model is inspired from film theory <ref> [Mon81] </ref> and work based on segmentation of video material. It is built around the concept of a StructuralComponent which has an associated Frame- Sequence of video material. Four different types of StructuralComponents are defined providing a hierarchical structure of CompoundUnits, Sequences, Scenes and Shots.
Reference: [Par91] <institution> Parallax Graphics, Inc. </institution> <note> XVideo User's Guide, </note> <year> 1991. </year>
Reference-contexts: The player is implemented in C++ and C and the interface is based on the X11 window system. No commercial DBMS software is currently being used to implement the prototype. The video player runs on a SUN SPARCstation LX where a Parallax XVideo board <ref> [Par91] </ref> is installed. A JPEG chip (C-CUBE) resides on the board and is used to support real-time video compression. Two 2.1 GB Seagate Barracuda hard disks are connected to the workstation and provide the storage facility for compressed digital video. The workstation is running internet protocols (TCP/IP) on Ethernet.
Reference: [RD89] <author> B. Rubin and G. Davenport. </author> <title> Structured Content Modeling for Cinematic Information. </title> <journal> SIGCIHI Bulletin, </journal> <volume> 21(2), </volume> <month> October </month> <year> 1989. </year>
Reference-contexts: This is because a single frame spans a very short interval of time and because there are so many individual frames even in a quite short video document (the Eu- ropean video standard, PAL, results for instance in 25 frames per second). <ref> [RD89] </ref> and [KHT91] strongly emphasize the need for some sort of structuring method. From our experiments [Mer93] we have learned that abstractions such as scenes and news items make it easier for the user to refer to some specific video information items and easier to comprehend its contents.
Reference: [Ske93] <author> S. Skeide. </author> <title> High-Quality Video Server. </title> <type> Master's thesis, </type> <institution> Norwegian Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: This work was primarily done by Sigurd Skeide <ref> [Ske93] </ref> and it was partly based on source code developed by Norwegian Telecom Research. The player is implemented in C++ and C and the interface is based on the X11 window system. No commercial DBMS software is currently being used to implement the prototype.
Reference: [Smi92] <author> T.G.A. Smith. </author> <title> If You Could See What I Mean... Descriptions of Video in an Anthropologist's Notebook. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <year> 1992. </year>
Reference-contexts: Our model provides a generic framework that can be tailored to different application domains. 3.2 Video Indexing The structure of a video document captures some aspects of the video material but is not suited as a representation of every characteristic of the material. As discussed in <ref> [Smi92] </ref> and [Hje94] it should be possible to make detailed descriptions of the content of the video material which are not necessarily directly linked to structural components but more often to arbitrary frame sequences.
Reference: [Ste91] <author> S.M. Stevens. </author> <title> Next Generation Network and Operating System Requirements for Continuous Time Media. </title> <booktitle> In Proceedings of the Second International Workshop for Network and Operating System Support for Digital Audio and Video, </booktitle> <address> Heidelberg, Germany, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: From our experiments [Mer93] we have learned that abstractions such as scenes and news items make it easier for the user to refer to some specific video information items and easier to comprehend its contents. Other researchers have shown that video information browsing is difficult (see <ref> [Ste91] </ref>). Our experiments show that structural abstractions give valuable support to video browsers. The structure part of our model is inspired from film theory [Mon81] and work based on segmentation of video material.
Reference: [Tir94] <author> W.R. Tirman. </author> <title> Strategies and capabilities in video services provisioning. </title> <type> Technical re-port, </type> <institution> Digital Equipment Corporation, </institution> <month> February 8 </month> <year> 1994. </year>
Reference-contexts: The busses will also connect the processors to network interface cards and storage drives. * Distributed Servers, such as the Digital video server <ref> [Tir94] </ref>, consist of individual nodes connected via a more or less general communications network.
Reference: [VR92] <author> P. Venkat Rangan, </author> <title> editor. Network and Operating System Support for Digital Audio and Video. </title> <booktitle> Third International Workshop, </booktitle> <address> La Jolla, California, USA, </address> <month> Novemer </month> <year> 1992. </year>
Reference-contexts: All components within a video information system should support this isochronity including the video database, the communications network and the viewing station. Much research is being performed regarding network and operating system support for video data - e.g. [Her91] and <ref> [VR92] </ref>. Less research has, however, been devoted to database support of video. Oracle is one of the first commercial database suppliers announcing support for video data in their Oracle Media Server [LL94].
Reference: [Wal91] <author> G.K. Wallace. </author> <title> The JPEG Still Picture Compression Standard. </title> <journal> Communications of the ACM, </journal> <volume> 32(4), </volume> <year> 1991. </year>
Reference-contexts: standard is 30 fps. 2 Several digital video formats exist ranging from low quality formats such as the Quarter-CIF (QCIF) the one of the two video format used in teleconferencing [Lio91] to high-definition television (HDTV) standards which gives high-quality video [Gal91]. 3 JPEG, the ISO standard for still image compression <ref> [Wal91] </ref>, takes advantage of spatial redundancy. 4 MPEG, the ISO standard for video compression [Gal91], and H.261, the CCITT standard for video compression [Lio91], take advantage of both spatial and temporal redundancies. 2 boxes and optical tape stations can be used to store the least frequently used video information.
Reference: [ZKS93] <author> H.J. Zhang, A. Kankanhalli, </author> <title> and S.W. Smoliar. Automatic partitioning of full-motion video. Multimedia Systems, </title> <booktitle> 1(1), 1993. </booktitle> <volume> 8 9 10 </volume>
Reference-contexts: However, it seems clear that if all descriptions are to be made after the video material has been produced it would still be a rather time consuming process. Work has been done to try to automatically detect shot transitions, see for instance <ref> [ZKS93] </ref> or [KO93]. The methods proposed so far are not reliable, partly because of special effects used to smooth out transitions. This kind of information is precisely known some production stage and it would be a superior solution to preserve this information during the lifetime of the video material.
References-found: 20

