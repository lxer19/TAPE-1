URL: http://www.cs.colostate.edu/~ftppub/TechReports/1993/tr-131.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Title: Domain Based Testing Increasing Test Case Reuse  
Affiliation: Department of Computer Science  Colorado State University  
Abstract: Anneliese von Mayrhauser, Richard Mraz, Jeff Walls, and Pete Ocken Technical Report CS-93-131 December 10, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman, </author> <booktitle> Compilers : Principles, Techniques, and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: of a system. (2) Individual Manipulation of Object (s): In Command Languages these would be single command templates. (3) Objective Attribute Value Selection: In Command Languages this refers to parameter value selection. 2 This should not be confused with Domain Testing as described in [3]. 3 VanWijngaarden grammars, Attribute grammars <ref> [1] </ref>. 4 This has been confirmed in private conversation with J. Hutchison and J. Schlauer, as well as our own experience. 2 The advantages of this approach are: 1. Separation of concerns simplifies test suite generation at each step 2. Reusability becomes possible at all three levels of refinement.
Reference: [2] <author> Anneliese von Mayrhauser and Steward Crawford-Hines, </author> <title> Automated Testing Support for a Robot Tape Library, </title> <booktitle> Proceedings of the Fourth International Software Reliability Engineering Conference, </booktitle> <month> November </month> <year> 1993, </year> <pages> pp. 6-14. </pages>
Reference-contexts: Script rules are valid for the duration of a command sequencing rule. To illustrate, the MOUNT DISMOUNT sequence is annotated with script parameter selection rules. 5 We experimented with a prototype <ref> [2] </ref> that used no sequencing rules and found that only about 30%-40% of the test cases were meaningful without sequencing rules. 7 Notation Description p* Choose any valid value for p p Choose a previously bound value for p p- Choose any except a previously bound value for p Table 3:
Reference: [3] <author> Boris Beizer, </author> <title> Software Testing Techniques. </title> <journal> VanNostrand, </journal> <note> second edition, </note> <year> 1990. </year>
Reference-contexts: actions on logical or physical objects of a system. (2) Individual Manipulation of Object (s): In Command Languages these would be single command templates. (3) Objective Attribute Value Selection: In Command Languages this refers to parameter value selection. 2 This should not be confused with Domain Testing as described in <ref> [3] </ref>. 3 VanWijngaarden grammars, Attribute grammars [1]. 4 This has been confirmed in private conversation with J. Hutchison and J. Schlauer, as well as our own experience. 2 The advantages of this approach are: 1. Separation of concerns simplifies test suite generation at each step 2.
Reference: [4] <author> Ted J. Biggerstaff and Alan J. Perlis, </author> <title> editors, Software Reusability, Volume I : Concepts and Models, Frontier Series, </title> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction Domain Analysis supports development and use of reusable components <ref> [4] </ref> [8]. Domain Analysis provides an organized model of a family of applications. Therefore, such a model, if defined properly should also be useful to develop a structured set of test cases for testing software in such domains.
Reference: [5] <author> A. Celentano, S. Crespi Reghizzi, P. Della Vigna, C. Ghezzi, G. Gramata, and F. Savoretti, </author> <title> Compiler Testing using a Sentence Generator, </title> <journal> Software-Practice and Experience, 1980, </journal> <volume> vol. 10, </volume> <pages> pp. 897-918. </pages>
Reference-contexts: Domain Based Testing combines domain analysis and automated test suite generation using a variety of sentence generation mechanisms to generate large sets of test cases that are syntactically and semantically correct. We do not, however, rely on traditional use of grammars to generate test cases <ref> [5] </ref> [6] [7]. The main reason is that for practical problems with significant amounts of semantic information, the underlying grammars 3 quickly become unmanageable and difficult to maintain 4 .
Reference: [6] <author> A.G. Duncan and J.S. Hutchison, </author> <title> Using Attributed Grammars to Test Designs and Implementations, </title> <booktitle> Proceedings of the Fifth International Conference on Software Engineering, </booktitle> <year> 1981, </year> <pages> pp. 170-177. </pages>
Reference-contexts: Domain Based Testing combines domain analysis and automated test suite generation using a variety of sentence generation mechanisms to generate large sets of test cases that are syntactically and semantically correct. We do not, however, rely on traditional use of grammars to generate test cases [5] <ref> [6] </ref> [7]. The main reason is that for practical problems with significant amounts of semantic information, the underlying grammars 3 quickly become unmanageable and difficult to maintain 4 .
Reference: [7] <author> Susumu Fujiwara, Gregor v. Bochmann, Ferhat Khendek, Mokhtar Amalou, and Abderrazak Ghedamsi, </author> <title> Test Selection Based on Finite State Models, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> (17)6, </volume> <month> June </month> <year> 1991, </year> <pages> pp. 591-603. </pages>
Reference-contexts: Domain Based Testing combines domain analysis and automated test suite generation using a variety of sentence generation mechanisms to generate large sets of test cases that are syntactically and semantically correct. We do not, however, rely on traditional use of grammars to generate test cases [5] [6] <ref> [7] </ref>. The main reason is that for practical problems with significant amounts of semantic information, the underlying grammars 3 quickly become unmanageable and difficult to maintain 4 .
Reference: [8] <author> Charles Krueger, </author> <title> Software Reuse, </title> <journal> ACM Computing Surveys, </journal> <volume> (24)2, pp.131-183, </volume> <month> June </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Domain Analysis supports development and use of reusable components [4] <ref> [8] </ref>. Domain Analysis provides an organized model of a family of applications. Therefore, such a model, if defined properly should also be useful to develop a structured set of test cases for testing software in such domains.
Reference: [9] <author> James W. Hooper and Rowena O. Chester, </author> <title> Software Reuse : Guidelines and Methods, </title> <publisher> Plenum Press, </publisher> <year> 1991. </year>
Reference-contexts: One way to capture this information 3 is to perform a Domain Analysis. Prieto-Diaz defines Domain Analysis as, "a process by which information used in developing software systems is identified, captured, and organized with the purpose of making it reusable when creating new systems" <ref> [9] </ref>. The result of a Domain Analysis is called a Domain Model. Domain Models represent the reuse problem domain and serve as a mechanism to create instances of reusable components when building new software for the same domain. <p> Software reuse can be exploited at every phase of the software life cycle. Prieto-Diaz suggests a "reuse infrastructure" for waterfall software development (see Figure 2) <ref> [9] </ref>. Domain Models are used at each phase of software development. Feedback loops are provided to update the Domain Models. We explored the possibilities of a Domain Model for testing and automated test generation. In Figure 2, those boxes highlighted with BOLD lines denote the focus.
Reference: [10] <author> Kenneth S. Rubin and Adele Goldberg, </author> <title> "Object Behavior Analysis", </title> <journal> Communications of the ACM, </journal> <volume> 35(9), pp.48-62, </volume> <month> September </month> <year> 1992. </year> <month> 16 </month>
Reference-contexts: Command Definition 3.1. Command Language Representation 3.2. Identify Pre/Post Conditions 3.3. Identify Intracommand Rules 4. Script Definition (Command Sequencing) 4.1. Script Analysis 4.2. Script Classes 4.3. Script Rules Table 1: Domain Analysis Steps for Domain Based Testing (OOA/OOD). An attribute in OOA/OOD defines qualities and properties of the object <ref> [10] </ref>. Rarely do OOA/OOD methods refine the concept of an object's attributes. For Domain Based Testing, we found that classifying attributes more precisely simplifies test generation. Table 3 shows our detailed classification for object elements. Object elements when derived from the command language can be attributes, modes, or states.
Reference: [11] <author> StorageTek, </author> <title> StorageTek 4400 Operator's Guide, Host Software Component (VM) Rel 1.2.0, </title> <address> StorageTek, </address> <year> 1992. </year> <month> 17 </month>
Reference-contexts: Generate Command List 2. Generate Command Template 3. Generate Parameter Values 4. Export Test Case Table 4: How to Create Reusable Tests in Sleuth 10 4 Example Problem Domain Robot Tape Library StorageTek Corporation produces an Automated Cartridge System (ACS) that stores and retrieves cartridge tapes <ref> [11] </ref>. The system maintains cartridge tapes in a 12-sided storage device called a Library Storage Module (LSM). Tapes are placed in storage cells in the outer and inner panels. New tapes can be entered into an LSM through a special door called a Cartridge Access Port (CAP).
References-found: 11

