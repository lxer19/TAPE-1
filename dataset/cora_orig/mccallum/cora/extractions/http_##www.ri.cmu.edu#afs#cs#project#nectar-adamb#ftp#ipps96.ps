URL: http://www.ri.cmu.edu/afs/cs/project/nectar-adamb/ftp/ipps96.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/nectar-adamb/ftp/
Root-URL: 
Email: Email: farabe,adamb,lowekamp,eriks,starkey,pstephang@cs.cmu.edu  
Title: Dome: Parallel Programming in a Distributed Computing Environment  
Author: Jose Nagib Cotrim Arabe Adam Beguelin Bruce Lowekamp Erik Seligman Mike Starkey k and Peter Stephan 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science, Carnegie Mellon University  
Abstract: The Distributed object migration environment (Dome) addresses three major issues of distributed parallel programming: ease of use, load balancing, and fault tolerance. Dome provides process control, data distribution, communication, and synchronization for Dome programs running in a heterogeneous distributed computing environment. The parallel programmer writes a C++ program using Dome objects which are automatically partitioned and distributed over a network of computers. Dome incorporates a load balancing facility that automatically adjusts the mapping of objects to machines at runtime, exhibiting significant performance gains over standard message passing programs executing in an imbalanced system. Dome also provides checkpointing of program state in an architecture independent manner allowing Dome programs to be checkpointed on one architecture and restarted on another. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Beguelin, J. Dongarra, A. Geist, R. Manchek, and V. Sunderam. </author> <title> Recent enhancements to PVM. </title> <journal> The International Journal of Supercomputer Applications and High Performance Computing, </journal> <volume> 9(2) </volume> <pages> 108-127, </pages> <month> Summer </month> <year> 1995. </year>
Reference-contexts: Intel Corporation. k IBM Canada Laboratory. These ideas are not new; parallel computing has long been an active area of research. The fact that networks of computers are commonly being used in this fashion is new. Software tools like PVM <ref> [1, 15] </ref>, P4 [5], Linda [7], Isis [2], Express [14], and MPI [16] allow a programmer to treat a heterogeneous network of computers as a parallel machine.
Reference: [2] <author> K. Birman and K. Marzullo. </author> <title> Isis and the META project. </title> <booktitle> Sun Technology, </booktitle> <pages> pages 90-104, </pages> <month> Summer </month> <year> 1989. </year>
Reference-contexts: Intel Corporation. k IBM Canada Laboratory. These ideas are not new; parallel computing has long been an active area of research. The fact that networks of computers are commonly being used in this fashion is new. Software tools like PVM [1, 15], P4 [5], Linda [7], Isis <ref> [2] </ref>, Express [14], and MPI [16] allow a programmer to treat a heterogeneous network of computers as a parallel machine. These tools are useful, but for efficient and practical use, load balancing and fault tolerance mechanisms must be developed that will work well in a heterogeneous multi-user environment.
Reference: [3] <author> F. Bodin, P. Beckman, D. Gannon, S. Yang, S. Kesa-van, A. Malony, and B. Mohr. </author> <title> Implementing a parallel C++ runtime system for scalable parallel systems. </title> <booktitle> In Supercomputing 93, </booktitle> <year> 1993. </year>
Reference-contexts: These systems also deal with load balancing, fault tolerance, parallelism, and heterogeneity. However, they operate on a different level, overseeing the distribution and placement of processes rather than data over the network. Dome shares attributes with many other research projects. pC++ <ref> [3] </ref> extends C++ to a parallel programming language. High Performance Fortran [17] is an emerging standard for writing distributed memory parallel Fortran programs.
Reference: [4] <author> S. H. Bokhari. </author> <title> Assignment Problems in Parallel and Distributed Computing. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1987. </year>
Reference-contexts: Most of this work addresses the problems of mapping tasks to processors given a set of tasks whose requirements are known a priori and a computing system whose resources are also well known <ref> [4] </ref>. Most distributed multi-user systems have unpredictable loads, making these approaches impractical for general use. Load balancing research in operating systems focuses on similar mapping problems but where little is known about the tasks or the target system's capacities. Thus, heuristics play a large role.
Reference: [5] <author> J. Boyle, R. Butler, T. Disz, B. Glickfeld, E. Lusk, R. Overbeek, J. Patterson, and R. Stevens. </author> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart and Winston, Inc., </publisher> <year> 1987. </year>
Reference-contexts: Intel Corporation. k IBM Canada Laboratory. These ideas are not new; parallel computing has long been an active area of research. The fact that networks of computers are commonly being used in this fashion is new. Software tools like PVM [1, 15], P4 <ref> [5] </ref>, Linda [7], Isis [2], Express [14], and MPI [16] allow a programmer to treat a heterogeneous network of computers as a parallel machine.
Reference: [6] <author> S. Capstick and B. D. Keister. </author> <title> Baryon current matrix elements in a light-front framework. </title> <journal> Physical Review D, </journal> <volume> 51 </volume> <pages> 3598-3612, </pages> <year> 1995. </year>
Reference-contexts: To show that Dome is useful for more complicated programs, we have implemented several real applications including a molecular dynamics water simulation [25] and a multidimensional integration nuclear physics application <ref> [6] </ref>. 4. Load balancing The object oriented architecture of Dome hides data placement and communication from the programmer. This makes it possible for Dome to alter data mappings and communication patterns dynamically during program execution in response to changes in the execution environment.
Reference: [7] <author> N. Carriero and D. Gelernter. </author> <title> How to write parallel programs: A guide to the perplexed. </title> <journal> ACM Computing Surveys, </journal> <pages> pages 323-357, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Intel Corporation. k IBM Canada Laboratory. These ideas are not new; parallel computing has long been an active area of research. The fact that networks of computers are commonly being used in this fashion is new. Software tools like PVM [1, 15], P4 [5], Linda <ref> [7] </ref>, Isis [2], Express [14], and MPI [16] allow a programmer to treat a heterogeneous network of computers as a parallel machine. These tools are useful, but for efficient and practical use, load balancing and fault tolerance mechanisms must be developed that will work well in a heterogeneous multi-user environment.
Reference: [8] <author> I. B. M. Corporation. </author> <title> IBM LoadLeveler: User's guide. </title> <type> Technical report, </type> <institution> IBM, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: For more detailed information on Dome's checkpointing methods, see [23]. 6. Related work Although addressing similar aspects, Dome is not a resource management system like Condor [20], LoadLeveler <ref> [8] </ref>, and DQS [10]. These systems also deal with load balancing, fault tolerance, parallelism, and heterogeneity. However, they operate on a different level, overseeing the distribution and placement of processes rather than data over the network.
Reference: [9] <author> J. Dongarra, R. Pozo, and D. Walker. </author> <title> An object oriented design for high performance linear algebra on distributed memory architectures. </title> <booktitle> In Proc. OON-SKI Object Oriented Numerics Conf., </booktitle> <pages> pages 257-264, </pages> <address> Sun River, Oregon, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Knowledge gained in developing Dome can, however, be used in compilers that target heterogeneous networks. LaPack++ <ref> [9] </ref> is an object oriented interface to the LaPack routines for parallel linear algebra. Like La-Pack++, Dome provides a library of parallel objects. However, Dome focuses on objects of general use and provides features like dynamic load balancing and fault tolerance that are not addressed by LaPack++. 6.1.
Reference: [10] <author> D. W. Duke, T. P. Green, and J. L. Pasko. </author> <title> Research toward a heterogeneous networked computing cluster: The distributed queueing system version 3.0. </title> <type> Technical report, </type> <institution> Florida State University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: For more detailed information on Dome's checkpointing methods, see [23]. 6. Related work Although addressing similar aspects, Dome is not a resource management system like Condor [20], LoadLeveler [8], and DQS <ref> [10] </ref>. These systems also deal with load balancing, fault tolerance, parallelism, and heterogeneity. However, they operate on a different level, overseeing the distribution and placement of processes rather than data over the network. Dome shares attributes with many other research projects. pC++ [3] extends C++ to a parallel programming language.
Reference: [11] <author> D. Eager, E. Lazowska, and J. Zahorjan. </author> <title> Adaptive load sharing in homogeneous distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(5), </volume> <month> May </month> <year> 1986. </year>
Reference-contexts: Thus, heuristics play a large role. For instance, Eager et al. [12] compare heuristics for task placement and migration under various system loads. It is generally agreed upon that simple heuristics are best when scheduling independent tasks in multi-user distributed system <ref> [11] </ref>. In this case no assumptions are made about inter-task relationships. For parallel computing, inter-task relationships are very important when making load balancing decisions. However, Dome's load balancing strategy still agrees with Eager's thesis that simple strategies are most effective and extends that idea to load balancing of parallel algorithms.
Reference: [12] <author> D. Eager, E. Lazowska, and J. Zahorjan. </author> <title> A comparison of receiver initiated and sender initiated dynamic load sharing. Performance Evaluation, </title> <type> 6(1), </type> <month> April </month> <year> 1986. </year>
Reference-contexts: Most distributed multi-user systems have unpredictable loads, making these approaches impractical for general use. Load balancing research in operating systems focuses on similar mapping problems but where little is known about the tasks or the target system's capacities. Thus, heuristics play a large role. For instance, Eager et al. <ref> [12] </ref> compare heuristics for task placement and migration under various system loads. It is generally agreed upon that simple heuristics are best when scheduling independent tasks in multi-user distributed system [11]. In this case no assumptions are made about inter-task relationships.
Reference: [13] <author> D. Ferrari and S. Zhou. </author> <title> An empirical investigation of load indices for load balancing applications. </title> <booktitle> In Proceedings of Performance '87, The 12th International Symposium on Computer Performance Modeling, Measurement and Evaluation, </booktitle> <pages> pages 515-528, </pages> <address> Amsterdam, November 1988. </address> <publisher> North Holland Publishers. </publisher>
Reference-contexts: It also differs from most parallel computing load balancing techniques in that external system load is a major consideration. Finally, in order to perform load balancing, resource management systems and schedulers in operating sys tems, in general, have to make use of load indices based on available system resources <ref> [13, 19] </ref>. Dome uses a direct approach for load measurement, namely, the timing of execution progress in each participating processor. This is a very simple way to capture both processor speed and amount of external and internal load present in each machine. 6.2.
Reference: [14] <author> J. Flower, A. Kolawa, and S. Bharadwaj. </author> <title> The express way to distributed processing. </title> <booktitle> Supercomputing Review, </booktitle> <pages> pages 54-55, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Intel Corporation. k IBM Canada Laboratory. These ideas are not new; parallel computing has long been an active area of research. The fact that networks of computers are commonly being used in this fashion is new. Software tools like PVM [1, 15], P4 [5], Linda [7], Isis [2], Express <ref> [14] </ref>, and MPI [16] allow a programmer to treat a heterogeneous network of computers as a parallel machine. These tools are useful, but for efficient and practical use, load balancing and fault tolerance mechanisms must be developed that will work well in a heterogeneous multi-user environment.
Reference: [15] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM: Parallel Virtual Machine | A Users' Guide and Tutorial for Net-worked Parallel Computing. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Intel Corporation. k IBM Canada Laboratory. These ideas are not new; parallel computing has long been an active area of research. The fact that networks of computers are commonly being used in this fashion is new. Software tools like PVM <ref> [1, 15] </ref>, P4 [5], Linda [7], Isis [2], Express [14], and MPI [16] allow a programmer to treat a heterogeneous network of computers as a parallel machine.
Reference: [16] <author> W. Gropp, E. Lusk, and A. Skjellum. </author> <title> Using MPI. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: These ideas are not new; parallel computing has long been an active area of research. The fact that networks of computers are commonly being used in this fashion is new. Software tools like PVM [1, 15], P4 [5], Linda [7], Isis [2], Express [14], and MPI <ref> [16] </ref> allow a programmer to treat a heterogeneous network of computers as a parallel machine. These tools are useful, but for efficient and practical use, load balancing and fault tolerance mechanisms must be developed that will work well in a heterogeneous multi-user environment.
Reference: [17] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <month> Jan. </month> <year> 1993. </year> <note> Version 1.0 DRAFT. </note>
Reference-contexts: However, they operate on a different level, overseeing the distribution and placement of processes rather than data over the network. Dome shares attributes with many other research projects. pC++ [3] extends C++ to a parallel programming language. High Performance Fortran <ref> [17] </ref> is an emerging standard for writing distributed memory parallel Fortran programs. While language based mechanisms for expressing parallelism and data map ping in distributed memory machines are important, we are most interested in using existing languages and exploring object oriented mechanisms for parallel and distributed computing.
Reference: [18] <author> C. Hofmeister and J. Purtilo. </author> <title> Dynamic reconfiguration in distributed systems: Adapting software modules for replacement. </title> <type> Technical Report UMIACS-TR-92-120, </type> <institution> University of Maryland, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Another system related to ours was developed by Hofmeister and Purtilo <ref> [18] </ref>. As in Dome, they use a preprocessing mechanism for saving the state of distributed programs. 7. Future work The Dome system is undergoing very active development.
Reference: [19] <author> T. Kunz. </author> <title> The influence of different workload descriptions on a heuristic load balancing scheme. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-17(7):725-730, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: It also differs from most parallel computing load balancing techniques in that external system load is a major consideration. Finally, in order to perform load balancing, resource management systems and schedulers in operating sys tems, in general, have to make use of load indices based on available system resources <ref> [13, 19] </ref>. Dome uses a direct approach for load measurement, namely, the timing of execution progress in each participating processor. This is a very simple way to capture both processor speed and amount of external and internal load present in each machine. 6.2.
Reference: [20] <author> M. Litzkow, M. Livny, and M. </author> <title> Mutka. Condor | A hunter of idle workstations. </title> <booktitle> In Proceedings of the Eighth Conference on Distributed Computing Systems, </booktitle> <address> San Jose, California, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: For more detailed information on Dome's checkpointing methods, see [23]. 6. Related work Although addressing similar aspects, Dome is not a resource management system like Condor <ref> [20] </ref>, LoadLeveler [8], and DQS [10]. These systems also deal with load balancing, fault tolerance, parallelism, and heterogeneity. However, they operate on a different level, overseeing the distribution and placement of processes rather than data over the network.
Reference: [21] <author> B. Lowekamp and A. Beguelin. </author> <title> ECO: Efficient collective operations for communication on heterogeneous networks. </title> <booktitle> In International Parallel Processing Symposium 1996, </booktitle> <address> Honolulu, HI, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: We have developed a separate package, called ECO, which deals with the issue of network load balancing by automatically determining network topology, partitioning the network into sub-nets, and establishing optimized communication patterns. More details on ECO can be found in <ref> [21] </ref>. 4.2. Initial timing results In order to evaluate the Dome approach to load balancing, we have written a matrix multiply program using dVectors (mmdome). <p> With respect to load balancing, there is still much work to do. Adaptation of the load balancing frequency based on runtime characteristics may be fruitful. This work will mesh well with the automatic network partitioning described in Section 4.1 and <ref> [21] </ref>. It is also possible that runtime metrics of communication performance can be used to develop a virtual topology for load balancing and collective communications. 8.
Reference: [22] <author> J. Plank and K. Li. </author> <title> ickp: A consistent checkpointer for multicomputers. </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <pages> pages 62-66, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: Related checkpointing work Most checkpointing libraries for distributed systems address checkpointing in a homogeneous environment using system-specific techniques to capture consistent memory images from each process efficiently. Plank and Li's <ref> [22] </ref>, for example, is designed to minimize the checkpointing overhead on multicomputers.
Reference: [23] <author> E. Seligman and A. Beguelin. </author> <title> High level fault tolerance in distributed programs. </title> <type> Technical Report CMU-CS-94-223, </type> <institution> Carnegie Mellon University, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Furthermore, the portability of the checkpoints themselves has also been successfully accomplished by restarting md on Alpha workstations from checkpoints created on the SGI workstations. For more detailed information on Dome's checkpointing methods, see <ref> [23] </ref>. 6. Related work Although addressing similar aspects, Dome is not a resource management system like Condor [20], LoadLeveler [8], and DQS [10]. These systems also deal with load balancing, fault tolerance, parallelism, and heterogeneity.
Reference: [24] <author> L. Silva, B. Veer, and J. Silva. </author> <title> Checkpointing SPMD applications on transputer networks. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 694-701, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Plank and Li's [22], for example, is designed to minimize the checkpointing overhead on multicomputers. An architecture independent package has also been developed by Silva, Veer, and Silva <ref> [24] </ref>, who have created a library based system where the user is responsible for inserting calls to specify the data to be saved and perform the checkpoints. Another system related to ours was developed by Hofmeister and Purtilo [18].
Reference: [25] <author> W. S. Young and C. Brooks, III. </author> <title> An implementation of a data parallel, logical domain decomposition method for interparticle interactions in molecular dynamics of structured molecular fluids. </title> <journal> Journal Computational Chemistry, </journal> <volume> 15 </volume> <pages> 44-53, </pages> <year> 1994. </year>
Reference-contexts: To show that Dome is useful for more complicated programs, we have implemented several real applications including a molecular dynamics water simulation <ref> [25] </ref> and a multidimensional integration nuclear physics application [6]. 4. Load balancing The object oriented architecture of Dome hides data placement and communication from the programmer.
References-found: 25

