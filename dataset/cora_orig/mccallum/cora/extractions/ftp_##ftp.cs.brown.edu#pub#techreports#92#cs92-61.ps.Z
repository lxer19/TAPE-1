URL: ftp://ftp.cs.brown.edu/pub/techreports/92/cs92-61.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-92-61.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [ Aalen, 1989 ] <author> O. O. Aalen. </author> <title> A linear regression model of the analysis of life times. </title> <booktitle> In Statistics in Medicine 8, </booktitle> <pages> pages 907-925. </pages> <publisher> Wiley, </publisher> <year> 1989. </year>
Reference-contexts: Such a model corresponds to the proportional hazards model of <ref> [ Cox, 1972; Aalen, 1989 ] </ref> . Given the above, we are now ready to define the continuous time net. Definition 4.3 A continuous time net for D is a Bayesian belief network B = (V; E).
Reference: [ Allen, 1983 ] <author> James Allen. </author> <title> Maintaining knowledge about temporal intervals. </title> <journal> Communications of the ACM, </journal> <volume> 26 </volume> <pages> 832-843, </pages> <year> 1983. </year>
Reference: [ Allen, 1984 ] <author> James Allen. </author> <title> Towards a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 123-154, </pages> <year> 1984. </year>
Reference-contexts: Their planning system maintains statistics about the result of actions in the form of confidence intervals. The confidence intervals are in terms of approximating binomial distributions by normal densities. Although their language notates actions and events relative to temporal intervals as in Allen's previous work <ref> [ Allen, 1984 ] </ref> , the actual temporal aspects do not appear to play a large role. In examples that they provide, there are statistics linking actions and effects, but they appear to hold for all time points.
Reference: [ Bacchus et al., 1989 ] <author> Fahiem Bacchus, Josh Tennenberg, and Johannes A. Koomen. </author> <title> A non-reified temporal logic. </title> <booktitle> In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 2-10, </pages> <address> Toronto, Ontario, </address> <year> 1989. </year>
Reference: [ Bacchus, 1991 ] <author> Fahiem Bacchus. </author> <title> Representating and Reasoning with Probabilistic Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year> <note> Previously issued as University of Alberta Ph.D. Thesis, and as Waterloo University Technical Report CS-88-31. </note>
Reference-contexts: possible worlds has a natural fit with temporal logics, and a number of temporal logics have possible worlds semantics. 3.1.2 The Object, Time, and Field Sorts As we mentioned, the logic of lifetimes combine elements of Shoham's logics of time [ 1988 ] with Bacchus and Halpern's logics of probability <ref> [ Bacchus, 1991; Halpern, 1989 ] </ref> . Basically, the features related to time are borrowed from Shoham, and features related to probability are borrowed from Bacchus and Halpern. <p> This is in contrast to Bacchus's approach, which adopts not the real line, but arbitrary totally ordered fields <ref> [ Bacchus, 1991 ] </ref> . Again, the field sort contains constants, variables for the first-order case, functions, and relations. There are typically a very rich class of field functions, to represent probability density functions. It is virtually impossible to define any interesting probability densities without field functions.
Reference: [ Basye et al., 1990 ] <author> Kenneth Basye, Moises Lejter, and Keiji Kanazawa. </author> <title> Reducing uncertainty in navigation and exploration. </title> <booktitle> In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 106-113, </pages> <address> Cambridge, Massachusetts, </address> <month> July </month> <year> 1990. </year> <booktitle> Association for Uncertainty in Artificial Intelligence. </booktitle>
Reference-contexts: In addition to time net based influence diagrams such as in domain models, we have applied influence diagrams to the task of spatial inference and learning <ref> [ Basye et al., 1990 ] </ref> . As we see in the Markov decision process sequential decision problem and in the continuous optimization problem, the use of influence diagrams in temporal decision making often involves prohibitive combinatorics.
Reference: [ Berzuini et al., 1989 ] <author> Carlo Berzuini, Riccardo Ballazzi, and Silvana Quaglini. </author> <title> Temporal reasoning with probabilities. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 14-21, </pages> <address> Detroit, Michigan, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: Sampling is the best available general method for estimating densities for continuous variables, and it has been employed for temporal reasoning in continuous-time Bayesian networks <ref> [ Berzuini et al., 1989 ] </ref> . A common variant of sampling, perhaps the best known, is Monte Carlo 5 There are extensions allowing normal distributions, but this is not expressive enough for representing continuous time nets in general. 108 CHAPTER 4. THE TIME NET simulation. <p> In this work, variables model air quality over time, given different decisions about pollution control, and there is a variable that models the value of resulting situations in terms of life expectancy of the population. Bayesian belief networks with continuous variables for reasoning about time are due to Berzuini <ref> [ Berzuini et al., 1989 ] </ref> , and perhaps to Spiegelhalter as well. Their 114 CHAPTER 4. THE TIME NET work grew out out of an attempt to remedy the deficiencies of the Markov time net model that we had presented in [ Dean and Kanazawa, 1988b ] .
Reference: [ Berzuini, to appear ] <author> Carlo Berzuini. </author> <title> A probabilistic framework for temporal reasoning. </title> <journal> Artificial Intelligence, </journal> <note> to appear. 171 172 BIBLIOGRAPHY </note>
Reference-contexts: The continuous time net models the probability of facts and events and a host of other useful random variables based on functions of facts and events. The continuous time net is based on the network of dates proposed by Berzuini <ref> [ Berzuini, to appear ] </ref> (and apparently by Spiegelhalter, as cited in same). Berzuini's networks model only what we have called events in our terminology. We have extended this model to include facts as well as arbitrary functions of event dates and fact durations. <p> Given an arbitrary domain instance that would not result in the creation of a cyclical network, is the result always a proper time net? Berzuini has shown results pertaining to the types of dependencies that can be represented in a network composed solely of events <ref> [ Berzuini, to appear ] </ref> . The short answer is that we cannot build time nets easily for arbitrary domain theories. To build a continuous time net for domains that are not restricted domains, care must be taken with the probability functions.
Reference: [ Boddy and Dean, 1989 ] <author> Mark Boddy and Thomas Dean. </author> <title> Solving time dependent planning problems. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, Michigan, </address> <year> 1989. </year> <pages> IJCAI. </pages>
Reference: [ Boddy, 1991 ] <author> Mark Boddy. </author> <title> Solving time-dependent problems: A decision-theoretic approach to planning in dynamic environments. </title> <type> Technical Report CS-91-06, </type> <institution> Brown University Department of Computer Science, Providence, RI, </institution> <month> May </month> <year> 1991. </year>
Reference: [ Box and Jenkins, 1976 ] <author> George E. P. Box and Gwilym M. Jenkins. </author> <title> Time Series Analysis : Forecasting and Control. </title> <publisher> Holden-Day, </publisher> <address> San Francisco, </address> <year> 1976. </year>
Reference-contexts: ODDS's continuous-time model, with its use of survivor functions have a basis in this area. Similar ideas are used in queueing theory, which is concerned with expected time between events, and expected time waiting for events, especially in the domains of manufacturing, transport, and communications. Time-Series Analysis Time-series analysis <ref> [ Box and Jenkins, 1976; Granger and Newbold, 1986 ] </ref> is concerned with temporal prediction of a series, and can be closely related to Markov processes. Times-series analysis has been applied in financial modeling and other areas.
Reference: [ Brachman et al., 1989 ] <editor> Ronald J. Brachman, Hector J. Levesque, and Raymond Re-iter, editors. </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <address> Toronto, Ontario, May 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Breese, 1987 ] <author> John S. Breese. </author> <title> Knowledge representation and inference in intelligent decision systems. </title> <type> Technical Report 2, </type> <institution> Rockwell International Science Center, </institution> <year> 1987. </year>
Reference: [ Cannings et al., 1978 ] <author> C. Cannings, E. A. Thompson, and M. H. Skolnick. </author> <title> Probability functions on complex pedigrees. </title> <journal> Adv. Appl. Probabil., </journal> <volume> 10 </volume> <pages> 26-61, </pages> <year> 1978. </year>
Reference-contexts: The clique tree algorithm was developed originally for a 3 The problem of propagation of probabilities in networks with loops also arises in genetics, and it turns out that a solution similar to the clique tree algorithm had been found earlier in that context <ref> [ Cannings et al., 1978 ] </ref> . However, these results were not generally known until recently. 4.4. COMPUTATION 101 medical diagnosis application [ Olesen et al., 1989 ] .
Reference: [ Chavez and Cooper, 1989 ] <author> R. Martin Chavez and Gregory F. Cooper. </author> <title> An empirical evaluation of a randomized algorithm for probabilistic inference. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 60-70, </pages> <address> Detroit, Michigan, </address> <year> 1989. </year>
Reference: [ Cheeseman, 1983 ] <author> Peter Cheeseman. </author> <title> A method of computing generalized bayesian probability values for expert systems. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <address> Karlsluhe, West Germany, </address> <year> 1983. </year> <pages> IJCAI. </pages>
Reference-contexts: This assumption is difficult to relax without a method of "completing" the model based on the incomplete probability distributions. The prototypical interactions that we discussed above is one method of model completion. Maximum entropy methods are another <ref> [ Jaynes, 1979; Cheeseman, 1983; Lippman, 1986 ] </ref> . Assumption 3 ensures that there is a single time net in consideration. This assumption can be relaxed trivially, at least conceptually.
Reference: [ Chow and Liu, 1968 ] <author> C. Chow and C. Liu. </author> <title> Approximating discrete probability distributions with dependence trees. </title> <journal> IEEE Transactions on Information Theory, </journal> <month> May </month> <year> 1968. </year>
Reference-contexts: Otherwise, the graph is acyclic and it is called a directed acyclic graph or dag for short. A graph with only one path connecting any two nodes is called a polytree, or generalized Chow tree <ref> [ Chow and Liu, 1968 ] </ref> . We say that a graph is singly-connected when it is a polytree. Otherwise, it is multiply-connected (see Figure 4.2).
Reference: [ Cooper et al., 1988 ] <author> Gregory F. Cooper, Eric J. Horvitz, and David E. Heckerman. </author> <title> A method for temporal probabilistic reasoning. </title> <institution> Memo KSL-88-30, Knowledge Systems Laboratory, Stanford University, </institution> <year> 1988. </year> <note> BIBLIOGRAPHY 173 </note>
Reference: [ Cooper, 1984 ] <author> Gregory F. Cooper. NESTOR: </author> <title> A computer-based medical diagnostic aid that integrates causal and probabilistic knowledge. </title> <type> PhD thesis, </type> <institution> Program in Medical Information Sciences, Stanford University, Stanford, </institution> <month> November </month> <year> 1984. </year>
Reference: [ Cooper, 1990 ] <author> Gregory F. Cooper. </author> <title> The computational complexity of probabilistic inference using bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):393-405, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: As time nets are simply Bayesian networks with a special interpretation of its random variables, the 4.4. COMPUTATION 97 algorithms employed for such computation are just Bayesian network algorithms. We define the problem of probabilistic inference in a Bayesian network <ref> [ Cooper, 1990 ] </ref> as the computation of a consistent distribution for each node v 2 V of a Bayesian network B, possibly given evidence on a subset of the nodes K V .
Reference: [ Cox and Oakes, 1984 ] <author> D. R. Cox and D. Oakes. </author> <title> Analysis of Survival Data. </title> <publisher> Wiley, </publisher> <year> 1984. </year>
Reference-contexts: Some of our present work, especially the experimental computational aspects outlined in Chapter 4 and Chapter 5 extends the practical applicability of the past work, both in computational and representational terms. Survival Analysis Another area of close relation to our present work is the work in survival analysis <ref> [ Cox and Oakes, 1984 ] </ref> . Survival analysis is concerned with predicting how long a fact stays true in the world for. The chief domain is that of medicine, where duration of diseases and life expectancy are modeled.
Reference: [ Cox, 1946 ] <author> Richard T. Cox. </author> <title> Probability, frequency and reasonable expectation. </title> <journal> American Journal of Physics, </journal> <volume> 14 </volume> <pages> 1-13, </pages> <year> 1946. </year>
Reference: [ Cox, 1972 ] <author> D. R. Cox. </author> <title> Regression models and life tables (with discussion). </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 34 </volume> <pages> 187-220, </pages> <year> 1972. </year>
Reference-contexts: Such a model corresponds to the proportional hazards model of <ref> [ Cox, 1972; Aalen, 1989 ] </ref> . Given the above, we are now ready to define the continuous time net. Definition 4.3 A continuous time net for D is a Bayesian belief network B = (V; E). <p> A different model might give it in terms of a proportional hazard model <ref> [ Cox, 1972 ] </ref> . The rule set is closed with the rules that give the time of occurrence of the enabling and clipping events of our location being Times Square given the arrival event for the former, and the leaving event for the latter.
Reference: [ Dean and Boddy, 1988 ] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time dependent planning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 49-54, </pages> <address> Minneapolis, Minnesota, 1988. </address> <publisher> AAAI. </publisher>
Reference: [ Dean and Kanazawa, 1987 ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Persistence and probabilistic inference. </title> <type> Technical Report CS-87-23, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1987. </year>
Reference-contexts: In this section, we review our own past work in the area. 2.3.1 ODDS Our initial effort in probabilistic temporal reasoning and decision theoretic control was the ODDS project <ref> [ Dean and Kanazawa, 1987; Dean and Kanazawa, 1989b ] </ref> . ODDS was designed as a planning system incorporating a temporal database that applied probabilistic causal rules to aid the process of reasoning about actions. It was implemented as a prototype in a simulated manufacturing domain.
Reference: [ Dean and Kanazawa, 1988a ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Probabilistic causal reasoning. </title> <booktitle> In Proceedings of the Seventh Biennial Conference of the Canadian Society for Computational Studies of Intelligence, </booktitle> <address> Edmonton, Alberta, </address> <year> 1988. </year> <pages> CSCSI. </pages>
Reference-contexts: Thus, if no causal rule is present that predicts the occurrence of ceasing, then it is consistent that ceasing does not occur. In <ref> [ Dean and Kanazawa, 1988a ] </ref> , we called this assumption the single default assumption of persistence. Although this assumption, akin to a "law of inertia" seems to conveniently get around the frame problem by making it unnecessary to write down frame axioms, it presents other problems.
Reference: [ Dean and Kanazawa, 1988b ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Probabilistic temporal reasoning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 524-528, </pages> <address> Minneapolis, Minnesota, 1988. </address> <publisher> AAAI. </publisher>
Reference-contexts: Time nets belong to a popular directed acyclic graph class of probabilistic networks called Bayesian networks. There are also undirected probabilistic networks, called Markov random fields, that have been used for temporal inference <ref> [ Dean and Kanazawa, 1988b ] </ref> . However, we focus on Bayesian networks exclusively in this dissertation. In the remainder of this chapter, we explore the expressive and computational properties of time nets. First, we introduce graph concepts and the Bayesian network. Then, we present the time net itself. <p> Their 114 CHAPTER 4. THE TIME NET work grew out out of an attempt to remedy the deficiencies of the Markov time net model that we had presented in <ref> [ Dean and Kanazawa, 1988b ] </ref> . As it turned out, their model shares similarity with the earlier ODDS work in its application of survival analysis to temporal reasoning. Technically, our continuous time net extends their network of dates. The network of dates only has what we call events.
Reference: [ Dean and Kanazawa, 1989a ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> A model for reasoning about persistence and causation. </title> <journal> Computational Intelligence, </journal> <volume> 5(3) </volume> <pages> 142-150, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: In certain cases, this can lead to significant errors (e.g., we always predict the truck leaving accurately). 2.3.2 A Discrete Approach In order to remedy the problems with ODDS, we subsequently adopted a discrete model of reasoning about probability and time <ref> [ Dean and Kanazawa, 1989a ] </ref> . In this model, all factors contributing to our belief in the truth or falsehood of a fact or event are separated and made explicit. A discrete model of time is adopted. <p> A node in a discrete time net typically represents the probability that a fact holds, or that an event occurs, during each of these intervals. 1 In past work, time nets were called temporal Bayes nets <ref> [ Dean and Kanazawa, 1989a ] </ref> . 74 CHAPTER 4. THE TIME NET Each node for expressing such a probability can be discrete-valued or continuous-valued. By contrast, a continuous time net has a continuous model of time.
Reference: [ Dean and Kanazawa, 1989b ] <author> Thomas Dean and Keiji Kanazawa. </author> <title> Persistence and probabilistic projection. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 19(3) </volume> <pages> 574-585, </pages> <address> May/June 1989. 174 BIBLIOGRAPHY </address>
Reference-contexts: From that information, you will be able to predict what time the flight arrives. Another example is that of a dispatcher at an automated warehouse who must decide what tasks are to be performed at what time <ref> [ Dean and Kanazawa, 1989b ] </ref> . At the warehouse, there are trucks delivering and picking up cargo all day long. Loading and unloading trucks is the job of automated robot handlers. Typically, the warehouse is so busy that not everything gets done as expeditely as one might hope. <p> In this section, we review our own past work in the area. 2.3.1 ODDS Our initial effort in probabilistic temporal reasoning and decision theoretic control was the ODDS project <ref> [ Dean and Kanazawa, 1987; Dean and Kanazawa, 1989b ] </ref> . ODDS was designed as a planning system incorporating a temporal database that applied probabilistic causal rules to aid the process of reasoning about actions. It was implemented as a prototype in a simulated manufacturing domain. <p> Formal analyses and 2.3. REASONING ABOUT TIME AND PROBABILITY 27 proofs pertaining to the use of these functions are contained in <ref> [ Dean and Kanazawa, 1989b ] </ref> . An exponential decay function takes the form e t where is the constant of decay. <p> It is sufficient to know how long it has passed since it has 28 CHAPTER 2. TIME AND CHANCE become true to predict what the likelihood is that the fact is still true. In <ref> [ Dean and Kanazawa, 1989b ] </ref> , we show how to construct a survivor function for a fact type ' from observations of when instances of ' become true and false. example to occur with probability 1.0 within the indicated intervals. <p> As it turns out, because of this memoryless character, it was possible to evaluate the integral in a single forward sweep through the time line. The same turned out to be true (with minor modifications) for the piecewise linear functions. The algorithmic details are presented in <ref> [ Dean and Kanazawa, 1989b ] </ref> . The second reason for the efficiency of the ODDS projection algorithm is that we made assumptions about facts in the database that precluded complex dependencies. In particular, we assumed that all antecedents to a projection rule were always conditionally independent. <p> A time point might itself be another event, or in reference to a global clock. The TMM always maintains constraints about facts and events, and incorporates sophisticated facilities for exception handling. Its development continues today in a more sophisticated form. The first probabilistic temporal database was ODDS <ref> [ Dean and Kanazawa, 1989b ] </ref> . We have described the way that it handles probabilistic inference. ODDS implemented a very simple forward chaining deductive assertional database that incrementally built up its probabilistic model on the basis of asserted facts and probabilistic rules.
Reference: [ Dean and Wellman, 1991 ] <author> Thomas Dean and Michael Wellman. </author> <title> Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1991. </year>
Reference-contexts: SUMMARY 161 Russell and Wefald, 1991 ] . The question of decision theoretic optimization in a continuous space is an important issue where much might be learnt from control theory <ref> [ Dean and Wellman, 1991 ] </ref> . 162 CHAPTER 6. DECISION MAKING Chapter 7 Conclusions We conclude by offering assessments and future directions. 7.1 Contributions This dissertation is about how to picture the world and how it changes over time.
Reference: [ Dean et al., 1990 ] <author> Thomas Dean, Kenneth Basye, and Moises Lejter. </author> <title> Planning and active perception. </title> <booktitle> In Proceedings of the DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control, </booktitle> <pages> pages 271-276, </pages> <address> Rochester, New York, </address> <year> 1990. </year> <pages> DARPA. </pages>
Reference-contexts: The approach developed here has been extended and applied to real mobile robots that navigate in an office environment using ultrasound and visual information <ref> [ Dean et al., 1990 ] </ref> . In addition to time net based influence diagrams such as in domain models, we have applied influence diagrams to the task of spatial inference and learning [ Basye et al., 1990 ] .
Reference: [ Dean, 1985 ] <author> Thomas Dean. </author> <title> Temporal imagery: An approach to reasoning about time for planning and problem solving. </title> <type> Technical Report 433, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1985. </year>
Reference-contexts: Rit [ 1986 ] and Dechter and Pearl [ 1989 ] show temporal constraint 34 CHAPTER 2. TIME AND CHANCE propagation systems for efficient inference involving temporal intervals. Dean's TMM <ref> [ Dean, 1985 ] </ref> , a temporal database system, is covered further in Section 5.4. 2.4.2 Probabilistic Temporal Reasoning Since we began investigations in reasoning about time and probability, there has been a small but growing body of work in this area in artificial intelligence.
Reference: [ Dechter et al., 1989 ] <author> Rina Dechter, I. Meiri, and Judea Pearl. </author> <title> Temporal constraint networks. </title> <editor> In Brachman et al. </editor> [ <year> 1989 </year> <month> ] , pages 83-93. </month>
Reference: [ Devroye, 1986 ] <author> Luc Devroye. </author> <title> Non-Uniform Random Variate Generation. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: The basic idea of sampling is simple. The idea is to estimate variables, in our case probability distributions, by repeated trials. In each trial, each random variable is sampled from its underlying distribution <ref> [ Devroye, 1986; Ripley, 1987 ] </ref> in a fixed order. For the moment, let us pretend that there is no evidence; adding evidence requires an additional step, albeit a simple step. A sample is a simulated value for the random variable.
Reference: [ Etzioni and Segal, 1992 ] <author> Oren Etzioni and Richard Segal. </author> <title> Softbots as testbeds for machine learning. </title> <booktitle> In Proceedings of the 1992 AAAI Spring Symposium on Knowledge Assimilation, </booktitle> <address> Stanford, 1992. </address> <publisher> AAAI. </publisher>
Reference-contexts: There is a lot of uncertainty involved in the inference and therapy planning, and the approach developed here seems ideally suited. Intelligent agents in distributed networks, or softbots <ref> [ Etzioni and Segal, 1992 ] </ref> , need to reason about network conditions, and the effects of actions by it and other agents over time. Because of the expected growth of the use of computer networks, such agents are promising domains for investigating planning and temporal reasoning.
Reference: [ Fagin et al., 1990 ] <author> Ronald Fagin, Joseph Y. Halpern, and Nimrod Megiddo. </author> <title> A logic for reasoning about probabilities. </title> <journal> Information and Computation, </journal> 87(1/2):78-128, July/August 1990. Academic Press. 
Reference-contexts: These logics directly take after Nilsson's probabilistic logic [ Nilsson, 1986 ] , as with the logics by Fagin and others <ref> [ Fagin et al., 1990 ] </ref> , and by Halpern [ Halpern, 1989 ] . Note though that theoretical computer scientists and philosophers predate the artificial intelligence practitioners with regard to this. We adopt the possible worlds approach.
Reference: [ Feldman, 1984 ] <author> Yishai Feldman. </author> <title> A decidable propositional probabilistic dynamic logic with explicit probabilities. </title> <journal> Information and Control, </journal> <volume> 63 </volume> <pages> 11-38, </pages> <year> 1984. </year>
Reference: [ Fikes and Nilsson, 1971 ] <author> Richard E. Fikes and Nils J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference: [ Fung and Chang, 1989 ] <author> Robert Fung and Kuo-Chu Chang. </author> <title> Weighing and integrating evidence for stochastic simulation in bayesian networks. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 112-117, </pages> <address> Detroit, Michigan, </address> <year> 1989. </year>
Reference-contexts: Monte Carlo schemes have nice conceptual properties, and they are the only general algorithm for continuous random variables. Therefore, for continuous time nets, these are the only algorithms considered. Such algorithms had problems with convergence in the past, but recently, these have been ameliorated <ref> [ Fung and Chang, 1989; Shachter and Peot, 1989 ] </ref> , and they have seen renewed interest [ Shwe and Cooper, 1990 ] . (4) Bounding. These algorithms bound the probabilities on items of interest through heuristic search.
Reference: [ Fung and Shachter, 1990 ] <author> Robert M. Fung and Ross D. Shachter. </author> <title> Contingent influence diagrams. </title> <note> Submitted for publication, 1990. BIBLIOGRAPHY 175 </note>
Reference-contexts: Then the algorithm will add an edge from ff to fi and vice versa, creating a cycle. This assumption can be relaxed in cases when there are certain types of asymmetric dependencies in the rule set <ref> [ Geiger and Heckerman, 1991; Fung and Shachter, 1990 ] </ref> . Asymmetric dependencies are best illustrated by example. Imagine that in doing my errands, I have a choice of either going to Times Square first and then Grand 5.2. <p> In are irrelevant to the plan choice. This suggests that the rule application criterion and algorithm can be revised to take advantage of this situation. Although Goo does not currently implement this, there is ongoing work in exploiting asymmetries in Bayesian networks <ref> [ Geiger and Heckerman, 1991; Fung and Shachter, 1990 ] </ref> which will be incorporated into future versions of Goo. 134 CHAPTER 5. GOO Finally, assumption 1 ensures that unintended cyclicities are not created by variable substitution in unifying rules against the database. This assumption is the most difficult to relax.
Reference: [ Geiger and Heckerman, 1991 ] <author> Dan Geiger and David Heckerman. </author> <booktitle> Advances in probabilistic reasoning. In Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 118-126, </pages> <address> Anaheim, California, </address> <year> 1991. </year>
Reference-contexts: Then the algorithm will add an edge from ff to fi and vice versa, creating a cycle. This assumption can be relaxed in cases when there are certain types of asymmetric dependencies in the rule set <ref> [ Geiger and Heckerman, 1991; Fung and Shachter, 1990 ] </ref> . Asymmetric dependencies are best illustrated by example. Imagine that in doing my errands, I have a choice of either going to Times Square first and then Grand 5.2. <p> In are irrelevant to the plan choice. This suggests that the rule application criterion and algorithm can be revised to take advantage of this situation. Although Goo does not currently implement this, there is ongoing work in exploiting asymmetries in Bayesian networks <ref> [ Geiger and Heckerman, 1991; Fung and Shachter, 1990 ] </ref> which will be incorporated into future versions of Goo. 134 CHAPTER 5. GOO Finally, assumption 1 ensures that unintended cyclicities are not created by variable substitution in unifying rules against the database. This assumption is the most difficult to relax.
Reference: [ Geweke, to appear ] <author> J. Geweke. </author> <title> Bayesian inference in econometric models using monte carlo integration. </title> <journal> Econometrica, </journal> <note> to appear. </note>
Reference-contexts: At the end, the scores are used to estimate the distribution for each random variable. Under certain conditions, the estimates are shown to converge to the true distribution (see, for example, <ref> [ Geweke, to appear ] </ref> ). In the simplest case, we design our algorithms so that the frequency with which a value is sampled for a random variable reflects the underlying distribution of the random variable faithfully, and we score each trial equally.
Reference: [ Glymour et al., 1987 ] <author> C. Glymour, R. Scheines, P. Spirtes, and K. Kelly. </author> <title> Discovering Causal Structure. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: It is important to incorporate learning of models into our framework, as model specification can impose a considerable burden on users. This is a wide open area, including simply learning fact duration and event occurrence statistics, learning statistics from cases, learning appropriate graph structure <ref> [ Pearl and Verma, 1991; Glymour et al., 1987 ] </ref> , and induction of logical theories. In decision-making applications, it may be equally important to bypass inference, and learn the right actions in different situations directly.
Reference: [ Goldman, 1990 ] <author> Robert Goldman. </author> <title> A Probabilistic Approach to Language Understanding. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1990. </year> <note> Available as Technical Report CS-TR-90-34. </note>
Reference: [ Good, 1976 ] <author> I. J. </author> <title> Good. Good Thinking. </title> <publisher> University of Minnesota Press, </publisher> <year> 1976. </year>
Reference: [ Granger and Newbold, 1986 ] <author> Clive William John Granger and Paul Newbold. </author> <title> Forecasting Economic Time Series. </title> <publisher> Academic Press, </publisher> <address> Orlando, </address> <year> 1986. </year>
Reference-contexts: ODDS's continuous-time model, with its use of survivor functions have a basis in this area. Similar ideas are used in queueing theory, which is concerned with expected time between events, and expected time waiting for events, especially in the domains of manufacturing, transport, and communications. Time-Series Analysis Time-series analysis <ref> [ Box and Jenkins, 1976; Granger and Newbold, 1986 ] </ref> is concerned with temporal prediction of a series, and can be closely related to Markov processes. Times-series analysis has been applied in financial modeling and other areas.
Reference: [ Haddawy, 1990 ] <author> Peter Haddawy. </author> <title> Time, chance, and action. </title> <booktitle> In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 147-154, </pages> <address> Cam-bridge, Massachusetts, </address> <year> 1990. </year>
Reference: [ Haddawy, 1991 ] <author> Peter Haddawy. </author> <title> Representing Plans Under Uncertainty: A Logic of Time, Chance, and Action. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: The utility function, or the cost function, is indeed a measuring function. We also discussed the addition of the expectation operator to LL. In that sense, LL already has the facility to represent decision theoretic choices. Each decision becomes, in effect, a conditioning event. As we noted, Haddawy <ref> [ Haddawy, 1991 ] </ref> defines a logic similar to LL for representing decision theoretic plans. His logic provides more facilities, and distinguishes between event occurrences and action attempts. Through these, he is able to provide a cleaner logic for decision theory.
Reference: [ Halpern, 1989 ] <author> Joseph Y. Halpern. </author> <title> An analysis of first-order logics of probability. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1375-1381, </pages> <address> Detroit, Michigan, </address> <year> 1989. </year> <pages> IJCAI. </pages>
Reference-contexts: These logics directly take after Nilsson's probabilistic logic [ Nilsson, 1986 ] , as with the logics by Fagin and others [ Fagin et al., 1990 ] , and by Halpern <ref> [ Halpern, 1989 ] </ref> . Note though that theoretical computer scientists and philosophers predate the artificial intelligence practitioners with regard to this. We adopt the possible worlds approach. <p> possible worlds has a natural fit with temporal logics, and a number of temporal logics have possible worlds semantics. 3.1.2 The Object, Time, and Field Sorts As we mentioned, the logic of lifetimes combine elements of Shoham's logics of time [ 1988 ] with Bacchus and Halpern's logics of probability <ref> [ Bacchus, 1991; Halpern, 1989 ] </ref> . Basically, the features related to time are borrowed from Shoham, and features related to probability are borrowed from Bacchus and Halpern.
Reference: [ Hanks and McDermott, 1987 ] <author> Steve Hanks and Drew V. McDermott. </author> <title> Nonmonotonic logic and temporal projection. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 379-412, </pages> <year> 1987. </year>
Reference-contexts: Perhaps a more damning problem with McDermott's approach concerns the general use of the nonmonotonic axioms such as involving consistent. An example of the problems with such approaches came to be very well known as the Yale Shooting Problem <ref> [ Hanks and McDermott, 1987 ] </ref> . In this work, it was shown that a nonmono-tonic logic such as McDermott's temporal logic could not draw some very simple commonsense inferences.
Reference: [ Hanks, 1988 ] <author> Steve Hanks. </author> <title> Representing and computing temporally scoped beliefs. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 501-505, </pages> <address> Minneapolis, Minnesota, 1988. </address> <publisher> AAAI. </publisher>
Reference-contexts: The approach taken in computing and reasoning about probability is similar to ODDS, in that the time line is partitioned into fixed length intervals, and then probability propagation is performed over those intervals. Hanks Hanks' work leading up to his dissertation <ref> [ Hanks, 1988; Hanks, 1990 ] </ref> was another early example of work in probabilistic temporal reasoning contemporaneous with ODDS. Hanks' thesis makes two main contributions. First, his probabilistic temporal manager is capable of multiple granularities of time, for instance, reasoning over different time scales such as minutes and days.
Reference: [ Hanks, 1990 ] <author> Steven John Hanks. </author> <title> Projecting Plans for Uncertain Worlds. </title> <type> PhD thesis, </type> <institution> Yale University Department of Computer Science, </institution> <month> January </month> <year> 1990. </year> <note> 176 BIBLIOGRAPHY </note>
Reference-contexts: The approach taken in computing and reasoning about probability is similar to ODDS, in that the time line is partitioned into fixed length intervals, and then probability propagation is performed over those intervals. Hanks Hanks' work leading up to his dissertation <ref> [ Hanks, 1988; Hanks, 1990 ] </ref> was another early example of work in probabilistic temporal reasoning contemporaneous with ODDS. Hanks' thesis makes two main contributions. First, his probabilistic temporal manager is capable of multiple granularities of time, for instance, reasoning over different time scales such as minutes and days.
Reference: [ Haugh, 1987 ] <author> Brian Haugh. </author> <title> Simple causal minimizations for temporal persistence and projection. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 218-223. </pages> <publisher> AAAI, </publisher> <year> 1987. </year>
Reference-contexts: In this work, it was shown that a nonmono-tonic logic such as McDermott's temporal logic could not draw some very simple commonsense inferences. It prompted a host of work that showed ways in which these inferences might be handled <ref> [ Shoham, 1988; Haugh, 1987; Lifschitz, 1987 ] </ref> . The issues raised by the Yale Shooting Problem are important, as is much of the work that followed it. However, the technical details concerning this are somewhat tangential to this thesis.
Reference: [ Hendrix, 1973 ] <author> Gary Hendrix. </author> <title> Modeling simultaneous actions and continuous processes. </title> <journal> Artificial Intelligence, </journal> <volume> 4 </volume> <pages> 145-180, </pages> <year> 1973. </year>
Reference: [ Henrion, ] <author> Max Henrion. </author> <type> Personal Communication. </type>
Reference-contexts: Tatman's result was not widely known [ Tatman and Shachter, 1990 ] at the time we developed our initial work with Markov time nets in [ Kanazawa and Dean, 1989 ] . Henrion <ref> [ Henrion, ] </ref> has developed discrete-time models with continuous random variables such as our water level example in the context of air quality modeling.
Reference: [ Henrion, 1988a ] <author> Max Henrion. </author> <title> Propagating uncertainty by logic sampling in bayes' networks. </title> <editor> In John F. Lemmer and Laveen F. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence2, </booktitle> <pages> pages 149-163. </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: Consequently, the clique tree algorithm appears to be less suitable for such networks. 4.4.3 Stochastic Simulation Stochastic simulation, often known as sampling, is a widely used method for estimating probability distributions, including its use for estimating probabilities in Bayesian networks <ref> [ Henrion, 1988a; Pearl, 1987; Shachter and Peot, 1990 ] </ref> . Sampling is the best available general method for estimating densities for continuous variables, and it has been employed for temporal reasoning in continuous-time Bayesian networks [ Berzuini et al., 1989 ] . <p> Such a combination is a prototypical interaction. In some sense, the interaction behaves like a logical gate. For this reason, some well known examples of interactions are known as noisy-OR, noisy-AND , and so on <ref> [ Henrion, 1988a; Pearl, 1988 ] </ref> . We do not implement this in Goo. However, it would be profitable to pursue it in future work. Note that the probability density functions for competing rules must be consistent.
Reference: [ Henrion, 1988b ] <author> Max Henrion. </author> <title> Towards efficient probabilistic diagnosis in multiply connected belief networks. </title> <booktitle> In Proceedings of the Conference on Influence Diagrams, </booktitle> <address> Berkeley, </address> <year> 1988. </year>
Reference: [ Horsch and Poole, 1990 ] <author> Michael C. Horsch and David Poole. </author> <title> A dynamic approach to probabilistic inference using Bayesian networks. </title> <booktitle> In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 155-161, </pages> <year> 1990. </year>
Reference: [ Horvitz et al., 1989 ] <author> Eric J. Horvitz, H. Jacques Suermondth, and Gregory F. Cooper. </author> <title> Bounded conditioning: Flexible inference for decisions under scarce resources. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 182-193, </pages> <address> Detroit, Michigan, </address> <year> 1989. </year>
Reference-contexts: These algorithms bound the probabilities on items of interest through heuristic search. Cooper [ 1984 ] and Henrion [ 1988b ] have heuristic search schemes with the aim of finding the most probable conjunctive hypothesis over an entire space of possible hypotheses. Horvitz and Suermondt's bounded cutset conditioning <ref> [ Horvitz et al., 1989 ] </ref> is reportedly an application of heuristic search to Pearl's method of cutset conditioning. 4.4.1 The Clique Tree Algorithm The clique (junction) tree algorithm, also known as the Bayesian belief universes algorithm, is due to Jensen, Lauritzen, Olesen, and Andersen [ Jensen et al., 1990; Jensen
Reference: [ Horvitz, 1987 ] <author> Eric J. Horvitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 429-439, </pages> <address> Seattle, Washington, </address> <year> 1987. </year> <editor> Also in L. Kanal, T. Levitt, and J. Lemmer, ed., </editor> <booktitle> Uncertainty in Artificial Intelligence 3, </booktitle> <publisher> Elsevier, </publisher> <year> 1989, </year> <month> pps. </month> <pages> 301-324. </pages>
Reference: [ Howard, 1960 ] <author> Ron A. Howard. </author> <title> Dynamic Programming and Markov Decision Processes. </title> <publisher> MIT Press, </publisher> <year> 1960. </year>
Reference-contexts: Operations Research Some of the closest work in probabilistic temporal reasoning have come from operations research in the context of Markov decision process theory <ref> [ Howard, 1960; Howard, 1969; Howard, 1971 ] </ref> . Our discrete-time time model of probability is essentially a Markov process. The fundamental results in this area come from the 1960s. It was impractical to attempt application of the ideas on the computing machinery of that time. <p> The part of the domain model in the figure encodes how certain actions, such as moving, change the robot's position with respect to locations, and models changing expectations about the energy remaining at a given location. These domain models can be considered descendants of Markov decision processes <ref> [ Howard, 1960; Howard, 1969; Howard, 1971 ] </ref> . A Markov decision process is a model in which there is a decision, state vector, and a value for each of a sequence of discrete points of time.
Reference: [ Howard, 1969 ] <author> Ron A. Howard. </author> <title> Dynamic Probabilistic Systems, volume I: Markov Models. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: Operations Research Some of the closest work in probabilistic temporal reasoning have come from operations research in the context of Markov decision process theory <ref> [ Howard, 1960; Howard, 1969; Howard, 1971 ] </ref> . Our discrete-time time model of probability is essentially a Markov process. The fundamental results in this area come from the 1960s. It was impractical to attempt application of the ideas on the computing machinery of that time. <p> The part of the domain model in the figure encodes how certain actions, such as moving, change the robot's position with respect to locations, and models changing expectations about the energy remaining at a given location. These domain models can be considered descendants of Markov decision processes <ref> [ Howard, 1960; Howard, 1969; Howard, 1971 ] </ref> . A Markov decision process is a model in which there is a decision, state vector, and a value for each of a sequence of discrete points of time.
Reference: [ Howard, 1971 ] <author> Ron A. Howard. </author> <title> Dynamic Probabilistic Systems, volume II: Semi-Markov and Decision Processes. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1971. </year> <note> BIBLIOGRAPHY 177 </note>
Reference-contexts: Operations Research Some of the closest work in probabilistic temporal reasoning have come from operations research in the context of Markov decision process theory <ref> [ Howard, 1960; Howard, 1969; Howard, 1971 ] </ref> . Our discrete-time time model of probability is essentially a Markov process. The fundamental results in this area come from the 1960s. It was impractical to attempt application of the ideas on the computing machinery of that time. <p> we say that V t is the objective value at time t As we noted earlier, f will be typically be a sum or discounted sum of the V t , i.e., f (V ) = t or X fl t V t ; where fl is a discount factor <ref> [ Howard, 1971 ] </ref> . In the domain models of our simplified environment, a decision maker needs to make only one decision at any point in time: what plan of action to follow. <p> The part of the domain model in the figure encodes how certain actions, such as moving, change the robot's position with respect to locations, and models changing expectations about the energy remaining at a given location. These domain models can be considered descendants of Markov decision processes <ref> [ Howard, 1960; Howard, 1969; Howard, 1971 ] </ref> . A Markov decision process is a model in which there is a decision, state vector, and a value for each of a sequence of discrete points of time.
Reference: [ Jaffar and Lassez, 1987 ] <author> Joxan Jaffar and Jean-Louis Lassez. </author> <title> Constraint logic programming. </title> <booktitle> In Proceedings of the 14th ACM Conference on the Principles of Programming Languages, </booktitle> <pages> pages 111-119, </pages> <address> Munich, </address> <year> 1987. </year>
Reference-contexts: FUTURE DIRECTION 167 of the temporal database and the theory underlying dynamic management of temporal uncertainty information. One possibility is to continue the path started in Goo. Another is to explore the relation of the probabilistic temporal database with constraint logic programming <ref> [ van Hentenryck, 1991; Jaffar and Lassez, 1987 ] </ref> and with non-probabilistic temporal databases such as the TMM, and combining discrete optimization methods with probabilities. Progress on translating arbitrary theories into time nets is essential for future development. This includes automatic unfolding of cyclical theories into acyclical models.
Reference: [ Jaynes, 1979 ] <author> Edwin T. Jaynes. </author> <title> Where do we stand on maximum entropy. </title> <editor> In Levin and Tribus, editors, </editor> <booktitle> The Maximum Entropy Formalism, </booktitle> <pages> pages 15-118. </pages> <publisher> MIT Press, </publisher> <year> 1979. </year>
Reference-contexts: This assumption is difficult to relax without a method of "completing" the model based on the incomplete probability distributions. The prototypical interactions that we discussed above is one method of model completion. Maximum entropy methods are another <ref> [ Jaynes, 1979; Cheeseman, 1983; Lippman, 1986 ] </ref> . Assumption 3 ensures that there is a single time net in consideration. This assumption can be relaxed trivially, at least conceptually.
Reference: [ Jensen et al., 1988 ] <author> Finn V. Jensen, Kristian G. Olesen, and Stig K. Andersen. </author> <title> An algebra of bayesian belief universes for knowledge based systems. </title> <type> R- 88-25, </type> <institution> Institute for Electronic Systems, Aalborg University, Aalborg, Denmark, </institution> <month> July </month> <year> 1988. </year>
Reference-contexts: and Suermondt's bounded cutset conditioning [ Horvitz et al., 1989 ] is reportedly an application of heuristic search to Pearl's method of cutset conditioning. 4.4.1 The Clique Tree Algorithm The clique (junction) tree algorithm, also known as the Bayesian belief universes algorithm, is due to Jensen, Lauritzen, Olesen, and Andersen <ref> [ Jensen et al., 1990; Jensen et al., 1988 ] </ref> 3 . The algorithm is closely related to another clique based algorithm, the somewhat better known Lauritzen-Spiegelhalter algorithm [ Lauritzen and Spiegelhalter, 1988 ] .
Reference: [ Jensen et al., 1990 ] <author> Finn V. Jensen, Steffen L. Lauritzen, and Kristian G. Olesen. </author> <title> Bayesian updating in recursive graphical models by local computations. </title> <journal> Computational Statistics Quarterly, </journal> <volume> 5(4) </volume> <pages> 269-282, </pages> <year> 1990. </year>
Reference-contexts: and Suermondt's bounded cutset conditioning [ Horvitz et al., 1989 ] is reportedly an application of heuristic search to Pearl's method of cutset conditioning. 4.4.1 The Clique Tree Algorithm The clique (junction) tree algorithm, also known as the Bayesian belief universes algorithm, is due to Jensen, Lauritzen, Olesen, and Andersen <ref> [ Jensen et al., 1990; Jensen et al., 1988 ] </ref> 3 . The algorithm is closely related to another clique based algorithm, the somewhat better known Lauritzen-Spiegelhalter algorithm [ Lauritzen and Spiegelhalter, 1988 ] . <p> Chordality in the Markov graph is a necessary and sufficient condition for guaranteeing consistency in computations with the junction tree [ Jensen, 1988 ] . Changes to clique distributions are propagated to neighboring cliques through the intersection of the cliques, in an operation called calibration or absorption <ref> [ Jensen et al., 1990 ] </ref> . The clique intersections themselves are called separating node sets or sepsets for short. Beliefs in individual nodes are obtained by marginalizing the clique distributions. Let us now describe in closer detail the steps required to transform a Bayesian network into a junction tree.
Reference: [ Jensen, 1988 ] <author> Finn V. Jensen. </author> <title> Junction trees and decomposable hypergraphs. </title> <type> Research report, </type> <institution> JUDEX, Aalborg, </institution> <year> 1988. </year>
Reference-contexts: We define distribution functions on the cliques of the chordal graph and the cliques are joined in a tree. This is the junction tree. Chordality in the Markov graph is a necessary and sufficient condition for guaranteeing consistency in computations with the junction tree <ref> [ Jensen, 1988 ] </ref> . Changes to clique distributions are propagated to neighboring cliques through the intersection of the cliques, in an operation called calibration or absorption [ Jensen et al., 1990 ] . The clique intersections themselves are called separating node sets or sepsets for short.
Reference: [ Jensen, 1990 ] <author> Finn V. Jensen. </author> <type> Personal communication, </type> <year> 1990. </year>
Reference: [ Kaelbling, 1990 ] <author> Leslie Pack Kaelbling. </author> <title> Learning in Embedded Systems. </title> <type> PhD thesis, </type> <institution> Stanford University, Stanford, </institution> <year> 1990. </year>
Reference-contexts: In decision-making applications, it may be equally important to bypass inference, and learn the right actions in different situations directly. Current work in this area includes work in reinforcement learning <ref> [ Sutton, 1990; Kaelbling, 1990 ] </ref> . 168 CHAPTER 7. CONCLUSIONS 7.3.7 Applications Last but not least, we must further explore the application of the ideas in this thesis in real applications. Domains of particular interest are medicine, distributed networks, transportation, and robotics and vision.
Reference: [ Kahn and Gorry, 1977 ] <author> Kenneth Kahn and G. Anthony Gorry. </author> <title> Mechanizing temporal knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 9 </volume> <pages> 87-108, </pages> <year> 1977. </year>
Reference: [ Kanazawa and Dean, 1989 ] <author> Keiji Kanazawa and Thomas Dean. </author> <title> A model for projection and action. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, Michigan, </address> <year> 1989. </year> <pages> IJCAI. </pages>
Reference-contexts: Intuitively, the more detailed and accurate a model, the more expensive it would be to compute with. This is a research area of growing interest in artificial intelligence, especially as pertaining to real-time systems. We have made preliminary investigations in <ref> [ Kanazawa and Dean, 1989 ] </ref> . At any rate, we are interested in domains that contain basic facts about time, and domain theories about how facts and their chances change over time. <p> Tatman's result was not widely known [ Tatman and Shachter, 1990 ] at the time we developed our initial work with Markov time nets in <ref> [ Kanazawa and Dean, 1989 ] </ref> . Henrion [ Henrion, ] has developed discrete-time models with continuous random variables such as our water level example in the context of air quality modeling. <p> Subsequent to ODDS, research in language issues were gradually put aside as sophisticated algorithms for computing probabilities were sought. In much of this research, which involved discrete time nets, the computational complexity of evaluation was such that we tended to concentrate on fixed models for each domain <ref> [ Kanazawa and Dean, 1989 ] </ref> . However, it was always assumed that there was a reasoning system that generated the fixed models to be used for evaluation. As the research moved from discrete time nets to continuous time nets, such issues came to the fore again. <p> In our own work, we have generally applied a Bayesian network algorithm to influence diagram evaluation, as there are more efficient special algorithms for the former, as we saw in Chapter 4. In <ref> [ Kanazawa and Dean, 1989 ] </ref> , we define a special class of influence diagram that we simply called domain models. A domain model is essentially an influence diagram where the chance nodes (and perhaps decision nodes) constitutes a discrete time net, 6.2. <p> In the domain models of our simplified environment, a decision maker needs to make only one decision at any point in time: what plan of action to follow. Figure 6.2 depicts part of a domain model for a simple simulated autonomous "agent" <ref> [ Kanazawa and Dean, 1989 ] </ref> . This agent is designed to model a mobile robot that moves about in a simple environment and tries to stay in operation by replenishing its energy at locations known to have energy sources.
Reference: [ Kanazawa, 1991 ] <author> Keiji Kanazawa. </author> <title> A logic and time nets for probabilistic inference. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <address> Ana-heim, California, 1991. </address> <publisher> AAAI. </publisher>
Reference-contexts: The field sort: * F c : A set of field constants. * F f : Field functions of various fixed arity. * =: The field relation operator. 2 A logic essentially similar to LL1 was presented in <ref> [ Kanazawa, 1991 ] </ref> under a different name. 3.2. LL1 45 We also have the probability operator P. Recall the fact that we allow field functions over both time and field sorts.
Reference: [ Kim and Pearl, 1983 ] <author> Jin H. Kim and Judea Pearl. </author> <title> A computational model for causal and diagnostic reasoning in inference systems. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <address> Karlsluhe, West Germany, </address> <year> 1983. </year> <title> IJCAI. 178 BIBLIOGRAPHY </title>
Reference: [ Knuth, 1981 ] <author> Donald E. Knuth. </author> <title> Seminumerical Algorithms, </title> <booktitle> volume 2 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> 2nd edition, </address> <year> 1981. </year>
Reference: [ Kyburg, 1983 ] <author> Henry E. Kyburg, Jr. </author> <title> The reference class. </title> <journal> Philosophy of Science, </journal> <volume> 50 </volume> <pages> 374-397, </pages> <year> 1983. </year>
Reference-contexts: Within AI, work in logics for reasoning about time and probability is a recent development. 60 CHAPTER 3. THE LOGIC OF LIFETIMES 3.4.1 Weber Weber [ 1989a; 1989b ] has developed a conceptually simple and clean framework for causal reasoning with uncertainty, based on the idea of reference classes <ref> [ Kyburg, 1983 ] </ref> . Reference classes feature, essentially, a type of inheritance reasoning. A given proposition P may belong to a number of reference classes, some more specific than others. More specific classes yield more specific statistics for members of a given reference class.
Reference: [ Lauritzen and Spiegelhalter, 1988 ] <author> Steffen L. Lauritzen and David J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 50(2) </volume> <pages> 157-194, </pages> <year> 1988. </year>
Reference-contexts: The algorithm is closely related to another clique based algorithm, the somewhat better known Lauritzen-Spiegelhalter algorithm <ref> [ Lauritzen and Spiegelhalter, 1988 ] </ref> .
Reference: [ Lauritzen et al., 1984 ] <author> S. L. Lauritzen, T. P. Speed, and K. Vijayan. </author> <title> Decomposable graphs and hypergraphs. </title> <journal> Journal Australian Mathematical Society, </journal> <volume> A(36):12-29, </volume> <year> 1984. </year>
Reference-contexts: The graph abstraction of probabilistic networks separates qualitative issues of dependence between random variables from the purely quantitative aspects of the probability distributions of the random variables. Inquiry into the formal properties of probabilistic networks has found them quite robust <ref> [ Lauritzen et al., 1984; Pearl, 1988 ] </ref> . Clear relationships between graphs and probability distributions have been proven, making it easy to ensure that their use is consistent. <p> First, we introduce graph concepts and the Bayesian network. Then, we present the time net itself. Finally, we discuss algorithms for evaluating time nets. 4.1 Graph Notation and Concepts First, we present some graph notation. This presentation follows that of Tarjan [ Tarjan and Yannakakis, 1984 ] and Lauritzen <ref> [ Lauritzen et al., 1984 ] </ref> . <p> Directed graph models of probability similar to Bayesian networks were apparently first formally investigated by Wright in his work on path analysis in genetics ( [ Wright, 1921 ] as cited in, e.g., <ref> [ Lauritzen et al., 1984 ] </ref> ). An excellent introduction to Bayesian networks, and to probabilistic networks in general, is Pearl's book [ 1988 ] . Another excellent text on Bayesian networks is Neapolitan's book [ 1990 ] . 4.2. <p> By contrast, methods by Lauritzen and Spiegelhalter [ 1988 ] and by Jensen and others [ 1990 ] form aggregates out of the cliques of the decomposition <ref> [ Lauritzen et al., 1984 ] </ref> of the original network. The cliques are then linked either in an undirected tree or chain over which an efficient propagation scheme similar to Kim-Pearl can be applied (see Figure 4.13 (c)).
Reference: [ Lauritzen et al., 1988 ] <author> Steffen L. Lauritzen, A.P. Dawid, B.N. Larsen, and H.-G. Leimer. </author> <title> Independence properties of directed markov fields. </title> <type> Technical Report R 88-32, </type> <institution> Institute for Electronic Systems, Department of Mathematics and Computer Science, University of Aalborg, </institution> <year> 1988. </year>
Reference: [ Lifschitz, 1987 ] <author> Vladimir Lifschitz. </author> <title> Formal theories of action: Preliminary report. </title> <editor> In Frank M. Brown, editor, </editor> <booktitle> The Frame Problem in Artificial Intelligence: proceedings of the 1987 Workshop. </booktitle> <publisher> Morgan Kaufmann, Lawrence, </publisher> <address> Kansas, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: One is the reified representation, which adopts a special predicate to associate the state of a fluent with a situation. Commonly, the predicate used is holds (e.g., <ref> [ Lifschitz, 1987 ] </ref> ). In this approach, the previous is written as holds (raining (x), s) (or with the situation and fluent arguments reversed). The other approach associates the situation directly with each fluent. An example would be raining (x, s). <p> In this work, it was shown that a nonmono-tonic logic such as McDermott's temporal logic could not draw some very simple commonsense inferences. It prompted a host of work that showed ways in which these inferences might be handled <ref> [ Shoham, 1988; Haugh, 1987; Lifschitz, 1987 ] </ref> . The issues raised by the Yale Shooting Problem are important, as is much of the work that followed it. However, the technical details concerning this are somewhat tangential to this thesis.
Reference: [ Lippman, 1986 ] <author> Alan F. Lippman. </author> <title> A Maximum Entropy Method for Expert System Construction. </title> <type> PhD thesis, </type> <institution> Brown University, </institution> <year> 1986. </year>
Reference-contexts: This assumption is difficult to relax without a method of "completing" the model based on the incomplete probability distributions. The prototypical interactions that we discussed above is one method of model completion. Maximum entropy methods are another <ref> [ Jaynes, 1979; Cheeseman, 1983; Lippman, 1986 ] </ref> . Assumption 3 ensures that there is a single time net in consideration. This assumption can be relaxed trivially, at least conceptually.
Reference: [ Martin and Allen, 1991 ] <author> Nathaniel Martin and James Allen. </author> <title> A language for planning with statistics. </title> <booktitle> In Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 220-227, </pages> <address> Anaheim, California, </address> <year> 1991. </year>
Reference: [ McCarthy and Hayes, 1969 ] <author> John McCarthy and Patrick J. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <journal> Machine Intelligence, </journal> <volume> 4, </volume> <year> 1969. </year>
Reference-contexts: The situation calculus was the first (AI) logical representation for reasoning about time and change. In the situation calculus the chief ontological entity is a set of 14 CHAPTER 2. TIME AND CHANCE instantaneous states, called situations. The definition of a situation is <ref> [ McCarthy and Hayes, 1969 ] </ref> : The complete state of the universe at an instant of time. In practice, a situation is an abstract entity that is usually never fully specified. Instead, a situation is only partly specified by the facts that are known about it. <p> There are many definitions of the frame problem, but the above definition suffices for our purposes. In trying to write down situation calculus axioms about how to undertake tasks, it was discovered that it may be necessary to write down knowledge about what remains true in each situation <ref> [ McCarthy and Hayes, 1969 ] </ref> . For instance, suppose that our task is to deliver a package X from city A to city B.
Reference: [ McCarthy, 1986 ] <author> John McCarthy. </author> <title> Applications of circumscription to formalizing commonsense knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 89-116, </pages> <year> 1986. </year>
Reference-contexts: TEMPORAL REASONING IN AI 23 nonmonotonic reasoning. The application of nonmonotonic reasoning is especially important in trying to solve the frame problem. A well-known attempt to solve the frame problem within the situation calculus is known as circumscription, due to Mc-Carthy <ref> [ McCarthy, 1986 ] </ref> . However, the first attempts at developing nonmonotonic reasoning was by McDermott again, in conjunction with Doyle [ 1980 ] . This approach was adopted in McDermott's temporal logic.
Reference: [ McDermott and Doyle, 1980 ] <author> Drew V. McDermott and Jon Doyle. </author> <title> Non-monotonic logic I. </title> <journal> Artificial Intelligence, </journal> <volume> 13 </volume> <pages> 41-72, </pages> <year> 1980. </year> <note> BIBLIOGRAPHY 179 </note>
Reference: [ McDermott, 1982 ] <author> Drew V. McDermott. </author> <title> A temporal logic for reasoning about processes and plans. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 101-155, </pages> <year> 1982. </year>
Reference-contexts: at t, we might write holds (t; ' 1 ^ ' 2 : : : ^ ' n ) ^ occ (t; " 1 ) occ (t + ffi; " 2 ): If the caused event is of a type E ('), this is often referred to as persistence causation <ref> [ McDermott, 1982 ] </ref> . <p> Goo&gt; (P (&lt; (date-of #-(arrive times-square)-) #@"noon")) 0.523 That concludes our short example of how Goo is programmed, and how interaction with Goo can proceed. 5.4 Historical Note McDermott considered the issues behind creating a system for managing knowledge about time in <ref> [ McDermott, 1982 ] </ref> . Dean [ 1985 ] developed those ideas in his TMM (Time Map Manager) work. Much of the conceptual underpinnings of the current work are inspired in part by this and other related work (especially [ Shoham, 1988 ] ).
Reference: [ Metropolis et al., 1953 ] <author> Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller. </author> <title> Equation of state calculations by fast computing machines. </title> <journal> The Journal of Chemical Physics, </journal> <volume> 21(6) </volume> <pages> 1087-1092, </pages> <month> June </month> <year> 1953. </year>
Reference-contexts: THE TIME NET simulation. Monte Carlo simulation, as with sampling itself, has its origins in the physical sciences <ref> [ von Neumann, 1951; Metropolis et al., 1953 ] </ref> . The basic idea of sampling is simple. The idea is to estimate variables, in our case probability distributions, by repeated trials.
Reference: [ Miller et al., 1976 ] <author> A.C. Miller, M. M. Merkhofer, R. A. Howard, J. E. Matheson, and T. R. Rice. </author> <title> Development of automated aids for decision analysis. </title> <type> Technical report, </type> <institution> Stanford Research Institute, </institution> <address> Menlo Park, </address> <year> 1976. </year> <note> cited by Tatman and Shachter. </note>
Reference-contexts: LL does not have such facilities. 6.2 The Influence Diagram We considered the extension of Bayesian network to include utility functions in Section 4.3.2. As it happens, there is a special class of such graph models tailored for use in decision theory known as the influence diagram <ref> [ Miller et al., 1976 ] </ref> . The influence diagram generalizes the Bayesian network by including the effects of deterministic decisions and the utility function. An influence diagram is a directed graph D = (N; A), consisting of a set of nodes N , and a set of arcs A.
Reference: [ Neapolitan, 1990 ] <author> Richard E. </author> <title> Neapolitan. Probabilistic Reasoning in Expert Systems, Theory and Algorithms. </title> <publisher> Wiley, </publisher> <year> 1990. </year>
Reference: [ Nilsson, 1986 ] <author> Nils Nilsson. </author> <title> Probabilistic logic. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 71-88, </pages> <year> 1986. </year>
Reference-contexts: Probability on Possible Worlds or on the Domain? The main ideas behind logics with a subjective interpretation of probability is that there is a probability distribution over possible worlds. These logics directly take after Nilsson's probabilistic logic <ref> [ Nilsson, 1986 ] </ref> , as with the logics by Fagin and others [ Fagin et al., 1990 ] , and by Halpern [ Halpern, 1989 ] . Note though that theoretical computer scientists and philosophers predate the artificial intelligence practitioners with regard to this.
Reference: [ Nunez, 1989 ] <author> Linda Mensinger Nunez. </author> <title> The relationship between temporal bayes networks and markov random process tables. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1989. </year>
Reference-contexts: Nunez <ref> [ Nunez, 1989 ] </ref> has proved equivalence in expressive power between temporal Bayes nets and Markov chains. She provides a procedure which, given a Markov time net, constructs a corresponding Markov model that encodes the same information.
Reference: [ Olesen et al., 1989 ] <author> Kristian G. Olesen, Uffe Kjaerluff, Frank Jensen, Finn V. Jensen, Bjorn Falck, Steen Andreassen, and StigK. Andersen. </author> <title> A munin network for the median nerve a case study on loops. </title> <journal> Applied Artificial Intelligence, </journal> <year> 1989. </year> <title> Special issue: Towards Causal AI Models in Practice. </title>
Reference-contexts: However, these results were not generally known until recently. 4.4. COMPUTATION 101 medical diagnosis application <ref> [ Olesen et al., 1989 ] </ref> . The basic idea of the clique tree algorithm is to transform a multiply-connected Bayesian network into a tree of clusters of nodes.
Reference: [ Pearl and Verma, 1991 ] <author> Judea Pearl and Thomas Verma. </author> <title> A theory of inferred causation. </title> <booktitle> In Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 441-452, </pages> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: It is important to incorporate learning of models into our framework, as model specification can impose a considerable burden on users. This is a wide open area, including simply learning fact duration and event occurrence statistics, learning statistics from cases, learning appropriate graph structure <ref> [ Pearl and Verma, 1991; Glymour et al., 1987 ] </ref> , and induction of logical theories. In decision-making applications, it may be equally important to bypass inference, and learn the right actions in different situations directly.
Reference: [ Pearl et al., 1989 ] <author> Judea Pearl, Dan Geiger, and Thomas Verma. </author> <title> Conditional independence and its representations. </title> <journal> Kybernetika, </journal> <volume> 25 </volume> <pages> 33-44, </pages> <year> 1989. </year>
Reference: [ Pearl, 1986 ] <author> Judea Pearl. </author> <title> A constraint propagation approach to probabilistic reasoning. </title> <editor> In Laveen N. Kanal and John F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence. </booktitle> <publisher> North-Holland, </publisher> <year> 1986. </year> <note> 180 BIBLIOGRAPHY </note>
Reference-contexts: Then the Kim-Pearl or Peot-Shachter algorithm can be applied. For any given network, a set of nodes that collectively render a multiply-connected network singly-connected in this fashion is a cutset of the graph. Pearl's method of cutset conditioning <ref> [ Pearl, 1986 ] </ref> takes such a cutset of a network, instantiates the nodes in the cutset to all possible values, and computes the weighted average of the posterior beliefs derived by applying Kim-Pearl to each instantiation.
Reference: [ Pearl, 1987 ] <author> Judea Pearl. </author> <title> Evidential reasoning using stochastic simulation of causal models. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 245-257, </pages> <year> 1987. </year>
Reference-contexts: Consequently, the clique tree algorithm appears to be less suitable for such networks. 4.4.3 Stochastic Simulation Stochastic simulation, often known as sampling, is a widely used method for estimating probability distributions, including its use for estimating probabilities in Bayesian networks <ref> [ Henrion, 1988a; Pearl, 1987; Shachter and Peot, 1990 ] </ref> . Sampling is the best available general method for estimating densities for continuous variables, and it has been employed for temporal reasoning in continuous-time Bayesian networks [ Berzuini et al., 1989 ] .
Reference: [ Pearl, 1988 ] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, </address> <year> 1988. </year>
Reference-contexts: The graph abstraction of probabilistic networks separates qualitative issues of dependence between random variables from the purely quantitative aspects of the probability distributions of the random variables. Inquiry into the formal properties of probabilistic networks has found them quite robust <ref> [ Lauritzen et al., 1984; Pearl, 1988 ] </ref> . Clear relationships between graphs and probability distributions have been proven, making it easy to ensure that their use is consistent. <p> The Bayesian network is only one class of graphical models about probabilistic dependencies, called dependency models. Some dependency models, such as cyclic theories, or complex mutual dependencies cannot be represented in a Bayesian network. For more details on these issues, see <ref> [ Pearl, 1988 ] </ref> 72 CHAPTER 4. THE TIME NET Identifying independence has important consequences for computation. Suppose that there is a Bayesian network consisting of hundreds of nodes, and we are interested in the probability of one of the random variables. <p> The state space of each aggregate node set is the cross product of the nodes in the set. The distribution for each node is derived by marginalization of the/an aggregate node set that it belongs to. There are two distinct classes of clustering algorithms. Pearl's method of node aggregation <ref> [ Pearl, 1988 ] </ref> forms a DAG out of a particular partition of nodes into clusters, and then applies the Kim-Pearl algorithm (see Figure 4.13 (b)). <p> Our method exploits the numbering obtained by a maximum cardinality search [ Tarjan and Yannakakis, 1984 ] that we employ in verifying the fill-in, and we form the junction tree utilizing the join tree algorithm in <ref> [ Pearl, 1988 ] </ref> (see In the junction tree, both cliques and sepsets have distribution functions, C and S . They are not probability distributions, as they are not required to be normalized (sum to 1). They are only required to have correct proportionalities. <p> Such a combination is a prototypical interaction. In some sense, the interaction behaves like a logical gate. For this reason, some well known examples of interactions are known as noisy-OR, noisy-AND , and so on <ref> [ Henrion, 1988a; Pearl, 1988 ] </ref> . We do not implement this in Goo. However, it would be profitable to pursue it in future work. Note that the probability density functions for competing rules must be consistent.
Reference: [ Peot and Shachter, 1991 ] <author> Mark Peot and Ross Shachter. </author> <title> Fusion and propagation with multiple observations in belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3), </volume> <year> 1991. </year>
Reference: [ Peot, 1992 ] <author> Mark Peot. </author> <title> Conditional nonlinear planning. </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <address> College Park, Maryland, </address> <year> 1992. </year>
Reference-contexts: Extensions for allowing assertion of holds and unground queries and assertions should be relatively straightforward. A more difficult but important extension is handling multiple models with strategies for conflict resolution. 7.3.5 Action The combination of nonlinear planning with decision theoretic models are a promising avenue to explore <ref> [ Peot, 1992 ] </ref> . In planning, there is a greater need to interleave construction and evaluation of multiple models.
Reference: [ Poole, 1991a ] <author> David Poole. </author> <title> Representing Bayesian networks within probabilistic Horn abduction. </title> <booktitle> In Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 271-278, </pages> <address> Anaheim, California, </address> <year> 1991. </year> <booktitle> Association for Uncertainty in Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The relatively simple framework of Goo is perhaps most similar to Breese's ALTERID. At present, LL is not an object level language for describing Bayesian networks such as Poole's Probabilistic Horn Abduction <ref> [ Poole, 1991a; Poole, 1991b ] </ref> , although it may be possible to make it one. Chapter 6 Decision Making As we have touched on, the ultimate goal of this research is to provide a way of making plans and of making decisions.
Reference: [ Poole, 1991b ] <author> David Poole. </author> <title> Representing diagnostic knowledge for probabilistic Horn abduction. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1129-1135, </pages> <address> Sydney, Australia, </address> <year> 1991. </year> <pages> IJCAI. </pages>
Reference-contexts: The relatively simple framework of Goo is perhaps most similar to Breese's ALTERID. At present, LL is not an object level language for describing Bayesian networks such as Poole's Probabilistic Horn Abduction <ref> [ Poole, 1991a; Poole, 1991b ] </ref> , although it may be possible to make it one. Chapter 6 Decision Making As we have touched on, the ultimate goal of this research is to provide a way of making plans and of making decisions.
Reference: [ Press et al., 1988 ] <author> William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling. </author> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1988. </year>
Reference: [ Ripley, 1987 ] <author> Brian D. Ripley. </author> <title> Stochastic Simulation. </title> <publisher> Wiley, </publisher> <year> 1987. </year>
Reference-contexts: The basic idea of sampling is simple. The idea is to estimate variables, in our case probability distributions, by repeated trials. In each trial, each random variable is sampled from its underlying distribution <ref> [ Devroye, 1986; Ripley, 1987 ] </ref> in a fixed order. For the moment, let us pretend that there is no evidence; adding evidence requires an additional step, albeit a simple step. A sample is a simulated value for the random variable. <p> It is also possible to sample the density for an event directly from its corresponding hazard function <ref> [ Ripley, 1987 ] </ref> . The Sam Bayesian network evaluator implements a range of such sampling functions (see Section 5.2.6). 4.4.4 Network Processing The performance of all Bayesian network evaluation algorithms depend on the number of nodes in the network.
Reference: [ Rit, 1986 ] <author> J.-F. Rit. </author> <title> Propagating temporal constraints for scheduling. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 383-388, </pages> <address> Philadelphia, Pennsylvania, 1986. </address> <publisher> AAAI. </publisher>
Reference: [ Rose et al., 1976 ] <author> Donald J. Rose, R. Endre Tarjan, and George S. Lueker. </author> <title> Algorithmic aspects of vertex elimination on graphs. </title> <journal> SIAM Journal of Computing, </journal> <volume> 3(2) </volume> <pages> 266-283, </pages> <month> June </month> <year> 1976. </year>
Reference-contexts: We conjecture that this problem is also NP-complete. Because of the exponential factor, a good heuristic is to minimize the quantity max . Jensen [ 1990; 1990 ] has developed a greedy heuristic algorithm for the first problem. The fill-in is given by the following elimination order ( <ref> [ Rose et al., 1976 ] </ref> is a good reference for elimination orders): Step 1. Eliminate any node whose neighborhood forms a clique. Step 2. Eliminate the node that would produce the smallest size clique. The algorithm runs in O ((ne) 2 ). <p> COMPUTATION 107 each time it was faster to do that, than to save the result of the triangulation to file, or to read it back. As it turned out, this simpler algorithm was previously discovered by Rose at least as early as 1976 <ref> [ Rose et al., 1976 ] </ref> . So although we improved Jensen's algorithm, it had been discovered long before Jensen. At any rate, the complexity of the Rose algorithm is O (n + e 0 ), where e 0 is the number of edges, plus the fill-in.
Reference: [ Rubinstein, 1981 ] <author> Reuven Y. Rubinstein. </author> <title> Simulation and the Monte Carlo Method. </title> <publisher> Wiley, </publisher> <year> 1981. </year>
Reference: [ Russell and Wefald, 1989 ] <author> Stuart J. Russell and Eric H. Wefald. </author> <note> Principles of metar-easoning. In Brachman et al. [ 1989 ] . BIBLIOGRAPHY 181 </note>
Reference: [ Russell and Wefald, 1991 ] <author> Stuart J. Russell and Eric H. Wefald. </author> <title> Do The Right Thing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: This has occurred most notably in relation to constraints about reasoning time. If there is a limited time in which to make a decision, then it may not be possible to explore all possible solutions. A decision maker in such a situation may have bounded rationality <ref> [ Russell and Wefald, 1991 ] </ref> , at least in the sense where rationality is defined as always doing the decision theoretically optimal action. 6.1.1 Language Issues Can we represent decision theoretic choice by a logic-like language such as we did with probability and time? We have seen in Chapter 2
Reference: [ Savage, 1954 ] <author> Leonard J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Dover, </publisher> <year> 1954. </year>
Reference-contexts: We may only know how things behave on average. The last two points often come under the single label of uncertainty, both in artificial intelligence and in philosophy. For example, in the Bayesian view <ref> [ Savage, 1954 ] </ref> , uncertainty and therefore chance is a measure of ignorance. If we had perfect information about the universe, then there would be no uncertainty, and thus no chance. We will not go into depth into this distinction here. <p> In this section, we outline how the model of reasoning about change introduced in the previous chapters support making plans and making decisions. In particular, we consider how to apply decision theory for the problem of planning and decision making. Decision theory is the (mathematical) study of decision making <ref> [ von Neumann and Morgenstern, 1947; Savage, 1954; Simon, 1957 ] </ref> . It tells us the course of action that a rational agent should choose from a set of alternatives. Decision theory in this sense is said to be a prescriptive theory.
Reference: [ Schubert, 1989 ] <author> Lenhart Schubert. </author> <title> Solving the original frame problem without frame axioms or nonmonotonicity or frame axioms. </title> <editor> In Henry Kyburg and Ron Loui, editors, </editor> <booktitle> Selected Papers from the 1988 Society for Exact Philosophy Conference, </booktitle> <year> 1989. </year>
Reference-contexts: This assumption that a fact remain true as long as no action takes place that specifies a 3 It turns out that this can be accomplished <ref> [ Schubert, 1989 ] </ref> , but this result is tangential to this thesis. 18 CHAPTER 2. TIME AND CHANCE change in the fact's status is known as the STRIPS assumption, and it represents one approach to a domain independent way of attacking the frame problem.
Reference: [ Shachter and Peot, 1989 ] <author> Ross D. Shachter and Mark A. Peot. </author> <title> Evidential reasoning using likelihood weighting. </title> <type> Technical report, </type> <institution> Artificial Intelligence, Engineering-Economic Systems Department, Stanford University, </institution> <year> 1989. </year>
Reference-contexts: Monte Carlo schemes have nice conceptual properties, and they are the only general algorithm for continuous random variables. Therefore, for continuous time nets, these are the only algorithms considered. Such algorithms had problems with convergence in the past, but recently, these have been ameliorated <ref> [ Fung and Chang, 1989; Shachter and Peot, 1989 ] </ref> , and they have seen renewed interest [ Shwe and Cooper, 1990 ] . (4) Bounding. These algorithms bound the probabilities on items of interest through heuristic search.
Reference: [ Shachter and Peot, 1990 ] <author> Ross D. Shachter and Mark A. Peot. </author> <title> Simulation approaches to general probabilistic inference on belief networks. </title> <editor> In John F. Lem-mer and Laveen F. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence5. </booktitle> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: Consequently, the clique tree algorithm appears to be less suitable for such networks. 4.4.3 Stochastic Simulation Stochastic simulation, often known as sampling, is a widely used method for estimating probability distributions, including its use for estimating probabilities in Bayesian networks <ref> [ Henrion, 1988a; Pearl, 1987; Shachter and Peot, 1990 ] </ref> . Sampling is the best available general method for estimating densities for continuous variables, and it has been employed for temporal reasoning in continuous-time Bayesian networks [ Berzuini et al., 1989 ] .
Reference: [ Shachter, 1986 ] <author> Ross D. Shachter. </author> <title> Evaluating influence diagrams. </title> <journal> Operations Research, </journal> <volume> 34(6) </volume> <pages> 871-882, </pages> <month> November/December </month> <year> 1986. </year>
Reference-contexts: We are also interested in input , in evidence. So we cannot remove any nodes for which we might expect to receive evidence. But potentially, all other nodes may be removed. In time interval 1 and 4. There is a well known method <ref> [ Shachter, 1986 ] </ref> for eliminating nodes in a Bayesian network. This is the process of absorption; when a node is absorbed, its children inherit its parents, and new conditional distributions are computed for each of the children. A node may not be removed under two conditions. <p> We adopt multiple value nodes as they have some representational and computational advantages. There are other constraints that define "proper" as opposed to irregular influence diagrams. For details, see <ref> [ Shachter, 1986 ] </ref> .
Reference: [ Shoham, 1988 ] <author> Yoav Shoham. </author> <title> Reasoning About Change: Time and Causation from the Standpoint of Artificial Intelligence. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1988. </year>
Reference-contexts: In this work, it was shown that a nonmono-tonic logic such as McDermott's temporal logic could not draw some very simple commonsense inferences. It prompted a host of work that showed ways in which these inferences might be handled <ref> [ Shoham, 1988; Haugh, 1987; Lifschitz, 1987 ] </ref> . The issues raised by the Yale Shooting Problem are important, as is much of the work that followed it. However, the technical details concerning this are somewhat tangential to this thesis. <p> Dean [ 1985 ] developed those ideas in his TMM (Time Map Manager) work. Much of the conceptual underpinnings of the current work are inspired in part by this and other related work (especially <ref> [ Shoham, 1988 ] </ref> ). The TMM was a database for knowledge about time, facts, and events. Its representation of time was discrete, and it did not address issues of probability directly. 5.4.
Reference: [ Shwe and Cooper, 1990 ] <author> Michael Shwe and Gregory Cooper. </author> <title> An empirical analysis of likelihood-weighting simulation on a large, multiply-connected belief network. </title> <booktitle> In Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 498-508, </pages> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Therefore, for continuous time nets, these are the only algorithms considered. Such algorithms had problems with convergence in the past, but recently, these have been ameliorated [ Fung and Chang, 1989; Shachter and Peot, 1989 ] , and they have seen renewed interest <ref> [ Shwe and Cooper, 1990 ] </ref> . (4) Bounding. These algorithms bound the probabilities on items of interest through heuristic search.
Reference: [ Simon and Kadane, 1975 ] <author> Herbert A. Simon and Joseph B. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference: [ Simon, 1957 ] <author> Herbert Simon. </author> <title> Models of Man: Social and Rational; Mathematical Essays on Rational Human Behavior in Society Setting. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1957. </year> <note> 182 BIBLIOGRAPHY </note>
Reference-contexts: In this section, we outline how the model of reasoning about change introduced in the previous chapters support making plans and making decisions. In particular, we consider how to apply decision theory for the problem of planning and decision making. Decision theory is the (mathematical) study of decision making <ref> [ von Neumann and Morgenstern, 1947; Savage, 1954; Simon, 1957 ] </ref> . It tells us the course of action that a rational agent should choose from a set of alternatives. Decision theory in this sense is said to be a prescriptive theory. <p> We believe that this accounts at least in part for the relatively small (although growing) body of work in artificial intelligence that uses decision theory. This is an issue for decision theory in general, and has led to an active interest in models of "bounded rationality" <ref> [ Simon, 1957; 6.3. SUMMARY 161 Russell and Wefald, 1991 ] </ref> . The question of decision theoretic optimization in a continuous space is an important issue where much might be learnt from control theory [ Dean and Wellman, 1991 ] . 162 CHAPTER 6.
Reference: [ Sutton, 1990 ] <author> Richard S. Sutton. </author> <title> Integrated architectures for learning, planning, and reacting based on approximating dynamic programming. </title> <booktitle> In Proceedings 7th International Conference on Machine Learning, </booktitle> <year> 1990. </year>
Reference-contexts: In decision-making applications, it may be equally important to bypass inference, and learn the right actions in different situations directly. Current work in this area includes work in reinforcement learning <ref> [ Sutton, 1990; Kaelbling, 1990 ] </ref> . 168 CHAPTER 7. CONCLUSIONS 7.3.7 Applications Last but not least, we must further explore the application of the ideas in this thesis in real applications. Domains of particular interest are medicine, distributed networks, transportation, and robotics and vision.
Reference: [ Syski, 1979 ] <author> Ryszard Syski. </author> <title> Random Processes. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Each persistence rule has the form persist (',), where ' is a fluent and is a function of time referred to as a survivor function <ref> [ Syski, 1979 ] </ref> .
Reference: [ Tarjan and Yannakakis, 1984 ] <author> Robert E. Tarjan and Mihalis Yannakakis. </author> <title> Simple linear-time algorithms to test chordality of graphs, test acyclicity of hyper-graphs, and selectively reduce acyclic hypergraphs. </title> <journal> SIAM Journal of Computing, </journal> <volume> 13(3) </volume> <pages> 566-579, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: First, we introduce graph concepts and the Bayesian network. Then, we present the time net itself. Finally, we discuss algorithms for evaluating time nets. 4.1 Graph Notation and Concepts First, we present some graph notation. This presentation follows that of Tarjan <ref> [ Tarjan and Yannakakis, 1984 ] </ref> and Lauritzen [ Lauritzen et al., 1984 ] . <p> Jensen shows [ 1988 ] that any maximal spanning tree of the cliques of the chordal graph will be a junction tree, and suggests finding this maximal spanning tree. Our method exploits the numbering obtained by a maximum cardinality search <ref> [ Tarjan and Yannakakis, 1984 ] </ref> that we employ in verifying the fill-in, and we form the junction tree utilizing the join tree algorithm in [ Pearl, 1988 ] (see In the junction tree, both cliques and sepsets have distribution functions, C and S .
Reference: [ Tatman and Shachter, 1990 ] <author> Joseph A. Tatman and Ross D. Shachter. </author> <title> Dynamic programming and influence diagrams. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 20(2) </volume> <pages> 265-379, </pages> <month> March/April </month> <year> 1990. </year>
Reference-contexts: This can result in substantial computational savings. We now focus on models with highly regular structure, models related to Markov processes. This type of model, the Markov time net , has been investigated in past work leading to this dissertation, and independently by Tatman and Shachter <ref> [ Tatman and Shachter, 1990 ] </ref> . In a Markov time net, the conditioning set for each 2 SS is restricted to asets either in the same or previous time interval (see Figure 4.7). <p> Thus, the applicability of space reduction is highly domain specific. 4.5 Related Work A model equivalent to the Markov time net was apparently first investigated by Tat-man <ref> [ Tatman, 1986; Tatman and Shachter, 1990 ] </ref> . Tatman developed such networks in the context of decision making using a generalization of Bayesian networks called influence diagrams that add decision and value variables (Chapter 6). <p> Tatman developed such networks in the context of decision making using a generalization of Bayesian networks called influence diagrams that add decision and value variables (Chapter 6). Tatman's result was not widely known <ref> [ Tatman and Shachter, 1990 ] </ref> at the time we developed our initial work with Markov time nets in [ Kanazawa and Dean, 1989 ] . <p> Such a model was apparently first investigated by 6.2. THE INFLUENCE DIAGRAM 159 Tatman <ref> [ Tatman, 1986; Tatman and Shachter, 1990 ] </ref> . In his paper, Tatman proves that influence diagram manipulation operations produce the same results as for the dynamic programming solution to the Markov decision process sequential decision problem. Again, such operations are of exponential order complexity.
Reference: [ Tatman, 1986 ] <author> Joseph A. Tatman. </author> <title> Decision processes in influence diagrams: Formulation and analysis. </title> <type> PhD thesis, </type> <institution> Stanford University Department of Engineering / Economic Systems, Stanford, California, </institution> <year> 1986. </year>
Reference-contexts: Thus, the applicability of space reduction is highly domain specific. 4.5 Related Work A model equivalent to the Markov time net was apparently first investigated by Tat-man <ref> [ Tatman, 1986; Tatman and Shachter, 1990 ] </ref> . Tatman developed such networks in the context of decision making using a generalization of Bayesian networks called influence diagrams that add decision and value variables (Chapter 6). <p> Such a model was apparently first investigated by 6.2. THE INFLUENCE DIAGRAM 159 Tatman <ref> [ Tatman, 1986; Tatman and Shachter, 1990 ] </ref> . In his paper, Tatman proves that influence diagram manipulation operations produce the same results as for the dynamic programming solution to the Markov decision process sequential decision problem. Again, such operations are of exponential order complexity.
Reference: [ van Fraassen, 1980 ] <author> B.C. van Fraassen. </author> <title> A temporal framework for conditionals and chance. </title> <editor> In William L. Harper, Robert Stalnaker, and Glenn Pearce, editors, </editor> <booktitle> IFs, </booktitle> <pages> pages 323-340. </pages> <address> D. </address> <publisher> Reidel, </publisher> <address> Dordrecht, </address> <year> 1980. </year>
Reference-contexts: Haddawy's logic is substantially similar to van Fraassen's logic of objective chance <ref> [ van Fraassen, 1980 ] </ref> . Within AI, Haddawy's logic is closest technically to our work in addition to being contemporaneous . Some of the basic ontology, syntax, and semantic features of Haddawy's logic and LL are similar.
Reference: [ van Hentenryck, 1991 ] <author> Pascal van Hentenryck. </author> <title> Constraint Satisfaction in Logic Programming. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: FUTURE DIRECTION 167 of the temporal database and the theory underlying dynamic management of temporal uncertainty information. One possibility is to continue the path started in Goo. Another is to explore the relation of the probabilistic temporal database with constraint logic programming <ref> [ van Hentenryck, 1991; Jaffar and Lassez, 1987 ] </ref> and with non-probabilistic temporal databases such as the TMM, and combining discrete optimization methods with probabilities. Progress on translating arbitrary theories into time nets is essential for future development. This includes automatic unfolding of cyclical theories into acyclical models.
Reference: [ Vere, 1983 ] <author> Steven Vere. </author> <title> Planning in time: Windows and durations for activities and goals. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5 </volume> <pages> 246-267, </pages> <year> 1983. </year>
Reference-contexts: In addition to the work already mentioned, some notable early work include that by Hendrix [ 1973 ] and by Kahn and Gorry [ 1977 ] . More recent work, focusing on applications in planning include Vere's work on DEVISER <ref> [ Vere, 1983 ] </ref> , Vilain [ 1982 ] , and Dean [ 1985 ] . Rit [ 1986 ] and Dechter and Pearl [ 1989 ] show temporal constraint 34 CHAPTER 2. TIME AND CHANCE propagation systems for efficient inference involving temporal intervals.
Reference: [ Vilain, 1982 ] <author> Marc Vilain. </author> <title> A system for reasoning about time. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. AAAI, </booktitle> <year> 1982. </year>
Reference: [ von Neumann and Morgenstern, 1947 ] <author> John von Neumann and O. Morgenstern. </author> <title> Theory of games and economic behavior. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, 2nd edition, </address> <year> 1947. </year>
Reference-contexts: The probability that a cold lasts longer than 3 days is written P (fl (cold) &gt; 3day): The utility of electing Dan Quayle President would be U (elect-president (Quayle)) assuming that U is the utility function <ref> [ von Neumann and Morgenstern, 1947 ] </ref> . The probability that the water level is greater than 3 meters at noon is P (holds (noon, water-level (x)) ^ x &gt; 3m): 3.3.1 Extensions The most interesting extensions to LL2 are in features that facilitate planning and decision making. <p> In this section, we outline how the model of reasoning about change introduced in the previous chapters support making plans and making decisions. In particular, we consider how to apply decision theory for the problem of planning and decision making. Decision theory is the (mathematical) study of decision making <ref> [ von Neumann and Morgenstern, 1947; Savage, 1954; Simon, 1957 ] </ref> . It tells us the course of action that a rational agent should choose from a set of alternatives. Decision theory in this sense is said to be a prescriptive theory.
Reference: [ von Neumann, 1951 ] <author> John von Neumann. </author> <title> Various techniques used in connection with random digits. U.S. </title> <journal> National Bureau of Standards Applied Math Series, </journal> <volume> 12 </volume> <pages> 36-38, </pages> <year> 1951. </year> <note> BIBLIOGRAPHY 183 </note>
Reference-contexts: THE TIME NET simulation. Monte Carlo simulation, as with sampling itself, has its origins in the physical sciences <ref> [ von Neumann, 1951; Metropolis et al., 1953 ] </ref> . The basic idea of sampling is simple. The idea is to estimate variables, in our case probability distributions, by repeated trials.
Reference: [ Weber, 1989a ] <author> Jay Weber. </author> <title> Principles and Algorithms for Causal Reasoning with Uncertainty. </title> <type> PhD thesis, </type> <institution> University of Rochester Department of Computer Science, </institution> <month> May </month> <year> 1989. </year> <type> Technical Report 287. </type>
Reference-contexts: The main lesson that was drawn from the Yale Shooting Problem was that it is difficult to have a domain independent way of solving it. This was also another motivation for moving to a probabilistic or statistical approach to temporal and causal reasoning <ref> [ Weber, 1989a ] </ref> . 2.3 Reasoning about Time and Probability We will now explore the use of probability in temporal reasoning, outlining the development of our theory as a means of addressing the question of persistence. This dissertation is about an experiment in reasoning about time with probability.
Reference: [ Weber, 1989b ] <author> Jay Weber. </author> <title> Representing and computing temporally scoped beliefs. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, Michigan, </address> <year> 1989. </year> <pages> IJCAI. </pages>
Reference: [ Wellman, 1990 ] <author> Michael P. Wellman. </author> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1990. </year>
Reference: [ Wright, 1921 ] <author> Sewall Wright. </author> <title> Correlation and causation. </title> <journal> Journal of Agricultural Research, </journal> <volume> 20 </volume> <pages> 557-85, </pages> <year> 1921. </year>
Reference-contexts: Directed graph models of probability similar to Bayesian networks were apparently first formally investigated by Wright in his work on path analysis in genetics ( <ref> [ Wright, 1921 ] </ref> as cited in, e.g., [ Lauritzen et al., 1984 ] ). An excellent introduction to Bayesian networks, and to probabilistic networks in general, is Pearl's book [ 1988 ] . Another excellent text on Bayesian networks is Neapolitan's book [ 1990 ] . 4.2.

References-found: 132

