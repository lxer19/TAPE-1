URL: http://www.cs.orst.edu/~margindr/Papers/conti96_paper.ps
Refering-URL: http://www.cs.orst.edu/~margindr/Data/publications.html
Root-URL: 
Email: fchatre,knutson,margindr,schulzcag@research.cs.orst.edu  
Title: Improving DLX Performance by Taking Some of the Reduction out of RISC  
Author: Stephane Chatre Charles D. Knutson Drago~s Margineantu Carsten Schulz-Key 
Address: Dearborn Hall, Corvallis, OR, USA 97331  
Affiliation: Department of Computer Science, Oregon State University  
Abstract: RISC architectures, such as DLX, achieve performance increases over CISC machines by simplifying instruction sets and pipelining sub-instructions to achieve instruction-level parallelism. However, some instructions do not completely utilize all stages of the pipeline. When two instructions underutilize pipeline stages in a complementary fashion, they can be combined without significantly increasing the number of cycles per instruction. When these instruction pairs occur naturally and frequently in programs, their combination into a single instruction produces increases in system performance. This slight "unreducing" of the DLX instruction set leads to performance improvements. This paper describes several candidate instruction pairs that can be combined to speed up performance in the DLX architecture. We describe changes to the DLX Simulator and DLX C Compiler to support these new instructions. Finally we present results of benchmark programs run against DLX before and after modification.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John D. Bunda. </author> <title> "Instruction-processing optimization techniques for VLSI microprocessors." </title> <type> Doctoral Dissertation, </type> <institution> Computer Science Department, Univ. of Texas, </institution> <month> May, </month> <year> 1993. </year>
Reference-contexts: Christianson et al. <ref> [1] </ref> explored predicated execution, in essence combining MOV instructions with Branch instructions to create a Conditional Move. They expected performance increases to arise from condensing instruction pairs into single instructions.
Reference: [2] <author> David Christianson, Omid Madani, and Kari Pulli. </author> <title> "Predicted execution on alpha architecture." </title> <type> Technical Report, </type> <institution> Computer Science Dep., Univ. of Washington, </institution> <month> March </month> <year> 1995. </year>
Reference: [3] <author> H. J. Curnow and B. A. Wichman. </author> <title> "A synthetic benchmark." </title> <booktitle> Computer, </booktitle> <month> February </month> <year> 1976. </year>
Reference: [4] <author> Michael J. Flynn, Chad L. Mitchell, and Johannes M. </author> <title> Mulder. "And now a case for more complex instructions sets." </title> <journal> Computer, </journal> <volume> 20(9) </volume> <pages> 71-83, </pages> <month> September </month> <year> 1987. </year>
Reference: [5] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach, 2nd Edition. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Palo Alto, CA, </address> <year> 1995 </year>
Reference-contexts: 1 Introduction RISC architectures, such as DLX <ref> [5] </ref>, achieve performance increases over CISC machines by simplifying instruction sets and pipelining sub-instructions to achieve instruction-level parallelism. These increases are made possible by dramatically decreasing the cycles per instruction required by the system. <p> This led us to investigate instructions that might rely heavily on MEM and WB with little or no action during EX. This approach did not yield much success. However, when we considered the implementation described by Hennessey and Patterson <ref> [5] </ref> we saw that an unconditional jump instruction would not use any stage after ID. This led us to consider arithmetic or memory operations that would naturally complement an unconditional jump. This led to the Jump Increment and Loop Increment instructions, which are described in section 2.1. <p> First, as mentioned above, it completely ignores the EX, MEM and WB cycles when implemented according to Hennessy and Patterson <ref> [5] </ref>. The presence of an additional adder in the ID stage facilitates the computation of the effective address before EX is entered. The remaining pipe stages are free to perform other useful work.
Reference: [6] <author> Larry B. Hosteler and Brian Mirtich, </author> <title> "DLXsim A Simulator for DLX" Course Project, </title> <institution> Computer Science Department, Univ. of California, Berkley, </institution> <year> 1990 </year>
Reference-contexts: These instructions are represented by the Main Opcodes table of Table 1, and include all immediate and load/store operations (I-type) as well as control operations (J-type). Instructions performing arithmetic operations on two operands (R-type) require special attention. The DLX Simulator <ref> [6] </ref> uses the following encoding scheme. All integer functions are given the opcode $00, and all floating point functions are given the opcode $01. R-type instructions in DLX designate the lowest 11 bits of the instruction to define the function.
Reference: [7] <author> Jerome C. Huck and Michael J. </author> <title> Flynn,Analyzing Computer Architectures. </title> <publisher> IEEE Com--puter Society Press, </publisher> <year> 1989. </year>
Reference: [8] <author> Scott McFarling and John Hennessy. </author> <title> "Reducing the cost of branches." </title> <booktitle> In Proceedings of the 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp 396-403, </pages> <address> Tokyo, Japan, </address> <month> June </month> <year> 1986. </year>
Reference: [9] <author> Edward M. Riseman and Caxton C. Foster. </author> <title> "The inhibition of potential parallelism by conditional jumps." </title> <journal> IEEE Transactions on Computers, </journal> <pages> pp 1405-1411, </pages> <month> December </month> <year> 1972. </year>
Reference: [10] <author> Michael D. Smith, Mike Johnson, and Mark A. Horowitz. </author> <title> "Limits on multiple instruction issue." </title> <journal> ACM SIGPLAN Notices, Proceedings ASPLOS-III, </journal> <volume> 24 </volume> <pages> 290-301, </pages> <month> May </month> <year> 1989. </year>
Reference: [11] <institution> The SPEC benchmark report, </institution> <year> 1991. </year>
Reference: [12] <author> Garold S. Tjaden and Michael J. Flynn. </author> <title> "Detection and parallel execution of independent instructions." </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-19(10):889-895, </volume> <month> October </month> <year> 1970. </year>
Reference: [13] <author> David W. Wall. </author> <title> "Limits of instruction-level parallelism." </title> <booktitle> In Proceedings ASPLOS IV, </booktitle> <pages> pages 176-188, </pages> <year> 1991. </year>
Reference: [14] <author> Reinhold P. Wiecker. "Dhrystone: </author> <title> a synthetic systems programming benchmark." </title> <journal> Communications of the ACM, </journal> <volume> 27(10) </volume> <pages> 1023-1030, </pages> <month> October </month> <year> 1984. </year>
References-found: 14

