URL: http://www.research.digital.com/wrl/projects/Database/ISCA98_1.ps
Refering-URL: http://www.research.digital.com/wrl/projects/Database/index.html
Root-URL: http://www.research.digital.com
Email: fbarroso,kouroshg@pa.dec.com bugnion@cs.stanford.edu  
Title: Memory System Characterization of Commercial Workloads  
Author: Luiz Andr e Barroso, Kourosh Gharachorloo, and Edouard Bugnion 
Affiliation: Western Research Laboratory Digital Equipment Corporation  
Date: June 1998.  
Note: To Appear in the Proceedings of the 25th International Symposium on Computer Architecture,  
Abstract: Commercial applications such as databases and Web servers constitute the largest and fastest-growing segment of the market for multiprocessor servers. Ongoing innovations in disk subsystems, along with the ever increasing gap between processor and memory speeds, have elevated memory system design as the critical performance factor for such workloads. However, most current server designs have been optimized to perform well on scientific and engineering workloads, potentially leading to design decisions that are non-ideal for commercial applications. The above problem is exacerbated by the lack of information on the performance requirements of commercial workloads, the lack of available applications for widespread study, and the fact that most representative applications are too large and complex to serve as suitable benchmarks for evaluating trade-offs in the design of processors and servers. This paper presents a detailed performance study of three important classes of commercial workloads: online transaction processing (OLTP), decision support systems (DSS), and Web index search. We use the Oracle commercial database engine for our OLTP and DSS workloads, and the AltaVista search engine for our Web index search workload. This study characterizes the memory system behavior of these workloads through a large number of architectural experiments on Alpha multiprocessors augmented with full system simulations to determine the impact of architectural trends. We also identify a set of simplifications that make these workloads more amenable to monitoring and simulation without affecting representative memory system behavior. We observe that systems optimized for OLTP versus DSS and index search workloads may lead to diverging designs, specifically in the size and speed requirements for off-chip caches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. M. Anderson, L. M. Berc, J. Dean, S. Ghemawat, M. R. Hen-zinger, S.-T. Leung, R. L. Sites, M. T. Vandervoorde, C. A. Wald-spurger, and W. E. Weihl. </author> <title> Continuous profiling: </title> <booktitle> Where have all the cycles gone? In Proceedings of the 16th International Symposium on Operating Systems Principles, </booktitle> <pages> pages 114, </pages> <month> Oct </month> <year> 1997. </year>
Reference-contexts: We have also confirmed this similarity on other Alpha multiprocessor platforms. We provide a few general statistics, gathered with the DCPI <ref> [1] </ref> profiling tool, on the high-level behavior of the workload. On a four processor AlphaServer, the workload spends 71% in user-mode, 18% in the kernel and 11% in the idle loop. <p> A typical monitoring experiment involved multiple runs of the workload with IPROBE, measuring a single event in each run. 1 Event types available include counts of accesses and misses in the various caches, TLB misses, types of instructions, branch mispredicts, issue widths, memory barriers, replay traps, etc. DCPI <ref> [1] </ref> (Digital Continuous Profiling Infrastructure) is an extremely low overhead sampling-based profiling system that is also based on the processor event counters, and is especially useful because of its ability to associate event frequencies with specific executable images or processes.
Reference: [2] <author> M. Burrows. </author> <title> Private communication. </title>
Reference-contexts: Determining and validating the appropriate set of simplifications is a non-trivial task. Our techniques result from several months of studying Oracle, and we benefited from the expertise of the designer of the AltaVista index search <ref> [2] </ref>. One of the most interesting results of this paper is with respect to OLTP. Although OLTP is known to be memory intensive, emerging architectural trends will allow off-chip caches to capture significant working sets and eliminate most capacity and conflict misses, leaving only communication misses.
Reference: [3] <author> Z. Cventanovic and D. Bhandarkar. </author> <title> Performance characterization of the Alpha 21164 microprocessor using TP and SPEC-workloads. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 6070, </pages> <month> Apr </month> <year> 1994. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> To begin with, the Alpha 21164 processor provides a rich set of event counters that can be used to construct a detailed view of processor behavior, including all activity within the three-level cache hierarchy <ref> [3] </ref>. We used the IPROBE monitoring tool to gain access to the processor event counters.
Reference: [4] <author> Z. Cvetanovic and D. D. Donaldson. </author> <title> AlphaServer 4100 performance characterization. </title> <journal> Digital Technical Journal, </journal> <volume> 8(4):320, </volume> <year> 1996. </year>
Reference-contexts: The Oracle 7.3.2 DBMS runs on both uniprocessors and multiprocessor shared memory machines, and recent benchmark results demonstrate that the software scales well on current SMP systems <ref> [4] </ref>. Figure 1 illustrates the different components of Oracle. The server executes as a collection of Unix processes that share a common large shared memory segment, called the System Global Area, or SGA. Oracle has two types of processes, daemons and servers. <p> We have verified this similarity by comparing our memory system performance results presented in Section 4 with results from audit-size TPC-C runs <ref> [4] </ref> on the same hardware platform (AlphaServer 4100). We have also confirmed this similarity on other Alpha multiprocessor platforms. We provide a few general statistics, gathered with the DCPI [1] profiling tool, on the high-level behavior of the workload. <p> The cycle breakdown shows a CPI of 7.0 for our OLTP workload based on TPC-B, which is about twice the CPI of audit-size TPC-C runs on the same family of hardware servers <ref> [4] </ref>. This difference is primarily due to more complex and compute intensive queries in TPC-C and the better locality of that workload due to the higher number of small database tables. <p> A few studies have raised the level of awareness in the architecture community to the fact that OLTP workloads have a very different behavior when compared with scientific applications. Cvetanovic and Donaldson <ref> [4] </ref>, in their characterization of the AlphaServer 4100, measure the performance of SPEC95 programs, the TPC-C benchmark and other industry benchmarks. Our paper differs from this study in that it focuses on the memory system, uses other commercial applications (in addition to OLTP), and extends system monitoring with detailed simulations.
Reference: [5] <author> Digital Equipment Corporation. </author> <title> Digital Semiconductor 21164 Alpha microprocessor hardware reference manual, </title> <month> March </month> <year> 1996. </year>
Reference-contexts: Our version of SimOS simulates the hardware components of Alpha-based multiprocessors (processors, MMU, caches, disks, console) in enough detail to run Digital's system software. Specifically, SimOS-Alpha models the micro-architecture of the Alpha 21164 processor <ref> [5] </ref> and runs essentially unmodified versions of Digital Unix 4.0 and the 21164 PALcode. SimOS-Alpha supports multiple levels of simulation detail, enabling the user to choose the most appropriate trade-off between simulation detail and slowdown.
Reference: [6] <author> M. Dubois, J. Skeppstedt, L. Ricciulli, K. Ramamurthy, and P. Stenstrom. </author> <title> The detection and elimination of useless misses in multiprocessors. </title> <booktitle> In Proceedings of the 20th International Symposium on Computer Architecture, </booktitle> <pages> pages 8897, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: We have separated the effect of user and kernel misses. For each configuration, we also show the breakdown into five categories. Communication misses are separated into true and false sharing using the methodology of Dubois et al. <ref> [6] </ref>. 5 Data capacity and conflict misses are merged into a single replacement category. Data cold misses and instruction misses complete the breakdown. Let us focus on user misses. There are large gains from set-associativity, even at large cache sizes.
Reference: [7] <author> R. J. Eickemeyer, R. E. Johnson, S. R. Kunkel, M. S. Squillante, and S. Liu. </author> <title> Evaluation of multithreaded uniprocessors for commercial application environments. </title> <booktitle> In Proceedings of the 21th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 203212, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> Although they agree with our observation that TPC-B memory behavior is representative of TPC-C, the limitations of their methodology do not allow them to study memory system performance in the level of detail done here. Eickemeyer et al. <ref> [7] </ref> take a uniprocessor IBM AS/400 trace of TPC-C and transform it to drive both a simulator and analytic models of coarse-grain multithreaded unipro-cessors. They conclude that multithreading is effective in hiding latency of OLTP.
Reference: [8] <author> C. Hristea, D. Lenoski, and J. Keen. </author> <title> Measuring memory hierarchy performance of cache-coherent multiprocessors using micro benchmarks. </title> <booktitle> In Proceedings of Supercomputing '97, </booktitle> <month> Novem-ber </month> <year> 1997. </year>
Reference-contexts: This trend is prevalent on other current multiprocessors with latencies of 742 ns (dirty) vs. 560 ns (clean) on the Sun Enterprise 10000 and of 1036 ns (dirty) vs. 472 ns (clean) on the SGI Origin 2000 <ref> [8] </ref>. Second, the fraction of dirty misses increases with both the size of Bcaches and with the number of CPUs.
Reference: [9] <author> T. Kawaf, D. J. Shakshober, and D. C. Stanley. </author> <title> Performance analysis using very large memory on the 64-bit AlphaServer system. </title> <journal> Digital Technical Journal, </journal> <volume> 8(3):5865, </volume> <year> 1996. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads.
Reference: [10] <author> J. L. Lo, L. A. Barroso, S. J. Eggers, K. Gharachorloo, H. M. Levy, and S. S. Parekh. </author> <title> An analysis of database workload performance on simultaneous multithreaded processors. </title> <booktitle> In Proceedings of the 25th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: Finally, the memory behavior of the database engine is dominated by the server processes, allowing the memory activity of daemon processes to be ignored as a simplification. This methodology has been used to study the effectiveness of simultaneous multithreading on database work-loads <ref> [10] </ref>.
Reference: [11] <author> T. Lovett and R. Clapp. STiNG: </author> <title> A CC-NUMA computer system for the commercial marketplace. </title> <booktitle> In Proceedings of the 23rd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 308317, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: However, the fraction of operating system activity in their studies of OLTP was more than twice what we have obtained after tuning our OLTP application. Some researchers have used database workloads to study various aspects of system design. Lovett and Clapp <ref> [11] </ref> describe a CC-NUMA multiprocessor system for the commercial marketplace, and evaluate it using abstract models that are based on the the behavior of TPC-B and TPC-D/Q6.
Reference: [12] <author> A. M. G. Maynard, C. M. Donnelly, and B. R. Olszewski. </author> <title> Contrasting characteristics and cache performance of technical and multi-user commercial workloads. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 145156, </pages> <month> Oct </month> <year> 1994. </year>
Reference-contexts: The dramatic change in the target market for shared-memory servers has yet to be fully reflected in the design of these systems. The behavior of commercial workloads is known to be very different from numeric workloads <ref> [12] </ref>. Yet, current processors have been primarily optimized to perform well on the SPEC95 [18] benchmark suite. <p> Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> Our paper differs from this study in that it focuses on the memory system, uses other commercial applications (in addition to OLTP), and extends system monitoring with detailed simulations. Maynard et al. <ref> [12] </ref> also compare commercial and scientific applications using trace-driven simulation, but use a uniprocessor system instead of a multiprocessor. As in our study, they recognize the importance of Icache misses in OLTP applications.
Reference: [13] <author> J. D. McCalpin. </author> <title> Memory bandwidth and machine balance in current high performance computers. </title> <booktitle> In IEEE Technical Committee on Computer Architecture Newsletter, </booktitle> <month> Dec </month> <year> 1995. </year>
Reference-contexts: Yet, current processors have been primarily optimized to perform well on the SPEC95 [18] benchmark suite. Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS <ref> [13] </ref>, with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads [3, 7, 9, 12, 14, 16, 20, 21, 24].
Reference: [14] <author> S. E. Perl and R. L. </author> <title> Sites. Studies of windows NT performance using dynamic execution traces. </title> <booktitle> In Proceedings of the Second Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 169184, </pages> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> We have observed that the I/O problem has indeed been addressed in modern database engines, and that memory system performance is already the main bottleneck. Perl and Sites <ref> [14] </ref> study Microsoft SQL Server performance on an Alpha-based Windows NT server through trace-driven simulation.
Reference: [15] <author> M. Rosenblum, E. Bugnion, S. A. Herrod, and S. Devine. </author> <title> Using the SimOS machine simulator to study complex computer systems. </title> <booktitle> ACM Transactions on Modeling and Computer Simulation, </booktitle> <address> 7(1):78103, </address> <month> Jan. </month> <year> 1997. </year>
Reference-contexts: The first set of results consists of a large number of monitoring experiments on Alpha multiprocessor platforms, using a wide range of hardware and software monitoring tools. The second set of results uses full system simulation (using our Alpha port of SimOS <ref> [15] </ref>) to study the effect of architectural variations. In dealing with the large scale and complexity of these workloads, we have identified a number of simplifications that make these workloads more amenable to monitoring and simulation studies (both full system and user-level only) without affecting their intrinsic memory behavior. <p> For this purpose, we developed an Alpha port of the Si-mOS simulation environment. SimOS <ref> [15] </ref> is a full system simulation environment originally developed at Stanford University to study MIPS-based multiprocessors. Our version of SimOS simulates the hardware components of Alpha-based multiprocessors (processors, MMU, caches, disks, console) in enough detail to run Digital's system software.
Reference: [16] <author> M. Rosenblum, E. Bugnion, S. A. Herrod, E. Witchel, and A. Gupta. </author> <title> The impact of architectural trends on operating system performance. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 285298, </pages> <year> 1995. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> For example, commercial database engines have improved tremendously during the past few years in scaling to more processors in shared-memory systems. Therefore, studies that are a few years old (e.g. <ref> [16] </ref>) or that are based on software that is not of commercial grade (e.g., the public domain Postgres database [21]) are likely to be outdated and non-representative. <p> Some previous studies have identified different bottlenecks for the performance of OLTP applications than the ones we underscore. Thakkar and Sweiger [20] have measured the performance of an early OLTP benchmark (TP1) in the Sequent Symmetry multiprocessor, using both memory-resident and out-of-memory databases. Rosenblum et al. <ref> [16] </ref> focused on the impact of architectural trends on the operating system performance using three applications, including TPC-B.
Reference: [17] <author> A. Srivastava and A. Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 196205, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: DCPI [1] (Digital Continuous Profiling Infrastructure) is an extremely low overhead sampling-based profiling system that is also based on the processor event counters, and is especially useful because of its ability to associate event frequencies with specific executable images or processes. ATOM <ref> [17] </ref> is a static binary translator that facilitates the instrumentation of an executable image. <p> For user-level simulations however, other simplifications beyond scaling have to be addressed. The following are observations from experiments we have done based on tracing user-level activity with ATOM <ref> [17] </ref> to determine the viability of using such traces. It is important to consider the effect of not modeling operating system instructions. For OLTP, operating system activity is non-negligible but it also does not dominate the memory system behavior in a well tuned system.
Reference: [18] <author> Standard Performance Council. </author> <title> The SPEC95 CPU Benchmark Suite. </title> <note> http://www.specbench.org, 1995. </note>
Reference-contexts: The behavior of commercial workloads is known to be very different from numeric workloads [12]. Yet, current processors have been primarily optimized to perform well on the SPEC95 <ref> [18] </ref> benchmark suite.
Reference: [19] <author> G. Sturner. Oracle7. </author> <title> A User's and developer's Guide. </title> <publisher> Thomson Computer Press, </publisher> <year> 1995. </year>
Reference-contexts: We have been fortunate to have access to the Oracle database engine <ref> [19] </ref> for running our database workloads, and the popular AltaVista search engine for our Web workload. Our characterization results consist of two classes of experiments.
Reference: [20] <author> S. S. Thakkar and M. Sweiger. </author> <title> Performance of an OLTP application on Symmetry multiprocessor system. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 228238, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> One such trend is the increasing sensitivity of OLTP applications to dirty miss latency. Some previous studies have identified different bottlenecks for the performance of OLTP applications than the ones we underscore. Thakkar and Sweiger <ref> [20] </ref> have measured the performance of an early OLTP benchmark (TP1) in the Sequent Symmetry multiprocessor, using both memory-resident and out-of-memory databases. Rosenblum et al. [16] focused on the impact of architectural trends on the operating system performance using three applications, including TPC-B.
Reference: [21] <author> P. Trancoso, J.-L. Larriba-Pey, Z. Zhang, and J. Torrellas. </author> <title> The memory performance of DSS commercial workloads in shared-memory multiprocessors. </title> <booktitle> In Third International Symposium on High-Performance Computer Architecture, </booktitle> <month> Jan </month> <year> 1997. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> For example, commercial database engines have improved tremendously during the past few years in scaling to more processors in shared-memory systems. Therefore, studies that are a few years old (e.g. [16]) or that are based on software that is not of commercial grade (e.g., the public domain Postgres database <ref> [21] </ref>) are likely to be outdated and non-representative. The above issues are even more pronounced for Web workloads since numerous applications in this area are yet to be developed, and the existing ones are only in their infancy. <p> They conclude that multithreading is effective in hiding latency of OLTP. Verghese et al. [24] use a DSS workload to evaluate operating system support for page migration and replication. Trancoso et al. <ref> [21] </ref> use a public domain database engine to perform a detailed study of the memory performance of some TPC-D queries. However their engine could not automatically parallelize the queries, nor had the efficiency of the Oracle en-gined used here. Therefore their execution patterns differ substantially from ours.
Reference: [22] <author> Transaction Processing Performance Council. </author> <title> TPC Benchmark B (Online Transaction Processing) Standard Specification, </title> <year> 1990. </year>
Reference-contexts: Oracle 7.3.2 has a single daemon process, the log writer that groups commit logs from independent transactions into a single disk write for more efficient use of the disk bandwidth. 2.1.2 OLTP Workload Our OLTP workload is modeled after the TPC-B benchmark <ref> [22] </ref>. This benchmark models a banking system, with each transaction simulating a balance update to a randomly chosen account. The account balance update involves updates to four tables: the branch table, the teller table, the account table itself, and the history table.
Reference: [23] <author> Transaction Processing Performance Council. </author> <title> TPC Benchmark D (Decision Support) Standard Specification, </title> <month> Dec </month> <year> 1995. </year>
Reference-contexts: Client processes run an even smaller number of instructions between blocking system calls. This leads to a fine interleaving between multiple server and client processes that share the same processor. 2.1.3 DSS Workload Our DSS workload is modeled after the TPC-D benchmark <ref> [23] </ref>. The benchmark simulates the decision support system for a wholesale supplier that distributes and sells products worldwide. The database size is specified by a scale factor (SF), with a scale factor of 1 corresponding to a raw data size of 1 GB.
Reference: [24] <author> B. Verghese, S. Devine, A. Gupta, and M. Rosenblum. </author> <title> Operating system support for improving data locality on CC-NUMA computer servers. </title> <booktitle> In Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 279289, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 [26] and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads <ref> [3, 7, 9, 12, 14, 16, 20, 21, 24] </ref>. The lack of architectural research on commercial applications is partly due to the fact that I/O issues have been historically considered as the primary performance bottleneck for such work-loads. <p> Eickemeyer et al. [7] take a uniprocessor IBM AS/400 trace of TPC-C and transform it to drive both a simulator and analytic models of coarse-grain multithreaded unipro-cessors. They conclude that multithreading is effective in hiding latency of OLTP. Verghese et al. <ref> [24] </ref> use a DSS workload to evaluate operating system support for page migration and replication. Trancoso et al. [21] use a public domain database engine to perform a detailed study of the memory performance of some TPC-D queries.
Reference: [25] <author> E. Witchel and M. Rosenblum. Embra: </author> <title> Fast and flexible machine simulation. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 6879, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: SimOS-Alpha supports multiple levels of simulation detail, enabling the user to choose the most appropriate trade-off between simulation detail and slowdown. Its fastest simulator uses an on-the-fly binary translation technique similar to Em-bra <ref> [25] </ref> to position the workload into a steady state. The ability to simulate both user and system code under SimOS is essential given the rich level of system interactions exhibited by commercial workloads.
Reference: [26] <author> S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 2436, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Yet, current processors have been primarily optimized to perform well on the SPEC95 [18] benchmark suite. Similarly, design of multiprocessor architectures, along with academic research in this area, have been heavily influenced by popular scientific and engineering benchmarks such as SPLASH-2 <ref> [26] </ref> and STREAMS [13], with only a handful of published architectural studies that have in some way tried to address issues specific to commercial work-loads [3, 7, 9, 12, 14, 16, 20, 21, 24].
References-found: 26

