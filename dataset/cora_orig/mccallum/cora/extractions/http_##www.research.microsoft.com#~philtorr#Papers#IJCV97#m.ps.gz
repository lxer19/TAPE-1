URL: http://www.research.microsoft.com/~philtorr/Papers/IJCV97/m.ps.gz
Refering-URL: http://www.research.microsoft.com/~philtorr/paper.html
Root-URL: http://www.research.microsoft.com
Email: [phst,dwm]@robots.ox.ac.uk  
Title: The Development and Comparison of Robust Methods for Estimating the Fundamental Matrix  
Author: P H S TORR AND D W MURRAY 
Date: Received 17th August 1995. Revised 10th July 1996.  
Address: Oxford, Parks Road, Oxford, OX1 3PJ, UK  
Affiliation: Department of Engineering Science, University of  
Note: Int. J Computer Vision, 1-33 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: This paper has two goals. The first is to develop a variety of robust methods for the computation of the Fundamental Matrix, the calibration-free representation of camera motion. The methods are drawn from the principal categories of robust estimators, viz case deletion methods, M-estimators and random sampling, and the paper develops the theory required to apply them to non-linear orthogonal regression problems. Although a considerable amount of interest has focussed on the application of robust estimation in computer vision, the relative merits of the many individual methods are unknown, leaving the potential practitioner to guess at their value. The second goal is therefore to compare and judge the methods. Comparative tests are carried out using correspondences generated both synthetically in a statistically controlled fashion and from feature matching in real imagery. In contrast with previously reported methods the goodness of fit to the synthetic observations is judged not in terms of the fit to the observations per se but in terms of fit to the ground truth. A variety of error measures are examined. The experiments allow a statistically satisfying and quasi-optimal method to be synthesized, which is shown to be stable with up to 50 percent outlier contamination, and may still be used if there are more than 50 percent outliers. Performance bounds are established for the method, and a variety of robust methods to estimate the standard deviation of the error and covariance matrix of the parameters are examined. The results of the comparison have broad applicability to vision algorithms where the input data are corrupted not only by noise but also by gross outliers. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, D.H. and Brown, </author> <title> C.M., </title> <booktitle> 1982. Computer Vision. </booktitle> <publisher> Prentice-Hall, </publisher> <address> New Jersey. </address>
Reference-contexts: This is discussed in (Torr et al. 1996). 7. A note on Hough Transforms In our study, techniques that fall into the three categories described already have proved the most successful. It is worth however mentioning the Hough transform <ref> (eg Ballard & Brown 1982) </ref> as it Robust estimation of the fundamental matrix 19 has long history of valuable service to computer vision. The parameter space is divided into cells, and each datum adds a vote to every cell of the parameter space whose parameters are consistent with that datum.
Reference: <author> Bar-Shalom, Y. and Fortmann, T.E., </author> <year> 1988. </year> <title> Tracking and Data Association. </title> <publisher> Academic Press. </publisher>
Reference: <institution> Beardsley, P.A., Torr, P.H.S and Zisserman, A.P., </institution> <year> 1996. </year> <title> 3d model acquisition from extended image sequence. </title> <type> OUEL Report 2089/96, </type> <institution> Department of Engineering Science, University of Oxford. </institution>
Reference: <author> Bookstein, F., </author> <year> 1979. </year> <title> Fitting conic sections to scattered data. </title> <booktitle> Computer Vision Graphics and Image Processing, </booktitle> <volume> 9 </volume> <pages> 56-71. </pages>
Reference: <author> Chaterjee, S. and Hadi, A.S., </author> <year> 1988. </year> <title> Sensitivity Analysis in Linear Regression. </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference-contexts: Category II: Case Deletion Diagnostics This section describes the methods based on influence measures, particularly case deletion diagnostics <ref> (Chaterjee & Hadi 1988) </ref>. The basic concept underlying influence is simple. Small perturbations are introduced into some aspect of the problem formulation and an assessment made of how much these change the outcome of the analysis.
Reference: <author> Cook, R.D. and Weisberg, S., </author> <year> 1980. </year> <title> Characterisations of an empirical influence function for detecting influential cases in regression. </title> <journal> Technometrics, </journal> <volume> 22 </volume> <pages> 337-344. </pages>
Reference-contexts: If Z is the matrix whose rows are z &gt; i then the least squares estimate f of f is given by the eigenvector of the moment matrix M = Z &gt; Z corresponding to the minimum eigenvalue. By analogy with Cook's D <ref> (Cook & Weisberg 1980) </ref> which was developed for ordinary least squares, we monitor the effect of deleting an observation on the estimated parameters f.
Reference: <author> Critchley, F., </author> <year> 1985. </year> <title> Influence in principal component analysis. </title> <journal> Biometrika, </journal> <volume> 72 </volume> <pages> 627-636. </pages>
Reference: <author> Dempster, A.P, Laird, N.M. and Rubin, D.B., </author> <year> 1997. </year> <title> Maximum likelihood from incomplete data via the em algorithm. </title> <journal> J. R. Statist. Soc., </journal> <volume> 39 B:1-38. </volume>
Reference: <author> Devlin S.J., Gnanadesikan, R., and Kettering, J.R., </author> <year> 1981. </year> <title> Robust estimation of dispersion matrices and principal components. </title> <journal> J. Amer. Stat. Assoc., </journal> <volume> 76 </volume> <pages> 354-362. </pages>
Reference: <author> Faugeras, O.D., </author> <year> 1992. </year> <title> What can be seen in three dimensions with an uncalibrated stereo rig? In G. </title> <editor> Sandini, editor, </editor> <booktitle> Proc. 2nd European Conference on Computer Vision , LNCS 588, </booktitle> <pages> pages 563-578. </pages>
Reference-contexts: in the first image is transformed to the set fx i 0 g in the second image, positions related by x 0&gt; where x = (x; y; ) &gt; is a homogeneous image co ordinate and F = 4 f 4 f 5 f 6 3 is the Fundamental Matrix <ref> (Faugeras 1992) </ref>. Although 3 fi 3, the matrix has only seven degrees of freedom because only the ratio of parameters is significant and because det F = 0.
Reference: <author> Fischler, M.A. and Bolles, R.C., </author> <year> 1981. </year> <title> Random sample consensus: a paradigm for model fitting with application to image analysis and automated cartography. </title> <journal> Commun. Assoc. Comp. Mach., </journal> <volume> vol. 24 </volume> <pages> 381-95. </pages>
Reference: <author> Gill, P.E. and Murray, W., </author> <year> 1978. </year> <title> Algorithms for the solution of the nonlinear least-squares problem. </title> <journal> SIAM J Num Anal, </journal> <volume> 15(5) </volume> <pages> 977-992. </pages>
Reference: <author> Golub, G.H., </author> <year> 1973. </year> <title> Some modified eigenvalue problems. </title> <journal> SIAM Review, </journal> <volume> 15(2) </volume> <pages> 318-335. </pages>
Reference: <author> Golub, G.H. and van Loan, C.F., </author> <year> 1989. </year> <title> Matrix Computations. </title> <publisher> The John Hopkins University Press. Numerical Algorithms Group, </publisher> <year> 1988. </year> <title> NAG Fortran Library vol 7. </title>
Reference-contexts: To force the estimated fundamental matrix to be rank 2, at each iteration F is replaced by the nearest rank 2 matrix before calculating the weights. The procrustean 3 approach adopted here proceeds as follows. Let the singular value decomposition <ref> (Golub & van Loan 1989) </ref> of the recovered F be F = VflU &gt; : Due to noise F will have full rank with non zero singular values: fl = diag ( p p p approximate F by a rank two matrix, let fl + = diag ( p p 2 <p> If matrix M is perturbed into M 0 = M + ffiM; and if the multiplicity of j is 1, i.e. the data is not degenerate, then the eigenvector u j is perturbed into <ref> (Golub & van Loan 1989) </ref> u 0 X u &gt; k ffiMu j j k u k + O (ffiM) 2 : In this case the deletion of the ith observation means that ffiM = z i z &gt; i .
Reference: <author> Gu, M. and Eisenstat, S.C., </author> <year> 1995. </year> <title> Downdating the singular value decomposition. </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <volume> 16 </volume> <pages> 793-810. </pages>
Reference: <author> Hampel J.P., Ronchetti, </author> <title> E.M., </title> <type> Rousseeuw, </type> <institution> P.J. and Stahel, W.A., </institution> <year> 1986. </year> <title> Robust Statistics: An Approach Based on Influence Functions. </title> <publisher> Wiley, </publisher> <address> New York. 32 Torr and Murray Hartley, R.I., </address> <year> 1992. </year> <title> Estimation of relative camera positions for uncalibrated cameras. </title> <booktitle> In Proc. 2nd Euro-pean Conference on Computer Vision , LNCS 588, </booktitle> <address> Santa Margherita Ligure, </address> <pages> pages 579-587. </pages> <publisher> Springer-Verlag. </publisher>
Reference: <author> Hartley, R.I., </author> <year> 1995. </year> <title> In defence of the 8-point algorithm. </title> <booktitle> Proc. 5th Int Conf on Computer Vision, </booktitle> <address> Boston MA, </address> <pages> pp 1064-1070. </pages> <publisher> IEEE Computer Society Press, </publisher> <address> Los Alamitos CA. </address>
Reference: <author> Hartley, R.I. and Sturm, Y., </author> <year> (1994). </year> <title> Triangulation. In AIUWS, pages 957-966. Exploring data tables, trends and shapes. Hoaglin, D.C., </title> <editor> Mosteller, F. and Tukey, J.W. </editor> <title> editors (1985) Robust Regression. </title> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Huber, P.J., </author> <year> 1981. </year> <title> Robust Statistics. </title> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Kanatani, K., </author> <year> 1992. </year> <title> Geometric Computation for Machine Vision. </title> <publisher> Oxford University Press. </publisher>
Reference: <author> Kanatani, K., </author> <year> 1994. </year> <title> Statistical bias of conic fitting and renormalization. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 16(3) </volume> <pages> 320-326. </pages>
Reference: <author> Kanatani, K., </author> <year> 1996. </year> <title> Statistical Optimization for Geometric Computation: Theory and Practice. </title> <publisher> Elsevier Science, Amsterdam. </publisher>
Reference: <author> Kendall, M. and Stuart, A., </author> <year> 1983. </year> <title> The Advanced Theory of Statistics. </title> <publisher> Charles Griffin and Company, London. </publisher>
Reference-contexts: Our evaluation places emphasis on two performance criteria: (i) relative efficiency and (ii) breakdown point, defined as follows. (i) The relative efficiency of a regression method is defined as the ratio between the lowest achievable variance for the estimated parameters (the Cramer-Rao bound <ref> (Kendall & Stuart 8 Torr and Murray 1983) </ref>) and the actual variance provided by the given method. <p> The jackknife is a well-known and extensively studied statistical non-parametric technique to gain an unbiased estimate of f together with its covariance. If f J is the jackknife estimate it can be shown that its bias decreases as a polynomial function of the number of observations n <ref> (Kendall & Stuart 1983) </ref>. Using the original sample of n data, all n subsamples of n 1 data are formed, by systematically deleting each observation in turn.
Reference: <author> Kumar, R. and Hanson, A.R., </author> <year> 1994. </year> <title> Robust methods for estimating pose and a sensitivity analysis. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> vol. 60(3) </volume> <pages> 313-342. </pages>
Reference: <author> Li, G., </author> <year> 1985. </year> <title> Exploring data tables, trends and shapes. </title>
Reference: <editor> In D. C. Hoaglin, F. Mosteller, and J. W. Tukey, editors, </editor> <booktitle> Robust Regression, </booktitle> <pages> pages 281-343. </pages> <publisher> John Wiley & Sons. </publisher>
Reference: <author> Li, H., Lavin, M.A. and LeMaster, R.J., </author> <year> 1986. </year> <title> Fast Hough transforms: a hierarchical approach. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 36 </volume> <pages> 139-161. </pages>
Reference-contexts: The Hough transform runs into problems when the dimension of the parameter space is high, because its space requirement is exponential in the dimensionality and the computational expense of even the Fast Hough Transform <ref> (Li et al. 1986) </ref> rises exponentially with the dimension of the parameter space (McLauchlan 1990). The dimensionality of the Fundamental Matrix is 7, and even the coarsest quantization of the parameter space, say into 10 cells per dimension, would demand 10 7 cells! 8.
Reference: <author> Longuet-Higgins, H.C., </author> <year> 1981. </year> <title> A computer algorithm for reconstructing a scene from two projections. Nature, </title> <publisher> vol.293:133-135. </publisher>
Reference: <author> Luong, Q.T., </author> <year> 1992. </year> <title> Matrice fondamentale et calibration visuelle sur l'environnement: Vers use plus grande au-tonomie des systemes robotiques. </title> <type> PhD Thesis, </type> <institution> Paris University. </institution>
Reference-contexts: Re-assess the matches, and re-estimate using the EM algorithm. 6. M-estimation (2): replace the iterative least squares by a non-linear method, using a pa rameterization that ensures the det F = 0 <ref> (see Luong 1992) </ref>. 7. Re-assess the matches, and re-estimate using the EM algorithm. Table 4.
Reference: <author> Luong, Q.T., Deriche, R., Faugeras, O.D. and Pa-padopoulo, T., </author> <year> 1993. </year> <title> On determining the fundamental matrix: analysis of different methods and experimental results. </title> <type> INRIA Technical Report 1894, </type> <institution> INRIA-Sophia Antipolis. </institution>
Reference: <author> Maronna, R.A., </author> <year> 1976. </year> <title> Robust M-estimators of multivari-ate location and scatter. </title> <journal> Ann. Stat., </journal> <volume> 4 </volume> <pages> 51-67. </pages>
Reference: <author> McLauchlan, P.F., </author> <year> 1990. </year> <title> Describing Textured Surfaces using Stereo Vision. </title> <type> PhD Thesis, </type> <institution> AI Vision Research Unit, University of Sheffield. </institution>
Reference-contexts: The Hough transform runs into problems when the dimension of the parameter space is high, because its space requirement is exponential in the dimensionality and the computational expense of even the Fast Hough Transform (Li et al. 1986) rises exponentially with the dimension of the parameter space <ref> (McLauchlan 1990) </ref>. The dimensionality of the Fundamental Matrix is 7, and even the coarsest quantization of the parameter space, say into 10 cells per dimension, would demand 10 7 cells! 8.
Reference: <author> Meer, M., Mintz, D. and Rosenfeld, A. </author> <year> (1991). </year> <title> Robust regression methods for computer vision: A review. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6 </volume> <pages> 59-70. </pages>
Reference: <author> Mosteller, F. and Tukey, J.W., </author> <year> 1977. </year> <title> Data and Analysis and Regression. </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA. </address>
Reference: <author> Olsen, S.I., </author> <year> 1992. </year> <title> Epipolar line estimation. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Proc. 2nd European Conference on Computer Vision, </booktitle> <volume> LNCS 588, </volume> <pages> pages 307-311. </pages> <publisher> Springer-Verlag. </publisher>
Reference: <author> Pearson, K., </author> <year> 1901. </year> <title> On lines and planes of closest fit to systems of points in space. </title> <journal> Philos. Mag. Ser. </journal> <volume> 6, </volume> <month> 2:559. </month>
Reference-contexts: | equation (1) written out is just f 1 x 0 i y i + f 3 x 0 i x i + i y i + f 6 y 0 Because errors exist in all the measured coordinates x; y; x 0 ; y 0 , orthogonal least squares <ref> (Pearson 1901) </ref> rather than ordinary least squares should be used, minimizing the sum of the squares of the distances shown in part (a) rather than (b) of Figure 2. <p> The best fitting hyperplane passes through the centroid of the data <ref> (Pearson 1901) </ref>.) Assuming that the noise is Gaussian and that the elements of z have equal variance 1 , the hyperplane f with maximum likelihood is estimated by minimizing the perpendicular sum of Euclidean distances from the points to the plane (Pearson 1901; Kendall & Stuart 1983) 4 Torr and Murray <p> For example the best fitting line to a 2 dimensional scatter (x i ; y i ), i = 1 : : : n is estimated by minimizing P n i=1 (ax i + by i + c) 2 subject to the constraint a 2 + b 2 = 1 <ref> (Pearson 1901) </ref>.
Reference: <author> Pratt, V., </author> <year> 1987. </year> <title> Direct least squares fitting of algebraic surfaces. </title> <journal> Computer Graphics, </journal> <volume> 21(4) </volume> <pages> 145-152. </pages>
Reference: <author> Roth, G. and Levine, M.D., </author> <year> 1993. </year> <title> Extracting geometric primitives. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 58(1) </volume> <pages> 1-22. </pages>
Reference-contexts: The LMS algorithm gives the best performance for both error measures. RANSAC gave an equivalent or slightly worse performance when the standard deviation of the error term was known, but it has been shown that RANSAC can perform well even when there are 90% outliers <ref> (Roth 1993) </ref>. This tallies with our experience in using RANSAC for motion segmentation (Torr & Murray 1994). Earlier it was noted that iterative estimation of the M-estimators is only successful if the starting estimate was good.
Reference: <author> Rousseeuw, P.J., </author> <year> 1987. </year> <title> Robust Regression and Outlier Detection. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: The detection of degeneracy within RANSAC is the subject of (Torr et al. 1995a). RANSAC originated in work on computer vision, and it was some years until a similar highly robust estimator was developed independently in the field of statistics, namely Rousseeuw's least median of squares (LMS) estimator <ref> (Rousseeuw 1987) </ref>. The algorithms differ slightly in that the solution giving least median is selected as the estimate in (Rousseeuw 1987). Both algorithms have been implemented with the Sampson/Weng and epipolar distances, not on the algebraic distance, and are presented in the Appendix. <p> work on computer vision, and it was some years until a similar highly robust estimator was developed independently in the field of statistics, namely Rousseeuw's least median of squares (LMS) estimator <ref> (Rousseeuw 1987) </ref>. The algorithms differ slightly in that the solution giving least median is selected as the estimate in (Rousseeuw 1987). Both algorithms have been implemented with the Sampson/Weng and epipolar distances, not on the algebraic distance, and are presented in the Appendix. The variances of the estimators, for D and E, run over the correspondences stored in the data base are presented in Figure 9. <p> If there are outliers and they are in the minority, a first estimate of the variance can be derived from the median squared error of the chosen parameter fit <ref> (Rousseeuw 1987) </ref>. It is known that med i jd i j= 1 (0:75) is an asymptotically consistent estimator of when the d i are distributed like N (0; 2 ), where is the cumulative distribu tion function for the Gaussian probability density function.
Reference: <author> Sampson, P.D., </author> <year> 1982. </year> <title> Fitting conic sections to `very scattered' data: An iterative refinement of the Bookstein algorithm. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 18 </volume> <pages> 97-108. </pages>
Reference: <author> Shapiro, L.S. and Brady, J.M., </author> <year> 1993. </year> <title> Rejecting outliers and estimating errors in an orthogonal regression framework. </title> <institution> Department of Engineering Science, University of Oxford, </institution> <note> Technical Report OUEL 1974/93, and to appear Philosophical Transactions of the Royal Society. </note>
Reference-contexts: be found in closed form, the change in the solution is calculated using eigenvector perturbation theory (Torr 1995, Golub & van Loan 1989). (As noted above, examination of the effects of perturbation on some other aspect of the model could be made, e.g. the covariance matrices or the minimum eigenvalue <ref> (Shapiro & Brady 1993) </ref>, but as our interest is in f it appears best to test eigenvector perturbations directly.) Let M be the p-dimensional symmetric moment matrix, having eigenvalues, in increasing order, 1 : : : p with u 1 : : : u p the corresponding eigen-vectors forming an orthonormal
Reference: <author> Spetsakis, M. and Aloimonos, Y., </author> <year> 1991. </year> <title> A multi-frame approach to visual motion perception. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6 </volume> <pages> 245-255. </pages>
Reference: <author> Sprent, P., </author> <year> 1989. </year> <title> Applied Nonparametric Statistical Methods. </title> <publisher> Chapman and Hall, London. </publisher>
Reference-contexts: Using the original sample of n data, all n subsamples of n 1 data are formed, by systematically deleting each observation in turn. The jackknife is given by f J = nf n i=1 the bias in each parameter being <ref> (Sprent 1989) </ref> 1 n X (f (i) f ) : It can be seen that there is only a small amount of extra computation necessary to get the bias-free estimates, as the quantities f (i) have already been calculated.
Reference: <author> Stewart, C.V., </author> <year> 1995. </year> <title> MINPRAN, a new robust estimator for computer vision. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, vol.PAMI-17,no.10:925-938. </journal>
Reference: <author> Taubin, G., </author> <year> 1991. </year> <title> Estimation of planar curves, surfaces, and nonplanar space curves defined by implicit equations with applications to edge and range image segmentation. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, vol.PAMI-13,no.11:1115-1138. </journal>
Reference: <author> Thisted, R.A., </author> <year> 1988. </year> <title> Elements of Statistical Computing. </title> <publisher> Chapman and Hall, </publisher> <address> New York. </address>
Reference: <author> Torr, P.H.S., </author> <year> 1995. </year> <title> Outlier Detection and Motion Segmentation. </title> <type> DPhil Thesis, </type> <institution> University of Oxford. </institution>
Reference-contexts: We do not show all the comparisons made between least squares methods <ref> (Torr 1995) </ref> here. <p> By analogy with Cook's D (Cook & Weisberg 1980) which was developed for ordinary least squares, we monitor the effect of deleting an observation on the estimated parameters f. As exact solutions cannot be found in closed form, the change in the solution is calculated using eigenvector perturbation theory <ref> (Torr 1995, Golub & van Loan 1989) </ref>. (As noted above, examination of the effects of perturbation on some other aspect of the model could be made, e.g. the covariance matrices or the minimum eigenvalue (Shapiro & Brady 1993), but as our interest is in f it appears best to test eigenvector <p> The norm is chosen to make T i both scaleless and invariant to non-singular linear transformations of the data. Robust estimation of the fundamental matrix 13 Now suppose the matrix M is used for L. In <ref> (Torr 1995) </ref> it is shown that M 2 is approximated by the pseudo inverse of f , the covariance matrix of the parameter estimate:an improved estimate is given in x5.4. <p> Some outliers, although consistent with the epipolar geometry, might appear behind the camera, allowing them to be identified as outlying. Nor have we considered the natural extension of the estimation process to motion segmentation: this is explored in (Torr & Murray 1993,1994) and <ref> (Torr et al. 1995) </ref>. There have been some other notable comparisons of robust estimators in computer vision, we shall now compare our findings with those of the other studies.
Reference: <author> Torr, P.H.S, Maybank, S. and Zisserman, A. </author> <title> (1996) Robust detection of degenerate configurations for the fundamental matrix. </title> <type> OUEL Report 2090/96, </type> <institution> Department of Engineering Science, University of Oxford. </institution>
Reference-contexts: This distance turns out to be intractable, but D 2 provides a first order approximation to it. Thirdly, as discussed more fully in <ref> (Torr 1996) </ref>, d = w S r is the first order approximation of the distance of a correspondence in the 4D space defined by (x; y; x 0 ; y 0 ) to the manifold defined by F in that space, an approximation good to 4 or 5 significant figures. <p> Like LMS, this does not require a priori knowledge of the variances. However, we do not use it here as it appears to make assumptions about the error distribution that are inappropriate for estimation of the fundamental matrix. This is discussed in <ref> (Torr et al. 1996) </ref>. 7. A note on Hough Transforms In our study, techniques that fall into the three categories described already have proved the most successful.
Reference: <author> Torr, P.H.S. and Murray, D.W., </author> <year> 1992. </year> <title> Statistical detection of non-rigid motion. </title> <editor> In D. Hogg, editor, </editor> <booktitle> Proc. 3rd British Machine Vision Conference, Leeds, Septem-ber 1992, </booktitle> <pages> pages 79-88. </pages> <publisher> Springer-Verlag. </publisher>
Reference: <author> Torr, P.H.S. and Murray, D.W., </author> <year> 1993a. </year> <title> Statistical detection of independent movement from a moving camera. </title> <journal> Image and Vision Computing, </journal> <volume> 1(4) </volume> <pages> 180-187. </pages>
Reference: <author> Torr, P.H.S. and Murray, D.W., </author> <year> 1993b. </year> <title> Outlier detection and motion segmentation. </title> <editor> In P. S. Schenker, editor, </editor> <booktitle> Proc. Sensor Fusion VI, </booktitle> <address> Boston MA, </address> <month> June </month> <year> 1993, </year> <pages> pages 432-443. </pages> <booktitle> SPIE volume 2059. </booktitle>
Reference-contexts: Extending Cook's D to the case of orthogo nal regression We now derive a formula for the influence of a point on orthogonal regression is derived, extending the works of Cook and Weisberg (1980), Critchley (1985) and Shapiro and Brady (1993). An early version was presented in <ref> (Torr & Mur-ray 1993b) </ref>. Consider the set of points lying on a hyper-plane f and let their measured values be z i , i = 1 : : : n, after perturbation by Gaussian noise with uniform 4 standard deviation .
Reference: <author> Torr, P.H.S. and Murray, D.W., </author> <year> 1994. </year> <title> Stochastic motion segmentation. </title> <editor> In J-O. Ecklundh, editor, </editor> <booktitle> Proc. 3rd Euro-pean Conference on Computer Vision, </booktitle> <address> Stockholm, </address> <month> May </month> <year> 1994, </year> <pages> pages 328-338. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Image pairs that give rise to unusually high standard deviations might possess independently moving objects, the detection of which is discussed in <ref> (Torr et al. 1994,1995b) </ref>. Given random perturbations of the image correspondences with unit standard deviation then the estimate of the standard deviation of F was found to be 1:07, this being a conflation of the image error and the error in the estimator. 9. <p> RANSAC gave an equivalent or slightly worse performance when the standard deviation of the error term was known, but it has been shown that RANSAC can perform well even when there are 90% outliers (Roth 1993). This tallies with our experience in using RANSAC for motion segmentation <ref> (Torr & Murray 1994) </ref>. Earlier it was noted that iterative estimation of the M-estimators is only successful if the starting estimate was good.
Reference: <author> Torr, P.H.S., Zisserman, A. and Maybank, S., </author> <year> 1995a. </year> <title> Robust detection of degeneracy. </title> <booktitle> Proc. 5th Int Conf on Computer Vision, </booktitle> <address> Boston MA, </address> <pages> pp 1037-1044. </pages> <publisher> IEEE Computer Society Press, </publisher> <address> Los Alamitos CA. </address>
Reference-contexts: Clearly the result estimated from this sample will not have many other consistent correspondences that conform to the underlying motion. It is desirable to devise a scheme to determine whether any subsample is degenerate. The detection of degeneracy within RANSAC is the subject of <ref> (Torr et al. 1995a) </ref>. RANSAC originated in work on computer vision, and it was some years until a similar highly robust estimator was developed independently in the field of statistics, namely Rousseeuw's least median of squares (LMS) estimator (Rousseeuw 1987). <p> This question becoming more problematic the more outliers there are in the data. An account of when degeneracy might arise, how to detect it and how to conduct estimation in the pres ence of degeneracy is given in <ref> (Torr et al. 1995a) </ref> and will be the subject of a sister paper. Acknowledgements This work was supported by a Grant GR/J65372 and a Research Studentship to PHST from the UK Engineering and Physical Science Research Council.
Reference: <author> Torr, P.H.S, Zisserman, A. and Murray, D.W., </author> <year> 1995b. </year> <title> Motion clustering using the trilinear constraint over three views. </title> <editor> In R. Mohr and C. Wu, editors, </editor> <title> Europe-China Robust estimation of the fundamental matrix 33 Workshop on Geometrical Modelling and Invariants for Computer Vision, </title> <address> pages 118-125. </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Tsai, R.Y. and Huang, T.S., </author> <year> 1984. </year> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects with curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 13-27. </pages>
Reference: <author> Teukolsky, S.A., Press, W.H., Flannery, B.P. and Vetter-ling, W.T., </author> <year> 1988. </year> <title> Numerical Recipes in C, </title> <booktitle> the art of scientific computing. </booktitle> <publisher> Cambridge University Press, Cam-bridge. </publisher>
Reference: <author> Weng, J., Ahuja, N. and Huang, T.S., </author> <year> 1993. </year> <title> Optimal motion and structure estimation. </title> <journal> IEEE PAMI, vol.15(9):864-884. </journal>
Reference: <author> Weng, J., Huang, T.S. and Ahuja, N., </author> <year> 1989. </year> <title> Motion and structure from two perspective views: Algorithms, error analysis, and error estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 451-476. </pages>
Reference-contexts: Unfortunately these `minimalist' algorithms were highly sensitive to noise, leading to an erroneous belief that recovery of structure and motion was essentially an ill-posed problem and that only qualitative solutions were possible. The third epoch was then directed towards minimizing the effects of noise by using more correspondences <ref> (Weng et al. 1989) </ref> and more images (Spetsakis & Aloimonos 1991; Weng et al. 1993). This has usually been done within a least-squares framework, with the concomitant difficulties highlighted Robust estimation of the fundamental matrix 3 above.
Reference: <author> Zhang, Z., Deriche, R., Faugeras, O.D. and Luong, Q.T., </author> <year> 1994. </year> <title> A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry. </title> <journal> AI Journal, vol.78:87-119. </journal>
References-found: 59

