URL: ftp://speech.cse.ogi.edu/pub/docs/rapid_prototyping.ps.Z
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: RAPID PROTOTYPING OF SPOKEN LANGUAGE SYSTEMS: THE YEAR 2000 CENSUS PROJECT  
Author: Ronald A. Cole, David G. Novick, Mark Fanty, Stephen Sutton, Brian Hansen and Daniel C. Burnett 
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000 USA  
Affiliation: Center for Spoken Language Understanding, Oregon Graduate Institute of Science Technology  
Abstract: In this paper, we describe a rapid-prototyping approach to developing spoken language systems (SLSs). This new design methodology facilitates more usable and quickly implemented SLSs. Moreover, it allows SLS developers to address the delicate balance between designing dialogues that are sufficiently constraining to meet current speech recognition capabilities, yet feel natural and intuitive to the user. This rapid-prototyping methodology was developed in the service of a project to determine the feasibility of using SLSs for the Year 2000 Census in the United States. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. A. Cole, L. Hirschman, et al., </author> <title> Workshop on Spoken Language Understanding, </title> <type> Technical Report CS/E 92-014, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Institute of Science & Technology, </institution> <year> 1992. </year>
Reference-contexts: 1. INTRODUCTION A spoken language system (SLS) engages the user in a dialogue to achieve some goal. The system must recognize words, interpret their meaning and respond appropriately to accomplish the goals of the task <ref> [1] </ref>. Current speech recognition technology represents a considerable bottleneck for many practical SLS applications, especially for speaker-independent systems handling spontaneous telephone speech. Typically, in order to develop an effective speech recognizer, it is necessary to impose constraints on the range and freedom of user responses.
Reference: [2] <author> C. Lewis, P. Poulson, C. Wharton, and J. Rieman, </author> <title> Testing a walkthrough methodology for theory-based design of walk-up-and-use interfaces, </title> <booktitle> Proceedings of CHI90, </booktitle> <pages> pp. 235-242, </pages> <year> 1990. </year>
Reference-contexts: Our approach is an extension of rapid-prototyping, which has played a significant role in human-computer interaction research, particularly with regard to usability (e.g., <ref> [2] </ref>) and user-centered design (e.g., [3]). In prior work, we developed a usability-based methodology for developing graphic user interfaces using prototype tools [4]). We have adapted this rapid-prototyping methodology as a basis for developing SLS dialogues. This development process iterates over two phases.
Reference: [3] <author> J. Grudin, </author> <title> interface, </title> <booktitle> Proceedings of CSCW90, </booktitle> <pages> pp. 269-278, </pages> <year> 1990. </year>
Reference-contexts: Our approach is an extension of rapid-prototyping, which has played a significant role in human-computer interaction research, particularly with regard to usability (e.g., [2]) and user-centered design (e.g., <ref> [3] </ref>). In prior work, we developed a usability-based methodology for developing graphic user interfaces using prototype tools [4]). We have adapted this rapid-prototyping methodology as a basis for developing SLS dialogues. This development process iterates over two phases.
Reference: [4] <author> D. Novick and S. Douglas, QUID: </author> <title> A quick user-interface design method using prototyping tools, </title> <booktitle> Proceedings of the Hawaii International Conference on System Sciences (HICSS90), </booktitle> <pages> 709-718, </pages> <year> 1990. </year>
Reference-contexts: Our approach is an extension of rapid-prototyping, which has played a significant role in human-computer interaction research, particularly with regard to usability (e.g., [2]) and user-centered design (e.g., [3]). In prior work, we developed a usability-based methodology for developing graphic user interfaces using prototype tools <ref> [4] </ref>). We have adapted this rapid-prototyping methodology as a basis for developing SLS dialogues. This development process iterates over two phases. In the first phase, the structure and surface form of a dialogue are designed and refined.
Reference: [5] <author> M. Fanty, R. A. Cole, and K. Roginski, </author> <title> English Alphabet Recognition with Telephone Speech, </title> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pp. 199-206, </pages> <publisher> Morgan Kaufmann Publishers (1992). </publisher>
Reference-contexts: It incorporates two separate recognizers: the OGI alphabet recognizer and the OGI word recognizer; we envision a separate recognizer for numbers in the final system. The alphabet recognizer is hand-tuned to recognize letters spoken with pauses and achieves 89% accuracy over the telephone <ref> [5] </ref>. The current word recognizer [6] is vocabulary-independent. It uses a neural-network-based phonetic front end trained on fluent telephone speech. The language model was built by hand and uses an all-word model to allow for some extraneous speech before and after the target response (e.g, Im in Im male).
Reference: [6] <author> M. Fanty, P. Schmid, and R. A. Cole, </author> <title> City name recognition over the telephone, </title> <booktitle> Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> I, </volume> <pages> pp. 549-552, </pages> <year> 1993. </year>
Reference-contexts: It incorporates two separate recognizers: the OGI alphabet recognizer and the OGI word recognizer; we envision a separate recognizer for numbers in the final system. The alphabet recognizer is hand-tuned to recognize letters spoken with pauses and achieves 89% accuracy over the telephone [5]. The current word recognizer <ref> [6] </ref> is vocabulary-independent. It uses a neural-network-based phonetic front end trained on fluent telephone speech. The language model was built by hand and uses an all-word model to allow for some extraneous speech before and after the target response (e.g, Im in Im male).
Reference: [7] <author> Ward, W., </author> <title> The CMU air travel information service: Understanding spontaneous speech, </title> <booktitle> Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <pages> pp. 127-129, </pages> <year> 1990. </year>
Reference-contexts: Research in noise robustness, word-spotting, rejection, barge-in (i.e., talking over prompts), and increased accuracy is in progress; features based on this research will be incorporated into the final system. 2. Semantic parser. This prototypes semantic parser is based on the Phoenix system developed at Carnegie-Mellon University <ref> [7] </ref>. The parser produces candidate meanings for a given word sequence. It parses semantic fragments using a frame-based semantic grammar. Development of the semantic grammar was based on observation of the range of protocol responses in the corpus from rounds 1 and 2. 3. Dialogue module.
References-found: 7

