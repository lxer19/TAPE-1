URL: http://www.cs.washington.edu/research/smt/papers/smtdatabase.ps
Refering-URL: http://www.cs.washington.edu/research/smt/papers/smtdatabaseabstract.html
Root-URL: 
Title: An Analysis of Database Workload Performance on Simultaneous Multithreaded Processors  
Author: Jack L. Lo, Luiz Andr Barroso*, Susan J. Eggers, Kourosh Gharachorloo*, Henry M. Levy, and Sujay S. Parekh 
Address: Box 352350  Seattle, WA 98195  250 University Ave. Palo Alto, CA 94301  
Affiliation: Dept. of Computer Science and Engineering  University of Washington  *Digital Equipment Corporation Western Research Laboratory  
Date: June 1998.  
Note: To appear in Proceedings of the 25th Annual International Symposium on Computer Architecture,  
Abstract: This paper examines database performance on SMT processors using traces of the Oracle database manage ment system. Our research makes three contributions. First, it characterizes the memory-system behavior of database systems running on-line transaction processing and decision support system workloads. Our data show that while DBMS workloads have large memory foot prints, there is substantial data reuse in a small, cache able critical working set. Second, we show that the additional data cache conflicts caused by simultaneous multithreaded instruction scheduling can be nearly elimi nated by the proper choice of software-directed policies for virtual-to-physical page mapping and per-process address offsetting. Our results demonstrate that with the best policy choices, D-cache miss rates on an 8-context SMT are roughly equivalent to those on a single-threaded superscalar. Multithreading also leads to better inter thread instruction cache sharing, reducing I-cache miss rates by up to 35%. Third, we show that SMTs latency tol erance is highly effective for database applications. For example, using a memory-intensive OLTP workload, an 8 context SMT processor achieves a 3-fold increase in instruction throughput over a single-threaded superscalar with similar resources. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson, et al. </author> <title> Continuous profiling: </title> <booktitle> Where have all the cycles gone? In 16th ACM Symp. on Operating System Prin ciples, </booktitle> <address> p. 114, </address> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: We therefore examined the behavior of the Oracle DBMS and the underlying Digital UNIX operating system to validate and strengthen our simulation methodology. Though DBMS source code was not available, we used both the Digital Continuous Profiling Infrastructure (DCPI) <ref> [1] </ref> and separate experi ments running natively on Digital AlphaServers to understand DBMS behavior and extract appropriate parameters for our simulations. The remainder of this sec tion describes the experimental methodology, including the workloads, trace generation, operating system activity (including modelling of I/O), and synchronization.
Reference: [2] <author> L. A. Barroso, et al. </author> <title> Memory system characterization of commercial workloads. </title> <booktitle> In 25th Ann. Intl Symp. on Comput er Arch., </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: Our OLTP work load is based on the TPC-B benchmark [20]. Although TPC-C has supplanted TPC-B as TPCs current OLTP benchmark, we found that the two workloads have simi lar processor and memory system characteristics <ref> [2] </ref>. We chose TPC-B because it is easier to set up and run. The OLTP workload models transaction processing for a bank, where each transaction corresponds to a bank account deposit. Each transaction is small, but updates several database tables (e.g., teller and branch). <p> The query scans the largest table (lineitem) to quantify the amount of revenue increase that would have resulted from eliminating certain discounts in a given percentage range in a given year. This query is representative of DSS workloads; other TPC-D queries tend to have similar memory system behavior <ref> [2] </ref>. Trace generation Commercial database applications require consider able tuning to achieve optimal performance. <p> For our DSS workload, scaling is more com plex, because the run time (and therefore, simulation time) grows linearly with the size of the database. Fortu nately, the DSS query exhibits very consistent behavior throughout its execution, so we could generate representa tive traces using sampling techniques <ref> [2] </ref>. With the sampled traces, each of our DSS experiments simulate roughly 500M instructions from queries on a 500MB database. Operating system activity Although ATOM generates only user-level traces, we took several measures to ensure that we carefully mod elled operating system effects.
Reference: [3] <author> Z. Cvetanovic and D. Bhandarkar. </author> <title> Characterization of Alpha AXP performance using TP and SPEC workloads. </title> <booktitle> In 21st Ann. Intl Symp. on Computer Arch., </booktitle> <address> p. 6070, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Maynard, et al., [12] highlighted the large instruction footprints and high instruction cache miss rates of OLTP workloads. In another study, Cvet anovic and Bhandarkar <ref> [3] </ref> used performance counters on the DEC Alpha chip family (21064 and 21164) to iden tify the performance characteristics of a range of applications, including two commercial workloads.
Reference: [4] <author> S. Eggers, et al. </author> <title> Simultaneous multithreading: A platform for next-generation processors. </title> <booktitle> In IEEE Micro, </booktitle> <address> p. 1219, </address> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: This paper examines the memory system behavior of database management systems on simultaneous multi threaded processors. Simultaneous multithreading (SMT) <ref> [4] </ref> is an architectural technique in which the processor issues instructions from multiple threads in a single cycle.
Reference: [5] <author> R. Eickemeyer, et al. </author> <title> Evaluation of multithreaded uniproces sors for commercial application environments. </title> <booktitle> In 23rd Ann. Intl Symp. on Computer Arch., </booktitle> <address> p. 203212, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Eickemeyer, et al., <ref> [5] </ref> used trace-driven simulation to evaluate the benefits of coarse grain multithreading for TPC-C on the OS/400 database. By using two or three threads, throughput increased by 70%; but with more than 3 threads, no further gains were achieved.
Reference: [6] <author> M. Franklin, et al. </author> <title> Commercial workload performance in the IBM POWER2 RISC System/6000 processor. IBM J. of Re search and Development, </title> <address> 38(5):555561, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: Operating system activity Although ATOM generates only user-level traces, we took several measures to ensure that we carefully mod elled operating system effects. While some previous studies have found that operating system kernel activity can dominate execution time for OLTP workloads <ref> [6, 12, 16] </ref>, we found that a well-tuned workload spends most of its time in user-level code. Using DCPI, we determined that for OLTP, roughly 70% of execution time was spent in user-level code, with the rest in the kernel and the idle loop. <p> Our study does not examine individual data structures, but contrasts the effects of OLTP and DSS workloads on the behavior of database memory regions in a widely-used commercial database application. Our paper also extends the cache behavior analysis presented in other prior work. Franklin, et al., <ref> [6] </ref> identi fied the scarcity of loops and context switches as contributors to high instruction cache miss rates in com mercial applications. Maynard, et al., [12] highlighted the large instruction footprints and high instruction cache miss rates of OLTP workloads.
Reference: [7] <author> V. Gokhale. </author> <title> Design of the 64-bit option for the Oracle7 rela tional database management system. Digital Technical Jour nal, </title> <address> 8(4):7682, </address> <year> 1996. </year>
Reference-contexts: However, with the latest generation of commer cial database engines employing numerous processes, disk arrays, increased I/O concurrency, and huge memo ries, many of the I/O limitations have been addressed <ref> [7] </ref>. Memory system performance is now the crucial problem: the high miss rates of database workloads, coupled with long memory latencies, make the design of future CPUs for database execution a significant challenge. This paper examines the memory system behavior of database management systems on simultaneous multi threaded processors.
Reference: [8] <author> T. Kawaf, et al. </author> <title> Performance analysis using very large mem ory on the 64-bit AlphaServer system. </title> <journal> Digital Technical Journal, </journal> <volume> 8(3):5865, </volume> <year> 1996. </year>
Reference-contexts: Lovett and Clapp [11] focused on the L2 cache behavior and scalability of the Sequent STiNG CC NUMA multiprocessor. Verghese, et al., [24] evaluated page migration and replication for CC-NUMA architectures. Torrellas, et al., [19] used Oracle running TP1 to characterize OS cache activity. Kawaf, et al., <ref> [8] </ref> and Piantedosi, et al., [15] described optimizations for improving TPC-C performance on Digital AlphaServers. 7 Conclusions This paper explored the behavior of database workloads on simultaneous multithreaded processors, concentrating in particular on the challenges presented to the memory system.
Reference: [9] <author> R. Kessler and M. Hill. </author> <title> Page placement algorithms for large real-indexed caches. </title> <journal> ACM Trans. on Computer and Systems, </journal> <volume> 10(4):338359, </volume> <month> November </month> <year> 1992. </year>
Reference-contexts: By mapping two virtual pages to different colors, the page-mapping policy can eliminate cache con flicts between data on the two pages and improve cache performance <ref> [9] </ref>. The two most commonly-used page-mapping policies are page coloring and bin hopping. Page coloring exploits spatial locality by mapping consecutive virtual pages to consecutive physical page colors.
Reference: [10] <author> J. Lo, et al. </author> <title> Tuning compiler optimizations for simultaneous multithreading. </title> <booktitle> In 30th Intl Symp. on Microarchitecture, </booktitle> <address> p. 114124, </address> <month> December </month> <year> 1997. </year>
Reference-contexts: By interleav ing instructions from multiple threads, and by choosing to fetch from threads that are making the most effective utilization of the execution resources [23], SMT reduces the need for (and more importantly, the cost of) specula tive execution <ref> [10] </ref>. SMT also greatly reduces the number of cycles in which no instructions can be fetched due to misfetches or I-cache misses. On the DSS workload SMT nearly eliminates all zero-fetch cycles.
Reference: [11] <author> T. Lovett and R. Clapp. STiNG: </author> <title> A CC-NUMA computer system for the commercial marketplace. </title> <booktitle> In 23rd Ann. Intl Symp. on Computer Arch., </booktitle> <address> p. 308317, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Finally, a few studies have used OLTP and DSS workloads to evaluate multiprocessor systems or investigate other performance issues. Thakkar and Sweiger [18] identified disk I/O and the system bus as bottlenecks for the TP1 benchmark on a Sequent Symmetry. Lovett and Clapp <ref> [11] </ref> focused on the L2 cache behavior and scalability of the Sequent STiNG CC NUMA multiprocessor. Verghese, et al., [24] evaluated page migration and replication for CC-NUMA architectures. Torrellas, et al., [19] used Oracle running TP1 to characterize OS cache activity.
Reference: [12] <author> A. M. Maynard, et al. </author> <title> Contrasting characteristics and cache performance of technical and multi-user commercial work loads. </title> <booktitle> In Sixth Intl Conference on Arch. Support for Prog. Lang. and Operating Systems, </booktitle> <address> p. 145156, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Operating system activity Although ATOM generates only user-level traces, we took several measures to ensure that we carefully mod elled operating system effects. While some previous studies have found that operating system kernel activity can dominate execution time for OLTP workloads <ref> [6, 12, 16] </ref>, we found that a well-tuned workload spends most of its time in user-level code. Using DCPI, we determined that for OLTP, roughly 70% of execution time was spent in user-level code, with the rest in the kernel and the idle loop. <p> Our paper also extends the cache behavior analysis presented in other prior work. Franklin, et al., [6] identi fied the scarcity of loops and context switches as contributors to high instruction cache miss rates in com mercial applications. Maynard, et al., <ref> [12] </ref> highlighted the large instruction footprints and high instruction cache miss rates of OLTP workloads. In another study, Cvet anovic and Bhandarkar [3] used performance counters on the DEC Alpha chip family (21064 and 21164) to iden tify the performance characteristics of a range of applications, including two commercial workloads.
Reference: [13] <author> S. McFarling. </author> <title> Combining branch predictors. </title> <type> Technical Re port TN-36, </type> <institution> DEC-WRL, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: In addition, the branch target buffer and translation lookaside buffer contain per-context identifiers. Table 1 provides more details describing our proces sor model, and Table 2 lists the memory system parameters. Branch prediction uses a McFarling-style, hybrid branch predictor <ref> [13] </ref> with an 8K-entry global pre Functional units 6 integer (including 4 ld/st units), 4 FP Instruction queue 32 integer entries, 32 FP entries Active list 128 entries/context Architectural registers 32*8 integer / 32*8 FP Renaming registers 100 integer / 100 FP Instruction retirement up to 12 instructions per cycle Table
Reference: [14] <author> S. Perl and R. </author> <title> Sites. Studies of Windows NT performance us ing dynamic execution traces. </title> <booktitle> In Second USENIX Symp. on Operating System Design and Implementation, </booktitle> <address> p. 169183, </address> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: In addition to characterizing database memory behavior, prior research has also identified other bottlenecks, such as pin bandwidth and I/O, in OLTP workloads. Perl and Sites <ref> [14] </ref> demonstrated that both high bandwidth and low latency are required to effectively run OLTP and other commercial applications. Their experiments assumed single-cycle instruction latencies and on-chip cache sizes of the Alpha 21064 (8KB I, 8KB D) and 21164 (8KB I, 8KB D, and 96KB unified on-chip L2).
Reference: [15] <author> J. Piantedosi, et al. </author> <title> Performance of TruCluster systems under the TPC-C benchmark. </title> <journal> Digital Technical Journal, </journal> <volume> 8(3):46 57, </volume> <year> 1996. </year>
Reference-contexts: Verghese, et al., [24] evaluated page migration and replication for CC-NUMA architectures. Torrellas, et al., [19] used Oracle running TP1 to characterize OS cache activity. Kawaf, et al., [8] and Piantedosi, et al., <ref> [15] </ref> described optimizations for improving TPC-C performance on Digital AlphaServers. 7 Conclusions This paper explored the behavior of database workloads on simultaneous multithreaded processors, concentrating in particular on the challenges presented to the memory system.
Reference: [16] <editor> M. Rosenblum, et al. </editor> <booktitle> The impact of architectural trends on operating system performance. In 15th ACM Symp. on Oper ating System Principles, </booktitle> <address> p. 285298, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Operating system activity Although ATOM generates only user-level traces, we took several measures to ensure that we carefully mod elled operating system effects. While some previous studies have found that operating system kernel activity can dominate execution time for OLTP workloads <ref> [6, 12, 16] </ref>, we found that a well-tuned workload spends most of its time in user-level code. Using DCPI, we determined that for OLTP, roughly 70% of execution time was spent in user-level code, with the rest in the kernel and the idle loop. <p> Pin bandwidth was therefore a smaller bottleneck; the larger caches and constructive instruction cache interference (due to SMT) also reduced the bandwidth demands. Rosenblum, et al., <ref> [16] </ref> found that both CPU idle time and kernel activity were significant when running an OLTP workload on Sybase. CPU idle time was greater than 30% because of disk I/O; kernel activity accounted for 38% of non-idle execution time.
Reference: [17] <author> A. Srivastava and A. Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In ACM SIGPLAN 94 Conference on Programming Language Design and Imple mentation, </booktitle> <address> p. 196205, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Using the best-performing configura tion, we instrumented the database application with ATOM <ref> [17] </ref> and generated a separate instruction trace file for each server process. We then fed these traces to our cycle-level SMT simulator, whose parameters were described above. In each experiment, our workload con sists of 16 processes (threads), unless otherwise noted.
Reference: [18] <author> S. Thakkar and M. Sweiger. </author> <title> Performance of an OLTP appli cation on Symmetry multiprocessor system. </title> <booktitle> In 17th Ann. Intl Symp. on Computer Arch., </booktitle> <address> p. 228238, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: For example, I/O latencies can be hidden more effectively by using more server processes (as is typically done in audit runs of TPC benchmarks). Finally, a few studies have used OLTP and DSS workloads to evaluate multiprocessor systems or investigate other performance issues. Thakkar and Sweiger <ref> [18] </ref> identified disk I/O and the system bus as bottlenecks for the TP1 benchmark on a Sequent Symmetry. Lovett and Clapp [11] focused on the L2 cache behavior and scalability of the Sequent STiNG CC NUMA multiprocessor. Verghese, et al., [24] evaluated page migration and replication for CC-NUMA architectures.
Reference: [19] <author> J. Torrellas, et al. </author> <title> Characterizing the caching and synchroni zation performance of a multiprocessor operating system. </title> <booktitle> In Fifth Intl Conference on Arch. Support for Prog. Lang. and Operating Systems, </booktitle> <address> p. 162174, </address> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: Lovett and Clapp [11] focused on the L2 cache behavior and scalability of the Sequent STiNG CC NUMA multiprocessor. Verghese, et al., [24] evaluated page migration and replication for CC-NUMA architectures. Torrellas, et al., <ref> [19] </ref> used Oracle running TP1 to characterize OS cache activity.
Reference: [20] <author> Transaction Processing Performance Council. </author> <title> TPC Bench mark B Standard Specification Revision 2.0. </title> <month> June </month> <year> 1994. </year>
Reference-contexts: The database workload On-line transaction processing (OLTP) and decision support systems (DSS) dominate the workloads handled by database servers; our studies use two workloads, one representative of each of these domains. Our OLTP work load is based on the TPC-B benchmark <ref> [20] </ref>. Although TPC-C has supplanted TPC-B as TPCs current OLTP benchmark, we found that the two workloads have simi lar processor and memory system characteristics [2]. We chose TPC-B because it is easier to set up and run.
Reference: [21] <author> Transaction Processing Performance Council. </author> <title> TPC Bench mark D (Decision Support) Standard Specification Revision 1.2. </title> <month> November </month> <year> 1996. </year>
Reference-contexts: In decision support systems, queries execute against a large database to answer critical business questions. The database consists of several inter-related tables, such as parts, nations, customers, orders, and lineitems. Our DSS workload is based on query 6 of the TPC-D benchmark <ref> [21] </ref>, which models the database activity for a business that manages, sells, or distributes products worldwide. The query scans the largest table (lineitem) to quantify the amount of revenue increase that would have resulted from eliminating certain discounts in a given percentage range in a given year.
Reference: [22] <author> P. Trancoso, et al. </author> <title> The memory performance of DSS com mercial workloads in shared-memory multiprocessors. </title> <booktitle> In 3rd Ann. Intl Symp. on High-Performance Computer Architec ture, </booktitle> <address> p. 250260, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: Therefore it hides latencies more effectively, and can utilize more hardware contexts to achieve greater throughput gains. While several other studies characterized memory system behavior of database workloads, only one study analyzed memory access patterns in detail. Trancoso, et al., <ref> [22] </ref> used a public-domain DBMS (Postgres95) to examine the memory access patterns of several DSS queries on cache-coherent shared-memory multi processors, and contrasted the cache effects on various data structures in the Postgres95 DBMS.
Reference: [23] <author> D. Tullsen, et al. </author> <title> Exploiting choice: Instruction fetch and is sue on an implementable simultaneous multithreading pro cessor. </title> <booktitle> In 23rd Ann. Intl Symp. on Computer Arch., p. </booktitle> <volume> 191 202, </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: For scientific workloads, SMT has been shown to substantially increase processor utilization through fine grained sharing of all processor resources (the fetch and issue logic, the caches, the TLBs, and the functional units) among the executing threads <ref> [23] </ref>. However, SMT performance on commercial databases is still an open research question, and is of interest for three related rea sons. First, a database workload is intrinsically multithreaded, providing a natural source of threads for an SMT processor. <p> This combination of wide-issue superscalar technology and fine-grain hardware multithreading improves utilization of processor resources, and therefore increases instruction throughput and program speedups. Previous research has shown that an SMT processor can be implemented with rather straightforward modifications to a standard dynamically-scheduled superscalar <ref> [23] </ref>. Our simulated SMT processor is an extension of a modern out-of-order, superscalar architecture, such as the MIPS R10000. During each cycle, the SMT processor fetches eight instructions from up to two of the eight hard ware contexts. <p> The superscalar fetches 50% and 100% more wrong-path (i.e., wasted) instructions than SMT for OLTP and DSS, respectively. By interleav ing instructions from multiple threads, and by choosing to fetch from threads that are making the most effective utilization of the execution resources <ref> [23] </ref>, SMT reduces the need for (and more importantly, the cost of) specula tive execution [10]. SMT also greatly reduces the number of cycles in which no instructions can be fetched due to misfetches or I-cache misses. On the DSS workload SMT nearly eliminates all zero-fetch cycles.
Reference: [24] <author> B. Verghese, et al. </author> <title> Operating system support for improving data locality on CC-NUMA compute servers. </title> <booktitle> In Seventh Intl Conference on Arch. Support for Prog. Lang. and Operating Systems, </booktitle> <address> p. 279289, </address> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: Thakkar and Sweiger [18] identified disk I/O and the system bus as bottlenecks for the TP1 benchmark on a Sequent Symmetry. Lovett and Clapp [11] focused on the L2 cache behavior and scalability of the Sequent STiNG CC NUMA multiprocessor. Verghese, et al., <ref> [24] </ref> evaluated page migration and replication for CC-NUMA architectures. Torrellas, et al., [19] used Oracle running TP1 to characterize OS cache activity.
References-found: 24

