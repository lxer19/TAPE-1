URL: http://www-ccs.cs.umass.edu/~krithi/rtdb/jpdd.ps
Refering-URL: http://www-ccs.cs.umass.edu/rtdb/publications.html
Root-URL: 
Title: Real-Time Databases  
Author: Krithi Ramamritham 
Note: Invited Paper To appear in International Journal of Distributed and Parallel Databases  
Date: February 28, 1996  
Address: Amherst, Mass. 01003  
Affiliation: Dept. of Computer and Information Science University of Massachusetts  
Abstract: Data in real-time databases has to be logically consistent as well as temporally consistent. The latter arises from the need to preserve the temporal validity of data items that reflect the state of the environment that is being controlled by the system. Some of the timing constraints on the transactions that process real-time data come from this need. These constraints, in turn, necessitate time-cognizant transaction processing so that transactions can be processed to meet their deadlines. This paper explores the issues in real-time database systems and presents an overview of the state of the art. After introducing the characteristics of data and transactions in real-time databases, we discuss issues that relate to the processing of time-constrained transactions. Specifically, we examine different approaches to resolving contention over data and processing resources. We also explore the problems of recovery, managing I/O, and handling overloads. Real-time databases have the potential to trade off the quality of the result of a query or a transaction for its timely processing. Quality can be measured in terms of the completeness, accuracy, currency, and consistency of the results. Several aspects of this tradeoff are also considered. fl This work was supported in part by NSF under grants CDA-8922572, IRI-9109210, and IRI-9114197.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Abbott and H. Garcia-Molina, </author> <title> "Scheduling Real-Time Transactions: A Performance Evaluation," </title> <booktitle> Proceedings of the 14th VLDB Conference, </booktitle> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: These can lead to pessimistic worst-case scenarios since worst-case assumptions must be made about the need to fetch data or program page from disk whenever the need arises. This will depend on the disk scheduling and buffer management algorithms used. Main memory databases <ref> [1] </ref> eliminate these problems. Transaction rollbacks also reduce predictability. Assume that a transaction is aborted and restarted a number of times before it commits. This has two negative consequences. The total execution time for the transaction increases and, if the number of aborts cannot be controlled, it may be unbounded. <p> For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict. <p> For example, with firm deadlines, a late transaction is aborted once its deadline expires [21]. In general, with soft deadlines, once a transaction's value drops to zero, it is aborted [25]. On the other hand, in the transaction model assumed in <ref> [1] </ref>, all transactions have to complete execution even if their deadlines have expired. In this model, delayed transactions may cause other transactions also to miss their deadlines and this can have a cascading effect.
Reference: [2] <author> R. Abbott and H. Garcia-Molina, </author> <title> "Scheduling Real-Time Transactions with Disk Resident Data," </title> <booktitle> Proceedings of the 15th VLDB Conference, </booktitle> <year> 1989. </year>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict.
Reference: [3] <author> R. Abbott and H. Garcia-Molina, </author> <title> "Scheduling I/O Requests with Deadlines: A Performance Evaluation," </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: This is the less preferred method since we now have a firm deadline associated with I/O requests if an I/O deadline is missed, there is no way for the transaction to complete by its deadline and so the requesting transaction must be aborted. Recent work on I/O scheduling includes <ref> [10, 3, 11] </ref>. The priority driven algorithm described in [10] is a variant of the traditional SCAN algorithm which works on the elevator principle to minimize disk arm movement. <p> In the case of requests arising from transactions with deadlines, priority assignment could be based on the deadline assigned to the I/O request. Another variant of SCAN, one which directly takes I/O deadlines into account is FD 21 SCAN <ref> [3] </ref>. In this algorithm, given the current position of the disk arm, the disk arm moves towards the request with the earliest deadline that can be serviced in time.
Reference: [4] <author> N. Audsley, A. Burns, M. Richardson, and A. Wellings, </author> <title> "A Database Model for Hard Real-Time Systems", </title> <type> Technical Report, </type> <institution> Real-Time Systems Group, Univ. of York, U.K., </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Needless to say, such a mishap can result in a major catastrophe. The need to maintain consistency between the actual state of the environment and the state as reflected by the contents of the database leads to the notion of temporal consistency. Temporal consistency has two components <ref> [48, 4] </ref>: * Absolute consistency between the state of the environment and its reflection in the database. <p> In general, however, temporal validity criteria are likely to be application dependent and so the timestamp of derived data can be stated as some function of those of the data in the corresponding R <ref> [4] </ref>. Let us pursue the relationships between avi's and rvi's further. Suppose data items u and v are used to derive data items x and y which in turn are used to derive z. <p> So we must ensure that in an interval where such a transaction executes, from the point where relative consistency holds until the end of the interval, there is sufficient time for the transaction to complete execution. Handling rvi's is clearly more involved <ref> [4] </ref>. Also, when we have a series of data derivations, each derivation being handled by a transaction, an alternative to using the rvi's is to impose precedence constraints on the transactions to conform with the derived-from relationship.
Reference: [5] <author> B. R. Badrinath and K. Ramamritham. </author> <title> "Semantics-Based Concurrency Control: Beyond Commutativity," </title> <journal> ACM Transactions on Database Systems, </journal> <month> March </month> <year> 1992. </year>
Reference-contexts: For instance, given that the data objects in real-time database systems will be abstract data type objects, as opposed to read/write objects, the semantics of the operations on these objects 22 can be exploited to improve concurrent access to these objects (see, for example, <ref> [5] </ref>). Gen--eralizing this, the parallelism and distribution inherent in real-time systems, which by their very nature function in physically distributed environments with multiple active processing elements, can be put to use to improve performance.
Reference: [6] <author> S. Baruah, G. Koren, D. Mao, B. Mishra, A. Raghunathan, L. Rosier, D. Shasha, F. Wang, </author> <title> "On the Competitiveness of On-Line Real-Time Scheduling", </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: Hence dealing with overleads is complex and solutions are still in their infancy <ref> [6, 8, 31] </ref>. An approach to this problem, based on discarding transactions immediately upon their arrival, given current system load and arriving transaction characteristics, is described in [22].
Reference: [7] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1987. </year> <month> 27 </month>
Reference-contexts: For instance, take case (b) in the the example discussed earlier. Here, time has progressed to a point where temperature and pressure become temporally invalid even if they are logically consistent. Thus, to satisfy logical consistency we use concurrency control techniques such as two phase locking <ref> [7] </ref> and to satisfy temporal consistency requirements we use time-cognizant transaction processing by tailoring the traditional concurrency control and transaction management techniques to explicitly deal with time.
Reference: [8] <author> S. Biyabani, J.A. Stankovic, and K. Ramamritham, </author> <title> "The Integration of Deadline and Criticalness in Hard Real-Time Scheduling," </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1988. </year>
Reference-contexts: Hence dealing with overleads is complex and solutions are still in their infancy <ref> [6, 8, 31] </ref>. An approach to this problem, based on discarding transactions immediately upon their arrival, given current system load and arriving transaction characteristics, is described in [22].
Reference: [9] <author> A.P. Buchmann, D.R. McCarthy, M. Chu, and U. Dayal, </author> <title> "Time-Critical Database Scheduling: A Framework for Integrating Real-Time Scheduling and Concurrency Control", </title> <booktitle> Proceedings of the Conference on Data Engineering, </booktitle> <year> 1989. </year>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict.
Reference: [10] <author> M.J. Carey, R. Jauhari, and M. Livny, </author> <title> "Priority in DBMS Resource Scheduling", </title> <booktitle> Proceedings of the 15th VLDB Conference, </booktitle> <month> Aug </month> <year> 1989, </year> <pages> pp. 397-410. </pages>
Reference-contexts: This is the less preferred method since we now have a firm deadline associated with I/O requests if an I/O deadline is missed, there is no way for the transaction to complete by its deadline and so the requesting transaction must be aborted. Recent work on I/O scheduling includes <ref> [10, 3, 11] </ref>. The priority driven algorithm described in [10] is a variant of the traditional SCAN algorithm which works on the elevator principle to minimize disk arm movement. <p> Recent work on I/O scheduling includes [10, 3, 11]. The priority driven algorithm described in <ref> [10] </ref> is a variant of the traditional SCAN algorithm which works on the elevator principle to minimize disk arm movement. Without specifying how priorities are assigned to individual I/O requests, [10] proposes a variant in which the SCAN algorithm is applied to each priority level. <p> Recent work on I/O scheduling includes [10, 3, 11]. The priority driven algorithm described in <ref> [10] </ref> is a variant of the traditional SCAN algorithm which works on the elevator principle to minimize disk arm movement. Without specifying how priorities are assigned to individual I/O requests, [10] proposes a variant in which the SCAN algorithm is applied to each priority level. Requests at lower priority are serviced only after those at higher priority are served. <p> Consider buffer replacement: in case there is a need to replace an existing buffer slot to make room for a new entry, the replacement policy may have an impact on performance, especially if the slot being replaced is used by an uncommitted transaction. Work done in this area includes <ref> [24, 10] </ref>. Whereas [24] reports of no significant performance improvements when time-cognizant buffer management policies are used, studies discussed in [10] show that transaction priorities must be considered in buffer management. <p> Work done in this area includes [24, 10]. Whereas [24] reports of no significant performance improvements when time-cognizant buffer management policies are used, studies discussed in <ref> [10] </ref> show that transaction priorities must be considered in buffer management.
Reference: [11] <author> S. Chen, J. Stankovic, J. Kurose, and D. Towsley, </author> <title> "Performance Evaluation of Two New Disk Scheduling Algorithms for Real-Time Systems", </title> <booktitle> Real-Time Systems, </booktitle> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: This is the less preferred method since we now have a firm deadline associated with I/O requests if an I/O deadline is missed, there is no way for the transaction to complete by its deadline and so the requesting transaction must be aborted. Recent work on I/O scheduling includes <ref> [10, 3, 11] </ref>. The priority driven algorithm described in [10] is a variant of the traditional SCAN algorithm which works on the elevator principle to minimize disk arm movement. <p> In either case, the direction of disk arm movement may change. Clearly, both these protocols involve checks after each request is served and so incur substantial run-time overheads. The protocols described in <ref> [11] </ref> are aimed at avoiding the impact of these checks on I/O performance. Specifically, the protocols perform the necessary computations while I/O is being performed. <p> The latter is accomplished by giving a high priority to requests which may have large deadlines but are very close to the current position of the disk arm. A variant of SSEDO is SSEDV which works with specific Deadline Values, rather than Deadline Orderings. <ref> [11] </ref> shows how both the algorithms can be implemented so as to perform disk scheduling while service is in progress and shows that the algorithms have better performance than the other variants of the SCAN algorithms. Another resource for which contention can arise is the database buffer.
Reference: [12] <author> U. Dayal, et. al. </author> <title> "The HiPAC Project: Combining Active Databases and Timing Constraints", </title> <booktitle> SIGMOD Record, </booktitle> <volume> 17, 1, </volume> <month> March </month> <year> 1988, </year> <pages> 51-70. </pages>
Reference-contexts: The condition can correspond to conditions on the state of the data or the environment. The action is said to be triggered <ref> [33, 12] </ref> and it can be an arbitrary transaction. Given this, it is not difficult to see that active databases provide a good model for the arrival (i.e., triggering) of periodic/aperiodic activities based on events and conditions.
Reference: [13] <author> K. R. Dittrich and U. Dayal. </author> <title> Active Database Systems (Tutorial Notes). </title> <booktitle> In The Seventeenth International Conference on Very Large Databases, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: Upon the occurrence of the specified event, if the condition holds, then the specified action can be taken. This construct provides a good mechanism by which integrity constraints can be maintained among related or overlapping data or by which views can be constructed <ref> [13] </ref>. The event can be arbitrary, including external events (as in the case of real-time events generated by the environment), timer events, or transaction related events (such as the begin and commit of transactions). The condition can correspond to conditions on the state of the data or the environment.
Reference: [14] <author> K. P. Eswaran, J. N. Gray, R. A. Lorie, and I. L. Traiger. </author> <title> The Notion of Consistency and Predicate Locks in a Database System. </title> <journal> Communications of the ACM, </journal> 19(11) 624-633, November 1976. 
Reference: [15] <author> Peter A. Franaszek, John T. Robinson, and Alexander Thomasian, </author> <title> "Access Invariance and its Use in High Contention Environments", </title> <booktitle> Proceedings of the Sixth International Conference on Database Engineering, </booktitle> <year> 1990, </year> <pages> pp 47-55. </pages>
Reference-contexts: Assume that the data dependent portions of the transactions are such that a transaction's execution path does not change due to possible concurrent changes done to the data by other transactions while a transaction is going through its pre-fetch phase <ref> [15] </ref>. That is to say, at the end of the pre-fetch phase, all the necessary data is in memory. We now attempt to guarantee that the transaction 13 will complete by its deadline.
Reference: [16] <author> M.C. Graham. </author> <title> "Issues in Real-Time Data Management", </title> <address> CMU/SEI-91-TR-17, </address> <month> July </month> <year> 1991. </year>
Reference: [17] <author> J. N. Gray, R. A. Lorie, G. R. Putzulo, and I. L. Traiger. </author> <title> Granularity of locks and degrees of consistency in a shared database. </title> <booktitle> In Proceedings of the First International Conference on Very Large Databases, </booktitle> <pages> pages 25-33, </pages> <address> Framingham, MA, </address> <month> September </month> <year> 1975. </year>
Reference-contexts: However, how to achieve this systematically is yet to be studied. What we need are notions similar to the degrees of consistency adopted in traditional database systems <ref> [17] </ref>. In this context, scheduling approaches that have been developed for the imprecise computation model in real-time systems could be tailored to apply to real-time database systems.
Reference: [18] <author> J.N. Gray and A. Reuter, </author> <title> "Transaction Processing: Techniques and Concepts", </title> <note> Morgan-Kaufman (book in preparation). </note>
Reference-contexts: But this consumes processing time that can affect the processing of transactions that are not waiting for locks to be released. Whereas optimistic concurrency control techniques or a shadow-pages based recovery strategy can be used to minimize this time, they have several disadvantages <ref> [18] </ref>. Secondly, unlike traditional databases where permanent data should always reflect a consistent state, in real-time databases, the presence of temporal data, while providing some opportunities for quicker recovery [51], adds to the complexities of the recovery of transactions.
Reference: [19] <author> N. Griffeth and A. Weinrib, </author> <title> "Scalability of a Real-Time Distributed Resource Counter", </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <address> Orlando, Florida (December 1990). </address>
Reference-contexts: Recent work in the real-time area can lead us to some partial answers [35]. In general, timeliness, a key performance measure, could be achieved by trading it off with completeness, accuracy, consistency, and currency <ref> [19, 40] </ref>. Below we consider each of these in turn. Let us first consider completeness. Suppose a transaction updates the screen of an operator in a chemical plant periodically.
Reference: [20] <author> J.R. Haritsa, M.J. Carey and M. Livny, </author> <title> "On Being Optimistic about Real-Time Constraints," </title> <booktitle> Proceedings of ACM PODS, </booktitle> <year> 1990. </year>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict. <p> However, depending on the characteristics of the validating transaction and those with which it con 17 flicts, we may prefer not to commit the validating transaction. Several policies have been studied in the literature <ref> [20, 21, 26] </ref>. In one, termed wait-50, a validating transaction is made to wait as long as more than half the transactions that conflict with it have earlier deadlines. This is shown to have superior performance. Time-cognizant extensions to timestamp-based protocols have also been proposed.
Reference: [21] <author> J.R. Haritsa, M.J. Carey and M. Livny, </author> <title> "Dynamic Real-Time Optimistic Concurrency Control," </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: Typically, the value drops to zero at a certain point past the deadline. If this point is the same as the deadline, we get firm deadline transactions which impart no value to the system once their deadlines expire <ref> [21] </ref>. For example, if components of a transaction are assigned deadlines derived from the deadline of the transaction, then even if a component misses its deadline, the overall transaction might still be able to make its deadline. Hence these deadlines are soft. <p> However, depending on the characteristics of the validating transaction and those with which it con 17 flicts, we may prefer not to commit the validating transaction. Several policies have been studied in the literature <ref> [20, 21, 26] </ref>. In one, termed wait-50, a validating transaction is made to wait as long as more than half the transactions that conflict with it have earlier deadlines. This is shown to have superior performance. Time-cognizant extensions to timestamp-based protocols have also been proposed. <p> The data displayed must have both absolute validity as well as relative validity. Different transaction semantics are possible with respect to discarding a transaction once its deadline is past. For example, with firm deadlines, a late transaction is aborted once its deadline expires <ref> [21] </ref>. In general, with soft deadlines, once a transaction's value drops to zero, it is aborted [25]. On the other hand, in the transaction model assumed in [1], all transactions have to complete execution even if their deadlines have expired.
Reference: [22] <author> J.R. Haritsa, M.J. Carey and M. Livny, </author> <title> "Earliest Deadline Scheduling for Real-Time Database Systems," </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> Dec. </month> <year> 1991. </year> <month> 28 </month>
Reference-contexts: Hence dealing with overleads is complex and solutions are still in their infancy [6, 8, 31]. An approach to this problem, based on discarding transactions immediately upon their arrival, given current system load and arriving transaction characteristics, is described in <ref> [22] </ref>. In managing overloads, some of the tradeoffs that we discussed earlier, involving timeliness vs. quality are also very pertinent. 7 Conclusions In this paper, we presented the characteristics of data and transactions in real-time database systems and discussed the differences between real-time database systems and traditional databases.
Reference: [23] <author> W. Hou, G. Ozsoyoglu, B. K. Taneja, </author> <title> "Processing Aggregate Relational Queries with Hard Time Constraints", </title> <booktitle> Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: When query processing involves computing aggregates, especially in a time-constrained environment, then one can achieve different degrees of accuracy by resorting to approximate query processing by sampling data <ref> [23] </ref>. Here, depending on time availability, results with different accuracies can be provided. Another example is that of a transaction that does not have all the necessary data for its processing but can recover from this situation by extrapolating based on previous data values.
Reference: [24] <author> J. Huang and J. Stankovic, </author> <title> "Real-Time Buffer Management," </title> <type> COINS TR 90-65, </type> <month> August </month> <year> 1990. </year>
Reference-contexts: Consider buffer replacement: in case there is a need to replace an existing buffer slot to make room for a new entry, the replacement policy may have an impact on performance, especially if the slot being replaced is used by an uncommitted transaction. Work done in this area includes <ref> [24, 10] </ref>. Whereas [24] reports of no significant performance improvements when time-cognizant buffer management policies are used, studies discussed in [10] show that transaction priorities must be considered in buffer management. <p> Work done in this area includes [24, 10]. Whereas <ref> [24] </ref> reports of no significant performance improvements when time-cognizant buffer management policies are used, studies discussed in [10] show that transaction priorities must be considered in buffer management.
Reference: [25] <author> J. Huang, J.A. Stankovic, D. Towsley and K. Ramamritham, </author> <title> "Experimental Evaluation of Real-Time Transaction Processing," </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> Dec. </month> <year> 1989 </year>
Reference-contexts: Note that priority assignment governs CPU scheduling and conflict resolution determines which of the many transactions contending for a data item will obtain access. As we will see, conflict resolution protocols make use of transaction priorities and because of this, the priority assignment policy plays a crucial role <ref> [25] </ref>. We discuss these two issues in Section 5.3.1. We also discuss the performance implications of different deadline semantics. <p> Possible policies are: * Earliest-deadline-first. * Highest-value-first. * Highest-value-per-unit-computation-time-first. * Longest-executed-transaction-first It has been shown that the priority assignment policy has significant impact on performance and that when different transactions have different values, both deadline and value must be considered <ref> [25] </ref>. For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature [1, 2, 9, 20, 25, 27, 26, 34, 47, 49]. These are discussed below. <p> For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict. <p> Different transaction semantics are possible with respect to discarding a transaction once its deadline is past. For example, with firm deadlines, a late transaction is aborted once its deadline expires [21]. In general, with soft deadlines, once a transaction's value drops to zero, it is aborted <ref> [25] </ref>. On the other hand, in the transaction model assumed in [1], all transactions have to complete execution even if their deadlines have expired. In this model, delayed transactions may cause other transactions also to miss their deadlines and this can have a cascading effect. <p> Of course, aborting a transaction also has performance implications given the costs of recovery. We discuss this in Section 6.3. Before we end this section, it should be pointed out that special time-cognizant deadlock detection, transaction wakeup, and restart policies appear to have little impact <ref> [25] </ref>. For example, breaking a deadlock cycle by aborting a transaction based on transaction timing characteristics does not seem to produce significantly better results.
Reference: [26] <author> J. Huang, J.A. Stankovic, K. Ramamritham and D. Towsley, </author> <title> "Experimental Evaluation of Real-Time Optimistic Concurrency Control Schemes", </title> <booktitle> Proceedings of the Conference on Very Large Data Bases, </booktitle> <month> Sep </month> <year> 1991. </year>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict. <p> However, depending on the characteristics of the validating transaction and those with which it con 17 flicts, we may prefer not to commit the validating transaction. Several policies have been studied in the literature <ref> [20, 21, 26] </ref>. In one, termed wait-50, a validating transaction is made to wait as long as more than half the transactions that conflict with it have earlier deadlines. This is shown to have superior performance. Time-cognizant extensions to timestamp-based protocols have also been proposed.
Reference: [27] <author> J. Huang, J.A. Stankovic, K. Ramamritham and D. Towsley, </author> <title> "On Using Priority Inheritance in Real-Time Databases," </title> <booktitle> Proceedings of the Real-Time Systems Symposium December 1991. </booktitle>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict. <p> Considerations involved in conflict resolution are the deadline and value (in general, the priority) of transactions, how long the transactions have executed, and how close they are to completion. Consider the following set of protocols investigated in <ref> [27] </ref>. 16 * If a transaction with a higher priority is forced to wait for a lower priority transaction to release the lock, a situation known as priority inversion arises. This is because a lower priority transaction makes a higher priority transaction to wait. <p> Otherwise let the lock requester wait. * If the lock holding transaction is closer to its deadline, lock requester waits, independent of its priority. Priority Inheritance is shown to reduce transaction blocking times <ref> [27] </ref>. This is because the lock holder executes at a higher priority (than that of the waiting transaction) and hence finishes early, thereby blocking the waiting higher priority transaction for a shorter duration. <p> Such a protocol is a combination of the abort-based protocol proposed for traditional databases [50] and the priority-inheritance protocol proposed for real-time systems [42]. Said differently, the superior performance of this protocol <ref> [27] </ref> shows that even though techniques that work in real-time systems on the one hand and database systems on the other hand may not be applicable directly, they can often be tailored and adapted to suit the needs of real-time database systems.
Reference: [28] <author> Jensen, E. D., Locke, C. D. and Tokuda, H., </author> <title> "A Time-Driven Scheduling Model For Real-Time Operating Systems", </title> <booktitle> Proceedings of 1985 IEEE Real-Time Systems Symposium, </booktitle> <pages> pp. 112-122. </pages>
Reference-contexts: In this paper, we use the terms hard, soft and firm to categorize the transactions. Viewed differently, this categorization tells us the value imparted to the system when a transaction meets its deadline. Whereas arbitrary types of value functions can be associated with activities <ref> [28] </ref>, we confine ourselves to simple functions as described below. * Hard deadline transactions are those which may result in a catastrophe if the deadline is missed. One can say that a large negative value is imparted to the system if a hard deadline is missed.
Reference: [29] <author> W. Kim and J. Srivastava, </author> <title> "Enhancing Real-Time DBMS Performance with Multi-version Data and Priority-Based Disk Scheduling", </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> Dec </month> <year> 1991, </year> <pages> pp. 222-231. </pages>
Reference-contexts: In these, when data accesses are out of timestamp order, the conflicts are resolved based on their priorities. In addition, several combinations of locking-based, optimistic and timestamp-based protocols have been proposed but require quantitative evaluation [34]. Exploiting multiple versions of data for enhanced performance has been addressed in <ref> [29] </ref>. Multiple versions can reduce conflicts over data. However, if data must have temporal validity, old versions which are outdated must be discarded.
Reference: [30] <author> Kitsurgawa, </author> <title> "The next generation of database machines", </title> <note> this issue. </note>
Reference-contexts: Of course, as we discussed earlier, distribution brings with it some special problems in the real-time context. With regard to predictability many advantages can be gained by the use of main memory databases. Also, the benefits afforded by database machines <ref> [30] </ref> for real-time database systems are worth exploring. Now let us consider approaches that are in some sense unique to real-time database systems.
Reference: [31] <author> G. Koren and D. Shasha, "D-Over: </author> <title> an optimal on-line scheduling algorithm for overloaded real-time systems" Real-Time Systems Symposium, </title> <month> Dec </month> <year> 1992. </year>
Reference-contexts: Hence dealing with overleads is complex and solutions are still in their infancy <ref> [6, 8, 31] </ref>. An approach to this problem, based on discarding transactions immediately upon their arrival, given current system load and arriving transaction characteristics, is described in [22].
Reference: [32] <author> H. F. Korth, E. Levy, and A. Silberschatz. </author> <title> Compensating Transactions: A New Recovery Paradigm. </title> <booktitle> In Proceedings of the Sixteenth International Conference on Very Large Databases, </booktitle> <pages> pages 95-106, </pages> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Available transaction as well as data semantics 24 (or state) must be exploited to minimize recovery overheads. Contingency or compensating transactions <ref> [32] </ref> are applicable here: Contingency transactions can take the form of multiple versions of a transaction each with different values and different computational and data requirements. <p> In case a real-time transaction has interacted with the environment, a compensating transaction may have to be invoked to recover from its failure <ref> [32] </ref>. The nature and state of the environment can be used to determine recovery strategies. In some situations, in the absence of new data that was to have been produced by an aborted transaction, extrapolation of new values from old values may be possible.
Reference: [33] <author> H. F. Korth, Soparkar, Silberschatz, A. </author> <title> "Triggered Real-Time databases with consistency constraints", </title> <booktitle> Proceedings of the Conference on Very Large Data Bases, </booktitle> <year> 1990. </year>
Reference-contexts: The condition can correspond to conditions on the state of the data or the environment. The action is said to be triggered <ref> [33, 12] </ref> and it can be an arbitrary transaction. Given this, it is not difficult to see that active databases provide a good model for the arrival (i.e., triggering) of periodic/aperiodic activities based on events and conditions.
Reference: [34] <author> Y. Lin and S.H. Son, </author> <title> "Concurrency Control in Real-Time Databases by Dynamic Adjustment of Serialization Order," </title> <booktitle> Proceedings of the Real-Time Systems Symposium, </booktitle> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict. <p> Time-cognizant extensions to timestamp-based protocols have also been proposed. In these, when data accesses are out of timestamp order, the conflicts are resolved based on their priorities. In addition, several combinations of locking-based, optimistic and timestamp-based protocols have been proposed but require quantitative evaluation <ref> [34] </ref>. Exploiting multiple versions of data for enhanced performance has been addressed in [29]. Multiple versions can reduce conflicts over data. However, if data must have temporal validity, old versions which are outdated must be discarded.
Reference: [35] <author> J. Liu, K. Lin, W. Shih, A. Yu, J. Chung, and W. Zhao, </author> <title> "Algorithms for Scheduling Imprecise Computation", </title> <journal> IEEE Computer, </journal> <volume> Vol. 24, No. 5, </volume> <month> May </month> <year> 1991. </year>
Reference-contexts: Thirdly, since timeliness is more important than correctness, in many situations, (approximate) correctness can be traded for timeliness. Similarly, atomicity may be relaxed. For instance, this happens with monotonic queries and transactions, which are the counterparts of monotonic tasks <ref> [35] </ref> in real-time systems. Furthermore, many of the extensions to serializability that have been proposed in databases are also applicable to real-time databases (See [41] for a review of these proposals). <p> However, it is not always clear what an acceptable partial result is or how a computation can be structured to provide acceptable partial results. Recent work in the real-time area can lead us to some partial answers <ref> [35] </ref>. In general, timeliness, a key performance measure, could be achieved by trading it off with completeness, accuracy, consistency, and currency [19, 40]. Below we consider each of these in turn. Let us first consider completeness. Suppose a transaction updates the screen of an operator in a chemical plant periodically.
Reference: [36] <author> J. E. B. Moss, </author> <title> Nested Transactions: An approach to reliable distributed computing. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> April </month> <year> 1981. </year> <month> 29 </month>
Reference-contexts: A distributed real-time database system introduces other complications as well, especially when we go beyond flat transactions. Let us consider nested transactions <ref> [36] </ref>. Even though transaction models that are more complex than flat transactions introduce additional unpredictability, some activities with soft time constraints may find them more suitable since, for instance, nested transactions allow the independent recovery of subtransactions. So far we assumed that each transaction has a value and a deadline.
Reference: [37] <author> P. O'Neil, K. Ramamritham, and C. Pu, </author> <title> "Towards Predictable Transaction Executions in Real-Time Database Systems", </title> <type> Technical Report 92-35, </type> <institution> University of Massachusetts, </institution> <month> August, </month> <year> 1992. </year>
Reference-contexts: Real-time database systems may introduce transaction aborts due to deadline misses. One way to avoid these aborts is to begin a transaction only if we know that it will complete by its deadline. We give an overview of this approach below. Details can be found in <ref> [37] </ref>. Preanalysis of a transaction is desirable because it provides an estimate of its computation time and data and resource requirements. But, for complex transactions this may not be feasible. In this case, to get the necessary information about a transaction the following approach can prove useful. <p> For example, in some situations, there may not even be a need to go to the execution phase. As in optimistic concurrency control this will happen if the data items used by the transaction were not used by any other concurrent transaction. Details can be found in <ref> [37] </ref>. 5.2 Dealing with Hard Deadlines All transactions with hard deadlines must meet their time constraints. Since dynamically managed transactions cannot provide such a guarantee, the data and processing resources as well as time needed by such transactions have to be guaranteed to be made available when necessary.
Reference: [38] <author> C. Pu and A. Leff. </author> <title> Replica Control in Distributed Systems: An Asynchronous Approach. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 377-386, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Turning to consistency, in the context of traditional databases, it has often been mentioned that correctness notions that relax serializability are appropriate (see [41] for a review of such relaxed notions.). For instance, epsilon serializability <ref> [38] </ref> allows a query to execute in spite of concurrent updates wherein the deviation of the query's results, from that of a serializable result, can be bounded. Such relaxations allow more transactions to execute concurrently thereby improving performance.
Reference: [39] <author> K. Ramamritham, J. Stankovic, and P. Shiah, </author> <title> "Efficient Scheduling Algorithms for Real-Time Multiprocessor Systems," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 1, No. 2, </volume> <month> April </month> <year> 1990, </year> <pages> pp. 184-194. </pages>
Reference-contexts: If such a plan cannot be constructed, the transaction is aborted without even starting it. The notion of guarantee and the planning algorithm are based on the resource constrained scheduling approach proposed for real-time systems and described in <ref> [39] </ref>. Let us see how this approach tackles the four major sources of unpredictability mentioned above. By using the pre-fetch phase to bring in the pages, the actual execution sequence is determined during this phase.
Reference: [40] <author> K. Ramamritham, S. Son, A. Buchmann, K. Dittrich, and C. Mohan, </author> <title> "Real-Time Databases" panel statement, </title> <booktitle> Proceedings of the Conference on Very-Large Databases, </booktitle> <month> September, </month> <year> 1991. </year>
Reference-contexts: Recent work in the real-time area can lead us to some partial answers [35]. In general, timeliness, a key performance measure, could be achieved by trading it off with completeness, accuracy, consistency, and currency <ref> [19, 40] </ref>. Below we consider each of these in turn. Let us first consider completeness. Suppose a transaction updates the screen of an operator in a chemical plant periodically.
Reference: [41] <author> K. Ramamritham and P. Chrysanthis, </author> <title> "In Search of Acceptability Criteria: Database Consistency Requirements and Transaction Correctness Properties" in Distributed Object Management, </title> <editor> Ozsu, Dayal, and Valduriez Ed., </editor> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1992. </year>
Reference-contexts: Similarly, atomicity may be relaxed. For instance, this happens with monotonic queries and transactions, which are the counterparts of monotonic tasks [35] in real-time systems. Furthermore, many of the extensions to serializability that have been proposed in databases are also applicable to real-time databases (See <ref> [41] </ref> for a review of these proposals). <p> Here again, if previous data values of different data items are used, their relatively consistency must be considered. Turning to consistency, in the context of traditional databases, it has often been mentioned that correctness notions that relax serializability are appropriate (see <ref> [41] </ref> for a review of such relaxed notions.). For instance, epsilon serializability [38] allows a query to execute in spite of concurrent updates wherein the deviation of the query's results, from that of a serializable result, can be bounded. Such relaxations allow more transactions to execute concurrently thereby improving performance.
Reference: [42] <author> L. Sha, R. Rajkumar, and J. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time Synchronization", </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(9), </volume> <pages> pp. 1175-1185, </pages> <year> 1990. </year>
Reference-contexts: This, for example, will be the case if the rate monotonic static priority approach, extended to deal with resources, <ref> [42, 43] </ref> is used to schedule periodic transactions executing on a main memory database. (Scheduling is discussed in greater detail in Section 5.) Thus, it follows from the above periodicity semantics that to maintain the avi of temperature, the period of the transaction that reads the temperature must be no more <p> Such a protocol is a combination of the abort-based protocol proposed for traditional databases [50] and the priority-inheritance protocol proposed for real-time systems <ref> [42] </ref>.
Reference: [43] <author> L. Sha, R. Rajkumar and J.P. Lehoczky, </author> <title> "Concurrency Control for Distributed Real-Time Databases," </title> <booktitle> ACM SIGMOD Record, </booktitle> <month> March </month> <year> 1988. </year>
Reference-contexts: This, for example, will be the case if the rate monotonic static priority approach, extended to deal with resources, <ref> [42, 43] </ref> is used to schedule periodic transactions executing on a main memory database. (Scheduling is discussed in greater detail in Section 5.) Thus, it follows from the above periodicity semantics that to maintain the avi of temperature, the period of the transaction that reads the temperature must be no more <p> The table-driven approach is obviously very inflexible. A priority-driven approach is the rate-monotonic priority assignment policy. One can apply the schedulability analysis tools associated with it to check if a set of transactions are schedulable given their periods and data requirements. This is the approach discussed in <ref> [43] </ref> where periodic transactions that access main memory resident data via read and write locks are scheduled using rate-monotonic priority assignment. We mentioned earlier that the variance between the worst-case computational needs and actual needs must not be very large. We can see why.
Reference: [44] <author> C. Shen, K. Ramamritham, and J. Stankovic, </author> <title> Resource Reclaiming in Real-Time, </title> <booktitle> Proc Real-Time System Symposium, </booktitle> <month> December </month> <year> 1990. </year> <note> (to appear in IEEE Transactions on Parallel and Distributed Systems). </note>
Reference-contexts: Static table-driven schedulers reserve specific time slots for each transaction. If a transaction does not use all of the time reserved for it, the time may be reclaimed <ref> [44] </ref> to start other hard real-time transactions earlier than planned. Otherwise, it can be used for soft real-time transactions or left idle. The table-driven approach is obviously very inflexible. A priority-driven approach is the rate-monotonic priority assignment policy.
Reference: [45] <author> K. P. Smith and J.W.S. Liu, </author> <title> "Monotonically improving approximate answers to relational algebra queries", </title> <booktitle> Proceedings of Compsac, </booktitle> <month> September </month> <year> 1989. </year>
Reference-contexts: In this context, scheduling approaches that have been developed for the imprecise computation model in real-time systems could be tailored to apply to real-time database systems. Preliminary work in this area is reported in <ref> [45] </ref>. 6.3 Recovery Issues Recovery is a complex issue even in traditional databases and is more so in real-time database systems for two reasons. (The approach discussed at the end of Section 5.1 was motivated in part by these complexities.) Firstly, the process of recovery can interfere with the processing of
Reference: [46] <author> R. Snodgrass and I. Ahn, </author> <title> "Temporal Databases", </title> <journal> IEEE Computer, </journal> <volume> Vol 19, No. 9, </volume> <month> September </month> <year> 1986, </year> <pages> pp. 35-42. </pages>
Reference-contexts: This derivation typically would depend on past temperature and pressure trends and so some of the needed information may have to be fetched from archival storage (a temporal database <ref> [46] </ref>). Based on the derived data, where the derivation may involve multiple steps, actuator commands are set. For instance, in our example, the derived reaction rate is used 4 to determine the amount of chemicals or coolant to be added to the reaction.
Reference: [47] <author> S. .H. Son, Y. Lin, and R. P. Cook, </author> <title> "Concurrency Control in Real-Time Database Systems", in Foundations of Real-Time Computing: Scheduling and Resource Management, </title> <editor> edited by Andre van Tilborg and Gary Koob, </editor> <publisher> Kluwer Academic Publishers, </publisher> <pages> pp. 185-202, </pages> <year> 1991. </year>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict.
Reference: [48] <author> X. Song and J.W.S. Liu, </author> <title> "How Well Can Data Temporal Consistency be Maintained?" Proceedings of the IEEE Symposium on Computer-Aided Control Systems Design, </title> <note> (to appear) 1992. </note>
Reference-contexts: Needless to say, such a mishap can result in a major catastrophe. The need to maintain consistency between the actual state of the environment and the state as reflected by the contents of the database leads to the notion of temporal consistency. Temporal consistency has two components <ref> [48, 4] </ref>: * Absolute consistency between the state of the environment and its reflection in the database. <p> Clearly, there will be some correlation between these timestamps and those of the data from which new data is derived. One possibility is to assign the timestamp of d 0 derived from data items in R to be equal to min d 2 R (d timestamp ) <ref> [48] </ref>. That is, derived data is only as recent as the oldest data from which the derivation occurs.
Reference: [49] <author> J.A. Stankovic, K. Ramamritham, and D. Towsley, </author> <title> "Scheduling in Real-Time Transaction Systems," in Foundations of Real-Time Computing: Scheduling and Resource Management, </title> <editor> edited by Andre van Tilborg and Gary Koob, </editor> <publisher> Kluwer Academic Publishers, </publisher> <pages> pp. 157-184, </pages> <year> 1991. </year> <month> 30 </month>
Reference-contexts: For the purpose of conflict resolution in real-time database systems, various time-cognizant extensions of two phase locking, optimistic, and timestamp based protocols have been proposed in the literature <ref> [1, 2, 9, 20, 25, 27, 26, 34, 47, 49] </ref>. These are discussed below. In the context of two-phase locking, when a transaction requests a lock that is currently held by another transaction we must take into account the characteristics of the transactions involved in the conflict.
Reference: [50] <author> Y. C. Tay and Nathan Goodman and Rajan Suri, </author> <title> "Locking performance in centralized databases", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> volume 10, number 4, </volume> <month> December, </month> <year> 1985, </year> <pages> pp. 415-462. </pages>
Reference-contexts: On the other hand, if a lower priority transaction that is closer to completion inherits priority rather than aborting, then a better performance results even when data contention is high. Such a protocol is a combination of the abort-based protocol proposed for traditional databases <ref> [50] </ref> and the priority-inheritance protocol proposed for real-time systems [42].
Reference: [51] <author> S. V. Vrbsky and K.J. Lin. </author> <title> "Recovering Imprecise Computations with Real-Time Constraints", </title> <booktitle> Proceedings of the Seventh Symp. on Reliable Distributed Systems, </booktitle> <month> October </month> <year> 1988, </year> <pages> pp. 185-193. </pages>
Reference-contexts: Secondly, unlike traditional databases where permanent data should always reflect a consistent state, in real-time databases, the presence of temporal data, while providing some opportunities for quicker recovery <ref> [51] </ref>, adds to the complexities of the recovery of transactions.
References-found: 51

