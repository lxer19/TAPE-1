URL: http://theory.lcs.mit.edu/~madhu/papers/kmsv.ps
Refering-URL: http://theory.lcs.mit.edu/~madhu/papers.html
Root-URL: 
Email: (sanjeev@theory.stanford.edu).  
Title: On Syntactic versus Computational Views of Approximability  
Author: SANJEEV KHANNA RAJEEV MOTWANI MADHU SUDAN UMESH VAZIRANI 
Keyword: approximation algorithms, complete problems, computational complexity, computational classes, polynomial reductions, local search.  
Note: AMS Subject Classification: 68Q15.  Supported by an OTL grant, NSF Grant CCR-9357849, and a Schlumberger Foundation Fellowship.  
Address: Berkeley  Stanford, CA 94305  
Affiliation: Stanford University Stanford University IBM Research U.C.  Department of Computer Science, Stanford University,  
Abstract: We attempt to reconcile the two distinct views of approximationclasses: syntactic and computational. Syntactic classes such as MAX SNP permit structural results and have natural complete problems, while computational classes such as APX allow us to work with classes of problems whose approximability is well-understood. Our results provide a syntactic characterization of computational classes, and give a computational framework for syntactic classes. We compare the syntactically defined class MAX SNP with the computationally defined class APX, and show that every problem in APX can be placed (i.e., has approximation preserving reduction to a problem) in MAX SNP. Our methods introduce a simple, yet general, technique for creating approximation-preserving reductions which show that any well approximable problem can be reduced in an approximation-preserving manner to a problem which is hard to approximate to corresponding factors. The reduction then follows easily from the recent non-approximability results for MAX SNP-hard problems. We demonstrate the generality of this technique by applying it to other classes such as RMAX(2) and MIN F + 2 (1) which have the clique problem and the set cover problem, respectively, as complete problems. The syntactic nature of MAX SNP was used by Papadimitriou and Yannakakis [23] to provide approximation algorithms for every problem in the class. We provide an alternate approach to demonstrating this result using the syntactic nature of MAX SNP. We develop a general paradigm, non-oblivious local search, useful for developing simple yet efficient approximation algorithms. We show that such algorithms can find good approximations for all MAX SNP problems, yielding approximation ratios comparable to the best-known for a variety of specific MAX SNP-hard problems. Non-oblivious local search provably out-performs standard local search in both the degree of approximation achieved and the efficiency of the resulting algorithms. y Department of Computer Science, Stanford University, Stanford, CA 94305 (rajeev@theory.stanford.edu). Supported by an Alfred P. Sloan Research Fellowship, an IBM Faculty Development Award, an OTL grant, and NSF Young Investigator Award CCR-9357849, with matching funds from IBM, Schlumberger Foundation, Shell Foundation, and Xerox Corporation. z IBM T.J. Watson Research Center, Yorktown Heights, NY 10598 (madhu@watson.ibm.com). x Computer Science Division, U.C. Berkeley, CA 94720 (vazirani@cs.berkeley.edu). Supported by NSF Grant CCR 9310214. A preliminary version of this paper appeared in [18]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Alimonti. </author> <title> New Local Search Approximation Techniques for Maximum Generalized Satisfiability Problems. </title> <booktitle> In Proceedings of the 2nd Italian Conference on Algorithms and Complexity (1994), </booktitle> <pages> pp. 40-53. </pages>
Reference-contexts: In fact, our results indicate that non-oblivious local search is significantly more powerful than standard local search in that it delivers strictly better constant ratios, and also will provide 2 constant factor approximations to problems not in GLO. Independently of our work, Alimonti <ref> [1] </ref> has used a similar local search technique for the approximation of a specific problem not contained in GLO or MAX SNP. 1.2 Summary of Results In Section 2, we present the definitions required to state our results, and in particular the definitions of an E-reduction, APX, APX-PB, MAX SNP and <p> obtain a representation of the k-CSP problem in the MAX SNP syntax: max jfx j (I; S; x)gj: The input structure is I = (Z [ fT; F g [ MAX; fARG; EVALg), where Z = fz 1 ; : : : ; z n g, MAX contains the integers <ref> [1; maxfk; n; mg] </ref>, the predicate ARG encodes the sets V i , and the predicate EVAL encodes the predicates P i , as described below. * ARG (r; s; z t ) is 3-ary predicate which is true if and only if the rth argument of C s is the
Reference: [2] <author> S. Arora, C. Lund, R. Motwani, M. Sudan and M. Szegedy. </author> <title> Proof Verification and Hardness of Approximation Problems. </title> <booktitle> In Proceedings of the 33rd Annual IEEE Symposium on Foundations of Computer Science (1992), </booktitle> <pages> pp. 14-23. </pages>
Reference-contexts: The syntactic prescription in the definition of these classes has proved very useful in the establishment of complete problems. Moreover, the recent results of Arora, Lund, Motwani, Sudan, and Szegedy <ref> [2] </ref> have established the hardness of approximating complete problems for MAX SNP to within (specific) constant factors unless P = NP. It is natural to wonder why the hardest problems in this syntactic sub-class of APX should bear any relation to all of NP. <p> The proof is based on the results of Arora et al <ref> [2] </ref> on efficient proof verifications. Theorem 1 MAX SNP = APX-PB. Remark 5 The seeming weakness that MAX SNP only captures polynomially bounded APX problems can be removed by using looser forms of approximation-preserving reduction in defining the closure. <p> Theorem 2 MAX NP = MAX SNP. Papadimitriou and Yannakakis [23] (implicitly) introduced both these closure classes but did not conjecture them to be the same. It would be interesting to see if this equality can be shown independent of the result of Arora et al <ref> [2] </ref>. We also obtain the following resolution to the problem posed by Papadimitriou and Yannakakis [23] of finding complete problems for MAX NP. Theorem 3 MAX SAT is complete for MAX NP. The following sub-sections establish that MAX SNP APX-PB. <p> c Thus a solution s to 0 with error ffi is a solution to with error at most (c + 1)ffi, implying an E-reduction with fi = c + 1. 3.2 NP Languages and MAX 3-SAT The following theorem, adapted from a result of Arora, Lund, Motwani, Sudan, and Szegedy <ref> [2] </ref>, is critical to our E-reduction of maximization problems to MAX 3-SAT. Theorem 4 ([2]) Given a language L 2 NP and an instance x 2 n , one can compute in polynomial time an instance F x of MAX 3-SAT, with the following properties. 1. <p> Some of the properties above may not be immediately obvious from the construction given by Arora, Lund, Motwani, Sudan, and Szegedy <ref> [2] </ref>. It is easy to verify that they provide a reduction with properties (1), (3) and (4). <p> Theorem 6 a) RMAX (2) = poly-APX. b) If SET COVER is canonically hard to approximate to within a factor of (log n), then log-APX = MIN F + 2 (1). We briefly sketch the proof of this theorem. The hardness reduction for MAX SAT and CLIQUE are canonical <ref> [2, 11] </ref>. The classes APX-PB, poly-APX, log-APX are expressible as classes F -APX for downward closed function families. The problems MAX SAT, MAX CLIQUE and SET COVER are additive. Thus, we can now apply Theorem 5.
Reference: [3] <author> G. Ausiello, P. Crescenzi and M. Protasi. </author> <title> Approximate Solution of NP Optimization Problems. </title> <booktitle> Theoretical Computer Science, 150 (1995), </booktitle> <pages> pp. 1-55. </pages>
Reference: [4] <author> G. Ausiello and M. Protasi. </author> <title> Local Search, Reducibility, and Approximability of NP Optimization Problems. </title> <journal> Inform. Process. Lett., </journal> <volume> 54 (1995), </volume> <pages> pp. 73-79. </pages>
Reference-contexts: An intriguing possibility is that this is not a coincidence, but rather a hint at the universality of the paradigm or some variant thereof. Our results are related to some extent to those of Ausiello and Protasi <ref> [4] </ref>. They define a class GLO (for Guaranteed Local Optima) of NPO problems which have the property that for all locally optimum solutions, the ratio between the value of the global and the local optimum is bounded by a constant. <p> Theorem 13 There exist problems in MAX SNP such that for ffi = o (n), no ffi-local oblivious algorithm can approximate them to within a constant performance ratio, i.e., MAX SNP 6 OBLIVIOUS GLO: 8.2 Vertex Cover Ausiello and Protasi <ref> [4] </ref> have shown that VERTEX COVER does not belong to the class GLO and, hence, there does not exist any constant ffi such that an oblivious ffi-local search algorithm can compute a constant factor approximation.
Reference: [5] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Russell. </author> <title> Efficient probabilistically checkable proofs and Applications to Approximation. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing (1993), </booktitle> <pages> pp. 294-304. </pages>
Reference: [6] <author> P. Berman and M. Furer. </author> <title> Approximating Maximum Independent Set in Bounded Degree Graphs. </title> <booktitle> In Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms (1993), </booktitle> <pages> pp. 365-371. </pages>
Reference-contexts: This improves upon the long-standing approximation ratio of =2 due to Hochbaum [15], when 10. However, very recently, there has been a flurry of new results for this problem. Berman and Furer <ref> [6] </ref> have given an algorithm with performance ratio ( + 3)=5 + * when is even, and ( + 3:25)=5 + * for odd , where * &gt; 0 is a fixed constant.
Reference: [7] <author> D.P. Bovet and P. Crescenzi. </author> <title> Introduction to the Theory of Complexity. </title> <publisher> Prentice-Hall, </publisher> <address> New York (1993). </address>
Reference-contexts: For any solution S to I, the value of the solution, denoted by V (I; S), is assumed to be a polynomial time computable function which takes positive integer values (see <ref> [7] </ref> for a precise definition of NPO).
Reference: [8] <author> P. Crescenzi and A. Panconesi. </author> <title> Completeness in approximation classes. </title> <journal> Information and Computation, </journal> <volume> vol. 93 (1991), </volume> <pages> pp. 241-262. </pages>
Reference-contexts: The advantage of working with classes defined using approximability as the criterion is that it allows us to work with problems whose approximability is well-understood. Crescenzi and Panconesi <ref> [8] </ref> have recently also been able to exhibit complete problems for such classes, particularly APX. Unfortunately such complete problems seem to be rare and artificial, and do not seem to provide insight into the more natural problems in the class. <p> Since all the reductions given in this paper are E-reductions, they would also qualify as approximation-preserving reductions under most other definitions and in particular they fit the definitions of F -reductions and P -reductions of Crescenzi and Panconesi <ref> [8] </ref>. Remark 2 Having / E 0 implies that is as well approximable as 0 ; in fact, an E-reduction is an FPTAS-preserving reduction. An important benefit is that this reduction can be applied uniformly at all levels of approximability. <p> An important benefit is that this reduction can be applied uniformly at all levels of approximability. This is not the case with the other existing definitions of FPTAS-preserving reduction in the literature. For example, the FPTAS-preserving reduction (F -reduction) of Crescenzi and Panconesi <ref> [8] </ref> is much more unrestricted in scope and does not share this important property of the E-reduction. Note that Crescenzi and Panconesi [8] showed that there exists a problem 0 2 PTAS such that for any problem 2 APX, / F 0 . <p> This is not the case with the other existing definitions of FPTAS-preserving reduction in the literature. For example, the FPTAS-preserving reduction (F -reduction) of Crescenzi and Panconesi <ref> [8] </ref> is much more unrestricted in scope and does not share this important property of the E-reduction. Note that Crescenzi and Panconesi [8] showed that there exists a problem 0 2 PTAS such that for any problem 2 APX, / F 0 . Thus, there is the undesirable situation that a problem with no PTAS has a FPTAS-preserving reduction to a problem 0 with a PTAS.
Reference: [9] <author> P. Crescenzi and L. Trevisan. </author> <title> On approximation scheme preserving reducibility and its applications. </title> <booktitle> 14th Conference on Foundations of Software Technology and Theoretical Computer Science, Lecture Notes in Computer Science, </booktitle> <volume> no. 880, </volume> <pages> pp 330-341, </pages> <year> 1994. </year>
Reference-contexts: Using such reductions to define the class MAX SNP we show that this equals APX-PB, the class of all polynomially bounded NP optimization problems which are approximable to within constant factors. By using slightly looser definitions of approximation preserving reductions (and in particular the PTAS-reductions of Crescenzi et al <ref> [9] </ref>) this can be extended to include all of APX into MAX SNP. We then build upon this result to identify an interesting hierarchy of such approximability classes. <p> Theorem 1 MAX SNP = APX-PB. Remark 5 The seeming weakness that MAX SNP only captures polynomially bounded APX problems can be removed by using looser forms of approximation-preserving reduction in defining the closure. In particular, Crescenzi and Trevisan <ref> [9] </ref> define the notion of a PTAS-preserving reduction under which APX = APX-PB. Using their result in conjunction with the above theorem, it is easily seen that MAX SNP = APX. This weaker reduction is necessary to allow for reductions from fine-grained optimization problems to coarser (polynomially-bounded) optimization problems (cf. [9]). <p> <ref> [9] </ref> define the notion of a PTAS-preserving reduction under which APX = APX-PB. Using their result in conjunction with the above theorem, it is easily seen that MAX SNP = APX. This weaker reduction is necessary to allow for reductions from fine-grained optimization problems to coarser (polynomially-bounded) optimization problems (cf. [9]). The following is a surprising consequence of Theorem 1. Theorem 2 MAX NP = MAX SNP. Papadimitriou and Yannakakis [23] (implicitly) introduced both these closure classes but did not conjecture them to be the same.
Reference: [10] <author> R. Fagin. </author> <title> Generalized First-Order Spectra and Polynomial-time Recognizable Sets. </title> <editor> In Richard Karp (ed.), </editor> <title> Complexity of Computer Computations, </title> <publisher> AMS, </publisher> <year> 1974. </year>
Reference-contexts: The second family of classes of NPO problems that have been studied are those defined via syntactic considerations, based on a syntactic characterization of NP due to Fagin <ref> [10] </ref>. Research in this direction, initiated by Papadimitriou and Yannakakis [23], and followed by Panconesi and Ranjan [22] and Kolaitis and Thakur [20], has led to the identification of approximation classes such as MAX SNP, RMAX (2), and MIN F + 2 (1).
Reference: [11] <author> U. Feige, S. Goldwasser, L. Lov asz, S. Safra, and M. Szegedy. </author> <title> Approximating clique is almost NP-complete. </title> <booktitle> In Proceedings of the 32nd Annual IEEE Symposium on Foundations of Computer Science (1991), </booktitle> <pages> pp. 2-12. </pages>
Reference-contexts: Theorem 6 a) RMAX (2) = poly-APX. b) If SET COVER is canonically hard to approximate to within a factor of (log n), then log-APX = MIN F + 2 (1). We briefly sketch the proof of this theorem. The hardness reduction for MAX SAT and CLIQUE are canonical <ref> [2, 11] </ref>. The classes APX-PB, poly-APX, log-APX are expressible as classes F -APX for downward closed function families. The problems MAX SAT, MAX CLIQUE and SET COVER are additive. Thus, we can now apply Theorem 5.
Reference: [12] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference: [13] <author> Michel X. Goemans and David P. Williamson. </author> <title> :878-Approximation Algorithms for MAX CUT and MAX 2SAT. </title> <booktitle> In Proceedings of the Twenty-Sixth ACM Symposium on Theory of Computing (1994), </booktitle> <pages> pp. 422-431. </pages>
Reference: [14] <author> M. M. Halldorsson and J. Radhakrishnan. </author> <title> Improved Approximations of Independent Sets in Bounded-Degree Graphs. </title> <journal> Nordic Journal of Computing, v. </journal> <volume> 1, </volume> <pages> pp. 475-492, </pages> <year> 1994. </year>
Reference-contexts: Berman and Furer [6] have given an algorithm with performance ratio ( + 3)=5 + * when is even, and ( + 3:25)=5 + * for odd , where * &gt; 0 is a fixed constant. Halldorsson and Radhakrishnan <ref> [14] </ref> have shown that algorithm A 1 when run on k-clique free graphs, yields an independent set of size at least 2n=( + k). They combine this algorithm with a clique-removal based scheme to achieve a performance ratio of =6 (1 + o (1)).
Reference: [15] <author> Dorit S. Hochbaum. </author> <title> Efficient bounds for the stable set, vertex cover, and set packing problems. </title> <journal> Discrete Applied Mathematics, </journal> <volume> vol. 6 (1982), </volume> <pages> pp. 243-254. </pages>
Reference-contexts: Thus we must have jI X j jI Xj + 2 (jOj jIj) : Rearranging, we get jIj + 1 jXj ( 1) ; which yields the desired result. This nearly matches the approximation ratio of =2 due to Hochbaum <ref> [15] </ref>. It should be noted that the above result holds for a broader class of graphs, viz., k-claw free graphs. <p> This improves upon the long-standing approximation ratio of =2 due to Hochbaum <ref> [15] </ref>, when 10. However, very recently, there has been a flurry of new results for this problem.
Reference: [16] <author> Viggo Kann. </author> <title> On the Approximability of NP-complete Optimization Problems. </title> <type> Ph.D. Thesis, </type> <institution> Department of Numerical Analysis and Computing Science. Royal Institute of Technology, </institution> <address> Stockholm, Sweden (1992). </address>
Reference: [17] <author> D. Karger, R. Motwani and G.D.S. Ramkumar. </author> <title> On approximating the longest path in a graph. </title> <booktitle> In Proceedings of the Third Workshop on Algorithms and Data Structures (1993), </booktitle> <pages> pp. 421-432. </pages>
Reference-contexts: In particular, this is true for all MAX SNP problems, MAX CLIQUE, CHROMATIC NUMBER, and SET COVER. Two cases where a hardness result does not seem to directly apply to an additive problem is that of LONGEST PATH <ref> [17] </ref> and BIN PACKING. In the former case, the closely related LONGEST S-T PATH problem is easily seen to be additive and the hardness result essentially stems from this problem.
Reference: [18] <author> S. Khanna, R. Motwani, M. Sudan, and U.V. Vazirani. </author> <title> On Syntactic versus Computational Views of Approx-imability. </title> <booktitle> In Proceedings of the 35th Annual IEEE Symposium on Foundations of Computer Science (1994), </booktitle> <pages> pp. 819-830. </pages>
Reference: [19] <author> S. Khanna, R. Motwani, and S. Vishwanathan. </author> <title> Approximating MAX SNP Problems via Semi-Definite Programming. </title> <note> In preparation, </note> <year> 1996. </year>
Reference-contexts: They combine this algorithm with a clique-removal based scheme to achieve a performance ratio of =6 (1 + o (1)). In conclusion, note that Khanna, Motwani and Vishwanathan <ref> [19] </ref> have recently shown that a semi-definite programming technique can be used to obtain a ( log log )=(log )-approximation algorithm for this problem.
Reference: [20] <author> P. G. Kolaitis and M. N. Thakur. </author> <title> Approximation Properties of NP Minimization Classes. </title> <journal> J. Comput. System Sci., </journal> <volume> 50 (1995), </volume> <pages> pp. 391-411. 26 </pages>
Reference-contexts: Research in this direction, initiated by Papadimitriou and Yannakakis [23], and followed by Panconesi and Ranjan [22] and Kolaitis and Thakur <ref> [20] </ref>, has led to the identification of approximation classes such as MAX SNP, RMAX (2), and MIN F + 2 (1). The syntactic prescription in the definition of these classes has proved very useful in the establishment of complete problems. <p> Definition 10 (MIN F + 2 (k) <ref> [20] </ref>) MIN F + 2 (k) is the class of NPO problems expressible as finding a structure S which minimizes the objective function V (I; S) = jf~x : S (~x)gj if 8~x; 9~y; (I; S; ~x; ~y) 0 otherwise where S is a single predicate, (I; S; ~y) is a <p> The results of Kolaitis and Thakur <ref> [20] </ref> can be adapted to show that SET COVER is complete under E-reductions for the class MIN F + 2 (1). 3 MAX SNP Closure and APX-PB In this section, we will establish the following theorem and examine its implications.
Reference: [21] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <journal> J. ACM, </journal> <volume> 41 (1994), </volume> <pages> pp. 960-981. </pages>
Reference: [22] <author> A. Panconesi and D. Ranjan. </author> <title> Quantifiers and Approximation. </title> <booktitle> Theoretical Computer Science, 107 (1993), </booktitle> <pages> pp. 145-163. </pages>
Reference-contexts: The second family of classes of NPO problems that have been studied are those defined via syntactic considerations, based on a syntactic characterization of NP due to Fagin [10]. Research in this direction, initiated by Papadimitriou and Yannakakis [23], and followed by Panconesi and Ranjan <ref> [22] </ref> and Kolaitis and Thakur [20], has led to the identification of approximation classes such as MAX SNP, RMAX (2), and MIN F + 2 (1). The syntactic prescription in the definition of these classes has proved very useful in the establishment of complete problems. <p> For any fixed integer k, MAX k-SAT belongs to the class MAX SNP. The results of Papadimitriou and Yannakakis [23] can be adapted to show that for k 2, MAX k-SAT is complete under E-reductions for the class MAX SNP. Definition 9 (RMAX (k) <ref> [22] </ref>) RMAX (k) is the class of NPO problems expressible as finding a structure S which maximizes the objective function V (I; S) = jf~x j S (~x)gj if 8~y; (I; S; ~y) 0 otherwise where S is a single predicate and (I; S; ~y) is a quantifier-free CNF formula in <p> jf~x j S (~x)gj if 8~y; (I; S; ~y) 0 otherwise where S is a single predicate and (I; S; ~y) is a quantifier-free CNF formula in which S occurs at most k times in each clause and all its occurrences are negative. 5 The results of Panconesi and Ranjan <ref> [22] </ref> can be adapted to show that MAX CLIQUE is complete under E-reductions for the class RMAX (2).
Reference: [23] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> Optimization, Approximation, and Complexity Classes. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> vol. 43 (1991), </volume> <pages> pp. 425-440. </pages>
Reference-contexts: The second family of classes of NPO problems that have been studied are those defined via syntactic considerations, based on a syntactic characterization of NP due to Fagin [10]. Research in this direction, initiated by Papadimitriou and Yannakakis <ref> [23] </ref>, and followed by Panconesi and Ranjan [22] and Kolaitis and Thakur [20], has led to the identification of approximation classes such as MAX SNP, RMAX (2), and MIN F + 2 (1). <p> We explore a different direction by studying the structure of the syntactically defined classes when we look at their closure under approximation-preserving reductions. The idea of looking at the closure of a class is implicit in the work of Papadimitriou and Yannakakis <ref> [23] </ref> who state that: minimization problems will be placed in the classes through L-reductions to maximization problems. <p> The exact nature of the result obtained depends upon the precise notion of an approximation preserving reduction used to define the closure of the class MAX SNP. The strictest notion of such reductions available in the literature are the L-reductions due to Papadimitriou and Yannakakis <ref> [23] </ref>. We work with a slight extension of the reduction, which we call E-reductions. Using such reductions to define the class MAX SNP we show that this equals APX-PB, the class of all polynomially bounded NP optimization problems which are approximable to within constant factors. <p> We then build upon this result to identify an interesting hierarchy of such approximability classes. An interesting side-effect of our results is the positive answer to the question of Papadimitriou and Yannakakis <ref> [23] </ref> about whether MAX NP has any complete problems. The syntactic view seems useful not only in obtaining structural complexity results but also in developing paradigms for designing efficient approximation algorithms. This was demonstrated first by Papadimitriou and Yannakakis [23] who show approximation algorithms for every problem in MAX SNP. <p> is the positive answer to the question of Papadimitriou and Yannakakis <ref> [23] </ref> about whether MAX NP has any complete problems. The syntactic view seems useful not only in obtaining structural complexity results but also in developing paradigms for designing efficient approximation algorithms. This was demonstrated first by Papadimitriou and Yannakakis [23] who show approximation algorithms for every problem in MAX SNP. We further exploit the syntactic nature of MAX SNP to develop another paradigm for designing good approximation algorithms for problems in that class and thereby provide an alternate computational view of it. <p> This reduction, which we call the E-reduction, is essentially the same as the L-reduction of Papadimitriou and Yannakakis <ref> [23] </ref> and differs from it in only one relatively minor aspect. <p> Thus, there is the undesirable situation that a problem with no PTAS has a FPTAS-preserving reduction to a problem 0 with a PTAS. Remark 3 The L-reduction of Papadimitriou and Yannakakis <ref> [23] </ref> enforces the condition that the optima of an instance I of be linearly related to the optima of the instance I 0 of 0 to which it is mapped. <p> More precise versions of these definitions are provided in Section 4. Let us briefly review the definition of some syntactic classes. Definition 8 (MAX SNP and MAX NP <ref> [23] </ref>) MAX SNP is the class of NPO problems expressible as finding the structure S which maximizes the objective function V (I; S) = jf~x j (I; S; ~x)gj ; where I = (U ; P ) denotes the input (consisting of a finite universe U and a finite set of <p> For any fixed integer k, MAX k-SAT belongs to the class MAX SNP. The results of Papadimitriou and Yannakakis <ref> [23] </ref> can be adapted to show that for k 2, MAX k-SAT is complete under E-reductions for the class MAX SNP. <p> This weaker reduction is necessary to allow for reductions from fine-grained optimization problems to coarser (polynomially-bounded) optimization problems (cf. [9]). The following is a surprising consequence of Theorem 1. Theorem 2 MAX NP = MAX SNP. Papadimitriou and Yannakakis <ref> [23] </ref> (implicitly) introduced both these closure classes but did not conjecture them to be the same. It would be interesting to see if this equality can be shown independent of the result of Arora et al [2]. <p> It would be interesting to see if this equality can be shown independent of the result of Arora et al [2]. We also obtain the following resolution to the problem posed by Papadimitriou and Yannakakis <ref> [23] </ref> of finding complete problems for MAX NP. Theorem 3 MAX SAT is complete for MAX NP. The following sub-sections establish that MAX SNP APX-PB. <p> Then, for some constant k, is a MAX k-CSP problem. Moreover, the k-CSP instance corresponding to any instance of this problem can be computed in polynomial time. Proof: The proof of part (b) is implicit in Theorem 1 in <ref> [23] </ref>, and so we concentrate on proving part (a).
Reference: [24] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> The traveling salesman problem with distances one and two. </title> <journal> Mathematics of Operations Research, </journal> <volume> vol. 18 (1993), </volume> <pages> pp. 1-11. </pages>
Reference-contexts: Papadimitriou and Yannakakis <ref> [24] </ref> showed that this problem is hard for MAX SNP. The natural weight function for TSP (1,2), that is, the weight of the tour, can be used to show that a 4-local algorithm yields a 3=2 performance ratio.
Reference: [25] <author> M. Yannakakis. </author> <title> The analysis of local search problems and their heuristics. </title> <booktitle> In Proceedings of the 7th Annual Symposium of Theoretical Aspects of Computer Science (1990), </booktitle> <pages> pp. 298-311. 27 </pages>
Reference-contexts: We refer to this paradigm as non-oblivious local search, and it is a modification of the standard local search technique <ref> [25] </ref>. We show that every MAX SNP problem can be approximated to within constant factors by such algorithms. It turns out that the performance of non-oblivious local search is comparable to that of the best-known approximation algorithms for several interesting and representative problems in MAX SNP.
References-found: 25

