URL: http://www.eecs.umich.edu/Rio/papers/vistagram.ps
Refering-URL: http://www.eecs.umich.edu/Rio/papers.html
Root-URL: http://www.eecs.umich.edu
Abstract: We present a new model for handling messages and state in a distributed application that we call Messages in Local Transactions (MLT). Under this model, messages and data are not lost after crashes, and all sends and receives are performed in local transactions. The model is unique in that it guarantees consistent recovery without the complexity or overhead of other recovery techniques. Applications using MLT do not need to coordinate checkpoints, track causal dependencies, or perform distributed commits. We show that MLT can be implemented using any reliable protocol. Finally, we describe our implementation of Vista-grams, a system based on the MLT model. We show that Vistagrams are just as fast as traditional messages, despite the recoverability they offer. The efficiency of our model and our Vistagrams implementation is enabled by the availability of fast stable storage, such as the reliable memory provided by the Rio file cache. 
Abstract-found: 1
Intro-found: 1
Reference: [Abbott94] <author> M. Abbott, D. Har, L. Herger, M. Kauffmann, K. Mak, J. Murdock, C. Schulz, T. B. Smith, B. Tremaine, D. Yeh, and L. Wong. </author> <title> Durable Memory RS/6000 System Design. </title> <booktitle> In Proceedings of the 1994 International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 414423, </pages> <year> 1994. </year>
Reference-contexts: Rio is geared towards providing safety from software failures (operating system and process crashes), which account for 90% of all failures [Gray91]. Furthermore, Rio can be extended to handle hardware failures by replicating data across multiple memories <ref> [Abbott94, Muller96, Gillett96] </ref>. Our work further assumes that failures in a distributed system will be transient. System crashes, packet loss, and network failures are all assumed to be temporary problems.
Reference: [Birman96] <author> Kenneth P. Birman. </author> <title> Building Secure and Reliable Network Applications. </title> <publisher> Manning Publications, </publisher> <year> 1996. </year>
Reference-contexts: Furthermore, many of the traditional techniques for recovery of distributed applications have not been widely adopted in the field because of performance issues, or because of the limited scope of applications those techniques support <ref> [Birman96] </ref>. The advent of reliable memory and fast transactions have created new options for recovery of distributed systems.
Reference: [Borg89] <author> Anita Borg, Wolfgang Blau, Wolfgang Gra-etsch, Ferdinand Herrman, and Wolfgang Oberle. </author> <title> Fault Tolerance Under UNIX. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(1):1 24, </volume> <month> February </month> <year> 1989. </year>
Reference-contexts: However, taking a coordinated checkpoint involves sending many messages at checkpoint time, and can thus delay normal processing. Message logging schemes, such as sender-based logging [Johnson87], optimistic logging [Strom85], and the logging used in Targon/32 <ref> [Borg89] </ref>, all record messages so they can be used to recompute the state of a distributed computation after a crash. All message logging systems assume the processes to be recovered are deterministic (i.e. given the same sequence of messages as input, they will compute the same result).

Reference: [Chen96] <author> Peter M. Chen, Wee Teck Ng, Subhachan-dra Chandra, Christopher M. Aycock, Gu-rushankar Rajamani, and David Lowell. </author> <title> The Rio File Cache: Surviving Operating System Crashes. </title> <booktitle> In Proceedings of the 1996 International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <pages> pages 7483, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Message sends and receives are grouped atomically with local state changes. Orphan processes are never created. The efficient implementation of systems based on our model depends on the availability of fast stable storage, such as the reliable memory provided by the Rio file cache <ref> [Chen96] </ref>. Such memory can provide the necessary durability for data and messages under our model, without the latency of disk writes. To show that efficient systems based on the MLT model can be built, we have implemented an MLT-based system called Vistagrams. <p> Like most file caches, Rio caches recently used file data in main memory to speed up future accesses <ref> [Chen96] </ref>. Rio seeks to protect this area of memory from its two common modes of failure: power loss and system crashes. While systems can protect against power loss in a straightforward manner (by using a $100 uninterruptible power supply, for example), protecting against software errors is trickier.
Reference: [Elnozahy92] <author> Elmootazbellah N. Elnozahy and Willy Zwaenepoel. Manetho: </author> <title> Transparent Rollback-Recovery with Low Overhead, Limited Rollback, and Fast Output Commit. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-41(5):526531, </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: Manetho extends sender-based logging to be able to survive the failure of arbitrary numbers of processes <ref> [Elnozahy92] </ref>. In optimistic logging, incoming messages and checkpoints are recorded asynchronously on stable storage. Because checkpointing and message logging proceed asynchronously, the system may have to roll back working nodes when some other node fails.
Reference: [Gillett96] <author> R. B. Gillett. </author> <title> Memory Channel Network for PCI. </title> <journal> IEEE Micro, </journal> <volume> 16(1):1218, </volume> <month> February </month> <year> 1996. </year>
Reference-contexts: Rio is geared towards providing safety from software failures (operating system and process crashes), which account for 90% of all failures [Gray91]. Furthermore, Rio can be extended to handle hardware failures by replicating data across multiple memories <ref> [Abbott94, Muller96, Gillett96] </ref>. Our work further assumes that failures in a distributed system will be transient. System crashes, packet loss, and network failures are all assumed to be temporary problems.
Reference: [Gray78] <author> J. N. Gray. </author> <title> Operating Systems: An Advanced Course. </title> <publisher> Springer-Verlag, </publisher> <year> 1978. </year> <booktitle> Notes on Database Operating Systems. </booktitle>
Reference-contexts: If a process fails, its backup process is activated and brought into a consistent state by letting it play through its input queue of messages. Targon/32 relies on specialized interconnect hardware to provide efficient, 3-way, atomic message delivery. Distributed transactions <ref> [Gray78] </ref> are also used to provide recovery for distributed systems. In distributed transactions, the decision to commit a transaction involves coordinating the commit of related transactions on other nodes. Several rounds of messages are needed to ensure that all the processes commit or abort together.
Reference: [Gray91] <author> Jim Gray and Daniel P. </author> <type> Siewiorek. </type> <institution> High-Availability Computer Systems. IEEE Computer, 24(9):3948, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: Our Vistagrams implementation of MLT uses the reliable memory provided by the Rio file cache for its stable storage. Rio is geared towards providing safety from software failures (operating system and process crashes), which account for 90% of all failures <ref> [Gray91] </ref>. Furthermore, Rio can be extended to handle hardware failures by replicating data across multiple memories [Abbott94, Muller96, Gillett96]. Our work further assumes that failures in a distributed system will be transient. System crashes, packet loss, and network failures are all assumed to be temporary problems.
Reference: [Johnson87] <author> David B. Johnson and Willy Zwaenepoel. </author> <title> Sender-Based Message Logging. </title> <booktitle> In Proceedings of the 1987 International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 1419, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: However, taking a coordinated checkpoint involves sending many messages at checkpoint time, and can thus delay normal processing. Message logging schemes, such as sender-based logging <ref> [Johnson87] </ref>, optimistic logging [Strom85], and the logging used in Targon/32 [Borg89], all record messages so they can be used to recompute the state of a distributed computation after a crash.
Reference: [Koo87] <author> R. Koo and S. Toueg. </author> <title> Checkpointing and Rollback-Recovery for Distributed Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(1):2331, </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: This problem could conceivably result in uncontrolled rollback of the distributed computation to some initial state, a scenario called the domino effect [Strom85]. 2.1. Existing recovery techniques Researchers have developed several techniques to help distributed computations recover to consistent states while avoiding the domino effect. In coordinated checkpointing <ref> [Chandy85, Koo87] </ref>, processes in a distributed system employ a protocol to synchronize the action of taking local checkpoints. The synchronization ensures that the point in the global computation preserved by the local checkpoints represents a consistent state in the computation.
Reference: [Lamport78] <author> Leslie Lamport. </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 21(7):558 565, </volume> <month> July </month> <year> 1978. </year>
Reference-contexts: The distributed computation would be in an inconsistent state because process B has received a message that process A does not remember it sent <ref> [Lamport78] </ref>. In this situation process B is said to be an orphan. The result of this inconsistency is that both processes could think they hold the lock.
Reference: [Lampson93] <author> Butler W. Lampson. </author> <title> Reliable Messages and Connection Establishment. </title> <booktitle> Addison-Wes-ley, 1993. in Distributed Systems, edited by Sape Mullender. </booktitle>
Reference-contexts: Exactly-once delivery guarantees that a sent message will be delivered exactly one time by the receiving process. Providing such a semantic efficiently has been acknowledged widely to be difficult, because system crashes can cause processes to forget which messages have already been delivered <ref> [Lampson93] </ref>. 5.1. Vistagrams implementation To show the structure of our Vistagrams implementation we will follow a request message from the client to the server and back.
Reference: [Lowell97] <author> David E. Lowell and Peter M. Chen. </author> <title> Free Transactions with Rio Vista. </title> <booktitle> In Proceedings of the 1997 Symposium on Operating Systems Principles, </booktitle> <pages> pages 92101, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: To show that efficient systems based on the MLT model can be built, we have implemented an MLT-based system called Vistagrams. Vistagrams is an extension to our lightweight transaction system Vista <ref> [Lowell97] </ref>. Vista-grams imposes no overhead for the reliability it offers, thanks to the reliable memory provided by the Rio file cache. 2. Background and Related Work The trick in restoring the state of a distributed computation after a crash is making sure that the state restored is meaningful. <p> Chen et al. verified experimentally that the Rio file cache was as safe as a disk from operating system crashes. Vista builds on the persistent memory Rio provides. Vista lets applications allocate chunks of persistent memory and perform atomic and durable transactions on that memory <ref> [Lowell97] </ref>. Vista provides atomicity by logging to persistent memory (provided by Rio) rather than to disk, and as a result Vistas transactions are extremely fast: small transactions can complete in under two microseconds.
Reference: [Muller96] <author> Gilles Muller, Michel Banatre, Nadine Pey-rouze, and Bruno Rochat. </author> <title> Lessons from FTM: An Experiment in Design and Implementation of a Low-Cost Fault-Tolerant System. </title> <journal> IEEE Transactions on Reliability, </journal> <volume> 45(2):332340, </volume> <month> June </month> <year> 1996. </year>
Reference-contexts: Rio is geared towards providing safety from software failures (operating system and process crashes), which account for 90% of all failures [Gray91]. Furthermore, Rio can be extended to handle hardware failures by replicating data across multiple memories <ref> [Abbott94, Muller96, Gillett96] </ref>. Our work further assumes that failures in a distributed system will be transient. System crashes, packet loss, and network failures are all assumed to be temporary problems.
Reference: [Schneider84] <author> Fred B. Schneider. </author> <title> Byzantine Generals in Action: Implementing Fail-Stop Processors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(2):145154, </volume> <month> May </month> <year> 1984. </year>
Reference-contexts: Failure model Our MLT model and Vistagrams implementation of the model are designed to handle a specific class of failures. Like most distributed systems, we assume processes follow the fail-stop model <ref> [Schneider84] </ref>. Specifically, we assume that processes do not commit transactions containing faulty memory stores or message sends. As the reader will see in Section 3, our model writes to stable storage. Correspondingly, its reliability is as good as the stable storage employed.
Reference: [Soparkar90] <author> N. Soparkar and A. Silberschatz. </author> <title> Data-Value Partitioning and Virtual Messages. </title> <booktitle> In Proceedings of the 1990 ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 357364, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Once that transaction commits, all the operations in 1. Aspects of this model were proposed by Soparkar et al. as a construct for databases <ref> [Soparkar90] </ref>. They were not able to explore the implications fully because they lacked fast stable storage. that transaction are permanent and will not be lost if the sys-tem crashes.
Reference: [Strom85] <author> Robert E. Strom and Shaula Yemini. </author> <title> Optimistic Recovery in Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3):204226, </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: But rolling back A could force B to roll back further still. This problem could conceivably result in uncontrolled rollback of the distributed computation to some initial state, a scenario called the domino effect <ref> [Strom85] </ref>. 2.1. Existing recovery techniques Researchers have developed several techniques to help distributed computations recover to consistent states while avoiding the domino effect. In coordinated checkpointing [Chandy85, Koo87], processes in a distributed system employ a protocol to synchronize the action of taking local checkpoints. <p> However, taking a coordinated checkpoint involves sending many messages at checkpoint time, and can thus delay normal processing. Message logging schemes, such as sender-based logging [Johnson87], optimistic logging <ref> [Strom85] </ref>, and the logging used in Targon/32 [Borg89], all record messages so they can be used to recompute the state of a distributed computation after a crash.
References-found: 17

