URL: http://www.isle.org/~langley/papers/sense.aa97.ps
Refering-URL: http://www-csli.stanford.edu/cll/research.html
Root-URL: 
Email: (Langley@cs.stanford.edu)  
Title: Learning to Sense Selectively in Physical Domains  
Author: Pat Langley 
Address: (1997). Marina del Rey, CA:  Stanford, CA 94305  
Affiliation: Agents  Robotics Laboratory, Computer Science Dept. Stanford University,  
Note: To appear in Proceedings of the First International Conference on Autonomous  ACM.  
Abstract: In this paper we describe an approach to representing, using, and improving sensory skills for physical domains. We present Icarus, an architecture that represents control knowledge in terms of durative states and sequences of such states. The system operates in cycles, activating a state that matches the environmental situation and letting that state control behavior until its conditions fail or until finding another matching state with higher priority. Information about the probability that conditions will remain satisfied minimizes demands on sensing, as does knowledge about the durations of states and their likely successors. Three statistical learning methods let the system gradually reduce sensory load as it gains experience in a domain. We report experimental evaluations of this ability on three simulated physical tasks: flying an aircraft, steering a truck, and balancing a pole. Our experiments include lesion studies that identify the reduction in sensing due to each of the learning mechanisms and others that examine the effect of domain characteristics. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abramson, B. </author> <year> (1991). </year> <title> An analysis of error recovery and sensory integration for dynamic planners. </title> <booktitle> Proceedings of the Twelfth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 744-749). </pages> <address> Anaheim, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Anderson, C. W. </author> <year> (1989). </year> <title> Learning to control an inverted pendulum. </title> <journal> IEEE Control Systems Magazine, </journal> <pages> it 9 , 31-37. </pages>
Reference: <author> Anderson, C. W., & Miller, W. T. </author> <year> (1991). </year> <title> Challenging control problems. </title> <editor> In W. T. Miller, R. S. Sutton, & P. J. Werbos (Eds.), </editor> <title> Neural networks for control . Cambridge, </title> <address> MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Anderson, J. R. </author> <year> (1983). </year> <title> The architecture of cognition. </title> <publisher> Cambridge: Harvard University Press. </publisher>
Reference: <author> Benson, S. </author> <year> (1995). </year> <title> Inductive learning of reactive action models. </title> <booktitle> Proceedings of the Twelfth International Conference on Machine Learning (pp. </booktitle> <pages> 47-54). </pages> <address> Lake Tahoe, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Chrisman, L., & Simmons, R. </author> <year> (1991). </year> <title> Sensible planning: Focusing perceptual attention. </title> <booktitle> Proceeding of the Ninth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 756-761). </pages> <address> Anaheim, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> DeJong, G. F. </author> <year> (1994). </year> <title> Learning to plan in continuous domains. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 64 , 71-141. </pages>
Reference: <author> Fikes, R. E., Hart, P. E., & Nilsson, N. J. </author> <year> (1971). </year> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 2 , 189-208. </pages>
Reference-contexts: Icarus neither allows self transitions nor requires them, since it models state durations directly. Icarus' state representation has much in common with Strips operators <ref> (Fikes, Hart, & Nilsson, 1971) </ref> in that they specify application conditions, actions, and effects; they also bear a close kinship to production rules (e.g., Anderson, 1983; Langley, 1987). However, recall that, in our framework, both actions and effects are optional.
Reference: <author> Forbus, K. D. </author> <year> (1985). </year> <title> Qualitative process theory. </title> <editor> In D. G. Bobrow (Ed.), </editor> <title> Qualitative reasoning about physical systems. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Goettl, B. P. </author> <year> (1993). </year> <title> Analysis of skill on a flight simulator: Implications for training. </title> <type> Unpublished manuscript, </type> <institution> Armstrong Laboratory, Brooks Air Force Base, Texas. </institution>
Reference: <author> Grefenstette, J. J., Ramsey, C. L., & Schultz, A. C. </author> <year> (1990). </year> <title> Learning sequential decision rules using simulation models and competition. </title> <booktitle> Machine Learning, </booktitle> <pages> 5 , 355-381. </pages>
Reference: <author> Hansen, E. A. </author> <year> (1994). </year> <title> Cost-effective sensing during plan execution. </title> <booktitle> Proceedings of the Twelfth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 1029-1035). </pages> <address> Seattle, WA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Hansen, E. A., & Cohen, P. R. </author> <year> (1993). </year> <title> Learning monitoring strategies to compensate for model uncertainty. </title> <booktitle> Working Notes of the AAAI-93 Workshop on Learning Action Models (pp. </booktitle> <pages> 33-35). </pages> <address> Washing-ton, D.C.: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Kaelbling, L. P. </author> <year> (1993). </year> <title> Hierarchical learning in stochastic domains: Preliminary results. </title> <booktitle> Proceedings of the Tenth International Conference on Machine Learning (pp. </booktitle> <pages> 167-173). </pages> <address> Amherst, MA. </address>
Reference: <author> Kinny, D., Georgeff, M., & Hendler, J. </author> <year> (1992). </year> <title> Experiments in optimal sensing for situated agents. </title> <booktitle> Proceedings of the Second Pacific Rim International Conference on Artificial Intelligence. </booktitle> <address> Seoul,Korea. </address>
Reference: <author> Kuipers, B. </author> <year> (1985). </year> <title> Commonsense reasoning about causality: Deriving behavior from structure. </title> <editor> In D. G. Bobrow (Ed.), </editor> <title> Qualitative reasoning about physical systems. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Laird, J. E., & Rosenbloom, P. S. </author> <year> (1990). </year> <title> Integrating execution, planning, and learning in Soar for external environments. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 1022-1029). </pages> <address> Boston: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Langley, P. </author> <year> (1987). </year> <title> A general theory of discrimination learning. </title> <editor> In D. Klahr, P. Langley, & R. Neches (Eds.), </editor> <title> Production system models of learning and development. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Langley, P., Iba, W., & Shrager, J. </author> <year> (1994). </year> <title> Reactive and automatic behavior in plan execution. </title> <booktitle> Proceedings of the Second International Conference on AI Planning Systems (pp. </booktitle> <pages> 299-304). </pages> <address> Chicago: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Minton, S. N. </author> <year> (1990). </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 42 , 363-391. </pages>
Reference-contexts: Here we assume that matching contributes little cost once the sensing process is complete, so that reduction in sensor load corresponds to potential increase in speed; this view contrasts with most work on `speedup' learning <ref> (e.g., Minton, 1990) </ref>, which emphasizes reduction in matching and search costs. For each domain, we provided Icarus with the control states mentioned earlier and ran the system a number of times.
Reference: <author> Nilsson, N. J. </author> <year> (1994). </year> <title> Teleoreactive programs for agent control. </title> <journal> Journal of Artificial Intelligence Research, </journal> <pages> 1 , 139-158. </pages>
Reference: <author> Nordhausen, B., & Langley, P. </author> <year> (1993). </year> <title> An integrated framework for empirical discovery. </title> <booktitle> Machine Learning, </booktitle> <pages> 12 , 17-47. </pages>
Reference: <author> Nguyen, D., & Widrow, B. </author> <year> (1989). </year> <title> The truck backer-upper: An example of self-learning in neural networks. </title> <booktitle> Proceedings of the International Joint Conference on Neural Networks. </booktitle> <address> Washington. </address>
Reference: <author> Sammut, C., Hurst, S., Kedzier, D., & Michie, D. </author> <year> (1992). </year> <title> Learning to fly. </title> <booktitle> Proceedings of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 385-393). </pages> <address> Aberdeen, Scotland: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Selfridge, O. G., Sutton, R. S., & Barto, A. G. </author> <year> (1985). </year> <booktitle> Proceedings of the Ninth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 670-672). </pages> <address> Los Angeles: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tan, M. </author> <year> (1991). </year> <title> Cost-sensitive robot learning. </title> <type> Doctoral dissertation, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Watkins, C. J. C. H. </author> <year> (1989). </year> <title> Learning from delayed rewards. </title> <type> Doctoral dissertation, </type> <institution> Department of Psychology, Cambridge University, </institution> <address> Cambridge, UK. </address>
References-found: 27

