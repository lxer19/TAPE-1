URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-391.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: pinhanez@media.mit.edu  mase@mic.atr.co.jp  bobick@media.mit.edu  
Title: Interval Scripts: a Design Paradigm for Story-Based Interactive Systems  
Author: Claudio S. Pinhanez Kenji Mase Aaron Bobick 
Affiliation: MIT Media Laboratory  ATR-MIC Research Lab.  MIT Media Laboratory  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 391 Submitted to CHI'97 | October 1996 Abstract A system to manage human interaction in im-mersive environments was designed and implemented. The interaction is defined by an interval script which describes the relationships between the time intervals which command actuators or gather information from sensors. With this formalism, reactive, linear, and tree-like interaction can be equally described, as well as less regular story and interaction patterns. Control of actuators and sensors is accomplished using PNF-restriction, a calculus which propagates the sensed information through the interval script, determining which intervals are or should be happening at each moment. The prototype was used in an immersive, story-based interactive environment called SingSong, where a user or a performer tries to conduct four computer character singers, in spite of the hostility of one of them.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James F. Allen. </author> <title> Towards a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 123-154, </pages> <year> 1984. </year>
Reference-contexts: No explicit time references are needed, for either duration, start, or finish of an interval. Examples of inter val scripts are provided later in this paper. 1 between 2 intervals <ref> [1] </ref>. 3.1 Allen's Interval Algebra To model the time relationships between two intervals we employ the interval algebra proposed by Allen [1]. The interval algebra is based on the 13 possible primitive relationships between two intervals which are summarized in fig. 1. <p> Examples of inter val scripts are provided later in this paper. 1 between 2 intervals <ref> [1] </ref>. 3.1 Allen's Interval Algebra To model the time relationships between two intervals we employ the interval algebra proposed by Allen [1]. The interval algebra is based on the 13 possible primitive relationships between two intervals which are summarized in fig. 1. In any actual situation, two intervals relate to each other exactly as described by one of the possible primitive time relationships. <p> For instance, if interval A is BEFORE B, and B is BEFORE C, Allen's representation enables the inference that A is BEFORE C. In fact, <ref> [1] </ref> provides an algorithm, later revised by [9], which propagates the time relations through a collection of intervals, determining the most constrained disjunction of relationships for each pair of intervals which satisfies the given relationships and is consistent in time.
Reference: [2] <author> Masaaki Fukumoto, Kenji Mase, and Yasuhito Sue-naga. Finger-pointer: </author> <title> Pointing interface by image processing. </title> <journal> Comput. & Graphics., </journal> <volume> 18(5) </volume> <pages> 633-642, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The outputs of those routines are mapped back into PNF-states of appropriate intervals, completing the cycle. Sensors In interactive environments, sensors can play the roles of chooser, locator, valuator, etc. (see <ref> [2] </ref>). We have analyzed and implemented only the binary case of a chooser sensor, that is, a sensor which detects whether something is happening or not.
Reference: [3] <author> Tinsley A. Galyean. </author> <title> Narrative Guidance of Interac-tivity. </title> <type> PhD thesis, </type> <institution> M.I.T. Media Arts and Sciences Program, </institution> <year> 1995. </year>
Reference-contexts: These environments can be either experienced directly by the user, as in the interactive cinema concept proposed by Tosa and Nakatsu ([8]); or employed in a computer theater performance, as described by Pinhanez [5]. With only a few exceptions (for example, <ref> [3] </ref>), immersive interactive environments have been exploratory, i.e., the user's basic objective is to navigate through an artificial world, discovering its interesting features and/or meeting with virtual creatures. We believe that immersive systems can be significantly enriched by incorporating dramatic structure from stories. <p> In reactive systems, the story (if it exists at all) unfolds as a result of the firing of behaviors as a response to the user's actions (for example, [4, 7]). In tree-like scripts, the user typically chooses between different paths in the story through some selective action (for example, <ref> [3] </ref>). Those scripting methods are not good for describing and managing the complex interactivity we are planning for our future immersive environments. It is hard to express progression of time in creatures controlled by reactive systems, and handling parallel events in a tree-like, multiple choice script is cumbersome.
Reference: [4] <author> Pattie Maes, Trevor Darrell, Bruce Blumberg, and Alex Pentland. </author> <title> The ALIVE system: Full-body interaction with autonomous agents. </title> <booktitle> In Proc. of the Computer Animation '95 Conference, </booktitle> <address> Geneva, Switzer-land, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Most story-based environments till now have relied on scripts which are either reactive or shaped in a tree-like structure. In reactive systems, the story (if it exists at all) unfolds as a result of the firing of behaviors as a response to the user's actions (for example, <ref> [4, 7] </ref>). In tree-like scripts, the user typically chooses between different paths in the story through some selective action (for example, [3]). Those scripting methods are not good for describing and managing the complex interactivity we are planning for our future immersive environments.
Reference: [5] <author> Claudio S. Pinhanez. </author> <title> Computer theater. </title> <type> Technical Report 378, </type> <institution> M.I.T. Media Laboratory Perceptual Computing Section, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: These environments can be either experienced directly by the user, as in the interactive cinema concept proposed by Tosa and Nakatsu ([8]); or employed in a computer theater performance, as described by Pinhanez <ref> [5] </ref>. With only a few exceptions (for example, [3]), immersive interactive environments have been exploratory, i.e., the user's basic objective is to navigate through an artificial world, discovering its interesting features and/or meeting with virtual creatures. <p> SingSong was designed to be enjoyed both as an user experience and as a computer theater performance. In the later case, as described by Pinhanez in <ref> [5] </ref>, our system provides computer-generated partners to the human performer which are not only reactive, but are also able to follow the script. 4 The transition between the performance and the user mode is seamless, enabling the user to experience the story as lived by the performer. <p> These are precisely the kind of effects we should expect in story-based environments, in opposition to "exploring the world" immersive systems. SingSong in the performance mode constitutes a typical experiment in computer theater, as defined in <ref> [5] </ref>. The choice of a clown costume, complete with red nose, produces an interesting effect: a more harmonious blending of real and the CG world.
Reference: [6] <author> Claudio S. Pinhanez and Aaron F. Bobick. </author> <title> PNF Calculus: Representing and propagating time constrains in Allen's interval algebra. </title> <type> Technical Report 389, </type> <institution> M.I.T. Media Laboratory Perceptual Computing Section, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: To use the relations between intervals in a system to manage real-time interaction we employ the PNF calculus developed by Pinhanez and Bobick <ref> [6] </ref> which defines a method for propagating occurrence information through a network of intervals. <p> PNF (PAST or NOW or FUT) stands for the situation where no information about the interval is presently known. The PNF-restriction algorithm developed by Pinhanez and Bobick <ref> [6] </ref> enables the propagation of known PNF-states of some intervals through a network of intervals. Typically in the cases described in this paper the current PNF-state 2 PNF-restriction algorithm. <p> In the second case, if A BEFORE B, the information that A is PAST is virtually useless, since B may have already happened (PAST) or be happening (NOW) or be in the future (FUT) characterizing a PNF state. In <ref> [6] </ref>, Pinhanez and Bobick also discuss the idea of time expanding a PNF-state. Basically, given the PNF-state of an interval, the time expansion of the interval is the PNF-state corresponding to possible states of that interval in the next instant of time. <p> If an interval is NOW, in the next instant it may be NOW or PAST, or PN; if it is PAST, it remains in PAST; if it is FUT it goes to NF. A comprehensive description of the PNF-restriction algorithm can be found in <ref> [6] </ref>, together with some theorems about its computational complexity and completeness. 4.2 Connecting to the Real World According to our proposal of interval scripts, the interaction of a system is described by intervals of time and their relationships. Some intervals are connected to sensors and some are connected to actuators.
Reference: [7] <author> Naoko Tosa, Hideki Hashimoto, Kaoru Sezaki, Ya-suharu Kunii, Toyotoshi Yamada, Kotaro Sabe, Ryosuke Nishino, Hiroshi Harashima, and Fumio Ha-rashima. </author> <title> Network-based neuro-baby with robotic hand. </title> <booktitle> In Proc. of IJCAI'95 Workshop on Entertainment and AI/Alife, </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Most story-based environments till now have relied on scripts which are either reactive or shaped in a tree-like structure. In reactive systems, the story (if it exists at all) unfolds as a result of the firing of behaviors as a response to the user's actions (for example, <ref> [4, 7] </ref>). In tree-like scripts, the user typically chooses between different paths in the story through some selective action (for example, [3]). Those scripting methods are not good for describing and managing the complex interactivity we are planning for our future immersive environments.
Reference: [8] <author> Naoko Tosa and Ryohei Nakatsu. </author> <title> For interactive virtual drama: Body communication actor. </title> <booktitle> In Proc. of 7th International Symposium on Electronic Art, </booktitle> <address> Rot-terdam, The Netherlands, </address> <month> September </month> <year> 1996. </year>
Reference: [9] <author> Marc Vilain, Henry Kautz, and Peter van Beek. </author> <title> Constraint propagation algorithms for temporal reasoning: A revised report. </title> <editor> In Daniel S. Weld and Johan de Kleer, editors, </editor> <booktitle> Readings in Qualitative Reasoning About Physical Systems, </booktitle> <pages> pages 373-381. </pages> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: For instance, if interval A is BEFORE B, and B is BEFORE C, Allen's representation enables the inference that A is BEFORE C. In fact, [1] provides an algorithm, later revised by <ref> [9] </ref>, which propagates the time relations through a collection of intervals, determining the most constrained disjunction of relationships for each pair of intervals which satisfies the given relationships and is consistent in time. There are many reasons to use Allen's algebra to describe relationships between intervals.
Reference: [10] <author> Christopher R. Wren, Ali Azarbayejani, Trevor Dar-rell, and Alex Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <type> Technical Report 353, </type> <institution> M.I.T. Media Laboratory Perceptual Computing Section, </institution> <year> 1995. </year> <month> 8 </month>
References-found: 10

