URL: http://www.cs.cmu.edu/%7etakeuchi/cvpr98/paper.ps.gz
Refering-URL: http://www.cs.cmu.edu/%7etakeuchi/landmarks.html
Root-URL: 
Abstract: Recognizing landmarks is a critical task for mobile robots. Landmarks are used for robot positioning, and for building maps of unknown environments. In this context, the traditional recognition techniques based on strong geometric models cannot be used. Rather, models of landmarks must be built from observations using image-based techniques. This paper addresses the issue of building image-based landmark descriptions from sequences of images and of recognizing those landmarks. Beyond its application to mobile robot navigation, this approach addresses the more general problem of identifying groups of images with common attributes in sequences of images. We show that, with the appropriate domain constraints and image descriptions, this can be done using efficient algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bach et al. </author> <title> The Virage Image Search Engine:An Open Framework for Image Management. </title> <booktitle> SPIE Proc. Image Storage and Retrieval. </booktitle> <year> 1996. </year>
Reference: [2] <author> S. Carlsson. </author> <title> Combinatorial Geometry for Shape Indexing. </title> <booktitle> Proc. Workshop on Object Representation for Comp.Vision. </booktitle> <address> Cambridge. </address> <year> 1996. </year>
Reference: [3] <author> F. Cozman. </author> <title> Position Estimation from Outdoor visual landmarks. </title> <booktitle> Proc. </booktitle> <address> WACV96. </address> <year> 1996. </year>
Reference-contexts: More general algorithms based on feature matching could be used if this assumption were not valid. This approach is similar to other registration algorithms based on skyline matching (see <ref> [3] </ref> for a review.) The initial estimate of H is built by placing a,b,c in the first row of the matrix. H is then refined by comparing the images directly.
Reference: [4] <author> P. Gros, O. Bournez and E. Boyer. </author> <title> Using Local Planar Geometric Invariants to Match and Model Images of Line Segments. </title> <note> To appear in Int. </note> <editor> J. </editor> <booktitle> of Comp. Vision and Image Underst. </booktitle>
Reference-contexts: The information most relevant to recognition is extracted from the collection of raw images and used as the model for recognition. Progress has been made recently in developing such approaches. For example, in object modeling <ref> [4] </ref>, 2D or 3D models of objects are built for recognition applications. Extensions to generic object recognition were reported [5]. Other approaches use the images directly to extract a small set of characteristic images of the objects; these images are compared with observed views at recognition time, e..g, eigen-images techniques.
Reference: [5] <author> R. Horaud, T. Skordas and F. Veillon. </author> <title> Finding Geometric and Relational Structures in An Image Proc. </title> <booktitle> of the 1st ECCV. Antibes, </booktitle> <address> France pages 374--384, </address> <month> April </month> <year> 1990 </year>
Reference-contexts: Progress has been made recently in developing such approaches. For example, in object modeling [4], 2D or 3D models of objects are built for recognition applications. Extensions to generic object recognition were reported <ref> [5] </ref>. Other approaches use the images directly to extract a small set of characteristic images of the objects; these images are compared with observed views at recognition time, e..g, eigen-images techniques.
Reference: [6] <author> B.Lamiroy and P.Gros. </author> <title> Rapid Object Indexing and Recognition Using Enhanced Geometric Hashing. </title> <booktitle> Proc. of the 5th ECCV, </booktitle> <address> Cambridge, England, </address> <booktitle> pages 59--70, </booktitle> <volume> vol. 1, </volume> <month> April </month> <year> 1996. </year>
Reference: [7] <author> R.W. </author> <title> Picard. A Society of Models for Video and Image Libraries. </title> <journal> IBM Systems Journal, </journal> <volume> 35(3-4):292-312. </volume> <year> 1996. </year>
Reference: [8] <author> D.A. Pomerleau. </author> <title> Neural network-based vision processing for autonomous robot guidance. </title> <booktitle> Proc. Appl. of Neural Networks II. </booktitle> <year> 1991. </year>
Reference-contexts: For the remaining pixels, the normalized red value is used in order to minimize the effect of shadows. This is similar to the approach taken in <ref> [8] </ref> for shadow reduction in outdoor imagery. In the remainder of the paper, the term color refers to the single normalized red value computed at points of high enough saturation. The color values are resampled by using a standard equal-size equalization.
Reference: [9] <author> Y. Rubner, L. Guibas, C. Tomasi. </author> <title> The Earth Movers Distance, Multi-Dimensional Scaling, </title> <booktitle> and Color-Based Image Retrieval. Proc. IU Workshop. </booktitle> <year> 1997. </year>
Reference-contexts: Because of the potentially large differences in viewpoint and illumination, color distribution cannot be directly compared in image space. Metrics have been proposed for comparing color histograms which can tolerate substantial variation in color distribution <ref> [9] </ref>. The approach chosen here uses a transition matrix rather than a direct histogram to represent the color distribution. Specifically, a color transition matrix Cij is created in which Cij is the number of pixels with value i and with at least one neighbor with value j.
Reference: [10] <author> C. Schmid and R. Mohr. </author> <title> Combining Greyvalue Invariants with Local Constraints for Object Recognition. </title> <booktitle> Proc. </booktitle> <address> CVPR. San Francisco, California, USA. pages 872--877, </address> <month> June </month> <year> 1996. </year>
Reference: [11] <author> M.J. Swain, D.H. Ballard. </author> <title> Color Indexing. </title> <journal> Int. J. of Comp.Vision, </journal> <volume> 7(1) </volume> <year> 11-32.1991. </year>
Reference-contexts: Experimental data on training and test sequences from an urban area are presented throughout the paper. 2 Representing Images Two standard classes of attributes are used for describing the images: color and edge distributions. As was demonstrated in image retrieval work, color distribution can be a powerful attribute <ref> [11] </ref>.
References-found: 11

