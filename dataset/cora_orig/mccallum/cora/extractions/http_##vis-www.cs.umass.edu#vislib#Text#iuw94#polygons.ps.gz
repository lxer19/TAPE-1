URL: http://vis-www.cs.umass.edu/vislib/Text/iuw94/polygons.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/vislib/Text/iuw94/files.html
Root-URL: 
Email: Email: @cs.umass.edu  
Title: Task Driven Perceptual Organization for Extraction of Rooftop Polygons building rooftop hypotheses. Virtual features are
Author: Christopher Jaynes Frank Stolle Robert Collins 
Note: Cycles in the graph correspond to possible  
Address: Amherst, MA 01003  
Affiliation: Computer Science Department University of Massachusetts  
Abstract: Orthogonal corners and lines are extracted and hierarchically related using perceptual grouping techniques. Top-down feature verification is used so that features, and links between the features, are verified with local information in the image and weighed in a graph structure according to the underlying support for each feature. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Boldt, R. Weiss, and E. </author> <title> Rise-man. </title> <journal> "Token-Based Extraction of Straight Lines" IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> Volume 19, No. 6, pp.1581-1594, </volume> <year> 1989. </year>
Reference-contexts: The low level features that are originally extracted are used to form collated features. 3.1 Straight Lines Straight lines are extracted using two different methods. The primary, bottom-up method for extracting low level straight line features is the Boldt algorithm <ref> [1] </ref>. This algorithm hierarchically groups edgels into progressively longer line segments based on proximity and collinearity constraints. Figure 2 shows the Boldt lines extracted from a typical aerial urban scene (a portion of the RADIUS model board image J1). <p> Boldt lines are assigned a certainty measure that is calculated during their extraction. The line certainty depends primarily on the contrast of the edge and on the least-squares residual error of the line fit to the grouped edges. For a detailed description of Boldt line certainty, see <ref> [1] </ref>. Another line detection scheme is used for top-down grouping verification. These local lines are extracted when possible groupings between features are being considered. This approach focuses the power of perceptual grouping to a predictive task and avoids reliance on single, globally extracted features.
Reference: [2] <author> R. Collins, A. Hanson, E. Riseman, and Y. Cheng. </author> <title> "Model Matching and Extension for Automated 3D Site Modeling." </title> <booktitle> Proc. DARPA Image Understanding Workshop, </booktitle> <year> 1992. </year>
Reference-contexts: The system is expected to perform similarly on other aerial images and is currently being tested on a wide variety of aerial photos [3]. Currently, polygon detection is a piece of the larger aerial image understanding system being developed at UMass under the RADIUS project <ref> [2, 3] </ref>. In subsequent steps, the hypothesized rooftop polygons are verified and refined through multi-image triangulation which computes a height for each polygon in the world. The final set of polygons are extruded to the ground plane for a final volumetric model of buildings.
Reference: [3] <author> R. Collins, A. Hanson, and E. Riseman. </author> <title> "Site Model Aquisition under the UMass RADIUS Project", </title> <booktitle> Proc. ARPA Image Understanding Workshop, </booktitle> <year> 1994, </year> <note> to appear. </note>
Reference-contexts: Conclusions and Future Work The results from the proposed approach are encouraging. The system is expected to perform similarly on other aerial images and is currently being tested on a wide variety of aerial photos <ref> [3] </ref>. Currently, polygon detection is a piece of the larger aerial image understanding system being developed at UMass under the RADIUS project [2, 3]. In subsequent steps, the hypothesized rooftop polygons are verified and refined through multi-image triangulation which computes a height for each polygon in the world. <p> The system is expected to perform similarly on other aerial images and is currently being tested on a wide variety of aerial photos [3]. Currently, polygon detection is a piece of the larger aerial image understanding system being developed at UMass under the RADIUS project <ref> [2, 3] </ref>. In subsequent steps, the hypothesized rooftop polygons are verified and refined through multi-image triangulation which computes a height for each polygon in the world. The final set of polygons are extruded to the ground plane for a final volumetric model of buildings.
Reference: [4] <author> M. Herman and T. Kanade. </author> <title> "Incremental Reconstruction of 3D Scenes from Multiple, Complex Images," </title> <journal> Artificial Intelligence, </journal> <volume> 30(3) pp.289-341, </volume> <month> Dec. </month> <year> 1986. </year>
Reference: [5] <author> A. Huertas, C. Lin, and R. Nevatia. </author> <title> "Detection of Buildings from Monocular Views Using Perceptual Grouping and Shadows" Proc. </title> <booktitle> DARPA Image Understanding Workshop, </booktitle> <year> 1993. </year>
Reference-contexts: Despite these difficulties, a successful system will discover rooftops that can be used for further image understanding tasks. 2. Task Driven Organization The power of perceptual organization for the extraction of structure in natural scenes is well known <ref> [5, 7] </ref>. In our approach, low level features are perceptually grouped to form collated features which are then used to hypothesize the final groupings. However, in addition to this bottom-up approach, each level of the hierarchy may search for features in a task driven, top-down manner.
Reference: [6] <author> J.C. McGlone and J. Shufelt, </author> <title> "Incorporating Vanishing Point Geometry into a Building Extraction System," </title> <booktitle> ARPA Image Understanding Workshop, </booktitle> <address> Washington DC, pp.437-448, </address> <year> 1993. </year>
Reference-contexts: The relative orientation of the city grid with respect to the camera completely determines how these four cardinal corner types will appear in the image. Currently, we compute this orientation from the given camera pose; however, the city-grid orientation can also be computed more generally using vanishing point analysis <ref> [6] </ref>. Once this orientation information is known, the perspective transformation mapping 3D orthogonal corners into 2D image corners can be determined, and ideal corner masks can be generated to accurately extract these important low level corner features. Four different corner masks are generated.
Reference: [7] <author> R. Mohan and R. Nevatia, </author> <title> "Using Perceptual Organization to Extract 3D Structures" Trans. </title> <journal> Pattern Analysis and Machine Intelligence, </journal> <year> 1989. </year>
Reference-contexts: Despite these difficulties, a successful system will discover rooftops that can be used for further image understanding tasks. 2. Task Driven Organization The power of perceptual organization for the extraction of structure in natural scenes is well known <ref> [5, 7] </ref>. In our approach, low level features are perceptually grouped to form collated features which are then used to hypothesize the final groupings. However, in addition to this bottom-up approach, each level of the hierarchy may search for features in a task driven, top-down manner.
Reference: [8] <author> A. Singh and M. Shneier. </author> <title> "Grey Level Corner Detection: A Generalization and a Robust Real Time Implementation" Computer Vision, Graphics, </title> <booktitle> and Image Processing, </booktitle> <year> 1990. </year>
Reference-contexts: Masks of this small size do well in localizing corners and in detecting non-obvious corners (see Section 6), however they are sensitive to noise. The performance of template-based corner detection in grey level images with respect to detection, localization, and stability is discussed in <ref> [8] </ref>. In our system, we allow a large number of false positives when detecting corners and rely on the higher level grouping processes to discard incorrect low level features. Once constructed, each mask is convolved with the image and the correlation value at each pixel in the image stored.
Reference: [9] <author> V. Venkateswar and R. Chellapa. </author> <title> "Intelligent Interpretation of Aerial Images", </title> <institution> University of Southern California, Dept. of Electrical Engineering Technical Report 137, </institution> <month> March </month> <year> 1989. </year>
References-found: 9

