URL: http://www.cs.berkeley.edu/~carson/papers/pami.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~carson/papers/pami.html
Root-URL: 
Email: Malik  
Title: Color- and Texture-Based Image Segmentation Using EM and Its Application to Image Querying and Classification  
Author: Chad Carson, Serge Belongie, Hayit Greenspan, and Jitendra 
Keyword: Segmentation and grouping, Image retrieval, Image databases, Image querying, Image classification, Expectation-Maximization  
Abstract: Retrieving images from large and varied collections using image content as a key is a challenging and important problem. In this paper we present a new image representation which provides a transformation from the raw pixel data to a small set of image regions which are coherent in color and texture space. This blobworld representation is based on segmentation using the Expectation-Maximization algorithm on combined color and texture features. The texture features we use for the segmentation arise from a new approach to texture description and scale selection. We describe a system that uses the blobworld representation to retrieve natural images. An important and unique aspect of the system is that, in the context of similarity-based querying, the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, the outcome of many queries on these systems can be quite inexplicable, despite the availability of knobs for adjusting the similarity metrics. Finally, we present the results of a simple machine-learning algorithm that uses the blobworld representation to classify images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Special issue on digital libraries. </editor> <title> IEEE Trans. </title> <journal> Pattern Analysis and Machine Intelligence, </journal> <volume> 18(8), </volume> <month> Aug </month> <year> 1996. </year>
Reference: [2] <editor> J. Ashley et al. </editor> <title> Automatic and semiautomatic methods for image annotation and retrieval in QBIC. </title> <booktitle> In SPIE Proc. Storage and Retrieval for Image and Video Databases, </booktitle> <pages> pages 24-35, </pages> <year> 1995. </year>
Reference-contexts: The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. Region segmentation is largely manual, but the most recent versions of QBIC <ref> [2] </ref> contain simple automated segmentation facilities. Photobook [34] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [22], VisualSEEk [46], Candid [29], and Chabot [10, 33].
Reference: [3] <author> S. Ayer and H. Sawhney. </author> <title> Layered representation of motion video using robust maximum-likelihood estimation of mixture models and MDL encoding. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <pages> pages 777-784, </pages> <year> 1995. </year>
Reference-contexts: Jacobs et al. [24] have used multiresolution wavelet decompositions to perform queries based on iconic matching. Our approach uses the EM algorithm for segmentation based on color and texture features jointly. Earlier work has used EM and/or the Minimum Description Length (MDL) principle to perform segmentation based on motion <ref> [3, 48] </ref> or scaled intensities [49], but EM has not previously been used on joint color and texture.
Reference: [4] <author> S. Belongie, C. Carson, H. Greenspan, and J. Malik. </author> <title> Color-and texture-based image segmentation using EM and its application to content-based image retrieval. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1998. </year>
Reference-contexts: In Section 4 we discuss automatic classification of images by a machine learning algorithm. We conclude with a brief discussion of our approach and some proposed directions for future work. Portions of this work have been previously published in <ref> [4, 9] </ref>. 1.1 Background The best-known image database system is IBM's Query by Image Content (QBIC) [14], which allows an operator to specify various properties of a desired image.
Reference: [5] <author> J. Bigun, G. Granlund, and J. Wiklund. </author> <title> Multidimensional orientation estimation with applications to texture analysis and optical flow. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(8) </volume> <pages> 775-790, </pages> <month> Aug </month> <year> 1991. </year>
Reference-contexts: At each pixel location, M (x; y) is a 2 fi 2 symmetric positive semidefinite matrix; thus it provides us with three pieces of information about each pixel. Rather than work with the raw entries in M , it is more common to deal with its eigenstructure <ref> [5, 15] </ref>. Consider a fixed scale and pixel location, let 1 and 2 ( 1 2 ) denote the eigenvalues of M at that location, and let denote the argument of the principal eigenvector of M .
Reference: [6] <author> C. M. Bishop. </author> <title> Neural Networks for Pattern Recognition. </title> <publisher> Clarendon Press, </publisher> <year> 1995. </year>
Reference-contexts: Given these feature vectors, there are a number of possible techniques for building a classifier, including neural nets, nearest neighbors, support vectors, Bayes nets, decision trees, and Gaussian classifiers. (See <ref> [6, 12, 39] </ref> for a discussion of classifiers.) As comparing various classifiers is not the purpose of this paper, we simply chose to use a classifier which mirrors the querying process.
Reference: [7] <author> D. Blair. STAIRS redux: </author> <title> thoughts on the STAIRS evaluation, ten years after. </title> <journal> J. Am. Soc. Inf. Sci., </journal> <volume> 47(1) </volume> <pages> 4-22, </pages> <year> 1996. </year>
Reference-contexts: The two classifiers are comparable, with blob-world slightly worse than color histograms. For blobworld, the average precision is 47%; for histograms, 50%. The performance of both classifiers varies greatly among categories. As a rough comparison, studies from the information retrieval community <ref> [7, 18] </ref> indicate that document retrieval by skilled users in manually indexed collections yields 70-80% precision, and fully automatic retrieval yields about 50% precision. (However, those figures are from larger data collections.) Several factors degrade the performance of the blobworld classifier: * The canonical blobs chosen are often in fact boring
Reference: [8] <author> L. Breiman, J. Friedman, R. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <year> 1984. </year>
Reference-contexts: We use the feature vectors for all the training images to train a decision tree classifier using C4.5 <ref> [8, 37, 38] </ref>. The resulting classifier provides a logical rule for membership in each category: each path through the tree is a conjunction of statements about atomic query scores, and the set of all paths leading to a particular category is a disjunction of these conjunctions.
Reference: [9] <author> C. Carson, S. Belongie, H. Greenspan, and J. Malik. </author> <title> Region-based image querying. </title> <booktitle> In IEEE Workshop on the Content-Based Access of Image and Video Libraries, </booktitle> <year> 1997. </year>
Reference-contexts: In Section 4 we discuss automatic classification of images by a machine learning algorithm. We conclude with a brief discussion of our approach and some proposed directions for future work. Portions of this work have been previously published in <ref> [4, 9] </ref>. 1.1 Background The best-known image database system is IBM's Query by Image Content (QBIC) [14], which allows an operator to specify various properties of a desired image.
Reference: [10] <author> C. Carson and V. Ogle. </author> <title> Storage and retrieval of feature data for a very large online image collection. </title> <journal> IEEE Data Engineering Bulletin, </journal> <volume> 19(4), </volume> <month> Dec </month> <year> 1996. </year>
Reference-contexts: Photobook [34] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [22], VisualSEEk [46], Candid [29], and Chabot <ref> [10, 33] </ref>. None of these systems codes spatial organization in a way that supports object queries. Classical object recognition techniques usually rely on clean segmentation of the object from the rest of the image or are designed for fixed geometric objects such as machine parts.
Reference: [11] <author> A. Dempster, N. Laird, and D. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Royal Statistical Soc., Ser. B, </journal> <volume> 39(1) </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: In order to divide these points into groups, we make use of the Expectation-Maximization (EM) algorithm <ref> [11] </ref> to determine the maximum likelihood parameters of a mixture of K Gaussians inside the 6-D feature space. The EM algorithm is used for finding maximum likelihood parameter estimates when there is missing or incomplete data.
Reference: [12] <author> R. Duda and P. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <year> 1973. </year>
Reference-contexts: Given these feature vectors, there are a number of possible techniques for building a classifier, including neural nets, nearest neighbors, support vectors, Bayes nets, decision trees, and Gaussian classifiers. (See <ref> [6, 12, 39] </ref> for a discussion of classifiers.) As comparing various classifiers is not the purpose of this paper, we simply chose to use a classifier which mirrors the querying process.
Reference: [13] <author> P. Enser. </author> <title> Query analysis in a visual information retrieval context. </title> <journal> J. Doc. and Text Management, </journal> <volume> 1(1) </volume> <pages> 25-52, </pages> <year> 1993. </year>
Reference-contexts: Copyright may be transferred without notice, after which this version will be superseded. * While users generally want to find images containing particular objects (things) <ref> [13, 17] </ref>, most existing image retrieval systems represent images based only on their low-level features (stuff), with little regard for the spatial organization of those features. * Systems based on user querying are often unintuitive and offer little help in understanding why certain images were returned and how to refine the
Reference: [14] <author> M. Flickner, H. Sawhney, W. Niblack, J. Ashley, et al. </author> <title> Query by image and video content: the QBIC system. </title> <journal> IEEE Computer, </journal> <volume> 28(9) </volume> <pages> 23-32, </pages> <month> Sep </month> <year> 1995. </year>
Reference-contexts: We conclude with a brief discussion of our approach and some proposed directions for future work. Portions of this work have been previously published in [4, 9]. 1.1 Background The best-known image database system is IBM's Query by Image Content (QBIC) <ref> [14] </ref>, which allows an operator to specify various properties of a desired image. The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. <p> Color histograms are commonly used in content-based retrieval systems <ref> [14, 33, 47] </ref> and have proven very useful; however, the global characterization is poor at, for example, distinguishing between a field of orange flowers and a tiger, because it lacks information about how the color is distributed spatially.
Reference: [15] <author> W. Forstner. </author> <title> A framework for low level feature extraction. </title> <booktitle> In Proc. Eur. Conf. Comp. Vis., </booktitle> <pages> pages 383-394, </pages> <year> 1994. </year>
Reference-contexts: However, it ignores the fact that for large values and saturations, hue differences are more perceptually relevant than saturation and value differences. 2 locations. 2.1.2 Texture Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks [32] and the second-moment matrix <ref> [15, 20] </ref>. We will not elaborate here on the classical approaches to texture segmentation and classification, both of which are challenging and well-studied tasks. Rather, we introduce a new perspective related to texture descriptors and texture grouping motivated by the content-based retrieval task. <p> At each pixel location, M (x; y) is a 2 fi 2 symmetric positive semidefinite matrix; thus it provides us with three pieces of information about each pixel. Rather than work with the raw entries in M , it is more common to deal with its eigenstructure <ref> [5, 15] </ref>. Consider a fixed scale and pixel location, let 1 and 2 ( 1 2 ) denote the eigenvalues of M at that location, and let denote the argument of the principal eigenvector of M . <p> Scale selection We may think of as controlling the size of the integration window around each pixel within which the outer product of the gradient vectors is averaged. has been called the integration scale or artificial scale by various authors <ref> [15, 20] </ref> to distinguish it from the natural scale used in linear smoothing of raw image intensities.
Reference: [16] <author> D. Forsyth and M. Fleck. </author> <title> Body plans. </title> <booktitle> In Proc. IEEE Comp. Soc. Conf. Comp. Vis. and Patt. Rec., </booktitle> <pages> pages 678-683, </pages> <year> 1997. </year>
Reference-contexts: We plan to explore the spatial relationships among blobs; we could use information about configurations in both querying and learning. (One possibility is the body plan approach of Forsyth and Fleck <ref> [16] </ref>.) Finally, our choice of a learning approach is motivated primarily by a desire to mirror the human querying process; other learning algorithms might be better suited to automatic classification in blobworld.
Reference: [17] <author> D. Forsyth, J. Malik, and R. Wilensky. </author> <title> Searching for digital pictures. </title> <journal> Scientific American, </journal> <volume> 276(6) </volume> <pages> 72-77, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Copyright may be transferred without notice, after which this version will be superseded. * While users generally want to find images containing particular objects (things) <ref> [13, 17] </ref>, most existing image retrieval systems represent images based only on their low-level features (stuff), with little regard for the spatial organization of those features. * Systems based on user querying are often unintuitive and offer little help in understanding why certain images were returned and how to refine the
Reference: [18] <author> W. B. Frakes and R. Baeza-Yates. </author> <title> Information Retrieval: Data Structures & Algorithms. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: The two classifiers are comparable, with blob-world slightly worse than color histograms. For blobworld, the average precision is 47%; for histograms, 50%. The performance of both classifiers varies greatly among categories. As a rough comparison, studies from the information retrieval community <ref> [7, 18] </ref> indicate that document retrieval by skilled users in manually indexed collections yields 70-80% precision, and fully automatic retrieval yields about 50% precision. (However, those figures are from larger data collections.) Several factors degrade the performance of the blobworld classifier: * The canonical blobs chosen are often in fact boring
Reference: [19] <author> W. T. Freeman and E. H. Adelson. </author> <title> The design and use of steerable filters. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <year> 1991. </year>
Reference-contexts: We define polarity as p = E + + E 1 Strictly speaking, eqn. (1) is not a convolution, since (x; y) is spa tially variant. 2 Polarity is related to the quadrature phase as discussed in <ref> [19, 21] </ref>. 3 The definitions of E + and E are E + = (x;y)2W and X G (x; y)[rI n] where [] + and [] are the rectified positive and negative parts of their argument, n is a unit vector perpendicular to , and W represents the neighborhood under consideration.
Reference: [20] <author> J. Garding and T. Lindeberg. </author> <title> Direct computation of shape cues using scale-adapted spatial derivative operators. </title> <journal> Int. J. Comp. Vis., </journal> <volume> 17(2) </volume> <pages> 163-191, </pages> <month> Feb </month> <year> 1996. </year>
Reference-contexts: However, it ignores the fact that for large values and saturations, hue differences are more perceptually relevant than saturation and value differences. 2 locations. 2.1.2 Texture Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks [32] and the second-moment matrix <ref> [15, 20] </ref>. We will not elaborate here on the classical approaches to texture segmentation and classification, both of which are challenging and well-studied tasks. Rather, we introduce a new perspective related to texture descriptors and texture grouping motivated by the content-based retrieval task. <p> Scale selection We may think of as controlling the size of the integration window around each pixel within which the outer product of the gradient vectors is averaged. has been called the integration scale or artificial scale by various authors <ref> [15, 20] </ref> to distinguish it from the natural scale used in linear smoothing of raw image intensities. <p> We declare a region to be uniform if its mean contrast across scale is less than 0:1. Another method of scale selection that has been proposed <ref> [20] </ref> is based on localizing extrema across scale of an invariant of M , such as the trace or determinant. <p> The other two, which are taken from M fl , are the anisotropy, defined as a = 1 2 = 1 , and the normalized texture contrast, defined as c = 2 p These are related to derived quantities reported in <ref> [20] </ref>. 2.1.3 Combining color and texture features The final color/texture descriptor for a given pixel consists of six values: three for color and three for texture. The three color components are the color-cone coordinates found after spatial averaging using a Gaussian at the selected scale.
Reference: [21] <author> G. H. Granlund and H. Knutsson. </author> <title> Signal Processing for Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: We define polarity as p = E + + E 1 Strictly speaking, eqn. (1) is not a convolution, since (x; y) is spa tially variant. 2 Polarity is related to the quadrature phase as discussed in <ref> [19, 21] </ref>. 3 The definitions of E + and E are E + = (x;y)2W and X G (x; y)[rI n] where [] + and [] are the rectified positive and negative parts of their argument, n is a unit vector perpendicular to , and W represents the neighborhood under consideration.
Reference: [22] <author> A. Gupta and R. Jain. </author> <title> Visual information retrieval. </title> <journal> Comm. Assoc. Comp. Mach., </journal> <volume> 40(5) </volume> <pages> 70-79, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Region segmentation is largely manual, but the most recent versions of QBIC [2] contain simple automated segmentation facilities. Photobook [34] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage <ref> [22] </ref>, VisualSEEk [46], Candid [29], and Chabot [10, 33]. None of these systems codes spatial organization in a way that supports object queries.
Reference: [23] <author> D. Harman. </author> <title> Relevance feedback and other query modification techniques. </title> <editor> In W. B. Frakes and R. Baeza-Yates, editors, </editor> <booktitle> Information retrieval: data structures & algorithms. </booktitle> <publisher> Pren-tice Hall, </publisher> <year> 1992. </year>
Reference-contexts: In a few systems, the user may also label the retrieved images as good or bad matches in order to provide more information to the retrieval algorithm; this is called relevance feedback <ref> [23] </ref>. Two major shortcomings of such interfaces are a lack of user control and the absence of information about the computer's view of the image.
Reference: [24] <author> C. Jacobs, A. Finkelstein, and D. Salesin. </author> <title> Fast multiresolu-tion image querying. </title> <booktitle> In Proc. SIGGRAPH, </booktitle> <year> 1995. </year>
Reference-contexts: Promising work by Lipson et al. [31] retrieves images based on spatial and photometric relationships within and across image regions. Little or no segmentation is done; the regions are derived from low-resolution images. Jacobs et al. <ref> [24] </ref> have used multiresolution wavelet decompositions to perform queries based on iconic matching. Our approach uses the EM algorithm for segmentation based on color and texture features jointly.
Reference: [25] <author> A. Jain. </author> <title> Fundamentals of Digital Image Processing. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: Although polarity is used for scale selection, we discard it here, since in any textured or uniform region it is approximately zero due to the scale selection process. Spatial descriptors There are various ways to represent the shape of a region, such as Fourier descriptors <ref> [25] </ref>, footprint matching [28], and moment-based approaches [25]. We have chosen a very simple approach: we replace each region with an equivalent ellipse that has the same first and second moments. <p> Spatial descriptors There are various ways to represent the shape of a region, such as Fourier descriptors <ref> [25] </ref>, footprint matching [28], and moment-based approaches [25]. We have chosen a very simple approach: we replace each region with an equivalent ellipse that has the same first and second moments. Thus the geometric descriptors of each blob are simply the centroid c and scatter matrix S of its corresponding region.
Reference: [26] <author> A. K. Jain and F. Farrokhnia. </author> <title> Unsupervised texture segmentation using Gabor filters. </title> <journal> Pattern Recognition, </journal> <volume> 24(12) </volume> <pages> 1167-1186, </pages> <year> 1991. </year>
Reference-contexts: Earlier work has used EM and/or the Minimum Description Length (MDL) principle to perform segmentation based on motion [3, 48] or scaled intensities [49], but EM has not previously been used on joint color and texture. Related approaches such as deterministic annealing [36] and classical clustering <ref> [26] </ref> have been applied to texture segmentation without color. 2 The blobworld image representation The blobworld representation is related to the notion of photographic or artistic scene composition.
Reference: [27] <author> J.-S. Jang, C.-T. Sun, and E. Mizutani. </author> <title> Neuro-Fuzzy and Soft Computing. </title> <publisher> Prentice Hall, </publisher> <year> 1997. </year>
Reference-contexts: This score is 1 if the blobs are identical in all relevant features; it decreases as the match becomes less perfect. 3. Take i = max j ij . The compound query score for the database image is calculated using fuzzy-logic operations <ref> [27] </ref>. For example, if the query is like-blob-1 and (like-blob-2 or like-blob-3), the overall score for the image is minf 1 ; maxf 2 ; 3 gg. The user can also specify a weighting i for each atomic query.
Reference: [28] <author> A. Kalvin et al. </author> <title> Two-dimensional model-based boundary matching using footprints. </title> <journal> Int. J. Rob. Res., </journal> <volume> 5 </volume> <pages> 38-55, </pages> <year> 1986. </year>
Reference-contexts: Although polarity is used for scale selection, we discard it here, since in any textured or uniform region it is approximately zero due to the scale selection process. Spatial descriptors There are various ways to represent the shape of a region, such as Fourier descriptors [25], footprint matching <ref> [28] </ref>, and moment-based approaches [25]. We have chosen a very simple approach: we replace each region with an equivalent ellipse that has the same first and second moments. Thus the geometric descriptors of each blob are simply the centroid c and scatter matrix S of its corresponding region.
Reference: [29] <author> P. Kelly, M. Cannon, and D. Hush. </author> <title> Query by image example: the CANDID approach. </title> <booktitle> In SPIE Proc. Storage and Retrieval for Image and Video Databases, </booktitle> <pages> pages 238-248, </pages> <year> 1995. </year>
Reference-contexts: Region segmentation is largely manual, but the most recent versions of QBIC [2] contain simple automated segmentation facilities. Photobook [34] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [22], VisualSEEk [46], Candid <ref> [29] </ref>, and Chabot [10, 33]. None of these systems codes spatial organization in a way that supports object queries. Classical object recognition techniques usually rely on clean segmentation of the object from the rest of the image or are designed for fixed geometric objects such as machine parts.
Reference: [30] <author> T. Leung and J. Malik. </author> <title> Detecting, localizing and grouping repeated scene elements from an image. </title> <booktitle> In Proc. Eur. Conf. Comp. Vis., </booktitle> <pages> pages 546-555, </pages> <year> 1996. </year>
Reference-contexts: We can think of E + and E as measures of how many gradient vectors in W are on the positive side and negative side of the dominant orientation, respectively. Note that p ranges from 0 to 1. A similar measure is used in <ref> [30] </ref> to distinguish a flow pattern from an edge. The polarity p varies as the scale changes; its behavior in typical image regions can be summarized as follows (see Fig. 2): Edge: The presence of an edge is signaled by p holding values close to 1 for all .
Reference: [31] <author> P. Lipson, E. Grimson, and P. Sinha. </author> <title> Configuration based scene classification and image indexing. </title> <booktitle> In Proc. IEEE Comp. Soc. Conf. Comp. Vis. and Patt. Rec., </booktitle> <pages> pages 1007-1013, </pages> <year> 1997. </year>
Reference-contexts: More recent techniques [35] can identify specific objects drawn from a finite (on the order of 100) collection, but no present technique is effective at the general image analysis task, which requires both image segmentation and image classification. Promising work by Lipson et al. <ref> [31] </ref> retrieves images based on spatial and photometric relationships within and across image regions. Little or no segmentation is done; the regions are derived from low-resolution images. Jacobs et al. [24] have used multiresolution wavelet decompositions to perform queries based on iconic matching.
Reference: [32] <author> J. Malik and P. Perona. </author> <title> Preattentive texture discrimination with early vision mechanisms. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 7(5) </volume> <pages> 923-932, </pages> <year> 1990. </year>
Reference-contexts: However, it ignores the fact that for large values and saturations, hue differences are more perceptually relevant than saturation and value differences. 2 locations. 2.1.2 Texture Texture is a well-researched property of image regions, and many texture descriptors have been proposed, including multi-orientation filter banks <ref> [32] </ref> and the second-moment matrix [15, 20]. We will not elaborate here on the classical approaches to texture segmentation and classification, both of which are challenging and well-studied tasks. Rather, we introduce a new perspective related to texture descriptors and texture grouping motivated by the content-based retrieval task.
Reference: [33] <author> V. Ogle and M. Stonebraker. Chabot: </author> <title> Retrieval from a relational database of images. </title> <journal> IEEE Computer, </journal> <volume> 28(9) </volume> <pages> 40-48, </pages> <month> Sep </month> <year> 1995. </year>
Reference-contexts: Photobook [34] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [22], VisualSEEk [46], Candid [29], and Chabot <ref> [10, 33] </ref>. None of these systems codes spatial organization in a way that supports object queries. Classical object recognition techniques usually rely on clean segmentation of the object from the rest of the image or are designed for fixed geometric objects such as machine parts. <p> Color histograms are commonly used in content-based retrieval systems <ref> [14, 33, 47] </ref> and have proven very useful; however, the global characterization is poor at, for example, distinguishing between a field of orange flowers and a tiger, because it lacks information about how the color is distributed spatially.
Reference: [34] <author> A. Pentland, R. Picard, and S. Sclaroff. Photobook: </author> <title> Content-based manipulation of image databases. </title> <journal> Int. J. Comp. Vis., </journal> <volume> 18(3) </volume> <pages> 233-254, </pages> <year> 1996. </year>
Reference-contexts: The system then displays a selection of potential matches to those criteria, sorted by a score of the appropriateness of the match. Region segmentation is largely manual, but the most recent versions of QBIC [2] contain simple automated segmentation facilities. Photobook <ref> [34] </ref> incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [22], VisualSEEk [46], Candid [29], and Chabot [10, 33]. None of these systems codes spatial organization in a way that supports object queries.
Reference: [35] <author> J. Ponce, A. Zisserman, and M. </author> <title> Hebert. </title> <booktitle> Object Representation in Computer VisionII. Number 1144 in LNCS. </booktitle> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: Neither constraint holds in the case of natural images: the shape, size, and color of objects like tigers and airplanes are quite variable, and segmentation is imperfect. Clearly, classical object recognition does not apply. More recent techniques <ref> [35] </ref> can identify specific objects drawn from a finite (on the order of 100) collection, but no present technique is effective at the general image analysis task, which requires both image segmentation and image classification.
Reference: [36] <author> J. Puzicha and J. M. Buhmann. </author> <title> Multiscale annealing for real-time unsupervised texture segmentation. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1998. </year>
Reference-contexts: Earlier work has used EM and/or the Minimum Description Length (MDL) principle to perform segmentation based on motion [3, 48] or scaled intensities [49], but EM has not previously been used on joint color and texture. Related approaches such as deterministic annealing <ref> [36] </ref> and classical clustering [26] have been applied to texture segmentation without color. 2 The blobworld image representation The blobworld representation is related to the notion of photographic or artistic scene composition.
Reference: [37] <author> J. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: We use the feature vectors for all the training images to train a decision tree classifier using C4.5 <ref> [8, 37, 38] </ref>. The resulting classifier provides a logical rule for membership in each category: each path through the tree is a conjunction of statements about atomic query scores, and the set of all paths leading to a particular category is a disjunction of these conjunctions.
Reference: [38] <author> J. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: We use the feature vectors for all the training images to train a decision tree classifier using C4.5 <ref> [8, 37, 38] </ref>. The resulting classifier provides a logical rule for membership in each category: each path through the tree is a conjunction of statements about atomic query scores, and the set of all paths leading to a particular category is a disjunction of these conjunctions.
Reference: [39] <author> B. Ripley. </author> <title> Pattern Recognition and Neural Networks. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: Given these feature vectors, there are a number of possible techniques for building a classifier, including neural nets, nearest neighbors, support vectors, Bayes nets, decision trees, and Gaussian classifiers. (See <ref> [6, 12, 39] </ref> for a discussion of classifiers.) As comparing various classifiers is not the purpose of this paper, we simply chose to use a classifier which mirrors the querying process.
Reference: [40] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Auto-matica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: Given this indicator, we can apply the Minimum Description Length (MDL) principle <ref> [40, 41] </ref> to select among values of K. This can be operationalized as follows [40, 43]: choose K to maximize log L (QjX ) 2 where m K is the number of free parameters needed for a model with K mixture components. <p> Given this indicator, we can apply the Minimum Description Length (MDL) principle [40, 41] to select among values of K. This can be operationalized as follows <ref> [40, 43] </ref>: choose K to maximize log L (QjX ) 2 where m K is the number of free parameters needed for a model with K mixture components.
Reference: [41] <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific, </publisher> <year> 1989. </year>
Reference-contexts: Given this indicator, we can apply the Minimum Description Length (MDL) principle <ref> [40, 41] </ref> to select among values of K. This can be operationalized as follows [40, 43]: choose K to maximize log L (QjX ) 2 where m K is the number of free parameters needed for a model with K mixture components.
Reference: [42] <author> C. Schmid and R. Mohr. </author> <title> Combining greyvalue invariants with local constraints for object recognition. </title> <booktitle> In Proc. IEEE Comp. Soc. Conf. Comp. Vis. and Patt. Rec., </booktitle> <pages> pages 872-877, </pages> <year> 1996. </year>
Reference: [43] <author> G. Schwarz. </author> <title> Estimating the dimension of a model. </title> <journal> Annals of Statistics, </journal> <volume> 6 </volume> <pages> 461-464, </pages> <year> 1978. </year>
Reference-contexts: Given this indicator, we can apply the Minimum Description Length (MDL) principle [40, 41] to select among values of K. This can be operationalized as follows <ref> [40, 43] </ref>: choose K to maximize log L (QjX ) 2 where m K is the number of free parameters needed for a model with K mixture components.
Reference: [44] <author> U. Shaft and R. Ramakrishnan. </author> <title> Data modeling and querying in the PIQ image DBMS. </title> <journal> IEEE Data Engineering Bulletin, </journal> <volume> 19(4) </volume> <pages> 28-36, </pages> <month> Dec </month> <year> 1996. </year> <month> 17 </month>
Reference-contexts: Related approaches such as deterministic annealing [36] and classical clustering [26] have been applied to texture segmentation without color. 2 The blobworld image representation The blobworld representation is related to the notion of photographic or artistic scene composition. In the sense discussed in <ref> [44] </ref>, the blobworld descriptors constitute an example of a summary representation because they are concise and relatively easy to process in a querying framework. Blobworld is distinct from color-layout matching as in QBIC [14]in that it is designed to find objects or parts of objects.
Reference: [45] <author> J. Shi and J. Malik. </author> <title> Normalized cuts and image segmenation. </title> <booktitle> In Proc. IEEE Comp. Soc. Conf. Comp. Vis. and Patt. Rec., </booktitle> <year> 1997. </year>
Reference-contexts: We have also implemented an automatic classifier that mimics the querying process. This approach is modular; the three stages are separate and somewhat independent. In the future we might explore replacing or improving the three modules: 1. We are experimenting with other segmentation algorithms such as normalized cuts <ref> [45] </ref> to replace the current EM-based segmentation. Since any segmentation algorithm will sometimes over-segment objects, we might also include a grouping algorithm in the system to build objects out of object parts.
Reference: [46] <author> J. R. Smith and S.-F. Chang. </author> <title> Single color extraction and image query. </title> <booktitle> In Proc. IEEE Int. Conf. on Image Processing, </booktitle> <pages> pages 528-531, </pages> <year> 1995. </year>
Reference-contexts: Region segmentation is largely manual, but the most recent versions of QBIC [2] contain simple automated segmentation facilities. Photobook [34] incorporates more sophisticated representations of texture and a degree of automatic segmentation. Other examples of systems that identify materials using low-level image properties include Virage [22], VisualSEEk <ref> [46] </ref>, Candid [29], and Chabot [10, 33]. None of these systems codes spatial organization in a way that supports object queries. Classical object recognition techniques usually rely on clean segmentation of the object from the rest of the image or are designed for fixed geometric objects such as machine parts.
Reference: [47] <author> M. Swain and D. Ballard. </author> <title> Color indexing. </title> <journal> Int. J. Comp. Vis., </journal> <volume> 7(1) </volume> <pages> 11-32, </pages> <year> 1991. </year>
Reference-contexts: Color histograms are commonly used in content-based retrieval systems <ref> [14, 33, 47] </ref> and have proven very useful; however, the global characterization is poor at, for example, distinguishing between a field of orange flowers and a tiger, because it lacks information about how the color is distributed spatially. <p> Sample queries are shown in Figs. 4-7. 7 3.3 Comparison to color histograms In order to evaluate the query system, we compared our results to those obtained using color histogram matching, following the procedure of Swain and Ballard <ref> [47] </ref>. The color histogram for each image uses 8 fi 16 fi 16 = 2048 color bins: 8 divisions for the intensity axis and 16 for each opponent color axis.
Reference: [48] <author> Y. Weiss and E. Adelson. </author> <title> A unified mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. </title> <booktitle> In Proc. IEEE Comp. Soc. Conf. Comp. Vis. and Patt. Rec., </booktitle> <pages> pages 321-326, </pages> <year> 1996. </year>
Reference-contexts: Jacobs et al. [24] have used multiresolution wavelet decompositions to perform queries based on iconic matching. Our approach uses the EM algorithm for segmentation based on color and texture features jointly. Earlier work has used EM and/or the Minimum Description Length (MDL) principle to perform segmentation based on motion <ref> [3, 48] </ref> or scaled intensities [49], but EM has not previously been used on joint color and texture.
Reference: [49] <author> W. Wells, R. Kikinis, W. Grimson, and F. Jolesz. </author> <title> Adaptive segmentation of MRI data. </title> <booktitle> In Int. Conf. on Comp. Vis., Virtual Reality and Robotics in Medicine, </booktitle> <pages> pages 59-69, </pages> <year> 1995. </year>
Reference-contexts: Our approach uses the EM algorithm for segmentation based on color and texture features jointly. Earlier work has used EM and/or the Minimum Description Length (MDL) principle to perform segmentation based on motion [3, 48] or scaled intensities <ref> [49] </ref>, but EM has not previously been used on joint color and texture.

References-found: 49

