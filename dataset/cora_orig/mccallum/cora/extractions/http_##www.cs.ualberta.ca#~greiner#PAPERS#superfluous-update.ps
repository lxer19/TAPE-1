URL: http://www.cs.ualberta.ca/~greiner/PAPERS/superfluous-update.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Email: E-mail: fgreiner, hancock, bharatg@scr.siemens.com  
Phone: Phone: (609)-734-6500, Fax: (609) 734-6565  
Title: Knowing What Doesn't Matter: Exploiting Omitted Superfluous Data  
Author: Russell Greiner, Thomas Hancock, and R. Bharat Rao 
Keyword: machine learning, decision trees, diagnosis, theory refinement  
Address: 755 College Road East, Princeton, NJ 08540-6632  
Affiliation: Learning Systems Department, Siemens Corporate Research  
Abstract: Most inductive inference algorithms (i.e., "learners") work most effectively when their training data contain completely specified labeled samples. In many diagnostic tasks, however, the data will include the values of only some of the attributes; we model this as a blocking process that hides the values of those attributes from the learner. While blockers that remove the values of critical attributes can handicap a learner, this paper instead focuses on blockers that remove only superfluous attribute values, i.e., values that are not needed to classify an instance, given the values of the other unblocked attributes. We first motivate and formalize this model of "superfluous-value blocking," and then demonstrate that these omissions can be useful, by showing that certain classes that seem hard to learn in the general PAC model | viz., decision trees | are trivial to learn in this setting, and can even be learned in a manner that is very robust to classification noise. We also discuss how this model can be extended to deal with (1) theory revision (i.e., modifying an existing decision tree); (2) "complex" attributes (which correspond to combinations of other atomic attributes); (3) blockers that occasionally include superfluous values or exclude re quired values; and (4) other hypothesis classes (e.g., DNF formulae). Declaration: This paper has not already been accepted by and is not currently under review for a journal or another conference, nor will it be submitted for such during IJCAI's review period. fl This is an extended version of a paper that appeared in working notes of the 1994 AAAI Fall Symposium on "Relevance", New Orleans, November 1994. y Authors listed alphabetically. We gratefully acknowledge receiving helpful comments from Dale Schuurmans and George Drastal. 
Abstract-found: 1
Intro-found: 1
Reference: [AS91] <author> D. Angluin and D. K. </author> <title> Slonim. Learning monotone DNF with an incomplete membership oracle. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 139-146. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Two final comments to help place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted <ref> [AS91, FGMP94] </ref>, or where the attribute value is changed [SV88a, Lit91, GS95]. Second, as our blocker is providing additional information to the learner, its Knowing What Doesn't Matter 4 role is similar to that of a benevolent teacher.
Reference: [BFOS84] <author> L. Breiman, J. Friedman, J. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA, </address> <year> 1984. </year>
Reference-contexts: His model differs, however, by using test-cost, rather than test-relevance, to decide which tests to omit. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different learning context, which is appropriate for a different situation [SG93, SG94]: After one process draws completely-specified samples at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete tuple <p> To motivate this model, consider the behavior of a classifier d t using a standard decision tree t, a la cart <ref> [BFOS84] </ref> or c4.5 [Qui92]. Here, given any instance, d t will perform only the tests on a single path through t. Hence, d t will see only the values of the attributes corresponding to those tests.
Reference: [BHL91] <author> A. Blum, L. Hellerstein, and N. Littlestone. </author> <title> Learning in the presence of finitely or infinitely many irrelevant attributes. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 157-166. </pages> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: John et al. [JKP94] would consider t 1 to be "weakly irrelevant"; by contrast, an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., <ref> [Lit88, Blu92, BHL91] </ref>. Of course, our situation differs from those models of learning, as our environment explicitly identifies which attributes are weakly irrelevant.
Reference: [Blu92] <author> A. Blum. </author> <title> Learning boolean functions in an infinite attribute space. </title> <journal> Machine Learning, </journal> <volume> 9(4) </volume> <pages> 373-386, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: John et al. [JKP94] would consider t 1 to be "weakly irrelevant"; by contrast, an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., <ref> [Lit88, Blu92, BHL91] </ref>. Of course, our situation differs from those models of learning, as our environment explicitly identifies which attributes are weakly irrelevant.
Reference: [EH89] <author> A. Ehrenfeucht and D. Haussler. </author> <title> Learning decision trees from random examples. </title> <journal> Information and Computation, </journal> <volume> 82(3) </volume> <pages> 231-246, </pages> <year> 1989. </year>
Reference-contexts: This subsection describes 4 The most general known algorithms run in pseudo-polynomial time, i.e., they learn an s-node decision tree in time polynomial in s O (log s) <ref> [EH89, Riv87] </ref>.
Reference: [FGMP94] <author> Mike Frazier, Sally Goldman, Nina Mishra, and Leonard Pitt. </author> <title> Learning from a consistently ignorant teacher. </title> <booktitle> In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 328-339, </pages> <year> 1994. </year>
Reference-contexts: Two final comments to help place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted <ref> [AS91, FGMP94] </ref>, or where the attribute value is changed [SV88a, Lit91, GS95]. Second, as our blocker is providing additional information to the learner, its Knowing What Doesn't Matter 4 role is similar to that of a benevolent teacher.
Reference: [GHR95] <author> Russell Greiner, Thomas Hancock, and R. Bharat Rao. </author> <title> Knowing what doesn't matter: Exploiting (intentionally) omitted superfluous data. </title> <type> Technical report, </type> <institution> Siemens Corporate Research, </institution> <year> 1995. </year>
Reference-contexts: Towards explaining this empirical observation, just note that a diagnosis, corresponding to a single path through a n-node decision tree, can require performing only O ( ln (n) ) of the n tests 1 The extended version of this paper <ref> [GHR95] </ref> provides a more comprehensive literature review, as well as proofs of the claims presented here. Knowing What Doesn't Matter 3 possible; here the remaining O ( nln (n) ) test values are irrelevant. <p> Here, this produces the the d 1 tree shown in Figure 4. 7 The extended paper <ref> [GHR95] </ref> presents the actual pseudo-code for this ModifyDT algorithm, and also bounds the number of samples needed, as a function of the number of additional nodes that must be added.
Reference: [GM93] <author> S. Golman and D. Mathias. </author> <title> Teaching a smarter learner. </title> <booktitle> In Proceedings of the Sixth Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 67-76. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Second, as our blocker is providing additional information to the learner, its Knowing What Doesn't Matter 4 role is similar to that of a benevolent teacher. However previous teaching models such as that of Goldman and Mathias <ref> [GM93] </ref> allow the teacher to present arbitrary instances to the learner, without regard to an underlying real-world distribution.
Reference: [GS95] <author> Sally A. Goldman and Robert A. Sloan. </author> <title> Can pac learning algorithms tolerate random attribute noise? Algorithmica, </title> <note> page to appear, </note> <year> 1995. </year>
Reference-contexts: Two final comments to help place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted [AS91, FGMP94], or where the attribute value is changed <ref> [SV88a, Lit91, GS95] </ref>. Second, as our blocker is providing additional information to the learner, its Knowing What Doesn't Matter 4 role is similar to that of a benevolent teacher. <p> Previous attribute noise models <ref> [KL88, SV88b, GS95] </ref> do not consider missing attribute values (i.e., they assume p rfl = p sfl = 0).
Reference: [HKLW91] <author> D. Haussler, M. Kearns, N. Littlestone, and M. K. Warmuth. </author> <title> Equiva lence of models for polynomial learnability. </title> <journal> Inform. Comput., </journal> <volume> 95(2) </volume> <pages> 129-161, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: While this algorithm is parameterized by the size of the tree s, it is easy to produce a modified version that does not require this parameter by using the standard technique <ref> [HKLW91] </ref> of repeated attempts with successively doubled estimates of s. We call this modified procedure GrowDT (n; *; ffi).
Reference: [JKP94] <author> George H. John, Ron Kohavi, and Karl Pfleger. </author> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Proceedings of the Eleventh International Machine Learning Workshop, </booktitle> <pages> pages 121-29, </pages> <address> N.J., </address> <year> 1994. </year>
Reference-contexts: Of course, if t 1 is negative, other tests may then be relevant for the diagnosis; perhaps a negative t 2 and a positive t 3 will also be sufficient to establish diseaseX, etc. John et al. <ref> [JKP94] </ref> would consider t 1 to be "weakly irrelevant"; by contrast, an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., [Lit88, Blu92, BHL91].
Reference: [KL88] <author> M. Kearns and M. Li. </author> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proc. 20th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 267-280. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: Previous attribute noise models <ref> [KL88, SV88b, GS95] </ref> do not consider missing attribute values (i.e., they assume p rfl = p sfl = 0).
Reference: [KLPV87] <author> Michael Kearns, Ming Li, Leonard Pitt, and Leslie Valiant. </author> <title> On the learnability of boolean formulae. </title> <booktitle> In Proceedings of the 19th Symposium on the Theory of Computations, </booktitle> <pages> pages 285-295, </pages> <address> New York, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: We now use the standard "PAC-criterion" <ref> [Val84, KLPV87] </ref> to specify the desired performance of our learners: Definition 2 (PAC-learning) An algorithm, L, PAC-learns a set of concepts C if, for some polynomial function p ( ), for all target concepts c 2 C, distributions P , and error parameters *; ffi &gt; 0, L runs in time
Reference: [LDRG94] <author> Pat Langley, George Drastal, R. Bharat Rao, and Russell Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Proceedings of The Fifth International Workshop on Principles of Diagnosis (DX-94), </booktitle> <address> New Paltz, NY, </address> <year> 1994. </year> <title> Knowing What Doesn't Matter 15 </title>
Reference-contexts: We let DT [T R+] refer to this model, where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. (We explain the final "+" below.) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section: First, notice from Theorem 1 that the number of samples required to build a decision tree is proportional to the size <p> Langley et al. <ref> [LDRG94] </ref> describes the implementation and experiments with a system in this model. Knowing What Doesn't Matter 9 total amount of expert-time may be much less than if we began with an empty tree.
Reference: [Lit88] <author> Nick Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning Journal, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: John et al. [JKP94] would consider t 1 to be "weakly irrelevant"; by contrast, an attribute is "strongly irrelevant" if its value never plays a role in the classification, under any circumstance (i.e., independent of the values of any other attributes); cf., <ref> [Lit88, Blu92, BHL91] </ref>. Of course, our situation differs from those models of learning, as our environment explicitly identifies which attributes are weakly irrelevant.
Reference: [Lit91] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 147-156. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: Two final comments to help place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted [AS91, FGMP94], or where the attribute value is changed <ref> [SV88a, Lit91, GS95] </ref>. Second, as our blocker is providing additional information to the learner, its Knowing What Doesn't Matter 4 role is similar to that of a benevolent teacher.
Reference: [LR87] <author> J. A. Little and D. B. Rubin. </author> <title> Statistical Analysis with Missing Data. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: His model differs, however, by using test-cost, rather than test-relevance, to decide which tests to omit. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different learning context, which is appropriate for a different situation [SG93, SG94]: After one process draws completely-specified samples at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete tuple
Reference: [MB88] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <booktitle> In Proceedings of IML-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: We let DT [T R+] refer to this model, where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. (We explain the final "+" below.) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section: First, notice from Theorem 1 that the number of samples required to build a decision tree is proportional to the size
Reference: [OM90] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 815-20, </pages> <year> 1990. </year>
Reference-contexts: We let DT [T R+] refer to this model, where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. (We explain the final "+" below.) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section: First, notice from Theorem 1 that the number of samples required to build a decision tree is proportional to the size
Reference: [PBH90] <author> B. W. Porter, R. Bareiss, and R. C. Holte. </author> <title> Concept learning and heuris tic classification in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45(1-2):229-63, </volume> <year> 1990. </year>
Reference-contexts: However, recent studies <ref> [PBH90, RCJ88] </ref> have shown that in practice many datasets are missing more than half of the feature values! Moreover, these attribute values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description" <p> RCJ88] have shown that in practice many datasets are missing more than half of the feature values! Moreover, these attribute values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description" <ref> [PBH90] </ref>, which is precisely the situation considered in this paper (see Definition 1).
Reference: [Qui92] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kauf-mann Publishers, </publisher> <address> San Mateo, </address> <year> 1992. </year>
Reference-contexts: His model differs, however, by using test-cost, rather than test-relevance, to decide which tests to omit. While there are several learning systems which are designed to handle incomplete information in the samples (cf., <ref> [BFOS84, Qui92, LR87] </ref>), they all appear to be based on a different learning context, which is appropriate for a different situation [SG93, SG94]: After one process draws completely-specified samples at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete tuple <p> To motivate this model, consider the behavior of a classifier d t using a standard decision tree t, a la cart [BFOS84] or c4.5 <ref> [Qui92] </ref>. Here, given any instance, d t will perform only the tests on a single path through t. Hence, d t will see only the values of the attributes corresponding to those tests.
Reference: [RCJ88] <author> K. Ruberg, S.M. Cornick, and K.A. James. </author> <title> House calls: Building and maintaining a diagnostic rule-base. </title> <booktitle> In Proceedings Third Knowledge Ac-quistion for Knowledge-Based Systems Workshop, </booktitle> <year> 1988. </year>
Reference-contexts: However, recent studies <ref> [PBH90, RCJ88] </ref> have shown that in practice many datasets are missing more than half of the feature values! Moreover, these attribute values are not randomly blocked, but in fact "are missing [blocked] when they are known to be irrelevant for classification or redundant with features already present in the case description"
Reference: [Riv87] <author> R. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: This subsection describes 4 The most general known algorithms run in pseudo-polynomial time, i.e., they learn an s-node decision tree in time polynomial in s O (log s) <ref> [EH89, Riv87] </ref>.
Reference: [SG93] <author> Dale Schuurmans and Russell Greiner. </author> <title> Learning to classify incomplete examples. </title> <booktitle> In Fourth Annual Workshop on Computational Learning Theory and `Natural' Learning Systems (CLNL93), </booktitle> <address> Provincetown MA, </address> <year> 1993. </year>
Reference-contexts: While there are several learning systems which are designed to handle incomplete information in the samples (cf., [BFOS84, Qui92, LR87]), they all appear to be based on a different learning context, which is appropriate for a different situation <ref> [SG93, SG94] </ref>: After one process draws completely-specified samples at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete tuple h1; 0; 0; 1i to the partial tuple hfl; 0; fl; 1i, where "fl" means this value is hidden. <p> These results, when coupled with <ref> [SG93, SG94] </ref>, help to form a comprehensive description of how learning algorithms should deal with missing data.
Reference: [SG94] <author> Dale Schuurmans and Russell Greiner. </author> <title> Learning default concepts. </title> <booktitle> In CSSCI-94, </booktitle> <year> 1994. </year>
Reference-contexts: While there are several learning systems which are designed to handle incomplete information in the samples (cf., [BFOS84, Qui92, LR87]), they all appear to be based on a different learning context, which is appropriate for a different situation <ref> [SG93, SG94] </ref>: After one process draws completely-specified samples at random, a second process (which also could be "nature") then hides the values of certain attributes, perhaps changing the complete tuple h1; 0; 0; 1i to the partial tuple hfl; 0; fl; 1i, where "fl" means this value is hidden. <p> These results, when coupled with <ref> [SG93, SG94] </ref>, help to form a comprehensive description of how learning algorithms should deal with missing data.
Reference: [SV88a] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In Proceedings COLT-88, </booktitle> <pages> pages 97-103, </pages> <year> 1988. </year>
Reference-contexts: Two final comments to help place our model within the framework of existing computational learning results: First, in our model, certain attribute values are omitted; this differs from models where the class label is omitted [AS91, FGMP94], or where the attribute value is changed <ref> [SV88a, Lit91, GS95] </ref>. Second, as our blocker is providing additional information to the learner, its Knowing What Doesn't Matter 4 role is similar to that of a benevolent teacher.
Reference: [SV88b] <author> G. Shackelford and D. Volper. </author> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In Proc. 1st Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 97-103, </pages> <address> San Mateo, CA, </address> <year> 1988. </year> <note> published by Morgan Kaufmann. </note>
Reference-contexts: Previous attribute noise models <ref> [KL88, SV88b, GS95] </ref> do not consider missing attribute values (i.e., they assume p rfl = p sfl = 0).
Reference: [Tow91] <author> Geoff Towell. </author> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement and Extraction. </title> <type> PhD thesis, </type> <institution> University of Wisconsin, Madison, </institution> <year> 1991. </year>
Reference-contexts: We let DT [T R+] refer to this model, where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. (We explain the final "+" below.) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section: First, notice from Theorem 1 that the number of samples required to build a decision tree is proportional to the size
Reference: [Tur95] <author> Peter D. Turney. </author> <title> Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree inductin algorithm. </title> <journal> Journal of AI Research, </journal> <note> (accepted subject to revision), </note> <year> 1995. </year>
Reference-contexts: Our model of learning can, therefore, be applicable to many diagnostic tasks, and will be especially useful where experts are unavailable or are unable to articulate the classification process they are using. Turney <ref> [Tur95] </ref> discusses a model that also assumes that experts intentionally perform only a subset of the possible tests. His model differs, however, by using test-cost, rather than test-relevance, to decide which tests to omit.
Reference: [Val84] <author> Leslie G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: We now use the standard "PAC-criterion" <ref> [Val84, KLPV87] </ref> to specify the desired performance of our learners: Definition 2 (PAC-learning) An algorithm, L, PAC-learns a set of concepts C if, for some polynomial function p ( ), for all target concepts c 2 C, distributions P , and error parameters *; ffi &gt; 0, L runs in time
Reference: [WP93] <author> James Wogulis and Michael J. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 1128-1134, </pages> <year> 1993. </year>
Reference-contexts: We let DT [T R+] refer to this model, where the T R designates "Theory Revision", corresponding to the many existing systems that perform essentially the same task, albeit in the framework of Horn-clause based reasoning systems; cf., <ref> [Tow91, WP93, MB88, OM90, LDRG94] </ref>. (We explain the final "+" below.) There are several obvious advantages to theory revision over the "grow from scratch" approach discussed in the previous section: First, notice from Theorem 1 that the number of samples required to build a decision tree is proportional to the size
References-found: 31

