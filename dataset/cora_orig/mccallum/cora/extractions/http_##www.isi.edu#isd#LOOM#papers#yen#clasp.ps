URL: http://www.isi.edu/isd/LOOM/papers/yen/clasp.ps
Refering-URL: http://www.isi.edu/isd/LOOM/papers/LOOM-PAPERS.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Yen@CSSUN.TAMU.EDU  
Phone: (409) 845-5466  
Title: CLASP: Integrating Term Subsumption Systems and Production Systems  
Author: John Yen, MEMBER, IEEE Robert Neches and Robert MacGregor 
Address: College Station, TX 77843  4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Department of Computer Science Texas A&M University  USC Information Sciences Institute  
Abstract: Appeared in IEEE Transactions on Knowledge and Data Engineering, Vol. 3, No. 1, pp. 25 - 32, 1991. The research described in this paper was supported by Engineering Excellence Fund at Texas A&M University, by DARPA under Contract No. MDA903-87-C-0641, and by the Air Force Logistics Command under Contract No. F33600-87-C-7047. Views and conclusions contained in this paper are those of the authors, and should not be interpreted as representing the official opinion or policy of the sponsoring agencies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. MacGregor and R. Bates, </author> <title> "The loom knowledge representation language," </title> <type> Technical Report ISI/RS-87-188, </type> <institution> USC/Information Sciences Institute, </institution> <year> 1987. </year>
Reference: [2] <author> P. F. Patel-Schneider, B. Owsnicki-Klewe, A. Kobsa, N. Guarino, R. MacGregor, W. S. Mark, D. McGuinness, B. Nebel, A. Schmiedel, and J. Yen, </author> <title> "Term subsumption languages in knowledge representation," </title> <journal> AI Magazine, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 16-23, </pages> <year> 1990. </year>
Reference: [3] <author> R. Brachman and J. Schmolze, </author> <title> "An overview of the KL-ONE knowledge representation system," </title> <journal> Cognitive Science, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 171-216, </pages> <month> August </month> <year> 1985. </year> <month> 19 </month>
Reference: [4] <author> W. A. Woods, </author> <title> "Whats's in a link: Foundations for semantic networks," </title> <booktitle> In Representation and Understanding: Studies in Cognitive Science, </booktitle> <editor> D. Bobrow and A. Collins, editors, </editor> <publisher> Academic Press, </publisher> <year> 1975. </year>
Reference: [5] <author> R. J. Brachman, </author> <title> "What is-a is and isn't: An analysis of taxonomic links in semantic networks," </title> <journal> Computer, </journal> <volume> vol. 16, no. 10, </volume> <pages> pp. 30-36, </pages> <month> October </month> <year> 1983. </year>
Reference: [6] <author> R. M. MacGregor, </author> <title> "A deductive pattern matcher," </title> <booktitle> In Proceedings of AAAI-88, </booktitle> <year> 1988. </year>
Reference-contexts: 1 We use the syntax of LOOM knowledge representation system <ref> [6] </ref> to define concepts and relations in this paper. 3 rule-based systems that critics have identified as hindering system maintenance and limiting the ability to generate high-quality explanations and justifications [8, 9]. <p> Therefore, an efficient semantic pattern matcher can be implemented by integrating the realizer with an efficient pattern matching algorithm (e.g., RETE match algorithm). 8 C.1 The CONCRETE Matching Network The semantic pattern matcher in CLASP is implemented by combining Forgy's Rete matching algorithm [20] with the deductive matcher of LOOM <ref> [6] </ref>, which is a counterpart of Vilain's KL-TWO's realizer [14]. The rule compiler builds a CONcept Classification RETE (CONCRETE) net as rules are loaded into the rule base.
Reference: [7] <author> J. Schmolze and T. Lipkis, </author> <title> "Classification in the KL-ONE knowledge representation system," </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 330-332. IJCAI, </pages> <year> 1983. </year>
Reference-contexts: Examples of normalized rules can be found in Figure 9. Normalizing a pattern is analogous to completing a concept definition in KL-ONE's classifier <ref> [7] </ref>. Both of them attempt to compute the deductive closure of the objects to be classified before actually classifying them for the same reason: to gain efficiency for the subsumption test. The actual algorithm for normalizing patterns depends on the language used for defining terms.
Reference: [8] <author> W. Swartout, "XPLAIN: </author> <title> A system for creating and explaining expert consulting systems," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 21, no. 3, </volume> <pages> pp. 285-325, </pages> <month> September </month> <year> 1983. </year>
Reference-contexts: 1 We use the syntax of LOOM knowledge representation system [6] to define concepts and relations in this paper. 3 rule-based systems that critics have identified as hindering system maintenance and limiting the ability to generate high-quality explanations and justifications <ref> [8, 9] </ref>. First, rules fail to explicitly separate different kinds of knowledge; different clauses in the same rule may implicitly serve to represent contexts, affect control, or capture structural knowledge [10, 11].
Reference: [9] <author> R. Neches, W. Swartout, , and J. Moore, </author> <title> "Enhanced maintenance and explanation of expert systems through explicit models of their development," </title> <journal> Transactions On Software Engineering, </journal> <volume> vol. SE-11, no. 11, </volume> <pages> pp. 1337-1351, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: 1 We use the syntax of LOOM knowledge representation system [6] to define concepts and relations in this paper. 3 rule-based systems that critics have identified as hindering system maintenance and limiting the ability to generate high-quality explanations and justifications <ref> [8, 9] </ref>. First, rules fail to explicitly separate different kinds of knowledge; different clauses in the same rule may implicitly serve to represent contexts, affect control, or capture structural knowledge [10, 11].
Reference: [10] <author> W. Clancey, </author> <title> "The epistemology of a rule-based expert system: A framework for explanation," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 20, no. 3, </volume> <pages> pp. 215-251, </pages> <month> May </month> <year> 1983. </year>
Reference-contexts: First, rules fail to explicitly separate different kinds of knowledge; different clauses in the same rule may implicitly serve to represent contexts, affect control, or capture structural knowledge <ref> [10, 11] </ref>. Because the intent behind them is unclear, it is hard to explain rules and difficult to determine how to correctly add or revise them. Second, the meaning of the terminology used by the rules is often ill-defined [12].
Reference: [11] <author> J. S. Aikins, </author> <title> "Prototypes and production rules: A knowledge representation for computer consultations," </title> <type> Technical Report STAN-CS-80-814, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1980. </year>
Reference-contexts: First, rules fail to explicitly separate different kinds of knowledge; different clauses in the same rule may implicitly serve to represent contexts, affect control, or capture structural knowledge <ref> [10, 11] </ref>. Because the intent behind them is unclear, it is hard to explain rules and difficult to determine how to correctly add or revise them. Second, the meaning of the terminology used by the rules is often ill-defined [12].
Reference: [12] <author> W. Swartout and R. Neches, </author> <title> "The shifting terminological space: An impediment to evolvability," </title> <booktitle> In AAAI-86, Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> Philadelphia, PA, </address> <month> August </month> <year> 1986, </year> <note> AAAI. </note>
Reference-contexts: Because the intent behind them is unclear, it is hard to explain rules and difficult to determine how to correctly add or revise them. Second, the meaning of the terminology used by the rules is often ill-defined <ref> [12] </ref>. This makes it difficult to determine when rules are, or should be, relevant to some shared abstraction which, in turn, makes it difficult to find and change abstractions. Third, it is difficult to structure a large set of rules [13].
Reference: [13] <author> R. Fikes and T. Kehler, </author> <title> "The role of frame-based representation in reasoning," </title> <journal> Communication of the ACM, </journal> <volume> vol. 28, no. 9, </volume> , <month> September </month> <year> 1985. </year>
Reference-contexts: This makes it difficult to determine when rules are, or should be, relevant to some shared abstraction which, in turn, makes it difficult to find and change abstractions. Third, it is difficult to structure a large set of rules <ref> [13] </ref>. This makes it difficult to decompose the set into smaller, more comprehensible and maintainable subsets. This paper will focus on two components of the CLASP architecture that serve to alleviate these problems. <p> II. Related Work KEE, ART, and Knowledge Craft combine frames and rules, but do not support automatic classifiers. Thus, the frames provide a vocabulary that can be used within the rules, and a means for partitioning, indexing, and organizing rules <ref> [13] </ref>. But the pattern matching process can not avail itself of terminological inferences and the burden of correctly maintaining the frame hierarchy falls totally upon the user. KL-TWO also provides a noticer mechanism for users to define demons that get executed when their conditions are met [14].
Reference: [14] <author> M. Vilain, "Kl-two, </author> <title> a hybrid knowledge representation system," </title> <type> Technical Report 5694, </type> <institution> Bolt Be-ranak and Newman, </institution> <month> September </month> <year> 1984. </year> <month> 20 </month>
Reference-contexts: But the pattern matching process can not avail itself of terminological inferences and the burden of correctly maintaining the frame hierarchy falls totally upon the user. KL-TWO also provides a noticer mechanism for users to define demons that get executed when their conditions are met <ref> [14] </ref>. Although the noticer has improved the expressive power and control of demons, it lacks a global control mechanism like the recognize-act cycle of production systems. Moreover, the 4 noticer does not fully support matching facility for conjunctive patterns. <p> by integrating the realizer with an efficient pattern matching algorithm (e.g., RETE match algorithm). 8 C.1 The CONCRETE Matching Network The semantic pattern matcher in CLASP is implemented by combining Forgy's Rete matching algorithm [20] with the deductive matcher of LOOM [6], which is a counterpart of Vilain's KL-TWO's realizer <ref> [14] </ref>. The rule compiler builds a CONcept Classification RETE (CONCRETE) net as rules are loaded into the rule base.
Reference: [15] <author> W. Mark, </author> <title> "Rule-based inference in large knowledge bases," </title> <booktitle> In Proceedings of the National Confer--ence on Artificial Intelligence. AAAI, </booktitle> <month> August </month> <year> 1980. </year>
Reference-contexts: Although the noticer has improved the expressive power and control of demons, it lacks a global control mechanism like the recognize-act cycle of production systems. Moreover, the 4 noticer does not fully support matching facility for conjunctive patterns. CONSUL <ref> [15, 16] </ref> was the first attempt to integrate rules into a term subsumption system.
Reference: [16] <author> W. Mark, </author> <title> "Representation and inference in the consul system," </title> <booktitle> In Proceedings of the Seventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 375-381. </pages> <publisher> IJCAI, Morgan Kaufman, </publisher> <year> 1981. </year>
Reference-contexts: Although the noticer has improved the expressive power and control of demons, it lacks a global control mechanism like the recognize-act cycle of production systems. Moreover, the 4 noticer does not fully support matching facility for conjunctive patterns. CONSUL <ref> [15, 16] </ref> was the first attempt to integrate rules into a term subsumption system.
Reference: [17] <author> A. Kobsa, </author> <title> "The sb-one knowledge representation workbench," </title> <booktitle> In Proceedings of the Workshop on Formal Aspects of Semantic Networks, </booktitle> <month> February </month> <year> 1989. </year>
Reference-contexts: Similar transformation rules have also been used to map linguistic structures to domain-specific knowledge in an natural language application built using SB-ONE <ref> [17] </ref>. Built in NIKL [18], CONSUL used its classifier to match data with rules. It also used the taxonomic structure of its knowledge base to infer specificity relations between rules. However, its inference architecture and rule language were not as general as that of a production system.
Reference: [18] <author> M. Moser, </author> <title> "An overview of NIKL, the new implementation of KL-ONE," </title> <booktitle> In Research in Natural Language Understanding, </booktitle> <institution> Bolt, Beranek, and Newman, Inc., </institution> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: Similar transformation rules have also been used to map linguistic structures to domain-specific knowledge in an natural language application built using SB-ONE [17]. Built in NIKL <ref> [18] </ref>, CONSUL used its classifier to match data with rules. It also used the taxonomic structure of its knowledge base to infer specificity relations between rules. However, its inference architecture and rule language were not as general as that of a production system.
Reference: [19] <author> T. Daly, J. Kastner, and E. Mays, </author> <title> "Integrating rules and inheritance networks in a knowledge based financial marketing consultation system," </title> <booktitle> In Hawaii Int. conf. on System Science, </booktitle> <month> January </month> <year> 1988. </year>
Reference-contexts: Moreover, due to the limitations of NIKL, CONSUL could only operate upon class concepts and could not match rules against data instances. An integration of rules and inheritance networks has also been reported in <ref> [19] </ref>. III. A Classification-based Production System CLASP extends the rule-based paradigm by taking advantage of terminological knowledge and classification reasoning in term subsumption systems. A.
Reference: [20] <author> C. L. Forgy, </author> <title> "Rete: A fast algorithm for the many pattern/many object pattern match problem," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 19, </volume> <pages> pp. 17-37, </pages> <year> 1982. </year>
Reference-contexts: Therefore, an efficient semantic pattern matcher can be implemented by integrating the realizer with an efficient pattern matching algorithm (e.g., RETE match algorithm). 8 C.1 The CONCRETE Matching Network The semantic pattern matcher in CLASP is implemented by combining Forgy's Rete matching algorithm <ref> [20] </ref> with the deductive matcher of LOOM [6], which is a counterpart of Vilain's KL-TWO's realizer [14]. The rule compiler builds a CONcept Classification RETE (CONCRETE) net as rules are loaded into the rule base.
Reference: [21] <author> J. Yen, </author> <title> "A principled approach to reasoning about the specificity of rules," </title> <booktitle> In Proc. National Conf. on Artificial Intelligence, </booktitle> <pages> pp. 701-707, </pages> <address> Boston, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: D. The Pattern Classifier The pattern classifier organizes patterns into a lattice where more specific patterns are below more general ones, based on the definitions of terms referred to in the patterns. Using the pattern classifier, CLASP can compute a well-defined specificity relation between rules during compile time <ref> [21] </ref>. Specificity is a classic conflict resolution heuristic used by many production system languages (e.g., OPS5) [22]. In addition, common sense reasoning often relies on the specificity of a rule's antecedents to override conclusions drawn by more general rules when they contradict the more specific rule.
Reference: [22] <author> J. McDermott and C. Forgy, </author> <title> "Production system conflict resolution strategies," In Pattern-Directed Inference Systems, </title> <editor> D. A. Waterman and F. Hayes-Roth, editors, </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: Using the pattern classifier, CLASP can compute a well-defined specificity relation between rules during compile time [21]. Specificity is a classic conflict resolution heuristic used by many production system languages (e.g., OPS5) <ref> [22] </ref>. In addition, common sense reasoning often relies on the specificity of a rule's antecedents to override conclusions drawn by more general rules when they contradict the more specific rule.
Reference: [23] <author> J. Yen, </author> <title> "Reasoning about the specificity of patterns in term subsumption-based systems," </title> <type> Technical Report TAMU 90-003, </type> <institution> Department of Computer Science, Texas A&M University, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: substitution that replaces variables of p 1 by p 2 's variables or constants such that p 2 terminologically implies p 1 based on the terminological knowledge base T , i.e., p 1 -p 2 iff 9 such that p 2 T Proof of the theorem can be found in <ref> [23] </ref>. 3 A more formal definition of pattern instantiation can be found in [23]. 10 P1: (:and (father ?x ?y) (father ?x ?z) ) P2: (father ?u ?v) The subsumption substitution S can also be viewed as a mapping because it maps each of p 1 's variables to a variable <p> constants such that p 2 terminologically implies p 1 based on the terminological knowledge base T , i.e., p 1 -p 2 iff 9 such that p 2 T Proof of the theorem can be found in <ref> [23] </ref>. 3 A more formal definition of pattern instantiation can be found in [23]. 10 P1: (:and (father ?x ?y) (father ?x ?z) ) P2: (father ?u ?v) The subsumption substitution S can also be viewed as a mapping because it maps each of p 1 's variables to a variable or a constant in pattern p 2 . <p> If a mapping that satisfies all the constraints is found, the subsumption test returns true. Otherwise, it returns false. H. Discussion We have shown elsewhere that CLASP's pattern classification algorithm is sound <ref> [23] </ref>. It is also complete for a simple term subsumption language whose expressiveness is equivalent to that of F L in [24]. Further discussions on the issues regarding soundness and completeness of the subsumption algorithm can be found in [23]. <p> We have shown elsewhere that CLASP's pattern classification algorithm is sound <ref> [23] </ref>. It is also complete for a simple term subsumption language whose expressiveness is equivalent to that of F L in [24]. Further discussions on the issues regarding soundness and completeness of the subsumption algorithm can be found in [23]. Determining the subsumption of normalized conjunctive patterns is NP-complete, for it can be reduced from the problem of determining subgraph isomorphism for directed graphs, which is known to be NP-complete [25]. However, worst case rarely occur in practice. <p> However, worst case rarely occur in practice. To analyze the behavior of an algorithm in reality, we have defined normal cases 4 and have shown that the complexity of the algorithm for normal cases is polynomial <ref> [23] </ref>. Brachman and Levesque have demonstrated that there is an important tradeoff between the expressiveness of a terminological language and the complexity of its reasoner [24]. A similarly tradeoff between the computational complexity of the normalization process and the expressiveness of the terminological language has also been investigated [23]. IV. <p> is polynomial <ref> [23] </ref>. Brachman and Levesque have demonstrated that there is an important tradeoff between the expressiveness of a terminological language and the complexity of its reasoner [24]. A similarly tradeoff between the computational complexity of the normalization process and the expressiveness of the terminological language has also been investigated [23]. IV. Summary We have presented the general architecture and an implementation of a CLASsification-based Production system (CLASP). Our main objective is to extend the benefits of classification capabilities in frame systems to the developers of rule-based systems.
Reference: [24] <author> R. J. Brachman and H. J. Levesque, </author> <title> "The tractability of subsumption in frame-based description languages," </title> <booktitle> In Proceedings of AAAI-84, </booktitle> <pages> pp. 34-37, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Otherwise, it returns false. H. Discussion We have shown elsewhere that CLASP's pattern classification algorithm is sound [23]. It is also complete for a simple term subsumption language whose expressiveness is equivalent to that of F L in <ref> [24] </ref>. Further discussions on the issues regarding soundness and completeness of the subsumption algorithm can be found in [23]. Determining the subsumption of normalized conjunctive patterns is NP-complete, for it can be reduced from the problem of determining subgraph isomorphism for directed graphs, which is known to be NP-complete [25]. <p> Brachman and Levesque have demonstrated that there is an important tradeoff between the expressiveness of a terminological language and the complexity of its reasoner <ref> [24] </ref>. A similarly tradeoff between the computational complexity of the normalization process and the expressiveness of the terminological language has also been investigated [23]. IV. Summary We have presented the general architecture and an implementation of a CLASsification-based Production system (CLASP).
Reference: [25] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability A Guide to the Theory of NP-Completeness, </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <institution> Cal., </institution> <year> 1979. </year>
Reference-contexts: Further discussions on the issues regarding soundness and completeness of the subsumption algorithm can be found in [23]. Determining the subsumption of normalized conjunctive patterns is NP-complete, for it can be reduced from the problem of determining subgraph isomorphism for directed graphs, which is known to be NP-complete <ref> [25] </ref>. However, worst case rarely occur in practice. To analyze the behavior of an algorithm in reality, we have defined normal cases 4 and have shown that the complexity of the algorithm for normal cases is polynomial [23].
Reference: [26] <author> B. Nebel, </author> <title> "Terminological reasoning is inherently intractable," </title> <type> Technical Report IWBS Report 82, </type> <institution> IWBS, IBM Deutschland, W. Germany, </institution> <month> October </month> <year> 1989. </year> <month> 21 </month>
Reference-contexts: First, the pattern matching operation is based on the terminological definitions of the 4 Using normal cases to analyze the complexity of intractable algorithm has been suggested by Bernard Nebel <ref> [26] </ref>. 18 symbols, not just the symbols themselves. Second, conflict resolution can be based on a well-defined specificity relationship between rules, which is computed by a pattern classifier using terminological knowledge and the subsumption lattice precomputed by its classifier.
References-found: 26

