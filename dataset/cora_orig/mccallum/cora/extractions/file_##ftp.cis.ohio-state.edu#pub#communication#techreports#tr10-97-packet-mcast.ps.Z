URL: file://ftp.cis.ohio-state.edu/pub/communication/techreports/tr10-97-packet-mcast.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/wormhole_pub.html
Root-URL: 
Title: Optimal Multicast with Packetization and Network Interface Support  
Abstract: Ram Kesavan and Dhabaleswar K. Panda Technical Report OSU-CISRC-2/97-TR10 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> The SP2 Communication Subsystem. </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: In modern networks, the size of the maximum packet is limited to minimize network contention and support efficient buffer utilization of buffer spaces both in the network and at the network interfaces. Therefore, long messages are broken up and transmitted as multiple packets. Such networks <ref> [1, 2, 4, 9] </ref> provide network interface support associated with each node. Such support, which includes a coprocessor and a small amount of memory, implements the lower layers of the communication protocol. <p> Such support, which includes a coprocessor and a small amount of memory, implements the lower layers of the communication protocol. This is not just true of workstations on a NOW, but even on high performance systems like the CrayT3D [9] and IBM SP2 <ref> [1] </ref>. This leads to a challenge for designing optimal multicast algorithms under packetization using network interface support. Recently, a solution for implementing multicast under packetization has been proposed in [8]. However, this work assumes that packetization is handled by the host processor which sends and receives messages packet by packet. <p> Typically, the maximum packet size is dictated by the design of the network and the associated communication protocol. For example, the packet size of the IBM SP2 is 256 bytes <ref> [1] </ref>, and Fast Messages on Myrinet has a packet size of 128 bytes [24]. The sender is responsible for fragmenting the message and sending out the individual packets into the network. The packets are routed as individual messages to the destination depending on the routing information contained in the headers. <p> System level support involves host processors at the sender and receiver sides executing some software to accomplish the above tasks. Such support is inefficient due to the large overheads of software execution, buffer copying, and loss of computing time at the host processor. To improve performance, modern network systems <ref> [1, 2, 4, 9] </ref> provide network interface associated with each node. <p> Therefore, finding the optimal multicast tree for an m-packet multicast reduces to 17 finding the d which produces the minimum value for the expression L + (m 1)d. It can also be easily observed that this optimal value of d lies in the interval <ref> [1; dlog 2 ne] </ref>. Definition 2 A k-binomial tree is defined as a recursively doubling tree where no vertex has more than k children.
Reference: [2] <author> ATM Forum. </author> <title> ATM User-Network Interface Specification, </title> <note> Version 3.1, </note> <month> September </month> <year> 1994. </year>
Reference-contexts: In modern networks, the size of the maximum packet is limited to minimize network contention and support efficient buffer utilization of buffer spaces both in the network and at the network interfaces. Therefore, long messages are broken up and transmitted as multiple packets. Such networks <ref> [1, 2, 4, 9] </ref> provide network interface support associated with each node. Such support, which includes a coprocessor and a small amount of memory, implements the lower layers of the communication protocol. <p> System level support involves host processors at the sender and receiver sides executing some software to accomplish the above tasks. Such support is inefficient due to the large overheads of software execution, buffer copying, and loss of computing time at the host processor. To improve performance, modern network systems <ref> [1, 2, 4, 9] </ref> provide network interface associated with each node.
Reference: [3] <author> M. Barnett, S. Gupta, D. G. Payne, L. Shuler, R. van de Geijn, and J. Watts. </author> <title> Interprocessor Collective Communication Library (Intercom). </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 357-364, </pages> <year> 1994. </year>
Reference: [4] <author> N. J. Boden, D. Cohen, and et al. Myrinet: </author> <title> A Gigabit-per-Second Local Area Network. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 29-35, </pages> <month> Feb </month> <year> 1995. </year>
Reference-contexts: In modern networks, the size of the maximum packet is limited to minimize network contention and support efficient buffer utilization of buffer spaces both in the network and at the network interfaces. Therefore, long messages are broken up and transmitted as multiple packets. Such networks <ref> [1, 2, 4, 9] </ref> provide network interface support associated with each node. Such support, which includes a coprocessor and a small amount of memory, implements the lower layers of the communication protocol. <p> System level support involves host processors at the sender and receiver sides executing some software to accomplish the above tasks. Such support is inefficient due to the large overheads of software execution, buffer copying, and loss of computing time at the host processor. To improve performance, modern network systems <ref> [1, 2, 4, 9] </ref> provide network interface associated with each node. <p> In the figures, the number in brackets indicates the 10 step number, and the subscript indicates the packet number being transmitted. For example <ref> [4] </ref> 2 indicates the second packet being transmitted in the fourth time step. It can be easily observed that the binomial tree takes 6 steps and the linear tree takes 5 steps.
Reference: [5] <author> R. V. Boppana, S. Chalasani, and C. S. Raghavendra. </author> <title> On Multicast Wormhole Routing in Multicomputer Networks. </title> <booktitle> In Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 722-729, </pages> <year> 1994. </year>
Reference: [6] <author> Y. M. Boura and C. R. Das. </author> <title> Modeling Virtual Channel Flow Control in Hypercubes. </title> <booktitle> In International Symposium on High Performance Computer Architecture, </booktitle> <pages> pages 166-175, </pages> <year> 1995. </year>
Reference: [7] <author> C.-M. Chiang and L. M. Ni. </author> <title> Efficient Software Multicast in Wormhole-routed Unidirec tional Multistage Networks. </title> <booktitle> In Symposium on Parallel and Distributed Processing, </booktitle> <year> 1995. </year>
Reference: [8] <author> L. De Coster, N. Dewulf, and C.-T. Ho. </author> <title> Efficient Multi-packet Multicast Algorithms on Meshes with Wormhole and Dimension-Ordered Routing. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages III:137-141, </pages> <month> Aug </month> <year> 1995. </year>
Reference-contexts: This leads to a challenge for designing optimal multicast algorithms under packetization using network interface support. Recently, a solution for implementing multicast under packetization has been proposed in <ref> [8] </ref>. However, this work assumes that packetization is handled by the host processor which sends and receives messages packet by packet. Moreover, this framework assumes user/system control over determining optimal packet size for a given multicast set and message length.
Reference: [9] <author> Cray Research, Inc. </author> <title> Cray T3D System Architecture Overview, </title> <year> 1993. </year>
Reference-contexts: In modern networks, the size of the maximum packet is limited to minimize network contention and support efficient buffer utilization of buffer spaces both in the network and at the network interfaces. Therefore, long messages are broken up and transmitted as multiple packets. Such networks <ref> [1, 2, 4, 9] </ref> provide network interface support associated with each node. Such support, which includes a coprocessor and a small amount of memory, implements the lower layers of the communication protocol. <p> Such support, which includes a coprocessor and a small amount of memory, implements the lower layers of the communication protocol. This is not just true of workstations on a NOW, but even on high performance systems like the CrayT3D <ref> [9] </ref> and IBM SP2 [1]. This leads to a challenge for designing optimal multicast algorithms under packetization using network interface support. Recently, a solution for implementing multicast under packetization has been proposed in [8]. <p> System level support involves host processors at the sender and receiver sides executing some software to accomplish the above tasks. Such support is inefficient due to the large overheads of software execution, buffer copying, and loss of computing time at the host processor. To improve performance, modern network systems <ref> [1, 2, 4, 9] </ref> provide network interface associated with each node.
Reference: [10] <author> J. Duato. </author> <title> A New Theory of Deadlock-Free Adaptive Routing in Wormhole Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(12) </volume> <pages> 1320-1331, </pages> <year> 1993. </year> <month> 23 </month>
Reference: [11] <author> J. Duato. </author> <title> A Theory of Deadlock-Free Adaptive Multicast Routing in Wormhole Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <pages> pages 976-987, </pages> <month> September </month> <year> 1995. </year>
Reference: [12] <author> T. V. Eicken, A. Basu, V. Buch, and W. Vogels. U-Net: </author> <title> A User-level Network Interface for Parallel and Distributed Computing. </title> <booktitle> In ACM Symposium on Operating Systems Principles, </booktitle> <year> 1995. </year>
Reference-contexts: In recent implementations of high performance messaging systems, there has been a trend of circumventing the operating system and providing applications direct access of the network device <ref> [12, 20, 24] </ref>. This has been done to reduce the send and receive overheads for messaging, so that the low latencies and high bandwidths required for cluster computing can be achieved. The programmable coprocessor at the network interface controls the actual sending and receiving of the messages. <p> Alternatively, the host processor can copy data into the DMA region, and write the message pointers to the network interface for the coprocessor to DMA the packets to the send queue <ref> [12] </ref>. Subsequently, the software executing at the coprocessor detects entries in the send queue, and sends the packets out to the network channel.
Reference: [13] <author> Y. Huang and P. K. McKinley. </author> <title> Efficient Collective Operations with ATM Network Interface Support. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, pages I:34-43, </booktitle> <address> Chicago, IL, </address> <month> Aug </month> <year> 1996. </year>
Reference-contexts: Thus, this result is not applicable for systems with fixed packet lengths and for systems with network interface support for packetization. Some recent research focus on implementing efficient collective communication operations on a NOW over ATM using the network interface support <ref> [13] </ref>. Since ATM switches provide hardware multicast capability, the network interface support in this work is primarily is geared towards achieving reliable multicast over the unreliable ATM layer. A recent work [28] describes an implementation of packetized multicast over the Myrinet network interface.
Reference: [14] <author> S. L. Johnsson and C.-T. Ho. </author> <title> Optimum Broadcasting and Personalized Communication in Hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 1249-1268, </pages> <month> September </month> <year> 1989. </year>
Reference: [15] <author> R. Kesavan, K. Bondalapati, and D. K. Panda. </author> <title> Multicast on Irregular Switch-based Net works with Wormhole Routing. </title> <booktitle> In Proceedings of the Int'l Symposium on High Performace Computer Architecture (HPCA-3), </booktitle> <year> 1997. </year> <note> accepted to be presented. </note>
Reference-contexts: This construction can be applied to different types of contention-free ordered chains. For k-ary n-cubes, the dimension-ordered chain [22] can be used to construct contention-free k-binomial trees. For irregular switch-based networks with no complete contention-free ordering, the concept of a POC <ref> [15] </ref> can be used to construct k-binomial trees with minimal contention.
Reference: [16] <author> R. Kesavan and D. K. Panda. </author> <title> Minimizing Node Contention in Multiple Multicast on Worm hole k-ary n-cube Networks. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, pages I:188-195, </booktitle> <address> Chicago, IL, </address> <month> Aug </month> <year> 1996. </year>
Reference: [17] <author> Y. Lan, A.-H. Esfahanian, and L. Ni. </author> <title> Multicast in Hypercube Multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 30-41, </pages> <year> 1990. </year>
Reference: [18] <author> X. Lin and L. M. Ni. </author> <title> Multicast Communication in Multicomputer Networks. </title> <booktitle> In Interna tional Conference on Parallel Processing, </booktitle> <pages> pages 114-118, </pages> <year> 1990. </year>
Reference: [19] <author> X. Lin and L. M. Ni. </author> <title> Deadlock-free Multicast Wormhole Routing in Multicomputer Net works. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 116-124, </pages> <year> 1991. </year>
Reference: [20] <author> R. P. Martin. HPAM: </author> <title> An Active Message Layer for a Network of HP Workstations. </title> <booktitle> In Proceedings of the Hot Interconnectes Symposium, </booktitle> <year> 1994. </year>
Reference-contexts: In recent implementations of high performance messaging systems, there has been a trend of circumventing the operating system and providing applications direct access of the network device <ref> [12, 20, 24] </ref>. This has been done to reduce the send and receive overheads for messaging, so that the low latencies and high bandwidths required for cluster computing can be achieved. The programmable coprocessor at the network interface controls the actual sending and receiving of the messages.
Reference: [21] <author> P. K. McKinley and D. F. Robinson. </author> <title> Collective Communication in Wormhole-Routed Massively Parallel Computers. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 39-50, </pages> <month> Dec </month> <year> 1995. </year>
Reference-contexts: Parallel systems supporting distributed memory or distributed-shared memory programming paradigms require fast implementation of multicast and broadcast operations in order to support various application and system level data distribution functions. Multicast and broadcast also get used for other collective communication operations like barrier synchronization and global combining <ref> [21, 25] </ref>. There have been many multicast/broadcast algorithms proposed in the literature in recent years [3, 5, 10, 11, 14, 15, 16, 19, 22, 26, 6, 5, 7, 27, 17, 18]. All these algorithms are designed assuming arbitrarily long single packet messages.
Reference: [22] <author> P. K. McKinley, H. Xu, A.-H. Esfahanian, and L. M. Ni. </author> <title> Unicast-based Multicast Com munication in Wormhole-routed Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(12) </volume> <pages> 1252-1265, </pages> <month> Dec </month> <year> 1994. </year> <month> 24 </month>
Reference-contexts: In order to derive the optimal multicast tree the properties of the FPFS implementation are studied to calculate multicast latency. Then, a new concept of k-binomial tree is defined and shown to be optimal for multi-packet multicast. The concept of a contention-free ordering of nodes has been developed in <ref> [22] </ref> to implement contention-free multicast with minimum latency. We develop a method to construct contention-free k-binomial trees on a similar ordering. <p> Proof: Follows from the results of Lemma 3 and Theorem 2. 18 nodes in the ith subtree from right is given by N (s i; k). 4.4 Constructing Contention-free k-binomial Trees For optimal multi-packet multicast performance, the multicast tree should be depth contention-free <ref> [22] </ref>. This means that the paths that the tree edges get mapped to in the network should be edge-disjoint with respect to each other. The concept of a contention free ordering of nodes in a system has been used to construct contention-free binomial trees [22]. <p> multicast tree should be depth contention-free <ref> [22] </ref>. This means that the paths that the tree edges get mapped to in the network should be edge-disjoint with respect to each other. The concept of a contention free ordering of nodes in a system has been used to construct contention-free binomial trees [22]. The same concept can be used to construct contention-free k-binomial trees. Let the N (s; k) participating nodes of a multicast be ordered in a contention free ordered chain. Let the symbol &lt; d denote the ordering. A contention free ordering has the following property. <p> Similarly, the source sends messages to each of k nodes. The intermediate nodes, like a and b cover the destinations to their right by building k-binomial trees in a recursive fashion. This construction can be applied to different types of contention-free ordered chains. For k-ary n-cubes, the dimension-ordered chain <ref> [22] </ref> can be used to construct contention-free k-binomial trees. For irregular switch-based networks with no complete contention-free ordering, the concept of a POC [15] can be used to construct k-binomial trees with minimal contention.
Reference: [23] <author> Message Passing Interface Forum. </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> Mar </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Multicast/broadcast is a common collective communication operation as defined by the MPI standard <ref> [23] </ref>. Parallel systems supporting distributed memory or distributed-shared memory programming paradigms require fast implementation of multicast and broadcast operations in order to support various application and system level data distribution functions. Multicast and broadcast also get used for other collective communication operations like barrier synchronization and global combining [21, 25].
Reference: [24] <author> S. Pakin, M. Lauria, and A. Chien. </author> <title> High Performance Messaging on Workstations: Illinois Fast Messages (FM). </title> <booktitle> In Proceedings of the Supercomputing, </booktitle> <year> 1995. </year>
Reference-contexts: Typically, the maximum packet size is dictated by the design of the network and the associated communication protocol. For example, the packet size of the IBM SP2 is 256 bytes [1], and Fast Messages on Myrinet has a packet size of 128 bytes <ref> [24] </ref>. The sender is responsible for fragmenting the message and sending out the individual packets into the network. The packets are routed as individual messages to the destination depending on the routing information contained in the headers. <p> In recent implementations of high performance messaging systems, there has been a trend of circumventing the operating system and providing applications direct access of the network device <ref> [12, 20, 24] </ref>. This has been done to reduce the send and receive overheads for messaging, so that the low latencies and high bandwidths required for cluster computing can be achieved. The programmable coprocessor at the network interface controls the actual sending and receiving of the messages. <p> At the sender side, one of two schemes can be used. One, the library at the sender host processor can fragment the message into fixed size packets, and transfer them to the send queue of the network interface <ref> [24] </ref>. Alternatively, the host processor can copy data into the DMA region, and write the message pointers to the network interface for the coprocessor to DMA the packets to the send queue [12].
Reference: [25] <author> D. K. Panda. </author> <title> Issues in Designing Efficient and Practical Algorithms for Collective Com munication in Wormhole-Routed Systems. </title> <booktitle> In 1995 Workshop on Challenges for Parallel Processing, </booktitle> <pages> pages 8-15, </pages> <year> 1995. </year>
Reference-contexts: Parallel systems supporting distributed memory or distributed-shared memory programming paradigms require fast implementation of multicast and broadcast operations in order to support various application and system level data distribution functions. Multicast and broadcast also get used for other collective communication operations like barrier synchronization and global combining <ref> [21, 25] </ref>. There have been many multicast/broadcast algorithms proposed in the literature in recent years [3, 5, 10, 11, 14, 15, 16, 19, 22, 26, 6, 5, 7, 27, 17, 18]. All these algorithms are designed assuming arbitrarily long single packet messages.
Reference: [26] <author> D. K. Panda, S. Singal, and P. Prabhakaran. </author> <title> Multidestination Message Passing Mechanism Conforming to Base Wormhole Routing Scheme. </title> <type> Technical Report OSU-CISRC-6/94-TR33, </type> <institution> Dept. of Computer and Information Science, The Ohio State University, </institution> <year> 1994. </year>
Reference: [27] <author> J. Y. L. Park, H. A. Choi, N. Nupairoj, and L. M. Ni. </author> <title> Construction of Optimal Mul ticast Trees Based on the Parameterized Communication Model. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <address> Chicago, IL, </address> <month> Aug </month> <year> 1996. </year>
Reference: [28] <author> K. Verstoep, K. Langendoen, and H. Bal. </author> <title> Efficient Reliable Multicast on Myrinet. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages III:156-165, </pages> <month> Aug </month> <year> 1996. </year>
Reference-contexts: Since ATM switches provide hardware multicast capability, the network interface support in this work is primarily is geared towards achieving reliable multicast over the unreliable ATM layer. A recent work <ref> [28] </ref> describes an implementation of packetized multicast over the Myrinet network interface. This work is also geared towards development of a reliable multicast communication layer and does not provide any formal multicast algorithms. <p> Therefore, there is need for larger buffering at the network interface. An example of such an implementation of a smart network interface has been described in <ref> [28] </ref>.
References-found: 28

