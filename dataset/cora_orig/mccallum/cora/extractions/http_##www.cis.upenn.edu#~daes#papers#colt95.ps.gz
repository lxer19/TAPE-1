URL: http://www.cis.upenn.edu/~daes/papers/colt95.ps.gz
Refering-URL: http://www.cis.upenn.edu/~daes/papers.html
Root-URL: 
Email: dale@cs.toronto.edu  greiner@scr.siemens.com  
Title: Sequential PAC Learning  
Author: Dale Schuurmans Russell Greiner 
Date: July 1995.  
Note: Appears in Proceedings of the Eighth ACM Conference on Computational Learning Theory (COLT-95),  
Address: Toronto, Ontario M5S 1A4, Canada  Princeton, NJ 08540, USA  Santa Cruz, CA,  
Affiliation: Department of Computer Science University of Toronto  Siemens Corporate Research  
Abstract: We consider the use of "on-line" stopping rules to reduce the number of training examples needed to pac-learn. Rather than collect a large training sample that can be proved sufficient to eliminate all bad hypotheses a priori, the idea is instead to observe training examples one-at-a-time and decide "on-line" whether to stop and return a hypothesis, or continue training. The primary benefit of this approach is that we can detect when a hypothesizer has actually "converged," and halt training before the standard fixed-sample-size bounds. This paper presents a series of such sequential learning procedures for: distribution-free pac-learning, "mistake-bounded to pac" conversion, and distribution-specific pac-learning, respectively. We analyze the worst case expected training sample size of these procedures, and show that this is often smaller than existing fixed sample size bounds | while providing the exact same worst case pac-guarantees. We also provide lower bounds that show these reductions can at best involve constant (and possibly log) factors. However, empirical studies show that these sequential learning procedures actually use many times fewer training examples in prac tice.
Abstract-found: 1
Intro-found: 1
Reference: [AKA91] <author> D. W. Aha, D. Kibler, and M. K. Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6(1) </volume> <pages> 37-66, </pages> <year> 1991. </year>
Reference-contexts: This motivates research that makes distributional assumptions in order to improve data-efficiency, e.g., <ref> [BI88a, Bau90, AKA91, BW91] </ref>. 3 However, there is a funda 1 Uniform convergence results assume the concept class C satisfies certain benign measurability restrictions. <p> Related work: Many authors have sought to improve the data-efficiency of pac-learning procedures, but gen erally by incorporating additional assumptions about the domain distribution, e.g., <ref> [Bau90, BW91, AKA91] </ref>. Our goal is to improve data-efficiency without making additional assumptions.
Reference: [Ash72] <author> R. B. Ash. </author> <title> Real Analysis and Probability. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1972. </year>
Reference-contexts: However, this can be bounded by E ln T H ln ET H , using Jensen's inequality and the fact that ln is concave; see e.g., <ref> [Ash72] </ref>. The rest follows from algebraic manipulation. fl Although this is a crude bound, it is interesting to note that it scales the same as T BEHW and T STAB . <p> Since p * by assumption, we have EZ &gt; 0 by Claim 10 below. Therefore, we get S t ! 1 wp1, since S t =t ! EZ wp1 by the law of large numbers <ref> [Ash72] </ref>.
Reference: [Bau90] <author> E. Baum. </author> <title> The perceptron algorithm is fast for nonmalicious distributions. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 248-260, </pages> <year> 1990. </year>
Reference-contexts: This motivates research that makes distributional assumptions in order to improve data-efficiency, e.g., <ref> [BI88a, Bau90, AKA91, BW91] </ref>. 3 However, there is a funda 1 Uniform convergence results assume the concept class C satisfies certain benign measurability restrictions. <p> Related work: Many authors have sought to improve the data-efficiency of pac-learning procedures, but gen erally by incorporating additional assumptions about the domain distribution, e.g., <ref> [Bau90, BW91, AKA91] </ref>. Our goal is to improve data-efficiency without making additional assumptions.
Reference: [BEHW89] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: E.g., for finite concept classes T finite (C; *; ffi) = 1 * ln ffi random training examples are sufficient to ensure F pac (*; ffi)-learns C. For infinite concept classes, Blumer et al. <ref> [BEHW89] </ref> use the results of Vapnik and Chervonenkis [VC71] to show that for any (well behaved 1 ) concept class C with vc (C) = d T BEHW (C; *; ffi) = max 8d 13 * log 2 ffi random examples are sufficient for Procedure F to solve (C; *; ffi).
Reference: [BH89] <author> E. B. Baum and D. Haussler. </author> <title> What size net gives valid generalization? Neural Computation, </title> <booktitle> 1 </booktitle> <pages> 151-160, </pages> <year> 1989. </year>
Reference-contexts: about 5 times smaller than T STAB , and 27 times smaller than T BEHW ! Moreover, this average was only 3 times larger than the empirical "rule of thumb" that w * training examples are needed to achieve * error, for a concept class defined by w free weights <ref> [BH89] </ref>. Not only do these results scale up well for harder problems (Figure 5), they are also robust to changes in the target concept, domain distribution, and concept class (with the same VCdimension) [SG95].
Reference: [BI88a] <author> G. Benedek and A. Itai. </author> <title> Learnability by fixed distributions. </title> <booktitle> In Proceedings COLT-88, </booktitle> <pages> pages 80-90, </pages> <year> 1988. </year>
Reference-contexts: Here we will consider two distinct models of prior knowledge: the distribution-free model [Val84], where the target concept c is known to belong to some class C, but nothing is known about the domain distribution P; and the distribution-specific model <ref> [BI88a, Kul91] </ref>, where the domain distribution P is known, but the target concept c is assumed only to belong to some class C. <p> This motivates research that makes distributional assumptions in order to improve data-efficiency, e.g., <ref> [BI88a, Bau90, AKA91, BW91] </ref>. 3 However, there is a funda 1 Uniform convergence results assume the concept class C satisfies certain benign measurability restrictions. <p> We show (Theorem 7) that Scov uses about 5 times fewer training examples (on aver age) than the fixed-sample-size procedure introduced in <ref> [BI88a] </ref>. However, a lower bound result (Theorem 8) shows that sequential learning does not increase the range of pac-learnable concept spaces. 1.4 Significance and related work Overall, these results show how one can achieve the standard pac-learning guarantees, while significantly reducing the number of training examples required in practice. <p> This is a significant practical savings, achieved without substantial additional computation. 3 Distribution-specific pac-learning We now consider the distribution-specific model, where the learner knows P and attempts to identify an unknown target concept c from some specified class C. This problem was thoroughly studied by Benedek and Itai <ref> [BI88a] </ref>, who developed a simple (collect; find) learning procedure BI for pac-learning concept spaces (C; P). <p> following inequality Pfd P (H T ; c) &gt; *g 1Pfd P (H t ; c) *gPfT &gt; tg: Thus, we seek upper bounds on each of these terms. (2) For any t, if ET t 2 then PfT &gt; tg 1 2 by Markov's inequality. (3) For any t, <ref> [BI88a, Lemma 5] </ref> shows that any hypoth esizer H is forced to obtain Pfd P (H t ; c 0 ) *g 2 t N 2* for some c 0 2 C.
Reference: [BI88b] <author> G. Benedek and A. Itai. </author> <title> Nonuniform learn-ability. </title> <booktitle> In Proceedings ICALP-88, </booktitle> <pages> pages 82-92, </pages> <year> 1988. </year>
Reference-contexts: Related work: Many authors have sought to improve the data-efficiency of pac-learning procedures, but gen erally by incorporating additional assumptions about the domain distribution, e.g., [Bau90, BW91, AKA91]. Our goal is to improve data-efficiency without making additional assumptions. While work on nonuniform pac-learning <ref> [BI88b, LMR91, Koi94] </ref> resembles the present study by also using "online" stopping rules, it has a fundamentally different aim: Our goal is to obtain a uniform improvement in data-efficiency for all target concepts c in C, whereas nonuniform pac-learning sacrifices data-efficiency for certain target concepts (late in a preference ranking C
Reference: [BW91] <author> P. L. Bartlett and R. C. Williamson. </author> <title> Investigating the distributional assumptions of the pac learning model. </title> <booktitle> In Proceedings COLT-91, </booktitle> <pages> pages 24-32, </pages> <year> 1991. </year>
Reference-contexts: This motivates research that makes distributional assumptions in order to improve data-efficiency, e.g., <ref> [BI88a, Bau90, AKA91, BW91] </ref>. 3 However, there is a funda 1 Uniform convergence results assume the concept class C satisfies certain benign measurability restrictions. <p> Related work: Many authors have sought to improve the data-efficiency of pac-learning procedures, but gen erally by incorporating additional assumptions about the domain distribution, e.g., <ref> [Bau90, BW91, AKA91] </ref>. Our goal is to improve data-efficiency without making additional assumptions.
Reference: [EHKV89] <author> A. Ehrenfeucht, D. Haussler, M. Kearns, and L. Valiant. </author> <title> A general lower bound on the number of examples needed for learning. </title> <journal> Information and Computation, </journal> <volume> 82 </volume> <pages> 247-261, </pages> <year> 1989. </year>
Reference-contexts: Chervonenkis [VC71] to show that for any (well behaved 1 ) concept class C with vc (C) = d T BEHW (C; *; ffi) = max 8d 13 * log 2 ffi random examples are sufficient for Procedure F to solve (C; *; ffi). 2 In addition, Ehrenfeucht et al. <ref> [EHKV89] </ref> have shown that no learning procedure can observe fewer than t EHKV (C; *; ffi) = max d1 * ln 1 random training examples and still meet the pac (*; ffi)-criterion for every target concept c 2 C and domain distribution P. <p> This involves generalizing the proof of <ref> [EHKV89, Theorem 1] </ref> to handle the fact that T might not terminate at the same time for every c 2 C. <p> This involves generalizing the proof of [EHKV89, Theorem 1] to handle the fact that T might not terminate at the same time for every c 2 C. Following <ref> [EHKV89] </ref>, we define a specific domain distribution P on a set of d objects fx 1 ; :::; x d g shattered by C: let Pfx 1 g = 1 8* and Pfx i g = 8* Let the r.v. <p> c) &gt; * fi T c &lt; U g We seek lower bounds on each of these terms. (2) For any P, t, and k &gt; 1, by Markov's inequality we know that if ET t k then PfT tg 1 1 k . (3) Given P defined as above, <ref> [EHKV89, Lemma 3] </ref> shows that PfU &gt; d1 32* g 1 e 1=12 &gt; 1 (4) Finally, for any learner L it can be shown that, given P defined as above, there must be some c 0 2 C for which Pf d P (H T ; c 0 ) &gt; <p> any learner L it can be shown that, given P defined as above, there must be some c 0 2 C for which Pf d P (H T ; c 0 ) &gt; * fi T c 0 &lt; U g 1 7 . (This involves generalizing the proof of <ref> [EHKV89, Lemma 2] </ref>; see [Sch95] for complete details.) Combining (1)-(4) shows that, for any k &gt; 1, if ET c d1 32k* for all c 2 C, then there must be some c 0 2 C for which Pfd P (H T ; c 0 ) &gt; *g 1 7 1
Reference: [HLL92] <author> D. Helmbold, N. Littlestone, and P. </author> <title> Long. Apple tasting and nearly one-sided learning. </title> <booktitle> In Proceedings FOCS-92, </booktitle> <pages> pages 493-502, </pages> <year> 1992. </year>
Reference-contexts: The real goal of nonuni form pac-learning is to increase the range of pac-learnable concept classes (e.g., to certain classes with infinite VCdimension), rather than improve data-efficiency on previously pac-learnable classes. 4 It is also important to distinguish our approach from on-line learning, e.g., <ref> [Lit89, LW89, HLL92] </ref>. On-line learning considers a "learning while doing" model which is fundamentally different from the "batch" paradigm considered here.
Reference: [Koi94] <author> P. Koiran. </author> <title> Efficient learning of continuous neural networks. </title> <booktitle> In Proceedings COLT-94, </booktitle> <pages> pages 348-355, </pages> <year> 1994. </year>
Reference-contexts: Related work: Many authors have sought to improve the data-efficiency of pac-learning procedures, but gen erally by incorporating additional assumptions about the domain distribution, e.g., [Bau90, BW91, AKA91]. Our goal is to improve data-efficiency without making additional assumptions. While work on nonuniform pac-learning <ref> [BI88b, LMR91, Koi94] </ref> resembles the present study by also using "online" stopping rules, it has a fundamentally different aim: Our goal is to obtain a uniform improvement in data-efficiency for all target concepts c in C, whereas nonuniform pac-learning sacrifices data-efficiency for certain target concepts (late in a preference ranking C
Reference: [Kul91] <author> S. Kulkarni. </author> <title> Problems of Computational and Information Complexity in Machine Vision and Learning. </title> <type> PhD thesis, </type> <institution> MIT, EECS, </institution> <year> 1991. </year>
Reference-contexts: Here we will consider two distinct models of prior knowledge: the distribution-free model [Val84], where the target concept c is known to belong to some class C, but nothing is known about the domain distribution P; and the distribution-specific model <ref> [BI88a, Kul91] </ref>, where the domain distribution P is known, but the target concept c is assumed only to belong to some class C.
Reference: [KV89] <author> M. J. Kearns and L. G. Valiant. </author> <title> Cryptographic limitations on learning Boolean formulae and finite automata. </title> <booktitle> In Proceedings STOC-89, </booktitle> <pages> pages 433-444, </pages> <year> 1989. </year>
Reference-contexts: First, in Section 2 we consider the general problem of distribution-free pac-learning. Here we introduce a novel learning procedure S that works by keeping a list of hypotheses (produced by some consistent hypothesizer), testing each one "on-line" with a sequential probability pac-learned (unless standard cryptographic assumptions are false) <ref> [KV89] </ref>, Schapire [Sch92] has demonstrated a poly-time learning procedure for (formulae; uniform). ratio test (sprt) [Wal47] to see whether any has suffi-ciently small error.
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: Little-stone has observed that a concept from a finite class can always be learned while making a finite number of mistakes, in an on-line model where the learner produces a hypothesis after each example and tests it on the next <ref> [Lit88] </ref>. In later work [Lit89] he showed how a hypothe-sizer H with a small mistake bound could be converted into a data-efficient pac-learner. <p> winnow which has a good mistake bound for this 2 1 2 3 2 5 * = 2 7 100 10000 T Li ET Smb bound max T Smb min T Smb with * = 2 1 ; :::; 2 8 . (Result of 200 runs each; log-log plot.) problem <ref> [Lit88] </ref>.
Reference: [Lit89] <author> N. Littlestone. </author> <title> From online to batch learning. </title> <booktitle> In Proceedings COLT-89, </booktitle> <pages> pages 269-284, </pages> <year> 1989. </year>
Reference-contexts: Next, in Section 2.1 we briefly consider the special case of finite concept classes. Here we show (Proposition 5) that a variant of Procedure S can perform "mistake bounded to pac" conversion while using strictly fewer training examples (on average) than the procedure proposed in <ref> [Lit89] </ref>. In fact, our procedure uses substantially fewer training examples in empirical tests. Finally, in Section 3 we address the distribution-specific model of pac-learning. <p> The real goal of nonuni form pac-learning is to increase the range of pac-learnable concept classes (e.g., to certain classes with infinite VCdimension), rather than improve data-efficiency on previously pac-learnable classes. 4 It is also important to distinguish our approach from on-line learning, e.g., <ref> [Lit89, LW89, HLL92] </ref>. On-line learning considers a "learning while doing" model which is fundamentally different from the "batch" paradigm considered here. <p> Little-stone has observed that a concept from a finite class can always be learned while making a finite number of mistakes, in an on-line model where the learner produces a hypothesis after each example and tests it on the next [Lit88]. In later work <ref> [Lit89] </ref> he showed how a hypothe-sizer H with a small mistake bound could be converted into a data-efficient pac-learner.
Reference: [LMR91] <author> N. Linial, Y. Mansour, and R. L. Rivest. </author> <title> Results on learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Information and Computation, </journal> <volume> 90 </volume> <pages> 33-49, </pages> <year> 1991. </year>
Reference-contexts: Related work: Many authors have sought to improve the data-efficiency of pac-learning procedures, but gen erally by incorporating additional assumptions about the domain distribution, e.g., [Bau90, BW91, AKA91]. Our goal is to improve data-efficiency without making additional assumptions. While work on nonuniform pac-learning <ref> [BI88b, LMR91, Koi94] </ref> resembles the present study by also using "online" stopping rules, it has a fundamentally different aim: Our goal is to obtain a uniform improvement in data-efficiency for all target concepts c in C, whereas nonuniform pac-learning sacrifices data-efficiency for certain target concepts (late in a preference ranking C
Reference: [LW89] <author> N. Littlestone and M. Warmuth. </author> <title> The weighted majority algorithm. </title> <booktitle> In Proceedings FOCS-89, </booktitle> <pages> pages 256-261, </pages> <year> 1989. </year>
Reference-contexts: The real goal of nonuni form pac-learning is to increase the range of pac-learnable concept classes (e.g., to certain classes with infinite VCdimension), rather than improve data-efficiency on previously pac-learnable classes. 4 It is also important to distinguish our approach from on-line learning, e.g., <ref> [Lit89, LW89, HLL92] </ref>. On-line learning considers a "learning while doing" model which is fundamentally different from the "batch" paradigm considered here.
Reference: [Sch92] <author> R. E. Schapire. </author> <title> The Design and Analysis of Efficient Learning Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1992. </year>
Reference-contexts: Here we introduce a novel learning procedure S that works by keeping a list of hypotheses (produced by some consistent hypothesizer), testing each one "on-line" with a sequential probability pac-learned (unless standard cryptographic assumptions are false) [KV89], Schapire <ref> [Sch92] </ref> has demonstrated a poly-time learning procedure for (formulae; uniform). ratio test (sprt) [Wal47] to see whether any has suffi-ciently small error. We show (Theorem 1) that S correctly solves any pac-learning problem (C; *; ffi) for which d = vc (C) &lt; 1, * &gt; 0, ffi &gt; 0.
Reference: [Sch95] <author> D. Schuurmans. </author> <title> Effective Classification Learning. </title> <type> PhD thesis, </type> <institution> University of Toronto, Computer Science, </institution> <year> 1995. </year> <month> (Forthcoming). </month>
Reference-contexts: can be shown that, given P defined as above, there must be some c 0 2 C for which Pf d P (H T ; c 0 ) &gt; * fi T c 0 &lt; U g 1 7 . (This involves generalizing the proof of [EHKV89, Lemma 2]; see <ref> [Sch95] </ref> for complete details.) Combining (1)-(4) shows that, for any k &gt; 1, if ET c d1 32k* for all c 2 C, then there must be some c 0 2 C for which Pfd P (H T ; c 0 ) &gt; *g 1 7 1 1 13 1 = <p> This can be done by taking derivatives of EZ with respect to * <ref> [Sch95] </ref>. fl Lemma 11 For 0 &lt; * &lt; 1 e 1 , ffi &gt; 0, &gt; 1: given a Boolean r.v. (x) such that Pf (x) = 1g * , ET sprt ((x); * ;*;ffi;0) * ln 1 Proof Recall the definition S t (x t ) = P given
Reference: [SG95] <author> D. Schuurmans and R. Greiner. </author> <title> Practical PAC learning. </title> <booktitle> In Proceedings IJCAI-95, </booktitle> <year> 1995. </year>
Reference-contexts: This bound actually beats T BEHW and T STAB for extremely small values of ffi (Proposition 3). However, we note that S's true data-efficiency is decoupled from any precise bounds we can prove about its performance, and empirical tests <ref> [SG95] </ref> show that S actually uses many times fewer training examples in practice. <p> Although this theoretical advantage is slight, we expect S to perform much better in practice than any bounds we can prove about its performance; n.b., this is not a possibility for fixed-sample-size approaches. In fact, this advantage is readily demonstrated in empirical case studies <ref> [SG95] </ref>. For example, we tested S on the pac-learning problem (X = IR 10 ; C = halfspaces; * = 0:01; ffi = 0:05); fixing a uniform distribution on [1; 1] n and a particular target concept, setting = 3:14619, and supplying S with a consistent halfspace hypothesizer. <p> Not only do these results scale up well for harder problems (Figure 5), they are also robust to changes in the target concept, domain distribution, and concept class (with the same VCdimension) <ref> [SG95] </ref>. One reason for this advantage is that S's data-efficiency is determined by the specific case at hand, not the worst case situation | or, worse yet, by what we can prove about the worst case situation.
Reference: [Shi78] <author> A. N. Shiryayev. </author> <title> Optimal Stopping Rules. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: Since S t is an i.i.d. sum, Wald's identity gives ES T = EZ ET for any stopping rule T <ref> [Wal47, Shi78] </ref>. Thus, ET = ES T =EZ.
Reference: [STAB93] <author> J. Shawe-Taylor, M. Anthony, and N. L. Biggs. </author> <title> Bounding sample size with the Vapnik-Chervonenkis dimension. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 42 </volume> <pages> 65-73, </pages> <year> 1993. </year>
Reference-contexts: All concept classes we consider are assumed to be suitably "well behaved" in this manner. 2 This result has since been improved by Shawe-Taylor et al. <ref> [STAB93] </ref> to T ST AB (C; *; ffi) = 1 *(1 p *) 2d ln 6 ffi . 3 This is a different motivation from using distributional assumptions to reduce the computational complexity of pac-learning. <p> Proof Let E t be the event that all *-bad concepts have been eliminated after t training examples. From <ref> [STAB93] </ref> we have that for all ffi &gt; 0 there is some t for which PE t 1 ffi, and hence PE t " 1. We are interested in the event E 1 = S 1 t=1 E t . <p> For any concept class C, vc (C) &lt; 1: all *-bad c 2 C are eliminated in expected time ET C (*) 1 p * + ln 2 + 1 : Proof We have PfT C (*) &gt; T STAB (C; *; ffi)g ffi for all ffi &gt; 0 from <ref> [STAB93] </ref>. Assume, pessimistically, that T C is a random variable that makes this an equality, i.e., PfT C &gt; T ST AB g = ffi for all ffi &gt; 0.
Reference: [Val84] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: Of course, the difficulty of achieving this criterion depends on our prior knowledge of c and P. Here we will consider two distinct models of prior knowledge: the distribution-free model <ref> [Val84] </ref>, where the target concept c is known to belong to some class C, but nothing is known about the domain distribution P; and the distribution-specific model [BI88a, Kul91], where the domain distribution P is known, but the target concept c is assumed only to belong to some class C. <p> On-line learning considers a "learning while doing" model which is fundamentally different from the "batch" paradigm considered here. We really are following the standard batch ("train then test") protocol introduced by <ref> [Val84] </ref> | the only difference is that we permit the size of the training sample to be under the learner's control rather than set by the designer a priori. 2 Distribution-free pac-learning We first consider the problem of distribution-free pac-learning.
Reference: [VC71] <author> V. N. Vapnik and A. Ya. Chervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: E.g., for finite concept classes T finite (C; *; ffi) = 1 * ln ffi random training examples are sufficient to ensure F pac (*; ffi)-learns C. For infinite concept classes, Blumer et al. [BEHW89] use the results of Vapnik and Chervonenkis <ref> [VC71] </ref> to show that for any (well behaved 1 ) concept class C with vc (C) = d T BEHW (C; *; ffi) = max 8d 13 * log 2 ffi random examples are sufficient for Procedure F to solve (C; *; ffi). 2 In addition, Ehrenfeucht et al. [EHKV89] have
Reference: [Wal47] <author> A. Wald. </author> <title> Sequential Analysis. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1947. </year>
Reference-contexts: we introduce a novel learning procedure S that works by keeping a list of hypotheses (produced by some consistent hypothesizer), testing each one "on-line" with a sequential probability pac-learned (unless standard cryptographic assumptions are false) [KV89], Schapire [Sch92] has demonstrated a poly-time learning procedure for (formulae; uniform). ratio test (sprt) <ref> [Wal47] </ref> to see whether any has suffi-ciently small error. We show (Theorem 1) that S correctly solves any pac-learning problem (C; *; ffi) for which d = vc (C) &lt; 1, * &gt; 0, ffi &gt; 0. <p> Procedure S is based on two ideas: First, instead of discarding hypotheses after a single mistake, S saves hypotheses, and continues testing them until one proves to have small error. Second, S tests hypotheses by using a sequential probability ratio test (sprt) <ref> [Wal47] </ref> that decides on-line whether a hypothesis is sufficiently ac curate; see Figure 4. Not only does S prove to be a correct pac-learning procedure, but we can also derive a reasonable upper bound on its expected sample size. <p> Proof (Outline) First, to show S terminates with probability 1 (wp1) we note that (i) sprt eventually accepts any * -good hypothesis wp1 (Lemma 9 in Appendix), and (ii) H eventually produces such a hypothesis wp1 (Lemma 12). Correctness then follows from the correctness of sprt <ref> [Wal47] </ref>, and the fact that S accepts an *- bad hypothesis with probability at most P ffi i = ffi.(Note that this result generalizes to any class C that can be decomposed as C = [ 1 1 C i , vc (C i ) &lt; 1, provided H guesses consistent <p> Since S t is an i.i.d. sum, Wald's identity gives ES T = EZ ET for any stopping rule T <ref> [Wal47, Shi78] </ref>. Thus, ET = ES T =EZ.
References-found: 25

