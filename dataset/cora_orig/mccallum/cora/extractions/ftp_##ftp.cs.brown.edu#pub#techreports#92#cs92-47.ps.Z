URL: ftp://ftp.cs.brown.edu/pub/techreports/92/cs92-47.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-92-47.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Eugene Charniak and Robert Goldman. </author> <title> A logic for semantic interpretation. </title> <booktitle> In Proceedings of the AAAI Conference, </booktitle> <year> 1988. </year>
Reference-contexts: These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension <ref> [9, 10, 1, 3] </ref>, circuit fault detection [7, 19], medical diagnosis [32] and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks.
Reference: [2] <author> Eugene Charniak and Drew McDermott. </author> <title> Introduction to Artificial Intelligence. </title> <publisher> Addison Wesley, </publisher> <year> 1985. </year>
Reference-contexts: The higher degree of sensitivity needed in this data means a finer grained discretization of random variable instantia-tions. In a related vein, consider the domain of medical diagnosis where we are modeling the correlations between diseases and symptoms. As Charniak and McDermott point out in <ref> [2] </ref>, when you start considering relationships between diseases and simultaneous multiple symptoms, that is, P (disease Ajsymptom S 1 ; . . . ; symptom S n ); the explosion becomes quite apparent since we have to keep a probability around for each combination of disease and symptoms.
Reference: [3] <author> Eugene Charniak and Eugene Santos, Jr. </author> <title> Dynamic map calculations for abduction. </title> <booktitle> In Proceedings of the AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension <ref> [9, 10, 1, 3] </ref>, circuit fault detection [7, 19], medical diagnosis [32] and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks. <p> In particular, we present an approach which may be used to solve the conditional table size problem in Bayesian networks. Our approach begins with the following recent result: Santos introduced a new technique for probabilistic computations <ref> [23, 25, 24, 3, 26] </ref>. Bayesian-style reasoning could be modeled as a linear constraint satisfaction problem. Once this was achieved, extremely efficient tools and techniques can be applied from Operations Research to perform our computations. Experimental results demonstrated that this approach was superior to existing techniques. <p> Our approach begins with an earlier successful model for computing on Bayesian networks. Without considering table-sizes, manipulating Bayesian networks have already proven to be NP-hard with respect to network size [5]. The earlier approach <ref> [23, 25, 24, 3, 26] </ref> transforms Bayesian networks into linear constraint satisfaction problems. Although the problem remains NP-hard, high levels of computational efficiency could be achieved by using tools and techniques from Operations Research. Tools such as Simplex method and Karmarkar's projective scaling algorithm formed the implemen-tational core.
Reference: [4] <author> Eugene Charniak and Solomon E. Shimony. </author> <title> Probabilistic semantics for cost based abduction. </title> <booktitle> In Proceedings of the AAAI Conference, </booktitle> <year> 1990. </year>
Reference-contexts: Basically, some evidence or observation is given to us, and our task is to come up with a set of hypothesis that together constitute the most satisfactory explanation/interpretation of the evidence at hand. This process has also been considered abductive reasoning in one form or another <ref> [12, 30, 20, 4] </ref>. More formally, if W is the set of all r.v.s in our given Bayesian network and e is our given evidence 4 , any complete instantiations to all the r.v.s in W which is consistent with e will be called an explanation or interpretation of e. <p> This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. Although the newly transformed problem remains NP-hard, empirical studies indicate the approach to exhibit an expected-case polynomial run-time [24, 23, 26], easily outperforming the best-first search technique of <ref> [31, 4] </ref>. Although the above methods are radically different in their approaches, they all generally suffer from a common problem. Namely, if the conditional tables are exponentially large, the computation times are also exponential.
Reference: [5] <author> Gregory F. Cooper. </author> <title> Probabilistic inference using belief networks is np-hard. </title> <type> Technical Report KSL-87-27, </type> <institution> Medical Computer Science Group, Stanford University, </institution> <year> 1987. </year>
Reference-contexts: Bayesian networks have been applied to various domains such as story comprehension [9, 10, 1, 3], circuit fault detection [7, 19], medical diagnosis [32] and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected <ref> [5] </ref>. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks. There are two key factors which prevent the general use of Bayesian networks. The first is network topology. <p> factor of trying to use Bayesian networks for modeling complex tasks. 3 Computational Methods Barring the fact that we may have a combinatorial explosion in the number of conditional probability entries, belief revision and updating on Bayesian networks, however, is also NP-hard with respect to the size of the network <ref> [5, 31] </ref>. Various techniques are available for performing the computations, but we must point out that although they may have reasonable expected run-times, these complexity measures are made with respect to the number of nodes/edges in the network and consider the table sizes to be some multiplicative constant. <p> Our approach begins with an earlier successful model for computing on Bayesian networks. Without considering table-sizes, manipulating Bayesian networks have already proven to be NP-hard with respect to network size <ref> [5] </ref>. The earlier approach [23, 25, 24, 3, 26] transforms Bayesian networks into linear constraint satisfaction problems. Although the problem remains NP-hard, high levels of computational efficiency could be achieved by using tools and techniques from Operations Research.
Reference: [6] <author> Steve B. Cousins, William Chen, and Mark E. Frisse. Caben: </author> <title> A collection of algorithms for belief networks. </title> <type> Technical Report WUCS-91-25, </type> <institution> Department of Computer Science, Washington University, </institution> <address> St. Louis, Mo., </address> <year> 1991. </year>
Reference-contexts: Obviously, when we have a table with an exponential number of entries, the run-times will generally be exponential for these techniques. Probably the two most popular approaches for performing belief updating are message-passing schemes [19] and stochastic simulations <ref> [29, 6, 33, 11] </ref>. In message-passing, the basic idea is to treat each node in the network as an individual processor. Information is then propagated back and forth between the nodes until equilibrium is achieved.
Reference: [7] <author> R. Davis. </author> <title> Diagnostic reasoning based on structure and behavior. </title> <journal> Artificial Intelligence, </journal> <volume> 24 </volume> <pages> 347-410, </pages> <year> 1984. </year>
Reference-contexts: These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension [9, 10, 1, 3], circuit fault detection <ref> [7, 19] </ref>, medical diagnosis [32] and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks.
Reference: [8] <author> R. O. Duda, P. E. Hart, and N. J. Nilsson. </author> <title> Subjective bayesian methods for rule-based inference systems. </title> <booktitle> In Proceedings of the National Computer Conference, </booktitle> <year> 1976. </year>
Reference-contexts: 1 Introduction Probabilistic reasoning has become the mainstay of almost all inferencing systems. From expert systems for geological surveying <ref> [8] </ref> to medical diagnosis systems [32], the probabilistic approach provides a rich framework for knowledge representation that is essential in these domains. Unfortunately, because of one thing or another, the various approaches generally suffer from NP-hard implementations. The systems built tend to be tailored or refitted around these problems.
Reference: [9] <author> Robert P. Goldman. </author> <title> A Probabilistic Approach to Language Understanding. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1990. </year>
Reference-contexts: These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension <ref> [9, 10, 1, 3] </ref>, circuit fault detection [7, 19], medical diagnosis [32] and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks.
Reference: [10] <author> Robert P. Goldman and Eugene Charniak. </author> <title> Probabilistic text understanding. </title> <booktitle> In Proceedings of the Third International Workshop on AI and Statistics, </booktitle> <address> Fort Lauderdale, FL, </address> <year> 1991. </year>
Reference-contexts: These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension <ref> [9, 10, 1, 3] </ref>, circuit fault detection [7, 19], medical diagnosis [32] and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks.
Reference: [11] <author> M. Henrion. </author> <title> Propagating uncertainty by logic sampling in bayes' networks. </title> <type> Technical report, </type> <institution> Department of Engineering and Public Policy, Carnegie-Mellon University, </institution> <year> 1986. </year>
Reference-contexts: Obviously, when we have a table with an exponential number of entries, the run-times will generally be exponential for these techniques. Probably the two most popular approaches for performing belief updating are message-passing schemes [19] and stochastic simulations <ref> [29, 6, 33, 11] </ref>. In message-passing, the basic idea is to treat each node in the network as an individual processor. Information is then propagated back and forth between the nodes until equilibrium is achieved.
Reference: [12] <author> Jerry R. Hobbs, Mark Stickel, Paul Martin, and Douglas Edwards. </author> <title> Interpretation as abduction. </title> <booktitle> In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1988. </year>
Reference-contexts: Basically, some evidence or observation is given to us, and our task is to come up with a set of hypothesis that together constitute the most satisfactory explanation/interpretation of the evidence at hand. This process has also been considered abductive reasoning in one form or another <ref> [12, 30, 20, 4] </ref>. More formally, if W is the set of all r.v.s in our given Bayesian network and e is our given evidence 4 , any complete instantiations to all the r.v.s in W which is consistent with e will be called an explanation or interpretation of e.
Reference: [13] <author> Eric J. Horvitz, J. Jacques Suermondt, and Gregory F. Cooper. </author> <title> Bounded conditioning: Flexible inference for decisions under scarce resources. </title> <booktitle> In 34 Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: A singly-connected network requires that there exists at most one directed path between any two nodes. However, message-passing fails on the more general class of multiply-connected networks. Although there are methods such as clustering and conditioning [19] for transforming a multiply-connected network into an equivalent singly-connected one <ref> [28, 13] </ref>, the transformations have also been shown to be quite difficult to accomplish. Stochastic simulation, on the other hand, has no such topological restriction.
Reference: [14] <author> N. Karmarkar and R. M. Karp. </author> <title> An efficient approximation scheme for the one-dimensional bin-packing problem. </title> <booktitle> In Proceedings of the 23rd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 206-13, </pages> <year> 1982. </year>
Reference-contexts: We would like to note though that these methods are general methods. There are other methods which exploit domain-dependent information that we can likely use. Methods which rival Simplex have actually exhibited expected linear and even log-linear run-times which are obviously superior to our initial polynomial time <ref> [21, 14, 16, 22] </ref>. Thus, this helps to provide further evidence for the expected success of our approach. 33
Reference: [15] <author> Jak Kirman, Kenneth Basye, and Thomas Dean. </author> <title> Sensor abstractions for control of navigation. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 2812-2817, </pages> <year> 1991. </year>
Reference-contexts: These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension [9, 10, 1, 3], circuit fault detection [7, 19], medical diagnosis [32] and planning systems <ref> [15] </ref>. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks. There are two key factors which prevent the general use of Bayesian networks. The first is network topology. <p> Although there have been arguments that human beings reason well with only coarse approximations [19], domains such as robotic navigation require rather precise problem formulations to handle quantitative data such as sonar readings and map locations <ref> [15] </ref>. The higher degree of sensitivity needed in this data means a finer grained discretization of random variable instantia-tions. In a related vein, consider the domain of medical diagnosis where we are modeling the correlations between diseases and symptoms. <p> By making various instantia-tions to these r.v.s, we can model the current state of the world. For example, consider the Mobile Target Localization problem (abbreviated mtl) <ref> [15] </ref>. It involves a robot equipped with sonars to track some given mobile target and reporting its location in the coordinate system of a global map.
Reference: [16] <author> Philip Klein, Serge A. Plotkin, C. Stein, and Eva Tardos. </author> <title> Faster approximation algorithms for the unit capacity concurrent flow problem with applications to routing and finding sparse cuts. </title> <type> Technical Report Technical Report 961, </type> <institution> Schools of Operations Research and Industrial Engineering, Cornell University, </institution> <year> 1991. </year>
Reference-contexts: We would like to note though that these methods are general methods. There are other methods which exploit domain-dependent information that we can likely use. Methods which rival Simplex have actually exhibited expected linear and even log-linear run-times which are obviously superior to our initial polynomial time <ref> [21, 14, 16, 22] </ref>. Thus, this helps to provide further evidence for the expected success of our approach. 33
Reference: [17] <author> C. McMillan. </author> <title> Mathematical Programming. </title> <publisher> John-Wiley & Sons, Inc., </publisher> <year> 1975. </year>
Reference-contexts: Most recently, Santos in [25, 26] introduced a new approach which reduces the problem of belief revision into linear constraint satisfaction. Having accomplished this reduction, efficient Operations Research tools such as the Simplex Method <ref> [17, 27, 18] </ref> could be used to solve the problem. This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. <p> Hence, minimizing it will get us our most-probable explanation. We have now reduced belief revision into linear constraint satisfaction. In particular, what we now have is an 0-1 integer linear programming problem <ref> [17, 27, 18] </ref>. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound [24, 25, 26]. Furthermore, by using a Cutting Plane approach [25, 26], we can generate all the alternative solutions in order of decreasing probability.
Reference: [18] <editor> G. L. Nemhauser, A. H. G. Rinnooy Kan, and M. J. Todd, editors. </editor> <booktitle> Optimization: Handbooks in Operations Research and Management Science Volume 1, </booktitle> <volume> volume 1. </volume> <publisher> North Holland, </publisher> <year> 1989. </year>
Reference-contexts: Most recently, Santos in [25, 26] introduced a new approach which reduces the problem of belief revision into linear constraint satisfaction. Having accomplished this reduction, efficient Operations Research tools such as the Simplex Method <ref> [17, 27, 18] </ref> could be used to solve the problem. This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. <p> Hence, minimizing it will get us our most-probable explanation. We have now reduced belief revision into linear constraint satisfaction. In particular, what we now have is an 0-1 integer linear programming problem <ref> [17, 27, 18] </ref>. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound [24, 25, 26]. Furthermore, by using a Cutting Plane approach [25, 26], we can generate all the alternative solutions in order of decreasing probability.
Reference: [19] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: This often results in various behavioral anomalies and general ad-hocness. Yet, we must keep in mind as always that these problems will persist only until efficient algorithms are found. Probably one of the most popular models for probabilistic reasoning is Pearl's Bayesian networks <ref> [19] </ref>. This approach provides a handy visualization of our knowledge through the means of a directed acyclic graph of random variable relationships. Basically, each node in the graph represents a "discrete" random variable. The directed arcs between the nodes represent probabilistic conditional (in)dependencies. <p> These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension [9, 10, 1, 3], circuit fault detection <ref> [7, 19] </ref>, medical diagnosis [32] and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks. <p> There are two key factors which prevent the general use of Bayesian networks. The first is network topology. Most of the existing algorithms are quite sensitive to this and often end up in a "do or die" situation (See <ref> [19, 31] </ref>). For example, Pearl's message-passing scheme [19] is restricted to singly-connected networks, that is, there can only exist at most one directed path between any two nodes in the graph. <p> There are two key factors which prevent the general use of Bayesian networks. The first is network topology. Most of the existing algorithms are quite sensitive to this and often end up in a "do or die" situation (See [19, 31]). For example, Pearl's message-passing scheme <ref> [19] </ref> is restricted to singly-connected networks, that is, there can only exist at most one directed path between any two nodes in the graph. Unfortunately, for those which aren't hindered by topological considerations, they invariably run into the second factor, conditional probability table size. <p> Thus, in the "toy" domains, precision is generally sacrificed resulting in relatively small tables. Extremely coarse approximations of information is typically sufficient for this relatively low level of prototyping. Although there have been arguments that human beings reason well with only coarse approximations <ref> [19] </ref>, domains such as robotic navigation require rather precise problem formulations to handle quantitative data such as sonar readings and map locations [15]. The higher degree of sensitivity needed in this data means a finer grained discretization of random variable instantia-tions. <p> as follows: P (S T i ; S R i ; O R i ; O T i ; A R i ) = (1) P (O R i jO T i ; A R i )P (O T i jA R i )P (A R i ): Bayesian networks <ref> [19] </ref> take this a step further by making the important observation that certain r.v. pairs may become uncorrelated once information concerning some other r.v.(s) is known. <p> Hence, we can simply ignore the r.v.s in U . 8 This type of computation performed with Bayesian networks is classified as belief updating <ref> [19] </ref>. In general, belief updating involves updating our beliefs about the different possible instantiations of a r.v. given certain instantiations of other r.v.s as evidence/observations. 3 Belief updating is one of two common computations performed with Bayesian networks. The second is called belief revision [19]. <p> networks is classified as belief updating <ref> [19] </ref>. In general, belief updating involves updating our beliefs about the different possible instantiations of a r.v. given certain instantiations of other r.v.s as evidence/observations. 3 Belief updating is one of two common computations performed with Bayesian networks. The second is called belief revision [19]. Belief revision is best used for modeling explanatory/diagnostic tasks. Basically, some evidence or observation is given to us, and our task is to come up with a set of hypothesis that together constitute the most satisfactory explanation/interpretation of the evidence at hand. <p> Obviously, when we have a table with an exponential number of entries, the run-times will generally be exponential for these techniques. Probably the two most popular approaches for performing belief updating are message-passing schemes <ref> [19] </ref> and stochastic simulations [29, 6, 33, 11]. In message-passing, the basic idea is to treat each node in the network as an individual processor. Information is then propagated back and forth between the nodes until equilibrium is achieved. <p> A singly-connected network requires that there exists at most one directed path between any two nodes. However, message-passing fails on the more general class of multiply-connected networks. Although there are methods such as clustering and conditioning <ref> [19] </ref> for transforming a multiply-connected network into an equivalent singly-connected one [28, 13], the transformations have also been shown to be quite difficult to accomplish. Stochastic simulation, on the other hand, has no such topological restriction. <p> We can consider the alternative solutions to be sample points for use in (8). By starting with the "best" explanation, we now have the sample point with the largest probability, hence, avoiding the problem encountered with random sampling we saw above. 5 Pearl in <ref> [19] </ref> calls this the most-probable-explanation (abbreviated, MPE) criterion. 11 One of the earliest methods for performing belief revision on Bayesian networks was a message-passing variant of the one mentioned above for belief updating [19]. Again, unfortunately, the scheme was restricted to singly-connected networks. <p> the largest probability, hence, avoiding the problem encountered with random sampling we saw above. 5 Pearl in <ref> [19] </ref> calls this the most-probable-explanation (abbreviated, MPE) criterion. 11 One of the earliest methods for performing belief revision on Bayesian networks was a message-passing variant of the one mentioned above for belief updating [19]. Again, unfortunately, the scheme was restricted to singly-connected networks. Also, the scheme had no mechanisms for computing alternative solutions beyond the second most-probable. Sy in [34] introduces another variant of message-passing which has been empirically shown to be more efficient than Pearl's method.
Reference: [20] <author> Y. Peng and J. A. Reggia. </author> <title> Abductive Inference Models for Diagnostic Problem-Solving. </title> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Basically, some evidence or observation is given to us, and our task is to come up with a set of hypothesis that together constitute the most satisfactory explanation/interpretation of the evidence at hand. This process has also been considered abductive reasoning in one form or another <ref> [12, 30, 20, 4] </ref>. More formally, if W is the set of all r.v.s in our given Bayesian network and e is our given evidence 4 , any complete instantiations to all the r.v.s in W which is consistent with e will be called an explanation or interpretation of e. <p> Our problem is to find an explanation w fl such that P (w fl je) = max P (wje): (5) Intuitively, we can think of the non-evidence r.v.s in W as possible hypothesis for e. For example, consider the probabilistic medical diagnosis model presented in <ref> [20] </ref>. It is a 2-layer Bayesian network consisting of a layer of manifestations (symptoms) and a layer of disorders (diseases). The manifestations are conditionally dependent on different sets of disorders. Given a set of manifestations, we must determine a set of disorders which maximizes (5).
Reference: [21] <author> Serge A. Plotkin, David B. Shmoys, and Eva Tardos. </author> <title> Fast approximation algorithms for fractional packing and covering problems. </title> <booktitle> In Proceedings of the 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 495-504, </pages> <year> 1991. </year>
Reference-contexts: We would like to note though that these methods are general methods. There are other methods which exploit domain-dependent information that we can likely use. Methods which rival Simplex have actually exhibited expected linear and even log-linear run-times which are obviously superior to our initial polynomial time <ref> [21, 14, 16, 22] </ref>. Thus, this helps to provide further evidence for the expected success of our approach. 33
Reference: [22] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms: Approximating packing intereger programs. </title> <journal> J. Comput. System Sciences, </journal> <volume> 37 </volume> <pages> 130-43, </pages> <year> 1988. </year>
Reference-contexts: We would like to note though that these methods are general methods. There are other methods which exploit domain-dependent information that we can likely use. Methods which rival Simplex have actually exhibited expected linear and even log-linear run-times which are obviously superior to our initial polynomial time <ref> [21, 14, 16, 22] </ref>. Thus, this helps to provide further evidence for the expected success of our approach. 33
Reference: [23] <author> Eugene Santos, Jr. </author> <title> Cost-based abduction, linear constraint satisfaction, and alternative explanations. </title> <booktitle> In Proceedings of the AAAI Workshop on Abduction, </booktitle> <year> 1991. </year>
Reference-contexts: In particular, we present an approach which may be used to solve the conditional table size problem in Bayesian networks. Our approach begins with the following recent result: Santos introduced a new technique for probabilistic computations <ref> [23, 25, 24, 3, 26] </ref>. Bayesian-style reasoning could be modeled as a linear constraint satisfaction problem. Once this was achieved, extremely efficient tools and techniques can be applied from Operations Research to perform our computations. Experimental results demonstrated that this approach was superior to existing techniques. <p> This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. Although the newly transformed problem remains NP-hard, empirical studies indicate the approach to exhibit an expected-case polynomial run-time <ref> [24, 23, 26] </ref>, easily outperforming the best-first search technique of [31, 4]. Although the above methods are radically different in their approaches, they all generally suffer from a common problem. Namely, if the conditional tables are exponentially large, the computation times are also exponential. <p> Our approach begins with an earlier successful model for computing on Bayesian networks. Without considering table-sizes, manipulating Bayesian networks have already proven to be NP-hard with respect to network size [5]. The earlier approach <ref> [23, 25, 24, 3, 26] </ref> transforms Bayesian networks into linear constraint satisfaction problems. Although the problem remains NP-hard, high levels of computational efficiency could be achieved by using tools and techniques from Operations Research. Tools such as Simplex method and Karmarkar's projective scaling algorithm formed the implemen-tational core.
Reference: [24] <author> Eugene Santos, Jr. </author> <title> A linear constraint satisfaction approach to cost-based abduction. </title> <note> Submitted to Artificial Intelligence Journal, 1991. 35 </note>
Reference-contexts: In particular, we present an approach which may be used to solve the conditional table size problem in Bayesian networks. Our approach begins with the following recent result: Santos introduced a new technique for probabilistic computations <ref> [23, 25, 24, 3, 26] </ref>. Bayesian-style reasoning could be modeled as a linear constraint satisfaction problem. Once this was achieved, extremely efficient tools and techniques can be applied from Operations Research to perform our computations. Experimental results demonstrated that this approach was superior to existing techniques. <p> This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. Although the newly transformed problem remains NP-hard, empirical studies indicate the approach to exhibit an expected-case polynomial run-time <ref> [24, 23, 26] </ref>, easily outperforming the best-first search technique of [31, 4]. Although the above methods are radically different in their approaches, they all generally suffer from a common problem. Namely, if the conditional tables are exponentially large, the computation times are also exponential. <p> We have now reduced belief revision into linear constraint satisfaction. In particular, what we now have is an 0-1 integer linear programming problem [17, 27, 18]. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound <ref> [24, 25, 26] </ref>. Furthermore, by using a Cutting Plane approach [25, 26], we can generate all the alternative solutions in order of decreasing probability. The individual methods themselves are well-understood in Operations Research allowing for many other variations to be used which may be even more effective. <p> Thus, we can proceed with our belief revision computations like we did earlier in this section. Since we have generalized our restrictions on what values a real variable may attain from simple 0 and 1, we must modify our original branch and bound algorithm found in <ref> [24, 26] </ref> to guarantee that we generate permissible solutions. Notation. Let x be a real variable and fk 1 ; k 2 ; . . . ; k n g be its permissible values such that k i &lt; k i+1 . <p> Our approach begins with an earlier successful model for computing on Bayesian networks. Without considering table-sizes, manipulating Bayesian networks have already proven to be NP-hard with respect to network size [5]. The earlier approach <ref> [23, 25, 24, 3, 26] </ref> transforms Bayesian networks into linear constraint satisfaction problems. Although the problem remains NP-hard, high levels of computational efficiency could be achieved by using tools and techniques from Operations Research. Tools such as Simplex method and Karmarkar's projective scaling algorithm formed the implemen-tational core.
Reference: [25] <author> Eugene Santos, Jr. </author> <title> On the generation of alternative explanations with implications for belief revision. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: In particular, we present an approach which may be used to solve the conditional table size problem in Bayesian networks. Our approach begins with the following recent result: Santos introduced a new technique for probabilistic computations <ref> [23, 25, 24, 3, 26] </ref>. Bayesian-style reasoning could be modeled as a linear constraint satisfaction problem. Once this was achieved, extremely efficient tools and techniques can be applied from Operations Research to perform our computations. Experimental results demonstrated that this approach was superior to existing techniques. <p> Hence, the problem of network topology is absorbed in the choice of a best-first search heuristic. Furthermore, through back-tracking, the alternative solutions could be generated. The biggest problem with this approach, though, is the explosive amount of search required as you progress to larger networks. Most recently, Santos in <ref> [25, 26] </ref> introduced a new approach which reduces the problem of belief revision into linear constraint satisfaction. Having accomplished this reduction, efficient Operations Research tools such as the Simplex Method [17, 27, 18] could be used to solve the problem. <p> define the probability of w to be P (w) = P (A 1 = a 1 ; . . . ; A n = a n ): 5 Constraints Formulation As we mentioned earlier, our new approach is based on the results of transforming belief revision into linear constraint satisfaction <ref> [25, 26] </ref>. This approach was shown to be topologically invariant, capable of generating alternative solutions and perform efficiently on moderately-connected networks. <p> A subspace of 8 Precise details and theoretical proofs can be found in <ref> [25, 26] </ref>. 14 &lt; n will represent "valid" instantiations where valid includes things like being consistent to the given evidence e, each r.v. has at most one instantiation, etc. <p> We have now reduced belief revision into linear constraint satisfaction. In particular, what we now have is an 0-1 integer linear programming problem [17, 27, 18]. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound <ref> [24, 25, 26] </ref>. Furthermore, by using a Cutting Plane approach [25, 26], we can generate all the alternative solutions in order of decreasing probability. The individual methods themselves are well-understood in Operations Research allowing for many other variations to be used which may be even more effective. <p> In particular, what we now have is an 0-1 integer linear programming problem [17, 27, 18]. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound [24, 25, 26]. Furthermore, by using a Cutting Plane approach <ref> [25, 26] </ref>, we can generate all the alternative solutions in order of decreasing probability. The individual methods themselves are well-understood in Operations Research allowing for many other variations to be used which may be even more effective. Unfortunately, this approach also suffers from table size explosions. <p> Our approach begins with an earlier successful model for computing on Bayesian networks. Without considering table-sizes, manipulating Bayesian networks have already proven to be NP-hard with respect to network size [5]. The earlier approach <ref> [23, 25, 24, 3, 26] </ref> transforms Bayesian networks into linear constraint satisfaction problems. Although the problem remains NP-hard, high levels of computational efficiency could be achieved by using tools and techniques from Operations Research. Tools such as Simplex method and Karmarkar's projective scaling algorithm formed the implemen-tational core.
Reference: [26] <author> Eugene Santos, Jr. </author> <title> A Linear Constraint Satisfaction Approach for Ab-ductive Reasoning. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1992. </year>
Reference-contexts: In particular, we present an approach which may be used to solve the conditional table size problem in Bayesian networks. Our approach begins with the following recent result: Santos introduced a new technique for probabilistic computations <ref> [23, 25, 24, 3, 26] </ref>. Bayesian-style reasoning could be modeled as a linear constraint satisfaction problem. Once this was achieved, extremely efficient tools and techniques can be applied from Operations Research to perform our computations. Experimental results demonstrated that this approach was superior to existing techniques. <p> Finding the alternatives also has implications for belief updating. From equation (8), it has been observed that P (AeX) and P (eY ) for any A, X and Y are simply explanations/diagnoses for evidence e <ref> [26] </ref>. We can consider the alternative solutions to be sample points for use in (8). <p> Hence, the problem of network topology is absorbed in the choice of a best-first search heuristic. Furthermore, through back-tracking, the alternative solutions could be generated. The biggest problem with this approach, though, is the explosive amount of search required as you progress to larger networks. Most recently, Santos in <ref> [25, 26] </ref> introduced a new approach which reduces the problem of belief revision into linear constraint satisfaction. Having accomplished this reduction, efficient Operations Research tools such as the Simplex Method [17, 27, 18] could be used to solve the problem. <p> This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. Although the newly transformed problem remains NP-hard, empirical studies indicate the approach to exhibit an expected-case polynomial run-time <ref> [24, 23, 26] </ref>, easily outperforming the best-first search technique of [31, 4]. Although the above methods are radically different in their approaches, they all generally suffer from a common problem. Namely, if the conditional tables are exponentially large, the computation times are also exponential. <p> define the probability of w to be P (w) = P (A 1 = a 1 ; . . . ; A n = a n ): 5 Constraints Formulation As we mentioned earlier, our new approach is based on the results of transforming belief revision into linear constraint satisfaction <ref> [25, 26] </ref>. This approach was shown to be topologically invariant, capable of generating alternative solutions and perform efficiently on moderately-connected networks. <p> A subspace of 8 Precise details and theoretical proofs can be found in <ref> [25, 26] </ref>. 14 &lt; n will represent "valid" instantiations where valid includes things like being consistent to the given evidence e, each r.v. has at most one instantiation, etc. <p> We have now reduced belief revision into linear constraint satisfaction. In particular, what we now have is an 0-1 integer linear programming problem [17, 27, 18]. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound <ref> [24, 25, 26] </ref>. Furthermore, by using a Cutting Plane approach [25, 26], we can generate all the alternative solutions in order of decreasing probability. The individual methods themselves are well-understood in Operations Research allowing for many other variations to be used which may be even more effective. <p> In particular, what we now have is an 0-1 integer linear programming problem [17, 27, 18]. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound [24, 25, 26]. Furthermore, by using a Cutting Plane approach <ref> [25, 26] </ref>, we can generate all the alternative solutions in order of decreasing probability. The individual methods themselves are well-understood in Operations Research allowing for many other variations to be used which may be even more effective. Unfortunately, this approach also suffers from table size explosions. <p> Thus, we can proceed with our belief revision computations like we did earlier in this section. Since we have generalized our restrictions on what values a real variable may attain from simple 0 and 1, we must modify our original branch and bound algorithm found in <ref> [24, 26] </ref> to guarantee that we generate permissible solutions. Notation. Let x be a real variable and fk 1 ; k 2 ; . . . ; k n g be its permissible values such that k i &lt; k i+1 . <p> Our approach begins with an earlier successful model for computing on Bayesian networks. Without considering table-sizes, manipulating Bayesian networks have already proven to be NP-hard with respect to network size [5]. The earlier approach <ref> [23, 25, 24, 3, 26] </ref> transforms Bayesian networks into linear constraint satisfaction problems. Although the problem remains NP-hard, high levels of computational efficiency could be achieved by using tools and techniques from Operations Research. Tools such as Simplex method and Karmarkar's projective scaling algorithm formed the implemen-tational core.
Reference: [27] <author> A. Schrijver. </author> <title> Theory of Linear and Integer Programming. </title> <publisher> John Wiley & Sons Ltd., </publisher> <year> 1986. </year>
Reference-contexts: Most recently, Santos in [25, 26] introduced a new approach which reduces the problem of belief revision into linear constraint satisfaction. Having accomplished this reduction, efficient Operations Research tools such as the Simplex Method <ref> [17, 27, 18] </ref> could be used to solve the problem. This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. <p> Hence, minimizing it will get us our most-probable explanation. We have now reduced belief revision into linear constraint satisfaction. In particular, what we now have is an 0-1 integer linear programming problem <ref> [17, 27, 18] </ref>. We can efficiently solve this problem by combining the Dual Simple Method with Branch and Bound [24, 25, 26]. Furthermore, by using a Cutting Plane approach [25, 26], we can generate all the alternative solutions in order of decreasing probability.
Reference: [28] <author> Ross D. Shachter. </author> <title> Evidence absorption and propagation through evidence reversals. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: A singly-connected network requires that there exists at most one directed path between any two nodes. However, message-passing fails on the more general class of multiply-connected networks. Although there are methods such as clustering and conditioning [19] for transforming a multiply-connected network into an equivalent singly-connected one <ref> [28, 13] </ref>, the transformations have also been shown to be quite difficult to accomplish. Stochastic simulation, on the other hand, has no such topological restriction.
Reference: [29] <author> Ross D. Shachter and Mark A. Peot. </author> <title> Simulation approaches to general probabilistic inference on belief networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: Obviously, when we have a table with an exponential number of entries, the run-times will generally be exponential for these techniques. Probably the two most popular approaches for performing belief updating are message-passing schemes [19] and stochastic simulations <ref> [29, 6, 33, 11] </ref>. In message-passing, the basic idea is to treat each node in the network as an individual processor. Information is then propagated back and forth between the nodes until equilibrium is achieved.
Reference: [30] <author> Murray Shanahan. </author> <title> Prediction is deduction but explanation is abduction. </title> <booktitle> In Proceeding of IJCAI Conference, </booktitle> <year> 1989. </year>
Reference-contexts: Basically, some evidence or observation is given to us, and our task is to come up with a set of hypothesis that together constitute the most satisfactory explanation/interpretation of the evidence at hand. This process has also been considered abductive reasoning in one form or another <ref> [12, 30, 20, 4] </ref>. More formally, if W is the set of all r.v.s in our given Bayesian network and e is our given evidence 4 , any complete instantiations to all the r.v.s in W which is consistent with e will be called an explanation or interpretation of e.
Reference: [31] <author> Solomon E. Shimony and Eugene Charniak. </author> <title> A new algorithm for finding map assignments to belief networks. </title> <booktitle> In Proceedings of the Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference-contexts: There are two key factors which prevent the general use of Bayesian networks. The first is network topology. Most of the existing algorithms are quite sensitive to this and often end up in a "do or die" situation (See <ref> [19, 31] </ref>). For example, Pearl's message-passing scheme [19] is restricted to singly-connected networks, that is, there can only exist at most one directed path between any two nodes in the graph. <p> factor of trying to use Bayesian networks for modeling complex tasks. 3 Computational Methods Barring the fact that we may have a combinatorial explosion in the number of conditional probability entries, belief revision and updating on Bayesian networks, however, is also NP-hard with respect to the size of the network <ref> [5, 31] </ref>. Various techniques are available for performing the computations, but we must point out that although they may have reasonable expected run-times, these complexity measures are made with respect to the number of nodes/edges in the network and consider the table sizes to be some multiplicative constant. <p> This variant changes the message passing into a strictly feed-forward manner, hence, requiring only one pass through the network. Furthermore, generating the alternative solutions is possible due to his architecture. 6 However, Sy's approach also stumbles on multiply-connected networks. Shimony and Charniak in <ref> [31] </ref> showed that belief revision can be solved using a best-first search strategy. Hence, the problem of network topology is absorbed in the choice of a best-first search heuristic. Furthermore, through back-tracking, the alternative solutions could be generated. <p> This approach is invariant under network topology and also provides a mechanism for generating the alternative solutions. Although the newly transformed problem remains NP-hard, empirical studies indicate the approach to exhibit an expected-case polynomial run-time [24, 23, 26], easily outperforming the best-first search technique of <ref> [31, 4] </ref>. Although the above methods are radically different in their approaches, they all generally suffer from a common problem. Namely, if the conditional tables are exponentially large, the computation times are also exponential.
Reference: [32] <author> M. Shwe, B. Middleton, D. Heckerman, M. Henrion, E. Horvitz, and H. Lehmann. </author> <title> Probabilistic diagnosis using a reformulation of the internist-1/qmr knowledge base: I. the probabilistic model and inference algorithms. </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> 30 </volume> <pages> 241-255, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Probabilistic reasoning has become the mainstay of almost all inferencing systems. From expert systems for geological surveying [8] to medical diagnosis systems <ref> [32] </ref>, the probabilistic approach provides a rich framework for knowledge representation that is essential in these domains. Unfortunately, because of one thing or another, the various approaches generally suffer from NP-hard implementations. The systems built tend to be tailored or refitted around these problems. <p> These computations take the form of multiplying conditional probability tables which have been associated with each node in the network. Bayesian networks have been applied to various domains such as story comprehension [9, 10, 1, 3], circuit fault detection [7, 19], medical diagnosis <ref> [32] </ref> and planning systems [15]. However, computing with these networks has proven to be NP-hard as we might have expected [5]. This has generally prevented problem formulations from utilizing the full representational capabilities of Bayesian networks. There are two key factors which prevent the general use of Bayesian networks.
Reference: [33] <author> Sampath Srinivas and Jack Breese. </author> <title> Ideal: Influence diagram evaluation and analysis in lisp documentation and users guide. </title> <type> Technical Report Technical Memorandum No. 23, </type> <institution> Rockwell International Science Center, </institution> <address> Palo Alto, CA, </address> <year> 1989. </year>
Reference-contexts: Obviously, when we have a table with an exponential number of entries, the run-times will generally be exponential for these techniques. Probably the two most popular approaches for performing belief updating are message-passing schemes [19] and stochastic simulations <ref> [29, 6, 33, 11] </ref>. In message-passing, the basic idea is to treat each node in the network as an individual processor. Information is then propagated back and forth between the nodes until equilibrium is achieved.
Reference: [34] <author> Bon K. Sy. </author> <title> Reasoning mpe to multiply connected belief networks using message passing. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <year> 1992. </year> <month> 36 </month>
Reference-contexts: Again, unfortunately, the scheme was restricted to singly-connected networks. Also, the scheme had no mechanisms for computing alternative solutions beyond the second most-probable. Sy in <ref> [34] </ref> introduces another variant of message-passing which has been empirically shown to be more efficient than Pearl's method. This variant changes the message passing into a strictly feed-forward manner, hence, requiring only one pass through the network.
References-found: 34

