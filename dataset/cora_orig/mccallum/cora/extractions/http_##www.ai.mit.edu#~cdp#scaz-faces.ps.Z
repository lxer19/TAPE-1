URL: http://www.ai.mit.edu/~cdp/scaz-faces.ps.Z
Refering-URL: http://www.ai.mit.edu/people/scaz/scaz.html
Root-URL: 
Email: scaz@ai.mit.edu  
Title: Eye Finding via Face Detection for a Foveated, Active Vision System  
Author: Brian Scassellati 
Address: Square  Cambridge, MA, 02139, USA  
Affiliation: 545 Technology  MIT Artificial Intelligence Lab  
Abstract: Eye finding is the first step toward building a machine that can recognize social cues, like eye contact and gaze direction, in a natural context. In this paper, we present a real-time implementation of an eye finding algorithm for a foveated active vision system. The system uses a motion-based prefilter to identify potential face locations. These locations are analyzed for faces with a template-based algorithm developed by Sinha (1996). Detected faces are tracked in real time, and the active vision system saccades to the face using a learned sensorimotor mapping. Once gaze has been centered on the face, a high-resolution image of the eye can be captured from the foveal camera using a self-calibrated peripheral-to-foveal mapping. We also present a performance analysis of Sinha's ratio template algorithm on a standard set of static face images. Although this algorithm performs relatively poorly on static images, this result is a poor indicator of real-time performance of the behaving system. We find that our system finds eyes in 94% of a set of behavioral trials. We suggest that alternate means of evaluating behavioral systems are necessary. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, D. </author> <year> 1989. </year> <title> Behavioral constraints on animate vision. </title> <booktitle> Image and Vision Computing 7:1:3-9. </booktitle>
Reference-contexts: The algorithm that we present has been implemented on a binocular, foveated active vision system (Scassellati 1998), which is part of a humanoid robot project (Brooks & Stein 1994; Brooks et al. 1998). Overview The nature of the active vision system constrains our implementation <ref> (Ballard 1989) </ref>. Three copies of this hardware system are currently in use, one on a humanoid robot (see Figure 1) and two as desktop development platforms (see Figure 2). Each has an identical computational environment and very similar mechanical and optical properties (Scassellati 1998). <p> The ratio template correctly detected 71% of the faces in the database, including each of these faces except for the middle image from the first column. tical imperfections, and the imperfect construction of any real system <ref> (Ballard 1989) </ref>. An accurate kinematic solution is also extremely hardware dependent; the kinematic solution for one of the development platforms would differ significantly from the solution for the active vision system of the humanoid robot.
Reference: <author> Baluja, S., and Pomerleau, D. </author> <year> 1994. </year> <title> Non-intrusive gaze tracking using artificial neural networks. </title> <type> Technical Report CMU-CS-94-102, </type> <institution> Carnegie Mellon University. </institution>
Reference: <author> Baron-Cohen, S. </author> <year> 1995. </year> <title> Mindblindness. </title> <publisher> MIT Press. </publisher>
Reference: <author> Brooks, R., and Stein, L. A. </author> <year> 1994. </year> <title> Building brains for bodies. </title> <booktitle> Autonomous Robots 1:1:7-25. </booktitle>
Reference: <author> Brooks, R. A.; Ferrell, C.; Irie, R.; Kemp, C. C.; Mar-janovic, M.; Scassellati, B.; and Williamson, M. </author> <year> 1998. </year> <title> Alternative essences of intelligence. </title> <booktitle> In Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98). </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Brooks, R. A. </author> <year> 1991. </year> <title> Intelligence without reason. </title> <booktitle> In Proceedings of the 1991 International Joint Conference on Artificial Intelligence, </booktitle> <pages> 569-595. </pages>
Reference-contexts: While individual trials are probably not completely statistically independent, we can see from this example how the behavior of the system can be self-stabilizing without requiring extremely accurate perceptual tools. Issues like these make quantitative analysis of behaving systems difficult, and often misleading <ref> (Brooks 1991) </ref>. Our system does not require a completely general-purpose face recognition engine. In a real-world environment, the humans to whom the robot must attend in order to gain the benefits of social interaction are generally cooperative.
Reference: <author> Burghardt, G. </author> <year> 1990. </year> <title> Cognitive ethology and critical anthropomorphism: A snake with two heads and hog-nosed snakes that play dead. </title> <editor> In Ristau, C., ed., </editor> <booktitle> Cognitive Ethology: The Minds of Other Animals. </booktitle> <address> Erl-baum. </address>
Reference-contexts: Introduction The ability to detect another creature looking at you is critical for many species. Many vertebrates, from snakes <ref> (Burghardt 1990) </ref>, to chickens (Ristau 1991), to primates (Povinelli & Preuss 1995), have been observed to change their behavior based on whether or not eyes are gazing at them. In humans, eye contact serves a variety of social functions, from indicating interest to displaying aggression (Nummenmaa 1964).
Reference: <author> Coombs, D. J. </author> <year> 1992. </year> <title> Real-time gaze holding in binocular robot vision. </title> <type> Technical Report TR415, </type> <institution> U. Rochester. </institution>
Reference: <author> Frith, U. </author> <year> 1990. </year> <title> Autism : Explaining the Enigma. </title> <publisher> Basil Blackwell. </publisher>
Reference: <author> Graf, H. P.; Chen, T.; Petajan, E.; and Cosatto, E. </author> <year> 1996. </year> <title> Locating faces and facial parts. </title> <type> Technical Report TR-96.4.1, </type> <institution> AT&T Bell Laboratories. </institution>
Reference: <author> Heinzmann, J., and Zelinsky, A. </author> <year> 1997. </year> <title> Robust real-time face tracking and gesture recognition. </title> <booktitle> In Proceedings of IJCAI-97, </booktitle> <volume> volume 2, </volume> <pages> 1525-1530. </pages>
Reference: <author> Kuniyoshi, Y.; Kita, N.; Sugimoto, K.; Nakamura, S.; and Suehiro, T. </author> <year> 1995. </year> <title> A foveated wide angle lens for active vision. </title> <booktitle> In Proc. IEEE Int. Conf. Robotics and Automation. </booktitle>
Reference: <author> Marjanovic, M.; Scassellati, B.; and Williamson, M. </author> <year> 1996. </year> <title> Self-taught visually-guided pointing for a humanoid robot. </title> <booktitle> In From Animals to Animats 4: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior (SAB-96), </booktitle> <pages> 35-44. </pages> <publisher> Bradford Books. </publisher>
Reference: <author> Maurer, T., and von der Malsburg, C. </author> <year> 1996. </year> <title> Tracking and learning graphs and pose on image sequences of faces. </title> <booktitle> In Proc. 2nd Int. Conf. on Automatic Face- and Gesture-Recognition, </booktitle> <pages> 176-181. </pages> <publisher> IEEE Press. </publisher>
Reference: <author> Nummenmaa, T. </author> <year> 1964. </year> <title> The Language of the Face, </title> <booktitle> volume 9 of University of Jyvaskyla Studies in Education, Psychology and Social Research. Reported in Baron-Cohen (1995). </booktitle>
Reference-contexts: Many vertebrates, from snakes (Burghardt 1990), to chickens (Ristau 1991), to primates (Povinelli & Preuss 1995), have been observed to change their behavior based on whether or not eyes are gazing at them. In humans, eye contact serves a variety of social functions, from indicating interest to displaying aggression <ref> (Nummenmaa 1964) </ref>. Eye direction can also be a critical element of social learning. Eye direction, like a pointing gesture, serves to indicate what object an individual is currently considering.
Reference: <author> Povinelli, D. J., and Preuss, T. M. </author> <year> 1995. </year> <title> Theory of mind: evolutionary history of a cognitive specialization. </title> <booktitle> Trends in Neuroscience 18(9) </booktitle> <pages> 418-424. </pages>
Reference-contexts: Introduction The ability to detect another creature looking at you is critical for many species. Many vertebrates, from snakes (Burghardt 1990), to chickens (Ristau 1991), to primates <ref> (Povinelli & Preuss 1995) </ref>, have been observed to change their behavior based on whether or not eyes are gazing at them. In humans, eye contact serves a variety of social functions, from indicating interest to displaying aggression (Nummenmaa 1964). Eye direction can also be a critical element of social learning.
Reference: <author> Ristau, C. </author> <year> 1991. </year> <title> Attention, purposes, and deception in birds. </title> <editor> In Whiten, A., ed., </editor> <title> Natural Theories of Mind. </title> <publisher> Blackwell. </publisher>
Reference-contexts: Introduction The ability to detect another creature looking at you is critical for many species. Many vertebrates, from snakes (Burghardt 1990), to chickens <ref> (Ristau 1991) </ref>, to primates (Povinelli & Preuss 1995), have been observed to change their behavior based on whether or not eyes are gazing at them. In humans, eye contact serves a variety of social functions, from indicating interest to displaying aggression (Nummenmaa 1964).
Reference: <author> Rowley, H.; Baluja, S.; and Kanade, T. </author> <year> 1995. </year> <title> Human face detection in visual scenes. </title> <type> Technical Report CMU-CS-95-158, </type> <institution> Carnegie Mellon University. </institution>
Reference: <author> Scaife, M., and Bruner, J. </author> <year> 1975. </year> <title> The capacity for joint visual attention in the infant. </title> <booktitle> Nature 253 </booktitle> <pages> 265-266. </pages>
Reference-contexts: Detection of eye direction is believed to be a critical precursor of linguistic Copyright 1998, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. development <ref> (Scaife & Bruner 1975) </ref>, theory of mind (Baron-Cohen 1995), and social learning and scaffolding (Wood, Bruner, & Ross 1976). This paper presents the first steps on a developmental progression for building robotic systems that can utilize eye direction as a social signal (Scassellati 1996).
Reference: <author> Scassellati, B. </author> <year> 1996. </year> <title> Mechanisms of shared attention for a humanoid robot. In Embodied Cognition and Action: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: All rights reserved. development (Scaife & Bruner 1975), theory of mind (Baron-Cohen 1995), and social learning and scaffolding (Wood, Bruner, & Ross 1976). This paper presents the first steps on a developmental progression for building robotic systems that can utilize eye direction as a social signal <ref> (Scassellati 1996) </ref>. The initial goal of our system is to obtain a high resolution image that contains an eye for further processing. We present an algorithm for finding faces and eyes in a cluttered environment. <p> Highly accurate (and computationally expensive) techniques for face and eye detection (Row-ley, Baluja, & Kanade 1995; Turk & Pentland 1991; Sung & Poggio 1994) may not be necessary. Finally, to better fit with the goals of building social skills developmentally <ref> (Scassellati 1996) </ref>, we prefer an implementation that is biologically plausible. Our strategy for finding eyes decomposes into the following five steps: 1. The incoming wide-field image is filtered using mo tion and past history to find potential face locations. 2.
Reference: <author> Scassellati, B. </author> <year> 1998. </year> <title> A binocular, foveated active vision system. </title> <type> Technical Report 1628, </type> <institution> MIT Artificial Intelligence Lab Memo. </institution>
Reference-contexts: The initial goal of our system is to obtain a high resolution image that contains an eye for further processing. We present an algorithm for finding faces and eyes in a cluttered environment. The algorithm that we present has been implemented on a binocular, foveated active vision system <ref> (Scassellati 1998) </ref>, which is part of a humanoid robot project (Brooks & Stein 1994; Brooks et al. 1998). Overview The nature of the active vision system constrains our implementation (Ballard 1989). <p> Three copies of this hardware system are currently in use, one on a humanoid robot (see Figure 1) and two as desktop development platforms (see Figure 2). Each has an identical computational environment and very similar mechanical and optical properties <ref> (Scassellati 1998) </ref>. Similar to other active vision systems (Sharkey et al. 1993; Coombs 1992), there are three degrees of freedom; each eye has an independent vertical axis of rotation (pan) and the eyes share a joint horizontal axis of rotation (tilt).
Reference: <author> Sharkey, P. M.; Murray, D. W.; Vandevelde, S.; Reid, I. D.; and McLauchlan, P. F. </author> <year> 1993. </year> <title> A modular head/eye platform for real-time reactive vision. </title> <journal> Mechatronics Journal 3(4) </journal> <pages> 517-535. </pages>
Reference: <author> Sinha, P. </author> <year> 1994. </year> <title> Object recognition via image invariants: A case study. </title> <booktitle> Investigative Ophthalmology and Visual Science 35 </booktitle> <pages> 1735-1740. </pages>
Reference-contexts: Ratio templates also offer multiple levels of biological plausibility; templates can be either hand-coded or learned adaptively from qualitative image invariants <ref> (Sinha 1994) </ref>. A ratio template is composed of a number of regions and a number of relations, as shown in Figure 3. For each target location in the grayscale peripheral image, a template comparison is performed using a special set of comparison rules.
Reference: <author> Sinha, P. </author> <year> 1996. </year> <title> Perceiving and recognizing three-dimensional forms. </title> <type> Ph.D. Dissertation, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference-contexts: Our strategy for finding eyes decomposes into the following five steps: 1. The incoming wide-field image is filtered using mo tion and past history to find potential face locations. 2. For each potential face location, a face detection algo rithm based on ratio templates <ref> (Sinha 1996) </ref> is used to verify the presence of a face. 3. The face location with the highest score is selected and the active vision system saccades to that face using a learned sensorimotor mapping. 4. <p> Third, it should be a biologically plausible technique. Based on these criteria, we selected the ratio template approach described by Sinha (1994). The ratio template algorithm was designed to detect frontal views of faces under varying lighting conditions, and is an extension of classical template approaches <ref> (Sinha 1996) </ref>. While other techniques handle rotational invariants more accurately (Sung & Poggio 1994), the simplicity of the ratio template algorithm allows us to operate in real time while detecting faces that are most likely to be engaged in social interactions.
Reference: <author> Sinha, P. </author> <year> 1997. </year> <type> Personal communication. </type> <month> August, </month> <year> 1997. </year>
Reference: <author> Sung, K.-K., and Poggio, T. </author> <year> 1994. </year> <title> Example-based learning for view-based human face detection. </title> <type> Technical Report 1521, </type> <institution> MIT Artificial Intelligence Lab Memo. </institution>
Reference-contexts: Based on these criteria, we selected the ratio template approach described by Sinha (1994). The ratio template algorithm was designed to detect frontal views of faces under varying lighting conditions, and is an extension of classical template approaches (Sinha 1996). While other techniques handle rotational invariants more accurately <ref> (Sung & Poggio 1994) </ref>, the simplicity of the ratio template algorithm allows us to operate in real time while detecting faces that are most likely to be engaged in social interactions.
Reference: <author> Terzopoulous, D., and Waters, K. </author> <year> 1991. </year> <title> Techniques for realistic facial modeling and animation. </title> <editor> In Magnenat-Thalmann, M., and Thalmann, D., eds., </editor> <title> Computer Animation '91. </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Other research has focused on the tracking of eyes and facial features for video conferencing (Graf et al. 1996; Maurer & von der Malsburg 1996), as a user interface (Baluja & Pomerleau 1994; Heinzmann & Zelinsky 1997), or in animation <ref> (Terzopoulous & Waters 1991) </ref>, however, these techniques generally begin with calibrated high resolution images where the face dominates the visual field.
Reference: <author> Thayer, S. </author> <year> 1977. </year> <title> Children's detection of on-face and off-face gazes. </title> <booktitle> Developmental Psychology 13 </booktitle> <pages> 673-674. </pages>
Reference: <author> Tsotsos, J. K. </author> <year> 1988. </year> <title> A "complexity level" analysis of vision. </title> <journal> International Journal of Computer Vision 1(4). </journal>
Reference: <author> Turk, M., and Pentland, A. </author> <year> 1991. </year> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience 3(1). van der Spiegel, J.; </journal> <note> Kreider, </note> <author> G.; Claeys, C.; Debuss-chere, I.; Sandini, G.; Dario, P.; Fantini, F.; Belluti, P.; and Soncini, G. </author> <year> 1989. </year> <title> A foveated retina-like sensor using ccd technology. </title> <editor> In Mead, C., and Ismail, M., eds., </editor> <title> Analog VLSI implementation of neural systems. </title> <publisher> Kluwer Academic Publishers. </publisher> <pages> pp. 189-212. </pages>
Reference: <author> Wood, D.; Bruner, J. S.; and Ross, G. </author> <year> 1976. </year> <title> The role of tutoring in problem-solving. </title> <journal> Journal of Child Psychology and Psychiatry 17 </journal> <pages> 89-100. </pages>
Reference-contexts: Detection of eye direction is believed to be a critical precursor of linguistic Copyright 1998, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. development (Scaife & Bruner 1975), theory of mind (Baron-Cohen 1995), and social learning and scaffolding <ref> (Wood, Bruner, & Ross 1976) </ref>. This paper presents the first steps on a developmental progression for building robotic systems that can utilize eye direction as a social signal (Scassellati 1996). The initial goal of our system is to obtain a high resolution image that contains an eye for further processing.
References-found: 31

