URL: http://www.almaden.ibm.com/cs/quest/papers/kdd97_const.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fsrikant,qvu,ragrawalg@almaden.ibm.com  
Title: Mining Association Rules with Item Constraints  
Author: Ramakrishnan Srikant and Quoc Vu and Rakesh Agrawal 
Address: 650 Harry Road, San Jose, CA 95120, U.S.A.  
Affiliation: IBM Almaden Research Center  
Abstract: The problem of discovering association rules has received considerable research attention and several fast algorithms for mining association rules have been developed. In practice, users are often interested in a subset of association rules. For example, they may only want rules that contain a specific item or rules that contain children of a specific item in a hierarchy. While such constraints can be applied as a post-processing step, integrating them into the mining algorithm can dramatically reduce the execution time. We consider the problem of integrating constraints that are boolean expressions over the presence or absence of items into the association discovery algorithm. We present three integrated algorithms for mining association rules with item constraints and discuss their tradeoffs. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agrawal, R., and Shafer, J. </author> <year> 1996. </year> <title> Parallel mining of association rules. </title> <journal> IEEE Transactions on Knowledge and Data Engineering 8(6). </journal>
Reference-contexts: All rights reserved. predicting telecommunications order failures and medical test results. There has been considerable work on developing fast algorithms for mining association rules, including <ref> (Agrawal et al. 1996) </ref> (Savasere, Omiecinski, & Navathe 1995) (Toivonen 1996) (Agrawal & Shafer 1996) (Han, Karypis, & Kumar 1997). Taxonomies (is-a hierarchies) over the items are often available. An example of a taxonomy is shown in Figure 1. <p> All rights reserved. predicting telecommunications order failures and medical test results. There has been considerable work on developing fast algorithms for mining association rules, including (Agrawal et al. 1996) (Savasere, Omiecinski, & Navathe 1995) (Toivonen 1996) <ref> (Agrawal & Shafer 1996) </ref> (Han, Karypis, & Kumar 1997). Taxonomies (is-a hierarchies) over the items are often available. An example of a taxonomy is shown in Figure 1. This taxonomy says that Jacket is-a Outerwear, Ski Pants is-a Outerwear, Outerwear is-a Clothes, etc. <p> Paper Organization We give a formal description of the problem in Section 2. Next, we review the Apri-ori algorithm <ref> (Agrawal et al. 1996) </ref> for mining association rules in Section 3. We use this algorithm as the basis for presenting the three integrated algorithms for mining associations with item constraints in Section 4. <p> The rule holds only if r minimum confidence. Note that the rule will have minimum support because ABCD is frequent. We now present the Apriori algorithm for finding all frequent itemsets <ref> (Agrawal et al. 1996) </ref>. We will use this algorithm as the basis for our presentation. Let k-itemset denote an itemset having k items. Let L k represent the set of frequent k-itemsets, and C k the set of candidate k-itemsets (potentially frequent item-sets). <p> A proof of correctness of the candidate generation procedure is given in <ref> (Agrawal et al. 1996) </ref>. We illustrate the above steps with an example. Let L 3 be ff1 2 3g, f1 2 4g, f1 3 4g, f1 3 5g, f2 3 4gg. After the join step, C 4 will be ff1 2 3 4g, f1 3 4 5gg.
Reference: <author> Agrawal, R.; Mannila, H.; Srikant, R.; Toivonen, H.; and Verkamo, A. I. </author> <year> 1996. </year> <title> Fast Discovery of Association Rules. </title> <editor> In Fayyad, U. M.; Piatetsky-Shapiro, G.; Smyth, P.; and Uthurusamy, R., eds., </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI/MIT Press. </publisher> <pages> chapter 12, 307-328. </pages>
Reference-contexts: All rights reserved. predicting telecommunications order failures and medical test results. There has been considerable work on developing fast algorithms for mining association rules, including <ref> (Agrawal et al. 1996) </ref> (Savasere, Omiecinski, & Navathe 1995) (Toivonen 1996) (Agrawal & Shafer 1996) (Han, Karypis, & Kumar 1997). Taxonomies (is-a hierarchies) over the items are often available. An example of a taxonomy is shown in Figure 1. <p> All rights reserved. predicting telecommunications order failures and medical test results. There has been considerable work on developing fast algorithms for mining association rules, including (Agrawal et al. 1996) (Savasere, Omiecinski, & Navathe 1995) (Toivonen 1996) <ref> (Agrawal & Shafer 1996) </ref> (Han, Karypis, & Kumar 1997). Taxonomies (is-a hierarchies) over the items are often available. An example of a taxonomy is shown in Figure 1. This taxonomy says that Jacket is-a Outerwear, Ski Pants is-a Outerwear, Outerwear is-a Clothes, etc. <p> Paper Organization We give a formal description of the problem in Section 2. Next, we review the Apri-ori algorithm <ref> (Agrawal et al. 1996) </ref> for mining association rules in Section 3. We use this algorithm as the basis for presenting the three integrated algorithms for mining associations with item constraints in Section 4. <p> The rule holds only if r minimum confidence. Note that the rule will have minimum support because ABCD is frequent. We now present the Apriori algorithm for finding all frequent itemsets <ref> (Agrawal et al. 1996) </ref>. We will use this algorithm as the basis for our presentation. Let k-itemset denote an itemset having k items. Let L k represent the set of frequent k-itemsets, and C k the set of candidate k-itemsets (potentially frequent item-sets). <p> A proof of correctness of the candidate generation procedure is given in <ref> (Agrawal et al. 1996) </ref>. We illustrate the above steps with an example. Let L 3 be ff1 2 3g, f1 2 4g, f1 3 4g, f1 3 5g, f2 3 4gg. After the join step, C 4 will be ff1 2 3 4g, f1 3 4 5gg.
Reference: <author> Agrawal, R.; Imielinski, T.; and Swami, A. </author> <year> 1993. </year> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> 207-216. </pages>
Reference-contexts: 1. Introduction The problem of discovering association rules was introduced in <ref> (Agrawal, Imielinski, & Swami 1993) </ref>. Given a set of transactions, where each transaction is a set of literals (called items), an association rule is an expression of the form X ) Y , where X and Y are sets of items.
Reference: <author> Ali, K.; Manganaris, S.; and Srikant, R. </author> <year> 1997. </year> <title> Partial Classification using Association Rules. </title> <booktitle> In Proc. of the 3rd Int'l Conference on Knowledge Discovery in Databases and Data Mining. </booktitle>
Reference-contexts: Applications include discovering affinities for market basket analysis and cross-marketing, catalog design, loss-leader analysis, store layout and customer segmentation based on buying patterns. See (Nearhos, Rothman, & Viveros 1996) for a case study of an application in health insurance, and <ref> (Ali, Manga-naris, & Srikant 1997) </ref> for case studies of applications in 1 Copyright c fl1997, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. predicting telecommunications order failures and medical test results.
Reference: <author> Han, J., and Fu, Y. </author> <year> 1995. </year> <title> Discovery of multiple-level association rules from large databases. </title> <booktitle> In Proc. of the 21st Int'l Conference on Very Large Databases. </booktitle>
Reference-contexts: This generalization of association rules and algorithms for finding such rules are described in (Srikant & Agrawal 1995) <ref> (Han & Fu 1995) </ref>. In practice, users are often interested only in a subset of associations, for instance, those containing at least one item from a user-defined subset of items.
Reference: <author> Han, E.-H.; Karypis, G.; and Kumar, V. </author> <year> 1997. </year> <title> Scalable parallel data mining for association rules. </title> <booktitle> In Proc. of the ACM SIGMOD Conference on Management of Data. </booktitle>
Reference-contexts: All rights reserved. predicting telecommunications order failures and medical test results. There has been considerable work on developing fast algorithms for mining association rules, including (Agrawal et al. 1996) (Savasere, Omiecinski, & Navathe 1995) (Toivonen 1996) (Agrawal & Shafer 1996) <ref> (Han, Karypis, & Kumar 1997) </ref>. Taxonomies (is-a hierarchies) over the items are often available. An example of a taxonomy is shown in Figure 1. This taxonomy says that Jacket is-a Outerwear, Ski Pants is-a Outerwear, Outerwear is-a Clothes, etc.
Reference: <author> Nearhos, J.; Rothman, M.; and Viveros, M. </author> <year> 1996. </year> <title> Applying data mining techniques to a health insurance information system. </title> <booktitle> In Proc. of the 22nd Int'l Conference on Very Large Databases. </booktitle>
Reference-contexts: The problem is to find all association rules that satisfy user-specified minimum support and minimum confidence constraints. Applications include discovering affinities for market basket analysis and cross-marketing, catalog design, loss-leader analysis, store layout and customer segmentation based on buying patterns. See <ref> (Nearhos, Rothman, & Viveros 1996) </ref> for a case study of an application in health insurance, and (Ali, Manga-naris, & Srikant 1997) for case studies of applications in 1 Copyright c fl1997, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. predicting telecommunications order failures and medical test results.
Reference: <author> Savasere, A.; Omiecinski, E.; and Navathe, S. </author> <year> 1995. </year> <title> An efficient algorithm for mining association rules in large databases. </title> <booktitle> In Proc. of the VLDB Conference. </booktitle>
Reference-contexts: All rights reserved. predicting telecommunications order failures and medical test results. There has been considerable work on developing fast algorithms for mining association rules, including (Agrawal et al. 1996) <ref> (Savasere, Omiecinski, & Navathe 1995) </ref> (Toivonen 1996) (Agrawal & Shafer 1996) (Han, Karypis, & Kumar 1997). Taxonomies (is-a hierarchies) over the items are often available. An example of a taxonomy is shown in Figure 1. This taxonomy says that Jacket is-a Outerwear, Ski Pants is-a Outerwear, Outerwear is-a Clothes, etc.
Reference: <author> Srikant, R., and Agrawal, R. </author> <year> 1995. </year> <title> Mining Generalized Association Rules. </title> <booktitle> In Proc. of the 21st Int'l Conference on Very Large Databases. </booktitle>
Reference-contexts: For example, we may infer a rule that people who buy Outerwear tend to buy Hiking Boots from the fact that people bought Jackets with Hiking Boots and Ski Pants with Hiking Boots. This generalization of association rules and algorithms for finding such rules are described in <ref> (Srikant & Agrawal 1995) </ref> (Han & Fu 1995). In practice, users are often interested only in a subset of associations, for instance, those containing at least one item from a user-defined subset of items. <p> Step 3 does not change C b 2 since all 1-subsets that satisfy B are frequent. Finally, we add f1 2g to C b 4.3 Taxonomies The enhancements to the Apriori algorithm for integrating item constraints apply directly to the algorithms for mining association rules with taxonomies given in <ref> (Srikant & Agrawal 1995) </ref>. We discuss the Cumulate algorithm here. 3 This algorithm adds all ancestors of each item in the transaction to the transaction, and then runs the Apriori algorithm over these "extended transactions". <p> Cumulate only checks for such candidates during the second pass (candidates of size 2). For subsequent passes, the apriori candidate generation procedure ensures that no candidate that 3 The other fast algorithm in <ref> (Srikant & Agrawal 1995) </ref>, EstMerge, is similar to Cumulate, but also uses sampling to decrease the number of candidates that are counted. contains both an item and its ancestor will be gen erated.
Reference: <author> Toivonen, H. </author> <year> 1996. </year> <title> Sampling large databases for association rules. </title> <booktitle> In Proc. of the 22nd Int'l Conference on Very Large Databases, </booktitle> <pages> 134-145. </pages>
Reference-contexts: All rights reserved. predicting telecommunications order failures and medical test results. There has been considerable work on developing fast algorithms for mining association rules, including (Agrawal et al. 1996) (Savasere, Omiecinski, & Navathe 1995) <ref> (Toivonen 1996) </ref> (Agrawal & Shafer 1996) (Han, Karypis, & Kumar 1997). Taxonomies (is-a hierarchies) over the items are often available. An example of a taxonomy is shown in Figure 1. This taxonomy says that Jacket is-a Outerwear, Ski Pants is-a Outerwear, Outerwear is-a Clothes, etc. <p> We use this algorithm as the basis for presenting the three integrated algorithms for mining associations with item constraints in Section 4. However, our techniques apply to other algorithms that use apriori candidate generation, including the recently published <ref> (Toivonen 1996) </ref>. We discuss the tradeoffs between the algorithms in Section 5, and conclude with a summary in Section 6. 2. Problem Statement Let L = fl 1 ; l 2 ; : : : ; l m g be a set of literals, called items. <p> Although we restricted our discussion to the Apriori algorithm, these ideas apply to other algorithms that use apriori candidate generation, including the recent <ref> (Toivonen 1996) </ref>. The main idea in (Toivonen 1996) is to first run Apriori on a sample of the data to find item-sets that are expected to be frequent, or all of whose subsets are are expected to be frequent. (We also need to count the latter to ensure that no frequent <p> Although we restricted our discussion to the Apriori algorithm, these ideas apply to other algorithms that use apriori candidate generation, including the recent <ref> (Toivonen 1996) </ref>. The main idea in (Toivonen 1996) is to first run Apriori on a sample of the data to find item-sets that are expected to be frequent, or all of whose subsets are are expected to be frequent. (We also need to count the latter to ensure that no frequent itemsets were missed.) These itemsets are
References-found: 10

