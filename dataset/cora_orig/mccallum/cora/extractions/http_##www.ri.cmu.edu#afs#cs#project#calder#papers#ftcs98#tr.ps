URL: http://www.ri.cmu.edu/afs/cs/project/calder/papers/ftcs98/tr.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/calder/www/raid.html
Root-URL: 
Title: Proving Correctness of a Controller Algorithm for the RAID Level 5 System  
Author: Mandana Vaziri Nancy Lynch and Jeannette Wing 
Address: Cambridge, MA 02139 Pittsburgh, PA 15213  
Affiliation: Laboratory for Computer Science Computer Science Department Massachusetts Institute of Technology Carnegie Mellon University  
Abstract: Most RAID controllers implemented in industry are complicated and difficult to reason about. This complexity has led to software and hardware systems that are difficult to debug and hard to modify. To overcome this problem Courtright and Gibson have developed a rapid prototyping framework for RAID architectures which relies on a generic controller algorithm [1]. The designer of a new architecture needs to specify parts of the generic controller algorithm and must justify the validity of the controller algorithm obtained. However the latter task may be difficult due to the concurrency of operations on the disks. This is the reason why it would be useful to provide designers with an automated verification tool tailored specifically for the RAID pro-totyping system. As a first step towards building such a tool, our approach consists of studying several controller algorithms manually, to determine the key properties that need to be verified. This paper presents the modeling and verification of a controller algorithm for the RAID Level 5 System [5]. We model the system using I/O automata [6], give an external requirements specification, and prove that the model implements its specification. We use a key invariant to find an error in a controller algorithm for the RAID Level 6 System [5]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. V. Courtright II and G. A. Gibson. </author> <title> "Backward error recovery in redundant disk arrays." </title> <booktitle> Proceedings of the 20th International Conference for the Resource Management and Performance Evaluation of Enterprise Computing Systems (CMG). </booktitle> <month> December 4-9 </month> <year> 1994, </year> <pages> pp. 63-74. </pages>
Reference-contexts: To overcome this problem Courtright and Gibson have developed a rapid prototyping framework for RAID architectures fl This work was supported by DARPA contracts F19628-95-C-0118 and F30602-97-2-0031, and AFOSR contract F49620-97-1-0337. which relies on a generic controller algorithm <ref> [1] </ref>. The designer of a new architecture needs to specify parts of the generic controller algorithm and must justify the validity of the controller algorithm obtained. However the latter task may be difficult due to the concurrency of operations on the disks. <p> This method involves enumerating a large number of erroneous states. Furthermore it results in architecture-specific controller algorithms, making extension to new architectures difficult. To overcome this problem, Courtright and Gibson propose a form of backward error-recovery method <ref> [1] </ref>, based on retry 1 . When an error is encountered, the state of the system is modified to note which disk has failed, and the operation is retried based on the new state. In this approach, operations are represented as Directed Acyclic Graphs (DAGs). <p> In this approach, operations are represented as Directed Acyclic Graphs (DAGs). Each node in a DAG is a low-level op to be performed on a disk or a low-level op that computes data. Courtright and Gibson's method of error recovery <ref> [1] </ref> has two requirements. First, each low-level op must be idempotent, which ensures that a low-level op that is executed several times has the same effect as if it is executed only once. <p> This task would be easier if an automated verification tool were provided. As a first step towards building such a tool, our approach consists of studying several controller algorithms manually. This paper studies the correctness of a controller algorithm <ref> [1] </ref> for the RAID Level 5 system [5], that uses Courtright and Gibson's error recovery method. We chose this architecture because of its popularity, as well as for its relative simplicity. We model the algorithm using I/O automata [7], and give an external requirements specification.
Reference: [2] <author> William V. </author> <title> Courtright II, "A Transactional Approach to Redundant Disk Array Implementation." </title> <institution> Dept. of Electrical and Computer Engineering, Carnegie Mel-lon University, Pittsburgh, PA, </institution> <type> Ph.D. thesis, </type> <month> April </month> <year> 1997. </year>
Reference-contexts: For each parity group, the controller chooses an algorithm for carrying out the operation and starts executing it. If a disk needed in an algorithm fails 1 Courtright has since moved on to a similar but different error recovery method called roll-away error recovery <ref> [2] </ref> i 0 RD RD 0 RD f+1 XOR while the algorithm is running, then the controller stops the execution of that algorithm and chooses another one to complete the operation. The controller assumes at most one failure. Disk array algorithms are represented as Directed Acyclic Graphs (DAGs). <p> However hand-proofs are essential at this stage of the design of the tool, because they allow us to determine the exact expression of properties to verify. Courtright credits our work in his PhD thesis <ref> [2] </ref> as playing a role in debugging his designs and he encourages continued work in this direction, especially in collaboration with industry partners. <p> Future work consists of proving correctness of other RAID controllers using Courtright and Gibson's error recovery, as well as considering controller algorithms that use Courtright's latest error recovery method <ref> [2] </ref>. Finally, we plan to build a special-purpose verification tool.
Reference: [3] <author> Garth Gibson. </author> <title> "Redundant Disk Arrays: Reliable, Parallel Secondary Storage". </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1990. </year> <note> Report UCB/CSD 91/613. </note>
Reference-contexts: We consider independent catastrophic disk failures, i.e., disk failures in which all data stored on the disk becomes inaccessible and the disk cannot be written any further. RAID systems are designed to be fault-tolerant by storing redundant data <ref> [3] </ref> on extra disks and to tolerate 1 or 2 disk failures. The redundancy can be an identical copy of each disk, also known as disk mirroring, or it can involve having a parity disk [9], for n disks containing data.
Reference: [4] <author> G. A. Gibson and D. A. Patterson, </author> <title> "Designing disk arrays for high data reliability", </title> <journal> Journal of Parallel and Distributed Computing. </journal> <pages> 17(1-2), </pages> <year> 1993, </year> <pages> 4-27. </pages>
Reference-contexts: When the number of disks increases in a disk array, the availability of data and the reliability of the disk array may decrease dramatically <ref> [4] </ref>. We consider independent catastrophic disk failures, i.e., disk failures in which all data stored on the disk becomes inaccessible and the disk cannot be written any further.
Reference: [5] <author> G. Gibson, W. Courtright II, M. Holland, and J. Ze-lenka, </author> <title> "RAIDframe: Rapid prototyping for disk arrays," </title> <institution> Computer Science Technical Report CMU-CS-95-200, Carnegie Mellon University, </institution> <year> 1995. </year>
Reference-contexts: As a first step towards building such a tool, our approach consists of studying several controller algorithms manually, to determine the key properties that need to be verified. This paper presents the correctness of a controller algorithm <ref> [5] </ref> for the RAID Level 5 system. We chose this architecture because of its popularity, as well as for its relative simplicity. Our method consists of modeling the controller formally, giving an external requirements specification and proving that the model satisfies its specification. <p> Our study results in a key invariant for the controller that can be generalized for other architectures. We use this invariant to find an error in a RAID Level 6 controller <ref> [5] </ref>. The outline of the paper is as follows. Section 2 gives background on RAID systems. Section 3 presents the RAID Level 5 system informally. Section 4 gives conventions used throughout the paper. Section 5 describes the specification and Section 6 our model of RAID Level 5. <p> This task would be easier if an automated verification tool were provided. As a first step towards building such a tool, our approach consists of studying several controller algorithms manually. This paper studies the correctness of a controller algorithm [1] for the RAID Level 5 system <ref> [5] </ref>, that uses Courtright and Gibson's error recovery method. We chose this architecture because of its popularity, as well as for its relative simplicity. We model the algorithm using I/O automata [7], and give an external requirements specification. <p> We then prove that the model implements its specification, in the sense that there exists a simulation relation [7] from the model to its specification. 3 Informal Description of the RAID Level 5 System RAID Level 5 <ref> [5] </ref> uses parity and can tolerate one disk failure. In this architecture, data is block-interleaved and parity blocks are distributed among all the disks in the array. A parity block is the bitwise XOR of all the blocks it covers. <p> for the step correspondence of read (i) (write (i,v)), in the case where RAID 0 is running a second DAG to complete an operation and this low-level op has been performed once before. 8 Extension We now turn our attention to a controller algorithm for the RAID Level 6 architecture <ref> [5] </ref>. We generalize part of the main invariant, consistency, and use it to find an error in a RAID Level 6 DAG. 8.1 RAID Level 6 RAID Level 6 uses two parity blocks for each group of n blocks stored on separate disks. It can tolerate two disk failures.
Reference: [6] <author> N. Lynch and M. Tuttle. </author> <title> An Introduction to Input/Output Automata. </title> <journal> CWI-Quaterly, </journal> <volume> 2(3): </volume> <pages> 219-246, </pages> <month> September </month> <year> 1989. </year> <institution> Centrum voor Wiskunde en In-formatica, </institution> <address> Amsterdam, The Netherlands. </address>
Reference: [7] <author> Nancy A. Lynch, </author> <title> "Distributed Algorithms", </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1996. </year>
Reference-contexts: This paper studies the correctness of a controller algorithm [1] for the RAID Level 5 system [5], that uses Courtright and Gibson's error recovery method. We chose this architecture because of its popularity, as well as for its relative simplicity. We model the algorithm using I/O automata <ref> [7] </ref>, and give an external requirements specification. We then prove that the model implements its specification, in the sense that there exists a simulation relation [7] from the model to its specification. 3 Informal Description of the RAID Level 5 System RAID Level 5 [5] uses parity and can tolerate one <p> We chose this architecture because of its popularity, as well as for its relative simplicity. We model the algorithm using I/O automata <ref> [7] </ref>, and give an external requirements specification. We then prove that the model implements its specification, in the sense that there exists a simulation relation [7] from the model to its specification. 3 Informal Description of the RAID Level 5 System RAID Level 5 [5] uses parity and can tolerate one disk failure. In this architecture, data is block-interleaved and parity blocks are distributed among all the disks in the array. <p> P n , Q 2 P, P := Q is equivalent to the following piece of code: for all i 2 I do P [i] := Q [i] od ; P [n] := ? 5 Specification In this section, we describe the specification, Spec, for the system using I/O Automata <ref> [7] </ref>. Spec makes the assumption that there are n bits, indexed from 0 to n 1 that can be read or written. <p> Rec is updated by fail (i), ReadBack (P ) and WriteOK. 7 Proof of Correctness This section presents the proof of correctness. We show that RAID 0 implements Spec 0 , by showing that there exists a simulation relation <ref> [7] </ref> from RAID 0 to Spec 0 . Section 7.1 presents the key invariant called consistency. Section 7.2 gives the simulation relation to be proved. Section 7.3 gives the step correspon dence of the proof.
Reference: [8] <author> K.L. McMillan, </author> <title> "Symbolic Model Checking: an Approach to the State Explosion Problem", </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1992, </year> <month> CMU-CS-92-131. </month>
Reference-contexts: By performing this case study, we formalized a key invariant, consistency, which helped in finding an error in a different more complicated RAID controller algorithm. This project started out by a preliminary study using the model checker SMV <ref> [8] </ref>. We modeled the DAGs for RAID Level 5 separately and used the tool to show that the DAGs preserve consistency. However it became clear that our notion of consistency was not accurate and that we needed to formalize this property.
Reference: [9] <author> David A. Patterson, Garth A. Gibson, and Randy Katz. </author> <title> "A Case for Redundant Arrays of Inexpensive Disks (RAID)". </title> <booktitle> Proceedings SIGMOD International Conference on Data Management, </booktitle> <year> 1988, </year> <pages> pp. 109-116. </pages>
Reference-contexts: Finally, Section 9 is a summary of our conclusions and future work. 2 RAID Systems RAID or Redundant Arrays of Inexpensive Disks were developed in the 1980's to address the need for secondary storage systems with higher performance <ref> [9] </ref>. A RAID system is composed of a disk array, and a disk array controller. The controller's function is to receive an operation from the user of the disk array, and to carry it out by performing a set of low-level operations (or low-level op) on specific disks. <p> RAID systems are designed to be fault-tolerant by storing redundant data [3] on extra disks and to tolerate 1 or 2 disk failures. The redundancy can be an identical copy of each disk, also known as disk mirroring, or it can involve having a parity disk <ref> [9] </ref>, for n disks containing data. The parity disk contains blocks, called parity blocks, that cover groups of n blocks independently stored. A set of n blocks along with the parity block that covers them is called a parity group. <p> The parity block is computed by performing a bit-wise XOR on the blocks it covers. Given any set of n blocks, the (n + 1)st block can be recovered by performing an XOR on the n blocks. There are several RAID architectures that are classified into five "levels" <ref> [9] </ref>. Different RAID architectures can be distinguished based on their type of encoding, mapping and algorithms used to access data. The encoding indicates the type of redundancy information used, and the mapping the placement of data and redundant information on the disk array.
Reference: [10] <author> Mandana Vaziri and Nancy Lynch. </author> <title> "Proving Correctness of a Controller Algorithm for the RAID Level 5 System". </title> <institution> MIT Laboratory for Computer Science, </institution> <type> Technical Report, </type> <month> December </month> <year> 1997. </year> <note> Available by anonymous ftp at ftp://theory.lcs.mit.edu/pub/tds/raid.ps.Z. </note>
Reference-contexts: Section 7.1 presents the key invariant called consistency. Section 7.2 gives the simulation relation to be proved. Section 7.3 gives the step correspon dence of the proof. The complete formal proof of the simulation relation is not presented here and appears in <ref> [10] </ref>. 7.1 Consistency In this section, we present the consistency property. A proof of this Lemma appears in [10]. Informally, a parity group with no failure is consistent, if the XOR of all bits is equal to 0. <p> Section 7.3 gives the step correspon dence of the proof. The complete formal proof of the simulation relation is not presented here and appears in <ref> [10] </ref>. 7.1 Consistency In this section, we present the consistency property. A proof of this Lemma appears in [10]. Informally, a parity group with no failure is consistent, if the XOR of all bits is equal to 0.
References-found: 10

