URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1992/UM-CS-1992-030.ps
Refering-URL: http://www-ml.cs.umass.edu/
Root-URL: 
Email: brodley@cs.umass.edu  
Title: Dynamic Automatic Model Selection  
Author: Carla E. Brodley 
Address: Amherst, Massachusetts 01003 USA  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: COINS Technical Report 92-30 February 1992 Abstract The problem of how to learn from examples has been studied throughout the history of machine learning, and many successful learning algorithms have been developed. A problem that has received less attention is how to select which algorithm to use for a given learning task. The ability of a chosen algorithm to induce a good generalization depends on how appropriate the model class underlying the algorithm is for the given task. We define an algorithm's model class to be the representation language it uses to express a generalization of the examples. Supervised learning algorithms differ in their underlying model class and in how they search for a good generalization. Given this characterization, it is not surprising that some algorithms find better generalizations for some, but not all tasks. Therefore, in order to find the best generalization for each task, an automated learning system must search for the appropriate model class in addition to searching for the best generalization within the chosen class. This thesis proposal investigates the issues involved in automating the selection of the appropriate model class. The presented approach has two facets. Firstly, the approach combines different model classes in the form of a model combination decision tree, which allows the best representation to be found for each subconcept of the learning task. Secondly, which model class is the most appropriate is determined dynamically using a set of heuristic rules. Explicit in each rule are the conditions in which a particular model class is appropriate and if it is not, what should be done next. In addition to describing the approach, this proposal describes how the approach will be evaluated in order to demonstrate that it is both an efficient and effective method for automatic model selection. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., & Kibler, D. </author> <year> (1989). </year> <title> Noise-tolerant instance-based learning algorithms. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 794-799). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: IB3-CI is an instance-based learning (IBL) algorithm that constructs new features in response to classification errors. IBL algorithms represent concept descriptions with a set of stored instances, and update the concept description after each instance is processed. IB3-CI integrates IB3 <ref> (Aha & Kibler, 1989) </ref> with STAGGER. Like STAGGER, IB3-CI uses LN and LS weights to guide its feature formation process. Its objective is to reduce the similarity between two instances (the new instance and the stored instance judged most similar) when a misclassification occurs.
Reference: <author> Aha, David W. </author> <year> (1990). </year> <title> A study of instance-based algorithms for supervised learning tasks: Mathematical, empirical, and psychological evaluations. </title> <type> Doctoral dissertation, </type> <institution> Department of Information and Computer Science, University of California, </institution> <address> Irvine, CA. </address>
Reference-contexts: In such cases, a multivariate test will underfit the instances (Duda & Hart, 1973) and the information metric used to select a univariate test will perform poorly <ref> (Aha, 1990) </ref>. 3.2.2 Control Strategy In this section we propose a control strategy for searching the model space described in the previous section. The control strategy is a rule-based system in which the rules use heuristic measurements to direct the search of the model space. <p> A common situation in which overfitting occurs is when there are too few training instances to make a good choice for which variable (s) to use as a test at a node. If the space is impoverished at a node, then an instance based classifier is a good model <ref> (Aha, 1990) </ref>. We can choose between pruning back a node to a leaf (and therefore a single class) or we can retain the training instances and use them to form an IBC.
Reference: <author> Aha, D. W. </author> <year> (1991). </year> <title> Incremental constructive induction: An instance-based approach. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (pp. </booktitle> <pages> 117-121). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: PT2 and LMDT use measures of the error rate of the current LTU (linear machine) to determine when to stop searching. Incremental Algorithms: In this section we describe two incremental concept learning algorithms, STAGGER (Schlimmer, 1987) and IB3-CI <ref> (Aha, 1991) </ref>, which adjust the concept formalism during the learning process. An incremental learning algorithm updates the concept description after each new instance is observed, such that after each update the current concept description can be used to classify all previously observed instances with a high degree of accuracy.
Reference: <author> Amarel, S. </author> <year> (1968). </year> <title> On representations of problems of reasoning about actions. </title> <editor> In Michie (Ed.), </editor> <booktitle> Machine Intelligence. </booktitle> <publisher> Edinburgh University Press. </publisher>
Reference-contexts: Hybrid algorithms seek to combine the strengths of different algorithms by selecting among a set of model classes. Indeed, we can trace this view back as far as 1968 when Amarel showed that by changing the representation of a problem one changes a system's ability to find a solution <ref> (Amarel, 1968) </ref>. Amarel suggests that we should design problem solving procedures such that they can find a point of view of the problem that maximally simplifies the process of finding a solution.
Reference: <author> Ash, T. </author> <year> (1989). </year> <title> Dynamic node creation in backpropagation networks, </title> <type> (ICS Report 8901), </type> <address> San Diego, CA: </address> <institution> University of California, Institute for Cognitive Science. </institution>
Reference-contexts: In addition, we will compare our system to an adaptive neural net algorithm, such as DNC <ref> (Ash, 1989) </ref>. The experiments will compare the quality of the generalization induced using our hybrid formalism to the generalizations induced by each of the other algorithms.
Reference: <author> Blumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. K. </author> <year> (1987). </year> <title> Learnability and the Vapnik-Chervonenkis dimension, </title> <institution> (UCSC-CRL-87-20), Santa Cruz, CA: University of California. </institution>
Reference: <author> Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. </author> <year> (1984). </year> <title> Classification and regression trees. </title> <address> Belmont, CA: </address> <publisher> Wadsworth International Group. </publisher>
Reference-contexts: Such metrics aim to reduce the impurity of each resulting partition. The impurity of a partition is at a minimum if it contains elements of only one class. The impurity is at a maximum if all classes are equally represented in the partition <ref> (Breiman, Friedman, Olshen & Stone, 1984) </ref>. A univariate decision tree is biased toward concepts that can be expressed as Boolean combinations of the initial input features that describe each instance.
Reference: <author> Brodley, C. E., & Utgoff, P. E. </author> <year> (1992). </year> <title> Multivariate versus univariate decision trees, </title> <type> (Coins Technical Report 92-8), </type> <institution> Amherst, MA: University of Massachusetts, Department of Computer and Information Science. </institution>
Reference-contexts: The control strategy for the perceptron tree algorithm employs a fixed order selection strategy; it first tries an LTU, if that fails, it then grows a symbolic decision tree node. There are two successor systems to the original perceptron tree algorithm, PT2 (Utgoff & Brodley, 1990) and LMDT <ref> (Brodley & Utgoff, 1992) </ref>. PT2 induces decision trees in which each node in the tree is an LTU. At each node in the tree, the algorithm trains an LTU based on all n of the input variables. <p> We would desire a less greedy search procedure than that used by LMDT <ref> (Brodley & Utgoff, 1992) </ref>. We will employ a search procedure similar to that used by PT2 and CART (Utgoff & Brodley, 1990; Breiman, Friedman, Olshen & Stone, 1984), which perform sequential backward elimination search procedures.
Reference: <author> Chatterjee, S., & Price, B. </author> <year> (1977). </year> <title> Regression analysis by example. </title> <address> New York: </address> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: the human analyst select the appropriate model, whereas in the field of machine learning they were created to replace the human analyst in the model selection process. 2.1 Statistical Approaches Model selection in statistics refers to the process of estimating the relationships among the variables of a given data set <ref> (Chatterjee & Price, 1977) </ref>. <p> Examination of the fit of a particular regression equation to the data requires a further assumption about the residuals: for a small data set the e i must be normally distributed <ref> (Chatterjee & Price, 1977) </ref>. (Due to the Central Limit Theorem this is always true for large data sets.) The first two assumptions, that the residual is a random variable, with mean zero and constant variance, 2 , follow from the assumptions about the disturbance terms (i.e, that the " i ; <p> The proportion is computed by R 2 = P P (Y i Y ) 2 . R 2 falls between 0 and 1 and we can measure its significance using an f-test <ref> (Chatterjee & Price, 1977) </ref>. With the advent of computers, automated model selection procedures have been created. There are several methods for finding the appropriate model, and all require specification of the entire set of terms to be considered for inclusion in the model. <p> We present the three most commonly used procedures for finding the appropriate model. A more comprehensive list can be found in Draper and Smith (1981). The first procedure evaluates all possible equations <ref> (Chatterjee & Price, 1977) </ref>. This method gives the analyst the maximum amount of information available concerning the relationships between y and the Z i 's.
Reference: <author> Clark, P., & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-283. </pages>
Reference: <author> Cover, T. M. </author> <year> (1973). </year> <title> Enumerative source coding. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-19, </volume> <pages> 73-77. </pages>
Reference: <author> Dietterich, T. G., London, B., Clarkson, K., & Dromey, G. </author> <year> (1982). </year> <title> Learning and inductive inference. </title> <editor> In Cohen & Feigenbaum (Eds.), </editor> <booktitle> The Handbook of Artificial Intelligence: Volume III. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Draper, N. R., & Smith, H. </author> <year> (1981). </year> <title> Applied regression analysis. </title> <address> New York: </address> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: The least squares method was invented independently by C. F. Gauss and A. M. Legendre <ref> (Draper & Smith, 1981) </ref>. The method finds estimates, b i (for the fi i ) by minimizing the sum of the squared residuals, e i ; i = 1; ::; n, where n is the number of observed data points. <p> If the disturbance terms of the independent variables are not independently distributed, then one must use the method of general least squares (GLS) (also called weighted least squares) <ref> (Draper & Smith, 1981) </ref>. GLS requires a specification of a matrix of weights, , which captures all systematic information about the disturbance process. <p> The first two assumptions, that the residual is a random variable, with mean zero and constant variance, 2 , follow from the assumptions about the disturbance terms (i.e, that the " i ; i = 1; ::k are random variables, with zero mean and an unknown constant variance, 2 ) <ref> (Draper & Smith, 1981) </ref>. To measure the fit of a regression equation to the data, we can measure the proportion of total variation about the mean Y explained by the regression. The proportion is computed by R 2 = P P (Y i Y ) 2 . <p> The two most common are stepwise forward selection (SFS) and stepwise backward elimination (SBE) <ref> (Draper & 7 Smith, 1981) </ref>. SFS begins with no variables in the model and adds one variable at a time until either all variables are in the model, or until a stopping criterion is satisfied.
Reference: <author> Duda, R. O., & Hart, P. E. </author> <year> (1973). </year> <title> Pattern classification and scene analysis. </title> <address> New York: </address> <publisher> Wiley & Sons. </publisher>
Reference-contexts: If the instances are linearly separable by a linear machine, then the above training procedure, with a suitable error correction rule as described below, will find a solution machine in a finite number of steps <ref> (Duda & Hart, 1973) </ref>. A linear machine is biased toward concepts that are linearly separable. If, however, the space is not linearly separable then a linear machine, trained using the absolute error correction rule (Duda & Hart, 1973), can not represent the concept and as a result will misclassify some percentage <p> correction rule as described below, will find a solution machine in a finite number of steps <ref> (Duda & Hart, 1973) </ref>. A linear machine is biased toward concepts that are linearly separable. If, however, the space is not linearly separable then a linear machine, trained using the absolute error correction rule (Duda & Hart, 1973), can not represent the concept and as a result will misclassify some percentage of the instances. There are several training procedures aimed at finding a good linear machine even when the space is not linearly separable. <p> There are several training procedures aimed at finding a good linear machine even when the space is not linearly separable. The LMS training rule seeks to minimize the squared length of the error vector; it tries to minimize the overall error rather than just focusing on misclassified instances <ref> (Duda & Hart, 1973) </ref>. Gallant's pocket algorithm searches for the set of weights that produce the most consecutive correct classifications when trained using instances drawn randomly from the training set (Gallant, 1986). <p> An instance based classifier (IBC) is a set of n distinct instances, each from one of m classes, that are used to assign an instance to one of the m classes. A simple IBC is the k-nearest neighbor (k-NN) classifier <ref> (Duda & Hart, 1973) </ref>, which classifies an instance according to the majority classification of its k nearest neighbors. Typically, to compute how near one instance is to another, the Euclidean distance between the two instances is used. To handle symbolic data we will encode symbolic variables as propositional variables. <p> Finally, instance based classifiers are well suited to instance spaces in which there are few observed instances, which can happen near the leaves of a decision tree. In such cases, a multivariate test will underfit the instances <ref> (Duda & Hart, 1973) </ref> and the information metric used to select a univariate test will perform poorly (Aha, 1990). 3.2.2 Control Strategy In this section we propose a control strategy for searching the model space described in the previous section. <p> For example, if the number of training instances is less than twice the number of features used to describe the instances (the capacity of a hyperplane), then a linear threshold unit will underfit the instances <ref> (Duda & Hart, 1973) </ref>. In this case, we find the best univariate test as measured by its information content. However, if the number of instances is greater than the capacity of a hyperplane, then we induce a linear machine based on all n input features.
Reference: <author> Elias, P. </author> <year> (1975). </year> <title> Universal codeword sets and representations of the integers. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-21, </volume> <pages> 194-203. </pages>
Reference: <author> Fahlman, S. E., & Lebiere, C. </author> <year> (1990). </year> <title> The cascade correlation architecture. </title> <booktitle> Advances in 43 Neural Information Processing Systems, </booktitle> <volume> 2, </volume> <pages> 524-532. </pages>
Reference-contexts: The upstart algorithm uses binary units and grows a binary tree-structured network (Frean, 1990b). Two new children are added if a parent cannot classify the instances correctly; the children correct the output of the parent. The cascade correlation algorithm starts with one layer <ref> (Fahlman & Lebiere, 1990) </ref>. If the required mapping can not be learned by the one layer, then a hidden unit is added as a hidden layer and trained while the previously trained weights are frozen. More hidden units are added until the correct mapping is learned.
Reference: <author> Falkenhainer, B. C., & Michalski, R. S. </author> <year> (1986). </year> <title> Integrating quantitative and qualitative discovery: The ABACUS system. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 367-401. </pages>
Reference-contexts: In summary, BACON uses a depth-first search to find the first equation (called a law in BACON) that is able to predict the value of the user specified dependent variable. ABACUS is a system that discovers multiple equations for numeric data <ref> (Falkenhainer & Michalski, 1986) </ref>. The system first discovers a set of equations that explain the data and then uses the A q algorithm (Michalski & Chilausky, 1980) to generate rules for when each equation should be used.
Reference: <author> Fisher, D. H., & McKusick, K.B. </author> <year> (1989). </year> <title> An empirical comparison of ID3 and backpropagation. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 788-793). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Frean, M. </author> <year> (1990a). </year> <title> Small nets and short paths: Optimising neural computation. </title> <type> Doctoral dissertation, </type> <institution> Center for Cognitive Science, University of Edinburgh. </institution>
Reference-contexts: Gallant's pocket algorithm searches for the set of weights that produce the most consecutive correct classifications when trained using instances drawn randomly from the training set (Gallant, 1986). The thermal training rule enables a linear threshold unit to converge to a set of boundaries using an annealing coefficient <ref> (Frean, 1990a) </ref>. Utgoff and Brodley (1992) have adapted this idea to a linear machine and we will use their method to train linear machines in the proposed system.
Reference: <author> Frean, M. </author> <year> (1990b). </year> <title> The upstart algorithm: A method for constructing and training feedfor-ward neural networks. </title> <journal> Neural Computation, </journal> <volume> 2, </volume> <pages> 198-209. </pages>
Reference-contexts: Ash's (1989) dynamic node creation algorithm trains networks that have only one hidden layer. If the rate of decrease in the error falls below a preset threshold, a new fully-connected unit is added. The upstart algorithm uses binary units and grows a binary tree-structured network <ref> (Frean, 1990b) </ref>. Two new children are added if a parent cannot classify the instances correctly; the children correct the output of the parent. The cascade correlation algorithm starts with one layer (Fahlman & Lebiere, 1990).
Reference: <author> Gallant, S. I. </author> <year> (1986). </year> <title> Optimal linear discriminants. </title> <booktitle> Proceedings of the International Conference on Pattern Recognition (pp. </booktitle> <pages> 849-852). </pages> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: PT2 induces decision trees in which each node in the tree is an LTU. At each node in the tree, the algorithm trains an LTU based on all n of the input variables. When a good set of weights has been found, as measured by Gallant's pocket algorithm <ref> (Gallant, 1986) </ref>, the system then tries to eliminate variables irrelevant to classification. It trains n LTUs, each based on n 1 variables (the result of eliminating a different variable each time). This greedy search procedure continues until further elimination will decrease the classification accuracy of the LTU. <p> Gallant's pocket algorithm searches for the set of weights that produce the most consecutive correct classifications when trained using instances drawn randomly from the training set <ref> (Gallant, 1986) </ref>. The thermal training rule enables a linear threshold unit to converge to a set of boundaries using an annealing coefficient (Frean, 1990a). Utgoff and Brodley (1992) have adapted this idea to a linear machine and we will use their method to train linear machines in the proposed system.
Reference: <author> Hanson, S. J., & Pratt, L. Y. </author> <year> (1989). </year> <title> Comparing biases for minimal network construction with backpropagation. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 1, </volume> <pages> 177-185. </pages>
Reference: <author> Hocking, R. R. </author> <year> (1986). </year> <title> The analysis and selection of variables in linear regression. </title> <journal> Biometrics, </journal> <volume> 32, </volume> <pages> 1-49. </pages>
Reference-contexts: To evaluate the different regression equations one of several different criteria can be used. The choice of which criterion to use should be related to the intended use of the regression <ref> (Hocking, 1986) </ref>. For example, if the objective is to obtain a good description of the independent variable and the OLS method is used, then the R 2 statistic is a good choice (Hocking, 1986). <p> The choice of which criterion to use should be related to the intended use of the regression <ref> (Hocking, 1986) </ref>. For example, if the objective is to obtain a good description of the independent variable and the OLS method is used, then the R 2 statistic is a good choice (Hocking, 1986). Another commonly used criterion is the residual mean square error, RM S p = SSE P =(n p), where SSE p is the residual sum of squares for a p-term equation given n data points. Given two equations, the one with the smaller RMS is preferred.
Reference: <author> Honavar, V., & Uhr, L. </author> <year> (1988). </year> <title> A network of neuron-like units that learn to perceive by generation as well as reweighting of its links. </title> <booktitle> Proc. of the 1988 Connectionist Summer School. </booktitle>
Reference: <author> Karnin, E. D. </author> <year> (1990). </year> <title> A simple procedure for pruning back-propagation trained neural networks. </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> 1, </volume> <pages> 239-242. </pages>
Reference: <author> Kokar, M. M. </author> <year> (1986). </year> <title> Determining arguments of invariant functional descriptions. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 403-422. </pages>
Reference-contexts: The search through the space is a breadth-first beam search from simple to complex models. Because the system has the ability to backtrack in the worst case the suspension search degenerates into a simple breadth-first search. COPER <ref> (Kokar, 1986) </ref> takes a different approach to quantitative discovery than the ABACUS and BACON systems. COPER uses dimensional analysis to constrain the search for a polynomial equation of the input variables. The system first finds the relevant arguments of the function and then finds the functional form.
Reference: <author> Langley, P., Bradshaw, G., & Simon, H. </author> <year> (1983). </year> <title> Rediscovering Chemistry with the BACON system. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Specifically, they search for a mathematical function of the independent variables, x 1 ; x 2 ; :::; x n , that predicts the the value of the dependent variable, y, to some prespecified 16 degree of accuracy. Such systems have been called numerical discovery systems <ref> (Langley, Bradshaw & Simon, 1983) </ref>. These systems search the model space using the following iterative control strategy: find numeric relationships among the existing set of terms and then test these relationships to see if any of them can predict the independent variable, y.
Reference: <author> Langley, P. </author> <year> (1986). </year> <title> Machine learning and discovery. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 363-366. </pages>
Reference-contexts: If all of the proposed relationships fail to predict y, then add these relationships to the existing set of terms and begin again. The initial set of terms is the set of input variables. The BACON programs <ref> (Langley, 1986) </ref> perform a depth first search for a polynomial function of the independent variables. The search is guided by the repeated application of heuristic production rules to find relationships among the current set of terms.
Reference: <author> Le Cun, Y., Denker, J. S., & Solla, S. A. </author> <year> (1990). </year> <title> Optimal brain damage. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> 2, </volume> <pages> 598-605. </pages>
Reference-contexts: As the feature set becomes more complex so does the underlying model class. FRINGE constructs Boolean combinations of the initial set of features to overcome the tree replication problem <ref> (Pagallo & Haussler, 1990) </ref>. Given positive and negative examples of a concept, each described by the same set of Boolean features, a decision tree can represent a DNF hypothesis of the examples. <p> The upstart algorithm uses binary units and grows a binary tree-structured network (Frean, 1990b). Two new children are added if a parent cannot classify the instances correctly; the children correct the output of the parent. The cascade correlation algorithm starts with one layer <ref> (Fahlman & Lebiere, 1990) </ref>. If the required mapping can not be learned by the one layer, then a hidden unit is added as a hidden layer and trained while the previously trained weights are frozen. More hidden units are added until the correct mapping is learned. <p> The control strategy for the perceptron tree algorithm employs a fixed order selection strategy; it first tries an LTU, if that fails, it then grows a symbolic decision tree node. There are two successor systems to the original perceptron tree algorithm, PT2 <ref> (Utgoff & Brodley, 1990) </ref> and LMDT (Brodley & Utgoff, 1992). PT2 induces decision trees in which each node in the tree is an LTU. At each node in the tree, the algorithm trains an LTU based on all n of the input variables. <p> An MCDT classifier can represent both Boolean and non-Boolean concepts by placing linear machines as tests at the nodes, allowing the system to find more compact representations by solving the tree-replication problem <ref> (Pagallo & Haussler, 1990) </ref>. Instance based classifiers can represent non-hyperplane boundaries and therefore can represent instance spaces that are not linearly separable. Finally, instance based classifiers are well suited to instance spaces in which there are few observed instances, which can happen near the leaves of a decision tree.
Reference: <author> Matheus, C. J. </author> <year> (1990). </year> <title> Feature construction: An analytic framework and an application to decision trees. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Science, University of Illinois, Urbana-Champaign, IL. </institution>
Reference-contexts: LINT was tested for r-of-k linear threshold functions, small disjunctions of r-of-k functions and on small random linear threshold functions. The results show that while LINT works well for small (0,1)DLF concepts, it does not do as well for linear threshold functions with arbitrary weights. CITRE <ref> (Matheus, 1990) </ref> uses the form of a decision tree induced from a set of instances, described by a set of Boolean features, to construct new terms. CITRE is similar to FRINGE, but the feature formation heuristic is slightly different. <p> The size of the store, the maximum number of features permitted in the current set, is a system parameter. It then repeats the process with the pairs ordered by their decreasing LS values. IB3-CI was applied to the tic-tac-toe endgame problem <ref> (Matheus, 1990) </ref>. The results show that feature construction improves the learning performance over IB3.
Reference: <author> Michalski, R. S., & Chilausky, R. L. </author> <year> (1980). </year> <title> Learning by being told and learning from examples: An experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> Policy Analysis and Information Systems, </journal> <volume> 4, </volume> <pages> 125-160. </pages>
Reference-contexts: ABACUS is a system that discovers multiple equations for numeric data (Falkenhainer & Michalski, 1986). The system first discovers a set of equations that explain the data and then uses the A q algorithm <ref> (Michalski & Chilausky, 1980) </ref> to generate rules for when each equation should be used. Unlike other quantitative discovery systems, ABACUS does not require the user to specify the dependent variable (s). ABACUS searches a potentially infinite space of polynomial functions.
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San 44 Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: By changing the instance description language, the system changes the underlying model class of the learning system. These methods have been called data-driven approaches to constructive induction <ref> (Michalski, 1983) </ref>. The systems described in this section have a cyclical refinement approach to model selection. Once the instance representation has been changed, the previous classifier is discarded and a new classifier is induced using the new instance representation.
Reference: <author> Mingers, J. </author> <year> (1989a). </year> <title> An empirical comparison of selection measures for decision tree induction. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 319-342. </pages>
Reference-contexts: We choose this particular metric because Mingers has shown that using the gain-ratio metric produces the smallest trees <ref> (Mingers, 1989a) </ref>. This is desirable because a smaller tree will be typically more accurate than a larger tree (Blumer, Ehrenfeucht, Haussler & Warmuth, 1987; Rissanen, 1989), although Mingers' experimental results did not validate this relationship. Traditionally, such measures have been used to evaluate a set of candidate symbolic univariate tests.
Reference: <author> Mingers, J. </author> <year> (1989b). </year> <title> An empirical comparison of pruning methods for decision tree induction. </title> <journal> Machine Learning, </journal> <volume> 4, </volume> <pages> 227-243. </pages>
Reference: <author> Minsky, M., & Papert, S. </author> <year> (1972). </year> <title> Perceptrons: An introduction to computational geometry (expanded edition). </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: A model class is the representation language used by the learning algorithm to induce a generalization. For example, the underlying model class of a decision tree algorithm, such as ID3 (Quinlan, 1986a), is the Disjunctive Normal Form (DNF). The underlying model class of a perceptron learning algorithm <ref> (Minsky & Papert, 1972) </ref> is linear discriminant functions. Given a model class, inductive learning can then be viewed as finding the model within the chosen class of models that best fits the data. For example, ID3 fits a DNF hypothesis to the data.
Reference: <author> Mooney, R., Shavlik, J., Towell, G., & Gove, A. </author> <year> (1989). </year> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 775-780). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Moret, B. M. E. </author> <year> (1982). </year> <title> Decision trees and diagrams. </title> <journal> Computing Surveys, </journal> <volume> 14, </volume> <pages> 593-623. </pages>
Reference: <author> Mozer, M. C., & Smolensky, P. </author> <year> (1989). </year> <title> Skeletonization: A technique for trimming the fat from a network via relevance assessment. </title> <journal> Connection Science, </journal> <volume> 1, </volume> <pages> 3-26. </pages>
Reference: <author> Nilsson, N. J. </author> <year> (1965). </year> <title> Learning machines. </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: Given a model class, inductive learning can then be viewed as finding the model within the chosen class of models that best fits the data. For example, ID3 fits a DNF hypothesis to the data. The absolute error correction procedure <ref> (Nilsson, 1965) </ref> fits a linear threshold function to the data by learning its weights. We view model fitting as the process in which a learning algorithm searches for the best model within a model class to represent a generalization of the data. <p> This greedy search procedure continues until further elimination will decrease the classification accuracy of the LTU. At that point, if necessary, the algorithm grows two subtrees, one for each branch, and the procedure repeats at each of the subtrees. LMDT, a successor to PT2, places a linear machine <ref> (Nilsson, 1965) </ref> at each node in the tree. A linear machine is a set of k linear discriminant functions, which together can discriminate among k different classes. Like PT2, LMDT searches for a good multivariate split by first training a linear machine based on all n of the input variables. <p> However, if the concept to be learned is not represented easily by a set of hyper-rectangular regions, then a univariate decision tree algorithm will produce a classifier that is a poor generalization of the concept. A linear machine <ref> (Nilsson, 1965) </ref> is a set of k linear discriminant functions that are used together to assign an instance to one of the k classes.
Reference: <author> Pagallo, G., & Haussler, D. </author> <year> (1990). </year> <title> Boolean feature discovery in empirical learning. </title> <booktitle> Machine Learning, </booktitle> <pages> 71-99. </pages>
Reference-contexts: As the feature set becomes more complex so does the underlying model class. FRINGE constructs Boolean combinations of the initial set of features to overcome the tree replication problem <ref> (Pagallo & Haussler, 1990) </ref>. Given positive and negative examples of a concept, each described by the same set of Boolean features, a decision tree can represent a DNF hypothesis of the examples. <p> An MCDT classifier can represent both Boolean and non-Boolean concepts by placing linear machines as tests at the nodes, allowing the system to find more compact representations by solving the tree-replication problem <ref> (Pagallo & Haussler, 1990) </ref>. Instance based classifiers can represent non-hyperplane boundaries and therefore can represent instance spaces that are not linearly separable. Finally, instance based classifiers are well suited to instance spaces in which there are few observed instances, which can happen near the leaves of a decision tree.
Reference: <author> Pagallo, G. M. </author> <year> (1990). </year> <title> Adaptive decision tree algorithms for learning from examples. </title> <type> Doctoral dissertation, </type> <institution> University of California at Santa Cruz. </institution>
Reference-contexts: As the feature set becomes more complex so does the underlying model class. FRINGE constructs Boolean combinations of the initial set of features to overcome the tree replication problem <ref> (Pagallo & Haussler, 1990) </ref>. Given positive and negative examples of a concept, each described by the same set of Boolean features, a decision tree can represent a DNF hypothesis of the examples. <p> An MCDT classifier can represent both Boolean and non-Boolean concepts by placing linear machines as tests at the nodes, allowing the system to find more compact representations by solving the tree-replication problem <ref> (Pagallo & Haussler, 1990) </ref>. Instance based classifiers can represent non-hyperplane boundaries and therefore can represent instance spaces that are not linearly separable. Finally, instance based classifiers are well suited to instance spaces in which there are few observed instances, which can happen near the leaves of a decision tree.
Reference: <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For example, Quinlan spent two months coming up with features that allowed a decision tree algorithm to induce a good generalization for the chess-end-game problem <ref> (Quinlan, 1983) </ref>. Indeed, throughout the study of Artificial Intelligence it is a well know problem that a machine's ability to reason is tied directly to its representation of a problem.
Reference: <author> Quinlan, J. R. </author> <year> (1986a). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: In the context of machine learning, we define a model to be a generalization of the data. A model class is the representation language used by the learning algorithm to induce a generalization. For example, the underlying model class of a decision tree algorithm, such as ID3 <ref> (Quinlan, 1986a) </ref>, is the Disjunctive Normal Form (DNF). The underlying model class of a perceptron learning algorithm (Minsky & Papert, 1972) is linear discriminant functions. Given a model class, inductive learning can then be viewed as finding the model within the chosen class of models that best fits the data. <p> A new tree is grown and the process repeats until only one positive-labeled leaf remains in the decision tree. Results show that for the domain of tic-tac-toe CITRE realizes a 15% increase in accuracy over the accuracy obtained by applying ID3 <ref> (Quinlan, 1986a) </ref> to a set of instances described by only the nine initial features. 2.2.3 Using the Error Rate In this section we describe learning systems in which a model is selected, or a new one proposed, in response to measures of the error rate of the current classifier. <p> used by the system to determine the matching rule. * Information Theory Measure: The gain ratio information metric measures the gain in information if test T i is used to partition the instances into v i subsets, where v i is the number of observed values for test T i <ref> (Quinlan, 1986a) </ref>. We choose this particular metric because Mingers has shown that using the gain-ratio metric produces the smallest trees (Mingers, 1989a).
Reference: <author> Quinlan, J. R. </author> <year> (1986b). </year> <title> The effect of noise on concept learning. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This problem surfaces in domains that contain noisy instances, i.e., instances for which either the class label is incorrect, some number of the attribute values are incorrect or a combination of both. Noise can be caused by factors such as faulty measurements, ill-defined thresholds and subjective interpretation, among others <ref> (Quinlan, 1986b) </ref>. Overfitting occurs when the training data contain noisy instances and the learning algorithm induces a classifier that classifies all instances in the training set correctly. Such a classifier will perform poorly for previously unseen instances.
Reference: <author> Quinlan, J. R. </author> <year> (1987a). </year> <title> Decision trees as probabilistic classifiers. </title> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning (pp. </booktitle> <pages> 31-37). </pages> <address> Irvine, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: A hybrid formalism is only useful if it subsumes the individual models from which it is constructed. Therefore we will compare our system to a univariate decision tree algorithm, such as C4.5 <ref> (Quinlan, 1987a) </ref>, a k-nearest neighbor algorithm and a linear machine.
Reference: <author> Quinlan, J. R. </author> <year> (1987b). </year> <title> Simplifying decision trees. </title> <journal> Internation Journal of Man-machine Studies, </journal> <volume> 27, </volume> <pages> 221-234. </pages>
Reference: <author> Rendell, L., & Cho, H. </author> <year> (1990). </year> <title> Empirical learning as a function of concept character. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 267-298. </pages>
Reference-contexts: Rendell and Cho show how to improve learning by transforming the instance space to decrease the number of distinct concept regions, which increases concept concentration <ref> (Rendell & Cho, 1990) </ref>. Adaptive neural net algorithms seek the appropriate model for a given task by searching for the appropriate network architecture dynamically (Gallant, 1986; Ash, 1989). Hybrid algorithms seek to combine the strengths of different algorithms by selecting among a set of model classes.
Reference: <author> Rissanen, J. </author> <year> (1989). </year> <title> Stochastic complexity in statistical inquiry. </title> <address> New Jersey: </address> <publisher> World Scientific. </publisher>
Reference-contexts: The codelength of a hypothesis is the number of bits needed to represent the hypothesis plus the number of bits needed to represent the error vector resulting from using the hypothesis to predict the data <ref> (Rissanen, 1989) </ref>. ACR uses the compressibility of the data as a measure of the suitability of an instance representation for a learning algorithm. <p> The reason stems from the fact that a good generalization is both accurate and concise. One generalization is more concise than another if it can be represented in a smaller number of bits <ref> (Rissanen, 1989) </ref>. Blumer, et al. (1987) have shown that these two characteristics are related; given two classifiers that both classify the training instances with the same degree of accuracy, the smaller of the two leads to better predictive accuracy for previously unseen instances. <p> Our use of this measure is based on the Minimum Description Length Principle, which states that the best "hypothesis" to induce from a data set is the one that minimizes the length of the hypothesis plus the length of the data when coded using the hypothesis to predict the data <ref> (Rissanen, 1989) </ref>. The codelength of a classifier (the hypothesis) is the number of bits required to code the classifier plus the number of bits needed to code the error vector resulting from using the classifier to partition the instances.
Reference: <author> Saxena, S. </author> <year> (1991a). </year> <title> Predicting the effect of instance representations on inductive learning. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Science, University of Massachusetts, </institution> <address> Amherst, MA. </address> <note> 45 Saxena, </note> <author> S. </author> <year> (1991b). </year> <title> An algorithm to evaluate instance representations, </title> <address> (TR-91-21), Amherst, MA: </address> <institution> University of Massachusetts, Computer and Information Science Department. </institution>
Reference-contexts: Although originally created to determine which of two input representations is better suited to the learning task, Saxena suggests that ACR could be applied to model selection <ref> (Saxena, 1991a) </ref>. Given one input representation, ACR would select which of two model classes, or algorithms, will produce a better compression of the data.
Reference: <author> Schlimmer, J. C. </author> <year> (1987). </year> <title> Concept acquisition through representational adjustment. </title> <type> Doctoral dissertation, </type> <institution> University of California, Irvine. </institution>
Reference-contexts: PT2 and LMDT use measures of the error rate of the current LTU (linear machine) to determine when to stop searching. Incremental Algorithms: In this section we describe two incremental concept learning algorithms, STAGGER <ref> (Schlimmer, 1987) </ref> and IB3-CI (Aha, 1991), which adjust the concept formalism during the learning process.
Reference: <author> Sutton, R. S., & Matheus, C. J. </author> <year> (1991). </year> <title> Learning polynomial functions by feature construction. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (pp. </booktitle> <pages> 208-212). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The system can also output the null answer, "no relationship found" if no equation passes the tests. Sutton and Matheus present a method for learning higher order polynomial functions from examples using linear regression and feature construction <ref> (Sutton & Matheus, 1991) </ref>. Their system begins by performing a regression on the training set to learn a regression equation for the model y = k 0 + k 1 x 1 + ::: + k p x p , where p is the number of input variables.
Reference: <author> Tcheng, D., Lambert, B., C-Y Lu, S., & Rendell, </author> <title> L (1989). Building robust learning systems by computing induction and optimization. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 806-812). </pages> <address> Detroit, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A better solution would try to determine, before too much effort has been expended, which model class is best and would then direct search to the appropriate place in the generalization space. Tcheng's system <ref> (Tcheng, Lambert, C-Y Lu & Rendell, 1989) </ref>, which searches for the best model by optimizing novelty and performance, has several limitations. Firstly, if the model with the best accuracy is to be found, then it must evaluate all models.
Reference: <author> Towell, G., Craven, M., & Shavlik, J. </author> <year> (1991). </year> <title> Constructive induction in knowledge-based neural networks. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (pp. </booktitle> <pages> 213-217). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Utgoff, P. E. </author> <year> (1989). </year> <title> Perceptron trees: A case study in hybrid concept representations. </title> <journal> Connection Science, </journal> <volume> 1, </volume> <pages> 377-391. </pages>
Reference-contexts: Because the ease with which the different representation languages can describe a particular concept varies, combining them allows the system to learn good generalizations for a wider class of learning tasks <ref> (Utgoff, 1989) </ref>. To validate our hypothesis we will evaluate the implemented system empirically to demonstrate that it adjusts its search bias effectively. <p> Hybrid Representations: In this section we describe systems that mix different formalisms to produce a hybrid representation <ref> (Utgoff, 1989) </ref>. A hybrid representation permits the learning algorithm to select the appropriate formalism for each subconcept, drawing on the special strengths of each of the individual model classes that make up the hybrid. A subconcept is defined by the partially learned classifier. <p> Examples of systems that combine various properties of different algorithms can be found in Clark and Niblett (1989), and Towel, Craven and Shalik (1991). One hybrid representation, a perceptron tree, combines a decision tree with linear threshold units (LTUs) <ref> (Utgoff, 1989) </ref>. Utgoff defines a perceptron tree to be either an LTU or an attribute test, with a branch to a perceptron tree for each value of the attribute; a decision tree in which every leaf node is an LTU. <p> Systems that use a hybrid representation permit different subspaces to be represented with different formalisms. Combining decision trees with linear threshold functions allows one to draw on the strengths of both formalisms <ref> (Utgoff, 1989) </ref>. However, the control strategies of perceptron trees, PT2 and LMDT implement biases that may be inappropriate for some learning tasks. <p> Rather than choose one model class to use for the entire instance space. the system will have the ability to combine the different classes, thereby forming a hybrid representation. A hybrid representation is the result of mixing one or more individual formalisms or statements within those formalisms <ref> (Utgoff, 1989) </ref>. In choosing which model classes to combine one desires that the individual model classes' strengths are complementary. Concepts or subconcepts that are difficult to represent well in one formalism may be easy to represent in another.
Reference: <author> Utgoff, P. E., & Brodley, C. E. </author> <year> (1990). </year> <title> An incremental method for finding multivariate splits for decision trees. </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning (pp. </booktitle> <pages> 58-65). </pages> <address> Austin, TX: </address> <publisher> Morgan Kaufmann. Van Nostrand (1989). Van nostrand's scientific encyclopedia. Van Nostrand Reinhold. </publisher>
Reference-contexts: The control strategy for the perceptron tree algorithm employs a fixed order selection strategy; it first tries an LTU, if that fails, it then grows a symbolic decision tree node. There are two successor systems to the original perceptron tree algorithm, PT2 <ref> (Utgoff & Brodley, 1990) </ref> and LMDT (Brodley & Utgoff, 1992). PT2 induces decision trees in which each node in the tree is an LTU. At each node in the tree, the algorithm trains an LTU based on all n of the input variables.
Reference: <author> Yang, D. S., Rendell, L., & Blix, G. </author> <year> (1991). </year> <title> Fringe-Like feature construction a comparitive study and a unifying scheme. </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop. </booktitle> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher> <pages> 46 </pages>
References-found: 56

