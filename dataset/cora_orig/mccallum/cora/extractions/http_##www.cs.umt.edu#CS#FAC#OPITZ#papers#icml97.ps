URL: http://www.cs.umt.edu/CS/FAC/OPITZ/papers/icml97.ps
Refering-URL: http://www.cs.umt.edu/CS/FAC/OPITZ/papers/icml97.html
Root-URL: 
Title: The Effective Size of a Neural Network: A Principal Component Approach  
Author: David W. Opitz 
Address: Missoula, MT 59812  
Affiliation: Department of Computer Science University of Montana  
Abstract: Often when learning from data, one attaches a penalty term to a standard error term in an attempt to prefer simple models and prevent overfitting. Current penalty terms for neural networks, however, often do not take into account weight interaction. This is a critical drawback since the effective number of parameters in a network usually differs dramatically from the total number of possible parameters. In this paper, we present a penalty term that uses Principal Component Analysis to help detect functional redundancy in a neural network. Results show that our new algorithm gives a much more accurate estimate of network complexity than do standard approaches. As a result, our new term should be able to improve techniques that make use of a penalty term, such as weight decay, weight pruning, feature selection, Bayesian, and prediction-risk tech niques.
Abstract-found: 1
Intro-found: 1
Reference: [ Chatterjee and Hadi, 1988 ] <author> S. Chatterjee and A. Hadi. </author> <title> Sensitivity Analysis in Linear Regression. </title> <publisher> Wiley, </publisher> <year> 1988. </year>
Reference-contexts: This reduced percentage of features are pruned from the network and the wrapper iterates again. Opitz 1997 compared our node salience estimate presented in this paper with a standard approach called sensitivity analysis <ref> [ Chatterjee and Hadi, 1988; Goh, 1993 ] </ref> . Briefly, this approach works by randomly perturbing one input (holding the other inputs constant) and monitoring the outputs. A large deviation in the outputs indicates dependence of the neural network on that randomly perturbed input.
Reference: [ Craven and Shavlik, 1994 ] <author> M. Craven and J. Shav-lik. </author> <title> Using sampling and queries to extract rules from trained neural networks. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 37-45, </pages> <address> New Brunswick, NJ, July 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Fu, 1991 ] <author> L. Fu. </author> <title> Rule learning by searching on adapted nets. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 590-595, </pages> <address> Anaheim, CA, 1991. </address> <publisher> AAAI/MIT Press. </publisher>
Reference: [ Geman et al., 1992 ] <author> S. Geman, E. Bienenstock, and R. Doursat. </author> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Overfitting is a well-studied phenomenon <ref> [ Geman et al., 1992; Holder, 1991; Weigend, 1993 ] </ref> where a learning algorithm tunes the parameters of a model too closely to the training set, thus reducing the overall generalization performance of the model. <p> One common method for combating overfitting is to attach a penalty term (also known as a complexity, regularizer, or prior term) to a model's error term <ref> [ Geman et al., 1992 ] </ref> . A good model is therefore defined as a simple model that also fits the data well. Common penalty terms for neural networks, however, suffer in that they are unable to detect functional redundancy in the network's weights.
Reference: [ Goh, 1993 ] <author> T. Goh. </author> <title> Semantic extraction using neural network modelling and sensitivity analysis. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks, </booktitle> <address> Nagoya, Japan, </address> <year> 1993. </year>
Reference-contexts: This reduced percentage of features are pruned from the network and the wrapper iterates again. Opitz 1997 compared our node salience estimate presented in this paper with a standard approach called sensitivity analysis <ref> [ Chatterjee and Hadi, 1988; Goh, 1993 ] </ref> . Briefly, this approach works by randomly perturbing one input (holding the other inputs constant) and monitoring the outputs. A large deviation in the outputs indicates dependence of the neural network on that randomly perturbed input.
Reference: [ Harp et al., 1989 ] <author> S. Harp, T. Samad, and A. Guha. </author> <title> Designing application-specific neural networks using the genetic algorithm. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 447-454, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Hassibi and Stork, 1992 ] <author> B. Hassibi and D. Stork. </author> <title> Second order derivatives for network pruning: Optimal brain surgeon. </title> <editor> In S. Hanson, J. Cowan, and C. Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> pages 164-171, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This objective function directly addresses the bias-variance tradeoff [ Ge-man et al., 1992 ] . Many techniques, such as weight decay [ Hinton, 1986; Nowlan and Hinton, 1992 ] , weight pruning <ref> [ Le Cun et al., 1989; Hassibi and Stork, 1992 ] </ref> , Bayesian approaches [ Richard and Lippmann, 1991; MacKay, 1992 ] (where the penalty term is commonly referred to as a prior), and prediction risk techniques [ Moody, 1991 ] can make use of an effective penalty term. <p> Also, since the significance of each weight gives an estimation of its necessity to the performance of the network, it can easily be used to give information of which weights to prune. This mainly differs from Levin et al. 's 1994 and Hessian-based <ref> [ Hassibi and Stork, 1992 ] </ref> approaches in that it estimates saliency with respect to how the weight signals are spread, rather than by analyzing the error on the training set. One question that has yet to be addressed is speed.
Reference: [ Hinton, 1986 ] <author> G. Hinton. </author> <title> Learning distributed representations of concepts. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 1-12, </pages> <address> Amherst, MA, </address> <year> 1986. </year> <title> Erlbaum. network, part (b) shows the corresponding Size i of each node and Sig ij of each weight in the network, and part (c) shows the resulting values of the three complexity terms. </title>
Reference-contexts: Another popular alternative is to embody Occam's Razor and create a new objective function by adding a penalty term to the error term. This objective function directly addresses the bias-variance tradeoff [ Ge-man et al., 1992 ] . Many techniques, such as weight decay <ref> [ Hinton, 1986; Nowlan and Hinton, 1992 ] </ref> , weight pruning [ Le Cun et al., 1989; Hassibi and Stork, 1992 ] , Bayesian approaches [ Richard and Lippmann, 1991; MacKay, 1992 ] (where the penalty term is commonly referred to as a prior), and prediction risk techniques [ Moody, 1991
Reference: [ Holder, 1991 ] <author> L. Holder. </author> <title> Maintaining the Utility of Learned Knowledge Using Model-Based Control. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of Illinois at Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: 1 Introduction Overfitting is a well-studied phenomenon <ref> [ Geman et al., 1992; Holder, 1991; Weigend, 1993 ] </ref> where a learning algorithm tunes the parameters of a model too closely to the training set, thus reducing the overall generalization performance of the model.
Reference: [ John et al., 1994 ] <author> G. John, R. Kohavi, and K. Pfleger. </author> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 121-129, </pages> <address> New Brunswick, NJ, July 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In fact, Opitz 1997 has shown the effectiveness of applying our node salience estimate to the problem of feature selection. Opitz 1997 built on the empirically successful "wrapper" approach <ref> [ John et al., 1994 ] </ref> . In the wrapper approach, the induction algorithm is run on various datasets where different sets of features are removed from the data. The subset of features with the highest estimated value is chosen as the set on which the induction algorithm is run.
Reference: [ Le Cun et al., 1989 ] <author> Y. Le Cun, J. Denker, and S. Solla. </author> <title> Optimal brain damage. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 598-605, </pages> <address> San Mateo, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This objective function directly addresses the bias-variance tradeoff [ Ge-man et al., 1992 ] . Many techniques, such as weight decay [ Hinton, 1986; Nowlan and Hinton, 1992 ] , weight pruning <ref> [ Le Cun et al., 1989; Hassibi and Stork, 1992 ] </ref> , Bayesian approaches [ Richard and Lippmann, 1991; MacKay, 1992 ] (where the penalty term is commonly referred to as a prior), and prediction risk techniques [ Moody, 1991 ] can make use of an effective penalty term.
Reference: [ Levin et al., 1994 ] <author> A. Levin, T. Leen, and J. Moody. </author> <title> Fast pruning using principal componenets. </title> <editor> In J. Cowan, G. Tesauro, and J. Alspector, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, volume 6, </booktitle> <address> San Mateo, CA, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ MacKay, 1992 ] <author> D. MacKay. </author> <title> A practical Bayesian framework for backpropagation networks. </title> <journal> Neural Computation, </journal> <volume> 4(3) </volume> <pages> 448-472, </pages> <year> 1992. </year>
Reference-contexts: When appropriate, this is often repeated in a cross-validated fashion. This class of methods suffers since (a) part of the training data cannot be used to train the network, (b) it can be a noisy approximator of the true generalization error <ref> [ MacKay, 1992 ] </ref> , and (c) it can be time consuming. Another popular alternative is to embody Occam's Razor and create a new objective function by adding a penalty term to the error term. This objective function directly addresses the bias-variance tradeoff [ Ge-man et al., 1992 ] . <p> This objective function directly addresses the bias-variance tradeoff [ Ge-man et al., 1992 ] . Many techniques, such as weight decay [ Hinton, 1986; Nowlan and Hinton, 1992 ] , weight pruning [ Le Cun et al., 1989; Hassibi and Stork, 1992 ] , Bayesian approaches <ref> [ Richard and Lippmann, 1991; MacKay, 1992 ] </ref> (where the penalty term is commonly referred to as a prior), and prediction risk techniques [ Moody, 1991 ] can make use of an effective penalty term. Current penalty functions, however, often do not provide an accurate estimate of neural network complexity. <p> Having a good estimate of the effective size of a neural network can be incorporated with architecture selection techniques such as Bayesian approximation of neural networks <ref> [ MacKay, 1992 ] </ref> , or Generalized Prediction Error [ Moody, 1991 ] . Such techniques can be used in applications such as comparing different Part (a) shows a network where the weights are equal in magnitude (w or w) and biases are w=2.
Reference: [ Moody, 1991 ] <author> J. Moody. </author> <title> The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems. </title> <editor> In J. Moody, S. Hanson, and R. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 4, </volume> <pages> pages 847-854, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: weight decay [ Hinton, 1986; Nowlan and Hinton, 1992 ] , weight pruning [ Le Cun et al., 1989; Hassibi and Stork, 1992 ] , Bayesian approaches [ Richard and Lippmann, 1991; MacKay, 1992 ] (where the penalty term is commonly referred to as a prior), and prediction risk techniques <ref> [ Moody, 1991 ] </ref> can make use of an effective penalty term. Current penalty functions, however, often do not provide an accurate estimate of neural network complexity. <p> Having a good estimate of the effective size of a neural network can be incorporated with architecture selection techniques such as Bayesian approximation of neural networks [ MacKay, 1992 ] , or Generalized Prediction Error <ref> [ Moody, 1991 ] </ref> . Such techniques can be used in applications such as comparing different Part (a) shows a network where the weights are equal in magnitude (w or w) and biases are w=2.
Reference: [ Nowlan and Hinton, 1992 ] <author> S. Nowlan and G. Hinton. </author> <title> Simplifying neural networks by soft weight-sharing. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 473-493, </pages> <year> 1992. </year>
Reference-contexts: Another popular alternative is to embody Occam's Razor and create a new objective function by adding a penalty term to the error term. This objective function directly addresses the bias-variance tradeoff [ Ge-man et al., 1992 ] . Many techniques, such as weight decay <ref> [ Hinton, 1986; Nowlan and Hinton, 1992 ] </ref> , weight pruning [ Le Cun et al., 1989; Hassibi and Stork, 1992 ] , Bayesian approaches [ Richard and Lippmann, 1991; MacKay, 1992 ] (where the penalty term is commonly referred to as a prior), and prediction risk techniques [ Moody, 1991
Reference: [ Opitz and Shavlik, 1994 ] <author> D. Opitz and J. Shavlik. </author> <title> Using genetic search to refine knowledge-based neural networks. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 208-216, </pages> <address> New Brunswick, NJ, </address> <month> July </month> <year> 1994. </year> <note> Morgan Kauf-mann. </note>
Reference: [ Opitz, 1997 ] <author> D. Opitz. </author> <title> Finding relevant inputs of a neural network using principal component analysis. </title> <booktitle> In Proceedings of the International Conference on Artificial Intelligence and Soft Computing, </booktitle> <address> Banff, Canada, </address> <year> 1997. </year>
Reference: [ Richard and Lippmann, 1991 ] <author> Michael D. Richard and Richard P. Lippmann. </author> <title> Neural network classifiers estimate bayesian a-posteriori probabilities. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 461-483, </pages> <year> 1991. </year>
Reference-contexts: This objective function directly addresses the bias-variance tradeoff [ Ge-man et al., 1992 ] . Many techniques, such as weight decay [ Hinton, 1986; Nowlan and Hinton, 1992 ] , weight pruning [ Le Cun et al., 1989; Hassibi and Stork, 1992 ] , Bayesian approaches <ref> [ Richard and Lippmann, 1991; MacKay, 1992 ] </ref> (where the penalty term is commonly referred to as a prior), and prediction risk techniques [ Moody, 1991 ] can make use of an effective penalty term. Current penalty functions, however, often do not provide an accurate estimate of neural network complexity.
Reference: [ Towell and Shavlik, 1991 ] <author> Geoffrey Towell and Jude Shavlik. </author> <title> Interpretation of artificial neural networks: Mapping knowledge-based neural networks into rules. </title> <editor> In J. Moody, S. Hanson, and R. Lipp-mann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 4, </volume> <pages> pages 977-984, </pages> <address> San Ma-teo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Weigend et al., 1990 ] <author> A. Weigend, B. Huberman, and D. Rumelhart. </author> <title> Predicting the future: A connectionist approach. </title> <journal> International Journal of Neural Systems, </journal> <volume> I:193-209, </volume> <year> 1990. </year>
Reference-contexts: Current penalty functions, however, often do not provide an accurate estimate of neural network complexity. Studies <ref> [ Weigend, 1993; Weigend et al., 1990 ] </ref> have shown that the weights in a network tend to move together and mimic each other early, then start fitting the variance of the data as training progresses. <p> Finally, we recursively propagate these signals back through the network, giving an estimate of the effective size of the network and the significance of each node and link to the overall network performance. Previous methods that applied PCA to neural networks <ref> [ Weigend, 1993; Weigend et al., 1990 ] </ref> only looked at the hidden node activation of single-hidden-layer networks. Our algorithm differs in that it applies to arbitrarily structured feed-forward neural networks and takes into account every weight in the network.
Reference: [ Weigend, 1993 ] <author> A. Weigend. </author> <title> On overfitting and the effective number of hidden units. </title> <booktitle> In Proceedings of the 1993 Connectionist Models Summer School, </booktitle> <pages> pages 335-342, </pages> <address> Boulder, CO, 1993. </address> <publisher> Lawrence Erl-baum Associates. </publisher>
Reference-contexts: 1 Introduction Overfitting is a well-studied phenomenon <ref> [ Geman et al., 1992; Holder, 1991; Weigend, 1993 ] </ref> where a learning algorithm tunes the parameters of a model too closely to the training set, thus reducing the overall generalization performance of the model. <p> Current penalty functions, however, often do not provide an accurate estimate of neural network complexity. Studies <ref> [ Weigend, 1993; Weigend et al., 1990 ] </ref> have shown that the weights in a network tend to move together and mimic each other early, then start fitting the variance of the data as training progresses. <p> Finally, we recursively propagate these signals back through the network, giving an estimate of the effective size of the network and the significance of each node and link to the overall network performance. Previous methods that applied PCA to neural networks <ref> [ Weigend, 1993; Weigend et al., 1990 ] </ref> only looked at the hidden node activation of single-hidden-layer networks. Our algorithm differs in that it applies to arbitrarily structured feed-forward neural networks and takes into account every weight in the network.
Reference: [ Yao, 1993 ] <author> Xin Yao. </author> <title> Evolutionary artificial neural networks. </title> <journal> International Journal of Neural Systems, </journal> <volume> 4(3) </volume> <pages> 203-221, </pages> <year> 1993. </year>
References-found: 22

