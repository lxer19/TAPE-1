URL: http://www-robotics.usc.edu/~maja/publications/jetai-arch.ps.gz
Refering-URL: http://www-robotics.usc.edu/~maja/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: maja@cs.brandeis.edu  
Phone: tel: (617) 736-2708, fax: (617) 736-2741  
Title: Behavior-Based Control: Examples from Navigation, Learning, and Group Behavior  
Author: Maja J Mataric 
Address: Waltham, MA 02254  
Affiliation: Volen Center for Complex Systems Computer Science Department Brandeis University  
Abstract: This paper describes the main properties of behavior-based approaches to control. Different approaches to designing and using behaviors as basic units for control, representation, and learning are illustrated on three empirical examples of robots performing navigation and path-finding, group behaviors, and learning behavior selection. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agre, P. E. </author> <year> (1988), </year> <title> The Dynamic Structure of Everyday Life, </title> <type> PhD thesis, </type> <institution> MIT. </institution>
Reference-contexts: For example, safe-wandering is a behavior that maintains the goal of avoiding collisions while the agent is moving. Behaviors are designed to utilize the interaction dynamics between the agents <ref> (Agre 1988) </ref>; they combine constraints from the agent, such as its mechanical characteristics, and the constraints for the environment, such as the sensory information the agent can obtain.
Reference: <author> Agre, P. E. & Chapman, D. </author> <year> (1987), </year> <title> Pengi: An Implementation of a Theory of Activity, </title> <booktitle> in `Proceedings, AAAI-87', </booktitle> <address> Seattle, WA, </address> <pages> pp. 268-272. </pages>
Reference: <author> Arkin, R. C. </author> <year> (1989), </year> <title> Towards the Unification of Navigational Planning and Reactive Control, </title> <booktitle> in `AAAI Spring Symposium on Robot Navigation', </booktitle> <pages> pp. 1-5. </pages>
Reference-contexts: It includes reactive planning or reactive execution used in Reactive Action Packages (RAPs), higher-level primitives for planning that hide and take care of the details of execution (Firby 1987), PRS (Procedural Reasoning System), an architecture for flexible control rule invocation (Georgeff & Lan-sky 1987), Schemas <ref> (Arkin 1989) </ref>, Internalized Plans (Payton 1990), Contingency Plans (Connell 1991), and others. Hybrid solutions tend to separate the control system into two or more communicating but otherwise independent parts.
Reference: <author> Brooks, R. A. </author> <year> (1986), </year> <title> `A Robust Layered Control System for a Mobile Robot', </title> <journal> IEEE Journal of Robotics and Automation RA-2, </journal> <pages> 14-23. </pages>
Reference-contexts: Various approaches for achieving real-time performance in autonomous agents have been proposed. Purely reactive bottom-up approaches are featured in various implemented systems. They embed the agent's control strategy into a collection of preprogrammed condition-action pairs with minimal internal state <ref> (Brooks & Connell 1986, Agre & Chap-man 1987, Connell 1990) </ref>. Reactive systems maintain no internal models and perform no search. <p> In most cases, the low-level reactive process takes care of the immediate safety of the agent, while the higher level uses the planner to select action sequences. 3 Behavior-Based Approaches Behavior-based approaches are an extension of reactive architectures and also fall between purely reactive and planner-based extremes <ref> (Brooks 1986, Maes 1989) </ref>. Although often conflated in the literature, reactive and behavior-based systems are fundamentally different. While behavior-based systems embody some of the properties of reactive systems, and usually contain reactive components, their computation is not limited to look-up and execution of simple functional mappings. <p> For the sake of simplicity, in the majority of systems the solution is a built-in, fixed control hierarchy imposing a priority ordering on the behaviors, much like such hierarchies have been used to employ priority schemes over reactive rules, such as for example in the Subsumption Architecture <ref> (Brooks 1986) </ref>. More flexible, although often less tractable, solutions have been suggested, commonly based on selecting an output behavior by computing a multi-variable function implicitly encoded in behavior activation levels, such as voting schemes (Payton, Keirsey, Kimble, Krozel & Rosen-blatt 1992) and spreading of activation (Maes 1991).
Reference: <author> Brooks, R. A. </author> <year> (1990), </year> <title> Elephants Don't Play Chess, </title> <editor> in P. Maes, ed., </editor> <title> `Designing Autonomous Agents', </title> <publisher> MIT Press, </publisher> <pages> pp. 3-15. </pages>
Reference-contexts: However, uncertainty in sensing and action, and changes in the environment, can require frequent replanning the cost of which may be prohibitive for complex systems. Planner-based approaches have been criticized for scaling poorly with the complexity of real-world problems, and making real-time reaction to sudden world changes impossible <ref> (Brooks 1990, Brooks 1991b) </ref>. Various approaches for achieving real-time performance in autonomous agents have been proposed. Purely reactive bottom-up approaches are featured in various implemented systems.
Reference: <author> Brooks, R. A. </author> <year> (1991a), </year> <title> Intelligence Without Reason, </title> <booktitle> in `Proceedings, IJCAI-91'. </booktitle>
Reference: <author> Brooks, R. A. </author> <year> (1991b), </year> <title> `Intelligence Without Representation', </title> <booktitle> Artificial Intelligence 47, </booktitle> <pages> 139-160. </pages>
Reference: <author> Brooks, R. A. & Connell, J. H. </author> <year> (1986), </year> <title> Asynchronous Distributed Control System for a Mobile Robot, </title> <booktitle> in `SPIE', </booktitle> <address> Cambridge, MA. </address>
Reference-contexts: Various approaches for achieving real-time performance in autonomous agents have been proposed. Purely reactive bottom-up approaches are featured in various implemented systems. They embed the agent's control strategy into a collection of preprogrammed condition-action pairs with minimal internal state <ref> (Brooks & Connell 1986, Agre & Chap-man 1987, Connell 1990) </ref>. Reactive systems maintain no internal models and perform no search. <p> In most cases, the low-level reactive process takes care of the immediate safety of the agent, while the higher level uses the planner to select action sequences. 3 Behavior-Based Approaches Behavior-based approaches are an extension of reactive architectures and also fall between purely reactive and planner-based extremes <ref> (Brooks 1986, Maes 1989) </ref>. Although often conflated in the literature, reactive and behavior-based systems are fundamentally different. While behavior-based systems embody some of the properties of reactive systems, and usually contain reactive components, their computation is not limited to look-up and execution of simple functional mappings. <p> For the sake of simplicity, in the majority of systems the solution is a built-in, fixed control hierarchy imposing a priority ordering on the behaviors, much like such hierarchies have been used to employ priority schemes over reactive rules, such as for example in the Subsumption Architecture <ref> (Brooks 1986) </ref>. More flexible, although often less tractable, solutions have been suggested, commonly based on selecting an output behavior by computing a multi-variable function implicitly encoded in behavior activation levels, such as voting schemes (Payton, Keirsey, Kimble, Krozel & Rosen-blatt 1992) and spreading of activation (Maes 1991).
Reference: <author> Chapman, D. </author> <year> (1989), </year> <title> `Penguins Can Make Cake', </title> <journal> AI Magazine 10(4), </journal> <pages> 45-50. </pages>
Reference: <author> Chatila, R. & Laumond, J.-C. </author> <year> (1985), </year> <title> Position Referencing and Consistent World Modeling for Mobile Robots, </title> <booktitle> in `IEEE International Conference on Robotics and Automation'. </booktitle>
Reference: <author> Connell, J. H. </author> <year> (1990), </year> <title> Minimalist Mobile Robotics: A Colony Architecture for an Artificial Creature, </title> <publisher> Academic Press. </publisher>
Reference: <author> Connell, J. H. </author> <year> (1991), </year> <title> SSS: A Hybrid Architecture Applied to Robot Navigation, </title> <booktitle> in `IEEE International Conference on Robotics and Automation', Nice, France, </booktitle> <pages> pp. 2719-2724. </pages>
Reference-contexts: planning or reactive execution used in Reactive Action Packages (RAPs), higher-level primitives for planning that hide and take care of the details of execution (Firby 1987), PRS (Procedural Reasoning System), an architecture for flexible control rule invocation (Georgeff & Lan-sky 1987), Schemas (Arkin 1989), Internalized Plans (Payton 1990), Contingency Plans <ref> (Connell 1991) </ref>, and others. Hybrid solutions tend to separate the control system into two or more communicating but otherwise independent parts.
Reference: <author> Firby, R. J. </author> <year> (1987), </year> <title> An investigation into reactive planning in complex domains, </title> <booktitle> in `Proceedings, Sixth National Conference on Artificial Intelligence', Seattle, </booktitle> <pages> pp. 202-206. </pages>
Reference-contexts: Hybrid systems span a large and diverse body of research. It includes reactive planning or reactive execution used in Reactive Action Packages (RAPs), higher-level primitives for planning that hide and take care of the details of execution <ref> (Firby 1987) </ref>, PRS (Procedural Reasoning System), an architecture for flexible control rule invocation (Georgeff & Lan-sky 1987), Schemas (Arkin 1989), Internalized Plans (Payton 1990), Contingency Plans (Connell 1991), and others. Hybrid solutions tend to separate the control system into two or more communicating but otherwise independent parts.
Reference: <author> Georgeff, M. P. & Lansky, A. L. </author> <year> (1987), </year> <title> Reactive Reasoning and Planning, </title> <booktitle> in `Proceedings, Sixth National Conference on Artificial Intelligence', Seattle, </booktitle> <pages> pp. 677-682. </pages>
Reference-contexts: It includes reactive planning or reactive execution used in Reactive Action Packages (RAPs), higher-level primitives for planning that hide and take care of the details of execution (Firby 1987), PRS (Procedural Reasoning System), an architecture for flexible control rule invocation <ref> (Georgeff & Lan-sky 1987) </ref>, Schemas (Arkin 1989), Internalized Plans (Payton 1990), Contingency Plans (Connell 1991), and others. Hybrid solutions tend to separate the control system into two or more communicating but otherwise independent parts.
Reference: <author> Giralt, G., Chatila, R. & Vaisset, M. </author> <year> (1983), </year> <title> An Integrated Navigation and Motion Control System for Autonomous Multi-sensory Mobile Robots, </title> <editor> in M. Brady & R. Paul, eds, </editor> <booktitle> `First International Symposium on Robotics Research', </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Laird, J. E. & Rosenbloom, P. S. </author> <year> (1990), </year> <title> Inte--grating, Execution, Planning, and Learning in Soar for External Environments, </title> <booktitle> in `Proceedings, AAAI-90', </booktitle> <pages> pp. 1022-1029. </pages>
Reference: <author> Maes, P. </author> <year> (1989), </year> <title> The Dynamics of Action Selection, </title> <booktitle> in `IJCAI-89', </booktitle> <address> Detroit, MI, </address> <pages> pp. 991-997. </pages>
Reference: <author> Maes, P. </author> <year> (1991), </year> <title> Learning Behavior Networks from Experience, </title> <editor> in F. Varela & P. Bourgine, eds, </editor> <booktitle> `Toward A Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life', </booktitle> <publisher> MIT Press, </publisher> <pages> pp. 48-57. </pages>
Reference-contexts: More flexible, although often less tractable, solutions have been suggested, commonly based on selecting an output behavior by computing a multi-variable function implicitly encoded in behavior activation levels, such as voting schemes (Payton, Keirsey, Kimble, Krozel & Rosen-blatt 1992) and spreading of activation <ref> (Maes 1991) </ref>.
Reference: <author> Maes, P. & Brooks, R. A. </author> <year> (1990), </year> <title> Learning to Coordinate Behaviors, </title> <booktitle> in `Proceedings, AAAI-91', </booktitle> <address> Boston, MA, </address> <pages> pp. 796-802. </pages>
Reference: <author> Mahadevan, S. & Connell, J. </author> <year> (1991), </year> <title> Automatic Programming of Behavior-based Robots using Reinforcement Learning, </title> <booktitle> in `Proceedings, AAAI-91', </booktitle> <address> Pittsburgh, PA, </address> <pages> pp. 8-14. </pages>
Reference: <author> Mataric, M. J. </author> <year> (1990a), </year> <title> A Distributed Model for Mobile Robot Environment-Learning and Navigation, </title> <type> Technical Report AI-TR-1228, </type> <institution> MIT Artificial Intelligence Laboratory. </institution>
Reference-contexts: In general, behavior-based systems do not employ centralized representations operated on by one or more reasoning engines. Instead, they typically rely on various forms of distributed representations and perform distributed computations on them. In some cases, the representations are not static, manipulable structures, but active, procedural processes <ref> (Mataric 1990a, Brooks 1991a) </ref>. Furthermore, behaviors are typically more time-extended than actions of reactive systems. The latter often produce coherent externally measurable output behaviors from the interaction of their rules in a particular environment. These are commonly labeled "emergent" in that no place in the system explicitly specifies them. <p> Unlike the rest of the system, map behaviors laterally inhibit each other so only one is active at a time, based on localization information from the sensors and a small amount of history built into the activation spreading <ref> (Mataric 1990a) </ref>. 1 Details of Toto's implementation and evaluation can be found in Mataric (1994a). Toto is a demonstration of a traditional planning task implemented with a behavior-based system using an active representation, i.e., one that is procedural and distributed.
Reference: <author> Mataric, M. J. </author> <year> (1990b), </year> <title> Navigating With a Rat Brain: A Neurobiologically-Inspired Model for Robot Spatial Representation, </title> <editor> in J.-A. Meyer & S. Wilson, eds, </editor> <booktitle> `From Animals to Animats: International Conference on Simulation of Adaptive Behavior', </booktitle> <publisher> MIT Press, </publisher> <pages> pp. 169-175. </pages>
Reference-contexts: Extending the planning paradigm 2 1 Inspired by the neurophysiology of rat navigation, Toto's behaviors bear a loose resemblance to some theories of the organization of the rat hippocampus <ref> (Mataric 1990b) </ref>. 2 The planning paradigm includes traditional and hybrid systems. In terms of multi-agent extensions, hybrid systems fit into the planner-based category from single-agent to multi-agent domains requires expanding the global state space to include the state of each of the agents.
Reference: <author> Mataric, M. J. </author> <year> (1992), </year> <title> `Integration of Representation Into Goal-Driven Behavior-Based Robots', </title> <journal> IEEE Transactions on Robotics and Automation 8(3), </journal> <pages> 304-312. </pages>
Reference: <author> Mataric, M. J. </author> <year> (1994a), </year> <title> Interaction and Intelligent Behavior, </title> <type> Technical Report AI-TR-1495, </type> <institution> MIT Artificial Intelligence Lab. </institution>
Reference-contexts: We dually constrain the process of choosing the set of basis behaviors for a given domain: from the bottom-up by the dynamics of the agent and the environment, and from the top-down by the agent's goals as specified by the task <ref> (Mataric 1994a) </ref>. The combination of the two types of constraints helps the designer prune the agent's behavior space and find an efficient basis set.
Reference: <author> Mataric, M. J. </author> <year> (1994b), </year> <title> Reward Functions for Accelerated Learning, </title> <editor> in W. W. Co-hen & H. Hirsh, eds, </editor> <booktitle> `Proceedings of the Eleventh International Conference on Machine Learning (ML-94)', </booktitle> <publisher> Mor-gan Kauffman Publishers, Inc., </publisher> <address> New Brunswick, NJ, </address> <pages> pp. 181-189. </pages>
Reference-contexts: Q is very effective at learning in non-dynamic domains where reinforcement can be propagated back in time. However, our noisy, non-stationary, and complex domain required shaped reinforcement in order to both enable learning and make it efficient <ref> (Mataric 1994b) </ref>. The details of the learning experiments and their evaluation can be found in Mataric (1994a). The experiments demonstrate basis behaviors as an effective substrate for automated synthesis of new higher-level behaviors.
Reference: <author> Mataric, M. J. </author> <year> (1996), </year> <title> Learning in Multi-Robot Systems, </title> <editor> in G. Weiss & S. Sen, eds, </editor> <booktitle> `Adaptation and Learning in Multi-Agent Systems', Vol. Lecture Notes in Artificial Intelligence Vol. </booktitle> <volume> 1042, </volume> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The general problem of automated synthesis of robot controllers has barely begun to be addressed, and scaling issues of the existing techniques are not encouraging <ref> (Mataric & Cliff 1996) </ref>. 6 Discussion One of the main goals of behavior-based systems has been to demonstrate that distributed approaches to autonomous agent control are feasible, efficient, and robust. In all cases we described, centralized behavior coordination was shown to be unnecessary.
Reference: <author> Mataric, M. J. & Cliff, D. T. </author> <year> (1996), </year> <title> `Challenges in Evolving Controllers for Physical Robots', </title> <note> to appear in Robotics and Autonomous Systems. </note>
Reference-contexts: The general problem of automated synthesis of robot controllers has barely begun to be addressed, and scaling issues of the existing techniques are not encouraging <ref> (Mataric & Cliff 1996) </ref>. 6 Discussion One of the main goals of behavior-based systems has been to demonstrate that distributed approaches to autonomous agent control are feasible, efficient, and robust. In all cases we described, centralized behavior coordination was shown to be unnecessary.
Reference: <author> Moravec, H. P. & Cho, D. W. </author> <year> (1989), </year> <title> A Bayesian Method for Certainty Grids, </title> <booktitle> in `AAAI Spring Symposium on Robot Navigation', </booktitle> <pages> pp. 57-60. </pages>
Reference: <author> Payton, D. </author> <year> (1990), </year> <title> Internalized Plans: a representation for action resources, </title> <editor> in P. Maes, ed., </editor> <title> `Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back', </title> <publisher> MIT Press. </publisher>
Reference-contexts: It includes reactive planning or reactive execution used in Reactive Action Packages (RAPs), higher-level primitives for planning that hide and take care of the details of execution (Firby 1987), PRS (Procedural Reasoning System), an architecture for flexible control rule invocation (Georgeff & Lan-sky 1987), Schemas (Arkin 1989), Internalized Plans <ref> (Payton 1990) </ref>, Contingency Plans (Connell 1991), and others. Hybrid solutions tend to separate the control system into two or more communicating but otherwise independent parts.
Reference: <author> Payton, D., Keirsey, D., Kimble, D., Krozel, J. & Rosenblatt, K. </author> <year> (1992), </year> <title> `Do Whatever Works: A robust approach to fault-tolerant autonomous control', </title> <journal> Journal of Applied Intelligence 3, </journal> <pages> 226-249. </pages>
Reference-contexts: More flexible, although often less tractable, solutions have been suggested, commonly based on selecting an output behavior by computing a multi-variable function implicitly encoded in behavior activation levels, such as voting schemes <ref> (Payton, Keirsey, Kimble, Krozel & Rosen-blatt 1992) </ref> and spreading of activation (Maes 1991).
Reference: <author> Rosenschein, S. J. & Kaelbling, L. P. </author> <year> (1986), </year> <title> The Synthesis of Machines with Provable Epistemic Properties, </title> <editor> in J. Halpern, ed., </editor> <booktitle> `Theoretical Aspects of Reasoning About Knowledge', </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Al--tos, CA, </address> <pages> pp. 83-98. </pages>
Reference-contexts: Reactive, constant-time run-time strategies can be derived from a planner, by computing all possible plans off-line beforehand. For example, situated automata achieve real-time performance by compiling all of the system's goals and associated plans of achievement into a language that compiles into circuits that have constant-time computation properties <ref> (Rosenschein & Kaelbling 1986) </ref>. In general, the entire control system of an agent can be precompiled as a decision graph into a collection of reactive rules ("a universal plan") (Schoppers 1987). While theoretically appealing, these strategies often scale poorly with the complexity of the environment and the agent's control system.
Reference: <author> Schoppers, M. J. </author> <year> (1987), </year> <title> Universal Plans for Reactive Robots in Unpredictable Domains, </title> <booktitle> in `IJCAI-87', </booktitle> <address> Menlo Park, </address> <pages> pp. 1039-1046. </pages>
Reference-contexts: In general, the entire control system of an agent can be precompiled as a decision graph into a collection of reactive rules ("a universal plan") <ref> (Schoppers 1987) </ref>. While theoretically appealing, these strategies often scale poorly with the complexity of the environment and the agent's control system. Hybrid architectures attempt a compromise between purely reactive and deliberative approaches, usually by employing a reactive system for low-level control and a planner for higher-level decision making. <p> However, it has been shown that for any well-defined task, well-known environment, and well-equipped robot, purely reactive solutions can be used to solve complex control problems <ref> (Schoppers 1987, Chapman 1989) </ref>. The burden on the designer is to predict and elaborate all possible relevant input states, and the appropriate corresponding output actions. Because of their minimal computational overhead, purely reactive approaches achieve great run-time efficiency but their limited representational power results in a lack of run-time flexibility.
Reference: <author> Simsarian, K. T. & Mataric, M. J. </author> <year> (1995), </year> <title> Learning to Cooperate Using Two Six-Legged Mobile Robots, </title> <booktitle> in `Proceedings, Third European Workshop of Learning Robots', </booktitle> <address> Heraklion, Crete, Greece. </address>
Reference-contexts: In it, two six-legged robots learned to push a box to a light and to communicate to each other what actions to take, since neither individually had sufficient sensors or effectors to complete the task <ref> (Simsarian & Mataric 1995, Mataric 1996) </ref>. The results of both sets of learning experiments provide further encouragement for continuing to work with and scale up behavior-based systems. 7 Conclusions The control architecture constrains the way an autonomous agent senses, reasons, and acts.
Reference: <editor> Steels, L. </editor> <booktitle> (1994), `The Artificial Life Roots of Artificial Intelligence', Artificial Life. </booktitle>
Reference-contexts: The latter often produce coherent externally measurable output behaviors from the interaction of their rules in a particular environment. These are commonly labeled "emergent" in that no place in the system explicitly specifies them. In contrast, behavior-based systems often internally specify such behaviors. Their "emergent properties" <ref> (Steels 1994) </ref> then result from the interaction of the behaviors and the world, are are typically higher-level. Section 4.1 describes a specific example of a robot navigation system that employs both reactive rules and behaviors. The two are compared, in order to clarify this subtle and rather confusing distinction.
References-found: 34

