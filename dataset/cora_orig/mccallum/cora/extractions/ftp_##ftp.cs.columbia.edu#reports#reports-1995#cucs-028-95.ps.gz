URL: ftp://ftp.cs.columbia.edu/reports/reports-1995/cucs-028-95.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1995.html
Root-URL: http://www.cs.columbia.edu
Title: Parametric Feature Detection CUCS-028-95  
Author: Shree K. Nayar, Simon Baker, and Hiroshi Murase 
Keyword: Category: Low-Level Processing, Pattern Analysis Index Terms: Parametrized features, feature modeling, optical effects, sensor effects, feature manifolds, normalizations, dimension reduction, efficient search, feature detection, parameter estimation, step edges, roof edges, corners, lines, discs, software modules, relaxation, modular hardware architecture.  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Abstract: A large number of visual features are parametric in nature, including, edges, lines, corners, and junctions. We present a general framework for the design and implementation of detectors for parametrized features. For robustness, we argue in favor of elaborate modeling of features as they appear in the physical world. In addition, optical and sensing artifacts are incorporated to achieve realistic feature models in image domain. Each feature is represented as a densely sampled parameterized manifold in a low-dimensional subspace. During detection, the brightness distribution around each image pixel is projected to the subspace. If the projection lies close to the feature manifold, the exact location of the closest manifold point reveals the parameters of the feature. The concepts of parameter reduction by normalization, dimension reduction, pattern rejection, and efficient search are employed to achieve high efficiency. Detectors have been implemented for five specific features, namely, step edge (5 parameters), roof edge (5 parameters), line (6 parameters), corner (5 parameters), and circular disc (6 parameters). All five of these detectors were generated using the same technique by simply inputing different feature models. Detailed experiments are reported on the robustness of detection and the accuracy of parameter estimation. In the case of the step edge, our results are compared with those obtained using popular detectors. We conclude with a brief discussion on the use of relaxation to refine outputs from multiple feature detectors, and sketch a hardware architecture for a general feature detection machine. 
Abstract-found: 1
Intro-found: 1
Reference: [Abdou and Pratt 79] <author> I.E. Abdou and W.K. Pratt, </author> <title> "Quantitative Design and Evaluation of Enhancement/Thresholding Edge Detectors," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 67 </volume> <pages> 753-763, </pages> <year> 1979. </year>
Reference-contexts: Of the papers that do comprehensively investigate detector performance, we strongly recommend both [Nalwa and Binford 86] and <ref> [Abdou and Pratt 79] </ref>. The monograph by Pratt [Pratt 90] also contains a thorough discussion of proposed techniques. We highlighted 4 ways to evaluate the performance of feature detectors: 1. Statistically compare the rates of occurrence of false positives and false negatives. 2.
Reference: [Baker and Nayar 95] <author> S. Baker and S.K. Nayar, </author> <title> "A Theory of Pattern Rejection," </title> <institution> Columbia University Technical Report, CUCS-013-95. </institution>
Reference-contexts: Further, it turns out that we do not need to perform the search for every pixel in the image. Amongst other rejection techniques, we use a recently developed rejection algorithm <ref> [Baker and Nayar 95] </ref> to quickly eliminate a vast majority of pixels from further consideration, without even projecting into the K-L subspace. Such a rejection scheme is feasible and effective since most pixels in an image do not represent features of interest. <p> Since, this is (approximately) a lower bound on the distance from the manifold, if the distance from the K-L subspace is too large, we can immediately decide that the pixel does not contain the feature, and so avoid the search. Using the techniques in <ref> [Baker and Nayar 95] </ref>, we can even avoid most of the cost of computing the distance from the K-L subspace.
Reference: [Barbe 80] <editor> D.F. Barbe, editor, Charge-Coupled Devices, </editor> <publisher> Springer-Verlag, </publisher> <year> 1980. </year>
Reference-contexts: First, the light flux falling within each pixel is summed, or averaged. If the pixels are rectangular in structure <ref> [Barbe 80] </ref> [Norton 82], the averaging function is simply the rectangular function [Bracewell 78]: a (x; y) = w x w y 1 x; w y where, w x and w y are the x and y dimensions of the pixel, respectively.
Reference: [Born and Wolf 65] <author> M. Born and E. Wolf, </author> <title> Principles of Optics, </title> <publisher> Permagon Press, </publisher> <year> 1965. </year>
Reference-contexts: For instance, a real scene edge would not be a perfect step but rather rounded. The effect of this in image space clearly depends on the magnification of the imaging system. The defocus factor can be approximated as a pillbox function <ref> [Born and Wolf 65] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian function [Koenderink 84]. <p> The effect of this in image space clearly depends on the magnification of the imaging system. The defocus factor can be approximated as a pillbox function <ref> [Born and Wolf 65] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian function [Koenderink 84].
Reference: [Bracewell 78] <author> R.N. Bracewell, </author> <title> The Fourier Transform and Its Applications, Second Edition, </title> <publisher> McGraw-Hill Book Co., </publisher> <year> 1978. </year> <month> 28 </month>
Reference-contexts: First, the light flux falling within each pixel is summed, or averaged. If the pixels are rectangular in structure [Barbe 80] [Norton 82], the averaging function is simply the rectangular function <ref> [Bracewell 78] </ref>: a (x; y) = w x w y 1 x; w y where, w x and w y are the x and y dimensions of the pixel, respectively. <p> Since the above image is simply a weighted sum of Kronecker delta functions <ref> [Bracewell 78] </ref>, it can also be written as F (m; n; q), where (m; n) 2 S are the (integer valued) pixels coordinates of the discrete sample locations within the feature window. 2.3 Parametric Feature Manifolds If the total number of pixels in the window is N , each feature image,
Reference: [Canny 86] <author> J. Canny, </author> <title> "A computational approach to edge detection," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 679-698, </pages> <year> 1986. </year>
Reference-contexts: In section 4, the implementation of detection is discussed, via manifold sampling, efficient search, and the use of rejection techniques. In section 5, our experimental results and comparisons with the Canny <ref> [Canny 86] </ref> and Nalwa-Binford [Nalwa and Binford 86] detectors are included. In section 6, we briefly describe a modular software package we are developing that will enable easy use of the proposed method. <p> We wish to emphasize the distinction between detection and parameter estimation, and so treat each task independently. 5.1 Feature Detection Rates We begin by statistically comparing our step edge detector with both the Canny <ref> [Canny 86] </ref> and Nalwa-Binford [Nalwa and Binford 86] detectors. A totally fair comparison constitutes a very difficult undertaking and warrants a detailed study in itself. For reasons of consistency with previous work, we follow the approach in [Nalwa and Binford 86]. <p> However, for the same reason as before, we will use our feature models to generate the synthetic features. In Figure 9 we compare the performance of our step edge detector with that of the Canny detector <ref> [Canny 86] </ref> and the Nalwa-Binford [Nalwa and Binford 86] detector. For fairness, as above we used the parametric step edge detector computed for a 5 fi 5 square window, and with the blurring parameter fixed at 0:6 pixels.
Reference: [Davis 75] <author> L.S. Davis, </author> <title> "A Survey of Edge Detection Techniques," </title> <journal> Computer Graphics and Image Processing,' </journal> <volume> 4 </volume> <pages> 349-376, </pages> <month> September </month> <year> 1975. </year>
Reference-contexts: The blurring parameter turns out to be 1 A concise description of the different types of features and a review of existing step edge detectors can be found in [Nalwa 93]. A survey of early edge detectors can be found in <ref> [Davis 75] </ref>. Given the extent to which feature detection has been explored, a survey of all the work in this area is well beyond the scope of this paper. In our discussion, we only use examples of previous detectors without attempting to mention all of them. <p> Parametric models for edges date back to the work of Hueckel [Hueckel 71]. Since then, the edge has been studied in more detail than any other visual feature (see <ref> [Davis 75] </ref>[Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of the step edge model we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87].
Reference: [Fukunaga 90] <author> K. Fukunaga, </author> <title> Introduction to Statistical Pattern Recognition, </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: It is therefore possible to represent the feature manifold in a low-dimensional subspace without significant loss of information 2 . If correlation between feature instances is the preferred measure of similarity (or dissimilarity), the Karhunen-Loeve (K-L) expansion [Oja 83] <ref> [Fukunaga 90] </ref>, yields the optimal subspace. The covariance matrix R = E [(F 0 E [F 0 ])(F 0 E [F 0 ]) T ] represents the correlation between corresponding pixels in the different feature instances.
Reference: [Haralick 84] <author> R.M. Haralick, </author> <title> "Digital Step Edges from Zero Crossing of Second Directional Derivatives," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 58-68, </pages> <year> 1984. </year>
Reference-contexts: This statement of the feature detection problem is certainly not new. It was first introduced for step edges and lines by Hueckel [Hueckel 71], and subsequently used by Hummel [Hummel 79] for step edges. More elaborate parametric models for step edges were used by Haralick <ref> [Haralick 84] </ref> and Nalwa and Binford [Nalwa and Binford 86], amongst others (see [Nalwa 93]). Hueckel and Hummel both argued that, for efficiency, a closed form solution to the feature fitting problem must be found. To make their derivations possible, they used simple continuous models for step edges and lines.
Reference: [Hueckel 71] <author> M.H. Hueckel, </author> <title> "An Operator Which Locates Edges in Digitized Pictures," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 18 </volume> <pages> 113-125, </pages> <year> 1971. </year>
Reference-contexts: If, on the other hand, the nearest manifold point is too far away, we declare the absence of the feature. This statement of the feature detection problem is certainly not new. It was first introduced for step edges and lines by Hueckel <ref> [Hueckel 71] </ref>, and subsequently used by Hummel [Hummel 79] for step edges. More elaborate parametric models for step edges were used by Haralick [Haralick 84] and Nalwa and Binford [Nalwa and Binford 86], amongst others (see [Nalwa 93]). <p> The same techniques may be applied to features found in data produced by other sensors, such as, infrared, X-ray, ultrasound, and range sensors. 3.1 Step Edge Our first example feature is the familiar step edge. Parametric models for edges date back to the work of Hueckel <ref> [Hueckel 71] </ref>. Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of the step edge model we use. This model is a generalization of those used in [Hueckel 71], [Hummel <p> of Hueckel <ref> [Hueckel 71] </ref>. Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of the step edge model we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87]. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86], but differs in its treatment of smoothing effects. <p> The idea of doing this is as old as edge detection itself, and is explicitly mentioned in <ref> [Hueckel 71] </ref>. Combining a variety of techniques, we have already reduced the time to process a 512 fi 480 image to less than a minute. In particular, we currently threshold on the magnitude, -, obtained during normalization.
Reference: [Hueckel 73] <author> M.H. Hueckel, </author> <title> "A Local Visual Operator Which Recognizes Edges and Lines," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20 </volume> <pages> 634-647, </pages> <year> 1973. </year>
Reference-contexts: The displayed roof edge manifold is parameterized by orientation and intrapixel displacement for a fixed blurring value. 12 3.3 Line The line consists of a pair of parallel step edges separated by a short distance, namely, the width w of the line <ref> [Hueckel 73] </ref> [Lenz 87]. Our line model is illustrated in Figure 3 (a). In our definition, we assume that the intensity steps are both of the same magnitude. <p> <ref> [Hueckel 73] </ref> [Lenz 87]. Our line model is illustrated in Figure 3 (a). In our definition, we assume that the intensity steps are both of the same magnitude. It is possible, to generalize this model to lines with arbitrary brightness on either side with the addition of one extra parameter [Hueckel 73].
Reference: [Hummel 79] <author> R.A. Hummel, </author> <title> "Feature Detection Using Basis Functions," </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9 </volume> <pages> 40-55, </pages> <year> 1979. </year>
Reference-contexts: If, on the other hand, the nearest manifold point is too far away, we declare the absence of the feature. This statement of the feature detection problem is certainly not new. It was first introduced for step edges and lines by Hueckel [Hueckel 71], and subsequently used by Hummel <ref> [Hummel 79] </ref> for step edges. More elaborate parametric models for step edges were used by Haralick [Haralick 84] and Nalwa and Binford [Nalwa and Binford 86], amongst others (see [Nalwa 93]). <p> The parametric feature manifold is constructed by simply projecting all instances of the feature to the subspace. This only requires dot products of each feature instance with the prominent eigenvectors that serve as a basis for the subspace. Since such a 2 This idea was first explored by Hummel <ref> [Hummel 79] </ref> for the case of an ideal step edge. Hummel analytically derived the optimal basis for representing a step edge. Later, a similar derivation was put forth by Lenz [Lenz 87] for the case of an ideal line. <p> Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of the step edge model we use. This model is a generalization of those used in [Hueckel 71], <ref> [Hummel 79] </ref>, and [Lenz 87]. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86], but differs in its treatment of smoothing effects. <p> The results of applying the Karhunen-Loeve expansion are displayed in Figures 1 (c) and 1 (d). In Figure 1 (c) we display the 8 most important eigenvectors, ordered by their eigenvalues. The similarity between the first 4 eigenvectors and the ones derived in <ref> [Hummel 79] </ref> is immediate. On closer inspection, however, we notice that while Hummel's eigenvectors are radially symmetric, the ones we computed are not. This is to be expected since the introduction of the parameters and serves to break the radial symmetry that Hummel's edge model assumes.
Reference: [Knuth 81] <author> D.E. Knuth, </author> <title> The Art of Computer Programming, Volume II: Seminumerical Algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> 1981. </year>
Reference-contexts: After the normalizations in subsection 2.4, this is (almost) equivalent to picking a "not edge" uniformly at random from the surface of the unit sphere in the N -dimensional Hilbert Space, upon which the edge manifold lies <ref> [Knuth 81] </ref>. In Figure 7 we compare the detection performance of the three edge detectors. For each pair of S.N.R. and detector, we plot a curve of false positives against false negatives obtained by varying the threshold inherent in each detection algorithm.
Reference: [Koenderink 84] <author> J.J. Koenderink, </author> <title> "The Structure of Images," </title> <journal> Biological Cybernetics,' </journal> <volume> 50 </volume> <pages> 363-370, </pages> <year> 1984. </year>
Reference-contexts: The defocus factor can be approximated as a pillbox function [Born and Wolf 65], the optical transfer function by the square of the first-order Bessel function of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian function <ref> [Koenderink 84] </ref>.
Reference: [Lenz 87] <author> R. Lenz, </author> <title> "Optimal Filters for the Detection of Linear Patterns in 2-D and Higher Dimensional Images," </title> <journal> Pattern Recognition, </journal> <volume> 20 </volume> <pages> 163-172, </pages> <year> 1987. </year>
Reference-contexts: Since such a 2 This idea was first explored by Hummel [Hummel 79] for the case of an ideal step edge. Hummel analytically derived the optimal basis for representing a step edge. Later, a similar derivation was put forth by Lenz <ref> [Lenz 87] </ref> for the case of an ideal line. Such closed-form derivations require detailed manipulations and the use of simplistic feature models to facilitate analysis. Furthermore, even with the use of simple models, closed-form solutions may not exist for many features of interest. <p> Figures 1 (a) and 1 (b) show isometric and plan views of the step edge model we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and <ref> [Lenz 87] </ref>. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86], but differs in its treatment of smoothing effects. <p> The displayed roof edge manifold is parameterized by orientation and intrapixel displacement for a fixed blurring value. 12 3.3 Line The line consists of a pair of parallel step edges separated by a short distance, namely, the width w of the line [Hueckel 73] <ref> [Lenz 87] </ref>. Our line model is illustrated in Figure 3 (a). In our definition, we assume that the intensity steps are both of the same magnitude. It is possible, to generalize this model to lines with arbitrary brightness on either side with the addition of one extra parameter [Hueckel 73].
Reference: [Moravec 77] <author> H.P. Moravec, </author> <title> "Towards Automatic Visual Obstacle Avoidance," </title> <booktitle> In Proc. of the Fifth Internation Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 598-600, </pages> <year> 1977. </year>
Reference-contexts: Combining a variety of techniques, we have already reduced the time to process a 512 fi 480 image to less than a minute. In particular, we currently threshold on the magnitude, -, obtained during normalization. This approach is similar to Moravec's interest operator <ref> [Moravec 77] </ref>, used to predict the usefulness of stereo correspondence matches. We also threshold on the distance from the K-L subspace.
Reference: [Murase and Nayar 95] <author> H. Murase and S.K. Nayar, </author> <title> Visual Learning and Recognition of 3-D Objects from Appearance," </title> <journal> International Journal of Computer Vision, </journal> <volume> 14 </volume> <pages> 5-24, </pages> <year> 1995 </year>
Reference-contexts: This enables us to achieve high detection rates by projecting the feature manifolds into spaces of dimension, d t N . In practice, d is generally in the range 4-10. Such a compressed representation was proposed for 3-D object recognition and pose estimation in <ref> [Murase and Nayar 95] </ref>. During detection itself, we use a heuristic search algorithm that exploits the local smoothness of the manifolds, to quickly find the closest sample point. Further, it turns out that we do not need to perform the search for every pixel in the image.
Reference: [Nalwa 93] <author> V.S. Nalwa, </author> <title> A Guided Tour of Computer Vision, </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: The blurring parameter turns out to be 1 A concise description of the different types of features and a review of existing step edge detectors can be found in <ref> [Nalwa 93] </ref>. A survey of early edge detectors can be found in [Davis 75]. Given the extent to which feature detection has been explored, a survey of all the work in this area is well beyond the scope of this paper. <p> It was first introduced for step edges and lines by Hueckel [Hueckel 71], and subsequently used by Hummel [Hummel 79] for step edges. More elaborate parametric models for step edges were used by Haralick [Haralick 84] and Nalwa and Binford [Nalwa and Binford 86], amongst others (see <ref> [Nalwa 93] </ref>). Hueckel and Hummel both argued that, for efficiency, a closed form solution to the feature fitting problem must be found. To make their derivations possible, they used simple continuous models for step edges and lines. Our view of feature detection is radically 2 different. <p> However, unlike the step edge, it has not been explored much in the past despite having been acknowledged as a pertinent feature <ref> [Nalwa 93] </ref>. The main difference between the two edge models is that the step discontinuity is removed from the step edge and the lower intensity step is replaced with a slanting "roof", as shown in Figure 2 (a). <p> Hence, we changed the window of our detector to be a square window containing N = 25 pixels, rather than the 49 pixel disc window used earlier. Another issue is the lack of a model for a characteristic "not edge" <ref> [Nalwa 93] </ref>. Whereas it is simple to generate ideal edges, add noise, and then apply the detector to estimate false positives, generating not edges that we can use to estimate false positives requires some model of a not edge.
Reference: [Nalwa and Binford 86] <author> V.S. </author> <title> Nalwa and T.O. Binford, "On detecting edges," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 699-714, </pages> <year> 1986. </year>
Reference-contexts: It was first introduced for step edges and lines by Hueckel [Hueckel 71], and subsequently used by Hummel [Hummel 79] for step edges. More elaborate parametric models for step edges were used by Haralick [Haralick 84] and Nalwa and Binford <ref> [Nalwa and Binford 86] </ref>, amongst others (see [Nalwa 93]). Hueckel and Hummel both argued that, for efficiency, a closed form solution to the feature fitting problem must be found. To make their derivations possible, they used simple continuous models for step edges and lines. <p> In section 4, the implementation of detection is discussed, via manifold sampling, efficient search, and the use of rejection techniques. In section 5, our experimental results and comparisons with the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detectors are included. In section 6, we briefly describe a modular software package we are developing that will enable easy use of the proposed method. The idea of using relaxation for extracting high-level image descriptions from multiple detected features and their parameters is outlined. <p> Figures 1 (a) and 1 (b) show isometric and plan views of the step edge model we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87]. It is closest to the one used by Nalwa and Binford <ref> [Nalwa and Binford 86] </ref>, but differs in its treatment of smoothing effects. <p> The blurring parameter, , is drawn from [0:3; 1:5]. As described in <ref> [Nalwa and Binford 86] </ref>, substantially larger values of could be used, but really represent an edge at a much higher magnification. Such cases would require the use of large image window for detection. The intensity parameters A and B are free to take any value. <p> Real-time performance, already achievable on todays fastest machines, will be possible on desktop machines within a few years. 5 Experimental Results Assessing the performance of a feature detector is rarely addressed in a satisfactory manner. Of the papers that do comprehensively investigate detector performance, we strongly recommend both <ref> [Nalwa and Binford 86] </ref> and [Abdou and Pratt 79]. The monograph by Pratt [Pratt 90] also contains a thorough discussion of proposed techniques. We highlighted 4 ways to evaluate the performance of feature detectors: 1. Statistically compare the rates of occurrence of false positives and false negatives. 2. <p> We wish to emphasize the distinction between detection and parameter estimation, and so treat each task independently. 5.1 Feature Detection Rates We begin by statistically comparing our step edge detector with both the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detectors. A totally fair comparison constitutes a very difficult undertaking and warrants a detailed study in itself. For reasons of consistency with previous work, we follow the approach in [Nalwa and Binford 86]. <p> We begin by statistically comparing our step edge detector with both the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detectors. A totally fair comparison constitutes a very difficult undertaking and warrants a detailed study in itself. For reasons of consistency with previous work, we follow the approach in [Nalwa and Binford 86]. The first difficulty is that, each detector is based on its own model of an edge. Our model and the Nalwa-Binford model are closely related, but comparison with the differential invariant based Canny operator is problematic. <p> Whereas it is simple to generate ideal edges, add noise, and then apply the detector to estimate false positives, generating not edges that we can use to estimate false positives requires some model of a not edge. We resolve this, as in <ref> [Nalwa and Binford 86] </ref>, by taking a constant intensity window as our not edge, and then adding white zero-mean Guassian noise. <p> We see that the Canny detector and the parametric manifold technique perform similarly, with the Canny detector doing marginally better for low levels of noise. The results for the Nalwa-Binford detector (which are consistent with the results presented in <ref> [Nalwa and Binford 86] </ref>) are completely different. probability that the result is approximately a step edge, but with a small value for the step parameter B. <p> If our reasoning is correct, we would expect to see Canny doing increasingly better than our technique as the noise level is reduced. This is consistent with Figure 7. Our results for the Nalwa-Binford detector are consistent 4 with those described in <ref> [Nalwa and Binford 86] </ref>. Applied to real images, the Nalwa-Binford detector does not perform as poorly as Figure 7 might indicate. This highlights the difficulty in statistically comparing edge detectors. The poor Nalwa-Binford results are probably due to thresholding on the step-size. <p> The poor Nalwa-Binford results are probably due to thresholding on the step-size. They may well be completely different if we fix the step-size threshold, 4 We did use step 2) 0 of the Nalwa-Binford algorithm. The inclusion of this step does not radically alter the performance. See <ref> [Nalwa and Binford 86] </ref> for a discussion of the exact details of how step 2) 0 effects the results. 22 S.N.R. = 1.5 and for a disc shaped window containing 49 pixels. We see that the step edge and circular disc are less noise sensitive than the other features. <p> As the noise level decreases, the parametric manifold approach outperforms both the Nalwa-Binford and Canny detectors. 5.2 Parameter Estimation Accuracy Compared to feature detection robustness, assessing the performance of parameter estimation is relatively straightforward. Generalizing the procedure in <ref> [Nalwa and Binford 86] </ref>, we randomly generate a set of feature parameters, synthesize a feature with these parameters, add a certain amount of noise, apply the detector, and then measure the accuracy of the estimated parameters. <p> However, for the same reason as before, we will use our feature models to generate the synthetic features. In Figure 9 we compare the performance of our step edge detector with that of the Canny detector [Canny 86] and the Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detector. For fairness, as above we used the parametric step edge detector computed for a 5 fi 5 square window, and with the blurring parameter fixed at 0:6 pixels. In the figure, we plot the r.m.s. error in the estimate of the orientation against the S.N.R. <p> In the figure, we plot the r.m.s. error in the estimate of the orientation against the S.N.R. The plot is consistent with the performance figures for the Nalwa-Binford detector presented in <ref> [Nalwa and Binford 86] </ref>. We see that for low S.N.R. the performance of all detectors is limited by the noise. For 24 parameter, we use it to compare the performance. We plot the (r.m.s.) orientation estimation error against the S.N.R.
Reference: [Nobel 88] <author> J.A. Nobel, </author> <title> "Finding corners," </title> <journal> Image and Vision Computing, </journal> <volume> 6 </volume> <pages> 121-127, </pages> <year> 1988. </year>
Reference-contexts: This results from the following symmetry in the line model: F L (x; y; A; B; + 180 o ; ; w; ) = F L (x; y; A; B; ; ; w; ) (13) 3.4 Corner The corner is a common and hence important image feature <ref> [Nobel 88] </ref>. In our corner model, shown in Figure 4 (a), 1 is the angle of one of the edges of the corner, and 2 the angle subtended by the corner itself.
Reference: [Norton 82] <author> H.N. Norton, </author> <title> Sensor and Analyzer Handbook, </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year> <month> 29 </month>
Reference-contexts: First, the light flux falling within each pixel is summed, or averaged. If the pixels are rectangular in structure [Barbe 80] <ref> [Norton 82] </ref>, the averaging function is simply the rectangular function [Bracewell 78]: a (x; y) = w x w y 1 x; w y where, w x and w y are the x and y dimensions of the pixel, respectively.
Reference: [Oja 83] <author> E. Oja, </author> <title> Subspace Methods of Pattern Recognition, </title> <publisher> Research Studies Press, </publisher> <year> 1983. </year>
Reference-contexts: First, we introduce a set of simple normalization procedures that reduce the dimensionality of the manifold to 3 or 4 (for the 5 features we experimented with) without loss of information or reduction of the signal-to-noise ratio (S.N.R.). Next, we apply the Karhunen-Loeve (K-L) expansion <ref> [Oja 83] </ref>, as a dimension reduction technique. This enables us to achieve high detection rates by projecting the feature manifolds into spaces of dimension, d t N . In practice, d is generally in the range 4-10. <p> It is therefore possible to represent the feature manifold in a low-dimensional subspace without significant loss of information 2 . If correlation between feature instances is the preferred measure of similarity (or dissimilarity), the Karhunen-Loeve (K-L) expansion <ref> [Oja 83] </ref> [Fukunaga 90], yields the optimal subspace. The covariance matrix R = E [(F 0 E [F 0 ])(F 0 E [F 0 ]) T ] represents the correlation between corresponding pixels in the different feature instances.
Reference: [Pentland et al. 94] <author> A.P. Pentland, B. Moghaddam, and T. Starner, </author> <title> "View-based and modular eigenspaces for face recognition," </title> <booktitle> Proc. of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 84-91, </pages> <year> 1994. </year>
Reference-contexts: Using the techniques in [Baker and Nayar 95], we can even avoid most of the cost of computing the distance from the K-L subspace. The distance from the K-L subspace has been used in the past for various classification purposes, for example in the field of face recognition <ref> [Pentland et al. 94] </ref>, where it is termed the distance from face/feature space. Parallel Implementation Feature detection is inherently a parallelizable task. As high performance multi-processor workstations become commonplace, the times mentioned above may easily be cut by factors on the order of 10 or more.
Reference: [Pratt 90] <author> W.K. Pratt, </author> <title> Digital Image Processing, </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: Of the papers that do comprehensively investigate detector performance, we strongly recommend both [Nalwa and Binford 86] and [Abdou and Pratt 79]. The monograph by Pratt <ref> [Pratt 90] </ref> also contains a thorough discussion of proposed techniques. We highlighted 4 ways to evaluate the performance of feature detectors: 1. Statistically compare the rates of occurrence of false positives and false negatives. 2. Compare the accuracy of parameter estimation also using statistical tests. 3. <p> Compare the accuracy of parameter estimation also using statistical tests. 3. Subjectively compare detector outputs applied to real and/or synthetic images. 4. Compare measures that combine feature detection rates with parameter estimation accuracy. One example is Pratt's Figure of Merit <ref> [Pratt 90] </ref>. In the next three subsections, we explore the first three methods in turn. We chose not to investigate any composite measures, even though we favor the use of standard performance 20 tests.
Reference: [Rosenfeld et al. 76] <author> A. Rosenfeld, R.A. Hummel, </author> <title> and S.W. Zucker, "Scene Labeling by Relaxation Operations," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 6 </volume> <pages> 420-433, </pages> <year> 1976. </year>
Reference-contexts: When multiple detectors are applied to an image, the result is a rich description of the scene. However, to extract high-level primitives from this description, such as, continuous lines and curves, the feature parameters need to be further analyzed. This could be achieved using a relaxation scheme <ref> [Rosenfeld et al. 76] </ref>. While previous relaxation algorithms have assumed a single feature in the image, often the edge, powerful constraints result from the use of multiple feature detectors. For instance, a corner cannot exist in isolation and must have edges in its vicinity.
Reference: [Yianilos 93] <author> P.N. Yianilos, </author> <title> "Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces," </title> <booktitle> Proc. of ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 311-321, </pages> <year> 1993. </year>
Reference-contexts: Possible exceptions are the burring parameters of the line and the corner. 4.2 Search for the Closest Manifold Point The general problem of finding the nearest neighbor to a given novel point in a high dimensional space is well studied in computational geometry. The paper by Yinailos <ref> [Yianilos 93] </ref> contains a comprehensive bibliography of work on nearest neighbor search. Rather than using any of the general purpose techniques mentioned in [Yianilos 93], we attempt to take advantage of the properties of the feature manifolds and develop a less general but faster search technique. <p> The paper by Yinailos <ref> [Yianilos 93] </ref> contains a comprehensive bibliography of work on nearest neighbor search. Rather than using any of the general purpose techniques mentioned in [Yianilos 93], we attempt to take advantage of the properties of the feature manifolds and develop a less general but faster search technique. We used a heuristic coarse-to-fine search, which relies upon, and takes advantage of, the locally smooth behavior of the feature manifolds.
References-found: 26

