URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1121/CS-TR-92-1121.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1121/
Root-URL: http://www.cs.wisc.edu
Email: hollings@cs.wisc.edu bart@cs.wisc.edu  
Title: Parallel Program Performance Metrics: A Comparison and Validation  
Author: Jeffrey K. Hollingsworth Barton P. Miller 
Address: 1210 W. Dayton Street Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: There are many metrics designed to assist in the performance debugging of large-scale parallel applications. We describe a new technique, called True Zeroing, that permits direct quantitative comparison of the guidance supplied by these metrics on real applications. We apply this technique to three programs that include both numeric and symbolic applications. We compare three existing metrics: Gprof, Critical Path, and Quartz/NPT, and several new variations. Critical Path provided the best overall guidance, but it was not infallible. We also include a set of recommendations to tool builders based on the experience gained during our case study. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> T. E. Anderson and E. D. Lazowska, "Quartz: </author> <title> A Tool for Tuning Parallel Program Performance", Proc. of the 1990 SIGMETRICS Conference on hhhhhhhhhhhhhhhh In fairness to the creators of Gprof, it was never intended to be used on parallel programs. </title> - -- <booktitle> Measurement and Modeling of Computer Systems, </booktitle> <address> Boston, </address> <month> May </month> <year> 1990, </year> <pages> pp. 115-125. </pages>
Reference-contexts: Profiling metrics (in sorted lists) also have the nice property that they scale well to massively parallel systems. These metrics are a natural complement to display and visualization tools. Many metrics have been developed to help in the performance debugging of parallel programs <ref> [1, 9, 15, 17, 18] </ref>. Typically, new metrics either are compared to existing sequential tools or used in a case study to provide testimonials to their usefulness. <p> True Zeroing computes the actual improvement in an application if a single procedure is removed. This technique makes it possible to validate the quality of performance metrics. We use this technique to directly compare six metrics: Gprof [10], IPS-2 Profiling, Critical Path [18], Quartz NPT <ref> [1] </ref>, Logical Zeroing [15], and a new metric called slack. We computed the value of the these six metrics for three programs representing both numeric and symbolic applications. Based on this study, Critical Path generally provided the best guidance, but each metric had strengths in specific cases. <p> time for that arc is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] <ref> [0, 1] </ref> [4, 6] [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. procedure calls <p> is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] [4, 6] <ref> [1, 3] </ref> [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. procedure calls and message passing). <p> to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] [4, 6] [1, 3] <ref> [1, 1] </ref> [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. procedure calls and message passing). <p> cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] [4, 6] [1, 3] <ref> [1, 1] </ref> [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. procedure calls and message passing). <p> This pass traverses the Critical Path and accumulates the time spent by each procedure on the path. The details of the imple mentation of this algorithm are described in [15]. 2.3. Quartz NPT Profiling Quartz's NPT <ref> [1] </ref> metric is computed by sliding a horizontal ruler down the PAG. At each node, the ruler is stopped and the elapsed time in each procedure since the last node is computed. Figure 2 shows a sample computation of this metric. <p> a slack value that indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) [6, 6] [5, 6] <ref> [0, 1] </ref> [4, 6] [1, 3] be altered. Slack is computed using the algorithm described in [12]. <p> indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) [6, 6] [5, 6] [0, 1] [4, 6] <ref> [1, 3] </ref> be altered. Slack is computed using the algorithm described in [12].
Reference: 2. <author> D. F. Bacon and R. E. Strom, </author> <title> "Optimistic Parallelization of Communicating Sequential Processes", </title> <booktitle> SIGPLAN '91 Symposium on Principals and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April 21-24, </month> <year> 1991, </year> <pages> pp. 155-166. </pages>
Reference-contexts: Overview of Metrics This section describes the performance metrics that we used in this study. We describe these metrics in terms of a graph of the application's execution history, called a Program Activity Graph (or PAG). Variations of this data structure are commonly used in parallel program correctness debugging <ref> [2, 6, 8, 14, 16] </ref> and performance debugging [7, 18]. Nodes in the graph represent significant events in the program's execution (e.g. lock and unlock operations, procedure calls and returns). Arcs represent the ordering of events within a process or the synchronization dependencies between processes.
Reference: 3. <author> T. Ball and J. R. Larus, </author> <title> "Optimally Profiling and Tracing Programs", </title> <booktitle> Conference Record of the Nineteenth ACM Symposium on Principles of Programming Languages, </booktitle> <address> Albuquerque, NM, </address> <month> January 19-22, </month> <year> 1992, </year> <pages> pp. 59-70. </pages>
Reference-contexts: is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] [4, 6] <ref> [1, 3] </ref> [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. procedure calls and message passing). <p> indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) [6, 6] [5, 6] [0, 1] [4, 6] <ref> [1, 3] </ref> be altered. Slack is computed using the algorithm described in [12]. <p> The goal of increasing the precision of data collected directly conflicts with the goal of reducing instrumentation overhead. To avoid this problem, tools need to incorporate better algorithms to reduce the amount of data collected. AE [13], QP <ref> [3] </ref>, and Mtool [9] are examples of this approach to the problem. Another option is to alter dynamically the level of instrumentation during a program's execution, depending on the desired information.
Reference: 4. <author> K. M. Chandy and J. Misra, </author> <title> "Distributed computation on graphs: Shortest path algorithms", </title> <journal> CACM 25(Nov. </journal> <year> 1982), </year> <pages> pp. 833-837. </pages>
Reference-contexts: that arc is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] <ref> [4, 6] </ref> [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. procedure calls and message <p> Unless one of these procedures is improved, the application will not run any faster. Since the PAG is a directed acyclic graph and none of the arcs are negative, a variation on the distributed shortest path algorithm described by Chandy and Misra in <ref> [4] </ref> is used for this calculation. This algorithm [18] passes messages along the arcs of the graph. Each message contains the value of the longest path to the current node. <p> value that indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) [6, 6] [5, 6] [0, 1] <ref> [4, 6] </ref> [1, 3] be altered. Slack is computed using the algorithm described in [12].
Reference: 5. <author> J. Choi, B. P. Miller and R. H. B. Netzer, </author> <title> "Techniques for Debugging Parallel Programs with Flowback Analysis", </title> <journal> ACM Trans. on Programming Languages and Systems 13, </journal> <month> 4 (October </month> <year> 1991), </year> <pages> pp. 491-530. </pages>
Reference-contexts: the CPU time for that arc is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] <ref> [5, 6] </ref> [0, 1] [4, 6] [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. <p> exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] [4, 6] [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] <ref> [5, 5] </ref> Nodes represent interesting events in the application (e.g. procedure calls and message passing). The ordered pair indicates the CPU and elapsed times between events. For a parallel application, the results for individual processes are aggregated, while ignoring inter-process arcs. <p> Path has a slack value that indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) [6, 6] <ref> [5, 6] </ref> [0, 1] [4, 6] [1, 3] be altered. Slack is computed using the algorithm described in [12]. <p> Removing each procedure from the program requires too much time. If it were possible to automate this process, the technique would be easier to apply to more programs. One possible approach is to use the methods of program re-execution developed for parallel debugging described in <ref> [5] </ref>. 5. Conclusion We presented a new technique, called True Zeroing, that permits direct, quantitative, and fair comparison of parallel program performance metrics. We applied this technique to six metrics on three parallel applications with widely varying styles.
Reference: 6. <author> J. Choi and S. L. Min, </author> <title> "Race Frontier: Reproducing Data Races in Parallel-Program Debugging", </title> <booktitle> SIGPLAN '91 Symposium on Principals and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April 21-24, </month> <year> 1991, </year> <pages> pp. 145-154. </pages>
Reference-contexts: Overview of Metrics This section describes the performance metrics that we used in this study. We describe these metrics in terms of a graph of the application's execution history, called a Program Activity Graph (or PAG). Variations of this data structure are commonly used in parallel program correctness debugging <ref> [2, 6, 8, 14, 16] </ref> and performance debugging [7, 18]. Nodes in the graph represent significant events in the program's execution (e.g. lock and unlock operations, procedure calls and returns). Arcs represent the ordering of events within a process or the synchronization dependencies between processes. <p> waiting time), the CPU time for that arc is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] <ref> [6, 6] </ref> [5, 6] [0, 1] [4, 6] [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the <p> the CPU time for that arc is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] <ref> [5, 6] </ref> [0, 1] [4, 6] [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. <p> that arc is added to the cumulative time for the currently active procedure. call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) initial node exit wait final node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] <ref> [4, 6] </ref> [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] [7, 7] [5, 5] Nodes represent interesting events in the application (e.g. procedure calls and message <p> the Critical Path has a slack value that indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) <ref> [6, 6] </ref> [5, 6] [0, 1] [4, 6] [1, 3] be altered. Slack is computed using the algorithm described in [12]. <p> Path has a slack value that indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) [6, 6] <ref> [5, 6] </ref> [0, 1] [4, 6] [1, 3] be altered. Slack is computed using the algorithm described in [12]. <p> value that indicates how much the procedure can be improved before the Critical Path will Critical Path Procedure Value B 6 Procedure Value B 1 Slack Metric call (A) unlock lock preLock preLock preLock & lock call (C) lock call (D) unlock call (B) [6, 6] [5, 6] [0, 1] <ref> [4, 6] </ref> [1, 3] be altered. Slack is computed using the algorithm described in [12].
Reference: 7. <author> R. J. Fowler, T. J. LeBlanc and J. M. Mellor-Crummey, </author> <title> "An Integrated Approach to Parallel Program Debugging and Performance Analsys on Large-Scale Multiprocessors", </title> <booktitle> Proc. of the SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <address> Madison, WI, </address> <month> May 5-6, </month> <year> 1988, </year> <pages> pp. 163-173. </pages>
Reference-contexts: We describe these metrics in terms of a graph of the application's execution history, called a Program Activity Graph (or PAG). Variations of this data structure are commonly used in parallel program correctness debugging [2, 6, 8, 14, 16] and performance debugging <ref> [7, 18] </ref>. Nodes in the graph represent significant events in the program's execution (e.g. lock and unlock operations, procedure calls and returns). Arcs represent the ordering of events within a process or the synchronization dependencies between processes. <p> node exit exit [0, 0] [0, 0] [0, 0] [6, 6] [5, 6] [0, 1] [4, 6] [1, 3] [1, 1] [1, 1] Useful Time Spinning Time [CPU Time, Elapsed Time] Legend call (A) call (B) call (C)call (C) preBarrier preBarrier barrier barrierRelease barrierRelease [36, 36] [30, 30] [24, 24] <ref> [7, 7] </ref> [5, 5] Nodes represent interesting events in the application (e.g. procedure calls and message passing). The ordered pair indicates the CPU and elapsed times between events. For a parallel application, the results for individual processes are aggregated, while ignoring inter-process arcs.
Reference: 8. <author> A. P. Goldberg, A. Gopal, A. Lowry and R. Strom, </author> <title> "Restoring Consistent Global State of Distributed Computations", </title> <booktitle> Proc. of the ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <address> Santa Cruz, CA, </address> <month> May 20-21, </month> <year> 1991, </year> <pages> pp. 144-154. </pages>
Reference-contexts: Overview of Metrics This section describes the performance metrics that we used in this study. We describe these metrics in terms of a graph of the application's execution history, called a Program Activity Graph (or PAG). Variations of this data structure are commonly used in parallel program correctness debugging <ref> [2, 6, 8, 14, 16] </ref> and performance debugging [7, 18]. Nodes in the graph represent significant events in the program's execution (e.g. lock and unlock operations, procedure calls and returns). Arcs represent the ordering of events within a process or the synchronization dependencies between processes.
Reference: 9. <author> A. J. Goldberg and J. L. Hennessy, </author> <title> "Performance Debugging Shared Memory Multiprocessor Programs with MTOOL", </title> <booktitle> Proc. of Supercomputing'91, </booktitle> <address> Albuquerque, NM, </address> <month> Nov. </month> <pages> 18-22, </pages> <year> 1991, </year> <pages> pp. 481-490. </pages>
Reference-contexts: Profiling metrics (in sorted lists) also have the nice property that they scale well to massively parallel systems. These metrics are a natural complement to display and visualization tools. Many metrics have been developed to help in the performance debugging of parallel programs <ref> [1, 9, 15, 17, 18] </ref>. Typically, new metrics either are compared to existing sequential tools or used in a case study to provide testimonials to their usefulness. <p> The goal of increasing the precision of data collected directly conflicts with the goal of reducing instrumentation overhead. To avoid this problem, tools need to incorporate better algorithms to reduce the amount of data collected. AE [13], QP [3], and Mtool <ref> [9] </ref> are examples of this approach to the problem. Another option is to alter dynamically the level of instrumentation during a program's execution, depending on the desired information.
Reference: 10. <author> S. L. Graham, P. B. Kessler and M. K. McKusick, </author> <title> "gprof: a Call Graph Execution Profiler", </title> <booktitle> SIGPLAN '82 Symposium on Compiler Construction, </booktitle> <address> Boston, </address> <month> June </month> <year> 1982, </year> <pages> pp. 120-126. </pages>
Reference-contexts: True Zeroing computes the actual improvement in an application if a single procedure is removed. This technique makes it possible to validate the quality of performance metrics. We use this technique to directly compare six metrics: Gprof <ref> [10] </ref>, IPS-2 Profiling, Critical Path [18], Quartz NPT [1], Logical Zeroing [15], and a new metric called slack. We computed the value of the these six metrics for three programs representing both numeric and symbolic applications.
Reference: 11. <author> J. K. Hollingsworth, R. B. Irvin and B. P. Miller, </author> <title> "The Integration of Application and System Based Metrics in A Parallel Program Performance Tool", </title> <booktitle> Proc. of the 1991 ACM SIGPLAN Symposium on Principals and Practice of Parallel Programming, </booktitle> <month> April </month> <year> 1991, </year> <pages> pp. 189-200. </pages>
Reference-contexts: We must also be alert for performance changes caused by interactions with architectural features such as caching and virtual memory. IPS-2 allows us to easily monitor the levels of cache and virtual memory activity <ref> [11] </ref>, so we can check that the modified program does not significantly change these behaviors. <p> While this time is important, unless the programmer is aware that the problem with a particular procedure is due to system time, they will not know how to fix it. Currently IPS-2 collects system time information via an external sampling process <ref> [11] </ref>. This approach provides good coarse-grained information, but does not isolate the cause of a system time bottleneck to a specific procedure. We also discovered that the slack metric generally failed to provide useful guidance.
Reference: 12. <author> J. K. Hollingsworth and B. P. Miller, "Slack: </author> <title> A Performance Metric for Parallel Programs", </title> <note> Computer Sciences Technical Report, </note> <month> March </month> <year> 1992. </year>
Reference-contexts: Slack is computed using the algorithm described in <ref> [12] </ref>. The motivation for Slack is that improving a procedure on the Critical Path might not decrease the elapsed time of the program because there might be a second longest path that is slightly shorter than the Critical Path.
Reference: 13. <author> J. R. Larus, </author> <title> "Abstract Execution: A Technique for Efficiently Tracing Programs", </title> <type> SPE 20, </type> <month> 12 (Dec </month> <year> 1990), </year> <pages> pp. 1241-1258. </pages>
Reference-contexts: The goal of increasing the precision of data collected directly conflicts with the goal of reducing instrumentation overhead. To avoid this problem, tools need to incorporate better algorithms to reduce the amount of data collected. AE <ref> [13] </ref>, QP [3], and Mtool [9] are examples of this approach to the problem. Another option is to alter dynamically the level of instrumentation during a program's execution, depending on the desired information.
Reference: 14. <author> B. P. Miller and J. Choi, </author> <title> "A Mechanism for Efficient Debugging of Parallel Programs", </title> <booktitle> Proc. of the SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <address> Madison, WI, </address> <month> May 5-6, </month> <year> 1988, </year> <pages> pp. 141-150. </pages>
Reference-contexts: Overview of Metrics This section describes the performance metrics that we used in this study. We describe these metrics in terms of a graph of the application's execution history, called a Program Activity Graph (or PAG). Variations of this data structure are commonly used in parallel program correctness debugging <ref> [2, 6, 8, 14, 16] </ref> and performance debugging [7, 18]. Nodes in the graph represent significant events in the program's execution (e.g. lock and unlock operations, procedure calls and returns). Arcs represent the ordering of events within a process or the synchronization dependencies between processes.
Reference: 15. <author> B. P. Miller, M. Clark, J. Hollingsworth, S. Kierstead, S. Lim and T. Torzewski, "IPS-2: </author> <title> The Second Generation of a Parallel Program Measurement System", </title> <journal> IEEE Transactions on Parallel and Distributed Systems 1, </journal> <month> 2 (April </month> <year> 1990), </year> <pages> pp. 206-217. </pages>
Reference-contexts: Profiling metrics (in sorted lists) also have the nice property that they scale well to massively parallel systems. These metrics are a natural complement to display and visualization tools. Many metrics have been developed to help in the performance debugging of parallel programs <ref> [1, 9, 15, 17, 18] </ref>. Typically, new metrics either are compared to existing sequential tools or used in a case study to provide testimonials to their usefulness. <p> True Zeroing computes the actual improvement in an application if a single procedure is removed. This technique makes it possible to validate the quality of performance metrics. We use this technique to directly compare six metrics: Gprof [10], IPS-2 Profiling, Critical Path [18], Quartz NPT [1], Logical Zeroing <ref> [15] </ref>, and a new metric called slack. We computed the value of the these six metrics for three programs representing both numeric and symbolic applications. Based on this study, Critical Path generally provided the best guidance, but each metric had strengths in specific cases. <p> Once the path is found, a second (backwards) pass is made though the graph. This pass traverses the Critical Path and accumulates the time spent by each procedure on the path. The details of the imple mentation of this algorithm are described in <ref> [15] </ref>. 2.3. Quartz NPT Profiling Quartz's NPT [1] metric is computed by sliding a horizontal ruler down the PAG. At each node, the ruler is stopped and the elapsed time in each procedure since the last node is computed. Figure 2 shows a sample computation of this metric. <p> For example, if a procedure is on both the Critical Path and a secondary path, improving it will reduce the length of both paths. Because slack ignores this synergistic effect, the value assigned to the procedure will be too low. 2.5. Logical Zeroing The Logical Zeroing <ref> [15] </ref> metric attempts to provide an estimate of how much the execution of an application will improve when a selected procedure is improved. <p> Techniques for Comparison The ultimate test of a performance metric is how useful it is in assisting programmers in improving their programs. To provide a test-bed for comparing metrics, we added Slack and NPT to the IPS-2 system <ref> [15] </ref> (IPS-2 already provided Critical Path Profiling, Logical Zeroing, and IPS-2 Profiling). IPS-2 provided a uniform environment that permitted direct comparison of each metric for a single execution of a parallel application.
Reference: 16. <author> R. H. B. Netzer and B. P. Miller, </author> <title> "Improving the Accuracy of Data Race Detection", </title> <booktitle> SIGPLAN '91 Symposium on Principals and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April 21-24, </month> <year> 1991, </year> <pages> pp. 133-144. </pages>
Reference-contexts: Overview of Metrics This section describes the performance metrics that we used in this study. We describe these metrics in terms of a graph of the application's execution history, called a Program Activity Graph (or PAG). Variations of this data structure are commonly used in parallel program correctness debugging <ref> [2, 6, 8, 14, 16] </ref> and performance debugging [7, 18]. Nodes in the graph represent significant events in the program's execution (e.g. lock and unlock operations, procedure calls and returns). Arcs represent the ordering of events within a process or the synchronization dependencies between processes.
Reference: 17. <author> R. </author> <title> Title, "Connection Machine Debugging and Performance Analysis: Present and Future", </title> <booktitle> Proc. of the ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <address> Santa Cruz, CA, </address> <month> May 20-21, </month> <year> 1991, </year> <pages> pp. 272-275. </pages>
Reference-contexts: Profiling metrics (in sorted lists) also have the nice property that they scale well to massively parallel systems. These metrics are a natural complement to display and visualization tools. Many metrics have been developed to help in the performance debugging of parallel programs <ref> [1, 9, 15, 17, 18] </ref>. Typically, new metrics either are compared to existing sequential tools or used in a case study to provide testimonials to their usefulness. <p> The ordered pair indicates the CPU and elapsed times between events. For a parallel application, the results for individual processes are aggregated, while ignoring inter-process arcs. The profiling environment on the Connection Machine <ref> [17] </ref> is an example of this metric. This metric is typically implemented by periodic sampling of the program counter. Gprof also provides a call graph profile, but we only consider the time directly consumed by a procedure.
Reference: 18. <author> C. Yang and B. P. Miller, </author> <title> "Critical Path Analysis for the Execution of Parallel and Distributed Programs", </title> <booktitle> 8th Int'l Conf. on Distributed Computing Systems, </booktitle> <address> San Jose, Calif., </address> <month> June </month> <year> 1988, </year> <pages> pp. 366-375. </pages>
Reference-contexts: Profiling metrics (in sorted lists) also have the nice property that they scale well to massively parallel systems. These metrics are a natural complement to display and visualization tools. Many metrics have been developed to help in the performance debugging of parallel programs <ref> [1, 9, 15, 17, 18] </ref>. Typically, new metrics either are compared to existing sequential tools or used in a case study to provide testimonials to their usefulness. <p> True Zeroing computes the actual improvement in an application if a single procedure is removed. This technique makes it possible to validate the quality of performance metrics. We use this technique to directly compare six metrics: Gprof [10], IPS-2 Profiling, Critical Path <ref> [18] </ref>, Quartz NPT [1], Logical Zeroing [15], and a new metric called slack. We computed the value of the these six metrics for three programs representing both numeric and symbolic applications. Based on this study, Critical Path generally provided the best guidance, but each metric had strengths in specific cases. <p> We describe these metrics in terms of a graph of the application's execution history, called a Program Activity Graph (or PAG). Variations of this data structure are commonly used in parallel program correctness debugging [2, 6, 8, 14, 16] and performance debugging <ref> [7, 18] </ref>. Nodes in the graph represent significant events in the program's execution (e.g. lock and unlock operations, procedure calls and returns). Arcs represent the ordering of events within a process or the synchronization dependencies between processes. <p> Since the PAG is a directed acyclic graph and none of the arcs are negative, a variation on the distributed shortest path algorithm described by Chandy and Misra in [4] is used for this calculation. This algorithm <ref> [18] </ref> passes messages along the arcs of the graph. Each message contains the value of the longest path to the current node. At split nodes (nodes with one inbound arc and two outbound arcs), the message is duplicated and sent on each of the outbound arcs.
References-found: 18

