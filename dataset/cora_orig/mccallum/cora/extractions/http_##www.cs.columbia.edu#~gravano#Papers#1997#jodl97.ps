URL: http://www.cs.columbia.edu/~gravano/Papers/1997/jodl97.ps
Refering-URL: http://www.cs.columbia.edu/~gravano/publications.html
Root-URL: http://www.cs.columbia.edu
Title: The Stanford Digital Library Metadata Architecture  
Author: Michelle Baldonado, Chen-Chuan K. Chang, Luis Gravano, and Andreas Paepcke 
Keyword: metadata architecture, interoperability, attribute model, attribute model translation, metadata repository, InfoBus, proxy architecture, heterogeneity, digital libraries, metadata survey  
Address: Stanford, CA 94305-9040, USA  
Affiliation: Computer Science Department Stanford University  
Note: International Journal of Digital Libraries Manuscript-Nr. (will be inserted by hand later)  
Email: fmichelle,kevin,gravano,paepckeg@db.stanford.edu  
Phone: Phone: +1-415-723-9684 FAX: +1-415-725-2588  
Abstract: The overall goal of the Stanford Digital Library project is to provide an infrastructure that affords interoperability among heterogeneous, autonomous digital library services. These services include both search services and remotely usable information processing facilities. In this paper, we survey and categorize the meta-data required for a diverse set of Stanford Digital Library services that we have built. We then propose an extensible metadata architecture that meets these requirements. Our metadata architecture fits into our established infrastructure and promotes interoperability among existing and de-facto metadata standards. Several pieces of this architecture are implemented; others are under construction. The architecture includes attribute model proxies, attribute model translation services, metadata information facilities for search services, and local meta-data repositories. In presenting and discussing the pieces of the architecture, we show how they address our motivating requirements. Together, these components provide, exchange, and describe metadata for information objects and metadata for information services. We also consider how our architecture relates to prior, relevant work on these two types of metadata. ? This material is based upon work supported by the National Science Foundation under Cooperative Agreement IRI-9411306. Funding for this cooperative agreement is also provided by DARPA, NASA, and the industrial partners of the Stanford Digital Libraries Project. Any opinions, finding, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation or the other sponsors. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Andreas Paepcke, Steve B. Cousins, Hector Garca-Molina, Scott W. Hassan, Steven K. Ketchpel, Martin Roscheisen, and Terry Winograd. </author> <title> Towards interoperability in digital libraries: Overview and selected highlights of the Stanford Digital Library Project. </title> <journal> IEEE Computer Magazine, </journal> <month> May </month> <year> 1996. </year>
Reference-contexts: Proxies 2 Michelle Baldonado, Chen-Chuan K. Chang, Luis Gravano, and Andreas Paepcke (also called "wrappers") allow heterogeneous services to give the illusion that they respond to a standard set of methods. We call our proxy-based infrastructure the In-foBus <ref> [1] </ref>. This paper provides a framework for understanding the classes of metadata and range of metadata needs that are necessary for our InfoBus services. We outline and ground this framework in Section 2 by surveying our InfoBus services and analyzing the categories of metadata that they require. <p> In this section, we begin by giving an overview of how our InfoBus works. Then we describe our metadata architecture and show how it fits into the InfoBus. 3.1 InfoBus Overview Details of the Stanford InfoBus design are described in <ref> [1] </ref>. We give here only enough detail to provide context for our metadata architecture. Our InfoBus consists of distributed objects that communicate with each other through remote method calls. In particular, we use the CORBA specifications [17], with Xerox PARC's ILU as the object system implementation [18].
Reference: 2. <author> Michelle Baldonado, Chen-Chuan K. Chang, Luis Gra-vano, and Andreas Paepcke. </author> <title> Metadata for digital libraries: Architecture and design rationale. </title> <type> Technical Report SIDL-WP-1997-0055, </type> <institution> Stanford University, </institution> <year> 1997. </year> <note> Accessible at http://www-diglib.stanford.edu/cgi-bin/WP/get/- SIDL-WP-1997-0055. </note>
Reference-contexts: We present the architecture in detail in Section 3 and show how its features map onto our concrete meta-data requirements. Readers interested in the design rationale for this architecture should refer to a separate paper on this topic <ref> [2] </ref>. 2 Our Metadata Requirements In this section, we present the InfoBus services that have motivated and shaped our metadata architecture. The discussion of each service illustrates a number of concrete requirements for the architecture.
Reference: 3. <author> Andreas Paepcke. </author> <title> Searching is not enough: What we learned on-site. </title> <journal> D-Lib Magazine, </journal> <month> May </month> <year> 1996. </year>
Reference-contexts: This problem is multi-faceted because it can involve a range of activities, including locating and selecting among relevant collections, retrieving information from these collections, interpreting the information retrieved from them, managing and organizing the retrieved information at a local level, and sharing this information with others <ref> [3, 4] </ref>. A simplified example scenario gives an overview of how metadata-related issues emerge. Imagine a user, Pat, who is interested in the topic of data mining. Pat's first task is to determine what searchable collections are relevant to this topic.
Reference: 4. <author> Andreas Paepcke. </author> <title> Information needs in technical work settings and their implications for the design of computer tools. Computer Supported Cooperative Work: </title> <journal> The Journal of Collaborative Computing, </journal> <volume> 5 </volume> <pages> 63-92, </pages> <year> 1996. </year>
Reference-contexts: This problem is multi-faceted because it can involve a range of activities, including locating and selecting among relevant collections, retrieving information from these collections, interpreting the information retrieved from them, managing and organizing the retrieved information at a local level, and sharing this information with others <ref> [3, 4] </ref>. A simplified example scenario gives an overview of how metadata-related issues emerge. Imagine a user, Pat, who is interested in the topic of data mining. Pat's first task is to determine what searchable collections are relevant to this topic.
Reference: 5. <author> Luis Gravano, Hector Garca-Molina, and Anthony Tomasic. </author> <title> The effectiveness of GlOSS for the text-database discovery problem. </title> <booktitle> In Proceedings of the 1994 ACM SIGMOD Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Furthermore, presumably only a few collections contain useful items for a given query. Therefore, a crucial component of a Digital Library is a tool that assists users in discovering the useful resources for their queries. Finding the best collections for a query is the goal of GlOSS <ref> [5, 6] </ref>, a resource-discovery service within our Digital Library testbed. A user submits a query to GlOSS, and GlOSS returns a rank of the available collections. This rank is based on estimates of the expected number of hits for the query at each collection (Figure 1). <p> These assumptions may not hold in reality, leading to wrong result-size estimates. However, the GlOSS information tends to be orders of magnitude smaller than the corresponding collections, facilitating scalability. Furthermore, experimental results with real-user queries showed that GlOSS ranks searchable collections correctly most of the time <ref> [5] </ref>. To suggest collections for a query, GlOSS extracts content summaries from each collection. These content summaries, like in the example above, include the vocabulary of each collection, together with frequency counts that are associated with them.
Reference: 6. <author> Luis Gravano and Hector Garca-Molina. </author> <title> Generalizing GlOSS to vector-space databases and broker hierarchies. </title> <booktitle> In Proceedings of VLDB '95, </booktitle> <pages> pages 78-89, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Furthermore, presumably only a few collections contain useful items for a given query. Therefore, a crucial component of a Digital Library is a tool that assists users in discovering the useful resources for their queries. Finding the best collections for a query is the goal of GlOSS <ref> [5, 6] </ref>, a resource-discovery service within our Digital Library testbed. A user submits a query to GlOSS, and GlOSS returns a rank of the available collections. This rank is based on estimates of the expected number of hits for the query at each collection (Figure 1).
Reference: 7. <author> Steve B. Cousins, Scott W. Hassan, Andreas Paepcke, and Terry Winograd. </author> <title> A distributed interface for the digital library. </title> <type> Technical Report SIDL-WP-1996-0037, </type> <institution> Stanford University, </institution> <year> 1996. </year> <note> Accessible at http://www-diglib.stanford.edu/- cgi-bin/WP/get/SIDL-WP-1996-0037. </note>
Reference-contexts: In query formulation, an important role of the user interface is thus to make the user aware of what attributes are available for searching. DLITE is a user interface service that has been developed for our Digital Library testbed <ref> [7, 8, 9] </ref>. It allows librarians or end users to specify workcenters for the various information-related tasks in which they frequently engage. A DLITE workcenter gathers together components and tools that a user might need to complete a task.
Reference: 8. <author> Steve B. Cousins. </author> <title> A task-oriented interface to a digital library. </title> <booktitle> In CHI 96 Conference Companion, </booktitle> <pages> pages 103-104, </pages> <year> 1996. </year>
Reference-contexts: In query formulation, an important role of the user interface is thus to make the user aware of what attributes are available for searching. DLITE is a user interface service that has been developed for our Digital Library testbed <ref> [7, 8, 9] </ref>. It allows librarians or end users to specify workcenters for the various information-related tasks in which they frequently engage. A DLITE workcenter gathers together components and tools that a user might need to complete a task.
Reference: 9. <author> Michelle Q Wang Baldonado and Steve B. Cousins. </author> <title> Addressing heterogeneity in the networked information environment. </title> <journal> Review of Information Networking, </journal> <note> to appear. </note>
Reference-contexts: In query formulation, an important role of the user interface is thus to make the user aware of what attributes are available for searching. DLITE is a user interface service that has been developed for our Digital Library testbed <ref> [7, 8, 9] </ref>. It allows librarians or end users to specify workcenters for the various information-related tasks in which they frequently engage. A DLITE workcenter gathers together components and tools that a user might need to complete a task. <p> Viewing heterogeneous results through the lens of a canonical attribute model allows users to obtain a unified overview of those results. Making result analysis easier for the user is one goal of SenseMaker, another user interface service developed for our Digital Library testbed <ref> [9, 16] </ref>. SenseMaker allows users to experiment iteratively with different views of their results. Within a view, complexity is reduced in two ways. Similar results may be bundled together, and identical results may be merged together.
Reference: 10. <author> D. T. Hawkins and L. R. Levy. </author> <title> Front end software for online database searching Part 1: Definitions, system features, and evaluation. </title> <journal> Online, </journal> <volume> 9(6) </volume> <pages> 30-37, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: There have been various approaches to address this problem. The most typical way is to provide a front-end that supports the least common denominator of the underlying services to hide the heterogeneity <ref> [10, 11] </ref>. In contrast, our approach is to allow a user to compose Boolean queries in one rich front-end language [12, 13].
Reference: 11. <author> M. E. Williams. </author> <title> Transparent information systems through gateways, front ends, intermediaries, and interfaces. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 37(4) </volume> <pages> 204-214, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: There have been various approaches to address this problem. The most typical way is to provide a front-end that supports the least common denominator of the underlying services to hide the heterogeneity <ref> [10, 11] </ref>. In contrast, our approach is to allow a user to compose Boolean queries in one rich front-end language [12, 13].
Reference: 12. <author> Chen-Chuan K. Chang, Hector Garca-Molina, and Andreas Paepcke. </author> <title> Boolean query mapping across heterogeneous information sources. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 8(4) </volume> <pages> 515-521, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: The most typical way is to provide a front-end that supports the least common denominator of the underlying services to hide the heterogeneity [10, 11]. In contrast, our approach is to allow a user to compose Boolean queries in one rich front-end language <ref> [12, 13] </ref>. For each user query and target source, we transform the user query into a subsuming query that can be supported by the source but that may return extra documents. The results are then processed by a filter query to yield the correct final result.
Reference: 13. <author> Chen-Chuan K. Chang, Hector Garca-Molina, and Andreas Paepcke. </author> <title> Predicate rewriting for translating boolean queries in a heterogeneous information system. </title> <type> Technical Report SIDL-WP-1996-0028, </type> <institution> Stanford University, </institution> <year> 1996. </year> <note> Accessible at http://www-diglib.stanford.edu. </note>
Reference-contexts: The most typical way is to provide a front-end that supports the least common denominator of the underlying services to hide the heterogeneity [10, 11]. In contrast, our approach is to allow a user to compose Boolean queries in one rich front-end language <ref> [12, 13] </ref>. For each user query and target source, we transform the user query into a subsuming query that can be supported by the source but that may return extra documents. The results are then processed by a filter query to yield the correct final result.
Reference: 14. <author> M. F. Porter. </author> <title> An algorithm for suffix stripping. </title> <booktitle> Program, </booktitle> <volume> 14(3) </volume> <pages> 130-137, </pages> <year> 1980. </year>
Reference-contexts: We need to be aware of the stopwords used. We need to know the vocabulary of the collection, i.e., the set of words indexed by the service. This is used, for instance, to enumerate words that match the stem of a particular word when stemming <ref> [14, 15] </ref> must be emulated because it is not a supported capability.
Reference: 15. <author> J. B. Lovins. </author> <title> Development of a stemming algorithm. </title> <journal> Mechanical Translation and Computational Linguistics, </journal> <volume> 11(1-2):22-31, </volume> <year> 1968. </year>
Reference-contexts: We need to be aware of the stopwords used. We need to know the vocabulary of the collection, i.e., the set of words indexed by the service. This is used, for instance, to enumerate words that match the stem of a particular word when stemming <ref> [14, 15] </ref> must be emulated because it is not a supported capability.
Reference: 16. <author> Michelle Q Wang Baldonado and Terry Winograd. Sense-Maker: </author> <title> An information-exploration interface supporting the contextual evolution of a user's interests. </title> <booktitle> In Proceedings of CHI 97, </booktitle> <year> 1997. </year>
Reference-contexts: Viewing heterogeneous results through the lens of a canonical attribute model allows users to obtain a unified overview of those results. Making result analysis easier for the user is one goal of SenseMaker, another user interface service developed for our Digital Library testbed <ref> [9, 16] </ref>. SenseMaker allows users to experiment iteratively with different views of their results. Within a view, complexity is reduced in two ways. Similar results may be bundled together, and identical results may be merged together.
Reference: 17. <author> Object Management Group. </author> <title> The Common Object Request Broker: Architecture and specification. </title> <institution> Accessible at ftp://- omg.org/pub/CORBA, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: We give here only enough detail to provide context for our metadata architecture. Our InfoBus consists of distributed objects that communicate with each other through remote method calls. In particular, we use the CORBA specifications <ref> [17] </ref>, with Xerox PARC's ILU as the object system implementation [18]. Existing external services with different interfaces are made accessible by service proxies. These are objects that provide a standard set of methods on "one side," but can also communicate with the services they represent.
Reference: 18. <author> Doug Cutting, Bill Janssen, Mike Spreitzer, and Farrell Wymore. </author> <title> ILU Reference Manual. </title> <institution> Xerox Palo Alto Research Center, </institution> <month> December </month> <year> 1993. </year> <note> Accessible at ftp://- ftp.parc.xerox.com/pub/ilu/ilu.html. </note>
Reference-contexts: We give here only enough detail to provide context for our metadata architecture. Our InfoBus consists of distributed objects that communicate with each other through remote method calls. In particular, we use the CORBA specifications [17], with Xerox PARC's ILU as the object system implementation <ref> [18] </ref>. Existing external services with different interfaces are made accessible by service proxies. These are objects that provide a standard set of methods on "one side," but can also communicate with the services they represent.
Reference: 19. <institution> USMARC format for bibliographic data: Including guidelines for content designation, </institution> <year> 1994. </year>
Reference-contexts: An attribute model proxy represents a real world attribute model, just as a search service proxy represents a real world search service. For example, we might have one attribute model proxy for the USMARC set of bibliographic attributes (referred to as "fields" in the US-MARC community) <ref> [19] </ref>, another for the Dublin Core set of attributes [20], and so on. An attribute model proxy allows us to encapsulate information that is specific to an attribute model and independent of a search service proxy. <p> The attrModelName is repeated in all items to make them self-contained. This is important when the items are passed around the system to components other than the attribute model proxy. For example, meta-information recorded for a particular book might include values for attributes from many attribute models, including US-MARC <ref> [19] </ref>, Dublin Core [20], Z39.50 Bib1 [21], and one of the Stanford structured attribute models. The attrValueType dictates the data type for the AttributeItem's values. We use the interface specification language that is part of our CORBA implementation to specify these types.
Reference: 20. <author> Stuart Weibel, Jean Godby, Eric Miller, and Ron Daniel, Jr. </author> <note> OCLC/NCSA metadata workshop report. Accessible at http://www.oclc.org:5047/oclc/research/publications/- weibel/metadata/dublin core report.html, </note> <month> March </month> <year> 1995. </year>
Reference-contexts: For example, we might have one attribute model proxy for the USMARC set of bibliographic attributes (referred to as "fields" in the US-MARC community) [19], another for the Dublin Core set of attributes <ref> [20] </ref>, and so on. An attribute model proxy allows us to encapsulate information that is specific to an attribute model and independent of a search service proxy. An attribute model translation service serves to mediate among the different metadata conventions that are represented by the attribute model proxies. <p> This is important when the items are passed around the system to components other than the attribute model proxy. For example, meta-information recorded for a particular book might include values for attributes from many attribute models, including US-MARC [19], Dublin Core <ref> [20] </ref>, Z39.50 Bib1 [21], and one of the Stanford structured attribute models. The attrValueType dictates the data type for the AttributeItem's values. We use the interface specification language that is part of our CORBA implementation to specify these types. <p> Relevant work in the first category (specification of metadata sets) includes, for instance, the Bib-1 attribute set in Z39.50 and the Dublin Core. The Z39.50 Bib-1 attribute set [23, 21] registers a large set of bibliographic attributes. The focus of the Dublin Core <ref> [20] </ref> is primarily on developing a simple yet usable set of attributes to describe the essential features of networked documents (e.g., World-Wide Web documents), which the report of the Dublin meeting terms "document-like objects." The Dublin Core metadata set consists of 13 metadata elements, including familiar descriptive attributes such as Author,
Reference: 21. <author> Z39.50 Maintenance Agency. </author> <title> Attribute set Bib-1 (Z39.50-1995): Semantics. </title> <institution> Accessible at ftp://ftp.loc.gov/pub/- z3950/defs/bib1.txt, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: This is important when the items are passed around the system to components other than the attribute model proxy. For example, meta-information recorded for a particular book might include values for attributes from many attribute models, including US-MARC [19], Dublin Core [20], Z39.50 Bib1 <ref> [21] </ref>, and one of the Stanford structured attribute models. The attrValueType dictates the data type for the AttributeItem's values. We use the interface specification language that is part of our CORBA implementation to specify these types. <p> Work in this area generally falls into two categories: specification of metadata sets and architectures that integrate them. Relevant work in the first category (specification of metadata sets) includes, for instance, the Bib-1 attribute set in Z39.50 and the Dublin Core. The Z39.50 Bib-1 attribute set <ref> [23, 21] </ref> registers a large set of bibliographic attributes.
Reference: 22. <author> Luis Gravano, Chen-Chuan K. Chang, Hector Garca-Molina, and Andreas Paepcke. </author> <title> STARTS: Stanford protocol proposal for Internet retrieval and search. </title> <type> Technical Report SIDL-WP-1996-0043, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1996. </year> <note> Accessible at http://www-diglib.stanford.edu/cgi-bin/WP/get/- SIDL-WP-1996-0043. </note>
Reference-contexts: Alternatively, each proxy may opt to "push" these metadata objects to its clients. The first metadata object (Table 1) contains the general service information, and it is based heavily on the source metadata objects defined by STARTS <ref> [22] </ref>. The general service information includes human-readable information about the (sub)collection, as well as information that is used by our query translation facility. Examples for the latter are the type of truncation that is applied to query terms, and the list of stopwords. <p> Content summaries are potentially large, hence our decision to make them retrievable using ftp, for example, instead of using our protocol. The content summary follows the STARTS <ref> [22] </ref> content summaries, and consists of the information that a resource-discovery service like GlOSS needs (Section 2.1). Content summaries are formatted as Harvest SOIFs (http://harvest.transarc.com/afs/transarc.com/- public/trg/Harvest/user-manual/). Example 3. <p> In this context, the efforts that are probably closest to what is described here are the Explain facility of Z39.50-1995 (i.e., Version 3 of Z39.50 [23]) and Stanford's STARTS <ref> [22] </ref>, both of which require services to export their "source metadata." The former represents a standard effort for information retrieval while the latter is intended to be an informal, lightweight agreement for interoperability among Internet search engine vendors. <p> However, our architecture can benefit from the Explain facility; it should be relatively easy to build proxies to Explain-compliant services that will support our proposed metadata facility. Finally, another relevant effort on top of which we built our architecture is STARTS <ref> [22] </ref> (http://www-db.- stanford.edu/~gravano/starts.html). STARTS is an informal "standards" effort coordinated by Stanford, whose main goal is to facilitate the interoperability of search engines for text. STARTS specifies what metadata should be exported by each collection of text documents.
Reference: 23. <author> National Information Standards Organization. </author> <title> Information Retrieval (Z39.50): Application Service Definition and Protocol Specification (ANSI/NISO Z39.50-1995). </title> <publisher> NISO Press, </publisher> <address> Bethesda, MD, </address> <year> 1995. </year> <note> Accessible at http://lcweb.loc.gov/- z3950/agency/. </note>
Reference-contexts: Work in this area generally falls into two categories: specification of metadata sets and architectures that integrate them. Relevant work in the first category (specification of metadata sets) includes, for instance, the Bib-1 attribute set in Z39.50 and the Dublin Core. The Z39.50 Bib-1 attribute set <ref> [23, 21] </ref> registers a large set of bibliographic attributes. <p> In addition to the work on metadata for information objects discussed above, there are also proposals that support metadata for search services. In this context, the efforts that are probably closest to what is described here are the Explain facility of Z39.50-1995 (i.e., Version 3 of Z39.50 <ref> [23] </ref>) and Stanford's STARTS [22], both of which require services to export their "source metadata." The former represents a standard effort for information retrieval while the latter is intended to be an informal, lightweight agreement for interoperability among Internet search engine vendors.
Reference: 24. <author> Carl Lagoze, Clifford A. Lynch, and Ron Daniel, Jr. </author> <title> The War-wick Framework: A container architecture for aggregating sets of metadata. </title> <type> Technical Report TR96-1593, </type> <institution> Cornell University, Computer Science Dept., </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Work on this aspect of the metadata problem includes the Warwick Framework <ref> [24] </ref>, and the Jet Propulsion Laboratory's DARE metadata model [25]. The Warwick Framework proposes a container architecture as a mechanism for incorporating attribute values from different metadata sets in a single information object. Within each object are "metadata packages," one for each distinct metadata set, e.g., Dublin Core or USMARC.
Reference: 25. <author> Jason J. Hyon and Rosana Bisciotti Borgen. </author> <title> Data archival and retrieval enhancement (DARE) metadata modeling and its user interface. </title> <booktitle> In Proceedings of the First IEEE Metadata Conference, </booktitle> <address> Silver Spring, Maryland, </address> <month> April </month> <year> 1996. </year> <title> IEEE. The Stanford Digital Library Metadata Architecture 15 </title>
Reference-contexts: Work on this aspect of the metadata problem includes the Warwick Framework [24], and the Jet Propulsion Laboratory's DARE metadata model <ref> [25] </ref>. The Warwick Framework proposes a container architecture as a mechanism for incorporating attribute values from different metadata sets in a single information object. Within each object are "metadata packages," one for each distinct metadata set, e.g., Dublin Core or USMARC.
Reference: 26. <institution> Government Information Locator Service (GILS), </institution> <year> 1996. </year> <note> Accessible at http://info.er.usgs.gov:80/gils/. </note>
Reference-contexts: This metadata is essentially another database that can be queried by the clients via the Z39.50 protocol. In the Explain database, server characteristics are divided into categories, and database record structures are defined for each category. The GILS profile for Z39.50 <ref> [26] </ref> defines a metadata attribute set for search services. The Explain facility provided by Z39.50 servers corresponds to the metadata general information facility supported by our service proxies.
Reference: 27. <author> Denis Lynch. </author> <title> Implementing Explain. Accessible at ftp://- ftp.loc.gov/pub/z3950/articles/denis.ps. This article was processed by the author using the L a T E X style file cljour2 from Springer-Verlag. </title>
Reference-contexts: As every service needs a proxy to enter our InfoBus, making proxies lightweight becomes critical. On the other hand, this simplicity may not be an issue for Z39.50 as both their clients and servers will necessarily have most of the required capabilities <ref> [27] </ref>. However, our architecture can benefit from the Explain facility; it should be relatively easy to build proxies to Explain-compliant services that will support our proposed metadata facility. Finally, another relevant effort on top of which we built our architecture is STARTS [22] (http://www-db.- stanford.edu/~gravano/starts.html).
References-found: 27

