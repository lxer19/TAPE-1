URL: http://www.cs.purdue.edu/homes/park/icga95.ps.Z
Refering-URL: http://www.cs.purdue.edu/homes/park/publ_regular.html
Root-URL: http://www.cs.purdue.edu
Title: A Comparative Study of Genetic Search  
Author: Kihong Park 
Address: Boston, MA 02215  
Affiliation: Computer Science Department Boston University  
Abstract: We present a comparative study of genetic algorithms and their search properties when treated as a combinatorial optimization technique. This is done in the context of the NP-hard problem MAX-SAT, the comparison being relative to the Metropolis process, and by extension, simulated annealing. Our contribution is two-fold. First, we show that for large and difficult MAX-SAT instances, the contribution of cross-over to the search process is marginal. Little is lost if it is dispensed altogether, running mutation and selection as an enlarged Metropolis process. Second, we show that for these problem instances, genetic search consistently performs worse than simulated annealing when subject to similar resource bounds. The correspondence between the two algorithms is made more precise via a decomposition argument, and provides a framework for interpreting our results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M Szegedy. </author> <title> Proof verification and hardness of approximation problems. </title> <booktitle> In Proc. 33rd IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 14-23, </pages> <year> 1992. </year>
Reference-contexts: In the case of MAX-kSAT, the existence of a bound on the constant approximation factor can be shown, thus making it unlikely that arbitrarily close approximations can be feasibly achieved <ref> [1] </ref>. The aforementioned facts provide strong evidence to indicate that MAX-kSAT is an inherently "easier" problem than MAX-CLIQUE, and it is interesting to ask whether the results obtained in [4, 17] are applicable to this problem domain. <p> The reason that D is not symmetric, in practice, is due do the selection operator which tends to discard low-fitness elements. In the case of CMS, the asymmetry of D is further pronounced by cross-over. Choose some definition for the diversity of a population div (A) with range <ref> [0; 1] </ref> where div (A) = 0 if, and only if, A consists of N copies of a single element, and div (A) 1 for a randomly chosen population.
Reference: [2] <author> S. Arora and S. Safra. </author> <title> Probabilistic checking of proofs: a new characterization of NP. </title> <booktitle> In Proc. 33rd IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 2-13, </pages> <year> 1992. </year>
Reference-contexts: Moreover, recent work has shown that unless P = NP, MAX-CLIQUE cannot be feasibly approximated to within a polynomial factor, much less a constant one <ref> [2] </ref>. In the case of MAX-kSAT, the existence of a bound on the constant approximation factor can be shown, thus making it unlikely that arbitrarily close approximations can be feasibly achieved [1].
Reference: [3] <author> T. Boseniuk, W. Ebeling, and A. </author> <title> Engel. Boltzmann and Darwin strategies in complex optimization. </title> <journal> Physics Letters A, </journal> 125(6/7):307-310, 1987. 
Reference-contexts: When treated as a strict optimization technique, the focus shifts exclusively to "how well" genetic algorithms fair relative to other algorithms. Although research abounds <ref> [3, 10, 12, 13, 15, 17, 21] </ref>, the jury is still out with respect to how effective GAs are at solving hard combinatorial optimization problems. In part, this is due to the nonuniformity of problem instances which makes comparing results across different domains difficult. <p> The resulting candidate solution was subject to the standard SA acceptance function. Similar hybrid algorithms have been considered in <ref> [3, 10] </ref>.
Reference: [4] <author> B. Carter and K. Park. </author> <title> Scalability problems of genetic search. </title> <booktitle> In Proc. IEEE International Conference on Systems, Man and Cybernetics, </booktitle> <pages> pages 1591-1596, </pages> <month> October, </month> <year> 1994. </year>
Reference-contexts: Hence, if the formula is satisfiable, an optimal assignment yields the fitness value m. In the following, we will work exclusively with MAX-3SAT, a popular variant. This paper extends previous work on the MAX-CLIQUE problem <ref> [4, 17] </ref> where it is shown that on a set of large, difficult problem instances belonging to the DIMACS benchmark set, simulated annealing consistently outperforms genetic algorithms. Although both problems are NP-hard, there is a significant difference with respect to their approximabil-ity. <p> The aforementioned facts provide strong evidence to indicate that MAX-kSAT is an inherently "easier" problem than MAX-CLIQUE, and it is interesting to ask whether the results obtained in <ref> [4, 17] </ref> are applicable to this problem domain. For instance, "easiness" may imply that the building-block hypothesis [9] is a more fitting attribute of instances belonging to this problem set, giving genetic algorithms an edge by virtue of its cross-over operator which is conjectured to exploit this feature. <p> The performance results indicate that for small problem instances, independent of their difficulty, genetic algorithms are able to find optimal solutions within "reasonable" time. This concurs with the scalability observations for MAX-CLIQUE <ref> [4, 17] </ref>. Table 2 shows the results for n = 600 with population size N = 300. Despite the increase in problem size, the m = 800 instance remains easy as predicted by the small = 1:33 &lt; 4:25 value. <p> This concurs with the observation of slow increase in the quality of solution found as a function of population size in the case of challenging MAX-CLIQUE instances <ref> [4] </ref>, where population sizes up to 32000 were tested using a CM-5. 3.3 Emulating Simulated Annealing without any diversity maintenance mechanism at population size N = 20 for up to 50000 generations. The mutation and cross-over rates were set at p m = 0:05 and p c = 0:5, respectively. <p> It is inherently more difficult to demonstrate negative than positive results experimentally. One can never claim to have exhausted all possible avenues of attack, and this paper makes no claims in this regard. The MAX-SAT results in conjunction with previous work on the MAX-CLIQUE problem <ref> [4, 17] </ref> suggest that for large and difficult problem instances, the building-block hypothesis may be an inadequate characterization, rendering cross-over's role marginal given its high computational cost. For linear and "near-linear" problems, it is possible to show that genetic algorithms are effective at finding optimal solutions [16, 18].
Reference: [5] <author> L. Davis (ed.). </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction Genetic algorithms [11] are increasingly being viewed as general-purpose optimization techniques applicable to a wide range of problem domains <ref> [5, 6, 12, 13, 15, 21] </ref>. The combination of the "survival of the fittest" principle and pairwise interaction among members of a population yields a non-local, yet intuitively appealing means of generating new elements, complementing the local mechanism facilitated by mutation.
Reference: [6] <author> K. De Jong and W. Spears. </author> <title> Using genetic algorithms to solve NP-complete problems. </title> <booktitle> In Proc. 3rd International Conf. on Genetic Algorithms, </booktitle> <pages> pages 124-132, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Genetic algorithms [11] are increasingly being viewed as general-purpose optimization techniques applicable to a wide range of problem domains <ref> [5, 6, 12, 13, 15, 21] </ref>. The combination of the "survival of the fittest" principle and pairwise interaction among members of a population yields a non-local, yet intuitively appealing means of generating new elements, complementing the local mechanism facilitated by mutation. <p> A Boolean assignment to n variables was en coded in the straightforward way as a n-bit string x with x i = 1 if, and only if, the ith variable was set to true. As noted in <ref> [6] </ref>, SAT is one of the problem domains having a "natural" GA representation. They go so far as to suggest that other NP-complete problems should be reduced to it because of this feature.
Reference: [7] <editor> D. Fogel and J. Atmar. </editor> <title> Comparing genetic operators with Gaussian mutations in simulated evolutionary processes using linear systems. </title> <journal> Biological Cybernetics, </journal> <volume> 63 </volume> <pages> 111-114, </pages> <year> 1990. </year>
Reference-contexts: We conclude with a discussion of the present methodology and some implications. 2 Characterization of Genetic Search 2.1 Isolating Cross-over's Contribution Evaluating the effects of cross-over in the overall search process of a GA has been an important theme <ref> [7, 8, 19, 20] </ref>. Given the strict combinatorial optimization setting of this paper, we take a direct approach by comparing the performance of CMS and CS against MS which does not employ the cross-over operator. Let p c and p m denote the cross-over rate and mutation rate, respectively.
Reference: [8] <author> S. Forrest and M. Mitchell. </author> <title> What makes a problem hard for a genetic algorithm? Some anomalous results and their explanation. </title> <type> Preprint, </type> <year> 1992. </year> <note> (To appear in Machine Learning.) </note>
Reference-contexts: We conclude with a discussion of the present methodology and some implications. 2 Characterization of Genetic Search 2.1 Isolating Cross-over's Contribution Evaluating the effects of cross-over in the overall search process of a GA has been an important theme <ref> [7, 8, 19, 20] </ref>. Given the strict combinatorial optimization setting of this paper, we take a direct approach by comparing the performance of CMS and CS against MS which does not employ the cross-over operator. Let p c and p m denote the cross-over rate and mutation rate, respectively.
Reference: [9] <author> D. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The aforementioned facts provide strong evidence to indicate that MAX-kSAT is an inherently "easier" problem than MAX-CLIQUE, and it is interesting to ask whether the results obtained in [4, 17] are applicable to this problem domain. For instance, "easiness" may imply that the building-block hypothesis <ref> [9] </ref> is a more fitting attribute of instances belonging to this problem set, giving genetic algorithms an edge by virtue of its cross-over operator which is conjectured to exploit this feature.
Reference: [10] <author> D. Goldberg. </author> <title> A note on Boltzmann tournament selection for genetic algorithms and population-oriented simulated annealing. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 445-460, </pages> <year> 1990. </year>
Reference-contexts: When treated as a strict optimization technique, the focus shifts exclusively to "how well" genetic algorithms fair relative to other algorithms. Although research abounds <ref> [3, 10, 12, 13, 15, 17, 21] </ref>, the jury is still out with respect to how effective GAs are at solving hard combinatorial optimization problems. In part, this is due to the nonuniformity of problem instances which makes comparing results across different domains difficult. <p> The resulting candidate solution was subject to the standard SA acceptance function. Similar hybrid algorithms have been considered in <ref> [3, 10] </ref>.
Reference: [11] <author> J. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Genetic algorithms <ref> [11] </ref> are increasingly being viewed as general-purpose optimization techniques applicable to a wide range of problem domains [5, 6, 12, 13, 15, 21].
Reference: [12] <author> P. Jog, J. Suh, and D. Gucht. </author> <title> Parallel genetic algorithms applied to the traveling salesman problem. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 1(4) </volume> <pages> 515-529, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Genetic algorithms [11] are increasingly being viewed as general-purpose optimization techniques applicable to a wide range of problem domains <ref> [5, 6, 12, 13, 15, 21] </ref>. The combination of the "survival of the fittest" principle and pairwise interaction among members of a population yields a non-local, yet intuitively appealing means of generating new elements, complementing the local mechanism facilitated by mutation. <p> When treated as a strict optimization technique, the focus shifts exclusively to "how well" genetic algorithms fair relative to other algorithms. Although research abounds <ref> [3, 10, 12, 13, 15, 17, 21] </ref>, the jury is still out with respect to how effective GAs are at solving hard combinatorial optimization problems. In part, this is due to the nonuniformity of problem instances which makes comparing results across different domains difficult.
Reference: [13] <author> D. Levine. </author> <title> A genetic algorithm for the set partitioning problem. </title> <booktitle> In Proc. 5th International Conf. on Genetic Algorithms, </booktitle> <pages> pages 481-487, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Genetic algorithms [11] are increasingly being viewed as general-purpose optimization techniques applicable to a wide range of problem domains <ref> [5, 6, 12, 13, 15, 21] </ref>. The combination of the "survival of the fittest" principle and pairwise interaction among members of a population yields a non-local, yet intuitively appealing means of generating new elements, complementing the local mechanism facilitated by mutation. <p> When treated as a strict optimization technique, the focus shifts exclusively to "how well" genetic algorithms fair relative to other algorithms. Although research abounds <ref> [3, 10, 12, 13, 15, 17, 21] </ref>, the jury is still out with respect to how effective GAs are at solving hard combinatorial optimization problems. In part, this is due to the nonuniformity of problem instances which makes comparing results across different domains difficult.
Reference: [14] <author> D. Mitchell, B. Selman, and H. Levesque. </author> <title> Hard and easy distributions for SAT problems. </title> <booktitle> In Proc. AAAI-92, </booktitle> <pages> pages 459-465, </pages> <year> 1992. </year>
Reference-contexts: To select generically difficult 3SAT instances without exerting a priori bias toward genetic search or simulated annealing, we will adopt the scheme proposed in <ref> [14] </ref>, where it is shown that the difficulty of 3SAT instances, as reflected by the amount of work done by the David-Putnam procedure in determining the sat-isfiability of a Boolean formula, varies as a function of the ratio = m=n (number of clauses / number of variables), exhibiting a sharp "phase <p> Two problem sizes were tested, the first with 100 variables, and the second with n = 600. For n = 100, three different clause sizes were employed, m = 200; 430, and 600. As described in <ref> [14] </ref>, for smaller problem sizes the "difficult" instances are found to lie at = m=n 4:3, not 4:25. For n = 600, the clause sizes tested were m = 800; 2550, and 4000. All instances were generated without forcing the formulae to be satisfiable.
Reference: [15] <author> H. Muhlenbein, M. Gorges-Schleuter and O. Kramer. </author> <title> Evolution algorithms in combinatorial optimization. </title> <journal> Parallel Computing, </journal> <volume> 7 </volume> <pages> 65-85, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction Genetic algorithms [11] are increasingly being viewed as general-purpose optimization techniques applicable to a wide range of problem domains <ref> [5, 6, 12, 13, 15, 21] </ref>. The combination of the "survival of the fittest" principle and pairwise interaction among members of a population yields a non-local, yet intuitively appealing means of generating new elements, complementing the local mechanism facilitated by mutation. <p> When treated as a strict optimization technique, the focus shifts exclusively to "how well" genetic algorithms fair relative to other algorithms. Although research abounds <ref> [3, 10, 12, 13, 15, 17, 21] </ref>, the jury is still out with respect to how effective GAs are at solving hard combinatorial optimization problems. In part, this is due to the nonuniformity of problem instances which makes comparing results across different domains difficult.
Reference: [16] <author> K. Park. </author> <title> A lower-bound result on the power of genetic algorithms. </title> <booktitle> In Proc. 5th International Conf. on Genetic Algorithms, </booktitle> <pages> pages 651, </pages> <year> 1993. </year>
Reference-contexts: For linear and "near-linear" problems, it is possible to show that genetic algorithms are effective at finding optimal solutions <ref> [16, 18] </ref>. In fact, it can be argued that linear and near-linear problems are, in some sense, the best representant problem class for the building-block hypothesis.
Reference: [17] <author> K. Park and B. Carter. </author> <title> On the effectiveness of genetic search in combinatorial optimization. </title> <booktitle> In Proc. 10th ACM Symposium on Applied Computing, Genetic Algorithms and Optimization Track, </booktitle> <pages> pages 329-336, </pages> <year> 1995. </year>
Reference-contexts: When treated as a strict optimization technique, the focus shifts exclusively to "how well" genetic algorithms fair relative to other algorithms. Although research abounds <ref> [3, 10, 12, 13, 15, 17, 21] </ref>, the jury is still out with respect to how effective GAs are at solving hard combinatorial optimization problems. In part, this is due to the nonuniformity of problem instances which makes comparing results across different domains difficult. <p> Hence, if the formula is satisfiable, an optimal assignment yields the fitness value m. In the following, we will work exclusively with MAX-3SAT, a popular variant. This paper extends previous work on the MAX-CLIQUE problem <ref> [4, 17] </ref> where it is shown that on a set of large, difficult problem instances belonging to the DIMACS benchmark set, simulated annealing consistently outperforms genetic algorithms. Although both problems are NP-hard, there is a significant difference with respect to their approximabil-ity. <p> The aforementioned facts provide strong evidence to indicate that MAX-kSAT is an inherently "easier" problem than MAX-CLIQUE, and it is interesting to ask whether the results obtained in <ref> [4, 17] </ref> are applicable to this problem domain. For instance, "easiness" may imply that the building-block hypothesis [9] is a more fitting attribute of instances belonging to this problem set, giving genetic algorithms an edge by virtue of its cross-over operator which is conjectured to exploit this feature. <p> The difficult instances for the decision problem are shown to be concentrated at 4:25, and this will be our main source for benchmark instances. The second goal of the paper is to provide a framework for understanding the performance results. We follow the approach of <ref> [17] </ref> where a decomposition method was proposed for isolating and evaluating the contribution of cross-over to the search process of a genetic algorithm. <p> MS, on the other hand, exhibits performance comparable to that of CMS. Thus we will show that with respect to the quality of solution found subject to similar resource bounds, CS MS ' CMS ; concurring with the results obtained for MAX-CLIQUE <ref> [17] </ref>. In other words, for the 3SAT benchmark instances considered, little power is gained when going from MS to CMS. 2.2 Genetic Search and Simulated Annealing CMS, MS, and CS are exactly describable as time-homogeneous Markov chains over the space of multi-sets of size N . <p> The performance results indicate that for small problem instances, independent of their difficulty, genetic algorithms are able to find optimal solutions within "reasonable" time. This concurs with the scalability observations for MAX-CLIQUE <ref> [4, 17] </ref>. Table 2 shows the results for n = 600 with population size N = 300. Despite the increase in problem size, the m = 800 instance remains easy as predicted by the small = 1:33 &lt; 4:25 value. <p> It is inherently more difficult to demonstrate negative than positive results experimentally. One can never claim to have exhausted all possible avenues of attack, and this paper makes no claims in this regard. The MAX-SAT results in conjunction with previous work on the MAX-CLIQUE problem <ref> [4, 17] </ref> suggest that for large and difficult problem instances, the building-block hypothesis may be an inadequate characterization, rendering cross-over's role marginal given its high computational cost. For linear and "near-linear" problems, it is possible to show that genetic algorithms are effective at finding optimal solutions [16, 18].
Reference: [18] <author> Y. Rabinovich and A. Wigderson. </author> <title> Analysis of a simple genetic algorithm. </title> <booktitle> In Proc. 4th International Conf. on Genetic Algorithms, </booktitle> <pages> pages 215-221, </pages> <year> 1991. </year>
Reference-contexts: For linear and "near-linear" problems, it is possible to show that genetic algorithms are effective at finding optimal solutions <ref> [16, 18] </ref>. In fact, it can be argued that linear and near-linear problems are, in some sense, the best representant problem class for the building-block hypothesis.
Reference: [19] <author> D. Schaffer, R. Caruana, and L. Eshelman. </author> <title> A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <booktitle> In Proc. 3th International Conf. on Genetic Algorithms, </booktitle> <pages> pages 51-60, </pages> <year> 1989. </year>
Reference-contexts: We conclude with a discussion of the present methodology and some implications. 2 Characterization of Genetic Search 2.1 Isolating Cross-over's Contribution Evaluating the effects of cross-over in the overall search process of a GA has been an important theme <ref> [7, 8, 19, 20] </ref>. Given the strict combinatorial optimization setting of this paper, we take a direct approach by comparing the performance of CMS and CS against MS which does not employ the cross-over operator. Let p c and p m denote the cross-over rate and mutation rate, respectively.
Reference: [20] <editor> D. Schaffer and L. Eshelman. </editor> <title> On crossover as an evolutionary viable strategy. </title> <booktitle> In Proc. 4th International Conf. on Genetic Algorithms, </booktitle> <pages> pages 61-68, </pages> <year> 1991. </year>
Reference-contexts: We conclude with a discussion of the present methodology and some implications. 2 Characterization of Genetic Search 2.1 Isolating Cross-over's Contribution Evaluating the effects of cross-over in the overall search process of a GA has been an important theme <ref> [7, 8, 19, 20] </ref>. Given the strict combinatorial optimization setting of this paper, we take a direct approach by comparing the performance of CMS and CS against MS which does not employ the cross-over operator. Let p c and p m denote the cross-over rate and mutation rate, respectively.
Reference: [21] <author> R. Unger and J. Moult. </author> <title> Genetic algorithms for 3D protein folding simulations. </title> <booktitle> In Proc. 5th International Conf. on Genetic Algorithms, </booktitle> <pages> pages 581-588, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Genetic algorithms [11] are increasingly being viewed as general-purpose optimization techniques applicable to a wide range of problem domains <ref> [5, 6, 12, 13, 15, 21] </ref>. The combination of the "survival of the fittest" principle and pairwise interaction among members of a population yields a non-local, yet intuitively appealing means of generating new elements, complementing the local mechanism facilitated by mutation. <p> When treated as a strict optimization technique, the focus shifts exclusively to "how well" genetic algorithms fair relative to other algorithms. Although research abounds <ref> [3, 10, 12, 13, 15, 17, 21] </ref>, the jury is still out with respect to how effective GAs are at solving hard combinatorial optimization problems. In part, this is due to the nonuniformity of problem instances which makes comparing results across different domains difficult.
Reference: [22] <author> M. Yannakakis. </author> <title> On the approximation of maximum satisfiability. </title> <journal> Journal of Algorithms, </journal> <volume> 17 </volume> <pages> 475-502, </pages> <year> 1994. </year>
Reference-contexts: In fact, it is complete for a large class of problems called MAX-SNP under a reduction that preserves approximability. worst-case ratio 3=4 (for 3SAT it is even better at 7=8) whereas for MAX-CLIQUE, no constant-ratio approximation scheme is known <ref> [22] </ref>. Moreover, recent work has shown that unless P = NP, MAX-CLIQUE cannot be feasibly approximated to within a polynomial factor, much less a constant one [2].
References-found: 22

