URL: ftp://ftp.cs.umass.edu/pub/eksl/tech-reports/94-15.ps
Refering-URL: http://eksl-www.cs.umass.edu/~stamant/publications.html
Root-URL: 
Title: Regression Can Build Predictive Causal Models  
Author: Paul R. Cohen, Lisa A. Ballesteros, Dawn E. Gregory, and Robert St. Amant 
Note: This research is supported by ARPA under contract F30602-93-C-0100, and by a NASA GSRP Training Grant, #NGT-70358.  
Address: Box 34610  Amherst, MA 01003-4610  
Affiliation: Computer Science  Experimental Knowlege Systems Laboratory Department of Computer Science,  Lederle Graduate Research Center University of Massachusetts  
Pubnum: Technical Report 94-15  
Abstract: Covariance information can help an algorithm search for predictive causal models and estimate the strengths of causal relationships. This information should not be discarded after conditional independence constraints are identified, as is usual in contemporary causal induction algorithms. Our fbd algorithm combines covariance information with an effective heuristic to build predictive causal models. We demonstrate that fbd is accurate and efficient. In one experiment we assess fbd's ability to find the best predictors for variables; in another we compare its performance, using many measures, with Pearl and Verma's ic algorithm. And although fbd is based on multiple linear regression, we cite evidence that it performs well on problems that are very difficult for regression algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Lisa Ballesteros. </author> <title> Regression-based causal induction with latent variable models. </title> <note> Submitted to AAAI, </note> <year> 1994. </year>
Reference-contexts: Selecting variables by their ! scores lessens this problem. We have obtained good results with models Glymour et al. [14, page 240] show are difficult for ordinary regression; see <ref> [1] </ref>. 3 Nevertheless, most causal induction algorithms attempt to build models that are consistent with conditional independence relationships, and they discard quantitative covariance information once these relationships are inferred.
Reference: [2] <author> P. Bentler. </author> <title> Theory and Implementation of EQS: A Strutural Equations Program. BMDP Statistical Software, </title> <publisher> Inc., </publisher> <address> Los Angeles, </address> <year> 1985. </year>
Reference-contexts: To estimate strengths of causal influence, these models (and the covariance matrices from which they are derived) are handed off to a statistical package such as LISREL or EQS <ref> [8, 2] </ref>. We claim that covariance information can guide the search for causal models, estimate the strengths of causal relationships, and yield predictive causal models. It shouldn't be thrown away after conditional independence constraints are identified.
Reference: [3] <author> Paul R. Cohen, Lisa Ballesteros, Dawn Gregory, and Robert St. Amant. </author> <title> Experiments with a regression-based causal induction algorithm. </title> <type> Unpublished technical report, </type> <year> 1994. </year>
Reference-contexts: A single member often rendered another conditionally independent of the predictee, but never was a member made conditionally independent by all the other members. Possible explanations for this phenomenon, and their consequences for the control of causal induction algorithms, are discussed in <ref> [3] </ref>. 3 3. The FBD Algorithm Briefly, here is the fbd algorithm. Let ! XY and fi XY denote X's ! and fi scores when X is used as a predictor of Y , and let T ! , T fi and T R 2 be thresholds as described above. <p> In practice, it takes less than 15 seconds to build models of 6 to 9 variables (100 variates per variable) on a Sparc 10. 4. Experiments with the FBD Algorithm The experiments reported here used a set of 60 target models (see <ref> [3] </ref> for experiments with a more extensive set). Models included 6, 9 or 12 variables. A target model is a directed acyclic graph with weights on its links and a set of 100 data that are probably sufficient to recreate the model given only the data. <p> The procedure for generating models is described in <ref> [3] </ref> and is similar to the procedure in [14]. 4.1 Experiment 1. Does FBD Choose Good Predictors? Because fbd works backwards|first predicting the dependent variable, then predicting the predictors|its ability to choose good predictors is crucial.
Reference: [4] <author> G. Cooper and E. Herskovits. </author> <title> A bayesian method for constructing bayesian belief networks from databases. </title> <editor> In Bruce D'Ambrosio, Philippe Smets, and Piero Bonissone, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 86-94. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference: [5] <author> David Hoaglin, Frederick Mosteller, and John Tukey. </author> <title> Understanding robust and exploratory data analysis. </title> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1983. </year>
Reference-contexts: Crudely, if x and y are conditionally independent given z, then either z causes both x and y or z sits between x and y in a causal chain. Another approach, dating back to Sewall Wright's path analysis, is closely related to multiple linear regression <ref> [9, 13, 5] </ref>. Historically, path analysis was used to estimate the strengths of causal influences in a causal model. Someone still had to propose a causal model, but path analysis could provide measures of how well it fit the data. <p> Linear regression is not popular, currently, with the causal induction community. One reason is that many relationships are not linear, but this concern can often be addressed by transforming one's data beforehand <ref> [5] </ref>. A more subtle issue, raised by Glymour, Spirtes and Scheines, is that beta coefficients are unstable, especially when unmeasured or latent variables influence them. Selecting variables by their ! scores lessens this problem.
Reference: [6] <author> Paul Holland. </author> <title> Statistics and causal inference. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 81 </volume> <pages> 945-960, </pages> <year> 1986. </year>
Reference: [7] <author> Y. Iwasaki and H.A. Simon. </author> <title> Causality in device behavior. </title> <journal> Artificial Intelligence, </journal> <volume> 29 </volume> <pages> 3-32, </pages> <year> 1986. </year>
Reference: [8] <author> K. Joreskog and D. Sorbom. </author> <title> LISREL VI User's Guide. Scientific Software, </title> <publisher> Inc., </publisher> <address> Mooresville, IN, </address> <year> 1984. </year>
Reference-contexts: To estimate strengths of causal influence, these models (and the covariance matrices from which they are derived) are handed off to a statistical package such as LISREL or EQS <ref> [8, 2] </ref>. We claim that covariance information can guide the search for causal models, estimate the strengths of causal relationships, and yield predictive causal models. It shouldn't be thrown away after conditional independence constraints are identified.
Reference: [9] <author> C.C. Li. </author> <title> Path analysis-a primer. </title> <publisher> Boxwood Press, </publisher> <year> 1975. </year>
Reference-contexts: Crudely, if x and y are conditionally independent given z, then either z causes both x and y or z sits between x and y in a causal chain. Another approach, dating back to Sewall Wright's path analysis, is closely related to multiple linear regression <ref> [9, 13, 5] </ref>. Historically, path analysis was used to estimate the strengths of causal influences in a causal model. Someone still had to propose a causal model, but path analysis could provide measures of how well it fit the data.
Reference: [10] <author> Judea Pearl and T.S. Verma. </author> <title> A statistical semantics for causation. </title> <journal> Statistics and Computing, </journal> <volume> 2 </volume> <pages> 91-95, </pages> <year> 1991. </year> <month> 14 </month>
Reference-contexts: out, though, we cannot spend our lives running controlled experiments, and sometimes we do infer cause from associations: ": : : the question remains how causal knowledge is ever acquired from experience." [11] Pearl and Verma have designed and implemented algorithms to infer causal relationships given only correlational (covariance) information <ref> [11, 10] </ref>. Spirtes, Glymour, Scheines and their colleagues have developed several algorithms with similar goals and underlying principles [14]. In fact, there have been several efforts in AI (e.g.[7, 4]) dating back to Simon [12] to induce causal relationships from observational data.
Reference: [11] <author> Judea Pearl and T.S. Verma. </author> <title> A theory of inferred causation. </title> <editor> In J. Allen, R. Fikes, and E. Sandewall, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference., </booktitle> <pages> pages 441-452. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1991. </year>
Reference-contexts: Thus, some assert that causal inferences without experiments are impossible (e.g.[6]). As Pearl and Verma point out, though, we cannot spend our lives running controlled experiments, and sometimes we do infer cause from associations: ": : : the question remains how causal knowledge is ever acquired from experience." <ref> [11] </ref> Pearl and Verma have designed and implemented algorithms to infer causal relationships given only correlational (covariance) information [11, 10]. Spirtes, Glymour, Scheines and their colleagues have developed several algorithms with similar goals and underlying principles [14]. <p> out, though, we cannot spend our lives running controlled experiments, and sometimes we do infer cause from associations: ": : : the question remains how causal knowledge is ever acquired from experience." [11] Pearl and Verma have designed and implemented algorithms to infer causal relationships given only correlational (covariance) information <ref> [11, 10] </ref>. Spirtes, Glymour, Scheines and their colleagues have developed several algorithms with similar goals and underlying principles [14]. In fact, there have been several efforts in AI (e.g.[7, 4]) dating back to Simon [12] to induce causal relationships from observational data. <p> We assessed eighteen different measures of its performance, summarized in Table 4 and, for most of these measures, compared fbd's performance with that of Pearl and Verma's ic algorithm <ref> [11] </ref>. The algorithms differ in three important ways. First, fbd is told which variable is the root of each target model, whereas the ic algorithm is given no such information. 2 Second, fbd runs regressions to find good predictors whereas the ic algorithm works with conditional independence relationships, only. <p> We look at both direct and conditional dependencies in the target and inferred models. Pearl and Verma state, "[When all relevant variables are included in the model,] two causal models are equivalent iff their dags have the same links and the same set of uncoupled head-to-head nodes." <ref> [11] </ref> To measure this notion of equivalence, we compare each inferred model to the target model, and calculate number of correct links, the number of correct head-to-head (collider) nodes, and the total number of correct dependencies and colliders. (For ic, undirected links counted toward the dependence score, and directed links, only,
Reference: [12] <author> H. Simon. </author> <title> Spurious correlations: A causal interpretation. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 49 </volume> <pages> 469-492, </pages> <year> 1954. </year>
Reference-contexts: Spirtes, Glymour, Scheines and their colleagues have developed several algorithms with similar goals and underlying principles [14]. In fact, there have been several efforts in AI (e.g.[7, 4]) dating back to Simon <ref> [12] </ref> to induce causal relationships from observational data. All rely on conditional independence in one way or another. Crudely, if x and y are conditionally independent given z, then either z causes both x and y or z sits between x and y in a causal chain.
Reference: [13] <author> Robert R. Sokal and F. James Rohlf. Biometry: </author> <booktitle> the principles and practice of statistics in biological research. W.H. </booktitle> <publisher> Freeman and Co., </publisher> <address> New York, </address> <note> second edition, </note> <year> 1981. </year>
Reference-contexts: Crudely, if x and y are conditionally independent given z, then either z causes both x and y or z sits between x and y in a causal chain. Another approach, dating back to Sewall Wright's path analysis, is closely related to multiple linear regression <ref> [9, 13, 5] </ref>. Historically, path analysis was used to estimate the strengths of causal influences in a causal model. Someone still had to propose a causal model, but path analysis could provide measures of how well it fit the data.
Reference: [14] <author> Peter Spirtes, Clark Glymour, and Richard Scheines. </author> <title> Causation, Prediction, and Search. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Spirtes, Glymour, Scheines and their colleagues have developed several algorithms with similar goals and underlying principles <ref> [14] </ref>. In fact, there have been several efforts in AI (e.g.[7, 4]) dating back to Simon [12] to induce causal relationships from observational data. All rely on conditional independence in one way or another. <p> The procedure for generating models is described in [3] and is similar to the procedure in <ref> [14] </ref>. 4.1 Experiment 1. Does FBD Choose Good Predictors? Because fbd works backwards|first predicting the dependent variable, then predicting the predictors|its ability to choose good predictors is crucial. <p> A more subtle issue, raised by Glymour, Spirtes and Scheines, is that beta coefficients are unstable, especially when unmeasured or latent variables influence them. Selecting variables by their ! scores lessens this problem. We have obtained good results with models Glymour et al. <ref> [14, page 240] </ref> show are difficult for ordinary regression; see [1]. 3 Nevertheless, most causal induction algorithms attempt to build models that are consistent with conditional independence relationships, and they discard quantitative covariance information once these relationships are inferred.
Reference: [15] <author> P.C. Suppes. </author> <title> A Probabilistic Theory of Causality. </title> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1970. </year>
Reference-contexts: Before we describe it in detail, let's consider the sense in which multi-level regression models are causal models. 2.1 Beta Coefficients as Strengths of Causal Influence If you subscribe to one notion of what a "cause" is, then beta coefficients are strengths of causal influence. Suppes <ref> [15] </ref> posits three requirements for x to cause y: x and y must covary, x must precede y, and other causes of y must be controlled . For instance, you flip a light switch 100 times and record that on 99 occasions, the light turns on; this is covariance.
Reference: [16] <author> Sewall Wright. </author> <title> Correlation and causation. </title> <journal> Journal of Agricultural Research, </journal> <volume> 20 </volume> <pages> 557-585, </pages> <year> 1921. </year>
Reference-contexts: Another way to assess whether a model is faithful to data is to calculate the predicted correlations between variables in the model and see how well they compare with the actual correlations in the data. The rules for predicting correlations come from path analysis <ref> [16] </ref>: The weight of a path between two variables is the product of the weights on the links along the path, and the predicted correlation is the sum of the weights of all legal paths.
References-found: 16

