URL: http://www.cs.utexas.edu/users/rraj/Pubs/ring.ps
Refering-URL: http://www.cs.utexas.edu/users/rraj/papers.html
Root-URL: 
Title: Rapid Convergence of a Local Load Balancing Algorithm for Asynchronous Rings  
Author: Johannes E. Gehrke ; C. Greg Plaxton ; Rajmohan Rajaraman ; 
Abstract: We consider the problem of load balancing in a ring network. We present an analysis of the following local algorithm. In each step, each node of the ring examines the number of tokens at its clockwise neighbor and sends a token to the neighbor if the neighbor has fewer tokens. We show that in a synchronous model, for any initial token distribution b, the algorithm converges to a completely balanced distribution within 4OPT(b) + n steps, where OPT(b) is the time taken by the optimal centralized algorithm to balance b completely. Our main result is an analysis of the algorithm in an asynchronous model in which local computations and messages may be arbitrarily delayed, subject to the constraint that each message is eventually delivered and each computation is eventually performed. By generalizing our analysis for the synchronous model, we show that for any initial token distribution b, the algorithm converges to a completely balanced distribution within 8OPT(b) + 2n rounds, where a round is a minimal sequence of steps in which every component of the network is scheduled at least once. We also show that for every initial token distribution, the message complexity of the algorithm is asymptotically optimal among all algorithms that move tokens in the clockwise direction.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> W. Aiello, B. Awerbuch, B. Maggs, and S. Rao. </author> <title> Approximate load balancing on dynamic and asynchronous networks. </title> <booktitle> In Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 632-641, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: A natural approach towards load balancing is to have each node periodically poll the other nodes to which it is connected, and send some of its load to neighbors with lesser load. Indeed, such local balancing algorithms have been studied extensively on different models of computation (e.g., see <ref> [1, 8, 10] </ref>). 1 Department of Computer Science, University of Wisconsin-Madison, Madison, WI 53706. Email: johannes@cs.wisc.edu. 2 Department of Computer Science, University of Texas at Austin, Austin, TX 78712. Supported by the National Science Foundation under Grant No. CCR-9504145. <p> A number of researchers have studied load balancing problems under different models of computation. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., [8, 10]), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., <ref> [1, 11] </ref>), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., [8, 10]), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., <ref> [1, 15] </ref>) (the capacity of an edge is the maximum number of tokens it can transmit per step).
Reference: 2. <author> E. Arjomandi, M. J. Fischer, and N. A. Lynch. </author> <title> Efficiency of synchronous versus asynchronous distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 449-456, </pages> <year> 1983. </year>
Reference-contexts: The time complexity of an algorithm is then defined as the maximum number of rounds taken over all possible schedulings of the components. (See Section 5 for a formal description of the asynchronous model.) The above notion of time is based on the model proposed in <ref> [2] </ref> for shared memory systems. An analogous model for message-passing systems was studied in [4]. <p> equivalent to that proposed in [20], where the time complexity of an algorithm is defined to be the longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most one <ref> [2] </ref>. (The model proposed in [20] has been subsequently used in the study of several distributed computing problems [6, 7].) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2; in particular, we show that: Thenumber of rounds taken by A
Reference: 3. <author> A. Arora and M. Gouda. </author> <title> Load balancing: An exercise in constrained convergence. </title> <editor> In J-M. Helary and M. Raynal, editors, </editor> <booktitle> Proceedings of the 9th International Workshop on Distributed Algorithms, Lecture Notes in Computer Science, </booktitle> <volume> volume 972, </volume> <pages> pages 183-197. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: In fact, it is easy to construct distributions with imbalance that can be balanced in O () steps. In recent work <ref> [3] </ref>, asynchronous balancing algorithms on several networks including the ring have been studied. However, the results of [3] are geared towards establishing eventual convergence in the presence of dynamic network changes, while we are interested in determining the time to convergence for static load balancing. <p> In fact, it is easy to construct distributions with imbalance that can be balanced in O () steps. In recent work <ref> [3] </ref>, asynchronous balancing algorithms on several networks including the ring have been studied. However, the results of [3] are geared towards establishing eventual convergence in the presence of dynamic network changes, while we are interested in determining the time to convergence for static load balancing.
Reference: 4. <author> H. Attiya and M. Mavronicolas. </author> <title> Efficiency of semi-synchronous versus asynchronous networks. </title> <journal> Mathematical Systems Theory, </journal> <volume> 27 </volume> <pages> 547-571, </pages> <year> 1994. </year>
Reference-contexts: An analogous model for message-passing systems was studied in <ref> [4] </ref>.
Reference: 5. <author> H. Attiya, M. Snir, and M. Warmuth. </author> <title> Computing on an anonymous ring. </title> <journal> Journal of the ACM, </journal> <volume> 35 </volume> <pages> 845-875, </pages> <year> 1988. </year>
Reference-contexts: In this paper, we study static load balancing on a ring network. The ring network has been studied extensively in both theory and practice. Several problems arising in distributed computing have been addressed on the ring (see <ref> [5, 13, 14, 19] </ref> for a variety of examples). From a practical perspective, the ring is an essential component of several parallel and distributed architectures [17, 25]. Our main contribution is a tight analysis of a simple algorithm that is based on the local balancing approach.
Reference: 6. <author> B. Awerbuch. </author> <title> Complexity of network synchronization. </title> <journal> Journal of the ACM, </journal> <volume> 32 </volume> <pages> 804-823, </pages> <year> 1985. </year>
Reference-contexts: longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most one [2]. (The model proposed in [20] has been subsequently used in the study of several distributed computing problems <ref> [6, 7] </ref>.) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2; in particular, we show that: Thenumber of rounds taken by A to balance any distribution b on an asyn chronous ring is at most 8OPT (b) + 2n. <p> Our result for the asynchronous model is similar in spirit to that of [7], in that our asynchronous algorithm is not obtained by using a general synchronizer <ref> [6] </ref> in conjunction with an algorithm optimized for a synchronous model.
Reference: 7. <author> B. Awerbuch, L. Cowen, and M. Smith. </author> <title> Efficient asynchronous distributed symmetry breaking. </title> <booktitle> In Proceedings of the 26th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 214-223, </pages> <year> 1994. </year>
Reference-contexts: longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most one [2]. (The model proposed in [20] has been subsequently used in the study of several distributed computing problems <ref> [6, 7] </ref>.) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2; in particular, we show that: Thenumber of rounds taken by A to balance any distribution b on an asyn chronous ring is at most 8OPT (b) + 2n. <p> Also related is the result of [9], where a worst-case bound on the number of token migrations is given for a model in which tokens can be transferred between any two nodes. Our result for the asynchronous model is similar in spirit to that of <ref> [7] </ref>, in that our asynchronous algorithm is not obtained by using a general synchronizer [6] in conjunction with an algorithm optimized for a synchronous model.
Reference: 8. <author> D. P. Bertsekas and J. N. Tsitsiklis. </author> <title> Parallel and Distributed Computation: Numer--ical Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: A natural approach towards load balancing is to have each node periodically poll the other nodes to which it is connected, and send some of its load to neighbors with lesser load. Indeed, such local balancing algorithms have been studied extensively on different models of computation (e.g., see <ref> [1, 8, 10] </ref>). 1 Department of Computer Science, University of Wisconsin-Madison, Madison, WI 53706. Email: johannes@cs.wisc.edu. 2 Department of Computer Science, University of Texas at Austin, Austin, TX 78712. Supported by the National Science Foundation under Grant No. CCR-9504145. <p> Previous and related work. A number of researchers have studied load balancing problems under different models of computation. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., <ref> [8, 10] </ref>), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., <ref> [8, 10] </ref>), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step).
Reference: 9. <author> E. Cohen. </author> <title> On the convergence span of greedy load balancing. </title> <journal> Information Processing Letters, </journal> <volume> 52 </volume> <pages> 181-182, </pages> <year> 1994. </year>
Reference-contexts: However, the results of [3] are geared towards establishing eventual convergence in the presence of dynamic network changes, while we are interested in determining the time to convergence for static load balancing. Also related is the result of <ref> [9] </ref>, where a worst-case bound on the number of token migrations is given for a model in which tokens can be transferred between any two nodes.
Reference: 10. <author> G. Cybenko. </author> <title> Dynamic load balancing for distributed memory multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 2 </volume> <pages> 279-301, </pages> <year> 1989. </year>
Reference-contexts: A natural approach towards load balancing is to have each node periodically poll the other nodes to which it is connected, and send some of its load to neighbors with lesser load. Indeed, such local balancing algorithms have been studied extensively on different models of computation (e.g., see <ref> [1, 8, 10] </ref>). 1 Department of Computer Science, University of Wisconsin-Madison, Madison, WI 53706. Email: johannes@cs.wisc.edu. 2 Department of Computer Science, University of Texas at Austin, Austin, TX 78712. Supported by the National Science Foundation under Grant No. CCR-9504145. <p> Previous and related work. A number of researchers have studied load balancing problems under different models of computation. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., <ref> [8, 10] </ref>), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., <ref> [8, 10] </ref>), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> In the discussion that follows, we restrict our attention to results for models of computation with the same basic characteristics as the model considered in the present paper, namely: distributed control, fixed-connection network communication, and bounded edge capacity. Local algorithms restricted to particular networks have been studied on hy-percubes <ref> [10, 24] </ref>, meshes [16, 21], and expanders [22, 23]. All of these papers analyze the worst-case complexity of certain local algorithms. More recently, it has been shown that a simple local algorithm is optimal in the worst-case on arbitrary networks [15].
Reference: 11. <author> X. Deng, H. N. Liu, L. Long, and B. Xiao. </author> <title> Competitive analysis of network load balancing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 40 </volume> <pages> 162-172, </pages> <year> 1997. </year>
Reference-contexts: A number of researchers have studied load balancing problems under different models of computation. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., [8, 10]), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., <ref> [1, 11] </ref>), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step).
Reference: 12. <author> D. Eager, D. Lazowska, and J. Zahorjan. </author> <title> Adaptive load sharing in homogeneous distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12 </volume> <pages> 662-675, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction An important problem in a distributed system is to balance the total workload over the processors. Such load balancing problems arise in a number of parallel and distributed applications including job scheduling in operating systems (e.g., see <ref> [12] </ref>), adaptive mesh partitioning (e.g., see [27]), and packet routing (e.g., see [22]). A natural approach towards load balancing is to have each node periodically poll the other nodes to which it is connected, and send some of its load to neighbors with lesser load.
Reference: 13. <author> P. Fizzano, D. Karger, C. Stein, and J. Wein. </author> <title> Job scheduling in rings. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 210-219, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In this paper, we study static load balancing on a ring network. The ring network has been studied extensively in both theory and practice. Several problems arising in distributed computing have been addressed on the ring (see <ref> [5, 13, 14, 19] </ref> for a variety of examples). From a practical perspective, the ring is an essential component of several parallel and distributed architectures [17, 25]. Our main contribution is a tight analysis of a simple algorithm that is based on the local balancing approach.
Reference: 14. <author> G. Frederickson and N. Lynch. </author> <title> Electing a leader in a synchronous ring. </title> <journal> Journal of the ACM, </journal> <volume> 34 </volume> <pages> 98-115, </pages> <year> 1987. </year>
Reference-contexts: In this paper, we study static load balancing on a ring network. The ring network has been studied extensively in both theory and practice. Several problems arising in distributed computing have been addressed on the ring (see <ref> [5, 13, 14, 19] </ref> for a variety of examples). From a practical perspective, the ring is an essential component of several parallel and distributed architectures [17, 25]. Our main contribution is a tight analysis of a simple algorithm that is based on the local balancing approach.
Reference: 15. <author> B. Ghosh, F. T. Leighton, B. M. Maggs, S. Muthukrishnan, C. G. Plaxton, R. Rajaraman, A. W. Richa, R. E. Tarjan, and D. Zuckerman. </author> <title> Tight analyses of two local load balancing algorithms. </title> <booktitle> In Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 548-558, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., [8, 10]), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., <ref> [1, 15] </ref>) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> All of these papers analyze the worst-case complexity of certain local algorithms. More recently, it has been shown that a simple local algorithm is optimal in the worst-case on arbitrary networks <ref> [15] </ref>. <p> While this approach simplifies the worst-case analysis for general networks (see <ref> [15] </ref>), it appears to be inadequate for our purposes since information about the particular distribution of imbalance is lost.
Reference: 16. <author> A. Heirich and S. Taylor. </author> <title> A parabolic theory of load balance. </title> <type> Technical Report Caltech-CS-TR-93-22, </type> <institution> Caltech Scalable Concurrent Computation Lab, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Local algorithms restricted to particular networks have been studied on hy-percubes [10, 24], meshes <ref> [16, 21] </ref>, and expanders [22, 23]. All of these papers analyze the worst-case complexity of certain local algorithms. More recently, it has been shown that a simple local algorithm is optimal in the worst-case on arbitrary networks [15].
Reference: 17. <author> D. Hutchinson. </author> <title> Local Area Network Architectures. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: Several problems arising in distributed computing have been addressed on the ring (see [5, 13, 14, 19] for a variety of examples). From a practical perspective, the ring is an essential component of several parallel and distributed architectures <ref> [17, 25] </ref>. Our main contribution is a tight analysis of a simple algorithm that is based on the local balancing approach. We show that this algorithm, which we denote by A, converges to a balanced distribution in near-optimal time for every initial distribution on both synchronous and asynchronous rings.
Reference: 18. <author> L. Lamport and N. Lynch. </author> <title> Distributed computing: Models and methods. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics, </booktitle> <pages> pages 1157-1199. </pages> <publisher> Elsevier/MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Our next result concerns an asynchronous model of computation, in which local computations may be performed at arbitrary speeds and messages may be delayed arbitrarily, subject to the constraint that each message is eventually delivered and each computation is eventually performed <ref> [18] </ref>. In order to measure time complexity in the asynchronous model, we define a round to be a minimal sequence of steps in which each component of the ring (i.e., each node or edge) is scheduled at least once.
Reference: 19. <author> F. T. Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, and Hypercubes. </title> <publisher> Morgan-Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: In this paper, we study static load balancing on a ring network. The ring network has been studied extensively in both theory and practice. Several problems arising in distributed computing have been addressed on the ring (see <ref> [5, 13, 14, 19] </ref> for a variety of examples). From a practical perspective, the ring is an essential component of several parallel and distributed architectures [17, 25]. Our main contribution is a tight analysis of a simple algorithm that is based on the local balancing approach.
Reference: 20. <author> N. Lynch and M. Fisher. </author> <title> On describing the behavior and implementation of distributed systems. </title> <journal> Theoretical Computer Science, </journal> <volume> 13 </volume> <pages> 17-43, </pages> <year> 1981. </year>
Reference-contexts: An analogous model for message-passing systems was studied in [4]. Moreover, our model is equivalent to that proposed in <ref> [20] </ref>, where the time complexity of an algorithm is defined to be the longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most one [2]. (The model proposed in [20] <p> <ref> [20] </ref>, where the time complexity of an algorithm is defined to be the longest amount of elapsed real time from the start to the completion of the algorithm, assuming that the time delay between two steps of the same network component is at most one [2]. (The model proposed in [20] has been subsequently used in the study of several distributed computing problems [6, 7].) We generalize our result for the synchronous model to the asynchronous model at the expense of a factor of 2; in particular, we show that: Thenumber of rounds taken by A to balance any distribution b
Reference: 21. <editor> F. Meyer auf der Heide, B. Oesterdiekhoff, and R. </editor> <title> Wanka. Strongly adaptive token distribution. </title> <journal> Algorithmica, </journal> <volume> 15 </volume> <pages> 413-427, </pages> <year> 1996. </year>
Reference-contexts: Previous and related work. A number of researchers have studied load balancing problems under different models of computation. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., <ref> [21, 26] </ref>) versus distributed control (e.g., [8, 10]), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> Local algorithms restricted to particular networks have been studied on hy-percubes [10, 24], meshes <ref> [16, 21] </ref>, and expanders [22, 23]. All of these papers analyze the worst-case complexity of certain local algorithms. More recently, it has been shown that a simple local algorithm is optimal in the worst-case on arbitrary networks [15].
Reference: 22. <author> D. Peleg and E. Upfal. </author> <title> The generalized packet routing problem. </title> <journal> Theoretical Computer Science, </journal> <volume> 53 </volume> <pages> 281-293, </pages> <year> 1987. </year>
Reference-contexts: Such load balancing problems arise in a number of parallel and distributed applications including job scheduling in operating systems (e.g., see [12]), adaptive mesh partitioning (e.g., see [27]), and packet routing (e.g., see <ref> [22] </ref>). A natural approach towards load balancing is to have each node periodically poll the other nodes to which it is connected, and send some of its load to neighbors with lesser load. <p> Local algorithms restricted to particular networks have been studied on hy-percubes [10, 24], meshes [16, 21], and expanders <ref> [22, 23] </ref>. All of these papers analyze the worst-case complexity of certain local algorithms. More recently, it has been shown that a simple local algorithm is optimal in the worst-case on arbitrary networks [15].
Reference: 23. <author> D. Peleg and E. Upfal. </author> <title> The token distribution problem. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18 </volume> <pages> 229-243, </pages> <year> 1989. </year>
Reference-contexts: Local algorithms restricted to particular networks have been studied on hy-percubes [10, 24], meshes [16, 21], and expanders <ref> [22, 23] </ref>. All of these papers analyze the worst-case complexity of certain local algorithms. More recently, it has been shown that a simple local algorithm is optimal in the worst-case on arbitrary networks [15].
Reference: 24. <author> C. G. Plaxton. </author> <title> Load balancing, selection, and sorting on the hypercube. </title> <booktitle> In Proceedings of the 1st Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 64-73, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: In the discussion that follows, we restrict our attention to results for models of computation with the same basic characteristics as the model considered in the present paper, namely: distributed control, fixed-connection network communication, and bounded edge capacity. Local algorithms restricted to particular networks have been studied on hy-percubes <ref> [10, 24] </ref>, meshes [16, 21], and expanders [22, 23]. All of these papers analyze the worst-case complexity of certain local algorithms. More recently, it has been shown that a simple local algorithm is optimal in the worst-case on arbitrary networks [15].
Reference: 25. <author> A. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: Several problems arising in distributed computing have been addressed on the ring (see [5, 13, 14, 19] for a variety of examples). From a practical perspective, the ring is an essential component of several parallel and distributed architectures <ref> [17, 25] </ref>. Our main contribution is a tight analysis of a simple algorithm that is based on the local balancing approach. We show that this algorithm, which we denote by A, converges to a balanced distribution in near-optimal time for every initial distribution on both synchronous and asynchronous rings.
Reference: 26. <author> A. N. Tantawi and D. Towsley. </author> <title> Optimal static load balancing in distributed computer systems. </title> <journal> Journal of the ACM, </journal> <volume> 32 </volume> <pages> 445-465, </pages> <year> 1985. </year>
Reference-contexts: Previous and related work. A number of researchers have studied load balancing problems under different models of computation. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., <ref> [21, 26] </ref>) versus distributed control (e.g., [8, 10]), (ii) uniform communication (e.g., [26]) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step). <p> Previous and related work. A number of researchers have studied load balancing problems under different models of computation. These models can be classified on the basis of three characteristics: (i) centralized control (e.g., [21, 26]) versus distributed control (e.g., [8, 10]), (ii) uniform communication (e.g., <ref> [26] </ref>) versus fixed-connection network communication (e.g., [1, 11]), and (iii) unbounded edge capacity (e.g., [8, 10]) versus bounded edge capacity (e.g., [1, 15]) (the capacity of an edge is the maximum number of tokens it can transmit per step).
Reference: 27. <author> R. D. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3 </volume> <pages> 457-481, </pages> <year> 1991. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: 1 Introduction An important problem in a distributed system is to balance the total workload over the processors. Such load balancing problems arise in a number of parallel and distributed applications including job scheduling in operating systems (e.g., see [12]), adaptive mesh partitioning (e.g., see <ref> [27] </ref>), and packet routing (e.g., see [22]). A natural approach towards load balancing is to have each node periodically poll the other nodes to which it is connected, and send some of its load to neighbors with lesser load.
References-found: 27

