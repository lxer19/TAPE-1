URL: http://www-rali.iro.umontreal.ca/Publications/euro-e.ps
Refering-URL: http://www-rali.iro.umontreal.ca/Publications.en.html
Root-URL: http://www.iro.umontreal.ca
Title: French Speech Recognition in an Automatic Dictation System for Translators: the TransTalk Project  
Author: Julie Brousseau Caroline Drouin George Foster Pierre Isabelle Roland Kuhn Yves Normandin and Pierre Plamondon 
Address: 1575 Boul. Chomedey, Laval, Quebec, Canada, H7V 2X2  1801 McGill College, Montreal, Quebec, Canada, H3A 2NA  
Affiliation: Centre d'Innovation en Technologies de l'Information (CITI)  Centre de recherche informatique de Montreal (CRIM)  
Abstract: This paper describes a system designed for use by professional translators that enables them to dictate their translation. Because the speech recognizer has access to the source text as well as the spoken translation, a statistical translation model can guide recognition. This can be done in many different ways|which is best? We discuss the experiments that led to integration of the translation model in a way that improves both speed and performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Marc Dymetman, Julie Brousseau, George Foster, Pierre Isabelle, Yves Nor-mandin, and Pierre Plamondon. </author> <title> Towards an automatic dictation system for translators: the TransTalk project. </title> <booktitle> In Proceedings, ICSLP 94, </booktitle> <volume> volume 2, </volume> <pages> pages 691-694, </pages> <address> Yokohama, Japan, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: We have implemented a prototype of TransTalk that takes as input an English text and a spoken French translation, and yields French text. An earlier paper <ref> [1] </ref> focused mainly on the machine translation aspects of TransTalk. Since that paper was written, we have made improvements in both components of the prototype|for instance, the French speech recognition component now handles continuous speech. <p> Version 1, described in <ref> [1] </ref>, was capable only of isolated-word speech recognition. The two more recent versions both carry out continuous mode dictation over a vocabulary of 20,000 French word forms and expressions. <p> A variety of translation models, all requiring bilingual training data, will yield probability estimates for French words, given the English source sentence <ref> [1, 2] </ref>. The models differ mainly in the extent to which they take into account the position of given words in the English and in the French sentence. <p> What models should be chosen, and how can the probabilities they generate be applied to constrain speech recognition? In version 1 of TransTalk (described in <ref> [1] </ref>) a simple combined translation-language model (TLM) is applied to the output of an isolated-word recognizer. For each acoustic token, the recognizer generates n word hypotheses; the TLM is applied during a Viterbi search to yield a French sentence with n words. <p> cause the number of recognition errors to increase (because the translation model wrongly removes correct words from consideration) or to decrease (because the translation model removes wrong words that are acoustically similar to the right ones from consideration). 6 Results Results for version 1 of our system are given in <ref> [1] </ref>. Table 1 pertains to version 2. The row SR gives results for the top hypothesis of the 200 generated by the speech recognizer; the average rank of the best hypothesis (the one closest to the truth) is 54.
Reference: [2] <author> J.L. Gauvain and L.F. Lamel et al. </author> <title> Speaker-independent continuous speech dictation. </title> <journal> Speech Communication, </journal> <volume> 15 </volume> <pages> 21-37, </pages> <year> 1994. </year>
Reference-contexts: Since that paper was written, we have made improvements in both components of the prototype|for instance, the French speech recognition component now handles continuous speech. The current paper will focus on the unique problems of large 1 vocabulary speech recognition in the French language <ref> [2] </ref>, and features of our system designed to deal with these problems, as well as presenting experimental results. 2 The Transtalk System We have tried out three quite different versions of our TransTalk prototype. Version 1, described in [1], was capable only of isolated-word speech recognition. <p> A variety of translation models, all requiring bilingual training data, will yield probability estimates for French words, given the English source sentence <ref> [1, 2] </ref>. The models differ mainly in the extent to which they take into account the position of given words in the English and in the French sentence.
Reference: [3] <author> M. Lennig. </author> <title> 3 listes de 10 phrases phonetiquement equilibrees. </title> <journal> Revue d'acoustique, </journal> <volume> 1(56) </volume> <pages> 39-42, </pages> <year> 1981. </year>
Reference-contexts: Finally, 29 speakers read 43 phonetically balanced French sentences <ref> [3] </ref>, yielding 1,247 spoken sentences. These 24,250 (total) spoken sentences were read in continuous mode, with verbalized punctuation. The bigram French language model was trained on a French corpus of 2.2 million words drawn from 40 Hansard files.
Reference: [4] <author> Y. Normandin and D. Bowness et al. </author> <title> CRIM's november 94 continuous speech recognition system. </title> <booktitle> In Proceedings of the Spoken Language Systems Technology Workshop, </booktitle> <address> Austin, Texas, </address> <month> January </month> <year> 1995. </year> <month> 8 </month>
Reference-contexts: In going from version 2 to version 3, we also made changes in the recognizer unrelated to the way in which the translation module is integrated into it. In the version 2 recognizer (described in detail in <ref> [4] </ref>) acoustic modeling is carried out by triphone HMMs with shared codebook output distributions (mixture Gaussian distributions with one codebook of Gaussian densities per phone). Recognition is performed in several passes. <p> In our 20,000 word vocabulary there are 6,020 words such that for each of them, at least one homophone exists. Thus, 30% of our lexicon is made up of homophones, compared to 5% for the 19,977 WSJ word lexicon <ref> [4] </ref>. Where only one member of a set of homophones is predicted by the English source sentence, the translation module will be particularly useful (e.g. children predicts enfants rather than enfant). A major challenge that must be overcome in French speech recognition is liaison.
Reference: [5] <author> S.J. Young, J. Odell, and P. Woodland. </author> <title> Tree-based state tying for high ac-curacy acoustic modeling. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology, </booktitle> <pages> pages 286-291, </pages> <month> March </month> <year> 1994. </year> <month> 9 </month>
Reference-contexts: The version 3 recognizer no longer employs triphones as the basic acoustic unit. Instead, the basic unit is now the tree state, i.e., each state of the HMM for a given phone is represented by a context-dependent decision tree <ref> [5] </ref>. So far, our experience with tree states both in English and in French speech recognition has been extremely positive. As compared with triphones, tree states use considerably less memory and speed up recognition, while yielding better performance.
References-found: 5

