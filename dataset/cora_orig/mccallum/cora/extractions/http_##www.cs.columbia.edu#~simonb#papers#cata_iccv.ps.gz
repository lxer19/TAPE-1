URL: http://www.cs.columbia.edu/~simonb/papers/cata_iccv.ps.gz
Refering-URL: http://www.cs.columbia.edu/~simonb/pub.html
Root-URL: http://www.cs.columbia.edu
Title: A Theory of Catadioptric Image Formation  
Author: Simon Baker and Shree K. Nayar 
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Date: January 1998.  
Note: Appeared in the Proceedings of the 6th International Conference on Computer Vision, Bombay,  
Abstract: Conventional video cameras have limited fields of view which make them restrictive for certain applications in computational vision. A catadioptric sensor uses a combination of lenses and mirrors placed in a carefully arranged configuration to capture a much wider field of view. When designing a catadioptric sensor, the shape of the mirror(s) should ideally be selected to ensure that the complete catadioptric system has a single effective viewpoint. In this paper, we derive the complete class of single-lens single-mirror catadioptric sensors which have a single viewpoint and an expression for the spatial resolution of a catadioptric sensor in terms of the resolution of the camera used to construct it. We also include a preliminary analysis of the defocus blur caused by the use of a curved mirror. 
Abstract-found: 1
Intro-found: 1
Reference: [ Adelson and Bergen, 1991 ] <author> E.H. Adelson and J.R. Bergen. </author> <title> The plenoptic function and elements of early vision. </title> <editor> In Landy and Movshon, editors, </editor> <booktitle> Computational Models of Visual Processing, chapter 1. </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: In other words, the catadioptric sensor can only sample the 5-D plenoptic function <ref> [ Adelson and Bergen, 1991 ] </ref> at a single point. The fixed 3-D point at which a catadioptric sensor samples the plenoptic function will be referred to as the effective viewpoint.
Reference: [ Bogner, 1995 ] <author> S. Bogner. </author> <title> Introduction to panoramic imaging. </title> <booktitle> In Proceedings of the IEEE SMC Conference, </booktitle> <pages> pages 3100-3106, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: in conjunction with lenses (see, for example, [ Rees, 1970 ] , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , <ref> [ Bogner, 1995 ] </ref> , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. <p> The cone has been used for wide-angle imaging a number of times [ Yagi and Kawato, 1990 ] [ Yagi and Yachida, 1991 ] <ref> [ Bogner, 1995 ] </ref> . In these implementations the pinhole is placed quite some distance from the apex of the cone. It is easy to show that in such cases the viewpoint is no longer a single point [ Nalwa, 1996 ] . <p> Since the viewpoint and pinhole coincide at the center of the sphere, the observer only sees itself. The sphere has also been used to enhance the field of view several times [ Hong, 1991 ] <ref> [ Bogner, 1995 ] </ref> [ Mur-phy, 1995 ] . In these implementations, the pinhole is placed outside the sphere and so there is no single effective viewpoint.
Reference: [ Charles et al., 1987 ] <author> J.R. Charles, R. Reeves, and C. </author> <title> Schur. How to build and use an all-sky camera. </title> <journal> Astronomy Magazine, </journal> <month> April </month> <year> 1987. </year>
Reference-contexts: One effective way to enhance the field of view is to use mirrors in conjunction with lenses (see, for example, [ Rees, 1970 ] , <ref> [ Charles et al., 1987 ] </ref> , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , [ Nalwa, 1996 ] , and [ Nayar,
Reference: [ Goshtasby and Gruver, 1993 ] <author> A. Goshtasby and W.A. Gruver. </author> <title> Design of a single-lens stereo camera system. </title> <journal> Pattern Recognition, </journal> <volume> 26(6) </volume> <pages> 923-937, </pages> <year> 1993. </year>
Reference-contexts: One effective way to enhance the field of view is to use mirrors in conjunction with lenses (see, for example, [ Rees, 1970 ] , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , <ref> [ Goshtasby and Gruver, 1993 ] </ref> , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. <p> On the other hand, in applications such as stereo where multiple viewpoints are a necessary requirement, the multiple views of a scene can be captured by a single camera using multiple planar mirrors. See, for example, <ref> [ Goshtasby and Gruver, 1993 ] </ref> . This brings us to the panoramic camera proposed by Nalwa [ 1996 ] . To ensure a single viewpoint while using multiple planar mirrors, Nalwa [ 1996 ] has arrived at a design that uses four separate imaging systems.
Reference: [ Hecht and Zajac, 1974 ] <author> E. Hecht and A. Zajac. </author> <title> Optics. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: The combination of refracting and reflecting elements is therefore referred to as catadioptrics <ref> [ Hecht and Zajac, 1974 ] </ref> . able is that it permits the generation of geometrically correct perspective images from the image (s) captured by the catadioptric cameras. <p> This expression should be carefully considered when constructing a catadioptric imaging system in order to ensure that the final sensor has sufficient resolution. Another optical property which is modified by the use of a catadioptric system is focusing. It is well known that a curved mirror increases image blur <ref> [ Hecht and Zajac, 1974 ] </ref> , and so in Section 4 we analyze this effect for catadioptric sensors. Two factors combine to cause blur in catadioptric systems: (1) the finite size of the lens aperture, and (2) the curvature of the mirror. <p> Then, since the hyperboloid mirror satisfies the fixed viewpoint constraint, a ray of light from w which is reflected by the mirror at m passes directly through the center of the lens (i.e. the pinhole.) This ray of light is known as the principal ray <ref> [ Hecht and Zajac, 1974 ] </ref> . <p> When this happens there is defocus blur. The locus of the intersection of the incoming rays through l and the image plane as l varies over the lens is known as the blur region or region of confusion <ref> [ Hecht and Zajac, 1974 ] </ref> . For an ideal thin lens, the blur region is circular and so is often referred to as the blur circle [ Hecht and Zajac, 1974 ] . <p> rays through l and the image plane as l varies over the lens is known as the blur region or region of confusion <ref> [ Hecht and Zajac, 1974 ] </ref> . For an ideal thin lens, the blur region is circular and so is often referred to as the blur circle [ Hecht and Zajac, 1974 ] . As is shown in [ Nayar and Baker, 1997b ] , for a catadioptric sensor the shape of the blur region is not, in general, circular. <p> First, the line through m 1 in the direction ~ lm 1 is extended to intersect the focused plane. By the thin lens law <ref> [ Hecht and Zajac, 1974 ] </ref> the focused plane is: z = c v = c u f where f is the focal length of the lens and u is the distance from the focal plane to the image plane. <p> However, it should be emphasized that the minimum area is very small, and in practice there is no problem focusing the image for a single world point. Moreover, is is possible to use additional corrective lenses to compensate for most of this effect <ref> [ Hecht and Zajac, 1974 ] </ref> . 41 distance to the focused plane v = fu uf for a point m = (0:125; 0:0; 0:125) on the hyperboloid mirror with k = 4.
Reference: [ Hong, 1991 ] <author> J. Hong. </author> <title> Image based homing. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: One effective way to enhance the field of view is to use mirrors in conjunction with lenses (see, for example, [ Rees, 1970 ] , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , <ref> [ Hong, 1991 ] </ref> , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] ). <p> Since the viewpoint and pinhole coincide at the center of the sphere, the observer only sees itself. The sphere has also been used to enhance the field of view several times <ref> [ Hong, 1991 ] </ref> [ Bogner, 1995 ] [ Mur-phy, 1995 ] . In these implementations, the pinhole is placed outside the sphere and so there is no single effective viewpoint.
Reference: [ Murphy, 1995 ] <author> J.R. Murphy. </author> <title> Application of panoramic imaging to a teleoperated lunar rover. </title> <booktitle> In Proceedings of the IEEE SMC Conference, </booktitle> <month> October </month> <year> 1995. </year>
Reference: [ Nalwa, 1996 ] <author> V.S. Nalwa. </author> <title> A true omnidirectional viewer. </title> <type> Technical report, </type> <institution> Bell Laboratories, </institution> <address> Holmdel, NJ 07733, USA, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: for example, [ Rees, 1970 ] , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , <ref> [ Nalwa, 1996 ] </ref> , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. As noted in [ Rees, 1970 ] , [ Yamazawa et al., 1995 ] , [ Nalwa, 1996 ] , <p> Bogner, 1995 ] , <ref> [ Nalwa, 1996 ] </ref> , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. As noted in [ Rees, 1970 ] , [ Yamazawa et al., 1995 ] , [ Nalwa, 1996 ] , and [ Nayar and Baker, 1997a ] , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection). <p> In these implementations the pinhole is placed quite some distance from the apex of the cone. It is easy to show that in such cases the viewpoint is no longer a single point <ref> [ Nalwa, 1996 ] </ref> . If the pinhole lies on the axis of the cone at a distance e from the apex of the cone, the locus of the effective viewpoint is a circle.
Reference: [ Nayar and Baker, 1997a ] <author> S.K. Nayar and S. Baker. </author> <title> Catadioptric image formation. </title> <booktitle> In Proceedings of the 1997 DARPA Image Understanding Workshop, </booktitle> <pages> pages 1431-1437, </pages> <address> New Orleans, Louisiana, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. As noted in [ Rees, 1970 ] , [ Yamazawa et al., 1995 ] , [ Nalwa, 1996 ] , and <ref> [ Nayar and Baker, 1997a ] </ref> , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection). <p> Although the parabola is not a solution of either Equa tion (11) or Equation (12) for finite values of c and k, it is a solution of Equation (11) in the limit that c ! 1, k ! 1, and c=k = h, a constant. As shown in <ref> [ Nayar and Baker, 1997a ] </ref> , this limiting case corresponds to orthographic projection.
Reference: [ Nayar and Baker, 1997b ] <author> S.K. Nayar and S. Baker. </author> <title> A theory of catadioptric image formation. </title> <type> Technical Report CUCS-015-97, </type> <institution> Department of Computer Science, Columbia University, USA, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: For an ideal thin lens, the blur region is circular and so is often referred to as the blur circle [ Hecht and Zajac, 1974 ] . As is shown in <ref> [ Nayar and Baker, 1997b ] </ref> , for a catadioptric sensor the shape of the blur region is not, in general, circular. If we know the points m 1 and l, we can find the point on the image plane where the ray of light through these points is imaged. <p> We were unable to find a closed form solution to these three equations (Equation (34) has 25 terms in general and so it is probable that none exists) but we did investigate numerical solutions. Some of the results are presented in Figure 7. (The interested reader is referred to <ref> [ Nayar and Baker, 1997b ] </ref> for a more complete presentation of the results, including an explanation of the 2 local minima in Figure 7.) For the numerical solutions we set c = 1 meter, used the hyperboloid mirror with k = 4, and assumed the radius of the lens to
Reference: [ Nayar, 1988 ] <author> S.K. Nayar. Sphereo: </author> <title> Recovering depth using a single camera and two specular spheres. </title> <booktitle> In Proceedings of SPIE: Optics, Illumination, and Image Sensing for Machine Vision II, </booktitle> <month> November </month> <year> 1988. </year>
Reference-contexts: One effective way to enhance the field of view is to use mirrors in conjunction with lenses (see, for example, [ Rees, 1970 ] , [ Charles et al., 1987 ] , <ref> [ Nayar, 1988 ] </ref> , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] ). <p> The locus of the effective viewpoint can be computed in a straightforward manner using a symbolic mathematics package, but it is a quite complex function of the distance between the center of the sphere and the pinhole. Spheres have also been used in stereo applications <ref> [ Nayar, 1988 ] </ref> , but as described before multiple viewpoints are a requirement for stereo. 2.3.4 Ellipsoidal Mirrors In Solution (12), when k &gt; 0 and c &gt; 0; we get the ellipsoidal mirror: 1 e z 2 + b 2 r 2 = 1 (16) where: a e =
Reference: [ Nayar, 1997 ] <editor> S.K. Nayar. Catadioptric omnidirectional camera. </editor> <booktitle> In Proceedings of the 1997 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 482-488, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , [ Nalwa, 1996 ] , and <ref> [ Nayar, 1997 ] </ref> ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. <p> As shown in [ Nayar and Baker, 1997a ] , this limiting case corresponds to orthographic projection. Moreover, in that setting the parabola does yield a practical omnidirectional sensor with a number of advantageous properties <ref> [ Nayar, 1997 ] </ref> . 37 straightforward to implement, but requires four of each component: i.e. four cameras and four lenses. 2.3.2 Conical Mirrors In Solution (11), if we set c = 0 and k 2, we get a conical mirror with circular cross section: z = k 2 r 2
Reference: [ Peri and Nayar, 1997 ] <author> V. Peri and S.K. Nayar. </author> <title> Generation of perspective and panoramic video from omnidirectional video. </title> <booktitle> In Proceedings of the 1997 DARPA Image Understanding Workshop, </booktitle> <address> New Orleans, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: These perspective images can subsequently be processed using the vast array of techniques developed in the field of computational vision which assume perspective projection. Moreover, if the image is to be presented to a human, as in <ref> [ Peri and Nayar, 1997 ] </ref> , it needs to be a perspective image in order to not appear distorted.
Reference: [ Rees, 1970 ] <author> D.W. Rees. </author> <title> Panoramic television viewing system. United States Patent No. </title> <address> 3,505,465, </address> <month> April </month> <year> 1970. </year>
Reference-contexts: One effective way to enhance the field of view is to use mirrors in conjunction with lenses (see, for example, <ref> [ Rees, 1970 ] </ref> , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , [ Nalwa, 1996 <p> We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. As noted in <ref> [ Rees, 1970 ] </ref> , [ Yamazawa et al., 1995 ] , [ Nalwa, 1996 ] , and [ Nayar and Baker, 1997a ] , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection).
Reference: [ Yagi and Kawato, 1990 ] <author> Y. Yagi and S. Kawato. </author> <title> Panoramic scene analysis with conic projection. </title> <booktitle> In Proceedings of the International Conference on Robots and Systems, </booktitle> <year> 1990. </year>
Reference-contexts: One effective way to enhance the field of view is to use mirrors in conjunction with lenses (see, for example, [ Rees, 1970 ] , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , <ref> [ Yagi and Kawato, 1990 ] </ref> , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Bogner, 1995 ] , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] ). <p> The cone has been used for wide-angle imaging a number of times <ref> [ Yagi and Kawato, 1990 ] </ref> [ Yagi and Yachida, 1991 ] [ Bogner, 1995 ] . In these implementations the pinhole is placed quite some distance from the apex of the cone.
Reference: [ Yagi and Yachida, 1991 ] <author> Y. Yagi and M. Yachida. </author> <title> Real-time generation of environmental map and obstacle avoidance using omnidirectional image sensor with conic mirror. </title> <booktitle> In Proceedings of the 1991 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 160-165, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The cone has been used for wide-angle imaging a number of times [ Yagi and Kawato, 1990 ] <ref> [ Yagi and Yachida, 1991 ] </ref> [ Bogner, 1995 ] . In these implementations the pinhole is placed quite some distance from the apex of the cone. It is easy to show that in such cases the viewpoint is no longer a single point [ Nalwa, 1996 ] .
Reference: [ Yamazawa et al., 1993 ] <author> K. Yamazawa, Y. Yagi, and M. Yachida. </author> <title> Omnidirectional imaging with hyperboloidal projection. </title> <booktitle> In Proceedings of the International Conference on Robots and Systems, </booktitle> <year> 1993. </year>
Reference-contexts: field of view is to use mirrors in conjunction with lenses (see, for example, [ Rees, 1970 ] , [ Charles et al., 1987 ] , [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , <ref> [ Yamazawa et al., 1993 ] </ref> , [ Bogner, 1995 ] , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation.
Reference: [ Yamazawa et al., 1995 ] <author> K. Yamazawa, Y. Yagi, and M. Yachida. </author> <title> Obstacle avoidance with omnidirectional image sensor HyperOmni Vision. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1062-1067, </pages> <month> May </month> <year> 1995. </year> <month> 42 </month>
Reference-contexts: We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. As noted in [ Rees, 1970 ] , <ref> [ Yamazawa et al., 1995 ] </ref> , [ Nalwa, 1996 ] , and [ Nayar and Baker, 1997a ] , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection).
References-found: 18

