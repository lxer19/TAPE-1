URL: ftp://ftp.eng.auburn.edu/pub/techreports/cse/97/TR-97-05.ps.gz
Refering-URL: ftp://ftp.eng.auburn.edu/pub/techreports/README.html
Root-URL: 
Author: N. Hari Narayanan Roland Hbscher 
Web: http://www.eng.auburn.edu/department/cse/research/vi3rg/vi3rg.html  
Address: Alabama 36849-5347 USA  
Affiliation: Visual Information, Intelligence Interaction Research Group Department of Computer Science Engineering Auburn University  
Date: September 30, 1997  
Pubnum: Technical Report CSE97-05  
Abstract: A revised version of this technical report appears as Chapter 3 (pp. 85-127) in K. Marriott & B. Meyer (Eds.), Visual Language Theory, Springer-Verlag Publishers, Berlin, 1997. 2 Author to whom correspondence should be addressed. Email: narayan@eng.auburn.edu VISUAL LANGUAGE THEORY: TOWARDS A HUMAN-COMPUTER INTERACTION PERSPECTIVE 1 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abelson H., Sussman G. J. & Sussman J. </author> <year> (1996). </year> <title> Structure and Interpretation of Computer Programs, 2nd ed., </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address> <note> 27 Andries, </note> <author> M., Engels, G. & Rekers, J. </author> <year> (1997). </year> <title> Using graph grammars to represent visual programs. </title> <note> Chapter in this volume. </note>
Reference: <author> Antonietti, A. </author> <year> (1991). </year> <title> Why does mental visualization facilitate problem solving? In R. </title> <editor> H. Logie & M. Denis, (Eds.), </editor> <title> Mental Images in Human Cognition, </title> <publisher> Elsevier Science Publishers B. V., </publisher> <address> Amsterdam, Netherlands, </address> <pages> pp. 211-227. </pages>
Reference: <author> Arnheim, R. </author> <year> (1969). </year> <institution> Visual Thinking, University of California Press, Berkeley, </institution> <address> CA. </address>
Reference-contexts: Thus many dimensions and taxonomies are needed to determine a languages overall effectiveness. Theories of human visual languages have existed for quite some time: visual thinking <ref> (Arnheim, 1969) </ref>, semiotics of visual languages (Saint-Martin, 1990), etc. But new types of theories are necessary for visual languages in the context of human-computer interaction. A theory of visual languages must be formal enough to derive its computational properties.
Reference: <author> Badre, A. & Allen, J. </author> <year> (1989). </year> <title> Graphic language representation and programming behavior. In S </title> . 
Reference-contexts: One usability study <ref> (Badre & Allen, 1989) </ref> appears to indicate that graphical notations do not provide an advantage for procedural languages.
Reference: <author> Salvendy & M. J. Smith, (Eds.), </author> <title> Designing and Using Human-Computer Interfaces and Knowledge Based Systems, </title> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, Netherlands, </address> <pages> pp. 59-65. </pages>
Reference: <author> Barwise, J. & Etchemendy, J. </author> <year> (1994). </year> <title> Hyperproof, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England. </address>
Reference-contexts: One of these, S VS: (O P, A D, R n n DR DV ) where every map is one-to-one, is called a consistent mapping. Consider, for example, Hyperproof <ref> (Barwise & Etchemendy, 1994) </ref> which is a mixed visual language consisting of geometric diagrams and logic sentences. It is an interactive language using which students solve logic problems assisted by the computer. Its AD is configurations of 3D geometric objects in 3-space. <p> There is no significant research yet that addresses both computational and cognitive evaluation of the same visual language. Hyperproof <ref> (Barwise & Etchemendy, 1994) </ref> is a mixed visual language system that was designed to teach logic to students. <p> Such guidance can result in a lower number of alternatives that the inference process needs to evaluate, thereby making it more efficient. Computer programs that use diagrams that humans find equally useful for guiding and controlling inferences, such as Redraw (Tessler, Iwasaki & Law, 1995) and Hyperproof <ref> (Barwise & Etchemendy, 1994) </ref>, illustrate this point. Characterizing this role of visual languages is an open problem in visual language theory. 25 VI.2 Other Issues Deriving Meaning from Multiple Pictures Many current theories specify pictures using text, such that for each meaningful visual sentence there is a corresponding propositional sentence.
Reference: <author> Barwise, J. & Etchemendy, J. </author> <year> (1995). </year> <title> Heterogeneous logic. In Diagrammatic Reasoning: Cognitive and Computational Perspectives, </title> <editor> J. Glasgow, N. H. Narayanan, </editor> & <address> B </address> . 
Reference-contexts: Two properties of visual representations make them difficult to parse and interpret. One is that they are multidimensional unlike text which can be linearly read and decomposed. The second is that visual primitives are typically token-referential unlike textual symbols which are generally type-referential <ref> (Barwise & Etchemendy, 1995) </ref>. Since visual primitives that are of the same type may not necessarily have common semantics because of token-referentiality, interpretation of such primitives is more difficult than that of type-referential primitives. This difficulty is overcome in human visual languages through the use of accepted conventions. <p> There is no significant research yet that addresses both computational and cognitive evaluation of the same visual language. Hyperproof (Barwise & Etchemendy, 1994) is a mixed visual language system that was designed to teach logic to students. While its authors have studied theoretical and computational issues <ref> (Barwise & Etchemendy, 1995) </ref>, others have looked at the cognitive effectiveness of the language - i.e., how well it helps students learn logic in comparison with traditional teaching methods.
Reference: <editor> Chandrasekaran, (Eds.), </editor> <publisher> AAAI Press, </publisher> <address> Menlo Park, </address> <publisher> CA and MIT Press, </publisher> <address> Cambridge, MA. </address> <pages> pp. 211-234. </pages>
Reference: <author> Bertin, J. </author> <year> (1967). </year> <title> Semiology of Graphics, English translation by W. </title> <institution> J. Berg, University of Wisconsin Press, Madison, WI, </institution> <year> 1983. </year>
Reference: <author> Blackwell, A. F. </author> <year> (1996). </year> <title> Metacognitive theories of visual programming: What do we think we are doing? Proc. </title> <booktitle> IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 240-246. </pages>
Reference-contexts: A research project intended to rigorously define the scientific basis for cognitive advantages of visual programming, an initial result from which is an explicit enumeration of metacognitive beliefs motivating the design of visual languages, holds considerable promise for achieving this goal <ref> (Blackwell, 1996) </ref>. There is no significant research yet that addresses both computational and cognitive evaluation of the same visual language. Hyperproof (Barwise & Etchemendy, 1994) is a mixed visual language system that was designed to teach logic to students.
Reference: <author> Bottoni, P., Costabile, M. F., Levialdi, S. & Mussio, P. </author> <year> (1995). </year> <title> Formalizing visual languages. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 45-52. </pages>
Reference: <author> Bottoni, P., Costabile, M. F., Levialdi, S. & Mussio, P. </author> <year> (1997). </year> <title> Specification of visual languages as means for interaction. </title> <note> Chapter in this volume. </note>
Reference: <author> Brooks, F. P. </author> <year> (1987). </year> <title> No silver bullet: </title> <journal> Essence and accidents of software engineering. IEEE Computer, </journal> <volume> 20(4), </volume> <pages> pp. 10-19. </pages>
Reference: <author> Brown, M. H. & Sedgewick, R. </author> <year> (1985). </year> <title> Techniques for algorithm animation. </title> <journal> IEEE Software, </journal> <volume> 2(1), </volume> <pages> pp. 28-38. </pages>
Reference-contexts: Generality of AD is an important dimension. Some visual languages are tailored to one specific AD. Weather maps used by meteorologists and circuit diagrams that electrical engineers use are examples. Algorithm animation systems such as Balsa <ref> (Brown & Sedgewick, 1985) </ref> can be used to automatically create and display a visual language that depicts the operation of a single algorithm. Others can represent a class of domains. <p> The results (Stenning, Cox & Oberlander, 1995) have been mixed in that while advanced students benefited, students with less knowledge or visual capability did not show improved learning. Researchers in software visualization in general (Price, Baecker & Small, 1993), and algorithm animation in particular <ref> (Brown & Sedgewick, 1985) </ref>, strive to create visual languages using which computers can communicate the inner workings of programs to humans. These are not visual languages that support the full cycle of interaction - instead, they are intended for one-way communication from the computational to the cognitive.
Reference: <author> Byrne, M. D., Catrambone, R. & Stasko, J. T. </author> <year> (1996). </year> <title> Do algorithm animations aid learning? Tech. </title> <type> Rep. </type> <institution> GIT-GVU-96-18, GVU Center, Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <month> August </month> <year> 1996. </year> <journal> CACM, (1996). Special section on educational technology, Communications of the ACM, </journal> <volume> 39(4), </volume> <month> April. </month>
Reference-contexts: Most visualizations that have been designed so far are special purpose languages designed for a particular algorithm or program, or a class of algorithms. Recent research on the cognitive effectiveness of such visualizations has also unearthed mixed results <ref> (Byrne, Catrambone & Stasko, 1996) </ref>. It should be noted that in all these cases the visual languages have already been designed and implemented in the computational realm before cognitive studies were undertaken. In contrast, Mahling and Fisher (1990) apply cognitive theory to design rather than evaluation of a visual language.
Reference: <author> Chang, S- K. </author> <year> (1987). </year> <title> Visual languages: A tutorial and survey. </title> <journal> IEEE Software, </journal> <volume> 4, </volume> <pages> pp. 29-39. </pages>
Reference: <author> Dinesh, T. B. & skdarli, S. </author> <year> (1997). </year> <title> Specifying input and output of visual languages. </title> <note> Chapter in this volume. </note>
Reference: <author> Douglas, S., Hundhausen, C. & McKeown, D. </author> <year> (1995). </year> <title> Toward empirically-based software visualization languages. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 342-349. </pages>
Reference-contexts: The signature morphism is a consistent mapping. While the authors propose it only for the static semantics of pictures, this approach appears suitable for dynamic semantics as well. On the other hand, Douglas et al <ref> (Douglas, et al., 1995) </ref> describe a technique called visualization storyboarding by which a mapping from the application domain of algorithms to a software visualization language can be derived empirically. 14 2.
Reference: <author> Engelhardt, Y., Bruin, J., Janssen, T. & Scha, R. </author> <year> (1996). </year> <title> The visual grammar of information graphics. </title> <editor> In N. H. Narayanan & J. Damski, (Eds.), </editor> <booktitle> Proc. AID96 Workshop on Visual Representation, Reasoning and Interaction in Design, </booktitle> <institution> Key Center for Design Computing, University of Sydney. </institution>
Reference: <author> Erwig, M. & Meyer, B. </author> <year> (1995). </year> <title> Heterogeneous visual languages: Integrating visual and textual programming. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 318-325. </pages> <note> 28 Frank, </note> <author> M. R. & Foley, J. D. </author> <year> (1994). </year> <title> A pure reasoning engine for programming by example. </title> <type> Tech. Rep. </type> <institution> GIT-GVU-94-11, GVU Center, Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <month> April </month> <year> 1994. </year>
Reference: <author> Freeman, E., Gelernter, D. & Jagannathan, S. </author> <year> (1995). </year> <title> In search of a simple visual vocabulary. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 302-309. </pages>
Reference: <author> Furnas, G. </author> <year> (1991). </year> <title> New graphical reasoning models for understanding graphical interfaces. </title> <booktitle> Proc. Human Factors in Computing Systems Conference (CHI91), </booktitle> <publisher> ACM Press, </publisher> <pages> pp. 71-78. </pages>
Reference: <author> Furnas, G. </author> <year> (1992). </year> <title> Reasoning with diagrams only. </title> <booktitle> Proc. AAAI Spring Symposium on Reasoning with Diagrammatic Representations, </booktitle> <publisher> AAAI Technical Report SS-92-02, AAAI Press, </publisher> <address> Menlo Park, CA, </address> <pages> pp. 118-123. </pages>
Reference: <author> Gero, J. S. & Yan, M. </author> <year> (1994). </year> <title> Shape emergence by symbolic reasoning. Environment and Planning B: </title> <journal> Planning and Design, </journal> <volume> 21, </volume> <pages> pp. 191-218. </pages>
Reference: <author> Glasgow, J., Narayanan, N. H. & Chandrasekaran, B. (Eds.) </author> <year> (1995). </year> <title> Diagrammatic Reasoning: Cognitive and Computational Perspectives, </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, </address> <publisher> CA and MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Glinert, E. P. </author> <year> (1990). </year> <title> Nontextual programming environments. </title> <editor> In S- K Chang (Ed.), </editor> <booktitle> Principles of Visual Programming Systems, </booktitle> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <pages> pp. 144-230. </pages>
Reference: <author> Goel, V. </author> <year> (1995). </year> <title> Sketches of Thought, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: This provides a strong argument for additional research on the dynamic syntax and semantics of visual languages. It has been observed that diagram generation and manipulation activities play an important role in creative thought processes such as architectural design <ref> (Goel, 1995) </ref>. This points to the potential utility of developing advanced knowledge-based visual languages to assist such human endeavors. Results from studies on how humans comprehend diagrammatic representations can serve to illuminate the cognitive processes.
Reference: <author> Gombrich, E. H. </author> <year> (1968). </year> <title> Art and Illusion: A Study in the Psychology of Pictorial Representations, </title> <address> Phaidon, London. </address>
Reference: <author> Gooday, J. M. & Cohn, A. G. </author> <year> (1997). </year> <title> Visual language syntax and semantics: A spatial logic approach. </title> <note> Chapter in this volume. </note>
Reference: <author> Goodman, N. </author> <year> (1976). </year> <title> Languages of Art: An Approach to a Theory of Symbols, </title> <publisher> Hackett Publishing Company, </publisher> <address> Indianapolis, Indiana. </address>
Reference-contexts: A continuous domain, on the other hand, is one in which state changes are fluid, making it difficult to distinguish discrete states and transitions. The ecosystem of a pond is an example. Such systems are semantically dense <ref> (Goodman, 1976) </ref>, and require explicit abstraction and quantization in order to be describable in terms of S and DS. Generality of AD is an important dimension. Some visual languages are tailored to one specific AD. Weather maps used by meteorologists and circuit diagrams that electrical engineers use are examples. <p> A complete treatment of various approaches can be found in (Marriott, Meyer & Wittenburg, 1997). One interesting issue to consider is the development of declarative specifications of syntactically and semantically dense <ref> (Goodman, 1976) </ref> visual languages. This requires deeming certain aspects of visual sentences as irrelevant and discarding them while explicitly describing certain others. To see this, consider developing a set of assertions to describe Mona Lisa. <p> This implies that visual sentences of the language will form a notational system rather than a much richer analog system <ref> (Goodman, 1976) </ref>. 1.4 Dynamic Syntax The dynamic syntax of a visual language specifies how visual sentences may be transformed. <p> The latter option is preferable for cognitive effectiveness because the visual language then becomes both syntactically and semantically dense <ref> (Goodman, 1976) </ref>, faithfully reflecting the continuous nature of the AD. However, this can create computational difficulties. Computational properties of such visual languages are yet to be explored. <p> Since such visual representations evolve in a continuous fashion and are syntactically and semantically dense <ref> (Goodman, 1976) </ref>, one can find many intermediate pictures between two that represent a qualitative change of state that can propositionally be asserted. For example, consider the set of pictures one can draw depicting states between over (cube,hole) and over (cube,hole) in Figure 7 above.
Reference: <author> Green, T. R. G. </author> <year> (1990). </year> <title> Cognitive dimensions of notations. </title> <booktitle> Proc. HCI90 Conference. </booktitle>
Reference: <author> Green, T. R. G. & Petre, M. </author> <year> (1992). </year> <title> When visual programs are harder to read than textual programs. </title> <editor> In G. C. van der Veer, M. J. Tauber, S. Bagnarola & M. Antavolits, (Eds.), </editor> <title> Human-Computer Interaction: Tasks and Organization, </title> <booktitle> Proc. 6th European Conference on Cognitive Ergonomics, </booktitle> <address> pp.167-180. </address>
Reference: <author> Green, T. R. G. & Petre, M. </author> <year> (1996). </year> <title> Usability analysis of visual programming environments: A cognitive dimensions framework. </title> <journal> Journal of Visual Languages and Computing, </journal> <volume> 7(2), </volume> <pages> pp. 131-174. </pages>
Reference: <author> Green, T. R. G., Petre, M. & Bellamy, R. K. E. </author> <year> (1992). </year> <title> Comprehensibility of visual and textual programs: A test of superlativism against the match-mismatch conjecture. </title> <editor> In J. Koenemann-Belliveau, T. G. Moher, S. P. Robertson (Eds.), </editor> <booktitle> Proc. Fourth Workshop on Empirical Studies of Programmers, </booktitle> <publisher> Ablex Publishers. </publisher>
Reference: <author> Gross, M. </author> <year> (1994). </year> <title> The fat pencil, the cocktail napkin, and the slide library. </title> <editor> In A. </editor> <publisher> Harfmann & M. </publisher>
Reference-contexts: Whether grammars and rewrite rules help human users understand computational processes in the interaction cycle has not yet been studied in the context of any visual language. Computer interpretation of diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin <ref> (Gross, 1994) </ref>, Beatrix (Novak & Bulko, 1993), Redraw (Tessler, Iwasaki & Law, 1995), and Anon (Joseph & Pridmore, 1992) are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors.
Reference: <editor> Fraser, (Eds.), </editor> <booktitle> Proc. ACADIA 94, Association for Computer Aided Design in Architecture, </booktitle> <address> pp.103-113. </address>
Reference: <author> Gurr, C. A. </author> <year> (1997). </year> <title> On the isomorphism (or otherwise) of representations. </title> <note> Chapter in this volume. </note>
Reference: <author> Haarslev, V. </author> <year> (1997). </year> <title> A fully formalized theory for describing visual notations. </title> <note> Chapter in this volume. </note>
Reference-contexts: Visual languages with a fine granularity of interaction are typically interpreted whereas those with a coarse granularity may be compiled. Some commercial mixed languages allow both. Researchers have addressed the issue of specifying meanings of visual sentences in such a way that the specifications are executable <ref> (Haarslev, 1997) </ref>. Whether grammars and rewrite rules help human users understand computational processes in the interaction cycle has not yet been studied in the context of any visual language. Computer interpretation of diagrams used in human visual languages remains a difficult problem as well.
Reference: <author> Hammer, E. </author> <year> (1995). </year> <title> Logic and visual information. In Studies in Logic, Language & Computation, </title> <publisher> CSLI Press, Stanford University. </publisher>
Reference: <author> Hegarty, M. </author> <year> (1992). </year> <title> Mental animation: Inferring motion from static displays of mechanical systems. </title> <journal> Journal of Experimental Psychology: Learning, Memory & Cognition, </journal> <volume> 18(5), </volume> <pages> pp. 1084-1102. </pages> <note> 29 Hegarty, </note> <author> M. & Just, M. A. </author> <year> (1993). </year> <title> Constructing mental models of machines from text and diagrams. </title> <journal> Journal of Memory and Language, </journal> <volume> 32, </volume> <pages> pp. 717-742. </pages>
Reference: <author> Hix, D. & Hartson, H. R. </author> <year> (1993). </year> <title> Developing User Interfaces: Ensuring Usability Through Product & Process, </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York. </address>
Reference: <author> Hbscher, R. </author> <year> (1995). </year> <title> Rewriting interaction. </title> <booktitle> Proc. Human Factors in Computing Systems Conference (CHI95), </booktitle> <publisher> ACM Press. </publisher>
Reference: <author> Hbscher, R. </author> <year> (1996). </year> <title> Composing complex behavior from simple visual descriptions. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 88-94. </pages>
Reference-contexts: Drawings by our cavedwelling ancestors were purely graphical. Most current human visual languages and visual programming environments use mixed notations. Bitpict (Furnas, 1991;1992) and Cartoonist <ref> (Hbscher, 1996) </ref> are visual programming languages that use purely graphical notations. There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. <p> There are four possible mappings: (1) S VS, (2) DS DVS, (3) S DVS, and (4) DS VS. (1) and (2) are commonly occurring mappings. An example is a visual language representation of a microworld consisting of moving balls and stationary walls <ref> (Hbscher, 1996) </ref> that maps balls and walls to circles and rectangles on a display, and maps the motions of balls to the corresponding motions of circles on the display.
Reference: <author> Huttenlocher, J. </author> <year> (1968). </year> <title> Constructing spatial images: A strategy in reasoning. </title> <journal> Psychological Review, </journal> <volume> 75(6), </volume> <pages> pp. 550-560. </pages>
Reference-contexts: In these kinds of problems, even when given a descriptive propositional or natural language representation people tend to draw or mentally image a corresponding visual representations in order to solve the problems <ref> (Huttenlocher, 1968) </ref>. Computational Complexity Visual representations make characteristics of the represented situation explicit, group related information spatially or by other visual cues, and facilitate inferences based on direct manipulation. In comparison, propositional representations contain considerable implicit information.
Reference: <author> Joseph, S. H. & Pridmore, T. P. </author> <year> (1992). </year> <title> Knowledge-directed interpretation of mechanical engineering drawings. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(9), </volume> <pages> pp. 928-940. </pages>
Reference-contexts: Computer interpretation of diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin (Gross, 1994), Beatrix (Novak & Bulko, 1993), Redraw (Tessler, Iwasaki & Law, 1995), and Anon <ref> (Joseph & Pridmore, 1992) </ref> are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors. <p> This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix (Novak & Bulko, 1993) and Anon <ref> (Joseph & Pridmore, 1992) </ref> employ.
Reference: <author> Kahn, K. M. & Saraswat, V. A. </author> <year> (1990). </year> <title> Complete visualizations of concurrent programs and their executions. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 7-14. </pages>
Reference-contexts: Algorithm animation systems such as Balsa (Brown & Sedgewick, 1985) can be used to automatically create and display a visual language that depicts the operation of a single algorithm. Others can represent a class of domains. Pictorial Janus <ref> (Kahn & Saraswat, 1990) </ref> and Prograph (Steinmann & Carver, 1995) are examples of visual programming languages that can represent a variety of concurrent and dataflow computations respectively.
Reference: <author> Koedinger, K. R. </author> <year> (1992). </year> <title> Emergent properties and structural constraints: Advantages of diagrammatic representations for reasoning and learning. </title> <booktitle> Proc. AAAI Spring Symposium on Reasoning with Diagrammatic Representations, </booktitle> <publisher> AAAI Technical Report SS-92-02, AAAI Press, </publisher> <address> Menlo Park, CA, </address> <pages> pp. 154-169. </pages>
Reference: <author> Larkin, J. </author> <year> (1989). </year> <title> Display based problem solving. </title> <editor> In D. Klahr & K. Kotovsky, (Eds.), </editor> <booktitle> Complex Information Processing, </booktitle> <publisher> Lawrence Erlbaum Publishers, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Larkin, J. H. & Simon, H. A. </author> <year> (1987). </year> <title> Why a diagram is (sometimes) worth ten thousand words. </title> <journal> Cognitive Science, </journal> <volume> 11, </volume> <pages> pp. 65-99. </pages>
Reference-contexts: One useful cognitive measure is comprehensibility - how easy is it for a user to understand and learn the syntax and semantics of the language. A number of factors influence comprehensibility. It has been noted that visual representations are easier to understand because they make information explicit <ref> (Larkin & Simon, 1987) </ref>. One way of achieving explicitness is through representations that are similar or analogous to the represented, and which preserve properties of the represented in an explicit way. Such representations have been called isomorphic representations. <p> Another dimension is secondary notations - the use of D and V to convey meaning. One way to accomplish this is by spatial clustering. Graphical 20 representations can spatially organize and localize relevant information together <ref> (Larkin & Simon, 1987) </ref> so that a visual search can locate information quickly. Very little research has been done on how secondary notations might improve cognitive effectiveness. <p> Thus, informationally equivalent representations can have different computational complexity depending on the operations performed on them and the nature of the underlying information processing architecture that performs the operations <ref> (Larkin & Simon, 1987) </ref>. The implication for visual language theories is that making visual languages easier for humans may in general result in making them harder for computers and vice versa. There are, however, exceptions to this.
Reference: <author> Lohse, G. I., Biolsi, K., Walker, N. & Rueler, H. H. </author> <year> (1994). </year> <title> A classification of visual representations. </title> <journal> Communications of the ACM, </journal> <volume> 37(12), </volume> <pages> pp. 36-49. </pages>
Reference-contexts: There are a variety of dimensions such as shape, geometry, color, texture, 2D and 3D locations, etc., and a variety of visual relations that can be used to carry meaning. There are a number of studies that have attempted to enumerate and classify visual representations <ref> (Lohse et al, 1994) </ref>, dimensions and relations (Bertin, 1967; Goel, 1995; Goodman, 1976). Nevertheless, a systematic categorization and the use of such a categorization to characterize and compare visual languages in terms of their visual syntax have not yet been done.
Reference: <author> Lowe, R. K. </author> <year> (1993). </year> <title> Constructing a mental representation from an abstract technical diagram. Learning and Instruction, </title> <booktitle> 3, </booktitle> <pages> pp. 157-179. </pages>
Reference-contexts: A number of findings from this research are relevant to visual languages. It has been found that parsing and semantic interpretation is not easy for humans <ref> (Lowe, 1993) </ref> and that realism facilitates semantic interpretation (Schwartz & Black, 1996). This supports the argument that isomorphism (Gurr, 1977) is an important property.
Reference: <author> Lowe, R. K. </author> <year> (1994). </year> <title> Selectivity in diagrams: Reading beyond the lines. </title> <journal> Educational Psychology, </journal> <volume> 14, </volume> <pages> pp. 467-491. </pages>
Reference-contexts: This is relevant to the type of mapping a visual language utilizes, indicating that one-to-many mappings from AD to visual sentences may not be a good idea. Prior knowledge, such as that of diagramming conventions, has been found to be critical to correct interpretation <ref> (Lowe, 1994) </ref>, and visual primitives help cue and retrieve relevant prior knowledge from long term memory (Narayanan, Suwa & Motoda, 1994b). This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix (Novak & Bulko, 1993) and Anon (Joseph & Pridmore, 1992) employ.
Reference: <author> Mahling, D. E. & Fisher, D. L. </author> <year> (1990). </year> <booktitle> The cognitive engineering of visual languages. Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 22-28. </pages>
Reference: <author> Marriott, K. & Meyer, B. </author> <year> (1997). </year> <title> Towards a hierarchy of visual languages. </title> <note> Chapter in this volume. </note>
Reference-contexts: Gooday and Cohn (1997) show how spatial logic can be used to describe syntax and procedural semantics of a visual language without having to first translate the visual language into a textual one before specifications can be written. A complete treatment of various approaches can be found in <ref> (Marriott, Meyer & Wittenburg, 1997) </ref>. One interesting issue to consider is the development of declarative specifications of syntactically and semantically dense (Goodman, 1976) visual languages. This requires deeming certain aspects of visual sentences as irrelevant and discarding them while explicitly describing certain others. <p> Other obstacles to efficient parsing and interpretation of general purpose visual representations are detecting emergent 3 objects (Koedinger, 1992; Gero & Yan, 1994), context sensitivity of their interpretations (Figure 6 provides an example), ambiguity, and semantic density (see 3.2 below). Another chapter in this volume <ref> (Marriott, Meyer & Wittenburg, 1997) </ref> provides more information on visual language parsing. 3 Emergence is a term used to describe the perception of objects that a visual sentence does not explicitly represent.
Reference: <author> Marriott, K. Meyer, B. & Wittenburg, K. </author> <year> (1997). </year> <title> A survey of visual language specification and recognition. </title> <note> Chapter in this volume. </note>
Reference-contexts: Gooday and Cohn (1997) show how spatial logic can be used to describe syntax and procedural semantics of a visual language without having to first translate the visual language into a textual one before specifications can be written. A complete treatment of various approaches can be found in <ref> (Marriott, Meyer & Wittenburg, 1997) </ref>. One interesting issue to consider is the development of declarative specifications of syntactically and semantically dense (Goodman, 1976) visual languages. This requires deeming certain aspects of visual sentences as irrelevant and discarding them while explicitly describing certain others. <p> Other obstacles to efficient parsing and interpretation of general purpose visual representations are detecting emergent 3 objects (Koedinger, 1992; Gero & Yan, 1994), context sensitivity of their interpretations (Figure 6 provides an example), ambiguity, and semantic density (see 3.2 below). Another chapter in this volume <ref> (Marriott, Meyer & Wittenburg, 1997) </ref> provides more information on visual language parsing. 3 Emergence is a term used to describe the perception of objects that a visual sentence does not explicitly represent.
Reference: <author> Menzies, T. </author> <year> (1995). </year> <title> Frameworks for Assessing Visual Languages. </title> <type> Technical Report TR95-35, </type> <institution> Department of Software Development, Monash University. </institution>
Reference: <author> Meyer, B. </author> <year> (1993). </year> <title> Pictures depicting pictures: On the specification of visual languages by visual grammars. </title> <type> Technical Report No. 139, </type> <institution> Informatik Berichte, FernUniversitat, Hagen, Germany. </institution> <note> (A shorter version appears in Proc. 1992 IEEE Symposium on Visual Languages, IEEE Computer Society Press, pp. 41-47.) </note> <author> McCorduck, P. </author> <year> (1991). </year> <title> Aaron's Code, </title> <publisher> Freeman, </publisher> <address> San Francisco, CA. </address>
Reference: <author> Myers, B. </author> <year> (1986). </year> <title> Visual programming, programming by example and program visualization: A taxonomy. </title> <booktitle> Proc. Human Factors in Computing Systems Conference (CHI86), </booktitle> <publisher> ACM Press, </publisher> <pages> pp. 59-66. </pages>
Reference: <author> Narayanan, N. H. (Ed.) </author> <year> (1992). </year> <booktitle> Proc. AAAI Spring Symposium on Reasoning with Diagrammatic Representations, </booktitle> <publisher> AAAI Technical Report SS-92-02, AAAI Press, </publisher> <address> Menlo Park, CA. </address> <note> 30 Narayanan, </note> <author> N. H. & Hegarty, M. </author> <title> (in press). On designing comprehensible interactive hypermedia manuals. </title> <journal> International Journal of Human-Computer Studies. </journal>
Reference: <author> Narayanan, N. H., Suwa, M. & Motoda, H. </author> <year> (1994a). </year> <title> How things appear to work: Predicting behaviors from device diagrams. </title> <booktitle> Proc. 12th National Conference on Artificial Intelligence, </booktitle> <publisher> AAAI Press, </publisher> <pages> pp. 1161-1167. </pages>
Reference: <author> Narayanan, N. H., Suwa, M. & Motoda, H. </author> <year> (1994b). </year> <title> A study of diagrammatic reasoning from verbal and gestural protocols. </title> <booktitle> Proc. 16th Annual Conference of the Cognitive Science Society, </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <pages> pp. 652-657. </pages>
Reference-contexts: Prior knowledge, such as that of diagramming conventions, has been found to be critical to correct interpretation (Lowe, 1994), and visual primitives help cue and retrieve relevant prior knowledge from long term memory <ref> (Narayanan, Suwa & Motoda, 1994b) </ref>. This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix (Novak & Bulko, 1993) and Anon (Joseph & Pridmore, 1992) employ.
Reference: <author> Narayanan, N. H., Suwa, M. & Motoda, H. </author> <year> (1995a). </year> <title> Diagram-based problem solving: The case of an impossible problem. </title> <booktitle> Proc. 17th Annual Conference of the Cognitive Science Society, </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <pages> pp. 206-211. </pages>
Reference: <author> Narayanan, N. H., Suwa, M. & Motoda, H. </author> <year> (1995b). </year> <title> Behavior hypothesis from schematic diagrams. </title> <booktitle> In Diagrammatic Reasoning: Cognitive and Computational Perspectives, </booktitle> <address> J </address> . 
Reference-contexts: It has been found that people employ mental visualization (Antonietti, 1991; 17 Hegarty, 1992; Narayanan, Suwa & Motoda, 1994b) to make inferences when static pictures are used to represent dynamic ADs, and that this process creates a mismatch between the external and internal representations resulting in increased cognitive load <ref> (Narayanan, Suwa & Motoda, 1995b) </ref>. This provides a strong argument for additional research on the dynamic syntax and semantics of visual languages. It has been observed that diagram generation and manipulation activities play an important role in creative thought processes such as architectural design (Goel, 1995).
Reference: <author> Glasgow, N. H. Narayanan, & B. </author> <title> Chandrasekaran, </title> <editor> (Eds.) </editor> <publisher> AAAI Press and MIT Press, </publisher> <pages> pp. </pages> <address> 501 -534. </address>
Reference: <author> Newell, A. & Simon, H. A. </author> <year> (1972). </year> <title> Human Problem Solving, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: Rewrite rules (Repenning, 1995) allow computers to transform existing visual sentences to represent some dynamic process. Rewrite rules are similar in nature to operators that allow a computation to move from one valid state to another in a problem space <ref> (Newell & Simon, 1972) </ref>. Visual languages with a fine granularity of interaction are typically interpreted whereas those with a coarse granularity may be compiled. Some commercial mixed languages allow both.
Reference: <author> Newman, W. M. & Lamming, M. G. </author> <year> (1995). </year> <title> Interactive System Design, </title> <publisher> Addison-Wesley, </publisher> <address> Wokingham, England. </address>
Reference: <author> Nickerson, J. V. </author> <year> (1994). </year> <title> Visual programming: Limits of graphic representation. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 178-179. </pages>
Reference-contexts: Application of these metrics to current visual programming languages does not paint an optimistic future for the use of fully general, fully diagrammatic visual programming languages due to their low density <ref> (Nickerson, 1994) </ref>. 19 Unfortunately this line of research, judging by the literature, appears not to have been pursued further. One useful cognitive measure is comprehensibility - how easy is it for a user to understand and learn the syntax and semantics of the language. A number of factors influence comprehensibility.
Reference: <author> Norman, D. A. </author> <year> (1986). </year> <title> Cognitive engineering. </title> <editor> In D. A. Norman & S. W. Draper, (Eds.), </editor> <title> User Centered System Design, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <pages> pp. 31-65. </pages>
Reference: <author> Norman, D. A. </author> <year> (1988). </year> <title> The Psychology of Everyday Things, </title> <publisher> Basic Books, </publisher> <address> New York. </address>
Reference-contexts: Thus, even an informationally equivalent propositional representation may not explicitly represent the same properties as the corresponding picture. It does not, of course, mean that all visual representations are good at explicating information they carry. 4 Affordance is a term that Norman introduced <ref> (Norman, 1988) </ref>. He defines it as the perceived and actual fundamental properties of something that allow a perceiver to determine just how it could possibly be used. In this sense, visual representations afford certain kinds of interpretations and inferences. 22 This requires careful design of representations.
Reference: <author> Novak, G. S. & Bulko, W. C. </author> <year> (1993). </year> <title> Diagrams and text as computer input. </title> <journal> Journal of Visual Languages and Computing, </journal> <volume> 4, </volume> <pages> pp. 161-175. </pages>
Reference-contexts: Whether grammars and rewrite rules help human users understand computational processes in the interaction cycle has not yet been studied in the context of any visual language. Computer interpretation of diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin (Gross, 1994), Beatrix <ref> (Novak & Bulko, 1993) </ref>, Redraw (Tessler, Iwasaki & Law, 1995), and Anon (Joseph & Pridmore, 1992) are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors. <p> These systems illustrate the difficulty of interpreting even highly stylized visual representations used in their respective ADs. When visual representations use a mixed vocabulary of diagrams and text, there is an additional source of difficulty - that of resolving coreferences <ref> (Novak & Bulko, 1993) </ref>. <p> multiple elements of the visual sentence have the same referent, as in the case of a mixed visual sentence consisting of text and picture in which many words and graphical units refer to same things, and constructing a unified model of information from text and diagrams is difficult both computationally <ref> (Novak & Bulko, 1993) </ref> and cognitively (Hegarty & Just, 1993). This is relevant to the type of mapping a visual language utilizes, indicating that one-to-many mappings from AD to visual sentences may not be a good idea. <p> This supports the use of knowledge intensive parsing and interpretation techniques that systems like Beatrix <ref> (Novak & Bulko, 1993) </ref> and Anon (Joseph & Pridmore, 1992) employ.
Reference: <author> Petre, M. </author> <year> (1995). </year> <title> Why looking isn't always seeing: Readership skills and graphical programming. </title> <journal> Communications of the ACM, </journal> <volume> 38, </volume> <pages> pp. 33-44. </pages>
Reference: <author> Petre, M., Blackwell, A. F. & Green, T. R. G. </author> <title> (in press). Cognitive questions in software visualization. </title> <editor> In J. Stasko, J. Domingue, B. Price & M. Brown, (Eds.), </editor> <title> Software Visualization: Programming as a MultiMedia Experience, </title> <publisher> MIT Press, to appear. </publisher>
Reference: <author> Price, B. A., Baecker, R. M. & Small, I. S. </author> <year> (1993). </year> <title> A principled taxonomy of software visualization. </title> <journal> Journal of Visual Languages and Computing, </journal> <volume> 4(3), </volume> <pages> pp. 211-266. </pages>
Reference-contexts: The results (Stenning, Cox & Oberlander, 1995) have been mixed in that while advanced students benefited, students with less knowledge or visual capability did not show improved learning. Researchers in software visualization in general <ref> (Price, Baecker & Small, 1993) </ref>, and algorithm animation in particular (Brown & Sedgewick, 1985), strive to create visual languages using which computers can communicate the inner workings of programs to humans.
Reference: <author> Puigsegur, J., Agusti, J. & Robertson, D. </author> <year> (1996). </year> <title> A visual programming language. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 214-215. </pages>
Reference: <author> Raymond, D. R. </author> <year> (1991). </year> <title> Characterizing visual languages. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 176-182. </pages>
Reference-contexts: Animations are examples of the latter. The former is suitable when the visual language is notational and the latter is suitable when the visual language is analog <ref> (Raymond, 1991) </ref>, and the corresponding AD is continuous. In practice, animations are employed even when the corresponding AD is not continuous (e.g., algorithm animations), but whether this contributes to 12 cognitive effectiveness or is merely an irrelevant and potentially distracting feature is yet to be determined. <p> Another interesting possibility is to examine computational implications of Goodmans (1976) notions of syntactic and semantic differentiation and density, and the corresponding notions of notational and analog systems <ref> (see Raymond, 1991 for definitions) </ref> for visual languages. 3.2 Cognitive Evaluation Conducting a cognitive evaluation requires experimental research with human participants, which is outside the scope of visual language theory. However, theorists can contribute by identifying relevant cognitive measures to characterize individual languages or to comparatively analyze multiple ones. <p> However, theorists can contribute by identifying relevant cognitive measures to characterize individual languages or to comparatively analyze multiple ones. Excellent beginnings along these lines are presented in <ref> (Raymond, 1991) </ref> and Nickerson (1994). Both authors come to similar conclusions regarding the kind of visual language that is likely to be most effective: The visual character of languages is rooted in their ability to use dense representations to describe dense domains (Raymond, 1991). <p> Excellent beginnings along these lines are presented in <ref> (Raymond, 1991) </ref> and Nickerson (1994). Both authors come to similar conclusions regarding the kind of visual language that is likely to be most effective: The visual character of languages is rooted in their ability to use dense representations to describe dense domains (Raymond, 1991).
Reference: <author> Repenning, A. </author> <year> (1995). </year> <title> Bending the rules: Steps toward semantically enriched graphical rewrite rules. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 226-233. </pages>
Reference-contexts: In practice, animations are employed even when the corresponding AD is not continuous (e.g., algorithm animations), but whether this contributes to 12 cognitive effectiveness or is merely an irrelevant and potentially distracting feature is yet to be determined. Rewrite rules that systems like Agentsheets <ref> (Repenning & Sumner, 1995) </ref> and Bitpict (Furnas, 1991; 1992) utilize are examples of dynamic syntax specifications. <p> Such grammars are useful for implementing interpreters or compilers for visual languages. But grammars are not useful for transforming one valid visual sentence to another in order to capture AD dynamics. Rewrite rules <ref> (Repenning, 1995) </ref> allow computers to transform existing visual sentences to represent some dynamic process. Rewrite rules are similar in nature to operators that allow a computation to move from one valid state to another in a problem space (Newell & Simon, 1972).
Reference: <author> Repenning, A. & Sumner, T. </author> <year> (1995). </year> <title> Agentsheets: A medium for creating domain-oriented visual languages. </title> <journal> IEEE Computer, </journal> <volume> 28, </volume> <pages> pp. 17-25. </pages>
Reference-contexts: In practice, animations are employed even when the corresponding AD is not continuous (e.g., algorithm animations), but whether this contributes to 12 cognitive effectiveness or is merely an irrelevant and potentially distracting feature is yet to be determined. Rewrite rules that systems like Agentsheets <ref> (Repenning & Sumner, 1995) </ref> and Bitpict (Furnas, 1991; 1992) utilize are examples of dynamic syntax specifications. <p> Such grammars are useful for implementing interpreters or compilers for visual languages. But grammars are not useful for transforming one valid visual sentence to another in order to capture AD dynamics. Rewrite rules <ref> (Repenning, 1995) </ref> allow computers to transform existing visual sentences to represent some dynamic process. Rewrite rules are similar in nature to operators that allow a computation to move from one valid state to another in a problem space (Newell & Simon, 1972).
Reference: <author> Resnick, M. </author> <year> (1996). </year> <title> Beyond the centralized mindset. </title> <journal> Journal of the Learning Sciences, </journal> <volume> 5(1), </volume> <pages> pp. 1-22. </pages>
Reference-contexts: The Alternate Reality Kit (Smith, 1986), which is an environment for users to create and experiment with the dynamics of moving particles, is an early example. KidSim (Smith, Cypher & Spohrer, 1994) and Star Logo <ref> (Resnick, 1996) </ref> are currently popular mixed visual languages using which one can build simulations of microworlds and processes occurring inside them. The computer then executes the simulations and depicts results graphically through interactive animations of the microworlds using pictures created by the user.
Reference: <author> Robertson, G. G., Card, S. K. & Mackinlay, J. D. </author> <year> (1993). </year> <title> Information visualization using 3D interactive animation. </title> <journal> Communications of the ACM, </journal> <volume> 36(4), </volume> <pages> pp. 57-71. </pages>
Reference: <author> Saint-Martin, F. </author> <year> (1990). </year> <title> Semiotics of Visual Language, </title> <publisher> Indiana University Press, </publisher> <address> Bloomington, </address> <note> IN. 31 Schwartz, </note> <author> D. L. & Black, J. B. </author> <year> (1996). </year> <title> Analog imagery in mental model reasoning: Depictive models. </title> <journal> Cognitive Psychology, </journal> <volume> 30, </volume> <pages> pp. 154-219. </pages>
Reference: <author> Selker, T. & Koved, L. </author> <year> (1988). </year> <title> Elements of visual language. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 38-44. </pages>
Reference: <author> Shepard, R. N. & Cooper, L. A. (Eds.) </author> <year> (1986). </year> <title> Mental Images and Their Transformations, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Shin, S-J. </author> <year> (1994). </year> <title> The Logical Status of Diagrams, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England. </address>
Reference: <author> Shu, N. C. </author> <year> (1986). </year> <title> Visual programming languages: A perspective and a dimensional analysis. </title> <editor> In S. K. Chang, T. Ichikawa & P. A. Ligomenides (Eds.), </editor> <booktitle> Visual Languages, </booktitle> <publisher> Plenum Publishing Corporation, </publisher> <address> New York, </address> <pages> pp. 11-34. </pages>
Reference: <author> Sinha, A. & Vessey, I. </author> <year> (1992). </year> <title> Cognitive fit in recursion and iteration: An empirical study. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> SE-10(5), </volume> <pages> pp. 386-379. </pages>
Reference-contexts: One usability study (Badre & Allen, 1989) appears to indicate that graphical notations do not provide an advantage for procedural languages. Cognitive fit <ref> (Sinha & Vessey, 1992) </ref>, or the match between the forms of information users seek in the context of a problem solving task or application domain and the forms in which the visual language presents information (Petre, Blackwell & Green, in press), is another factor affecting the usability of visual languages.
Reference: <author> Smith, D. C., Cypher, A. & Spohrer, J. </author> <year> (1994). </year> <title> Kidsim: Programming agents without a programming language. </title> <journal> Communications of the ACM, </journal> <volume> 37, </volume> <pages> pp. 54-68. </pages>
Reference-contexts: The Alternate Reality Kit (Smith, 1986), which is an environment for users to create and experiment with the dynamics of moving particles, is an early example. KidSim <ref> (Smith, Cypher & Spohrer, 1994) </ref> and Star Logo (Resnick, 1996) are currently popular mixed visual languages using which one can build simulations of microworlds and processes occurring inside them.
Reference: <author> Smith, R. B. </author> <year> (1986). </year> <title> The alternate reality kit: An animated environment for creating interactive simulations. </title> <booktitle> Proc. IEEE Symposium on Visual Languages, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <pages> pp. 99-106. </pages>
Reference-contexts: The Alternate Reality Kit <ref> (Smith, 1986) </ref>, which is an environment for users to create and experiment with the dynamics of moving particles, is an early example.
Reference: <author> Steinman, S. & Carver, K. </author> <year> (1995). </year> <title> Visual programming with Prograph CPX, </title> <publisher> Manning Publications/Prentice Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: Algorithm animation systems such as Balsa (Brown & Sedgewick, 1985) can be used to automatically create and display a visual language that depicts the operation of a single algorithm. Others can represent a class of domains. Pictorial Janus (Kahn & Saraswat, 1990) and Prograph <ref> (Steinmann & Carver, 1995) </ref> are examples of visual programming languages that can represent a variety of concurrent and dataflow computations respectively.
Reference: <author> Stenning, K., Cox, R. & Oberlander, J. </author> <year> (1995). </year> <title> Contrasting the cognitive effects of graphical and sentential logic teaching: Reasoning, representation and individual differences. </title> <booktitle> Language and Cognitive Processes, </booktitle> <volume> 10(3/4), </volume> <pages> pp. 333-354. </pages>
Reference-contexts: While its authors have studied theoretical and computational issues (Barwise & Etchemendy, 1995), others have looked at the cognitive effectiveness of the language - i.e., how well it helps students learn logic in comparison with traditional teaching methods. The results <ref> (Stenning, Cox & Oberlander, 1995) </ref> have been mixed in that while advanced students benefited, students with less knowledge or visual capability did not show improved learning.
Reference: <author> Stenning, K. & Oberlander, J. </author> <year> (1995). </year> <title> A cognitive theory of graphical and linguistic reasoning: Logic and implementation. </title> <journal> Cognitive Science, </journal> <volume> 19, </volume> <pages> pp. 97-140. </pages>
Reference-contexts: While its authors have studied theoretical and computational issues (Barwise & Etchemendy, 1995), others have looked at the cognitive effectiveness of the language - i.e., how well it helps students learn logic in comparison with traditional teaching methods. The results <ref> (Stenning, Cox & Oberlander, 1995) </ref> have been mixed in that while advanced students benefited, students with less knowledge or visual capability did not show improved learning.
Reference: <author> Tessler, S., Iwasaki, Y. & Law, K. </author> <year> (1995). </year> <title> Qualitative structural analysis using diagrammatic reasoning. </title> <booktitle> In Diagrammatic Reasoning: Cognitive and Computational Perspectives, </booktitle> <address> J </address> . 
Reference-contexts: Computer interpretation of diagrams used in human visual languages remains a difficult problem as well. Electronic Cocktail Napkin (Gross, 1994), Beatrix (Novak & Bulko, 1993), Redraw <ref> (Tessler, Iwasaki & Law, 1995) </ref>, and Anon (Joseph & Pridmore, 1992) are examples of computer programs that use artificial intelligence techniques to understand diagrams commonly employed in human endeavors. <p> Such guidance can result in a lower number of alternatives that the inference process needs to evaluate, thereby making it more efficient. Computer programs that use diagrams that humans find equally useful for guiding and controlling inferences, such as Redraw <ref> (Tessler, Iwasaki & Law, 1995) </ref> and Hyperproof (Barwise & Etchemendy, 1994), illustrate this point.
Reference: <author> Glasgow, N. H. Narayanan, & B. </author> <title> Chandrasekaran, </title> <editor> (Eds.), </editor> <publisher> AAAI Press and MIT Press, </publisher> <pages> pp. 711-730. </pages>
Reference: <author> Tufte, E. R. </author> <year> (1983). </year> <title> The Visual Display of Quantitative Information, </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT. </address>
Reference: <author> Tufte, E. R. </author> <year> (1990). </year> <title> Envisioning Information, </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT. </address>
Reference: <author> Tufte, E. R. </author> <year> (1997). </year> <title> Visual Explanations, </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT. </address>
Reference: <author> Tversky, B. </author> <year> (1995). </year> <title> Cognitive origins of graphic productions. </title> <editor> In F. T. Marchese (Ed.), </editor> <title> Understanding Images: Finding Meaning in Digital Imagery, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <pages> pp. 29-53. </pages>
Reference: <author> Wang, D. & Lee, J. R. & Zeevat, H. </author> <year> (1995). </year> <title> Reasoning with diagrammatic representations. In Diagrammatic Reasoning: Cognitive and Computational Perspectives, </title> <editor> J. Glasgow, N. </editor> <publisher> H </publisher> . 
Reference-contexts: In this sense, visual representations afford certain kinds of interpretations and inferences. 22 This requires careful design of representations. One informal yardstick to apply might be guessability of the signature morphism <ref> (Wang, Lee & Zeevat, 1995) </ref> of the visual representation. Consider the configuration of disks in Figure 6, which can easily be described in propositional form using their absolute coordinates.
Reference: <editor> Narayanan, & B. Chandrasekaran, (Eds.), </editor> <publisher> AAAI Press and MIT Press, </publisher> <pages> pp. 339-396. </pages>
Reference: <author> Wang, D. & Zeevat, H. </author> <year> (1997). </year> <title> A syntax directed approach to picture semantics. </title> <note> Chapter in this volume. </note>
Reference: <author> Wittenburg, K. & Weitzman, L. </author> <year> (1997). </year> <title> Relational grammars: Theory and practice in a visual language interface for process modeling. </title> <note> Chapter in this volume. </note>
Reference-contexts: Gooday and Cohn (1997) show how spatial logic can be used to describe syntax and procedural semantics of a visual language without having to first translate the visual language into a textual one before specifications can be written. A complete treatment of various approaches can be found in <ref> (Marriott, Meyer & Wittenburg, 1997) </ref>. One interesting issue to consider is the development of declarative specifications of syntactically and semantically dense (Goodman, 1976) visual languages. This requires deeming certain aspects of visual sentences as irrelevant and discarding them while explicitly describing certain others. <p> Software visualization systems such as algorithm animators, on the other hand, require users to use textual means for specifying visualizations, the result of executing which is a visual language that depicts program execution for the benefit of the user. Other visual languages such as ShowBiz <ref> (Wittenburg & Weitzman, 1997) </ref> or those used in virtual reality systems are designed for two-way communication. <p> Other obstacles to efficient parsing and interpretation of general purpose visual representations are detecting emergent 3 objects (Koedinger, 1992; Gero & Yan, 1994), context sensitivity of their interpretations (Figure 6 provides an example), ambiguity, and semantic density (see 3.2 below). Another chapter in this volume <ref> (Marriott, Meyer & Wittenburg, 1997) </ref> provides more information on visual language parsing. 3 Emergence is a term used to describe the perception of objects that a visual sentence does not explicitly represent.
References-found: 100

