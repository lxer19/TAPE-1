URL: http://http.cs.berkeley.edu/~alok/acad/bench.ps
Refering-URL: http://http.cs.berkeley.edu/~alok/acad/cs252_project.html
Root-URL: http://www.cs.berkeley.edu
Email: alok@cs.berkeley.edu  
Title: Benchmarking for Graphics Applications  
Author: Alok Mittal 
Date: December 11, 1995  
Abstract: The benchmarks extensively in use today to assess the CPU performance are based on integer and floating point applications (Spec92 benchmarks). However, lately, there has been a growing emphasis on graphics and multimedia applications and this calls for developing a new set of benchmarks to assess system performance on these kinds of applications. We have benchmarked some of these applications and tried to see if the performance of various systems on these benchmarks concur with that on Spec92 programs. Our study highlights the fact that performance questions can only be answered on a per-application basis, and the general performance figures quoted are often misleading when one tries to extrapolate them to other applications. We present GRAPHmarks a measure of non real time graphics capability of a system, and point out the need for separate real time graphics benchmarks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> SPEC Benchmark Suite Release 1.0, </institution> <month> October 2, </month> <year> 1989. </year>
Reference: [2] <institution> SPEC Newsletter, </institution> <month> June, </month> <year> 1994. </year>
Reference: [3] <editor> Anon, Et Al., </editor> <title> "A Measure of Transaction Processing Power," </title> <journal> Datamation, </journal> <month> April 1, </month> <year> 1985. </year> <note> [4] xstones Benchmark, http://hpux.csc.liv.ac.uk/hpux/X11/Graphics/xstones-1.0.html </note>
Reference: [5] <author> GPC Benchmark, </author> <note> http://sunsite.unc.edu/gpc/gpc.html 24 </note>
Reference: [6] <author> Chen, P. M., Patterson, D. A., </author> <title> "A New Approach to I/O Performance Evaluation Self--scaling I/O Benchmarks, Predicted I/O Performance," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12:4, </volume> <month> November </month> <year> 1994. </year>
Reference: [7] <institution> Project Homepage, </institution> <address> http://http.cs.berkeley.edu/~alok/acad/cs252 project.html </address>
Reference-contexts: With Lensd, the effect of discarding the events in the middle of a motion sequence has a major effect on end-user performance. To examine this effect, another driver program (available on <ref> [7] </ref>) was written for Lensd. This driver sent events at constant time intervals, rather than waiting for events to be processed. The events sent simulated a user dragging the mouse at 200 pixels per second.
Reference: [8] <editor> XV Homepage, </editor> <address> http://www.sun.com/sunsoft/catlink/xv/xv.html </address>
Reference: [9] <institution> XV Source, ftp://ftp.cis.upenn.edu/pub/xv/ </institution>
Reference-contexts: It supports the viewing of images, adjustments in image size and shape, simple editing of images and a large range of algorithms that manipulate the images in some way. As a very widely used program, and because it is distributed in source form (ver 3.10a <ref> [9] </ref>), XV is ideal as a benchmark for image manipulation. We choose a medium sized photographic image and instruct XV to perform a 5 sequence of operations typical of those carried out by users. The operation sequence starts by loading the image abq-statue.jpg which includes decompressing the image.
Reference: [10] <institution> MPEG Berkeley Homepage, </institution> <note> http://www-plateau.cs.berkeley.edu/mpeg/index.html </note>
Reference: [11] <institution> MPEG Play Source, ftp://mm-ftp.cs/pub/multimedia/mpeg/play/ </institution>
Reference-contexts: MPEG-Play is available in source form from the Berkeley multimedia distribution (ver 2.3 <ref> [11] </ref>). We have chosen two images already encoded into MPEG files for playback as our benchmark. One of these is a computer generated sequence, while the other is a real-life scene.
Reference: [12] <institution> MPEG Encode Source, ftp://mm-ftp.cs/pub/multimedia/mpeg/encode/ </institution>
Reference-contexts: Also, people using these two packages might be two very different communities. While MPEG decoding is used by practically everyone on the Internet, encoding performance would interest only those who actually make videos available for distribution. MPEG-Encode is available in source form from the Berkeley multimedia distribution (ver 1.5b <ref> [12] </ref>). 7 We have chosen a sequence of images available at the Berkeley multimedia distribution. Thus it is a representative example of what people use in practice. The input consists of 150 frames of size 352x240. The output file is 875 KB and it represents a real-life scene.
Reference: [13] <editor> Rayshade Homepage, </editor> <address> http://www-graphics.stanford.edu/ cek/rayshade/ </address>
Reference: [14] <author> Rayshade Source, </author> <month> ftp://graphics.stanford.edu/pub/rayshade/ </month>
Reference-contexts: We ran the benchmark in realquiet mode to suppress printing on stdout to the extent possible, because this is not required for the purpose of benchmarking. 3.2.4 Rayshade Benchmark Rayshade ([13]) is a freely available (ver 4.0 <ref> [14] </ref>) raytracing program. It takes as input a description of the geometry and surface properties of objects in a world, and produces an image of the world rendered from a specified viewpoint.
Reference: [15] <author> Lensd Source, </author> <note> http://http.cs.berkeley.edu/~schenney/cs252/lensd.tar.gz </note>
Reference: [16] <editor> Quantify Homepage, </editor> <address> http://www.pure.com/ </address>
Reference: [17] <institution> Sparc 10/40 Spec92 Source, </institution> <address> http://performance.netlib.org/performance/html/ PDSsearch.html </address>
Reference-contexts: Lensd) Sparc 10 1.00 1.00 1.00 1.00 1.00 1.00 HP 715/80 1.68 1.16 0.91 1.38 1.18 1.25 SGI Indy 2.48 1.12 1.41 1.26 87.73 1.49 SGI Indigo 2 2.80 1.47 1.61 1.74 117.72 1.84 Machine Specint92 Specfp92 Specint92 Specfp92 Source normalized normalized Sparc 10/40 50.2 60.2 1.00 1.00 <ref> [17] </ref> HP 715/80 99.0 121.8 1.97 2.02 [18] SGI Indy 113.5 73.7 2.26 1.22 [19] SGI Indigo 2 140.0 131.0 2.79 2.18 [20] large difference in the relative performance on different benchmarks. None of these could have been predicted accurately on the basis of Spec92 ratings.
Reference: [18] <institution> HP 715/80 Spec92 Source, </institution> <note> http://www.dmo.hp.com/wsg/products/715ds.html </note>
Reference-contexts: 1.00 1.00 1.00 1.00 HP 715/80 1.68 1.16 0.91 1.38 1.18 1.25 SGI Indy 2.48 1.12 1.41 1.26 87.73 1.49 SGI Indigo 2 2.80 1.47 1.61 1.74 117.72 1.84 Machine Specint92 Specfp92 Specint92 Specfp92 Source normalized normalized Sparc 10/40 50.2 60.2 1.00 1.00 [17] HP 715/80 99.0 121.8 1.97 2.02 <ref> [18] </ref> SGI Indy 113.5 73.7 2.26 1.22 [19] SGI Indigo 2 140.0 131.0 2.79 2.18 [20] large difference in the relative performance on different benchmarks. None of these could have been predicted accurately on the basis of Spec92 ratings.
Reference: [19] <institution> SGI Indy Spec92 Source, </institution> <note> http://www.sgi.com/Products/Indy/Indy perf charts-TS.html </note>
Reference-contexts: 1.16 0.91 1.38 1.18 1.25 SGI Indy 2.48 1.12 1.41 1.26 87.73 1.49 SGI Indigo 2 2.80 1.47 1.61 1.74 117.72 1.84 Machine Specint92 Specfp92 Specint92 Specfp92 Source normalized normalized Sparc 10/40 50.2 60.2 1.00 1.00 [17] HP 715/80 99.0 121.8 1.97 2.02 [18] SGI Indy 113.5 73.7 2.26 1.22 <ref> [19] </ref> SGI Indigo 2 140.0 131.0 2.79 2.18 [20] large difference in the relative performance on different benchmarks. None of these could have been predicted accurately on the basis of Spec92 ratings.
Reference: [20] <institution> SGI Indigo 2 Spec92 Source, </institution> <address> http://www.sgi.com/Products/Indigo2/IMPACT/Products/ ind2specs.html </address>
Reference-contexts: 1.12 1.41 1.26 87.73 1.49 SGI Indigo 2 2.80 1.47 1.61 1.74 117.72 1.84 Machine Specint92 Specfp92 Specint92 Specfp92 Source normalized normalized Sparc 10/40 50.2 60.2 1.00 1.00 [17] HP 715/80 99.0 121.8 1.97 2.02 [18] SGI Indy 113.5 73.7 2.26 1.22 [19] SGI Indigo 2 140.0 131.0 2.79 2.18 <ref> [20] </ref> large difference in the relative performance on different benchmarks. None of these could have been predicted accurately on the basis of Spec92 ratings.
Reference: [21] <author> XMark93, </author> <note> http://sunsite.unc.edu/gpc/xmark93 article.html </note>
Reference: [22] <editor> Shade Tutorial, </editor> <address> http://po.eecs.berkeley.edu/ cs252/tools.ps </address>
Reference: [23] <author> Hennessy, J. L., Patterson, D. A., </author> <title> "Computer Architecture A Quantitative Approach, </title> <publisher> Second Edition" Morgan Kaufmann, </publisher> <year> 1995. </year> <note> 25 Appendices </note>
Reference-contexts: The results of MPEG-Play, MPEG-Encode and Rayshade have been analyzed by studying the dynamic instruction mixes obtained using ifreq which is a Shade ([22]) tool. The Spec92 ratings reported were not measured but were taken from online sources. The instruction mix for Spec92 programs was taken from <ref> [23] </ref>. All the timing results and Spec92 ratings were normalized with respect to Sun.
References-found: 22

