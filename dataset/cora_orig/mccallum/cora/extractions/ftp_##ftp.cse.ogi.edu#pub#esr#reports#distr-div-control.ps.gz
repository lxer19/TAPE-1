URL: ftp://ftp.cse.ogi.edu/pub/esr/reports/distr-div-control.ps.gz
Refering-URL: http://www.cse.ogi.edu/~calton/publication.html
Root-URL: http://www.cse.ogi.edu
Title: Divergence Control for Distributed Database Systems  
Author: Calton Pu Wenwey Hseush and Gail E. Kaiser Kun-Lung Wu and Philip S. Yu 
Keyword: Index terms: epsilon serializability, distributed divergence control, extended transaction models, distributed databases, heterogeneous transaction processing.  
Address: New York, NY 10027  P.O. Box 704 Yorktown Heights, NY 10598  
Affiliation: Department of Computer Science Columbia University  IBM T.J. Watson Research Center  
Abstract: This paper presents distributed divergence control algorithms for epsilon serializability for both homogeneous and heterogeneous distributed databases. Epsilon serializability allows for more con-currency by permitting non-serializable interleavings of database operations among epsilon transactions. We first present a strict 2-phase locking divergence control algorithm and an optimistic divergence control algorithm for a homogeneous distributed database system, where the local or-derings of all the sub-transactions of a distributed epsilon transaction are the same. In such an environment, the total inconsistency of a distributed epsilon transaction is simply the sum of those of all its sub-transactions. We then describe a divergence control algorithm for a heterogeneous distributed database system, where the local orderings of all the sub-transactions of a distributed epsilon transaction may not be the same and the total inconsistency of a distributed epsilon transaction may be greater than the sum of those of all its sub-transactions. As a result, in addition to executing a local divergence control algorithm in each site to maintain the local inconsistency, a global mechanism is needed to take into account the additional inconsistency. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Barbara and H. Garcia-Molina. </author> <title> The demarcation protocol: A technique for maintaining linear arithmetic constraints in distributed database systems. </title> <booktitle> In Proceedings of the International Conference in Extending Database Technology, </booktitle> <address> Vienna, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: The trade-offs inherent in these choices are a subject of future research. Nevertheless, we describe a negotiation algorithm as an existential proof that such an algorithm can be incorporated into a distributed divergence control. Our choice is the demarcation protocol described in <ref> [1] </ref>. The demarcation protocol was designed to maintain global arithmetic constraints among sites, by establishing safe limits as "lines drawn in the sand" for updates. It provides a way to change these limits dynamically and asynchronously. <p> After receiving the allocated fuzziness, t 1 updates the entry for t 3 and continues to execute. It has been shown in <ref> [1] </ref> that the loss of messages does not cause the constraints to be violated, even though it may decrease performance. <p> The second sub-ET may decide to give $2,000 to the first sub-ET. After the first sub-ET increases its local limit by $2,000, it can proceed with more fuzziness tolerated. The justification of Demarcation protocol design has been discussed in <ref> [1] </ref>. The second global algorithm is a commit protocol to guarantee the same transaction outputs and global orderings. Even though S2PLDDC and ODDC have similar characteristics, but they have different implementations. ODDC needs to maintain the information of who holds a weak lock. <p> However, their queries still see a transaction-consistent view of the database, possibly with some older version that does not contain all the updates. In addition to the demarcation protocol <ref> [1] </ref> mentioned in Section 3.3, there are other papers concerning different approaches to dynamically distributing resources in a distributed system [?, ?, ?]. With appropriate modifications, these general resource allocation approaches can also be used to redistribute the *-spec among the sub-ETs in the design of distributed divergence control algorithms.
Reference: [2] <author> P.M. Bober and M.J. Carey. </author> <title> Multiversion query locking. </title> <booktitle> In Proceedings of the Twenty-First International Conference on Very Large Data Bases, </booktitle> <address> Vancouver, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: This observation underlies the concept of similarity among data values. Another paper that allows weaker forms of consistency in a way similar to Read-Only transactions [6] is a recent algorithm by Bober and Carey <ref> [2] </ref>. However, their queries still see a transaction-consistent view of the database, possibly with some older version that does not contain all the updates.
Reference: [3] <author> Y. Breitbart, D. Georgakopoulos, M. Rusinkiewicz, and A. Silberschatz. </author> <title> On rigorous transaction scheduling. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-17(9):954-960, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: In the simplest case, to be discussed in Section 3, the total fuzziness of a distributed ET is equal to the sum of the local fuzziness of all its sub-ETs: Z total = X subET Z local : This simple case corresponds to the rigorous schedules in <ref> [3] </ref>, or the commitment ordering in [17], where the local orderings of sub-ETs are the same among all the sites.
Reference: [4] <author> A. Elmagarmid and W. Du. </author> <title> A paradigm for concurrency control in heterogeneous distributed database systems. </title> <booktitle> In Proceedings of the Sixth International Conference on Data Engineering, </booktitle> <pages> pages 37-46, </pages> <address> Los Angeles, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: Although the Superdatabase paper [15] described an optimistic validation algorithm, there are other alternative schedulers for heterogeneous concurrency control that enforce global serializability more conservatively. For example, one could distribute an ordering at transaction creation time <ref> [4] </ref>. This solution depends on the ability of element databases to enforce the ordering, which is not the case for 2PL-based element databases, to give one example. Another possibility is the use of forced local conflicts to obtain a rigorous schedule [7].
Reference: [5] <author> K.P. Eswaran, J.N. Gray, R.A. Lorie, </author> <title> and I.L. Traiger. The notions of consistency and predicate locks in a database system. </title> <journal> Communications of ACM, </journal> 19(11) 624-633, November 1976. 
Reference-contexts: A constructive proof depends on the mechanism that bounds the distance and is similar to traditional concurrency control algorithm proofs. For example, a constructive proof that two-phase locking divergence control produces histories with such H SR is similar to the one in <ref> [5] </ref>. 5 2.2 Centralized Divergence Control Algorithms We briefly summarize the general design methodology of centralized divergence control algorithms in [19]. Import fuzziness (Z import ) is the amount of inconsistency that an ET "sees" from the database or other ETs through operations.
Reference: [6] <author> H. Garcia-Molina and G. Wiederhold. </author> <title> Read-only transactions in a distributed database. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 7(2) </volume> <pages> 209-234, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: However, data values of a data object that are slightly different in age or in precision are oftenacceptable as read data for transactions. This observation underlies the concept of similarity among data values. Another paper that allows weaker forms of consistency in a way similar to Read-Only transactions <ref> [6] </ref> is a recent algorithm by Bober and Carey [2]. However, their queries still see a transaction-consistent view of the database, possibly with some older version that does not contain all the updates.
Reference: [7] <author> D. Georgakopoulos and M. Rusinkiewicz. </author> <title> On serializability of multidatabase transactions through forced local conflitcs. </title> <booktitle> In Proceedings of the Seventh International Conference on Data Engineering, </booktitle> <address> Kobe, Japan, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: This solution depends on the ability of element databases to enforce the ordering, which is not the case for 2PL-based element databases, to give one example. Another possibility is the use of forced local conflicts to obtain a rigorous schedule <ref> [7] </ref>. Whether these other algorithms can be easily modified to support distributed divergence control is a subject of research. 8 Summary In this paper, we demonstrated the feasibility of epsilon serializability in both homogeneous and heterogeneous distributed databases by showing various concrete and representative distributed divergence control algorithms for ESR.
Reference: [8] <author> P.M. Herlihy and J.M. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: However, although all the sub-ETs may be locally serializable in each site, the global orderings of distributed ETs in general may not be serializable, especially in a heterogeneous distributed database system. This is a consequence of serializability being a global property <ref> [8] </ref>; the union of local serializability does not guarantee global serializability. Thus, the total fuzziness of a distributed ET may be greater than the sum of local fuzziness of all its sub-ETs. Our discussions of distributed divergence control algorithms will proceed from simple cases to more complex ones.
Reference: [9] <author> Gail E. Kaiser and Brent Hailpern. </author> <title> An object model for shared data. </title> <booktitle> In International Conference on Computer Languages, </booktitle> <pages> pages 135-144, </pages> <address> New Orleans LA, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: users (human or program); (3) frequent changes to data outside the control of the system; (4) soft real-time constraints, where updates must be accepted within a time interval or they will be missed; and (5) the acceptance by application designers that decisions may be based on obsolete or inconsistent data <ref> [9] </ref>. The purpose of distributed divergence control is to limit the obsolescence or inconsistency seen by query ETs to the degree that can be tolerated by the application. Changes that may come from outside the system may not be encapsulated in traditional transactions.
Reference: [10] <author> Iyengar Krishnan and Wolfgang Zimmer, </author> <title> editors. </title> <booktitle> IFIP TC6/WG6.6 2nd International Symposium on Integrated Network Management, </booktitle> <address> Washington DC, April 1991. </address> <publisher> North-Holland. </publisher>
Reference-contexts: Two major application areas for rapidly changing data are on-line financial decision support systems, such as automated portfolio managers [18], and automated network management systems for high-speed networks <ref> [10] </ref>. In the former case, a large volume of updates come from outside the system itself, e.g., from the stock exchange wire. The portfolio managers make financial decisions based on monitoring of trends over time as well as recently reported prices.
Reference: [11] <author> B. Lindsay. </author> <title> A retrospective of R fl : A distributed database management system. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 75(5) </volume> <pages> 668-673, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: A distributed ET consists of one or more sub-ETs, with each sub-ET on one site. For homogeneous distributed databases, our distributed transaction model is similar to the traditional model, such as the R fl <ref> [11] </ref>, where the local orderings of all sub-ETs are the same. However, for heterogeneous distributed databases, our model is similar to the one used in the Superdatabase [15], where the local orderings of all sub-ETs may be different.
Reference: [12] <author> C. Pu. </author> <title> Generalized transaction processing with epsilon-serializability. </title> <booktitle> In Proceedings of Fourth International Workshop on High Performance Transaction Systems, Asilomar, </booktitle> <address> Cali-fornia, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: In this paper, we only address transient inconsistency associated with transactions. We focus on the environments where query ETs may access inconsistent data through non-serializable interleavings with other update ETs, but update ETs are serializable among themselves. The same assumptions are also made in <ref> [12, 13, 14, 19] </ref>, where [12, 14] describes ESR for autonomous transaction executions and as a general framework for transaction processing, [13] describes the application of ESR to replica control in distributed systems and [19] describes the algorithms to maintain ESR histories for centralized database systems. <p> In this paper, we only address transient inconsistency associated with transactions. We focus on the environments where query ETs may access inconsistent data through non-serializable interleavings with other update ETs, but update ETs are serializable among themselves. The same assumptions are also made in [12, 13, 14, 19], where <ref> [12, 14] </ref> describes ESR for autonomous transaction executions and as a general framework for transaction processing, [13] describes the application of ESR to replica control in distributed systems and [19] describes the algorithms to maintain ESR histories for centralized database systems.
Reference: [13] <author> C. Pu and A. Leff. </author> <title> Replica control in distributed systems: An asynchronous approach. </title> <booktitle> In Proceedings of the 1991 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 377-386, </pages> <address> Denver, </address> <month> May </month> <year> 1991. </year> <month> 26 </month>
Reference-contexts: 1 Introduction Epsilon Serializability (ESR) <ref> [13, 19] </ref> is a generalization of classic serializability (SR). ESR allows a limited amount of inconsistency in transaction processing. An epsilon transaction (ET) is a sequence of operations that maintain database consistency when executed atomically. <p> In this paper, we only address transient inconsistency associated with transactions. We focus on the environments where query ETs may access inconsistent data through non-serializable interleavings with other update ETs, but update ETs are serializable among themselves. The same assumptions are also made in <ref> [12, 13, 14, 19] </ref>, where [12, 14] describes ESR for autonomous transaction executions and as a general framework for transaction processing, [13] describes the application of ESR to replica control in distributed systems and [19] describes the algorithms to maintain ESR histories for centralized database systems. <p> The same assumptions are also made in [12, 13, 14, 19], where [12, 14] describes ESR for autonomous transaction executions and as a general framework for transaction processing, <ref> [13] </ref> describes the application of ESR to replica control in distributed systems and [19] describes the algorithms to maintain ESR histories for centralized database systems.
Reference: [14] <author> C. Pu and A. Leff. </author> <title> Autonomous transaction execution with epsilon-serializability. </title> <booktitle> In Proceed--ings of 1992 RIDE Workshop on Transaction and Query Processing, Phoenix, </booktitle> <month> February </month> <year> 1992. </year> <journal> IEEE/Computer Society. </journal>
Reference-contexts: In this paper, we only address transient inconsistency associated with transactions. We focus on the environments where query ETs may access inconsistent data through non-serializable interleavings with other update ETs, but update ETs are serializable among themselves. The same assumptions are also made in <ref> [12, 13, 14, 19] </ref>, where [12, 14] describes ESR for autonomous transaction executions and as a general framework for transaction processing, [13] describes the application of ESR to replica control in distributed systems and [19] describes the algorithms to maintain ESR histories for centralized database systems. <p> In this paper, we only address transient inconsistency associated with transactions. We focus on the environments where query ETs may access inconsistent data through non-serializable interleavings with other update ETs, but update ETs are serializable among themselves. The same assumptions are also made in [12, 13, 14, 19], where <ref> [12, 14] </ref> describes ESR for autonomous transaction executions and as a general framework for transaction processing, [13] describes the application of ESR to replica control in distributed systems and [19] describes the algorithms to maintain ESR histories for centralized database systems.
Reference: [15] <author> Calton Pu. </author> <title> Superdatabases for composition of heterogeneous databases. </title> <editor> In Amar Gupta, editor, </editor> <booktitle> Integration of Information Systems: Bridging Heterogeneous Databases, </booktitle> <pages> pages 150-157. </pages> <publisher> IEEE Press, </publisher> <year> 1989. </year> <title> Also in IEEE Computer Society Tutorial, Multidatabase Systems: An Advanced Solution for Global Information Sharing. </title> <booktitle> The paper originally appeared in the Proceedings of Fourth International Conference on Data Engineering, 1988, </booktitle> <address> Los Angeles. </address>
Reference-contexts: In this case, merely employing a local divergence control algorithm in each site and accumulating all the local inconsistencies are not sufficient to enforce the bounded global inconsistency for a distributed ET. Thus, a global mechanism is needed to guarantee ESR. We use the Superdatabase architecture in <ref> [15] </ref> as a general model and present a corresponding distributed divergence control algorithm based upon it. The paper is organized as follows. <p> For homogeneous distributed databases, our distributed transaction model is similar to the traditional model, such as the R fl [11], where the local orderings of all sub-ETs are the same. However, for heterogeneous distributed databases, our model is similar to the one used in the Superdatabase <ref> [15] </ref>, where the local orderings of all sub-ETs may be different. We designate a special sub-ET to be the coordinator as the collector of results and the coordinator of the commit protocol. We assume that each distributed ET has one *-spec, i.e., only input one parameter for each ET. <p> This is due to conditions 2 and 3 and the fact that strict 2PL guarantees global serializability if all subtransactions are locally serializable (e.g., see <ref> [15] </ref>). However, a sub-ET may exceed its local fuzziness limit. If any local fuzziness of a sub-ET exceeds the assigned local limit, it can request or negotiate more *-spec from other sub-ETs. This is the step to be described in Section 3.3. <p> Z local + Z global : Z local is maintained by the local divergence control algorithm, and Z global is the global fuzziness calculated by the global divergence control mechanism, to be described in the next section. 4.2 Superdatabase Distributed Divergence Control Superdatabase Concurrency Control We use the Superdatabase architecture <ref> [15] </ref> as a general model for heterogeneous distributed databases. In the Superdatabase architecture, element databases are integrated together by a superda-tabase [15]. The element databases maintain local serializability while the superdatabase controls global serializability. <p> global fuzziness calculated by the global divergence control mechanism, to be described in the next section. 4.2 Superdatabase Distributed Divergence Control Superdatabase Concurrency Control We use the Superdatabase architecture <ref> [15] </ref> as a general model for heterogeneous distributed databases. In the Superdatabase architecture, element databases are integrated together by a superda-tabase [15]. The element databases maintain local serializability while the superdatabase controls global serializability. Each element database returns the ordering information about its subtrans-actions in the form of Order-element (O-element), one for each sub-ETs. The serialization order of each local sub-ET is represented by its O-element. <p> Any committed ET in the history but outside of H must precede t i or be independent (concurrent) to t i . The details about the algorithm to derive H can be found in <ref> [15] </ref>. <p> With appropriate modifications, these general resource allocation approaches can also be used to redistribute the *-spec among the sub-ETs in the design of distributed divergence control algorithms. Although the Superdatabase paper <ref> [15] </ref> described an optimistic validation algorithm, there are other alternative schedulers for heterogeneous concurrency control that enforce global serializability more conservatively. For example, one could distribute an ordering at transaction creation time [4].
Reference: [16] <author> K. Ramamrithan and C. Pu. </author> <title> A formal characterization of epsilon serializability. </title> <type> Technical Report CUCS-044-91, </type> <institution> Department of Computer Science, Columbia University, </institution> <year> 1991. </year>
Reference-contexts: Section 6 discusses some advanced issues in the design of a general distributed divergence control algorithm. Section 7 summarizes related work. 2 Background and Motivation 2.1 Semi-Formal Definition of ESR 2.1.1 Epsilon Serializability A formal ESR model has been discussed by Ramamrithan and Pu <ref> [16] </ref> based on the ACTA framework [?]. We briefly describe the formal model. We say that two operations, a and b, conflict, denoted by conf lict (a; b), if both operate on the same data item and one of them is a read operation. <p> First, the number of ETs in C update is zero, since we do not wish to introduce permanent inconsistency into the database. This follows from the assumptions made in divergence control work in this paper (sections 3.2, 3.4) and other previous papers <ref> [19, 16] </ref>, that update ETs are serializable with respect to each other. jC update j = 0 Second, the import fuzziness of a committed query ET that conflicts with t i may increase by M U (t i ), if t i is committed. The following condition must hold. <p> Since inconsistency propagation depends on the semantics of each computation, it is non-trivial to estimate the output inconsistency from the input inconsistency <ref> [16] </ref>. Here, we only sketch a possible way to handle the problem. If a data item Y is a function of a data item X, we say that Y is consistency-dependent on X. A consistency-dependency must be encapsulated in an ET.
Reference: [17] <author> Y. Raz. </author> <title> The principle of commitment ordering. </title> <booktitle> In Proceedings of the 18th International Conference on Very Large Data Bases, </booktitle> <pages> pages 292-312, </pages> <booktitle> Auguest 1992. [18] 1st International Conference on Artificial Intelligence Applications on Wall Street, </booktitle> <address> New York NY, October 1991. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: case, to be discussed in Section 3, the total fuzziness of a distributed ET is equal to the sum of the local fuzziness of all its sub-ETs: Z total = X subET Z local : This simple case corresponds to the rigorous schedules in [3], or the commitment ordering in <ref> [17] </ref>, where the local orderings of sub-ETs are the same among all the sites. However, although all the sub-ETs may be locally serializable in each site, the global orderings of distributed ETs in general may not be serializable, especially in a heterogeneous distributed database system.
Reference: [19] <author> K.L. Wu, P. S. Yu, and C. Pu. </author> <title> Divergence control for epsilon-serializability. </title> <booktitle> In Proceedings of Eighth International Conference on Data Engineering, </booktitle> <pages> pages 506-515, </pages> <address> Phoenix, </address> <month> February </month> <year> 1992. </year> <journal> IEEE/Computer Society. </journal> <volume> 27 </volume>
Reference-contexts: 1 Introduction Epsilon Serializability (ESR) <ref> [13, 19] </ref> is a generalization of classic serializability (SR). ESR allows a limited amount of inconsistency in transaction processing. An epsilon transaction (ET) is a sequence of operations that maintain database consistency when executed atomically. <p> In this paper, we only address transient inconsistency associated with transactions. We focus on the environments where query ETs may access inconsistent data through non-serializable interleavings with other update ETs, but update ETs are serializable among themselves. The same assumptions are also made in <ref> [12, 13, 14, 19] </ref>, where [12, 14] describes ESR for autonomous transaction executions and as a general framework for transaction processing, [13] describes the application of ESR to replica control in distributed systems and [19] describes the algorithms to maintain ESR histories for centralized database systems. <p> The same assumptions are also made in [12, 13, 14, 19], where [12, 14] describes ESR for autonomous transaction executions and as a general framework for transaction processing, [13] describes the application of ESR to replica control in distributed systems and <ref> [19] </ref> describes the algorithms to maintain ESR histories for centralized database systems. The bounded inconsistency in ESR is automatically maintained by divergence control (DC) 1 algorithms similar to the way in which serializability is enforced by concurrency control algorithms in classic transaction processing systems. <p> The bounded inconsistency in ESR is automatically maintained by divergence control (DC) 1 algorithms similar to the way in which serializability is enforced by concurrency control algorithms in classic transaction processing systems. Various divergence control algorithms for centralized transaction processing systems have been described in <ref> [19] </ref>. In this paper, we introduce divergence control algorithms for distributed transaction processing systems. In general, a distributed ET consists of many sub-ETs, each executing in one component database, or site. <p> For example, a constructive proof that two-phase locking divergence control produces histories with such H SR is similar to the one in [5]. 5 2.2 Centralized Divergence Control Algorithms We briefly summarize the general design methodology of centralized divergence control algorithms in <ref> [19] </ref>. Import fuzziness (Z import ) is the amount of inconsistency that an ET "sees" from the database or other ETs through operations. Export fuzziness (Z export ) is the amount of fuzziness that an ET introduces to other ETs. <p> The local divergence control algorithm is similar to the 2PLDC algorithm described in <ref> [19] </ref> and in Section 2.2 of this paper with an additional assumption that locks at any site are released only at the commit time of a distributed ET. The calculation of Z local export and Z local import for a sub-ET can be done locally. <p> Theorem 1 The distributed strict 2-phase divergence control algorithm guarantees ESR. Proof: The local strict 2PLDC algorithm (pessimistically) calculates the maximum amount of inconsistency potentially caused by read/write operations <ref> [19] </ref>. Since each site maintains conditions 4 and 5 locally and the local serialization orderings of all sub-ETs are the same, when we add up the Z local export for all sites we have the safe conditions 2 and 3. <p> Further improvements to increase performance, reliability, availability, or autonomy of demarcation protocol are possible but they are beyond the scope of this paper. 3.4 Optimistic Distributed Divergence Control Using Weak Locks We start by summarizing the centralized optimistic validation divergence control algorithm (ODC) in <ref> [19] </ref>, and then extend it to the optimistic distributed divergence control algorithm (ODDC). The centralized ODC method was implemented using strong locks and weak locks. Either one can be in a shared mode (a read-only lock) or an exclusive mode (an update lock). <p> First, the number of ETs in C update is zero, since we do not wish to introduce permanent inconsistency into the database. This follows from the assumptions made in divergence control work in this paper (sections 3.2, 3.4) and other previous papers <ref> [19, 16] </ref>, that update ETs are serializable with respect to each other. jC update j = 0 Second, the import fuzziness of a committed query ET that conflicts with t i may increase by M U (t i ), if t i is committed. The following condition must hold. <p> programmer must take this into account, since the calculation of fuzziness propagation (as in Section 6.1) typically makes the assumption that the total fuzziness will not exceed the ET's *-spec. 7 Related Work This paper describes distributed divergence control algorithms in contrast to the centralized divergence control algorithms discussed in <ref> [19] </ref>.
References-found: 18

