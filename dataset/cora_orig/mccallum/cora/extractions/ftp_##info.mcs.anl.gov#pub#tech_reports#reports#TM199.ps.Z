URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/TM199.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Title: Users Guide for the ANL IBM SPx A R G O N N E N
Author: William Gropp and Ewing Lusk MATHEMATICS AND 
Date: Revised November 30, 1995  
Web: http://www.mcs.anl.gov/sp1/guide-r2/guide-r2.html  
Affiliation: Mathematics and Computer Science Division  COMPUTER SCIENCE DIVISION  
Note: ANL/MCS-TM-199, Rev 1  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Ralph Butler and Ewing Lusk. </author> <title> User's guide to the p4 parallel programming system. </title> <type> Technical Report ANL-92/17, </type> <institution> Argonne National Laboratory, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Our implementation uses Chameleon, so the usual Chameleon methods of preparing programs and starting jobs apply. There are man pages for all of the MPI routines in `/usr/local/mpi/man'. Supported Transport Layers: Switch/IP, Switch/US, Ethernet/IP. Contact: gropp@mcs.anl.gov or lusk@mcs.anl.gov for more information. 3.2.5 p4 p4 <ref> [2, 1] </ref> is a portable message-passing system that runs on a very wide variety of parallel systems and workstations. It is in use at approximately 200 sites around the world. Existing p4 programs will run unchanged on the SPx. <p> Examples: `/usr/local/p4-1.4a/SP2/examples' on bonnie and clyde contains C and Fortran examples, example makefiles, and a makefile that can be used to construct your makefiles with the appropriate options for the SPx's various transport layers. 10 Documentation: `/home/lusk/ibm/p4-1.4b/doc' contains the latexinfo source for the manual <ref> [1] </ref>, an ASCII version, and the postscript for a reference card. `/home/lusk/p4.manual' contains the postscript for the manual itself in (`p4.ps'). The manual is also online via info and any of the inside-Emacs or stand-alone info readers (e.g., gnu-info). Supported Transport Layers: Ethernet/IP, Switch/IP, Switch/us.
Reference: [2] <author> Ralph Butler and Ewing Lusk. </author> <title> Monitors, messages, and clusters: The p4 parallel programming system. </title> <journal> Journal of Parallel Computing, </journal> <note> 1993. To appear (Also Argonne National Laboratory Mathematics and Computer Science Division preprint P362-0493). </note>
Reference-contexts: Our implementation uses Chameleon, so the usual Chameleon methods of preparing programs and starting jobs apply. There are man pages for all of the MPI routines in `/usr/local/mpi/man'. Supported Transport Layers: Switch/IP, Switch/US, Ethernet/IP. Contact: gropp@mcs.anl.gov or lusk@mcs.anl.gov for more information. 3.2.5 p4 p4 <ref> [2, 1] </ref> is a portable message-passing system that runs on a very wide variety of parallel systems and workstations. It is in use at approximately 200 sites around the world. Existing p4 programs will run unchanged on the SPx.
Reference: [3] <author> Message Passing Interface Forum. </author> <title> Document for a standard message-passing interface. </title> <type> Technical Report CS-93-214, </type> <institution> University of Tennessee, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Contact: fortran-m@mcs.anl.gov for more information. 3.2.4 MPI MPI (Message-Passing Interface) is a new message-passing system "standard" that has recently been defined by a broadly based group of parallel computing vendors, library writers (including us), and users. The current draft is now in the public-comment stage <ref> [3] </ref>. It was completed in the spring of 1994. The standard draft is available by anonymous ftp from `info.mcs.anl.gov' in `pub/mpi/mpi-report.ps.Z', or on the WWW in http://www.mcs.anl.gov/mpi/mpi-report/mpi-report.html. There are two implementations: one being done by us and a group from Mis-sissippi State University, and the other being done by IBM.
Reference: [4] <author> William D. Gropp and Barry F. Smith. </author> <title> Chameleon parallel programming tools users manual. </title> <type> Technical Report ANL-93/23, </type> <institution> Argonne National Laboratory, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Documentation: `/home/gropp/tools.n/docs/tutorial/parallel.tex'. The script `/home/gropp/tools.n/bin/toolman' will start an xman for the manual pages for the Chameleon routines (and others). See also <ref> [4] </ref>. Supported Communication Layers: MPL, MPI, p4 Special Comments: The Chameleon makefiles provide portability by using names defined on the make command line. You should set ARCH=rs6000 and BOPT=g (for debugging) or BOPT=O (for production) and COMM=p4, COMM=eui, or COMM=mpi for the interfaces p4, MPL, and MPI respectively. <p> Contact: gropp@mcs.anl.gov for more information. How to compile and link: Examples may be found in `/usr/local/tools.core/comm/examples'. Chameleon uses fairly complicated makefiles to achive portability to a wide variety of systems; you should look at the Chameleon manual <ref> [4] </ref> for more details. The value of ARCH for the SPx is rs6000. If you are using the usual Chameleon makefile, an appropriate make line for MPL is make ARCH=rs6000 COMM=eui BOPT=O How to run: Chameleon provides a nearly consistent interface for all transport layers.
Reference: [5] <author> Virginia Herrarte and Ewing Lusk. </author> <title> Studying parallel program behavior with Upshot. </title> <type> Technical Report ANL-91/15, </type> <institution> Argonne National Laboratory, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: This is useful for finding the cause of deadlock in parallel applications. 7.5 upshot Upshot <ref> [5] </ref> is a portable X Windows program for visualizing the behavior of a parallel program. Both Chameleon and p4 can generate the event logs that upshot reads. To generate an event log from Chameleon, use the -event flag a.out -np 4 -event This generates a file `bl'.
Reference: [6] <author> IBM. </author> <title> IBM AIX Parallel Environment Parallel Programming Subroutine Reference Release 2.0, </title> <month> June </month> <year> 1994. </year>
Reference-contexts: PE is the parallel environment, and is IBM's term for all of the parallel tools (such as MPL, POE, pdbx, etc.) PE supports a parallel symbolic debugger (pdbx; xpdbx is not yet available) and a performance visualization tool (vt). MPL is documented in <ref> [6] </ref>. Any environment that makes use of Switch/us uses POE; all options described in the man page on poe (man poe) may be used. Note that MPL has a large number of options. The options can be set with shell environment variables.
Reference: [7] <author> D. H. Lawrie. </author> <title> Access and alignment of data in an array processor. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-24(12):1145-1155, </volume> <month> December </month> <year> 1975. </year>
Reference-contexts: In practice, each node can achieve between 15 and 70 MFlops on Fortran code. Higher performance can be reached by using the BLAS or ESSL routines. 2.1.1 Details on the High Performance Switch References for omega networks include [8] and <ref> [7] </ref>. 3 2.2 Software As each SPx node is running a full Unix, most of the usual Unix tools are available.
Reference: [8] <author> H. J. Siegel. </author> <title> Interconnection Networks for Large Scale Parallel Processing. </title> <publisher> Lexington Books, </publisher> <year> 1985. </year> <month> 36 </month>
Reference-contexts: In practice, each node can achieve between 15 and 70 MFlops on Fortran code. Higher performance can be reached by using the BLAS or ESSL routines. 2.1.1 Details on the High Performance Switch References for omega networks include <ref> [8] </ref> and [7]. 3 2.2 Software As each SPx node is running a full Unix, most of the usual Unix tools are available.
References-found: 8

