URL: http://purcell.ecn.purdue.edu/~terran/facts/research/pubs/aaai97-ws.ps
Refering-URL: 
Root-URL: 
Email: email: fterran,brodleyg@ecn.purdue.edu  
Phone: Phone: +1 765 494-3462  
Title: Sequence Matching and Learning in Anomaly Detection for Computer Security  
Author: Terran Lane and Carla E. Brodley 
Keyword: Application, Sequence learning, Partial matching, Classification, Recognition, Computer se curity, Anomaly detection, Behavioral modeling.  
Address: Building  West Lafayette, IN 47907-1285  
Affiliation: School of Electrical and Computer Engineering 1285 Electrical Engineering  Purdue University  
Abstract: Two problems of importance in computer security are to 1) detect the presence of an intruder masquerading as the valid user and 2) detect the perpetration of abusive actions on the part of an otherwise innocuous user. We have developed an approach to these problems that examines sequences of user actions (UNIX commands) to classify behavior as normal or anomalous. In this paper we explore the matching function needed to compare a current behavioral sequence to a historical profile. We discuss the difficulties of performing matching in human-generated data and show that exact string matching is insufficient to this domain. We demonstrate a number of partial matching functions and examine their behavior on user command data. In particular, we explore two methods for weighting scores by adjacency of matches as well as two growth functions (polynomial and exponential) for scoring similarities. We find, empirically, that the optimal similarity measure is user dependant but that measures based on the assumption of causal linkage between user commands are superior for this domain. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J. P. </author> <year> (1980). </year> <title> Computer security threat monitoring and surveillance, </title> <type> (Technical Report), </type> <address> Washington, PA, James P. </address> <publisher> Anderson Co. </publisher>
Reference: <author> Baffes, P., & Mooney, R. </author> <year> (1996). </year> <title> A novel application of theory refinement to student modeling. </title> <booktitle> Proceedings of the Thirteenth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 403-408). </pages> <address> Portland, OR: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Fur- thermore, they allow an encoding of domain knowledge (in terms of the higher-level features employed) but may overlook other characteristics present in the data. Machine learning researchers have studied modeling of human behavior in the contexts of, for example, automatic tutoring <ref> (Baffes & Mooney, 1996) </ref>. This work models a student's understanding of a subject as a set of Horn-clauses which defines deviations from the correct theory of the subject.
Reference: <author> Denning, D. E. </author> <year> (1987). </year> <title> An intrusion-detection model. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13, </volume> <pages> 222232. </pages>
Reference: <author> Dietterich, T. G. , & Michalski, R. S. </author> <year> (1986). </year> <title> Learning to predict sequences. </title> <editor> In Michalski, Carbonell & Mitchell (Eds.), </editor> <booktitle> Machine learning: An artificial in-telligence approach. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Forrest, S., Hofmeyr, S. A., Somayaji, A., & Longstaff, T. A. </author> <year> (1996a). </year> <title> A sense of self for Unix processes. </title> <booktitle> Proceedings of 1996 IEEE Symposium on Computer Security and Privacy. </booktitle>
Reference: <author> Forrest, S., Hofmeyr, S., & Somayaji, A. </author> <year> (1996b). </year> <title> Computer immunology. </title> <journal> Communications of the ACM. </journal>
Reference: <author> Frank, J. </author> <year> (1994). </year> <title> Machine learning and intrusion de-tection: Current and future directions. </title> <booktitle> Proc. of the 17th National Computer Security Conference. </booktitle>
Reference: <author> Fukunaga, K. </author> <year> (1990). </year> <title> Statistical Pattern Recognition (second edition). </title> <address> San Diego, CA: </address> <publisher> Academic Press. </publisher>
Reference-contexts: A smaller allowed error rate, therefore, corresponds to a wider range of acceptable similarities. We acknowledge that this classification scheme is relatively unsophisticated, but it turns out to perform surprisingly well in many cases. We are currently investigating employing other non-parametric classification techniques, such as clustering with Parzen windows <ref> (Fukunaga, 1990) </ref>, to this task. Examination of Similarity Measures To examine the degree of class separation produced by each of these similarity measures, we used each to classify user command history traces. <p> We are also examining the possibility of replacing the simple threshold classification system employed here with either a non-parametric clustering classification system based on Parzen windows <ref> (Fukunaga, 1990) </ref> or a classification system based on Hidden Markov Models (Rabiner, 1989) of user behavior. Under any of these classification schemes, the problem of the selection of an optimal similarity measure for each user needs to be examined.
Reference: <author> Heberlein, L. T., Dias, G. V., Levitt, K. N., Mukherjee, B., Wood, J., & Wolber, D. </author> <year> (1990). </year> <title> A network security monitor. </title> <booktitle> Proceedings of the 1990 IEEE Symposium on Research in Security and Privacy (pp. </booktitle> <pages> 296304). </pages>
Reference: <author> Hirsh, H., & Japkowicz, N. </author> <year> (1994). </year> <title> Bootstrapping training-data representations for inductive learning: A case study in molecular biology. </title> <booktitle> Proceedings of the Twelfth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 639-644). </pages> <address> Seattle, WA. </address>
Reference: <author> Krsul, I., & Spafford, E. H. </author> <year> (1996). </year> <title> Authorship anal-ysis: Identifying the author of a program, </title> <type> (CSD-TR 96-052), </type> <institution> West Lafayette, IN: Purdue University, De-partment of Computer Sciences. </institution>
Reference: <author> Kumar, S. </author> <year> (1995). </year> <title> Classification and detection of computer intrusions. </title> <type> Doctoral dissertation, </type> <institution> Department of Computer Sciences, Purdue University, W. Lafayette, </institution> <note> IN. </note>
Reference: <author> Lane, T., & Brodley, C. E. </author> <year> (1997). </year> <title> Detecting the ab-normal: </title> <booktitle> Machine learning in computer security, </booktitle> <address> (TRECE 97-1), </address> <institution> West Lafayette, IN: Purdue University. </institution>
Reference-contexts: Detecting anomalous behavior can be viewed as a binary valued classification problem in which measurements of system activity such as system log files, resource usage, command traces, and audit trails are used to produce a classification of the state of the system as normal or abnormal. In other work <ref> (Lane & Brodley, 1997) </ref> we have presented a system intended to address the anomaly detection domain. Our system learns a user profile and subsequently employs it to detect anomalous behavior. <p> We demonstrated that the closed world assumption can be used to address the positive training examples difficulty, and that user behaviors can be distinguished under a particular definition of behavioral similarity <ref> (Lane & Brodley, 1997) </ref>. In this paper we explore the issue of similarity measurement | matching a current behavioral pattern with historical behavior. We demonstrate a number of possible matching functions and examine some of the behavioral differences among them. <p> Classifying User Behavior Given an input stream of command tokens parsed by the data collection module (as described in <ref> (Lane & Brodley, 1997) </ref>), the detection module classifies the current user as normal or anomalous after each token. <p> In an intuitive sense, this stream represents the familiarity of the input commands at each time step, given knowledge about the previous behavior of the user. The similarity stream is smoothed to reduce noise <ref> (Lane & Brodley, 1997) </ref> and classification is performed for each time step. In the current implementation the classification is made with a threshold decision: if the current smoothed similarity measure is between maximum and minimum allowable bounds, then classify the current time step as normal, otherwise classify it as abnormal. <p> The user profiles were initialized with all available training data and were pruned down to the desired testing sizes of 200, 500, or 1000 sequences via the LRU instance selection algorithm as described in <ref> (Lane & Brodley, 1997) </ref>. <p> All experiments employed a sequence length of ten tokens and a smoothing window length of eighty sequences. These values were selected based on previous experimentation <ref> (Lane & Brodley, 1997) </ref>. Profiles were created for four of the users and then the test data from all seven users were classified against the profiles according to each similarity measure.
Reference: <author> Lunt, T. F. </author> <year> (1990). </year> <title> IDES: An intelligent system for detecting intruders. </title> <booktitle> Proceedings of the Symposium: Computer Security, Threat and Countermeasures. </booktitle> <address> Rome, Italy. </address>
Reference: <author> Norton, S. W. </author> <year> (1994). </year> <title> Learning to recognize promoter sequences in E. coli by modelling uncertainty in the training data. </title> <booktitle> Proceedings of the Twelfth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 657-663). </pages> <address> Seattle, WA. </address>
Reference-contexts: Because of privacy issues, and the fact that it is impossible to characterize the full space of user behaviors, only positive examples of the account owner's behavior are available for training. Norton has explored sequence learning for DNA sequences <ref> (Norton, 1994) </ref>, but his data had both positive and negative training examples. The anomaly detection domain differs from traditional concept formation tasks in that one must characterize user behavior from "positive" examples only.
Reference: <author> Rabiner, L. R. </author> <year> (1989). </year> <title> A tutorial on Hidden Markov Models and selected applications in speech recogni-tion. </title> <booktitle> Proceedings of the IEEE. </booktitle>
Reference-contexts: We are also examining the possibility of replacing the simple threshold classification system employed here with either a non-parametric clustering classification system based on Parzen windows (Fukunaga, 1990) or a classification system based on Hidden Markov Models <ref> (Rabiner, 1989) </ref> of user behavior. Under any of these classification schemes, the problem of the selection of an optimal similarity measure for each user needs to be examined. Finally, the issue of concept drift must be addressed, including the influence of concept drift on the optimal similarity measure.
Reference: <author> Salzberg, S. </author> <year> (1995). </year> <title> Locating protein coding regions in human DNA using a decision tree algorithm. </title> <journal> Journal of Computational Biology, </journal> <volume> 2, </volume> <pages> 473-485. </pages>
Reference: <author> Smaha, S. E. </author> <year> (1988). </year> <title> Haystack: An intrusion de-tection system. </title> <booktitle> Proceedings of the Fourth Aerospace Computer Security Applications Conference (pp. </booktitle> <pages> 3744). </pages>
Reference: <author> Spafford, E. H., & Weeber, S. A. </author> <year> (1992). </year> <title> Software forensics: Can we track code to its authors? 15 th National Computer Security Conference (pp. </title> <type> 641-650). </type>
Reference-contexts: User profiling is a widely studied problem in the literatures of computer security and machine learning. In the area of security, the applications of behavioral modeling are in anomaly detection (as described previously) and in software forensics <ref> (Spafford & Weeber, 1992) </ref>. Krsul and Spafford (1996) have examined the topic of authorship analysis and used a set of software metrics such as mean line length, placement of syntactic structures, ratio of global to local variable counts, and ratio of white lines to code lines to identify program authors.
Reference: <author> Srikant, R., & Agrawal, R. </author> <year> (1996). </year> <title> Mining sequential patterns: Generalizations and performance improve-ments, </title> . <booktitle> Proc. of the Fifth Int'l Conference on Extending Database Technology (EDBT). </booktitle> <address> Avignon, France. </address>
Reference: <author> Acknowledgments: We would like to thank Tim Stough, Gene Spafford, Ronny Kohavi, Paul Utgoff, Craig Codrington, </author> <title> and our anonymous reviewers for their helpful comments. We are also grateful to the members of the Purdue MILLENNIUM Lab and our other data donors for their contributions of data and insight to this work. A portion of this research was funded by the commercial and government sponsors and supporters of the COAST Laboratory: </title> <institution> Cisco Systems, HP, Schlumberger, MITRE, Sprint, Sun Microsystems, Hughes Research Laboratories, Thompson Consumer Electronics, and the U.S. Department of Defense. </institution>
References-found: 21

