URL: http://www.isi.edu/~frank/Papers/dis95.ps
Refering-URL: http://www.isi.edu/~frank/Papers/papers.html
Root-URL: http://www.isi.edu
Email: foley-@cc.gatech.edu  
Title: Inference Bear: Designing Interactive Interfaces through Before and After Snapshots unique in its use of
Author: Martin R. Frank Piyawadee Noi Sukaviriya James D. Foley -martin, noi, 
Keyword: Rapid prototyping, human-computer dialog  
Note: Inference Bear is  However, it is also more difficult to design domain-independent demonstrational systems that are as easy to use as their domainspecific counterparts. The paper addresses this issue, and other issues relating to domain-independence.  specification, programming by demonstration.  
Address: Atlanta, Georgia 30332-0280  
Affiliation: Graphics, Visualization Usability Center Georgia Institute of Technology  
Abstract: We present Inference Bear (An Inference Creature based on Before and After Snapshots) which lets users build functional graphical user interfaces by demonstration. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Allen Cypher. EAGER: </author> <title> Programming repetitive tasks by example. </title> <booktitle> In Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 3339, </pages> <address> (New Orleans, LA, </address> <month> Apr. 28-May 2) </month> <year> 1991. </year>
Reference-contexts: Peridot [10] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [12] focuses on creating applicationspecific objects. Metamouse [9] learns graphical procedures by example. Druid [13] lets designers attach simple functionality to graphical user interfaces, such as enabling, disabling, hiding and showing buttons. Eager <ref> [1] </ref> watches users perform operations and detects and automates repetition. Mondrian [in 2] is a graphical editor that can learn new composite commands by demonstration. DEMO [15,3] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. Chimera [8] infers constraints on the movement of objects given multiple snapshots. <p> 1989 Yes Clarification, Prediction Yes Medium Touch Sensitive d No Event Recording Graphical Procedure Druid e [13] 1990 No Clarificaton No not applicable None c No Event Recording Script Mondrian [in 2] 1991 Yes (in teach ing mode) Synthesized Speech Yes Medium None c Yes Event Recording Macro f Eager <ref> [1] </ref> 1991 Yes Prediction not applicable not applicable not applicable No Event Recording Macro DEMO [15,3] 1991/92 No Clarification Yes High Auxiliary Objects Yes (DEMO II) Compressed Snapshots Response Description Chimera g [8] 1991 No None c No High Auxiliary Objects h No Snapshots Two-Way Constraints Marquise [11] 1993 No (optional)
Reference: [2] <author> Allen Cypher, </author> <title> editor. Watch What I Do: Programming by Demonstration. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference: [3] <author> Gene Fisher, Dale Busse, and David Wolber. </author> <title> Adding rule-based reasoning to a demonstrational interface builder. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 8997, </pages> <address> (Monterey, CA, </address> <month> Nov. 15-18) </month> <year> 1992. </year>
Reference: [4] <author> James Foley, Won Chul Kim, Srdjan Kovacevic, </author> <title> and companion for Inference Bear. Kevin Murray. Defining user interfaces at a high level of abstraction. </title> <journal> IEEE Software, </journal> <volume> 6(1):2532, </volume> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: The current user interface design is shown in the center , consisting of an ellipse and a circle which are connected by a line. The middle control panel belongs to UIDE, a descendant of the original User Interface Design Environment <ref> [4] </ref>. In the context of this paper, it suffices to know that it lets you open the text editor shown on the right-hand side of Figure 1, and that it can switch the interface to run mode by reading and executing the specification in this editor.
Reference: [5] <author> Martin Frank and James Foley. </author> <title> Model-based user interface design by example and by interview. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 129137, </pages> <address> (Atlanta, GA, </address> <month> Nov. 3-5) </month> <year> 1993. </year>
Reference-contexts: The UIDE Tools control panel provides the interface to advanced tools in the UIDE environment. The Interview Tool helps the designer fill in the textual model by asking questions about the current user interface layout. It is described in <ref> [5] </ref> and will not further be discussed here. The Inference Bear is the tool we are concerned with - it lets designers describe the behavior of the user interface by demonstration. For example, it can infer the body of the transition shown in Figure 1.
Reference: [6] <author> Martin Frank and James Foley. </author> <title> A pure reasoning engine for programming by demonstration. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 95101, </pages> <address> (Marina del Rey, CA, </address> <month> Nov. 2-4) </month> <year> 1994. </year>
Reference-contexts: INTRODUCTION This paper will focus on the interactive design process when using Inference Bear, as is appropriate for this conference. Inference Bear is built on top of a reasoning engine whose computational aspects we have described in a previous paper <ref> [6] </ref>. Using an existing reasoning engine puts constraints on the user interface of the demonstrational tool while also leaving many degrees of freedom. <p> Some systems use auxiliary objects such as guide wires to let the user specify the relevant objects and their relationship. Inference Bear limits the number of objects it considers to those that change during the demonstration <ref> [6] </ref>. The sixth column describes if the inferencing is based on rules or on an algorithm. The advantage of rule-based systems is that they can encode knowledge about common use of the system. <p> If such a rule exists the system can infer the solution from a single example. Our reasoning is based only on the types and values of attributes but not on their names <ref> [6] </ref>. A demonstration consisting of a single example will always be solved by assigning constants to the variables. The engine uses the simplest solution to a demonstration because there generally is an inf i-nite number of more complex solutions to a demonstration, 2. <p> Other behavior can then be dependent on the selection status of objects. Reasoning about user-defined attributes would not be possible if Inference Bear relied on attribute names to draw inferences <ref> [6] </ref>. EXAMPLE 4: SET REASONING Inference Bear can infer set expressions such as objects that are higher than two hundred pixels or objects that are not red on the left-hand side of assignments. Inference Bear looks for set expressions only if it cannot solve the demonstration using conventional assignments.
Reference: [7] <author> Thomas Kuehme and Matthias Schneider-Huf-schmidt. </author> <title> SX/Tools - An open design environment for adaptable multimedia user interfaces. </title> <journal> Computer Graphics Forum, </journal> <volume> 11(3):93105, </volume> <month> Sep. </month> <year> 1992. </year>
Reference-contexts: The last column describes the result of the inferenc-ing process. THE DESIGN ENVIRONMENT three small windows are the control panels of its main components. The left-hand control panel belongs to the interface builder we use <ref> [7] </ref>. It lets you open user interface designs and palettes of reusable interface elements (toolboxes). One such toolbox is shown on the left, labelled Graphics. The current user interface design is shown in the center , consisting of an ellipse and a circle which are connected by a line.
Reference: [8] <author> David Kurlander and Steven Feiner. </author> <title> Inferring constraints from multiple snapshots. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 12(4):277304, </volume> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Eager [1] watches users perform operations and detects and automates repetition. Mondrian [in 2] is a graphical editor that can learn new composite commands by demonstration. DEMO [15,3] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. Chimera <ref> [8] </ref> infers constraints on the movement of objects given multiple snapshots. Finally , Marquise [11] uses domain knowledge in order to support building graphical editors. All of these systems use by-demonstration techniques but they are not easily compared because they have dif ferent goals and use different techniques. <p> 1991 Yes (in teach ing mode) Synthesized Speech Yes Medium None c Yes Event Recording Macro f Eager [1] 1991 Yes Prediction not applicable not applicable not applicable No Event Recording Macro DEMO [15,3] 1991/92 No Clarification Yes High Auxiliary Objects Yes (DEMO II) Compressed Snapshots Response Description Chimera g <ref> [8] </ref> 1991 No None c No High Auxiliary Objects h No Snapshots Two-Way Constraints Marquise [11] 1993 No (optional) Clarification Yes Low None c Yes Event Recording LISP Code Inference Bear 1995 No Script Display Yes Medium Motion Sensitive No Ev. Rec. and Snapshots Script (Transition) Table 1.
Reference: [9] <author> David Maulsby, Ian Witten, and Kenneth Kittlitz. Metamouse: </author> <title> Specifying graphical procedures by example. </title> <booktitle> In Proceedings of Siggraph, </booktitle> <pages> pages 127136, </pages> <address> (Boston, MA, </address> <month> Jul. 31-Aug. 4) </month> <year> 1989. </year>
Reference-contexts: PROGRAMMING BY DEMONSTRATION We shortly review related work on demonstrational systems. Peridot [10] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [12] focuses on creating applicationspecific objects. Metamouse <ref> [9] </ref> learns graphical procedures by example. Druid [13] lets designers attach simple functionality to graphical user interfaces, such as enabling, disabling, hiding and showing buttons. Eager [1] watches users perform operations and detects and automates repetition. <p> Instantiation Capabilities (Subjective) Strength in Geometric Relations Internals Search Space Reduction Internals Is Rule-Based Internals Temporary Behavior Storage Internals Inferencing Result Peridot [10] 1987 Yes Clarification Partially a Low Selecting (Optional) b Yes Snapshots One-Way Constraints Lapidary [12] 1989 No Clarification No Low None c No Snapshots One-Way Constraints Metamouse <ref> [9] </ref> 1989 Yes Clarification, Prediction Yes Medium Touch Sensitive d No Event Recording Graphical Procedure Druid e [13] 1990 No Clarificaton No not applicable None c No Event Recording Script Mondrian [in 2] 1991 Yes (in teach ing mode) Synthesized Speech Yes Medium None c Yes Event Recording Macro f Eager
Reference: [10] <author> Brad Myers. </author> <title> Creating User Interfaces by Demonstration. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: PROGRAMMING BY DEMONSTRATION We shortly review related work on demonstrational systems. Peridot <ref> [10] </ref> supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [12] focuses on creating applicationspecific objects. Metamouse [9] learns graphical procedures by example. Druid [13] lets designers attach simple functionality to graphical user interfaces, such as enabling, disabling, hiding and showing buttons. <p> Chimera also uses a variety of other techniques to reduce the search space. Interface Is Eager (Constantly Watches User) Interface Feedback about Inference Process Capabilities Run-time Object Instantiation Capabilities (Subjective) Strength in Geometric Relations Internals Search Space Reduction Internals Is Rule-Based Internals Temporary Behavior Storage Internals Inferencing Result Peridot <ref> [10] </ref> 1987 Yes Clarification Partially a Low Selecting (Optional) b Yes Snapshots One-Way Constraints Lapidary [12] 1989 No Clarification No Low None c No Snapshots One-Way Constraints Metamouse [9] 1989 Yes Clarification, Prediction Yes Medium Touch Sensitive d No Event Recording Graphical Procedure Druid e [13] 1990 No Clarificaton No not <p> Which event is the one that triggers the behavior to be demonstrated? There are several solutions to this problem. Peridot <ref> [10] </ref> uses a simulated mouse which is a window depicting a mouse including the state of its buttons. The system can then use the state and position of the simulated mouse, freeing the real mouse for metalevel commands.
Reference: [11] <author> Brad Myers, Richard McDaniel, and David Kosbie. Marquise: </author> <title> Creating complete user interfaces by demonstration. </title> <booktitle> In Proceedings of INTERCHI, ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 293300, </pages> <address> (Amsterdam, The Netherlands, </address> <month> Apr. 24-29) </month> <year> 1993. </year>
Reference-contexts: Mondrian [in 2] is a graphical editor that can learn new composite commands by demonstration. DEMO [15,3] uses a stimulus-response paradigm for demonstrating the behavior of graphical objects. Chimera [8] infers constraints on the movement of objects given multiple snapshots. Finally , Marquise <ref> [11] </ref> uses domain knowledge in order to support building graphical editors. All of these systems use by-demonstration techniques but they are not easily compared because they have dif ferent goals and use different techniques. We make an attempt to classify them in Table 1 nevertheless. <p> Macro f Eager [1] 1991 Yes Prediction not applicable not applicable not applicable No Event Recording Macro DEMO [15,3] 1991/92 No Clarification Yes High Auxiliary Objects Yes (DEMO II) Compressed Snapshots Response Description Chimera g [8] 1991 No None c No High Auxiliary Objects h No Snapshots Two-Way Constraints Marquise <ref> [11] </ref> 1993 No (optional) Clarification Yes Low None c Yes Event Recording LISP Code Inference Bear 1995 No Script Display Yes Medium Motion Sensitive No Ev. Rec. and Snapshots Script (Transition) Table 1. Overview of Demonstrational Systems. firmation and clarification after each inference.
Reference: [12] <author> Brad Myers, Brad Vander Zanden, and Roger Dan-nenberg. </author> <title> Creating graphical interactive application objects by demonstration. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 95104, </pages> <address> (Williamsburg, VA, </address> <month> Nov. 13-15) </month> <year> 1989. </year>
Reference-contexts: PROGRAMMING BY DEMONSTRATION We shortly review related work on demonstrational systems. Peridot [10] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary <ref> [12] </ref> focuses on creating applicationspecific objects. Metamouse [9] learns graphical procedures by example. Druid [13] lets designers attach simple functionality to graphical user interfaces, such as enabling, disabling, hiding and showing buttons. Eager [1] watches users perform operations and detects and automates repetition. <p> Is Eager (Constantly Watches User) Interface Feedback about Inference Process Capabilities Run-time Object Instantiation Capabilities (Subjective) Strength in Geometric Relations Internals Search Space Reduction Internals Is Rule-Based Internals Temporary Behavior Storage Internals Inferencing Result Peridot [10] 1987 Yes Clarification Partially a Low Selecting (Optional) b Yes Snapshots One-Way Constraints Lapidary <ref> [12] </ref> 1989 No Clarification No Low None c No Snapshots One-Way Constraints Metamouse [9] 1989 Yes Clarification, Prediction Yes Medium Touch Sensitive d No Event Recording Graphical Procedure Druid e [13] 1990 No Clarificaton No not applicable None c No Event Recording Script Mondrian [in 2] 1991 Yes (in teach ing
Reference: [13] <author> Gurminder Singh, Chun Hong Kok, and Teng Ye Ngan. Druid: </author> <title> A system for demonstrational rapid user interface development. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 167177, </pages> <address> (Snowbird, UT, </address> <month> Oct. 3-5) </month> <year> 1990. </year>
Reference-contexts: PROGRAMMING BY DEMONSTRATION We shortly review related work on demonstrational systems. Peridot [10] supports designing scrollbars, buttons, choice boxes and similar objects by demonstration. Lapidary [12] focuses on creating applicationspecific objects. Metamouse [9] learns graphical procedures by example. Druid <ref> [13] </ref> lets designers attach simple functionality to graphical user interfaces, such as enabling, disabling, hiding and showing buttons. Eager [1] watches users perform operations and detects and automates repetition. Mondrian [in 2] is a graphical editor that can learn new composite commands by demonstration. <p> Storage Internals Inferencing Result Peridot [10] 1987 Yes Clarification Partially a Low Selecting (Optional) b Yes Snapshots One-Way Constraints Lapidary [12] 1989 No Clarification No Low None c No Snapshots One-Way Constraints Metamouse [9] 1989 Yes Clarification, Prediction Yes Medium Touch Sensitive d No Event Recording Graphical Procedure Druid e <ref> [13] </ref> 1990 No Clarificaton No not applicable None c No Event Recording Script Mondrian [in 2] 1991 Yes (in teach ing mode) Synthesized Speech Yes Medium None c Yes Event Recording Macro f Eager [1] 1991 Yes Prediction not applicable not applicable not applicable No Event Recording Macro DEMO [15,3] 1991/92
Reference: [14] <author> Piyawadee Sukaviriya, James Foley, and Todd Grif-fith. </author> <title> A second generation user interface design environment: The model and the runtime architecture. </title> <booktitle> In Proceedings of INTERCHI, ACM Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 375382, </pages> <address> (Amsterdam, The Netherlands, </address> <month> Apr. 24-29) </month> <year> 1993. </year>
Reference-contexts: The Expression Finders tentative user interface is shown in Figure 8. All the transitions in the preceding four examples are highly specific to their particular user interfaces. In the second-generation User Interface Design Environment <ref> [14] </ref>, functionality at this level is captured in the interface model. UIDE offers an optional higher level of abstraction which is called the application model. It consists of the same data de scr iption and c ontrol descr iption construc ts a s the lower-level interface model (elements and transitions).
Reference: [15] <author> David Wolber and Gene Fisher. </author> <title> A demonstrational technique for developing interfaces with dynamically created objects. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 221230, </pages> <address> (Hilton Head, SC, </address> <month> Nov. 11-13) </month> <year> 1991. </year>
Reference-contexts: Peridot [10] uses a simulated mouse which is a window depicting a mouse including the state of its buttons. The system can then use the state and position of the simulated mouse, freeing the real mouse for metalevel commands. DEMO <ref> [15] </ref> always records a press event and then asks the user whether she really meant press or one of three other event types (release, enter and leave in our terminology).
References-found: 15

