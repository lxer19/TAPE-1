URL: ftp://ftp.cs.orst.edu/pub/tgd/papers/tr-calibration.ps.gz
Refering-URL: http://www.cs.orst.edu/~tgd/cv/pubs.html
Root-URL: 
Title: A Divide-and-Conquer Approach to Learning from Prior Knowledge  
Author: Eric Chown Thomas G. Dietterich 
Date: February 27, 1998  
Address: Corvallis, OR 97331-3202  
Affiliation: Department of Computer Science Oregon State University,  
Abstract: This paper introduces a new machine learning task|model calibration|and presents a method for solving a particularly difficult model calibration task that arose as part of a global climate change research project. The model calibration task is the problem of training the free parameters of a scientific model in order to optimize the accuracy of the model for making future predictions. It is a form of supervised learning from examples in the presence of prior knowledge. An obvious approach to solving calibration problems is to formulate them as global optimization problems in which the goal is to find values for the free parameters that minimize the error of the model on training data. Unfortunately, this global optimization approach becomes computationally infeasible when the model is highly nonlinear. This paper presents a new divide-and-conquer method that analyzes the model to identify a series of smaller optimization problems whose sequential solution solves the global calibration problem. This paper argues that methods of this kind|rather than global optimization techniques|will be required in order for agents with large amounts of prior knowledge to learn efficiently. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bertsekas, D. P., & Rhodes, I. B. </author> <year> (1971). </year> <title> Recursive state estimation for a set-membership description of uncertainty. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-16 (2), </volume> <pages> 117-128. </pages>
Reference: <author> Brent, R. P. </author> <year> (1973). </year> <title> Algorithms for Minimization without Derivatives. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: We tried computing the gradient numerically, but gradient descent was unable to make much progress in reducing J from good starting points. Next, we investigated Powell's method <ref> (Brent, 1973) </ref>. This is a search technique that can be applied when no gradient information is available, and it is more efficient that standard gradient descent with numerically-computed gradients. Unfortunately, it behaved the same as gradient descent. It was unable to make much progress in minimizing J .
Reference: <author> Clark, P., & Matwin, S. </author> <year> (1993). </year> <title> Using qualitative models to guide inductive learning. </title> <booktitle> In Machine Learning: Proceedings of the Tenth International Conference, </booktitle> <pages> pp. </pages> <address> 49-56 San Francisco, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Cohen, W. W. </author> <year> (1992). </year> <title> Compiling prior knowledge into an explicit bias. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pp. </pages> <address> 102-110 San Francisco, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Combettes, P. L. </author> <year> (1993). </year> <title> The foundations of set theoretic estimation. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81 (2), </volume> <pages> 182-208. </pages>
Reference: <author> Deller, J. R., Nayeri, M., & Odeh, S. F. </author> <year> (1993). </year> <title> Least-square identificatioin with error bounds for real-time signal processing and control. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81 (6). </volume>
Reference: <author> Dempster, A. P., Laird, N. M., & Rubin, D. B. </author> <year> (1976). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Proceedings of the Royal Statistical Society, B, </journal> <volume> 39, </volume> <pages> 1-38. </pages>
Reference-contexts: For example, in the code from Table 2, the value of Drain_rate can determine whether the condition of the second if statement is satisfied. How can we solve this problem? A natural approach is to use an EM-style algorithm <ref> (Dempster, Laird, & Rubin, 1976) </ref>. An EM approach would start with an initial value for the unknown parameters fi. It would then take each training example and compute the probability that that example belonged to each path (the "E-step").
Reference: <author> Futamura, Y. </author> <year> (1971). </year> <title> Partial evaluation of computation process|an approach to a compiler-compiler. </title> <journal> Systems, Computers, Controls, </journal> <volume> 2 (5), </volume> <pages> 45-50. </pages>
Reference-contexts: The evaluator takes as input the declarative-MAPSS code, a list of known parameters, and a threshold M specifying the maximum number of relevant unknown parameters that a path can contain. The partial evaluator then symbolically evaluates the program <ref> (Futamura, 1971) </ref>. An assignment statement is processed by storing its value in the symbol table and by analyzing the expression to determine whether it contains any new unknown parameters. If so, these unknown parameters are added to the set of unknown parameters for the current path.
Reference: <author> Hirsh, H. </author> <year> (1994). </year> <title> Generalizing version spaces. </title> <journal> Machine Learning, </journal> <volume> 17, </volume> <pages> 5-46. </pages>
Reference: <author> Ingber, L. </author> <year> (1995). </year> <title> Adaptive simulated annealing [software package]. </title> <type> Tech. rep., </type> <institution> California Institute of Technology, </institution> <note> http://alumni.caltech.edu/~ingber/. </note>
Reference: <author> Klepper, O., & Hendrix, E. M. T. </author> <year> (1994). </year> <title> A method for robust calibration of ecological models under different types of uncertainty. </title> <journal> Ecological Modelling, </journal> <volume> 74, </volume> <pages> 161-182. </pages>
Reference: <author> Neilson, R. P. </author> <year> (1995). </year> <title> A model for predicting continental scale vegetation distribution and water balance. </title> <journal> Ecological Applications, </journal> <volume> 5, </volume> <pages> 362-385. </pages>
Reference-contexts: In this paper, we describe an approach to automating the calibration of a very complex global vegetation model called MAPSS <ref> (Mapped Atmosphere-Plant-Soil System, Neilson, 1995) </ref>. We show that standard ideas from machine learning are not able to scale up to handle this problem. Then we present a new divide-and-conquer approach to model calibration.
Reference: <author> Pazzani, M., & Kibler, D. </author> <year> (1992). </year> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 57-94. </pages>
Reference-contexts: Over the past two decades, many methods have been developed. It is important to realize, however, that most of these pursue the global search approach. Take FOCL <ref> (Pazzani & Kibler, 1992) </ref>, for example.
Reference: <author> Towell, G. G., Shavlik, J. W., & Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence Menlo Park, </booktitle> <address> CA. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: predicates) guides a FOIL-like algorithm for growing a set of decision rules. 10 Table 6: Calibration Progress of Saturated Drainage Parameters Iteration Deep1 Deep2 Mid1 Mid2 Top1 Top2 1 3 5 7 0.849 11.447 Target 0.80 10.00 0.80 3.00 0.50 1.0 Range 0-1 1-20 0-1 1-5 0-1 0.5-3 In KBANN <ref> (Towell, Shavlik, & Noordewier, 1990) </ref>, a fixed neural network structure constrains a gradient descent search. In the work of Clark and Matwin (1993), a qualitative process model constrains a rule-learning algorithm. In Cohen's (1992) work, a grammar constrains the space of horn-clause theories.
Reference: <author> Williams, B. C., & Millar, B. </author> <year> (1996). </year> <title> Automated decomposition of model-based learning problems. In Qualitative Reasoning: </title> <booktitle> The Tenth International Workshop, </booktitle> <pages> pp. </pages> <address> 265-273 Cambridge, MA. </address> <publisher> AAAI Press/MIT Press. </publisher> <pages> 12 </pages>
References-found: 15

