URL: http://www.cse.psu.edu/~barlow/svd-update.ps
Refering-URL: http://www.cse.psu.edu/~barlow/papers.html
Root-URL: http://www.cse.psu.edu
Title: STABLE CHASING ALGORITHMS FOR MODIFYING THE SINGULAR VALUE DECOMPOSITION  
Author: JESSE L. BARLOW HONGYUAN ZHA AND PETER A. YOON 
Keyword: schemes. Key words. singular value decomposition, partial singular value decomposition, bidiagonal form, updating, downdating, stability  
Note: An error analysis is presented which shows that this property leads to more accurate chasing  AMS(MOS) subject classifications. primary 15A18, 15A21, 65F15; secondary 62H20  
Abstract: Methods for updating and downdating singular value decompositions (SVDs) are introduced. The algorithms can be extended to partially reduced bidiagonal forms (partial SVDs). and are based upon chasing procedures for updating the SVD and downdating procedures for orthogonal decompositions. The main feature of these methods is the ability to separate the singular values into "large" and "small" sets and then obtain an updated bidiagonal form with corresponding "large" and "small" columns. This makes for a more accurate update or downdate. 1. Introduction. We discuss methods for updating and downdating two different types of complete orthogonal decomposition of an m fi n matrix A where m n. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Abdallah and Y. Hu. </author> <title> Parallel VLSI computing array implementation for signal subspace updating algorithm. </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> ASSP-37:742-748, </volume> <year> 1989. </year>
Reference-contexts: B B @ 0 fl 2 OE 2 0 fl n1 OE n1 1 C C C C : We may also use the MATLAB-like shorthand B = bidiag (fl (1 : n); OE (1 : n 1)): Our approaches to downdating the decompositions (1.2)-(1.3) use ideas from "chasing" algorithms <ref> [25, 1, 28, 20] </ref>. A systolic array implementation of a scheme with similar data movement patterns to this one (but not similar numerical properties) is implemented in [21]. <p> The use of this perturbation theory shows that we should expect accurate singular subspaces associated with "large" and "small" sets of singular values. Thus we see potential use of these algorithms in subspace tracking because of the possibility of systolic array implementation <ref> [1, 21] </ref>. Acknowledgement. Dr. Zhenyue Zhang made his helpful suggestions that improved this paper.
Reference: [2] <author> J.L. Barlow. </author> <title> Error analysis of update methods for the symmetric eigenvalue problem. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 14 </volume> <pages> 598-618, </pages> <year> 1993. </year>
Reference-contexts: The alternative to our approach is that of finding the zeroes of a particular spectral function <ref> [15, 7, 23, 26, 2, 18, 17] </ref>. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper.
Reference: [3] <author> J.L. Barlow and J.W. Demmel. </author> <title> Computing accurate eigensystems of scaled diagonally dominant matrices. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 27 </volume> <pages> 762-791, </pages> <year> 1990. </year>
Reference-contexts: This form preserves more of the accuracy of the small singular values and is not achieved by standard chasing procedures. We can then use one of several algorithms to find the singular values of the bidiagonal matrix B <ref> [10, 3, 13] </ref>. The singular vector matrices can be modified by a procedure due to Gu and Eisenstat [18] in O (mn) operations (the constant on mn depends upon machine precision). <p> From <ref> [10, 3] </ref> this relative change in the entries of the bidiagonal matrix makes only relative changes in the singular values. Thus this update procedure is very stable. Proposition 3.2.
Reference: [4] <author> J.L. Barlow, P.A. Yoon, and H. Zha. </author> <title> An algorithm and a stability theory for downdating the ULV decomposition. </title> <type> Technical Report CSE-95-010, </type> <institution> Department of Computer Science and Engineering, The Pennsylvania State University, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Same as step 3 of Algorithm 2.2. Thus we have simple algorithms to perform either an update or downdate. The downdating procedure has the following two consistency properties. This is the same as a consistency property discussed by the authors for a ULV downdating method <ref> [4, Propostion 3.2] </ref>, since it is essentially the same procedure applied to the 2 fi 2 matrix in step three. 2.4. Extensions to Partially Reduced Bidiagonal Forms.
Reference: [5] <author> A. Bjorck. </author> <title> Stability analysis of the method of semi-normal equations for linear least squares problems. </title> <journal> Lin. Alg. Appl., </journal> 88/89:31-48, 1987. 
Reference-contexts: One possible remedy, is to try to obtain a better value for x = V T 1 A T e 1 . That can be done using the corrected semi-normal equations <ref> [5, 6] </ref>.
Reference: [6] <author> A. Bjorck, H. Park, and L. Elden. </author> <title> Accurate downdating of least squares solutions. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 15 </volume> <pages> 549-568, </pages> <year> 1994. </year>
Reference-contexts: One possible remedy, is to try to obtain a better value for x = V T 1 A T e 1 . That can be done using the corrected semi-normal equations <ref> [5, 6] </ref>. <p> This is similar to the approach taken in <ref> [6] </ref>. The CSNE approach was used in all three examples and most extensively in Example 3 when downdating a row with an outlier. However, the performance of our algorithm was less satisfactory for the larger outlier. 5. Conclusion.
Reference: [7] <author> J.R. Bunch and C.P. Nielsen. </author> <title> Updating the singular value decomposition. </title> <journal> Numerical Mathe-matik, </journal> <volume> 31 </volume> <pages> 111-129, </pages> <year> 1978. </year>
Reference-contexts: The alternative to our approach is that of finding the zeroes of a particular spectral function <ref> [15, 7, 23, 26, 2, 18, 17] </ref>. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper.
Reference: [8] <author> J. Carrier, L. Greengard, and V. Rokhlin. </author> <title> A fast adaptive multipole algorithm for particle simulation. </title> <journal> SIAM J. Sci. Stat. Computing, </journal> <volume> 9 </volume> <pages> 669-685, </pages> <year> 1988. </year>
Reference-contexts: A recent result of Gu and Eisenstat [18] show that if we keep B in diagonal form, in theory, the vectors can be updated in O (n 2 ) flops using the adaptive fast multipole algorithm of Carrier et al. <ref> [8] </ref>. However, this procedure is slower than most O (n 3 ) updating procedures until n 1000. There are contexts where updating a "partial SVD" would be helpful [22]. 3. Error analysis. 3.1. Error Bounds for Blockwise Algorithms for the SVD.
Reference: [9] <author> J.W. Demmel and W.B. Gragg. </author> <title> On computing accurate singular values and eigenvalues of matrices with acyclic graphs. </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 185 </volume> <pages> 203-217, </pages> <year> 1993. </year>
Reference-contexts: The alternative to our approach is that of finding the zeroes of a particular spectral function [15, 7, 23, 26, 2, 18, 17]. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper. Demmel and Gragg <ref> [9] </ref> have given a bisection technique that will find the singular values for the updating problem (but not the downdating problem) to relative accuracy. There are five sections after this introductory one. In section two we give some basic chasing procedures for modifying the SVD.
Reference: [10] <author> J.W. Demmel and W.H. Kahan. </author> <title> Accurate singular values of bidiagonal matrices. </title> <journal> SIAM J. Sci. Stat. Computing, </journal> <volume> 11 </volume> <pages> 873-912, </pages> <year> 1990. </year>
Reference-contexts: This form preserves more of the accuracy of the small singular values and is not achieved by standard chasing procedures. We can then use one of several algorithms to find the singular values of the bidiagonal matrix B <ref> [10, 3, 13] </ref>. The singular vector matrices can be modified by a procedure due to Gu and Eisenstat [18] in O (mn) operations (the constant on mn depends upon machine precision). <p> # r r r ^r r r r 0 0 0 0 x ! r r r r =) 0 0 0 0 x ^r r r r r =) r r r r r MODIFYING THE SVD AND PARTIAL SVD 12 Thus, using algorithms such as the zero-shift QR <ref> [10] </ref> or the qd algorithm [13], it is possible to find the singular values that are below a certain threshold, and thus obtain a partially bidiagonal matrix of the form (1.3). <p> From <ref> [10, 3] </ref> this relative change in the entries of the bidiagonal matrix makes only relative changes in the singular values. Thus this update procedure is very stable. Proposition 3.2.
Reference: [11] <author> J.W. Demmel and K. Veselic. </author> <title> Jacobi's method is more accurate than QR. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 </volume> <pages> 1204-1243, </pages> <year> 1992. </year>
Reference-contexts: In step j, the row p + j of the observation matrix is added and the row j is deleted, giving the data matrix A (j) . The one-sided Jacobi method <ref> [11] </ref> was used to compute the SVD of the initial window matrix A (0) = U (0) B (0) V (0) T , which consists of the first p rows of A, and to compare with our algorithms for rank estimation and the accuracy of the subspaces.
Reference: [12] <author> S.C. Eisenstat and I.C.F. Ipsen. </author> <title> Relative perturbation techniques for singular value problems. </title> <type> Technical Report YALEU/DCS/RR-942, </type> <institution> Department of Computer Science, Yale University, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: The componentwise backward error ffi B 0 in Proposition 3.1 has a very small effect on the error in the subspaces which follows from this result from Ipsen and Eisenstat <ref> [12, Corollary 4.5] </ref>. For completeness the result is given below. Proposition 3.3. [12, Corollary 4.5] Let B = bidiag (fl 1 ; : : : ; fl n ; OE 1 ; : : : ; OE n1 )(3.36) and let ~ B = bidiag (ff 1 fl 1 ; : <p> The componentwise backward error ffi B 0 in Proposition 3.1 has a very small effect on the error in the subspaces which follows from this result from Ipsen and Eisenstat <ref> [12, Corollary 4.5] </ref>. For completeness the result is given below. Proposition 3.3. [12, Corollary 4.5] Let B = bidiag (fl 1 ; : : : ; fl n ; OE 1 ; : : : ; OE n1 )(3.36) and let ~ B = bidiag (ff 1 fl 1 ; : : : ; ff n fl n ; ff n+1 OE 1
Reference: [13] <author> K.V. Fernando and B.N. Parlett. </author> <title> Accurate singular values and differential QD algorithms. </title> <type> Technical Report PAM-554, </type> <institution> Center for Pure and Applied Mathematics, University of Cal-ifornia, Berkeley, </institution> <address> CA, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Note that it is always possible to determine k B 1 1 k for a bidiagonal matrix from the bound k B 1 1 k q 1 k 1 k B 1 1 k 1 <ref> [13] </ref>. We use k k to denote the Euclidean norm and k k F to denote the Frobenius norm. For (1.2) we presume oe k tol where tol is some user defined tolerence. The form (1.2) is the familiar singular value decomposition (SVD). <p> This form preserves more of the accuracy of the small singular values and is not achieved by standard chasing procedures. We can then use one of several algorithms to find the singular values of the bidiagonal matrix B <ref> [10, 3, 13] </ref>. The singular vector matrices can be modified by a procedure due to Gu and Eisenstat [18] in O (mn) operations (the constant on mn depends upon machine precision). <p> r r r 0 0 0 0 x ! r r r r =) 0 0 0 0 x ^r r r r r =) r r r r r MODIFYING THE SVD AND PARTIAL SVD 12 Thus, using algorithms such as the zero-shift QR [10] or the qd algorithm <ref> [13] </ref>, it is possible to find the singular values that are below a certain threshold, and thus obtain a partially bidiagonal matrix of the form (1.3).
Reference: [14] <author> P.E. Gill, G.H. Golub, W. Murray, and M.A. Saunders. </author> <title> Methods for modifying matrix factor MODIFYING THE SVD AND PARTIAL SVD 21 izations. </title> <journal> Math. Comp., </journal> <volume> 28 </volume> <pages> 505-535, </pages> <year> 1974. </year>
Reference-contexts: Otherwise, the algorithm proceeds in a similar manner to Algorithm 2.2. First, we do the reductions (2.12)-(2.15) to produce B (1) i ; ae i , i = 1; 2 as before. We then perform a 2 fi 2 downdate using Saunders's algorithm <ref> [14] </ref>. This is done as follows. Set a 1 = ae 1 =fl k :(2.31) We note that ja 1 j =k B 1 1 x k=k s k, thus B 1 can be downdated by x if and only if ja 1 j 1.
Reference: [15] <author> G.H. Golub. </author> <title> Some modified matrix eigenvalue problems. </title> <journal> SIAM Review, </journal> <volume> 15 </volume> <pages> 318-344, </pages> <year> 1973. </year>
Reference-contexts: The alternative to our approach is that of finding the zeroes of a particular spectral function <ref> [15, 7, 23, 26, 2, 18, 17] </ref>. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper.
Reference: [16] <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations, Second Edition. </title> <publisher> The Johns Hopkins Press, </publisher> <address> Baltimore, </address> <year> 1989. </year>
Reference-contexts: The horizontal axis represents the window steps and the vertical axis the numerical rank of the window matrix. Let W (j) and V (j) be the right singular vector matrices computed by the Jacobi method and our algorithms, respectively. Then, using the algorithm described in <ref> [16] </ref>, the angles between the subspaces can be computed as sin = kW 1 V 2 k where W (j) = (W (j) (j) (j) (j) 2 ). We plot log 10 sin in the second plot of each figure.
Reference: [17] <author> W.B. Gragg, J.R. Thorton, </author> <title> and D.D. Warner. Parallel divide and conquer algorithms for the symmetric tridiagonal eigenproblem and bidiagonal singular value problem. </title> <type> Technical report, </type> <institution> Department of Mathematics, Naval Postgraduate School, </institution> <address> Monterey, CA, </address> <year> 1992. </year>
Reference-contexts: The alternative to our approach is that of finding the zeroes of a particular spectral function <ref> [15, 7, 23, 26, 2, 18, 17] </ref>. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper.
Reference: [18] <author> M. Gu and S.C. Eisenstat. </author> <title> A stable and efficient algorithm for the rank-one modification of the symmetric eigenproblem. </title> <type> Technical Report YALEU/DCS/RR-916, </type> <institution> Department of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: We can then use one of several algorithms to find the singular values of the bidiagonal matrix B [10, 3, 13]. The singular vector matrices can be modified by a procedure due to Gu and Eisenstat <ref> [18] </ref> in O (mn) operations (the constant on mn depends upon machine precision). MODIFYING THE SVD AND PARTIAL SVD 3 * A perturbation theory for the singular subspaces from downdated matrices and blockwise error bounds for the above procedures. <p> The alternative to our approach is that of finding the zeroes of a particular spectral function <ref> [15, 7, 23, 26, 2, 18, 17] </ref>. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper. <p> A recent result of Gu and Eisenstat <ref> [18] </ref> show that if we keep B in diagonal form, in theory, the vectors can be updated in O (n 2 ) flops using the adaptive fast multipole algorithm of Carrier et al. [8]. However, this procedure is slower than most O (n 3 ) updating procedures until n 1000.
Reference: [19] <author> S. Van Huffel. </author> <title> Analysis of the Total Least Squares Problem and its Use in Parameter Estimation. </title> <type> PhD thesis, </type> <institution> Katholieke Unvisiteit Leuven, Leuven, Belguim, </institution> <year> 1987. </year>
Reference-contexts: For (1.2) we presume oe k tol where tol is some user defined tolerence. The form (1.2) is the familiar singular value decomposition (SVD). The form (1.3) is a special case of the partial singular value decomposition (partial SVD) described by Van Huffel <ref> [22, 19] </ref>. fl Department of Computer Science and Engineering, The Pennsylvania State University, University Park, PA 16802-6106. e-mail: barlow@cse.psu.edu, zha@cse.psu.edu. The research of Jesse L. Barlow and Hongyuan Zha was supported by the National Science Foundation under grant no. CCR-9201612 (Barlow) and grant no.
Reference: [20] <author> S. Van Huffel and H. Park. </author> <title> Efficient reduction algorithms for bordered band matrices. </title> <type> Technical report, </type> <institution> ESAT Laboratory, Katholieke Universiteit Leuven, Leuven, Belgium, </institution> <year> 1992. </year>
Reference-contexts: B B @ 0 fl 2 OE 2 0 fl n1 OE n1 1 C C C C : We may also use the MATLAB-like shorthand B = bidiag (fl (1 : n); OE (1 : n 1)): Our approaches to downdating the decompositions (1.2)-(1.3) use ideas from "chasing" algorithms <ref> [25, 1, 28, 20] </ref>. A systolic array implementation of a scheme with similar data movement patterns to this one (but not similar numerical properties) is implemented in [21]. <p> Extensions to Partially Reduced Bidiagonal Forms. Algorithms 2.2 and 2.3 can be easily extended to the case where either B 1 or B 2 is bidiagonal as long as they are decoupled. We need only modify step 1 and note from Van Huffel and Park <ref> [20] </ref> that there are chasing algorithms that will take a k fi k B 1 upper bidiagonal and produce U 1 and V 1 such that U T 1 B 1 V 1 = ^ B 1 upper bidiagonal V T Below we show how such an algorithm would work on
Reference: [21] <author> S. Van Huffel and H. Park. </author> <title> Parallel tri- and bi-diagonalization of bordered bi-diagonal matrices. </title> <type> Techinical Report 93-024, </type> <institution> Army High Performance Computing Research Center, University of Minnesota, Minneapolis, MN, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: A systolic array implementation of a scheme with similar data movement patterns to this one (but not similar numerical properties) is implemented in <ref> [21] </ref>. <p> The use of this perturbation theory shows that we should expect accurate singular subspaces associated with "large" and "small" sets of singular values. Thus we see potential use of these algorithms in subspace tracking because of the possibility of systolic array implementation <ref> [1, 21] </ref>. Acknowledgement. Dr. Zhenyue Zhang made his helpful suggestions that improved this paper.
Reference: [22] <author> S. Van Huffel and J. Vandewalle. </author> <title> The Total Least Squares Problem: Computational Aspects and Analysis. </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference-contexts: For (1.2) we presume oe k tol where tol is some user defined tolerence. The form (1.2) is the familiar singular value decomposition (SVD). The form (1.3) is a special case of the partial singular value decomposition (partial SVD) described by Van Huffel <ref> [22, 19] </ref>. fl Department of Computer Science and Engineering, The Pennsylvania State University, University Park, PA 16802-6106. e-mail: barlow@cse.psu.edu, zha@cse.psu.edu. The research of Jesse L. Barlow and Hongyuan Zha was supported by the National Science Foundation under grant no. CCR-9201612 (Barlow) and grant no. <p> However, this procedure is slower than most O (n 3 ) updating procedures until n 1000. There are contexts where updating a "partial SVD" would be helpful <ref> [22] </ref>. 3. Error analysis. 3.1. Error Bounds for Blockwise Algorithms for the SVD. We now give error bounds for the process of one update or downdate using the procedures in section three. All of the matrices below are computed except those with ffi in front of them.
Reference: [23] <author> E. R. Jessup and D.C. Sorensen. </author> <title> A parallel algorithm for computing the singular value decomposition of a matrix. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 15 </volume> <pages> 530-548, </pages> <year> 1994. </year>
Reference-contexts: The alternative to our approach is that of finding the zeroes of a particular spectral function <ref> [15, 7, 23, 26, 2, 18, 17] </ref>. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper.
Reference: [24] <author> C.L. Lawson, R.J. Hanson, D.R. Kincaid, and F.T. Krogh. </author> <title> Basic linear algebra subprogams for FORTRAN usage. </title> <journal> ACM Trans. Math. Soft., </journal> <volume> 5 </volume> <pages> 308-25, </pages> <year> 1979. </year>
Reference-contexts: Large elements can creep down into the lower part of the bidiagonal matrix ^ B. For quantitative reasons we formally write the algorithm below. We use the BLAS <ref> [24] </ref> conventions of defining the procedure rotg (a,b,cn,sn) as one that generates a Givens rotation from the 2-vector (a; b) T such that sn cn a 0 ; cn 2 + sn 2 = 1; MODIFYING THE SVD AND PARTIAL SVD 5 We also define the procedure rot (cn,sn,a,b) that rotates
Reference: [25] <author> H. </author> <title> Rutishauser. On Jacobi rotation patterns. </title> <booktitle> In Experimental Arithmetic, </booktitle> <pages> pages 219-239, </pages> <address> Providence, RI, </address> <year> 1963. </year> <journal> Amer. Math. Soc. </journal>
Reference-contexts: B B @ 0 fl 2 OE 2 0 fl n1 OE n1 1 C C C C : We may also use the MATLAB-like shorthand B = bidiag (fl (1 : n); OE (1 : n 1)): Our approaches to downdating the decompositions (1.2)-(1.3) use ideas from "chasing" algorithms <ref> [25, 1, 28, 20] </ref>. A systolic array implementation of a scheme with similar data movement patterns to this one (but not similar numerical properties) is implemented in [21].
Reference: [26] <author> D.C. Sorensen and P.T. Tang. </author> <title> On the orthogonality of eigenvectors computed by the divide-and-conquer techniques. </title> <journal> SIAM J. Num. Anal., </journal> <volume> 28 </volume> <pages> 1752-1775, </pages> <year> 1991. </year>
Reference-contexts: The alternative to our approach is that of finding the zeroes of a particular spectral function <ref> [15, 7, 23, 26, 2, 18, 17] </ref>. That approach, as yet, does not allow us to separate the singular values into separate blocks in the manner discussed in this paper.
Reference: [27] <author> J.H. Wilkinson. </author> <title> The Algebraic Eigenvalue Problem. </title> <publisher> Oxford University Press, </publisher> <address> London, </address> <year> 1965. </year>

References-found: 27

