URL: http://www.pdos.lcs.mit.edu/papers/tcc-pldi97.ps
Refering-URL: http://www.pdos.lcs.mit.edu/PDOS-papers.html
Root-URL: 
Email: kaashoekg@lcs.mit.edu  
Title: tcc: A System for Fast, Flexible, and High-level Dynamic Code Generation  
Author: Massimiliano Poletto, Dawson R. Engler, and M. Frans Kaashoek fmaxp, engler, 
Address: Cambridge, MA 02139  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: tcc is a compiler that provides efficient and high-level access to dynamic code generation. It implements the `C (Tick-C) programming language, an extension of ANSI C that supports dynamic code generation [15]. `C gives power and flexibility in specifying dynamically generated code: whereas most other systems use annotations to denote run-time invariants, `C allows the programmer to specify and compose arbitrary expressions and statements at run time. This degree of control is needed to efficiently implement some of the most important applications of dynamic code generation, such as just in time compilers [17] and efficient simulators [10, 48, 46]. The paper focuses on the techniques that allow tcc to provide `C's flexibility and expressiveness without sacrificing run-time code generation efficiency. These techniques include fast register allocation, efficient creation and composition of dynamic code specifications, and link-time analysis to reduce the size of dynamic code generators. tcc also implements two different dynamic code generation strategies, designed to address the tradeoff of dynamic compilation speed versus generated code quality. To characterize the effects of dynamic compilation, we present performance measurements for eleven programs compiled using tcc. On these applications, we measured performance improvements of up to one order of magnitude. To encourage further experimentation and use of dynamic code generation, we are making the tcc compiler available in the public domain. This is, to our knowledge, the first high-level dynamic compilation system to be made available. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Auslander, M. Philipose, C. Chambers, S. Eggers, and B. Bershad. </author> <title> Fast, effective dynamic compilation. </title> <booktitle> In Proceedings of the SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 149-159, </pages> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: On one side, annotation-driven approaches allow the programmer to communicate high-level hints about run-time invariants to the compiler, but provide relatively limited code specification This research was supported in part by the Advanced Research Projects Agency under contracts N00014-94-1-0985 and N66001-96-C-8522, and by a NSF National Young Investigator Award. flexibility <ref> [1, 11, 32] </ref>. On the other, library-based approaches allow flexible specification of code, but require programmers to work with a low-level representation [14, 19]. <p> No performance data is provided for Tempo, so it is difficult to compare the two implementations. The dynamic compilation project at the University of Wash-ington also uses automatic compiler support for detecting run-time constants <ref> [1] </ref>. Their compiler employs programmer annotations to indicate some run-time constants; the compiler computes what variables are derived run-time constants. <p> One way to generate good code with low overhead is to structure the system so that most optimizations can be performed statically <ref> [1, 11, 32] </ref>, but in all existing systems this ability comes at the expense of language flexibility and expressiveness (furthermore, in practice, only Leone and Lee [32] appear to generate code more quickly than tcc). `C, by contrast, allows the user to dynamically compose arbitrary pieces of code, which makes static <p> Our current implementation does not propagate run-time constant information to discover additional run-time constants in a fully general manner, as done in <ref> [1] </ref>. This restriction is mostly an engineering problem, since there is little framework for performing relaxation analyses at static compile time within lcc. As an example of these optimizations, consider writing code that computes the dot-product of a vector col with a run-time constant vector row.
Reference: [2] <author> B. N. Bershad, S. Savage, P. Pardyak, E. G. Sirer, M. Fiuczynski, D. Becker, S. Eggers, and C. Chambers. </author> <title> Extensibility, safety and performance in the SPIN operating system. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 267-284, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: We discuss the basic architecture of tcc in Section 4, details of its code generation strategies in Section 5, and experimental results in Section 6. 2 Related Work Dynamic code generation has a long history [29]. It has been used to increase the performance of operating systems <ref> [2, 16, 39, 40] </ref>, windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [3] <author> A. D. Birrell and B. J. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: This is a powerful feature. For instance, it allows the construction of code to marshal and unmarshal arguments stored in a byte vector, operations frequently performed to support remote procedure call <ref> [3] </ref>. By generating specialized code for the most active functions it is possible to gain substantial performance benefits [44]. Our two benchmarks, mshl and umshl, dynamically generate marshaling and unmarshaling code, respectively, given a printf-style format string specifying the types of arguments.
Reference: [4] <author> J. Bradley. xv-3.10. </author> <month> ftp://ftp.cis.upenn.edu. </month>
Reference-contexts: They have been chosen to highlight different styles of dynamic code generation use. Many of them are fully described (but not measured) in [15]. We also describe modifications made to xv <ref> [4] </ref>, a relatively sophisticated share-ware image manipulation package, to exploit dynamic code generation, and the resulting performance benefits. Run-time constants. Dynamic code generation can be used to hardwire infrequently changing values into the instruction stream.
Reference: [5] <author> D. Callahan and B. Koblenz. </author> <title> Register allocation via hierarchical graph coloring. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(6) </volume> <pages> 192-203, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: In addition to this register allocator, we also provide a Chaitin-style graph-coloring register allocator [6]. This register allocation technique is not new: it has been studied and optimized extensively <ref> [5, 8, 25, 34] </ref>, performs well in many cases, and is simple to implement. As a result, it is a good means of evaluating our simpler and faster register allocation algorithm. Emitting code.
Reference: [6] <author> G. J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <journal> SIGPLAN Notices, </journal> <volume> 17(6) </volume> <pages> 201-207, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: In addition to this register allocator, we also provide a Chaitin-style graph-coloring register allocator <ref> [6] </ref>. This register allocation technique is not new: it has been studied and optimized extensively [5, 8, 25, 34], performs well in many cases, and is simple to implement. As a result, it is a good means of evaluating our simpler and faster register allocation algorithm. Emitting code.
Reference: [7] <author> C. Chambers and D. Ungar. </author> <title> Customization: Optimizing compiler technology for SELF, a dynamically-typed object-oriented programming language. </title> <booktitle> In Proceedings of PLDI '89, </booktitle> <pages> pages 146-160, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages <ref> [7, 12, 26] </ref>, and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [8] <author> F. C. Chow and J. L. Hennessy. </author> <title> Register allocation by priority-based coloring. </title> <journal> SIGPLAN Notices, </journal> <volume> 19(6) </volume> <pages> 222-232, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: In addition to this register allocator, we also provide a Chaitin-style graph-coloring register allocator [6]. This register allocation technique is not new: it has been studied and optimized extensively <ref> [5, 8, 25, 34] </ref>, performs well in many cases, and is simple to implement. As a result, it is a good means of evaluating our simpler and faster register allocation algorithm. Emitting code.
Reference: [9] <author> D. D. Clark and D. L. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In ACM Communication Architectures, Protocols, and Applications (SIGCOMM) 1990, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: This functionality is analogous to being able to dynamically inline the code referenced by arbitrary function pointers. Networking code is one important application of this type of composition. The networking community has long aimed to modularly compose protocol layers <ref> [9] </ref>. Each protocol layer frequently involves data manipulation operations (e.g., checksumming, byte-swapping, etc.). Since performing multiple data manipulation passes is expensive, it is desirable to compose the layers so that all the data handling occurs in one phase [9]. This modular composition of data operations is an active research area. <p> The networking community has long aimed to modularly compose protocol layers <ref> [9] </ref>. Each protocol layer frequently involves data manipulation operations (e.g., checksumming, byte-swapping, etc.). Since performing multiple data manipulation passes is expensive, it is desirable to compose the layers so that all the data handling occurs in one phase [9]. This modular composition of data operations is an active research area. The two main limitations of current approaches to this problem are that they use specialized languages and, with the exception of work using VCODE [14], they are static, in that passes cannot be built at run time.
Reference: [10] <author> R. F. Cmelik and D. Keppel. Shade: </author> <title> A fast instruction-set simulator for execution profiling. </title> <booktitle> In Proceedings of the 1994 ACM SIG-METRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 128-137, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: This code specification flexibility is necessary to efficiently implement some of the most profitable applications of dynamic code generation, such as just in time compilers [17] and efficient simulators <ref> [10, 48, 46] </ref>, which require the composition of arbitrary statements and expressions and the creation of routines with statically-unknown type signatures. tcc aims to provide the ease of specifying dynamic code at a high level while retaining the flexibility and expressiveness of low-level systems. tcc compiles the `C programming language, an
Reference: [11] <author> C. Consel and F. Noel. </author> <title> A general approach for run-time specialization and its application to C. </title> <booktitle> In Proceedings of the 23th Annual Symposium on Principles of Programming Languages, </booktitle> <pages> pages 145-156, </pages> <address> St. Petersburg, FL, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: On one side, annotation-driven approaches allow the programmer to communicate high-level hints about run-time invariants to the compiler, but provide relatively limited code specification This research was supported in part by the Advanced Research Projects Agency under contracts N00014-94-1-0985 and N66001-96-C-8522, and by a NSF National Young Investigator Award. flexibility <ref> [1, 11, 32] </ref>. On the other, library-based approaches allow flexible specification of code, but require programmers to work with a low-level representation [14, 19]. <p> Additionally, `C provides support for dynamic code generation in the context of ANSI C, a complex imperative language. Another interesting automatic code generation system is Tempo <ref> [11] </ref>, a general-purpose dynamic specializer for C. Like other automatic systems, it can be less flexible than `C. For example, the scope of Tempo's optimizations is limited by the usual challenges C presents to optimizing compilers (e.g., unrestricted aliasing). <p> One way to generate good code with low overhead is to structure the system so that most optimizations can be performed statically <ref> [1, 11, 32] </ref>, but in all existing systems this ability comes at the expense of language flexibility and expressiveness (furthermore, in practice, only Leone and Lee [32] appear to generate code more quickly than tcc). `C, by contrast, allows the user to dynamically compose arbitrary pieces of code, which makes static
Reference: [12] <author> P. Deutsch and A.M. Schiffman. </author> <title> Efficient implementation of the Smalltalk-80 system. </title> <booktitle> In Proceedings of 11th POPL, </booktitle> <pages> pages 297-302, </pages> <address> Salt Lake City, UT, </address> <month> January </month> <year> 1984. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages <ref> [7, 12, 26] </ref>, and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [13] <author> S. Draves. </author> <title> Lightweight languages for interactive graphics. </title> <type> Technical Report CMU-CS-95-148, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1995. </year>
Reference: [14] <author> D. R. Engler. </author> <title> VCODE: a retargetable, extensible, very fast dynamic code generation system. </title> <booktitle> In Proceedings of the SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year> <note> http://www.pdos.lcs.mit.edu/engler/ vcode.html. </note>
Reference-contexts: On the other, library-based approaches allow flexible specification of code, but require programmers to work with a low-level representation <ref> [14, 19] </ref>. <p> We build on work done by Engler, Hsieh, and Kaashoek [15]. They describe the `C language and a prototype compiler for it. We provide the first real, high-performance implementation of `C. Our implementation uses an extension of VCODE <ref> [14] </ref>, a fast, portable dynamic code generation system, as its target machine. 3 Language Overview This section briefly describes `C in enough detail to provide context for the tcc compiler; a more complete discussion can be found in [15, 18]. `C extends ANSI C to support dynamic code generation. <p> a pointer to its code generating function. c, on the other hand, has more dependencies on its environment: its closure also stores run-time constants, pointers to free variables, and other information. tcc's abstract machines. tcc compiles dynamic code to two abstract machines based on the VCODE dynamic code generation system <ref> [14] </ref>. <p> As tcc matures, we may add machine-specific back ends. Since tcc preserves the features that make lcc retargetable, this process should not be difficult. The first of tcc's abstract machines is the VCODE system itself <ref> [14] </ref>. VCODE provides an interface resembling that of an idealized load/store RISC architecture; each instruction in this interface is a C macro which emits the corresponding instruction (or series of instructions) for the target architecture. <p> This modular composition of data operations is an active research area. The two main limitations of current approaches to this problem are that they use specialized languages and, with the exception of work using VCODE <ref> [14] </ref>, they are static, in that passes cannot be built at run time. A more powerful approach is to use `C to compose functions dynamically; programmers can use a language they are accustomed to, and data manipulation steps can be flexibly composed at run time. This benchmark is called cmp.
Reference: [15] <author> D. R. Engler, W. C. Hsieh, and M. F. Kaashoek. </author> <title> `C: A language for high-level, efficient, and machine-independent dynamic code generation. </title> <booktitle> In Proceedings of the 23th Annual Symposium on Principles of Programming Languages, </booktitle> <pages> pages 131-144, </pages> <address> St. Petersburg, FL, </address> <year> 1995. </year>
Reference-contexts: Existing template-based systems, by contrast, use dynamic compilation solely for its performance advantages, extending to run-time the applicability of traditional optimizations such as copy propagation and dead code elimination. We build on work done by Engler, Hsieh, and Kaashoek <ref> [15] </ref>. They describe the `C language and a prototype compiler for it. We provide the first real, high-performance implementation of `C. <p> Our implementation uses an extension of VCODE [14], a fast, portable dynamic code generation system, as its target machine. 3 Language Overview This section briefly describes `C in enough detail to provide context for the tcc compiler; a more complete discussion can be found in <ref> [15, 18] </ref>. `C extends ANSI C to support dynamic code generation. It introduces two unary operators, ` and $, and two postfix-declared type constructors. Programmers use these extensions to denote code that should be generated at run time. The units of code specification are ANSI C expressions, statements and variables. <p> These are implemented as special forms which the compiler translates to calls to a small library, reducing the number of actual language changes necessary for `C, and facilitating changes in implementation and functionality. These and other features of `C are described in depth in <ref> [15, 18] </ref>. 4 Architecture The design of tcc has been driven by three goals: providing flexibility to the programmer, minimizing the overhead of dynamic compilation, and generating high-quality code. <p> Complete data from these experiments appears in Section 6.3, below. 6.2 Benchmarks This subsection describes the benchmarks we used to evaluate the tcc compiler. They have been chosen to highlight different styles of dynamic code generation use. Many of them are fully described (but not measured) in <ref> [15] </ref>. We also describe modifications made to xv [4], a relatively sophisticated share-ware image manipulation package, to exploit dynamic code generation, and the resulting performance benefits. Run-time constants. Dynamic code generation can be used to hardwire infrequently changing values into the instruction stream.
Reference: [16] <author> D. R. Engler, M. F. Kaashoek, and J. O'Toole Jr. Exokernel: </author> <title> an operating system architecture for application-specific resource management. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 251-266, </pages> <address> Copper Mountain Resort, Col-orado, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: We discuss the basic architecture of tcc in Section 4, details of its code generation strategies in Section 5, and experimental results in Section 6. 2 Related Work Dynamic code generation has a long history [29]. It has been used to increase the performance of operating systems <ref> [2, 16, 39, 40] </ref>, windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [17] <author> D. R. Engler and M. Frans Kaashoek. DPF: </author> <title> Fast, flexible message demultiplexing using dynamic code generation. </title> <booktitle> Proceedings of ACM SIGCOMM'96 Conference on Applications, Technologies, Architectures and Protocols for Computer Communication, </booktitle> <pages> pages 53-59, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: On the other, library-based approaches allow flexible specification of code, but require programmers to work with a low-level representation [14, 19]. This code specification flexibility is necessary to efficiently implement some of the most profitable applications of dynamic code generation, such as just in time compilers <ref> [17] </ref> and efficient simulators [10, 48, 46], which require the composition of arbitrary statements and expressions and the creation of routines with statically-unknown type signatures. tcc aims to provide the ease of specifying dynamic code at a high level while retaining the flexibility and expressiveness of low-level systems. tcc compiles the
Reference: [18] <author> D. R. Engler and M. Poletto. </author> <title> A `C tutorial. </title> <type> Technical Memo MIT-LCS-TM-564, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: Our implementation uses an extension of VCODE [14], a fast, portable dynamic code generation system, as its target machine. 3 Language Overview This section briefly describes `C in enough detail to provide context for the tcc compiler; a more complete discussion can be found in <ref> [15, 18] </ref>. `C extends ANSI C to support dynamic code generation. It introduces two unary operators, ` and $, and two postfix-declared type constructors. Programmers use these extensions to denote code that should be generated at run time. The units of code specification are ANSI C expressions, statements and variables. <p> These are implemented as special forms which the compiler translates to calls to a small library, reducing the number of actual language changes necessary for `C, and facilitating changes in implementation and functionality. These and other features of `C are described in depth in <ref> [15, 18] </ref>. 4 Architecture The design of tcc has been driven by three goals: providing flexibility to the programmer, minimizing the overhead of dynamic compilation, and generating high-quality code.
Reference: [19] <author> D.R. Engler and T.A. Proebsting. </author> <title> DCG: An efficient, retargetable dynamic code generation system. </title> <booktitle> Proceedings of ASPLOS-VI, </booktitle> <pages> pages 263-272, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: On the other, library-based approaches allow flexible specification of code, but require programmers to work with a low-level representation <ref> [14, 19] </ref>.
Reference: [20] <author> G. E. </author> <title> Forsythe. Computer Methods for Mathematical Computations. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1977. </year>
Reference-contexts: Objects of type cspec are therefore implemented just like pointers: they have the same size, alignment requirements, etc.. Closures are heap-allocated, but their allocation cost is greatly reduced (down to a pointer increment, in the normal case) by using arenas <ref> [20] </ref>. <p> ICODE has full information about control flow at indirect jumps. In addition to constructing control flow information, ICODE collects a minimal amount of local data flow information (def and use sets for each basic block). All memory management occurs through arenas <ref> [20] </ref>, ensuring low amortized cost for memory allocation and essentially free deallocation. Finding live intervals. In the interest of fast code generation, ICODE does not compute precise live range information, but instead uses a coarse approximation that we call live intervals.
Reference: [21] <author> C. Fraser. copt. </author> <month> ftp://ftp.cs.princeton.edu/pub/ lcc/contrib/copt.shar. </month>
Reference-contexts: Additionally, the intermediate representation of each tick-expression is processed by the common subexpression elimination and other local optimizations performed by the lcc front end. tcc also uses copt <ref> [21] </ref> to statically perform peephole optimizations on the code generating macros used by CGFs. However, not all register allocation and instruction selection can occur statically.
Reference: [22] <author> C. W. Fraser and D. R. Hanson. </author> <title> A code generation interface for ANSI C. </title> <type> Technical Report CS-TR-270-90, </type> <institution> Department of Computer Science, Princeton University, </institution> <year> 1990. </year>
Reference-contexts: The subsequent section looks in detail at several of the optimizations and techniques we have developed to improve the performance of both dynamic code and the dynamic code generation process. 4.1 Overview The tcc compiler is based on lcc <ref> [23, 22] </ref>, a terse and portable compiler for ANSI C. lcc performs common subexpression elimination within extended basic blocks and uses lburg [38] to find the lowest-cost implementation of a certain IR-level construct, but it performs few other optimizations. <p> We are currently studying ways of doing this. Fast linear-scan register allocation. Given a set of live intervals, our global register allocation algorithm is simple and fast. Variants have been considered in the literature <ref> [22, 24, 27] </ref> in the context of local register allocation and for spill-code minimization within a single basic block [42].
Reference: [23] <author> C. W. Fraser and D. R. Hanson. </author> <title> A retargetable C compiler: design and implementation. </title> <publisher> Benjamin/Cummings Publishing Co., </publisher> <address> Redwood City, CA, </address> <year> 1995. </year>
Reference-contexts: The subsequent section looks in detail at several of the optimizations and techniques we have developed to improve the performance of both dynamic code and the dynamic code generation process. 4.1 Overview The tcc compiler is based on lcc <ref> [23, 22] </ref>, a terse and portable compiler for ANSI C. lcc performs common subexpression elimination within extended basic blocks and uses lburg [38] to find the lowest-cost implementation of a certain IR-level construct, but it performs few other optimizations.
Reference: [24] <author> R. A. </author> <title> Freiburghouse. Register allocation via usage counts. </title> <journal> Communications of the ACM, </journal> <volume> 17(11) </volume> <pages> 638-642, </pages> <month> November </month> <year> 1974. </year>
Reference-contexts: We are currently studying ways of doing this. Fast linear-scan register allocation. Given a set of live intervals, our global register allocation algorithm is simple and fast. Variants have been considered in the literature <ref> [22, 24, 27] </ref> in the context of local register allocation and for spill-code minimization within a single basic block [42].
Reference: [25] <author> R. Gupta, Mary Lou Soffa, and T. Steele. </author> <title> Register allocation via clique separators. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(7) </volume> <pages> 264-274, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: In addition to this register allocator, we also provide a Chaitin-style graph-coloring register allocator [6]. This register allocation technique is not new: it has been studied and optimized extensively <ref> [5, 8, 25, 34] </ref>, performs well in many cases, and is simple to implement. As a result, it is a good means of evaluating our simpler and faster register allocation algorithm. Emitting code.
Reference: [26] <author> U. Holzle and D. Ungar. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In Proceedings of PLDI '94, </booktitle> <pages> pages 326-335, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages <ref> [7, 12, 26] </ref>, and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [27] <author> W-C. Hsu, Charles N. Fischer, and J. R. Goodman. </author> <title> On the minimization of loads and stores in local register allocation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(10) </volume> <pages> 1252-1260, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: We are currently studying ways of doing this. Fast linear-scan register allocation. Given a set of live intervals, our global register allocation algorithm is simple and fast. Variants have been considered in the literature <ref> [22, 24, 27] </ref> in the context of local register allocation and for spill-code minimization within a single basic block [42].
Reference: [28] <author> D. Keppel. </author> <title> A portable interface for on-the-fly instruction space modification. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 86-95, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This approach is extremely flexible but, unfortunately, comes at a high price: since these languages are dynamically typed, little code generation cost can be pushed to compile time. Keppel addressed some issues relevant to retargeting dynamic code generation in <ref> [28] </ref>. He developed a portable system for modifying instruction spaces on a variety of machines. His system dealt with the difficulties presented by caches and operating system restrictions, but it did not address how to select and emit actual binary instructions.
Reference: [29] <author> D. Keppel, S.J. Eggers, and R.R. Henry. </author> <title> A case for runtime code generation. </title> <type> TR 91-11-04, </type> <institution> Univ. of Washington, </institution> <year> 1991. </year>
Reference-contexts: Section 3 gives a concise overview of tcc's input language, `C. We discuss the basic architecture of tcc in Section 4, details of its code generation strategies in Section 5, and experimental results in Section 6. 2 Related Work Dynamic code generation has a long history <ref> [29] </ref>. It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46].
Reference: [30] <author> D. Keppel, S.J. Eggers, and R.R. Henry. </author> <title> Evaluating runtime-compiled value-specific optimizations. </title> <type> TR 93-11-02, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: He developed a portable system for modifying instruction spaces on a variety of machines. His system dealt with the difficulties presented by caches and operating system restrictions, but it did not address how to select and emit actual binary instructions. Keppel, Eggers, and Henry <ref> [30] </ref> demonstrated that dynamic code generation can be effective for several different applications. Leone and Lee [31] use programmer-supplied hints to perform compile-time specialization in a simple functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML [32]. <p> Small language compilation. Many small, primitive languages are both time-critical and amenable to dynamic compilation. The query languages used to interrogate data bases are well-known targets for dynamic code generation <ref> [30] </ref>; since databases are large, dynamically compiled queries will be applied many times. We have developed a small query language and benchmarked a dynamic query compiler for it, query. Each query is a boolean expression formed by accessing record fields and comparing them to other fields or to constant values.
Reference: [31] <author> M. Leone and P. Lee. </author> <title> Lightweight run-time code generation. </title> <booktitle> In Proceedings of the Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 97-106, </pages> <address> Copenhagen, Denmark, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: His system dealt with the difficulties presented by caches and operating system restrictions, but it did not address how to select and emit actual binary instructions. Keppel, Eggers, and Henry [30] demonstrated that dynamic code generation can be effective for several different applications. Leone and Lee <ref> [31] </ref> use programmer-supplied hints to perform compile-time specialization in a simple functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML [32].
Reference: [32] <author> M. Leone and P. Lee. </author> <title> Optimizing ML with run-time code generation. </title> <booktitle> In Proceedings of the SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: On one side, annotation-driven approaches allow the programmer to communicate high-level hints about run-time invariants to the compiler, but provide relatively limited code specification This research was supported in part by the Advanced Research Projects Agency under contracts N00014-94-1-0985 and N66001-96-C-8522, and by a NSF National Young Investigator Award. flexibility <ref> [1, 11, 32] </ref>. On the other, library-based approaches allow flexible specification of code, but require programmers to work with a low-level representation [14, 19]. <p> Keppel, Eggers, and Henry [30] demonstrated that dynamic code generation can be effective for several different applications. Leone and Lee [31] use programmer-supplied hints to perform compile-time specialization in a simple functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML <ref> [32] </ref>. They achieve low code generation costs using some of the techniques we independently derived for tcc. `C, however, provides the programmer with a wider range of mechanisms for dynamic code generation. Additionally, `C provides support for dynamic code generation in the context of ANSI C, a complex imperative language. <p> In such systems, the static compiler emits templates that at run time are filled with appropriate values, optimized in relatively simple but effective ways, and emitted directly. In practice, however, only Leone and Lee <ref> [32] </ref> appear to generate code more quickly than tcc. <p> One way to generate good code with low overhead is to structure the system so that most optimizations can be performed statically <ref> [1, 11, 32] </ref>, but in all existing systems this ability comes at the expense of language flexibility and expressiveness (furthermore, in practice, only Leone and Lee [32] appear to generate code more quickly than tcc). `C, by contrast, allows the user to dynamically compose arbitrary pieces of code, which makes static <p> One way to generate good code with low overhead is to structure the system so that most optimizations can be performed statically [1, 11, 32], but in all existing systems this ability comes at the expense of language flexibility and expressiveness (furthermore, in practice, only Leone and Lee <ref> [32] </ref> appear to generate code more quickly than tcc). `C, by contrast, allows the user to dynamically compose arbitrary pieces of code, which makes static analysis of the dynamic code problematic. The following subsections give an overview of tcc and discuss how tcc achieves its goal of performance and flexibility.
Reference: [33] <author> P. G. Lowney, S. M. Freudenberger, T. J. Karzes, W. D. Lichtenstein, R. P. Nix, J. S. O'Donnell, and J. C. Ruttenberg. </author> <title> The Multiflow trace scheduling compiler. </title> <journal> In The Journal of Supercomputing, </journal> <volume> volume 7, </volume> <pages> pages 51-142, </pages> <year> 1993. </year>
Reference-contexts: Their compiler employs programmer annotations to indicate some run-time constants; the compiler computes what variables are derived run-time constants. Published results seem to indicate that it dynamically generates code up to an order of magnitude more slowly than tcc but, since it is integrated with the Multiflow optimizing compiler <ref> [33] </ref>, we assume that the code it generates is superior in quality. In theory, the three systems described above can generate good code with relatively low overhead by moving almost all the work to static compilation.
Reference: [34] <author> G. Lueh, T. Gross, and A. Adl-Tabatabai. </author> <title> Global register allocation based on graph fusion. </title> <type> Technical Report CMU-CS-96-106, </type> <institution> Carnegie Mellon University, </institution> <month> March </month> <year> 1996. </year>
Reference-contexts: In addition to this register allocator, we also provide a Chaitin-style graph-coloring register allocator [6]. This register allocation technique is not new: it has been studied and optimized extensively <ref> [5, 8, 25, 34] </ref>, performs well in many cases, and is simple to implement. As a result, it is a good means of evaluating our simpler and faster register allocation algorithm. Emitting code.
Reference: [35] <author> J.K. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley Professional Computing Series. Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1994. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl <ref> [35] </ref>, and Perl [47], provide an eval operation that allows code to be generated dynamically. This approach is extremely flexible but, unfortunately, comes at a high price: since these languages are dynamically typed, little code generation cost can be pushed to compile time.
Reference: [36] <author> R. Pike, B.N. Locanthi, and J.F. Reiser. </author> <title> Hardware/software trade-offs for bitmap graphics on the Blit. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 15(2) </volume> <pages> 131-151, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations <ref> [36] </ref>, dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [37] <author> M. Poletto, D. R. Engler, and M. F. Kaashoek. tcc: </author> <title> A template-based compiler for `C. </title> <booktitle> In Workshop on Compiler Support for Systems Software, </booktitle> <address> Tucson, AZ, </address> <month> February </month> <year> 1996. </year>
Reference: [38] <author> T. A. Proebsting. </author> <title> Simple and efficient BURS table generation. </title> <journal> SIG-PLAN Notices, </journal> <volume> 27(7) </volume> <pages> 331-340, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: and techniques we have developed to improve the performance of both dynamic code and the dynamic code generation process. 4.1 Overview The tcc compiler is based on lcc [23, 22], a terse and portable compiler for ANSI C. lcc performs common subexpression elimination within extended basic blocks and uses lburg <ref> [38] </ref> to find the lowest-cost implementation of a certain IR-level construct, but it performs few other optimizations. All parsing and semantic checking of dynamic expressions occurs at static compile time. Semantic checks are performed at the level of dynamically generated expressions.
Reference: [39] <author> C. Pu, T. Autry, A. Black, C. Consel, C. Cowan, J. Inouye, L. Kethana, J. Walpole, and K. Zhang. </author> <title> Optimistic incremental specialization: streamlining a commerical operating system. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles, </booktitle> <address> Copper Mountain, CO, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: We discuss the basic architecture of tcc in Section 4, details of its code generation strategies in Section 5, and experimental results in Section 6. 2 Related Work Dynamic code generation has a long history [29]. It has been used to increase the performance of operating systems <ref> [2, 16, 39, 40] </ref>, windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [40] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <year> 1988. </year>
Reference-contexts: We discuss the basic architecture of tcc in Section 4, details of its code generation strategies in Section 5, and experimental results in Section 6. 2 Related Work Dynamic code generation has a long history [29]. It has been used to increase the performance of operating systems <ref> [2, 16, 39, 40] </ref>, windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [41] <editor> J. Rees, W. Clinger (editors), et al. </editor> <title> Revised 4 report on the algorithmic language Scheme. </title> <institution> AIM 848b, MIT AI Lab, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects <ref> [41, 43] </ref>, Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically. This approach is extremely flexible but, unfortunately, comes at a high price: since these languages are dynamically typed, little code generation cost can be pushed to compile time.
Reference: [42] <author> V. Sarkar. Personal communcation, </author> <month> September </month> <year> 1996. </year>
Reference-contexts: Fast linear-scan register allocation. Given a set of live intervals, our global register allocation algorithm is simple and fast. Variants have been considered in the literature [22, 24, 27] in the context of local register allocation and for spill-code minimization within a single basic block <ref> [42] </ref>. Given R available registers and a list of live intervals, allocating registers so as to minimize the number of spilled intervals involves removing the smallest number of live intervals so that no more than R live intervals overlap any one instruction.
Reference: [43] <author> G.L. Steele Jr. </author> <title> Common Lisp. </title> <note> Digital Press, second edition, </note> <year> 1990. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects <ref> [41, 43] </ref>, Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically. This approach is extremely flexible but, unfortunately, comes at a high price: since these languages are dynamically typed, little code generation cost can be pushed to compile time.
Reference: [44] <author> C. A. Thekkath and H. M. Levy. </author> <title> Limits to low-latency communication on high-speed networks. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2) </volume> <pages> 179-203, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: This is a powerful feature. For instance, it allows the construction of code to marshal and unmarshal arguments stored in a byte vector, operations frequently performed to support remote procedure call [3]. By generating specialized code for the most active functions it is possible to gain substantial performance benefits <ref> [44] </ref>. Our two benchmarks, mshl and umshl, dynamically generate marshaling and unmarshaling code, respectively, given a printf-style format string specifying the types of arguments. This ability goes beyond mere performance: ANSI C simply does not provide mechanisms for dynamically constructing function calls with varying numbers of arguments.
Reference: [45] <author> K. Thompson. </author> <title> Regular expression search algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 11(6), </volume> <month> June </month> <year> 1968. </year>
Reference: [46] <author> J.E. Veenstra and R.J. Fowler. MINT: </author> <title> a front end for efficient simulation of shared-memory multiprocessors. </title> <booktitle> In Modeling and Simulation of Computers and Telecommunications Systems, </booktitle> <year> 1994. </year>
Reference-contexts: This code specification flexibility is necessary to efficiently implement some of the most profitable applications of dynamic code generation, such as just in time compilers [17] and efficient simulators <ref> [10, 48, 46] </ref>, which require the composition of arbitrary statements and expressions and the creation of routines with statically-unknown type signatures. tcc aims to provide the ease of specifying dynamic code at a high level while retaining the flexibility and expressiveness of low-level systems. tcc compiles the `C programming language, an <p> It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages [7, 12, 26], and simulators <ref> [48, 46] </ref>. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
Reference: [47] <author> L. Wall. </author> <title> The Perl Programming Language. </title> <publisher> Prentice Hall Software Series, </publisher> <year> 1994. </year>
Reference-contexts: It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages [7, 12, 26], and simulators [48, 46]. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl <ref> [47] </ref>, provide an eval operation that allows code to be generated dynamically. This approach is extremely flexible but, unfortunately, comes at a high price: since these languages are dynamically typed, little code generation cost can be pushed to compile time.
Reference: [48] <author> E. Witchel and M. Rosenblum. Embra: </author> <title> Fast and flexible machine simulation. </title> <booktitle> Proceedings of ACM SIGMETRICS '96 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 68-79, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: This code specification flexibility is necessary to efficiently implement some of the most profitable applications of dynamic code generation, such as just in time compilers [17] and efficient simulators <ref> [10, 48, 46] </ref>, which require the composition of arbitrary statements and expressions and the creation of routines with statically-unknown type signatures. tcc aims to provide the ease of specifying dynamic code at a high level while retaining the flexibility and expressiveness of low-level systems. tcc compiles the `C programming language, an <p> It has been used to increase the performance of operating systems [2, 16, 39, 40], windowing operations [36], dynamically typed languages [7, 12, 26], and simulators <ref> [48, 46] </ref>. Many languages, such as most Lisp dialects [41, 43], Tcl [35], and Perl [47], provide an eval operation that allows code to be generated dynamically.
References-found: 48

