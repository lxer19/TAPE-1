URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/92-022.ps.Z
Refering-URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/FILE.html
Root-URL: http://www.cs.unc.edu
Title: Synthetic Experience: A Taxonomy, Survey of Earlier Thought, and Speculations on the Future  
Author: Warren Robinett 
Address: Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science University of North Carolina,  
Abstract: A taxonomy is proposed to classify all varieties of technologically-mediated experience. This includes virtual reality and teleoperation, as well as earlier devices such as the microscope and telephone. The model of mediated interaction assumes a sensor-display link from the world to the human, and an action-actuator link going back from the human to the world, with the mediating technology transforming the transmitted experience in some way. The taxonomy is used to classify a number of sample systems. Earlier visions of technologically-based experience are compared with the ideas presented in this paper. Then the long-term prospects of this field are speculated upon, ignoring constraints of cost, effort, or time to develop. Finally, the ultimate limits of synthetic experience are discussed, derived from properties of the physical universe and the human neural apparatus. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Airey, J. , Rohlf, J., Brooks, F. P. </author> <year> (1990). </year> <title> Towards Image Realism with Interactive Update Rates in Complex Virtual Building Environments, </title> <booktitle> Computer Graphics: Proceedings of 1990 Symposium on Interactive 3D Graphics, Snowbird, Utah, </booktitle> <pages> 41-50. </pages>
Reference: <author> Barlow, J. P. </author> <year> (1990). </year> <title> Life in the DataCloud: Scratching Your Eyes Back In, </title> <booktitle> Mondo 2000, Summer. </booktitle>
Reference-contexts: This system was called "Reality Built for Two" or RB2 (Blanchard, Burgess, Harvill, Lanier, Lasko, Oberman & Teitel, 1990). Lanier coined the term virtual reality. He asserted that this computersimulated world could have any desired properties, and described it as an "intentional dream <ref> (Barlow, 1990) </ref>. He talked about "jacking into lobsters," that is, using your own body to control simulations of creatures with more limbs than you possess.
Reference: <author> Batter, J.J. and F.P. Brooks, Jr. </author> <year> 1971. </year> <title> GROPE-I: A computer display to the sense of feel. </title> <booktitle> Information Processing: Proceedings of IFIP Congress 71. </booktitle> <pages> 759-763. </pages>
Reference: <author> Blanchard, C., S. Burgess, Y. Harvill, J. Lanier, A. Lasko, M. Oberman, M. Teitel. </author> <title> Reality Built for Two: A Virtual Reality Tool. </title> <booktitle> "Proc. 1990 Workshop on Interactive 3D Graphics. </booktitle> <pages> 35-36. </pages> <note> 27 Boff, </note> <author> K. R., Kaufman, L., Thomas, J. P. </author> <year> (1986). </year> <title> Handbook of Perception and Human Performance . New York: </title> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: The glove was invented by Tom Zimmerman of VPL. In 1989, VPL began selling a commercial HMD, the EyePhone, and the hardware and software to link together two people wearing HMDs in the same virtual world. This system was called "Reality Built for Two" or RB2 <ref> (Blanchard, Burgess, Harvill, Lanier, Lasko, Oberman & Teitel, 1990) </ref>. Lanier coined the term virtual reality. He asserted that this computersimulated world could have any desired properties, and described it as an "intentional dream (Barlow, 1990).
Reference: <author> Bright, M. </author> <year> (1984). </year> <title> Animal Language, </title> <type> 55-108. </type> <institution> London: British Broadcasting Corporation. </institution>
Reference-contexts: Technological masquerade has been used to study intra-species communication in animals by using recordings and sophisticated puppets to fool the animals into behaving as if they were interacting with another member of their species. This has been done extensively with recorded bird calls <ref> (Bright, 1984) </ref>, and also with a computer-controlled robot bee, which was able to direct real bees to specific locations far from the hive by moving in the patterned dance that bees use to communicate and then dispensing a sweet liquid sample of the (pretended) distant pollen (Weiss, 1989).
Reference: <author> Brooks, F. P. </author> <year> (1986). </year> <title> WalkthroughA dynamic graphics system for simulating virtual buildings. </title> <booktitle> In Proceedings of 1986 Workshop on Interactive 3D Graphics. </booktitle> <address> UNC-Chapel Hill. </address> <pages> 9-21. </pages>
Reference-contexts: They also explored interactive 3D graphical simulations, with particular emphasis on using computer graphics to represent and simulate molecules (Wright, 1972) and to represent the interior of buildings <ref> (Brooks, 1986) </ref>(Airey, Rohlf & Brooks, 1990). A see-through HMD was built and tested for various applications (Chung, Harris, Brooks, Fuchs, Kelley, Hughes, Ouh-Young, Cheung, Holloway & Pique, 1989).
Reference: <author> Brooks, F.P., Jr., M. Ouh-Young, J.J. Batter, and P.J. Kilpatrick. </author> <year> 1990. </year> <title> Project GROPEHaptic displays for scientific visualization. </title> <booktitle> Computer Graphics: Proceedings of SIGGRAPH 90. Dallas,TX. </booktitle> <pages> 177-185. </pages>
Reference: <author> Brooks, F. P. Jr. </author> <year> (1988). </year> <title> Grasping reality through illusion. </title> <booktitle> Proceedings of CHI 88. </booktitle> <address> Washington, D.C. </address>
Reference-contexts: In his paper "Grasping Reality Through Illusion: Interactive Graphics Serving Science," Brooks made a case for interactive computer graphic simulation as a "potent tool ... in man's ongoing scientific enterprise - the understanding of the physical universe" <ref> (Brooks, 1988) </ref>.
Reference: <author> Bricken, W. </author> <year> (1990a). </year> <title> A Vision of Virtual Reality, </title> <type> Tech. Report HITL-P-90-1, </type> <institution> Human Interface Technology Lab, University of Washington. </institution>
Reference-contexts: In his 1990 papers, "A Vision of Virtual Reality" and "Virtual Reality: Directions for Growth," Bricken defines virtual reality broadly as "the body of techniques that apply computation to the generation of experientially valid realities <ref> (Bricken, 1990a) </ref>(Bricken, 1990b). He discussed a great range of topics, including multi-sensory display, behavior transducers, telepresence, interactive fiction, collaborative work, and simulated creatures (which he called "entities"). He discussed many applications, including therapy, art, travel, education, and simulation.
Reference: <author> Bricken, W. </author> <year> (1990b). </year> <title> Virtual Reality: Directions of Growth, </title> <type> Tech. Report HITL-R-90-1, </type> <institution> Human Interface Technology Lab, University of Washington. </institution>
Reference: <author> Buchroeder, R. A., Seeley, G. W., & Vukobradatovich, D. </author> <year> (1981). </year> <title> Design of a Catadioptric VCASS Helmet-Mounted Display, </title> <institution> Optical Sciences Center, University of Arizona, </institution> <note> under contract to the U.S. </note> <institution> Air Force Armstrong Aerospace Medical Research Laboratory, Wright-Patterson Air Force Base, Dayton, Ohio, AFAMRL-TR-81-133. </institution>
Reference-contexts: In this new kind of cockpit for aircraft pilots, the aircraft sensor data was transformed for display to the pilot into 3D visual and auditory representations <ref> (Buchroeder, Seeley & Vukobradatovich, 1981) </ref> (Furness, 1986a) (Kocian, 1988).
Reference: <author> Bush, V. </author> <year> (1945). </year> <title> As We May Think, </title> <journal> Atlantic Monthly, </journal> <month> July. </month>
Reference-contexts: These fields are not covered either in this section. Vannevar Bush, 1945 In his article "As We May Think," Vannevar Bush, who headed the American scientific effort during World War II, proposed the "memex," a storage and access device for human knowledge <ref> (Bush, 1945) </ref>. The idea was basically to create an automated library, containing text, mathematical models, and images.
Reference: <author> Chung, J. C., Harris, M. R., Brooks, F. P., Jr., Fuchs, H., Kelley, M. T., Hughes, J., Ouh-Young, M., Cheung, C., Holloway, R. L., & Pique, M. </author> <year> (1989). </year> <title> Exploring Virtual Worlds with Head-Mounted Displays, Non-Holographic True 3-Dimensional Display Technologies, </title> <booktitle> SPIE Proc. </booktitle> <volume> Vol. </volume> <pages> 1083. </pages>
Reference: <author> Caudell, T. P., Mizell, D. W. </author> <year> (1992). </year> <title> Augmented Reality: an application of heads-up display technology to manual manufacturing processes, </title> <booktitle> HICSS conference, </booktitle> <month> January </month> <year> 1992. </year>
Reference-contexts: The superimposed virtual world may be labels or diagrams located at specific points in the real world <ref> (Caudell & Mizell, 1992) </ref>.
Reference: <author> Clarke, A. C. </author> <year> (1962). </year> <title> Profiles of the Future. </title> <address> New York: </address> <publisher> Holt, Reinhart & Winston. </publisher>
Reference-contexts: We will try to extrapolate as far as we can, without regard to cost or effort or time to develop, but limited by what ultimately seems possible. Our model in this constrained speculation is Arthur C. Clarkes Profiles of the Future <ref> (Clarke, 1962) </ref>.
Reference: <author> Corliss & Johnsen (1968). </author> <note> NASA Special Publication 5070. </note>
Reference: <author> Drexler, K. E. </author> <year> (1991). </year> <title> Unbounding the Future. </title> <address> New York: </address> <publisher> William Morrow & Co. </publisher>
Reference: <author> Englebart, D. </author> <year> (1963). </year> <title> A Conceptual Framework for the Augmentation of Man's Intellect, </title> <booktitle> Vistas in Information-Handling, </booktitle> <volume> 1, </volume> <pages> 1-29, </pages> <editor> Howerton, P. W., ed. </editor> <address> Washington DC: </address> <publisher> Spartan Books. </publisher>
Reference-contexts: Doug Englebart, 1963 In his paper "A Conceptual Framework for the Augmentation of Man's Intellect," Doug Englebart proposed that computers could be used, not just for calculation, but to increase human understanding and problemsolving ability <ref> (Englebart, 1963) </ref>. He foresaw this as being an interactive process, involving computer-controlled changing images on cathode-ray tubes and controlled by the human with interactive manual input devices.
Reference: <author> Eyles, J., J. Austin, H. Fuchs, T. Greer and J. Poulton. </author> <title> Pixel-Planes 4: A summary. </title> <booktitle> Proceedings of the Eurographics 87 Second Workshop on Graphics Hardware: Advances in Computer Graphics Hardware II. </booktitle> <pages> 183-208. </pages>
Reference: <author> Feynman, R. P. </author> <year> (1960). </year> <note> Theres Plenty of Room at the Bottom, reprinted in Journal of Micromechanical Systems 1(1), </note> <month> January </month> <year> 1992. </year>
Reference-contexts: However, we can expect storage density to continue to increase until it hits some sort of physical limit. It should ultimately be possible to encode information in the arrangement of matter on the atomic scale <ref> (Feynman, 1960) </ref>(Drexler, 1991). Assuming a nanotechnological storage device that stores 1 bit for every 1000 atoms gives us a storage density of 10 20 bits per cubic centimeter.
Reference: <author> Fisher, S. S. </author> <year> (1982). </year> <title> Viewpoint Dependent Imaging: An Interactive Stereoscopic Display, </title> <booktitle> Proceedings SPIE 367. </booktitle> <volume> 28 Fisher, </volume> <editor> S.S., McGreevy, M., Humphries, J., & Robinett, W. </editor> <year> (1986). </year> <title> Virtual Environment Display System, </title> <booktitle> Proc. 1986 Workshop on Interactive 3D Graphics, </booktitle> <pages> 77-87. </pages>
Reference-contexts: Scott Fisher, 1982 At MIT in 1982, Scott Fisher built a viewpoint-dependent imaging system which used a stereoscopic display, head tracker, and videodisc to give the user head-motion parallax while looking through the window of the screen at a prerecorded static scene <ref> (Fisher, 1982) </ref>. The videodisc stored a 2D array of images of the same scene from varying viewpoints, and the head tracking allowed selecting the displayed image to match the user's head position as it changed from moment to moment. The effect was similar to looking at a hologram.
Reference: <author> Foley, J. D. </author> <year> (1987). </year> <title> Interfaces for Advanced Computing, </title> <publisher> Scientific American 257(4) 126-135, </publisher> <month> October. </month>
Reference-contexts: The system consisted of a relatively inexpensive HMD made from monochrome LCD displays and wide-angle optics (Howlett, 1983), a magnetic tracker for the head and hand, an instrumented glove which measured the bending angles of the fingers <ref> (Foley, 1987) </ref>, a 3D sound subsystem (Wenzel, Wightman & Foster, 1988), and a speech recognizer. A freely-movable stereoscopic display mounted on a counterbalanced mechanical linkage was also developed.
Reference: <author> Fuchs, H., Duran, J., & Johnson, B. </author> <year> (1977). </year> <title> A system for automatic acquisition of three-dimensional data. </title> <booktitle> In Proceedings of the 1977 National Computer Conference. </booktitle> <volume> 46 </volume> <pages> 49-53. </pages>
Reference-contexts: Henry Fuchs, 1977 Henry Fuchs was a student at the University of Utah where Sutherland and his students experimented with the first HMD prototype. Tracking was a major problem for that early HMD, and Fuchs built a one-dimensional CCD-based optical tracker that measured lateral head movements <ref> (Fuchs, Duran & Johnson, 1977) </ref>. For his Ph.D. dissertation in 1977, Fuchs built a laser-based 3D scanner which could capture the 3D profile of a surface.
Reference: <author> Fuchs, H., J. Goldfeather, J.P. Hultquist, S. Spach, J.D. Austin, F.P. Brooks, Jr., J.G. Eyles and J. Poulton. </author> <year> 1985. </year> <title> Fast spheres, shadows, textures, transparencies, and image enhancements in Pixel-Planes. </title> <booktitle> Computer Graphics: SIGGRAPH '85 Conference Proceedings. 19:3:111-120. Reprinted in Advances in Computer Graphics I. </booktitle> <editor> G. Enderle, M. Grave, and F. Lillehagen, eds. </editor> <publisher> Springer-Verlag. </publisher> <year> 1986. </year> <pages> 169-187. </pages> <note> Also reprinted in Tutorial: </note> <institution> Computer Graphics HardwareImage Generation and Display. Hassan K. </institution>
Reference-contexts: Throughout the Eighties, Fuchs and his colleagues worked to design special-purpose real-time 3D graphics computers, and this work culminated in Pixel-Planes 4 <ref> (Fuchs, Goldfeather, Hultquist, Spach, Austin, Brooks, Eyles & Poulton, 1985) </ref> (Eyles, Austin, Fuchs, Greer & Poulton, 1987) and Pixel-Planes 5 (Fuchs, Poulton, Eyles, Greer, Goldfeather, Ellsworth, Molnar, Turk, Tebbs & Israel, 1989).
Reference: <editor> Reghbati and Anson Y.C. Lee, eds. </editor> <publisher> IEEE Computer Society Press. </publisher> <year> 1988. </year> <pages> 222-231. </pages>
Reference: <author> Fuchs, H., J. Poulton, J. Eyles, T. Greer, J. Goldfeather, D. Ellsworth, S. Molnar, G. Turk, B. Tebbs and L. Israel. </author> <year> 1989. </year> <title> A heterogeneous multiprocessor graphics system using processor-enhanced memories. </title> <booktitle> Computer Graphics: Proceedings of SIGGRAPH '89. </booktitle> <address> 23:4:79-88. </address>
Reference-contexts: These high-powered graphics engines were used to explore applications for the HMD in medical imaging <ref> (Fuchs, Levoy & Pizer, 1989) </ref> (Mills & Fuchs, 1990) (Ohbuchi & Fuchs, 1990) (Ohbuchi & Fuchs, 1991), molecular graphics, and architecture. An optical tracker was also developed (Wang, Azuma, Bishop, Chi, Eyles & Fuchs, 1990).
Reference: <author> Fuchs, H., M. Levoy, S. M. Pizer, </author> <title> "Interactive Visualization of 3D Medical Data," </title> <journal> IEEE Computer, </journal> <volume> Vol. 22, No. 8, </volume> <month> August </month> <year> 1989, </year> <pages> pp. 46-51. </pages>
Reference-contexts: These high-powered graphics engines were used to explore applications for the HMD in medical imaging <ref> (Fuchs, Levoy & Pizer, 1989) </ref> (Mills & Fuchs, 1990) (Ohbuchi & Fuchs, 1990) (Ohbuchi & Fuchs, 1991), molecular graphics, and architecture. An optical tracker was also developed (Wang, Azuma, Bishop, Chi, Eyles & Fuchs, 1990).
Reference: <author> Furness, T. </author> <year> (1986a). </year> <title> The Super Cockpit and Human Factors Challenges, </title> <type> Tech. Report HITL-M-86-1, </type> <institution> Human Interface Technology Lab, University of Washington. </institution>
Reference-contexts: In this new kind of cockpit for aircraft pilots, the aircraft sensor data was transformed for display to the pilot into 3D visual and auditory representations (Buchroeder, Seeley & Vukobradatovich, 1981) <ref> (Furness, 1986a) </ref> (Kocian, 1988). This was, in essence, creating synthetic senses for the pilot to allow, for example, seeing compass headings superimposed on the horizon, seeing maps superimposed onto the world for night flying, seeing spatial envelopes representing dangerous areas to avoid, and hearing the direction of approaching aircraft.
Reference: <author> Furness, T. </author> <year> (1986b). </year> <title> Putting Humans into Virtual Space, </title> <type> Tech. Report HITL-R-86-1, </type> <institution> Human Interface Technology Lab, University of Washington. </institution>
Reference-contexts: Furness's work with the Air Force focussed on synthetic senses for aircraft pilots and possible remote piloting. He later wrote about applications of HMDs in other fields, for example, computer-aided design, sensory prostheses, medical imaging, and the control of microscopes <ref> (Furness, 1986b) </ref>. Henry Fuchs, 1977 Henry Fuchs was a student at the University of Utah where Sutherland and his students experimented with the first HMD prototype.
Reference: <author> Goertz, R. C. </author> <year> (1961). </year> <title> The ANL Model 3 MasterSlave Electric Manipulator - Its Design and Use in a Cave, </title> <booktitle> Proc. 9th Conf. </booktitle> <institution> on Hot Laboratories and Equipment, Washington D.C., United States Atomic Energy Commission. </institution>
Reference: <author> Goertz, R. C. </author> <year> (1965). </year> <title> An experimental head-controlled television system to provide viewing for a manipulator operator, </title> <booktitle> Proc. 13th RSTD Conf. </booktitle> <pages> 57. </pages>
Reference: <author> Heilig, M. </author> <year> (1955). </year> <title> Cinema of the Future, </title> <address> Espacios (Mexico City), </address> <month> January. </month>
Reference-contexts: He mentioned photographing the invisible and visualizing microsecondscale events on an oscilloscope. He finished by mentioning the possibility of direct neural connection to machines. 15 Mort Heilig, 1955 In his article "Cinema of the Future," Mort Heilig, a filmmaker, proposed creating multi-sensory films that covered the entire human sensorium <ref> (Heilig, 1955) </ref>. He asserted that the relative importance of the senses of vision, hearing, smell, touch, and taste were in the proportion 70%, 20%, 5%, 4%, and 1%.
Reference: <author> Holloway, R. L. </author> <year> (1987). </year> <type> Head-Mounted Display Technical Report, </type> <institution> #TR87-015, Dept. of Computer Science, University of North Carolina at Chapel Hill Holloway, </institution> <note> R., </note> <author> H. Fuchs, W. Robinett. </author> <year> 1991. </year> <institution> Virtual-Worlds Research at the University of North Carolina at Chapel Hill. Proc. Computer Graphics 91. </institution> <address> London, England. </address>
Reference-contexts: Fuchs went to the University of North Carolina, where, in 1986, he codirected the construction of a see-through HMD system which used half-silvered mirrors and small color LCD displays <ref> (Holloway, 1987) </ref>.
Reference: <author> Howlett, E. M. </author> <year> (1983, </year> <month> September 27). </month> <title> Wide Angle Color Photography Method and System, </title> <type> U.S. Patent Number 4,406,532. </type>
Reference-contexts: The intended applications were control of autonomous and semi-autonomous telerobots, display of abstract "data-spaces," and human factors research. The system consisted of a relatively inexpensive HMD made from monochrome LCD displays and wide-angle optics <ref> (Howlett, 1983) </ref>, a magnetic tracker for the head and hand, an instrumented glove which measured the bending angles of the fingers (Foley, 1987), a 3D sound subsystem (Wenzel, Wightman & Foster, 1988), and a speech recognizer. A freely-movable stereoscopic display mounted on a counterbalanced mechanical linkage was also developed.
Reference: <author> Johnsen & Corliss (1967). </author> <note> NASA Special Publication 5047. </note>
Reference: <author> Kandel, E. R. & Schwartz, J. H. </author> <year> (1985). </year> <booktitle> Principles of Neural Science, </booktitle> <pages> 418-419. </pages> <address> New York: </address> <publisher> Elsevier Science Publishing Co. </publisher>
Reference-contexts: Taste has four dimensions, (salty, sour, sweet, and bitter), and arbitrary tastes may be synthesized with combinations of these primaries, just as arbitrary colors are synthesized from the red, green, and blue phosphor dots of the television screen. Similarly, smell appears to have seven dimensions <ref> (Kandel & Schwartz, 1985) </ref>, although there is some scientific dispute about this. Thus, smells could probably be synthesized from primary components also.
Reference: <author> Kocian, D. F. </author> <year> (1988). </year> <title> Design Considerations for Virtual Panoramic Display (VPD) Helmet Systems, </title> <institution> Armstrong Aerospace Medical Research Laboratory, Visual Display Systems Branch, Wright-Patterson Air Force Base, Dayton, Ohio 45433-6573. </institution> <note> 29 Krueger, </note> <editor> M. </editor> <booktitle> (1983). Artificial Reality. </booktitle> <address> Reading MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In this new kind of cockpit for aircraft pilots, the aircraft sensor data was transformed for display to the pilot into 3D visual and auditory representations (Buchroeder, Seeley & Vukobradatovich, 1981) (Furness, 1986a) <ref> (Kocian, 1988) </ref>. This was, in essence, creating synthetic senses for the pilot to allow, for example, seeing compass headings superimposed on the horizon, seeing maps superimposed onto the world for night flying, seeing spatial envelopes representing dangerous areas to avoid, and hearing the direction of approaching aircraft.
Reference: <author> Laurel, B. </author> <year> (1991a). </year> <title> Computers As Theater. </title> <address> New York: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In the last section of the book, Rheingold considers teledildonics, "electronic LSD," and remotely-operated warplanes, which lead him to questions about ethics and about human nature. Brenda Laurel, 1991 Brenda Laurel's book, Computers As Theater ,uses uses a theatrical point of view to analyze computer-mediated experience <ref> (Laurel, 1991a) </ref>. The Art of Human-Computer Interface Design, edited by Laurel, also has several articles on virtual environments (Laurel, 1991b). 4.
Reference: <author> Laurel, B. </author> <year> (1991b). </year> <title> The Art of Human-Computer Interface Design. </title> <address> New York: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Brenda Laurel, 1991 Brenda Laurel's book, Computers As Theater ,uses uses a theatrical point of view to analyze computer-mediated experience (Laurel, 1991a). The Art of Human-Computer Interface Design, edited by Laurel, also has several articles on virtual environments <ref> (Laurel, 1991b) </ref>. 4.
Reference: <author> Linvill, J. G. </author> <year> (1973). </year> <title> Research and Development of Tactile Facsimile Reading Aid for the Blind (the Opticon), </title> <type> report to U.S. </type> <institution> Dept. of Health, Education, and Welfare, Stanford Electronics Laboratory, Stanford University. </institution>
Reference-contexts: A sensory prosthesis corrects, amplifies, or otherwise improves the fidelity of an ordinary built-in human sense. Examples are corrective spectacles, sunglasses, and hearing aids. For people with defective or nonfunctional senses, cross-sensory substitution can compensate for the disability. For example, the Opticon <ref> (Linvill, 1973) </ref> is an optical-to-tactile transducer array which allows blind people, after some training, to read from ordinary printed books by, in effect, running their finger over the printed text and feeling the black marks as raised bumps. 1.2 On taxonomies in general Taxonomy can help to think about a group <p> A full body force-feedback exoskeleton can therefore be imagined. Tactile arrays that can display texture and vibration to the finger or other surfaces of the skin exist <ref> (Linvill, 1973) </ref>(Rheingold, 1991). Building a flexible, body-covering tactile array would be very difficult but not impossible. This completes the list of external sensory organs, leading to the conclusion that experience can potentially be reproduced with a fidelity that is indistinguishable from natural experience.
Reference: <author> Lippman, A. </author> <year> (1980). </year> <title> Movie-Maps: An Application of the Optical Videodisc to Computer Graphics, </title> <booktitle> Computer Graphics 14(3). </booktitle>
Reference-contexts: An optical tracker was also developed (Wang, Azuma, Bishop, Chi, Eyles & Fuchs, 1990). Micheal Naimark, 1980 Micheal Naimark did the cinematography for the Aspen "movie-map," the interactive videodisc-based simulation of driving around Aspen, Colorado <ref> (Lippman, 1980) </ref>.
Reference: <author> McGreevy, M. W. </author> <year> (1984). </year> <title> NASA Ames Virtual Environment Display: Applications Requirements [internal technical document], Aerospace Human Factors Research Division, </title> <institution> NASA Ames Research Center. </institution>
Reference-contexts: Mike McGreevy, 1984 At NASA Ames Research Center, starting in 1984, Mike McGreevy assembled LCD screens from pocket television sets, stereoscopic optics, a head tracker, and a motorcycle helmet to make the prototype HMD which was later refined and extended by Fisher, Robinett, and others <ref> (McGreevy, 1984) </ref>(Fisher, McGreevy, Humphries & Robinett, 1986).
Reference: <author> McGreevy, M. W. </author> <year> (1991). </year> <title> Virtual Reality and Planetary Exploration, </title> <booktitle> 29th AAS Goddard Memorial Symposium, </booktitle> <address> Washington DC. </address>
Reference-contexts: McGreevy's interests were in space applications of the HMD, and he tapped the image data of Mars returned by the Viking spacecraft to make a prototype system allowing simulated presence on the real topography of the Martian landscape as it was sensed by the spacecraft <ref> (McGreevy, 1991) </ref>. One potential use for this, given that lightspeed delays made teleoperation impossible on Mars, was to plan the exploration route for a semi-autonomous unmanned Mars rover vehicle.
Reference: <author> Mills, Peter H., Henry Fuchs. </author> <year> 1990. </year> <title> 3D ultrasound display using optical tracking. </title> <booktitle> Proceedings of the First Conference on Visualization in Biomedical Computing. </booktitle> <address> Atlanta, GA. </address> <pages> 490-497. </pages>
Reference-contexts: These high-powered graphics engines were used to explore applications for the HMD in medical imaging (Fuchs, Levoy & Pizer, 1989) <ref> (Mills & Fuchs, 1990) </ref> (Ohbuchi & Fuchs, 1990) (Ohbuchi & Fuchs, 1991), molecular graphics, and architecture. An optical tracker was also developed (Wang, Azuma, Bishop, Chi, Eyles & Fuchs, 1990).
Reference: <author> Naimark, M. </author> <year> (1991). </year> <title> Elements of Realspace Imaging: A Proposed Taxonomy, </title> <booktitle> Proceedings of SPIE: Electronic Imaging, </booktitle> <pages> 1457. </pages>
Reference-contexts: allows the user to pan in two dimensions through aerial views of the Bay Area with the direction of view always centered on the Golden Gate Bridge. 18 In his paper "Elements of Realspace Imaging," Naimark proposed a taxonomy of six successively more complete methods for recording and reproducing experience <ref> (Naimark, 1991) </ref>. These are: monoscopic imaging, stereoscopic imaging, multiscopic imaging, panoramics, surrogate travel, and "real-time" imaging. The first five categories cover techniques which allow successively greater freedom in achieving during replay arbitrary viewpoints in the 3D scene which was recorded.
Reference: <author> Ohbuchi, R. and H. Fuchs. </author> <year> 1990. </year> <title> Incremental 3D ultrasound imaging from a 2D scanner. </title> <booktitle> Proceedings of the First Conference on Visualization in Biomedical Computing. </booktitle> <address> Atlanta, GA. </address> <pages> 360-367. </pages>
Reference-contexts: These high-powered graphics engines were used to explore applications for the HMD in medical imaging (Fuchs, Levoy & Pizer, 1989) (Mills & Fuchs, 1990) <ref> (Ohbuchi & Fuchs, 1990) </ref> (Ohbuchi & Fuchs, 1991), molecular graphics, and architecture. An optical tracker was also developed (Wang, Azuma, Bishop, Chi, Eyles & Fuchs, 1990). Micheal Naimark, 1980 Micheal Naimark did the cinematography for the Aspen "movie-map," the interactive videodisc-based simulation of driving around Aspen, Colorado (Lippman, 1980).
Reference: <author> Ohbuchi, R., and H. Fuchs. </author> <year> 1991. </year> <title> Incremental volume rendering algorithm for interactive 3D ultrasound imaging. </title> <booktitle> Proceedings of the Information Processing in Medical Imaging (IPMI) Conference XII. </booktitle> <pages> 486-500. </pages>
Reference-contexts: These high-powered graphics engines were used to explore applications for the HMD in medical imaging (Fuchs, Levoy & Pizer, 1989) (Mills & Fuchs, 1990) (Ohbuchi & Fuchs, 1990) <ref> (Ohbuchi & Fuchs, 1991) </ref>, molecular graphics, and architecture. An optical tracker was also developed (Wang, Azuma, Bishop, Chi, Eyles & Fuchs, 1990). Micheal Naimark, 1980 Micheal Naimark did the cinematography for the Aspen "movie-map," the interactive videodisc-based simulation of driving around Aspen, Colorado (Lippman, 1980).
Reference: <author> Ouh-Young, M., D.V. Beard and F.P. Brooks, Jr. </author> <year> 1989. </year> <title> Force display performs better than visual display in a simple 6-D docking task. </title> <booktitle> Proceedings of IEEE 1989 Robotics and Automation Conference. </booktitle> <address> Scottsdale, AZ. </address> <month> 3 </month> <pages> 1462-1466. </pages> <editor> Rheingold, H.. </editor> <year> 1991. </year> <title> Virtual Reality. </title> <address> New York. </address> <publisher> Summit. </publisher>
Reference: <author> Robinett, W., Grimm, L. </author> <year> (1982). </year> <title> Rockys Boots [software product]. </title> <address> Fremont CA: </address> <publisher> The Learning Company. </publisher>
Reference-contexts: Rocky's Boots , published in 1982, was an interactive graphical simulation which taught digital logic design to children by allowing them to manually construct circuits on the screen and see signals flowing through the circuitry as it operated <ref> (Robinett & Grimm, 1982) </ref>(Robinett, 1983). In 1986, Robinett joined the team at NASA Ames with McGreevy and Fisher and wrote much of the initial software for the NASA HMD system (Fisher, McGreevy, Humphries & Robinett, 1986)(Rheingold, 1991).
Reference: <author> Robinett, W. </author> <year> (1983). </year> <title> Imaginary Worlds (unpublished book manuscript). </title>
Reference: <author> Robinett, W. </author> <year> (1990). </year> <institution> Artificial Reality at UNC Chapel Hill [videotape], </institution> <note> 10 minutes, SIGGRAPH Video Review. </note>
Reference-contexts: In 1986, Robinett joined the team at NASA Ames with McGreevy and Fisher and wrote much of the initial software for the NASA HMD system (Fisher, McGreevy, Humphries & Robinett, 1986)(Rheingold, 1991). In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project <ref> (Robinett, 1990) </ref> (Robinett & Rolland, 1991) (Robinett, 1991a) (Robinett, 1991b) (Holloway, Fuchs & Robinett, 1991) (Robinett & Holloway, 1992) and, later codirected the Nanomanipulator Project 19 (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992).
Reference: <author> Robinett, W., and J. Rolland. </author> <year> 1991. </year> <title> A computational model for the stereoscopic optics of a head-mounted display. To appear in Presence. </title> <booktitle> 1:1. Also in Proceedings of SPIE: Electronic Imaging, </booktitle> <volume> Vol. </volume> <pages> 1457, </pages> <address> Santa Clara, California, </address> <month> February </month> <year> 1991. </year>
Reference-contexts: In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project (Robinett, 1990) <ref> (Robinett & Rolland, 1991) </ref> (Robinett, 1991a) (Robinett, 1991b) (Holloway, Fuchs & Robinett, 1991) (Robinett & Holloway, 1992) and, later codirected the Nanomanipulator Project 19 (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992). <p> In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project (Robinett, 1990) (Robinett & Rolland, 1991) (Robinett, 1991a) (Robinett, 1991b) <ref> (Holloway, Fuchs & Robinett, 1991) </ref> (Robinett & Holloway, 1992) and, later codirected the Nanomanipulator Project 19 (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992).
Reference: <author> Robinett, W. </author> <year> (1991a). </year> <title> Electronic expansion of human perception. </title> <journal> Whole Earth Review. </journal> <pages> 16-21. </pages> <address> 30 Robinett, </address> <publisher> W. </publisher> <year> (1991b). </year> <title> Technological Augmentation of Memory, Perception, and Imagination, Virtual Seminar on the Bioapparatus, </title> <type> 17. Banff, </type> <institution> Alberta, Canada: The Banff Centre for the Arts. </institution>
Reference-contexts: The doctor can see and touch the abdomen of a pregnant woman and sees the data from the ultrasound scanner superimposed at the location from which it came, giving the perception of seeing into the living tissue <ref> (Robinett, 1991a) </ref>. A sensory prosthesis corrects, amplifies, or otherwise improves the fidelity of an ordinary built-in human sense. Examples are corrective spectacles, sunglasses, and hearing aids. For people with defective or nonfunctional senses, cross-sensory substitution can compensate for the disability. <p> A sensor-display linkage of this sort creates a synthetic sense, an apparatus that extends human perception and awareness <ref> (Robinett, 1991a) </ref>. Using a HMD as a display device offers the possibility of mapping sensed phenomena to specific locations 12 relative to the body of the user. <p> In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project (Robinett, 1990) (Robinett & Rolland, 1991) <ref> (Robinett, 1991a) </ref> (Robinett, 1991b) (Holloway, Fuchs & Robinett, 1991) (Robinett & Holloway, 1992) and, later codirected the Nanomanipulator Project 19 (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992).
Reference: <author> Robinett, W., and R. Holloway. </author> <year> 1992. </year> <title> Flying, grabbing and scaling in virtual worlds. </title> <booktitle> Proceedings 1992 ACM Symposium on Interactive 3D Graphics, </booktitle> <address> Cambridge MA. </address>
Reference-contexts: The Scanning-Tunneling Microscope (STM) is wellsuited to micro-teleoperation since it uses a tiny probe scanned over the sample surface to capture a 3D image of the 4 surface (at atomic resolution), and the probe tip can also be used as a micromanipulator to interact with the sample material <ref> (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992) </ref>. <p> In a system in which all of these data paths are present, all of these modes of operation are possible. In the UNC Nanomanipulator Project <ref> (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992) </ref>, for example, in which a HMD and force-feedback arm control a Scanning Tunneling Microscope (STM), transmitted experience, recorded experience, simulated experience, and supervisory control are all possible. <p> In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project (Robinett, 1990) (Robinett & Rolland, 1991) (Robinett, 1991a) (Robinett, 1991b) (Holloway, Fuchs & Robinett, 1991) <ref> (Robinett & Holloway, 1992) </ref> and, later codirected the Nanomanipulator Project 19 (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992). <p> In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project (Robinett, 1990) (Robinett & Rolland, 1991) (Robinett, 1991a) (Robinett, 1991b) (Holloway, Fuchs & Robinett, 1991) (Robinett & Holloway, 1992) and, later codirected the Nanomanipulator Project 19 <ref> (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992) </ref>.
Reference: <author> Robinett, W., Taylor, R., Chi, V., Wright. W. V., Brooks, F. P. Jr., Williams, R. S., & Snyder, E. J. </author> <year> (1992). </year> <title> The Nanomanipulator Project: An Atomic Scale Teleoperator (to appear in 1992 SIGGRAPH course notes for the course Implementation of Immersive Virtual Worlds). </title>
Reference-contexts: The Scanning-Tunneling Microscope (STM) is wellsuited to micro-teleoperation since it uses a tiny probe scanned over the sample surface to capture a 3D image of the 4 surface (at atomic resolution), and the probe tip can also be used as a micromanipulator to interact with the sample material <ref> (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992) </ref>. <p> In a system in which all of these data paths are present, all of these modes of operation are possible. In the UNC Nanomanipulator Project <ref> (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992) </ref>, for example, in which a HMD and force-feedback arm control a Scanning Tunneling Microscope (STM), transmitted experience, recorded experience, simulated experience, and supervisory control are all possible. <p> In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project (Robinett, 1990) (Robinett & Rolland, 1991) (Robinett, 1991a) (Robinett, 1991b) (Holloway, Fuchs & Robinett, 1991) <ref> (Robinett & Holloway, 1992) </ref> and, later codirected the Nanomanipulator Project 19 (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992). <p> In 1989, he went to the University of North Carolina where he directed the Head-Mounted Display Project (Robinett, 1990) (Robinett & Rolland, 1991) (Robinett, 1991a) (Robinett, 1991b) (Holloway, Fuchs & Robinett, 1991) (Robinett & Holloway, 1992) and, later codirected the Nanomanipulator Project 19 <ref> (Robinett, Taylor, Chi, Wright, Brooks, Williams & Snyder, 1992) </ref>.
Reference: <author> Sheridan, T. B. </author> <year> (1992). </year> <title> Musings on Telepresence and Virtual Presence, </title> <type> Presence 1(1). </type>
Reference: <author> Steelman, H.S. </author> <year> 1968. </year> <title> The GROPE-I system: An analysis of friction and backlash problems. </title> <type> MS thesis. </type> <institution> University of North Carolina, Chapel Hill. </institution>
Reference-contexts: pioneered using computer graphics and computersimulated virtual worlds for training aircraft pilots. 16 Fred Brooks, 1968 Beginning in the late Sixties, Fred Brooks and his students constructed and tested force-feedback devices for display of force to the hand, which were used in conjunction with graphic displays of interactive virtual worlds <ref> (Steelman, 1968) </ref>(Batter & Brooks, 1971)(Ouh-Young, Beard & Brooks, 1989)(Brooks, Ouh-Young, Batter & Kilpatrick, 1990). They also explored interactive 3D graphical simulations, with particular emphasis on using computer graphics to represent and simulate molecules (Wright, 1972) and to represent the interior of buildings (Brooks, 1986)(Airey, Rohlf & Brooks, 1990).
Reference: <author> Sutherland, I. E. </author> <year> (1965). </year> <title> The ultimate display, </title> <booktitle> 1965 Proceedings of the IFIPS Congress, </booktitle> <volume> 2, </volume> <pages> 506-508. </pages>
Reference-contexts: Ivan Sutherland, 1965 In his paper "The Ultimate Display," Ivan Sutherland proposed that a computer-based, multi-sensory, interactive simulated world could be created with the ultimate goal that it "look real, feel real, and act real" <ref> (Sutherland, 1965) </ref>. He proposed that a mathematical simulation, such as one of forces on charged particles, could give a user an experience not possible in the physical world. He considered covering all the senses, and discussed visual, auditory, and kinesthetic displays but dismissed smell and taste displays.
Reference: <author> Sutherland, I. E. </author> <year> (1968). </year> <title> A head-mounted three-dimensional display, </title> <booktitle> 1968 Fall Joint Computer Conference, AFIPS Conference Proceedings, </booktitle> <volume> 33, </volume> <pages> 757-764. </pages>
Reference-contexts: He considered covering all the senses, and discussed visual, auditory, and kinesthetic displays but dismissed smell and taste displays. His discussion was of simulated experience and did not consider transmitted or recorded experience. A few years later, Sutherland built the first head-mounted display for displaying computersimulated 3D virtual worlds <ref> (Sutherland, 1968) </ref>. This prototype was monochromatic, eventually stereoscopic, and could display simple wire-frame images in correct perspective. The position and orientation of the user's head, which was allowed to move within certain limits, was measured with a mechanical linkage.
Reference: <author> Vickers, D. L. </author> <year> (1974). </year> <title> Sorcerors Apprentice: head mounted display and wand, </title> <type> Ph.D. dissertation, </type> <institution> Dept. of Computer Science, Univ. of Utah, </institution> <address> Salt Lake City. </address>
Reference-contexts: The position and orientation of the user's head, which was allowed to move within certain limits, was measured with a mechanical linkage. A manual input device was later added which could also move in 3D <ref> (Vickers, 1974) </ref>.
Reference: <author> Wang, J., R. Azuma, G. Bishop, V. Chi, J. Eyles, and H. Fuchs. </author> <year> 1990. </year> <title> Tracking a head-mounted display in a roomsized environment with head-mounted cameras. </title> <booktitle> Proceedings: SPIE 90 Technical Symposium on Optical Engineering & Photonics in Aerospace Sensing. </booktitle> <address> Orlando, FL. </address>
Reference-contexts: These high-powered graphics engines were used to explore applications for the HMD in medical imaging (Fuchs, Levoy & Pizer, 1989) (Mills & Fuchs, 1990) (Ohbuchi & Fuchs, 1990) (Ohbuchi & Fuchs, 1991), molecular graphics, and architecture. An optical tracker was also developed <ref> (Wang, Azuma, Bishop, Chi, Eyles & Fuchs, 1990) </ref>. Micheal Naimark, 1980 Micheal Naimark did the cinematography for the Aspen "movie-map," the interactive videodisc-based simulation of driving around Aspen, Colorado (Lippman, 1980).
Reference: <author> Weiss, R. </author> <year> (1989). </year> <title> New Dancer in the Hive, </title> <journal> Science News 136(18), </journal> <note> 282-3 Wenzel, </note> <author> E. M., Wightman, F. L., Foster, S. H. </author> <year> (1988). </year> <title> A Virtual Acoustic Display for Conveying Three-Dimensional Information, </title> <booktitle> Proceedings of the Human Factors Society. </booktitle>
Reference-contexts: with recorded bird calls (Bright, 1984), and also with a computer-controlled robot bee, which was able to direct real bees to specific locations far from the hive by moving in the patterned dance that bees use to communicate and then dispensing a sweet liquid sample of the (pretended) distant pollen <ref> (Weiss, 1989) </ref>. The connection with synthetic experience is that a human could potentially teleoperate a robot bee to attempt to communicate in real-time with real bees.
Reference: <author> Wright, W. V. </author> <year> (1972). </year> <title> An Interactive Computer Graphics System for Molecular Studies, </title> <type> Ph.D. dissertation, </type> <institution> Dept. of Computer Science, University of North Carolina, Chapel Hill. </institution>
Reference-contexts: They also explored interactive 3D graphical simulations, with particular emphasis on using computer graphics to represent and simulate molecules <ref> (Wright, 1972) </ref> and to represent the interior of buildings (Brooks, 1986)(Airey, Rohlf & Brooks, 1990). A see-through HMD was built and tested for various applications (Chung, Harris, Brooks, Fuchs, Kelley, Hughes, Ouh-Young, Cheung, Holloway & Pique, 1989).
Reference: <author> Zeltzer, D. </author> <year> (1992). </year> <title> Autonomy, Interaction, and Presence, </title> <type> Presence 1(1). </type>
Reference-contexts: Knowledge is in experience. Data is in the environment. Scale and time are explorable dimensions. One experience is worth a trillion bits. Realism is not necessary." David Zeltzer, 1991 In his 1991 paper "Autonomy, Interaction, and Presence," David Zeltzer proposed "a taxonomy of graphical simulation systems <ref> (Zeltzer, 1992) </ref>. The taxonomy consisted of three independent scalar dimensions which defined a space of possibilities, the "AIP cube". The dimension autonomy described the sophistication and dynamics of the model defining the virtual world. Interaction measured the degree to which user actions could affect what happened in the virtual world.
References-found: 64

