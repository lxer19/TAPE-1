URL: http://polaris.cs.uiuc.edu/reports/1310.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Automatic Generation and Management of Program Analyses  
Author: Kwangkeun Yi 
Degree: THESIS Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosphy in Computer Science in the Graduate College of the  
Note: 1993 1 This work was supported in part by the U.S. Department of Energy under Grant No. DE FG02-85ER25001 with additional support from NSF under Grant No. NSF CCR 90-24554.  
Address: 1  
Affiliation: Department of Computer Science Center for Supercomputing Research and Development  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [AGT89] <author> Alfred V. Aho, Mahadevan Ganapathi, and Steven W. K. Tjiang. </author> <title> Code generation using tree matching and dynamic programming. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 491-516, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: analyses for these languages using Z1. * System Z1 facilitates the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG <ref> [AGT89] </ref> and [NN, App85, Ras82] for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90].
Reference: [AH87] <editor> Samson Abramsky and Chris Hankin, editors. </editor> <title> Abstract Interpretation of Declarative Languages. </title> <publisher> Ellis Horwood Limited, </publisher> <year> 1987. </year>
Reference-contexts: The specification is an abstract interpreter definition. This abstract interpreter specification is the starting point for (input to) system Z1. The abstract interpretation framework <ref> [CC92a, CC79, CC77, AH87] </ref> is a method for designing approximate interpreters which can provide sound answers to questions about the run-time behavior of programs. An abstract interpreter determines how to simulate the programs correctly at compile-time (that is, without overlooking any of their run-time behavior).
Reference: [Amm92] <author> Zahira Ammarguellat. </author> <title> A control-flow normalization algorithm and its complexity. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 18(3) </volume> <pages> 237-251, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: It has no goto or return. These control constructs in the source programs are removed by the MIPRAC front-ends using the control flow normalization method in <ref> [Amm92] </ref>. The reader may want to see [HA92] or [Har92] for the definition of MIL. An informal semantics for each expression constructs is as follows.
Reference: [App85] <author> Andrew W. Appel. </author> <title> Semantics-directed code generation. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 315-324, </pages> <year> 1985. </year>
Reference-contexts: these languages using Z1. * System Z1 facilitates the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and <ref> [NN, App85, Ras82] </ref> for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90].
Reference: [Bar77] <author> Jeffrey M. Barth. </author> <title> An interprocedural data flow analysis algorithm. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 119-131, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: An approximate, compile-time interpretation rule for procedure calls is all that is needed for interprocedural analysis. As defined in this rule, the analysis will bind the parameters and interpret the body. This approach is different from conventional ones <ref> [Cal88, Mye81, Wei80, Bar77] </ref> in two respects. First, aliases (due to reference parameters) and recursive calls, which were considered two principal problems of interprocedural analysis, are treated by simulating directly the language construct that causes them (in this case, the call expression).
Reference: [BC86] <author> Michael Burke and Ron Cytron. </author> <title> Interprocedural dependence analysis and parallelization. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction (SIGPLAN Notice Vol.21, No.7), </booktitle> <pages> pages 162-175, </pages> <month> July </month> <year> 1986. </year>
Reference: [BH91] <author> B.A.Davey and H.A.Priestley. </author> <title> Introduction to Lattices and Order. </title> <publisher> Cam-bridge Mathematical Texbooks. Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: Our definition follows from the fact that a lattice isomorphism is equivalent to an order isomor-phism (an order preserving one-to-one and onto map; see Definition 1.11 and Proposition 5.11 in <ref> [BH91] </ref>). Our definition helps to simplify the proof of Property 8 (page 39) because it does not involve the join and meet operations.
Reference: [Bur87] <author> Geoffrey L. Burn. </author> <title> Abstract Interpretation and the Parallel Evaluation of Functional Languages. </title> <type> PhD thesis, </type> <institution> Department of Computing, Imperial College, University of London, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in [CC92b, CC92a]) for defining correct abstract interpreters, which are based either on denotational semantics <ref> [Bur87, Bur91, MJ85, Nie85] </ref> or on operational semantics [CC77, CC79, CC92b]. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. Projection is not a complete notion for controlling the accuracy-cost tradeoff of an abstract interpreter.
Reference: [Bur91] <author> Geoffrey L. Burn. </author> <title> The abstract interpretation of higher-order functional languages: From properties to abstract domains (technical summary). </title> <type> 160 BIBLIOGRAPHY 161 Technical report, </type> <institution> Imperial Collge of Science, Technology and Medicine, </institution> <year> 1991. </year>
Reference-contexts: Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in [CC92b, CC92a]) for defining correct abstract interpreters, which are based either on denotational semantics <ref> [Bur87, Bur91, MJ85, Nie85] </ref> or on operational semantics [CC77, CC79, CC92b]. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. Projection is not a complete notion for controlling the accuracy-cost tradeoff of an abstract interpreter.
Reference: [Cal88] <author> David Callahan. </author> <title> The program summary graph and flow-sensitive interpro-cedural data flow analysis. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 47-56, </pages> <year> 1988. </year>
Reference-contexts: An approximate, compile-time interpretation rule for procedure calls is all that is needed for interprocedural analysis. As defined in this rule, the analysis will bind the parameters and interpret the body. This approach is different from conventional ones <ref> [Cal88, Mye81, Wei80, Bar77] </ref> in two respects. First, aliases (due to reference parameters) and recursive calls, which were considered two principal problems of interprocedural analysis, are treated by simulating directly the language construct that causes them (in this case, the call expression). <p> Second, the program's call graph is not assumed as given prior to the analysis. As we discussed above, this is important when the target language allows procedures as first-class objects. Accuracy improvement by clever representations of the call graph <ref> [Cal88, Mye81] </ref> may still be applicable in abstract interpretation, if the improvement is applied as a post-analysis process, when the call graph has been constructed. * The abstract interpretation framework makes it feasible to generate compile time analyses from high-level specifications automatically.
Reference: [CC77] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> In Conference Record of the 4th ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1977. </year>
Reference-contexts: From this input, the system generates a program analyzer in C. The system arranges that the generated analyzer should conduct the analysis with the specified cost-accuracy tradeoff. System Z1 is based on abstract interpretation <ref> [CC77, CC79, CC92a] </ref>. The input for the generation part is an abstract interpreter of the target language. The input for the management part is a set of expressions (called projection expressions) that controls the degree of abstraction of the interpreter. <p> Thus, its virtues come from the power of the abstract interpretation framework <ref> [CC77, CC79, CC92a] </ref>. Z1 allows us to specify a detailed analysis for difficult and dynamic language features (e.g., aliases, unrestrained pointer manipulation, dynamic memory allocation, first-class functions). <p> The specification is an abstract interpreter definition. This abstract interpreter specification is the starting point for (input to) system Z1. The abstract interpretation framework <ref> [CC92a, CC79, CC77, AH87] </ref> is a method for designing approximate interpreters which can provide sound answers to questions about the run-time behavior of programs. An abstract interpreter determines how to simulate the programs correctly at compile-time (that is, without overlooking any of their run-time behavior). <p> Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in [CC92b, CC92a]) for defining correct abstract interpreters, which are based either on denotational semantics [Bur87, Bur91, MJ85, Nie85] or on operational semantics <ref> [CC77, CC79, CC92b] </ref>. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. Projection is not a complete notion for controlling the accuracy-cost tradeoff of an abstract interpreter.
Reference: [CC79] <author> Patrick Cousot and Radhia Cousot. </author> <title> Systematic design of program analysis frameworks. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 269-282, </pages> <year> 1979. </year>
Reference-contexts: From this input, the system generates a program analyzer in C. The system arranges that the generated analyzer should conduct the analysis with the specified cost-accuracy tradeoff. System Z1 is based on abstract interpretation <ref> [CC77, CC79, CC92a] </ref>. The input for the generation part is an abstract interpreter of the target language. The input for the management part is a set of expressions (called projection expressions) that controls the degree of abstraction of the interpreter. <p> Thus, its virtues come from the power of the abstract interpretation framework <ref> [CC77, CC79, CC92a] </ref>. Z1 allows us to specify a detailed analysis for difficult and dynamic language features (e.g., aliases, unrestrained pointer manipulation, dynamic memory allocation, first-class functions). <p> The specification is an abstract interpreter definition. This abstract interpreter specification is the starting point for (input to) system Z1. The abstract interpretation framework <ref> [CC92a, CC79, CC77, AH87] </ref> is a method for designing approximate interpreters which can provide sound answers to questions about the run-time behavior of programs. An abstract interpreter determines how to simulate the programs correctly at compile-time (that is, without overlooking any of their run-time behavior). <p> Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in [CC92b, CC92a]) for defining correct abstract interpreters, which are based either on denotational semantics [Bur87, Bur91, MJ85, Nie85] or on operational semantics <ref> [CC77, CC79, CC92b] </ref>. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. Projection is not a complete notion for controlling the accuracy-cost tradeoff of an abstract interpreter.
Reference: [CC92a] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation frameworks. </title> <type> Technical Report LIX/RR/92/10, </type> <institution> Ecole Polytechnique, </institution> <year> 1992. </year>
Reference-contexts: From this input, the system generates a program analyzer in C. The system arranges that the generated analyzer should conduct the analysis with the specified cost-accuracy tradeoff. System Z1 is based on abstract interpretation <ref> [CC77, CC79, CC92a] </ref>. The input for the generation part is an abstract interpreter of the target language. The input for the management part is a set of expressions (called projection expressions) that controls the degree of abstraction of the interpreter. <p> Thus, its virtues come from the power of the abstract interpretation framework <ref> [CC77, CC79, CC92a] </ref>. Z1 allows us to specify a detailed analysis for difficult and dynamic language features (e.g., aliases, unrestrained pointer manipulation, dynamic memory allocation, first-class functions). <p> The specification is an abstract interpreter definition. This abstract interpreter specification is the starting point for (input to) system Z1. The abstract interpretation framework <ref> [CC92a, CC79, CC77, AH87] </ref> is a method for designing approximate interpreters which can provide sound answers to questions about the run-time behavior of programs. An abstract interpreter determines how to simulate the programs correctly at compile-time (that is, without overlooking any of their run-time behavior). <p> For example, it does not check 157 6.2 Limitations and Discussion 158 the monotonicity of the functions in the abstract interpreter. Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in <ref> [CC92b, CC92a] </ref>) for defining correct abstract interpreters, which are based either on denotational semantics [Bur87, Bur91, MJ85, Nie85] or on operational semantics [CC77, CC79, CC92b]. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections.
Reference: [CC92b] <author> Patrick Cousot and Radhia Cousot. </author> <title> Inductive definitions, semantics and abstract interpretation. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 83-94, </pages> <year> 1992. </year>
Reference-contexts: For example, it does not check 157 6.2 Limitations and Discussion 158 the monotonicity of the functions in the abstract interpreter. Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in <ref> [CC92b, CC92a] </ref>) for defining correct abstract interpreters, which are based either on denotational semantics [Bur87, Bur91, MJ85, Nie85] or on operational semantics [CC77, CC79, CC92b]. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. <p> Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in [CC92b, CC92a]) for defining correct abstract interpreters, which are based either on denotational semantics [Bur87, Bur91, MJ85, Nie85] or on operational semantics <ref> [CC77, CC79, CC92b] </ref>. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. Projection is not a complete notion for controlling the accuracy-cost tradeoff of an abstract interpreter.
Reference: [CCF91] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> Automatic construction of sparse data flow evaluation graphs. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 55-66, </pages> <year> 1991. </year>
Reference: [CCKT86] <author> David Callahan, Keith D. Cooper, Ken Kennedy, and Linda Torczon. </author> <title> Interprocedural constant propagation. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(7) </volume> <pages> 152-161, </pages> <month> July </month> <year> 1986. </year>
Reference: [CH92] <author> Liling Chen and Williams Ludwell Harrison III. </author> <title> An efficient algorithm for complex program analysis. </title> <type> Technical report, </type> <institution> Center for Supercomputing R & D, Univ. of Illinois at Urbana-Champaign, </institution> <year> 1992. </year>
Reference-contexts: We do not address this issue in this thesis. A number of good heuristics for the order are reported in <ref> [CH92] </ref>. Entailment Graph: A By-product of the Worklist Algorithm The principal outputs of the collecting analysis are the two tables T X and T Y that map each program point to the pre-state and the post-state that occur before and after the program point during execution.
Reference: [CJ83] <author> Henning Christiansen and Neil Jones. </author> <title> Control flow treatment in a simple semantics-directed compiler generator. </title> <editor> In D. Bjorner, editor, </editor> <booktitle> Formal Description of Programming Concepts II, </booktitle> <pages> pages 73-97. </pages> <publisher> North-Holland Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE [Gau80]), and <ref> [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] </ref> We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [CR88] <author> Martin D. Carroll and Barbara G. Ryder. </author> <title> Incremental data flow analysis via dominator and attribute updates. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 274-284, </pages> <year> 1988. </year> <note> BIBLIOGRAPHY 162 </note>
Reference: [Eor91] <author> Istvan Eorgacs. </author> <title> Occurrence-sensitive interprocedural data flow analysis. </title> <booktitle> In Proceedings of the Second Symposium on Programming Languages and Software Tools, </booktitle> <pages> pages 55-69, </pages> <month> August </month> <year> 1991. </year>
Reference: [ES86] <author> M. E.Lesk and E. Schmidt. Lex: </author> <title> A lexical analyzer generator. In Unix Programmer's Manual Supplementary Documents 1. </title> <year> 1986. </year>
Reference-contexts: We can design a variety of program analyses for these languages using Z1. * System Z1 facilitates the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX <ref> [ES86] </ref> for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and [NN, App85, Ras82] for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer.
Reference: [Far86] <author> Rodney Farrow. </author> <title> Automatic generation of fixed-point-finding evaluators for circular, but well-defined, attribute grammars. </title> <booktitle> In Proceedings of SIGPLAN '86 Symposium on Compiler Construction, SIGPLAN Notices, </booktitle> <pages> pages 85-98, </pages> <year> 1986. </year>
Reference-contexts: of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and [NN, App85, Ras82] for the code generator, LIGA [Kas90] and <ref> [Far86] </ref> for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90].
Reference: [Gau80] <author> M. C. </author> <title> Gaudel. Specification of compliers as abstract data type representation. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 94, </volume> <pages> pages 140-164, </pages> <year> 1980. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE <ref> [Gau80] </ref>), and [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [GG82] <author> Harald Ganzinger and Robert Giegerich. </author> <title> A truly generative semantics-directed compiler generator. </title> <booktitle> In Proceedings of SIGPLAN '82 Symposium on Compiler Construction, volume 17 of SIGPLAN Notices, </booktitle> <pages> pages 172-184, </pages> <year> 1982. </year>
Reference-contexts: Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 <ref> [Wil81, GG82] </ref>, HLP84 [KNPS88], and Rie/Jun [Sas90]. <p> Z1 is distinguished from other similar tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> in three ways. First, system Z1 is based on the abstract interpretation framework. <p> Projections over the types of an abstract interpreter permits high-level management of the accuracy-cost tradeoff of the analysis. Third, it has a high-level specification language in which the user can conveniently express an abstract interpreter succinctly and conveniently. Other analysis generation tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> have difficulty in handling interprocedural analysis specifications, are limited to specific target languages, are limited to a class of simple analyses (e.g. bit-vector representation of the data flow values), require substantial amount of code (in the implementation language) from the user, and have no high-level facility
Reference: [GHLaWMW92] <author> R. W. Gray, V. P. Heuring, S. P. Levi, and A. M. Sloane ans W. M. Waite. Eli: </author> <title> A complete, flexible compiler construction system. </title> <journal> Communications of the ACM, </journal> <volume> 35(2), </volume> <year> 1992. </year>
Reference-contexts: Collections of compiler-component generators have been integrated into single compiler writing systems: ELI <ref> [GHLaWMW92] </ref>, MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90].
Reference: [GK88] <author> J. Grosch and E. Klein. </author> <title> User manual for the pgs system. </title> <type> Technical report, </type> <institution> GMD, Research Institute at the University of Karlsruhe, </institution> <year> 1988. </year>
Reference-contexts: design a variety of program analyses for these languages using Z1. * System Z1 facilitates the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS <ref> [GK88] </ref> for the parser, TWIG [AGT89] and [NN, App85, Ras82] for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer.
Reference: [GKK + 80] <author> G.Giertz, K.H.Hofmann, K.Keimel, J.D.Lawson, M.Mislove, and D.S.Scott. </author> <title> A Compendium of Continuous Lattices. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1980. </year>
Reference-contexts: A projection is a function from a lattice into itself such that its image is still a lattice <ref> [GKK + 80] </ref> but has shorter chains than the original lattice does (this is implied by its extensivity Id v ). Figure 2.3 shows how projections simplify the domain structures.
Reference: [GW76] <author> Susan L. Graham and Mark Wegman. </author> <title> A fast and usually linear algorithm for global flow analysis. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 172-202, </pages> <year> 1976. </year>
Reference: [HA92] <author> Williams Ludwell Harrison III and Zahira Ammarguellat. </author> <title> A program's eye view of miprac. </title> <editor> In D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <title> Languages and Compilers for Parallel Computing (Also as a UIUC CSRD Report 1227). </title> <publisher> MIT Press, </publisher> <month> August </month> <year> 1992. </year>
Reference-contexts: System Z1 does not generate the syntax tree, nor does it provide any operator to access its nodes. The user must write C procedures for those operations and use them as foreign procedures. Currently, we have implemented ANSI C, FORTRAN, and SCHEME front-ends for an intermediate language MIL (MIPRAC <ref> [HA92] </ref> Intermediate Language), along with a set of routines to access MIL programs, so that Z1 may be used to analyze programs in these source languages. 64 4.10 Syntax of Z1 65 4.10 Syntax of Z1 4.10.1 Lexical Rule Lexical rule for identifier, number, and comment is the following. initial [a-zA-Z] <p> We also show how projections are used to manage their accuracy and cost. We discuss a case in which the analysis cost is reduced by projections without a loss of accuracy. The target language for all our examples is an intermediate language called MIL (MIPRAC Intermediate Language <ref> [HA92] </ref>), into which C, FORTRAN, and SCHEME programs are translated. The generated analyzers do not have any restriction regarding the input program text; they perform an interprocedural analysis of any legitimate program in the target language. We have implemented the following analyses: * Alias analysis. <p> The interval from the creation time until the last access point is the longevity of an object. 5.1 The Target Language MIL All the analyses in this chapter have MIL (MIPRAC <ref> [HA92] </ref> Intermediate Language) as the target language. That is, the generated analyzers analyze source programs written in MIL. Since we have ANSI C, FORTRAN, and SCHEME front-ends already built for MIL, our analyses analyze programs written in those languages. The abstract syntax of MIL is shown in Figure 5.1. <p> It has no goto or return. These control constructs in the source programs are removed by the MIPRAC front-ends using the control flow normalization method in [Amm92]. The reader may want to see <ref> [HA92] </ref> or [Har92] for the definition of MIL. An informal semantics for each expression constructs is as follows. We need to understand the standard semantics of MIL because we will define abstract interpreters (approximate semantics) for it later. * (begin e 0 e n ): Evaluate the expressions in sequence. <p> Although it is possible to use the system to analyze any programming language, we use it to analyze MIL (MIPRAC <ref> [Har92, HA92] </ref> Intermediate Language) programs, because we have C, FORTRAN, and SCHEME translators to MIL already built.
Reference: [Har89] <author> Williams L. Harrison III. </author> <title> The interprocedural analysis and automatic parallelization of scheme programs. </title> <booktitle> Lisp and Symbolic Computation, 2(3 and </booktitle> 4):179-396, 1989. 
Reference-contexts: When we access a location whose instance gs has multiple elements of setG, we join the store entries (@ ss g) for each g in gs. 3 We borrow this term from <ref> [Har89] </ref>, where a much more elaborate version than ours is used. 114 5.4 Alias Analysis and Constant Propagation 115 (types (domain PRE (* E S P)) ; pre-state (domain POST (* S V)) ; post-stae (domain S (-&gt; Id SS)) ; store (domain SS (-&gt; G V)) ; second-level store (domain
Reference: [Har92] <author> Williams Ludwell Harrison III. </author> <title> Semantic Analysis of Symbolic Programs for Automatic Parallelization. </title> <note> Book in preparation, 1992. 162 BIBLIOGRAPHY 163 </note>
Reference-contexts: We will discuss these properties in Chapter 3. Worklist Algorithm for Computing the Fixpoint uses a worklist algorithm which invokes F only for a subset of program points whose T X and T Y entries were changed by the previous iteration. The worklist algorithm <ref> [Har92] </ref> is in Figure 2.2. Note that we can further improve the speed of this worklist algorithm. It depends on how the Select and Add procedures are implemented. These determine the order in which program points are selected from and added to the worklist. <p> An important by-product of the worklist algorithm (Figure 2.2) is the entailment graph <ref> [Har92] </ref> of the input program. The nodes of this graph are the program points. An edge x ! y from a program point x to y indicates that the evaluation of x requires (entails) that of y. <p> It has no goto or return. These control constructs in the source programs are removed by the MIPRAC front-ends using the control flow normalization method in [Amm92]. The reader may want to see [HA92] or <ref> [Har92] </ref> for the definition of MIL. An informal semantics for each expression constructs is as follows. We need to understand the standard semantics of MIL because we will define abstract interpreters (approximate semantics) for it later. * (begin e 0 e n ): Evaluate the expressions in sequence. <p> An example translation of a C program into its MIL counterpart is shown in Figure 5.2 and This front end for C is written by Harrison as a component of the MIPRAC <ref> [Har92] </ref> compiler system. 5.2 Starting Point: A Template Abstract Interpreter An abstract interpreter for MIL will be an instantiation of the template abstract interpreter E in Figure 5.4. <p> The read, write, and call expression requires some complicated manipulations of the block index values. The reader is recommended to see <ref> [Har92] </ref> or in [YH92] for those operations written in conventional mathematical form. Ours are just a transliteration of those definitions into Z1. * Analysis of array.c (Figure 5.32) with Projection (project (height&gt; 1)) and No Projection of Locations Consider the C program array.c in Figure 5.32. <p> Although it is possible to use the system to analyze any programming language, we use it to analyze MIL (MIPRAC <ref> [Har92, HA92] </ref> Intermediate Language) programs, because we have C, FORTRAN, and SCHEME translators to MIL already built.
Reference: [Hec77] <author> Matthew S. Hecht. </author> <title> Flow Analysis of Comptuer Programs. </title> <publisher> Elsevier North-Holland, Inc., </publisher> <year> 1977. </year>
Reference-contexts: Conventional data flow analysis methods (as summarized in <ref> [RP86, Hec77] </ref>) have several limitations. First, they assume the control flow graphs of programs prior to the analysis. For languages like FORTRAN this is not a problem because the control flow graph of a program can be (largely) determined from its text.
Reference: [HK92] <author> Mary W. Hall and Ken Kennedy. </author> <title> Efficient call graph analysis. </title> <type> Technical Report COMP TR92-187, </type> <institution> Rice University, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: In order to avoid this overly conservative approach, we must follow the program execution and simulate the parameter binding mechanism. But this requires as complicated a computation as another program analysis! This problem is well-known and addressed in several studies <ref> [Shi91, Shi88, HK92] </ref>. Shivers [Shi91, Shi88] used continuation passing style representations of SCHEME programs to simplify his control flow analysis. Hall and Kennedy [HK92] devised a compile-time method of simulating the parameter binding mechanism to compute the call graph of C or SCHEME programs. <p> But this requires as complicated a computation as another program analysis! This problem is well-known and addressed in several studies [Shi91, Shi88, HK92]. Shivers [Shi91, Shi88] used continuation passing style representations of SCHEME programs to simplify his control flow analysis. Hall and Kennedy <ref> [HK92] </ref> devised a compile-time method of simulating the parameter binding mechanism to compute the call graph of C or SCHEME programs. In the abstract interpretation, however, determining the control flow graph is not a prerequisite for an analysis.
Reference: [HM90] <author> John Hannan and Dale Miller. </author> <title> From oeprational semantics to abstract machines: Preliminary results. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Lisp and Functional Programming, </booktitle> <pages> pages 323-332, </pages> <year> 1990. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE [Gau80]), and <ref> [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] </ref> We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [HY91] <author> Paul Hudak and Jonathan Young. </author> <title> Collecting interpretations of expressions. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 269-290, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: We call this a collecting analysis <ref> [HY91] </ref>. The input to the generated analyzer is the source program to be compiled.
Reference: [JM82] <author> Neil D. Jones and Steven S. Muchnick. </author> <title> A flexible approach to interpro-cedural data flow analysis and programs with recursive data structures. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 66-74, </pages> <year> 1982. </year>
Reference: [Joh86] <author> Stephen C. Johnson. </author> <title> Yacc: Yet another compiler-compiler. In Unix Programmer's Manual Supplementary Documents 1. </title> <year> 1986. </year>
Reference-contexts: We can design a variety of program analyses for these languages using Z1. * System Z1 facilitates the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC <ref> [Joh86] </ref> and PGS [GK88] for the parser, TWIG [AGT89] and [NN, App85, Ras82] for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer.
Reference: [JS80] <author> Neil D. Jones and David A. Schmidt. </author> <title> Compiler generation from denota-tional semantics. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 94, </volume> <pages> pages 70-93, </pages> <year> 1980. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE [Gau80]), and <ref> [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] </ref> We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [Kas90] <author> U. Kastens. Liga: </author> <title> A language independent generator for attribute evaluator. </title> <type> Technical report, </type> <institution> University of Paderborn, </institution> <year> 1990. </year>
Reference-contexts: the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and [NN, App85, Ras82] for the code generator, LIGA <ref> [Kas90] </ref> and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90].
Reference: [Ken76] <author> Ken Kennedy. </author> <title> A comparison of two algorithms for global data flow analysis. </title> <journal> SIAM Journal on Computing, </journal> <volume> 5(1) </volume> <pages> 158-180, </pages> <month> March </month> <year> 1976. </year>
Reference: [KNPS88] <author> Kai Koskimies, Otto Nurmi, Jukka Paakki, and Seppo Sippu. </author> <title> The design of a language processor generator. </title> <journal> Software-Practice and Experience, </journal> <volume> 18(2) </volume> <pages> 107-135, </pages> <year> 1988. </year>
Reference-contexts: Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 <ref> [KNPS88] </ref>, and Rie/Jun [Sas90]. <p> Z1 is distinguished from other similar tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> in three ways. First, system Z1 is based on the abstract interpretation framework. <p> Projections over the types of an abstract interpreter permits high-level management of the accuracy-cost tradeoff of the analysis. Third, it has a high-level specification language in which the user can conveniently express an abstract interpreter succinctly and conveniently. Other analysis generation tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> have difficulty in handling interprocedural analysis specifications, are limited to specific target languages, are limited to a class of simple analyses (e.g. bit-vector representation of the data flow values), require substantial amount of code (in the implementation language) from the user, and have no high-level facility
Reference: [KU76] <author> John B. Kam and Jeffrey D. Ullman. </author> <title> Global data flow analysis and iterative alorithm. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 158-171, </pages> <year> 1976. </year>
Reference: [KU77] <author> John B. Kam and Jeffrey D. Ullman. </author> <title> Monotone data flow analysis frameworks. </title> <journal> Acta Informatica, </journal> <volume> 7 </volume> <pages> 305-317, 77. </pages>
Reference: [Lee89] <author> Peter Lee. </author> <title> Realistic Compiler Generation. </title> <booktitle> Foundations of Computing Series. </booktitle> <publisher> The MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess <ref> [LP87, Lee89] </ref>, Ceres [Tof90], PERLUETTE [Gau80]), and [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways.
Reference: [LP87] <author> Peter Lee and Uwe Pleban. </author> <title> A realistic compiler generator based on high-level semantics. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 284-295, </pages> <year> 1987. </year> <note> 163 BIBLIOGRAPHY 164 </note>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess <ref> [LP87, Lee89] </ref>, Ceres [Tof90], PERLUETTE [Gau80]), and [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways.
Reference: [MJ85] <author> Alan Mycroft and Neil D. Jones. </author> <title> A relational framework for abstract interpretation. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 217. </volume> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in [CC92b, CC92a]) for defining correct abstract interpreters, which are based either on denotational semantics <ref> [Bur87, Bur91, MJ85, Nie85] </ref> or on operational semantics [CC77, CC79, CC92b]. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. Projection is not a complete notion for controlling the accuracy-cost tradeoff of an abstract interpreter.
Reference: [Mos76] <author> P. D. Mosses. </author> <title> Compiler generation using denotational semantics. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 76, </volume> <pages> pages 436-441. </pages> <publisher> Springer-Verlag, </publisher> <year> 1976. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE [Gau80]), and <ref> [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] </ref> We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [Mos80] <author> Peter Mosses. </author> <title> A constructive approach to compiler correctness. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 94, </volume> <pages> pages 189-210. </pages> <year> 1980. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE [Gau80]), and <ref> [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] </ref> We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [MR90] <author> Thomas J. Marlowe and Barbara G. Ryder. </author> <title> An efficient hybrid algorithm for incremental data flow analysis. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 184-196, </pages> <year> 1990. </year>
Reference: [Mye81] <author> Eugene W. Myers. </author> <title> A precise inter-procedural data flow algorithm. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 219-230, </pages> <year> 1981. </year>
Reference-contexts: An approximate, compile-time interpretation rule for procedure calls is all that is needed for interprocedural analysis. As defined in this rule, the analysis will bind the parameters and interpret the body. This approach is different from conventional ones <ref> [Cal88, Mye81, Wei80, Bar77] </ref> in two respects. First, aliases (due to reference parameters) and recursive calls, which were considered two principal problems of interprocedural analysis, are treated by simulating directly the language construct that causes them (in this case, the call expression). <p> Second, the program's call graph is not assumed as given prior to the analysis. As we discussed above, this is important when the target language allows procedures as first-class objects. Accuracy improvement by clever representations of the call graph <ref> [Cal88, Mye81] </ref> may still be applicable in abstract interpretation, if the improvement is applied as a post-analysis process, when the call graph has been constructed. * The abstract interpretation framework makes it feasible to generate compile time analyses from high-level specifications automatically.
Reference: [Nie85] <author> Flemming Nielson. </author> <title> Program transformations in a denotational setting. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 359-379, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Its input is assumed to be a correct abstract interpreter. The user should refer to one of the frameworks (as summarized in [CC92b, CC92a]) for defining correct abstract interpreters, which are based either on denotational semantics <ref> [Bur87, Bur91, MJ85, Nie85] </ref> or on operational semantics [CC77, CC79, CC92b]. In Section 2.1.2 we discussed one approach based on denotational semantics. * Completeness of Projections. Projection is not a complete notion for controlling the accuracy-cost tradeoff of an abstract interpreter.
Reference: [NN] <author> Flemming Nielson and Hanne R. Nielson. </author> <title> Code generation from two-level denotational meta-languages. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 217, </volume> <pages> pages 192-205. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: these languages using Z1. * System Z1 facilitates the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and <ref> [NN, App85, Ras82] </ref> for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90].
Reference: [NN86] <author> Hanne R. Nielson and Flemming Nielson. </author> <title> Semantics directed compiling for functional languages. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Lisp and Functional Programming, </booktitle> <pages> pages 249-257, </pages> <year> 1986. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE [Gau80]), and <ref> [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] </ref> We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [Pau82] <author> Lawrence Paulson. </author> <title> A semantics-directed compiler generator. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 224-233, </pages> <year> 1982. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres [Tof90], PERLUETTE [Gau80]), and <ref> [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] </ref> We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [Ras82] <author> Martin R. Raskovsky. </author> <title> Denotational semantics as a specification of code generators. </title> <booktitle> In Proceedings of SIGPLAN '82 Symposium on Compiler Construction, volume 17 of SIGPLAN Notices, </booktitle> <pages> pages 230-244, </pages> <year> 1982. </year>
Reference-contexts: these languages using Z1. * System Z1 facilitates the use of abstract interpretation for imperative as well as func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and <ref> [NN, App85, Ras82] </ref> for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis [WS91] for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90].
Reference: [Rey72] <author> John C. Reynolds. </author> <title> Definitional interpreters for higher-order programming languages. </title> <booktitle> In Proceedings of the ACM Annual Conference, </booktitle> <pages> pages 717-740, </pages> <month> August </month> <year> 1972. </year>
Reference-contexts: The input is an abstract semantics of the target language which is expressed as a definitional interpreter <ref> [Rey72] </ref>. Second, it has a convenient mechanism (projection expression) by which the user can control the accuracy and cost tradeoff of the analysis. Projections over the types of an abstract interpreter permits high-level management of the accuracy-cost tradeoff of the analysis.
Reference: [Ros77] <author> Barry K. Rosen. </author> <title> Applications of high level control flow. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 38-47. CACM, </pages> <month> January </month> <year> 1977. </year> <note> 164 BIBLIOGRAPHY 165 </note>
Reference: [Ros80] <author> Barry K. Rosen. </author> <title> Monoids for rapid data flow analysis. </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(1), </volume> <month> February </month> <year> 1980. </year>
Reference: [RP86] <author> Barbara G. Ryder and Marvin C. Paull. </author> <title> Elimination algorithms for data flow analysis. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(3) </volume> <pages> 277-316, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Conventional data flow analysis methods (as summarized in <ref> [RP86, Hec77] </ref>) have several limitations. First, they assume the control flow graphs of programs prior to the analysis. For languages like FORTRAN this is not a problem because the control flow graph of a program can be (largely) determined from its text.
Reference: [Rut65] <author> D.E. Rutherford. </author> <title> Introduction to Lattice Theory. </title> <publisher> Hafner Publishing Company, </publisher> <address> New York, </address> <year> 1965. </year>
Reference-contexts: Given this characteristics it is not surprising that in a modular lattice any two maximal chains between two elements, if they are finite, are of the same length. This is Jordan-Holder theorem <ref> [Rut65] </ref>. Definition 10 (Atom) A non-bottom element x of a lattice L which satisfies y v x =) y = ? or x = y 8y 2 L is an atom. We write Atoms (L) to indicate the set of atoms of a lattice L. <p> Proof. In general, more than one maximal chain can exist between two elements. However, because every lattice in L is finite and modular, every maximal chain between two elements is of the same length (Jordan-Holder theorem <ref> [Rut65] </ref>). 2 Thank to this, every element of L in L has unique height and depth. Definition 18 (Element Height (Depth)) The height h (x) (respectively, the depth d (x)) of x 2 L 2 L is the length of a maximal chain from ? (respectively, &gt;) to x.
Reference: [Sas90] <author> Masataka Sassa. Rie and jun: </author> <title> Towards the generation of all compiler phases. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 477, </volume> <pages> pages 56-70. </pages> <year> 1990. </year>
Reference-contexts: Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun <ref> [Sas90] </ref>. <p> Z1 is distinguished from other similar tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> in three ways. First, system Z1 is based on the abstract interpretation framework. <p> Projections over the types of an abstract interpreter permits high-level management of the accuracy-cost tradeoff of the analysis. Third, it has a high-level specification language in which the user can conveniently express an abstract interpreter succinctly and conveniently. Other analysis generation tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> have difficulty in handling interprocedural analysis specifications, are limited to specific target languages, are limited to a class of simple analyses (e.g. bit-vector representation of the data flow values), require substantial amount of code (in the implementation language) from the user, and have no high-level facility
Reference: [Sco70] <author> Dana S. Scott. </author> <title> Outline of a mathematical theory of computation. </title> <booktitle> In Proceedings of the 4th Annual Princeton Conference on Information Sciences and Systems. IEEE, </booktitle> <year> 1970. </year>
Reference-contexts: Each abstract element denotes a (possibly infinite) set of concrete values. Concrete values are the entities that occur during real executions of programs: integers, reals, strings, procedures, variables, records, pointers, stores, environments, etc. A precise mathematical model for these entities is provided by denotational semantics <ref> [Sto77, Sco72, Sco70] </ref>. This mathematical semantics makes "visible" [Sco70] what we have in mind about what these entities are. The precise semantics of concrete values determines the precise meanings of the corresponding abstract values. <p> Concrete values are the entities that occur during real executions of programs: integers, reals, strings, procedures, variables, records, pointers, stores, environments, etc. A precise mathematical model for these entities is provided by denotational semantics [Sto77, Sco72, Sco70]. This mathematical semantics makes "visible" <ref> [Sco70] </ref> what we have in mind about what these entities are. The precise semantics of concrete values determines the precise meanings of the corresponding abstract values. In denotational semantics [Sto77], a mathematical structure called a domain is used to give mathematical meaning to concrete values.
Reference: [Sco72] <author> Dana S. Scott. </author> <booktitle> Mathematical concepts in programming language semantics. In AFIPS Conference Proceedings, </booktitle> <volume> volume 40, </volume> <pages> pages 225-234, </pages> <year> 1972. </year>
Reference-contexts: Each abstract element denotes a (possibly infinite) set of concrete values. Concrete values are the entities that occur during real executions of programs: integers, reals, strings, procedures, variables, records, pointers, stores, environments, etc. A precise mathematical model for these entities is provided by denotational semantics <ref> [Sto77, Sco72, Sco70] </ref>. This mathematical semantics makes "visible" [Sco70] what we have in mind about what these entities are. The precise semantics of concrete values determines the precise meanings of the corresponding abstract values.
Reference: [Shi88] <author> Olin Shivers. </author> <title> Control flow analysis in scheme. </title> <booktitle> In Proceedings of the SIG-PLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: In order to avoid this overly conservative approach, we must follow the program execution and simulate the parameter binding mechanism. But this requires as complicated a computation as another program analysis! This problem is well-known and addressed in several studies <ref> [Shi91, Shi88, HK92] </ref>. Shivers [Shi91, Shi88] used continuation passing style representations of SCHEME programs to simplify his control flow analysis. Hall and Kennedy [HK92] devised a compile-time method of simulating the parameter binding mechanism to compute the call graph of C or SCHEME programs. <p> In order to avoid this overly conservative approach, we must follow the program execution and simulate the parameter binding mechanism. But this requires as complicated a computation as another program analysis! This problem is well-known and addressed in several studies [Shi91, Shi88, HK92]. Shivers <ref> [Shi91, Shi88] </ref> used continuation passing style representations of SCHEME programs to simplify his control flow analysis. Hall and Kennedy [HK92] devised a compile-time method of simulating the parameter binding mechanism to compute the call graph of C or SCHEME programs.
Reference: [Shi91] <author> Olin Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: In order to avoid this overly conservative approach, we must follow the program execution and simulate the parameter binding mechanism. But this requires as complicated a computation as another program analysis! This problem is well-known and addressed in several studies <ref> [Shi91, Shi88, HK92] </ref>. Shivers [Shi91, Shi88] used continuation passing style representations of SCHEME programs to simplify his control flow analysis. Hall and Kennedy [HK92] devised a compile-time method of simulating the parameter binding mechanism to compute the call graph of C or SCHEME programs. <p> In order to avoid this overly conservative approach, we must follow the program execution and simulate the parameter binding mechanism. But this requires as complicated a computation as another program analysis! This problem is well-known and addressed in several studies [Shi91, Shi88, HK92]. Shivers <ref> [Shi91, Shi88] </ref> used continuation passing style representations of SCHEME programs to simplify his control flow analysis. Hall and Kennedy [HK92] devised a compile-time method of simulating the parameter binding mechanism to compute the call graph of C or SCHEME programs.
Reference: [Ste91] <author> Bernahard Steffen. </author> <title> Data flow analysis as model checking. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 526, </volume> <pages> pages 346-364. </pages> <year> 1991. </year>
Reference-contexts: In addition to analysis specification, Sharlit allows optimization specification, that system Z1 lacks. Young [You89] reported a library that he used to implement several semantic analyses. Steffen <ref> [Ste91] </ref> reported a specification framework that uses modal logic formulae to specify data flow analysis algorithms. Venkatesh [Ven89] defines a specification language that allows denotational semantics to be augmented with a collecting mechanism for program analysis.
Reference: [Sto77] <author> Joseph E. Stoy. </author> <title> Denotational Semantics: the Scott-Strachey Approach to Programming Language Theory. </title> <publisher> MIT Press, </publisher> <year> 1977. </year>
Reference-contexts: Designing a program analysis is equivalent to designing an abstract interpreter. Thus an appropriate formalism for interpreter specification provides a comfortable ground 21 2.1 Input to Z1: An Abstract Interpreter 22 for automatic generation of a global program analysis. In denotational semantics <ref> [Sto77] </ref>, abstract interpreters are defined by domain equations together with semantics equations over the domains. For a useful class of domains these specifications can automatically be made executable. <p> Each abstract element denotes a (possibly infinite) set of concrete values. Concrete values are the entities that occur during real executions of programs: integers, reals, strings, procedures, variables, records, pointers, stores, environments, etc. A precise mathematical model for these entities is provided by denotational semantics <ref> [Sto77, Sco72, Sco70] </ref>. This mathematical semantics makes "visible" [Sco70] what we have in mind about what these entities are. The precise semantics of concrete values determines the precise meanings of the corresponding abstract values. <p> A precise mathematical model for these entities is provided by denotational semantics [Sto77, Sco72, Sco70]. This mathematical semantics makes "visible" [Sco70] what we have in mind about what these entities are. The precise semantics of concrete values determines the precise meanings of the corresponding abstract values. In denotational semantics <ref> [Sto77] </ref>, a mathematical structure called a domain is used to give mathematical meaning to concrete values. A domain is a pointed, complete, partially ordered set. Pointedness requires an element (bottom) which is lower than all other elements.
Reference: [Tar76] <author> Robert Endre Tarjan. </author> <title> Iterative algorithms for global flow analysis. </title> <type> Technical Report Stan-cs-76-547, </type> <institution> Stanford University, </institution> <month> March 76. </month>
Reference: [TH92] <author> Steven W. K. Tjiang and John L. Hennessy. </author> <title> Sharlit a tool for building optimizers. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 82-93, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: func tional programming languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and [NN, App85, Ras82] for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit <ref> [TH92] </ref> and GOSpeL/GENesis [WS91] for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90]. <p> Z1 is distinguished from other similar tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> in three ways. First, system Z1 is based on the abstract interpretation framework. <p> Projections over the types of an abstract interpreter permits high-level management of the accuracy-cost tradeoff of the analysis. Third, it has a high-level specification language in which the user can conveniently express an abstract interpreter succinctly and conveniently. Other analysis generation tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> have difficulty in handling interprocedural analysis specifications, are limited to specific target languages, are limited to a class of simple analyses (e.g. bit-vector representation of the data flow values), require substantial amount of code (in the implementation language) from the user, and have no high-level facility <p> All the value structures and semantic actions at each attribute grammar node must be provided in the implementation language by the user. Tjiang and Hennessy <ref> [TH92] </ref> reported a tool called Sharlit which generates program analyzers and program optimizer. Its specification language is C++. An interesting feature of this tool is that its fixpoint computation procedure can be simplified by means of flow graph reduction rules. <p> Depending on the target language, however, we can improve its performance. For example, for a language which enables us to determine, before the analysis starts, the control flow graph of an input program, the fixpoint computation method can be tailored for the control flow graph. As in <ref> [TH92] </ref>, system 158 6.2 Limitations and Discussion 159 Z1 can provide a facility by which the user can specify such optimizations when possible. * Optimization of the Generated Code. There are ways in which we can further improve the performance of the generated C code.
Reference: [Tof90] <author> Mads Tofte. </author> <title> Compiler Generators: What They Can do, What They Might Do, and What They Will Probably Never Do. </title> <booktitle> EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Moreover, based on the observation that compiling a program amounts to emitting a representation of its meaning as object code, a rich set of semantics-directed compiler generation tools are reported: Mess [LP87, Lee89], Ceres <ref> [Tof90] </ref>, PERLUETTE [Gau80]), and [Mos76, Mos80, Pau82, NN86, CJ83, JS80, HM90] We have added system Z1 (a program analyzer generator) to this collection. Z1 is distinguished from other similar tools [TH92, Sas90, KNPS88, GG82, Wil81] in three ways. First, system Z1 is based on the abstract interpretation framework.
Reference: [Ven89] <author> G. A. Venkatesh. </author> <title> A framework for construction and evaluation of high-level specifications for program analysis techniques. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1-12, </pages> <year> 1989. </year> <note> 165 BIBLIOGRAPHY 166 </note>
Reference-contexts: In addition to analysis specification, Sharlit allows optimization specification, that system Z1 lacks. Young [You89] reported a library that he used to implement several semantic analyses. Steffen [Ste91] reported a specification framework that uses modal logic formulae to specify data flow analysis algorithms. Venkatesh <ref> [Ven89] </ref> defines a specification language that allows denotational semantics to be augmented with a collecting mechanism for program analysis. None of these tools provides a high-level facility to tune the analysis in accuracy and cost. Whitfield and Soffa [WS91] reported an optimizer generator called GOSpeL/GENesis.
Reference: [Wei80] <author> William E. Weihl. </author> <title> Interprocedural data flow analysis in the presence of pointers, procedure variables, and label variables. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 83-94, </pages> <year> 1980. </year>
Reference-contexts: An approximate, compile-time interpretation rule for procedure calls is all that is needed for interprocedural analysis. As defined in this rule, the analysis will bind the parameters and interpret the body. This approach is different from conventional ones <ref> [Cal88, Mye81, Wei80, Bar77] </ref> in two respects. First, aliases (due to reference parameters) and recursive calls, which were considered two principal problems of interprocedural analysis, are treated by simulating directly the language construct that causes them (in this case, the call expression).
Reference: [Wil81] <author> Reinhard Wilhelm. </author> <title> Global flow analysis and optimization in the mug2 compiler generating system. </title> <editor> In Steven S. Muchnick and Neil D. Jones, editors, </editor> <title> Program Flow Analysis: Theory and Applications, chapter 5. </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 <ref> [Wil81, GG82] </ref>, HLP84 [KNPS88], and Rie/Jun [Sas90]. <p> Z1 is distinguished from other similar tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> in three ways. First, system Z1 is based on the abstract interpretation framework. <p> Projections over the types of an abstract interpreter permits high-level management of the accuracy-cost tradeoff of the analysis. Third, it has a high-level specification language in which the user can conveniently express an abstract interpreter succinctly and conveniently. Other analysis generation tools <ref> [TH92, Sas90, KNPS88, GG82, Wil81] </ref> have difficulty in handling interprocedural analysis specifications, are limited to specific target languages, are limited to a class of simple analyses (e.g. bit-vector representation of the data flow values), require substantial amount of code (in the implementation language) from the user, and have no high-level facility
Reference: [WS91] <author> Deborah Whitfield and Mary Lou Soffa. </author> <title> Automatic generation of global optimizers. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 120-129, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: languages. 6.1 Related Works Almost every compiler-component has a corresponding automatic tool: LEX [ES86] for the lexical analyzer, YACC [Joh86] and PGS [GK88] for the parser, TWIG [AGT89] and [NN, App85, Ras82] for the code generator, LIGA [Kas90] and [Far86] for the attribute grammar evaluator, and Sharlit [TH92] and GOSpeL/GENesis <ref> [WS91] </ref> for the code optimizer. Collections of compiler-component generators have been integrated into single compiler writing systems: ELI [GHLaWMW92], MUG2 [Wil81, GG82], HLP84 [KNPS88], and Rie/Jun [Sas90]. <p> Venkatesh [Ven89] defines a specification language that allows denotational semantics to be augmented with a collecting mechanism for program analysis. None of these tools provides a high-level facility to tune the analysis in accuracy and cost. Whitfield and Soffa <ref> [WS91] </ref> reported an optimizer generator called GOSpeL/GENesis. The user specifies an optimization preconditions and actions; analysis result of the input program is assumed.
Reference: [YH92] <author> Kwangkeun Yi and Williams Ludwell Harrison III. </author> <title> Interprocedural data flow analysis for compile-time memory management. </title> <type> Technical Report 1244, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: The read, write, and call expression requires some complicated manipulations of the block index values. The reader is recommended to see [Har92] or in <ref> [YH92] </ref> for those operations written in conventional mathematical form. Ours are just a transliteration of those definitions into Z1. * Analysis of array.c (Figure 5.32) with Projection (project (height&gt; 1)) and No Projection of Locations Consider the C program array.c in Figure 5.32. <p> Note that the procedure pointers bound to the parameters x (Id 19) and y (Id 20) are either for sum (index 3) or mult (index 4) (See Figure 5.42). 5.6 Memory Object Lifetime Analysis In <ref> [YH92] </ref> we presented an analysis that estimates the memory object lifetime and the temporal locality of memory accesses. Using Z1 we will duplicate the analysis, which was hand-crafted at that time.
Reference: [YH93] <author> Kwangkeun Yi and Williams Ludwell Harrison III. </author> <title> Automatic generation and management of interprocedural program analyses. </title> <booktitle> In Proceedings of the Annual ACM Symposium on Principles of Programming Languages, </booktitle> <volume> pages 246-259 (also as CSRD Report No. 1260), </volume> <month> January </month> <year> 1993. </year>
Reference-contexts: By def-use/use-def chain analysis, we can determine in-terprocedural side-effects: e.g., procedure A defines a memory location and procedure B reads or modifies the value at that location. * Memory object lifetime analysis. This is a duplication by Z1 of the one in <ref> [YH93] </ref>. During program executions some memory is allocated, used, and deallocated. Procedure parameters, local variables, malloc'd objects, and cons cells are of such a kind. This analysis computes the longevity and temporal locality of each allocated memory object: the interval from its creation until the access points. <p> Using Z1 we will duplicate the analysis, which was hand-crafted at that time. Again, we present an abstract interpreter which is based upon Eval1 rather than on Eval3, because it will simplify our presentation. An Eval3-based specification, which would be a true duplication of <ref> [YH93] </ref>, should not cause any problem. We estimate, for each object, the intervals between its birth point and its access points. A memory object is a memory location that is allocated for program variables and for "malloc" expressions.
Reference: [You89] <author> Jonathan H. Young. </author> <title> The Theory and Practice of Semantic Program Analysis for Higher-Order Functional Programming Languages. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> May </month> <year> 1989. </year> <month> 166 </month>
Reference-contexts: It is unclear, however, how this feature can be used for the case where the flow graph of a program must be derived during analysis. In addition to analysis specification, Sharlit allows optimization specification, that system Z1 lacks. Young <ref> [You89] </ref> reported a library that he used to implement several semantic analyses. Steffen [Ste91] reported a specification framework that uses modal logic formulae to specify data flow analysis algorithms. Venkatesh [Ven89] defines a specification language that allows denotational semantics to be augmented with a collecting mechanism for program analysis.
References-found: 77

