URL: http://www.informatik.uni-stuttgart.de/ifi/is/Personen/Irene/ilp94.ps.gz
Refering-URL: http://www.informatik.uni-stuttgart.de/ifi/is/Personen/weber.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fweberi,tausendg@informatik.uni-stuttgart.de  
Title: A three-tiered Confidence Model for Revising Logical Theories  
Author: Irene Weber Birgit Tausend 
Keyword: theory revision, predicate invention.  
Date: August 5, 1994  
Address: Breitwiesenstr. 20-22, D-70565 Stuttgart, Germany  
Affiliation: Fakultat Informatik, Universitat Stuttgart  
Abstract: The task of theory revision in Inductive Logic Programming is to correct the current theory when contradictions with new examples arise. Confidence models are used to assess and compare the different alternatives of revising a theory in order to choose the best revision. In this paper, we propose an augmentation of the two-tiered confidence model of MOBAL/KRT that allows to combine different heuristic confidence measures and can be adapted to different learning strategies. 
Abstract-found: 1
Intro-found: 1
Reference: [Ab&So90] <author> Aben, Manfred und Maarten van Someren. </author> <title> Heuristic Refinement of Logic Programs. </title> <booktitle> Proc. of the 9 th ECAI, S. </booktitle> <pages> 7-12, </pages> <address> Stockholm, </address> <year> 1990. </year>
Reference-contexts: If the clauses in a knowledge base result from different sources, e. g., learning operators or experts, the origin of the clauses can provide further useful classification criteria. Confidence classes are a widely used criterion in knowledge revision systems <ref> [Ab&So90, Gi&al85] </ref>. In general, confidence classification is a measure that applies to clauses. In our setting, as described in the revision algorithm, we need confidence values for MRS s, which are sets of clause instances. <p> Preference criteria, e. g., an ordering of rule models, compression-based measures, or complexity of clauses might be useful as confidence criteria in particular applications. Confidence level 3. At this level, the least reliable confidence measure, the em-pirical support <ref> [Gi&al85, Ab&So90] </ref>, is applied. This frequently used confidence measure evaluates the usefulness of a clause in proving positive and negative examples. The empirical support of a clause is computed as the ratio of its applications in successful proofs of positive examples to that in proofs of negative examples. <p> Since the confidence measures the comparison of the minimal removal sets is based on are heuristic, the task of selecting the MRS with minimal confidence does not justify the expense of calculating all MRS s. This is why some revision systems adopt a greedy strategy <ref> [Ab&So90] </ref>. However, simultaneously processing all provable negative examples, N eg, provides valuable information for the revision task. But in applications where there are many or lengthy proofs of negative examples, the calculation of M is not feasible.
Reference: [Bai&Mu92] <author> Bain, Michael und Stephen Muggleton. </author> <title> Non-monotonic learning. </title> <editor> In: Muggleton, B. (Her.), </editor> <booktitle> Inductive Logic Programming, </booktitle> <publisher> Academic Press Ltd, </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: One approach is to completely remove the clauses C from the theory. However, a lot of information will be lost if this brute-force approach is applied. As shown in <ref> [Bai&Mu92] </ref>, it is necessary to augment the classical logic representation if we want to to preserve as much information as possible. For example, the representation can be extended by exceptions. Logic Programming as well as ILP provides several methods to realize exception handling, e. g., the CWS method in [Bai&Mu92] or <p> in <ref> [Bai&Mu92] </ref>, it is necessary to augment the classical logic representation if we want to to preserve as much information as possible. For example, the representation can be extended by exceptions. Logic Programming as well as ILP provides several methods to realize exception handling, e. g., the CWS method in [Bai&Mu92] or the sets of support in MOBAL [Wro93]. In MILES, the exceptions of a clause are stored in a data structure that is associated with each clause.
Reference: [Duden] <institution> Duden | die Grammatik. Bibliographisches Institut Mannheim, </institution> <year> 1973. </year>
Reference-contexts: Thus, this problem seems to be an interesting domain for experimentation on specializing overgeneral theories. The theory consists of a set of clauses defining plural formation adapted from the <ref> [Duden] </ref>, and relevant background knowledge. A subset of it is shown in table 1.
Reference: [Gi&al85] <author> Ginsberg, Allen, Sholom Weiss und Peter Politakis. </author> <title> A generalized approach to automatic knowledge base refinement. </title> <booktitle> Proceedings IJCAI-85, </booktitle> <year> 1985. </year>
Reference-contexts: If the clauses in a knowledge base result from different sources, e. g., learning operators or experts, the origin of the clauses can provide further useful classification criteria. Confidence classes are a widely used criterion in knowledge revision systems <ref> [Ab&So90, Gi&al85] </ref>. In general, confidence classification is a measure that applies to clauses. In our setting, as described in the revision algorithm, we need confidence values for MRS s, which are sets of clause instances. <p> Preference criteria, e. g., an ordering of rule models, compression-based measures, or complexity of clauses might be useful as confidence criteria in particular applications. Confidence level 3. At this level, the least reliable confidence measure, the em-pirical support <ref> [Gi&al85, Ab&So90] </ref>, is applied. This frequently used confidence measure evaluates the usefulness of a clause in proving positive and negative examples. The empirical support of a clause is computed as the ratio of its applications in successful proofs of positive examples to that in proofs of negative examples.
Reference: [Kop93] <author> Kopcke, Klaus-Michael. </author> <title> Schemata bei der Pluralbildung im Deutschen. </title> <publisher> Gunter Narr Verlag, Tubingen, </publisher> <year> 1993. </year>
Reference-contexts: There are several ways to form the plural of a noun in German. In general it is assumed that there are no exact rules describing which suffix to take for a given noun, e.g., <ref> [Kop93] </ref>, although there are some regularities. Thus, this problem seems to be an interesting domain for experimentation on specializing overgeneral theories. The theory consists of a set of clauses defining plural formation adapted from the [Duden], and relevant background knowledge. A subset of it is shown in table 1.
Reference: [Mo93] <editor> Morik, K., S. Wrobel, J.-U. Kietz. </editor> <title> Knowledge Acquisition and Machine Learning: Theory, Methods, and Applications. </title> <publisher> Academic Press, </publisher> <address> London, New York, </address> <year> 1993. </year>
Reference-contexts: In contrast, incremental systems like MOBAL interleave construction and application of the theory. Contradictions arising from applying the theory are used to correct and refine it. The theory is built and refined in several cycles using different sources of knowledge as described by the sloppy modelling paradigm <ref> [Mo93] </ref>. The need for theory revision is obvious in such a setting, because contradicting information is likely to arise and to demand correction of the theory that has been built so far. Two types of contradicting information can occur.
Reference: [Mug&Fen90] <author> Muggleton, S. , C. Feng. </author> <title> Efficient Induction of Logic Programs. </title> <booktitle> Proc. of the 1 st Conference on Algorithmic Learning Theory, </booktitle> <address> Tokyo, </address> <publisher> OHMSHA, </publisher> <year> 1990. </year>
Reference-contexts: 1 Introduction The difference between incremental learning systems that receive their examples one by one and adapt their theories accordingly, and one-shot systems plays an important role in Machine Learning and especially in ILP. Here, systems range between highly user-independent, non-incremental methods like Golem <ref> [Mug&Fen90] </ref>, and incremental approaches trying to support the more general task of model building like MOBAL [Wro93]. Though the formers are often very efficient and produce well-defined output, they suffer from the intrinsic shortcomings of each non-incremental method.
Reference: [Mug&al92a] <author> Muggleton, S., M. Bain und A. Srinivasan. </author> <title> Distinguishing exceptions from noise in non-monotonic learning. </title> <editor> In: Mug-gleton, B. (Her.), </editor> <booktitle> Inductive Logic Programming, </booktitle> <publisher> Academic Press Ltd, </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: Of course, this operation should only be performed if a given plausibility criterion is met, e. g., if the ratio of exceptions to permissible bindings of a clause exceeds a reasonable limit [Wro93], or if the new predicate improves the compression of the theory <ref> [Mug&al92a] </ref>. In this case, a successive generalisation step introduces new predicates which discriminate between exceptions and permissible bindings of a clause and replace the specialization by exceptions. Each minimal removal set represents one possibility to correct the theory.
Reference: [Mug92] <author> Muggleton, B. (Her.), </author> <title> Inductive Logic Programming, </title> <publisher> Academic Press Ltd, </publisher> <address> London, </address> <year> 1992. </year>
Reference: [Shap83] <author> Shapiro, Ehud Y. </author> <title> Algorithmic Program Debugging, </title> <publisher> MIT press, </publisher> <year> 1983. </year>
Reference-contexts: Though our approach offers the ability to integrate interaction with an oracle, the goal is to do the selection automatically by the system. If more interaction is preferred, other approaches, e. g., contradiction backtracing <ref> [Shap83] </ref>, are more suitable, since selection of a MRS requires very complex decisions compared to answering ground oracle questions. 5 Conclusion Theory revision faces the problem of assessing and choosing one of an expontial number of alternative revision operations.
Reference: [St&We94] <author> Stahl, I. und Weber, I. </author> <title> The arguments of newly invented predicates. </title> <booktitle> Proc. of ILP 94, </booktitle> <year> 1994. </year>
Reference-contexts: with vars (C) = (X 1 ; : : : ; X n ) do Exc (C) := Exc (C) [ f (X 1 ; : : : ; X n )g The result of a theory revision often serves as a starting point for the invention of new predicates <ref> [St&We94] </ref>. Of course, this operation should only be performed if a given plausibility criterion is met, e. g., if the ratio of exceptions to permissible bindings of a clause exceeds a reasonable limit [Wro93], or if the new predicate improves the compression of the theory [Mug&al92a].
Reference: [St&Ta93] <author> Stahl, I. und Tausend, B. </author> <title> MILES | a Modular Inductive Logic Programming Experimentation System. </title> <booktitle> Deliverable STU1.2 of ESPRIT BRA 6020: Inductive Logic Programming (ILP), </booktitle> <year> 1993, </year> <note> not published. </note>
Reference-contexts: MILES was developed to simulate and compare different ILP approaches. MILES allows to experiment with and investigate known and new learning operators, control mechanisms, biases, and methods for shifting the bias <ref> [St&Ta93] </ref>. According to the experimental setting, the three-tiered confidence model allows to combine several heuristic confidence measures and can be adapted to different learning situations.
Reference: [Tan&Shi93] <author> Tangkitvanich, S. und Shimura, M. </author> <title> Learning from an approximate theory and noisy examples. </title> <booktitle> Proc. of AAAI 1993, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Obviously, this additional information could not have been incorporated in clause 49 since the gender information is not available here. 4 Discussion Compared to other systems, our approach is more flexible, because several confidence measures can be combined. Other approaches, as for example <ref> [Tan&Shi93] </ref>, base the selection of the clauses to be corrected on only one measure, e.g., the minimal description length criterion. Furthermore, our approach is not restricted to correcting theories which consist of clauses with identical heads as [Tan&Shi93]. <p> Other approaches, as for example <ref> [Tan&Shi93] </ref>, base the selection of the clauses to be corrected on only one measure, e.g., the minimal description length criterion. Furthermore, our approach is not restricted to correcting theories which consist of clauses with identical heads as [Tan&Shi93]. Extending the two-tiered confidence model of MOBAL by an intermediate level, level 2 in our approach, offers additional possibilities to influence the selection of the clauses to be specialized as to be seen from the example application.
Reference: [Weber94] <author> Weber, Irene. </author> <title> Integration von Ausnahmen in MILES. </title> <type> Studienarbeit Nr. 1283, </type> <institution> Universitat Stuttgart. </institution>
Reference-contexts: The theorem prover applies a clause in a proof only if the instantiations of the clause variables do not match any of its exceptions. 1 This definition assumes, that all substitutions are ground substitutions. For definitions for the general case see [Wro93] or <ref> [Weber94] </ref>. Definition: An exception set Exc (C) of a clause C with variables vars (C) = (X 1 ; : : : ; X n ) is a set of variable instantiations of C.
Reference: [Wro93] <author> Wrobel, Stefan. </author> <title> Concept Formation and Knowledge Revision </title> | 
Reference-contexts: Here, systems range between highly user-independent, non-incremental methods like Golem [Mug&Fen90], and incremental approaches trying to support the more general task of model building like MOBAL <ref> [Wro93] </ref>. Though the formers are often very efficient and produce well-defined output, they suffer from the intrinsic shortcomings of each non-incremental method. The theory cannot be updated after learning, even if its practical application leads to contradictions. In this case, a new theory has to be learned from scratch. <p> For example, the representation can be extended by exceptions. Logic Programming as well as ILP provides several methods to realize exception handling, e. g., the CWS method in [Bai&Mu92] or the sets of support in MOBAL <ref> [Wro93] </ref>. In MILES, the exceptions of a clause are stored in a data structure that is associated with each clause. <p> The theorem prover applies a clause in a proof only if the instantiations of the clause variables do not match any of its exceptions. 1 This definition assumes, that all substitutions are ground substitutions. For definitions for the general case see <ref> [Wro93] </ref> or [Weber94]. Definition: An exception set Exc (C) of a clause C with variables vars (C) = (X 1 ; : : : ; X n ) is a set of variable instantiations of C. <p> This operation performs a minimal base revision as defined by the base revision postulates (1) to (5) described in <ref> [Wro93] </ref>. 2.3 Revision Algorithm The revision algorithm of MILES can be sketched as follows: Algorithm sketch: Given a theory T and a set of provable negative examples Neg, do: (1) calculate M (T; Neg) (2) select MRS 2 M (T; Neg) (3) 8C 2 MRS with vars (C) = (X 1 <p> Of course, this operation should only be performed if a given plausibility criterion is met, e. g., if the ratio of exceptions to permissible bindings of a clause exceeds a reasonable limit <ref> [Wro93] </ref>, or if the new predicate improves the compression of the theory [Mug&al92a]. In this case, a successive generalisation step introduces new predicates which discriminate between exceptions and permissible bindings of a clause and replace the specialization by exceptions. Each minimal removal set represents one possibility to correct the theory. <p> Each minimal removal set represents one possibility to correct the theory. From a theoretical point of view, these possibilities are equivalent, since each of them leads to a minimal change in the theory ensuring that no negative example can be proved <ref> [Wro93] </ref>. On the other hand, it is obvious that the success of the induction step and the quality of the resulting theory strongly depend on the choice in step 2 of the revision algorithm. So, the selection step 2 is the crucial part of the theory revision algorithm. <p> A weakness of this confidence measure is that the empirical support for a clause depends not only on the selection of positive and negative examples used for computing the empirical support, but also on the other clauses in the theory which are needed for proving its antecedents <ref> [Wro93] </ref>. 3.2 Confidence Vectors Selecting the MRS with minimal confidence requires that the individual confidence measures on the three levels are combined into one. This combination must consider the importance of the individual confidence measures. <p> A problem of the approach is its computational complexity. The revision algorithm is very costly since the calculation of all minimal removal sets demands an exponential algorithm. In fact, the problem of finding the MRS with minimal confidence is NP-hard for certain confidence measures <ref> [Wro93] </ref>. Since the confidence measures the comparison of the minimal removal sets is based on are heuristic, the task of selecting the MRS with minimal confidence does not justify the expense of calculating all MRS s. This is why some revision systems adopt a greedy strategy [Ab&So90].
References-found: 15

