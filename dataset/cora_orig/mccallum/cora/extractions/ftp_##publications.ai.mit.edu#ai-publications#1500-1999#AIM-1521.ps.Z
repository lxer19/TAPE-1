URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1521.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/cbcl/old-course9.520/class-3.html
Root-URL: 
Title: Example-based Learning for View-based Human Face Detection  
Author: Kah-Kay Sung and Tomaso Poggio 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c Massachusetts Institute of Technology, 1994  
Date: 1521 December, 1994  112  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING  
Pubnum: A.I. Memo No.  C.B.C.L. Paper No.  
Abstract: Finding human faces automatically in an image is a difficult yet important first step to a fully automatic face recognition system. It is also an interesting academic problem because a successful face detection system can provide valuable insight on how one might approach other similar object and pattern detection problems. This paper presents an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based "face" and "non-face" prototype clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector, whether or not a human face exists at the current image location. We show empirically that the prototypes we choose for our distribution-based model, and the distance metric we adopt for computing difference feature vectors, are both critical for the success of our system. This report describes research done at the Artificial Intelligence Laboratory and within the Center for Biological and Computational Learning in the Department of Brain and Cognitive Sciences at the Massachusetts Institute of Technology. This research is sponsored by grants from ARPA-ONR under contract N00014-92-J-1879; and by a grant from the National Science Foundation under contract ASC-9217041 (this award includes funds from ARPA provided under the HPCC program). Additional support is provided by the North Atlantic Treaty Organization, ATR Audio and Visual Perception Research Laboratories, Mitsubishi Electric Corporation, Sumitomo Metal Industries, and Siemens AG. Support for the A.I. Laboratory's artificial intelligence research is provided by ARPA-ONR contract N00014-91-J-4038. Tomaso Poggio is supported by the Uncas and Helen Whitaker Chair at MIT's Whitaker College. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Beymer, A. Shashua, and T. Poggio. </author> <title> Example Based Image Analysis and Synthesis. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1431, </pages> <institution> Artificial Intelligence Laboratory, Mas-sachusetts Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: We believe that our current approach can in fact be used without modification to perform this new task. All we need is a means of obtaining or artificially generating a sufficiently large example database of human faces at the different poses <ref> [1] </ref>. 19 Second, we would like to demonstrate the versatility and generality of our approach by building a few more feature and pattern detection applications in other problem domains. Some possibilities include industrial inspection applications for detecting defects in manufactured products and terrain feature classification applications for SAR imagery.
Reference: [2] <author> M. Bichsel. </author> <title> Strategies of Robust Objects Recognition for Automatic Identification of Human Faces. </title> <type> PhD thesis, </type> <institution> ETH, </institution> <address> Zurich, </address> <year> 1991. </year>
Reference-contexts: While the class of all face patterns is probably too varied to be modeled by fixed correlation templates, there are some face detection approaches that use a bank of several correlation templates to detect major facial sub-features in the image <ref> [2] </ref> [3]. The assumption here is that the degree of non-rigidity in these facial subfeatures is small enough to be adequately described by a few fixed templates. At a later stage, the technique infers the presence of faces by analyzing the spatial relationship between the detected subfeatures.
Reference: [3] <author> R. Brunelli and T. Poggio. </author> <title> Face Recognition: Features versus Templates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(10) </volume> <pages> 1042-1052, </pages> <year> 1993. </year>
Reference-contexts: While the class of all face patterns is probably too varied to be modeled by fixed correlation templates, there are some face detection approaches that use a bank of several correlation templates to detect major facial sub-features in the image [2] <ref> [3] </ref>. The assumption here is that the degree of non-rigidity in these facial subfeatures is small enough to be adequately described by a few fixed templates. At a later stage, the technique infers the presence of faces by analyzing the spatial relationship between the detected subfeatures.
Reference: [4] <author> M. C. Burl, U. Fayyad, P. Perona, P. Smyth, and M. P. Burl. </author> <title> A Trainable Tool for Finding Small Volcanoes in SAR Imagery of Venus. </title> <type> Technical Report CNS TR 34, </type> <institution> California Institute of Technology, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Feature and pattern detection in images is a classical computer vision problem with many potential applications, ranging from automatic target recognition to industrial inspection tasks in assembly lines. While there has been some successful pattern detection systems in the past, especially those using pictorial templates <ref> [4] </ref> [10] [11] or geometric models [7] for describing objects, most such systems are limited by some serious constraints. For example, in some systems, the target objects must be rigid or at least made up of rigid parts. <p> This distance component accounts for pattern differences not 11 al. <ref> [4] </ref>. The approach assumes that the set of all volcano patterns lies within a low dimensional model space, spanned by a small number of the largest principal component vectors from a volcano image database. <p> Similarly, one can determine whether or not a given pattern is a face by measuring how well or poorly the eigen-images reconstruct the pattern | i.e., the pattern's distance (d in Figure 8) from the "face space" [12]. In another recent application of classical techniques, Burl et. al. <ref> [4] </ref> have used a different PCA based approach for a terrain classification task on finding volcanos in SAR images of Venus.
Reference: [5] <author> Richard O. Duda and Peter E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley and Sons Inc., </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: the "complete" Mahalanobis distance with D 2 vanishing in size and importance. 4.6 Relationship between our 2-Value Distance and some PCA-based Classical Distance Measures Our 2-Value distance metric is also closely related to the classical distance measures used by principal components analysis (PCA, also called Karhunen-Loeve expansion) based classification schemes <ref> [5] </ref> [6] [18]. We examine two such distance measures below. A standard way of modeling a 3D object for pattern recognition is to represent its space of 2D views using a few basis images, obtained by performing principal components analysis on a comprehensive set of 2D views.
Reference: [6] <author> K. Fukunaga. </author> <title> Introduction to Statistical Pattern Recognition. </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: "complete" Mahalanobis distance with D 2 vanishing in size and importance. 4.6 Relationship between our 2-Value Distance and some PCA-based Classical Distance Measures Our 2-Value distance metric is also closely related to the classical distance measures used by principal components analysis (PCA, also called Karhunen-Loeve expansion) based classification schemes [5] <ref> [6] </ref> [18]. We examine two such distance measures below. A standard way of modeling a 3D object for pattern recognition is to represent its space of 2D views using a few basis images, obtained by performing principal components analysis on a comprehensive set of 2D views.
Reference: [7] <author> W. E. L. Grimson and T. Lozano-Perez. </author> <title> Model-Based Recognition and Localization from Sparse Range Data. </title> <editor> In A. Rosenfeld, editor, </editor> <title> Techniques for 3-D Machine Perception. </title> <publisher> North-Holland, </publisher> <address> Ams-terdam, </address> <year> 1985. </year>
Reference-contexts: While there has been some successful pattern detection systems in the past, especially those using pictorial templates [4] [10] [11] or geometric models <ref> [7] </ref> for describing objects, most such systems are limited by some serious constraints. For example, in some systems, the target objects must be rigid or at least made up of rigid parts. In others, lighting must be controlled or the imaging geometry must be known.
Reference: [8] <author> G. Hinton, M. Revow, and P. Dayan. </author> <title> Recognizing Handwritten Digits using Mixture of Linear Models. </title> <editor> In D. Touretzky G. Tesauro and J. Alspector, editors, </editor> <booktitle> Advances in Neural Information Processings Systems 7, </booktitle> <address> San Mateo, CA, 1995. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: The approximation degrades gracefully by using its limited degrees of freedom to capture the most prominent pixel correlations in the data distribution. Notice 1 See <ref> [8] </ref> for a similar interpretation and presentation. Our explanation here is adapted from theirs. 12 of distance measurements. The net has 12 pairs of input units to accept the 12 pairs of distance values from our matching stage.
Reference: [9] <author> M. Kirby and L. Sirovich. </author> <title> Applications of the Karhunen-Loeve Procedure for the Characterization of Human Faces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(1) </volume> <pages> 103-108, </pages> <year> 1990. </year>
Reference-contexts: The low dimensional sub-space is linearly spanned by the principal components. Each new view of the target object can be represented by a set of coefficients that describes the view as a linearly weighted superposition of the principal components. Kirby and Sirovich [16] <ref> [9] </ref> have used principal components analysis methods to build low-dimensional models for characterizing the space of human faces. As a representative recent example, let us consider Turk and Pentland's application of PCA techniques to face recognition [19] and facial feature detection [12].
Reference: [10] <author> B. Kumar, D. Casasent, and H. Murakami. </author> <title> Principal Component Imagery for Statistical Pattern Recognition Correlators. </title> <journal> Optical Engineering, </journal> <volume> 21(1), </volume> <month> Jan/Feb </month> <year> 1982. </year>
Reference-contexts: 1 Introduction Feature and pattern detection in images is a classical computer vision problem with many potential applications, ranging from automatic target recognition to industrial inspection tasks in assembly lines. While there has been some successful pattern detection systems in the past, especially those using pictorial templates [4] <ref> [10] </ref> [11] or geometric models [7] for describing objects, most such systems are limited by some serious constraints. For example, in some systems, the target objects must be rigid or at least made up of rigid parts. In others, lighting must be controlled or the imaging geometry must be known.
Reference: [11] <author> A. Mahalanobis, A. Forman, N. Day, M. Bower, and R. Cherry. </author> <title> Multi-Class SAR ATR using Shift-Invariant Correlation Filters. </title> <journal> Pattern Recognition, </journal> <volume> 27(4) </volume> <pages> 619-626, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Feature and pattern detection in images is a classical computer vision problem with many potential applications, ranging from automatic target recognition to industrial inspection tasks in assembly lines. While there has been some successful pattern detection systems in the past, especially those using pictorial templates [4] [10] <ref> [11] </ref> or geometric models [7] for describing objects, most such systems are limited by some serious constraints. For example, in some systems, the target objects must be rigid or at least made up of rigid parts. In others, lighting must be controlled or the imaging geometry must be known.
Reference: [12] <author> A. Pentland, B. Moghaddam, and T. Starner. </author> <title> View-based and Modular Eigenspaces for Face Recognition. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 84-91, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: At a later stage, the technique infers the presence of faces by analyzing the spatial relationship between the detected subfeatures. A closely related approach to correlation templates is that of view-based eigen-spaces <ref> [12] </ref>. The approach assumes that the set of all possible face patterns occupies a small and easily parameterizable sub-space in the original high dimensional input image vector space. To detect faces, the approach first recovers a representation of the sub-space of face patterns as a reference for matching. <p> One commonly used distance metric is the Euclidean distance of a pattern from the nearest face sub-space location, which may be interpreted as a difference measure between the observed pattern and some "typical" face pattern <ref> [12] </ref>. So far, this approach has only been demonstrated on images with not-so-cluttered backgrounds. The view-based eigen-space approach has also been used for detecting and locating individual facial sub-features. <p> Kirby and Sirovich [16] [9] have used principal components analysis methods to build low-dimensional models for characterizing the space of human faces. As a representative recent example, let us consider Turk and Pentland's application of PCA techniques to face recognition [19] and facial feature detection <ref> [12] </ref>. To optimally represent their "face space", Turk and Pentland compute an orthonormal set of eigen-images from an example database of face patterns to span the space. New face views are represented by projecting their image patterns onto the set of eigen-images to obtain their linear combination coefficients. <p> Similarly, one can determine whether or not a given pattern is a face by measuring how well or poorly the eigen-images reconstruct the pattern | i.e., the pattern's distance (d in Figure 8) from the "face space" <ref> [12] </ref>. In another recent application of classical techniques, Burl et. al. [4] have used a different PCA based approach for a terrain classification task on finding volcanos in SAR images of Venus.
Reference: [13] <author> T. Poggio and T. Vetter. </author> <title> Recognition and Structure from One (2D) Model View: Observations on Prototypes, Object Classes, and Symmetries. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1347, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: In fact, to make our set of "face" patterns more comprehensive, we even artificially enlarged our data set by adding virtual examples <ref> [13] </ref> of faces to the "face" database. These virtual examples are mirror images and slightly rotated versions of the original face patterns, as shown in Fig 14 images above. We use these false detects as new negative examples to re-train our system in a "boot-strap" fashion. ure 11.
Reference: [14] <editor> D. Rumelhart and J. McClelland. </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1. </volume> <publisher> MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: We train our multi-layer perceptron classifier on feature distance vectors from a database of 47316 window patterns. There are 4150 positive examples of "face" patterns in the database and the rest are "non-face" patterns. The net is trained with a standard backpropagation learning algorithm <ref> [14] </ref> until the output error stabilizes at a very small value.
Reference: [15] <author> P. Sinha. </author> <title> Object Recognition via Image Invariants: </title>
Reference-contexts: To detect faces, one has to compile such a set of image invariants and check for positive occurrences of these invariants at all candidate image locations. One image-invariance scheme is based on a set of observed brightness invariants between different parts of a human face <ref> [15] </ref>. The underlying observation is that that while illumination and other changes can significantly alter brightness levels at different parts of a face, the local ordinal structure of brightness distribution remains largely unchanged.
References-found: 15

