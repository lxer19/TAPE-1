URL: http://www.cse.psu.edu/~zha/papers/growth.ps
Refering-URL: http://www.cse.psu.edu/~zha/papers.html
Root-URL: http://www.cse.psu.edu
Title: GROWTH IN GAUSSIAN ELIMINATION, ORTHOGONAL MATRICES, AND THE EUCLIDEAN NORM  
Author: JESSE L. BARLOW AND HONGYUAN ZHA 
Keyword: Key words. LU factorization, orthogonal invariance, triangular matrix.  
Note: AMS subject classifications. 65F05,65F35  
Abstract: It is shown that maximal growth for Gaussian elimination as measured in the Eu clidean norm is achieved by orthogonal matrices. A new, sharp bound on that growth is given. 1. Introduction. We consider Gaussian elimination with partial pivoting 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Faddeev, V. Kublanovskaya, and V. Faddeeva, </author> <title> Solution of linear algebraic systems with rectangular matrices, </title> <booktitle> Proc. </booktitle> <institution> Steklov Inst. Math, </institution> <month> 96 </month> <year> (1968), </year> <pages> pp. 93-111. </pages>
Reference-contexts: It is similar to a bound given by Faddeev, Kublanovskaya, and Fadeeva <ref> [1] </ref> whose proof is given by Lawson and Hanson [3, pp.28-35]. Lemma 2.2. Let L k 2 &lt; nfin satisfy the hypothesis of Lemma 2.1 and let ae (k) defined by ((1.9)). Then ae (k) 4 k 1 + n 3 1=2 Proof.
Reference: [2] <author> N. Higham, </author> <title> Accuracy and Stability of Numerical Algorithms, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: Combining (2.3) and (2.4) yields (1.13). Three lemmas are necessary to prove Proposition 1.2. The first lemma is closely related to a bound for the norm of the inverse of a triangular matrix given in Higham <ref> [2, pp.159-161,Theorems 8.11 and 8.13] </ref>. For the Euclidean norm, the bound we prove in Proposition 1.2 is slightly sharper. 3 Lemma 2.1.
Reference: [3] <author> C. Lawson and R. Hanson, </author> <title> Solving Least Squares Problems, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliff, NJ, </address> <year> 1974. </year>
Reference-contexts: It is similar to a bound given by Faddeev, Kublanovskaya, and Fadeeva [1] whose proof is given by Lawson and Hanson <ref> [3, pp.28-35] </ref>. Lemma 2.2. Let L k 2 &lt; nfin satisfy the hypothesis of Lemma 2.1 and let ae (k) defined by ((1.9)). Then ae (k) 4 k 1 + n 3 1=2 Proof.
Reference: [4] <author> B. Parlett, </author> <title> The Symmetric Eigenvalue Problem, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1980. </year>
Reference-contexts: If k = n 1, oe n1 (F (L k )) = 1, otherwise oe n1 (F (L k )) p Proof. First consider the case k = n 1. Let F (L n1 ) = ( ^ F n1 e n ): The Cauchy interlace theorem <ref> [4, p.186,Theorem 10-1-2] </ref> applied to F (L n1 ) T F (L n1 ) states that oe n1 (F (L n1 )) oe n1 ( ^ F n1 ): We now show that oe n1 ( ^ F n1 ) = p Note that F (L n1 ) T F (L
Reference: [5] <author> G. Stewart, </author> <title> Introduction to Matrix Computations, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: By a similar argument Q = P L k Q k (2.2) where Q k = A k R 1 and L k and A k are given in (1.5)-(1.6). Since the first k columns of Q k are zero below the diagonal, the uniqueness of the L-U decomposition <ref> [5, pp.121,Theorem 2.6] </ref> assures us that (2.2) is the kth stage of GEPP applied to Q.
Reference: [6] <author> J. Wilkinson, </author> <title> Error analysis of direct methods of matrix inversion, </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 8 (1961), </volume> <pages> pp. 281-330. </pages>
Reference-contexts: Equation (1.7) assures that L = (` ij ), where j` ij j 1 for all i and j and that the same holds for each L k . Wilkinson <ref> [6] </ref> showed that the stability of GEPP depends upon the growth factor i A = (k) max (i;j) ja ij j He also showed that max A2&lt; nfin i A = 2 k ; and that i n = max A2&lt; nfin i A = 2 n1 : The decomposition (1.1) <p> Wilkinson's Example Revisited and Conclusions. Let A = (a ij ) 2 &lt; 25fi25 be the matrix a ij = &lt; 0 if 1 &lt; i &lt; j 1 if i &gt; j. This is a famous example due to Wilkinson <ref> [6] </ref>. We then let the P-L-U factorization by GEPP be given by (1.1) and the orthgonal factorization of A be given by (1.10).
References-found: 6

