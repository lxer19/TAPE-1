URL: http://ftp.cs.yale.edu/pub/technical-reports/tr882.ps.gz
Refering-URL: http://ftp.cs.yale.edu/pub/technical-reports/
Root-URL: http://www.cs.yale.edu
Email: chen-marina@cs.yale.edu wu-jan-jan@cs.yale.edu  
Title: Optimizing FORTRAN-90 Programs for Data Motion on Massively Parallel Systems Draft main sources of communication,
Author: Marina C. Chen Jan-Jan Wu 
Note: The  
Address: New Haven, CT 06520-2158  
Affiliation: Department of Computer Science Yale University  
Abstract: This paper describes a general compiler optimization technique that reduces communication overhead for FORTRAN-90 (and High Performance FORTRAN currently being drafted) implementations on massively parallel machines. A model of data motion and an algebraic representation of data motion and data layout are presented. Yale Extension, a set of layout declarations for directing the compiler in distributing the data, is described. An array reference or an array operation extracted from the source FORTRAN-90 program, given a particular data layout specified in Yale Extension, is represented as a communication expression. A communication algebra and a set of communication idioms are described. Experimental results (on the Intel iPSC/2) demonstrating the effectiveness of the approach are provided. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> The Connection Machine CM-5 Technical Summary. </institution> <type> Technical report, </type> <institution> Thinking Machines Corporation, </institution> <year> 1991. </year>
Reference-contexts: The default will be Gray code encoding, if no directives are explicitly given. In the future, we expect new encoding schemes for networks such as the fat-tree network of CM-5 <ref> [1] </ref>. The directive is of the form PMAP A BY G where A is an array and G one of the axis-encoding schemes.
Reference: [2] <author> H. Berryman and J. Saltz. </author> <title> A Manual for PARTI Runtime Primitives. </title> <type> Interim Report 90-13, </type> <institution> ICASE, </institution> <year> 1990. </year>
Reference-contexts: The optimization of data motion coupled with parameterized or input dependent data distribution mainly consists of partial compile-time optimization and a heavy-duty runtime support system, such as the runtime preprocessing techniques proposed in <ref> [2, 23, 26] </ref>.
Reference: [3] <author> Shahid H. Bokhari. </author> <title> Complete Exchange on The iPSC-860. </title> <type> Technical report, </type> <institution> ICASE, NASA Langley Research Center, </institution> <year> 1991. </year>
Reference-contexts: All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications <ref> [3, 4, 13, 18, 17, 24] </ref>, and dimension permutations [13, 14, 15, 17] using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work.
Reference: [4] <author> Shahid H. Bokhari. </author> <title> Multiphase Complete Exchange on A Circuit Switched Hypercube. </title> <type> Technical report, </type> <institution> ICASE, NASA Langley Research Center, </institution> <year> 1991. </year>
Reference-contexts: All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications <ref> [3, 4, 13, 18, 17, 24] </ref>, and dimension permutations [13, 14, 15, 17] using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work.
Reference: [5] <author> M. Bromley, S. Heller, T. McNerney, and G. L. Steele Jr. </author> <title> Fortran at Ten Gigaflops: The Connection Machine Convolution Compiler. </title> <booktitle> In ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 145-156, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: This work relates to other research in two main areas. Thinking Machine's CM/2 Convolution Compiler <ref> [5] </ref> optimizes data motion between processors as well as within a processor (register allocation) for a very specialized class of FORTRAN-90 expressions (stencil patterns) and for a specific target (microcoded optimizations). <p> Typical examples are stencil communication patterns. For efficient implementation, the boundaries along all dimensions are unified so that every processor concurrently exchanges the same amount of data with its 2n neighbors in the n-dimensional logical processor array. For detail discussion please refer to <ref> [5] </ref>. Idiom 7 Matrix Transposition 1D partition for the matrix implies all-to-all personalized communications. With multidimensional partition, matrix transposition is a permutation of the global address at each dimension. For instance, 2D partition of the matrix implies the exchange of the row address and the column address.
Reference: [6] <author> L. E. Cannon. </author> <title> A Cellular Computer to Implement the Kalman Filter Algorithm. </title> <type> Technical report, </type> <institution> Montana State University, </institution> <year> 1969. </year>
Reference-contexts: The results are from running hand-compiled, hand-optimized programs from the FORTRAN-90 source running on a 64-processor Intel iPSC/2. Gray code encoding, the default encoding scheme for hypercube networks, is used for the entire program. The matrix multiplication subroutine mm uses Cannon's algorithm <ref> [6] </ref> which requires that the two operand matrices be cyclically skewed by using the array operator CSKEW (line 10 and 11 of mm).
Reference: [7] <author> Barbara Chapman, Piyush Mehrotra, and Hans Zima. </author> <title> Vienna FORTRAN A Fortran Language Extension for Distributed Memory Multiprocessors. In High Performance FORTRAN Forum, </title> <address> Houston, Texas, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: Yale Extension grew out of the domain morphism construct in Crystal [8] and, in many ways, is similar to layout extensions proposed in FORTRAN-D [11] and Vienna FORTRAN <ref> [7] </ref>. <p> Among various proposals for FORTRAN-90 extensions <ref> [7, 11, 21, 22, 25] </ref>, points (1) and (2) above are unique while point (3) is consistent with the proposal from Thinking Machines Corporation. The techniques described in this paper is currently being integrated with the FORTRAN-90-Y compiler [9] developed at Yale. <p> There are two major differences between Yale Extension and other layout specifications such as the extension in FORTRAN-D [11] and Vienna FORTRAN <ref> [7] </ref>. <p> REAL, DIMENSION (n,n) :: A, B P1 BEGIN_PHASE ALIGN A WITH B BY EOSHIFT (A,dim=1,shift=1) PARTITION B by (BLOCK,*) ... P2 BEGIN_PHASE DEALIGN A PARTITION A by (BLOCK,BLOCK) ... END_PHASE ... END_PHASE The following code segment defines an iteration in an ADI method (example from <ref> [7] </ref>), which contains one parent phase P1 and one child phase P2, each containing a loop. In the parent phase P1, arrays U, F and V are partitioned as blocks of columns.
Reference: [8] <author> Marina Chen, Young-il Choo, and Jingke Li. </author> <title> Theory and pragmatics of generating efficient parallel code. </title> <booktitle> In Parallel Functional Languages and Compilers, chapter 7. </booktitle> <publisher> ACM Press and Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: Thinking Machine's CM/2 Convolution Compiler [5] optimizes data motion between processors as well as within a processor (register allocation) for a very specialized class of FORTRAN-90 expressions (stencil patterns) and for a specific target (microcoded optimizations). Yale Extension grew out of the domain morphism construct in Crystal <ref> [8] </ref> and, in many ways, is similar to layout extensions proposed in FORTRAN-D [11] and Vienna FORTRAN [7]. <p> We consider in this paper index domains which are Cartesian products of interval domains, denoted as [l::u] where l u is a set of contiguous integers fl; l + 1; : : :; ug. We model alignments, partitions, and physical maps as index domain morphisms <ref> [8] </ref>, each of which maps an index domain to another index domain. The type of domain morphisms considered in this paper are reshape morphisms except for replication. A reshape morphism is a bijective function 2 g : D ! E from one index domain to another.
Reference: [9] <author> Marina Chen and James Cowie. </author> <title> prototyping Fortran-90 Compilers for Massively Parallel Machines. </title> <booktitle> In Proceedings of the ACM SIGPLAN'92 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: Among various proposals for FORTRAN-90 extensions [7, 11, 21, 22, 25], points (1) and (2) above are unique while point (3) is consistent with the proposal from Thinking Machines Corporation. The techniques described in this paper is currently being integrated with the FORTRAN-90-Y compiler <ref> [9] </ref> developed at Yale. The organization of the rest of the paper is as follows: In Section 2 the model of data motion is introduced. In Section 3 the Yale extension for specifying data layout is presented. In Section 4 our method of optimization is described. <p> The Communication Algebra has been implemented in Scheme and is currently being reimplemented in Standard ML, in order to integrate the optimization module described in this paper with the FORTRAN-90-Y compiler at Yale <ref> [9] </ref>. Our plan is to use this platform to test a variety of applications so that we will gain a better understanding of how the layout directives and scoping rules would work in reality.
Reference: [10] <author> Marina Chen and Jan-Jan Wu. </author> <title> The Algebraic Machinery for Optimizing Communications and Layout Conversions in Parallel Programs. </title> <note> Technical Report in preparation, </note> <institution> Department of Computer Science, Yale University, </institution> <year> 1992. </year>
Reference-contexts: For more detail discussion on the communication algebra, please refer to <ref> [10] </ref>. 4.2 Communication Idioms Since the advent of massively parallel machines, many researchers (e.g. [12]) have developed specialized communication routines to facilitate direct programming of distributed-memory machines.
Reference: [11] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu. </author> <title> Fortran D Language Specification. In High Performance FORTRAN Forum, </title> <address> Houston, Texas, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: Yale Extension grew out of the domain morphism construct in Crystal [8] and, in many ways, is similar to layout extensions proposed in FORTRAN-D <ref> [11] </ref> and Vienna FORTRAN [7]. <p> Among various proposals for FORTRAN-90 extensions <ref> [7, 11, 21, 22, 25] </ref>, points (1) and (2) above are unique while point (3) is consistent with the proposal from Thinking Machines Corporation. The techniques described in this paper is currently being integrated with the FORTRAN-90-Y compiler [9] developed at Yale. <p> If layout strategies are to be automatically determined by a compiler, these layout directives and operators are to be used internally to specify which layout strategy has been chosen. There are two major differences between Yale Extension and other layout specifications such as the extension in FORTRAN-D <ref> [11] </ref> and Vienna FORTRAN [7].
Reference: [12] <author> Geoffrey C. Fox, Mark A. Johnson, Gregory A. Lysenga, Steve W. Otto, John K. Salmon, and David W. Walker. </author> <title> Solving Problems on Concurrent Processors. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: For more detail discussion on the communication algebra, please refer to [10]. 4.2 Communication Idioms Since the advent of massively parallel machines, many researchers (e.g. <ref> [12] </ref>) have developed specialized communication routines to facilitate direct programming of distributed-memory machines. In building compilers, we might as well take advantage of these handcrafted, highly optimized routines which become part of the runtime system for the language. In [19], this approach is used to generate intraprocedure communication.
Reference: [13] <author> Ching-Tien Ho. </author> <title> Optimal Communication Primitives and Graph Embeddings on Hypercubes. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Yale University, </institution> <year> 1990. </year>
Reference-contexts: In [19], this approach is used to generate intraprocedure communication. Here we extend that work further to include those communication routines for converting layouts between program phases or subroutine calls. All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation <ref> [13] </ref>. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications [3, 4, 13, 18, 17, 24], and dimension permutations [13, 14, 15, 17] using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work. <p> All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications <ref> [3, 4, 13, 18, 17, 24] </ref>, and dimension permutations [13, 14, 15, 17] using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work. <p> All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications [3, 4, 13, 18, 17, 24], and dimension permutations <ref> [13, 14, 15, 17] </ref> using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work.
Reference: [14] <author> Ching-Tien Ho and S. Lennart Johnsson. </author> <title> Optimal Algorithms for Stable Dimension Permutations on Boolean Cubes. </title> <booktitle> In The Third Conference on Hypercube Concurrent Computers and Applications, </booktitle> <pages> pages 725-736. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications [3, 4, 13, 18, 17, 24], and dimension permutations <ref> [13, 14, 15, 17] </ref> using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work.
Reference: [15] <author> Ching-Tien Ho and S. Lennart Johnsson. </author> <title> The Complexity of Reshaping Arrays on Boolean Cubes. </title> <booktitle> In proceedings of 5th Distributed Memory Computing Conference, </booktitle> <year> 1990. </year>
Reference-contexts: All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications [3, 4, 13, 18, 17, 24], and dimension permutations <ref> [13, 14, 15, 17] </ref> using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work. <p> Idiom 1 Change Encoding In <ref> [15] </ref> the conversion between binary code and binary reflected Gray code is formulated as reshaping a 1D array of size 2 n to a 2 fi 2 fi : : : fi 2 array of n dimensions, which can be done efficiently using a sequence of nearest-neighbor communications. 12 Idiom 2 <p> Idiom 8 Skewing Specialized implementations are given for skewing along single dimension with constant skewing offsets. Idiom 9 Array Reshaping Array axis spliting and axis combining are special cases of array reshaping. Efficient algorithms using a sequence of nearest-neighbor communicatinos are presented in <ref> [15] </ref>. Idiom 10 Regular Section Remapping Layout conversion over regular sections may imply local memory accesses or personalized communications. The analysis for regular section remapping is analogous to change of partition except that the data motion is confined to a subset of the processors.
Reference: [16] <author> S. Lennart Johnsson. </author> <title> The FFT and Fast Poisson Solvers on Parallel Architectures. </title> <type> Technical report, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1987. </year> <month> 26 </month>
Reference-contexts: Depending on the implementation, different target machines may have different default mapping schemes. Three different axis-encoding schemes <ref> [16] </ref>, namely, binary encoding (BINARY), Gray (binary reflected) encoding (GRAY), and random assignment (RANDOM) are used for mapping multidimensional grids to hypercube networks. The default will be Gray code encoding, if no directives are explicitly given.
Reference: [17] <author> S. Lennart Johnsson and Ching-Tien Ho. </author> <title> Matrix Transposition on Boolean n-cube Configured En--semble Architectures. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 9(3) </volume> <pages> 419-454, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications <ref> [3, 4, 13, 18, 17, 24] </ref>, and dimension permutations [13, 14, 15, 17] using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work. <p> All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications [3, 4, 13, 18, 17, 24], and dimension permutations <ref> [13, 14, 15, 17] </ref> using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work. <p> The permutations for changing partition scheme, changing processor configuration and changing encoding may be combined into one. The most general case will be an arbitrary dimension permutation over the global address bits, which can be done in logarithmic steps using two phases of all-to-all personalized communications <ref> [17] </ref>. Idiom 4 1D ALIGN-I Data movement in this group included shift, cyclic shift and reflection along a single dimension. Shifts imply nearest-neighbor communications, while reflection is a reversal permutation. Both can be done in 1-hop with Gray code encoding. <p> With multidimensional partition, matrix transposition is a permutation of the global address at each dimension. For instance, 2D partition of the matrix implies the exchange of the row address and the column address. Efficient recursive algorithms for matrix transposition have been presented in <ref> [17] </ref>. Idiom 8 Skewing Specialized implementations are given for skewing along single dimension with constant skewing offsets. Idiom 9 Array Reshaping Array axis spliting and axis combining are special cases of array reshaping. Efficient algorithms using a sequence of nearest-neighbor communicatinos are presented in [15].
Reference: [18] <author> S. Lennart Johnsson and Ching-Tien Ho. </author> <title> Spanning graphs for optimum broadcasting and personalized communication in hypercubes. </title> <journal> IEEE Trans. Computers, </journal> <volume> 38(9) </volume> <pages> 1249-1268, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications <ref> [3, 4, 13, 18, 17, 24] </ref>, and dimension permutations [13, 14, 15, 17] using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work.
Reference: [19] <author> Jingke Li and Marina Chen. </author> <title> Compiling Communication-Efficient Programs for Masssively Parallell Machines. </title> <journal> IEEE Transactions on Parallel and Distributed System, </journal> <volume> (3), </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: In building compilers, we might as well take advantage of these handcrafted, highly optimized routines which become part of the runtime system for the language. In <ref> [19] </ref>, this approach is used to generate intraprocedure communication. Here we extend that work further to include those communication routines for converting layouts between program phases or subroutine calls. All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13].
Reference: [20] <author> Jingke Li and Marina Chen. </author> <title> The data alignment phase in compiling programs for distributed-memory machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <year> 1991. </year>
Reference-contexts: In this simple case it is clear how an alignment directive can be inserted by a compiler automatically. In general, when multiple arrays and multiple assignments are involved, the problem of finding the optimal alignment is NP-complete but heuristics are sufficiently effective <ref> [20] </ref>. REAL, DIMENSION (n) :: A, B ALIGN B WITH A BY EOSHIFT (B,shift=1) A = EOSHIFT (B,shift=1) + A Let's say that the source array in an ALIGN-WITH-BY statement precedes the target array. The closure of multiple ALIGN-WITH-BY statements determines the final alignment of all arrays involved.
Reference: [21] <author> David B. Loveman. </author> <title> High Performance Fortran Proposal. In High Performance FORTRAN Forum, </title> <address> Houston, Texas, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: Among various proposals for FORTRAN-90 extensions <ref> [7, 11, 21, 22, 25] </ref>, points (1) and (2) above are unique while point (3) is consistent with the proposal from Thinking Machines Corporation. The techniques described in this paper is currently being integrated with the FORTRAN-90-Y compiler [9] developed at Yale.
Reference: [22] <author> D. M. Pase. </author> <title> MPP Fortran Programming Model. In High Performance FORTRAN Forum, </title> <address> Houston, Texas, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: Among various proposals for FORTRAN-90 extensions <ref> [7, 11, 21, 22, 25] </ref>, points (1) and (2) above are unique while point (3) is consistent with the proposal from Thinking Machines Corporation. The techniques described in this paper is currently being integrated with the FORTRAN-90-Y compiler [9] developed at Yale.
Reference: [23] <author> J. Saltz, H. Berryman, and J. Wu. </author> <title> Runtime Compilation for Multiprocessors. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3(6) </volume> <pages> 573-592, </pages> <year> 1991. </year>
Reference-contexts: Another example shows an indirect data mapping using user-defined layout functions. The concept of indirect mapping is adopted from the PARTI compiler <ref> [23] </ref>, FORTRAN-D, as well as Vienna FORTRAN. In the example, array A is distributed indirectly according to the mapping array AMAP, whose value may be given as input data or be computed during program execution. <p> The optimization of data motion coupled with parameterized or input dependent data distribution mainly consists of partial compile-time optimization and a heavy-duty runtime support system, such as the runtime preprocessing techniques proposed in <ref> [2, 23, 26] </ref>.
Reference: [24] <author> T. Schmiermund and S. R. Seidel. </author> <title> A Communication Model for the Intel iPSC/2. </title> <type> Technical report, </type> <institution> Michigan Technological University, </institution> <year> 1990. </year>
Reference-contexts: All of the data motion in layout conversion can be formulated as so-called personalized communication and dimension permutation [13]. Optimal algorithms have been devised for one-to-all and all-to-all personalized communications <ref> [3, 4, 13, 18, 17, 24] </ref>, and dimension permutations [13, 14, 15, 17] using nearest-neighbor communication on hypercubes. We have collected a set of frequently occurring data motions based on the results of this work.
Reference: [25] <author> Guy Steele. </author> <title> Proposals for Amending High Performance Fortran. In High Performance FORTRAN Forum, </title> <address> Houston, Texas, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: Among various proposals for FORTRAN-90 extensions <ref> [7, 11, 21, 22, 25] </ref>, points (1) and (2) above are unique while point (3) is consistent with the proposal from Thinking Machines Corporation. The techniques described in this paper is currently being integrated with the FORTRAN-90-Y compiler [9] developed at Yale.
Reference: [26] <author> J. Wu, J. Saltz, H. Berryman, and S. Hiranandani. </author> <title> Distributed Memory Compiler Design for Sparse Problems. </title> <type> Report 91-13, </type> <institution> ICASE, </institution> <year> 1991. </year> <month> 27 </month>
Reference-contexts: The optimization of data motion coupled with parameterized or input dependent data distribution mainly consists of partial compile-time optimization and a heavy-duty runtime support system, such as the runtime preprocessing techniques proposed in <ref> [2, 23, 26] </ref>.
References-found: 26

