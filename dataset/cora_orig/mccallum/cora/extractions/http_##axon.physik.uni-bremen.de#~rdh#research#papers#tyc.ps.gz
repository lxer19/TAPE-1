URL: http://axon.physik.uni-bremen.de/~rdh/research/papers/tyc.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00267.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: henkel@theo.physik.uni-bremen.de  
Title: Fast Stereovision by Coherence Detection  
Author: R.D. Henkel 
Address: Postfach 330 440 D-28334 Bremen, Germany  
Affiliation: Institute of Theoretical Neurophysics, University of Bremen  
Abstract: In human stereovision, a vivid sensation of depth is created by the small relative displacements of objects in the retinal images of the left and right eye. Utilizing only two different views of a scene, the range of disparities which simple disparity units can estimate is severely limited by aliasing effects. A new computational approach to stereo vision utilizes these aliasing effects in a coherence detection scheme to allow the calculation of dense disparity maps over a large range of disparities with plausible biological hardware. The fast, non-iterative algorithm creates within a single network structure simultaneously a disparity map exhibiting hyperacuity, a verification count of the disparity data and fuses the left and right input images to the cyclopean view of the scene.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U. R. Dhond and J. K. Aggarwal, </author> <title> Structure from Stereo A Review, </title> <journal> IEEE Trans. Syst., Man and Cybern. </journal> <volume> 19, </volume> <pages> 1489-1510, </pages> <year> 1989. </year>
Reference-contexts: Classical approaches to stereo vision try to counteract this whole set of distorting signal variations with two basic algorithmic paradigms, known as feature- and as area-based approaches <ref> [1] </ref>. In feature-based stereo algorithms, the intensity data is first converted to a set of features assumed to be a more stable image property than the raw intensities. The matching stage operates only on these extracted image features.
Reference: [2] <author> J. P. </author> <title> Frisby, Stereo Correspondence and Neural Networks, in "Handbook of Brain Theory", </title> <editor> ed. M. A. </editor> <booktitle> Arbib, </booktitle> <pages> 937-941, </pages> <publisher> MIT Press 1995. </publisher>
Reference-contexts: These constraints are usually derived from reasonable assumptions about the physical properties of object surfaces, and rule out certain combination of matches. Classical constraints include the uniqueness of a match, figural continuity and the preserved ordering of matches along horizontal scanlines <ref> [2] </ref>. In conjunction with the features extracted from the images, constraints define a complicated error measure which can be minimized by direct search techniques or through cooperative processes.
Reference: [3] <author> J. Weng, </author> <title> Image Matching Using the Windowed Fourier Phase, </title> <journal> Int. J. of Comp. Vis. </journal> <volume> 3, </volume> <pages> 211-236, </pages> <year> 1993. </year>
Reference-contexts: In the extreme case, one might utilize a continuum of feature-classes. For example, the locally computed Fourier phase can be used for classifying local intensity variations into feature-classes indexed by the continuous phase value <ref> [3] </ref>. Using such a continuum of feature-classes, with the feature index derived from some small image area, is very similar to standard area-based stereo algorithms. In these algorithms, not only a single feature value, but the full vector of image intensities over a small image patch is used for matching.
Reference: [4] <author> T.D. Sanger, </author> <title> Stereo Disparity Computations Using Gabor Filter, </title> <journal> Biol. Cy-bern. </journal> <volume> 59, </volume> <pages> 405-418, </pages> <year> 1988. </year>
Reference-contexts: The disparity estimate might be wrong, might have a different value than at finer scales, or might not be present at all. Thus hierarchical approaches will fail under various circumstances. A third way for calculating disparities is known as phase-based methods <ref> [4, 5] </ref>. These approaches derive Fourier-phase images from the raw intensity data. Extraction of the Fourier phase can be considered as a local contrast equalization reducing the effects of many intensity variations between the two stereo views.
Reference: [5] <author> M. R. M. Jenkin and A. D. Jepson, </author> <title> Recovering Local Surface Structure through Local Phase Difference Methods, </title> <type> CVGIP 59, </type> <pages> 72-93, </pages> <year> 1994. </year>
Reference-contexts: The disparity estimate might be wrong, might have a different value than at finer scales, or might not be present at all. Thus hierarchical approaches will fail under various circumstances. A third way for calculating disparities is known as phase-based methods <ref> [4, 5] </ref>. These approaches derive Fourier-phase images from the raw intensity data. Extraction of the Fourier phase can be considered as a local contrast equalization reducing the effects of many intensity variations between the two stereo views.
Reference: [6] <author> J. L. Barron, D.J. Fleet and S. S. Beauchemin, </author> <title> Performance of Optical Flow Techniques, </title> <journal> Int. J. Comp. Vis. </journal> <volume> 12, </volume> <pages> 43-77, </pages> <year> 1994. </year>
Reference-contexts: Using optical flow estimation techniques for disparity calculations, this problem is always present, since only the two samples obtained from the left and right eye are available for flow estimation. tical flow methods, with the time-derivative approximated by the difference between the left and right Fourier-phase images <ref> [6] </ref>. The Fourier phase exhibits wrap-around, making it again necessary to employ hierarchical methods | with the already discussed drawbacks. Furthermore, additional steps have to be taken to ensure the exclusion of regions with ill-defined Fourier phase [7]. <p> A valid disparity estimate would show up in such a network as a strong coherent neuronal signal. For the disparity estimators, various circuitry can be used. In the simulations reported below, units based on motion-energy filtering [12, 13, 14], units based on standard optical flow estimation techniques <ref> [6] </ref> and units based on algorithms 5 Simple disparity estimators are arranged in horizontal layers, which have slightly overlapping working ranges. Image data is fed into the network along diagonal running data lines.
Reference: [7] <author> D.J. Fleet and A. D. Jepson, </author> <title> Stability of Phase Information, </title> <journal> IEEE Trans. Patt. Anal. Mach. Intel. </journal> <volume> 15, </volume> <pages> 1253-1268, </pages> <year> 1993. </year>
Reference-contexts: The Fourier phase exhibits wrap-around, making it again necessary to employ hierarchical methods | with the already discussed drawbacks. Furthermore, additional steps have to be taken to ensure the exclusion of regions with ill-defined Fourier phase <ref> [7] </ref>. The new approach to stereo vision presented in this paper rests on simple disparity estimators which also employ classical optical flow estimation techniques. However, essential to the new approach are aliasing effects of these disparity units in connection with a simple coherence detection scheme.
Reference: [8] <author> R. Blake and H. R. Wilson, </author> <title> Neural Models of Stereoscopic Vision, </title> <booktitle> TINS 14, </booktitle> <pages> 445-452, </pages> <year> 1991. </year>
Reference-contexts: Cortical cells respond to spatial frequencies up to about twice their peak wavelength opt , therefore limiting the range of detectable disparities to values less than 1=4 opt . This is known as Marr's quarter-cycle limit <ref> [8, 9] </ref>. Since image data is usually sampled in spatial direction with some fixed receptor spacing ', the highest wavevector k ' max which can be present in the data after retinal sampling is given by k ' max = ='. <p> The structure of the new network resembles superficially earlier cooperative schemes used to disambiguate false matches <ref> [8, 15] </ref>, but the dynamics and the link structures of the new network are quite different. In the new scheme, the disparity stacks do not interact with each other; thus no direct spatial facilitation of disparity estimates is taking place.
Reference: [9] <author> D. Marr and T. Poggio, </author> <title> A Computational Theory of Human Stereo Vision, </title> <journal> Proc. R. Soc. Lond. </journal> <volume> B 204, </volume> <pages> 301-328, </pages> <year> 1979. </year>
Reference-contexts: Cortical cells respond to spatial frequencies up to about twice their peak wavelength opt , therefore limiting the range of detectable disparities to values less than 1=4 opt . This is known as Marr's quarter-cycle limit <ref> [8, 9] </ref>. Since image data is usually sampled in spatial direction with some fixed receptor spacing ', the highest wavevector k ' max which can be present in the data after retinal sampling is given by k ' max = ='.
Reference: [10] <author> H. R. Wilson and J. D. Cowan, </author> <title> Excitatory and inhibitory interactions in localized populations of model neurons, </title> <journal> Biophys. J. </journal> <volume> 12, </volume> <pages> 1-24, </pages> <year> 1972. </year> <month> 10 </month>
Reference-contexts: Only the largest cluster found in each stack is read out by the coherence mechanism. This type of coherence detection can be realized easily with biological hardware, for example with neuronally implemented limit-cycle oscillators <ref> [10] </ref>. Assuming appropriate links structures, these neural oscillators will synchronize their responses, but only if they code approximately the same stimulus value [11]. A valid disparity estimate would show up in such a network as a strong coherent neuronal signal. For the disparity estimators, various circuitry can be used.
Reference: [11] <author> R.D. Henkel, </author> <title> Segmentation in Scale Space, </title> <booktitle> in: "Computer Analysis of Im--ages and Pattern, CAIP '95 Proceedings", </booktitle> <volume> LNCS 970, </volume> <pages> 41-48, </pages> <publisher> Springer 1995. </publisher>
Reference-contexts: This type of coherence detection can be realized easily with biological hardware, for example with neuronally implemented limit-cycle oscillators [10]. Assuming appropriate links structures, these neural oscillators will synchronize their responses, but only if they code approximately the same stimulus value <ref> [11] </ref>. A valid disparity estimate would show up in such a network as a strong coherent neuronal signal. For the disparity estimators, various circuitry can be used.
Reference: [12] <author> N. Qian and Y. Zhu, </author> <title> Physiological Computation of Binocular Disparity, </title> <note> to appear in Vision Research '97. </note>
Reference-contexts: A valid disparity estimate would show up in such a network as a strong coherent neuronal signal. For the disparity estimators, various circuitry can be used. In the simulations reported below, units based on motion-energy filtering <ref> [12, 13, 14] </ref>, units based on standard optical flow estimation techniques [6] and units based on algorithms 5 Simple disparity estimators are arranged in horizontal layers, which have slightly overlapping working ranges. Image data is fed into the network along diagonal running data lines.
Reference: [13] <author> G. C. DeAngelis, I. Ohzawa, and R. D. Freeman, </author> <title> Depth is Encoded in the Visual Cortex by a Specialized Receptive Field Structure, </title> <booktitle> Nature 11, </booktitle> <pages> 156-159, </pages> <year> 1991. </year>
Reference-contexts: A valid disparity estimate would show up in such a network as a strong coherent neuronal signal. For the disparity estimators, various circuitry can be used. In the simulations reported below, units based on motion-energy filtering <ref> [12, 13, 14] </ref>, units based on standard optical flow estimation techniques [6] and units based on algorithms 5 Simple disparity estimators are arranged in horizontal layers, which have slightly overlapping working ranges. Image data is fed into the network along diagonal running data lines.
Reference: [14] <author> E. H. Adelson and J. R. Bergen, </author> <title> Spatiotemporal Energy Models for the Perception of Motion, </title> <journal> J. Opt. Soc. Am. </journal> <volume> A 2, </volume> <pages> 284-299, </pages> <year> 1985. </year>
Reference-contexts: A valid disparity estimate would show up in such a network as a strong coherent neuronal signal. For the disparity estimators, various circuitry can be used. In the simulations reported below, units based on motion-energy filtering <ref> [12, 13, 14] </ref>, units based on standard optical flow estimation techniques [6] and units based on algorithms 5 Simple disparity estimators are arranged in horizontal layers, which have slightly overlapping working ranges. Image data is fed into the network along diagonal running data lines.
Reference: [15] <author> K. Prazdny, </author> <title> Detection of Binocular Disparities, </title> <journal> Biol. </journal> <volume> Cybern 52, </volume> <pages> 93-99, </pages> <year> 1985. </year>
Reference-contexts: The structure of the new network resembles superficially earlier cooperative schemes used to disambiguate false matches <ref> [8, 15] </ref>, but the dynamics and the link structures of the new network are quite different. In the new scheme, the disparity stacks do not interact with each other; thus no direct spatial facilitation of disparity estimates is taking place.
Reference: [16] <author> J. Bigun, G. H. Granlund and J. Wiklund, </author> <title> Multidimensional Orientation Estimation with Application to Texture Analysis and Optical Flow, </title> <journal> IEEE Trans. Patt. Anal. and Mach. Intl. </journal> <volume> 13, </volume> <pages> 775-790, </pages> <year> 1991. </year>
Reference-contexts: Image data is fed into the network along diagonal running data lines. Within each of the vertical disparity stacks, coherently coding subpopulations of disparity units are detected, and the average disparity value of these pools is finally read out by the mechanism. for the estimation of principal texture direction <ref> [16] </ref> were utilized. All these disparity estimators can be realized by simple spatial filter operations combined with local nonlinearities; at least the units based on motion-energy filtering are currently discussed as models for cortical processing by complex cells.
Reference: [17] <author> A. Fusiello, V. Roberto, and E. Trucco, </author> <title> A Symmetry-based Stereo Algorithm, </title> <note> Research report udmi/53/96/rr, submitted to CVPR 97, </note> <institution> Machine Vision Lab, University of Udine, Italy, </institution> <year> 1996. </year>
Reference-contexts: Additional units are simply included in the appropriate coherence stack. The coherence scheme will combine only the information from the coherently acting units and ignore the rest of the data. For example, adding units with asymmetric receptive fields <ref> [17] </ref> will result in more precise disparity estimates close to object boundaries. Presumably, this is the situation in a biological context: various disparity units with rather random properties are grouped into stacks responding to common view directions.
Reference: [18] <author> P. A. Arndt, HP. A. Mallot, H. H. Bulthoff, </author> <title> Human stereovision without localized image features, </title> <journal> Biol. Cybern. </journal> <volume> 72, </volume> <pages> 279-293, </pages> <year> 1995. </year> <month> 11 </month>
Reference-contexts: Fig. 5B shows results obtained with a disparity unit based on an algorithm for the estimation of principal texture direction. Classical feature-based stereo algorithms would fail with this stimulus set, since the stereo data lacks any localized images features <ref> [18] </ref>. Finally, in Fig. 5C, a disparity map obtained from an outdoor scene is shown. Natural imagery usually has sufficient detail present in all image areas and at all spatial scales, so dense and stable disparity maps can be obtained with the coherence-based stereo algorithm.
References-found: 18

