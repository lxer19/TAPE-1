URL: http://www.is.cs.cmu.edu/papers/speech/1996/ICSLP96-zhan.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: Email: fzhan,ries,marsal,dmg,alavie,ahwg@cs.cmu.edu  
Title: JANUS-II: Towards Spontaneous Spanish Speech Recognition  
Author: Puming Zhan, Klaus Ries, Marsal Gavalda Donna Gates, Alon Lavie, and Alex Waibel 
Address: Pittsburgh, PA 15213  
Affiliation: Interactive Systems Laboratories Carnegie Mellon University  
Abstract: JANUS-II is a research system for investigating various issues in speech-to-speech translations and has been implemented for speech-to-speech translations on many languages [1]. In this paper, we address the Spanish speech recognition part of JANUS-II. First, we report the bootstrap and optimization of the recognition system. Then we investigate the difference between push-to-talk and cross-talk dialogs, which are two different kinds of data in our database. We give a detail noise analysis for the push-to-talk and cross-talk dialogs and present some recognition results for the comparison. We have observed that the cross-talk dialogs are harder than the push-to-talk dialogs for speech recognition, because they are more noisy than the latter. Currently, the error rate of our Spanish recognizer is 27% for push-to-talk test set and 32% for crosstalk test set. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A.Waibel, M.Finke, D.Gates, M.Gavalda, T.Kemp, A.Lavie, L.Levin, M.Maier, L.Mayfield, A.McNair, I.Rogina, K.Shima, T.Sloboda, M.Woszczyna, T.Zeppenfiled, and P.Zhan. </author> <title> Jnaus-ii advances in spontaneous speech recognition. </title> <address> ICASSP-96, </address> <year> 1996. </year>
Reference-contexts: Database The JANUS system is built for and evaluated on the appointment scheduling task. The details of this Database, including English, German, Korea, Japanese and Spanish data, can be found in <ref> [1] </ref>. The Spanish Database consists of two different kinds of data: push-to-talk dialogs and crosstalk dialogs. More than a half of the data in the database are cross-talk dialogs. Although they are all human to human dialogs, these data are recorded in very different styles. <p> We use the Viterbi algorithm for acoustic model training and update the parameters of the best matched component of Gaussian-Mixture density. For recognition, we use the standard JANUS-II decoder which includes three passes, i.e. Tree-pass, Flat-pass and Lattice-pass <ref> [1, 6] </ref>. All results we report in this paper are obtained from the Flat-pass, with which word accuracy is about 1.5% - 2.5% better than the Tree-pass and 0.5% - 1.5% lower than the Lattice-pass. We have used two different trigram language models.
Reference: 2. <author> Fukunnaga and Keinosuke. </author> <title> Introduction to statistical pattern recognition. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: We combine 13 cep-strum coefficients with its Delta and Delta-Delta coefficients together to generate a 39-dimension feature vector. Finally, this feature vector is transformed by a 39x39 matrix which is generated by Linear Discriminant Analysis <ref> [2] </ref>. The first 16 components of the transformed vector are kept as the final feature vector. Our experiments showed that the above PLP is better than the Mel-Frequency-Scale Coefficients (MFSC). The word accuracy with PLP feature is about 1.5% better than that with MFSC feature. 4. <p> Optimization of the LDA transformation matrix Linear Discriminant Analysis (LDA) is a traditional technique for pattern recognition <ref> [2] </ref>. It has been used in speech recognition systems as a preprocessing method for several years. But how to embed the LDA matrix into the training process of speech recognition is still a open problem [5]. The LDA transformation matrix is created based on the classes of the patterns.
Reference: 3. <author> Hynek Hermansky, Nelson Morgan, Aruna Bayya, and Phil Kohn. </author> <title> Rasta-plp speech analysis technique. </title> <journal> ICASSP-92, </journal> <volume> 1 </volume> <pages> 121-124, </pages> <year> 1992. </year>
Reference-contexts: The test vocabulary consists of 3911 unique words in the training set. For both test sets, the out of vocabulary word rate is 1.6%. 3. Preprocessing The feature we are using is Perceptual Linear Predictive (PLP) coefficients, which are generated based on <ref> [3] </ref>. The speech signal is sampled with 16KHz rate. After passing through a preemphasis filter and Hamming window as usual, 128 points FFT spectrum is calculated. The FFT spectrum is integrated with a critical band in Bark-scale, and oper-ated with the cube 0.33 cubic-root amplitude compression.
Reference: 4. <author> Reinhard Knesey and Hermann Ney. </author> <title> Improved backing-off for m-gram language modeling. </title> <booktitle> ICASSP-95, </booktitle> <pages> pages 181-184, </pages> <year> 1995. </year>
Reference-contexts: We have used two different trigram language models. One is generated with the standard LM Tools at CMU, which is based on the standard backoff algorithm. The other is generated by using the Knesey/Ney backoff algorithm <ref> [4] </ref>. We found that Knesey/Ney's algorithm gives us about 4% error reduction. Therefore we keep using this language model in the paper. 4.2.
Reference: 5. <author> E. Gunter Schukat-Talamazzini, Joachim Hornegger, and Heinrich Niemann. </author> <title> Optimal linear feature transformations for semi-continuous hidden markov models. </title> <booktitle> ICASSP-95, </booktitle> <pages> pages 369-372, </pages> <year> 1995. </year>
Reference-contexts: It has been used in speech recognition systems as a preprocessing method for several years. But how to embed the LDA matrix into the training process of speech recognition is still a open problem <ref> [5] </ref>. The LDA transformation matrix is created based on the classes of the patterns. The goal is to build a linear transformation matrix, with which the feature can be projected into its subspace, and meanwhile keep or increase the separability of the patterns. <p> After the dynamic match or force-alignment, we first update the LDA matrix according to the alignment, then update the models. Finally, the new models are obtained by projecting the updated models into a new space based on the new LDA matrix. <ref> [5] </ref> gives a rigorous algorithm for the LDA optimization, but did not get significant improvement. Compared to it, our method is simple and suboptimal. But we got 5%-7% error reduction from it. 6.
Reference: 6. <author> M. Woszczyna and M.Finke. </author> <title> Minimizing search errors due to delayed bigrams in real-time speech recognition system. </title> <address> ICASSP-96, </address> <year> 1996. </year>
Reference-contexts: We use the Viterbi algorithm for acoustic model training and update the parameters of the best matched component of Gaussian-Mixture density. For recognition, we use the standard JANUS-II decoder which includes three passes, i.e. Tree-pass, Flat-pass and Lattice-pass <ref> [1, 6] </ref>. All results we report in this paper are obtained from the Flat-pass, with which word accuracy is about 1.5% - 2.5% better than the Tree-pass and 0.5% - 1.5% lower than the Lattice-pass. We have used two different trigram language models.
References-found: 6

