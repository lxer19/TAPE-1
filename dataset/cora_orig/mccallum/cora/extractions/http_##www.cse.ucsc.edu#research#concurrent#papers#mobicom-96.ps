URL: http://www.cse.ucsc.edu/research/concurrent/papers/mobicom-96.ps
Refering-URL: http://www.cse.ucsc.edu/research/concurrent/reports/
Root-URL: http://www.cse.ucsc.edu
Title: A Dynamic Disk Spin-down Technique for Mobile Computing  
Author: David P. Helmbold, Darrell D. E. Long and Bruce Sherrod 
Address: Santa Cruz  
Affiliation: Department of Computer Science University of California,  
Abstract: We address the problem of deciding when to spin down the disk of a mobile computer in order to extend battery life. Since one of the most critical resources in mobile computing environments is battery life, good energy conservation methods can dramatically increase the utility of mobile systems. We use a simple and efficient algorithm based on machine learning techniques that has excellent performance in practice. Our experimental results are based on traces collected from HP C2474s disks. Using this data, the algorithm outperforms several algorithms that are theoretically optimal in under various worst-case assumptions, as well as the best fixed time-out strategy. In particular, the algorithm reduces the power consumption of the disk to about half (depending on the disk's properties) of the energy consumed by a one minute fixed time-out. Since the algorithm adapts to usage patterns, it uses as little as 88% of the energy consumed by the best fixed time-out computed in retrospect. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kinshuk Govil, Edwin Chan, and Hal Wasserman, </author> <title> "Comparing algorithms for dynamic speed-setting of a low-power cpu", </title> <booktitle> in The First Annual International Conference on Mobile Computing and Networking (MobiCom), </booktitle> <address> Berkeley, CA, 1995, </address> <publisher> ACM, </publisher> <pages> pp. 13-25. </pages>
Reference-contexts: Several researchers have even considered dynamically changing the speed of the CPU in order to conserve energy <ref> [1, 2] </ref>. We show that a simple algorithm for deciding when to power down the disk drive is even more effective in reducing the energy consumed by the disk than the best fixed time-out value computed in retrospect.
Reference: [2] <author> Mark Weiser, Brent Welch, Alan Demers, and Scott Shenker, </author> <title> "Scheduling for reduced CPU energy", </title> <booktitle> in Proceedings of the First Symposium on Operating Systems Design and Implementation (OSDI), </booktitle> <address> Monterey, CA, </address> <month> Nov. </month> <year> 1994, </year> <booktitle> Usenix Association, </booktitle> <pages> pp. 13-23. </pages>
Reference-contexts: Several researchers have even considered dynamically changing the speed of the CPU in order to conserve energy <ref> [1, 2] </ref>. We show that a simple algorithm for deciding when to power down the disk drive is even more effective in reducing the energy consumed by the disk than the best fixed time-out value computed in retrospect.
Reference: [3] <author> Fred Douglis, P. Krishnan, and Brian Marsh, </author> <title> "Thwarting the power-hungry disk", </title> <booktitle> in Proceedings of the Usenix Technical Conference, </booktitle> <address> San Francisco, CA, </address> <booktitle> Winter 1994, Usenix Association, </booktitle> <pages> pp. 292-306. </pages>
Reference-contexts: We show that a simple algorithm for deciding when to power down the disk drive is even more effective in reducing the energy consumed by the disk than the best fixed time-out value computed in retrospect. Douglis et al. <ref> [3] </ref> show that the disk sub-system on portable computers consumes a major portion of the available energy (Greenawalt [4] states 30% or more). It is well-known that spinning the disk down when it is not in use can save energy [3, 5, 6, 7]. <p> Douglis et al. [3] show that the disk sub-system on portable computers consumes a major portion of the available energy (Greenawalt [4] states 30% or more). It is well-known that spinning the disk down when it is not in use can save energy <ref> [3, 5, 6, 7] </ref>. Since spinning the disk back up consumes a significant amount of energy, spinning the disk down immediately after each access is likely to use more energy than is saved. <p> A timer is set when the disk becomes idle and if the disk remains idle until the timer expires then the disk is spun down. This time-out can be set by the user, and typical values range from 30 seconds up to 15 minutes. Douglis et al. <ref> [3] </ref>, Golding et al. [5], and other researchers [4, 8, 6] have proposed algorithms which spin the disk down more aggressively, conserving much more power than these relatively long time-outs. <p> So t 0 &gt; 1:176t and the battery life is extended by more than 17%. fixed time-out, such as several minutes <ref> [3] </ref>. 2 It has been shown that energy consumption can be improved dramatically by picking a shorter fixed time-out, such as just a few seconds [3, 5]. <p> So t 0 &gt; 1:176t and the battery life is extended by more than 17%. fixed time-out, such as several minutes [3]. 2 It has been shown that energy consumption can be improved dramatically by picking a shorter fixed time-out, such as just a few seconds <ref> [3, 5] </ref>. For any particular sequence of idle times, the best fixed time-out 3 is the fixed timeout that causes the least amount of energy to be consumed over the sequence of idle times. <p> These two views of the disk spin-down problem are equivalent when the algorithm is allowed to choose a different time-out for each trial. We measure the performance of the algorithms in terms of "seconds of energy" used, a measure introduced by Douglis et al. <ref> [3] </ref>. One "second of energy" is the difference in energy consumed between a spinning disk and a spun down disk over one second. One second of energy corresponds to some number of joules, depending on the model of disk drive used. <p> If we assume that a mobile computer user's disk usage is independent of the type of disk that they have, then this single parameter, the spin-down cost s, is the only statistic about the physical disk that we need for our simulations. Douglis et al. <ref> [3] </ref> compute this value for two disks, giving spin-down costs of 5 seconds and 14.9 seconds. Golding et al. [5] gives disk statistics that correspond to a spin-down cost of 9 or 10 seconds. We analyze the share algorithm's performance for spin-down costs varying from 1 to 20 seconds.
Reference: [4] <author> Paul Greenawalt, </author> <title> "Modeling power management for hard disks", </title> <booktitle> in Proceedings of the Conference on Modeling, Analysis, </booktitle> <institution> and Simulation of Computer and Telecommunication Systems. IEEE, </institution> <month> Jan. </month> <year> 1994, </year> <pages> pp. 62-66. </pages>
Reference-contexts: Douglis et al. [3] show that the disk sub-system on portable computers consumes a major portion of the available energy (Greenawalt <ref> [4] </ref> states 30% or more). It is well-known that spinning the disk down when it is not in use can save energy [3, 5, 6, 7]. <p> This time-out can be set by the user, and typical values range from 30 seconds up to 15 minutes. Douglis et al. [3], Golding et al. [5], and other researchers <ref> [4, 8, 6] </ref> have proposed algorithms which spin the disk down more aggressively, conserving much more power than these relatively long time-outs. We use a simple algorithm called the share algorithm, a machine learning technique developed by Herb-ster and Warmuth [9], to determine when to spin the disk down. <p> This makes it very unlikely that these algorithms will use less energy than the best fixed time-out. If the fixed distribution on idle times is known in advance, then one can analyze the distribution in order to choose a good fixed time-out time. Greenawalt <ref> [4] </ref> takes this approach using a Poisson distribution to model the disk drive idle times. He uses this rather strong assumption to solve for the single time-out value giving the best expected performance (over the random choice of idle times).
Reference: [5] <author> Richard Golding, Peter Bosch, Carl Staelin, Tim Sullivan, and John Wilkes, </author> <title> "Idleness is not sloth", </title> <booktitle> in Proceedings of the Usenix Technical Conference, </booktitle> <address> New Orleans, </address> <month> Jan. </month> <year> 1995, </year> <booktitle> Usenix Association, </booktitle> <pages> pp. 201-212. </pages>
Reference-contexts: Douglis et al. [3] show that the disk sub-system on portable computers consumes a major portion of the available energy (Greenawalt [4] states 30% or more). It is well-known that spinning the disk down when it is not in use can save energy <ref> [3, 5, 6, 7] </ref>. Since spinning the disk back up consumes a significant amount of energy, spinning the disk down immediately after each access is likely to use more energy than is saved. <p> This time-out can be set by the user, and typical values range from 30 seconds up to 15 minutes. Douglis et al. [3], Golding et al. <ref> [5] </ref>, and other researchers [4, 8, 6] have proposed algorithms which spin the disk down more aggressively, conserving much more power than these relatively long time-outs. <p> So t 0 &gt; 1:176t and the battery life is extended by more than 17%. fixed time-out, such as several minutes [3]. 2 It has been shown that energy consumption can be improved dramatically by picking a shorter fixed time-out, such as just a few seconds <ref> [3, 5] </ref>. For any particular sequence of idle times, the best fixed time-out 3 is the fixed timeout that causes the least amount of energy to be consumed over the sequence of idle times. <p> Whereas we concentrate on the energy used by the spin-down algorithm, Douglis et al. pay particular attention to those spin-downs likely to inconvenience the user and analyze the tradeoff between energy consumed and these undesirable spin-downs. In Gold-ing et al. <ref> [5] </ref>, similar incrementally adaptive policies are evaluated. We compare the performances of the share algorithm and these incrementally adaptive policies in x5.4. 3 Problem Description We define the disk spin-down problem as follows. <p> Douglis et al. [3] compute this value for two disks, giving spin-down costs of 5 seconds and 14.9 seconds. Golding et al. <ref> [5] </ref> gives disk statistics that correspond to a spin-down cost of 9 or 10 seconds. We analyze the share algorithm's performance for spin-down costs varying from 1 to 20 seconds. We define the following metrics, summarized in Table 1, to measure and compare the performance of algorithms.
Reference: [6] <author> Kester Li, Roger Kumpf, Paul Horton, and Thomas Anderson, </author> <title> "A quantitative analysis of disk drive power management in portable computers", </title> <booktitle> in Proceeding of the Usenix Technical Conference, </booktitle> <address> San Francisco, </address> <booktitle> Winter 1994, Usenix Association, </booktitle> <pages> pp. 279-291. </pages>
Reference-contexts: Douglis et al. [3] show that the disk sub-system on portable computers consumes a major portion of the available energy (Greenawalt [4] states 30% or more). It is well-known that spinning the disk down when it is not in use can save energy <ref> [3, 5, 6, 7] </ref>. Since spinning the disk back up consumes a significant amount of energy, spinning the disk down immediately after each access is likely to use more energy than is saved. <p> This time-out can be set by the user, and typical values range from 30 seconds up to 15 minutes. Douglis et al. [3], Golding et al. [5], and other researchers <ref> [4, 8, 6] </ref> have proposed algorithms which spin the disk down more aggressively, conserving much more power than these relatively long time-outs. We use a simple algorithm called the share algorithm, a machine learning technique developed by Herb-ster and Warmuth [9], to determine when to spin the disk down.
Reference: [7] <author> John Wilkes, </author> <title> "Predictive power conservation", </title> <type> Tech. Rep. </type> <institution> HPL-CSP-92-5, Hewlett-Packard Laboratories, </institution> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Douglis et al. [3] show that the disk sub-system on portable computers consumes a major portion of the available energy (Greenawalt [4] states 30% or more). It is well-known that spinning the disk down when it is not in use can save energy <ref> [3, 5, 6, 7] </ref>. Since spinning the disk back up consumes a significant amount of energy, spinning the disk down immediately after each access is likely to use more energy than is saved.
Reference: [8] <author> P. Krishnan, Philip Long, and Jeffrey Scott Vitter, </author> <title> "Adaptive disk spin-down via optimal rent-to-buy in probabilistic environments", </title> <booktitle> in Proceedings of the Twelfth International Conference on Machine Learning (ML95), </booktitle> <address> Tahoe City, CA, July 1995, </address> <publisher> Mor-gan Kaufman, </publisher> <pages> pp. 322-330. </pages>
Reference-contexts: This time-out can be set by the user, and typical values range from 30 seconds up to 15 minutes. Douglis et al. [3], Golding et al. [5], and other researchers <ref> [4, 8, 6] </ref> have proposed algorithms which spin the disk down more aggressively, conserving much more power than these relatively long time-outs. We use a simple algorithm called the share algorithm, a machine learning technique developed by Herb-ster and Warmuth [9], to determine when to spin the disk down. <p> With this assumption, the best fixed time-out on the past idle times should closely approximate the best fixed time-out for the future idle times. Krishnan et al. <ref> [8] </ref> introduce an algorithm designed to operate under this assumption. Their basic algorithm operates in two phases. In the first phase it predicts arbitrarily while building a set of candidate time-outs from the idle times. <p> In practice, it is desirable for algorithms to perform best on the likely input values. One class of algorithms adapts to the input patterns, deducing from the past which values are likely to occur in the future. This approach was taken by Krishnan et al. <ref> [8] </ref> (see x2). Their algorithm keeps information which allows it to approximate the best fixed time-out for the entire sequence, and thus its performance is about that of the best fixed time-out. We use an algorithm that takes this approach a step further. <p> While the worst case bounds proven for the fixed share version of the algorithm are not as good as the version we use, we have not yet fully explored this variant's empirical behavior. 6.2 Related Problems The power management problem can be viewed as a type of rent-to-buy problem <ref> [8] </ref>. A single rent-to-buy decision can be described as follows: we need a resource for an unknown amount of time, and we have the option to rent it for $1 per unit time, or to buy it once and for all for $c. <p> For how long do we rent the resource before buying it? Many interesting problems can be modeled as a sequence of rent-to-buy decisions. This is called the sequential rent-to-buy problem, or just the rent-to-buy problem <ref> [8] </ref>. For example, the disk spin-down scenario can be modeled as a rent-to-buy problem as follows. A round is the time between any two requests for data on the disk. For each round, we need to solve the disk spin-down problem. <p> Other rent-to-buy problems where the algorithm can be applied include applications such as deciding when a thread that is trying to acquire a lock should busy-wait or context switch or computing virtual circuit holding times in IP-over-ATM networks <ref> [8] </ref>. Our implementation of the share algorithm is efficient, taking taking constant space and constant time per trial. This constant is adjustable, and adjusts the accuracy of the algorithm.
Reference: [9] <author> M. Herbster and M. K. Warmuth, </author> <title> "Tracking the best expert", </title> <booktitle> in Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <address> Tahoe City, CA, 1995, </address> <publisher> Morgan Kaufmann, </publisher> <pages> pp. 286-294. </pages>
Reference-contexts: We use a simple algorithm called the share algorithm, a machine learning technique developed by Herb-ster and Warmuth <ref> [9] </ref>, to determine when to spin the disk down. Our implementation of the share algorithm dynamically chooses a time-out value as a function of the (recent) disk activity. Since the algorithm adapts to the recent disk access patterns, it is able to exploit the bursty nature of disk activity. <p> The more misleading the expert the more drastically the expert's weight is slashed. This method causes the predictions of the algorithm to quickly converge to the those of the best expert. Herbster and Warmuth have recently developed the method of a "sharing update" <ref> [9] </ref>. Briefly stated, this update takes some of the weight of each misleading expert and "shares" it among the other experts. Thus an expert whose weight was severely slashed, but is now predicting well, can regain its influence on the algorithm's predictions. <p> Similarly, different values of between 3.5 to 4.5 cause the algorithm's performance to change by at most a factor of 0.0018. We intend to explore methods for self-tuning these parameters in the future. We can now precisely state the algorithm we use: Herbster and Warmuth's <ref> [9] </ref> variable-share algorithm. On each trial the algorithm: 1. Uses a time-out equal to the weighted average of the experts: time-out = P n P n ; 2. Slashes the weights of poorly performing experts w 0 i = w i e Loss (x i ) ; 3. <p> Herbster and Warmuth <ref> [9] </ref> show that if the loss function meets certain properties then this algorithm has very good performance, even in the worst case. Although the loss function we use does not have the properties required for their proof, we show in the next section that its empirical performance is excellent. <p> There is a version of the share update which shares a fixed amount from each expert per trial, instead of an amount proportional to the loss of that expert <ref> [9] </ref>.
Reference: [10] <author> Daniel D. Sleator and Robert E. Tarjan, </author> <title> "Amortized efficiency of list update and paging rules", </title> <journal> Communications of the ACM, </journal> <volume> vol. 28, no. 2, </volume> <pages> pp. 202-228, </pages> <month> Feb. </month> <year> 1985. </year>
Reference-contexts: For larger idle periods, this algorithm never consumes more than twice the energy used by the optimal algorithm. An algorithm is called c-competitive or has a competitive ratio of c if it never uses more then c times the energy used by the optimal algorithm <ref> [10, 11] </ref>. So this natural algorithm is 2-competitive, and we will refer to it as the 2-competitive algorithm.
Reference: [11] <author> A. Karlin, M. Manasse, L. Rudolph, and D. Sleator, </author> <title> "Competitive snoopy caching", </title> <booktitle> in Proceedings of the Twenty-seventh Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <address> Toronto, </address> <month> Oct. </month> <year> 1986, </year> <booktitle> ACM, </booktitle> <pages> pp. 224-254. </pages>
Reference-contexts: For larger idle periods, this algorithm never consumes more than twice the energy used by the optimal algorithm. An algorithm is called c-competitive or has a competitive ratio of c if it never uses more then c times the energy used by the optimal algorithm <ref> [10, 11] </ref>. So this natural algorithm is 2-competitive, and we will refer to it as the 2-competitive algorithm.
Reference: [12] <author> Anna Karlin, Mark S. Manasse, Lyle A. McGeoch, and Susan Owicki, </author> <title> "Competitive randomized algorithms for non-uniform problems", </title> <booktitle> in Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1990, </year> <pages> pp. 301-309. </pages>
Reference-contexts: Randomized algorithms can be viewed as selecting time-out values from some distribution, and can have smaller (expected) competitive ratios. Although we still compute the competitive ratio based on a worst-case idle time between accesses, we average the energy used over the algorithm's random choice of time-out. Karlin et al. <ref> [12] </ref> give an (expected) ( e e1 )-competitive randomized algorithm.
Reference: [13] <author> Fred Douglis, P. Krishnan, and Brian Bershad, </author> <title> "Adaptive disk spin-down policies for mobile computers", </title> <booktitle> in Proceedings of the Second Usenix Sym posium on Mobile and Location-Independent Com--puting, </booktitle> <address> Ann Arbor, MI, </address> <month> Apr. </month> <year> 1995, </year> <institution> Usenix Association. </institution>
Reference-contexts: The share algorithm uses constant time and space, and is simple to implement. In trace-driven simulations, it performs better than all of the algorithms described above, and even conserves more energy than the best fixed time-out. Douglis et al. <ref> [13] </ref> have recently studied some incrementally adaptive disk spin-down policies. The policies they consider maintains a changing time-out value. Whenever the disk access pattern indicates that the current time-out value may be either too long or too short, the current time-out is modified by an additive or multiplicative factor. <p> In particular, although the best fixed time-out is 16.115, the energy used by the 9.34 time-out is within 5% of the energy used by the 16.115 time-out over this 10 minute interval. 5.4 Adaptive Results Douglis et al. <ref> [13] </ref> consider a family of incrementally adaptive spin-down schemes. This family of algorithms has been shown to save significant amounts of energy. These schemes change the time-out after each idle time by either an additive or multiplicative factor. <p> Similarly, we considered three ways of decreasing the time-out: halving it, decreasing it by 1 second, and decreasing it by 0.1 seconds. This gives us nine variations in the incrementally adaptive family. These values were also used in Douglis et al. <ref> [13] </ref> and the long version of Golding et al.[5]. The time-out should never become negative, we constrained the time-out to be at least one decrement amount above zero. We compared each of these nine algorithms with the share algorithm and the daily best time-outs on three different traces.
Reference: [14] <author> N. Cesa-Bianchi, Y. Freund, D. Haussler, D. P. Helmbold, R. E. Schapire, and M. K. Warmuth, </author> <title> "How to use expert advice", </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-94-33, University of California, Santa Cruz, </institution> <year> 1994. </year>
Reference-contexts: This family has a long history and excellent performance for a wide variety of on-line problems <ref> [14, 15, 16, 17, 18, 19, 20] </ref>. Algorithms in this family receive as input a set of "experts," other algorithms which make predictions. On each trial, each expert makes a prediction.
Reference: [15] <author> J. Kivinen and M.K. Warmuth, </author> <title> "Using experts for predicting continuous outcomes", </title> <booktitle> in Computational Learning Theory: Eurocolt '93. </booktitle> <publisher> Oxford University Press, </publisher> <month> Dec. </month> <year> 1993, </year> <title> vol. </title> <booktitle> New Series Number 53 of The Institute of Mathematics and its Applications Conference Series, </booktitle> <pages> pp. 109-120. </pages>
Reference-contexts: This family has a long history and excellent performance for a wide variety of on-line problems <ref> [14, 15, 16, 17, 18, 19, 20] </ref>. Algorithms in this family receive as input a set of "experts," other algorithms which make predictions. On each trial, each expert makes a prediction.
Reference: [16] <author> N. Littlestone and M. K. Warmuth, </author> <title> "The weighted majority algorithm", </title> <journal> Information and Computation, </journal> <volume> vol. 108, no. 2, </volume> <pages> pp. 212-261, </pages> <year> 1994. </year>
Reference-contexts: This family has a long history and excellent performance for a wide variety of on-line problems <ref> [14, 15, 16, 17, 18, 19, 20] </ref>. Algorithms in this family receive as input a set of "experts," other algorithms which make predictions. On each trial, each expert makes a prediction.
Reference: [17] <author> D. Haussler, J. Kivinen, and M. K. Warmuth, </author> <title> "Tight worst-case loss bounds for predicting with expert advice", </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-94-36, University of California, Santa Cruz, </institution> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: This family has a long history and excellent performance for a wide variety of on-line problems <ref> [14, 15, 16, 17, 18, 19, 20] </ref>. Algorithms in this family receive as input a set of "experts," other algorithms which make predictions. On each trial, each expert makes a prediction.
Reference: [18] <author> N. Littlestone, </author> <title> "Learning when irrelevant attributes abound: A new linear-threshold algorithm", </title> <journal> Machine Learning, </journal> <volume> vol. 2, </volume> <pages> pp. 285-318, </pages> <year> 1988. </year>
Reference-contexts: This family has a long history and excellent performance for a wide variety of on-line problems <ref> [14, 15, 16, 17, 18, 19, 20] </ref>. Algorithms in this family receive as input a set of "experts," other algorithms which make predictions. On each trial, each expert makes a prediction.
Reference: [19] <author> N. Littlestone, </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms, </title> <type> Ph.D. dissertation, </type> <institution> University of California Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: This family has a long history and excellent performance for a wide variety of on-line problems <ref> [14, 15, 16, 17, 18, 19, 20] </ref>. Algorithms in this family receive as input a set of "experts," other algorithms which make predictions. On each trial, each expert makes a prediction.
Reference: [20] <author> V. Vovk, </author> <title> "Aggregating strategies", </title> <booktitle> in Proceedings of the Third Annual Workshop on Computational Learning Theory, </booktitle> <address> Rochester, NY, 1990, </address> <publisher> Mor-gan Kaufmann, </publisher> <pages> pp. 371-383. </pages>
Reference-contexts: This family has a long history and excellent performance for a wide variety of on-line problems <ref> [14, 15, 16, 17, 18, 19, 20] </ref>. Algorithms in this family receive as input a set of "experts," other algorithms which make predictions. On each trial, each expert makes a prediction.
Reference: [21] <author> Avrim Blum, </author> <title> "Empirical support for Winnow and weighted-majority based algorithms: results on a calendar scheduling domain", </title> <booktitle> in Proceedings of the Twelfth International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1995, </year> <pages> pp. 64-72. </pages>
Reference-contexts: Although these parameters must be chosen carefully to prove good worst-case bounds on the learning algorithm, the real-world performance of multiplicative weight algorithms appears less sensitive to the choice of parameters (for another example see Blum <ref> [21] </ref> on predicting calendar events). <p> As mentioned in x3, the performance varies by less than one-fifth of one percent as the share rate varies from 0.5 to 1 or the learning rate varies from 3.5 to 4.5. This observation is in agreement with other empirical work on multiplicative weight algorithms <ref> [21] </ref>. The number of experts and distribution of the experts appears to have more impact on the algorithm's performance. Before presenting our main results, we discuss the differences between various fixed time-outs on a typical day's trace data.
Reference: [22] <author> Chris Ruemmler and John Wilkes, </author> <title> "Unix disk access patterns", </title> <booktitle> in Proceedings of the Usenix Technical Conference, </booktitle> <address> San Diego, CA, </address> <booktitle> Winter 1993, Usenix Association, </booktitle> <pages> pp. 405-420. </pages>
Reference-contexts: simulation results to compare the energy used by our implementation with the energy used by various other proposed algorithms, as well as the (impractical) best fixed time-out and optimal algorithms. 5.1 Methodology We used traces of HP C2474s disks collected from April 18, 1992 through June 19, 1992 (63 days) <ref> [22] </ref>. We compare the share algorithm with several algorithms, including the 2-competitive algorithm, the randomized ( e e1 )-competitive algorithm, (an approximation to) the best fixed time-out, and the optimal algorithm. These other algorithms are described in x2.
Reference: [23] <author> Mary G. Baker, John H. Hartman, Michael D. Kupfer, Ken W. Shirriff, and John K. Ousterhout, </author> <title> "Measurements of a distributed file system", </title> <booktitle> in Proceedings of the Thirteenth Symposium on Operating Systems Principles, Asilomar, </booktitle> <address> Pacific Grove, CA, </address> <month> Oct. </month> <year> 1991, </year> <booktitle> ACM, </booktitle> <pages> pp. 198-212. </pages>
Reference-contexts: Since the share algorithm outperforms the best fixed time-out, it is exploiting time dependencies in the input values. Of course, it is not surprising that there are time dependencies as it is well-known that user access patterns exhibit bursty behavior <ref> [23] </ref>. from 360 to 370 minutes of Figure 5. 5.3 Predictions of the Share Algorithm a portion of a typical day (Monday, April 20), using a spin-down cost of 10.
References-found: 23

