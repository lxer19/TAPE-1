URL: ftp://cse.ogi.edu/pub/dsrg/synthetix/ogi-cse-93-007.ps.gz
Refering-URL: http://www.cse.ogi.edu/~walpole/publications.html
Root-URL: http://www.cse.ogi.edu
Email: fcalton,walpoleg@cse.ogi.edu  
Title: A Study of Dynamic Optimization Techniques: Lessons and Directions in Kernel Design  
Author: Calton Pu and Jonathan Walpole 
Address: P.O. Box 91000 Portland, OR 97291-1000  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Pubnum: Technical Report No. OGI-CSE-93-007  
Abstract: The Synthesis kernel [21, 22, 23, 27, 28] showed that dynamic code generation, software feedback, and fine-grain modular kernel organization are useful implementation techniques for improving the performance of operating system kernels. In addition, and perhaps more importantly, we discovered that there are strong interactions between the techniques. Hence, a careful and systematic combination of the techniques can be very powerful even though each one by itself may have serious limitations. By identifying these interactions we illustrate the problems of applying each technique in isolation to existing kernels. We also highlight the important common under-pinnings of the Synthesis experience and present our ideas on future operating system design and implementation. Finally, we outline a more uniform approach to dynamic optimizations called incremental partial evaluation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young. </author> <title> Mach: A new kernel foundation for Unix development. </title> <booktitle> In Proceedings of the 1986 Usenix Conference, </booktitle> <pages> pages 93-112. </pages> <publisher> Usenix Association, </publisher> <year> 1986. </year>
Reference-contexts: Coarse-grain modularity has been studied in the context of microkernel-based operating systems such as Mach <ref> [1] </ref>, Chorus [33] and V [9]. Mach, for example, offers an encapsulated kernel, in which kernel resources and services are hidden behind a port/message-based interface [5].
Reference: [2] <author> P. Amaral, R. Lea, and C. Jacquemot. </author> <title> A model for persistent shared memory addressing in distributed systems. </title> <booktitle> In Proceedings of the Second International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 2-12, </pages> <address> Dourdan, France, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: Moving from the center to the right of Figure 3 represents the introduction of fine-grain modularity within the kernel code at the level of objects or abstract data types. The most well known systems in this category are Choices [14] and Chorus <ref> [2] </ref>, which use object oriented programming languages and techniques. Other systems in this category are discussed in [7, 6]. Even in the presence of fine-grain modularity, considerable work must be done to incorporate dynamic optimization techniques into a kernel.
Reference: [3] <author> Anonymous et al. </author> <title> SUNOS release 3.5 source code. SUN Microsystems Source License, </title> <year> 1988. </year>
Reference-contexts: The more regular an input stream is, the less information the feedback mechanism needs to remember. Software implementations of feedback mechanisms are used in Synthesis to solve two problems: fine-grain scheduling [22] and scheduling for real-time I/O processing. A serious problem in the SUNOS adaptive scheduling algorithm <ref> [3] </ref> is the assumption that 6 all processes are independent of each other. In a pipeline of processes, this assumption is false and the resulting schedule may not be good. Fine-grain scheduling was introduced in Synthesis to solve this problem.
Reference: [4] <author> A. Black, N. Hutchinson, E. Jul, H. Levy, and L. Carter. </author> <title> Distribution and abstract types in Emerald. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(12):65-76, </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: A natural interface to specialized code in incremental partial evaluation would distinguish between abstract types and concrete types (as in Emerald <ref> [4] </ref>). Multiple implementations can be seen as the concrete types supporting the same abstract type. The invariants distinguish the concrete types and describe their relationship to each other in the implementation hierarchy. From this point of view, the hierarchy of multiple implementations is the symmetric reverse of inheritance.
Reference: [5] <author> D.L. Black, D.B. Golub, D.P. Julin, R.F. Rashid, R.P. Draves, R.W. Dean, A. Forin, J. Barrera, H. Tokuda, G. Malan, and D. Bohman. </author> <title> Microkernel operating system architecture and mach. </title> <booktitle> In Proceedings of the Workshop on Micro-Kernels and Other Kernel Architectures, </booktitle> <pages> pages 11-30, </pages> <address> Seattle, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: The significance of this evolution is that it becomes progressively easier to apply Synthesis-style dynamic optimization techniques. Moving from the left to the center of Figure 3 represents the introduction of encapsulated kernel and server interfaces in systems such as Mach <ref> [5] </ref>, for example. This is the first requirement for applying dynamic optimization techniques. Moving from the center to the right of Figure 3 represents the introduction of fine-grain modularity within the kernel code at the level of objects or abstract data types. <p> Coarse-grain modularity has been studied in the context of microkernel-based operating systems such as Mach [1], Chorus [33] and V [9]. Mach, for example, offers an encapsulated kernel, in which kernel resources and services are hidden behind a port/message-based interface <ref> [5] </ref>. The facilities that allow dynamic linking and loading of servers into the address space of a running Chorus kernel are also related to our research in that they allow a choice between different implementations of the kernel interface to made dynamically [16].
Reference: [6] <author> L-F. Cabrera and E. </author> <month> Jul, </month> <editor> editors. </editor> <booktitle> Proceedings of the Second International Workshop on Object Orientation in Operating Systems, </booktitle> <address> Dourdan, France, September 1992. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: The most well known systems in this category are Choices [14] and Chorus [2], which use object oriented programming languages and techniques. Other systems in this category are discussed in <ref> [7, 6] </ref>. Even in the presence of fine-grain modularity, considerable work must be done to incorporate dynamic optimization techniques into a kernel. Selected modules must be rewritten using incremental partial evaluation and/or software feedback before being reintroduced in the original system.
Reference: [7] <author> L-F. Cabrera, V. Russo, and M. Shapiro, </author> <title> editors. </title> <booktitle> Proceedings of the International Workshop on Object Orientation in Operating Systems, </booktitle> <address> Palo Alto, California, October 1991. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: The most well known systems in this category are Choices [14] and Chorus [2], which use object oriented programming languages and techniques. Other systems in this category are discussed in <ref> [7, 6] </ref>. Even in the presence of fine-grain modularity, considerable work must be done to incorporate dynamic optimization techniques into a kernel. Selected modules must be rewritten using incremental partial evaluation and/or software feedback before being reintroduced in the original system.
Reference: [8] <author> R.H. Campbell, N. Islam, and P. Madany. </author> <title> Choices, frameworks, and refinement. </title> <journal> Computing Systems, </journal> <volume> 5(3), </volume> <month> Summer </month> <year> 1992. </year>
Reference-contexts: The use of object-oriented programming languages and design approaches has allowed operating systems such as Choices <ref> [8] </ref>, Chorus [30], and Apertos [31] to utilize finer-grain modularity within their kernel code. The x-kernel [25] also offers relatively fine-grain modularity through its concept of micro-protocols.
Reference: [9] <author> D. Cheriton. </author> <title> The V distributed system. </title> <journal> Communications of ACM, </journal> <volume> 31(3) </volume> <pages> 314-333, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: Coarse-grain modularity has been studied in the context of microkernel-based operating systems such as Mach [1], Chorus [33] and V <ref> [9] </ref>. Mach, for example, offers an encapsulated kernel, in which kernel resources and services are hidden behind a port/message-based interface [5].
Reference: [10] <author> C. Consel. </author> <title> Binding time analysis for higher order untyped functional languages. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 264-272, </pages> <year> 1990. </year>
Reference-contexts: As we start to emphasize a formal approach to dynamic optimization, existing partial evaluation work becomes more relevant. Dynamic optimization can benefit from off-line algorithms such as binding-time analysis <ref> [10] </ref> in practical systems [11]. Another related area of research on dynamic optimization is on reflection and meta-object protocols [32]. While most of the programming languages supporting meta-object protocols are interpreted, there are significant efforts focused on building an open compiler with customizable components [18].
Reference: [11] <author> C. Consel. </author> <note> Report on Schism'92. Research report, </note> <institution> Pacific Software Research Center, Oregon Graduate Institute of Science and Technology, Beaverton, Oregon, USA, </institution> <year> 1992. </year> <month> 14 </month>
Reference-contexts: As we start to emphasize a formal approach to dynamic optimization, existing partial evaluation work becomes more relevant. Dynamic optimization can benefit from off-line algorithms such as binding-time analysis [10] in practical systems <ref> [11] </ref>. Another related area of research on dynamic optimization is on reflection and meta-object protocols [32]. While most of the programming languages supporting meta-object protocols are interpreted, there are significant efforts focused on building an open compiler with customizable components [18].
Reference: [12] <author> C. Consel and O. Danvy. </author> <title> Tutorial notes on partial evaluation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <year> 1993. </year>
Reference-contexts: At the Oregon Graduate Institute, in collaboration with Charles Con-sel, we are developing a uniform programming methodology for next-generation operating system kernels, based on theoretical foundations in partial evaluation <ref> [12] </ref>. The approach, called incremental partial evaluation [13], applies partial evaluation repeatedly, whenever information useful for optimization becomes available in the system. Dynamic code generation in Synthesis can be seen as a concrete illustration of this general approach. Section 5.2 presents an overview of incremental partial evaluation.
Reference: [13] <author> C. Consel, C. Pu, and J. Walpole. </author> <title> Incremental partial evaluation: The key to high performance, modularity and portability in operating systems. </title> <booktitle> In ACM Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Copenhagen, </address> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: At the Oregon Graduate Institute, in collaboration with Charles Con-sel, we are developing a uniform programming methodology for next-generation operating system kernels, based on theoretical foundations in partial evaluation [12]. The approach, called incremental partial evaluation <ref> [13] </ref>, applies partial evaluation repeatedly, whenever information useful for optimization becomes available in the system. Dynamic code generation in Synthesis can be seen as a concrete illustration of this general approach. Section 5.2 presents an overview of incremental partial evaluation.
Reference: [14] <author> A. Dave, M. Sefika, and R.H. Campbell. </author> <title> Proxies, application interfaces, </title> <booktitle> and distributed systems. In Proceedings of the Second International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 212-220, </pages> <address> Dourdan, France, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: This is the first requirement for applying dynamic optimization techniques. Moving from the center to the right of Figure 3 represents the introduction of fine-grain modularity within the kernel code at the level of objects or abstract data types. The most well known systems in this category are Choices <ref> [14] </ref> and Chorus [2], which use object oriented programming languages and techniques. Other systems in this category are discussed in [7, 6]. Even in the presence of fine-grain modularity, considerable work must be done to incorporate dynamic optimization techniques into a kernel.
Reference: [15] <author> L. Georgiadis and C. Nikolaou. </author> <title> Adaptive scheduling algorithms that satisfy average response time objectives. </title> <type> Technical Report TR-RC-14851, </type> <institution> IBM Research, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: Their application to system software has been focused in two areas: network protocols and resource management. In network protocols, feedback has been applied in the design of protocols for congestion avoidance [29]. In resource management, feedback has been used in goal-oriented CPU scheduling <ref> [15] </ref>. The principal distinction between Synthesis and these other research efforts is that Synthesis has applied these techniques extensively, and in careful combination, in the design of an operating system kernel. As we start to emphasize a formal approach to dynamic optimization, existing partial evaluation work becomes more relevant.
Reference: [16] <author> M. Guillemont, J. Lipkis, D. Orr, and M. Rozier. </author> <title> A second-generation micro-kernel based unix: Lessons in performance and compatibility. </title> <booktitle> In Proceedings of the Winter Technical USENIX Conference '91, </booktitle> <address> Dallas, </address> <year> 1991. </year>
Reference-contexts: Finally, the necessary process of emulating existing monolithic operating systems above micro-kernel-based operating systems makes the problem even worse. Current approaches to implementing emulation, such as redirecting system calls to user-level emulation libraries before invoking operating system function, introduce additional latency for kernel calls <ref> [16] </ref>. This in turn leads to unwanted increases in end-to-end latency for interactive real-time applications. Again, there are many important and well-accepted reasons for supporting emulation, e.g., utility and application software compatibility. What is needed are new implementation techniques to support it more efficiently. <p> The facilities that allow dynamic linking and loading of servers into the address space of a running Chorus kernel are also related to our research in that they allow a choice between different implementations of the kernel interface to made dynamically <ref> [16] </ref>. The use of object-oriented programming languages and design approaches has allowed operating systems such as Choices [8], Chorus [30], and Apertos [31] to utilize finer-grain modularity within their kernel code. The x-kernel [25] also offers relatively fine-grain modularity through its concept of micro-protocols.
Reference: [17] <author> M. Herlihy and E.B. Moss. </author> <title> Transactional memory: Architectural support for lock-free data structures. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1993. </year> <note> Full paper as DEC/CRL TR number CRL-92/07. </note>
Reference-contexts: In Synthesis, lock-free synchronization [20] was adopted and implemented with the compare-and-swap instruction. Since the compare-and-swap instruction is not available on all processor architectures, the portability of the synchronization mechanism is a serious question. We plan to adopt an abstract lock-free synchronization mechanism, such as transactional memory <ref> [17] </ref>, and then use incremental partial evaluation to select an appropriate implementation of it using the facilities available on the target hardware platform. We are in the process of defining high-level programming language support for incremental partial evaluation.
Reference: [18] <author> J. Lamping, G. Kiczales, L. Rodriguez, and E. Ruf. </author> <title> An architecture for an open compiler. </title> <booktitle> In Proceedings of the International Workshop on New Models for Software Architecture '92, </booktitle> <pages> pages 95-106, </pages> <address> Tokyo, Japan, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Another related area of research on dynamic optimization is on reflection and meta-object protocols [32]. While most of the programming languages supporting meta-object protocols are interpreted, there are significant efforts focused on building an open compiler with customizable components <ref> [18] </ref>. An experiment to add reflection to C ++ [19] resulted in a recommendation to not modify C ++ to support reflection.
Reference: [19] <author> P. Madany, P. Kougiouris, N. Islam, and R.H. Campbell. </author> <booktitle> Practical examples of reificationand reflection in c ++ . In Proceedings of the International Workshop on New Models for Software Architecture '92, </booktitle> <pages> pages 76-81, </pages> <address> Tokyo, Japan, </address> <month> November </month> <year> 1992. </year> <title> RISE, IPA, </title> <booktitle> ACM SIGPLAN. </booktitle>
Reference-contexts: Another related area of research on dynamic optimization is on reflection and meta-object protocols [32]. While most of the programming languages supporting meta-object protocols are interpreted, there are significant efforts focused on building an open compiler with customizable components [18]. An experiment to add reflection to C ++ <ref> [19] </ref> resulted in a recommendation to not modify C ++ to support reflection.
Reference: [20] <author> H. Massalin. </author> <title> Efficient Implementation of Fundamental Operating System Services. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: This technique is especially useful when the work done on each data element is also small compared to the traversal cost. The Synthesis run queue, composed of thread table elements, is an example of an executable data structure <ref> [20] </ref>. At thread creation time, each element is optimized to reduce context switch cost. <p> Each program repeatedly executes the specified system calls (the left column). The validation program contains only user level memory location references. time (almost 4 times). A more recent experiment <ref> [20] </ref> illustrates the relative I/O latency for Synthesis and two widely used commercial operating systems. <p> It also explains the difficulty in applying dynamic code generation extensively to microkernels modularized solely at server and kernel boundaries. The internal dependencies in such coarse-grain modules limit the potential benefits of applying dynamic code generation. Lessons one and two led to the "objectification" of the Synthesis kernel <ref> [27, 20] </ref>. In the current version of Synthesis, the kernel is composed of small encapsulated modules called quajects. For example, queues, buffers, threads and windows are considered basic quajects since they support some kernel calls by themselves. Composite quajects provide high level kernel services such as a file system. <p> Although the Synthesis implementation is minimally sufficient for the degree of fine-grain modularity required for dynamic code generation, Section 5.2 discusses the kind of language support needed for a fine-grain modularization of kernels. 3.4 Important Questions The Synthesis kernel has shown that dynamic code generation can produce significant performance improvements <ref> [21, 23, 20] </ref>. In this sense, the Synthesis project was useful as a proof of concept for the application of dynamic code generation in operating systems. However, the focus on dynamic code generation required hand-coded optimizations written in macro-assembler. <p> Another important application of software feedback is to guarantee the I/O rate in a pipeline of threads that process high-rate real-time data streams, as in next-generation operating systems supporting multimedia (section 2). A Synthesis program <ref> [20] </ref> that plays a compact disc simply reads from /dev/cd and writes to /dev/speaker. Specialized schedulers monitor the data flow through both queues. A high input rate from CD will drive up the CPU slice of the player thread and allow it to move data to its output buffer. <p> A third goal in the incremental partial evaluation approach is to make synchronization primitives efficient and portable. Since we are building an operating system kernel for parallel and distributed systems, efficient synchronization is fundamental. In Synthesis, lock-free synchronization <ref> [20] </ref> was adopted and implemented with the compare-and-swap instruction. Since the compare-and-swap instruction is not available on all processor architectures, the portability of the synchronization mechanism is a serious question.
Reference: [21] <author> H. Massalin and C. Pu. </author> <title> Threads and input/output in the Synthesis kernel. </title> <booktitle> In Proceedings of the Twelfth Symposium on Operating Systems Principles, </booktitle> <pages> pages 191-201, </pages> <address> Arizona, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: An example of collapsing layers is the networking protocol stack [24]. A virtual circuit can allocate message buffer space at the top level and share it with the lower levels without additional copying. The Unix emulator in Synthesis also uses collapsing layers to reduce kernel call emulation cost <ref> [21] </ref>. Executable data structures are data structures (usually with fixed traversal order) optimized with embedded code to reduce interpretation overhead. Although this technique only saves a few instructions at a time, the savings are significant when the total number of instructions executed during each traversal step is small. <p> Although the measured numbers on the Quamachine represent the compounded effects of custom software (the Synthesis kernel) and hardware, an effort was made to compare Synthesis performance fairly with that of an existing operating system kernel. We summarize here a comparison reported earlier <ref> [21] </ref>. The Quamachine was fitted with a Motorola 68020 CPU running at 16 MHz and memory speed comparable to a SUN-3/160, which has a 68020 processor at 16.67 MHz. <p> Note, however that Synthesis also improves on SUNOS performance when reading and writing a pipe 4 kilobytes at a 1 Figure extracted from Table 1 of <ref> [21] </ref>. 3 Test Program SUN Synthesis Speed Synthesis Loops Description runtime Emulator Ratio throughput in prog ------------ --- ------ ---- --------- ------ Validation 20.3 21.42 0.95 500000 R/W pipe 1 Byte 10.0 0.18 56. 100KB/sec 10000 R/W pipe 4 KB 37.9 9.64 3.9 8MB/sec 10000 R/W RAM file 20.6 2.91 7.1 <p> Although the Synthesis implementation is minimally sufficient for the degree of fine-grain modularity required for dynamic code generation, Section 5.2 discusses the kind of language support needed for a fine-grain modularization of kernels. 3.4 Important Questions The Synthesis kernel has shown that dynamic code generation can produce significant performance improvements <ref> [21, 23, 20] </ref>. In this sense, the Synthesis project was useful as a proof of concept for the application of dynamic code generation in operating systems. However, the focus on dynamic code generation required hand-coded optimizations written in macro-assembler.
Reference: [22] <author> H. Massalin and C. Pu. </author> <title> Fine-grain adaptive scheduling using feedback. </title> <journal> Computing Systems, </journal> <volume> 3(1) </volume> <pages> 139-173, </pages> <month> Winter </month> <year> 1990. </year> <booktitle> Special Issue on selected papers from the Workshop on Experiences in Building Distributed Systems, </booktitle> <address> Florida, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: Each of these techniques has been described in detail in our earlier papers <ref> [22, 23, 28] </ref>. <p> The more regular an input stream is, the less information the feedback mechanism needs to remember. Software implementations of feedback mechanisms are used in Synthesis to solve two problems: fine-grain scheduling <ref> [22] </ref> and scheduling for real-time I/O processing. A serious problem in the SUNOS adaptive scheduling algorithm [3] is the assumption that 6 all processes are independent of each other. In a pipeline of processes, this assumption is false and the resulting schedule may not be good.
Reference: [23] <author> H. Massalin and C. Pu. </author> <title> Reimplementing the Synthesis kernel. </title> <booktitle> In Proceedings of Workshop on Micro-kernels and Other Kernel Architecturs, </booktitle> <address> Seattle, </address> <month> April </month> <year> 1992. </year> <institution> Usenix Association. </institution>
Reference-contexts: Each of these techniques has been described in detail in our earlier papers <ref> [22, 23, 28] </ref>. <p> Although the Synthesis implementation is minimally sufficient for the degree of fine-grain modularity required for dynamic code generation, Section 5.2 discusses the kind of language support needed for a fine-grain modularization of kernels. 3.4 Important Questions The Synthesis kernel has shown that dynamic code generation can produce significant performance improvements <ref> [21, 23, 20] </ref>. In this sense, the Synthesis project was useful as a proof of concept for the application of dynamic code generation in operating systems. However, the focus on dynamic code generation required hand-coded optimizations written in macro-assembler.
Reference: [24] <author> Thomas Matthews. </author> <title> Implementation of tcp/ip for the Synthesis kernel. </title> <type> Master's thesis, </type> <institution> Columbia University, Department of Computer Science, </institution> <address> New York City, </address> <year> 1991. </year>
Reference-contexts: When a high-level function calls a lower level procedure, the code is expanded in-line. This inlining eliminates unnecessary barriers (the source of most data copying), allowing controlled and efficient data sharing by all the layers. An example of collapsing layers is the networking protocol stack <ref> [24] </ref>. A virtual circuit can allocate message buffer space at the top level and share it with the lower levels without additional copying. The Unix emulator in Synthesis also uses collapsing layers to reduce kernel call emulation cost [21]. <p> Although the Synthesis kernel was not production quality software, several talented project students were able to understand it, modify it, and extend it using the kernel monitor <ref> [24] </ref>. Nevertheless, from a software engineering point of view, the problem of debugging executable code for which no source code exists remains a challenge. 4 Software Feedback 4.1 The Technique, Uses, and Benefits Feedback mechanisms are well known in control systems.
Reference: [25] <author> S. O'Malley and L. Peterson. </author> <title> A dynamic network architecture. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(2) </volume> <pages> 110-143, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: The use of object-oriented programming languages and design approaches has allowed operating systems such as Choices [8], Chorus [30], and Apertos [31] to utilize finer-grain modularity within their kernel code. The x-kernel <ref> [25] </ref> also offers relatively fine-grain modularity through its concept of micro-protocols.
Reference: [26] <author> R. Pike, B. Locanthi, and J. Reiser. </author> <title> Hardware/software trade-offs for bitmap graphics on the blit. </title> <journal> Software|Practice and Experience, </journal> <volume> 15(2) </volume> <pages> 131-151, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Dynamic code generation has been used in a number of other research efforts. The Blit terminal from Bell Labs, for example, used dynamically optimized bitblt operations to improve display update speed <ref> [26] </ref>. Feedback systems have been discussed extensively in the context of control theory. Their application to system software has been focused in two areas: network protocols and resource management. In network protocols, feedback has been applied in the design of protocols for congestion avoidance [29].
Reference: [27] <author> C. Pu and H. Massalin. </author> <title> Quaject composition in the Synthesis kernel. </title> <booktitle> In Proceedings of International Workshop on Object Orientation in Operating Systems, </booktitle> <address> Palo Alto, </address> <month> October </month> <year> 1991. </year> <journal> IEEE/Computer Society. </journal>
Reference-contexts: It also explains the difficulty in applying dynamic code generation extensively to microkernels modularized solely at server and kernel boundaries. The internal dependencies in such coarse-grain modules limit the potential benefits of applying dynamic code generation. Lessons one and two led to the "objectification" of the Synthesis kernel <ref> [27, 20] </ref>. In the current version of Synthesis, the kernel is composed of small encapsulated modules called quajects. For example, queues, buffers, threads and windows are considered basic quajects since they support some kernel calls by themselves. Composite quajects provide high level kernel services such as a file system.
Reference: [28] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: Each of these techniques has been described in detail in our earlier papers <ref> [22, 23, 28] </ref>. <p> A good example of factoring invariants is the file system open call, which returns a critical path of a few dozen machine instructions that are used later by the calling thread to read/write that specific file <ref> [28] </ref>. In this case, the invariants are the thread requesting access, the file descriptor, and the file usage parameters. Collapsing layers addresses the performance problem introduced by the increasingly popular abstract layered interfaces for systems software.
Reference: [29] <author> K. K. Ramakrishnan and Raj Jain. </author> <title> A binary feedback scheme for congestion avoidance in computer networks. </title> <journal> ACM Transaction on Computer Systems, </journal> <volume> 8(2), </volume> <month> May </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: Feedback systems have been discussed extensively in the context of control theory. Their application to system software has been focused in two areas: network protocols and resource management. In network protocols, feedback has been applied in the design of protocols for congestion avoidance <ref> [29] </ref>. In resource management, feedback has been used in goal-oriented CPU scheduling [15]. The principal distinction between Synthesis and these other research efforts is that Synthesis has applied these techniques extensively, and in careful combination, in the design of an operating system kernel.
Reference: [30] <author> M. Rozier, V. Abrossimov, F. Armand, I. Boule, M. Gien, M. Guillemont, F. Herrman, C. Kaiser, S. Langlois, P. Leonard, and W. Neuhauser. </author> <title> Overview of the chorus distributed operating system. </title> <booktitle> In Proceedings of the Workshop on Micro-Kernels and Other Kernel Architectures, </booktitle> <pages> pages 39-69, </pages> <address> Seattle, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: The use of object-oriented programming languages and design approaches has allowed operating systems such as Choices [8], Chorus <ref> [30] </ref>, and Apertos [31] to utilize finer-grain modularity within their kernel code. The x-kernel [25] also offers relatively fine-grain modularity through its concept of micro-protocols.
Reference: [31] <author> Y. Yokote, F. Teraoka, and M. Tokoro. </author> <title> A reflective architecture for an object-oriented distributed operating system. </title> <booktitle> In Proceedings of the 189 European Conference on Object-Oriented Programming, </booktitle> <pages> pages 89-108, </pages> <address> Nottingham, UK, July 1989. </address> <publisher> Cambridge Unversity Press. </publisher>
Reference-contexts: The use of object-oriented programming languages and design approaches has allowed operating systems such as Choices [8], Chorus [30], and Apertos <ref> [31] </ref> to utilize finer-grain modularity within their kernel code. The x-kernel [25] also offers relatively fine-grain modularity through its concept of micro-protocols.
Reference: [32] <editor> A. Yonezawa and B.C. Smith, editors. </editor> <booktitle> Proceedings of the International Workshop on New Models for Software Architecture '92, </booktitle> <address> Tokyo, Japan, </address> <month> November </month> <year> 1992. </year> <title> RISE, IPA, </title> <booktitle> ACM SIGPLAN. </booktitle>
Reference-contexts: As we start to emphasize a formal approach to dynamic optimization, existing partial evaluation work becomes more relevant. Dynamic optimization can benefit from off-line algorithms such as binding-time analysis [10] in practical systems [11]. Another related area of research on dynamic optimization is on reflection and meta-object protocols <ref> [32] </ref>. While most of the programming languages supporting meta-object protocols are interpreted, there are significant efforts focused on building an open compiler with customizable components [18]. An experiment to add reflection to C ++ [19] resulted in a recommendation to not modify C ++ to support reflection.
Reference: [33] <author> H. Zimmermann, J-S. Banino, A. Caristan, M. Guillemont, and G. Morisset. </author> <title> Basic concepts for the support of distributed systems: the Chorus approach. </title> <booktitle> In Proceedings of 2nd International Conference on Distributed Computing Systems, </booktitle> <month> July </month> <year> 1981. </year> <month> 16 </month>
Reference-contexts: Coarse-grain modularity has been studied in the context of microkernel-based operating systems such as Mach [1], Chorus <ref> [33] </ref> and V [9]. Mach, for example, offers an encapsulated kernel, in which kernel resources and services are hidden behind a port/message-based interface [5].
References-found: 33

