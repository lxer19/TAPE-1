URL: ftp://mesquite.cs.panam.edu/pub/FOX/AI/debug-tr.ps
Refering-URL: http://www.cs.panam.edu/~fox/pubs.html
Root-URL: http://www.cs.panam.edu
Email: Email: fox@cs.panam.edu  
Phone: (210) 381-3635  
Title: Automated Debugging of Syntax Errors  
Author: Richard Fox, Christian Bilke, James Mendoza 
Date: August 2, 1995  
Address: Pan American  TX 78539, USA  
Affiliation: Department of Computer Science The University of Texas  Edinburg,  
Pubnum: Technical Report  
Abstract: Program debugging is a form of diagnosis that might be referred to as "routine." As such, debugging has similar properties as diagnosis and yet can be solved in a more straight-forward manner than many diagnostic problems. Automating the debugging problem is of interest for several reasons. Debugging is a time-consuming process that tends to haunt many programmers from novices to experts. Yet the debugging problem is of a scope that is implementable unlike many other diagnostic problems which have shown to require massive and unmanageable amounts of knowledge. In this paper, automated debugging of syntax errors in Turbo Pascal programs is considered. The debugging process is compared to diagnosis. Inference types are discussed along with the knowledge of Pascal that is required to perform these inferences. Finally, two prototype automated debugging systems are introduced and demonstrated by an example. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Bylander and S. Mittal. CSRL: </author> <title> a language for classificatory problem solving and uncertainty handling. </title> <journal> AI Magazine, </journal> <volume> 7(3) </volume> <pages> 66-77, </pages> <month> August </month> <year> 1986. </year> <month> 8 </month>
Reference-contexts: The classification hierarchy is traversed using a strategy called "establish-refine" <ref> [1] </ref> in which a node in the hierarchy is considered for plausibility (that is, the hypothesis that the node represents is considered for plausibility.) If found plausible, then the node is established. In order to refine a hypothesis into more detail, the established node's children are examined.
Reference: [2] <author> Tom Bylander, Todd Johnson, and Ashok Goel. </author> <title> Structured matching: A task-specific technique for making decisions. </title> <journal> Knowledge Acquisition, </journal> <volume> 3(1) </volume> <pages> 1-20, </pages> <year> 1991. </year>
Reference-contexts: Each test is represented in the system as a recognition agent. A recognition agent has knowledge (in the form of pattern matching) of how to determine the likelihood of the hypothesis that it represents <ref> [2] </ref>. For instance, the node "Missing Else" represents the hypothesis that the current instruction is an If-Then-Else statement which is missing the word "Else". A recognition agent for "Missing Else" is called on to determine how likely this hypothesis is.
Reference: [3] <author> H. L. Capron and J. D. </author> <title> Perron. Computers and Information Systems: Tools for an Information Age. </title> <publisher> Benjamin/Cummings Publishing Company, </publisher> <address> 3rd edition edition, </address> <year> 1993. </year>
Reference-contexts: Automating the process of debugging is worthwhile for several reasons. First, an automated debugger would save programmers much effort. It is not untypical for programmers to spend as much as 50% of their time debugging and so an automated debugger would make the programming task much more efficient <ref> [3] </ref>. Second, while debugging is routine it is still an interesting problem. One might find several forms of routine diagnosis which could be solved using similar ideas as shown in an automated debugger. Third, a deeper understanding in the syntactic debugging process might aid educators who teach programming.
Reference: [4] <author> B. Chandrasekaran. </author> <title> Generic tasks in knowledge-based reasoning: High-level building blocks for expert system design. </title> <journal> IEEE Expert, </journal> <pages> pages 23-30, </pages> <year> 1986. </year> <month> Fall </month> <year> 1986. </year>
Reference-contexts: In this prototype debugging system, a Generic Task approach is taken <ref> [4] </ref>. The knowledge is arranged based on three tasks, hierarchical classification, routine recognition and data inferencing. The error causes (hypotheses) are arranged in a classification hierarchy [5, 6] where each possible error is a node in the hierarchy. The root node, "syntax error", indicates that an error arose.
Reference: [5] <author> B. Chandrasekaran. </author> <title> Towards a functional architecture for intelligence based on generic information processing tasks. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1987. </year>
Reference-contexts: In this prototype debugging system, a Generic Task approach is taken [4]. The knowledge is arranged based on three tasks, hierarchical classification, routine recognition and data inferencing. The error causes (hypotheses) are arranged in a classification hierarchy <ref> [5, 6] </ref> where each possible error is a node in the hierarchy. The root node, "syntax error", indicates that an error arose.
Reference: [6] <author> B. Chandrasekaran. </author> <title> Generic tasks as building blocks for knowledge-based systems: The diagnosis and routine design examples. </title> <type> Technical report, </type> <institution> The Ohio State University, </institution> <year> 1988. </year>
Reference-contexts: In this prototype debugging system, a Generic Task approach is taken [4]. The knowledge is arranged based on three tasks, hierarchical classification, routine recognition and data inferencing. The error causes (hypotheses) are arranged in a classification hierarchy <ref> [5, 6] </ref> where each possible error is a node in the hierarchy. The root node, "syntax error", indicates that an error arose.
Reference: [7] <author> B. Chandrasekaran and S. Mittal. </author> <title> Conceptual representation of medical knowledge for diagnosis by computer: Mdx and related systems. </title> <editor> In M. Yovits, editor, </editor> <booktitle> Advances in Computers, </booktitle> <volume> volume 22, </volume> <pages> pages 217-293. </pages> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: This makes debugging a much simpler search problem than other forms of diagnosis. The inference rules used in debugging do not include typical forms of diagnostic inferences such as data abstraction or inheritance <ref> [7, 14] </ref>. Instead, debugging requires inferences which are based on pattern matching where the patterns are well-known. These inferences usually involve identifying misspellings of reserved words and identifiers, determining if clauses were omitted, or if improper punctuation was used.
Reference: [8] <author> W. Lewis Johnson. </author> <title> Intention-based Diagnosis of Novice Programming Errors. </title> <booktitle> Release Notes in Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: To solve this problem, the programmer uses the syntax error as a clue, searches through the program looking for the code that caused the error, and attempts a correction. As described, debugging is a form of diagnosis (or more generally credit assignment) <ref> [8, 11, 12] </ref>. This form of diagnosis is more "routine" than other forms of diagnosis because of the limited amounts of knowledge required and the uniform types of inferences that are used in debugging.
Reference: [9] <author> J. Josephson, D. Smetters, R. Fox, D. Oblinger, A. Welch, and G. Northrup. </author> <title> The integrated generic task toolset: Fafner release 1.0. </title> <type> Technical report, </type> <institution> The Ohio State University, </institution> <year> 1989. </year>
Reference-contexts: Presently, steps one and two have been accomplished and step three is being undertaken (developing tests for the various causes of a syntax error.) This second prototype is being written using the Integrated Generic Task Toolset (which contains tools for hierarchical classification, routine recognition, data inference and abductive assembly <ref> [9, 10] </ref>) in Common Lisp. In this prototype debugging system, a Generic Task approach is taken [4]. The knowledge is arranged based on three tasks, hierarchical classification, routine recognition and data inferencing.
Reference: [10] <author> John Josephson and Richard Fox. Peirce-IGTT: </author> <title> a domain-independent problem solver for abductive assembly. </title> <type> Technical report, </type> <institution> The Ohio State University, </institution> <year> 1991. </year>
Reference-contexts: Presently, steps one and two have been accomplished and step three is being undertaken (developing tests for the various causes of a syntax error.) This second prototype is being written using the Integrated Generic Task Toolset (which contains tools for hierarchical classification, routine recognition, data inference and abductive assembly <ref> [9, 10] </ref>) in Common Lisp. In this prototype debugging system, a Generic Task approach is taken [4]. The knowledge is arranged based on three tasks, hierarchical classification, routine recognition and data inferencing.
Reference: [11] <author> Marvin Minksy. </author> <title> Steps towards artificial intelligence. </title> <booktitle> Computers and Thought, </booktitle> <year> 1963. </year>
Reference-contexts: To solve this problem, the programmer uses the syntax error as a clue, searches through the program looking for the code that caused the error, and attempts a correction. As described, debugging is a form of diagnosis (or more generally credit assignment) <ref> [8, 11, 12] </ref>. This form of diagnosis is more "routine" than other forms of diagnosis because of the limited amounts of knowledge required and the uniform types of inferences that are used in debugging.
Reference: [12] <author> William R. Murray. </author> <title> Automatic program debugging for intelligent tutoring systems. </title> <booktitle> Release Notes in Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1988. </year>
Reference-contexts: To solve this problem, the programmer uses the syntax error as a clue, searches through the program looking for the code that caused the error, and attempts a correction. As described, debugging is a form of diagnosis (or more generally credit assignment) <ref> [8, 11, 12] </ref>. This form of diagnosis is more "routine" than other forms of diagnosis because of the limited amounts of knowledge required and the uniform types of inferences that are used in debugging.
Reference: [13] <author> E. Rich and K. Knight. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw Hill Inc, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: For instance, a misspelled procedure name in a procedure call makes determining whether the instruction is a procedure call or some other construct problematical. In this case, data inferencing occurs <ref> [13] </ref>. Typical data inference revolves around checking the spelling of identifiers and reserved words, matching up comment delimiters, comparing syntactic structures (such as the ":=" in an assignment statement versus ": =") and matching begin-end clauses.
Reference: [14] <author> J. Sticklen. MDX2: </author> <title> An Integrated Medical Diagnostic System. </title> <type> PhD thesis, </type> <institution> The Ohio State University, </institution> <year> 1987. </year>
Reference-contexts: This makes debugging a much simpler search problem than other forms of diagnosis. The inference rules used in debugging do not include typical forms of diagnostic inferences such as data abstraction or inheritance <ref> [7, 14] </ref>. Instead, debugging requires inferences which are based on pattern matching where the patterns are well-known. These inferences usually involve identifying misspellings of reserved words and identifiers, determining if clauses were omitted, or if improper punctuation was used.
References-found: 14

