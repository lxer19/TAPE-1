URL: http://www.cs.toronto.edu/~parodi/papiro.ps.gz
Refering-URL: http://www.cs.toronto.edu/~parodi/abstract_tr.html
Root-URL: 
Email: parodi@vis.toronto.edu  picci@ge.infm.it  
Phone: 2  
Title: An efficient and flexible method for text extraction in document pages  
Author: Pietro Parodi Giulia Piccioli 
Address: 6 King's College Road, Room 265 C Toronto (ON), Canada M5S 3H5  Via Dodecaneso 33 16146 Genova, Italy  
Affiliation: 1 Department of Computer Science University of Toronto  Dipartimento di Fisica Universita di Genova  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> L.A. Fletcher and R. Kasturi. </author> <title> A robust algorithm for text string separation from mixed text/graphics images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10(6) </volume> <pages> 910-918, </pages> <year> 1988. </year>
Reference-contexts: Many techniques for text extraction and document segmentation have been developed through the years. They are commonly subdivided into three main categories: top-down, bottom-up and hybrid techniques. Bottom-up techniques <ref> [1, 2, 3, 4] </ref> progressively merge evidence at increasing scales to form, e.g., words from characters, lines from words, columns from text lines.
Reference: [2] <author> J.L. Fisher, </author> <title> S.C. Hinds, and D.P. D'Amato. A rule-based system for document image segmentation. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pages 567-572, </pages> <year> 1990. </year>
Reference-contexts: Many techniques for text extraction and document segmentation have been developed through the years. They are commonly subdivided into three main categories: top-down, bottom-up and hybrid techniques. Bottom-up techniques <ref> [1, 2, 3, 4] </ref> progressively merge evidence at increasing scales to form, e.g., words from characters, lines from words, columns from text lines.
Reference: [3] <author> F. Esposito, D. Malerba, G. Semeraro, E. Annese, and G. Scafuro. </author> <title> An experimental page layout recognition system for office document automatic classification: an integrated approach for inductive generalization. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pages 557-562, </pages> <year> 1990. </year>
Reference-contexts: Many techniques for text extraction and document segmentation have been developed through the years. They are commonly subdivided into three main categories: top-down, bottom-up and hybrid techniques. Bottom-up techniques <ref> [1, 2, 3, 4] </ref> progressively merge evidence at increasing scales to form, e.g., words from characters, lines from words, columns from text lines.
Reference: [4] <author> L. O'Gorman. </author> <title> The document spectrum for page layout analysis. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(11):1162 - 1173, </volume> <month> November </month> <year> 1993. </year>
Reference-contexts: Many techniques for text extraction and document segmentation have been developed through the years. They are commonly subdivided into three main categories: top-down, bottom-up and hybrid techniques. Bottom-up techniques <ref> [1, 2, 3, 4] </ref> progressively merge evidence at increasing scales to form, e.g., words from characters, lines from words, columns from text lines.
Reference: [5] <author> K.Y. Wong, R.G. Casey, </author> <title> and F.M. Wahl. Document analysis system. I.B.M. </title> <journal> Journal of Research and Development, </journal> <volume> 26(6) </volume> <pages> 647-656, </pages> <year> 1982. </year>
Reference-contexts: They are usually more flexible than top-down methods, but they are computationally more expensive and may suffer from the accumulation of mistakes when going from the small-scale details up to the large-scale features. Top-down techniques <ref> [5, 6, 7, 8] </ref> start by detecting the large-scale features of the image (e.g., the columns) and proceed by successive splittings until they reach the smallest-scale features (i.e., the individual characters, or the text lines).
Reference: [6] <author> D. Wang and S.N. Srihari. </author> <title> Classification of newspaper image blocks using texture analysis. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 47 </volume> <pages> 327-352, </pages> <year> 1989. </year>
Reference-contexts: They are usually more flexible than top-down methods, but they are computationally more expensive and may suffer from the accumulation of mistakes when going from the small-scale details up to the large-scale features. Top-down techniques <ref> [5, 6, 7, 8] </ref> start by detecting the large-scale features of the image (e.g., the columns) and proceed by successive splittings until they reach the smallest-scale features (i.e., the individual characters, or the text lines).
Reference: [7] <author> F.M. Wahl, K.Y. Wong, and R.G. Casey. </author> <title> Block segmentation and text extraction in mixed text/image documents. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 20 </volume> <pages> 375-390, </pages> <year> 1982. </year>
Reference-contexts: They are usually more flexible than top-down methods, but they are computationally more expensive and may suffer from the accumulation of mistakes when going from the small-scale details up to the large-scale features. Top-down techniques <ref> [5, 6, 7, 8] </ref> start by detecting the large-scale features of the image (e.g., the columns) and proceed by successive splittings until they reach the smallest-scale features (i.e., the individual characters, or the text lines).
Reference: [8] <author> G. Nagy and S.C.Seth. </author> <title> Hierarchical representation of optical scanned documents. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pages 347-349. </pages> <publisher> IEEE, </publisher> <address> Montreal, Canada, </address> <year> 1984. </year>
Reference-contexts: They are usually more flexible than top-down methods, but they are computationally more expensive and may suffer from the accumulation of mistakes when going from the small-scale details up to the large-scale features. Top-down techniques <ref> [5, 6, 7, 8] </ref> start by detecting the large-scale features of the image (e.g., the columns) and proceed by successive splittings until they reach the smallest-scale features (i.e., the individual characters, or the text lines).
Reference: [9] <author> H. S. Baird, S. E. Jones, and S. J. Fortune. </author> <title> Image segmentation by shape-directed covers. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pages 820-825, </pages> <year> 1990. </year>
Reference-contexts: Most methods do not really fit into any of the two categories above and they have therefore been called hybrid. It is impossible to give an overview of these methods here, so we will only cite a few works based on background analysis <ref> [9, 10, 11, 12] </ref> and some very general methods for segmentation based on texture analysis [13, 14, 15]. A more thorough survey on papers on document segmentation can be found in [16]. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. <p> In this section we compare our work to three other works based on background analysis: the work by Pavlidis & Zhou [10, 11], that by Baird et al. <ref> [9] </ref>, and that by Antonacopoulos & Ritchings [12]. Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou [10, 11]. <p> Baird et al., 1990. The idea of using the background as a basis for image segmentation had been used before by Baird et al. <ref> [9] </ref>. The method works by covering the background with a set of maximal white rectangles, and identifying the different text regions as the connected non-white components. <p> Antonacopoulos & Ritchings, 1994. Also based on background analysis and on covering the background with a set of white tiles is the work by Antonacopoulos & Ritchings [12]. 30 Unlike <ref> [9] </ref>, it does not require that the layout be Manhattan-like, nor it requires as in [11] that the text regions be surrounded by straight streams of white spaces. <p> Observe that in our case when a text region is surrounded by a white stream of sufficient width (once or twice the size of a character) the reconstruction precision is not * anymore but exactly 1 pixel. Observe that our method, as well as the methods in <ref> [11, 12, 9] </ref>, uses the background, and specifically the streams of white space, as a basis for image segmentation. <p> Observe that our method, as well as the methods in [11, 12, 9], uses the background, and specifically the streams of white space, as a basis for image segmentation. However, whereas in <ref> [9] </ref> and in [12] the white streams are themselves the basic units for the successive steps of the segmentation, and they are aggregated so as to encircle the regions of text, in [11] and in this work the non-white intervals (column intervals and line elements, respectively) rather than the white streams
Reference: [10] <author> T. Pavlidis and J. Zhou. </author> <title> Page segmentation by white streams. </title> <booktitle> In Proceedings of the International Conference on Document Analysis and Recognition, </booktitle> <pages> pages 945-953, </pages> <year> 1991. </year>
Reference-contexts: Most methods do not really fit into any of the two categories above and they have therefore been called hybrid. It is impossible to give an overview of these methods here, so we will only cite a few works based on background analysis <ref> [9, 10, 11, 12] </ref> and some very general methods for segmentation based on texture analysis [13, 14, 15]. A more thorough survey on papers on document segmentation can be found in [16]. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. <p> In this section we compare our work to three other works based on background analysis: the work by Pavlidis & Zhou <ref> [10, 11] </ref>, that by Baird et al. [9], and that by Antonacopoulos & Ritchings [12]. Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou [10, 11]. <p> & Zhou <ref> [10, 11] </ref>, that by Baird et al. [9], and that by Antonacopoulos & Ritchings [12]. Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou [10, 11]. In both our work and [10, 11], one of the key-ideas is that the problems caused by the complexity of the layout and by the skew can be circumvented if one subdivides the document into small stripes and then assembles the information gathered in the different stripes. <p> Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou <ref> [10, 11] </ref>. In both our work and [10, 11], one of the key-ideas is that the problems caused by the complexity of the layout and by the skew can be circumvented if one subdivides the document into small stripes and then assembles the information gathered in the different stripes.
Reference: [11] <author> T. Pavlidis and J. Zhou. </author> <title> Page segmentation and classification. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 54 </volume> <pages> 484-496, </pages> <year> 1992. </year>
Reference-contexts: Most methods do not really fit into any of the two categories above and they have therefore been called hybrid. It is impossible to give an overview of these methods here, so we will only cite a few works based on background analysis <ref> [9, 10, 11, 12] </ref> and some very general methods for segmentation based on texture analysis [13, 14, 15]. A more thorough survey on papers on document segmentation can be found in [16]. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. <p> In this section we compare our work to three other works based on background analysis: the work by Pavlidis & Zhou <ref> [10, 11] </ref>, that by Baird et al. [9], and that by Antonacopoulos & Ritchings [12]. Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou [10, 11]. <p> & Zhou <ref> [10, 11] </ref>, that by Baird et al. [9], and that by Antonacopoulos & Ritchings [12]. Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou [10, 11]. In both our work and [10, 11], one of the key-ideas is that the problems caused by the complexity of the layout and by the skew can be circumvented if one subdivides the document into small stripes and then assembles the information gathered in the different stripes. <p> Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou <ref> [10, 11] </ref>. In both our work and [10, 11], one of the key-ideas is that the problems caused by the complexity of the layout and by the skew can be circumvented if one subdivides the document into small stripes and then assembles the information gathered in the different stripes. <p> Apart from this formal analogy, however, the two methods are different. Here are some of the differences: * the two methods use the same idea of analyzing thin stripes of the document for different purposes: <ref> [11] </ref> aims at finding the text columns, we aim at finding the text lines directly; * an important conceptual difference is that our vertical columns overlap. This, as we have already remarked, allows to control segmentation precision. In [11] text columns are found with a segmentation precision which coincides with the <p> same idea of analyzing thin stripes of the document for different purposes: <ref> [11] </ref> aims at finding the text columns, we aim at finding the text lines directly; * an important conceptual difference is that our vertical columns overlap. This, as we have already remarked, allows to control segmentation precision. In [11] text columns are found with a segmentation precision which coincides with the height of the horizontal stripes. <p> In our case, the overlapping between columns allows for the decoupling of the two problems, precision and representativeness; * our method deals with a wider class of document pages than that by Pavlidis & Zhou. The method in <ref> [11] </ref> is in fact limited to documents where text regions are surrounded by straight streams of white space, and is therefore unsuitable for documents where, e.g., text is cropped around pictures, such as in in Fig. 16. <p> Antonacopoulos & Ritchings, 1994. Also based on background analysis and on covering the background with a set of white tiles is the work by Antonacopoulos & Ritchings [12]. 30 Unlike [9], it does not require that the layout be Manhattan-like, nor it requires as in <ref> [11] </ref> that the text regions be surrounded by straight streams of white spaces. It is reportedly fast, requiring about 1.5 seconds on a Sun SparcStation2 for images acquired at 300 dpi and subsampled so that only every third pixel is considered [19]. <p> Observe that in our case when a text region is surrounded by a white stream of sufficient width (once or twice the size of a character) the reconstruction precision is not * anymore but exactly 1 pixel. Observe that our method, as well as the methods in <ref> [11, 12, 9] </ref>, uses the background, and specifically the streams of white space, as a basis for image segmentation. <p> However, whereas in [9] and in [12] the white streams are themselves the basic units for the successive steps of the segmentation, and they are aggregated so as to encircle the regions of text, in <ref> [11] </ref> and in this work the non-white intervals (column intervals and line elements, respectively) rather than the white streams are used as the basic units which are merged to give text regions. In the latter case we have therefore foreground aggregation rather than background aggregation 9 .
Reference: [12] <author> A. Antonacopoulos and R. T. Ritchings. </author> <title> Flexible page segmentation using the background. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition. IEEE, </booktitle> <address> Jerusalem, Israel, </address> <year> 1994. </year>
Reference-contexts: Most methods do not really fit into any of the two categories above and they have therefore been called hybrid. It is impossible to give an overview of these methods here, so we will only cite a few works based on background analysis <ref> [9, 10, 11, 12] </ref> and some very general methods for segmentation based on texture analysis [13, 14, 15]. A more thorough survey on papers on document segmentation can be found in [16]. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. <p> In this section we compare our work to three other works based on background analysis: the work by Pavlidis & Zhou [10, 11], that by Baird et al. [9], and that by Antonacopoulos & Ritchings <ref> [12] </ref>. Pavlidis & Zhou, 1992. Our work is not a modification of any pre-existing method in the literature. The most closely related work in spirit, however, is probably the papers by Pavlidis and Zhou [10, 11]. <p> Antonacopoulos & Ritchings, 1994. Also based on background analysis and on covering the background with a set of white tiles is the work by Antonacopoulos & Ritchings <ref> [12] </ref>. 30 Unlike [9], it does not require that the layout be Manhattan-like, nor it requires as in [11] that the text regions be surrounded by straight streams of white spaces. <p> Observe that in our case when a text region is surrounded by a white stream of sufficient width (once or twice the size of a character) the reconstruction precision is not * anymore but exactly 1 pixel. Observe that our method, as well as the methods in <ref> [11, 12, 9] </ref>, uses the background, and specifically the streams of white space, as a basis for image segmentation. <p> Observe that our method, as well as the methods in [11, 12, 9], uses the background, and specifically the streams of white space, as a basis for image segmentation. However, whereas in [9] and in <ref> [12] </ref> the white streams are themselves the basic units for the successive steps of the segmentation, and they are aggregated so as to encircle the regions of text, in [11] and in this work the non-white intervals (column intervals and line elements, respectively) rather than the white streams are used as
Reference: [13] <author> A.K. Jain and S. Bhattacharjee. </author> <title> Text segmentation using Gabor filters for automatic document processing. </title> <journal> Machine Vision and Applications, </journal> <volume> 5 </volume> <pages> 169-184, </pages> <year> 1992. </year> <month> 32 </month>
Reference-contexts: It is impossible to give an overview of these methods here, so we will only cite a few works based on background analysis [9, 10, 11, 12] and some very general methods for segmentation based on texture analysis <ref> [13, 14, 15] </ref>. A more thorough survey on papers on document segmentation can be found in [16]. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. Fast segmentation methods are needed that do not rely on heavy prior assumptions about the document.
Reference: [14] <author> K.Etemad, R. Chellappa, and D. Doermann. </author> <title> Document page segmentation by integrat-ing distributed soft decisions. </title> <booktitle> In Proceedings of the International Conference on Neural Networks, </booktitle> <pages> pages 4022 - 4027, </pages> <year> 1994. </year>
Reference-contexts: It is impossible to give an overview of these methods here, so we will only cite a few works based on background analysis [9, 10, 11, 12] and some very general methods for segmentation based on texture analysis <ref> [13, 14, 15] </ref>. A more thorough survey on papers on document segmentation can be found in [16]. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. Fast segmentation methods are needed that do not rely on heavy prior assumptions about the document.
Reference: [15] <author> K.Etemad, R. Chellappa, and D. Doermann. </author> <title> Page segmentation using wavelet packets and decision integration. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <volume> volume 2, </volume> <pages> pages 345 - 349, </pages> <year> 1994. </year>
Reference-contexts: It is impossible to give an overview of these methods here, so we will only cite a few works based on background analysis [9, 10, 11, 12] and some very general methods for segmentation based on texture analysis <ref> [13, 14, 15] </ref>. A more thorough survey on papers on document segmentation can be found in [16]. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. Fast segmentation methods are needed that do not rely on heavy prior assumptions about the document.
Reference: [16] <author> L. O'Gorman and R. Kasturi. </author> <title> Document Image Analysis. </title> <publisher> IEEE Computer Society, </publisher> <year> 1995. </year>
Reference-contexts: A more thorough survey on papers on document segmentation can be found in <ref> [16] </ref>. Despite the many efforts spent on the subject, document segmentation is not a completely solved problem. Fast segmentation methods are needed that do not rely on heavy prior assumptions about the document.
Reference: [17] <author> D.S. Le, G.R. Thoma, and H. Wechsler. </author> <title> Automated page orientation and skew angle detection for binary document images. </title> <journal> Pattern Recognition, </journal> <volume> 27(10) </volume> <pages> 1325-1344, </pages> <year> 1994. </year>
Reference-contexts: Section 3 gives a detailed description of the algorithm. Section 4 describes some experimental results, including some studies on time performances. Section 5 discusses advantages and disadvantages of the method and compares the work to related works in the field. 1 profile. The picture is borrowed from Le <ref> [17] </ref>. 2 Rationale of the approach Our approach is based on the following consideration: If the document consists of a single column of text, extracting text lines is fairly easy: we simply compute the horizontal projection profile of the page as in Fig. 1 that is, we count the number of
Reference: [18] <author> P. Parodi and G. Piccioli. </author> <title> An efficient pre-processing of mixed-content document images for ocr systems. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <year> 1996. </year>
Reference-contexts: This is done using a very loose and conservative criterion, which is based 7 In a previous implementation of the algorithm <ref> [18] </ref> the skew angle fl was estimated as the weighted average of the coefficients a k , tan fl = k n k a k P ; where n k was is the number of line elements belonging to L k .
Reference: [19] <author> A. Antonacopoulos. </author> <type> Personal communication. 33 </type>
Reference-contexts: It is reportedly fast, requiring about 1.5 seconds on a Sun SparcStation2 for images acquired at 300 dpi and subsampled so that only every third pixel is considered <ref> [19] </ref>. <p> Giulia Piccioli was funded by Elsag S.p.A.. Pietro Parodi was partially funded by the IBM Center of Advanced Studies in Toronto. Fernando Nuflo checked the English. 9 This was pointed out to us by Antonacopoulos <ref> [19] </ref>. 31
References-found: 19

