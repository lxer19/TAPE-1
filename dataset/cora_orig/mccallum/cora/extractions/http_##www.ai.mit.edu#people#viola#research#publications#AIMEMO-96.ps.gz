URL: http://www.ai.mit.edu/people/viola/research/publications/AIMEMO-96.ps.gz
Refering-URL: http://www.ai.mit.edu/projects/lv/publications/
Root-URL: 
Title: Complex Feature Recognition: A Bayesian Approach for Learning to Recognize Objects  
Author: Paul A. Viola 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c Massachusetts Institute of Technology, 1996  
Date: 1591 November, 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  
Abstract: We have developed a new Bayesian framework for visual object recognition which is based on the insight that images of objects can be modeled as a conjunction of local features. This framework can be used to both derive an object recognition algorithm and an algorithm for learning the features themselves. The overall approach, called complex feature recognition or CFR, is unique for several reasons: it is broadly applicable to a wide range of object types, it makes constructing object models easy, it is capable of identifying either the class or the identity of an object, and it is computationally efficient requiring time proportional to the size of the image. Instead of a single simple feature such as an edge, CFR uses a large set of complex features that are learned from experience with model objects. The response of a single complex feature contains much more class information than does a single edge. This significantly reduces the number of possible correspondences between the model and the image. In addition, CFR takes advantage of a type of image processing called oriented energy. Oriented energy is used to efficiently pre-process the image to eliminate some of the difficulties associated with changes in lighting and pose. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for this research was provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-96-1-0311. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, D. H. </author> <year> (1981). </year> <title> Generalizing the Hough transform to detect arbitrary shapes. Pattern Recognition, </title> <publisher> 3(2):836840. </publisher>
Reference-contexts: Among the confounding influences are pose, lighting, clutter and occlusion. As a result, many researchers have eschewed the use of the image itself as the representation for recognition. Instead they choose to define and identify simple image features that are supposed to capture the important characteristics of the image <ref> (Ballard, 1981) </ref>, (Bolles and Cain, 1982), (Grimson and Lozano-Perez, 1984). A typical example of such a feature is an intensity edge. There are three main motivations for using simple features. First, it is assumed that simple features are detectable under a wide variety of pose and lighting changes.
Reference: <author> Becker, S. </author> <year> (1993). </year> <title> Learning to categorize objects using temporal coherence. </title> <editor> In Han-son, S. J., Cowan, J. D., and Giles, C. L., editors, </editor> <booktitle> Advances in Neural Information Processing, volume 5, </booktitle> <address> Denver 1992. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo. </address>
Reference-contexts: Viola 5 ORIENTED ENERGY AND FEATURE MATCHING the previous location). Both (F oldiak, 1991) and <ref> (Becker, 1993) </ref> have suggested that temporal continuity may serve as a mechanism for learning object identity. These difference sources of information about the likelihood of a feature representation can then be combined.
Reference: <author> Beymer, D. </author> <year> (1993). </year> <title> Face recognition under varying pose. </title> <type> AI Memo 1461, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology. </institution>
Reference-contexts: Learned Random Learned Features Features Features Features Objects 20 99 99 Faces 10 70 90 90 95 These results are about as good as the results that Nayar reports on his own data, but not as good as the results that Beymer reports on his data (Murase and Nayar, 1993) <ref> (Beymer, 1993) </ref>. In general CFR is very easy to use. For the most part CFR runs without requiring any intervention. The features are learned, the models are created and images are recognized without supervision. The exact same code runs on both the objects and the faces.
Reference: <author> Bolles, R. C. and Cain, R. </author> <year> (1982). </year> <title> Recognizing and locating partially visible objects: The localfeaturefocus method. </title> <journal> International Journal of Robotics Research, 1(3):5782. </journal>
Reference-contexts: As a result, many researchers have eschewed the use of the image itself as the representation for recognition. Instead they choose to define and identify simple image features that are supposed to capture the important characteristics of the image (Ballard, 1981), <ref> (Bolles and Cain, 1982) </ref>, (Grimson and Lozano-Perez, 1984). A typical example of such a feature is an intensity edge. There are three main motivations for using simple features. First, it is assumed that simple features are detectable under a wide variety of pose and lighting changes.
Reference: <author> Brunelli, R. and Poggio, T. </author> <year> (1992). </year> <title> Face recognition: Feature versus templates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(10):10421052. </journal>
Reference-contexts: No simple threshold on feature response 2 We use the maximal value of the normalized correlation between the feature and the image as a measure of image distance. Normalized correlation is a widely used matching metric that eliminates some of the dependency on lighting <ref> (Brunelli and Poggio, 1992) </ref>.
Reference: <author> Canny, J. F. </author> <year> (1986). </year> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-8(6):679698. </journal>
Reference-contexts: can be eliminated by normalizing the length of both S (I; l i ) and f i before the comparison is made. 5 In fact Freeman and Adelson used oriented energy as an input to a Canny edge detector and found that performance was significantly improved (Freeman and Adelson, 1991) <ref> (Canny, 1986) </ref>. 15 Paul A. Viola 6 EXPERIMENTS is computed by two banks of filters, an odd bank shown on the right, and and on even bank shown on the left. The image is convolved separately with each of the 12 filters. The resulting 12 images are then squared.
Reference: <author> Cover, T. M. and Thomas, J. A. </author> <year> (1991). </year> <title> Elements of Information Theory. </title> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: By defining d I G becomes a measure which compares the vectors d I and d M . There are a number of reasonable candidates for G, perhaps the best motivated is the cross entropy or asymmetric divergence (see <ref> (Cover and Thomas, 1991) </ref> for an excellent review entropy and divergence).
Reference: <author> F oldiak, P. </author> <year> (1991). </year> <title> Learning invariance from transformation sequences. Neural Computation, </title> <publisher> 3(2):194200. </publisher>
Reference-contexts: Viola 5 ORIENTED ENERGY AND FEATURE MATCHING the previous location). Both <ref> (F oldiak, 1991) </ref> and (Becker, 1993) have suggested that temporal continuity may serve as a mechanism for learning object identity. These difference sources of information about the likelihood of a feature representation can then be combined. <p> Multiplicative effects can be eliminated by normalizing the length of both S (I; l i ) and f i before the comparison is made. 5 In fact Freeman and Adelson used oriented energy as an input to a Canny edge detector and found that performance was significantly improved <ref> (Freeman and Adelson, 1991) </ref> (Canny, 1986). 15 Paul A. Viola 6 EXPERIMENTS is computed by two banks of filters, an odd bank shown on the right, and and on even bank shown on the left. The image is convolved separately with each of the 12 filters.
Reference: <author> Freeman, W. T. and Adelson, E. H. </author> <year> (1991). </year> <title> The design and use of steerable filters. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> 13(9):891906. 20 REFERENCES AI Memo 1591 Grimson, </note> <author> W. E. L. and Lozano-Perez, T. </author> <year> (1984). </year> <title> Model-based recognition and localization from sparse range or tactile data. </title> <journal> International Journal of Robotics Research, 3(3):335. </journal>
Reference-contexts: Multiplicative effects can be eliminated by normalizing the length of both S (I; l i ) and f i before the comparison is made. 5 In fact Freeman and Adelson used oriented energy as an input to a Canny edge detector and found that performance was significantly improved <ref> (Freeman and Adelson, 1991) </ref> (Canny, 1986). 15 Paul A. Viola 6 EXPERIMENTS is computed by two banks of filters, an odd bank shown on the right, and and on even bank shown on the left. The image is convolved separately with each of the 12 filters.
Reference: <author> Kandel, E. and Schwartz, J. </author> <year> (1985). </year> <booktitle> Principles of Neural Science. </booktitle> <publisher> Elsevier, </publisher> <address> New York, </address> <note> second edition. </note>
Reference-contexts: In order to improve the generalization of CFR to novel poses and different illumination, images are processed to extract information about rapid changes in intensity. Similar pre-processing can be found in the visual cortex of primates (see <ref> (Kandel and Schwartz, 1985) </ref> for example) and underlies the computational definition of the intensity edge by (Marr and Hildreth, 1980). Rather than the discrete detection of intensity edges, CFR instead uses a continuous measure of the edge-ness of pixels.
Reference: <author> Le Cun, Y., Boser, B., Denker, J., Henderson, D., Howard, R., Hubbard, W., and Jackel, L. </author> <year> (1989). </year> <title> Backpropagation applied to handwritten zip code recognition. Neural Computation, </title> <publisher> 1:541551. </publisher>
Reference-contexts: Techniques that use complex global features come in a wide variety of types. Recent examples include color histograms (Swain and Ballard, 1991), shape measures such as those proposed in (Sclaroff and Pentland, 1995) or monolithic neural networks such as those proposed by <ref> (Le Cun et al., 1989) </ref>. These techniques are distinguished because they are capable of using many different types of information, like color and texture. They do, however, share a sensitivity to clutter and frequently assume that the object is segmented from the background.
Reference: <author> Marr, D. and Hildreth, E. </author> <year> (1980). </year> <title> Theory of edge detection. </title> <journal> Proceedings of the Royal Society of London, B(207):187217. </journal>
Reference-contexts: Similar pre-processing can be found in the visual cortex of primates (see (Kandel and Schwartz, 1985) for example) and underlies the computational definition of the intensity edge by <ref> (Marr and Hildreth, 1980) </ref>. Rather than the discrete detection of intensity edges, CFR instead uses a continuous measure of the edge-ness of pixels. The edge-ness of a pixel is proportional to the energy in a number of oriented band-pass filters centered on the pixel.
Reference: <author> Murase, H. and Nayar, S. K. </author> <year> (1993). </year> <title> Learning and recognition of 3-d objects from brightness images. </title> <booktitle> In AAAI Fall Symposium Series Working Notes. </booktitle> <publisher> AAAI. </publisher>
Reference-contexts: CFR-DISC CFR-MEM CFR-DISC Random Learned Random Learned Features Features Features Features Objects 20 99 99 Faces 10 70 90 90 95 These results are about as good as the results that Nayar reports on his own data, but not as good as the results that Beymer reports on his data <ref> (Murase and Nayar, 1993) </ref> (Beymer, 1993). In general CFR is very easy to use. For the most part CFR runs without requiring any intervention. The features are learned, the models are created and images are recognized without supervision. The exact same code runs on both the objects and the faces.
Reference: <author> Poggio, T., Torre, V., and Koch, C. </author> <year> (1985). </year> <title> Computational vision and regularization theory. Nature, </title> <publisher> 317:314319. </publisher>
Reference-contexts: One useful definition of stable is that as an object slowly changes pose, large changes in representation are rare while small changes in representation are more common. One can formulate this in a way that is very similar to a smoothness prior that is common in regularization theory <ref> (Poggio, Torre and Koch, 1985) </ref>.
Reference: <author> Rao, R. P. N. and Ballard, D. H. </author> <year> (1995). </year> <title> Object indexing using an iconic sparse distributed memory. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 2431, </pages> <address> Cambridge, MA. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: In fact the very concept of global pre-supposes that the extent of the object is known. We hope that CFR combines the best properties of both the global and local techniques. Recently, <ref> (Rao and Ballard, 1995) </ref> have proposed that a type of pre-processing similar to oriented energy be used on images before they are matched to models.
Reference: <author> Rumelhart, D. E., Hinton, G. E., and Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E. and McLelland, J. L., editors, </editor> <booktitle> Parallel Distributed Processing: Exploration in the Microstructure of Cognition, chapter 8. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: A more direct approach is to learn a classifier. A classifier is a function C (~v) that computes object identity. We have chosen to use a multi-layer perceptron, also known as a neural network, to learn a classifier <ref> (Rumelhart, Hinton and Williams, 1986) </ref>. Briefly, a neural network is a clever way of parameterizing a function C (~v;W ) with a set of weights W .
Reference: <author> Sclaroff, S. and Pentland, A. P. </author> <year> (1995). </year> <title> Modal matching for correspondence and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(6):545561. </journal>
Reference-contexts: Each square corresponds to a region that is about 2 times the size of the largest head in the image. Techniques that use complex global features come in a wide variety of types. Recent examples include color histograms (Swain and Ballard, 1991), shape measures such as those proposed in <ref> (Sclaroff and Pentland, 1995) </ref> or monolithic neural networks such as those proposed by (Le Cun et al., 1989). These techniques are distinguished because they are capable of using many different types of information, like color and texture.
Reference: <author> Swain, M. J. and Ballard, D. H. </author> <year> (1991). </year> <title> Color indexing. </title> <journal> International Journal of Computer Vision, 7:1132. </journal>
Reference-contexts: These regions were labeled with a white square. Each square corresponds to a region that is about 2 times the size of the largest head in the image. Techniques that use complex global features come in a wide variety of types. Recent examples include color histograms <ref> (Swain and Ballard, 1991) </ref>, shape measures such as those proposed in (Sclaroff and Pentland, 1995) or monolithic neural networks such as those proposed by (Le Cun et al., 1989). These techniques are distinguished because they are capable of using many different types of information, like color and texture.
Reference: <author> Wells III, W. M. </author> <year> (1991). </year> <title> MAP Model Matching. </title> <booktitle> In Proceedings of the Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 486492, </pages> <address> Lahaina, Maui, Hawaii. </address> <publisher> IEEE. </publisher> <pages> 21 </pages>
Reference-contexts: This type of approach is not new. Most well-known object recognition systems can be formulated as a search for the model that makes the image most likely (see for example <ref> (Wells III, 1991) </ref> which makes this analogy very explicit). Of course the details of these algorithms can be quite different. Some algorithms use the input image directly, comparing the input image and the predicted image directly. Most techniques that use correlation for image matching fall into this category.
References-found: 19

