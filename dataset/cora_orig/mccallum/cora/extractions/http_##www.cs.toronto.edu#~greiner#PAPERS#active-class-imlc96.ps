URL: http://www.cs.toronto.edu/~greiner/PAPERS/active-class-imlc96.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: greiner@scr.siemens.com  grove@research.nj.nec.com  danr@wisdom.weizmann.ac.il  
Title: Learning Active Classifiers  
Author: Russell Greiner Adam J. Grove Dan Roth 
Date: July 1996.  
Note: Appears in the Proceedings of the Thirteenth International Conference on Machine Learning (IMLC-96),  
Address: 755 College Road East Princeton, NJ 08540-6632  4 Independence Way Princeton, NJ 08540  Rehovot 76100, Israel  Italy,  
Affiliation: Siemens Corporate Research  NEC Research Institute  Dept. of Appl. Math. CS Weizmann Institute of Science  Bari  
Abstract: Many classification algorithms are "passive", in that they assign a class-label to each instance based only on the description given, even if that description is incomplete. In contrast, an active classifier can | at some cost | obtain the values of missing attributes, before deciding upon a class label. The expected utility of using an active classifier depends on both the cost required to obtain the additional attribute values and the penalty incurred if it outputs the wrong classification. This paper considers the problem of learning near-optimal active classifiers, using a variant of the probably-approximately-correct (PAC) model. After defining the framework | which is perhaps the main contribution of this paper | we describe a situation where this task can be achieved efficiently, but then show that the task is often intractable. 
Abstract-found: 1
Intro-found: 1
Reference: [Aha96] <author> D. Aha. </author> <title> Special issue on "Lazy Learning". </title> <booktitle> Artificial Intelligence Review, 1996. (in progress). </booktitle>
Reference-contexts: Thus the representation of the classifier is essentially just the sample itself | which is reminiscent of lazy learning <ref> [Aha96] </ref>. Finally, we consider the p = (constant) case. Unfor tunately, it is fairly easy to see that this case can be extremely difficult, as it can sometimes require learning exponentially many probabilities (e.g., the probabilities that '(~x) is T conditioned on each possible initial configuration).
Reference: [AHM95] <author> P. Auer, R. C. Holte, and W. Maass. </author> <title> Theory and applications of agnostic PAC-learning with small decision trees. </title> <booktitle> In ICML-95, </booktitle> <pages> pages 21-29, </pages> <year> 1995. </year>
Reference-contexts: Then the optimal active classifier is completely determined once we specify which attribute we should request, and which classification (T or F ) is most likely given each value that this attribute might take (forming "decision-stumps" of the form studied in <ref> [Hol93, AHM95] </ref>). We can sometimes discover this classifier without knowing the full concept itself. Of course, knowing the full concept would be important if we were frequently asked to classify complete (unblocked) instances.
Reference: [Ang87] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Inform. Comput., </journal> <volume> 75(2) </volume> <pages> 87-106, </pages> <year> 1987. </year>
Reference-contexts: Our task, of learning active classifiers, should also be distinguished from another interesting problem, that of actively learning (passive) classifiers. For example, <ref> [Ang87, Ang88] </ref>, [KMT93] consider models in which the learner can query for labels of examples as it is learning. In contrast, our learner is passive; see Section 7. Utility: There are several learning projects that attempt to learn classifiers that are sensitive to test costs.
Reference: [Ang88] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Our task, of learning active classifiers, should also be distinguished from another interesting problem, that of actively learning (passive) classifiers. For example, <ref> [Ang87, Ang88] </ref>, [KMT93] consider models in which the learner can query for labels of examples as it is learning. In contrast, our learner is passive; see Section 7. Utility: There are several learning projects that attempt to learn classifiers that are sensitive to test costs.
Reference: [Ang92] <author> D. Angluin. </author> <title> Computational learning theory: survey and selected bibliography. </title> <booktitle> In STOC-92, </booktitle> <pages> pages 351-369, </pages> <year> 1992. </year>
Reference-contexts: Proof: This claim reduces to the fact that not everything is known to be PAC learnable <ref> [Ang92] </ref> because, if all costs c (x i ) are zero, the classifier can ask for all attributes and then we will classify optimally if and only if it knows the concept.
Reference: [BDD93] <author> S. Ben-David and E. Dichterman. </author> <title> Learning with restricted focus of attention. </title> <booktitle> In COLT93, </booktitle> <pages> pages 287-296, </pages> <year> 1993. </year>
Reference-contexts: Missing attribute values: Several other learning algorithms produce classifiers that can deal with partially specified instances; cf., [DLR77, LR87, Qui89, SG94]. However, these classifiers are not able to actively obtain missing information. <ref> [BDD93, KR95] </ref> consider the problem of learning from partially specified instances, but with the goal of (resp.) later classifying complete instances, or later reasoning with respect to the learned concept. [GGK96] also considers learning from partially specified instances, but in situations where this missing information is known not to matter to
Reference: [BF85] <author> D. Berry and B. Fristedt. </author> <title> Bandit Problems: Sequential Allocation of Experiments. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: The goal would be to minimize total cost over some lifetime. Among the new difficulties this would introduce is the characteristic dilemma of bandit problems <ref> [BF85] </ref>: finding the right balance between learning and performance in terms of the number of attributes requested. The model in this paper was (at the expense of some realism) designed so that this particular tradeoff is avoided.
Reference: [Blu94] <author> A. Blum. </author> <title> Relevant examples and relevant features: Thoughts from computational learning theory. </title> <booktitle> In AAAI Fall Symposium on `Relevance', </booktitle> <year> 1994. </year>
Reference-contexts: But even the simpler problem, of learning boolean functions that depend on only log n variables, even under the uniform distribution, is regarded as a challenging open problem <ref> [Blu94] </ref>. On the other hand, the news is not all bad here. The difficulty here concerns computational complexity, and not sample complexity nor the nonexistence of a good small classifier.
Reference: [BMSJ78] <author> B. G. Buchanan, T. M. Mitchell, R. G. Smith, and C. R. Johnson, Jr. </author> <title> Models of learning systems. </title> <booktitle> In Encyclopedia of Computer Science and Technology, </booktitle> <volume> volume 11. </volume> <publisher> Dekker, </publisher> <year> 1978. </year>
Reference-contexts: But Section 6 then shows that the problem is very often intractable. The conclusion, Section 7, presents some ideas for future work, and some thoughts on the contrast between learning active versus passive classifiers. 2 LITERATURE SURVEY Our framework is based upon the "standard" learning model <ref> [BMSJ78] </ref>, in which a learner receives a set of labeled (i.e., correctly classified) training examples as input, and must output a good classifier. Furthermore, the notion of "good" we use is a derivative of the popular probably-approximately-correct (PAC) model [Val84].
Reference: [DLR77] <author> A. Dempster, N. Laird, and D. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Royal Statistics Society, B, </journal> <volume> 39 </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: Third, the quality of such a classifiers depends on the expected cost of obtaining attributes, as well as its classification accuracy. Missing attribute values: Several other learning algorithms produce classifiers that can deal with partially specified instances; cf., <ref> [DLR77, LR87, Qui89, SG94] </ref>.
Reference: [GGK96] <author> R. Greiner, A. Grove, and A. Kogan. </author> <title> Exploiting the omission of irrelevant data. </title> <booktitle> In ICML-96, </booktitle> <year> 1996. </year>
Reference-contexts: However, these classifiers are not able to actively obtain missing information. [BDD93, KR95] consider the problem of learning from partially specified instances, but with the goal of (resp.) later classifying complete instances, or later reasoning with respect to the learned concept. <ref> [GGK96] </ref> also considers learning from partially specified instances, but in situations where this missing information is known not to matter to the classification. Active classification: "Active" classification is not a novel concept; many diverse areas use related ideas (including planning, diagnosis, decision theory, and so on).
Reference: [GGR96] <author> R. Greiner, A. Grove, and D. Roth. </author> <title> Learning active classifiers. </title> <type> Technical report, </type> <institution> Siemens Corp. Res., </institution> <year> 1996. </year>
Reference-contexts: As it also knows ', it can estimate the probability of T versus F and thus determine which is the better response. In general, 4 All proofs are sketched or omitted entirely, due to space limitations. The extended report, <ref> [GGR96] </ref>, containing all proofs, is in preparation. 4 it can also determine whether it should ask for the value of an attribute using straightforward dynamic programming; see Section 5 below.
Reference: [Hau92] <author> David Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100(1) </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: For example, Turney [Tur95] (and others; see references therein) uses heuristic methods to build decision trees which minimize classification and test costs; by contrast, we are seeking provably optimal active classifiers, of any representation. Haussler <ref> [Hau92] </ref> studies a decision-theoretic generalization of the PAC model, in which the learner may output a classification or a decision rule with the goal of minimizing a given loss function. However, his classifier always receives complete instances, and so is not active in our sense.
Reference: [HBR94] <author> D. Heckerman, J. Breese, and K. Rommelse. </author> <title> Troubleshooting under uncertainty. </title> <booktitle> In International Workshop on Principles of Diagnosis, </booktitle> <year> 1994. </year>
Reference-contexts: Active classification: "Active" classification is not a novel concept; many diverse areas use related ideas (including planning, diagnosis, decision theory, and so on). As just one illustrative example, Heckerman et al. <ref> [HBR94] </ref> describe how to translate any given Bayesian net (which satisfies certain properties) into (what we call) an effective "active classifier" that both isolates and repairs the fault, taking account of costs and the probability of various diagnoses being correct. 1 Of course, the classifier will be tested on instances drawn <p> Section 3 explains why it is reasonable to give the learner this more complete information. However such work usually does not consider the problem of learning such classifiers. One possible reason is that the tasks of learning and classifying can often be decoupled from each other. For instance, <ref> [HBR94] </ref> could appeal to standard Bayesian-network learning techniques to learn the necessary distributions. While conceding that such a decoupling is possible in many cases, the basic question examined in this paper is whether there can be any advantage in studying learning and active classification together; see Section 4. <p> If we know all of these, then then we are faced with a very interesting optimization problem <ref> [HBR94] </ref> | one which, however, has nothing to do with learning. Sometimes this problem is tractable as, for instance, in the following case involving product distributions (i.e., distributions in which each attribute's value is determined independently) and classifiers that can only ask a constant number of questions.
Reference: [Hol93] <author> R. Holte. </author> <title> Very simple classification rules perform well on most commonly used datasets. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 63-91, </pages> <year> 1993. </year>
Reference-contexts: Then the optimal active classifier is completely determined once we specify which attribute we should request, and which classification (T or F ) is most likely given each value that this attribute might take (forming "decision-stumps" of the form studied in <ref> [Hol93, AHM95] </ref>). We can sometimes discover this classifier without knowing the full concept itself. Of course, knowing the full concept would be important if we were frequently asked to classify complete (unblocked) instances.
Reference: [Kha96] <author> R. Khardon. </author> <title> Learning to act. </title> <booktitle> In AAAI-96, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: However, his classifier always receives complete instances, and so is not active in our sense. A final contrast is with work that assumes that a learner gets to see a (hopefully good) active classifier in action, and tries to learn to duplicate its performance <ref> [Kha96] </ref>.
Reference: [KLPV87] <author> M. Kearns, M. Li, L. Pitt, and L. G. Valiant. </author> <title> On the learnability of boolean formulae. </title> <booktitle> In STOC-87, </booktitle> <pages> pages 285-295, </pages> <year> 1987. </year>
Reference-contexts: 8ac 2 A 0 ; Ec P (ac ';A 0 ;P ) Ec P (ac). (When the dependence on A 0 and P is clear, we will write ac ' rather than ac ';A 0 ;P .) We define the following variant of the standard "Probably Approximately Correct" (PAC) criterion <ref> [Val84, KLPV87] </ref> to specify the desired performance of such a learner.
Reference: [KMT93] <author> S. R. Kulkarni, S. K. Mitter, and J. N. Tsit-siklis. </author> <title> Active learning using arbitrary binary valued queries. </title> <journal> Machine Learning, </journal> <volume> 11(1), </volume> <year> 1993. </year>
Reference-contexts: Our task, of learning active classifiers, should also be distinguished from another interesting problem, that of actively learning (passive) classifiers. For example, [Ang87, Ang88], <ref> [KMT93] </ref> consider models in which the learner can query for labels of examples as it is learning. In contrast, our learner is passive; see Section 7. Utility: There are several learning projects that attempt to learn classifiers that are sensitive to test costs.
Reference: [KR94] <author> R. Khardon and D. Roth. </author> <title> Learning to reason. </title> <booktitle> In AAAI-94, </booktitle> <pages> pages 682-687, </pages> <year> 1994. </year>
Reference-contexts: In particular, one can sometimes learn a good active classifier without having learned (even implicitly) the concept or the distribution. This basic idea | of learning just enough to perform some particular task, rather than trying to learn everything | has been used by Khardon and Roth <ref> [KR94] </ref> in their Learning to Reason framework.
Reference: [KR95] <author> R. Khardon and D. Roth. </author> <title> Learning to reason with a restricted view. </title> <booktitle> In COLT-95, </booktitle> <pages> pages 301-310, </pages> <year> 1995. </year>
Reference-contexts: Missing attribute values: Several other learning algorithms produce classifiers that can deal with partially specified instances; cf., [DLR77, LR87, Qui89, SG94]. However, these classifiers are not able to actively obtain missing information. <ref> [BDD93, KR95] </ref> consider the problem of learning from partially specified instances, but with the goal of (resp.) later classifying complete instances, or later reasoning with respect to the learned concept. [GGK96] also considers learning from partially specified instances, but in situations where this missing information is known not to matter to
Reference: [KS90] <author> M. Kearns and R. Shapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In FOCS-90, </booktitle> <year> 1990. </year>
Reference-contexts: Theorem 4, while rather restrictive in many other respects, works for any concept at all. To explain this difference, first note that when one does not see all the attributes then the induced probabilistic concept <ref> [KS90] </ref> over the visible attributes can, in general, be quite complex, even if the real concept is a simple one. A second issue is that the distribution appears to matter more.
Reference: [LR87] <author> J. Little and D. Rubin. </author> <title> Statistical Analysis with Missing Data. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Third, the quality of such a classifiers depends on the expected cost of obtaining attributes, as well as its classification accuracy. Missing attribute values: Several other learning algorithms produce classifiers that can deal with partially specified instances; cf., <ref> [DLR77, LR87, Qui89, SG94] </ref>.
Reference: [PP91] <author> Gregory Provan and David Poole. </author> <title> The utility of consistency-based diagnostic techniques. </title> <booktitle> In KR-91, </booktitle> <pages> pages 461-72, </pages> <year> 1991. </year>
Reference-contexts: The correct measure is decision theoretic, balancing the costs of acquiring addition information against the penalties for incorrect classification. For instance, it may not be worth spending $1,000 to perform an expensive test to distinguish two minor variants of hepatitis, especially if the treatment is the same for both <ref> [PP91] </ref>; similarly, it is not appropriate to spend $100 to obtain the information required to win a $1 bet. On any given instance, an active classifier ac has a total cost, defined as the final penalty plus all costs incurred.
Reference: [Qui89] <author> J. R. Quinlan. </author> <title> Unknown attribute values in induction. </title> <booktitle> In ICML-89, </booktitle> <pages> pages 164-168, </pages> <year> 1989. </year>
Reference-contexts: Third, the quality of such a classifiers depends on the expected cost of obtaining attributes, as well as its classification accuracy. Missing attribute values: Several other learning algorithms produce classifiers that can deal with partially specified instances; cf., <ref> [DLR77, LR87, Qui89, SG94] </ref>.
Reference: [SG94] <author> D. Schuurmans and R. Greiner. </author> <title> Learning default concepts. </title> <booktitle> In CSCSI-94, </booktitle> <pages> pages 519-523, </pages> <year> 1994. </year>
Reference-contexts: Third, the quality of such a classifiers depends on the expected cost of obtaining attributes, as well as its classification accuracy. Missing attribute values: Several other learning algorithms produce classifiers that can deal with partially specified instances; cf., <ref> [DLR77, LR87, Qui89, SG94] </ref>. <p> This extended model raises a number of interesting questions (e.g., how does fi decide which attributes to reveal? <ref> [SG94] </ref>), which space limitations prevent us from pursuing; but see the brief discussion in Section 6.
Reference: [Tur95] <author> P. D. Turney. </author> <title> Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm. </title> <journal> Journal of AI Research, </journal> <volume> 2 </volume> <pages> 369-409, </pages> <year> 1995. </year>
Reference-contexts: In contrast, our learner is passive; see Section 7. Utility: There are several learning projects that attempt to learn classifiers that are sensitive to test costs. For example, Turney <ref> [Tur95] </ref> (and others; see references therein) uses heuristic methods to build decision trees which minimize classification and test costs; by contrast, we are seeking provably optimal active classifiers, of any representation.
Reference: [Val84] <author> L. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year> <month> 9 </month>
Reference-contexts: Furthermore, the notion of "good" we use is a derivative of the popular probably-approximately-correct (PAC) model <ref> [Val84] </ref>. However, we differ from the usual model in (at least) the following respects. First, our classifier receives only partially specified instances, which can omit the values of some or all attributes. <p> 8ac 2 A 0 ; Ec P (ac ';A 0 ;P ) Ec P (ac). (When the dependence on A 0 and P is clear, we will write ac ' rather than ac ';A 0 ;P .) We define the following variant of the standard "Probably Approximately Correct" (PAC) criterion <ref> [Val84, KLPV87] </ref> to specify the desired performance of such a learner.
References-found: 27

