URL: http://www-eksl.cs.umass.edu/papers/jensenaaaiss97.ps
Refering-URL: http://eksl-www.cs.umass.edu/publications.html
Root-URL: 
Title: Abstract knowledge discovery jensen@cs.umass.edu Unique Challenges of Managing Inductive Knowledge  
Author: David Jensen 
Date: October 25, 1996  
Address: Amherst, MA 01003-4610  
Affiliation: Experimental Knowledge Systems Lab Computer Science Department University of Massachusetts  
Abstract: Techniques for inducing knowledge from databases, often grouped under the term , are becoming increasingly important to organizations in business, government, and science. However, relatively little attention has been paid to the long-term management of induced knowledge. Induced knowledge presents unique challenges, including managing statistical significance and inductive bias. These two challenges have important implications for valid and efficient knowledge management. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. </author> <title> Cohen (1996). </title> <publisher> MIT Press. </publisher>
Reference-contexts: A statistic summarizes the quality of a relationship in a single scalar measure. A standard statistic for the type of table in Figure 1 is the statistic <ref> [1] </ref>. = 2 ln (1) where is the number of occurrences, or frequency, in the cell and ^ is the expected value of that cell.
Reference: [2] <author> P. Cohen and D. </author> <title> Jensen (1997). Overfitting explained. </title> <booktitle> Accepted to the Sixth International Workshop on Artificial Intelligence and Statistics (Poster). </booktitle> <month> January. </month>
Reference-contexts: The adjustment is necessary because the reference distribution for is constructed under the assumption of a single comparison of a model to a data sample. Multiple comparisons renders this reference distribution inaccurate <ref> [2] </ref>. A Bonferroni adjustment also makes an assumption: that the comparisons are | i.e., that the results of one comparison tell us nothing about the outcome of another comparison. Unfortunately, multiple comparisons by induction algorithms are rarely independent.
Reference: [3] <author> U. Fayyad, G. Piatetsky-Shapiro, and P. </author> <title> Smyth (1996). From data mining to knowledge discovery in databases. </title> . <booktitle> Fall. </booktitle> <pages> 37-54. </pages>
Reference: [4] <editor> U. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy (1996). </editor> . <publisher> AAAI Press/MIT Press. </publisher>
Reference: [5] <author> B. </author> <title> Gaines (1989). An ounce of knowledge is worth a ton of data: Quantitative studies of the trade-off between expertise and data based on statistically well-founded empirical induction. </title> <publisher> Morgan Kaufmann. </publisher> <pages> 156-159. </pages>
Reference-contexts: As a result, adjusting for these multiple comparisons becomes essential to accurately estimate . Equation 2 is one of a class of Bonferroni equations, commonly used to adjust statistical tests for multiple comparisons and more recently applied to induction algorithms <ref> [8, 5, 9] </ref>. The adjustment is necessary because the reference distribution for is constructed under the assumption of a single comparison of a model to a data sample. Multiple comparisons renders this reference distribution inaccurate [2].
Reference: [6] <author> D. Gordon and M. </author> <title> Desjardins (1996). Evaluation and selection of biases in machine learning. 20 5-22. </title> <journal> 11 Applied Statistics Science American Statistician. Journal of the American Statistical Association </journal>
Reference-contexts: Indeed, induction algorithms are largely defined by their inductive bias | the space they search and their relative preferences within that space are some of the most critical factors that define a particular algorithm. There are at least two types of inductive bias <ref> [6] </ref>. refers to limits imposed on the search space by the selected representation. For example, only certain types of relationships can be represented as DNF rules. or bias refers to ordering or limits imposed by search algorithm.
Reference: [7] <author> D. </author> <title> Jensen (1992). Induction with Randomization Testing: Decision-Oriented Analysis of Large Data Sets. </title> <type> Doctoral dissertation. </type> <institution> Washing-ton University, St. Louis Missouri. </institution>
Reference-contexts: To a first approximation, however, potential correlation can sometimes be ignored, and we will not deal further with this issue here. In addition to the Bonferroni adjustment, there are several other techniques that can be used to compensate for multiple comparisons. These include randomization testing <ref> [7] </ref>, a method of empirically constructing reference distributions based on analyzing random data, and cross-validation [10], a method of systematically providing fresh data for evaluating the results of extensive search.
Reference: [8] <author> D. </author> <title> Jensen (1997). Adjusting for multiple testing in decision tree pruning. </title> <booktitle> Accepted to the Sixth International Workshop on Artificial Intelligence and Statistics (Poster). </booktitle> <month> January. </month>
Reference-contexts: As a result, adjusting for these multiple comparisons becomes essential to accurately estimate . Equation 2 is one of a class of Bonferroni equations, commonly used to adjust statistical tests for multiple comparisons and more recently applied to induction algorithms <ref> [8, 5, 9] </ref>. The adjustment is necessary because the reference distribution for is constructed under the assumption of a single comparison of a model to a data sample. Multiple comparisons renders this reference distribution inaccurate [2].
Reference: [9] <author> G. </author> <title> Kass (1980). An exploratory technique for investigating large quantities of categorical data. </title> <booktitle> 29(2) </booktitle> <pages> 119-127. </pages>
Reference-contexts: As a result, adjusting for these multiple comparisons becomes essential to accurately estimate . Equation 2 is one of a class of Bonferroni equations, commonly used to adjust statistical tests for multiple comparisons and more recently applied to induction algorithms <ref> [8, 5, 9] </ref>. The adjustment is necessary because the reference distribution for is constructed under the assumption of a single comparison of a model to a data sample. Multiple comparisons renders this reference distribution inaccurate [2].
Reference: [10] <author> R. </author> <title> Kohavi (1995). A study of cross-validation and bootstrap for accuracy estimation and model selection. </title> <booktitle> Proceedings of the International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: In addition to the Bonferroni adjustment, there are several other techniques that can be used to compensate for multiple comparisons. These include randomization testing [7], a method of empirically constructing reference distributions based on analyzing random data, and cross-validation <ref> [10] </ref>, a method of systematically providing fresh data for evaluating the results of extensive search. All of these techniques, however, require information on which data were used to construct the model and what alternative models were tested during the construction.
Reference: [11] <author> C. </author> <title> Mann (1990). </title> <booktitle> Meta-analysis in the breech. </booktitle> <volume> 249: </volume> <pages> 476-480. </pages>
Reference-contexts: Negative results are rarely published, thus potentially causing statistically spurious results to be identified as significant.[14] Statisticians are exploring this issue in a growing literature on | the combination of the results of multiple published studies to potentially reach conclusions that no single study can reach <ref> [11] </ref> appear that has been independently verified. Potential mistakes of this kind can only be avoided if a link is maintained to the original data used to derive a model. Thirty analysts work independently on data sample , each evaluating the accuracy of a different model.
Reference: [12] <author> T. </author> <title> Mitchell (1980). The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117. </type> <institution> Rutgers University. </institution>
Reference-contexts: In addition, induction algorithms impose an ordering on the models within their search space. They select some models over others, based on apparent accuracy, relative complexity, and other factors. Machine learning researchers label these factors <ref> [12] </ref>. Inductive bias is a necessary characteristic of any induction algorithm. Indeed, induction algorithms are largely defined by their inductive bias | the space they search and their relative preferences within that space are some of the most critical factors that define a particular algorithm.
Reference: [13] <author> H. Selvin and A. </author> <title> Stuart (1966). Data-dredging procedures in survey analysis. </title> <month> June. </month> <pages> 20-23. </pages>
Reference: [14] <author> T. </author> <title> Sterling (1959). Publication decisions and their possible effects on inferences drawn from tests of significance | or vice-versa. </title> <booktitle> 54: </booktitle> <pages> 30-34. </pages>
References-found: 14

