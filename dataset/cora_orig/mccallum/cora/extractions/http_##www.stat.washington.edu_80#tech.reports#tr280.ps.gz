URL: http://www.stat.washington.edu:80/tech.reports/tr280.ps.gz
Refering-URL: http://www.stat.washington.edu:80/tech.reports/
Root-URL: 
Title: A Region Based Image Segmentation Method for Multi-Channel Data.  
Author: Smarajit Bose and Finbarr O'Sullivan 
Note: 98195. This research was supported in part by the National Institutes of Health under CA-57903, CA-42593, and CA-42045.  
Address: Seattle, WA  
Affiliation: 1 Department of Statistics, Ohio State University, Columbus, OH. and Department of Statistics, University of Washington,  
Date: November 30, 1994  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Adams R. and Bischof L. </author> <title> Seeded Region Growing. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 16 </volume> <pages> 641-647, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Images in which there are several observations per pixel is a common data type in many fields of science and engineering <ref> [1, 8, 17, 23] </ref>. With these multi-channel images, segmentation has often been found useful for analysis. Segmentation has the ability to capture features that are not readily apparent from a sequence of single channel views of the data. <p> Two main varieties of image segmentation are commonly used: (i) Threshold Methods and (ii) Region Based Methods. A more detailed taxonomy appears in the recent article by Adams and Bischof <ref> [1] </ref>. Threshold methods segment on the basis of the marginal distribution of selected features of interest, the raw grey scale values for example. Statistical clustering tools are often useful here. <p> This can make the interpretation of structures identified by the segmentation difficult [9]. Region based methods impose direct spatial contiguity constraints on image segments. A range of alternative approaches for achieving this have been proposed. Amoung the most popular are so-called split-and-merge techniques <ref> [1, 8, 15] </ref>. As the name suggests, split-and-merge segmentation algorithms comprise of two steps: splitting and merging. Splitting is used to decompose the image into homogeneous subsets and an associated hierarchical tree-based data structure.
Reference: [2] <author> Altman N. </author> <title> Kernel smoothing of data with correlated errors. </title> <journal> J. Amer. Statist. Assoc., </journal> <volume> 85 </volume> <pages> 749-759, </pages> <year> 1990. </year>
Reference-contexts: However it is important to appreciate that the choice of segmentation model is then not quite objective anymore. Similar difficulties have been noted in attempts to adaptively choose regularization parameters in 1-dimensional smoothers when the data are correlated <ref> [2, 11] </ref>. Image Segmentation 6 3 Numerical Simulation Experiments.
Reference: [3] <author> Blomqvist G. Stone-Elander S. Halldin G. Roland P.E. Widen L. Linqvist M. Sivahm C.G. Langstrom B. Wissel L.A. </author> <title> Positron emission tomographic measurement of cerebral glucose utilization using [1 11 C]D-glucose. </title> <journal> J. Cereb. Blood Flow Metab., </journal> <volume> 10 </volume> <month> 467-483 </month> <year> 1990. </year>
Reference-contexts: For active brain tumors, the metabolic rate of glucose is typically higher than that of normal brain <ref> [3] </ref>. At the University of Washington PET center an investigation of alternate tracers, F-18 labeled deoxyglucose (FDG) and C-11 labeled glucose (GLC), for measuring glucose utilization is being carried out by a group lead by Dr. Spence [27].
Reference: [4] <author> Breiman L Friedman J.H. Olshen R.A. and Stone C.J. </author> <title> Classification and Regression Trees. </title> <booktitle> Wadsworth International Group, </booktitle> <address> Belmont CA. </address> <year> 1984. </year>
Reference-contexts: Merging recombines terminal nodes in the tree until some measure of goodness of fit (objective or subjective) is reached. From a statistical perspective, the split-and-merge segmentation has many elements in common with modern classification and regression tree (CART) methodology <ref> [4] </ref>. Splitting is a process a kin to tree growing and merging similar to pruning in CART [4]. However, there are some important differences: Probably due the large number of cases (pixels) the splitting process is not optimized as in CART. <p> From a statistical perspective, the split-and-merge segmentation has many elements in common with modern classification and regression tree (CART) methodology <ref> [4] </ref>. Splitting is a process a kin to tree growing and merging similar to pruning in CART [4]. However, there are some important differences: Probably due the large number of cases (pixels) the splitting process is not optimized as in CART. <p> Because there are only a finite number of models in the merged sequence, each member of the sequence potentially minimizes the cost complexity criterion for a continuous range of ff-values. The ranges of ff-values and corresponding segmentation models can be determined by a simple algorithm, c:f: <ref> [4, Chapter 3] </ref>: Begin by setting ff 1 = 0 and select f ff 1 from the merged sequence to minimize the corresponding cost-complexity criterion, R 0 . <p> Vapnik-Chevronenkis class of sets and an associated set of Image Segmentation 7 conditions to ensure that certain empirical measures defined on those classes of sets are convergent. 1 Unfortunately, the detailed verification of those conditions for particular adaptive partitioning schemes of interest, including even the specific algorithm in the CART <ref> [4] </ref> book, has not yet been demonstrated. In any event, the theory would not apply to our segmentation methodology because the types of partitions formed comprise of regions that cannot be considered as polyhedra with a fixed number of faces, as required by Vapnik-Chevronenkis classes of sets in Breiman et: al:[4]. <p> The results are also plotted in Figure 3.2 The kernel smooth performs better that the segmentation model as the smoothness of the image is increased. 1 e:g: equations (12.8) and (12.9) <ref> [4, page 322] </ref> Image Segmentation 8 Blurring (h) 0 10 40 Segmentation 2.53 (.13) 0.65 (.02) 0.55 (.05) Kernel 0.47 (.01) 0.62 (.01) 0.83 (.02) Table 1. Estimates rates of estimation for the segmentation algorithm and a kernel smoother for the images shown in Figure 3.2.
Reference: [5] <author> Carson R.E. Yan Y. Daube-Witherspoon M.E. Freedman N. Bacharach S.L. Herscov-itch P. </author> <title> An approximation formula for PET region-of-interest values. </title> <journal> IEEE Trans. Med. Imag., </journal> <volume> 12 </volume> <pages> 240-251, </pages> <year> 1993. </year>
Reference-contexts: In a number of empirical investigations, reconstructed PET data have been shown to be consistent with a scaled Poisson distribution, at least the variance is proportional to the mean <ref> [5, 12] </ref>. The image data sets of dimension 125 fi 125 were obtained by simulating realizations from an inhomogeneous Poisson process with mean proportional to an underlying fixed image, (i; j) for i; j = 1; 2; : : :125. The underlying image is shown in Figure 3.1 (True). <p> The marginal distribution of residuals shows a positive skewness, which is probably a result of the well-known pseudo-Poisson character of reconstructed PET data <ref> [5] </ref>. The horizontally and vertically averaged serial auto-correlation plots of the residual image shows a strong substantial degree of dependence between pixels up to a lag of 5 pixels. The dimension of the pixels is 2.1mm.
Reference: [6] <author> Chambers J.M. Hastie T.J. </author> <title> Statistical Models in S. </title> <booktitle> Wadsworth International Group, </booktitle> <address> Pacific Grove CA. </address> <year> 1992. </year>
Reference-contexts: Part of the problem is that piecewise constant segmentation model has trouble approximating even very simple smooth function. This is also true of nonparametric regression estimators based on CART, for example Figure 9.1 of Chambers and Hastie <ref> [6] </ref> illustrates the difficulty that a CART model has in approximating a simple linear relation. An approach to addressing this problem while maintaining the simplicity and interpretability of the CART model structure is suggested by Chaudhuri et: al:[7]. We have not pursued these approaches here.
Reference: [7] <author> Chaudhuri P., Huang M-C., Loh W-Y., and Yao R. </author> <title> Piecewise-Polynomial Regression Trees. </title> <journal> Statistica Sinica, </journal> <volume> 4 </volume> <pages> 143-167, </pages> <year> 1994. </year>
Reference: [8] <author> Chen S-Y., Lin W-C., and Chen C-T. </author> <title> Split-and-merge image segmentation based on localized feature analysis and statistical tests. Graphical Models and Image Processing, </title> <booktitle> 53 </booktitle> <pages> 457-475, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Images in which there are several observations per pixel is a common data type in many fields of science and engineering <ref> [1, 8, 17, 23] </ref>. With these multi-channel images, segmentation has often been found useful for analysis. Segmentation has the ability to capture features that are not readily apparent from a sequence of single channel views of the data. <p> Even with single channel images segmentation can be a useful either as a way to organize an understanding of local homogeneity characteristics or as aid to identifying and quantifying features of primary interest <ref> [8] </ref>. The goals of segmentation are often not clearly specified which leads to a certain amount of difficulty in attempting to understand alternative approaches [8, 17]. Two main varieties of image segmentation are commonly used: (i) Threshold Methods and (ii) Region Based Methods. <p> The goals of segmentation are often not clearly specified which leads to a certain amount of difficulty in attempting to understand alternative approaches <ref> [8, 17] </ref>. Two main varieties of image segmentation are commonly used: (i) Threshold Methods and (ii) Region Based Methods. A more detailed taxonomy appears in the recent article by Adams and Bischof [1]. <p> This can make the interpretation of structures identified by the segmentation difficult [9]. Region based methods impose direct spatial contiguity constraints on image segments. A range of alternative approaches for achieving this have been proposed. Amoung the most popular are so-called split-and-merge techniques <ref> [1, 8, 15] </ref>. As the name suggests, split-and-merge segmentation algorithms comprise of two steps: splitting and merging. Splitting is used to decompose the image into homogeneous subsets and an associated hierarchical tree-based data structure. <p> Splitting is a process a kin to tree growing and merging similar to pruning in CART [4]. However, there are some important differences: Probably due the large number of cases (pixels) the splitting process is not optimized as in CART. For example, the algorithm of Chen, Lin and Chen <ref> [8] </ref> involves recursive division of rectangular regions of the image into four sub-regions each comprising (approximately) one quarter of the number of pixels in the parent region. This leads to quad-trees as opposed to the binary-trees of CART.
Reference: [9] <author> Choi H.S. Haynor D.R. and Kim Y. </author> <title> Multivariate tissue classification of MRI images for 3-d volume reconstruction a statistical approach. </title> <booktitle> SPIE Medical Imaging III: Image Processing, </booktitle> <volume> 1092 </volume> <pages> 183-193, </pages> <year> 1989. </year>
Reference-contexts: This can make the interpretation of structures identified by the segmentation difficult <ref> [9] </ref>. Region based methods impose direct spatial contiguity constraints on image segments. A range of alternative approaches for achieving this have been proposed. Amoung the most popular are so-called split-and-merge techniques [1, 8, 15]. As the name suggests, split-and-merge segmentation algorithms comprise of two steps: splitting and merging.
Reference: [10] <author> Friedman J.H. </author> <title> Multivariate adaptive regression splines (with discussion). </title> <journal> Ann. Statis., </journal> <volume> 19 </volume> <pages> 1-140, </pages> <year> 1991. </year>
Reference-contexts: Experimentation with alternative strategies for simplifying model complexity in the presence of blurring included adaptation of the 1-SE rule proposed in Breiman et: al:[4], as well as some variants of generalized cross-validation similar to those used in the MARS methodology of Friedman <ref> [10] </ref>. The blocking approach appeared to have the greatest promise in our simulations and also seemed more readily adaptable to real PET data.
Reference: [11] <author> Hart J.D. </author> <title> Kernel regression estimation with time series errors. </title> <journal> J. Royal Statist. Soc. B, </journal> <volume> 53 </volume> <pages> 173-187, </pages> <year> 1991. </year>
Reference-contexts: However it is important to appreciate that the choice of segmentation model is then not quite objective anymore. Similar difficulties have been noted in attempts to adaptively choose regularization parameters in 1-dimensional smoothers when the data are correlated <ref> [2, 11] </ref>. Image Segmentation 6 3 Numerical Simulation Experiments.
Reference: [12] <author> Haynor D.R. and Woods S.D. </author> <title> Resampling estimates of precision in emission tomography. </title> <journal> IEEE Trans. on Medical Imaging, </journal> <volume> MI-8: </volume> <pages> 337-343, </pages> <year> 1989. </year>
Reference-contexts: In a number of empirical investigations, reconstructed PET data have been shown to be consistent with a scaled Poisson distribution, at least the variance is proportional to the mean <ref> [5, 12] </ref>. The image data sets of dimension 125 fi 125 were obtained by simulating realizations from an inhomogeneous Poisson process with mean proportional to an underlying fixed image, (i; j) for i; j = 1; 2; : : :125. The underlying image is shown in Figure 3.1 (True).
Reference: [13] <author> Hoffman B.D. Ficke D.C. Holmes T.J. Politte D. and Ter-Pogossian M.M. </author> <title> Image reconstruction of data from SUPER PETT 1: a first generation time-of-flight positron emission tomograph. </title> <journal> IEEE Trans. Nucl. Sci., </journal> <volume> NS-33:428-434, </volume> <year> 1986. </year>
Reference-contexts: Emisson computed reconstructions of the activity distribution in the phantom integrated over 5 minutes time frames were acquired for a period of an hour on the UWPET. The reconstruction method was the standard confidence-weighted filtered backprojection algorithm <ref> [13] </ref>. This lead to a data set with a total of 13 images each of dimension 216 fi 216. The second image in the series was lost. The total uptake scan, i:e: sum of the remaining twelve images, over a 192 fi 96 sub-region is presented in Figure 4.2.
Reference: [14] <author> Hoffman E.J., Cutler P.D., Digby W.M., and Mazziotta J.C. </author> <title> 3-D phantom to simulate cerebral blood flow and metabolic images for PET. </title> <journal> IEEE Trans. Nucl. Sci., </journal> <volume> NS-37: </volume> <pages> 616-620, </pages> <year> 1990. </year>
Reference: [15] <author> Horowitz S.L. and Pavlidis T. </author> <title> Picture segmentation by a directed split-and-merge procedure. </title> <booktitle> Proc. 2nd Int. Joint Conf. Pattern Recognit., </booktitle> <pages> 424-433, </pages> <year> 1974. </year> <title> Image Segmentation 15 </title>
Reference-contexts: This can make the interpretation of structures identified by the segmentation difficult [9]. Region based methods impose direct spatial contiguity constraints on image segments. A range of alternative approaches for achieving this have been proposed. Amoung the most popular are so-called split-and-merge techniques <ref> [1, 8, 15] </ref>. As the name suggests, split-and-merge segmentation algorithms comprise of two steps: splitting and merging. Splitting is used to decompose the image into homogeneous subsets and an associated hierarchical tree-based data structure.
Reference: [16] <institution> Lewellen T.K. Bice A.B. Harrison R.L. Pencke M.D. and Link J.M. Performance measurements of the SP3000/UW time-of-flight positron emission tomograph. IEEE Trans. Nucl. Sci., NS-35:665-669, </institution> <year> 1988. </year>
Reference-contexts: Section 4 presents analyses of physical phantom data sets from an actual positron tomograph the modified SP-3000 scanner <ref> [16] </ref>. These data sets arise from both transmission and emission computed tomography studies. Applications to some patient image sets are presented in section 5.
Reference: [17] <author> Marr D. </author> <title> Vision. </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1982. </year>
Reference-contexts: 1 Introduction Images in which there are several observations per pixel is a common data type in many fields of science and engineering <ref> [1, 8, 17, 23] </ref>. With these multi-channel images, segmentation has often been found useful for analysis. Segmentation has the ability to capture features that are not readily apparent from a sequence of single channel views of the data. <p> The goals of segmentation are often not clearly specified which leads to a certain amount of difficulty in attempting to understand alternative approaches <ref> [8, 17] </ref>. Two main varieties of image segmentation are commonly used: (i) Threshold Methods and (ii) Region Based Methods. A more detailed taxonomy appears in the recent article by Adams and Bischof [1].
Reference: [18] <author> Natterer F. </author> <title> Mathematics of Computerized Tomography. </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester, </address> <year> 1986. </year>
Reference-contexts: The acquired data was used to reconstruct an estimate of the attenuation distribution of the phantom. The mathematics of this reconstruction problem are the same as those of standard computerized tomography, see Natterer <ref> [18] </ref> for a review. Figure 4.1 (a) shows an image of a reconstructed attenuation data set. The attenuation is elevated on the phantom. Four mounting rods are seen as small discs outside the elliptical region.
Reference: [19] <author> O'Sullivan F., Muzi M., Spence A. and Graham M.M. </author> <title> An improved analysis technique for dual tracer PET studies with particular application to lumped constant imaging. </title> <institution> J. Nucl. Med. 33:944, </institution> <year> 1992. </year>
Reference-contexts: Previously this effect had been measured in an animal tumor model by Spence [27], for instance. Further analysis of the PET data using compartmental kinetic models enables one to construct a quantitative measure of the effect of interest for human brain tumors, in-vivo <ref> [19] </ref>.
Reference: [20] <author> O'Sullivan F., Pawitan Y., and Haynor D.R. </author> <title> Reducing negative artifacts in emission tomography reconstructions: post-processing filtered backprojection solutions. </title> <journal> IEEE Trans. Med. Imaging., </journal> <volume> 12 </volume> <month> 653-663 </month> <year> 1993. </year>
Reference-contexts: The efficiency is the ratio of the mean square errors achieved with K and ^ K. Standard deviations are in parentheses. Sensitivity to Image Blurr Smoothing is always used in the reconstruction of actual PET data <ref> [20] </ref> so the final images really represent blurred pictures of the truth. In order to examine the effect of blurring, a series of further simulations were carried out in which sample images generated from in Figure 3.2 (a), were subject to Gaussian blurring before being used for segmentation.
Reference: [21] <author> O'Sullivan F. </author> <title> Imaging radiotracer model parameters in PET: A mixture analysis approach. </title> <journal> IEEE Trans. Med. Imaging, </journal> <volume> 12 </volume> <pages> 399-412, </pages> <year> 1993. </year>
Reference-contexts: The motivation for this paper was to develop a segmentation algorithm for use in the analysis of data from dynamic positron emission tomography studies <ref> [21, 22] </ref>. A region-based method was of interest because it was felt it would facilitate the anatomic interpretation of results. A previous approach based on thresholding [21] was not unsatisfactory from this point of view. The region-based algorithm is described in section 2. <p> A region-based method was of interest because it was felt it would facilitate the anatomic interpretation of results. A previous approach based on thresholding <ref> [21] </ref> was not unsatisfactory from this point of view. The region-based algorithm is described in section 2. <p> For such models the texture over the elliptical region of the phantom is excessive. A 5 region thresholded segmentation of the data set using the algorithm described in O'Sullivan <ref> [21] </ref> is included for comparison. Not surprisingly, the result is inferior to the region based segmentation the thresholded image show an artifactual pattern over the main body of the phantom. <p> Segmentation is a key element in the implementation of analysis tools for imaging kinetic model parameters on a pixel-by-pixel basis derived from PET <ref> [21, 22] </ref>. 5.2 Magnetic Resonance Images (MRI) of a Human Brain A set of three magnetic resonance images (proton density, T1-weighted and T2-weighted) from a human brain study were considered next. The data come from a cross-sectional slice of a head of a normal volunteer.
Reference: [22] <author> O'Sullivan F. </author> <title> Metabolic images from dynamic positron emission tomography studies. </title> <journal> Statistical Methods in Medical Research, </journal> <volume> 3 </volume> <pages> 87-101, </pages> <year> 1994. </year>
Reference-contexts: The motivation for this paper was to develop a segmentation algorithm for use in the analysis of data from dynamic positron emission tomography studies <ref> [21, 22] </ref>. A region-based method was of interest because it was felt it would facilitate the anatomic interpretation of results. A previous approach based on thresholding [21] was not unsatisfactory from this point of view. The region-based algorithm is described in section 2. <p> The use of the Poisson distribution is motivated by our interest in applying the segmentation method to data from PET scans <ref> [22] </ref>. In a number of empirical investigations, reconstructed PET data have been shown to be consistent with a scaled Poisson distribution, at least the variance is proportional to the mean [5, 12]. <p> Segmentation is a key element in the implementation of analysis tools for imaging kinetic model parameters on a pixel-by-pixel basis derived from PET <ref> [21, 22] </ref>. 5.2 Magnetic Resonance Images (MRI) of a Human Brain A set of three magnetic resonance images (proton density, T1-weighted and T2-weighted) from a human brain study were considered next. The data come from a cross-sectional slice of a head of a normal volunteer.
Reference: [23] <author> Pavlidis T. and Liow Y-T. </author> <title> Integrating region growing and edge detection. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 12 </volume> <pages> 225-233, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Images in which there are several observations per pixel is a common data type in many fields of science and engineering <ref> [1, 8, 17, 23] </ref>. With these multi-channel images, segmentation has often been found useful for analysis. Segmentation has the ability to capture features that are not readily apparent from a sequence of single channel views of the data.
Reference: [24] <author> Phelps M.E. Huang S.C. Hoffman E.J. Selin C Sokoloff L and Kuhl D.E. </author> <title> Tomographic measurement of local cerebral glucose metabolic rate in humans with [F-18]2-Fluoro-2-deoxy-D-glucose: validation of method Ann. </title> <journal> Neurol., </journal> <volume> 6 </volume> <pages> 371-388, </pages> <year> 1979. </year>
Reference: [25] <author> Politte D., and Snyder D. </author> <title> Corrections for accidental coincidences and attenuation in ML image reconstruction. </title> <journal> IEEE Trans. on Medical Imaging, </journal> <volume> 10 </volume> <pages> 82-89, </pages> <year> 1991. </year>
Reference: [26] <author> Snyder D.L. Thomas L.J. and Ter-Pogossian M.M. </author> <title> A mathematical model for positron emission tomography systems having time of flight measurement. </title> <journal> IEEE Trans. Nucl. Sci., </journal> <volume> 28 </volume> <pages> 3575-3581, </pages> <year> 1981. </year>
Reference: [27] <author> Spence A.M. Graham M.M Muzi M. Abbott G.L. Krohn K.A. Kapoor R. and Woods S.D. </author> <title> Deoxyglucose lumped constant estimated in a transplanted rat astro-cytic glioma by the hexose utilization index. </title> <journal> J. Cereb. Blood Flow Metab., </journal> <volume> 10 </volume> <pages> 190-198, </pages> <year> 1990. </year>
Reference-contexts: At the University of Washington PET center an investigation of alternate tracers, F-18 labeled deoxyglucose (FDG) and C-11 labeled glucose (GLC), for measuring glucose utilization is being carried out by a group lead by Dr. Spence <ref> [27] </ref>. The imaging protocol involves bolus injections of the GLC and FDG tracers, separated by between 1 and 2 hours. The long separation is to allow the GLC tracer to decay before the FDG is injected. The data are time-binned similar to the simulations in section 4.2. <p> Previously this effect had been measured in an animal tumor model by Spence <ref> [27] </ref>, for instance. Further analysis of the PET data using compartmental kinetic models enables one to construct a quantitative measure of the effect of interest for human brain tumors, in-vivo [19].
Reference: [28] <author> Sprawls P. </author> <title> Physical Principles of Medical Imaging. </title> <publisher> Aspen Publishers, </publisher> <year> 1987. </year>
Reference-contexts: This is not based on any information regarding the intrinsic resolution of the images, as we were able to do with the PET analyses. In MRI resolution depends on various parameters such as magnetic strength, imaging time and pulse repetition <ref> [28] </ref>. Although this diminishes the scientific value of the segmentation result, from the point of view of appreciating the complex structures which the region based segmentation model can capture, it seems interesting.
Reference: [29] <author> Stone C.J. </author> <title> Optimal global rates of convergence for nonparametric regression. </title> <journal> Ann. Statist., </journal> <volume> 13 </volume> <pages> 689-705, </pages> <year> 1982. </year>
Reference-contexts: This contrasts with simpler non-parametric regression estimators which can be approximated in terms of linear operations such as kernel smoothers and about which there is an extensive collection of easily verifyable results concerning rates of convergence of such estimators in a variety of norms, see Stone <ref> [29] </ref> for example. To develop some insight into the situation, we generated a sequence of 100 realizations from our simulation model with counts ranging from N c = 10 3 to N c = 10 6 . <p> This suggests that the error for the optimal segmentation as a function of counts follows an asymptotic power law, similar to what one might expect to see with more well studied nonparametric function estimators <ref> [29] </ref>, e:g: log (Error N c ()) = A () r () log (N c ) : Here slope parameter r () is the rate of estimation. In general the rate and the intercept depend on the underlying function, .

References-found: 29

