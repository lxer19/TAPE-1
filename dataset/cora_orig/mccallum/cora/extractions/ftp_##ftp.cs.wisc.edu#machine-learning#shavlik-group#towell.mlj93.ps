URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/towell.mlj93.ps
Refering-URL: http://www.cs.wisc.edu/~shavlik/abstracts/towell.mlj93.ps.abstract.html
Root-URL: 
Title: Extracting Refined Rules from Knowledge-Based Neural Networks representational shift rule extraction from neural networks Running
Author: Geoffrey G. Towell Jude W. Shavlik 
Keyword: theory refinement  
Address: 1210 West Dayton Street Madison, Wisconsin 53706  College Road East, Princeton, NJ, 08540.  
Affiliation: University of Wisconsin  
Note: Originally submitted to Machine Learning 8/91 Accepted 11/92  integrated learning  Currently at Siemens Corporate Research, 755  Please direct all correspondence to this address.  
Email: towell@learning.siemens.com shavlik@cs.wisc.edu  Email: towell@learning.siemens.com.  
Phone: (608) 262-6613  
Abstract: Neural networks, despite their empirically-proven abilities, have been little used for the refinement of existing knowledge because this task requires a three-step process. First, knowledge must be inserted into a neural network. Second, the network must be refined. Third, the refined knowledge must be extracted from the network. We have previously described a method for the first step of this process. Standard neural learning techniques can accomplish the second step. In this paper, we propose and empirically evaluate a method for the final, and possibly most difficult, step. Our method efficiently extracts symbolic rules from trained neural networks. The four major results of empirical tests of this method are that the extracted rules: (1) closely reproduce the accuracy of the network from which they are extracted; (2) are superior to the rules produced by methods that directly refine symbolic rules; (3) are superior to those produced by previous techniques for extracting rules from trained neural networks; (4) are "human comprehensible." Thus, this method demonstrates that neural networks can be used to effectively refine symbolic knowledge. Moreover, the rule-extraction technique developed herein contributes to the understanding of how symbolic and connectionist approaches to artificial intelligence can be profitably integrated. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Berenji, H. R. </author> <year> (1991). </year> <title> Refinement of approximate reasoning-based controllers by reinforcement learning. </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop (pp. </booktitle> <pages> 475-479). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The second assumption is that training does not significantly alter the meaning of units. By making this assumption, the methods are able to attach labels to extracted 2 Exceptions to this generalization include a method proposed by Bochereau and Bourgine (1990) and most methods for extracting fuzzy rules <ref> (e.g., Berenji, 1991) </ref>.
Reference: <author> Bochereau, L. & Bourgine, P. </author> <year> (1990). </year> <title> Extraction of semantic features and logical rules from a multilayer neural network. </title> <booktitle> International Joint Conference on Neural Networks (Vol. </booktitle> <pages> 2) (pp. 579-582). </pages> <address> Washington, D.C.: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Bruner, J. S., Goodnow, J. J., & Austin, G. A. </author> <year> (1956). </year> <title> A Study of Thinking. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference-contexts: On the other hand, the rules Subset extracts are much less likely to be comprehensible. A second important global statistic is the number of antecedents per rule. If this value is large, individual rules are unlikely to be understandable <ref> (Bruner et al., 1956) </ref>. Furthermore, negated antecedents add to the difficulty of evaluating rules (Nessier & Weene, 1962). However, the effects of negated antecedents are difficult to quantify. Weighted antecedents, such as those appearing in MofN rules and which implicitly appear in trained networks, cloud the picture further.
Reference: <author> Dzeroski, S. & Lavrac, N. </author> <year> (1991). </year> <title> Learning relations from noisy examples: An empirical comparison of LINUS and FOIL. </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop (pp. </booktitle> <pages> 399-402). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: examines the meanings of individual rules, includes samples of the rules extracted from trained KNNs by both Subset and MofN. 4.3.1 Systems and methodology In addition to comparing our MofN algorithm to Subset, we compare MofN to three "symbolic" algorithms: Either (Ourston & Mooney, 1990), C4.5 (Quinlan, 1987), and Linus <ref> (Dzeroski & Lavrac, 1991) </ref>. The first of these algorithms, Either (Ourston & Mooney, 1990), is a method for empirically adapting a set of propositional rules so that they are correct on the training examples.
Reference: <author> Fahlman, S. E. & Lebiere, C. </author> <year> (1989). </year> <booktitle> The cascade-correlation learning architecture. Advances in Neural Information Processing Systems (Vol. </booktitle> <pages> 2) (pp. 524-532). </pages> <address> Denver, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference: <author> Fisher, D. H. & McKusick, K. B. </author> <year> (1989). </year> <title> An empirical comparison of ID3 and backpropagation. </title> <booktitle> Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 788-793). </pages> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Where possible, simplify rules to eliminate superfluous weights and thresholds. ered by Subset often contain M-of-N style concepts. Further support for this method comes from experiments that indicate neural networks are good at learning M-of-N concepts <ref> (Fisher & McKusick, 1989) </ref>, as well as experiments with a variant of ID3 that show a bias towards M-of-N style concepts is useful (Murphy & Pazzani, 1991).
Reference: <author> Fu, L. M. </author> <year> (1991). </year> <title> Rule learning by searching on adapted nets. </title> <booktitle> Proceedings of the Ninth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 590-595). </pages> <address> Anaheim, CA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: This considerably reduces the size of the search space <ref> (Fu, 1991) </ref>. Finally, note that short of exactly copying a unit and its links, there is no way to limit the kinds of differences that extracted rules will have from a network of reasonable complexity.
Reference: <author> Goldman, S. A. & Kearns, M. J. </author> <year> (1991). </year> <title> On the complexity of teaching. </title> <booktitle> Proceedings of the Fourth Annual Workshop on Computational Learning Theory (pp. </booktitle> <pages> 303-314). </pages> <address> Santa Cruz, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: section is `how difficult is it to recover the correct domain theory when provided with a theory that is not quite correct?' We define difficulty as the average size of the training set needed to correctly identify the entire population. (This definition of difficulty is similar to the teaching dimension <ref> (Goldman & Kearns, 1991) </ref> except that teaching dimension is not learning-system specific.) These experiments compare only the ability of a KNN to learn a concept to the ability of MofN and Subset to extract rules that express the concept. We modify the domain theories in three ways.
Reference: <author> Harley, C. B. & Reynolds, R. P. </author> <year> (1987). </year> <title> Analysis of E. coli promoter sequences. </title> <journal> Nucleic Acids Research, </journal> <volume> 15, </volume> <pages> 2343-2361. </pages>
Reference: <author> Hartigan, J. A. </author> <year> (1975). </year> <title> Clustering Algorithms. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference-contexts: Backpropagation training tends to group links in KNNs into loose clusters rather than the equivalence classes assumed by the MofN algorithm. 3 Hence, the first step of MofN creates equivalence classes. We do this by clustering links using a standard clustering method; the join algorithm <ref> (Hartigan, 1975) </ref>. This method operates by successively combining the two closest clusters; it starts which each cluster holding a single link. Clustering stops when no pair of clusters is closer than a set distance (MofN uses 0.25). Step 2, averaging.
Reference: <author> Hawley, D. K. & McClure, W. R. </author> <year> (1983). </year> <title> Compilation and analysis of escherichia coli promoter DNA sequences. </title> <journal> Nucleic Acids Research, </journal> <volume> 11, </volume> <pages> 2237-2255. </pages>
Reference: <author> Hayashi, Y. </author> <year> (1990). </year> <title> A neural expert system with automated extraction of fuzzy if-then rules. </title> <booktitle> Advances in Neural Information Processing Systems (Vol. </booktitle> <pages> 3) (pp. 578-584). </pages> <address> Denver, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference: <author> Hinton, G. E. </author> <year> (1989). </year> <title> Connectionist learning procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 185-234. </pages>
Reference-contexts: classification occurs for five presentations of every training example. (The last termination criterion is based upon Fahlman and Lebiere's (1989) "patience" metric.) Following Hinton's (1989) suggestion for improved network interpretability, all weights are subject to gentle "decay" during training. 6 In addition, networks are trained using the cross-entropy error function <ref> (Hinton, 1989) </ref>, as our experience indicates that it is better able to handle the type of errors that occur in KNNs than the standard error function (Rumelhart et al., 1986). During testing, examples are considered correctly classified when all outputs are within 0.5 of correct.
Reference: <author> Judd, S. </author> <year> (1988). </year> <title> On the complexity of loading shallow neural networks. </title> <journal> Journal of Complexity, </journal> <volume> 4, </volume> <pages> 177-192. </pages>
Reference-contexts: Moreover, measuring time with respect to the number of links to each unit, Subset is an exponential algorithm whereas MofN is 5 Training some simple classes of neural networks has been proven NP-complete <ref> (Judd, 1988) </ref>. Hinton (1989) suggests that, in practice, backpropagation usually runs in O ((u fi l) 3 ) time. Towell & Shavlik Extracting Rules 13 approximately cubic.
Reference: <author> Koudelka, G. B., Harrison, S. C., & Ptashne, M. </author> <year> (1987). </year> <title> Effect of non-contacted bases on the affinity of 434 operator for 434 repressor and Cro. </title> <journal> Nature, </journal> <volume> 326, </volume> <month> 886-888. </month> <title> Towell & Shavlik Extracting Rules 36 Le Cun, </title> <editor> Y., Denker, J. S., & Solla, S. A. </editor> <year> (1989). </year> <title> Optimal brain damage. </title> <booktitle> Advances in Neural Information Processing Systems (Vol. </booktitle> <pages> 2) (pp. 598-605). </pages> <address> Denver, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference-contexts: The conformation rules are also dropped Either and are not often used by Linus. This suggests that dropping these rules is not an artifact of our method but rather that DNA nucleotides outside the minus35 and minus10 regions are less important than the conformation hypothesis <ref> (Koudelka et al., 1987) </ref> suggests. Hence, we demonstrate that machine learning methods can provide valuable evidence confirming or refuting biological theories. In general, the rules MofN extracts confirm the importance of the bases identified in the initial rules.
Reference: <author> Masuoka, R., Watanabe, N., Kawamura, A., Owada, Y., & Asakawa, K. </author> <year> (1990). </year> <title> Neurofuzzy system | fuzzy inference using a structured neural network. </title> <booktitle> Proceedings of the International Conference on Fuzzy Logic & Neural Networks (pp. </booktitle> <pages> 173-177). </pages> <address> Iizuka, Japan. </address>
Reference: <author> McDermott, J. </author> <year> (1982). </year> <title> R1: A rule-based configurer of computer systems. </title> <journal> Artificial Intelligence, </journal> <volume> 19. </volume>
Reference-contexts: The settings we use result in finding about 300 rules in each of the real-world domains we studied. In general, more accurate reproduction of KNNs require many more rules. While Subset extracts a large set of rules, it is smaller than many handcrafted expert systems <ref> (e.g., McDermott, 1982) </ref>. Hence, Subset delivers sets of rules that are, at least potentially, tractable. However, these rules tend to hide significant structures in trained networks.
Reference: <author> McMillan, C., Mozer, M. C., & Smolensky, P. </author> <year> (1991). </year> <title> The connectionist scientist game: Rule extraction and refinement in a neural network. </title> <booktitle> Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society. </booktitle> <address> Chicago, IL: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Miller, G. A. </author> <year> (1956). </year> <title> The magical number seven, plus or minus two: Some limits on our capacity for processing information. </title> <journal> Psychological Review, </journal> <volume> 63, </volume> <pages> 81-97. </pages>
Reference-contexts: On this measure, as with rule-set size, the symbolic methods are the clear winners. The MofN rules are slightly larger than Subset rules and contain more negative antecedents. Still, both methods return rules that are well within the limits of human comprehensibility <ref> (Miller, 1956) </ref> but recall MofN extracts many fewer rules. Individual Comprehensibility. Global statistics, such as those just discussed, are sufficient to indicate whether or not a whole rule set is likely to be comprehensible.
Reference: <author> Mozer, M. C. & Smolensky, P. </author> <year> (1988). </year> <title> Skeletonization: A technique for trimming the fat from a network via relevance assessment. </title> <booktitle> Advances in Neural Information Processing Systems (Vol. </booktitle> <pages> 1) (pp. 107-115). </pages> <address> Denver, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference: <author> Murphy, P. M. & Pazzani, M. J. </author> <year> (1991). </year> <title> ID2-of-3: Constructive induction of N-of-M concepts for discriminators in decision trees. </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop (pp. </booktitle> <pages> 183-187). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Further support for this method comes from experiments that indicate neural networks are good at learning M-of-N concepts (Fisher & McKusick, 1989), as well as experiments with a variant of ID3 that show a bias towards M-of-N style concepts is useful <ref> (Murphy & Pazzani, 1991) </ref>. Finally, note that purely conjunctive rules result if N = M , while a set of disjunctive rules results when M = 1; hence, using M-of-N rules does not restrict generality.
Reference: <author> Nessier, U. & Weene, P. </author> <year> (1962). </year> <title> Hierarchies in concept attainment. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 64, </volume> <pages> 640-645. </pages>
Reference-contexts: A second important global statistic is the number of antecedents per rule. If this value is large, individual rules are unlikely to be understandable (Bruner et al., 1956). Furthermore, negated antecedents add to the difficulty of evaluating rules <ref> (Nessier & Weene, 1962) </ref>. However, the effects of negated antecedents are difficult to quantify. Weighted antecedents, such as those appearing in MofN rules and which implicitly appear in trained networks, cloud the picture further.
Reference: <author> Noordewier, M. O., Towell, G. G., & Shavlik, J. W. </author> <year> (1991). </year> <title> Training knowledge-based neural networks to recognize genes in DNA sequences. </title> <booktitle> Advances in Neural Information Processing Systems (Vol. </booktitle> <pages> 3) (pp. 530-536). </pages> <address> Denver, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference: <author> Nowlan, S. J. & Hinton, G. E. </author> <year> (1991). </year> <title> Simplifying neural networks by soft weight-sharing. </title> <booktitle> Advances in Neural Information Processing Systems (Vol. </booktitle> <pages> 4) (pp. 993-1000). </pages> <address> Denver, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference: <author> Ourston, D. </author> <year> (1991). </year> <title> Using Explanation-Based and Empirical Methods in Theory Revision. </title> <type> PhD thesis, </type> <institution> Austin, TX: Deptartment of Computer Sciences, University of Texas. </institution>
Reference: <author> Ourston, D. & Mooney, R. J. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 815-820). </pages> <address> Boston, MA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: The final part of this section, which examines the meanings of individual rules, includes samples of the rules extracted from trained KNNs by both Subset and MofN. 4.3.1 Systems and methodology In addition to comparing our MofN algorithm to Subset, we compare MofN to three "symbolic" algorithms: Either <ref> (Ourston & Mooney, 1990) </ref>, C4.5 (Quinlan, 1987), and Linus (Dzeroski & Lavrac, 1991). The first of these algorithms, Either (Ourston & Mooney, 1990), is a method for empirically adapting a set of propositional rules so that they are correct on the training examples. <p> rules extracted from trained KNNs by both Subset and MofN. 4.3.1 Systems and methodology In addition to comparing our MofN algorithm to Subset, we compare MofN to three "symbolic" algorithms: Either <ref> (Ourston & Mooney, 1990) </ref>, C4.5 (Quinlan, 1987), and Linus (Dzeroski & Lavrac, 1991). The first of these algorithms, Either (Ourston & Mooney, 1990), is a method for empirically adapting a set of propositional rules so that they are correct on the training examples. C4.5 (Quinlan, 1987), is distinct from the other algorithms we compare, in that it builds decision trees without using any background knowledge.
Reference: <author> Pazzani, M. </author> <year> (1992). </year> <title> When prior knowledge hinders learning. Workshop Notes of Constraining Learning with Prior Knowledge (pp. </title> <address> 44-52). San Jose, CA. </address>
Reference-contexts: While the observation that prior knowledge can hinder learning is significant, the observation has been previously made <ref> (Pazzani, 1992) </ref> and is not the focus of this paper. (Not surprisingly, when the KNN was unable to learn the concept, MofN and Subset rarely extracted rules that expressed the concept.) In conclusion, these experiments show that when a KNN is capable of learning the rules that underlie a concept, the
Reference: <author> Pratt, L. Y., Mostow, J., & Kamm, C. A. </author> <year> (1991). </year> <title> Direct transfer of learned information among neural networks. </title> <booktitle> Proceedings of the Ninth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 584-589). </pages> <address> Anaheim, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1987). </year> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27, </volume> <pages> 221-234. </pages> <note> Towell & Shavlik Extracting Rules 37 Rumelhart, </note> <author> D. E., Hinton, G. E., & Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart & J. L. McClelland (Eds.), </editor> <booktitle> Parallel Distributed Processing: Explorations in the microstructure of cognition. Volume 1: Foundations. </booktitle> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: of this section, which examines the meanings of individual rules, includes samples of the rules extracted from trained KNNs by both Subset and MofN. 4.3.1 Systems and methodology In addition to comparing our MofN algorithm to Subset, we compare MofN to three "symbolic" algorithms: Either (Ourston & Mooney, 1990), C4.5 <ref> (Quinlan, 1987) </ref>, and Linus (Dzeroski & Lavrac, 1991). The first of these algorithms, Either (Ourston & Mooney, 1990), is a method for empirically adapting a set of propositional rules so that they are correct on the training examples. C4.5 (Quinlan, 1987), is distinct from the other algorithms we compare, in that <p> MofN to three "symbolic" algorithms: Either (Ourston & Mooney, 1990), C4.5 <ref> (Quinlan, 1987) </ref>, and Linus (Dzeroski & Lavrac, 1991). The first of these algorithms, Either (Ourston & Mooney, 1990), is a method for empirically adapting a set of propositional rules so that they are correct on the training examples. C4.5 (Quinlan, 1987), is distinct from the other algorithms we compare, in that it builds decision trees without using any background knowledge. However, it extracts rules from those trees so like all other systems we consider, the final result of C4.5 is a set of rules. <p> The monks problems consist of a population of 432 examples defined over the six 7 There is also a large body of literature in "symbolic" machine learning which suggests that methods to reduce overfitting of the training set can improve generalization <ref> (e.g., Quinlan, 1987) </ref>. Towell & Shavlik Extracting Rules 26 features appearing at the top of Table 9. The first monks problem is to learn to classify the examples according to the domain theory appearing in the middle of Table 9. This domain theory is simply a disjunction of four conjunctions.
Reference: <author> Saito, K. & Nakano, R. </author> <year> (1988). </year> <title> Medical diagnostic expert system based on PDP model. </title> <booktitle> Proceedings of IEEE International Conference on Neural Networks (Vol. </booktitle> <pages> 1) (pp. 255-262). </pages> <address> San Diego, CA: </address> <publisher> IEEE. </publisher>
Reference: <author> Sestito, S. & Dillon, T. </author> <year> (1990). </year> <title> Using multi-layered neural networks for learning symbolic knowledge. </title> <booktitle> Proceedings of the Fourth Australian Joint Conference on Artificial Intelligence. </booktitle> <address> Perth, Australia: </address> <publisher> World Scientific. </publisher>
Reference: <author> Shavlik, J. W., Mooney, R. J., & Towell, G. G. </author> <year> (1991). </year> <title> Symbolic and neural net learning algorithms: An empirical comparison. </title> <journal> Machine Learning, </journal> <volume> 6, </volume> <pages> 111-143. </pages>
Reference-contexts: The rules generated by the Subset method are much worse. Perhaps the most interesting result on this dataset is that the MofN rules outperform the networks from which they came in terms of training set accuracy. Earlier tests <ref> (Towell & Shavlik, 1991) </ref> showed the error Towell & Shavlik Extracting Rules 19 Table 6: Fidelity of extracted rules to trained KNNs on training examples.
Reference: <author> Stormo, G. D. </author> <year> (1990). </year> <title> Consensus patterns in DNA. </title> <booktitle> Methods in Enzymology (Vol. 183). </booktitle> <address> Orlando, FL: </address> <publisher> Academic Press. </publisher>
Reference-contexts: While the rules extracted by MofN in Table 7 are somewhat murky, they are vastly more comprehensible than the network of 3000 links from which they were induced. Moreover, these rules can be rewritten in a form very similar to one used in the biological community, namely weight matrices <ref> (Stormo, 1990) </ref>. One major pattern is apparent in the rules extracted by both MofN and Subset. Specifically, the KNN learned to disregard conformation. The conformation rules are also dropped Either and are not often used by Linus.
Reference: <author> Sutton, R. S. </author> <year> (1986). </year> <title> Two problems with backpropagation and other steepest descent learning procedures for networks. </title> <booktitle> Program of the Eighth Annual Conference of the Cognitive Science Society (pp. </booktitle> <pages> 823-831). </pages> <address> Amherst, MA: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Thompson, K., Langley, P., & Iba, W. </author> <year> (1991). </year> <title> Using background knowledge in concept formation. </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop (pp. </booktitle> <pages> 554-558). </pages> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Thrun, S., Bala, J., Bloedorn, E., Bratko, I., Cestnik, B., Cheng, J., De Jong, K., Dzeroski, S., Fahlman, S., Fisher, D., Hamann, R., Kaufman, K., Keller, S., Kononenko, I., Kreuziger, J., Michalski, R., Mitchell, T., Pachowicz, P., Reich, Y., Vafaie, H., Van de Welde, W., Wenzel, W., Wnek, J., & Zhang, J. </author> <year> (1991). </year> <title> The MONK's Problem: A Performance Comparison of Different Learning Algorithms. </title> <type> (Technical Report CMU-CS-91-197), </type> <institution> Pittsburgh, PA: Carnegie Mellon. </institution>
Reference-contexts: Therefore, in this section we step away from the real-world, and look at two very artificial problems, the "monks problems" <ref> (Thrun et al., 1991) </ref>. In so doing, we gain control over the distance between the correct theory and the theory provided to the learning system.
Reference: <author> Towell, G. G. </author> <year> (1991). </year> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement, and Extraction. </title> <type> PhD thesis, </type> <institution> Madison, WI: Computer Sciences Department, University of Wisconsin. </institution> <note> (Available as Technical Report 1072). </note>
Reference-contexts: The rules generated by the Subset method are much worse. Perhaps the most interesting result on this dataset is that the MofN rules outperform the networks from which they came in terms of training set accuracy. Earlier tests <ref> (Towell & Shavlik, 1991) </ref> showed the error Towell & Shavlik Extracting Rules 19 Table 6: Fidelity of extracted rules to trained KNNs on training examples. <p> The two problems also share aspects that are not related to sequence analysis. For example, Towell & Shavlik Extracting Rules 32 the initial domain theory of both problems is overly specific. Empirical tests suggest that Kbann is slightly more effective when the domain theory is overly specific <ref> (Towell, 1991) </ref>. Hence, tests on a broader range of datasets are needed to prove the generality of the method. In addition to extending Kbann and the MofN method to address these limitations, we are currently working on a rule-extraction algorithm that operates during the training of a KNN.
Reference: <author> Towell, G. G. & Shavlik, J. W. </author> <year> (1991). </year> <title> Interpretation of artificial neural networks: Mapping knowledge-based neural networks into rules. </title> <booktitle> Advances in Neural Information Processing Systems (Vol. </booktitle> <pages> 4) (pp. 977-984). </pages> <address> Denver, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference-contexts: The rules generated by the Subset method are much worse. Perhaps the most interesting result on this dataset is that the MofN rules outperform the networks from which they came in terms of training set accuracy. Earlier tests <ref> (Towell & Shavlik, 1991) </ref> showed the error Towell & Shavlik Extracting Rules 19 Table 6: Fidelity of extracted rules to trained KNNs on training examples. <p> The two problems also share aspects that are not related to sequence analysis. For example, Towell & Shavlik Extracting Rules 32 the initial domain theory of both problems is overly specific. Empirical tests suggest that Kbann is slightly more effective when the domain theory is overly specific <ref> (Towell, 1991) </ref>. Hence, tests on a broader range of datasets are needed to prove the generality of the method. In addition to extending Kbann and the MofN method to address these limitations, we are currently working on a rule-extraction algorithm that operates during the training of a KNN.
Reference: <author> Towell, G. G., Shavlik, J. W., & Noordewier, M. O. </author> <year> (1990). </year> <title> Refinement of approximately correct domain theories by knowledge-based neural networks. </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 861-866). </pages> <address> Boston, MA: </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Thus, the approach we present makes possible the use of neural networks as the empirical learning algorithm underlying a rule-refinement system. The first link of our three-link chain is to insert knowledge, which need be neither complete nor correct, into a neural network using Kbann <ref> (Towell et al., 1990) </ref>. (Hereafter, networks created using Kbann will be referred to as Knowledge-based Neural Networks - KNNs.) This step changes the representation of the rules from symbolic to neurally-based, thereby making the rules refinable by standard neural learning methods. <p> As a measure, quality is at least two dimensional. First, the rules must accurately categorize examples that were not seen during training. If the rules lose the advantage in accuracy that Kbann provides over symbolic learning algorithms <ref> (Towell et al., 1990) </ref>, then there is little value in rule extraction. It would be simpler to use an "all symbolic" method to 6 That is, to the standard weight change function a term is added (0 &lt; &lt; 1). <p> The relative ease of this shift has resulted in a plethora of comparisons among empirical learning systems. Domain-specific knowledge is much more difficult to shift between representations. Our initial work with Kbann provided a method for shifting domain-specific knowledge in the form of propositional Horn clauses into neural networks <ref> (Towell et al., 1990) </ref>. This shift made the knowledge available to neural learning algorithms such as backpropagation. The result of our initial efforts were classifiers more accurate than those obtained using only training examples (Towell et al., 1990; Noordewier et al., 1991).
Reference: <author> Weiss, S. M. & Kulikowski, C. A. </author> <year> (1990). </year> <title> Computer Systems that Learn. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: More importantly, we show that the MofN method extracts rules that are equivalent to the networks at classifying testing examples. Accuracy. To assess the accuracy of each system we use ten repetitions of 10-fold cross-validation <ref> (Weiss & Kulikowski, 1990) </ref>. Figure 6 plots the average of our ten-fold cross-validation runs. For comparison, Figure 6 includes the accuracy of the trained KNNs prior to rule extraction (the bars labeled "Network").
References-found: 40

