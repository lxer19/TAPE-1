URL: http://www.cs.umn.edu/research/darpa/p_sparslib/psp/DOCS/short_paper.ps
Refering-URL: http://www.cs.umn.edu/research/darpa/p_sparslib/psp/DOCS/
Root-URL: http://www.cs.umn.edu
Email: malevsky@ncsa.uiuc.edu  
Phone: 2  
Title: Data Structures, Computational, and Communication Kernels for Distributed Memory Sparse Iterative Solvers  
Author: Yousef Saad and Andrei V. Malevsky 
Keyword: P-SPARSLIB, a library of distributed sparse iterative solvers.  
Address: 200 Union Street S.E., Minneapolis, MN 55455 USA  405 N. Mathews Ave., Urbana, Il 61801 USA;  
Affiliation: 1 University of Minnesota, Department of Computer Science,  National Center for Supercomputing Applications,  
Abstract: Domain Decomposition techniques constitute an important class of methods especially appropriate in a parallel computing environ ment, but only a few general purpose codes based on these techniques have been developed so far. In this work, we attempt to develop not only algorithms but also software libraries and tools to help in the parallel implementation of such techniques. These algorithms and tools form 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Ashby, S. F., and M. Seager: </author> <title> A proposed standard for iterative linear solvers. </title> <type> Technical report, </type> <institution> Lawrence Livermore National Laboratory (1990). </institution>
Reference-contexts: To further enhance flexibility, we found it extremely helpful to include an additional feature referred to as a `reverse communication mechanism' whose goal is to avoid passing data structures to the iterative solver <ref> [1] </ref>. The passing of a matrix can an be a heavy burden on the programmer since it is nearly impossible to find a data structure that will be suitable for all possible cases. The solution is not to pass the matrices in any form.
Reference: 2. <author> Beguelin, A., J. Dongarra, A. Geist, R. Manchek, K. Moore, and V. Sunderam: </author> <title> Tools for heterogeneous network computing, </title> <booktitle> In: Proceedings of the 6th SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> (1993) </year> <month> 854-862. </month>
Reference-contexts: We have also tried to make the code as machine-independent as possible to keep the bulk of the routines reusable if an architecture or a message-passing paradigm changes. We have not embraced any of the proposed message-passing standards such as PVM <ref> [2] </ref> or MPI [3] throughout the code. Instead, we have isolated the communications routines in order to be able to port them with minor efforts and to utilize the native libraries and other vendor-supplied software and hardware solutions.
Reference: 3. <author> Gropp, W., E. Lusk, and A. Skjellum: </author> <title> Using MPI: Portable Parallel Programming with the Message-Passing Interface, </title> <publisher> MIT Press, </publisher> <pages> 328 pp., </pages> <year> 1994. </year>
Reference-contexts: We have also tried to make the code as machine-independent as possible to keep the bulk of the routines reusable if an architecture or a message-passing paradigm changes. We have not embraced any of the proposed message-passing standards such as PVM [2] or MPI <ref> [3] </ref> throughout the code. Instead, we have isolated the communications routines in order to be able to port them with minor efforts and to utilize the native libraries and other vendor-supplied software and hardware solutions. <p> Many parallel computer manufacturers are starting to provide hardware and software support for performing global reduction operations efficiently. For instance, the reductions are performed on the CM-5 by a separate low-bandwidth and low-latency network. Global reductions are included in the MPI standard <ref> [3] </ref> and in the CRAY-T3D message-passing library (SHMEM). However, the global reductions must be coded employing the point-to-point communications for the PVM version.
Reference: 4. <author> Saad, Y., and M. H. Schultz: </author> <title> GMRES: a generalized minimal residual algorithm for solving nonsymmetric linear systems. </title> <journal> SIAM J. Sci. Statist. Comput. </journal> <month> 7 </month> <year> (1986) </year> <month> 856-869. </month>
Reference-contexts: The GMRES algorithm was introduced in <ref> [4] </ref> for solving general sparse nonsymmetric linear systems. Here, we would like to illustrate the implementation of these methods with only one such technique, namely the Flexible variant of the GMRES algorithm (FGMRES) [5]. The FGMRES allows the preconditioner to vary from step to step.
Reference: 5. <author> Saad, Y.: </author> <title> A flexible inner-outer preconditioned GMRES algorithm. </title> <journal> SIAM J. Sci. Statist. Comput. </journal> <month> 14 </month> <year> (1993) </year> <month> 461-469. </month> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: The GMRES algorithm was introduced in [4] for solving general sparse nonsymmetric linear systems. Here, we would like to illustrate the implementation of these methods with only one such technique, namely the Flexible variant of the GMRES algorithm (FGMRES) <ref> [5] </ref>. The FGMRES allows the preconditioner to vary from step to step. In our context, we would like to be able to use any secondary iterative procedure as a preconditioner, a feature which is quite helpful in DD methods or in any parallel computing implementation.
References-found: 5

