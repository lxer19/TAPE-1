URL: ftp://ftp.cs.columbia.edu/reports/reports-1997/cucs-015-97.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1997.html
Root-URL: http://www.cs.columbia.edu
Email: Email: fnayar,simonbg@cs.columbia.edu  
Title: A Theory of Catadioptric Image Formation  
Author: Shree K. Nayar and Simon Baker 
Keyword: Image formation, sensor design, sensor resolution, defocus blur.  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Pubnum: (Technical Report CUCS-015-97)  
Abstract: Conventional video cameras have limited fields of view which make them restrictive for certain applications in computational vision. A catadioptric sensor uses a combination of lenses and mirrors placed in a carefully arranged configuration to capture a much wider field of view. When designing a catadioptric sensor, the shape of the mirror(s) should ideally be selected to ensure that the complete catadioptric system has a single effective viewpoint. The reason a single viewpoint is so desirable is that it is a requirement for the generation of pure perspective images from the sensed image(s). In this paper, we derive and analyze the complete class of single-lens single-mirror catadioptric sensors which satisfy the fixed viewpoint constraint. Some of the solutions turn out to be degenerate with no practical value, while other solutions lead to realizable sensors. We also derive an expression for the spatial resolution of a catadioptric sensor, and include a preliminary analysis of the defocus blur caused by the use of a curved mirror. 
Abstract-found: 1
Intro-found: 1
Reference: [ Adelson and Bergen, 1991 ] <author> E.H. Adelson and J.R. Bergen. </author> <title> The plenoptic function and elements of early vision. </title> <editor> In Landy and Movshon, editors, </editor> <booktitle> Computational Models of Visual Processing, chapter 1. </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The direction of the light passing through this point may vary, but that is all. In other words, the catadioptric sensor can only sample the 5-D plenoptic function <ref> [ Adelson and Bergen, 1991 ] </ref> [ Gortler et al., 1996 ] at a single point in 3-D space. The fixed 3-D point at which a catadioptric sensor samples the plenoptic function is known as the effective viewpoint.
Reference: [ Gortler et al., 1996 ] <author> S.J. Gortler, R. Grzeszczuk, R. Szeliski, and M. Cohen. </author> <booktitle> The lumi-graph. In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 43-54. </pages> <publisher> ACM SIGGRAPH, </publisher> <year> 1996. </year>
Reference-contexts: The direction of the light passing through this point may vary, but that is all. In other words, the catadioptric sensor can only sample the 5-D plenoptic function [ Adelson and Bergen, 1991 ] <ref> [ Gortler et al., 1996 ] </ref> at a single point in 3-D space. The fixed 3-D point at which a catadioptric sensor samples the plenoptic function is known as the effective viewpoint.
Reference: [ Goshtasby and Gruver, 1993 ] <author> A. Goshtasby and W.A. Gruver. </author> <title> Design of a single-lens stereo camera system. </title> <journal> Pattern Recognition, </journal> <volume> 26(6) </volume> <pages> 923-937, </pages> <year> 1993. </year>
Reference-contexts: This approach to image capture is fast gaining in popularity (see, for example, [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , <ref> [ Goshtasby and Gruver, 1993 ] </ref> , [ Yamazawa et al., 1993 ] , [ Nalwa, 1996 ] , [ Nayar and Baker, 1997 ] , and [ Nayar, 1997 ] ). <p> On the other hand, in applications such as stereo where multiple viewpoints are a necessary requirement, the multiple views of a scene can be captured by a single camera using multiple planar mirrors. See, for example, <ref> [ Goshtasby and Gruver, 1993 ] </ref> . This brings us to the panoramic camera proposed by Nalwa [ Nalwa, 1996 ] . To ensure a single viewpoint while using multiple planar mirrors, Nalwa [ Nalwa, 1996 ] has arrived at a design that uses four separate imaging systems.
Reference: [ Hecht and Zajac, 1974 ] <author> E. Hecht and A. Zajac. </author> <title> Optics. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year> <month> 28 </month>
Reference-contexts: Since we know the geometry of the catadioptric sys 1 Dioptrics is the science of refracting elements (lenses) whereas catoptrics is the optics of reflecting surfaces (mirrors). The combination of refracting and reflecting elements is therefore referred to as cata-dioptrics <ref> [ Hecht and Zajac, 1974 ] </ref> . 1 tem, we can precompute this direction for each pixel. Therefore we can map the irradiance value measured by each pixel onto a plane at any distance from the viewpoint to form a perspective image. <p> It is a well known fact that a curved mirror increases image blur <ref> [ Hecht and Zajac, 1974 ] </ref> , and so in Section 4 we analyze the effect which the use of a curved mirror has on defocus blur. Two factors combine to cause blur in catadioptric systems: (1) the finite size of the lens, and (2) the curvature of the mirror. <p> Then, since the hyperboloid mirror satisfies the fixed viewpoint constraint, a ray of light from w which is reflected by the mirror at m passes directly through the center of the lens (i.e. the pinhole.) This ray of light is known as the principal ray <ref> [ Hecht and Zajac, 1974 ] </ref> . <p> When this happens there is defocus blur. The locus of the intersection of the incoming rays through l and the image plane as l varies over the lens is known as the blur region or region of confusion <ref> [ Hecht and Zajac, 1974 ] </ref> . 21 (v; ^ x; ^ y; ^ z) where ^ x and ^ y are orthogonal unit vectors in the plane z = 0. <p> angle of reflection, and (3) the normal n to the mirror at m 1 , and the two vectors l m 1 and w m 1 must be coplanar. 22 For an ideal thin lens, the blur region is circular and so is often referred to as the blur circle <ref> [ Hecht and Zajac, 1974 ] </ref> . As well shall see, for a catadioptric sensor using a curved mirror, the shape of the blur region is not, in general, circular. <p> First, the line through m 1 in the direction ~ lm 1 is extended to intersect the focused plane. By the thin lens law <ref> [ Hecht and Zajac, 1974 ] </ref> the focused plane is the plane: z = c v = c u f where f is the focal length of the lens and u is the distance from the focal plane to the image plane.
Reference: [ Hong, 1991 ] <author> J. Hong. </author> <title> Image based homing. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: A recently developed and effective way to enhance the field of view is to use mirrors in conjunction with lenses. This approach to image capture is fast gaining in popularity (see, for example, [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , <ref> [ Hong, 1991 ] </ref> , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Nalwa, 1996 ] , [ Nayar and Baker, 1997 ] , and [ Nayar, 1997 ] ). <p> The sphere has been used to enhance the field of view for landmark navigation <ref> [ Hong, 1991 ] </ref> . In this implementation, the pinhole is placed outside the sphere and so there is no single effective viewpoint.
Reference: [ Nalwa, 1996 ] <author> V.S. Nalwa. </author> <title> A true omnidirectional viewer. </title> <type> Technical report, </type> <institution> Bell Laboratories, </institution> <address> Holmdel, NJ 07733, USA, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: This approach to image capture is fast gaining in popularity (see, for example, [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , <ref> [ Nalwa, 1996 ] </ref> , [ Nayar and Baker, 1997 ] , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. <p> Recent work in this area has led to the development of a truly omnidirectional video camera with a spherical field of view [ Nayar, 1997 ] . As noted in [ Yamazawa et al., 1995 ] , <ref> [ Nalwa, 1996 ] </ref> , and [ Nayar, 1997 ] , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection). <p> This means that it is impossible to enhance the field of view using a single perspective camera and an arbitrary number of planar mirrors, while still respecting the fixed viewpoint constraint. If multiple cameras are used then solutions using multiple planar mirrors are possible <ref> [ Nalwa, 1996 ] </ref> . 10 not enhance the field of view, since, discounting occlusions, the same camera moved from p to v and reflected in the mirror would have exactly the same field of view. <p> See, for example, [ Goshtasby and Gruver, 1993 ] . This brings us to the panoramic camera proposed by Nalwa <ref> [ Nalwa, 1996 ] </ref> . To ensure a single viewpoint while using multiple planar mirrors, Nalwa [ Nalwa, 1996 ] has arrived at a design that uses four separate imaging systems. <p> See, for example, [ Goshtasby and Gruver, 1993 ] . This brings us to the panoramic camera proposed by Nalwa <ref> [ Nalwa, 1996 ] </ref> . To ensure a single viewpoint while using multiple planar mirrors, Nalwa [ Nalwa, 1996 ] has arrived at a design that uses four separate imaging systems. Four planar mirrors are arranged in a square-based pyramid and each of the four cameras is placed above one of the faces of the pyramid. <p> In these implementations the pinhole is placed quite some distance from the apex of the cone. It is easy to show that in such cases the viewpoint is no longer a single point <ref> [ Nalwa, 1996 ] </ref> . If the pinhole lies on the axis of the cone at a distance e from the apex of the cone, the locus of the effective viewpoint is a circle.
Reference: [ Nayar and Baker, 1997 ] <author> Shree K. Nayar and Simon Baker. </author> <title> Catadioptric image formation. </title> <booktitle> In Proceedings of the 1997 DARPA Image Understanding Workshop, </booktitle> <address> New Orleans, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: This approach to image capture is fast gaining in popularity (see, for example, [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Nalwa, 1996 ] , <ref> [ Nayar and Baker, 1997 ] </ref> , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation.
Reference: [ Nayar, 1988 ] <author> S.K. Nayar. Sphereo: </author> <title> Recovering depth using a single camera and two specular spheres. </title> <booktitle> In Proceedings of SPIE: Optics, Illumination, and Image Sensing for Machine Vision II, </booktitle> <month> November </month> <year> 1988. </year>
Reference-contexts: A recently developed and effective way to enhance the field of view is to use mirrors in conjunction with lenses. This approach to image capture is fast gaining in popularity (see, for example, <ref> [ Nayar, 1988 ] </ref> , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Nalwa, 1996 ] , [ Nayar and Baker, 1997 ] , and [ Nayar, 1997 ] ). <p> The locus is of comparable size to the mirror. Spheres have also been used in stereo applications <ref> [ Nayar, 1988 ] </ref> , but as described before multiple viewpoints are a requirement for stereo and hence the fixed viewpoint constraint is not critical. 14 2.3.4 Ellipsoidal Mirrors In Solution (17), when k &gt; 0 and c &gt; 0; we get the ellipsoidal mirror: 1 e z 2 + b
Reference: [ Nayar, 1997 ] <author> S.K. Nayar. </author> <title> Omnidirectional video camera. </title> <booktitle> In Proceedings of the 1997 DARPA Image Understanding Workshop, </booktitle> <month> May </month> <year> 1997. </year> <note> (A related paper will appear in CVPR 97). </note>
Reference-contexts: gaining in popularity (see, for example, [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Nalwa, 1996 ] , [ Nayar and Baker, 1997 ] , and <ref> [ Nayar, 1997 ] </ref> ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. Recent work in this area has led to the development of a truly omnidirectional video camera with a spherical field of view [ Nayar, 1997 ] <p> ] , and <ref> [ Nayar, 1997 ] </ref> ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. Recent work in this area has led to the development of a truly omnidirectional video camera with a spherical field of view [ Nayar, 1997 ] . As noted in [ Yamazawa et al., 1995 ] , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection). <p> Recent work in this area has led to the development of a truly omnidirectional video camera with a spherical field of view <ref> [ Nayar, 1997 ] </ref> . As noted in [ Yamazawa et al., 1995 ] , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection). <p> Under these limiting conditions, Equation (16) tends to: z = 2h As shown in <ref> [ Nayar, 1997 ] </ref> , this limiting case corresponds to orthographic projection. More over, in that setting the parabola does yield a practical omnidirectional sensor with a num 8 ber of advantageous properties. <p> shown in <ref> [ Nayar, 1997 ] </ref> , this limiting case corresponds to orthographic projection. More over, in that setting the parabola does yield a practical omnidirectional sensor with a num 8 ber of advantageous properties. In this paper we restrict attention to the perspective case and refer the reader to [ Nayar, 1997 ] for a discussion of the orthographic case.
Reference: [ Peri and Nayar, 1997 ] <author> V. Peri and S.K. Nayar. </author> <title> Generation of perspective and panoramic video from omnidirectional video. </title> <booktitle> In Proceedings of the 1997 DARPA Image Understanding Workshop, </booktitle> <address> New Orleans, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: This perspective image can subsequently be processed using the vast array of techniques developed in the field of computational vision which assume perspective projection. Moreover, if the image is to be presented to a human, as in <ref> [ Peri and Nayar, 1997 ] </ref> , it needs to be a perspective image in order to not appear distorted. Naturally, when the catadioptric imaging system is omnidirectional in its field of view, a single viewpoint permits the construction of panoramic images in addition to perspective ones.
Reference: [ Yagi and Kawato, 1990 ] <author> Y. Yagi and S. Kawato. </author> <title> Panoramic scene analysis with conic projection. </title> <booktitle> In Proceedings of the International Conference on Robots and Systems, </booktitle> <year> 1990. </year>
Reference-contexts: A recently developed and effective way to enhance the field of view is to use mirrors in conjunction with lenses. This approach to image capture is fast gaining in popularity (see, for example, [ Nayar, 1988 ] , <ref> [ Yagi and Kawato, 1990 ] </ref> , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , [ Yamazawa et al., 1993 ] , [ Nalwa, 1996 ] , [ Nayar and Baker, 1997 ] , and [ Nayar, 1997 ] ). <p> The cone has been used for wide-angle imaging <ref> [ Yagi and Kawato, 1990 ] </ref> [ Yagi and Yachida, 1991 ] . In these implementations the pinhole is placed quite some distance from the apex of the cone.
Reference: [ Yagi and Yachida, 1991 ] <author> Y. Yagi and M. Yachida. </author> <title> Real-time generation of environmental map and obstacle avoidance using omnidirectional image sensor with conic mirror. </title> <booktitle> In Proceedings of the 1991 Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 160-165, </pages> <month> June </month> <year> 1991. </year> <month> 29 </month>
Reference-contexts: The cone has been used for wide-angle imaging [ Yagi and Kawato, 1990 ] <ref> [ Yagi and Yachida, 1991 ] </ref> . In these implementations the pinhole is placed quite some distance from the apex of the cone. It is easy to show that in such cases the viewpoint is no longer a single point [ Nalwa, 1996 ] .
Reference: [ Yamazawa et al., 1993 ] <author> K. Yamazawa, Y. Yagi, and M. Yachida. </author> <title> Omnidirectional imaging with hyperboloidal projection. </title> <booktitle> In Proceedings of the International Conference on Robots and Systems, </booktitle> <year> 1993. </year>
Reference-contexts: This approach to image capture is fast gaining in popularity (see, for example, [ Nayar, 1988 ] , [ Yagi and Kawato, 1990 ] , [ Hong, 1991 ] , [ Goshtasby and Gruver, 1993 ] , <ref> [ Yamazawa et al., 1993 ] </ref> , [ Nalwa, 1996 ] , [ Nayar and Baker, 1997 ] , and [ Nayar, 1997 ] ). We refer to the general approach of using mirrors in combination with conventional imaging systems as catadioptric 1 image formation. <p> The curvature of the mirror and the field of view both increase with k. In the other direction, in the limit k ! 2, the hyperboloid flattens out to the planar mirror of Section 2.3.1. Yamazawa et al. <ref> [ Yamazawa et al., 1993 ] </ref> [ Yamazawa et al., 1995 ] recognized that the hyperboloid is indeed a practical solution. They have implemented a sensor designed for autonomous navigation and demonstrated the generation of perspective images. 15 viewpoint are located at the two foci of the ellipsoid. <p> This solution does produce the desired increase in field of view. The curvature of the mirror and hence the field of view increase with k. In the limit k ! 2, the hyperboloid flattens to the planar mirror of Section 2.3.1. Yamazawa et al. <ref> [ Yamazawa et al., 1993 ] </ref> [ Yamazawa et al., 1995 ] recognized that the hyperboloid is indeed a practical solution and have implemented a sensor designed for autonomous navigation. 17 3 Resolution of a Catadioptric Sensor In this section, we assume that the conventional camera used in the catadioptric sensor
Reference: [ Yamazawa et al., 1995 ] <author> K. Yamazawa, Y. Yagi, and M. Yachida. </author> <title> Obstacle avoidance with omnidirectional image sensor HyperOmni Vision. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1062-1067, </pages> <month> May </month> <year> 1995. </year> <month> 30 </month>
Reference-contexts: Recent work in this area has led to the development of a truly omnidirectional video camera with a spherical field of view [ Nayar, 1997 ] . As noted in <ref> [ Yamazawa et al., 1995 ] </ref> , [ Nalwa, 1996 ] , and [ Nayar, 1997 ] , it is highly desirable that a catadioptric system (or, in fact, any imaging system) have a single viewpoint (center of projection). <p> The curvature of the mirror and the field of view both increase with k. In the other direction, in the limit k ! 2, the hyperboloid flattens out to the planar mirror of Section 2.3.1. Yamazawa et al. [ Yamazawa et al., 1993 ] <ref> [ Yamazawa et al., 1995 ] </ref> recognized that the hyperboloid is indeed a practical solution. They have implemented a sensor designed for autonomous navigation and demonstrated the generation of perspective images. 15 viewpoint are located at the two foci of the ellipsoid. <p> The curvature of the mirror and hence the field of view increase with k. In the limit k ! 2, the hyperboloid flattens to the planar mirror of Section 2.3.1. Yamazawa et al. [ Yamazawa et al., 1993 ] <ref> [ Yamazawa et al., 1995 ] </ref> recognized that the hyperboloid is indeed a practical solution and have implemented a sensor designed for autonomous navigation. 17 3 Resolution of a Catadioptric Sensor In this section, we assume that the conventional camera used in the catadioptric sensor has a frontal image plane located
References-found: 14

