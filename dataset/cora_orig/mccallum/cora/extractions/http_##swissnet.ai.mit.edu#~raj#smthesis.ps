URL: http://swissnet.ai.mit.edu/~raj/smthesis.ps
Refering-URL: http://www-swiss.ai.mit.edu/~raj/index.html
Root-URL: 
Title: Practical Partial Evaluation  
Author: by Rajeev Surati Harold Abelson 
Degree: (1992) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Masters of Science in Electrical Engineering at the  All rights reserved. Author  Certified by  Class Of 1922 Professor and Macvicar Teaching Fellow Department of Electrical Engineering and Computer Science Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Date: May 1995  May 26, 1995  
Affiliation: S.B. Massachusetts Institute of Technology  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1995.  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Abelson, A. Berlin, J. Katzenelson, W. McAllister, G. Rozas, G. Sussman, </author> <title> "The Supercomputer Toolkit and its Applications," </title> <institution> MIT Artificial Intelligence Laboratory Memo 1249, Cambridge, Massachusetts. </institution>
Reference: [2] <author> S. Adams, </author> <note> personal communications May 10, </note> <year> 1994 </year>
Reference-contexts: FP vectors in MIT Scheme enable one to perform this optimization. From table 3.1 one can see that on average, the speedup achieved by using FP vectors was about a factor of 4.1. 1 , which is in line with Berlin's prediction. One might also note that, according to <ref> [2] </ref> and [21], when partially evaluated code consists of long streams of FP instructions, one can expect at least a 20 to 30 percent speedup if instruction scheduling is performed and values that are used once are not stored or loaded, as is the current default in Blitzkrieg.
Reference: [3] <author> A.V. Aho, R. Sethi and J.D. Ullman, </author> <booktitle> Compilers: Principles, Techniques and Tools Addison Wesley, </booktitle> <year> 1988 </year>
Reference: [4] <author> A. Berlin and R. Surati, </author> <title> "Partial Evaluation for Scientific Computing," </title> <booktitle> Proceedings of the ACM SIGPLAN Workshop on Partial Evaluation and Semantic-Based Program Manipulation, </booktitle> <year> 1994 </year>
Reference-contexts: The numerical code implementing the desired integrations is data independent and consists primarily of floating-point computation instructions. The applicability of partial evaluation to this problem, as well as the problem's scientific importance, are discussed in a recent paper by Surati and Berlin <ref> [4] </ref>. Experimental results of partially evaluating several solar system integration programs have been previously presented by Berlin [6].
Reference: [5] <author> A. Berlin and D. Weise, </author> <title> "Compiling Scientific Code using Partial Evaluation," </title> <note> IEEE Computer December 1990. </note>
Reference: [6] <author> A. </author> <title> Berlin, "Partial Evaluation Applied to Numerical Computation", in proceedings of the 1990 ACM Conference on Lisp and Functional Programming. Also see "A Compilation strategy for numerical programs based on partial evaluation," </title> <institution> MIT Artificial Intelligence Laboratory Technical Report TR-1144, </institution> <month> July, </month> <year> 1989. </year>
Reference-contexts: Blitzkrieg partially evaluates an input program by passing it to the MIT Scheme interpreter that I extended to perform abstract interpretation. Throughout abstract interpretation, unknown inputs are represented by placeholder objects <ref> [6] </ref>. The presence of a placeholder in a computation indicates that the computation cannot be performed right away; therefore, the system residualizes the computation until run time. Initially, only unknown inputs to the entire program 9 are represented by placeholders. <p> Essentially, what is meant by "data-dependent computation" is code that has control flow rather than one gigantic basic block of straight-line code. The mechanism to handle conditionals employed by Blitzkrieg is similar to the one described by Berlin in <ref> [6] </ref>. Berlin's system has several limitations, and some of them are severe. One limitation is that one must be able to execute the consequent of a conditional without affecting the result of executing the alternative, and vice versa, in order for his partial evaluator to work correctly. <p> The applicability of partial evaluation to this problem, as well as the problem's scientific importance, are discussed in a recent paper by Surati and Berlin [4]. Experimental results of partially evaluating several solar system integration programs have been previously presented by Berlin <ref> [6] </ref>. In our experiment, four different programs were partially evaluated: a 6-body 4th order Runge-Kutta Integration, a 9-body 4th order Runge-Kutta Integration, a 6-body 13th order Stormer Integration, and a 9-body 13th order Stormer Integration. These are exactly the same programs as used in [6]. <p> have been previously presented by Berlin <ref> [6] </ref>. In our experiment, four different programs were partially evaluated: a 6-body 4th order Runge-Kutta Integration, a 9-body 4th order Runge-Kutta Integration, a 6-body 13th order Stormer Integration, and a 9-body 13th order Stormer Integration. These are exactly the same programs as used in [6]. Thus, the experiment provides a point of comparison between Blitzkrieg and Berlin's partial evaluator, supplying an excellent test of Blitzkrieg's performance as a partial evaluator. 3.1.1 Performance Measurements Measurements were made of the actual speedup Blitzkrieg was able to achieve on the various integration algorithms. <p> A "*" denotes computations that could not be compiled because of insufficient heap for compilation; "**" denotes information that Berlin was also unable to measure due to similar problems, as explained in <ref> [6] </ref>. taken. The first set of timings measures the speedup from partially evaluating the code with boxed floating-point (FP) numbers (i.e., heap-allocated FP numbers that are tagged and require one level of indirection to read or write read from memory). <p> These timings are labeled "Specialized Program (with boxing)," and are presented in order to make comparisons with timings made by Berlin <ref> [6] </ref>, who also used boxed FP numbers. <p> In <ref> [6] </ref>, Berlin predicts a factor of 4 speedup if memory allocation due to boxing and unboxing of FP numbers is eliminated. FP vectors in MIT Scheme enable one to perform this optimization. <p> optimizations was shown on a 3D transformation system, yielding a speedup factor of 4.04 over the original code and a factor of 3.06 over partially evaluated code without the domain-specific optimizations. 35 Chapter 4 Related Work Several partial evaluation systems exist for the Scheme language, most notably Berlin's partial evaluator <ref> [6] </ref>, FUSE [23][22], and Similix [7]. In this chapter I compare the capabilities of Blitzkrieg with each of these systems. 4.1 Berlin's Partial Evaluator Throughout this thesis, I have referred to Andy Berlin's partial evaluator from [6]. <p> Several partial evaluation systems exist for the Scheme language, most notably Berlin's partial evaluator <ref> [6] </ref>, FUSE [23][22], and Similix [7]. In this chapter I compare the capabilities of Blitzkrieg with each of these systems. 4.1 Berlin's Partial Evaluator Throughout this thesis, I have referred to Andy Berlin's partial evaluator from [6]. Berlin's partial evaluator was written as part of MIT's Project for Mathematics and Computation's (Project MaC) scientific computing project at MIT. The Blitzkrieg system represents the next generation of partial evaluators from Project MaC. Thus, the two systems are similar in many respects. <p> In addition, Blitzkrieg's result for floating point code as demonstrated on the solar system integrators are superior to Berlin's results. This is primarily because recent additions to the MIT Scheme system made it possible to use constructs that eliminated floating point consing. Berlin predicted such results in <ref> [6] </ref>, but did not have this capability when he implemented his system. 36 Another major difference between Blitzkrieg and Berlin's system is that Berlin's placeholders do not carry a representation of the residualized code.
Reference: [7] <author> A. Bondorf, </author> <title> "Similix 5.0 Users Manaul" GNU Free Software Distribution 1993. </title>
Reference-contexts: 3D transformation system, yielding a speedup factor of 4.04 over the original code and a factor of 3.06 over partially evaluated code without the domain-specific optimizations. 35 Chapter 4 Related Work Several partial evaluation systems exist for the Scheme language, most notably Berlin's partial evaluator [6], FUSE [23][22], and Similix <ref> [7] </ref>. In this chapter I compare the capabilities of Blitzkrieg with each of these systems. 4.1 Berlin's Partial Evaluator Throughout this thesis, I have referred to Andy Berlin's partial evaluator from [6]. <p> Additionally, unlike FUSE, Blitzkrieg is not restricted to a functional subset of Scheme. It can handle the many types of mutation that most commonly occur in Scheme code. 4.3 Similix Danvy and Bondorf's Similix system <ref> [7] </ref> is a publicly available o*ine self-applicable partial evaluation system. It also handles only a functional subset of Scheme, with some consideration given to file input and output. Similix enjoys several advantages over Blitzkrieg. Since it is self-applicable, all of the renowned Futamura projections [12] are feasible.
Reference: [8] <author> C. Colby and P. Lee, </author> <title> "A Modular Implementation of Partial Evaluation" Technical Report CMU-CS-92-123, </title> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh PA, </address> <year> 1992. </year>
Reference: [9] <author> C. Consel and S. C. </author> <title> Koo, </title> <booktitle> "Paramerized Partial Evaluation" Proceedings of the SIG PLAN 91 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1991, </year> <pages> 92-106 </pages>
Reference: [10] <author> O. Danvy, </author> <title> Personal Communication May 1995. </title>
Reference: [11] <author> J. Ellis, Bulldog: </author> <title> A Compiler for VLIW Architectures. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1985. </year> <note> Also available as the ACM PhD Dissertation of the Year, MIT Press 1985. </note>
Reference: [12] <author> Y. Futamura. </author> <title> "Partial Evaluation of Computation Process| An Approach to a Com piler Compiler" Systems, </title> <journal> Computers, Controls, </journal> <volume> 2(5) </volume> <pages> 45-50, </pages> <year> 1971. </year>
Reference-contexts: It also handles only a functional subset of Scheme, with some consideration given to file input and output. Similix enjoys several advantages over Blitzkrieg. Since it is self-applicable, all of the renowned Futamura projections <ref> [12] </ref> are feasible. In Similix, one can write a so-called "compiler generator" that, given an interpreter, generates a compiler. Blitzkrieg is not self-applicable.
Reference: [13] <author> C. Hanson, </author> <title> "The Scheme Object System Reference Manual" [14] </title>
Reference: [15] <author> C. Hanson, </author> <title> "The MIT Scheme Reference Manual," </title> <institution> MIT Artificial Laboratory Techni cal Report 1281, </institution> <year> 1991 </year> <month> [16] </month>
Reference-contexts: with an object; otherwise, it dispatches to the appropriate parsing primitives|the procedures parse-object/symbol, parse-object/atom, or discard-whitespace.These input procedures in turn call various input primitives to read the object in character by character. 2 read is part of the MIT Scheme runtime library and is fully documented along with ports in <ref> [15] </ref>. When the format of the input file is unknown, read provides a nice general way to read in data from the file. But if the port's format is fixed, calls to read result in a lot of wasteful and unnecessary parsing.
Reference: [17] <author> N. D. Jones, C. K. Gomard and P. Sestoft, </author> <title> Partial Evaluation and Automatic Program Generations Prentice Hall, </title> <year> 1993 </year>
Reference: [18] <author> S. Keene, </author> <title> Object-Oriented Programming in Common Lisp: A Programmer's Guide to CLOS, </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: A user need do only two things to extend the partial evaluator to handle his application. First, he needs to construct placeholder subclasses for his application's data structures. This can be done by simply creating a new class (a mixin <ref> [18] </ref>) that inherits from both his data structure's class and the placeholder class. Second, he needs to identify the procedures that do actual work within his application that will be given placeholder inputs, and redefine these procedures to residualize on the proper placeholder inputs.
Reference: [19] <author> G. Kiczales, J. Rivieres, and D. Bobrow, </author> <title> The Art of the Metaobject Protocol, </title> <publisher> MIT Press, </publisher> <year> 1991 </year>
Reference: [20] <author> H. Masselin, </author> <title> "Efficient Implementation of Fundamental Operating System Services," </title> <type> Columbia University PhD Thesis 1992 </type>
Reference-contexts: It has already been shown that partial evaluation techniques are capable of producing orders of magnitude speed-ups on real-world applications ([6], <ref> [20] </ref>). Despite this tremendous potential, however, partial evaluators are rarely used to support real-world applications, and this is due to four major reasons. First of all, traditional partial evaluators are not easily extended to work on most user's applications.
Reference: [21] <author> G. </author> <title> Rozas, </title> <type> personal communications May 10, </type> <year> 1994 </year>
Reference-contexts: From table 3.1 one can see that on average, the speedup achieved by using FP vectors was about a factor of 4.1. 1 , which is in line with Berlin's prediction. One might also note that, according to [2] and <ref> [21] </ref>, when partially evaluated code consists of long streams of FP instructions, one can expect at least a 20 to 30 percent speedup if instruction scheduling is performed and values that are used once are not stored or loaded, as is the current default in Blitzkrieg.
Reference: [22] <author> E. Ruf, </author> <title> "Topics in Online Partial Evaluation", </title> <type> Technical Report CSL-TR-93-563, </type> <institution> Com puter Systems Laboratory, Stanford University, Stanford, </institution> <address> CA. </address> <year> 1993. </year>
Reference-contexts: In addition, the aggressiveness of o*ine systems like Similix in optimization is adversely affected by the fact that they are self-applicable. O*ine systems decide to reduce or residualize a computation in a phase before the specialization actually occurs. Ruf <ref> [22] </ref> explains why o*ine partial evaluators choose to residualize computations that could be computed at run time by an online one.
Reference: [23] <author> E. Ruf and D. </author> <title> Weise, </title> <booktitle> "Avoiding Redundant Specialization During Partial Evalua tion" In Proceedings of the 1991 ACM SIGPLAN Symposium on Partial Evaluationand Semantics-Based Program Manipulation, </booktitle> <address> New Haven, CN. </address> <month> June </month> <year> 1991. </year>
Reference-contexts: This is, of course, because Berlin's system was not designed for user extensibility and domain-specific optimizations. Obviously there is some space cost associated with this since one is essentially carrying a flow graph representation of the program. 4.2 FUSE FUSE <ref> [23] </ref> is a set of online partial evaluators implemented at Stanford. FUSE partially evaluates programs written in a functional subset of Scheme. The FUSE system has a number of advantages over Blitzkrieg.
Reference: [24] <author> G. Steele Jr. </author> <title> Common Lisp: The Language 2nd Edition Digital Press, </title> <year> 1990 </year>
Reference: [25] <author> R. Surati, </author> <title> "A Parallelizing Compiler Based on Partial Evaluation", </title> <institution> MIT Artificial Intelligence Laboratory Technical Report TR-1377, </institution> <month> July </month> <year> 1992 </year>
Reference: [26] <author> R. Surati and A. </author> <title> Berlin, "Exploiting the Parallelism Exposed By Partial Evaluation" International Conference on Parallel Architectures and Compilation Techniques, </title> <institution> Else-vier Science, </institution> <year> 1994 </year>
Reference-contexts: These estimates are further supported in <ref> [26] </ref>, where a factor of 6.2 speedup of the 9-body Stormer computation was achieved after partial evaluation by carefully scheduling the computation onto a VLIW parallel processor in order to take advantage of the fine-grain parallelism available in this 1 from 3.8 speedup on 6-body Stormer and 4.4 speedup on 6-body
Reference: [27] <author> G. J. Sussman and J. </author> <title> Wisdom, "Numerical Evidence that the Motion of Pluto is Chaotic," </title> <journal> Science, </journal> <volume> Volume 241, </volume> <month> 22 July </month> <year> 1988. </year>
Reference-contexts: The particular programs involved were used by Gerald Jay Sussman and Jack Wisdom <ref> [27] </ref> to make a landmark scientific discovery concerning the chaotic nature of solar system dynamics. The numerical code implementing the desired integrations is data independent and consists primarily of floating-point computation instructions.
Reference: [28] <author> D. Weise and E. Ruf, </author> <title> "Computing Types During Program Specialization" Technical Report CSL-TR-90-441 Computer Systems Laboratory, </title> <institution> Stanford Univerisity, Stanford, </institution> <address> CA 1990. </address>
References-found: 26

