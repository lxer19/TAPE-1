URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-94-48.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Parallelizing Subgraph Isomorphism Refinement for Classification and Retrieval of Conceptual Structures  
Author: James D. Roberts 
Address: Santa Cruz, CA 95064 USA  
Affiliation: Baskin Center for Computer Engineering Information Sciences University of California, Santa Cruz  
Date: December 20, 1994  
Pubnum: UCSC-CRL-94-48  
Abstract: Major applications of graph-based knowledge representations will require quick response times on extremely large knowledge bases. Although algorithmic developments have provided tremendous improvements in speed, we believe implementation on parallel processors will be needed to meet long-term needs. This paper presents a new parallelization of a subgraph isomorphism refinement algorithm for performing projection tests and retrieving conceptual structures. The improved algorithm is faster, requires fewer processors, and is compatible with recent relation-based representations of conceptual structures. The new parallelization takes advantage of the features of contemporary data-parallel parallel machines by exploiting bit-parallelism in wide data words. Processing numerous graphs on a single parallel array, it combines the strengths of prior parallel subgraph isomorphism parallelizations with multi-level indexed search. It incorporates lattice codes of the concept-type hierarchy to avoid a bottleneck in our prior parallelization and forms all node candidate binding lists in parallel. Simulation results of the behavior of the refinement algorithm with parameterized synthetic data sets are presented as are implications for hardware tailored to processing conceptual structures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Hassan Ait-Kaci et al. </author> <title> Efficient implementation of lattice operations. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(1) </volume> <pages> 115-146, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: As a basic example, the poset is represented as an adjacency matrix and the reflexive-transitive closure of the matrix is computed. Each row of the resulting matrix is the code for its respective element in the partial order <ref> [1] </ref>. These simple codes are N bits long where N is the number of elements in the poset. <p> More formally, the poset is plunged into a lattice and the lattice is then encoded; more advanced encoding algorithms approach the lower bound of (lg N ) length codes for ideal poset topologies <ref> [1, 3] </ref>. Lattice codes are useful in speeding operations on a CS concept-type hierarchy and can also be used to further prune comparisons in a Method III graph classification, provided the "query" graph is known to be in the knowledge base.
Reference: [2] <author> Franz Baader, Bernhard Hollunder, Bernhard Nebel, Hans-Jurgen Profitlich, and Enrico Franconi. </author> <title> An empirical analysis of optimization techniques for terminological representation systems. </title> <booktitle> In Proceedings of the 3rd International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <address> Cambridge, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: As an independent survey shows Levinson and Ellis' methodology to be the fastest known structure search pruning <ref> [2] </ref>, it forms the framework and motivation for our parallelization efforts. Rather than providing a single level of indexing as in conventional databases, Levinson's Method III MIS creates a partial order over the knowledge base using the more-general-than relation.
Reference: [3] <author> Gerard Ellis. </author> <title> Efficient retrieval from hierarchies of objects using lattice operations. </title> <booktitle> In Conceptual Graphs for Knowledge Representations, </booktitle> <pages> pages 274-293, </pages> <address> New York, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: More formally, the poset is plunged into a lattice and the lattice is then encoded; more advanced encoding algorithms approach the lower bound of (lg N ) length codes for ideal poset topologies <ref> [1, 3] </ref>. Lattice codes are useful in speeding operations on a CS concept-type hierarchy and can also be used to further prune comparisons in a Method III graph classification, provided the "query" graph is known to be in the knowledge base. <p> In addition to reducing storage, shorter codes reduce execution time. The time to compute subsumption, greatest lower bound, or least upper bound between two concept types or two graphs in the hierarchy is proportional to the length of the code <ref> [3] </ref>. On a parallel machine, one lattice code can be simultaneously compared against numerous others.
Reference: [4] <author> Richard Hughey, Robert Levinson, and James D. Roberts. </author> <title> Issues in parallel hardware for graph retrieval. </title> <booktitle> In Proceedings of the 1st International Conference on Conceptual Structures, </booktitle> <pages> pages 62-81, </pages> <year> 1993. </year>
Reference-contexts: First, selected graphs are moved from main memory into the processors; those selected could include all graphs (exhaustive comparison) [14], those which pass filtering criteria (single-level indexing) [14, 6], or those passing multi-level indexing (initial graph SI tests filtering subsequent graphs) <ref> [9, 4] </ref>. Second, the match matrix M is formed. Third, the backtracking refinement search is performed. The refinement procedure is called at each branch of a backtracking search tree (including the root), significantly pruning the number of branches explored. <p> Hughey et al. describe this and another example of subgraph isomorphism using Ullmann's algorithm in somewhat greater detail <ref> [4] </ref>. The matrix operations are readily parallelizable with all candidate bindings (bits in the match matrix) processed simultaneously. Willett et al. present a parallelization for the DAP-610, an older parallel machine with 4096 single-bit processors [14]. <p> Willett et al. propose a fourth method that uses the second method, adding new graphs as earlier graphs complete processing. 2.2 Subgraph Isomorphism and Conceptual Structures We make several modifications in applying SI refinement to conceptual structures <ref> [4] </ref>. First we must account for edge direction; Ullmann's algorithm is for undirected graphs and cannot be adapted to SI in DAGs. <p> By incorporating multi-level indexed search (MIS) we can minimize, and in some cases eliminate, unnecessary graph comparisons. 6.1 Improvement in Multi-Level Indexed Over Exhaustive Search The multi-bit implementation strengthens our prior analysis demonstrating the advantage of MIS over exhaustive parallel search <ref> [4] </ref>. With b-bit processors we now need 1=b as many processors, or we can process b times as many graphs simultaneously. Updating the prior analysis to the multi-bit implementation is straightforward. <p> Previously, a parallel array of a thousand processors could handle only one to a few graphs; with a dozen or more graphs available at any stage in the MIS comparisons would be farmed out to several processor arrays <ref> [4] </ref>. This processor-farm model included implicit load balancing (each array requesting more work when it was done) and there were more graphs queued for comparison than the available processors could handle so that a graph need not be compared until it was certain that the comparison was necessary.
Reference: [5] <author> George G. Lendaris. </author> <title> Representing conceptual graphs for parallel processing. </title> <booktitle> In Conceptual Graphs Workshop, </booktitle> <year> 1988. </year>
Reference-contexts: Lendaris has used an inherently parallel neural network approach to processing conceptual structures (CS), including join, simplify, and projection <ref> [5, 6] </ref>. His results demonstrate 2. Background 3 neural networks performing important filtering of candidate graphs which must then be further processed for projection.
Reference: [6] <author> George G. Lendaris. </author> <title> A neural-network approach to implementing conceptual graphs. </title> <editor> In Timothy E. Nagel et al., editors, </editor> <booktitle> Conceptual Structures, Current Research and Practice, chapter 8, </booktitle> <pages> pages 155-188. </pages> <publisher> Ellis Horwood, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Lendaris has used an inherently parallel neural network approach to processing conceptual structures (CS), including join, simplify, and projection <ref> [5, 6] </ref>. His results demonstrate 2. Background 3 neural networks performing important filtering of candidate graphs which must then be further processed for projection. <p> Figure 2.1 diagrams the overall structure of the algorithm. First, selected graphs are moved from main memory into the processors; those selected could include all graphs (exhaustive comparison) [14], those which pass filtering criteria (single-level indexing) <ref> [14, 6] </ref>, or those passing multi-level indexing (initial graph SI tests filtering subsequent graphs) [9, 4]. Second, the match matrix M is formed. Third, the backtracking refinement search is performed.
Reference: [7] <author> Robert Levinson. UDS: </author> <title> A universal data structure. </title> <editor> In W. M. Tepfenhart, I. P. Dide, and J. F. Sowa, editors, </editor> <booktitle> Conceptual Structures: Theory and Practice, </booktitle> <pages> pages 230-250. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1994. </year> <booktitle> Lecture Notes in AI 835. </booktitle>
Reference-contexts: lattice-code operations are independent of the number of elements in the poset or the lengths of the inheritance paths. 3 A Relation-Based Representation for CS Levinson's Universal Data Structure (UDS) combines the features and benefits of neural networks, semantic networks, relational databases, and conceptual structures in a single representational framework <ref> [7] </ref>. Its relation-based representation of graphs is of particular relevance to the new work presented in this paper. In UDS, conceptual structures are transformed such that the relations and their adjacent concept-types in the CS become nodes in the UDS graph.
Reference: [8] <author> Robert A. Levinson. </author> <title> A Self-Organizing Retrieval System for Graphs. </title> <type> PhD thesis, </type> <institution> University of Texas at Austin, </institution> <year> 1985. </year>
Reference: [9] <author> Robert A. Levinson and Gerard Ellis. </author> <title> Multi-level hierarchical retrieval. </title> <journal> Knowledge-Based Systems Journal, </journal> <volume> 5(3), </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: First, selected graphs are moved from main memory into the processors; those selected could include all graphs (exhaustive comparison) [14], those which pass filtering criteria (single-level indexing) [14, 6], or those passing multi-level indexing (initial graph SI tests filtering subsequent graphs) <ref> [9, 4] </ref>. Second, the match matrix M is formed. Third, the backtracking refinement search is performed. The refinement procedure is called at each branch of a backtracking search tree (including the root), significantly pruning the number of branches explored. <p> This is readily handled by relaxing the mapping criteria applied in the backtracking portion of the algorithm. 2.3 Multilevel Indexed Search Multilevel indexed search (MIS) <ref> [9] </ref> can significantly reduce the number of SI tests necessary. As an independent survey shows Levinson and Ellis' methodology to be the fastest known structure search pruning [2], it forms the framework and motivation for our parallelization efforts.
Reference: [10] <author> John R. Nickolls. </author> <title> The design of the Maspar MP-1: A cost effective massively parallel computer. </title> <booktitle> In Proceedings of COMPCON, </booktitle> <pages> pages 25-28, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: We have thereby run simulations of the refinement procedure, emulating two data parallel machines: the proposed 16-bit MISC architecture [11] and the commercially available 32-bit MasPar MP-2 <ref> [10] </ref>. The simulations use parameterized synthetic data sets to study the effect of different graph characteristics on refinement behavior.
Reference: [11] <author> James D. Roberts et al. </author> <title> Hardware for PEIRCE. </title> <booktitle> In Proceedings of the International Workshop on PEIRCE: A Conceptual Graphs Workbench, </booktitle> <address> 1992,1993. </address>
Reference-contexts: We have thereby run simulations of the refinement procedure, emulating two data parallel machines: the proposed 16-bit MISC architecture <ref> [11] </ref> and the commercially available 32-bit MasPar MP-2 [10]. The simulations use parameterized synthetic data sets to study the effect of different graph characteristics on refinement behavior.
Reference: [12] <editor> John F. Sowa, editor. </editor> <booktitle> Principles of Semantic Networks. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Conceptual structures, a graph-based information processing methodology representing knowledge as sets of concept nodes and relation nodes <ref> [12] </ref>, has been extensively researched over the last 10 years and is now being incorporated into a variety of applications as well as into ANSI standards.
Reference: [13] <author> J. R. </author> <title> Ullmann. An algorithm for subgraph isomorphism. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 31-42, </pages> <month> January </month> <year> 1976. </year>
Reference-contexts: Although having exponential time in the worst case, subgraph isomorphism has an empirical expected-case time of O (n 4 ) bit operations (where n is the number of nodes in the larger of the two graphs) using the SI refinement algorithm developed by Ullmann <ref> [13] </ref>. The polynomial expected-case time means that parallelization can provide a substantial speedup. <p> Ullmann's original implementation used the bit-parallelism in the data word of a conventional serial processor to achieve O (n 3 ) empirical time on graph isomorphism <ref> [13] </ref>. Implementations by Willett et al. on a data-parallel processor empirically show O (n 2 ) time using n 2 single-bit processors, demonstrating an efficient parallelization of SI with substantial time improvement [14]. <p> This is followed by a brief description of multilevel search and lattice coding as relevant to our new SI parallelization. 2.1 Subgraph Isomorphism Refinement Ullmann's algorithm features a refinement procedure to extensively prune the search tree in a backtracking algorithm <ref> [13] </ref>, speeding SI tests. Given two graphs G a and G b a SI test determines if G a is a subgraph of G b . Ullmann's refinement algorithm represents the graphs 4 2. <p> In the latter case no subgraph isomorphisms exist. As a simple example, consider the conceptual structures in Figure 2.2. The initial matrices for the graphs are: 1 I.e. the graphs must be undirected; Ullmann shows modifications for directed graph isomorphism, but they are not applicable to subgraph isomorphism <ref> [13] </ref>. 2.
Reference: [14] <author> Peter Willett, Terence Wilson, and Stewart F. Reddaway. </author> <title> Atom-by-atom searching using massive parallelism: Implementation of the Ullmann subgraph isomorphism algorithm on the distributed array processor. </title> <journal> Journal of the Chemical Information Computation Society, </journal> (31):225-233, 1991. 
Reference-contexts: Implementations by Willett et al. on a data-parallel processor empirically show O (n 2 ) time using n 2 single-bit processors, demonstrating an efficient parallelization of SI with substantial time improvement <ref> [14] </ref>. Lendaris has used an inherently parallel neural network approach to processing conceptual structures (CS), including join, simplify, and projection [5, 6]. His results demonstrate 2. Background 3 neural networks performing important filtering of candidate graphs which must then be further processed for projection. <p> Figure 2.1 diagrams the overall structure of the algorithm. First, selected graphs are moved from main memory into the processors; those selected could include all graphs (exhaustive comparison) <ref> [14] </ref>, those which pass filtering criteria (single-level indexing) [14, 6], or those passing multi-level indexing (initial graph SI tests filtering subsequent graphs) [9, 4]. Second, the match matrix M is formed. Third, the backtracking refinement search is performed. <p> Figure 2.1 diagrams the overall structure of the algorithm. First, selected graphs are moved from main memory into the processors; those selected could include all graphs (exhaustive comparison) [14], those which pass filtering criteria (single-level indexing) <ref> [14, 6] </ref>, or those passing multi-level indexing (initial graph SI tests filtering subsequent graphs) [9, 4]. Second, the match matrix M is formed. Third, the backtracking refinement search is performed. <p> The matrix operations are readily parallelizable with all candidate bindings (bits in the match matrix) processed simultaneously. Willett et al. present a parallelization for the DAP-610, an older parallel machine with 4096 single-bit processors <ref> [14] </ref>. Their coding optimizes the matrix expressions, eliminating the transpose for one of the Boolean matrix multiplications. They present three parallel implementations of Ullmann's algorithm. In the first, each processor stores 1 bit from each of the matrices and the parallel processor computes one SI test at a time.
References-found: 14

