URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-402.ps.Z
Refering-URL: http://www.cs.gatech.edu/computing/classes/cs7322_98_spring/readings.html
Root-URL: 
Email: (jdavis j bobick@media.mit.edu)  
Title: Representation and Recognition of Action Using Temporal Templates  
Author: James W. Davis and Aaron F. Bobick 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: MIT Media Laboratory,  
Note: The  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 402 Appears in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR'97) Abstract A new view-based approach to the representation and recognition of action is presented. The basis of the representation is a temporal template | a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence. Using 18 aerobics exercises as a test domain, we explore the representational power of a simple, two component version of the templates: the first value is a binary value indicating the presence of motion, and the second value is a function of the recency of motion in a sequence. We then develop a recognition method which matches these temporal templates against stored instances of views of known actions. The method automatically performs temporal segmentation, is invariant to linear changes in speed, and runs in real-time on a standard platform. We recently incorporated this technique into the KidsRoom: an interactive, narrative play-space for children. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Akita, K. </author> <title> Image sequence analysis of real world human motion. </title> <journal> Pattern Recognition, </journal> <volume> 17, </volume> <year> 1984. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. In [4] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [2] <author> Black, M. and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motion using local parametric models of image motion. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1995. </year>
Reference-contexts: The approach is a natural extension of Black and Yacoob's Frame 5 25 40 in each frame people can trivially recognize the action as someone sitting. work on facial expression recognition <ref> [2] </ref>. In this work we continue to develop this approach. We review the construction of a binary motion-energy image (MEI) which represents where motion has occurred in an image sequence. <p> However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [16, 19, 20, 2, 10, 15, 4] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson [16] is the most relevant to the results presented here.
Reference: [3] <author> A. Bobick, J. Davis, S. Intille, F. Baird, L. Camp-bell, Y. Ivanov, C. Pinhanez, A. Schutte, and A. Wilson. Kidsroom: </author> <title> Action recognition in an interactive story environment. </title> <type> PerCom TR 398, </type> <institution> MIT Media Lab, </institution> <year> 1996. </year>
Reference-contexts: 1 Introduction The recent shift in computer vision from static images to video sequences has focused research on the understanding of action or behavior. In particular, the lure of wireless interfaces (e.g. [11]) and interactive environments <ref> [9, 3] </ref> has heightened interest in understanding human actions. Recently a number of approaches have appeared attempting the full three-dimensional reconstruction of the human form from image sequences, with the presumption that such information would be useful and perhaps even necessary to understand the action taking place (e.g. [17]). <p> On October 30th, 1996 we debuted The KidsRoom, an interactive play-space for children <ref> [3] </ref>. The basic idea is that the room is aware of the children (maximum of 4) and takes them through a story where the responses of the room are affected by what the children do.
Reference: [4] <author> Bobick, A. and J. Davis. </author> <title> An appearance-based representation of action. </title> <booktitle> In Proc. Int. Conf. Pat. Rec., </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: This paper presents an alternative to the three-dimensional reconstruction proposal. We develop a view-based approach to the representation and recognition of action that is designed to support the direct recognition of the motion itself. In previous work <ref> [4, 5] </ref> we described how people can easily recognize action in even extremely blurred image sequences such as shown in Figure 1. <p> Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in [1, 6, 12, 17, 18, 8, 21]. In <ref> [4] </ref> we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [16, 19, 20, 2, 10, 15, 4] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson [16] is the most relevant to the results presented here. <p> Fortunately, in the recognition section we derive a backward-looking (in time) algorithm which can dynamically search over a range of t . In Figure 3 we display the MEIs of viewing a sitting action across 90 ffi . In <ref> [4] </ref> we exploited the smooth variation of motion over angle to compress the entire view circle into a low-order representation.
Reference: [5] <author> Bobick, A. and J. Davis. </author> <title> Real time recognition of activity using temporal templates. </title> <booktitle> In IEEE Workshop on Applications of Computer Vision, </booktitle> <address> Sarasota, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: This paper presents an alternative to the three-dimensional reconstruction proposal. We develop a view-based approach to the representation and recognition of action that is designed to support the direct recognition of the motion itself. In previous work <ref> [4, 5] </ref> we described how people can easily recognize action in even extremely blurred image sequences such as shown in Figure 1.
Reference: [6] <author> Campbell, L. and A. Bobick. </author> <title> Recognition of human body motion using phase space constraints. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1995. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. In [4] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [7] <author> Cedras, C., and Shah, M. </author> <title> Motion-based recognition: A survey. </title> <journal> Image and Vision Computing, </journal> <volume> 13(2) </volume> <pages> 129-155, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: For an excellent review on the machine understanding of motion see <ref> [7] </ref>. We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include [1, 6, 12, 17, 18, 8, 21].
Reference: [8] <author> Cui, Y., D. Swets, and J. Weng. </author> <title> Learning-based hand sign recognition using shoslif-m. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1995. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. In [4] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [9] <author> Darrell, T., P. Maes, B. Blumberg, and A. Pent-land. </author> <title> A novel environment for situated vision and behavior. In IEEE Wkshp. for Visual Behaviors (CVPR-94), </title> <year> 1994. </year>
Reference-contexts: 1 Introduction The recent shift in computer vision from static images to video sequences has focused research on the understanding of action or behavior. In particular, the lure of wireless interfaces (e.g. [11]) and interactive environments <ref> [9, 3] </ref> has heightened interest in understanding human actions. Recently a number of approaches have appeared attempting the full three-dimensional reconstruction of the human form from image sequences, with the presumption that such information would be useful and perhaps even necessary to understand the action taking place (e.g. [17]).
Reference: [10] <author> Essa, I. and A. Pentland. </author> <title> Facial expression recognition using a dynamic model and motion energy. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [16, 19, 20, 2, 10, 15, 4] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson [16] is the most relevant to the results presented here.
Reference: [11] <author> Freeman, W., and M. Roth. </author> <title> Orientation histogram for hand gesture recognition. </title> <booktitle> In Int'l Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: 1 Introduction The recent shift in computer vision from static images to video sequences has focused research on the understanding of action or behavior. In particular, the lure of wireless interfaces (e.g. <ref> [11] </ref>) and interactive environments [9, 3] has heightened interest in understanding human actions.
Reference: [12] <author> Hogg, D. </author> <title> Model-based vision: a paradigm to see a walking person. </title> <journal> Image and Vision Computing, </journal> <volume> 1(1), </volume> <year> 1983. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. In [4] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [13] <author> Hu, M. </author> <title> Visual pattern recognition by moment invariants. </title> <journal> IRE Trans. Information Theory, </journal> <volume> IT-8(2), </volume> <year> 1962. </year>
Reference-contexts: We first collect training examples of each action from a variety of viewing angles. Given a set of MEIs and MHIs for each view/action combination, we compute statistical descriptions of the these images using moment-based features. Our current choice are 7 Hu moments <ref> [13] </ref> which are known to yield reasonable shape discrimination in a translation- and scale-invariant manner. For each view of each action a statistical model of the moments (mean and covariance matrix) is generated for both the MEI and MHI.
Reference: [14] <author> D. Jones and J. Malik. </author> <title> Computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <journal> Image and Vision Computing, </journal> <volume> 10(10) </volume> <pages> 699-708, </pages> <year> 1992. </year>
Reference-contexts: The vector-image template is similar in spirit to the vector-image based on orientation and edges used by Jones and Malik <ref> [14] </ref> for robust stereo matching. For the results in this paper we use only the two components derived above (MEI and MHI) for representation and recognition.
Reference: [15] <author> Little, J., and J. Boyd. </author> <title> Describing motion for recognition. </title> <booktitle> In International Symposium on Computer Vision, </booktitle> <pages> pages 235-240, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [16, 19, 20, 2, 10, 15, 4] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson [16] is the most relevant to the results presented here.
Reference: [16] <author> Polana, R. and R. Nelson. </author> <title> Low level recognition of human motion. </title> <booktitle> In IEEE Workshop on Non-rigid and Articulated Motion, </booktitle> <year> 1994. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [16, 19, 20, 2, 10, 15, 4] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson [16] is the most relevant to the results presented here. <p> Alternatively, there is the work on direct motion recognition [16, 19, 20, 2, 10, 15, 4]. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson <ref> [16] </ref> is the most relevant to the results presented here. <p> components of the temporal templates include power in directional motion integrated over time (e.g. "in this pixel there has been a large amount of motion in the down direction during the integrating time window") or the spatially localized periodicity of motion (a pixel by pixel version of Polana and Nelson <ref> [16] </ref>). The vector-image template is similar in spirit to the vector-image based on orientation and edges used by Jones and Malik [14] for robust stereo matching. For the results in this paper we use only the two components derived above (MEI and MHI) for representation and recognition.
Reference: [17] <author> Rehg, J. and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1995. </year>
Reference-contexts: Recently a number of approaches have appeared attempting the full three-dimensional reconstruction of the human form from image sequences, with the presumption that such information would be useful and perhaps even necessary to understand the action taking place (e.g. <ref> [17] </ref>). This paper presents an alternative to the three-dimensional reconstruction proposal. We develop a view-based approach to the representation and recognition of action that is designed to support the direct recognition of the motion itself. <p> Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. In [4] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [18] <author> Rohr, K. </author> <title> Towards model-based recognition of human movements in image sequences. CVGIP, Image Understanding, </title> <type> 59(1), </type> <year> 1994. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. In [4] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [19] <author> Shavit, E. and A. Jepson. </author> <title> Motion understanding using phase portraits. </title> <booktitle> In IJCAI Workshop: Looking at People, </booktitle> <year> 1995. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [16, 19, 20, 2, 10, 15, 4] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson [16] is the most relevant to the results presented here.
Reference: [20] <author> Yacoob, Y. and L. Davis. </author> <title> Computing spatio-temporal representations of human faces. </title> <booktitle> In Proc. Comp. Vis. and Pattern Rec., </booktitle> <year> 1994. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [16, 19, 20, 2, 10, 15, 4] </ref>. These approaches attempt to characterize the motion itself without any reference to the underlying static images or a sequence of poses. Of these techniques, the work of Polana and Nelson [16] is the most relevant to the results presented here.
Reference: [21] <author> Yamato, J., J. Ohya, and K. Ishii. </author> <title> Recognizing human action in time sequential images using hidden markov models. </title> <booktitle> In Proc. Comp. Vis. and Pattern Rec., </booktitle> <year> 1992. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. In [4] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 6, 12, 17, 18, 8, 21] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
References-found: 21

