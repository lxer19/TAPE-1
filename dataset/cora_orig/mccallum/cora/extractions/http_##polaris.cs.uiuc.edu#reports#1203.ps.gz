URL: http://polaris.cs.uiuc.edu/reports/1203.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: A MEMORY-CONSERVING HYBRID METHOD FOR SOLVING LINEAR SYSTEMS WITH MULTIPLE RIGHT HAND SIDES  
Author: V. SIMONCINI AND E. GALLOPOULOS 
Note: AMS(MOS) subject classifications. 65F10,65Y20  
Abstract: We propose a method for the solution of sparse linear, nonsymmetric systems AX = B where A is a sparse and nonsymmetric matrix of order n while B is an arbitrary rectangular matrix of order n fi s with s of moderate size. The method uses a single Krylov subspace per step as a generator of approximations, a projection process, and a Richardson acceleration technique. It thus combines the advantages of recent hybrid methods with those for solving symmetric systems with multiple right hand sides. Numerical experiments indicate that provided hybrid techniques are applicable, the method has significantly lower memory requirements and better practical performance than block versions of nonsymmetric solvers such as GMRES. Unlike block BCG it does not require the use of the transpose, it is not sensitive to the right hand sides and it can be used even when not all the elements of B are simultaneously available. 1. Introduction. We consider techniques for the solution of systems with a single, sparse 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. T. CHRONOPOULOS AND S. MA, </author> <title> On squaring Krylov subspace iterative methods for nonsymmetric linear systems, </title> <type> Tech. Rep. 89-67, </type> <institution> Computer Science Dept., U. Minnesota, Minneapolis, </institution> <month> Sept. </month> <year> 1989. </year>
Reference-contexts: Numerical experiments. In this section we examine the behavior of the aforementioned methods for solving the problem (1.1) for two different matrices A. The right hand sides B = [b 1 ; b 2 ; :::; b s ], with s 8, were chosen as follows: b 1 = <ref> [1; 1; 1; :::; 1] </ref> T ; b 2 = [1; 1; 1; 1; :::] T ; b 3 = [1; 1; 1; 1; 1; 1; 1; 1; :::] T ; b 4 = [1; 1; 1; 1; 1; 1; 1; 1; :::] T ; b 5 = RAND (n; 1); <p> The right hand sides B = [b 1 ; b 2 ; :::; b s ], with s 8, were chosen as follows: b 1 = [1; 1; 1; :::; 1] T ; b 2 = <ref> [1; 1; 1; 1; :::] </ref> T ; b 3 = [1; 1; 1; 1; 1; 1; 1; 1; :::] T ; b 4 = [1; 1; 1; 1; 1; 1; 1; 1; :::] T ; b 5 = RAND (n; 1); b 6 = e 1 ; b 7 = e <p> The right hand sides B = [b 1 ; b 2 ; :::; b s ], with s 8, were chosen as follows: b 1 = [1; 1; 1; :::; 1] T ; b 2 = [1; 1; 1; 1; :::] T ; b 3 = <ref> [1; 1; 1; 1; 1; 1; 1; 1; :::] </ref> T ; b 4 = [1; 1; 1; 1; 1; 1; 1; 1; :::] T ; b 5 = RAND (n; 1); b 6 = e 1 ; b 7 = e 2 ; b 8 = e n . <p> 2 ; :::; b s ], with s 8, were chosen as follows: b 1 = [1; 1; 1; :::; 1] T ; b 2 = [1; 1; 1; 1; :::] T ; b 3 = <ref> [1; 1; 1; 1; 1; 1; 1; 1; :::] </ref> T ; b 4 = [1; 1; 1; 1; 1; 1; 1; 1; :::] T ; b 5 = RAND (n; 1); b 6 = e 1 ; b 7 = e 2 ; b 8 = e n . <p> We finally mention that in the context of methods for the solution of systems with multiple right hand sides, block versions of transpose free, nonsymmetric Lanczos methods such as QMR [2] or <ref> [1] </ref> may be a good alternative to block GMRES and the other methods described in the paper. Acknowledgments. We would like to thank Miloud Sadkane for providing us with the BGMRES programs and Randall Bramley and Paul Saylor for helpful discussions.
Reference: [2] <author> R. W. FREUND, </author> <title> A transpose-free quasi-minimal residual algorithm for non-Hermitian linear systems, </title> <type> tech. rep., </type> <institution> RIACS, NASA Ames Research Center, </institution> <month> Sept. </month> <year> 1991. </year> <note> Presented at the Fourth SIAM Conf. Appl. Lin. Alg., Minneapolis. </note>
Reference-contexts: We finally mention that in the context of methods for the solution of systems with multiple right hand sides, block versions of transpose free, nonsymmetric Lanczos methods such as QMR <ref> [2] </ref> or [1] may be a good alternative to block GMRES and the other methods described in the paper. Acknowledgments. We would like to thank Miloud Sadkane for providing us with the BGMRES programs and Randall Bramley and Paul Saylor for helpful discussions.
Reference: [3] <author> Y. HUANG AND H. VAN DER VORST, </author> <title> Some observations on the convergence behavior of GMRES, </title> <type> Tech. Rep. 89-09, </type> <institution> Faculty of Technical Mathematics and Informatics, Delft University of Technology, Delft, </institution> <year> 1989. </year>
Reference-contexts: Nevertheless, for the reasons discussed in Section 2 we expect MHGMRES to be an attractive alternative to BBCG. We next illustrate the point made in Section 3 regarding the behavior of BGMRES (m; s) as m and s vary. The sensitivity of GMRES (m) on m is well known <ref> [3] </ref>. For BGMRES (m; s) there is an additional parameter s affecting convergence. It was shown in [17] that as with the block CG and BBCG methods of [6], BGMRES can benefit from a larger s. We discuss here the effect of s on the restarted form of BGMRES.
Reference: [4] <author> T. MANTEUFFEL, </author> <title> Adaptive procedure for estimating parameters for the nonsymmetric Tchebychev iteration, </title> <journal> Numer. Math., </journal> <volume> 31 (1978), </volume> <pages> pp. 183-208. </pages>
Reference-contexts: This example is from <ref> [4] </ref>. The right hand sides were random vectors with values in the range (0; 1). Table 1 shows the number of restarts necessary for BGMRES to converge, as m and s vary.
Reference: [5] <author> N. M. NACHTIGAL, L. REICHEL, AND L. N. TREFETHEN, </author> <title> A hybrid GMRES algorithm for nonsymmetric matrix iterations, </title> <note> SIAM J. Matrix Anal. Appl., (to appear). </note>
Reference-contexts: See for example <ref> [5, Eq. 4.5] </ref>. In practice, function COEF builds C m column by column in the course of the modified Gram-Schmidt procedure. In line 10 the least squares problems min y j 2R m kHy j V m+1 r j k, j = 1; : : : ; s are solved. <p> Unfortunately, except for special cases, there is no a priori information to guarantee the quality of the approximation. We thus propose to apply Richard-son iteration to improve the approximation. The combination of GMRES with Richardson was inspired by recent work on hybrid methods [13][14] and in particular <ref> [5] </ref>. As described in [5], the use of the GMRES polynomial for the Richardson step is less likely to lead to the problems encountered with approximating the (convex hull of the) spectrum first from the Arnoldi procedure, followed by the generation of the Richardson iteration polynomial for the convex hull. <p> We thus propose to apply Richard-son iteration to improve the approximation. The combination of GMRES with Richardson was inspired by recent work on hybrid methods [13][14] and in particular <ref> [5] </ref>. As described in [5], the use of the GMRES polynomial for the Richardson step is less likely to lead to the problems encountered with approximating the (convex hull of the) spectrum first from the Arnoldi procedure, followed by the generation of the Richardson iteration polynomial for the convex hull. <p> One difference with the algorithm presented in <ref> [5] </ref> is that we are using restarting, instead of either (i) the repeated implementation of the Richardson step, or (ii) the continuation of the GMRES process where is left off, since that would lead to an increase in the memory requirements made by the algorithm. <p> A comment was made in <ref> [5, p. 21] </ref> for handling multiple right hand sides. The idea was to apply the GMRES phase of the algorithm to all the residuals and then use the best polynomial amongst the ones generated for the subsequent Richardson phase. <p> The first columns of both tables correspond to s = 1 and demonstrate the behavior of the restarted hybrid GMRES method of <ref> [5] </ref> (rows MHGMRES) relative to GMRES (m) (rows BGMRES). As discussed in Section 6, method BGMRES (m; s) mostly profits from its block strategy and exhibits impressive reductions in matrix vector multiplications as s increases only when m is large.
Reference: [6] <author> D. P. O'LEARY, </author> <title> The block conjugate gradient algorithm and related methods, </title> <journal> Lin. Alg. Appl., </journal> <volume> 29 (1980), </volume> <pages> pp. 293-322. </pages>
Reference-contexts: We would also like these methods to be applicable when the right hand sides b j are not all available at the same time. When matrix A is symmetric the block CG algorithm described in <ref> [6] </ref> as well as the method in [12] are appropriate for handling problem (1.1) while the Lanczos scheme described in [10] and the method of [16] are suitable when not all b j 's available. The literature for nonsymmetric systems with multiple right hand sides is less well developed. <p> The literature for nonsymmetric systems with multiple right hand sides is less well developed. In particular, two methods have been discussed, which are block generalizations of solvers for nonsymmetric systems. These are the block biconjugate gradient algorithm described in <ref> [6] </ref> and block GMRES, discussed in [17]. In this paper we propose an alternative scheme to the latter two block methods. <p> Several comments on the complexity of the methods are presented in Section 6. Finally numerical experiments and conclusions are presented in Sections 7 and 8. 2. Block BCG. The BCG algorithm was generalized to handle problem (1.1) in <ref> [6] </ref>. This BBCG algorithm is outlined next in a MATLAB-like language. <p> This is monitored by re-orthogonalizing during the iteration and restarting the algorithm with deflated right hand side when rank-deficiency is detected <ref> [6] </ref>. Finally, an organization drawback of the method is that it requires the use of the transpose of A. 3. Block GMRES. This was described in [17]. We first introduce some notation. <p> Function NEWROT computes and applies the s 2 rotations necessary to update T . Mathematically, BGMRES is an excellent choice as it carries the convergence advantage of the block methods of <ref> [6] </ref>, namely that the solution cost per system is lower than if the systems were to be solved separately [17], while the method does not suffer from the problems of BBCG, in particular due to the loss of full rank of the search direction block. <p> The sensitivity of GMRES (m) on m is well known [3]. For BGMRES (m; s) there is an additional parameter s affecting convergence. It was shown in [17] that as with the block CG and BBCG methods of <ref> [6] </ref>, BGMRES can benefit from a larger s. We discuss here the effect of s on the restarted form of BGMRES.
Reference: [7] <author> G. OPFER AND G. SCHOBER, </author> <title> Richardson's iteration for nonsymmetric matrices, </title> <journal> Lin. Alg. Appl., </journal> <volume> 58 (1984), </volume> <pages> pp. 343-361. </pages>
Reference-contexts: We use the Leja ordering, constructed via function LEJA, which was shown to be robust for this purpose [5][8][9]. 4 Complex values are avoided by pairing complex roots and their conjugates <ref> [7] </ref>. Function RICHARDSON applies the polynomial q m (A) to each of the residuals r j ; j = 1; : : : ; s. 4.1. Discussion. The memory-conserving attribute of the algorithm is a direct consequence of the fact that only one subspace is being generated at each step.
Reference: [8] <author> L. REICHEL, </author> <title> Newton interpolation at Leja points, </title> <journal> BIT, </journal> <volume> 30 (1990), </volume> <pages> pp. </pages> <month> 332-346. </month> <title> [9] , The application of Leja points to Richardson iteration and polynomial preconditioning, </title> <journal> Lin. Alg. Appl., </journal> <month> 154-156 </month> <year> (1991), </year> <pages> pp. 389-414. </pages>
Reference: [10] <author> Y. SAAD, </author> <title> On the Lanczos method for solving symmetric systems with several right hand sides, </title> <journal> Math. Comp., </journal> <month> 48 (Apr. </month> <year> 1987), </year> <pages> pp. 651-662. </pages>
Reference-contexts: When matrix A is symmetric the block CG algorithm described in [6] as well as the method in [12] are appropriate for handling problem (1.1) while the Lanczos scheme described in <ref> [10] </ref> and the method of [16] are suitable when not all b j 's available. The literature for nonsymmetric systems with multiple right hand sides is less well developed. In particular, two methods have been discussed, which are block generalizations of solvers for nonsymmetric systems. <p> The method uses one subspace as a generator of approximations, a projection process, and a Richardson acceleration technique. It thus combines the advantages of recent hybrid techniques [5][13][14] with the methods of <ref> [10] </ref> for solving symmetric systems with multiple right hand sides. The structure of the paper is as follows: Sections 2 and 3 review the block BCG and block GMRES algorithms. Sections 4 and 5 describe the new method and its convergence properties. <p> Error bounds for this approximation, when A is symmetric positive definite, and x := x 1 were obtained in <ref> [10] </ref>. Unfortunately, except for special cases, there is no a priori information to guarantee the quality of the approximation. We thus propose to apply Richard-son iteration to improve the approximation. The combination of GMRES with Richardson was inspired by recent work on hybrid methods [13][14] and in particular [5]. <p> Then the residuals ~r j obtained after the application of GMRES (m; s) satisfy: k~r j k k (I P m+1 )r j k + jff 0 j 2* where ffi m = inf p (0)=1 5 We note that Theorem 5.1 is a generalization of Theorem 3.1 of <ref> [10] </ref>. We refer to [15] regarding the notion of pseudo-eigenvalues. The magnitude of the residual depends on the distance of the previous residual from the space spanned by the seed system as well as on the polynomial approximation problem defined on the *-pseudo-spectrum.
Reference: [11] <author> Y. SAAD AND M. H. SCHULTZ, </author> <title> GMRES: A generalizedminimal residual algorithm for solving nonsymmetric linear systems, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <month> 7 (July </month> <year> 1986), </year> <pages> pp. 856-869. </pages>
Reference-contexts: In particular, since the memory requirements of standard GMRES grow linearly in m, the presence of multiple right hand sides in the block version is bound to exacerbate the storage problem. This problem is handled in GMRES by applying a restarted or truncated form GMRES (m) <ref> [11] </ref>. This however causes loss of the properties of finite termination and minimization over the entire Krylov subspace [3][11].
Reference: [12] <author> M. SADKANE AND B. </author> <title> VITAL, Davidson's method for linear systems of equations. Implementation of a block algorithm on a multi-processor, </title> <type> Tech. Rep. </type> <institution> TR/PA/91/60, CERFACS, Toulouse, </institution> <month> Sep. </month> <year> 1991. </year>
Reference-contexts: We would also like these methods to be applicable when the right hand sides b j are not all available at the same time. When matrix A is symmetric the block CG algorithm described in [6] as well as the method in <ref> [12] </ref> are appropriate for handling problem (1.1) while the Lanczos scheme described in [10] and the method of [16] are suitable when not all b j 's available. The literature for nonsymmetric systems with multiple right hand sides is less well developed.
Reference: [13] <author> P. E. SAYLOR AND D. C. SMOLARSKI, </author> <title> Implementation of an adaptive algorithm for Richardson's method, </title> <journal> Lin. Alg. Appl., </journal> <year> (1991), </year> <pages> pp. 615-646. </pages>
Reference: [14] <author> G. STARKE AND R. S. VARGA, </author> <title> A hybrid Arnoldi-Faber iterative method for nonsymmetric systems of linear equations, </title> <type> Tech. Rep. </type> <institution> ICM-9108-11, Institute for Computational Mathematics, Kent State University, Kent, </institution> <month> Aug. </month> <year> 1991. </year>
Reference: [15] <author> L. N. TREFETHEN, </author> <title> Approximation theory and numerical linear algebra, in Algorithms for Approximation II, </title> <editor> J. C. Mason and M. G. Cox, eds., </editor> <publisher> Chapman and Hall, </publisher> <year> 1990. </year>
Reference-contexts: We refer to <ref> [15] </ref> regarding the notion of pseudo-eigenvalues. The magnitude of the residual depends on the distance of the previous residual from the space spanned by the seed system as well as on the polynomial approximation problem defined on the *-pseudo-spectrum.
Reference: [16] <author> H. VAN DER VORST, </author> <title> An iterative solution method for solving f (A)x = b using Krylov subspace information obtained for the symmetric positive definite matrix A, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 18 (1987), </volume> <pages> pp. 249-263. </pages>
Reference-contexts: When matrix A is symmetric the block CG algorithm described in [6] as well as the method in [12] are appropriate for handling problem (1.1) while the Lanczos scheme described in [10] and the method of <ref> [16] </ref> are suitable when not all b j 's available. The literature for nonsymmetric systems with multiple right hand sides is less well developed. In particular, two methods have been discussed, which are block generalizations of solvers for nonsymmetric systems.
Reference: [17] <author> B. </author> <title> VITAL, Etude de quelques methodes de resolution de problemes lineaires de grande taille sur multipro-cesseur, </title> <type> PhD thesis, </type> <institution> Universite de Rennes I, Rennes, </institution> <month> Nov. </month> <year> 1990. </year> <month> 9 </month>
Reference-contexts: The literature for nonsymmetric systems with multiple right hand sides is less well developed. In particular, two methods have been discussed, which are block generalizations of solvers for nonsymmetric systems. These are the block biconjugate gradient algorithm described in [6] and block GMRES, discussed in <ref> [17] </ref>. In this paper we propose an alternative scheme to the latter two block methods. Compared to block BCG this method shares with (block) GMRES the advantage of being transpose-free and being less prone to breakdown due to the composition of the right hand sides. <p> The pseudo-norm k:k of a matrix R is defined as the maximum amongst the 2-norms of each column of the matrix. Function BMGS is a block version of the modified Gram-Schmidt algorithm <ref> [17] </ref>. Given a matrix R, BMGS (R) calculates fl and P such that P = Rfl has orthogonal columns. ~ R is chosen for ( ~ R; R) not to be zero at the initialization step, where (U; V ) denotes the block inner product U T V . <p> This is monitored by re-orthogonalizing during the iteration and restarting the algorithm with deflated right hand side when rank-deficiency is detected [6]. Finally, an organization drawback of the method is that it requires the use of the transpose of A. 3. Block GMRES. This was described in <ref> [17] </ref>. We first introduce some notation. Block U i (i = 1; : : : ; m + 1) is of dimension n fi s and denotes the i th block of the orthogonal basis of the Krylov subspace K m (A; R). <p> Mathematically, BGMRES is an excellent choice as it carries the convergence advantage of the block methods of [6], namely that the solution cost per system is lower than if the systems were to be solved separately <ref> [17] </ref>, while the method does not suffer from the problems of BBCG, in particular due to the loss of full rank of the search direction block. There are however some practical disadvantages with the method. <p> We next illustrate the point made in Section 3 regarding the behavior of BGMRES (m; s) as m and s vary. The sensitivity of GMRES (m) on m is well known [3]. For BGMRES (m; s) there is an additional parameter s affecting convergence. It was shown in <ref> [17] </ref> that as with the block CG and BBCG methods of [6], BGMRES can benefit from a larger s. We discuss here the effect of s on the restarted form of BGMRES. Borrowing notation from [17], once the Krylov subspace K m (A; R) has been computed, the norm of the <p> It was shown in <ref> [17] </ref> that as with the block CG and BBCG methods of [6], BGMRES can benefit from a larger s. We discuss here the effect of s on the restarted form of BGMRES. Borrowing notation from [17], once the Krylov subspace K m (A; R) has been computed, the norm of the residual J s;R (Y 1 ; : : : ; Y m ) = kR (ARY 1 + : : : + A m RY m )k has to be minimized. <p> Here Y 1 ; : : : ; Y m are s fi s matrices with Y i being matrix with diagonal (ff i s ), for i = 1; : : : ; m. It was shown in <ref> [17] </ref> that the following holds: min i=1;:::;s ff i kR (:; i) (ff i m A m R (:; i))k ]: Hence the solution of the least squares problem for the block version leads to a residual which is smaller than the larger residual of the non-block version. <p> All numbers except those corresponding to BBCG were obtained using Fortran on an Al-liant FX/2800 multiprocessor and 64-bit arithmetic. The BGMRES (m; s) code is a modification of Fortran codes due to Sadkane and Vital <ref> [17] </ref>. The numbers for BBCG were obtained using MATLAB 4.0 on a Sun Sparkstation. The stopping criterion is kr k k=kr 0 k 1:e 6 for some k &gt; 0.
References-found: 16

