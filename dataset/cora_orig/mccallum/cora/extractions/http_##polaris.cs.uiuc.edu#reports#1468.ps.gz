URL: http://polaris.cs.uiuc.edu/reports/1468.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: raynaud,zzhang,torrella@csrd.uiuc.edu  
Title: Distance-Adaptive Update Protocols for Scalable Shared-Memory Multiprocessors 1  
Author: Alain Raynaud, Zheng Zhang, and Josep Torrellas 
Address: IL 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign,  
Abstract: While update protocols generally induce lower miss rates than invalidate protocols, they tend to generate much traffic. This is one of the reasons why they are considered less cost-effectively scalable than invalidate protocols and, as a result, are avoided in most existing designs of scalable shared-memory multiprocessors. However, given the increasing relative cost of cache misses, update protocols are becoming more worthy of exploration. In this paper, we present a model of sharing that is key to investigating the performance of optimized update protocols: the Update Distance Model. The model gives insight into the update patterns that optimized protocols need to handle. Using this model, we design a new family of protocols that we call Distance-Adaptive Protocols. In these schemes, the directory records the update patterns observed and then uses them to selectively send updates and invalidations to processors. As a result, traffic and miss rates are kept low. We present an implementation of these protocols based on a dynamic pointer scheme. A performance comparison between one of these protocols and efficient invalidate and delayed competitive-update protocols over five applications shows that the new protocol decreases the execution time by an average of 15% and 10% respectively. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal. </author> <title> Limits on Interconnection Network Performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 398-412, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: We use the release consistency model. The network is a 32-bit wide bidirectional mesh. While only shared data is simulated, all contention in the machine is modeled, including the network. For the network, we use the model proposed in <ref> [1] </ref>. The machine has the following read latencies without contention: 1 cycle for a primary cache hit, 15 cycles for a secondary cache hit, an average of 120 cycles for a 2-hop global memory access and an average of 180 cycles for a 3-hop global memory access.
Reference: [2] <author> F. Dahlgren and P. Stenstrom. </author> <title> Reducing the Write Traffic for a Hybrid Cache Protocol. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 26(2) </volume> <pages> 193-210, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Obviously, the threshold used directly influences the resulting traffic. A study by Nilsson et al [10] found that a threshold of four is an optimal choice. A second study by Dahlgren and Stenstrom <ref> [2] </ref> using write caches in the context of relaxed consistency concluded that a threshold of one is sufficient. A second technique to reduce traffic is update combining. Basic combining of updates has been proposed by Glasco et al [5]. <p> Basic combining of updates has been proposed by Glasco et al [5]. One class of protocols that provides opportunities for combining is delayed protocols, proposed and described by Dubois et al [3] in the context of invalidate protocols. Write caches constitute one implementation of combining <ref> [2] </ref>. A final technique to reduce traffic is to extend migratory data detection and handling to update protocols. This has been presented by Nilsson and Stenstrom [9]. The idea is to use an invalidate protocol for migratory data and an update protocol for the rest.
Reference: [3] <author> M. Dubois, L. Barroso, J.C. Wang, and Y.S. Chen. </author> <title> Delayed Consistency and its Effects on the Miss Rate of Parallel Programs. </title> <booktitle> In Supercomputing 91, </booktitle> <pages> pages 197-206, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: A second technique to reduce traffic is update combining. Basic combining of updates has been proposed by Glasco et al [5]. One class of protocols that provides opportunities for combining is delayed protocols, proposed and described by Dubois et al <ref> [3] </ref> in the context of invalidate protocols. Write caches constitute one implementation of combining [2]. A final technique to reduce traffic is to extend migratory data detection and handling to update protocols. This has been presented by Nilsson and Stenstrom [9]. <p> This environment, however, can be approximated by using a delayed protocol. Delayed invalidate schemes were proposed by Dubois et al <ref> [3] </ref> and can be trivially extended to update schemes. In these schemes, the updates issued by a processor-cache node are combined in a write cache and propagated to the rest of the system only at release points. This combining reduces the traffic and exposes the behavior that we seek. <p> Note, however, that in the receiver cache, the update should be processed immediately. Indeed, if the consumer does not immediately acknowledge the update or the invalidation of the line, the competitive behavior may be lost and many update messages may be sent. Therefore, we use send-delayed protocols <ref> [3] </ref>, not receive-delayed. Finally, since competitive updates do not handle migratory data well, we add a scheme proposed by Nilsson and Stenstrom [9] to detect migratory data in update protocols.
Reference: [4] <author> S. J. Eggers and R. H. Katz. </author> <title> A Characterization of Sharing in Parallel Programs and its Application to Coherency Protocol Evaluation. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 373-382, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Much more importantly, however, there is no framework that illuminates the features that advanced update protocols need to provide to successfully minimize misses and traffic. Indeed, previous models like Eggers and Katz's write run model <ref> [4] </ref> do not necessarily provide such insights for advanced protocols like delayed update protocols. In this paper, we present a new model of sharing that gives such insights: the Update Distance model. Then, using the model, we design a new family of scalable update protocols called Distance-Adaptive Protocols. <p> This model, called the Update Distance model, is useful because it shows how well optimized update protocols can perform. Older models, like Eggers and Katz's write run model <ref> [4] </ref>, do not provide the right insight for advanced protocols like delayed update protocols. In the following, we first present our model and then apply it to the applications. 3.1 The Update Distance Model The model is based on the concept of update distance.
Reference: [5] <author> D. Glasco, B. Delagi, and M. Flynn. </author> <title> Update-Based Cache Coherence Protocols for Scalable Shared-Memory Multiprocessors. </title> <booktitle> In Proceedings of the 27st Annual Hawaii International Conference of System Sciences, </booktitle> <pages> pages 543-545, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: A second study by Dahlgren and Stenstrom [2] using write caches in the context of relaxed consistency concluded that a threshold of one is sufficient. A second technique to reduce traffic is update combining. Basic combining of updates has been proposed by Glasco et al <ref> [5] </ref>. One class of protocols that provides opportunities for combining is delayed protocols, proposed and described by Dubois et al [3] in the context of invalidate protocols. Write caches constitute one implementation of combining [2].
Reference: [6] <author> S. Goldschmidt. </author> <title> Simulation of Multiprocessors: Accuracy and Performance. </title> <type> Ph.D. Thesis, </type> <institution> Stanford University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: The fourth column shows the most frequent type of data sharing pattern in the applications. The patterns can be migratory (Mig), producer-consumer (P-C), or a mixture of several patterns (Mix). 2.2 Simulation Environment We perform detailed execution-driven simulations of a shared-memory multiprocessor. We use TangoLite <ref> [6] </ref> to simulate a 24-node NUMA multiprocessor.
Reference: [7] <author> A.R. Karlin, M.S. Manasee, L. Rudolph, and D.D. Sleator. </author> <title> Competitive Snoopy Caching. </title> <booktitle> In Proceedings of the 27th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 244-254, </pages> <year> 1986. </year>
Reference-contexts: This is especially true if we can design update protocols with low traffic requirements. In recent years, several techniques have been proposed to reduce the traffic in update protocols. The first one is to add a competitive threshold to the updates <ref> [7] </ref>: after a certain threshold number of updates have been received by a cache whose processor has not used the data in the meantime, the data is invalidated. Obviously, the threshold used directly influences the resulting traffic. <p> Figure 1 shows an example of the update distance for a reference. that processor 1 issues a read and a write reference re spectively. All references access the same word. The intuition behind the update distance model is to determine how well a competitive update protocol <ref> [7] </ref> performs in an optimistic scenario. Imagine an ideal scenario where a processor could read and write a variable several times and not update anything until just before a second processor accessed the variable. At that point, the first processor would update all the sharers.
Reference: [8] <author> J. Kuskin et al. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: In the following, we describe the first two modules. Directory Module We support distance-adaptive protocols by using a slightly-modified directory with dynamic pointers. Dynamic pointers have been proposed by Simoni and Horowitz [11] and implemented in FLASH <ref> [8] </ref>. In a dynamic pointer scheme, each link in a linked-list stores the ID of the sharer processor.
Reference: [9] <author> H. Nilsson and P. Stenstrom. </author> <title> An Adaptive Update-Based Cache Coherence Protocol for Reduction of Miss Rate and Traffic. </title> <booktitle> In Proceedings of Parallel Architectures and Languages Europe (PARLE'94), </booktitle> <pages> pages 363-374, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Write caches constitute one implementation of combining [2]. A final technique to reduce traffic is to extend migratory data detection and handling to update protocols. This has been presented by Nilsson and Stenstrom <ref> [9] </ref>. The idea is to use an invalidate protocol for migratory data and an update protocol for the rest. This scheme reduces the traffic because migratory data is particularly traffic-intensive under update protocols. <p> Therefore, we use send-delayed protocols [3], not receive-delayed. Finally, since competitive updates do not handle migratory data well, we add a scheme proposed by Nilsson and Stenstrom <ref> [9] </ref> to detect migratory data in update protocols. <p> Unfortunately, traffic reduction has only a second-order effect on the latency of misses. For this reason, we propose to improve the migratory data handling in <ref> [9] </ref> by forcing the processor operating on the migratory data to update the home memory at re lease time. Consequently, when a new processor requests the data, it will get it directly from the home node in 2 hops instead of from a third node in 3 hops. <p> This protocol is quite sophis ticated. * CompUp: Non-delayed competitive update with thresh old of one. We call it base update protocol. Delayed competitive update protocols: * DCU: Delayed competitive update with a threshold of one. * DCU+Mg: DCU with Nilsson's migratory data han dling <ref> [9] </ref>. * DCU+Mg+Hm: DCU+Mg plus the home memory update optimization for migratory data that we propose in Section 4.1.1. Distance-adaptive protocols.
Reference: [10] <author> H. Nilsson, P. Stenstrom, and M. Dubois. </author> <title> Implementation and Evaluation of Update-Based Cache Protocols Under Relaxed Memory Consistency Models. </title> <booktitle> In Future Generation Computer Systems, </booktitle> <pages> pages 247-271, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Obviously, the threshold used directly influences the resulting traffic. A study by Nilsson et al <ref> [10] </ref> found that a threshold of four is an optimal choice. A second study by Dahlgren and Stenstrom [2] using write caches in the context of relaxed consistency concluded that a threshold of one is sufficient. A second technique to reduce traffic is update combining.
Reference: [11] <author> R. Simoni and M. Horowitz. </author> <title> Dynamic Pointer Allocation for Scalable Cache Coherence Directories. </title> <booktitle> In proceedings of the International Symposium on Shared Memory Multiprocessing, </booktitle> <pages> pages 72-81, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This is true for all iterative and loop-based algorithms and, indeed, we have yet to find an application which does not exhibit such behavior. These protocols can be efficiently implemented using a directory with dynamic pointers <ref> [11] </ref> with some modifications. In the following, we start by describing the most basic protocol in this family, which we call Base Distance-Adaptive; then, we examine a more advanced one called Advanced Distance-Adaptive; finally we discuss their implementation. <p> Finally, the message module builds and decodes messages and is not specific to distance-adaptive protocols. In the following, we describe the first two modules. Directory Module We support distance-adaptive protocols by using a slightly-modified directory with dynamic pointers. Dynamic pointers have been proposed by Simoni and Horowitz <ref> [11] </ref> and implemented in FLASH [8]. In a dynamic pointer scheme, each link in a linked-list stores the ID of the sharer processor. <p> In the following, we analyze the resulting storage overhead and any slowdown caused by the use of distance-adaptive protocols. The addition of these fields does not increase the directory storage much. For instance, assume the implementation described by Simoni and Horowitz <ref> [11] </ref> and that each processor node has 32 Mbytes of main memory. We run our applications under an invalidate, competitive update, and the two distance-adaptive protocols. We select the applica tion that requires the largest number of links.
Reference: [12] <author> J. P. Singh, W. Weber, and A. Gupta. </author> <title> SPLASH: Stan-ford Parallel Applications for Shared-Memory. </title> <type> Technical Report CSL-TR-91-469, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: Since all sections of the paper refer to the applications and simulation system used, we introduce them first in this section. 2.1 Applications We use a subset of the parallel applications in the Splash benchmark suite <ref> [12] </ref>. Table 1 describes what they do and their input data sizes. The fourth column shows the most frequent type of data sharing pattern in the applications.
Reference: [13] <author> P. Stenstrom, M. Brorsson, and L. Sandberg. </author> <title> An Adaptive Cache Coherence Protocol Optimized for Migratory Sharing. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 109-118, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: As a reference, we also evaluate state of the art non-delayed invalidate and update protocols. The protocols that we examine are: Protocols used as a reference: * Inval+Mg: Non-delayed invalidate with migratory data handling as described in <ref> [13] </ref>. We call this protocol base invalidate protocol. This protocol is quite sophis ticated. * CompUp: Non-delayed competitive update with thresh old of one. We call it base update protocol.
Reference: [14] <author> W. Weber and A. Gupta. </author> <title> Analysis of Cache Invalidation Patterns in Multiprocessors. </title> <booktitle> In Proceedings of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 243-256, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: MP3D and Water have the typical (1,1) peak, created by several data structures. In addition, however, they also have other shapes generated mostly by migratory data. Migratory data <ref> [14] </ref> is data that is accessed in sequence by different processors. When a processor accesses the data, it first reads it, and then performs a series of reads and writes number of instances of an update distance x preceded by an update distance y.
References-found: 14

