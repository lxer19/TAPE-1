URL: http://www.cs.umn.edu/Users/dept/users/du/papers/flips_framework.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/du/papers/
Root-URL: http://www.cs.umn.edu
Email: schnepf@csbsju.edu, fylee,du,kang,laig@cs.umn.edu  
Title: Building A Framework for FLexible Interactive Presentations  
Author: James A. Schnepf Yen-Jen Lee, David H.C. Du, Lan Lai Liang-Wei Kang 
Keyword: FLIPS, multimedia, synchronization, authoring, content-based search  
Note: This work was conducted while the author was a PhD candidate in  Authors' e-mail addresses are:  Support provided by US WEST, Honeywell, IVI Publishing, Computing Devices International, and Network Systems This work was conducted while the author was an MS student in  
Address: Collegeville, Minnesota, USA  Minneapolis, Minnesota, USA  Hsinchu, Taiwan, ROC  USA  
Affiliation: Computer Science Department College of St. Benedict/St. John's University  Distributed Multimedia Research Center Department of Computer Science University of Minnesota  Computer Communication Research Laboratories Industrial Technology Research Institute  Department of Computer Science, University of Minnesota, Minneapolis, Minnesota,  Department of Computer Science, University of Minnesota, Minneapolis, Minnesota, USA  
Abstract: As presentation technology advances, it is possible to incorporate a wider range of media including variable duration media such as simulations and animations. At the same time, users are able to take more control over presentations by controlling the rate and selection of media being played. To make full use of these advances, multimedia systems must support flexible presentations that incorporate many variations in the way they are played. As a result of content-based searches and other methods of selections such as a selection from an index of slides, viewers may skip to different parts of a presentation or start viewing a presentation in the middle. These presentations must remain semantically coherent in the face of these interactions. This paper presents the work we have done to design and implement a framework to support the inclusion of diverse media displayers into a presentation and to support user interaction. The implementation maintains a consistent and coherent presentation in the face of user interactions such as skipping forward and backward to different points within the presentation or modifying the speed of a single media segment. The implementation is modular and allows easy inclusion of new media types and displayers. The framework allows the displayer to control the navigation within an object (pause, fast-forward, reverse) while synchronization among objects is handled by the framework. The implementation also provides an easy-to-use authoring tool to compose a presentation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Schnepf, V. Mashayekhi, J. Riedl, and D. Du. </author> <title> Closing the gap in distance learning: Computer-supported, </title> <journal> participative, media-rich education. ED-TECH Review, </journal> <month> fall/winter </month> <year> 1994. </year>
Reference-contexts: Course presentations can be captured and stored to allow students access to the university according to their own schedules and at locations of their choosing <ref> [1] </ref>. Viewers control the pace of their learning by pausing, skipping forward and backward in the presentation, and interacting with dynamic media displayers 1 that incorporate viewer interaction into the presentation. Hypermedia objects, for example, allow a user to explore a presentation segment in greater or lesser detail.
Reference: [2] <author> Little T.D.C. etal. </author> <title> A digital on-demand video service supporting content-based queries. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 427-436. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: An area where the application has great potential is to integrate this presentation application with content-based search tools. Researchers have been developing schemes for content-based searches. Recent work on searches on video databases using metabases include the work of Little et al. <ref> [2] </ref> and Rowe et al. [3]. Rowe et al. have defined query interfaces that provide relational, hierarchical browsing, and keyword search operations to the metadata indices.
Reference: [3] <author> L.A. Rowe, J. S. Boreczky, and C. A. Eads. </author> <title> Indexes for user access to large video databases. In Proceedings of Storage and Retrieval for Image and Video Databases II, </title> <booktitle> IS&T/SPIE Symposium on Elec. </booktitle> <institution> Imaging Sci. & Tech., </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: An area where the application has great potential is to integrate this presentation application with content-based search tools. Researchers have been developing schemes for content-based searches. Recent work on searches on video databases using metabases include the work of Little et al. [2] and Rowe et al. <ref> [3] </ref>. Rowe et al. have defined query interfaces that provide relational, hierarchical browsing, and keyword search operations to the metadata indices. But until now, there was not a reasonable way to jump into the middle of a presentation of multiple media streams based on these searches.
Reference: [4] <author> J. Schnepf, J. Konstan, and D. Du. </author> <title> Doing FLIPS: FLexible Interactive Presentation Synchronization. </title> <journal> IEEE Journal on Selected Areas in Communications. </journal> <note> To be published in special issue on multimedia synchronization. </note>
Reference-contexts: Our implementation provides the ability to view and interact with a flexible presentation that can incorporate standard media displayers as well as many nonstandard displayers such as simulations and visualizations. Our framework supports an event-based model, FLexible Interactive Presentation Synchronization (FLIPS) <ref> [4] </ref>, that can handle the synchronization of variable duration objects and a wider range of specifications than the typical binary equality relation of many models. This model, together with the enforcement mechanism, provides a richer presentation environment that supports user interaction in a multimedia presentation. <p> The entire specification is in effect a network of media objects connected by enabler and barrier links to the begin and end events of the objects. A detailed description is beyond the scope of this paper and can be found in <ref> [4] </ref>. A possible specification for the architecture example is shown in Figure 1. Enablers are represented as A ! B and barriers are shown as A a B. 4 Systems Design The system design has a modular architecture built around a few simple data structures. <p> The presentation coordinator maintains the status of each object in the presentation. It maintains a valid global state in response to each event by propagating changes in the network of objects until a consistent state is reached (the algorithm is described in <ref> [4] </ref>). The presentation coordinator is event driven. When an event occurs, the presentation coordinator determines a valid global state and sends messages to the appropriate 5 media displayers to achieve that state. <p> When a change occurs in one of the displayers or the user interface, the appropriate module sends a message (DONE or JUMP) to the coordinator notifying it of that change. When a message arrives, the coordinator navigates the presentation graph, updating each node according to the synchronization algorithm <ref> [4] </ref>. When a valid global state is achieved, it generates and sends STOP and START messages to the appropriate media displayers to achieve that state. This can be better understood by viewing an example. <p> The presentation specification generated through the authoring 15 16 tool then uses that object name for the presentation interface. The Media Specific check box in the parameter window implements Alternative Actions defined in the FLIPS model <ref> [4] </ref>. The user can define the duration of display and the action taken after the display comes to an end but must wait for barriers to be removed. Common alternative actions for a media object include holding the display until the barrier is satisfied or looping through the object again. <p> These abstractions are covered in more detail in <ref> [4] </ref>. The authoring tool maintains the consistency between objects and their relations with other objects.
Reference: [5] <author> L.A. Rowe and B.C. Smith. </author> <title> A continuous media player. </title> <booktitle> In Proceedings Third International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Fine-grain synchronization (e.g. lip-synching) is not handled directly, but is integrated by incorporating composite objects representing fine grain synchronization along with an appropriate displayer such as the Berkeley CM Player <ref> [5] </ref>. The organization of the paper is as follows. Section 2 relates our design to other work. In section 3, we provide an example of a flexible presentation and the basic constructs used in the FLIPS model. <p> Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work The specification, modeling and enforcement of temporal synchronization has been the subject of much research. Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. <p> If the slide corresponds to a different narrative, the appropriate narrative (or background music) is started. This differs from the timeline model such as is used in the CM Player <ref> [5] </ref>, where any shift in the presentation affects all the corresponding objects. In addition, each displayer could have its own user interface that allowed the viewer to control and interact with the individual object. The FLIPS model supports the specification of flexible presentations.
Reference: [6] <author> T.D.C. Little and A. Ghafoor. </author> <title> Spatial-temporal composition of distributed multimedia objects for value-added networks. </title> <booktitle> IEEE Computer, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work The specification, modeling and enforcement of temporal synchronization has been the subject of much research. Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. <p> Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [7] <author> T.D.C. Little and A. Ghafoor. </author> <title> Synchronization and storage models for multimedia objects. </title> <journal> IEEE Journal on Selected Areas of Communications, </journal> <month> April </month> <year> 1990. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work The specification, modeling and enforcement of temporal synchronization has been the subject of much research. Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. <p> Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [8] <author> B. Prabhakaran and S.V. Raghavan. </author> <title> Synchronization models for presentation with user participation. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 157-165. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work The specification, modeling and enforcement of temporal synchronization has been the subject of much research. Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10].
Reference: [9] <author> L. Hardman, G. vanRossum, and D. Bulterman. </author> <title> Structured multimedia authoring. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 283-289. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work The specification, modeling and enforcement of temporal synchronization has been the subject of much research. Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10].
Reference: [10] <author> D. Wijesekera, D. Kenchamanna-Hosekote, and J. Srivastava. </author> <title> Specification, verification, and translation of multimedia compositions. </title> <type> Technical report, </type> <institution> University of Minnesota, </institution> <year> 1994. </year>
Reference-contexts: Section 7 summarizes the results and describes the direction we are proceeding. 2 Comparison with Related Work The specification, modeling and enforcement of temporal synchronization has been the subject of much research. Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. <p> Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [11] <author> A. Poggio. CCWS: </author> <title> A computer-based multimedia information system. </title> <booktitle> IEEE Computer, </booktitle> <month> Oct </month> <year> 1985. </year>
Reference-contexts: Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [12] <author> L. Li, A. Karmouch, </author> <title> and N.D. Georganas. Multimedia teleorchestra with independent sources: Part 1 temporal modeling of collaborative multimedia scenarios. </title> <journal> ACM Multimedia Systems, </journal> <volume> 1(1) </volume> <pages> 143-153, </pages> <year> 1994. </year>
Reference-contexts: In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. Li, et al. <ref> [12] </ref> suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [13] <author> G. Blakowski et al. </author> <title> Tool support for the synchronization and presentation of distributed multimedia. </title> <journal> Computer Communications, </journal> <volume> 15(10) </volume> <pages> 611-618, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project <ref> [13] </ref>, Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [14] <author> M. C. Buchanan and P. T. Zellweger. </author> <title> Scheduling multimedia documents using temporal constraints. </title> <booktitle> In Proceedings Third International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly <ref> [14] </ref>, CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Drapeau in [16] allows for varied media displayers to be incorporated, but these applications must be modified to work with the Maestro system. The work of Buchanan and Zellweger <ref> [14] </ref> is the closest to ours. They also handle variable duration objects and asynchronous events such as user interactions. Their scheme differs from ours in their mapping of events to a timeline.
Reference: [15] <author> G. van Rossum, J. Jansen, K. Mullender, and D. Bulterman. CMIFed: </author> <title> A presentation system for portable hypermedia documents. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 183-188. </pages> <publisher> ACM, </publisher> <year> 1993. </year> <month> 19 </month>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed <ref> [15] </ref>, Maestro [16], Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [16] <author> G. Drapeau. </author> <title> Synchronization in the maestro multimedia authoring environment. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 331-339. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro <ref> [16] </ref>, Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. As in the models discussed above, the support of user interaction and skips presume that all concurrent media are affected by a jump. Drapeau in <ref> [16] </ref> allows for varied media displayers to be incorporated, but these applications must be modified to work with the Maestro system. The work of Buchanan and Zellweger [14] is the closest to ours. They also handle variable duration objects and asynchronous events such as user interactions.
Reference: [17] <author> R. Hamakawa and J. Rekimoto. </author> <title> Object composition and playback models for handling multimedia data. </title> <journal> ACM Multimedia Systems, </journal> <volume> 2(1) </volume> <pages> 26-35, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier <ref> [17] </ref>, and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [18] <author> S.Eun, E.S. No, H.C. Kim, H. Yoon, and S. R. Maeng. Eventor: </author> <title> an authoring system for interactive multimedia applications. </title> <journal> ACM Multimedia Systems, </journal> <volume> 2(3) </volume> <pages> 129-140, </pages> <month> September </month> <year> 1994. </year> <month> 20 </month>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor <ref> [18] </ref>. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this 3 supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
References-found: 18

