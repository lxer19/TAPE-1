URL: http://www.math.tau.ac.il/~megiddo/psfiles/focs95.ps.gz
Refering-URL: http://www.math.tau.ac.il/~megiddo/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-Mail: ajtai@almaden.ibm.com  E-Mail: megiddo@almaden.ibm.com  E-Mail: waarts@cs.berkeley.edu  
Title: Improved Algorithms and Analysis for Secretary Problems and Generalizations  
Author: Miklos Ajtai Nimrod Megiddo Orli Waarts 
Address: Center.  
Web: N-00014-94-C-0007.  N-00014-94-C-0007.  
Note: Research supported in part by ONR Contract  Research supported in part by ONR Contract  Research supported in part by ONR Contract N-00014-94-C-0007 and NSF postdoctoral fellowship. Part of this research was done while this author was  1 log k maxf1; log 2 kg.  
Affiliation: IBM Research Division, Almaden Research Center.  IBM Research Division, Almaden Research Center, and School of Mathematical Sciences, Tel Aviv University,  Computer Science Division, U.C. Berkeley.  at IBM Almaden Research  
Abstract: In the classical secretary problem, n objects from an ordered set arrive in random order, and one has to accept k of them so that the final decision about each object is made only on the basis of its rank relative to the ones already seen. Variants of the problem depend on the goal: either maximize the probability of accepting the best k objects, or minimize the expectation of the sum of the ranks (or powers of ranks) of the accepted objects. The problem and its generalizations are at the core of tasks with a large data set, in which it may be impractical to backtrack and select previous choices. Optimal algorithms for the special case of k = 1 are well known. Partial solutions for the first variant with general k are also known. In contrast, an explicit solution for the second variant with general k has not been known; even the question of whether or not the expected sum of powers of the ranks of selected items tends to infinity with n has been unresolved. We answer these open questions by obtaining explicit algorithms. For each z 1, the resulting expected sum of the zth powers of the ranks of the selected objects is at most 1 k z+1 =(z + 1) + C(z) k z+0:5 log k, whereas the best possible value at all is k z+1 =(z+1)+ O(k z ). Our methods are very intuitive and apply to some generalizations. We also derive a lower bound on the trade-off between the probability of selecting the best object and its expected rank. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. S. Chow, H. Robbins, S. Moriguti, and S. M. Samuels. </author> <title> Optimal selection based on relative rank (the "secretary problem"). </title> <journal> Israel J. Math. </journal> <volume> 2, </volume> <pages> 81-90, </pages> <year> 1964. </year>
Reference-contexts: Thus, not surprisingly, finding an approximate solution for the dynamic programming recurrence for this problem seems significantly harder than in the case of the first variant of the problem, i.e., when the goal is to maximize the probability of selecting the best. Chow, Moriguti, Robbins, and Samuels, <ref> [1] </ref> showed that the optimal expected rank of the selected object is approximately 3:8695. The question of whether higher powers of the rank of the selected object tend to finite limits as n tends to infinity was resolved in [11]. <p> Let z be the positive integer that we are given. Denote p = 64 + log 2 k. For the convenience of exposition, we assume without loss of generality that n is a power of 2. We partition the sequence <ref> [1; . . .; n] </ref> (corresponding to the objects in the order of arrival) into m = log n + 1 consecutive intervals I i (i = 1 . . . ; m), so that I i = 1 + n j=1 2 j ; n j=1 2 j if 1 <p> arrival) into m = log n + 1 consecutive intervals I i (i = 1 . . . ; m), so that I i = 1 + n j=1 2 j ; n j=1 2 j if 1 i m 1 In other words, the first m 1 intervals are <ref> [1; n 2 ] </ref>, 2 +1; 3n 4 ]; . . . ; each containing a half of the remaining elements. The mth interval contains the last element. Note that jI i j = dn=2 i e (i = 1; . . . ; m 1). <p> Notation: Denote by BA, BR, and BOPT the events in which A, R and OPT, repectively, accept the best object. Denote by B1, B2, and B3 the events in which the best object appears in the intervals <ref> [1; n=d] </ref>, (n=d; t 0 = n c 1 *], and (t 0 ; n], respectively. Denote by IA1, IA2 and IA3 the events in which A makes a selection in the intervals [1; n=d], (n=d; t 0 = n c 1 *], and (t 0 ; n], respectively. <p> Denote by B1, B2, and B3 the events in which the best object appears in the intervals <ref> [1; n=d] </ref>, (n=d; t 0 = n c 1 *], and (t 0 ; n], respectively. Denote by IA1, IA2 and IA3 the events in which A makes a selection in the intervals [1; n=d], (n=d; t 0 = n c 1 *], and (t 0 ; n], respectively. We distinguish between two cases. Case I: ProbfIA1g 3*=p 0 : Claim 4.1 ProbfBR j IA1g P fBA j IA1g + p 0 =2: Proof: Suppose that A made a selection by time n=d. <p> Case II: ProbfIA1g &lt; 3*=p 0 . Denote by BR1, BR2, and BR3 the events when R picks the best object and its selections are in the interval <ref> [1; n=d] </ref>; (n=d; t 0 ] and (t 0 ; n], respectively. Denote by BA1, BA2, and BA3 the corresponding events for A.
Reference: [2] <author> E. B. Dynkin. </author> <title> The optimum choice of the instant for stopping a Markov process. </title> <journal> Soviet Math. </journal> <volume> 4, </volume> <pages> 627-629, </pages> <year> 1963. </year>
Reference-contexts: Later, Gilbert and Mosteller provided a slightly more accurate bound for r [5]. Dynkin established the result as an application of the theory of Markov stopping times <ref> [2] </ref>.) It is not as easy to see that the optimal expected rank of the selected object tends to a finite limit as n tends to infinity.
Reference: [3] <author> T. S. Ferguson. </author> <title> Who solved the secretary problem? Statistical Science 4, </title> <type> 282-296, </type> <year> 1989. </year>
Reference: [4] <author> P. R. Freeman. </author> <title> The secretary problem and its extensions: A review. </title> <journal> International Statistical Review 51, </journal> <pages> 189-206, </pages> <year> 1983. </year>
Reference-contexts: In addition to providing intuition and upper and lower bounds for the above important generalizations of the problem, solutions to the classical problem also provide in many cases very good approximations, or even exact solutions (see <ref> [4, 13, 14] </ref> for survey and also [8]). Our methods can also be directly extended to apply for these generalizations. <p> In other applications the items may be jobs for scheduling, opportunities for investment, objects for fellowships, etc. 1.1 Background and Intuition The problem has been extensively studied in the probability and statistics literature (see <ref> [4, 13, 14] </ref> for surveys and also [10]). The case of k = 1. Let us first review the case of k = 1, i.e., only one object has to be selected.
Reference: [5] <author> J. Gilbert and F. Mosteller. </author> <title> Recognizing the maximum of a sequence. </title> <journal> J. Amer. Statist. As-soc. </journal> <volume> 61, </volume> <pages> 35-73, </pages> <year> 1966. </year>
Reference-contexts: When n tends to infinity, the optimal value of r tends to n=e, and the probability of selecting the best is approximately 1=e. (Lind-ley showed the above using backward induction [7]. Later, Gilbert and Mosteller provided a slightly more accurate bound for r <ref> [5] </ref>. Dynkin established the result as an application of the theory of Markov stopping times [2].) It is not as easy to see that the optimal expected rank of the selected object tends to a finite limit as n tends to infinity. <p> algorithm accepts the best object with the highest possible prob ability, and hence with probability p 0 [7]. 3 3 In fact, r = [(n 1 2 )e 1 + 1 2 ] is a better approximation to r than ne 1 although the difference is never more than 1 <ref> [5] </ref>. We ignore this difference for the sake of simplicity. We define R by modifying A. The definition will depend on parameters c 1 &gt; d &gt; 0. We will assume that d is a sufficiently large absolute constant and c 1 is sufficiently large with respect to d.
Reference: [6] <author> K. S. Glasser, R. Holzagar, and A. Barron. </author> <title> The d Choice secretary problem. </title> <journal> Commun. Statist. Sequential Analysis 2(3), </journal> <pages> 177-179, </pages> <year> 1983. </year>
Reference-contexts: The probability that the best k objects belong to distinct intervals tends to k!=k k as n tends to infinity. For this first variant of the problem, the case of k = 2 was considered in [9]; Vanderbei [16], and indepen dently Glasser, Holzager, and Barron <ref> [6] </ref>, considered the problem for general k. <p> Both papers derive recursive relations using backward induction. General solutions to their recurrences are not known, but the authors give explicit solutions (i.e., critical values and probability) for the case of n = 2k <ref> [6, 16] </ref> and n = 2k + 1 [6]. Van-derbei [16] also presents certain asymptotic results as n tends to infinity and k is fixed and also as both k and n tend to infinity so that (2k n)= p n remains finite. <p> Both papers derive recursive relations using backward induction. General solutions to their recurrences are not known, but the authors give explicit solutions (i.e., critical values and probability) for the case of n = 2k [6, 16] and n = 2k + 1 <ref> [6] </ref>. Van-derbei [16] also presents certain asymptotic results as n tends to infinity and k is fixed and also as both k and n tend to infinity so that (2k n)= p n remains finite.
Reference: [7] <author> D. V. Lindley. </author> <title> Dynamic programming and decision theory. </title> <journal> Appl. Statist. </journal> <volume> 10, </volume> <pages> 39-52, </pages> <year> 1961. </year>
Reference-contexts: When n tends to infinity, the optimal value of r tends to n=e, and the probability of selecting the best is approximately 1=e. (Lind-ley showed the above using backward induction <ref> [7] </ref>. Later, Gilbert and Mosteller provided a slightly more accurate bound for r [5]. <p> If no object was accepted by the time the last object arrives, accept the last object. For n sufficiently large, this algorithm accepts the best object with the highest possible prob ability, and hence with probability p 0 <ref> [7] </ref>. 3 3 In fact, r = [(n 1 2 )e 1 + 1 2 ] is a better approximation to r than ne 1 although the difference is never more than 1 [5]. We ignore this difference for the sake of simplicity. We define R by modifying A.
Reference: [8] <editor> M. Henke. Sequentialle Auswahlprobleme bei Unsicherheit. </editor> <publisher> Meisenheim: Anton Hain Verlag, </publisher> <year> 1970. </year>
Reference-contexts: In addition to providing intuition and upper and lower bounds for the above important generalizations of the problem, solutions to the classical problem also provide in many cases very good approximations, or even exact solutions (see [4, 13, 14] for survey and also <ref> [8] </ref>). Our methods can also be directly extended to apply for these generalizations. The obvious application to choosing a best applicant for a job gives the problem its common name, although the problem (and our results) has a num-ber of other applications in computer science. <p> Backward induction gives recurrences that seem even harder to solve than those derived for the case of maximizing the probability of selecting the best k. Such equations were presented by Henke <ref> [8] </ref>, but he was unable to approximate their general solutions. Thus, the question of whether the expected sum of ranks of selected items tends to infinity with n has been open. There has not been any explicit solution for obtaining a bounded expected sum.
Reference: [9] <author> M. L. Nikolaev. </author> <title> A generalization of the best choice problem. </title> <journal> Theory Probability Appl. </journal> <volume> 22, </volume> <pages> 187-190, </pages> <year> 1977. </year>
Reference-contexts: The probability that the best k objects belong to distinct intervals tends to k!=k k as n tends to infinity. For this first variant of the problem, the case of k = 2 was considered in <ref> [9] </ref>; Vanderbei [16], and indepen dently Glasser, Holzager, and Barron [6], considered the problem for general k.
Reference: [10] <author> J. Preater. </author> <title> On multiple choice secretary problems. </title> <journal> Mathematics of Operations Research 19(3), </journal> <pages> 597-602, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: In other applications the items may be jobs for scheduling, opportunities for investment, objects for fellowships, etc. 1.1 Background and Intuition The problem has been extensively studied in the probability and statistics literature (see [4, 13, 14] for surveys and also <ref> [10] </ref>). The case of k = 1. Let us first review the case of k = 1, i.e., only one object has to be selected.
Reference: [11] <author> H. Rubin and S. M. Samuels. </author> <title> The finite memory secretary problem. </title> <journal> Ann. Probab. </journal> <volume> 5, </volume> <pages> 627-635, </pages> <year> 1977. </year>
Reference-contexts: Note that while the optimal algorithm for maximizing the probability of selecting the best has to remember only the best object seen so far, the threshold algorithm has to remember all the previous objects. (See <ref> [11] </ref> for solutions where the observer is allowed to remember only one of the previously presented items.) This fact suggests that minimizing the expected rank is harder. <p> Chow, Moriguti, Robbins, and Samuels, [1] showed that the optimal expected rank of the selected object is approximately 3:8695. The question of whether higher powers of the rank of the selected object tend to finite limits as n tends to infinity was resolved in <ref> [11] </ref>. It has also been shown that if the order of arrivals is determined by an adversary, then no algorithm can yield an expected rank better than n=2 [12]. The case of a general k.
Reference: [12] <author> S. M. Samuels. </author> <title> Optimal counter strategies for the secretary problem. </title> <journal> IMS Bull. </journal> <note> 7, 93 (Abstract 78t-43). </note>
Reference-contexts: It has also been shown that if the order of arrivals is determined by an adversary, then no algorithm can yield an expected rank better than n=2 <ref> [12] </ref>. The case of a general k. There has been much interest in the case where more than one object has to be selected.
Reference: [13] <author> S. M. Samuels. </author> <title> Secretary problems. In Handbook of sequential analysis. </title> <editor> B. K. Gosh and P. K. Sen, eds. </editor> <publisher> Marcel Dekker, </publisher> <address> New York. 381-405 (chapter 16), </address> <year> 1991. </year>
Reference-contexts: In addition to providing intuition and upper and lower bounds for the above important generalizations of the problem, solutions to the classical problem also provide in many cases very good approximations, or even exact solutions (see <ref> [4, 13, 14] </ref> for survey and also [8]). Our methods can also be directly extended to apply for these generalizations. <p> In other applications the items may be jobs for scheduling, opportunities for investment, objects for fellowships, etc. 1.1 Background and Intuition The problem has been extensively studied in the probability and statistics literature (see <ref> [4, 13, 14] </ref> for surveys and also [10]). The case of k = 1. Let us first review the case of k = 1, i.e., only one object has to be selected.
Reference: [14] <author> S. M. Samuels. </author> <title> Secretary problems as a source of benchmark sounds. </title> <booktitle> Stochastic Inequalities IMS Lecture Notes Monograph Series, </booktitle> <volume> 22, </volume> <pages> 371-387, </pages> <year> 1993. </year>
Reference-contexts: In addition to providing intuition and upper and lower bounds for the above important generalizations of the problem, solutions to the classical problem also provide in many cases very good approximations, or even exact solutions (see <ref> [4, 13, 14] </ref> for survey and also [8]). Our methods can also be directly extended to apply for these generalizations. <p> In other applications the items may be jobs for scheduling, opportunities for investment, objects for fellowships, etc. 1.1 Background and Intuition The problem has been extensively studied in the probability and statistics literature (see <ref> [4, 13, 14] </ref> for surveys and also [10]). The case of k = 1. Let us first review the case of k = 1, i.e., only one object has to be selected.
Reference: [15] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list updates and paging rules. </title> <booktitle> Communication of ACM 28(2), </booktitle> <pages> 202-208, </pages> <year> 1985. </year>
Reference: [16] <author> R. J. Vanderbei. </author> <title> The optimal choice of a subset of a population. </title> <journal> Mathematics of Operations Research 5(4), </journal> <pages> 481-486, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: The probability that the best k objects belong to distinct intervals tends to k!=k k as n tends to infinity. For this first variant of the problem, the case of k = 2 was considered in [9]; Vanderbei <ref> [16] </ref>, and indepen dently Glasser, Holzager, and Barron [6], considered the problem for general k. <p> Both papers derive recursive relations using backward induction. General solutions to their recurrences are not known, but the authors give explicit solutions (i.e., critical values and probability) for the case of n = 2k <ref> [6, 16] </ref> and n = 2k + 1 [6]. Van-derbei [16] also presents certain asymptotic results as n tends to infinity and k is fixed and also as both k and n tend to infinity so that (2k n)= p n remains finite. <p> Both papers derive recursive relations using backward induction. General solutions to their recurrences are not known, but the authors give explicit solutions (i.e., critical values and probability) for the case of n = 2k [6, 16] and n = 2k + 1 [6]. Van-derbei <ref> [16] </ref> also presents certain asymptotic results as n tends to infinity and k is fixed and also as both k and n tend to infinity so that (2k n)= p n remains finite.
References-found: 16

