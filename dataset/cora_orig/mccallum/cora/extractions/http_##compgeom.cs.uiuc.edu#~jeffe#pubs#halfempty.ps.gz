URL: http://compgeom.cs.uiuc.edu/~jeffe/pubs/halfempty.ps.gz
Refering-URL: http://compgeom.cs.uiuc.edu/~jeffe/pubs/halfempty.html
Root-URL: http://www.cs.uiuc.edu
Email: jeffe@cs.berkeley.edu  
Title: New Lower Bounds for Halfspace Emptiness  
Author: Jeff Erickson 
Web: http://http.cs.berkeley.edu/ jeffe  
Address: Berkeley, CA 94720-1776  
Affiliation: Computer Science Division University of California  
Abstract: We derive a lower bound of (n 4=3 ) for the half-space emptiness problem: Given a set of n points and n hyperplanes in IR 5 , is every point above every hyper-plane? This matches the best known upper bound to within polylogarithmic factors, and improves the previous best lower bound of (n log n). The lower bound applies to partitioning algorithms in which every query region is a polyhedron with a constant number of facets. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. K. Agarwal, D. Eppstein, and J. Matousek. </author> <title> Dynamic half-space reporting, geometric optimization, and minimum spanning trees. </title> <booktitle> In Proc. 33rd Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 80-89, </pages> <year> 1992. </year>
Reference-contexts: Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time <ref> [19, 1, 7] </ref>. For extensions and applications of half-space range reporting, see [1, 2, 6, 7, 22, 20]. <p> Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time [19, 1, 7]. For extensions and applications of half-space range reporting, see <ref> [1, 2, 6, 7, 22, 20] </ref>.
Reference: [2] <author> P. K. Agarwal and J. Matousek. </author> <title> Ray shooting and parametric search. </title> <journal> SIAM J. Comput., </journal> <volume> 22(4) </volume> <pages> 794-806, </pages> <year> 1993. </year>
Reference-contexts: Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time [19, 1, 7]. For extensions and applications of half-space range reporting, see <ref> [1, 2, 6, 7, 22, 20] </ref>.
Reference: [3] <author> A. Aggarwal, M. Hansen, and T. Leighton. </author> <title> Solving query-retrieval problems by compacting Voronoi diagrams. </title> <booktitle> In Proc. 22nd Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 331-340, </pages> <year> 1990. </year>
Reference-contexts: In two and three dimensions, we can easily build a linear-size data structure in O (n log n) time, that allows halfspace emptiness queries to be answered in logarithmic time <ref> [3, 10, 14] </ref>. In higher dimensions, a randomized algorithm due to Clarkson [12] answers halfspace emptiness queries in time O (log n) after O (n bd=2c+" ) 1 preprocessing time.
Reference: [4] <author> M. Ben-Or. </author> <title> Lower bounds for algebraic computation trees. </title> <booktitle> In Proc. 15th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 80-86, </pages> <year> 1983. </year>
Reference-contexts: The only lower bound previously known for this problem is (n log m + m log n), in the algebraic decision tree or algebraic computation tree models, by reduction from set intersection <ref> [26, 4] </ref>. Thus, the two- and three-dimensional algorithms are optimal, but there is still a large gap in dimensions four and higher.
Reference: [5] <author> H. Bronnimann, B. Chazelle, and J. Pach. </author> <title> How hard is halfspace range searching. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10 </volume> <pages> 143-155, </pages> <year> 1993. </year>
Reference-contexts: Bronnimann, Chazelle, and Pach <ref> [5] </ref> have proven time-space tradeoffs for halfspace counting data structures in the Fredman/Yao semigroup model.
Reference: [6] <author> T. M. Chan. </author> <title> Fixed-dimensional linear programming queries made easy. </title> <booktitle> In Proc. 12th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 284-290, </pages> <year> 1996. </year>
Reference-contexts: Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time [19, 1, 7]. For extensions and applications of half-space range reporting, see <ref> [1, 2, 6, 7, 22, 20] </ref>. <p> A problem closely related to halfspace range searching is linear programming. The best known data structures of linear programming queries are based on data structures for halfspace emptiness [22] and halfspace reporting queries <ref> [6] </ref>. However, no nontrivial lower bounds are known for linear programming queries in any model of computation. One application of particular interest is deciding, given a set of points, whether every point is a vertex of the set's convex hull.
Reference: [7] <author> T. M. Y. Chan. </author> <title> Output-sensitive results on convex hulls, extreme points, and related problems. </title> <booktitle> In Proc. 11th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 10-19, </pages> <year> 1995. </year>
Reference-contexts: Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time <ref> [19, 1, 7] </ref>. For extensions and applications of half-space range reporting, see [1, 2, 6, 7, 22, 20]. <p> Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time [19, 1, 7]. For extensions and applications of half-space range reporting, see <ref> [1, 2, 6, 7, 22, 20] </ref>. <p> One application of particular interest is deciding, given a set of points, whether every point is a vertex of the set's convex hull. Bounds for this problem closely match the best known bounds for halfspace emptiness <ref> [7] </ref>, but the best known lower bound is (n log n). It seems unlikely that lower bounds can be derived for this problem in the parti tioning algorithm model, since the extremity of a point depends on several other points arbitrarily far away.
Reference: [8] <author> B. Chazelle. </author> <title> Lower bounds on the complexity of polytope range searching. </title> <journal> J. Amer. Math. Soc., </journal> <volume> 2 </volume> <pages> 637-666, </pages> <year> 1989. </year>
Reference: [9] <author> B. Chazelle. </author> <title> Lower bounds for off-line range searching. </title> <booktitle> In Proc. 27th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 733-740, </pages> <year> 1995. </year>
Reference-contexts: Better such configurations would immediately lead to better lower bounds. Lower bounds in the Fredman/Yao semigroup arithmetic model have a similar basis. For example, Chazelle's lower bounds for o*ine simplex range searching <ref> [9] </ref> is based on a similar configuration of points and slabs. (See also [11].) Can we derive better polyhedral cover size bounds for points and hyperplanes from these configurations? Another open problem is to prove tight lower bounds for online halfspace range query problems.
Reference: [10] <author> B. Chazelle, L. J. Guibas, and D. T. Lee. </author> <title> The power of geometric duality. </title> <journal> BIT, </journal> <volume> 25 </volume> <pages> 76-90, </pages> <year> 1985. </year>
Reference-contexts: In two and three dimensions, we can easily build a linear-size data structure in O (n log n) time, that allows halfspace emptiness queries to be answered in logarithmic time <ref> [3, 10, 14] </ref>. In higher dimensions, a randomized algorithm due to Clarkson [12] answers halfspace emptiness queries in time O (log n) after O (n bd=2c+" ) 1 preprocessing time.
Reference: [11] <author> B. Chazelle and B. Rosenberg. </author> <title> Simplex range reporting on a pointer machine. </title> <journal> Comput. Geom. Theory Appl., </journal> <volume> 5 </volume> <pages> 237-247, </pages> <year> 1996. </year>
Reference-contexts: Better such configurations would immediately lead to better lower bounds. Lower bounds in the Fredman/Yao semigroup arithmetic model have a similar basis. For example, Chazelle's lower bounds for o*ine simplex range searching [9] is based on a similar configuration of points and slabs. (See also <ref> [11] </ref>.) Can we derive better polyhedral cover size bounds for points and hyperplanes from these configurations? Another open problem is to prove tight lower bounds for online halfspace range query problems. Bronnimann, Chazelle, and Pach [5] have proven time-space tradeoffs for halfspace counting data structures in the Fredman/Yao semigroup model. <p> Chazelle and Rosenberg <ref> [11] </ref> have developed quasi-optimal tradeoffs for simplex reporting data structures in Tarjan's pointer machine model, but no lower bounds are known for halfspace reporting. No lower bounds are known for online halfspace emptiness queries in any model of computation.
Reference: [12] <author> K. L. Clarkson. </author> <title> New applications of random sampling in computational geometry. </title> <journal> Discrete Comput. Geom., </journal> <volume> 2 </volume> <pages> 195-222, </pages> <year> 1987. </year>
Reference-contexts: In two and three dimensions, we can easily build a linear-size data structure in O (n log n) time, that allows halfspace emptiness queries to be answered in logarithmic time [3, 10, 14]. In higher dimensions, a randomized algorithm due to Clarkson <ref> [12] </ref> answers halfspace emptiness queries in time O (log n) after O (n bd=2c+" ) 1 preprocessing time. <p> Proof: Theorems 5.1 and 5.2 together imply that the worst case running time is (n log m + d (n; m) + n log m). The lower bounds then follow immediately from Theorem 4.6 and 4.7. fl Partitioning algorithms for the halfspace emptiness problem can (and do <ref> [12, 19] </ref>) apply a version of the "containment shortcut" described in [16]. If some query region lies entirely in a hyperplane's lower half-space, then the hyperplane need not traverse the corresponding edge.
Reference: [13] <author> K. L. Clarkson. </author> <title> A Las Vegas algorithm for linear programming when the dimension is small. </title> <booktitle> In Proc. 29th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 452-456, </pages> <year> 1988. </year>
Reference-contexts: In this paper, we will consider the following formulation of the problem: Given a set of points and hyper-planes, is every point above every hyperplane? Using linear programming <ref> [13, 21, 24, 25] </ref>, we can decide in linear time whether the union of a set of halfspaces is IR d . If it is, then every input point must lie in a halfspace.
Reference: [14] <author> D. P. Dobkin and D. G. Kirkpatrick. </author> <title> Determining the separation of preprocessed polyhedra a unified approach. </title> <booktitle> In Proc. 17th Internat. Colloq. Automata Lang. Program., volume 443 of Lecture Notes in Computer Science, </booktitle> <pages> pages 400-413. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: In two and three dimensions, we can easily build a linear-size data structure in O (n log n) time, that allows halfspace emptiness queries to be answered in logarithmic time <ref> [3, 10, 14] </ref>. In higher dimensions, a randomized algorithm due to Clarkson [12] answers halfspace emptiness queries in time O (log n) after O (n bd=2c+" ) 1 preprocessing time.
Reference: [15] <author> H. Edelsbrunner. </author> <title> Algorithms in Combinatorial Geometry, </title> <booktitle> volume 10 of EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, West Germany, </address> <year> 1987. </year>
Reference-contexts: Proof: Let P be a set of n points and H a set of m lines in the plane such that I (P; H) = (n + n 2=3 m 2=3 + m). Such a point-line configuration was first constructed by Erd-os; see, for example, <ref> [15, p. 112] </ref>. Consider any subsets P i P and H i H such that P i and H i are r-separable.
Reference: [16] <author> J. Erickson. </author> <title> New lower bounds for Hopcroft's problem. </title> <booktitle> In Proc. 11th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 127-137, </pages> <year> 1995. </year>
Reference-contexts: 1. Introduction The halfspace emptiness problem asks, given a set of points and a set of halfspaces, whether any halfspace contains a point. In this paper, we derive new lower bounds for the time required to solve this problem, generalizing earlier lower bounds for Hopcroft's point-line incidence problem <ref> [16] </ref>. <p> We obtain marginally larger bounds in dimensions 9 and higher. Our lower bounds apply to polyhedral partitioning algorithms, a restriction of the class of partitioning algorithms introduced in <ref> [16] </ref>. Informally, a polyhedral partitioning algorithm covers space with a constant number of constant-complexity polyhedra, determines which points and halfspaces intersect each polyhedron, and recursively solves the resulting subproblems. The basic approach is the same as the one used to prove lower bounds for Hopcroft's problem [16]. <p> partitioning algorithms introduced in <ref> [16] </ref>. Informally, a polyhedral partitioning algorithm covers space with a constant number of constant-complexity polyhedra, determines which points and halfspaces intersect each polyhedron, and recursively solves the resulting subproblems. The basic approach is the same as the one used to prove lower bounds for Hopcroft's problem [16]. We first define polyhedral covers, and develop lower bounds on their combinatorial complexity. Our main result (Theorem 5.2) states that the running time of a polyhedral partitioning algorithm is bounded below by the polyhedral cover size of its input. <p> Both P and H may intersect the relative boundary of . We say that P and H are r-separable if there is a projective polyhedron with at most r faces that separates them. The lower bound proofs in <ref> [16] </ref> relied on the following trivial observation: if we perturb a set of points and hyperplanes just enough to remove any point-hyperplane incidences, and every point is above every hyperplane in the perturbed configuration, then no point was below a hyperplane in the original configuration. <p> Finally, Lemma 4.2 implies that we can perturb P slightly, removing all the incidences, without decreas ing the polyhedral cover size. fl Our higher-dimensional lower bounds are based on the following generalization of the Erd-os configuration, originally described in <ref> [16] </ref>. Lemma 4.4. <p> If the relative growth rates of n and m are fixed, the entire sum can be reduced to a single term. Following the terminology in <ref> [16] </ref>, we say that a point-hyperplane configuration in IR d is monochromatic if every point lies above every hyperplane. Let ^ d;r (m; n) denote the maximum of r (P; H) over all monochromatic configurations of n points and of m hyperplanes in IR d IRIP d . <p> We conjecture that ^ d (n; n) = (n bd=2c=(bd=2c+1) ) for all d, but are unable to prove this when d = 4 or d 6. 5. Polyhedral Partitioning Algorithms The definitions and proofs in this section are almost exactly the same as those in Section 4 of <ref> [16] </ref>. The details are included here to keep the paper self-contained. A polyhedral partition graph is a directed acyclic graph with one source, called the root, and several sinks, called leaves. Associated with each non-leaf node v is a set R v of query regions, satisfying three conditions. 1. <p> The lower bounds then follow immediately from Theorem 4.6 and 4.7. fl Partitioning algorithms for the halfspace emptiness problem can (and do [12, 19]) apply a version of the "containment shortcut" described in <ref> [16] </ref>. If some query region lies entirely in a hyperplane's lower half-space, then the hyperplane need not traverse the corresponding edge. Instead, if any point lies in that region, we immediately halt and report that some point is below a hyperplane. <p> Although this shortcut decreases the running time of the algorithm, we easily verify that Theorem 5.2 still applies in the faster model. Our techniques allow us to slightly improve earlier lower bounds for Hopcroft's problem in higher dimensions <ref> [16] </ref>: Given a set of points and hyperplanes, does any point lie on a hyperplane? Theorem 5.4. Let A be an polyhedral partitioning algorithm that solves Hopcroft's problem, and let P be a set of points and H a set of hyperplanes such that I (P; H) = 0.
Reference: [17] <author> J. Erickson. </author> <title> On the relative complexities of some geometric problems. </title> <booktitle> In Proc. 7th Canad. Conf. Comput. Geom., </booktitle> <pages> pages 85-90, </pages> <year> 1995. </year>
Reference-contexts: In particular, the four dimensional case is wide open. It is not even known whether the four-dimensional halfspace emptiness problem is harder (or easier) than Hopcroft's problem in the plane <ref> [17] </ref>. The inner product doubling maps d can be used to reduce Hopcroft's problem in IR d to halfspace emptiness in IR d (d3)=2 in linear time.
Reference: [18] <author> J. E. Goodman and R. Pollack. </author> <title> Allowable sequences and order types in discrete and computational geometry. </title> <editor> In J. Pach, editor, </editor> <booktitle> New Trends in Discrete and Computational Geometry, volume 10 of Algorithms and Combinatorics, </booktitle> <pages> pages 103-134. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference: [19] <author> J. Matousek. </author> <title> Reporting points in halfspaces. </title> <journal> Comput. Geom. Theory Appl., </journal> <volume> 2(3) </volume> <pages> 169-186, </pages> <year> 1992. </year>
Reference-contexts: In higher dimensions, a randomized algorithm due to Clarkson [12] answers halfspace emptiness queries in time O (log n) after O (n bd=2c+" ) 1 preprocessing time. Matousek <ref> [19] </ref> describes two halfspace emptiness data structures, one answering queries in time O (n 11=bd=2c polylog n) time after O (n log n) preprocessing time, and the other answering queries in time O (n 11=bd=2c 2 O (log fl n) ) 2 after O (n 1+" ) preprocessing time. <p> Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time <ref> [19, 1, 7] </ref>. For extensions and applications of half-space range reporting, see [1, 2, 6, 7, 22, 20]. <p> Proof: Theorems 5.1 and 5.2 together imply that the worst case running time is (n log m + d (n; m) + n log m). The lower bounds then follow immediately from Theorem 4.6 and 4.7. fl Partitioning algorithms for the halfspace emptiness problem can (and do <ref> [12, 19] </ref>) apply a version of the "containment shortcut" described in [16]. If some query region lies entirely in a hyperplane's lower half-space, then the hyperplane need not traverse the corresponding edge.
Reference: [20] <author> J. Matousek and O. Schwarzkopf. </author> <title> On ray shooting in convex polytopes. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10(2) </volume> <pages> 215-232, </pages> <year> 1993. </year>
Reference-contexts: Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time [19, 1, 7]. For extensions and applications of half-space range reporting, see <ref> [1, 2, 6, 7, 22, 20] </ref>.
Reference: [21] <author> J. Matousek, M. Sharir, and E. Welzl. </author> <title> A subexponen-tial bound for linear programming. </title> <booktitle> In Proc. 8th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 1-8, </pages> <year> 1992. </year>
Reference-contexts: In this paper, we will consider the following formulation of the problem: Given a set of points and hyper-planes, is every point above every hyperplane? Using linear programming <ref> [13, 21, 24, 25] </ref>, we can decide in linear time whether the union of a set of halfspaces is IR d . If it is, then every input point must lie in a halfspace.
Reference: [22] <author> J. Matousek. </author> <title> Linear optimization queries. </title> <journal> J. Algorithms, </journal> <volume> 14 </volume> <pages> 432-448, </pages> <year> 1993. </year>
Reference-contexts: Combining Clarkson's and Matousek's data structures, for a fixed parameter n s n bd=2c , one can answer queries in time O ((n log n)=s 1=bd=2c ) after O (s polylog n) preprocessing time [19, 1, 7]. For extensions and applications of half-space range reporting, see <ref> [1, 2, 6, 7, 22, 20] </ref>. <p> A problem closely related to halfspace range searching is linear programming. The best known data structures of linear programming queries are based on data structures for halfspace emptiness <ref> [22] </ref> and halfspace reporting queries [6]. However, no nontrivial lower bounds are known for linear programming queries in any model of computation. One application of particular interest is deciding, given a set of points, whether every point is a vertex of the set's convex hull.
Reference: [23] <author> J. Matousek. </author> <title> Range searching with efficient hierarchical cuttings. </title> <journal> Discrete Comput. Geom., </journal> <volume> 10(2) </volume> <pages> 157-182, </pages> <year> 1993. </year>
Reference-contexts: Bronnimann, Chazelle, and Pach [5] have proven time-space tradeoffs for halfspace counting data structures in the Fredman/Yao semigroup model. Specifically, they prove that any data structure that uses space n s n d has worst-case query time (n= log n) d (d+1) ! Results of Matousek <ref> [23] </ref> imply the upper bound O ((n=s 1=d ) polylog n), which is almost certainly optimal (except possibly for the polylog factor), so the lower bounds have significant room for improvement.
Reference: [24] <author> N. Megiddo. </author> <title> Linear programming in linear time when the dimension is fixed. </title> <journal> J. ACM, </journal> <volume> 31 </volume> <pages> 114-127, </pages> <year> 1984. </year>
Reference-contexts: In this paper, we will consider the following formulation of the problem: Given a set of points and hyper-planes, is every point above every hyperplane? Using linear programming <ref> [13, 21, 24, 25] </ref>, we can decide in linear time whether the union of a set of halfspaces is IR d . If it is, then every input point must lie in a halfspace.
Reference: [25] <author> R. Seidel. </author> <title> Small-dimensional linear programming and convex hulls made easy. </title> <journal> Discrete Comput. Geom., </journal> <volume> 6 </volume> <pages> 423-434, </pages> <year> 1991. </year>
Reference-contexts: In this paper, we will consider the following formulation of the problem: Given a set of points and hyper-planes, is every point above every hyperplane? Using linear programming <ref> [13, 21, 24, 25] </ref>, we can decide in linear time whether the union of a set of halfspaces is IR d . If it is, then every input point must lie in a halfspace.
Reference: [26] <author> J. M. Steele and A. C. Yao. </author> <title> Lower bounds for algebraic decision trees. </title> <journal> J. Algorithms, </journal> <volume> 3 </volume> <pages> 1-8, </pages> <year> 1982. </year>
Reference-contexts: The only lower bound previously known for this problem is (n log m + m log n), in the algebraic decision tree or algebraic computation tree models, by reduction from set intersection <ref> [26, 4] </ref>. Thus, the two- and three-dimensional algorithms are optimal, but there is still a large gap in dimensions four and higher.
Reference: [27] <author> J. Stolfi. </author> <title> Oriented Projective Geometry: A Framework for Geometric Computations. </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: We easily verify that fl is a projective polyhedron whose face lattice is the inverse of the face lattice of . In particular, and fl have the same number of faces. See [28, pp. 59-64] and <ref> [27, pp. 143-150] </ref> for similar definitions. 3. Polyhedral Separation Let P be a set of points, let H be a set of hyper-planes, and let be a projective polyhedron in IRIP d .
Reference: [28] <author> G. M. Ziegler. </author> <title> Lectures on Polytopes, volume 152 of Graduate Texts in Mathematics. </title> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Everything we describe in this section can be formalized algebraically in the language of polyhedral cones and linear sub-spaces one dimension higher; we will give a much less formal, purely geometric treatment. For more technical details, we refer the reader to Chapters 1 and 2 of Ziegler's lecture notes <ref> [28] </ref>. The projective space IRIP d can be defined as the set of lines through the origin in IR d+1 . Every k-dimensional linear subspace of IR d+1 induces a (k 1)- dimensional flat f in IRIP d , and its orthogonal complement induces the dual flat f fl . <p> This definition generalizes both the polar of a convex polytope and the projective dual of a flat. We easily verify that fl is a projective polyhedron whose face lattice is the inverse of the face lattice of . In particular, and fl have the same number of faces. See <ref> [28, pp. 59-64] </ref> and [27, pp. 143-150] for similar definitions. 3. Polyhedral Separation Let P be a set of points, let H be a set of hyper-planes, and let be a projective polyhedron in IRIP d .
References-found: 28

