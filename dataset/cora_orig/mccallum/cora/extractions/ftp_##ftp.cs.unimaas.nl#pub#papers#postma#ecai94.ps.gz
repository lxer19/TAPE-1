URL: ftp://ftp.cs.unimaas.nl/pub/papers/postma/ecai94.ps.gz
Refering-URL: http://www.cs.unimaas.nl/~postma/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Attentional Scanning  
Author: Eric O. Postma H. Jaap van den Herik and Patrick T.W. Hudson 
Abstract: A model for attentional scanning is constructed in the form of a gating network which consists of gating lattices. A gating lattice is a sparsely-connected neural network. The process of covert attention is interpreted as a biological solution to the problem of translation-invariant pattern processing. We arrive at the final result by a sequence of pattern translations channelled through the gating network. Simulation studies and theoretical considerations reveal that the gating lattice gives rise to a trade off between gating quality and gating flexibility. The gating network is shown to be capable of translation-invariant processing of object patterns that are part of a natural image. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Biederman and E.E. Cooper, </author> <title> `Evidence for complete translational and reflectional invariance in visual object priming', </title> <journal> Perception, </journal> <volume> 20, </volume> <pages> 585-593, </pages> <year> (1991). </year>
Reference-contexts: An example of such a property is object identity. Visual priming (i.e., the facilitated speed and enhanced accuracy of identification due to prior object exposure) has been shown to be independent of the position of prime and object <ref> [1] </ref>. Our aim is to realise a model of covert attention capable of translation-invariant processing of object patterns.
Reference: [2] <author> J.P. </author> <title> Frisby, Seeing, illusion, brain and mind, </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1980. </year>
Reference-contexts: Our approach requires to deal with the segmentation problem and the channelling problem. The segmentation problem, treating the question which part of the visual data form objects (see, e.g., <ref> [2] </ref>, is not included in this contribution. Instead we focus on the channelling problem, being the problem of how an object pattern, once segmented, can be translated into a format appropriate for identification (cf. [3]).
Reference: [3] <author> C.H. Anderson and D.C. Van Essen, </author> <title> `Shifter circuits: A computational strategy for dynamic aspects of visual processing', </title> <booktitle> Proceedings of the National Academy of Sciences USA, </booktitle> <volume> 84, </volume> <pages> 6297-6301, </pages> <year> (1987). </year>
Reference-contexts: Instead we focus on the channelling problem, being the problem of how an object pattern, once segmented, can be translated into a format appropriate for identification (cf. <ref> [3] </ref>). Our model is based on a gating network achieving translation-invariant pattern processing through a sequence of pattern translations. The gating network incorporates a solution to the channelling problem. This contribution is organized as follows. <p> Postma, J. van den Herik, and P. Hudson ECAI 94. 11th European Conference on Artificial Intelligence Edited by A. Cohn Published in 1994 by John Wiley & Sons, Ltd. mation available at that location is channelled towards an identification stage (cf. <ref> [3] </ref>). Interpreted as such, attentional scanning combines active selection with translation-invariant object recognition. <p> Clearly, attentional selection at a scale comparable to that of human vision requires a larger number of patterns selectable for gating. We therefore combine gating lattices in a multilayer gating network (cf. <ref> [3, 15, 16] </ref>). With L layers, the gating network is capable of selecting one out of 3 L patterns. This number is equal to the number of control signals feeding into the 3 L1 gating lattices at the base level.
Reference: [4] <author> D.H. Ballard, D.H., </author> <title> `Animate vision', </title> <journal> Artificial Intelligence, </journal> <volume> 48, </volume> <pages> 57-86, </pages> <year> (1991). </year>
Reference-contexts: Finally, Section 6 concludes that our model provides an artificial realisation of the covert-attention process for active computer vision. 2 COVERT ATTENTION Human observers can make an active spatial selection of visual data in two ways. The most obvious one is through gaze control <ref> [4] </ref>. Directing the eyes towards an object provides a rough control over what part of the visual environment is taken as input. The second way of selecting visual data is through the process of covert attention. This process allows for a fine-grained spatial selection of visual data (e.g., [5]).
Reference: [5] <author> A.H.C. Van der Heijden, </author> <title> Selective attention in vision. </title> <address> Rout-ledge, London, </address> <year> (1991). </year>
Reference-contexts: Directing the eyes towards an object provides a rough control over what part of the visual environment is taken as input. The second way of selecting visual data is through the process of covert attention. This process allows for a fine-grained spatial selection of visual data (e.g., <ref> [5] </ref>). To a certain extent, its action may be likened to a searchlight illuminating a contiguous part of the visual scene (i.e., the attended part) [6]. The effectiveness of the attentional searchlight can be verified through Figure 1 (after [7]).
Reference: [6] <author> M.I. Posner, </author> <title> `Orienting of attention', </title> <journal> Quarterly Journal of Experimental Psychology, </journal> <volume> 32, </volume> <pages> 3-25, </pages> <year> (1980). </year>
Reference-contexts: This process allows for a fine-grained spatial selection of visual data (e.g., [5]). To a certain extent, its action may be likened to a searchlight illuminating a contiguous part of the visual scene (i.e., the attended part) <ref> [6] </ref>. The effectiveness of the attentional searchlight can be verified through Figure 1 (after [7]).
Reference: [7] <author> S.M. Anstis, </author> <title> `A chart demonstrating the variations in acuity with retinal position', </title> <journal> Vision Research, </journal> <volume> 14, </volume> <pages> 589-592, </pages> <year> (1974). </year>
Reference-contexts: To a certain extent, its action may be likened to a searchlight illuminating a contiguous part of the visual scene (i.e., the attended part) [6]. The effectiveness of the attentional searchlight can be verified through Figure 1 (after <ref> [7] </ref>).
Reference: [8] <author> E.O. Postma, H.J. van den Herik, and P.T.W. Hudson, </author> <title> `The gating lattice: a neural substrate for dynamic gating', </title> <editor> In F.H. Eeckman and J.M. Bower (Eds.), </editor> <booktitle> Computation and neural systems, </booktitle> <pages> pp. 221-225. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> (1993). </year>
Reference-contexts: The channelling is assumed to proceed by a sequence of pattern translations each of which is performed by a parallel distributed switch called the gating lattice. searchlight may subserve translation-invariant identification. 3 THE GATING LATTICE The gating lattice is a neural network composed of locally interconnected gating elements or gates <ref> [8] </ref>. An open gate allows a signal to flow through the gate, whereas a closed gate shuts off signal flow. Neighbouring gates have opposite preferences, hence promoting configurations where an open gate is surrounded by closed gates.
Reference: [9] <author> S. Grossberg, </author> <title> `Contour enhancement, short term memory, </title> <booktitle> and constancies in reverberating neural networks', Studies in Applied Mathematics, LII, </booktitle> <pages> 213-257, </pages> <year> (1973). </year>
Reference-contexts: Neighbouring gates have opposite preferences, hence promoting configurations where an open gate is surrounded by closed gates. The (spatially) distributed competition realised by this nearest-neighbour inhibition endows the gating lattice with a distributed form of the Winner-Take-All property <ref> [9] </ref>. Our main design principle focuses on the amount and length of wiring. To facilitate scaling towards larger problems (i.e., large natural images) we define the gating lattice as a sparsely-connected neural network. The gating lattice is partitioned into three sublattices denoted by A, B, and C.
Reference: [10] <author> R.J. </author> <title> Glauber, `Time-dependent statistics of the Ising model', </title> <journal> Journal of Mathematical Physics, </journal> <volume> 4, </volume> <pages> 294-307, </pages> <year> (1963). </year>
Reference-contexts: The probability that a gate changes its state from open to closed or vice versa, P (G X (i; j) ! G X (i; j)) is according to Glauber <ref> [10] </ref>: P (G X (i; j) ! G X (i; j)) = 1 + exp G X (i; j) 1 1 with T a positive intrinsic-noise (temperature) parameter.
Reference: [11] <author> M. Plischke and B. Bergersen, </author> <title> Equilibrium statistical mechanics, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> (1989). </year>
Reference-contexts: The amount of randomness in gate updating is proportional to T . 3.3 Statistical mechanics of gating lattices Through the above definitions, we have formulated the gating lattice as an antiferromagnetic triangular Ising lattice (i.e., a statistical-mechanics model of magnetism, see, e.g., <ref> [11] </ref>. Consequently, properties of the Ising model may be used to understand the global behaviour of the gating lattice. <p> We briefly summarize two main properties of the Ising model in terms of the gating lattice where it is assumed that H X = 0 for all X: * States with one-third of all gates open and all remaining gates closed are obtained for H bias 2 h0; 6i (e.g., <ref> [11] </ref>). * An (almost) ordered state appears spontaneously when the intrinsic-noise parameter T is smaller than the critical value at H bias : T c (H bias ). The maximum critical value on the interval h0; 6i is T c (3:1) 1:48 [12].
Reference: [12] <author> N. Akutsu and Y. Akutsu, </author> <title> `Critical curve of two-dimensional Ising antiferromagnet in a magnetic field', </title> <journal> Journal of Magnetism and Magnetic Materials, </journal> <volume> 90/91, </volume> <pages> 296-298, </pages> <year> (1990). </year>
Reference-contexts: The maximum critical value on the interval h0; 6i is T c (3:1) 1:48 <ref> [12] </ref>. The spontaneous emergence of ordered states for T &lt; T c (H bias ) indicates at an important property of the gating lattice. As a result of distributed competition the gating lattice is intrinsically inclined to open all gates on one sublattice.
Reference: [13] <author> E.O. Postma, </author> <title> SCAN: a neural model of covert attention, </title> <note> PhD Thesis (to appear). </note>
Reference-contexts: It allows the gating lattice to re cover from moderate amounts of extrinsic noise (see below). 4 GATING PERFORMANCE We have performed several experiments with gating lattices of various sizes <ref> [13] </ref>. Below, we describe the performance of a gating lattice containing N = 99 2 gates. The global bias H bias is set to the value where the tendency to open all gates on one sublattice is maximal; H bias = 3:1 ([13]). <p> A partly independent network formed by triplets of gates, with each triplet coupled to a distinct gating lattice, ensures that the appropriate control values are channelled through the gating tree (see <ref> [13] </ref> for more details). A concatenated sequence of open sublattices channels a pattern centred at one of the 3 L inputs towards the top of the gating network. This sequence may be interpreted as the beam of the attentional searchlight.
Reference: [14] <author> J. Hertz, A. Krogh, and R.G. Palmer, </author> <title> Introduction to the theory of neural computation, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> (1991). </year>
Reference-contexts: This choice deviates from the standard procedure of neural-network initialization in which networks are set to a neutral state at t = 0 (e.g., <ref> [14] </ref>). The reason for choosing a neutral initial state in standard fully-connected networks is that the intrinsic noise T has to be large, for allowing the network to escape from the local minimum associated with an ordered initial state.
Reference: [15] <author> C. Koch and S. Ullman, </author> <title> `Shifts in selective visual attention: towards the underlying neural circuitry', </title> <booktitle> Human Neurobiol-ogy, </booktitle> <volume> 4, </volume> <pages> 219-277, </pages> <year> (1985). </year>
Reference-contexts: Clearly, attentional selection at a scale comparable to that of human vision requires a larger number of patterns selectable for gating. We therefore combine gating lattices in a multilayer gating network (cf. <ref> [3, 15, 16] </ref>). With L layers, the gating network is capable of selecting one out of 3 L patterns. This number is equal to the number of control signals feeding into the 3 L1 gating lattices at the base level.
Reference: [16] <author> B.A. Olshausen, C.H. Anderson, and D.C. Van Essen, </author> <title> `A neu-robiological model of visual attention and invariant pattern recognition based on dynamic routing of information', </title> <journal> The Journal of Neuroscience, </journal> <volume> 13, </volume> <pages> 4700-4719, </pages> <year> (1993). </year> <title> Cognitive Modelling 177 E. Postma, </title> <editor> J. van den Herik, and P. </editor> <publisher> Hudson </publisher>
Reference-contexts: Clearly, attentional selection at a scale comparable to that of human vision requires a larger number of patterns selectable for gating. We therefore combine gating lattices in a multilayer gating network (cf. <ref> [3, 15, 16] </ref>). With L layers, the gating network is capable of selecting one out of 3 L patterns. This number is equal to the number of control signals feeding into the 3 L1 gating lattices at the base level.
References-found: 16

