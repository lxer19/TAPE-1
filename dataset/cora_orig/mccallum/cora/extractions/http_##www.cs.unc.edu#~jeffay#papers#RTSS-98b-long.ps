URL: http://www.cs.unc.edu/~jeffay/papers/RTSS-98b-long.ps
Refering-URL: http://www.cs.unc.edu/Research/real-time.html
Root-URL: http://www.cs.unc.edu
Email: E-mail: fanderson,jain,jeffayg@cs.unc.edu  
Phone: Phone: (919) 962-1757 Fax: (919) 962-1799  
Title: Efficient Object Sharing in Quantum-Based Real-Time Systems  
Author: James H. Anderson, Rohit Jain, and Kevin Jeffay 
Note: Work supported by NSF grant CCR 9510156. The first author was also supported by a Young Investigator Award from the U.S. Army Research Office, grant number DAAH04-95-1-0323, and by an Alfred P. Sloan Research Fellowship. The second author was supported by a UNC Board of Governor's Fellowship. The third author was supported by a grant from IBM Corporation.  
Date: May 1998  
Address: Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science University of North Carolina  
Abstract: We consider the problem of implementing shared objects in uniprocessor and multiprocessor real-time systems in which tasks are executed using a scheduling quantum. In most quantum-based systems, the size of the quantum is quite large in comparison to the length of an object call. As a result, most object calls can be expected to execute without preemption. A good object-sharing scheme should optimize for this expected case, while achieving low overhead when preemptions do occur. Our approach is to use an optimistic retry scheme coupled with the assumption that each task can be preempted at most once across two object calls. Given this preemption assumption, each object call can be retried at most once. Experimental evidence is cited that suggests that for most quantum-based systems, our preemption assumption is reasonable. Major contributions of this paper include several new retry-based shared-object algorithms for uniprocessors and multiprocessors, and scheduling analysis results that can be used in conjunction with these algorithms. We consider both conventional periodic real-time task systems implemented using a scheduling quantum, and also proportional-share systems. The retry mechanism used in our multiprocessor implementation is based on a preemptable queue-lock algorithm. Our queue-lock is much simpler than preemptable queue locks proposed previously. Experimental results are presented that show that the performance of our lock is up to 25% better than one presented at last year's RTSS, when applied in quantum-based systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson, R. Jain, and D. Ott. </author> <title> Wait-free synchronization in quantum-based multiprogrammed systems, </title> <booktitle> in submission. </booktitle> <year> 1998. </year>
Reference-contexts: We have presented experimental evidence that shows that such implementations should entail low overhead in practice. In a recent related paper, Anderson, Jain, and Ott presented a number of new results on the theoretical foundations of wait-free synchronization in quantum-based systems <ref> [1] </ref>. It was shown in that paper that the ability to achieve wait-free synchronization in quantum-based systems is a function of both the "power" of available synchronization primitives and the size of the scheduling quantum. <p> In addition, an asymptotically tight characterization of the conditions under which wait-free synchronization is possible was given. Intuitively, synchronization primitives allow processes on different processors to coordinate, and the scheduling quantum allows processes on the same processor to coordinate. We hope the results of <ref> [1] </ref> and this paper will spark further research on synchronization problems arising in quantum-based systems. Acknowledgement: We are grateful to Alex Blate for his help in running simulation experiments. We also acknowledge David Koppelman for his help with the Proteus simulator.
Reference: [2] <author> J. Anderson, R. Jain, and S. Ramamurthy. </author> <title> Wait-free object-sharing schemes for real-time uniprocessors and multiprocessors. </title> <booktitle> In Proceedings of the Eighteenth IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 111-122. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1997. </year> <month> 20 </month>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way. <p> As its definition shows, CCAS is a restriction of CAS2 in which one word is a compare-only value. Lock-free and wait-free objects can be implemented by using a "version number" that is incremented by each object call <ref> [2, 13] </ref>. CCAS is useful because the version number can be used to ensure that a "late" CCAS operation performed by a task after having been preempted has no effect. works by packing a task index into the words being accessed. The task index field is used to detect preemptions.
Reference: [3] <author> J. Anderson and S. Ramamurthy. </author> <title> A framework for implementing objects and scheduling tasks in lock-free real-time systems. </title> <booktitle> In Proceedings of the 17th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 92-105. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1996. </year>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way. <p> In previous work, Anderson and Ramamurthy showed that when using lock-free shared objects under RM or EDF scheduling, retry costs can be bounded by solving a linear programming problem <ref> [3] </ref>. We show that a slightly different linear programming must be solved to bound retries when the proposed object implementations are used in a quantum-based uniprocessor system. <p> We also show that, when analyzing such a system, the techniques we present result in better retry-cost estimates and a much faster schedulability test than when using the results of <ref> [3] </ref>. In addition to RM and EDF scheduling, we also consider proportional-share (PS) scheduling. Under PS scheduling, lag-bound calculations are an important concern. We show how object-sharing overheads affect such calculations when using either our algorithms or lock-based schemes. <p> Nonetheless, the blocking calculations due to quantum-based scheduling are the same in both models. 9 Bounding interference costs using linear programming. Anderson and Ramamurthy showed that when lock-free objects are used in a uniprocessor system, object interference costs due to preemptions can be more accurately bounded using linear programming <ref> [3] </ref>. Given the Preemption Axiom, we show that it is possible to obtain bounds that are tighter than those of Anderson and Ramamurthy. Our linear programming conditions make use of a bit of additional notation. <p> 2 Constraint Set 5: (8i :: P i1 P w j i (j; t) ( c 0 Q 1) t+1 m Constraint Set 6: (8i :: P i1 P w j i (j; t) x i t+1 m There first three constraint sets were given previously by Anderson and Ramamurthy <ref> [3] </ref>. The first set of constraints follows because the number of interferences in jobs of T i due to T j in an interval I of length t is bounded by the maximum number of jobs of T j that can be released in I. <p> using the proposed retry algorithms is schedulable if the following holds for every task T i . (9t : 0 &lt; t p i :: min (Q; max j&gt;i (c 0 P i l p j c j + E 0 This condition is obtained by modifying one proved in <ref> [3] </ref> by including a blocking factor for the scheduling quantum. For EDF scheduling, we have the following. <p> We did not minimize the constraint sets in this way because we felt that this would make them more difficult to understand, especially when comparing them against those in <ref> [3] </ref>. 11 This condition was also proved in [3]. Since t is checked beginning at time 0, a blocking factor is not required. As stated, the expression in Theorem 4 cannot be verified because the value of t is unbounded. However, there is an implicit bound on t. <p> We did not minimize the constraint sets in this way because we felt that this would make them more difficult to understand, especially when comparing them against those in <ref> [3] </ref>. 11 This condition was also proved in [3]. Since t is checked beginning at time 0, a blocking factor is not required. As stated, the expression in Theorem 4 cannot be verified because the value of t is unbounded. However, there is an implicit bound on t. <p> All of the scheduling conditions presented in this subsection can be improved by accounting for this fact. Experimental Comparison. In order to compare the retry-cost estimates produced by the linear programming methods proposed in this paper and in <ref> [3] </ref>, we conducted a series of simulation experiments involving randomly-generated task sets scheduled under the RM scheme. <p> It can be seen in Figure 5 that both methods yield similar retry costs for lower-priority tasks. However, the method of this paper yields retry-cost estimates for higher-priority tasks that are about 10% to 20% lower than those produced by the method of <ref> [3] </ref>. In addition to determining retry-cost estimates, we also kept track of how long each schedulability check took to complete. On average, the schedulability check proposed in this paper took 11.7 seconds per task set, while the one proposed in [3] took 235 seconds. <p> to 20% lower than those produced by the method of <ref> [3] </ref>. In addition to determining retry-cost estimates, we also kept track of how long each schedulability check took to complete. On average, the schedulability check proposed in this paper took 11.7 seconds per task set, while the one proposed in [3] took 235 seconds. This is because of the complicated procedure invoked to compute 12 f v i values in the method of [3]. Our method renders this procedure unnecessary by exploiting characteristics of quantum-based systems. Proportional-share scheduling. <p> On average, the schedulability check proposed in this paper took 11.7 seconds per task set, while the one proposed in <ref> [3] </ref> took 235 seconds. This is because of the complicated procedure invoked to compute 12 f v i values in the method of [3]. Our method renders this procedure unnecessary by exploiting characteristics of quantum-based systems. Proportional-share scheduling. In the PS scheduling literature, the term "client" is used to refer to a schedulable entity. In a PS system, clients may join and leave the system arbitrarily.
Reference: [4] <author> J. Anderson, S. Ramamurthy, and R. Jain. </author> <title> Implementing wait-free objects in priority-based systems. </title> <booktitle> In Proceedings of the 16th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 229-238. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way.
Reference: [5] <author> J. Anderson, S. Ramamurthy, and K. Jeffay. </author> <title> Real-time computing with lock-free objects. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 15(6) </volume> <pages> 388-395, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way. <p> The second set of constraints follows from a result presented in <ref> [5] </ref>, which states that the total number of interferences in all jobs of tasks T 1 through T i in an interval I of length t is bounded by the maximum number of jobs of tasks T 1 through T i1 released in I. <p> Task periods were initially selected at random with a range of 6,000 to 50,000 time units. The periods were then scaled up until the task set was deemed to be schedulable by applying a non-linear-programming-based scheduling condition for tasks using lock-free objects reported in <ref> [5] </ref>. This condition provides a less accurate schedulability check than either of the two methods being compared. As a result, it was known before submitting a task set to either method that it was indeed schedulable. The results of these experiments are depicted in Figure 5.
Reference: [6] <author> J. Anderson, S. Ramamurthy, M. Moir, and K. Jeffay. </author> <title> Lock-free transactions for real-time systems. In Real-Time Databases: Issues and Applications. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Amsterdam, </address> <year> 1997. </year>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way. <p> The idea of using MWCAS to atomically access many objects can be generalized to implement arbitrary lock-free transactions on memory-resident data. Such an implementation was presented recently by Anderson, Ramamurthy, Moir, and Jeffay <ref> [6] </ref>. Our MWCAS implementation uses a rollback mechanisms. Before beginning a MWCAS operation, a task T i first checks to see if there exists a partially-completed operation that was preempted (line 2). If such an operation exists, T i marks it as having failed (line 3).
Reference: [7] <author> T. Anderson. </author> <title> The performance of spin lock alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Queue locks come in two flavors: array-based locks, which use an array of spin locations <ref> [7, 12] </ref>, and list-based locks, in which spinning tasks form a linked list [19]. List-based queue locks have the advantage of requiring only constant space overhead per task per lock.
Reference: [8] <author> N. C. Audsley, I. J. Bate, and A. Burns. </author> <title> Putting fixed priority scheduling into engineering practice for safety critical applications. </title> <booktitle> In Proceedings of the 1996 IEEE Real-Time Technology and Applications Symposium, </booktitle> <pages> pages 2-10, </pages> <year> 1996. </year>
Reference-contexts: Nonpreemptive systems have several advantages over preemptive systems, including lower scheduling overheads (if preemptions are frequent) and simpler object-sharing protocols <ref> [8, 14] </ref>. In addition, timing analysis is simplified because cache behavior is easier to predict. However, these advantages come at the potential expense of longer response times for higher-priority tasks. Quantum-based systems can be seen as a compromise between these two extremes.
Reference: [9] <author> S. Baruah, J. Gehrke, C. Plaxton, I. Stoica, H. Abdel-Wahab, and K. Jeffay. </author> <title> Fair on-line scheduling of a dynamic set of tasks on a single resource. </title> <journal> Information Processing Letters, </journal> <volume> 64(1) </volume> <pages> 43-51, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: Alternatives to our approach include using non-uniform quanta, so that object accesses are nonpreemptive <ref> [9] </ref>, and using lock-based implementations, with ceiling- or inheritance-like schemes [23] to bound blocking times. 14 In this paper, we have strictly limited attention to systems with a uniform quantum. We hope to investigate systems with non-uniform quanta in future work.
Reference: [10] <author> S. Baruah, R. Howell, and L. Rosier. </author> <title> Feasibility problems for recurring tasks on one processor. </title> <journal> Theoretical Computer Science, </journal> <volume> 118 </volume> <pages> 3-20, </pages> <year> 1993. </year>
Reference-contexts: In particular, we only need to consider values less than or equal to the least common multiple of the task periods. (If an upper bound on the utilization available for the tasks is known, then we can restrict t to a much smaller range <ref> [10] </ref>.) Note that, in a quantum-based system, no object access by a task that is guaranteed to complete within the first quantum allocated to a job of that task can be interfered with. Thus, such an access can be performed using a less-costly code fragment that is purely sequential.
Reference: [11] <author> E. Brewer, C. Dellarocas, A. Colbrook, and W. Weihl. Proteus: </author> <title> A high-performance parallel-architecture simulator. </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, Mas-sachusetts, </address> <year> 1992. </year>
Reference-contexts: The SPEPP/MCS algorithm was the fastest in the face of preemptions of several lock algorithms tested by Takada and Sakamura. Our experiments were conducted using the Proteus parallel architecture simulator <ref> [11] </ref>. Using a simulator made it easy to provide the kernel interface needed by each algorithm. The simulator was configured to simulate a bus-based shared-memory multiprocessor, with an equal number of processors and memory modules. The simulated system follows a bus-based snoopy protocol with write-invalidation for cache coherence.
Reference: [12] <author> G. Graunke and S. Thakkar. </author> <title> Synchronization algorithms for shared-memory multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 23 </volume> <pages> 60-69, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Queue locks come in two flavors: array-based locks, which use an array of spin locations <ref> [7, 12] </ref>, and list-based locks, in which spinning tasks form a linked list [19]. List-based queue locks have the advantage of requiring only constant space overhead per task per lock.
Reference: [13] <author> M. Greenwald and D. Cheriton. </author> <title> The synergy between non-blocking synchronization and operating system structure. </title> <booktitle> In Proceedings of the USENIX Association Second Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 123-136, </pages> <year> 1996. </year>
Reference-contexts: As its definition shows, CCAS is a restriction of CAS2 in which one word is a compare-only value. Lock-free and wait-free objects can be implemented by using a "version number" that is incremented by each object call <ref> [2, 13] </ref>. CCAS is useful because the version number can be used to ensure that a "late" CCAS operation performed by a task after having been preempted has no effect. works by packing a task index into the words being accessed. The task index field is used to detect preemptions.
Reference: [14] <author> K. Jeffay, D. Stanat, and C. Martel. </author> <title> On non-preemptive scheduling of periodic and sporadic tasks. </title> <booktitle> In Proceedings of the 12 th IEEE Symposium on Real-Time Systems, </booktitle> <pages> pages 129-139. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: Nonpreemptive systems have several advantages over preemptive systems, including lower scheduling overheads (if preemptions are frequent) and simpler object-sharing protocols <ref> [8, 14] </ref>. In addition, timing analysis is simplified because cache behavior is easier to predict. However, these advantages come at the potential expense of longer response times for higher-priority tasks. Quantum-based systems can be seen as a compromise between these two extremes. <p> P N c 0 p i (8i : 1 i N :: (8t : p 1 &lt; t &lt; p i :: min (Q; c 0 P i1 p j j t)) 2 The above condition is obtained by adapting the condition given by Jeffay et al. in <ref> [14] </ref> for nonpreemptive EDF scheduling. Note that this condition reduces to that of Jeffay et al. when Q = 1 and to that for preemptive EDF scheduling [18] when Q = 0. 2 In [16], it is assumed that timer interrupts are spaced apart by a constant amount of time.
Reference: [15] <author> T. Johnson and K. Harathi. </author> <title> Interruptible critical sections. </title> <type> Technical Report TR94-007, </type> <institution> University of Florida, Gainesville, Florida, </institution> <year> 1994. </year> <month> 21 </month>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way.
Reference: [16] <author> D. Katcher, H. Arakawa, and J.K. Strosnider. </author> <title> Engineering and analysis of fixed priority schedulers. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(9) </volume> <pages> 920-934, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Round-robin scheduling is a simpler scheme in which each task has an identical share. Quantum-based execution also arises when conventional priority-based scheduling disciplines, such as rate-monotonic (RM) and earliest-deadline-first (EDF) scheduling, are implemented on top of a timer-driven real-time kernel <ref> [16] </ref>. In such an implementation, interrupts are scheduled to occur at regular intervals, and scheduling decisions are made when these interrupts occur. The length of time between interrupts defines the scheduling quantum. Timer-driven systems can be seen as a compromise between nonpreemptive and completely preemptive systems. <p> task T i . (9t : 0 &lt; t p i :: min (Q; max j&gt;i (c 0 P i l p j c 0 In the above expression, min (Q; max j&gt;i (c 0 j )) is a blocking term that arises due to the use of quantum-based scheduling <ref> [16] </ref>. 2 The next theorem gives a scheduling condition for the EDF scheme. Theorem 2: In an EDF-scheduled quantum-based uniprocessor system, a set of tasks with objects implemented using the proposed retry algorithms is schedulable if the following holds. <p> Note that this condition reduces to that of Jeffay et al. when Q = 1 and to that for preemptive EDF scheduling [18] when Q = 0. 2 In <ref> [16] </ref>, it is assumed that timer interrupts are spaced apart by a constant amount of time. If a task completes execution between these interrupts, then the processor is allocated to the next ready task, if such a task exist.
Reference: [17] <author> H. Kopetz and J. Reisinger. </author> <title> The non-blocking write protocol nbw: A solution to a real-time synchronization problem. </title> <booktitle> In Proceedings of the 14 th IEEE Symposium on Real-Time Systems, </booktitle> <pages> pages 131-137. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way.
Reference: [18] <author> C. Liu and J. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard real-time environment. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: Note that this condition reduces to that of Jeffay et al. when Q = 1 and to that for preemptive EDF scheduling <ref> [18] </ref> when Q = 0. 2 In [16], it is assumed that timer interrupts are spaced apart by a constant amount of time. If a task completes execution between these interrupts, then the processor is allocated to the next ready task, if such a task exist.
Reference: [19] <author> J. Mellor-Crummey and M. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Our approach is to use a retry mechanism in conjunction with a preemptable queue lock. A queue lock is a spin lock in which waiting tasks form a queue <ref> [19] </ref>. In our approach, a task performs an operation on an object by first acquiring a lock; if a task is preempted before its operation is completed, then its operation is retried. <p> Our approach is to use a retry mechanism in conjunction with a preemptable queue lock. A queue lock is a spin lock in which waiting tasks form a queue <ref> [19] </ref>. Queue locks are useful in real-time systems because waiting times can be bounded. With a preemptable queue lock, a task waiting for or holding a lock can be preempted without impeding the progress of other tasks waiting for the lock. <p> Queue locks come in two flavors: array-based locks, which use an array of spin locations [7, 12], and list-based locks, in which spinning tasks form a linked list <ref> [19] </ref>. List-based queue locks have the advantage of requiring only constant space overhead per task per lock. In addition, list-based queue locks exist in which all spins are 15 local if applied on multiprocessors either with coherent caches or distributed shared memory [19]. <p> in which spinning tasks form a linked list <ref> [19] </ref>. List-based queue locks have the advantage of requiring only constant space overhead per task per lock. In addition, list-based queue locks exist in which all spins are 15 local if applied on multiprocessors either with coherent caches or distributed shared memory [19]. In contrast, with existing array-based locks, spins are local only if applied in a system with coherent caches. All work known to us on preemptable queue locks involves list-based locks [25, 26]. <p> Their lock is designated as the "SPEPP/MCS algorithm" in their paper, so we will use that term here (SPEPP stands for "spinning processor executes for preempted processors"; MCS denotes that this lock is derived from one published previously by Mellor-Crummey and Scott <ref> [19] </ref>). The SPEPP/MCS algorithm was the fastest in the face of preemptions of several lock algorithms tested by Takada and Sakamura. Our experiments were conducted using the Proteus parallel architecture simulator [11]. Using a simulator made it easy to provide the kernel interface needed by each algorithm.
Reference: [20] <author> R. Rajkumar. </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: Our approach also has the advantage that the kernel can be completely oblivious to the fact that tasks share objects, with the lone exception of assigning state variables when preemptions occur. The multiprocessor priority-ceiling protocol (MPCP) is perhaps the best known approach to implementing shared objects in real-time multiprocessors <ref> [20] </ref>. When using the MPCP, tasks are susceptible to very large block factors. In practice, we believe that our approach would lead to much better schedulability than the MPCP.
Reference: [21] <author> S. Ramamurthy. </author> <title> A Lock-Free Approach to Object Sharing in Real-Time Systems. </title> <type> PhD thesis, </type> <institution> University of North Carolina, Chapel Hill, North Carolina, </institution> <year> 1997. </year>
Reference-contexts: Even with the technology of several years ago, one could make the case that object calls are typically short compared to a quantum. As evidence of this, we cite results from experiments conducted by Ramamurthy to compute access times for several common objects <ref> [21] </ref>. These experiments were performed on a 25 MHz 68030 machine and involved objects ranging from queues to linked lists to medium-sized balanced trees. Both lock-based and lock-free (see below) object implementations were evaluated. <p> Three objects were defined to have access times of 7-8 time units, five to have access times of 57-96 time units, and two to have access times of 134-180 time units. These values were chosen based upon the object-access times reported by Ramamurthy <ref> [21] </ref>. Each task was assigned a computation cost of between one and three quanta, with a quantum being 1000 time units. The number of quanta required by a task was selected at random, with 40% of the generated tasks taking one quantum, 40% taking two, and 20% taking three.
Reference: [22] <author> S. Ramamurthy, M. Moir, and J. Anderson. </author> <title> Real-time object sharing with minimal support. </title> <booktitle> In Proceedings of the 15th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 233-242. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1996. </year>
Reference-contexts: Our work has been heavily influenced by recent research by us and others on using lock-free and wait-free shared-object algorithms in real-time systems <ref> [2, 3, 4, 5, 6, 15, 17, 22] </ref>. Operations on lock-free objects are optimistically performed using a user-level retry loop. Such an operation is atomically validated and committed by invoking a synchronization primitive such as compare-and-swap (CAS). Figure 1 depicts a lock-free enqueue operation that is implemented in this way.
Reference: [23] <author> L. Sha, R. Rajkumar, and J. Lehoczky. </author> <title> Priority inheritance protocols: An approach to real-time system synchronization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(9) </volume> <pages> 1175-1185, </pages> <year> 1990. </year>
Reference-contexts: Alternatives to our approach include using non-uniform quanta, so that object accesses are nonpreemptive [9], and using lock-based implementations, with ceiling- or inheritance-like schemes <ref> [23] </ref> to bound blocking times. 14 In this paper, we have strictly limited attention to systems with a uniform quantum. We hope to investigate systems with non-uniform quanta in future work.
Reference: [24] <author> I. Stoica, H. Abdel-Wahab, K. Jeffay, S. Baruah, J. Gehrke, and C. Plaxton. </author> <title> A proportional share resource allocation algorithm for real-time, time-shared systems. </title> <booktitle> In Proceedings of the 17th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 288-299. </pages> <publisher> IEEE, </publisher> <year> 1996. </year>
Reference-contexts: When a processor is allocated to some task, that task is guaranteed to execute without preemption for Q time units, where Q is the length of the quantum, or until it terminates, whichever comes first. Many real-time applications are designed based on scheduling disciplines such as proportional-share <ref> [24] </ref> and round-robin scheduling that are expressly quantum-based. Under proportional-share scheduling, each task is assigned a share of the processor, which represents the fraction of processing time that that task should receive. <p> Stoica et al. showed that optimal lag bounds can be achieved by using earliest-eligible-virtual-deadline-first (EEVDF) scheduling <ref> [24] </ref>. Due to space limitations, give here only a very brief overview of the EEVDF scheme | the interested reader is referred to [24] for details. The EEVDF algorithm makes scheduling decisions in the virtual-time domain, where virtual times are defined by considering an ideal system. <p> Stoica et al. showed that optimal lag bounds can be achieved by using earliest-eligible-virtual-deadline-first (EEVDF) scheduling <ref> [24] </ref>. Due to space limitations, give here only a very brief overview of the EEVDF scheme | the interested reader is referred to [24] for details. The EEVDF algorithm makes scheduling decisions in the virtual-time domain, where virtual times are defined by considering an ideal system. Informally, the ideal PS system executes client k for w k time units during each virtual-time unit, where w k is its weight.
Reference: [25] <author> H. Takada and K. Sakamura. </author> <title> A novel approach to multiprogrammed multiprocessor synchronization for real-time kernels. </title> <booktitle> In Proceedings of the Eighteenth IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 134-143. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1997. </year>
Reference-contexts: To overcome such problems, several researchers have proposed queue lock algorithms that use kernel support to ensure that preemptions do not adversely impact performance <ref> [25, 26] </ref>. Unfortunately, many of these previous algorithms are based on a kernel interface that is provided only on very few machines. Most previous algorithms that do not rely on such an interface are quite complicated. <p> In contrast, with existing array-based locks, spins are local only if applied in a system with coherent caches. All work known to us on preemptable queue locks involves list-based locks <ref> [25, 26] </ref>. This is probably due to the advantages listed in the previous paragraph that (nonpreemptable) list-based locks have over array-based ones. However, correctly maintaining a linked list of spinning tasks in the face of preemptions is very trick. <p> In the absence of such a kernel interface, list maintenance becomes quite hard, leading to complicated algorithms. For example, a list-based preemptable queue lock proposed by Takada and Sakamura at last year's RTSS requires a total of 63 executable statements <ref> [25] </ref>. Our preemptable queue lock is an array-based lock and is quite simple, consisting of only 17 lines of code. In addition, all that we require the kernel to do is to set a shared variable whenever a task is preempted indicating that that task is no longer running. <p> Actually verifying this belief would involve implementing the MPCP, which to the best of our knowledge, no one has ever done. 3.2 Experimental Comparison We have conducted performance experiments to compare our preemptable queue lock algorithm to a preemptable queue lock presented last year by Takada and Sakamura <ref> [25] </ref>. Their lock is designated as the "SPEPP/MCS algorithm" in their paper, so we will use that term here (SPEPP stands for "spinning processor executes for preempted processors"; MCS denotes that this lock is derived from one published previously by Mellor-Crummey and Scott [19]). <p> In other words, worst-case performance is linear in the number of tasks that may access the lock. In <ref> [25] </ref>, Takada and Sakamura suggest a variant of the SPEPP/MCS algorithm in which there is a single node for all tasks on one processor, resulting in fi (P ) worst-case performance for P processors, like our algorithm.
Reference: [26] <author> R. Wisniewski, L. Kontothanassis, and M. Scott. </author> <title> High performance synchronization algorithms for multi-programmed multiprocessors. </title> <booktitle> In Proceedings of the Fifth ACM Symposium on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 199-206. </pages> <publisher> ACM, </publisher> <month> July </month> <year> 1995. </year> <month> 22 </month>
Reference-contexts: To overcome such problems, several researchers have proposed queue lock algorithms that use kernel support to ensure that preemptions do not adversely impact performance <ref> [25, 26] </ref>. Unfortunately, many of these previous algorithms are based on a kernel interface that is provided only on very few machines. Most previous algorithms that do not rely on such an interface are quite complicated. <p> In contrast, with existing array-based locks, spins are local only if applied in a system with coherent caches. All work known to us on preemptable queue locks involves list-based locks <ref> [25, 26] </ref>. This is probably due to the advantages listed in the previous paragraph that (nonpreemptable) list-based locks have over array-based ones. However, correctly maintaining a linked list of spinning tasks in the face of preemptions is very trick. <p> Wisniewski et al. handle such problems by exploiting a rather non-standard kernel interface that has the ability to "warn" tasks before they are preempted so that they can take appropriate action in time <ref> [26] </ref>. In the absence of such a kernel interface, list maintenance becomes quite hard, leading to complicated algorithms. For example, a list-based preemptable queue lock proposed by Takada and Sakamura at last year's RTSS requires a total of 63 executable statements [25].
References-found: 26

