URL: http://www.csl.sri.com/reports/postscript/csl-95-1.ps.gz
Refering-URL: http://www.csl.sri.com/trlist.html
Root-URL: 
Email: Rushby@csl.sri.com  
Phone: Phone: +1 (415) 859-5456 Fax: +1 (415) 859-2844  
Title: Formal Methods and their Role in the Certification of Critical Systems  
Author: John Rushby 
Date: March 1995  
Address: Menlo Park CA 94025 USA  
Affiliation: Computer Science Laboratory SRI International  
Pubnum: Technical Report CSL-95-1  
Abstract: fl Preparation of this report was sponsored by the Federal Aviation Administration, FAA Technical Center, Atlantic City NJ, and by the National Aeronautics and Space Administration Langley Research Center, Langley VA, under Contract NAS1-18969, monitored by NASA Langley Research Center. 
Abstract-found: 1
Intro-found: 1
Reference: [BCAG95] <institution> Statistical Summary of Commercial Jet Aircraft Accidents, </institution> <note> Worldwide Operations, 1959-1994. Published annually by: </note> <institution> Airplane Safety Engineering (B-210B), Boeing Commercial Airplane Group, </institution> <address> Seattle, WA, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: For example, in addition to all the other assurance techniques that may be applied, it will be valuable to prove that mode-switching logic does not contain states with no escape, 11 The appalling safety record of the Airbus A320 aircraft <ref> [BCAG95] </ref> seems attributable to poor human factors rather than to specific software faults [Mel94]. 43 and that sensor data is distributed consistently despite the presence of faults.
Reference: [BF93] <author> Ricky W. Butler and George B. Finelli. </author> <title> The infeasibility of experimental quantification of life-critical software reliability. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(1) </volume> <pages> 3-12, </pages> <month> January </month> <year> 1993. </year>
Reference: [Bid91] <author> Wayne Biddle. </author> <title> Barons of the Sky: From Early Flight to Strategic Warfare, the Story of the American Aerospace Industry. </title> <editor> Simon and Schus-ter, </editor> <address> New York, NY, </address> <year> 1991. </year> <note> Paperback edition by Henry Holt, </note> <year> 1993. </year>
Reference-contexts: inside a seaplane supported on wooden trestles "to see if it was strong enough." Douglas noted that "this didn't represent any load that the plane bore in flight." Aided by proper engineering analysis, his first design (the Model S) had almost twice the range and payload of Martin's previous products <ref> [Bid91, pp. 85, 86] </ref>. It is inconceivable today that an aeronautical engineer could be ignorant of aerodynamics or structural mechanics, still less argue that such mathematical modeling is irrelevant to the practical business of designing airfoils. I expect formal methods eventually to play a similar role in software engineering.
Reference: [BJ94] <author> J. Brazendale and A. R. Jeffs. </author> <title> Out of control: Failures involving control systems. </title> <booktitle> High Integrity Systems, </booktitle> <volume> 1(1) </volume> <pages> 67-72, </pages> <year> 1994. </year>
Reference-contexts: Design faults can occur in any system, independently of the technologies used in its construction (see, for example, <ref> [BJ94] </ref>) but, because design faults are often due to a failure to anticipate certain interactions among the components of the system, or between the system and its environment, they become more likely as the number and complexity of possible behaviors and interactions increases.
Reference: [Bur93] <author> R. W. Burns. </author> <title> Genius at work. </title> <journal> IEE Review, </journal> <volume> 39(5) </volume> <pages> 187-189, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Example include certain kinds of protocols [HK90, CGH + 95] and hardware designs [MS95]. a For example, Tesla quit Edison's laboratory after less than a year complaining of Edison's preference for empirical methods "knowing that a little theory and calculation would have saved him 90% of his labor" <ref> [Bur93] </ref>. 28 Standards and guidance documents for safety-critical systems generally rank software components by criticality according to the severity of the consequences that could result from their malfunction.
Reference: [CGH + 95] <author> Edmund M. Clarke, Orna Grumberg, Hiromi Haraishi, Somesh Jha, David E. Long, Kenneth L. McMillan, and Linda A. Ness. </author> <title> Verification of the Futurebus+ cache coherence protocol. </title> <booktitle> Formal Methods in System Design, </booktitle> <volume> 6(2) </volume> <pages> 217-232, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: It is not necessary to train every programmer to get valuable returns from formal methods. Another opportunity lies in problems where formal methods can be massively automated. Example include certain kinds of protocols <ref> [HK90, CGH + 95] </ref> and hardware designs [MS95]. a For example, Tesla quit Edison's laboratory after less than a year complaining of Edison's preference for empirical methods "knowing that a little theory and calculation would have saved him 90% of his labor" [Bur93]. 28 Standards and guidance documents for safety-critical systems
Reference: [CGL94] <author> E. Clarke, O. Grumberg, and D. </author> <title> Long. Verification tools for finite-state concurrent systems. </title> <editor> In J. W. de Bakker, W. P. de Roever, and G. Rozenberg, editors, </editor> <booktitle> A Decade of Concurrency, </booktitle> <pages> pages 124-175, </pages> <booktitle> REX Workshop, Mook, </booktitle> <address> The Netherlands, </address> <month> June </month> <year> 1994. </year> <booktitle> Volume 803 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Hardware, and distributed algorithms such as protocols are particularly suitable for this kind of examination through exhaustive state exploration [DDHY92] (related technologies are known as model checking <ref> [CGL94] </ref> and language inclusion [HK90]). A specification may admit too many behaviors for state exploration to succeed, but it may be possible to develop a "downscaled" version that can be examined in this way.
Reference: [Coo93] <author> Henry S. F. Cooper Jr. </author> <title> The Evening Star: Venus Observed. </title> <address> Farrar Straus Giroux, New York, NY, </address> <year> 1993. </year>
Reference-contexts: As luck would have it, this random address sent the processor to a piece of code where it sat in a tight loop that continually reset the watchdog timer, thereby disabling the very mechanism that was intended to thwart such runaways <ref> [Coo93, pp. 209-221] </ref>. a Computer scientists are thoroughly familiar with the dangers of being interrupted while adjusting critical data structures and will normally arrange for such actions to take place inside a "critical section" that cannot be interrupted.
Reference: [CRSS94] <author> D. Cyrluk, S. Rajan, N. Shankar, and M. K. Srivas. </author> <title> Effective theorem proving for hardware verification. </title> <editor> In Ramayya Kumar and Thomas Kropf, editors, </editor> <booktitle> Theorem Provers in Circuit Design (TPCD '94), </booktitle> <pages> pages 203-222, </pages> <address> Bad Herrenalb, Germany, </address> <month> September </month> <year> 1994. </year> <booktitle> Volume 910 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For example, mechanized verification of the microcode for a simple processor called "Tamarack" represented a significant challenge just five years ago [Joy89], whereas it can now be done completely automatically in about five minutes <ref> [CRSS94] </ref>. Progress is uneven however, and the amount of human time and effort required to undertake a Level 3 analysis can vary by two orders of magnitude or more from one verification system to another.
Reference: [DDHY92] <author> David L. Dill, Andreas J. Drexler, Alan J. Hu, and C. Han Yang. </author> <title> Protocol verification as a hardware design aid. </title> <booktitle> In 1992 IEEE International Conference on Computer Design: VLSI in Computers and Processors, </booktitle> <pages> 54 pages 522-525. </pages> <publisher> IEEE Computer Society, </publisher> <address> 1992. Cambridge, MA, Octo--ber 11-14. </address>
Reference-contexts: Hardware, and distributed algorithms such as protocols are particularly suitable for this kind of examination through exhaustive state exploration <ref> [DDHY92] </ref> (related technologies are known as model checking [CGL94] and language inclusion [HK90]). A specification may admit too many behaviors for state exploration to succeed, but it may be possible to develop a "downscaled" version that can be examined in this way.
Reference: [Dor91] <author> Michael A. Dornheim. </author> <title> X-31 flight tests to explore combat agility to 70 deg. </title> <booktitle> AOA. Aviation Week and Space Technology, </booktitle> <pages> pages 38-41, </pages> <month> March 11, </month> <year> 1991. </year>
Reference-contexts: The air data logic dates back to the mid-1960s and had a divide-by-zero that occurred briefly. This was not a problem in its previous application, but the X31 flight-control system would not tolerate it" <ref> [Dor91] </ref>.
Reference: [ECK + 91] <author> Dave E. Eckhardt, Alper K. Caglayan, John C. Knight, Larry D. Lee, David F. McAllister, Mladen A. Vouk, and John P. J. Kelly. </author> <title> An experimental evaluation of software redundancy as a strategy for improving reliability. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(7) </volume> <pages> 692-702, </pages> <month> July </month> <year> 1991. </year>
Reference: [FAA88] <institution> System Design and Analysis. Federal Aviation Administration, </institution> <month> June 21, </month> <year> 1988. </year> <title> Advisory Circular 25.1309-1A. </title>
Reference-contexts: For example, catastrophic failure conditions in aircraft ("those which would prevent continued safe flight and landing") must be "extremely improbable." That is, "so unlikely that they are not anticipated to occur during the entire operational life of all airplanes of one type" <ref> [FAA88, paragraphs 6.h (3) and 9.e (3)] </ref>. <p> This is indeed the number suggested as an "aid to engineering judgment to help determine compliance" with the requirement for extremely improbable failure conditions <ref> [FAA88, paragraph 10.b] </ref>. a For a simple physical system where breakdown or wearout is the only potential cause for a catastrophic failure condition, experience with similar systems together with testing and analysis, may yield data that can substantiate a claimed failure rate as low as 10 9 .
Reference: [FAA89] <institution> Digital Systems Validation Handbook-Volume II. Federal Aviation Administration Technical Center, Atlantic City, NJ, </institution> <month> February </month> <year> 1989. </year> <month> DOT/FAA/CT-88/10. </month>
Reference-contexts: Introduction This report is based on one prepared as a chapter for the FAA Digital Systems Validation Handbook (a guide for aircraft certifiers) <ref> [FAA89] </ref>. Its purpose is to outline what is meant by "formal methods" and to explain their rationale and suggest techniques for their use in providing assurance for critical applications.
Reference: [FB92] <editor> John H. Fielder and Douglas Birsch, editors. </editor> <title> The DC-10 Case: A Case Study in Applied Ethics, </title> <institution> Technology, and Society. State University of New York Press, </institution> <year> 1992. </year>
Reference-contexts: Examples of this approach are fault injection (an empirical method) and failure modes, effects and criticality analysis (FMECA, an analytical method). 4 For a critical examination of ethical and regulatory issues concerning the DC-10, see the compendium edited by Fielder and Birsch <ref> [FB92] </ref>. 11 An Aside on Multiple-Version Software. The topic of constructing systems that can tolerate faults in their own design using multiple-version software is controversial. The main questions are whether this approach provides any significant additional assurance of safety, and whether that assurance is quantifiable.
Reference: [GH90] <author> G. Guiho and C. </author> <title> Hennebert. </title> <booktitle> SACEM software validation. In 12th International Conference on Software Engineering, </booktitle> <pages> pages 186-191, </pages> <address> Nice, France, March 1990. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: The practicality and cost/benefit of formal methods are heavily dependent on the type of applications considered. Program verification of the kind illustrated in my examples is undeniably tedious and expensive (see, for example the figures quoted in <ref> [GH90] </ref>), and must compete with traditional methods that are quite effective. My opinion is that the greatest benefits are likely to be found when formal methods are applied to the hardest and most difficult problems|where traditional methods are ineffective or unavailable.
Reference: [GY76] <author> S. L. Gerhart and L. Yelowitz. </author> <title> Observations of fallibility in modern programming methodologies. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-2(3):195-207, </volume> <month> September </month> <year> 1976. </year>
Reference-contexts: That is, we might ask whether sort (sort (x)) = sort (x) is a theorem of the specification (assuming sort is a function that takes a sequence as argument and returns the sorted sequence as its value). Gerhart and Yelowitz <ref> [GY76] </ref> describe how early formal specifications of sorting were deficient in that they required the output of the operation to be ordered, but neglected to stipulate that it should also be a permutation of the input.
Reference: [Hec93] <author> Herbert Hecht. </author> <title> Rare conditions: An important cause of failures. </title> <booktitle> In COMPASS '93 (Proceedings of the Eighth Annual Conference on Computer Assurance), </booktitle> <pages> pages 81-85, </pages> <address> Gaithersburg, MD, </address> <month> June </month> <year> 1993. </year> <institution> IEEE Washington Section. </institution>
Reference-contexts: For required failure rates on the order of 10 9 , this means that it will be necessary to construct many millions of the very rare scenarios that will each be encountered only one time in a billion. (Catastrophic failures usually arise in situations compounded by several rare events <ref> [Hec93] </ref>.) Divergence between the test and operational profiles in these remote regions can lead to inaccurate estimates of reliability and spurious assurance of safety.
Reference: [HJ89] <author> I. J. Hayes and C. B. Jones. </author> <title> Specifications are not (necessarily) executable. </title> <journal> IEE/BCS Software Engineering Journal, </journal> <volume> 4(6) </volume> <pages> 320-338, </pages> <month> Novem-ber </month> <year> 1989. </year>
Reference-contexts: Model-oriented specifications tend to lend themselves more naturally to direct execution than do property-oriented specifications. Note that executability may be at odds with other desirable properties of a specification (such as abstractness, and nonprescriptiveness) <ref> [HJ89] </ref>. For specifications that cannot be executed directly, it may be desirable to construct a simulator or rapid prototype for testing purposes.
Reference: [HK90] <author> Zvi Har'El and Robert P. Kurshan. </author> <title> Software for analytical development of communications protocols. </title> <journal> AT&T Technical Journal, </journal> <volume> 69(1) </volume> <pages> 45-59, </pages> <month> January/February </month> <year> 1990. </year> <month> 55 </month>
Reference-contexts: It is not necessary to train every programmer to get valuable returns from formal methods. Another opportunity lies in problems where formal methods can be massively automated. Example include certain kinds of protocols <ref> [HK90, CGH + 95] </ref> and hardware designs [MS95]. a For example, Tesla quit Edison's laboratory after less than a year complaining of Edison's preference for empirical methods "knowing that a little theory and calculation would have saved him 90% of his labor" [Bur93]. 28 Standards and guidance documents for safety-critical systems <p> Hardware, and distributed algorithms such as protocols are particularly suitable for this kind of examination through exhaustive state exploration [DDHY92] (related technologies are known as model checking [CGL94] and language inclusion <ref> [HK90] </ref>). A specification may admit too many behaviors for state exploration to succeed, but it may be possible to develop a "downscaled" version that can be examined in this way.
Reference: [Jon90] <author> Cliff B. Jones. </author> <title> Systematic Software Development Using VDM. </title> <publisher> Prentice Hall International Series in Computer Science. Prentice Hall, </publisher> <address> Hemel Hempstead, UK, </address> <note> second edition, </note> <year> 1990. </year>
Reference-contexts: Level 2 formal methods address the problems of communication and training by providing fixed specification notations (Z [Spi93] and VDM <ref> [Jon90] </ref> are well-known examples) and, usually, a methodology for using them. Individual Level 2 methods are well suited to some types of applications (e.g., data processing), and less well suited to others (e.g., concurrent systems); users must be careful not to stretch their chosen method beyond its limits.
Reference: [Joy89] <author> Jeffrey Joyce. </author> <title> Multi-Level Verification of Microprocessor-Based Systems. </title> <type> PhD thesis, </type> <institution> University of Cambridge, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: An Aside on Mechanized Proof Checking. The effectiveness of mechanized proof checkers and theorem provers for formal methods is advancing very rapidly. For example, mechanized verification of the microcode for a simple processor called "Tamarack" represented a significant challenge just five years ago <ref> [Joy89] </ref>, whereas it can now be done completely automatically in about five minutes [CRSS94]. Progress is uneven however, and the amount of human time and effort required to undertake a Level 3 analysis can vary by two orders of magnitude or more from one verification system to another.
Reference: [Keu91] <author> Kurt Keutzer. </author> <title> The need for formal verification in hardware design and what formal verification has not done for me lately. </title> <editor> In Phillip Windley, editor, </editor> <booktitle> Proceedings of the 1991 International Workshop on the HOL Theorem Proving System and its Applications, </booktitle> <pages> pages 77-86, </pages> <address> Davis, CA, </address> <month> August </month> <year> 1991. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: For example, Lutz [Lut93] reports on 197 significant software faults detected during integration and system testing of the Voyager and Galileo spacecraft. Only three of these faults were programming errors; the vast majority were requirements problems. Similarly, Keutzer <ref> [Keu91] </ref> reports that fully half of all ASICs are faulty on first fabrication, and that these faults are invariably due to errors in requirements or high-level design: no errors are reported in implementation below the register-transfer level.
Reference: [KL86] <author> J. C. Knight and N. G. Leveson. </author> <title> An experimental evaluation of the assumption of independence in multiversion programming. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(1):96-109, </volume> <month> January </month> <year> 1986. </year>
Reference: [KP93] <author> Rick Kasuda and Donna Sexton Packard. </author> <title> Spacecraft fault tolerance: The Magellan experience. </title> <editor> In Robert D. Culp and George Bickley, editors, </editor> <booktitle> Proceedings of the Annual Rocky Mountain Guidance and Control Conference, </booktitle> <pages> pages 249-267, </pages> <publisher> Keystone, CO, </publisher> <month> February </month> <year> 1993. </year> <booktitle> Volume 81 of Advances in the Astronautical Sciences, </booktitle> <publisher> American Astronautical Society. </publisher>
Reference-contexts: While in orbit around Venus, the Magellan spacecraft broke contact with Earth and entered "safing" modes|preempting its scientific mission|on a number of occasions. Extensive efforts were undertaken to find the source of the problem and, after eight months, the most likely cause was identified <ref> [KP93] </ref>. Two flags determine whether a background task should be run in the otherwise unused time after the end of all the foreground tasks in the current frame and before the end-of-frame interrupt.
Reference: [KSH92] <author> John C. Kelly, Joseph S. Sherif, and Jonathan Hops. </author> <title> An analysis of defect densities found during software inspections. </title> <journal> Journal of Systems Software, </journal> <volume> 17 </volume> <pages> 111-117, </pages> <year> 1992. </year>
Reference-contexts: Notice how this process of subjecting specifications to formal challenges probes the completeness as well as the correctness of specifications. Data from the Jet Propulsion Laboratory indicates that two-thirds of the defects in requirements specifications are omissions <ref> [KSH92] </ref>, so that systematic methods of exploring completeness are highly desirable. Challenges can be undertaken at any level of formality, but I believe that all those who write or review formal specifications should have experience in challenging specifications at Level 3 using a mechanized proof checker or theorem prover.
Reference: [Lev95] <author> Nancy G. Leveson. Safeware: </author> <title> System Safety and Computers. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: This approach is inspired by hazard analysis, which is a central concept in safety-critical systems; one particular method for doing it that has been adapted to software is fault-tree analysis (FTA) <ref> [Lev95, Section 14.3] </ref>. The property that is common to the different assurance techniques is that they provide ways to group "essentially similar" behaviors together so that fewer cases need to be considered while still providing effectively complete coverage of all possible behaviors.
Reference: [LM94] <author> Leslie Lamport and Stephan Merz. </author> <title> Specifying and verifying fault-tolerant systems. </title> <editor> In H. Langmaack, W.-P. de Roever, and J. Vytopil, editors, </editor> <booktitle> Formal Techniques in Real-Time and Fault-Tolerant Systems, </booktitle> <pages> pages 41-76, </pages> <address> Lubeck, Germany, </address> <month> September </month> <year> 1994. </year> <booktitle> Volume 863 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This is a distributed algorithm, and if we are concerned with issues of the timing and transfer of the messages that are communicated in the algorithm, then it is necessary to model these mechanisms in some detail, and the analysis will be correspondingly detailed and lengthy <ref> [LM94] </ref>. But if we are mainly concerned with the fault masking properties of the algorithm, then the mechanisms of distributed computation and communication can be ignored and the algorithm can be modeled as a recursive function, in which form its analysis is quite straightforward.
Reference: [LMS85] <author> L. Lamport and P. M. Melliar-Smith. </author> <title> Synchronizing clocks in the presence of faults. </title> <journal> Journal of the ACM, </journal> <volume> 32(1) </volume> <pages> 52-78, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: These are precisely the kinds of arguments where informal reasoning may be expected to go astray|and go astray it does: for example, the published proof for one synchronization algorithm <ref> [LMS85] </ref> has flaws in its main theorem and in four of its five lemmas [RvH93]. The flaws in this example were discovered while undertaking formal analysis at Level 3 and suggest the benefits that may be derived from this level of rigor.
Reference: [LR93] <author> Patrick Lincoln and John Rushby. </author> <title> A formally verified algorithm for interactive consistency under a hybrid fault model. </title> <booktitle> In Fault Tolerant Computing Symposium 23, </booktitle> <pages> pages 402-411, </pages> <address> Toulouse, France, </address> <month> June </month> <year> 1993. </year> <journal> IEEE Computer Society. </journal> <volume> 56 </volume>
Reference-contexts: In this particular example, it is possible to increase the number of different types of faults that are considered in the most abstracted representation, and this allows the fault tolerance of the algorithm to be analyzed in greater detail (and reveals a bug in a published algorithm) <ref> [LR93] </ref>. As this example makes clear, abstraction is closely related to the modeling activity that is inherent in formal methods. The whole basis of formal methods is to create mathematical models of certain physical and computational phenomena and to make predictions about these phenomena through analysis of the models.
Reference: [LSP82] <author> Leslie Lamport, Robert Shostak, and Marshall Pease. </author> <title> The Byzantine generals problem. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 4(3) </volume> <pages> 382-401, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: When formal methods are applied to algorithms, there is further scope for abstraction in the choice of how much detail to include. For example, one of the important algorithms in fault-tolerant systems is one for distributing sensor samples consistently in the presence of faults <ref> [LSP82] </ref>. This is a distributed algorithm, and if we are concerned with issues of the timing and transfer of the messages that are communicated in the algorithm, then it is necessary to model these mechanisms in some detail, and the analysis will be correspondingly detailed and lengthy [LM94].
Reference: [LT82] <author> E. Lloyd and W. Tye. </author> <title> Systematic Safety: Safety Assessment of Aircraft Systems. Civil Aviation Authority, </title> <address> London, England, </address> <year> 1982. </year> <note> Reprinted 1992. </note>
Reference-contexts: A little arithmetic suggests 10 7 hours as the operational lifetime of an aircraft fleet, and hazard analysis might typically reveal ten potentially catastrophic failure conditions in each of ten systems on board the aircraft, so that the maximum allowable failure rate for each is about 10 9 per hour <ref> [LT82, page 37] </ref>.
Reference: [LT93] <author> Nancy G. Leveson and Clark S. Turner. </author> <title> An investigation of the Therac-25 accidents. </title> <journal> IEEE Computer, </journal> <volume> 26(7) </volume> <pages> 18-41, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Similarly, much of the software in the Therac 25 medical electron accelerator, which led to massive overdoses of radiation and the subsequent deaths of six patients, had been used in an earlier machine without accident <ref> [LT93] </ref>. 15 The infeasibility of experimental quantification of reliability for safety-critical software means that its assurance must chiefly be provided by other means. Now, experimental evaluation is not the only means for providing assurance about the behaviors of physically engineered systems.
Reference: [Lut93] <author> Robyn R. Lutz. </author> <title> Analyzing software requirements errors in safety-critical embedded systems. </title> <booktitle> In IEEE International Symposium on Requirements Engineering, </booktitle> <pages> pages 126-133, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Another criterion that should be considered is the likely effectiveness of formal methods versus traditional methods for quality control and assurance. It is to be expected, and there is some evidence to support the expectation <ref> [Lut93] </ref>, that the intrinsically hard design problems tend to be the most prone to faults, and the most resistant to traditional means of assurance. These intrinsically hard problems generally involve complex interactions, such as the coordination of distributed, concurrent, or real-time computations, and redundancy management. <p> For example, Lutz <ref> [Lut93] </ref> reports on 197 significant software faults detected during integration and system testing of the Voyager and Galileo spacecraft. Only three of these faults were programming errors; the vast majority were requirements problems.
Reference: [Mac88] <author> Dale A. Mackall. </author> <title> Development and flight test experiences with a flight-crucial digital control system. </title> <type> NASA Technical Paper 2857, </type> <institution> NASA Ames Research Center, Dryden Flight Research Facility, Edwards, </institution> <address> CA, </address> <year> 1988. </year>
Reference-contexts: on test flight 44, disagreements among the threshold voters in the AFTI-F16 digital flight control system caused each computer to declare the others failed, the analog backup was not selected because simultaneous failure of two or more digital channels had not been anticipated in design of the redundancy management system <ref> [Mac88, p. 44] </ref>.
Reference: [Mel94] <author> Peter Mellor. </author> <title> CAD: Computer-aided disaster. </title> <booktitle> High Integrity Systems, </booktitle> <volume> 1(2) </volume> <pages> 101-156, </pages> <year> 1994. </year>
Reference-contexts: addition to all the other assurance techniques that may be applied, it will be valuable to prove that mode-switching logic does not contain states with no escape, 11 The appalling safety record of the Airbus A320 aircraft [BCAG95] seems attributable to poor human factors rather than to specific software faults <ref> [Mel94] </ref>. 43 and that sensor data is distributed consistently despite the presence of faults. These are not the only properties required of mode switching and sensor distribution, but they are among the most crucial and among the most difficult to assure using traditional methods.
Reference: [MOD91] <institution> Interim Defence Standard 00-55: The procurement of safety critical software in defence equipment. UK Ministry of Defence, </institution> <month> April </month> <year> 1991. </year> <note> Part 1, Issue 1: Requirements; Part 2, Issue 1: Guidance. </note>
Reference-contexts: Formal methods are not specifically endorsed by DO-178B (in contrast to certain other guidelines and standards that do recommend or require their use <ref> [MOD91] </ref>), but are included among the "alternative methods" discussed in its section 12.3. 12.3. Alternative Methods: Some methods were not discussed in the previous sections of this document because of inadequate maturity at the time this document was written or limited applicability for airborne software. <p> Level 1) argument that is subjected to intense human review, and it is the combination of stringent mechanical and human scrutiny (and other evidence, such as tests) that should be considered in certification. 17 17 For this reason, I do not endorse the requirement in UK Interim Defence Standard 00-55 <ref> [MOD91, paragraph 32.2.3] </ref> that a second mechanically checked proof using a "diverse tool" 51 The construction of a mechanically checked proof that certain algorithms and architectural mechanisms accomplish certain goals subject to certain assumptions addresses only part of the problem: it is also necessary to validate the modeling employed.
Reference: [MS95] <author> Steven P. Miller and Mandayam Srivas. </author> <title> Formal verification of the AAMP5 microprocessor: A case study in the industrial use of formal methods. </title> <booktitle> In WIFT '95: Workshop on Industrial-Strength Formal Specification Techniques, </booktitle> <pages> pages 2-16, </pages> <address> Boca Raton, FL, 1995. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: It is not necessary to train every programmer to get valuable returns from formal methods. Another opportunity lies in problems where formal methods can be massively automated. Example include certain kinds of protocols [HK90, CGH + 95] and hardware designs <ref> [MS95] </ref>. a For example, Tesla quit Edison's laboratory after less than a year complaining of Edison's preference for empirical methods "knowing that a little theory and calculation would have saved him 90% of his labor" [Bur93]. 28 Standards and guidance documents for safety-critical systems generally rank software components by criticality according
Reference: [ORSvH95] <author> Sam Owre, John Rushby, Natarajan Shankar, and Friedrich von Henke. </author> <title> Formal verification for fault-tolerant architectures: Prolegomena to the design of PVS. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(2) </volume> <pages> 107-125, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: My opinion is that the greatest benefits are likely to be found when formal methods are applied to the hardest and most difficult problems|where traditional methods are ineffective or unavailable. Examples of hard problems are those involving distributed and concurrent execution and, especially, redundancy management <ref> [ORSvH95] </ref>. These problems can be considered practical because, though hard, they are not large and can therefore be undertaken by a few highly skilled people. It is not necessary to train every programmer to get valuable returns from formal methods.
Reference: [PW85] <author> David L. Parnas and David M. Weiss. </author> <title> Active design reviews: </title> <booktitle> Principles and practices. In 8th International Conference on Software Engineering, </booktitle> <pages> pages 132-136, </pages> <address> London, UK, </address> <month> August </month> <year> 1985. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: you consider the requirements are complete?" and it will be necessary to add items such as "do you consider that you have been able to fully comprehend the formal specification?" The assurance that participants do fully comprehend a formal specification may be enhanced if the suggestions of Parnas and Weiss <ref> [PW85] </ref> are followed: for example, someone other than the author of a specification should be expected to explain it during the review, and the author should pose questions to the reviewers (rather than vice versa).
Reference: [RBP + 91] <author> James Rumbaugh, Michael Blaha, William Premerlani, Frederick Eddy, and William Lorensen. </author> <title> Object-Oriented Modeling and Design. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1991. </year> <month> 57 </month>
Reference-contexts: More modern notations, derived from programming languages like Ada and ideas from object-oriented design <ref> [RBP + 91] </ref>, have significantly raised the level of abstraction and improved the organization of data descriptions, but the orientation is still that of implementation.
Reference: [RTCA92] <author> DO-178B: </author> <title> Software Considerations in Airborne Systems and Equip--ment Certification. Requirements and Technical Concepts for Aviation, </title> <address> Washington, DC, </address> <month> December </month> <year> 1992. </year> <note> This document is known as EURO-CAE ED-12B in Europe. </note>
Reference-contexts: degree of protection provided by software diversity "is not usually measurable" and dissimilar software versions do not provide a means for achieving safety-critical requirements, but "are usually used as a means of providing additional protection after the software verification process objectives for the software level: : : have been met" <ref> [RTCA92, Subsection 2.3.2] </ref>. 12 The general idea behind the second approach to quality assurance is to hypoth-esize that the system has done something bad and then to analyze all the circumstances that could cause this to come about and to show that the design prevents them from happening. <p> Numerical estimates of reliability are not assigned to airborne software <ref> [RTCA92, Subsection 2.2.3] </ref>, but the figure gives an idea of the quality required. b In flight tests of the X31, the control system "went into a reversionary mode four times in the first nine flights, usually due to disagreement between the two air-data sources. <p> For example, DO-178B identifies software criticality levels A through E according to the severity of their potential failure conditions (i.e., Level A is software whose malfunction could contribute to a catastrophic failure condition) <ref> [RTCA92, Subsection 2.2.2] </ref>. Software criticality level determines the amount of effort and evidence required to show compliance with certification requirements. It provides a natural criterion for selecting components for which formal methods should be considered. <p> For example, the important property of a particular component may not be that it does its job (there may be backups to accomplish that), but that it is free of "specific anomalous behaviors" <ref> [RTCA92, Section 2.6] </ref>. Negative properties such as this (i.e., properties that state what must not happen) are particularly difficult to test and can be good candidates for formal analysis. 2.1.4 Lifecycle Stages The example shown earlier involving the exponentiation program illustrated the use of formal methods in the late lifecycle. <p> By that measure, other promising applications for formal methods are in the general area of requirements specification and analysis|where current processes, though fairly effective, are ad-hoc and unstructured. 3.2 Interpretation for DO-178B The RTCA ("Requirements and Technical Concepts for Aviation, Inc.") document known in the USA as DO-178B <ref> [RTCA92] </ref> and in Europe as EUROCAE ED-12B provides industry-accepted guidelines for meeting certification requirements for software used in airborne systems and equipment, and is incorporated by reference into European and United States regulatory and advisory documents.
Reference: [Rus93] <author> John Rushby. </author> <title> Formal methods and the certification of critical systems. </title> <type> Technical Report SRI-CSL-93-7, </type> <institution> Computer Science Laboratory, SRI International, </institution> <address> Menlo Park, CA, </address> <month> December </month> <year> 1993. </year> <note> Also issued under the title Formal Methods and Digital Systems Validation for Airborne Systems as NASA Contractor Report 4551, </note> <month> December </month> <year> 1993. </year>
Reference-contexts: The report is intended as an introduction for those to whom these topics are new and assumes no background beyond some exposure to software engineering and to safety-critical systems. A more technical examination of formal methods is provided in a companion report <ref> [Rus93] </ref>.
Reference: [RvH93] <author> John Rushby and Friedrich von Henke. </author> <title> Formal verification of algorithms for critical systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(1) </volume> <pages> 13-23, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: These are precisely the kinds of arguments where informal reasoning may be expected to go astray|and go astray it does: for example, the published proof for one synchronization algorithm [LMS85] has flaws in its main theorem and in four of its five lemmas <ref> [RvH93] </ref>. The flaws in this example were discovered while undertaking formal analysis at Level 3 and suggest the benefits that may be derived from this level of rigor.
Reference: [Spi93] <author> J. M. Spivey, </author> <title> editor. The Z Notation: A Reference Manual. </title> <publisher> Prentice Hall International Series in Computer Science. Prentice Hall, </publisher> <address> Hemel Hempstead, UK, </address> <note> second edition, </note> <year> 1993. </year>
Reference-contexts: Level 2 formal methods address the problems of communication and training by providing fixed specification notations (Z <ref> [Spi93] </ref> and VDM [Jon90] are well-known examples) and, usually, a methodology for using them.

References-found: 45

