URL: file://ftp.cs.wisc.edu/tech-reports/reports/92/tr1094.ps.Z
Refering-URL: http://www.cs.wisc.edu/shore/shore.papers.html
Root-URL: 
Title: Client-Server DBMS Architectures  
Author: Michael J. Franklin Michael J. Carey Miron Livny 
Keyword: Global Memory Management  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Note: in  This work was partially supported by the Defense Advanced Research Projects Agency under contract DAAB07-92-C-Q508, by the Na tional Science Foundation under grant IRI-8657323, and by a research grant from IBM Corporation.  
Abstract: An abridged version of this paper appears in: The Proceedings of the 18th International Conference on Very Large Data Bases, Vancouver, BC, Canada, August 1992. Computer Sciences Technical Report #1094 June 1992 
Abstract-found: 1
Intro-found: 1
Reference: [Care91] <author> Carey, M., Franklin, M., Livny, M., Shekita, E., </author> <title> "Data Caching Tradeoffs in Client-Server DBMS Architectures", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Denver, CO, </address> <month> June, </month> <year> 1991. </year>
Reference-contexts: We also focus on systems with a single server, both in our descriptions and our experiments. 1.1. Performance of Page Server Systems Recently, there have been several studies of the performance aspects of caching algorithms for page server systems <ref> [Wilk90, Care91, Wang91, Fran92a] </ref>. These studies have shown the advantages and potential pitfalls of attempting to offload servers by caching locks and/or data at client workstations across transaction boundaries. Such caching is referred to as inter-transaction caching. <p> Furthermore, two additional inefficiencies of this type of data caching were identified in <ref> [Care91] </ref>. First, when small numbers of workstations were present, there was often a high correlation between the pages resident in the server buffer pool and those resident in the client buffer pools. <p> MODELING A CLIENT-SERVER DBMS In order to study the performance of alternative global memory management techniques, we have extended the client-server DBMS simulation model that was used in our earlier studies <ref> [Care91, Fran92a] </ref>. In this section we describe how the model captures the database, workload, and physical resources of a client-server DBMS that supports the proposed global memory management techniques. 3.1. Database and Workload Models Table 1 presents the parameters used to model the database and its workload.
Reference: [Chen84] <author> Cheng, J., Loosley, C., Shibamiya, A., Worthington, P., </author> <title> "IBM Database 2 performance: Design, Implementation, and Tuning", </title> <journal> IBM Systems Journal, </journal> <volume> Vol. 23, No. 2., </volume> <year> 1984. </year>
Reference-contexts: On one hand, reclaiming a dirty page's buffer slot requires an I/O to write the page to disk, so keeping a dirty page in the buffer longer can reduce I/O by combining multiple writes to the same page into a single disk write <ref> [Chen84] </ref>.
Reference: [Dan91] <author> Dan, A., Dias, D., Yu, P., </author> <title> "Analytical Modelling of a Hierarchical Buffer for a Data Sharing Environment", </title> <booktitle> Proc. ACM SIGMETRICS Conf. on Measurement and Modeling of Computer Systems, </booktitle> <address> San Diego, CA, </address> <month> May, </month> <year> 1991. </year>
Reference-contexts: All of the algorithms were broadcast-based, and the study did not consider concurrency control or data contention issues. 5.2. Transaction Processing Systems Issues related to some of the global memory management techniques discussed here are addressed in a data-sharing context in several papers from IBM Yorktown. In one paper <ref> [Dan91] </ref> an analytical model was used to study a two-level buffer hierarchy. <p> An added dimension is the use of non-volatile memory to avoid data and log disk writes. The paper also investigates other types of extended memory such as solid-state disks and disk caches. Many of the correlation issues found in our study (and in <ref> [Dan91] </ref>) also arise in this environment. In particular, the correlation caused by forcing dirty pages to the extended memory (similar to our copying of dirty pages back to the server), was shown to reduce the effectiveness of the extended memory.
Reference: [Dan92] <author> Dan, A., Yu, P., </author> <title> "Performance Analysis of Coherency Control Policies through Lock Retention", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> San Diego, CA, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: As will be discussed in Section 5.2, a similar issue (forcing dirty pages to disk) has been investigated for shared-disk environments <ref> [Moha91, Dan92] </ref>. As future work, we plan to further investigate policies for handling dirty pages in the client-server environment. 4.4. Experiment 3: PRIVATE Workload The third experiment that we report here uses the PRIVATE workload. <p> Therefore, the complex interaction of server-client correlation and server hit rates that arose here in the HOTCOLD workloads were not identified. A more recent paper <ref> [Dan92] </ref> studies callback-style shared-disk caching algorithms and investigates the performance gains that are available by avoiding disk writes for dirty pages when transferring a page between sites. Adding this optimization to a shared-disk system results in more complex recovery schemes, as described in [Moha91].
Reference: [Deux91] <editor> Deux, O., et al., </editor> <title> "The O2 System", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 34, No. 10, </volume> <month> Oct., </month> <year> 1991. </year>
Reference-contexts: Performance tradeoffs among several data-shipping approaches are examined in [DeWi90]. Many recent client-server database systems (e.g. ObServer [Horn87], ObjectStore [Lamb91], O2 <ref> [Deux91] </ref>, and client-server EXODUS [Exod91, Fran92b]) utilize a page server architecture. In these systems, clients interact with servers by sending requests for specific database pages or groups of pages. The server then provides the requested pages back to the client.
Reference: [DeWi90] <author> DeWitt, D., Futtersack, P., Maier, D., Velez, F., </author> <title> "A Study of Three Alternative Workstation-Server Architectures for Object-Oriented Database Systems," </title> <booktitle> Proc. 16th Int'l Conf. on Very Large Data Bases, </booktitle> <address> Brisbane, </address> <month> Aug., </month> <year> 1990. </year>
Reference-contexts: Data-shipping architectures can be further categorized into page servers, which transfer physical units (e.g., pages or segments) of data among clients and servers, and object servers, which interact using logical units of data such as objects or tuples. Performance tradeoffs among several data-shipping approaches are examined in <ref> [DeWi90] </ref>. Many recent client-server database systems (e.g. ObServer [Horn87], ObjectStore [Lamb91], O2 [Deux91], and client-server EXODUS [Exod91, Fran92b]) utilize a page server architecture. In these systems, clients interact with servers by sending requests for specific database pages or groups of pages.
Reference: [Exod91] <author> EXODUS Project Group, </author> <title> EXODUS Storage Manager Architectural Overview, EXODUS Project Document, </title> <institution> University of Wisconsin - Madison, </institution> <month> Nov., </month> <year> 1991. </year>
Reference-contexts: Performance tradeoffs among several data-shipping approaches are examined in [DeWi90]. Many recent client-server database systems (e.g. ObServer [Horn87], ObjectStore [Lamb91], O2 [Deux91], and client-server EXODUS <ref> [Exod91, Fran92b] </ref>) utilize a page server architecture. In these systems, clients interact with servers by sending requests for specific database pages or groups of pages. The server then provides the requested pages back to the client.
Reference: [Felt91] <author> Felten, E., Zahorjan, J., </author> <title> "Issues in the Implementation of a Remote Memory Paging System", </title> <type> Tech. </type> <institution> Rept. 91-03-09, University of Washington, </institution> <month> March, </month> <year> 1991. </year>
Reference-contexts: The idea of using the memory of idle workstations as a backing store for virtual memory was investigated in <ref> [Felt91] </ref>. This paper raised several policy issues and presented a simple queueing model study that indicated that the approach has potential for significant performance gains over swapping to disk, even with current networking and OS technology.
Reference: [Fran92a] <author> Franklin M., Carey, M., </author> <title> "Client-Server Caching Revisited", </title> <booktitle> Proc. of the International Workshop on Distributed Object Management, </booktitle> <address> Edmonton, Canada, </address> <month> Aug., </month> <year> 1992. </year>
Reference-contexts: We also focus on systems with a single server, both in our descriptions and our experiments. 1.1. Performance of Page Server Systems Recently, there have been several studies of the performance aspects of caching algorithms for page server systems <ref> [Wilk90, Care91, Wang91, Fran92a] </ref>. These studies have shown the advantages and potential pitfalls of attempting to offload servers by caching locks and/or data at client workstations across transaction boundaries. Such caching is referred to as inter-transaction caching. <p> The variant studied here allows caching of read locks but not write locks, as caching write locks was found to be somewhat detrimental to performance for the workloads used in this study <ref> [Fran92a] </ref>. The caching of a page at a client gives that client an implicit read lock on the page at the server. <p> MODELING A CLIENT-SERVER DBMS In order to study the performance of alternative global memory management techniques, we have extended the client-server DBMS simulation model that was used in our earlier studies <ref> [Care91, Fran92a] </ref>. In this section we describe how the model captures the database, workload, and physical resources of a client-server DBMS that supports the proposed global memory management techniques. 3.1. Database and Workload Models Table 1 presents the parameters used to model the database and its workload.
Reference: [Fran92b] <author> Franklin, M., Zwilling, M., Tan, C., Carey, M., DeWitt, D., </author> <title> "Crash Recovery in Client-Server EXODUS", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> San Diego, CA, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: Performance tradeoffs among several data-shipping approaches are examined in [DeWi90]. Many recent client-server database systems (e.g. ObServer [Horn87], ObjectStore [Lamb91], O2 [Deux91], and client-server EXODUS <ref> [Exod91, Fran92b] </ref>) utilize a page server architecture. In these systems, clients interact with servers by sending requests for specific database pages or groups of pages. The server then provides the requested pages back to the client. <p> The sending of dirty pages to the server at commit time helps to simplify the recovery system in a client-server DBMS <ref> [Fran92b] </ref>, but it could be avoided or reduced at the expense of increasing recovery complexity. As will be discussed in Section 5.2, a similar issue (forcing dirty pages to disk) has been investigated for shared-disk environments [Moha91, Dan92]. <p> However, there are significant differences between the client-server environment and the data-sharing environment (e.g, the use of the server for logging and recovery <ref> [Fran92b] </ref>, and the expense of messages in a client-server system). Thus, many of the tradeoffs that we have identified in a client-server context differ from those observed in data-sharing systems.
Reference: [Horn87] <author> M. Hornick and S. Zdonik, </author> <title> "A Shared, Segmented Memory System for an Object-Oriented Database," </title> <journal> ACM Trans. on Office Information Systems 5, </journal> <volume> 1, </volume> <month> Jan., </month> <year> 1987. </year>
Reference-contexts: Performance tradeoffs among several data-shipping approaches are examined in [DeWi90]. Many recent client-server database systems (e.g. ObServer <ref> [Horn87] </ref>, ObjectStore [Lamb91], O2 [Deux91], and client-server EXODUS [Exod91, Fran92b]) utilize a page server architecture. In these systems, clients interact with servers by sending requests for specific database pages or groups of pages. The server then provides the requested pages back to the client.
Reference: [Howa88] <author> Howard, J., et al, </author> <title> "Scale and Performance in a Distributed File System," </title> <journal> ACM Trans. on Computer Systems 6, </journal> <volume> 1, </volume> <month> Feb., </month> <year> 1988. </year>
Reference-contexts: The other four algorithms are extensions of the baseline algorithm, each of which uses the forwarding technique along with neither, one, or both of the other two global techniques. 2.3.1. Callback Locking (CBL) CBL is a lock and data caching algorithm based on callback locking <ref> [Howa88, Lamb91, Wang91] </ref>. In this algorithm, clients initially obtain locks and data by sending requests to the server. Once a page and its corresponding lock are obtained, they can be cached at the client across transaction boundaries.
Reference: [Jul88] <author> Jul, E., Levy, H., Hutchinson, N., Black, A., </author> <title> "Fine Grained Mobility in the Emerald System", </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> Vol. 6, No. 1, </volume> <month> February, </month> <year> 1988. </year>
Reference-contexts: Non-DBMS Approaches Issues related to global memory management have also been addressed in distributed object systems such as Emerald <ref> [Jul88] </ref>, where methods for allowing objects to migrate among sites were addressed. Migration in this case was intended to improve performance by bringing objects to the sites where they were being accessed, and also to simplify the programming of distributed applications, rather than to avoid disk I/O.
Reference: [Lamb91] <author> Lamb, C., Landis, G., Orenstein, J. Weinreb, D., </author> <title> "The ObjectStore Database System", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 34, No. 10, </volume> <month> Oct., </month> <year> 1991. </year>
Reference-contexts: Performance tradeoffs among several data-shipping approaches are examined in [DeWi90]. Many recent client-server database systems (e.g. ObServer [Horn87], ObjectStore <ref> [Lamb91] </ref>, O2 [Deux91], and client-server EXODUS [Exod91, Fran92b]) utilize a page server architecture. In these systems, clients interact with servers by sending requests for specific database pages or groups of pages. The server then provides the requested pages back to the client. <p> The other four algorithms are extensions of the baseline algorithm, each of which uses the forwarding technique along with neither, one, or both of the other two global techniques. 2.3.1. Callback Locking (CBL) CBL is a lock and data caching algorithm based on callback locking <ref> [Howa88, Lamb91, Wang91] </ref>. In this algorithm, clients initially obtain locks and data by sending requests to the server. Once a page and its corresponding lock are obtained, they can be cached at the client across transaction boundaries. <p> If the page is currently in use, however, the client queues the callback request and then immediately informs the server that the page is in use. This immediate notification allows the server to perform deadlock detection using accurate information <ref> [Lamb91] </ref>. The server grants the write lock request only after all conflicting locks have been released. The fact that the caching of a page at a client grants the client an implicit read lock requires that the server be informed when a page is replaced from a client's buffer pool.
Reference: [LaRo90] <author> LaRowe, P., Ellis, C., </author> <title> "Experimental Comparison of Memory Management Policies for NUMA Multiprocessors", </title> <type> Tech. Rep. </type> <institution> CS-1990-10, Duke University, </institution> <month> April, </month> <year> 1990. </year>
Reference-contexts: Finally, work in Non-Uniform Memory Access architectures, in which the memories of nodes in a multiprocessor system are viewed as a single - 31 - memory hierarchy, is relevant as well. This work includes <ref> [LaRo90] </ref>, which studied the performance of a wide range of proposed memory management policies and [LaRo91], which investigated dynamic policies that can be adapted to particular page reference behaviors. 6. CONCLUSIONS AND FUTURE WORK In this paper, we have studied performance tradeoffs for global memory management in page-server database systems.
Reference: [LaRo91] <author> LaRowe, P., Ellis, C., Kaplan, </author> <title> L, "The Robustness of NUMA Memory Management", </title> <booktitle> Proc. 13th ACM Symp. on Operating Systems Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> Oct., </month> <year> 1991. </year>
Reference-contexts: Finally, work in Non-Uniform Memory Access architectures, in which the memories of nodes in a multiprocessor system are viewed as a single - 31 - memory hierarchy, is relevant as well. This work includes [LaRo90], which studied the performance of a wide range of proposed memory management policies and <ref> [LaRo91] </ref>, which investigated dynamic policies that can be adapted to particular page reference behaviors. 6. CONCLUSIONS AND FUTURE WORK In this paper, we have studied performance tradeoffs for global memory management in page-server database systems. Three different memory management techniques were presented.
Reference: [Leff91] <author> Leff, A., Yu, P., Wolf, J., </author> <title> "Policies for Efficient Memory Utilization in a Remote Caching Architecture", </title> <booktitle> Proc. 1st Int'l Conf. on Parallel and Distributed Information Systems, </booktitle> <address> Miami Beach, FL, </address> <month> Dec., </month> <year> 1991. </year>
Reference-contexts: RELATED WORK In this section we briefly discuss work related to global memory management in client-server DBMSs, data sharing DBMSs, and other distributed systems. 5.1. Workstation-Server Database Systems Several recent papers have investigated issues of global memory management for DBMSs in a workstation-server environment. In <ref> [Leff91] </ref>, the problem of replica management for efficient use of the global memory resources of a distributed system was addressed.
Reference: [Moha91] <author> Mohan, C., Narang, I., </author> <title> "Recovery and Coherency-Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment", </title> <booktitle> Proc. 17th Int'l Conf. on Very Large Data Bases, </booktitle> <address> Barcelona, </address> <month> Sept., </month> <year> 1991. </year> <month> - 33 </month> - 
Reference-contexts: As will be discussed in Section 5.2, a similar issue (forcing dirty pages to disk) has been investigated for shared-disk environments <ref> [Moha91, Dan92] </ref>. As future work, we plan to further investigate policies for handling dirty pages in the client-server environment. 4.4. Experiment 3: PRIVATE Workload The third experiment that we report here uses the PRIVATE workload. <p> A more recent paper [Dan92] studies callback-style shared-disk caching algorithms and investigates the performance gains that are available by avoiding disk writes for dirty pages when transferring a page between sites. Adding this optimization to a shared-disk system results in more complex recovery schemes, as described in <ref> [Moha91] </ref>. An algorithm which avoids replicating copies at multiple sites was studied and was found to have tradeoffs similar to some of those seen for our forwarding techniques.
Reference: [Pu91] <author> Pu, C., Florissi, D., Soares, P., Yu, P., Wu, K., </author> <title> "Performance Comparison of Sender-Active and Receiver-Active Mutual Data Serving", </title> <type> Tech. </type> <institution> Rept. CUCS-014-090, Columbia University, </institution> <year> 1991. </year>
Reference-contexts: Algorithms for using the memory of underutilized workstations (called mutual-servers) to keep more of the database in memory were proposed and studied in <ref> [Pu91] </ref>. The algorithms included variations in which the sender and/or the receiver played active roles in initiating the caching of a page at a mutual-server. All of the algorithms were broadcast-based, and the study did not consider concurrency control or data contention issues. 5.2.
Reference: [Rahm92] <author> Rahm, E., </author> <title> "Performance Evaluation of Extended Storage Architectures for Transaction Processing", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> San Diego, CA, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: Thus, many of the tradeoffs that we have identified in a client-server context differ from those observed in data-sharing systems. Another recent paper <ref> [Rahm92] </ref> studies the use of several types of extended memory to improve the performance of transaction processing systems. Extended memory adds a new memory hierarchy level between main memory and disk. An added dimension is the use of non-volatile memory to avoid data and log disk writes.
Reference: [Sarg76] <author> Sargent, R., </author> <title> "Statistical Analysis of Simulation Output Data," </title> <booktitle> Proc. 4th Annual Symp. on the Simulation of Computer Systems,1976. </booktitle>
Reference-contexts: To ensure the statisti cal validity of our results, we verified that the 90% confidence intervals for transaction response times (computed using batch means <ref> [Sarg76] </ref>) were sufficiently tight. The size of these confidence intervals was within a few percent of the mean in all cases, which is more than sufficient for our purposes. Throughout the paper we discuss only performance differences that were found to be statistically significant.
Reference: [Wang91] <author> Wang, Y., Rowe, L., </author> <title> "Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Denver, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: We also focus on systems with a single server, both in our descriptions and our experiments. 1.1. Performance of Page Server Systems Recently, there have been several studies of the performance aspects of caching algorithms for page server systems <ref> [Wilk90, Care91, Wang91, Fran92a] </ref>. These studies have shown the advantages and potential pitfalls of attempting to offload servers by caching locks and/or data at client workstations across transaction boundaries. Such caching is referred to as inter-transaction caching. <p> The other four algorithms are extensions of the baseline algorithm, each of which uses the forwarding technique along with neither, one, or both of the other two global techniques. 2.3.1. Callback Locking (CBL) CBL is a lock and data caching algorithm based on callback locking <ref> [Howa88, Lamb91, Wang91] </ref>. In this algorithm, clients initially obtain locks and data by sending requests to the server. Once a page and its corresponding lock are obtained, they can be cached at the client across transaction boundaries.
Reference: [Wilk90] <author> Wilkinson, W., and Neimat, M.-A., </author> <title> "Maintaining Consistency of Client Cached Data," </title> <booktitle> Proc. 16th Int'l Conf. on Very Large Data Bases, </booktitle> <address> Brisbane, </address> <month> Aug., </month> <year> 1990. </year> <month> - 34 </month> - 
Reference-contexts: We also focus on systems with a single server, both in our descriptions and our experiments. 1.1. Performance of Page Server Systems Recently, there have been several studies of the performance aspects of caching algorithms for page server systems <ref> [Wilk90, Care91, Wang91, Fran92a] </ref>. These studies have shown the advantages and potential pitfalls of attempting to offload servers by caching locks and/or data at client workstations across transaction boundaries. Such caching is referred to as inter-transaction caching.
References-found: 23

