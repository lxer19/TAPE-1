URL: http://www.research.att.com/~lewis/papers/lewis95b.ps
Refering-URL: http://www.research.att.com/~lewis/chronobib.html
Root-URL: 
Email: lewis@research.att.com  
Title: Evaluating and Optimizing Autonomous Text Classification Systems  
Author: David D. Lewis 
Date: corrected.)  
Note: (Appeared (w/ same pagination) in SIGIR 95: Proceedings of the Eighteenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, July, 1995, pp. 246-254. One typo on p. 249 has been  
Address: Murray Hill, NJ 07974; USA  
Affiliation: AT&T Bell Laboratories  
Abstract: Text retrieval systems typically produce a ranking of documents and let a user decide how far down that ranking to go. In contrast, programs that filter text streams, software that categorizes documents, agents which alert users, and many other IR systems must make decisions without human input or supervision. It is important to define what constitutes good effectiveness for these autonomous systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed. We show how to do this for binary text classification systems, emphasizing that different goals for the system lead to different optimal behaviors. Optimizing and estimating effectiveness is greatly aided if classifiers that explicitly estimate the probability of class membership are used. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> D. K. Harman, editor. </editor> <booktitle> The Second Text REtrieval Conference (TREC-2), </booktitle> <address> Gaithersburg, MD 20899, </address> <year> 1994. </year> <institution> National Institute of Standards and Technology. </institution> <note> Special Publication 500-215. </note>
Reference: [2] <author> William S. Cooper. </author> <title> On selecting a measure of retrieval effectiveness. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 24 </volume> <pages> 87-100, </pages> <month> March-April </month> <year> 1973. </year>
Reference: [3] <author> Alexander M. Mood, Franklin A. Graybill, and Duane C. Boes. </author> <title> Introduction to the Theory of Statistics. </title> <publisher> Mcgraw-Hill, </publisher> <address> New York, </address> <note> 3rd edition, </note> <year> 1974. </year>
Reference: [4] <author> Tefko Saracevic. </author> <title> Relevance: A review of and a framework for the thinking on the notion in information science. </title> <journal> Journal of the American Society for Information Science, </journal> <pages> pages 321-343, </pages> <month> November-December </month> <year> 1975. </year>
Reference: [5] <author> C. J. van Rijsbergen. </author> <title> Information Retrieval. </title> <publisher> Butterworths, </publisher> <address> London, </address> <note> second edition, </note> <year> 1979. </year>
Reference: [6] <author> S. E. Robertson. </author> <title> The probability ranking principle in IR. </title> <journal> Journal of Documentation, </journal> <volume> 33(4) </volume> <pages> 294-304, </pages> <month> December </month> <year> 1977. </year>
Reference: [7] <author> Richard O. Duda and Peter E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1973. </year>
Reference: [8] <author> William S. Cooper. </author> <title> On selecting a measure of retrieval effectiveness. Part II. Implementation of a philosophy. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 24 </volume> <pages> 413-424, </pages> <month> November-December </month> <year> 1973. </year>
Reference: [9] <author> Davis B. McCarn. </author> <title> Online systemstechniques and services. </title> <editor> In Martha E. Williams, editor, </editor> <booktitle> Annual Review of Information Science and Technology, </booktitle> <volume> Vol. 13, </volume> <pages> pages 85-124. </pages> <publisher> Knowledge Industry Publications, Inc., </publisher> <year> 1978. </year>
Reference-contexts: First, we need more research into which effectiveness measures best capture what users want autonomous classifiers to do. In a rare study of this sort, McCarn <ref> [9, 10] </ref>, analyzing data of Pollitt [17] on searches of bibliographic databases, found that a loss-based effectiveness measure was highly predictive of the amount of money a user stated they would be willing to pay for the search result.
Reference: [10] <author> Davis B. McCarn and Craig M. Lewis. </author> <title> A mathematical model of retrieval system performance. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(7) </volume> <pages> 495-500, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: First, we need more research into which effectiveness measures best capture what users want autonomous classifiers to do. In a rare study of this sort, McCarn <ref> [9, 10] </ref>, analyzing data of Pollitt [17] on searches of bibliographic databases, found that a loss-based effectiveness measure was highly predictive of the amount of money a user stated they would be willing to pay for the search result.
Reference: [11] <author> Bernard W. Lindgren. </author> <title> Statistical Theory. </title> <publisher> Chapman & Hall, </publisher> <address> New York, 4th edition, </address> <year> 1993. </year>
Reference: [12] <author> T. Thomas, C. Kruger, C. Scovel, and J. Shumate. </author> <title> Text to information: Sampling uncertainty in an example from physician/patient encounters. </title> <booktitle> In Symposium on Document Analysis and Information Retrieval, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference: [13] <author> Norbert Fuhr and Hubert Huther. </author> <title> Optimum probability estimation from empirical distributions. </title> <booktitle> Information Processing and Management, </booktitle> <pages> pages 493-507, </pages> <year> 1989. </year>
Reference: [14] <author> Norbert Fuhr and Ulrich Pfeifer. </author> <title> Probabilistic information retrieval as a combination of abstraction, inductive learning, and probabilistic assumptions. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 12(1) </volume> <pages> 92-115, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Our approach relies on classifiers that produce accurate estimates of the probability of class membership. While there has been recent progress in producing probabilistic text classifiers <ref> [14, 15, 16] </ref>, more work is needed. We also need a better understanding of the bias and variance of the estimates produced by these classifiers, and of how these impact, for instance, confidence intervals on effectiveness measures.
Reference: [15] <author> David D. Lewis and William A. Gale. </author> <title> A sequential algorithm for training text classifiers. </title> <editor> In W. Bruce Croft and C. J. van Rijs-bergen, editors, </editor> <booktitle> SIGIR 94: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 3-12, </pages> <address> London, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Our approach relies on classifiers that produce accurate estimates of the probability of class membership. While there has been recent progress in producing probabilistic text classifiers <ref> [14, 15, 16] </ref>, more work is needed. We also need a better understanding of the bias and variance of the estimates produced by these classifiers, and of how these impact, for instance, confidence intervals on effectiveness measures. <p> This does not seem an undue burden when setting up a system that will act autonomously over a long period of time. The amount of judged training data necessary to produce probabilistic classifiers can be reduced by active learning <ref> [15] </ref>, though this complicates estimating the bias and variance of the resulting probability estimates. 9 Future Work Our approach to estimating and optimizing the effectiveness of autonomous text classification systems raises new questions. <p> For instance, Lewis and Gale <ref> [15] </ref> categorized documents so as to minimize E [L 0;1;1;0 ] (expected error rate), but then evaluated those categorizations using F 1 . 251 Do users want effectiveness to be optimized on a daily, weekly, or some other basis, and how do we determine this? Earlier we presented possible approaches to
Reference: [16] <author> Wm. S. Cooper, Aitao Chen, and Frederic C. Gey. </author> <title> Full text retrieval based on probabilistic equations with coefficients fitted by logistic regression. </title> <editor> In D. K. Harman, editor, </editor> <booktitle> The Second Text Retrieval Conference (TREC-2), </booktitle> <pages> pages 57-65, </pages> <address> Gaithers-burg, MD, </address> <year> 1994. </year> <institution> National Institute of Standards and Technology. </institution> <note> NIST Special Publication 500-215. </note>
Reference-contexts: Our approach relies on classifiers that produce accurate estimates of the probability of class membership. While there has been recent progress in producing probabilistic text classifiers <ref> [14, 15, 16] </ref>, more work is needed. We also need a better understanding of the bias and variance of the estimates produced by these classifiers, and of how these impact, for instance, confidence intervals on effectiveness measures.
Reference: [17] <author> Arthur S. Pollitt. </author> <title> CANCERLINE evaluation project: </title> <type> Final report. Technical report, </type> <institution> Medical Library, School of Medicine, The University of Leeds, Leeds, </institution> <address> England, </address> <year> 1977. </year>
Reference-contexts: First, we need more research into which effectiveness measures best capture what users want autonomous classifiers to do. In a rare study of this sort, McCarn [9, 10], analyzing data of Pollitt <ref> [17] </ref> on searches of bibliographic databases, found that a loss-based effectiveness measure was highly predictive of the amount of money a user stated they would be willing to pay for the search result. This is encouraging, since loss-based measures are easy to estimate and optimize.
Reference: [18] <author> Richard von Mises. </author> <title> Mathematical Theory of Probability and Statistics. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1964. </year> <month> 252 </month>
References-found: 18

