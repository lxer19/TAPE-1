URL: file://ftp.cis.ohio-state.edu/pub/communication/papers/spdp93-clustered.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/cluster_pub.html
Root-URL: 
Email: Email: fbasak,pandag@cis.ohio-state.edu  
Title: Scalable Architectures with k-ary n-cube cluster-c Organization  
Author: Debashis Basak and Dhabaleswar K. Panda 
Address: Columbus, OH 43210-1277  
Affiliation: Department of Computer and Information Science The Ohio State University,  
Note: In Proc. of the Symposium of Parallel and Distributed Processing, 1993, pp. 780-787  
Abstract: Recent advancements in VLSI and packaging technologies demonstrate attractiveness in building scalable parallel systems using clustered configurations while exploiting communication locality. Clustered architectures using buses or MINs as the inter-cluster interconnection do not satisfy both the above objectives. This paper proposes a new class of k-ary n-cube cluster-c scalable architectures by combining the scalability of k-ary n-cube wormhole-routed networks with the cost-effectiveness of processor cluster designs. This paper focuses on direct cluster interconnection. The interplay between various system parameters and routing schemes are analyzed to determine optimal configurations under the constant bisection bandwidth constraint. Our analysis indicates that small sized clusters with a ring intra-cluster topology and a 2D/3D/4D inter-cluster network connecting these clusters offer best system performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agrawal. </author> <title> Limits on Interconnection Network Performance. </title> <journal> IEEE TPDS, </journal> <volume> 2(4), </volume> <month> Oct </month> <year> 1991. </year>
Reference-contexts: These properties depend on various parameters like cluster size, the intranet and the internet topologies, and the routing schemes used. Our objective is to select the configuration that offers best system performance. For a given hierarchical configuration, we use the constant bisection bandwidth constraint <ref> [1, 8] </ref> to determine channel widths in each network. The number of wires that need to cross the bisection of a network is called bisection width. <p> This limit directly affects the channel width and indirectly determines the number of flits required for a given message. Consider a k-ary n-cube with bidirectional channels each of width W bits. It has a bisection width of 4W k n1 <ref> [1] </ref>. With N being total number of nodes, this width is equal to 4W N=k. For a linear array of processors, this width is 2W . For comparison across different topologies, we normalize bisection widths to that of a 2-ary n-cube (hypercube) with unit-width bidirectional channels. <p> We used the NAB routing strategy with dimension-order routing. Simulations were done for both uniform and localized traffic. We used the locality model developed by Agarwal in <ref> [1] </ref> in which a processor generates messages with equal probability to some nearest subset of processors. We compared the performance for various cluster sizes and topologies. 5.1 Effect of cluster size Simulation results verified our earlier observation 3 that throughput falls with growth in cluster size.
Reference: [2] <author> A. Asthana, H. Jagdish, and B. Mathews. </author> <title> Impact of Advanced VLSI packaging on the design of a large parallel computer. </title> <booktitle> In ICPP, </booktitle> <month> Aug </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Traditionally, research in interconnection networks have assumed one processing element per node. However advancements in VLSI and packaging technologies are making it cost-effective to integrate multiple processing elements into a chip, multiple chips into a board, and multiple boards into a system <ref> [2] </ref>. Any of these building blocks can represent a processor cluster. Such clusters can be interconnected together to build large-scale systems. A variety of hierarchical configurations have been proposed by researchers in the last decade to build scalable systems, using either single processor or processor cluster per node.
Reference: [3] <author> D. Basak and D. K. Panda. </author> <title> Designing Scalable Systems with two-level k-ary n-cube Wormhole-routed Interconnections. </title> <institution> TR29-1993, Dept. of Computer and Information Science, The Ohio State University, </institution> <month> Aug </month> <year> 1993. </year>
Reference-contexts: For the NAB strategy proving deadlock freedom for these algorithms is not trivial as worms can simultaneously occupy channels in more than one network. Hierarchical routing schemes with deadlock-freedom are developed in <ref> [3] </ref>. Table 1: Summary of Symbols Used for k-ary n-cube k1-ary k1-cube or (k; n; k1; n1) Clustered System.
Reference: [4] <author> D. Basak and D. K. Panda. </author> <title> Scalable Architectures with k-ary n-cube cluster-c organization. </title> <institution> TR28-1993, Dept. of Computer and Information Science, The Ohio State University, </institution> <month> Aug </month> <year> 1993. </year>
Reference-contexts: These constraints refer to the maximum possible message injection rate (m) by each processor such that the respective channel capacities and bandwidths are not exceeded. In <ref> [4] </ref>, we have derived these constraints leading to the following inequality: m inter sat m out sat m intra sat (1) The constraints m inter sat is most strict and its value is dependent only on the size of the cluster and quite independent of the cluster topology. <p> This leads to: Observation 2 Keeping the internet topology, internet size, and cluster size fixed, a ring cluster offers the least average latency. The expression m inter sat = 4 CL (1p) <ref> [4] </ref> leads us to: Observation 3 The maximum system throughput falls as cluster size and message length grow. From the above observation one would tend to conclude that clustering is not that a good idea. <p> The concerned pair of processors might belong to the same cluster or to different clusters. We will derive an expression for T for a (k; n; k1; n1) system as follows <ref> [4] </ref>: T = (T inter + 2T intra ) (1 p) + (T intra ) p = (T inter ) (1 p) + (T intra ) (2 p) = T c ((D + L=W )(1 p) + (D1 + L=W 1)(2 p)) (2) where, T inter and T intra are contention-free
Reference: [5] <author> D. Carlson. </author> <title> The Mesh with a Global Mesh: a Flexible, High-speed Organization for Parallel Computation. </title> <booktitle> In Proc. of the 1 st Int. Conf. on Supercomputer Systems. </booktitle> <year> 1985. </year>
Reference-contexts: A variety of hierarchical configurations have been proposed by researchers in the last decade to build scalable systems, using either single processor or processor cluster per node. Some examples include cluster of processors with buses and MINs [7], local and global meshes <ref> [5] </ref>, two-level systems based on hypercube and other network topologies [9, 15], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [12]. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications.
Reference: [6] <author> A. A. Chien and J. H. Kim. </author> <title> Planar Adaptive Routing: Low cost adaptive networks for multiprocessors. </title> <booktitle> In Proc. 19 th Ann.Int.Symp.on Comp.Arch, </booktitle> <pages> pages 268-277, </pages> <year> 1992. </year>
Reference-contexts: Both AB and NAB are general strategies in the sense that they do not specify the actual routing algorithm to be used in each network e.g. dimension-order, fully-adaptive [10], or planar <ref> [6] </ref> etc. For the NAB strategy proving deadlock freedom for these algorithms is not trivial as worms can simultaneously occupy channels in more than one network. Hierarchical routing schemes with deadlock-freedom are developed in [3].
Reference: [7] <author> D. J. Kuck et al. </author> <title> The Cedar System and an Initial Performance Study. </title> <booktitle> In Proc. of the Int'l Symposium on Comp. Arch., </booktitle> <pages> pp. 213-223, </pages> <year> 1993. </year>
Reference-contexts: Such clusters can be interconnected together to build large-scale systems. A variety of hierarchical configurations have been proposed by researchers in the last decade to build scalable systems, using either single processor or processor cluster per node. Some examples include cluster of processors with buses and MINs <ref> [7] </ref>, local and global meshes [5], two-level systems based on hypercube and other network topologies [9, 15], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [12].
Reference: [8] <author> W. J. Dally. </author> <title> Performance Analysis of k-ary n-cube Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: The analysis in [12] worked with fixed cluster sizes and did not consider the optimality of the network configuration, in terms of inter-cluster and intra-cluster network sizes and topologies. Research by Dally <ref> [8] </ref> has demonstrated the attractiveness of low dimensional k-ary n-cube topology with wormhole routing to build scalable systems with low average message latency under physical wiring constraint. <p> These properties depend on various parameters like cluster size, the intranet and the internet topologies, and the routing schemes used. Our objective is to select the configuration that offers best system performance. For a given hierarchical configuration, we use the constant bisection bandwidth constraint <ref> [1, 8] </ref> to determine channel widths in each network. The number of wires that need to cross the bisection of a network is called bisection width. <p> The number of wires that need to cross the bisection of a network is called bisection width. In general, this width cannot be increased arbitrarily and is limited by factors like available layout area <ref> [8] </ref>, allowable system size, cost, and power considerations. With a given set of factors, the bisection width can be held constant at some limit. This limit directly affects the channel width and indirectly determines the number of flits required for a given message. <p> We define this problem as flit mismatch problem, since it arises because of mismatch in flit sizes in the two networks. We suggest the use of virtual channels <ref> [8] </ref> with demand multiplexing, along with the concatenation scheme, to alleviate this flit mismatch problem. The NAB scheme now works like this. Due to concatenation, on any physical link on the worm's path in the internet, flits can only appear at periodic intervals of W=W 1 cycles.
Reference: [9] <author> S. Dandamudi and D. Eager. </author> <title> Hierarchical Interconnection Networks for Multicomputer Systems. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-39(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: Some examples include cluster of processors with buses and MINs [7], local and global meshes [5], two-level systems based on hypercube and other network topologies <ref> [9, 15] </ref>, and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [12]. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications.
Reference: [10] <author> J. Duato. </author> <title> On the design of deadlock-free adaptive routing algorithms for multicomputers: </title> <booktitle> Theoretical aspects. In PARLE 91, </booktitle> <pages> pp. 234-243, </pages> <year> 1991. </year>
Reference-contexts: Both AB and NAB are general strategies in the sense that they do not specify the actual routing algorithm to be used in each network e.g. dimension-order, fully-adaptive <ref> [10] </ref>, or planar [6] etc. For the NAB strategy proving deadlock freedom for these algorithms is not trivial as worms can simultaneously occupy channels in more than one network. Hierarchical routing schemes with deadlock-freedom are developed in [3].
Reference: [11] <author> D. Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <year> 1990. </year>
Reference-contexts: Each cluster consists of c processors and the possible intra-cluster interconnection can be direct network or indirect network. Such architectures are becoming the trend for building scalable parallel systems. Example systems are Intel Paragon [13], Stanford DASH <ref> [11] </ref>, and the KSR system [14]. Though machines of this type are being built in the industry and academia, there is still lack of understanding and analysis as to how to build the optimal system under different technological and packaging constraints. <p> For example, Intel's proposed Paragon [13] system is a k-ary 2-cube bus-5 organization with a mesh connecting the clusters and each cluster having 4 application and 1 communication processor connected through a bus. A 64-processor DASH prototype, developed by Hennessy at Stanford <ref> [11] </ref>, is a 4-ary 2-cube bus-5 system. The KSR machine is 32-ary 1-cube 32-ary 1-cube system with a 2-level hierarchy of rings of processors.
Reference: [12] <author> W. Hsu and P. C. Yew. </author> <title> The Performance of Hierarchical Systems with wiring constraints. </title> <booktitle> In Proc. of the ICPP, </booktitle> <month> Aug </month> <year> 1991. </year>
Reference-contexts: Some examples include cluster of processors with buses and MINs [7], local and global meshes [5], two-level systems based on hypercube and other network topologies [9, 15], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks <ref> [12] </ref>. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications. <p> MINs as the inter-cluster interconnection do not satisfy both the above objectives. In the architectures supporting scalable inter-cluster interconnections, the focus has been restricted to 2D meshes or hypercubes as the inter-cluster topology with packet switched or circuit switched routing. The analysis in <ref> [12] </ref> worked with fixed cluster sizes and did not consider the optimality of the network configuration, in terms of inter-cluster and intra-cluster network sizes and topologies.
Reference: [13] <author> Intel Corporation. </author> <title> Paragon XP/S Product Overview, </title> <year> 1991. </year>
Reference-contexts: Each cluster consists of c processors and the possible intra-cluster interconnection can be direct network or indirect network. Such architectures are becoming the trend for building scalable parallel systems. Example systems are Intel Paragon <ref> [13] </ref>, Stanford DASH [11], and the KSR system [14]. Though machines of this type are being built in the industry and academia, there is still lack of understanding and analysis as to how to build the optimal system under different technological and packaging constraints. <p> In such systems we can associate any of the cluster processors to handle specialized communication tasks. 2.3 On-going trend The k-ary n-cube cluster-c architectures with different cluster configurations appear to be the future trend for building scalable parallel systems. For example, Intel's proposed Paragon <ref> [13] </ref> system is a k-ary 2-cube bus-5 organization with a mesh connecting the clusters and each cluster having 4 application and 1 communication processor connected through a bus. A 64-processor DASH prototype, developed by Hennessy at Stanford [11], is a 4-ary 2-cube bus-5 system.
Reference: [14] <institution> Kendall Square Research. </institution> <type> KSR Technical Summary, </type> <year> 1992. </year>
Reference-contexts: Each cluster consists of c processors and the possible intra-cluster interconnection can be direct network or indirect network. Such architectures are becoming the trend for building scalable parallel systems. Example systems are Intel Paragon [13], Stanford DASH [11], and the KSR system <ref> [14] </ref>. Though machines of this type are being built in the industry and academia, there is still lack of understanding and analysis as to how to build the optimal system under different technological and packaging constraints.
Reference: [15] <author> K. Padmanabhan. </author> <title> Effective Architectures for Data Access in a Shared Memory Hierarchy. </title> <booktitle> Jour. of Parallel and Distr. Computing, </booktitle> <volume> 11, </volume> <year> 1991. </year>
Reference-contexts: Some examples include cluster of processors with buses and MINs [7], local and global meshes [5], two-level systems based on hypercube and other network topologies <ref> [9, 15] </ref>, and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [12]. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications.
References-found: 15

