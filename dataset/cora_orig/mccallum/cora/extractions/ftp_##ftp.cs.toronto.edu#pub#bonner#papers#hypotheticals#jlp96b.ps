URL: ftp://ftp.cs.toronto.edu/pub/bonner/papers/hypotheticals/jlp96b.ps
Refering-URL: http://www.cs.toronto.edu/~bonner/papers.html
Root-URL: http://www.cs.toronto.edu
Email: Email: bonner@db.toronto.edu  
Title: INTUITIONISTIC DEDUCTIVE DATABASES AND THE POLYNOMIAL TIME HIERARCHY  
Author: ANTHONY J. BONNER 
Address: Ontario, Canada M5S 3G4.  655 Avenue of the Americas, New York, NY 10010  
Affiliation: University of Toronto, Department of Computer Science, Toronto,  
Date: 1997, 33(1):1-47 1  
Note: J. LOGIC PROGRAMMING  Address correspondence to  THE JOURNAL OF LOGIC PROGRAMMING c Elsevier Science Inc., 1997  
Abstract: Deductive databases are poor at tasks such as planning and design, where one must explore the consequences of hypothetical actions and possibilities. To address this limitation, we have developed a deductive database language in which a user can create hypotheses and draw inferences from them. In earlier work, we established initial results on the complexity and expressibility of this language. In this paper, we establish more comprehensive results by exploring the interaction of negation-as-failure with a natural syntactic restriction called linearity. The main result is a tight connection between intuitionistic logic, database queries, and the polynomial time hierarchy. A tight connection with second-order logic follows as a corollary. First, we show that rulebases in our language fit neatly into a well-established logical framework|intuitionistic logic. Second, we show that linearity reduces their data complexity from PSPACE to NP. Third, we show that negation-as-failure increases their complexity from NP to some level in the polynomial time hierarchy (PHIER). Specifically, linear rulebases with k strata are data complete for P k , the k th level in the hierarchy. Fourth, we show that linear rulebases express exactly the generic database queries in PHIER. Finally, we characterize the generic queries in P k in terms of rulebases with k strata. Unlike many other expressibility results in the literature, these results do not depend on the artificial assumption that the data domain is linearly ordered. We thus establish a strong link between two well-established, but previously unrelated areas: intuitionistic logic and the polynomial time hierarchy. /
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Abiteboul, M.Y. Vardi, and V. Vianu. </author> <title> Fixpoint Logics, Relational Machines, and Computational Complexity. </title> <booktitle> In Proceedings of the Seventh Annual Structure in Complexity Theory Conference, </booktitle> <pages> pages 156-168, </pages> <address> Boston, MA, June 22-25 1992. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Unlike many expressibility results in the literature (e:g:, [27, 51, 12]), these results do not assume that the data domain is linearly ordered. The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases <ref> [1] </ref>. Intuitionistic rulebases do not need this assumption, since they can generate linear orders on a domain hypothetically [6]. 5 Finally, we recall that the generic queries in PHIER are precisely the queries definable in second-order logic [47, 28]. <p> The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases <ref> [1] </ref>. Embedded implications do not need this artificial assumption, since they can generate linear orders on the domain hypothetically [6]. Thus, the results of this section are for arbitrary databases, ordered or not. Before continuing, we comment briefly on the difference between complexity and expressibility.
Reference: 2. <author> K.R. Apt, H.A. Blair, and A. Walker. </author> <title> Towards a Theory of Declarative Knowledge. </title> <editor> In Jack Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, chapter 2, </booktitle> <pages> pages 89-148. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: The upper bound is more difficult and is proved by showing that for any linear rulebase, all proof trees are of polynomial size. Third, we augment intuitionistic rulebases with negation-as-failure. Following [5], we extend the notion of stratification <ref> [2, 12] </ref> from Horn rules to intuitionistic rules. We then show that the data complexity of a linear rulebase depends crucially on the number of strata it has. <p> Thus, A is inferred if B C cannot be inferred. Unfortunately, as in Horn logic programming, the semantics of negation-as-failure is problematic when recursion occurs through negation. To avoid these problems, we focus on a class of stratified rulebases <ref> [2, 12] </ref>. We first extend the idea of stratification from Horn rulebases to hypothetical rulebases, and then develop the proof theory. The material in this section is adapted from [5], where we develop the model theory and proof theory for hypothetical deletion as well as insertion.
Reference: 3. <author> K.R. Apt and M.H. Van Emden. </author> <title> Contributions to the Theory of Logic Programming. </title> <journal> Journal of the ACM, </journal> <volume> 29(3) </volume> <pages> 841-862, </pages> <year> 1982. </year>
Reference-contexts: PROVE P i is a bottom-up iterative procedure based on the bottom-up procedure for computing the least fixpoint of a Horn rulebase <ref> [50, 3] </ref>. The idea is to add inferred atoms to a set, S, until saturation is reached. Starting with S = DB , the procedure repeatedly applies ground instantiations of the rules in the i th stratum.
Reference: 4. <author> F. Bancilhon and R. Ramakrishnan. </author> <title> An Amateur's Introduction to Recursive Query Processing Strategies. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 16-52, </pages> <address> Washington, D.C., </address> <month> May 28-30 </month> <year> 1986. </year>
Reference-contexts: Unlike other proofs in the literature [20, 36, 39], ours is based on the Henkin constructions of modal logic [14, 26]. Next, we develop the notion of linear intuitionistic rulebases, generalizing the notion of linear Horn rulebases <ref> [4] </ref>. Intuitively, a rule is linear if recursion occurs through only one premise. In classical Horn logic, "linear rules play an important role because, (i) there is a belief that most `real life' recursive rules are linear, and (ii) algorithms have been developed to handle them efficiently" [4]. <p> linear Horn rulebases <ref> [4] </ref>. Intuitively, a rule is linear if recursion occurs through only one premise. In classical Horn logic, "linear rules play an important role because, (i) there is a belief that most `real life' recursive rules are linear, and (ii) algorithms have been developed to handle them efficiently" [4]. We show that linearity reduces the data complexity of intuitionistic rulebases from PSPACE to NP. The lower bound is proved by encoding the computations of an arbitrary NP-machine as a linear rulebase. <p> Informally, a rule is linear if recursion occurs through only one premise. In classical Horn logic, "linear rules play an important role because, (i) there is a belief that most `real life' recursive rules are linear, and (ii) algorithms have been developed to handle them efficiently" <ref> [4] </ref>. We first extend the notion of linearity from Horn clauses to embedded implications. We then show that linearity reduces their data complexity from PSPACE to NP. To prove the lower complexity bound, we use linear embedded implications to encode the computations of arbitrary NP-machines. <p> Besides establishing NP-completeness, the proofs in this section also form a model for the more complex proofs in Section 6, which involve negation-as-failure, oracle Turing machines, and the polynomial time hierarchy. The first step is to define linearity precisely. We generalize the definition given in <ref> [4] </ref> for Horn rules. Central to this definition is the concept of mutually recursive predicates. Definition 4.1.
Reference: 5. <author> A.J. Bonner. </author> <title> A logical semantics for hypothetical rulebases with deletion. </title> <note> To appear in the Journal of Logic Programming (JLP). </note>
Reference-contexts: And McCarty, also motivated by legal applications, has developed a wide class of hypothetical rules for computer-based consultation systems, especially systems for reasoning about corporate tax law and estate tax law [36, 38, 44]. In <ref> [6, 5] </ref>, we investigated hypothetical reasoning in deductive databases. We considered rules that can hypothetically insert or delete facts from a database. <p> Without hypothetical operations, the language reduces to Datalog (function-free Horn logic), whose data complexity is complete for PTIME. We also proved completeness results on the logic's ability to express databases queries. In <ref> [5] </ref>, we developed a logical semantics for hypothetical reasoning with insertion and deletion, including a proof theory, model theory and fixpoint theory. We then extended the semantics to account for negation-as-failure. Other researchers in the logic programming community have investigated the semantics of hypothetical inference. <p> The lower bound is proved by encoding the computations of an arbitrary NP-machine as a linear rulebase. The upper bound is more difficult and is proved by showing that for any linear rulebase, all proof trees are of polynomial size. Third, we augment intuitionistic rulebases with negation-as-failure. Following <ref> [5] </ref>, we extend the notion of stratification [2, 12] from Horn rules to intuitionistic rules. We then show that the data complexity of a linear rulebase depends crucially on the number of strata it has. <p> In particular, the rule within1 (s) [grad (s) take (s; c)] defines those students who are "within one course of graduation." The next example illustrates, in simplified form, the kind of rules used in the Turing-machine encodings of Section 6.2. Additional examples are given in <ref> [6, 5, 7] </ref>. <p> Intuitionistic logic makes finer distinctions than classical logic. For instance, the formulas A B and A _ B are equivalent classically, but not intuitionisti-cally. Similarly, the formulas G A; B and (G A) _ (G B) are equivalent classically, but not intuitionistically <ref> [7, 5] </ref>. Intuitionistic logic also admits fewer inferences than classical logic, such as the above equivalences. This can be seen in the inference system of Definition 2.4. <p> Proof Trees for Linear Rulebases: Corollary 4.4 assures us that for a rulebase of hypothetical additions, every minimal proof tree has polynomial depth. Such a tree may still have exponential size however, as the examples in <ref> [7, 5] </ref> show. However, these examples all involve non-linear rulebases. This section shows that such examples cannot be constructed from linear rulebases. In particular, we show that every minimal proof tree of a linear rulebase has polynomial size, polynomial in the size of the data domain. <p> To avoid these problems, we focus on a class of stratified rulebases [2, 12]. We first extend the idea of stratification from Horn rulebases to hypothetical rulebases, and then develop the proof theory. The material in this section is adapted from <ref> [5] </ref>, where we develop the model theory and proof theory for hypothetical deletion as well as insertion. That proof theory is equivalent to the one developed in [6], but is simpler and more intuitive, and is a straightforward extension of negation-free inference. <p> Let DB be a database, and let OE be a goal. Then R + DB ` OE if the expression R + DB ` OE is in A fl . This completes the proof theory of stratified embedded implications. Additional details and discussion can be found in <ref> [5, 8] </ref>. Note that although the proof theory is defined in a bottom-up fashion, top-down inference is also possible, as the following examples show. Example 5.3. [Stratified Inference] Suppose B 62 DB , and R is the rulebase consisting of the single rule A (B C).
Reference: 6. <author> A.J. Bonner. </author> <title> Hypothetical Datalog: Complexity and Expressibility. </title> <journal> Theoretical Computer Science (TCS), </journal> <volume> 76 </volume> <pages> 3-51, </pages> <year> 1990. </year> <booktitle> Special issue on the 2 nd International Conference on Database Theory (ICDT'88). </booktitle> <pages> 45 </pages>
Reference-contexts: And McCarty, also motivated by legal applications, has developed a wide class of hypothetical rules for computer-based consultation systems, especially systems for reasoning about corporate tax law and estate tax law [36, 38, 44]. In <ref> [6, 5] </ref>, we investigated hypothetical reasoning in deductive databases. We considered rules that can hypothetically insert or delete facts from a database. <p> In [6, 5], we investigated hypothetical reasoning in deductive databases. We considered rules that can hypothetically insert or delete facts from a database. In <ref> [6] </ref>, we showed that with both insertion and deletion, the data complexity of hypothetical inference is complete for EXPTIME, while with insertion alone it is complete for PSPACE. Without hypothetical operations, the language reduces to Datalog (function-free Horn logic), whose data complexity is complete for PTIME. <p> Such rulebases might be called intuitionistic deductive databases. Several questions naturally arise. For instance, what is their data complexity, and what database queries can they express? Initial results along these lines were provided by Statman [46] for the propositional case, and by our own PSPACE results for hypothetical insertion <ref> [6] </ref>. In this paper, we 4 provide new results on semantics, and a comprehensive set of results on complexity and expressibility. The main result is a tight connection between intuitionistic logic, database queries, and the polynomial time hierarchy. A tight connection with second-order logic follows as a corollary. <p> The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1]. Intuitionistic rulebases do not need this assumption, since they can generate linear orders on a domain hypothetically <ref> [6] </ref>. 5 Finally, we recall that the generic queries in PHIER are precisely the queries definable in second-order logic [47, 28]. We have therefore characterized the second-order definable queries in terms of intuitionistic deductive databases. 1.3. <p> Given a query, OE, the expression R + DB ` OE means that OE can be inferred from the rules in R and the facts in DB . The examples below are selected and adapted from <ref> [6] </ref>. Additional examples can be found in [6, 7]. <p> Given a query, OE, the expression R + DB ` OE means that OE can be inferred from the rules in R and the facts in DB . The examples below are selected and adapted from [6]. Additional examples can be found in <ref> [6, 7] </ref>. <p> complexity, function symbols are not included in the language. (However, because the set of constant symbols is infinite, it should be possible to extend our development to include function symbols, by treating each ground Herbrand term as a distinct constant symbol.) The material presented in this section is adapted from <ref> [6] </ref>, to which the reader is referred for additional details. Definition 2.1. [Hypothetical Queries] A hypothetical query is a formula of the form B C 1 ; C 2 ; : : : ; C k where B and each C i are atomic formulas, and k 0. <p> In particular, the rule within1 (s) [grad (s) take (s; c)] defines those students who are "within one course of graduation." The next example illustrates, in simplified form, the kind of rules used in the Turing-machine encodings of Section 6.2. Additional examples are given in <ref> [6, 5, 7] </ref>. <p> This is a more restrictive notion of entailment than that given by Definition 3.6. Thus, embedded implications can be viewed as having a kind of simplified intuitionistic semantics. This is true even for larger classes of embedded implications, such as those defined in [9]. 4. LINEAR RECURSION In <ref> [6] </ref>, we showed that the data complexity of embedded implications is complete for PSPACE. In this section, we develop a syntactic restriction that reduces their complexity. The restriction is called linearity. Informally, a rule is linear if recursion occurs through only one premise. <p> The language of embedded implications thus defines a set of queries. The following theorem, which is the main result of this section, establishes the data complexity of this set. Theorem 4.1. The data complexity of linear embedded implications is NP-complete. In <ref> [6] </ref>, we showed that the data complexity of embedded implications is complete for PSPACE. The NP lower bound in Theorem 4.1 is implicit in the proof of the PSPACE lower bound. To establish this lower bound, [6] uses embedded implications to encode the computations of alternating Turing machines [13], which are <p> Theorem 4.1. The data complexity of linear embedded implications is NP-complete. In <ref> [6] </ref>, we showed that the data complexity of embedded implications is complete for PSPACE. The NP lower bound in Theorem 4.1 is implicit in the proof of the PSPACE lower bound. To establish this lower bound, [6] uses embedded implications to encode the computations of alternating Turing machines [13], which are a generalization of non-deterministic machines. To be more precise, let M be a one-tape Turing machine that runs in alternating polynomial time (an APTIME-machine), and let s be an input string for the machine. In [6], <p> <ref> [6] </ref> uses embedded implications to encode the computations of alternating Turing machines [13], which are a generalization of non-deterministic machines. To be more precise, let M be a one-tape Turing machine that runs in alternating polynomial time (an APTIME-machine), and let s be an input string for the machine. In [6], we encode s as a 16 database DB (s), and M as a rulebase R (M ) so that R (M ) + DB (s) ` ACCEPT if and only if M accepts s: (4.1) where ACCEPT is a 0-ary predicate symbol. <p> This shows that the data-complexity of query processing is APTIME-hard. PSPACE-hardness follows immediately since PSPACE = APTIME [13]. As a special case, M may be an NP-machine. In this case, the rulebase R (M ) constructed in <ref> [6] </ref> is linear. (A generalization of these linear rulebases is constructed in Section 6.2, to encode NP oracle machines.) Thus, linear embedded implications can simulate the computations of arbitrary NP-machines. This proves the lower complexity bound of Theorem 4.1. 4.2. <p> NEGATION AS FAILURE Section 4 showed that the data complexity of linear embedded implications is NP complete. However, despite this great computational power, there are some simple, low-complexity queries that embedded implications cannot express. This is 1 This fact was originally proved in <ref> [6] </ref>. 22 because, like all inference systems, embedded implications are monotonic: As the database expands, the answer to a query also expands. Such systems cannot express non-monotonic queries, such as retrieving those students who are not eligible to graduate. <p> The material in this section is adapted from [5], where we develop the model theory and proof theory for hypothetical deletion as well as insertion. That proof theory is equivalent to the one developed in <ref> [6] </ref>, but is simpler and more intuitive, and is a straightforward extension of negation-free inference. In [8], we develop an extension of intuitionistic model theory for which the proof theory presented here is sound and complete. <p> This means that a stipend is available only to those students who need exactly one course to graduate. 23 5.1. Stratified Hypothetical Rulebases This subsection gives a precise definition of stratified embedded implications, adapting the definitions of <ref> [6] </ref>. The first step is to extend some of the definitions given in Section 2. <p> The simplest result to state is the following: The data com plexity of linear rulebases with k strata is complete for P k . 4 It turns out, however, 2 For general embedded implications, the data complexity is complete for PSPACE <ref> [6] </ref>. <p> The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1]. Embedded implications do not need this artificial assumption, since they can generate linear orders on the domain hypothetically <ref> [6] </ref>. Thus, the results of this section are for arbitrary databases, ordered or not. Before continuing, we comment briefly on the difference between complexity and expressibility. Section 4 showed that without negation, the data complexity of linear embedded implications is NP-complete. <p> This gives another characterization of the queries expressed by stratified linear rulebases. Corollary 7.7. [Second-Order Queries] Stratified linear rulebases of embedded implications that are constant-free express exactly the second-order definable queries. Proof Sketch of Theorem 7.3: In <ref> [6] </ref>, we proved that embedded implications are expressively complete for PSPACE; i:e:, they can express any generic query computable in polynomial space. The proof is easily adapted to Theorem 7.3. This section outlines the proof. Details can be found in [6]. <p> Proof Sketch of Theorem 7.3: In <ref> [6] </ref>, we proved that embedded implications are expressively complete for PSPACE; i:e:, they can express any generic query computable in polynomial space. The proof is easily adapted to Theorem 7.3. This section outlines the proof. Details can be found in [6]. Let OE be a generic database query of type ff ! fi whose graph is in P k . There is a P k -machine that recognizes this graph, i:e:, that accepts the language L = fhx; DBi j x 2 OE (DB )g. <p> DB (s) is also assumed to contain a counter. DB (s) is therefore different from the database DB in Theorem 7.3, which is an arbitrary database. We must provide rules which when given DB , will construct DB (s). We defined such rules in <ref> [6] </ref> for use with PSPACE-machines. These rules are linear, and can be applied to cascaded oracle machines with very few changes. <p> This determines whether x is an answer to the query. Because the query is generic, the result of this step is independent of the specific linear order generated in step (i) <ref> [6] </ref>. The rules involved in these steps are added to R 1 (M ), to give a new rulebase called R 2 (M ). The rules involved in steps (i), (ii) and (iv) are hypothetical, and are added to the top stratum of R 1 (M ).
Reference: 7. <author> A.J. Bonner. </author> <title> Hypothetical Reasoning in Deductive Databases. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ 08903, USA, </address> <month> October </month> <year> 1991. </year> <note> Published as Rutgers Technical Report DCS-TR-283. </note>
Reference-contexts: Given a query, OE, the expression R + DB ` OE means that OE can be inferred from the rules in R and the facts in DB . The examples below are selected and adapted from [6]. Additional examples can be found in <ref> [6, 7] </ref>. <p> In particular, the rule within1 (s) [grad (s) take (s; c)] defines those students who are "within one course of graduation." The next example illustrates, in simplified form, the kind of rules used in the Turing-machine encodings of Section 6.2. Additional examples are given in <ref> [6, 5, 7] </ref>. <p> Intuitionistic logic makes finer distinctions than classical logic. For instance, the formulas A B and A _ B are equivalent classically, but not intuitionisti-cally. Similarly, the formulas G A; B and (G A) _ (G B) are equivalent classically, but not intuitionistically <ref> [7, 5] </ref>. Intuitionistic logic also admits fewer inferences than classical logic, such as the above equivalences. This can be seen in the inference system of Definition 2.4. <p> Proof Trees for Linear Rulebases: Corollary 4.4 assures us that for a rulebase of hypothetical additions, every minimal proof tree has polynomial depth. Such a tree may still have exponential size however, as the examples in <ref> [7, 5] </ref> show. However, these examples all involve non-linear rulebases. This section shows that such examples cannot be constructed from linear rulebases. In particular, we show that every minimal proof tree of a linear rulebase has polynomial size, polynomial in the size of the data domain.
Reference: 8. <author> A.J. Bonner and L.T. McCarty. </author> <title> Adding Negation-as-Failure to Intuitionistic Logic Programming. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming (NACLP), </booktitle> <pages> pages 681-703, </pages> <address> Austin, Texas, Oct 29-Nov 1 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic [36, 39]. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications <ref> [19, 8, 24, 42, 23, 15] </ref>, which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, [22, 30, 16, 41]). <p> That proof theory is equivalent to the one developed in [6], but is simpler and more intuitive, and is a straightforward extension of negation-free inference. In <ref> [8] </ref>, we develop an extension of intuitionistic model theory for which the proof theory presented here is sound and complete. Example 5.1. [Negation-as-Failure] The rules below are part of a stratified hypothetical rulebase that defines a student's eligibility for financial aid. <p> Let DB be a database, and let OE be a goal. Then R + DB ` OE if the expression R + DB ` OE is in A fl . This completes the proof theory of stratified embedded implications. Additional details and discussion can be found in <ref> [5, 8] </ref>. Note that although the proof theory is defined in a bottom-up fashion, top-down inference is also possible, as the following examples show. Example 5.3. [Stratified Inference] Suppose B 62 DB , and R is the rulebase consisting of the single rule A (B C).
Reference: 9. <author> A.J. Bonner, L.T. McCarty, and K. Vadaparty. </author> <title> Expressing Database Queries with Intuitionistic Logic. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming (NACLP), </booktitle> <pages> pages 831-850, </pages> <address> Cleveland, Ohio, October 16-20 1989. </address> <publisher> MIT Press. </publisher>
Reference-contexts: This is a more restrictive notion of entailment than that given by Definition 3.6. Thus, embedded implications can be viewed as having a kind of simplified intuitionistic semantics. This is true even for larger classes of embedded implications, such as those defined in <ref> [9] </ref>. 4. LINEAR RECURSION In [6], we showed that the data complexity of embedded implications is complete for PSPACE. In this section, we develop a syntactic restriction that reduces their complexity. The restriction is called linearity. Informally, a rule is linear if recursion occurs through only one premise.
Reference: 10. <author> A.K. Chandra and D. Harel. </author> <title> Computable Queries for Relational Databases. </title> <journal> Journal of Computer and System Sciences (JCSS), </journal> <volume> 21(2) </volume> <pages> 156-178, </pages> <year> 1980. </year>
Reference-contexts: The upper bounds are proved by a procedure that combines bottom-up, deterministic inference with top-down, non-deterministic inference. Fourth, we characterize the generic database queries expressible by linear intu-itionistic rulebases. A query is generic if it satisfies the consistency criterion of Chandra and Harel <ref> [10, 11] </ref>. Genericity captures the idea that the constant symbols in a database are uninterpreted. We first show that stratified linear rulebases are expressively complete for the polynomial time hierarchy (PHIER); that is, any generic database query in PHIER can be expressed as a stratified linear rulebase. <p> EXPRESSIBILITY This section characterizes the expressibility of linear embedded implications with negation. The results establish a tight relationship between embedded implications, computational complexity, and generic queries. Informally, a query is generic if it treats all constant symbols equally <ref> [10, 11] </ref>. We first show that stratified linear rulebases are expressively complete for PHIER. That is, any generic query in the polynomial time hierarchy can be expressed as a stratified linear rulebase of embedded implications. <p> The second rule says that y is an internal node if it has a child, z. 7.1. Generic Queries This section makes precise the ideas discussed above. The first two definitions are due to Chandra and Harel <ref> [10, 11] </ref>. Definition 7.1. [Relational Databases] Let U be a countable set, called the universal data domain.
Reference: 11. <author> A.K. Chandra and D. Harel. </author> <title> Structure and Complexity of Relational Queries. </title> <booktitle> In Proceedings of the Symposium on the Foundations of Computer Science (FOCS), </booktitle> <pages> pages 333-347, </pages> <year> 1980. </year>
Reference-contexts: The upper bounds are proved by a procedure that combines bottom-up, deterministic inference with top-down, non-deterministic inference. Fourth, we characterize the generic database queries expressible by linear intu-itionistic rulebases. A query is generic if it satisfies the consistency criterion of Chandra and Harel <ref> [10, 11] </ref>. Genericity captures the idea that the constant symbols in a database are uninterpreted. We first show that stratified linear rulebases are expressively complete for the polynomial time hierarchy (PHIER); that is, any generic database query in PHIER can be expressed as a stratified linear rulebase. <p> Formally, if is a database query, then its data-complexity is the complexity of the language fhx; DB i j x 2 (DB )g where x is a tuple, DB is a database, and (DB ) is the value of the query applied to DB <ref> [11, 51] </ref>. This language is called the graph of the query . The data complexity of a set of queries is the complexity of their graphs. When studying the data complexity of a query language, one looks for the most complex query in the language. <p> <ref> [11, 51] </ref>. This language is called the graph of the query . The data complexity of a set of queries is the complexity of their graphs. When studying the data complexity of a query language, one looks for the most complex query in the language. This motivates the following definition [11, 51]. Definition 4.3. A set of queries is data complete for a complexity class C if (1) the graph of each query is in C, and (2) there is some query in the set whose graph is a complete language for C. <p> M i suspends its own computations while M i1 is computing. In effect, M k invokes M k1 as a subrou 5 See <ref> [11] </ref> for examples of such languages. 33 tine. Likewise, M k1 invokes M k2 as a subroutine, etc. The language accepted by this compound machine is the language accepted by M k when it is the root of this cascade of machines. <p> EXPRESSIBILITY This section characterizes the expressibility of linear embedded implications with negation. The results establish a tight relationship between embedded implications, computational complexity, and generic queries. Informally, a query is generic if it treats all constant symbols equally <ref> [10, 11] </ref>. We first show that stratified linear rulebases are expressively complete for PHIER. That is, any generic query in the polynomial time hierarchy can be expressed as a stratified linear rulebase of embedded implications. <p> The second rule says that y is an internal node if it has a child, z. 7.1. Generic Queries This section makes precise the ideas discussed above. The first two definitions are due to Chandra and Harel <ref> [10, 11] </ref>. Definition 7.1. [Relational Databases] Let U be a countable set, called the universal data domain.
Reference: 12. <author> A.K. Chandra and D. Harel. </author> <title> Horn Clause Queries and Generalizations. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 2(1) </volume> <pages> 1-15, </pages> <year> 1985. </year>
Reference-contexts: The upper bound is more difficult and is proved by showing that for any linear rulebase, all proof trees are of polynomial size. Third, we augment intuitionistic rulebases with negation-as-failure. Following [5], we extend the notion of stratification <ref> [2, 12] </ref> from Horn rules to intuitionistic rules. We then show that the data complexity of a linear rulebase depends crucially on the number of strata it has. <p> This establishes a tight connection between two previously unrelated, but well-established areas: intuitionistic logic and the polynomial time hierarchy. Unlike many expressibility results in the literature (e:g:, <ref> [27, 51, 12] </ref>), these results do not assume that the data domain is linearly ordered. The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1]. <p> Thus, A is inferred if B C cannot be inferred. Unfortunately, as in Horn logic programming, the semantics of negation-as-failure is problematic when recursion occurs through negation. To avoid these problems, we focus on a class of stratified rulebases <ref> [2, 12] </ref>. We first extend the idea of stratification from Horn rulebases to hypothetical rulebases, and then develop the proof theory. The material in this section is adapted from [5], where we develop the model theory and proof theory for hypothetical deletion as well as insertion. <p> In addition, we characterize the queries in each level, P k , of the hierarchy. 40 Unlike many expressibility results in the literature (e:g:, <ref> [27, 51, 12] </ref>), the results in this section do not assume that the data domain is linearly ordered. The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1].
Reference: 13. <author> A.K. Chandra, D. Kozen, and L.J. Stockmeyer. </author> <title> Alternation. </title> <journal> Journal of the ACM, </journal> <volume> 28 </volume> <pages> 114-133, </pages> <year> 1981. </year>
Reference-contexts: In [6], we showed that the data complexity of embedded implications is complete for PSPACE. The NP lower bound in Theorem 4.1 is implicit in the proof of the PSPACE lower bound. To establish this lower bound, [6] uses embedded implications to encode the computations of alternating Turing machines <ref> [13] </ref>, which are a generalization of non-deterministic machines. To be more precise, let M be a one-tape Turing machine that runs in alternating polynomial time (an APTIME-machine), and let s be an input string for the machine. <p> The important point is that the rulebase R (M ) is independent of the input s. This shows that the data-complexity of query processing is APTIME-hard. PSPACE-hardness follows immediately since PSPACE = APTIME <ref> [13] </ref>. As a special case, M may be an NP-machine. In this case, the rulebase R (M ) constructed in [6] is linear. (A generalization of these linear rulebases is constructed in Section 6.2, to encode NP oracle machines.) Thus, linear embedded implications can simulate the computations of arbitrary NP-machines.
Reference: 14. <author> B.F. Chellas. </author> <title> Modal Logic: an Introduction. </title> <publisher> Cambridge University Press, </publisher> <year> 1980. </year>
Reference-contexts: We present the proof theory for hypothetical insertion, and show that it is sound and complete with respect to intuitionistic model theory. Unlike other proofs in the literature [20, 36, 39], ours is based on the Henkin constructions of modal logic <ref> [14, 26] </ref>. Next, we develop the notion of linear intuitionistic rulebases, generalizing the notion of linear Horn rulebases [4]. Intuitively, a rule is linear if recursion occurs through only one premise. <p> Instead, it is intuitionistic, as several researchers have shown [20, 36, 39]. This section reviews intuitionistic semantics and develops a new and simpler proof that the inference system is sound and complete intuitionistically. This proof is inspired by the Henkin constructions of modal logic <ref> [14, 26] </ref>. Given a rulebased system R, we define an intuitionistic structure, M R , called the canonical model of R. This structure, defined proof-theoretically, provides the necessary link between inference and semantics, and leads to a simple proof of completeness. Intuitionistic logic makes finer distinctions than classical logic. <p> The axioms are trivially valid, and inference rules 1 and 2 correspond to modus ponens and the deduction theorem, respectively. The rest of this section proves the only if direction (i:e:, completeness). The approach taken here is inspired by the Henkin constructions of modal logic <ref> [14, 26] </ref>. Given a rulebased system R, we define an intuitionistic structure M R called the canonical model of R. This structure, defined proof-theoretically, provides the necessary link between inference and semantics. Definition 3.7. Let R = [R; dom; pred ] be a rulebased system.
Reference: 15. <author> P.M. Dung. </author> <title> Declarative Semantics of Hypothetical Logic Programming with Negation as Failure. </title> <booktitle> In Proceedings of the Third International Workshop on Extensions of Logic Programming, </booktitle> <pages> pages 45-58, </pages> <address> Bologna, Italy, </address> <month> February </month> <year> 1992. </year> <note> Springer-Verlag. Published as volume 660 of Lecture Notes in Artificial Intelligence, </note> <year> 1993. </year>
Reference-contexts: Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic [36, 39]. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications <ref> [19, 8, 24, 42, 23, 15] </ref>, which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, [22, 30, 16, 41]).
Reference: 16. <author> T. Eiter and G. Gottlob. </author> <title> On the complexity of propositional knowledge base revision, updates and counterfactuals. </title> <booktitle> In Proceedings of the ACM Symposium on the Principles of Database Systems (PODS), </booktitle> <pages> pages 261-273, </pages> <address> San Diego, CA, </address> <month> June 2-4 </month> <year> 1992. </year>
Reference-contexts: Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications [19, 8, 24, 42, 23, 15], which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, <ref> [22, 30, 16, 41] </ref>). In this work, a database (or knowledge base) is treated as a set of arbitrary logical formulas, and the issue is what to do when a formula inserted into the database contradicts formulas already there. The focus is therefore on the resolution of logical contradictions.
Reference: 17. <author> M.C. </author> <title> Fitting. Intuitionistic Logic, Model Theory and Forcing. </title> <publisher> North-Holland, </publisher> <year> 1969. </year>
Reference-contexts: We then extended the semantics to account for negation-as-failure. Other researchers in the logic programming community have investigated the semantics of hypothetical inference. This work has focussed on the hypothetical insertion of facts into a database, since such updates fit neatly into a well-established logical framework|intuitionistic logic <ref> [17] </ref>. In intuitionistic logic, hypothetical insertion arises from formulas called embedded implications [36]. These are rules of the form A (B C), which informally means that A can be inferred if assuming C allows B to be inferred. The assumption of C is a hypothetical insertion into the database. <p> It includes three infinite, enumerable sets: a set of variables x; y; z; :::; a set of constant symbols a; b; c; :::; and a set of predicate symbols A; B; C; :::. More extensive treatment and discussion of intuitionistic logic can be found in <ref> [17, 32] </ref>. Definition 3.1. [Structures] A first-order intuitionistic structure is a quadruple M = hS; ; ; di, where 1. S is a non-empty set. 2. is a partial order on S. 3. is a monotonic mapping from elements of S to sets of ground atomic formulas. <p> Note that unlike classical logic, intuitionistic implication is not defined in terms of disjunction and negation. Instead, it has an independent semantic definition. It is this definition that captures hypothetical insertion. The following basic result is an immediate consequence of the above definitions <ref> [17] </ref>. It reflects the idea that knowledge increases monotonically as we climb from one substate to a higher one. Lemma 3.1. s; M j= OE if and only if r; M j= OE for all r s.
Reference: 18. <author> The Committee for Advanced DBMS function. </author> <title> Third-Generation Database System Manifesto. </title> <booktitle> SIGMOD Record, </booktitle> <volume> 19(3) </volume> <pages> 31-44, </pages> <month> September </month> <year> 1990. </year> <note> Also published as Memorandum No. </note> <institution> UCB/ERL M90/28, Electronics Research Laboratory, College of Engineering, University of California, Berkeley. </institution>
Reference-contexts: Or he might want a table of deficit predictions for a number of hypothetical salary increases [52, 53]. Similar problems occur in computer aided design (CAD). Here, one must evaluate the effect on the overall design of local design alternatives and of various external factors <ref> [18, 45] </ref>. For example, an engineer may need to know how much the price of an automobile would increase if supplier X raised his prices by Y percent [18]. The number of hypothetical scenarios multiplies quickly when several factors are varied simultaneously, such as prices, interest rates, tax rates, etc. <p> Here, one must evaluate the effect on the overall design of local design alternatives and of various external factors [18, 45]. For example, an engineer may need to know how much the price of an automobile would increase if supplier X raised his prices by Y percent <ref> [18] </ref>. The number of hypothetical scenarios multiplies quickly when several factors are varied simultaneously, such as prices, interest rates, tax rates, etc. One may also need to consider variations in more complex factors, such as government regulations, company policy, tax laws, etc. 1.1.
Reference: 19. <author> D.M. Gabbay. N-Prolog: </author> <title> an Extension of Prolog with Hypothetical Implications. II. Logical Foundations and Negation as Failure. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 2(4) </volume> <pages> 251-283, </pages> <year> 1985. </year>
Reference-contexts: Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic [36, 39]. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications <ref> [19, 8, 24, 42, 23, 15] </ref>, which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, [22, 30, 16, 41]).
Reference: 20. <editor> D.M. Gabbay and U. Reyle. N-Prolog: </editor> <title> an Extension of Prolog with Hypothetical Implications. I. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 1(4) </volume> <pages> 319-355, </pages> <year> 1984. </year>
Reference-contexts: Gabbay and Reyle, for instance, have reported a need to augment Prolog with hypothetical rules in order to encode the British Nationality Act, because the act contains rules such 3 as, "You are eligible for citizenship if your father would be eligible if he were still alive" <ref> [20] </ref>. And McCarty, also motivated by legal applications, has developed a wide class of hypothetical rules for computer-based consultation systems, especially systems for reasoning about corporate tax law and estate tax law [36, 38, 44]. In [6, 5], we investigated hypothetical reasoning in deductive databases. <p> These are rules of the form A (B C), which informally means that A can be inferred if assuming C allows B to be inferred. The assumption of C is a hypothetical insertion into the database. Gabbay first showed that embedded implications are intuitionistic <ref> [20] </ref>. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic [36, 39]. <p> Our first result is a new and simplified proof that hypothetical insertion is in-tuitionistic. We present the proof theory for hypothetical insertion, and show that it is sound and complete with respect to intuitionistic model theory. Unlike other proofs in the literature <ref> [20, 36, 39] </ref>, ours is based on the Henkin constructions of modal logic [14, 26]. Next, we develop the notion of linear intuitionistic rulebases, generalizing the notion of linear Horn rulebases [4]. Intuitively, a rule is linear if recursion occurs through only one premise. <p> Note that the premise of the first rule is a hypothetical query similar to the query in Example 1.2. 2. SYNTAX AND PROOF THEORY This section describes a logical inference system for hypothetical rules. Similar systems have been developed by other researchers <ref> [20, 36, 39, 34] </ref>. This section defines a simplified system, one that retains many of the essential properties of the more elaborate systems while admitting a clean theoretical analysis. The system is an extension of classical Horn logic, both syntactically and proof-theoretically. <p> If R 1 + DB 1 ` OE then R 2 + DB 2 ` OE 3. MODEL THEORY The inference system of Definition 2.4 is not classical. Instead, it is intuitionistic, as several researchers have shown <ref> [20, 36, 39] </ref>. This section reviews intuitionistic semantics and develops a new and simpler proof that the inference system is sound and complete intuitionistically. This proof is inspired by the Henkin constructions of modal logic [14, 26].
Reference: 21. <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: In the special case in which R is linear, Theorem 4.8 assures us that if R; DB ` is true, then it has a proof tree of polynomial size; so PROVE has an accepting computation of polynomial length. Thus, for linear rulebases, PROVE runs in NP-time <ref> [21] </ref>. This establishes the upper bound of Theorem 4.1.
Reference: 22. <author> M.L. Ginsberg. </author> <title> Counterfactuals. </title> <journal> Artificial Intelligence, </journal> <volume> 30(1) </volume> <pages> 35-79, </pages> <year> 1986. </year>
Reference-contexts: Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications [19, 8, 24, 42, 23, 15], which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, <ref> [22, 30, 16, 41] </ref>). In this work, a database (or knowledge base) is treated as a set of arbitrary logical formulas, and the issue is what to do when a formula inserted into the database contradicts formulas already there. The focus is therefore on the resolution of logical contradictions.
Reference: 23. <author> L. Giordano and N. Olivetti. </author> <title> Negation as Failure in Intuitionistic Logic Programming. </title> <booktitle> In Proceedings of the Joint International Conference and Symposium on Logic Programming (JICSLP), </booktitle> <pages> pages 431-445, </pages> <address> Washington, D.C., 1992. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic [36, 39]. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications <ref> [19, 8, 24, 42, 23, 15] </ref>, which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, [22, 30, 16, 41]).
Reference: 24. <author> J. Harland. </author> <title> A Kripke-like model for negation as failure. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming (NACLP), </booktitle> <pages> pages 626-642, </pages> <address> Cleveland, Ohio, October 1989. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic [36, 39]. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications <ref> [19, 8, 24, 42, 23, 15] </ref>, which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, [22, 30, 16, 41]).
Reference: 25. <author> J.E. Hopcroft and J.D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison-Wesley, </publisher> <year> 1979. </year>
Reference-contexts: This computation can be done in polynomial space. Thus, the entire computation, including guesses, runs in non-deterministic polynomial space. The data complexity of embedded implications is therefore in NPSPACE, and thus in PSPACE, since PSPACE = NPSPACE, by Savitch's Theorem <ref> [25] </ref>. 5. NEGATION AS FAILURE Section 4 showed that the data complexity of linear embedded implications is NP complete. However, despite this great computational power, there are some simple, low-complexity queries that embedded implications cannot express. <p> Section 7 uses these results to characterize the expressibility of linear embedded implications, and to characterize the second-order definable queries in terms of embedded implications. The polynomial-time hierarchy is a sequence of complexity classes between P and PSPACE. It is based on oracle Turing machines <ref> [25] </ref>, and can be defined recursively as follows [47]: * P 0 = P. k+1 = P P k = those languages accepted in deterministic polynomial time by an oracle machine whose oracle is a language in P k . k+1 = NP P k = those languages accepted in non-deterministic <p> In this case, negation has no effect on the data complexity, since PSPACE = coPSPACE <ref> [25] </ref>. 3 Although considered likely, it is an open question as to whether any of these containments are strict. 4 It would be tempting to conclude that the set of all stratified rulebases is complete for the entire polynomial time hierarchy; but this would be incorrect.
Reference: 26. <author> G.E. Hughes and M.J. Cresswell. </author> <title> An Introduction to Modal Logic. </title> <publisher> Methuen and Co. Ltd., </publisher> <address> London, </address> <year> 1968. </year>
Reference-contexts: We present the proof theory for hypothetical insertion, and show that it is sound and complete with respect to intuitionistic model theory. Unlike other proofs in the literature [20, 36, 39], ours is based on the Henkin constructions of modal logic <ref> [14, 26] </ref>. Next, we develop the notion of linear intuitionistic rulebases, generalizing the notion of linear Horn rulebases [4]. Intuitively, a rule is linear if recursion occurs through only one premise. <p> Instead, it is intuitionistic, as several researchers have shown [20, 36, 39]. This section reviews intuitionistic semantics and develops a new and simpler proof that the inference system is sound and complete intuitionistically. This proof is inspired by the Henkin constructions of modal logic <ref> [14, 26] </ref>. Given a rulebased system R, we define an intuitionistic structure, M R , called the canonical model of R. This structure, defined proof-theoretically, provides the necessary link between inference and semantics, and leads to a simple proof of completeness. Intuitionistic logic makes finer distinctions than classical logic. <p> The axioms are trivially valid, and inference rules 1 and 2 correspond to modus ponens and the deduction theorem, respectively. The rest of this section proves the only if direction (i:e:, completeness). The approach taken here is inspired by the Henkin constructions of modal logic <ref> [14, 26] </ref>. Given a rulebased system R, we define an intuitionistic structure M R called the canonical model of R. This structure, defined proof-theoretically, provides the necessary link between inference and semantics. Definition 3.7. Let R = [R; dom; pred ] be a rulebased system.
Reference: 27. <author> N. Immerman. </author> <title> Relational Queries Computable in Polynomial Time. </title> <booktitle> In Proceedings 46 of the ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 147-152, </pages> <year> 1982. </year>
Reference-contexts: This establishes a tight connection between two previously unrelated, but well-established areas: intuitionistic logic and the polynomial time hierarchy. Unlike many expressibility results in the literature (e:g:, <ref> [27, 51, 12] </ref>), these results do not assume that the data domain is linearly ordered. The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1]. <p> In addition, we characterize the queries in each level, P k , of the hierarchy. 40 Unlike many expressibility results in the literature (e:g:, <ref> [27, 51, 12] </ref>), the results in this section do not assume that the data domain is linearly ordered. The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1].
Reference: 28. <author> N. Immerman. </author> <title> Languages that Capture Complexity Classes. </title> <journal> SIAM Journal of Computing, </journal> <volume> 16(4) </volume> <pages> 760-778, </pages> <year> 1987. </year>
Reference-contexts: Intuitionistic rulebases do not need this assumption, since they can generate linear orders on a domain hypothetically [6]. 5 Finally, we recall that the generic queries in PHIER are precisely the queries definable in second-order logic <ref> [47, 28] </ref>. We have therefore characterized the second-order definable queries in terms of intuitionistic deductive databases. 1.3. Introductory Examples A deductive database consists of a set of atomic formulas (the database) and a set of logical rules (the rulebase). <p> This result provides a characterization of the generic queries in PHIER in terms of intuitionistic logic. It also provides a new characterization of the second-order definable queries, since the generic queries in PHIER are exactly the queries definable in second-order logic <ref> [47, 28] </ref>. In addition, we characterize the queries in each level, P k , of the hierarchy. 40 Unlike many expressibility results in the literature (e:g:, [27, 51, 12]), the results in this section do not assume that the data domain is linearly ordered. <p> Hence, Corollary 7.6. [Characterization of PHIER] Stratified linear rulebases of embedded implications that are constant-free express exactly the typed generic queries in the polynomial time hierarchy. The typed generic queries in PHIER are precisely the queries definable in second-order logic <ref> [47, 28] </ref>. This gives another characterization of the queries expressed by stratified linear rulebases. Corollary 7.7. [Second-Order Queries] Stratified linear rulebases of embedded implications that are constant-free express exactly the second-order definable queries.
Reference: 29. <editor> R.H. Sprague Jr. and H.J. Watson, editors. </editor> <title> Decisions Support Systems: Putting Theory into Practice. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: 1. INTRODUCTION Researchers from several areas have recognized the need for computer systems that reason hypothetically. Decision support systems (DSS) are a good example, especially in domains like financial planning where many "what if" scenarios must be considered <ref> [29, 43] </ref>. A typical example is an analyst who must predict a company's deficit for the upcoming year assuming that employee salaries are increased by a given percentage. Or he might want a table of deficit predictions for a number of hypothetical salary increases [52, 53].
Reference: 30. <author> H. Katsuno and A.O. Mendelzon. </author> <title> On the difference between updating a knowledge database and revising it. </title> <booktitle> In Proceedings of the International Conference on Knowledge Representation and Reasoning (KR), </booktitle> <pages> pages 387-394, </pages> <address> Boston, Mass., </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications [19, 8, 24, 42, 23, 15], which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, <ref> [22, 30, 16, 41] </ref>). In this work, a database (or knowledge base) is treated as a set of arbitrary logical formulas, and the issue is what to do when a formula inserted into the database contradicts formulas already there. The focus is therefore on the resolution of logical contradictions.
Reference: 31. <author> R. Kowalski. </author> <title> Logic for Problem Solving. </title> <publisher> North-Holland, </publisher> <year> 1979. </year>
Reference-contexts: are representing time explicitly; i:e:, the database represents a sequence of id's, and rules are needed to copy the unchanged portion of an id from one instant of time to the next. 38 In Horn logic programming, negation-as-failure normally plays a central role in any solution to the frame problem <ref> [31] </ref>. We do not have this luxury however. The rulebase R (L) which we are constructing must have no more than k strata, and we have already created k of them, one for each oracle machine. Any attempt to use negation-as-failure would add new strata to the rulebase.
Reference: 32. <author> S. Kripke. </author> <title> Semantical Analysis of Intuitionistic Logic. </title> <editor> I. In J.N. Crossley and M.A.E. Dummett, editors, </editor> <booktitle> Formal Systems and Recursive Functions, </booktitle> <pages> pages 92-130. </pages> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1965. </year>
Reference-contexts: It includes three infinite, enumerable sets: a set of variables x; y; z; :::; a set of constant symbols a; b; c; :::; and a set of predicate symbols A; B; C; :::. More extensive treatment and discussion of intuitionistic logic can be found in <ref> [17, 32] </ref>. Definition 3.1. [Structures] A first-order intuitionistic structure is a quadruple M = hS; ; ; di, where 1. S is a non-empty set. 2. is a partial order on S. 3. is a monotonic mapping from elements of S to sets of ground atomic formulas.
Reference: 33. <author> S. Manchanda and D.S. Warren. </author> <title> A Logic-based Language for Database Updates. </title> <editor> In Jack Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, chapter 10, </booktitle> <pages> pages 363-394. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Vieille, et al, for instance, have implemented a deductive database along these lines [52, 53], and Warren and Manchanda have used hypothetical rules to reason about database updates <ref> [54, 33] </ref>. In [39], Miller shows that hypothetical insertions can structure the runtime environment of logic programs, resulting in programs that are more elegant, more efficient, and easier to maintain. In [40], he develops a theory of lexical scoping based on the hypothetical creation of constant symbols during inference.
Reference: 34. <author> Sanjay Manchanda. </author> <title> A Dynamic Logic Programming Language for Relational Updates. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, State University of New York at Stony Brook, Stony Brook, </institution> <address> New York, </address> <month> December </month> <year> 1987. </year> <note> Also published as Technical Report TR 88-2, </note> <institution> Department of Computer Science, The University of Arizona, Tuscon, Arizona 85721, </institution> <month> January, </month> <year> 1988. </year>
Reference-contexts: Note that the premise of the first rule is a hypothetical query similar to the query in Example 1.2. 2. SYNTAX AND PROOF THEORY This section describes a logical inference system for hypothetical rules. Similar systems have been developed by other researchers <ref> [20, 36, 39, 34] </ref>. This section defines a simplified system, one that retains many of the essential properties of the more elaborate systems while admitting a clean theoretical analysis. The system is an extension of classical Horn logic, both syntactically and proof-theoretically.
Reference: 35. <author> J.M. McCarthy and P.J. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 4, </volume> <pages> pages 463-502. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year> <note> Reprinted in Readings in Artificial Intelligence, </note> <year> 1981, </year> <title> Tioga Publ. </title> <publisher> Co. </publisher>
Reference-contexts: However, the greater part of an id remains unchanged by these transitions: except for those cells under the tape heads, the contents of the machine tapes remain unchanged. This is an instance of the frame problem <ref> [35] </ref>, and we must write linear rules to account for it.
Reference: 36. <author> L.T. McCarty. </author> <title> Clausal Intuitionistic Logic. I. Fixed-Point Semantics. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 5(1) </volume> <pages> 1-31, </pages> <year> 1988. </year>
Reference-contexts: And McCarty, also motivated by legal applications, has developed a wide class of hypothetical rules for computer-based consultation systems, especially systems for reasoning about corporate tax law and estate tax law <ref> [36, 38, 44] </ref>. In [6, 5], we investigated hypothetical reasoning in deductive databases. We considered rules that can hypothetically insert or delete facts from a database. <p> This work has focussed on the hypothetical insertion of facts into a database, since such updates fit neatly into a well-established logical framework|intuitionistic logic [17]. In intuitionistic logic, hypothetical insertion arises from formulas called embedded implications <ref> [36] </ref>. These are rules of the form A (B C), which informally means that A can be inferred if assuming C allows B to be inferred. The assumption of C is a hypothetical insertion into the database. Gabbay first showed that embedded implications are intuitionistic [20]. <p> The assumption of C is a hypothetical insertion into the database. Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic <ref> [36, 39] </ref>. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications [19, 8, 24, 42, 23, 15], which presents interesting technical challenges because of the intuitionistic setting. <p> Our first result is a new and simplified proof that hypothetical insertion is in-tuitionistic. We present the proof theory for hypothetical insertion, and show that it is sound and complete with respect to intuitionistic model theory. Unlike other proofs in the literature <ref> [20, 36, 39] </ref>, ours is based on the Henkin constructions of modal logic [14, 26]. Next, we develop the notion of linear intuitionistic rulebases, generalizing the notion of linear Horn rulebases [4]. Intuitively, a rule is linear if recursion occurs through only one premise. <p> Note that the premise of the first rule is a hypothetical query similar to the query in Example 1.2. 2. SYNTAX AND PROOF THEORY This section describes a logical inference system for hypothetical rules. Similar systems have been developed by other researchers <ref> [20, 36, 39, 34] </ref>. This section defines a simplified system, one that retains many of the essential properties of the more elaborate systems while admitting a clean theoretical analysis. The system is an extension of classical Horn logic, both syntactically and proof-theoretically. <p> If R 1 + DB 1 ` OE then R 2 + DB 2 ` OE 3. MODEL THEORY The inference system of Definition 2.4 is not classical. Instead, it is intuitionistic, as several researchers have shown <ref> [20, 36, 39] </ref>. This section reviews intuitionistic semantics and develops a new and simpler proof that the inference system is sound and complete intuitionistically. This proof is inspired by the Henkin constructions of modal logic [14, 26].
Reference: 37. <author> L.T. McCarty. </author> <title> Clausal Intuitionistic Logic. II. Tableau Proof Procedures. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 5(2) </volume> <pages> 93-132, </pages> <year> 1988. </year>
Reference-contexts: The predicate symbol A appearing in the rule head is called the head predicate. In a top-down, Prolog-style proof procedure, goal predicates would become subgoals and would be resolved against head predicates. (McCarty has developed such a proof procedure for embedded implications <ref> [37] </ref>.) When establishing the data complexity of hypothetical inference in Section 4, we will focus on specific sets of constant and predicate symbols. These sets will be finite, but of unbounded size. It is convenient to treat these sets as parameters of the proof theory.
Reference: 38. <author> L.T. McCarty. </author> <title> A Language for Legal Discourse. I. Basic Features. </title> <booktitle> In Proceedings of the Second International Conference on Artificial Intelligence and Law, </booktitle> <pages> pages 180-189. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: And McCarty, also motivated by legal applications, has developed a wide class of hypothetical rules for computer-based consultation systems, especially systems for reasoning about corporate tax law and estate tax law <ref> [36, 38, 44] </ref>. In [6, 5], we investigated hypothetical reasoning in deductive databases. We considered rules that can hypothetically insert or delete facts from a database.
Reference: 39. <author> D. Miller. </author> <title> A Logical Analysis of Modules in Logic Programming. </title> <journal> Journal of Logic Programming (JLP), </journal> <volume> 6 </volume> <pages> 79-108, </pages> <year> 1989. </year>
Reference-contexts: Vieille, et al, for instance, have implemented a deductive database along these lines [52, 53], and Warren and Manchanda have used hypothetical rules to reason about database updates [54, 33]. In <ref> [39] </ref>, Miller shows that hypothetical insertions can structure the runtime environment of logic programs, resulting in programs that are more elegant, more efficient, and easier to maintain. In [40], he develops a theory of lexical scoping based on the hypothetical creation of constant symbols during inference. <p> The assumption of C is a hypothetical insertion into the database. Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic <ref> [36, 39] </ref>. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications [19, 8, 24, 42, 23, 15], which presents interesting technical challenges because of the intuitionistic setting. <p> Our first result is a new and simplified proof that hypothetical insertion is in-tuitionistic. We present the proof theory for hypothetical insertion, and show that it is sound and complete with respect to intuitionistic model theory. Unlike other proofs in the literature <ref> [20, 36, 39] </ref>, ours is based on the Henkin constructions of modal logic [14, 26]. Next, we develop the notion of linear intuitionistic rulebases, generalizing the notion of linear Horn rulebases [4]. Intuitively, a rule is linear if recursion occurs through only one premise. <p> Note that the premise of the first rule is a hypothetical query similar to the query in Example 1.2. 2. SYNTAX AND PROOF THEORY This section describes a logical inference system for hypothetical rules. Similar systems have been developed by other researchers <ref> [20, 36, 39, 34] </ref>. This section defines a simplified system, one that retains many of the essential properties of the more elaborate systems while admitting a clean theoretical analysis. The system is an extension of classical Horn logic, both syntactically and proof-theoretically. <p> If R 1 + DB 1 ` OE then R 2 + DB 2 ` OE 3. MODEL THEORY The inference system of Definition 2.4 is not classical. Instead, it is intuitionistic, as several researchers have shown <ref> [20, 36, 39] </ref>. This section reviews intuitionistic semantics and develops a new and simpler proof that the inference system is sound and complete intuitionistically. This proof is inspired by the Henkin constructions of modal logic [14, 26].
Reference: 40. <author> D. Miller. </author> <title> Lexical scoping as universal quantification. </title> <editor> In G. Levi and M. Martelli, editors, </editor> <booktitle> Logic Programming: Proceedings of the Sixth International Conference, </booktitle> <pages> pages 268-283, </pages> <address> Cambridge, MA, 1989. </address> <publisher> MIT Press. </publisher>
Reference-contexts: In [39], Miller shows that hypothetical insertions can structure the runtime environment of logic programs, resulting in programs that are more elegant, more efficient, and easier to maintain. In <ref> [40] </ref>, he develops a theory of lexical scoping based on the hypothetical creation of constant symbols during inference. These logical systems are well-suited to solving problems in Artificial Intelligence, especially problems that involve reasoning about alternative courses of action.
Reference: 41. <author> B. Nebel. </author> <title> Belief revision and default reasoning: Syntax-based approach. </title> <booktitle> In Proceedings of the International Conference on Knowledge Representation and Reasoning (KR), </booktitle> <pages> pages 417-428, </pages> <address> Cambridge, MA, </address> <month> April 11-25 </month> <year> 1991. </year>
Reference-contexts: Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications [19, 8, 24, 42, 23, 15], which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, <ref> [22, 30, 16, 41] </ref>). In this work, a database (or knowledge base) is treated as a set of arbitrary logical formulas, and the issue is what to do when a formula inserted into the database contradicts formulas already there. The focus is therefore on the resolution of logical contradictions.
Reference: 42. <author> N. Olivetti and L. Terracini. </author> <title> N-Prolog and Equivalence of Logic Programs (Part 1). </title> <journal> Journal Of Logic, Language and Information, </journal> <volume> 1(4) </volume> <pages> 253-340, </pages> <year> 1992. </year>
Reference-contexts: Gabbay first showed that embedded implications are intuitionistic [20]. Working independently, McCarty and Miller extended embedded implications to a wider class of formulas, and developed fixpoint semantics based on intuition-istic logic [36, 39]. Recently, researchers have begun investigating the semantics of negation-as-failure for embedded implications <ref> [19, 8, 24, 42, 23, 15] </ref>, which presents interesting technical challenges because of the intuitionistic setting. The related phenomenon of counterfactual reasoning has been explored extensively in the context of belief revision and knowledge base updates (e:g:, [22, 30, 16, 41]).
Reference: 43. <author> R.L. Olson and R.H. Sprague Jr. </author> <title> Financial Planning in Action. </title> <editor> In R.H. Sprague Jr. and H.J. Watson, editors, </editor> <booktitle> Decisions Support Systems: Putting Theory into Practice, </booktitle> <pages> pages 373-381. </pages> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: 1. INTRODUCTION Researchers from several areas have recognized the need for computer systems that reason hypothetically. Decision support systems (DSS) are a good example, especially in domains like financial planning where many "what if" scenarios must be considered <ref> [29, 43] </ref>. A typical example is an analyst who must predict a company's deficit for the upcoming year assuming that employee salaries are increased by a given percentage. Or he might want a table of deficit predictions for a number of hypothetical salary increases [52, 53].
Reference: 44. <author> D.A. Schlobohm and L.T. McCarty. EPS-II: </author> <title> Estate planning with prototypes. </title> <booktitle> In Proceedings of the Second International Conference on Artificial Intelligence and Law, </booktitle> <pages> pages 1-10. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: And McCarty, also motivated by legal applications, has developed a wide class of hypothetical rules for computer-based consultation systems, especially systems for reasoning about corporate tax law and estate tax law <ref> [36, 38, 44] </ref>. In [6, 5], we investigated hypothetical reasoning in deductive databases. We considered rules that can hypothetically insert or delete facts from a database.
Reference: 45. <editor> Editor: A.P. Sheth. </editor> <booktitle> Database Research at Bellcore. SIGMOD Record, </booktitle> <volume> 19(3) </volume> <pages> 45-52, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Or he might want a table of deficit predictions for a number of hypothetical salary increases [52, 53]. Similar problems occur in computer aided design (CAD). Here, one must evaluate the effect on the overall design of local design alternatives and of various external factors <ref> [18, 45] </ref>. For example, an engineer may need to know how much the price of an automobile would increase if supplier X raised his prices by Y percent [18]. The number of hypothetical scenarios multiplies quickly when several factors are varied simultaneously, such as prices, interest rates, tax rates, etc.
Reference: 46. <author> R. Statman. </author> <title> Intuitionistic Propositional Logic is Polynomial-Space Complete. </title> <journal> Theoretical Computer Science (TCS), </journal> <volume> 9(1) </volume> <pages> 67-72, </pages> <year> 1979. </year>
Reference-contexts: Such rulebases might be called intuitionistic deductive databases. Several questions naturally arise. For instance, what is their data complexity, and what database queries can they express? Initial results along these lines were provided by Statman <ref> [46] </ref> for the propositional case, and by our own PSPACE results for hypothetical insertion [6]. In this paper, we 4 provide new results on semantics, and a comprehensive set of results on complexity and expressibility.
Reference: 47. <author> L.J. Stockmeyer. </author> <title> The Polynomial Time Hierarchy. </title> <journal> Theoretical Computer Science 47 (TCS), </journal> <volume> 3(1) </volume> <pages> 1-22, </pages> <year> 1976. </year>
Reference-contexts: Intuitionistic rulebases do not need this assumption, since they can generate linear orders on a domain hypothetically [6]. 5 Finally, we recall that the generic queries in PHIER are precisely the queries definable in second-order logic <ref> [47, 28] </ref>. We have therefore characterized the second-order definable queries in terms of intuitionistic deductive databases. 1.3. Introductory Examples A deductive database consists of a set of atomic formulas (the database) and a set of logical rules (the rulebase). <p> The polynomial-time hierarchy is a sequence of complexity classes between P and PSPACE. It is based on oracle Turing machines [25], and can be defined recursively as follows <ref> [47] </ref>: * P 0 = P. k+1 = P P k = those languages accepted in deterministic polynomial time by an oracle machine whose oracle is a language in P k . k+1 = NP P k = those languages accepted in non-deterministic polynomial time by an oracle machine whose oracle <p> This result provides a characterization of the generic queries in PHIER in terms of intuitionistic logic. It also provides a new characterization of the second-order definable queries, since the generic queries in PHIER are exactly the queries definable in second-order logic <ref> [47, 28] </ref>. In addition, we characterize the queries in each level, P k , of the hierarchy. 40 Unlike many expressibility results in the literature (e:g:, [27, 51, 12]), the results in this section do not assume that the data domain is linearly ordered. <p> Hence, Corollary 7.6. [Characterization of PHIER] Stratified linear rulebases of embedded implications that are constant-free express exactly the typed generic queries in the polynomial time hierarchy. The typed generic queries in PHIER are precisely the queries definable in second-order logic <ref> [47, 28] </ref>. This gives another characterization of the queries expressed by stratified linear rulebases. Corollary 7.7. [Second-Order Queries] Stratified linear rulebases of embedded implications that are constant-free express exactly the second-order definable queries.
Reference: 48. <author> M. Stonebraker. </author> <title> Hypothetical databases as views. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 224-229, </pages> <year> 1981. </year>
Reference-contexts: Hypothetical databases are derived from a real database by a series of hypothetical assumptions, or updates. Early work in this area was done by Stone-braker, who showed that hypothetical databases can be efficiently implemented by slight extensions to conventional database mechanisms <ref> [49, 48] </ref>. He pointed out that hypothetical databases are useful for debugging purposes, for generating test data, and for carrying out a variety of simulations. He also argued that "there are advantages to making hypothetical databases central to the operation of a database management system" [48]. <p> He pointed out that hypothetical databases are useful for debugging purposes, for generating test data, and for carrying out a variety of simulations. He also argued that "there are advantages to making hypothetical databases central to the operation of a database management system" <ref> [48] </ref>. The logic-programming community has taken these ideas one step further, integrating hypothetical updates not just with query processing, but with logical inference as well.
Reference: 49. <author> M. Stonebraker and K. Keller. </author> <title> Embedding expert knowledge and hypothetical databases into a data base system. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 58-66, </pages> <address> Santa Monica, CA, </address> <year> 1980. </year>
Reference-contexts: Hypothetical databases are derived from a real database by a series of hypothetical assumptions, or updates. Early work in this area was done by Stone-braker, who showed that hypothetical databases can be efficiently implemented by slight extensions to conventional database mechanisms <ref> [49, 48] </ref>. He pointed out that hypothetical databases are useful for debugging purposes, for generating test data, and for carrying out a variety of simulations. He also argued that "there are advantages to making hypothetical databases central to the operation of a database management system" [48].
Reference: 50. <author> M.H. Van Emden and R.A. Kowalski. </author> <title> The Semantics of Predicate Logic as a Programming Language. </title> <journal> Journal of the ACM, </journal> <volume> 23(4) </volume> <pages> 733-742, </pages> <year> 1976. </year>
Reference-contexts: PROVE P i is a bottom-up iterative procedure based on the bottom-up procedure for computing the least fixpoint of a Horn rulebase <ref> [50, 3] </ref>. The idea is to add inferred atoms to a set, S, until saturation is reached. Starting with S = DB , the procedure repeatedly applies ground instantiations of the rules in the i th stratum.
Reference: 51. <author> M. Vardi. </author> <title> The Complexity of Relational Query Languages. </title> <booktitle> In Proceedings of the ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 137-146, </pages> <year> 1982. </year>
Reference-contexts: This establishes a tight connection between two previously unrelated, but well-established areas: intuitionistic logic and the polynomial time hierarchy. Unlike many expressibility results in the literature (e:g:, <ref> [27, 51, 12] </ref>), these results do not assume that the data domain is linearly ordered. The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1]. <p> Formally, if is a database query, then its data-complexity is the complexity of the language fhx; DB i j x 2 (DB )g where x is a tuple, DB is a database, and (DB ) is the value of the query applied to DB <ref> [11, 51] </ref>. This language is called the graph of the query . The data complexity of a set of queries is the complexity of their graphs. When studying the data complexity of a query language, one looks for the most complex query in the language. <p> <ref> [11, 51] </ref>. This language is called the graph of the query . The data complexity of a set of queries is the complexity of their graphs. When studying the data complexity of a query language, one looks for the most complex query in the language. This motivates the following definition [11, 51]. Definition 4.3. A set of queries is data complete for a complexity class C if (1) the graph of each query is in C, and (2) there is some query in the set whose graph is a complete language for C. <p> In addition, we characterize the queries in each level, P k , of the hierarchy. 40 Unlike many expressibility results in the literature (e:g:, <ref> [27, 51, 12] </ref>), the results in this section do not assume that the data domain is linearly ordered. The assumption of ordered domains is a technical device that is often used to achieve expressibility results, but it is not an intrinsic feature of databases [1].
Reference: 52. <author> L. Vieille, P. Bayer, V. Kuchenhoff, and A. Lefebvre. EKS-V1, </author> <title> A Short Overview. </title> <booktitle> Presented at the AAAI-90 Workshop on Knowledge Base Management Systems, </booktitle> <address> July 1990, Boston, USA. </address>
Reference-contexts: A typical example is an analyst who must predict a company's deficit for the upcoming year assuming that employee salaries are increased by a given percentage. Or he might want a table of deficit predictions for a number of hypothetical salary increases <ref> [52, 53] </ref>. Similar problems occur in computer aided design (CAD). Here, one must evaluate the effect on the overall design of local design alternatives and of various external factors [18, 45]. <p> Since the premise of a logical rule is just a query, several researchers have developed hypothetical rules, in which the premise can query not only a real database, but hypothetical databases as well. Vieille, et al, for instance, have implemented a deductive database along these lines <ref> [52, 53] </ref>, and Warren and Manchanda have used hypothetical rules to reason about database updates [54, 33]. In [39], Miller shows that hypothetical insertions can structure the runtime environment of logic programs, resulting in programs that are more elegant, more efficient, and easier to maintain.
Reference: 53. <author> L. Vieille, P. Bayer, V. Kuchenhoff, A. Lefebvre, and R. Manthey. </author> <title> The EKS-V1 system. </title> <booktitle> In Proceedings of the International Conference on Logic Programming and Automated Reasoning (LPAR'92), number 624 in Lecture Notes in Computer Science, </booktitle> <pages> pages 504-506. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: A typical example is an analyst who must predict a company's deficit for the upcoming year assuming that employee salaries are increased by a given percentage. Or he might want a table of deficit predictions for a number of hypothetical salary increases <ref> [52, 53] </ref>. Similar problems occur in computer aided design (CAD). Here, one must evaluate the effect on the overall design of local design alternatives and of various external factors [18, 45]. <p> Since the premise of a logical rule is just a query, several researchers have developed hypothetical rules, in which the premise can query not only a real database, but hypothetical databases as well. Vieille, et al, for instance, have implemented a deductive database along these lines <ref> [52, 53] </ref>, and Warren and Manchanda have used hypothetical rules to reason about database updates [54, 33]. In [39], Miller shows that hypothetical insertions can structure the runtime environment of logic programs, resulting in programs that are more elegant, more efficient, and easier to maintain.
Reference: 54. <author> D.S. Warren. </author> <title> Database Updates in Pure Prolog. </title> <booktitle> In Proceedings of the International Conference on Fifth Generation Computer Systems, </booktitle> <pages> pages 244-253, </pages> <year> 1984. </year>
Reference-contexts: Vieille, et al, for instance, have implemented a deductive database along these lines [52, 53], and Warren and Manchanda have used hypothetical rules to reason about database updates <ref> [54, 33] </ref>. In [39], Miller shows that hypothetical insertions can structure the runtime environment of logic programs, resulting in programs that are more elegant, more efficient, and easier to maintain. In [40], he develops a theory of lexical scoping based on the hypothetical creation of constant symbols during inference.
References-found: 54

