URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-436.ps.Z
Refering-URL: http://www.cs.gatech.edu/computing/classes/cs7322_98_spring/readings.html
Root-URL: 
Email: (jdavis@media.mit.edu)  
Title: Virtual PAT: A Virtual Personal Aerobics Trainer  
Author: James W. Davis Aaron F. Bobick 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: MIT Media Laboratory,  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 436 Vision and Modeling group Abstract A prototype system for implementing a virtual Personal Aerobics Trainer (PAT) is presented. Unlike workout video tapes or TV exercise shows, this system allows the user to create and personalize an aerobics session to meet the user's needs and desires. Various media technology and computer vision algorithms are used to enhance the interaction of the character by enabling it to watch and talk to the user (instead of just the user watching the TV). Throughout the paper, we report the system components and discuss the advantages, problems, and extensions of the design. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Blumberg, B. </author> <title> Old tricks, new dogs: ethology and interactive cratures. </title> <type> PhD dissertation, </type> <institution> MIT Media Lab, MIT, </institution> <year> 1996. </year>
Reference-contexts: Here, the correct state of the instructor (e.g. doing jumping jacks while complementing the user) could be controlled and rendered at run-time. It might even be quite fun to have virtual cartoonish-like characters as the instructors. Each character could have their own "attitude" and behavior <ref> [1] </ref>, which would possibly increase the entertainment value of the system. But in this system, we chose to use stored movie clips for simplicity. While we use only one instructor (the Army Drill Sargent), the system is designed to have multiple instructors from which to choose.
Reference: [2] <author> A. Bobick, S. Intille, J. Davis, F. Baird, L. Cam-bell, Y. Ivanov, C. Pinhanez, A. Schutte, and A. Wilson. </author> <title> The KidsRoom: Action recognition in an interactive story environment. MIT Media Lab Perceptual Computing Group Technical Report No. 398, </title> <publisher> MIT, </publisher> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: This vision technology is different from many other sensing technologies in that the user need not wear any special devices or be tethered to machines with bundles of wires. This enables the experience to be more natural and desirable <ref> [2, 6, 4] </ref>. The underlying motivation for building such a system is that many forms of media that pretend to be interactive are in fact deaf, dumb, and blind. <p> One additional task of the vision system is to monitor the area and make sure someone is actually present in the space. A background-subtracted image of the room yielding only a silhouette of the person <ref> [2, 6] </ref> is used to track the location of the person. The tracking procedure simply follows the centroid of the silhouette and determines the location, within the video image, of the person.
Reference: [3] <author> Davis, J. and A. Bobick. </author> <title> The representation and recognition of human movement using temporal templates. </title> <booktitle> In Proc. Comp. Vis. and Pattern Rec., </booktitle> <pages> pages 928-934, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: We now explain the design of this system. 2 System design The PAT system is a modular design of media and vision components <ref> [3] </ref> (See Figure 2). All software 1 was written in C++ and run on SGI R10000 O2 computer systems (though we believe all the components could be placed within a much smaller hardware setup). <p> Also, if the person prematurely leaves the area during the workout session, the system recognizes that the person has left and correspondingly closes down the session. Recent work in computer vision has show promising results in recognizing large-scale aerobic movements <ref> [3] </ref>. This research uses temporally-collapsed motion templates to recognize various aerobic exercise (and other) movements in real-time. To ease in discussion here, we point the reader to [3] for details on the al-gorthim. We currently have six stretching and aerobic moves entered into the system. <p> Recent work in computer vision has show promising results in recognizing large-scale aerobic movements <ref> [3] </ref>. This research uses temporally-collapsed motion templates to recognize various aerobic exercise (and other) movements in real-time. To ease in discussion here, we point the reader to [3] for details on the al-gorthim. We currently have six stretching and aerobic moves entered into the system. For recognition of these moves from the computer vision module, the system was trained using six people performing multiple repetitions of the six moves.
Reference: [4] <author> Claudio S. Pinhanez, Kenji Mase, and Aaron F. Bobick. </author> <title> Interval scripts: A design paradigm for story-based interactive systems. </title> <booktitle> In CHI'97, </booktitle> <pages> pages 287-294, </pages> <address> Atlanta, Georgia, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: This vision technology is different from many other sensing technologies in that the user need not wear any special devices or be tethered to machines with bundles of wires. This enables the experience to be more natural and desirable <ref> [2, 6, 4] </ref>. The underlying motivation for building such a system is that many forms of media that pretend to be interactive are in fact deaf, dumb, and blind. <p> The system was designed so that each session is guided from a script which controls the flow of the session (as in <ref> [4] </ref>). Included in the script are the names for the workout moves, the time allotted for each move, the choice of music for the workout, and lastly the instructor to run the session. This allows the user to easily choose their own tailored workout.
Reference: [5] <author> Scheirer, E. </author> <title> Tempo and beat analysis of acoustic musical signals. </title> <publisher> Acoustic Society of America (in press), </publisher> <year> 1997. </year>
Reference-contexts: The tempo of the beats found then directly affect the speed of the instructor's example movie. We would like to note that there exists methods for accomplishing the above task using other musical media forms (e.g. CD), and such a method can be found in <ref> [5] </ref>. The MIDI songs are all queued up at the beginning of the session so one song plays immediately after another.
Reference: [6] <author> Wren, C., Azarbayejani, A., Darrell, T., and A. Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <booktitle> In SPIE Conference on Integration Issues in Large Commercial Media Delivery Systems, </booktitle> <year> 1995. </year>
Reference-contexts: This vision technology is different from many other sensing technologies in that the user need not wear any special devices or be tethered to machines with bundles of wires. This enables the experience to be more natural and desirable <ref> [2, 6, 4] </ref>. The underlying motivation for building such a system is that many forms of media that pretend to be interactive are in fact deaf, dumb, and blind. <p> One additional task of the vision system is to monitor the area and make sure someone is actually present in the space. A background-subtracted image of the room yielding only a silhouette of the person <ref> [2, 6] </ref> is used to track the location of the person. The tracking procedure simply follows the centroid of the silhouette and determines the location, within the video image, of the person.
References-found: 6

