URL: http://www.isi.edu/sims/papers/91-thesis.ps
Refering-URL: http://www.isi.edu/~knoblock/
Root-URL: 
Title: Automatically Generating Abstractions for Problem Solving  
Author: Craig Alan Knoblock Craig A. Knoblock 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in  
Note: Copyright c 1991  The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of the U. S. Government.  
Affiliation: Computer Science at Carnegie Mellon University.  
Date: May 1991  
Abstract: The author was supported by an Air Force Laboratory Graduate Fellowship through the Human Resources Laboratory at Brooks AFB. This research was sponsored by the Avionics Laboratory, Wright Research and Development Center, Aeronautical Systems Division (AFSC), U. S. Air Force, Wright-Patterson AFB, OH 45433-6543 under Contract F33615-90-C-1465, Arpa Order No. 7597. 
Abstract-found: 1
Intro-found: 1
Reference: [ Aho et al., 1974 ] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1974. </year>
Reference-contexts: By Theorems 4.2 and 4.3, the constraints are sufficient to guarantee that a hierarchy built from these constraints will have the ordered monotonicity property. * Step 2 finds the strongly connected components of the graph using a depth-first search <ref> [ Aho et al., 1974 ] </ref> . Two nodes in a directed graph are in the same strongly connected component if there is a path from one node to the other and back again. <p> The complexity of steps 2-5 in the algorithm above is linear in the size of the graph. The complexity of both finding the strongly connected components of a directed graph and performing the topological sort is O (max (e; v)) <ref> [ Aho et al., 1974 ] </ref> , where e is the number of edges (constraints) and v is the number of vertices (literals). Creating the reduced graph is also O (max (e; v)) since the new graph can be created by scanning through each of the vertices and edges once.
Reference: [ Aho et al., 1983 ] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year>
Reference-contexts: The literals within a node in the reduced graph must be placed in the same abstraction space and the constraints between nodes define a partial order of the possible abstraction hierarchies. * Step 4 transforms the partial order into a total order using a topological sort <ref> [ Aho et al., 1983 ] </ref> . The total order defines a single ordered monotonic abstraction hierarchy. There may be a number of possible total orders for a given partial order and one order may be better than another.
Reference: [ Amarel, 1968 ] <author> Saul Amarel. </author> <title> On representations of problems of reasoning about actions. </title> <editor> In Donald Michie, editor, </editor> <booktitle> Machine Intelligence 3, </booktitle> <pages> pages 131-171. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <address> Scotland, </address> <year> 1968. </year>
Reference-contexts: Problem reduction is a related technique, where a problem is replaced by a number of easier to solve subproblems <ref> [ Amarel, 1968 ] </ref> . Riddle [ 1990 ] developed a system that automates this type of problem reformulation by analyzing example solutions and identifying the "critical" subgoals of a problem, which correspond to the most constrained subgoals. This approach success 6.2.
Reference: [ Amarel, 1984 ] <author> Saul Amarel. </author> <title> Expert behaviour and problem representations. </title> <booktitle> In Artificial and Human Intelligence, </booktitle> <pages> pages 1-41. </pages> <publisher> North-Holland, </publisher> <address> New York, NY, </address> <year> 1984. </year>
Reference-contexts: To illustrate this point, consider a variant of the Tower of Hanoi problem that has the additional restriction that no disk can be moved twice in a row alpine produces modest improvements in both search time and solution quality. 92 CHAPTER 5. EMPIRICAL RESULTS <ref> [ Anzai and Simon, 1979, Amarel, 1984, VanLehn, 1989 ] </ref> . This constrains the problem considerably since the suboptimal plans in the previous graph were caused by moving a disk to the wrong peg and then moving the same disk again.
Reference: [ Anderson and Farley, 1988 ] <author> John S. Anderson and Arthur M. Farley. </author> <title> Plan abstraction based on operator generalization. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 100-104, </pages> <address> Saint Paul, Minnesota, </address> <year> 1988. </year>
Reference: [ Anzai and Simon, 1979 ] <author> Yuichiro Anzai and Herbert A. Simon. </author> <title> The theory of learning by doing. </title> <journal> Psychological Review, </journal> <volume> 86 </volume> <pages> 124-140, </pages> <year> 1979. </year>
Reference-contexts: To illustrate this point, consider a variant of the Tower of Hanoi problem that has the additional restriction that no disk can be moved twice in a row alpine produces modest improvements in both search time and solution quality. 92 CHAPTER 5. EMPIRICAL RESULTS <ref> [ Anzai and Simon, 1979, Amarel, 1984, VanLehn, 1989 ] </ref> . This constrains the problem considerably since the suboptimal plans in the previous graph were caused by moving a disk to the wrong peg and then moving the same disk again.
Reference: [ Banerji and Ernst, 1977a ] <author> Ranan B. Banerji and George W. Ernst. </author> <title> A comparison of three problem-solving methods. </title> <booktitle> In Proceedings of the Fifth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 442-449, </pages> <address> Cambridge, MA, </address> <year> 1977. </year>
Reference: [ Banerji and Ernst, 1977b ] <author> Ranan B. Banerji and George W. Ernst. </author> <title> Some properties of GPS-type problem solvers. </title> <type> Technical Report 1179, </type> <institution> Department of Computer Engineering, Case Western Reserve University, </institution> <year> 1977. </year>
Reference: [ Benjamin et al., 1990 ] <author> Paul Benjamin, Leo Dorst, Indur Mandhyan, and Madeleine Rosar. </author> <title> An introduction to the decomposition of task representations in autonomous systems. </title> <editor> In D. Paul Benjamin, editor, </editor> <booktitle> Change of Representation and Inductive Bias, </booktitle> <pages> pages 125-146. </pages> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1990. </year> <note> 189 190 BIBLIOGRAPHY </note>
Reference: [ Campbell, 1988 ] <author> Murray S. Campbell. </author> <title> Chunking as an Abstraction Mechanism. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <year> 1988. </year>
Reference-contexts: This aggregation is equivalent to the abstraction of the Tower of Hanoi described in Section 3.4, but it is generated by a very different means. There has also been work on automatically generating aggregations for chess. One system, called chunker <ref> [ Campbell, 1988 ] </ref> , groups pawn configurations into chunks and then plans in the abstract space by reasoning about the interactions between pawn chunks.
Reference: [ Carbonell and Gil, 1990 ] <author> Jaime G. Carbonell and Yolanda Gil. </author> <title> Learning by experimentation: The operator refinement method. </title> <booktitle> In Machine Learning, An Artificial Intelligence Approach, Volume III, </booktitle> <pages> pages 191-213. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: HIERARCHICAL PROBLEM SOLVING 3 learning [ Etzioni, 1990 ] , learning by analogy [ Veloso and Carbonell, 1990 ] , learning by experimentation <ref> [ Carbonell and Gil, 1990 ] </ref> , graphical knowledge acquisition [ Joseph, 1989 ] , and abstraction generation. While this thesis describes only the problem solving and abstraction generation components of prodigy, it does provide comparisons with the explanation-based and static learning modules. <p> PROBLEM SOLVING riety of learning mechanisms. In addition to the automatic generation of abstractions described in this thesis, prodigy includes modules for explanation-based learning [ Minton, 1988a ] , static learning [ Etzioni, 1990 ] , learning by analogy [ Veloso and Car-bonell, 1990 ] , learning by experimentation <ref> [ Carbonell and Gil, 1990 ] </ref> , and graphical knowledge acquisition [ Joseph, 1989 ] . prodigy has been applied to a variety of domains including the blocks world [ Nilsson, 1980 ] , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain
Reference: [ Carbonell et al., 1991 ] <author> Jaime G. Carbonell, Craig A. Knoblock, and Steven Minton. </author> <title> PRODIGY: An integrated architecture for planning and learning. </title> <editor> In Kurt Van-Lehn, editor, </editor> <booktitle> Architectures for Intelligence, </booktitle> <pages> pages 241-278. </pages> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1991. </year>
Reference-contexts: This process is repeated until the initial state is transformed into a state that satisfies the goal. Other means-ends analysis problem solvers include strips [ Fikes and Nilsson, 1971 ] and prodigy <ref> [ Carbonell et al., 1991 ] </ref> . A least-commitment problem solver, which was first implemented in noah [ Sac-erdoti, 1977 ] , searches through the space of plan refinements, instead of searching the state space, in order to build a partially ordered sequence of operators that solves a given problem.
Reference: [ Carbonell, 1986 ] <author> Jaime G. Carbonell. </author> <title> Derivational analogy: A theory of reconstructive problem solving and expertise acquisition. </title> <booktitle> In Machine Learning, An Artificial Intelligence Approach, </booktitle> <volume> Volume II, </volume> <pages> pages 371-392. </pages> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1986. </year>
Reference-contexts: This makes it easier to combine the use of abstraction with other types of problem-space learning such as explanation-based learning [ Minton, 1988b ] , macro-operator learning [ Korf, 1985b ] , or learning by analogy <ref> [ Carbonell, 1986 ] </ref> . Fourth, creating a reduced model allows operators and objects that are indistinguishable at an abstract level to be combined into abstract operators or objects.
Reference: [ Chapman, 1987 ] <author> David Chapman. </author> <title> Planning for conjunctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32(3) </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: Least-Commmitment Hierarchical Problem Solving The model of hierarchical problem solving described in Chapter 3 is based on a state-space problem solver. An alternative is to use a least-commitment approach to problem solving <ref> [ Sacerdoti, 1977, Chapman, 1987 ] </ref> , which searches through the space of plan refinements instead of searching through the state space. This approach is referred to as a least-commitment approach because ordering commitments are delayed as long as possible.
Reference: [ Cheng and Irani, 1989 ] <author> Jie Cheng and Keki B. Irani. </author> <title> Ordering problem subgoals. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 931-936, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: In contrast, alpine produces a single hierarchy for the four-disk problem, which orders the disks from largest to smallest. Irani and Cheng <ref> [ Irani and Cheng, 1987, Cheng and Irani, 1989 ] </ref> present an approach to both ordering goals and augmenting the goals with additional information. The goal orderings are based on necessary interactions determined statically from the 120 CHAPTER 6. RELATED WORK operator definitions.
Reference: [ Christensen, 1990 ] <author> Jens Christensen. </author> <title> A hierarchical planner that creates its own hierarchies. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1004-1009, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: The augmented and ordered goals are then used in an admissible heuristic evaluation function. The augmentation of the goals is similar to the goal augmentation performed in alpine (Section 4.4.3), but the approach to ordering the goals is much more similar to the analysis in pablo <ref> [ Christensen, 1990 ] </ref> . In addition, the use of the goal orderings is more similar to the way abstractions are used in absolver [ Mostow and Prieditis, 1989 ] .
Reference: [ Eavarone, 1969 ] <author> Daniel S. Eavarone. </author> <title> A program that generates difference orderings for GPS. </title> <type> Technical Report SRC-69-6, </type> <institution> Systems Research Center, Case Western Reserve University, </institution> <year> 1969. </year>
Reference-contexts: The problem solving proceeds by attempting to reduce the differences between the initial state and goal. The problem of finding good orderings of the differences has been extensively explored in gps <ref> [ Eavarone, 1969, Goldstein, 1978, Ernst and Goldstein, 1982 ] </ref> . The criterion for ordering the differences is to attempt to find an ordering such that achieving one difference will not affect a difference reduced by operators selected earlier in the ordering. <p> For example, in the Tower of Hanoi the techniques for producing good difference orders for gps is only able to identify the positions of the different sized disks as good differences, but cannot produce a useful ordering of the disks. <ref> [ Eavarone, 1969 ] </ref> presents a program that produces 24 possible difference orderings for the four-disk problem without any preferences among them. In contrast, alpine produces a single hierarchy for the four-disk problem, which orders the disks from largest to smallest.
Reference: [ Ernst and Goldstein, 1982 ] <author> George W. Ernst and Michael M. Goldstein. </author> <title> Mechanical discovery of classes of problem-solving strategies. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 29(1) </volume> <pages> 1-23, </pages> <year> 1982. </year>
Reference-contexts: The problem solving proceeds by attempting to reduce the differences between the initial state and goal. The problem of finding good orderings of the differences has been extensively explored in gps <ref> [ Eavarone, 1969, Goldstein, 1978, Ernst and Goldstein, 1982 ] </ref> . The criterion for ordering the differences is to attempt to find an ordering such that achieving one difference will not affect a difference reduced by operators selected earlier in the ordering.
Reference: [ Ernst and Newell, 1969 ] <author> George W. Ernst and Allen Newell. </author> <title> GPS: A Case Study in Generality and Problem Solving. </title> <booktitle> ACM Monograph Series. </booktitle> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1969. </year>
Reference-contexts: On a first reading, the reader may want to skim the formal definitions and proofs. Chapter 2 Problem Solving Problem solving is a process that has been widely studied in AI from the early days of gps <ref> [ Newell et al., 1962, Ernst and Newell, 1969 ] </ref> and strips [ Fikes and Nilsson, 1971 ] to more recent planners such as sipe [ Wilkins, 1984 ] , soar [ Laird et al., 1987 ] and prodigy [ Minton et al., 1989b, Minton et al., 1989a, Carbonell et al., <p> This section reviews only the work that employs techniques for goal ordering that are related to the abstraction generation techniques described in this thesis. gps <ref> [ Ernst and Newell, 1969 ] </ref> is a means-ends analysis problem solver, which employs a table of differences to select relevant operators and thus focus the search. The problem solving proceeds by attempting to reduce the differences between the initial state and goal.
Reference: [ Ernst, 1969 ] <author> George W. Ernst. </author> <title> Sufficient conditions for the success of GPS. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 16(4) </volume> <pages> 517-533, </pages> <year> 1969. </year> <note> BIBLIOGRAPHY 191 </note>
Reference-contexts: Also, the control rules are used to guide the search in the original space, while the abstractions are used for hierarchical problem solving. 6.3 Properties of Abstractions Banerji and Ernst [ 1977a, 1977b ] compared three similar problem solvers, gps <ref> [ Ernst, 1969 ] </ref> , Planning gps [ Newell and Simon, 1972 ] , and abstrips [ Sacerdoti, 1974 ] . They developed a formal model of these systems that makes some additional assumptions not actually present in the three problem solvers. <p> A well-stratified problem is one that, for a given abstraction hierarchy, can be divided up into subproblems and solved strictly in the order imposed by the hierarchy. They go on to show that if a problem is well-stratified, then it has a totally ordered solution <ref> [ Ernst, 1969 ] </ref> , which requires that once a difference is reduced it need not be reintroduced to solve the problem. Ernst [ 1969 ] showed that the combination of 6.3.
Reference: [ Etzioni, 1990 ] <author> Oren Etzioni. </author> <title> A Structural Theory of Explanation-Based Learning. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1990. </year> <note> Available as Technical Report CMU-CS-90-185. </note>
Reference-contexts: In addition to the basic problem solver, prodigy consists of a number of learning modules, including modules for explanation-based learning [ Minton, 1988a ] , static 1.2. HIERARCHICAL PROBLEM SOLVING 3 learning <ref> [ Etzioni, 1990 ] </ref> , learning by analogy [ Veloso and Carbonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , graphical knowledge acquisition [ Joseph, 1989 ] , and abstraction generation. <p> PROBLEM SOLVING riety of learning mechanisms. In addition to the automatic generation of abstractions described in this thesis, prodigy includes modules for explanation-based learning [ Minton, 1988a ] , static learning <ref> [ Etzioni, 1990 ] </ref> , learning by analogy [ Veloso and Car-bonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , and graphical knowledge acquisition [ Joseph, 1989 ] . prodigy has been applied to a variety of domains including the blocks world [ Nilsson, 1980 ] <p> Control knowledge is acquired through experience as in EBL [ Minton, 1988a ] and derivational analogy [ Veloso and Carbonell, 1990 ] or through problem-space analysis as in static <ref> [ Etzioni, 1990 ] </ref> and alpine (described in the following chapters). 24 CHAPTER 2. PROBLEM SOLVING Chapter 3 Hierarchical Problem Solving Abstraction has been used to reduce search in a variety of problem solvers. <p> In addition, the use of the goal orderings is more similar to the way abstractions are used in absolver [ Mostow and Prieditis, 1989 ] . Etzioni <ref> [ Etzioni, 1990 ] </ref> developed a system called static, which statically analyzes the problem space definition to identify potential interactions. Based on these interactions, static generates a set of search control rules for prodigy to guide the problem solving. <p> move another disk, there are only two places to move the disk, one of which is the "right" place and the other will interfere with the placement of another disk. ebl is particularly good at recognizing this type of interaction, called a 1 alpine could also be combined with static <ref> [ Etzioni, 1990 ] </ref> , which performs static analysis of a problem space to produce control knowledge. The integration of alpine and static would be analogous to combining alpine with ebl. 7.3. USING ABSTRACTIONS 133 prerequisite violation, and learning control rules to avoid them. <p> The second set of six tables below compares prodigy with the control rules produced by ebl [ Minton, 1988a ] , prodigy with the control rules produced by static <ref> [ Etzioni, 1990 ] </ref> , and prodigy with both the hand-code control rules and the abstractions produced by alpine. The first 100 problems in each set of tables are the test problems used in Minton's experiments [ Minton, 1988a ] .
Reference: [ Fikes and Nilsson, 1971 ] <author> Richard E. Fikes and Nils J. Nilsson. </author> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> 2(3/4):189-208, 1971. 
Reference-contexts: However, what makes a good abstraction for one problem may make a bad abstraction for another. Thus, the algorithm presented in the thesis generates abstraction hierarchies that are tailored to the individual problems. For example, the strips robot planning domain <ref> [ Fikes and Nilsson, 1971 ] </ref> involves using a robot to move boxes among rooms and opening and closing doors as necessary. For problems that simply involve moving boxes between rooms, doors are a detail that can be ignored since the robot can simply open the doors as needed. <p> The algorithm for generating abstractions is implemented in the alpine system. Given a problem space and problem, alpine generates an abstraction hierarchy for the hierarchical version of prodigy. The system has been successfully tested on a number of problem-solving domains including the original strips domain <ref> [ Fikes and Nilsson, 1971 ] </ref> , a more complex robot planning domain [ Minton, 1988a ] , and a machine-shop planning and scheduling domain [ Minton, 1988a ] . <p> On a first reading, the reader may want to skim the formal definitions and proofs. Chapter 2 Problem Solving Problem solving is a process that has been widely studied in AI from the early days of gps [ Newell et al., 1962, Ernst and Newell, 1969 ] and strips <ref> [ Fikes and Nilsson, 1971 ] </ref> to more recent planners such as sipe [ Wilkins, 1984 ] , soar [ Laird et al., 1987 ] and prodigy [ Minton et al., 1989b, Minton et al., 1989a, Carbonell et al., 1991 ] . <p> Otherwise the problem solver attempts to reduce the differences between the current state and the state in which the selected operator can be applied. This process is repeated until the initial state is transformed into a state that satisfies the goal. Other means-ends analysis problem solvers include strips <ref> [ Fikes and Nilsson, 1971 ] </ref> and prodigy [ Carbonell et al., 1991 ] . <p> learning by analogy [ Veloso and Car-bonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , and graphical knowledge acquisition [ Joseph, 1989 ] . prodigy has been applied to a variety of domains including the blocks world [ Nilsson, 1980 ] , the strips domain <ref> [ Fikes and Nilsson, 1971 ] </ref> , an augmented version of the strips domain [ Minton, 1988a ] , discrete machine-shop planning and scheduling domain [ Minton, 1988a ] , a brewery scheduling domain [ Wilkins, 1989 ] , and a computer configuration domain [ McDermott, 1982, Rosenbloom et al., 1985 <p> Note that this restriction only applies to those goals that arise as a conjunctive set of goals, either as a conjunction of top-level goals or as a conjunctive set of preconditions to an operator. Consider an example from the strips robot planning domain <ref> [ Fikes and Nilsson, 1971 ] </ref> . In this domain a robot can move between rooms, pushing boxes and opening 38 CHAPTER 3. HIERARCHICAL PROBLEM SOLVING and closing doors. <p> These results are described in Chapter 5. To illustrate the ideas in this section, examples from the extended robot planning domain are used. This domain is an augmented version of the original strips robot planning domain <ref> [ Fikes and Nilsson, 1971 ] </ref> . In the original domain a robot can move among rooms, push boxes around, and open and close doors. In the augmented version, the robot can both push and carry objects and lock and unlock doors. <p> This domain is an extended version of the strips robot planning domain <ref> [ Fikes and Nilsson, 1971 ] </ref> and includes locks, keys, and a robot that can both push and carry objects. <p> EMPIRICAL RESULTS automate the construction of abstraction hierarchies for problem solving and was only applied to the strips robot planning domain. The resulting abstraction hierarchies were then used for problem solving in an extended version of the strips planner <ref> [ Fikes and Nilsson, 1971 ] </ref> . This section compares the abstraction hierarchy generated by abstrips to the dynamically-tailored abstraction hierarchies generated by alpine in the strips domain. <p> 415 0 2.3 245 0.2 1 0 0.2 1 0 2.3 1 0 2.1 247 0.1 1 0 0.2 1 0 2.6 1 0 2.9 249 0.1 1 0 0.1 1 0 7.5 69 0 2.1 Appendix D STRIPS Robot Planning Domain This is the original strips robot planning domain <ref> [ Fikes and Nilsson, 1971 ] </ref> as it is encoded in prodigy. The only differences are that the variable arguments are typed and the deletes are changed into conditional deletes. The numbers after the precon ditions are the criticalities that abstrips assigned and are used in the comparison with alpine.
Reference: [ Fikes et al., 1972 ] <author> Richard E. Fikes, Peter E. Hart, and Nils J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3(4) </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference: [ Flann, 1989 ] <author> Nicholas S. Flann. </author> <title> Learning appropriate abstractions for planning in formation problems. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 235-239, </pages> <address> Ithaca, NY, </address> <year> 1989. </year>
Reference-contexts: There has also been work on automatically generating aggregations for chess. One system, called chunker [ Campbell, 1988 ] , groups pawn configurations into chunks and then plans in the abstract space by reasoning about the interactions between pawn chunks. Another system, called place <ref> [ Flann, 1989 ] </ref> , forms aggregate objects, operators, and goals using an explanation-based generalization approach. 6.2.3 Problem Reductions In many systems, abstraction spaces are used to find an abstract solution, which can then be used to divide a problem into a number of subproblems.
Reference: [ Giunchiglia and Walsh, 1990 ] <author> Fausto Giunchiglia and Toby Walsh. </author> <title> A theory of abstraction. </title> <type> Technical Report 9001-14, </type> <institution> Istituto per la Ricerca Scientifica e Techno-logica, Trento, Italy, </institution> <year> 1990. </year>
Reference-contexts: In general, using an abstraction space formed by dropping information it is impossible to guarantee this property. The same problem arises in the use of abstraction in theorem proving, where it is called the false proof problem <ref> [ Plaisted, 1981, Giunchiglia and Walsh, 1990 ] </ref> . Since the downward solution property does not hold in general, there is no guarantee that a refinement of the abstract solution exists. To make matters worse, there are a potentially infinite number of possible refinements of each abstract plan.
Reference: [ Goldstein, 1978 ] <author> Michael M. Goldstein. </author> <title> The mechanical discovery of problem solving strategies. </title> <type> Technical Report ESCI-77-1, </type> <institution> Systems Engineering, Computer Engineering and Information Sciences, Case Western Reserve University, </institution> <year> 1978. </year>
Reference-contexts: The problem solving proceeds by attempting to reduce the differences between the initial state and goal. The problem of finding good orderings of the differences has been extensively explored in gps <ref> [ Eavarone, 1969, Goldstein, 1978, Ernst and Goldstein, 1982 ] </ref> . The criterion for ordering the differences is to attempt to find an ordering such that achieving one difference will not affect a difference reduced by operators selected earlier in the ordering.
Reference: [ Guvenir and Ernst, 1990 ] <author> H. Altay Guvenir and George W. Ernst. </author> <title> Learning problem solving strategies using refinement and macro generation. </title> <journal> Artificial Intelligence, </journal> <volume> 44(1-2):209-243, </volume> <year> 1990. </year>
Reference: [ Hansson and Mayer, 1989 ] <author> Othar Hansson and Andrew Mayer. </author> <title> Subgoal generation from problem relaxation. </title> <booktitle> In Proceedings of the AAAI Symposium on Planning and Search, </booktitle> <year> 1989. </year>
Reference: [ Hobbs, 1985 ] <author> Jerry R. Hobbs. </author> <title> Granularity. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 432-435, </pages> <address> Los Angeles, CA, </address> <year> 1985. </year>
Reference: [ Iba, 1989 ] <author> Glenn A. Iba. </author> <title> A heuristic approach to the discovery of macro-operators. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 285-317, </pages> <year> 1989. </year>
Reference: [ Irani and Cheng, 1987 ] <author> Keki B. Irani and Jie Cheng. </author> <title> Subgoal ordering and goal augmentation for heuristic problem solving. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1018-1024, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference-contexts: In contrast, alpine produces a single hierarchy for the four-disk problem, which orders the disks from largest to smallest. Irani and Cheng <ref> [ Irani and Cheng, 1987, Cheng and Irani, 1989 ] </ref> present an approach to both ordering goals and augmenting the goals with additional information. The goal orderings are based on necessary interactions determined statically from the 120 CHAPTER 6. RELATED WORK operator definitions.
Reference: [ Joseph, 1989 ] <author> Robert L. Joseph. </author> <title> Graphical knowledge acquisition. </title> <booktitle> In Proceedings of the Fourth Knowledge Acquisition For Knowledge-Based Systems Workshop, </booktitle> <address> Banff, Canada, </address> <year> 1989. </year> <note> 192 BIBLIOGRAPHY </note>
Reference-contexts: HIERARCHICAL PROBLEM SOLVING 3 learning [ Etzioni, 1990 ] , learning by analogy [ Veloso and Carbonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , graphical knowledge acquisition <ref> [ Joseph, 1989 ] </ref> , and abstraction generation. While this thesis describes only the problem solving and abstraction generation components of prodigy, it does provide comparisons with the explanation-based and static learning modules. <p> automatic generation of abstractions described in this thesis, prodigy includes modules for explanation-based learning [ Minton, 1988a ] , static learning [ Etzioni, 1990 ] , learning by analogy [ Veloso and Car-bonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , and graphical knowledge acquisition <ref> [ Joseph, 1989 ] </ref> . prodigy has been applied to a variety of domains including the blocks world [ Nilsson, 1980 ] , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain [ Minton, 1988a ] , discrete machine-shop planning and scheduling domain
Reference: [ Joslin and Roach, 1989 ] <author> David Joslin and John Roach. </author> <title> A theoretical analysis of conjunctive-goal problems. </title> <journal> Artificial Intelligence, </journal> <volume> 41(1) </volume> <pages> 97-106, </pages> <year> 1989. </year>
Reference-contexts: However, this is not a necessary condition since a nonlinear subproblem can be solved by the nonhierarchical problem solver P, which is assumed to be complete. (See <ref> [ Joslin and Roach, 1989 ] </ref> for a precise characterization of linear and nonlinear problems.) A problem is linearizable relative to an abstraction hierarchy if every conjunctive set of goals that arises while solving the problem can be solved in the order that the goals appear in the levels of the <p> At this point the problem solver would need to either backtrack or insert additional steps for closing the door again. In fact, the original abstrips system would not have even noticed that it had violated the precondition, and would simply produce an incorrect plan <ref> [ Joslin and Roach, 1989, pg.100 ] </ref> . alpine would first solve this problem in the abstract space by generating the plan for moving the boxes into the appropriate rooms. At the next level it would deal with both closing the doors and moving the robot.
Reference: [ Kaplan and Simon, 1990 ] <author> Craig A. Kaplan and Herbert A. Simon. </author> <title> In search of insight. </title> <journal> Cognitive Psychology, </journal> <volume> 22 </volume> <pages> 374-419, </pages> <year> 1990. </year>
Reference-contexts: To solve this problem does not require search in either the state space or the plan space, but search through the space of possible problem spaces <ref> [ Kaplan and Simon, 1990 ] </ref> .
Reference: [ Kibler, 1985 ] <author> Dennis Kibler. </author> <title> Natural generation of heuristics by transforming the problem representation. </title> <type> Technical Report TR-85-20, </type> <institution> Department of Computer Science, University of California at Irvine, </institution> <year> 1985. </year>
Reference-contexts: The resulting abstract models are then tested to see if they provide useful abstractions for use in an admissible search procedure <ref> [ Pearl, 1984, Kibler, 1985 ] </ref> . The reduced or relaxed models are used to compute lower bounds and check solvability. The abstraction transformations include dropping preconditions, dropping goals, and dropping predicates from the problem space. The abstractions are selected using a generate-and-test procedure.
Reference: [ Knoblock et al., 1990 ] <author> Craig A. Knoblock, Josh D. Tenenberg, and Qiang Yang. </author> <title> A spectrum of abstraction hierarchies for planning. In Proceedings of the Workshop on Automatic Generation of Approximations and Abstractions, </title> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: these definitions, this section provides restrictions on the possible abstraction 1 The properties and algorithms described in this section are my own [ Knoblock, 1990c, Knoblock, 1990b ] , but the formal definitions in this section were joint work with Josh Tenenberg and Qiang Yang and are also described in <ref> [ Knoblock et al., 1990, Knoblock et al., 1991b ] </ref> . 55 56 CHAPTER 4. GENERATING ABSTRACTIONS hierarchies that are sufficient to guarantee these properties.
Reference: [ Knoblock et al., 1991a ] <author> Craig A. Knoblock, Steven Minton, and Oren Etzioni. </author> <title> Integrating abstraction and explanation-based learning in PRODIGY. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 541-546, </pages> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference-contexts: node (noton diskA peg1)) (candidate-op node move-disk-A-peg-1-2) (alt-on-deck node (on diskB peg2) move-disk-B-peg1-2) (candidate-op node op) (not-equal move-disk-A-peg-1-2 op))) (then (prefer operator op move-disk-A-peg-1-2)) Table 7.2: Control Rule Learned by ebl in an Abstract Space The combination of the two techniques produces performance improvements that neither system can achieve independently <ref> [ Knoblock et al., 1991a ] </ref> . In the Tower of Hanoi the abstraction module can reduce the search from exponential-to-linear in the solution length, but it cannot completely eliminate the search within each abstraction level.
Reference: [ Knoblock et al., 1991b ] <author> Craig A. Knoblock, Josh D. Tenenberg, and Qiang Yang. </author> <title> Characterizing abstraction hierarchies for planning. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 692-697, </pages> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference-contexts: these definitions, this section provides restrictions on the possible abstraction 1 The properties and algorithms described in this section are my own [ Knoblock, 1990c, Knoblock, 1990b ] , but the formal definitions in this section were joint work with Josh Tenenberg and Qiang Yang and are also described in <ref> [ Knoblock et al., 1990, Knoblock et al., 1991b ] </ref> . 55 56 CHAPTER 4. GENERATING ABSTRACTIONS hierarchies that are sufficient to guarantee these properties.
Reference: [ Knoblock, 1990a ] <author> Craig A. Knoblock. </author> <title> Abstracting the Tower of Hanoi. </title> <booktitle> In Proceedings of the Workshop on Automatic Generation of Approximations and Abstractions, </booktitle> <pages> pages 13-23, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: An algorithm that implements this restriction is shown in Table 4.2. The algorithm is similar to the problem-independent one, but forms the constraints based on a particular set of goals to solve. 2 Thanks to Charles Elkan for pointing out that my original O (d 2 ) algorithm <ref> [ Knoblock, 1990a ] </ref> could be transformed into a linear algorithm. 68 CHAPTER 4. GENERATING ABSTRACTIONS The algorithm is given the operators and the goals of the problem to be solved and it returns a directed graph of the constraints on the abstraction hierarchy.
Reference: [ Knoblock, 1990b ] <author> Craig A. Knoblock. </author> <title> Learning abstraction hierarchies for problem solving. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 923-928, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: These properties are first described informally and then defined formally. 1 Along with these definitions, this section provides restrictions on the possible abstraction 1 The properties and algorithms described in this section are my own <ref> [ Knoblock, 1990c, Knoblock, 1990b ] </ref> , but the formal definitions in this section were joint work with Josh Tenenberg and Qiang Yang and are also described in [ Knoblock et al., 1990, Knoblock et al., 1991b ] . 55 56 CHAPTER 4.
Reference: [ Knoblock, 1990c ] <author> Craig A. Knoblock. </author> <title> A theory of abstraction for hierarchical planning. </title> <editor> In D. Paul Benjamin, editor, </editor> <booktitle> Change of Representation and Inductive Bias, </booktitle> <pages> pages 81-104. </pages> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: These properties are first described informally and then defined formally. 1 Along with these definitions, this section provides restrictions on the possible abstraction 1 The properties and algorithms described in this section are my own <ref> [ Knoblock, 1990c, Knoblock, 1990b ] </ref> , but the formal definitions in this section were joint work with Josh Tenenberg and Qiang Yang and are also described in [ Knoblock et al., 1990, Knoblock et al., 1991b ] . 55 56 CHAPTER 4.
Reference: [ Knoblock, 1991 ] <author> Craig A. Knoblock. </author> <title> Search reduction in hierarchical problem solving. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 686-691, </pages> <address> Anaheim, CA, </address> <year> 1991. </year>
Reference-contexts: approach is that the worst-case complexity of hierarchical problem solver will be increased because the problems can no longer be decomposed into smaller independent subproblems. 3.3 Analysis of the Search Reduction This section presents a complexity analysis of single-level problem solving, two-level hierarchical problem solving, and multi-level hierarchical problem solving <ref> [ Knoblock, 1991 ] </ref> . The last part of this section identifies under precisely what assumptions hierarchical problem solving can reduce an exponential search to a linear one.
Reference: [ Korf, 1980 ] <author> Richard E. Korf. </author> <title> Toward a model of representation changes. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 41-78, </pages> <year> 1980. </year>
Reference-contexts: While there are advantages of reduced models over relaxed models, they are similar in that the same basic techniques for generating and using abstractions apply to either model. Relaxed and reduced models are both homomorphisms <ref> [ Korf, 1980 ] </ref> of a problem space, which means that information is discarded in the process of constructing these models.
Reference: [ Korf, 1985a ] <author> Richard E. Korf. </author> <title> Depth-first iterative-deepening: An optimal admissible tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 27(1) </volume> <pages> 97-109, </pages> <year> 1985. </year> <note> BIBLIOGRAPHY 193 </note>
Reference-contexts: Since the size of the search spaces are potentially infinite, the analysis assumes the use of a brute-force search procedure that is bounded by the length of the solution (e.g., depth-first iterative-deepening <ref> [ Korf, 1985a ] </ref> ). The analysis is similar to the analysis of abstraction planning with macros by Korf [ 1987 ] . Korf showed that the use of a hierarchy of macros can reduce an exponential search to a linear one.
Reference: [ Korf, 1985b ] <author> Richard E. Korf. Macro-operators: </author> <title> A weak method for learning. </title> <journal> Artificial Intelligence, </journal> <volume> 26(1) </volume> <pages> 35-77, </pages> <year> 1985. </year>
Reference-contexts: This makes it easier to combine the use of abstraction with other types of problem-space learning such as explanation-based learning [ Minton, 1988b ] , macro-operator learning <ref> [ Korf, 1985b ] </ref> , or learning by analogy [ Carbonell, 1986 ] . Fourth, creating a reduced model allows operators and objects that are indistinguishable at an abstract level to be combined into abstract operators or objects. <p> This is not surprising since the restrictions on a problem that are needed to guarantee completeness (Section 3.2) are equivalent to requiring that a problem is well-stratified. In Korf's work on generating macros <ref> [ Korf, 1985b ] </ref> , he identified a property called serial decomposability, which is sufficient to guarantee that a set of macros can serialize a problem.
Reference: [ Korf, 1987 ] <author> Richard E. Korf. </author> <title> Planning as search: A quantitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 65-88, </pages> <year> 1987. </year>
Reference-contexts: Instead of abstracting operators to form an abstract problem space, operators are combined into macro operators to form a macro problem space <ref> [ Korf, 1987 ] </ref> . This approach is similar to using abstraction spaces in that a problem is mapped into an abstract space, which is defined by a set of macro operators, and then solved in the abstract space. <p> However, unlike the use of abstract problem spaces, once a problem is solved in the macro space, the problem is completely solved since the macros are defined by operators in the original problem space. Korf <ref> [ Korf, 1987 ] </ref> shows that a single level of abstraction can reduce the total search time from O (n) to O ( p n), and he shows that multiple levels of abstraction can reduce the search time from O (n) to O (logn), where n is the number of states <p> In contrast, a hierarchical problem solver may expend a great deal of work searching for an appropriate specialization and in some cases no corresponding specialization exists. Consider the route planning domain that Korf describes in <ref> [ Korf, 1987 ] </ref> . The problem is to plan a route between any two points where the operators are used to move between adjacent intersections. By building up a set of macro operators he creates abstract operators that move between more distant points. Planning involves 6.2.
Reference: [ Laird et al., 1986 ] <author> John E. Laird, Paul S. Rosenbloom, and Allen Newell. </author> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 11-46, </pages> <year> 1986. </year>
Reference: [ Laird et al., 1987 ] <author> John E. Laird, Allen Newell, and Paul S. Rosenbloom. </author> <title> SOAR: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: However, all of these systems must be provided with abstractions that are hand-crafted for the individual domains. More recently, Unruh and Rosenbloom [ 1989 ] developed a weak method in soar <ref> [ Laird et al., 1987 ] </ref> that dynamically forms abstractions for look-ahead search by ignoring unmatched preconditions. The choices made in the look-ahead search are stored by soar's chunking mechanism and the chunks are then used to guide the search in the original space. <p> Solving Problem solving is a process that has been widely studied in AI from the early days of gps [ Newell et al., 1962, Ernst and Newell, 1969 ] and strips [ Fikes and Nilsson, 1971 ] to more recent planners such as sipe [ Wilkins, 1984 ] , soar <ref> [ Laird et al., 1987 ] </ref> and prodigy [ Minton et al., 1989b, Minton et al., 1989a, Carbonell et al., 1991 ] . A problem solver is a given a problem space definition and a problem and is asked to find a solution to the problem. <p> Unruh and Rosenbloom [ 1989, 1990 ] present a weak method for soar <ref> [ Laird et al., 1987 ] </ref> that dynamically forms abstractions by dropping applicability conditions of the operators. <p> Forward-Chaining Problem Solving The problem solving method presented in this thesis assumed that the goals introduced at each abstraction level will be achieved by chaining backward from the goal. However the same abstractions could also be used in a forward-chaining problem solver, such as soar <ref> [ Laird et al., 1987 ] </ref> . The only problem that arises with a forward-chaining system is that operators from more abstract levels might be applied at levels in which they should not be considered and potentially violate the ordered mono-tonicity property.
Reference: [ Lifschitz, 1986 ] <author> Vladimir Lifschitz. </author> <title> On the semantics of STRIPS. </title> <booktitle> In Proceedings of the Workshop on Reasoning about Actions and Plans, </booktitle> <pages> pages 1-9, </pages> <address> Timberline, Oregon, </address> <year> 1986. </year>
Reference-contexts: n solves a problem = (S 0 ; S g ) whenever is correct and the goal S g is satisfied in the final state: S g A (; S 0 ). 1 The formalization of problem solving presented in this section is loosely based on Lifschitz's formalization of strips <ref> [ Lifschitz, 1986 ] </ref> . 2.2.
Reference: [ McCarthy, 1964 ] <author> John McCarthy. </author> <title> A tough nut for proof procedures. </title> <institution> Stanford Artificial Intelligence Project Memo 16, Computer Science Department, Stanford University, </institution> <year> 1964. </year>
Reference: [ McDermott, 1982 ] <author> John McDermott. </author> <title> R1: A rule-based configurer of computer systems. </title> <journal> Artificial Intelligence, </journal> <volume> 19(1) </volume> <pages> 39-88, </pages> <year> 1982. </year>
Reference-contexts: 1980 ] , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain [ Minton, 1988a ] , discrete machine-shop planning and scheduling domain [ Minton, 1988a ] , a brewery scheduling domain [ Wilkins, 1989 ] , and a computer configuration domain <ref> [ McDermott, 1982, Rosenbloom et al., 1985 ] </ref> . The section below presents an overview of the basic prodigy problem solver. It describes prodigy's problem space and problem definitions, describes how the problem solver searches this space, and explains prodigy's use of control rules to guide this search.
Reference: [ Minsky, 1963 ] <author> Marvin Minsky. </author> <title> Steps toward artificial intelligence. </title> <editor> In Edward A. Feigenbaum, editor, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 406-450. </pages> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1963. </year>
Reference-contexts: Thus, the partitioning and ordering imposed by H could not prevent a problem from being solved. 2 The decomposability restriction on a problem is no stronger than the usual assumptions that are made to show that the complexity of a problem can be reduced by identifying intermediate states <ref> [ Minsky, 1963, Simon, 1977 ] </ref> . These analyses always assume that the problem can be divided into a number of smaller subproblems. As shown in the next section, dividing up the problem into independent subproblems is central to reducing the complexity of a problem. <p> Polya [ 1945 ] was one of the first to describe this idea of decomposing a problem into a number of simpler subproblems. Since then several people have shown that dividing a problem into subproblems can produce significant reductions in search <ref> [ Newell et al., 1962, Minsky, 1963 ] </ref> . These analyses implicitly assume a problem can be divided into small, equal-sized, independent subproblems that can be solved without backtracking.
Reference: [ Minton et al., 1989a ] <author> Steven Minton, Jaime G. Carbonell, Craig A. Knoblock, Daniel R. Kuokka, Oren Etzioni, and Yolanda Gil. </author> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40(1-3):63-118, </volume> <year> 1989. </year>
Reference-contexts: The description of prodigy that follows draws on an example from a machine-shop planning and scheduling domain. This example was previously described in 2.3. PROBLEM SOLVING IN PRODIGY 17 <ref> [ Minton et al., 1989a ] </ref> . The machine-shop domain contains a variety of machines, such as a lathe, mill, drill, punch, spray painter, etc, which are used to perform various operations to produce the desired parts.
Reference: [ Minton et al., 1989b ] <author> Steven Minton, Craig A. Knoblock, Daniel R. Kuokka, Yolanda Gil, Robert L. Joseph, and Jaime G. Carbonell. </author> <title> PRODIGY 2.0: The manual and tutorial. </title> <type> Technical Report CMU-CS-89-146, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1989. </year>
Reference-contexts: It describes prodigy's problem space and problem definitions, describes how the problem solver searches this space, and explains prodigy's use of control rules to guide this search. A complete description of the prodigy problem solver is presented in <ref> [ Minton et al., 1989b ] </ref> , and the extensions to prodigy for hierarchical problem solving are described in the next chapter. The description of prodigy that follows draws on an example from a machine-shop planning and scheduling domain. This example was previously described in 2.3. <p> An operator is composed of a precondition expression and a list of effects. The precondition expression describes the conditions that must be satisfied before the operator can be applied. The expressions are well-formed formulas in the prodigy description language (PDL) <ref> [ Minton et al., 1989b ] </ref> , a language based on predicate logic that includes negation, conjunction, disjunction, existential quantification, and universal quantification over sets. The list of effects describe how the application of the operator changes the world.
Reference: [ Minton, 1985 ] <author> Steven Minton. </author> <title> Selectively generalizing plans for problem solving. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 596-599, </pages> <address> Los Angeles, CA, </address> <year> 1985. </year>
Reference-contexts: Other people have explored the use of macros in problem solving [ Fikes et al., 1972, Minton, 1985, Laird et al., 1986, Shell and Carbonell, 1989 ] , but in most cases the macros are simply added to the original problem space, which may or may not reduce search <ref> [ Minton, 1985 ] </ref> . The work in this thesis builds on the first approach problem solving using abstract problem spaces. Before describing this approach to hierarchical problem solving in detail, the first section compares two models of abstraction spaces and describes the one used in this thesis. <p> In most systems, these macro operators are then added to the original space. Adding macros to the original problem space can reduce the solution depth, but it has the side-effect of increasing the branching factor, which can reduce the overall performance <ref> [ Minton, 1985 ] </ref> . There are also systems that construct aggregate objects for problem solving. The idea is to reduce the complexity of problem solving by reasoning about larger-grained objects.
Reference: [ Minton, 1988a ] <author> Steven Minton. </author> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <year> 1988. </year> <note> 194 BIBLIOGRAPHY </note>
Reference-contexts: In addition to the basic problem solver, prodigy consists of a number of learning modules, including modules for explanation-based learning <ref> [ Minton, 1988a ] </ref> , static 1.2. HIERARCHICAL PROBLEM SOLVING 3 learning [ Etzioni, 1990 ] , learning by analogy [ Veloso and Carbonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , graphical knowledge acquisition [ Joseph, 1989 ] , and abstraction generation. <p> Given a problem space and problem, alpine generates an abstraction hierarchy for the hierarchical version of prodigy. The system has been successfully tested on a number of problem-solving domains including the original strips domain [ Fikes and Nilsson, 1971 ] , a more complex robot planning domain <ref> [ Minton, 1988a ] </ref> , and a machine-shop planning and scheduling domain [ Minton, 1988a ] . <p> The system has been successfully tested on a number of problem-solving domains including the original strips domain [ Fikes and Nilsson, 1971 ] , a more complex robot planning domain <ref> [ Minton, 1988a ] </ref> , and a machine-shop planning and scheduling domain [ Minton, 1988a ] . In all these domains, the system efficiently generates problem-specific abstraction hierarchies that provide significant reductions in search. 1.4 Closely Related Work This section briefly describes the most closely related work on both generating and using abstractions for problem solving. <p> The use of abstraction is compared in prodigy to single-level problem solving, as well as problem solving with hand-coded control knowledge and control knowledge learned by ebl <ref> [ Minton, 1988a ] </ref> and static [ Et-zioni, 1990 ] . <p> PROBLEM SOLVING riety of learning mechanisms. In addition to the automatic generation of abstractions described in this thesis, prodigy includes modules for explanation-based learning <ref> [ Minton, 1988a ] </ref> , static learning [ Etzioni, 1990 ] , learning by analogy [ Veloso and Car-bonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , and graphical knowledge acquisition [ Joseph, 1989 ] . prodigy has been applied to a variety of domains including <p> Carbonell and Gil, 1990 ] , and graphical knowledge acquisition [ Joseph, 1989 ] . prodigy has been applied to a variety of domains including the blocks world [ Nilsson, 1980 ] , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain <ref> [ Minton, 1988a ] </ref> , discrete machine-shop planning and scheduling domain [ Minton, 1988a ] , a brewery scheduling domain [ Wilkins, 1989 ] , and a computer configuration domain [ McDermott, 1982, Rosenbloom et al., 1985 ] . <p> Joseph, 1989 ] . prodigy has been applied to a variety of domains including the blocks world [ Nilsson, 1980 ] , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain <ref> [ Minton, 1988a ] </ref> , discrete machine-shop planning and scheduling domain [ Minton, 1988a ] , a brewery scheduling domain [ Wilkins, 1989 ] , and a computer configuration domain [ McDermott, 1982, Rosenbloom et al., 1985 ] . The section below presents an overview of the basic prodigy problem solver. <p> Thus, the emphasis is on an elegant and simple problem solving architecture that can produce sophisticated behavior by learning control knowledge specific to a problem space. Control knowledge is acquired through experience as in EBL <ref> [ Minton, 1988a ] </ref> and derivational analogy [ Veloso and Carbonell, 1990 ] or through problem-space analysis as in static [ Etzioni, 1990 ] and alpine (described in the following chapters). 24 CHAPTER 2. <p> This section describes the abstractions generated by alpine on two problem solving domains and the use of these abstractions in prodigy to reduce search. These domains were previously described in <ref> [ Minton, 1988a ] </ref> , where they were used to evaluate the effectiveness of the explanation-based learning (ebl) module in prodigy. <p> The version of the domain used for the experiments differs syntactically from the original extended strips domain <ref> [ Minton, 1988a ] </ref> . These minor syntactic differences allow alpine to produce finer-grained abstraction hierarchies. Appendix B describes the differences and provides a complete specification of the problem space. The definition of the problem space includes some control information that was not included in the original problem space. <p> The comparison was made on a set of 250 randomly generated problems. Of these problems, 100 were used in Minton's experiments <ref> [ Minton, 1988a ] </ref> to test the EBL module. The hand-coded control rules correspond to the ones that were used in the EBL experiments. <p> It compares the performance of alpine to prodigy with no control knowledge, and prodigy with a set of hand-coded control rules. The hand-coded rules are the same rules that were used in the original comparisons with the EBL system <ref> [ Minton, 1988a ] </ref> . All the configurations were run 102 CHAPTER 5. EMPIRICAL RESULTS on 250 randomly generated problems including the 100 problems used for testing the EBL system. <p> This section sketches approaches to combining the abstractions generated by alpine with both explanation 132 CHAPTER 7. CONCLUSION based learning and learning by analogy. 1 Explanation-Based Learning Explanation-based learning is used in prodigy to learn control knowledge to guide the search <ref> [ Minton, 1988a ] </ref> . The control knowledge learned by ebl in prodigy provides significant reductions in search. However, a difficulty with this approach is that the examples from which the system learns often contain an abundance of unnecessary details. <p> The tables below compare prodigy without any control knowledge, prodigy with a set of hand-code control rules, and prodigy with the abstractions generated by alpine. The first 100 problems are the test problems used in Minton's experiments <ref> [ Minton, 1988a ] </ref> . The entries in the table are defined as follows: Prob Num The problem number. Time Total CPU time used in solving the problem. A 600 CPU second time bound was imposed on all problems. Nodes Total number of nodes searched in solving the problem. <p> EXTENDED STRIPS DOMAIN Appendix C Machine-Shop Planning and Scheduling The version of the machine-shop domain used in these experiments is almost identical to the original prodigy version presented in <ref> [ Minton, 1988a ] </ref> . There are only two minor syntactic differences from the original problem-space definition. <p> The first set of six tables below compares prodigy without any control knowledge, prodigy with a set of hand-code control rules, and prodigy with the abstractions generated by alpine. The second set of six tables below compares prodigy with the control rules produced by ebl <ref> [ Minton, 1988a ] </ref> , prodigy with the control rules produced by static [ Etzioni, 1990 ] , and prodigy with both the hand-code control rules and the abstractions produced by alpine. <p> ebl <ref> [ Minton, 1988a ] </ref> , prodigy with the control rules produced by static [ Etzioni, 1990 ] , and prodigy with both the hand-code control rules and the abstractions produced by alpine. The first 100 problems in each set of tables are the test problems used in Minton's experiments [ Minton, 1988a ] . The entries in the table are defined as follows: Prob Num The problem number. Time Total CPU time used in solving the problem. A 600 CPU second time bound was imposed on all problems. Nodes Total number of nodes searched in solving the problem.
Reference: [ Minton, 1988b ] <author> Steven Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
Reference-contexts: Third, a reduced model is a smaller problem space with fewer literals and operators, which can be more concisely represented and reasoned about. This makes it easier to combine the use of abstraction with other types of problem-space learning such as explanation-based learning <ref> [ Minton, 1988b ] </ref> , macro-operator learning [ Korf, 1985b ] , or learning by analogy [ Carbonell, 1986 ] . Fourth, creating a reduced model allows operators and objects that are indistinguishable at an abstract level to be combined into abstract operators or objects.
Reference: [ Minton, 1990 ] <author> Steven Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):363-392, </volume> <year> 1990. </year>
Reference-contexts: Comparing the results of the different configurations on the set of test problems is complicated by the fact that some of the problems cannot be solved within the time limit. Similar comparisons in the past have been done using cumulative time graphs <ref> [ Minton, 1990 ] </ref> , but Segre et al. [ 1991 ] argue that such comparisons could be misleading because changing the time limit can change the results. To avoid this problem, the total time expended solving all of the problems is graphed against the CPU time bound.
Reference: [ Mostow and Prieditis, 1989 ] <author> Jack Mostow and Armand E. </author> <title> Prieditis. Discovering admissible heuristics by abstracting and optimizing: A transformational approach. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 701-707, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: Second, planereus forms abstract operators by ignoring the differences between operators without regard to the difficulty of achieving those differences, while alpine drops conditions based on an interaction and dependency analysis of the entire problem space. absolver <ref> [ Mostow and Prieditis, 1989 ] </ref> employs a set of abstraction transformations to create abstractions of a problem. The resulting abstract models are then tested to see if they provide useful abstractions for use in an admissible search procedure [ Pearl, 1984, Kibler, 1985 ] . <p> In addition, the use of the goal orderings is more similar to the way abstractions are used in absolver <ref> [ Mostow and Prieditis, 1989 ] </ref> . Etzioni [ Etzioni, 1990 ] developed a system called static, which statically analyzes the problem space definition to identify potential interactions. Based on these interactions, static generates a set of search control rules for prodigy to guide the problem solving.
Reference: [ Newell and Simon, 1972 ] <author> Allen Newell and Herbert A. Simon. </author> <title> Human Problem Solving. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: An effective approach to building more intelligent problem solvers is to use abstraction in order to help focus the search. Abstraction has been used successfully to reduce search in a number of problem solvers including gps <ref> [ Newell and Simon, 1972 ] </ref> , abstrips [ Sacerdoti, 1974 ] , noah [ Sacerdoti, 1977 ] , nonlin [ Tate, 1976 ] molgen [ Stefik, 1981 ] and sipe [ Wilkins, 1984 ] . <p> Chapter 6 provides a more comprehensive discussion of the work related to this thesis. The first hierarchical problem solver was implemented as a planning method in gps <ref> [ Newell and Simon, 1972 ] </ref> . Given a problem space and an abstraction of that problem space, gps maps the problem into the abstract space, solves the abstract problem and then uses the solution to guide the problem solving in the original space. <p> An abstraction space can be either a simplification or reformulation of the original problem space, such as the relaxed and reduced model described in Section 3.1.2. A problem is usually solved in an abstract space and then refined at successively more detailed levels. Planning gps <ref> [ Newell and Simon, 1972 ] </ref> was the first system to employ this approach to problem solving. The system was applied to the domain of propositional logic problems. In this logic domain, gps is given an abstract problem space that ignores the logical connectives in the formulas. <p> Also, the control rules are used to guide the search in the original space, while the abstractions are used for hierarchical problem solving. 6.3 Properties of Abstractions Banerji and Ernst [ 1977a, 1977b ] compared three similar problem solvers, gps [ Ernst, 1969 ] , Planning gps <ref> [ Newell and Simon, 1972 ] </ref> , and abstrips [ Sacerdoti, 1974 ] . They developed a formal model of these systems that makes some additional assumptions not actually present in the three problem solvers.
Reference: [ Newell et al., 1962 ] <author> Allen Newell, J. C. Shaw, and Herbert A. Simon. </author> <title> The processes of creative thinking. </title> <booktitle> In Contemporary Approaches to Creative Thinking, </booktitle> <pages> pages 63-119. </pages> <publisher> Atherton Press, </publisher> <address> New York, </address> <year> 1962. </year>
Reference-contexts: On a first reading, the reader may want to skim the formal definitions and proofs. Chapter 2 Problem Solving Problem solving is a process that has been widely studied in AI from the early days of gps <ref> [ Newell et al., 1962, Ernst and Newell, 1969 ] </ref> and strips [ Fikes and Nilsson, 1971 ] to more recent planners such as sipe [ Wilkins, 1984 ] , soar [ Laird et al., 1987 ] and prodigy [ Minton et al., 1989b, Minton et al., 1989a, Carbonell et al., <p> There are a variety of approaches to problem solving, which range from simple forward-chaining or backward chaining to more sophisticated goal-directed approaches, such as means-ends analysis and least-commitment planning. Means-ends analysis, which was developed in gps <ref> [ Newell et al., 1962 ] </ref> , integrates the forward- and backward-chaining approaches. A means-ends analysis problem solver identifies the differences between the goal and the current state and then selects an operator that reduces these differences. <p> This type of hierarchical problem solving is sometimes called length-first hierarchical problem solving since a problem is solved at one level of abstraction before moving to the next level. The technique was first used in gps <ref> [ Newell et al., 1962 ] </ref> and abstrips [ Sacerdoti, 1974 ] . The second approach, hierarchical problem solving using abstract operators, uses a predefined set of abstractions of the operators and expands each operator in the abstract plan to varying levels of detail. <p> Polya [ 1945 ] was one of the first to describe this idea of decomposing a problem into a number of simpler subproblems. Since then several people have shown that dividing a problem into subproblems can produce significant reductions in search <ref> [ Newell et al., 1962, Minsky, 1963 ] </ref> . These analyses implicitly assume a problem can be divided into small, equal-sized, independent subproblems that can be solved without backtracking.
Reference: [ Nilsson, 1971 ] <author> Nils J. Nilsson. </author> <booktitle> Problem-Solving Methods in Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1971. </year>
Reference-contexts: The state space, which is the set of states reachable from the initial state using the given operators, for the three-disk puzzle is shown in Figure 2.2 <ref> [ Nilsson, 1971 ] </ref> . Each node represents a state and is labeled with a picture of that state, and each arrow represents an operator that can be applied to reach the adjacent state.
Reference: [ Nilsson, 1980 ] <author> Nils J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Publishing Co., </publisher> <address> Palo Alto, CA, </address> <year> 1980. </year>
Reference-contexts: , static learning [ Etzioni, 1990 ] , learning by analogy [ Veloso and Car-bonell, 1990 ] , learning by experimentation [ Carbonell and Gil, 1990 ] , and graphical knowledge acquisition [ Joseph, 1989 ] . prodigy has been applied to a variety of domains including the blocks world <ref> [ Nilsson, 1980 ] </ref> , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain [ Minton, 1988a ] , discrete machine-shop planning and scheduling domain [ Minton, 1988a ] , a brewery scheduling domain [ Wilkins, 1989 ] , and a computer configuration <p> Thus, the abstraction hierarchies are based on the possible interactions, which are a superset of the actual interactions. As a result it will in many cases overconstrain the hierarchy, thus reducing the granularity of the possible abstraction hierarchies. The "blocks world" <ref> [ Nilsson, 1980 ] </ref> is a domain in which alpine is unable to generate abstractions, although there are ordered monotonic abstractions for some problems.
Reference: [ Pearl, 1984 ] <author> Judea Pearl. </author> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: In the initial model, the robot can only change 3.1. ABSTRACTION HIERARCHIES 27 rooms if the door between the rooms is open, and the robot can open or close the door from either room. Relaxed models <ref> [ Pearl, 1984 ] </ref> are constructed by removing preconditions of operators. This is the approach taken in abstrips, where the preconditions of the operators are assigned criticality values and all preconditions with criticality values below a certain threshold are ignored. <p> The resulting abstract models are then tested to see if they provide useful abstractions for use in an admissible search procedure <ref> [ Pearl, 1984, Kibler, 1985 ] </ref> . The reduced or relaxed models are used to compute lower bounds and check solvability. The abstraction transformations include dropping preconditions, dropping goals, and dropping predicates from the problem space. The abstractions are selected using a generate-and-test procedure.
Reference: [ Plaisted, 1981 ] <author> David A. Plaisted. </author> <title> Theorem proving with abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 16(1) </volume> <pages> 47-108, </pages> <year> 1981. </year>
Reference-contexts: In general, using an abstraction space formed by dropping information it is impossible to guarantee this property. The same problem arises in the use of abstraction in theorem proving, where it is called the false proof problem <ref> [ Plaisted, 1981, Giunchiglia and Walsh, 1990 ] </ref> . Since the downward solution property does not hold in general, there is no guarantee that a refinement of the abstract solution exists. To make matters worse, there are a potentially infinite number of possible refinements of each abstract plan.
Reference: [ Polya, 1945 ] <author> George Polya. </author> <title> How to Solve It. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1945. </year>
Reference: [ Riddle, 1990 ] <author> Patricia Riddle. </author> <title> Automating problem reformulation. </title> <editor> In D. Paul Benjamin, editor, </editor> <booktitle> Change of Representation and Inductive Bias, </booktitle> <pages> pages 105-124. </pages> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference: [ Rosenbloom et al., 1985 ] <author> Paul S. Rosenbloom, John E. Laird, John McDermott, Allen Newell, and E. Orciuch. R1-Soar: </author> <title> An experiment in knowledge-intensive programming in a problem-solving architecture. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 7(5) </volume> <pages> 561-569, </pages> <year> 1985. </year>
Reference-contexts: 1980 ] , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain [ Minton, 1988a ] , discrete machine-shop planning and scheduling domain [ Minton, 1988a ] , a brewery scheduling domain [ Wilkins, 1989 ] , and a computer configuration domain <ref> [ McDermott, 1982, Rosenbloom et al., 1985 ] </ref> . The section below presents an overview of the basic prodigy problem solver. It describes prodigy's problem space and problem definitions, describes how the problem solver searches this space, and explains prodigy's use of control rules to guide this search.
Reference: [ Rosenschein, 1981 ] <author> Stanley J. Rosenschein. </author> <title> Plan synthesis: A logical perspective. </title> <booktitle> In Proceedings of the Seventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 331-337, </pages> <address> Vancouver, B.C., Canada, </address> <year> 1981. </year> <note> BIBLIOGRAPHY 195 </note>
Reference: [ Ruby and Kibler, 1989 ] <author> David Ruby and Dennis Kibler. </author> <title> Learning subgoal sequences for planning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 609-614, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: This approach success 6.2. GENERATING ABSTRACTIONS FOR PROBLEM SOLVING 119 fully automates some of the reformulations of the Missionaries and Cannibals problem that were first described by Amarel [ 1968 ] . Ruby and Kibler <ref> [ Ruby and Kibler, 1989 ] </ref> developed a system called SteppingStone that also learns sequences of subgoals. SteppingStone employs the learned subgoal sequences only when the basic means-ends analysis problem solver fails to find a solution that does not involve undoing a previously achieved goal.
Reference: [ Sacerdoti, 1974 ] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: An effective approach to building more intelligent problem solvers is to use abstraction in order to help focus the search. Abstraction has been used successfully to reduce search in a number of problem solvers including gps [ Newell and Simon, 1972 ] , abstrips <ref> [ Sacerdoti, 1974 ] </ref> , noah [ Sacerdoti, 1977 ] , nonlin [ Tate, 1976 ] molgen [ Stefik, 1981 ] and sipe [ Wilkins, 1984 ] . <p> An alternative approach to constructing abstraction spaces is to form a relaxed model by weakening the applicability conditions of the operators in a problem space. This was the approach taken in abstrips <ref> [ Sacerdoti, 1974 ] </ref> , where the preconditions of the operators were assigned criticality values and all preconditions with criticality values below a certain threshold were ignored. <p> The system was tested in the domain of propositional logic, where in the abstract space the differences between the connectives is ignored. gps provided the first automated use of abstraction for problem solving, but did not automate the construction of the abstractions. abstrips <ref> [ Sacerdoti, 1974 ] </ref> employs a similar problem-solving technique to gps 1.4. CLOSELY RELATED WORK 7 and was the first system to demonstrate empirically that abstraction could be used to reduce search in problem solving, In addition, the work on abstrips was the earliest attempt at automating abstraction formation. <p> This type of hierarchical problem solving is sometimes called length-first hierarchical problem solving since a problem is solved at one level of abstraction before moving to the next level. The technique was first used in gps [ Newell et al., 1962 ] and abstrips <ref> [ Sacerdoti, 1974 ] </ref> . The second approach, hierarchical problem solving using abstract operators, uses a predefined set of abstractions of the operators and expands each operator in the abstract plan to varying levels of detail. <p> If is a refinement of A , then we say that A refines to . This formal definition captures the notion of plan refinement used in many different planners, including abstrips <ref> [ Sacerdoti, 1974 ] </ref> , noah [ Sacerdoti, 1977 ] , sipe [ Wilkins, 1984 ] , and abtweak [ Yang and Tenenberg, 1990 ] . 4.1.3 Monotonic Abstraction Hierarchies In Lemma 4.1, the relationship between and its justifications at successive levels of abstraction reveals that not only are operators being <p> RELATED WORK spaces generated by alpine, the abstraction of the propositional logic problems does not just ignore conditions, but provides a different representation of the problem. While gps provided the first automated use of abstraction for problem solving, it did not automate the construction of the abstractions. abstrips <ref> [ Sacerdoti, 1974 ] </ref> also employs abstract problem spaces for hierarchical problem solving. The abstraction spaces for a problem domain are represented by assigning criticalities, numbers indicating the relative difficulty, to the preconditions of each operator. The system uses these criticalities to plan abstractly. <p> Second, how is this knowledge used for problem solving (e.g., subgoals, control rules, evaluation functions). Third, what is the approach to producing this knowledge (e.g., analysis of interactions, partial evaluation). This section is loosely organized by the type of knowledge produced by the various approaches. 6.2.1 Abstractions abstrips <ref> [ Sacerdoti, 1974 ] </ref> was the first attempt to automate the formation of abstraction hierarchies for hierarchical planning. However, the system only partially automates this process. <p> to guide the search in the original space, while the abstractions are used for hierarchical problem solving. 6.3 Properties of Abstractions Banerji and Ernst [ 1977a, 1977b ] compared three similar problem solvers, gps [ Ernst, 1969 ] , Planning gps [ Newell and Simon, 1972 ] , and abstrips <ref> [ Sacerdoti, 1974 ] </ref> . They developed a formal model of these systems that makes some additional assumptions not actually present in the three problem solvers. It is interesting to note that the additional assumptions correspond to enforcing the ordered monotonicity property.
Reference: [ Sacerdoti, 1977 ] <author> Earl D. Sacerdoti. </author> <title> A Structure for Plans and Behavior. </title> <publisher> American Elsevier, </publisher> <address> New York, NY, </address> <year> 1977. </year>
Reference-contexts: Abstraction has been used successfully to reduce search in a number of problem solvers including gps [ Newell and Simon, 1972 ] , abstrips [ Sacerdoti, 1974 ] , noah <ref> [ Sacerdoti, 1977 ] </ref> , nonlin [ Tate, 1976 ] molgen [ Stefik, 1981 ] and sipe [ Wilkins, 1984 ] . <p> Since these early efforts, there have been a number of systems that use abstractions for problem solving. These systems include noah <ref> [ Sacerdoti, 1977 ] </ref> , molgen [ Stefik, 1981 ] , nonlin [ Tate, 1976 ] , and sipe [ Wilkins, 1984 ] . However, all of these systems must be provided with abstractions that are hand-crafted for the individual domains. <p> Instead the problem solver first selects abstract operators that directly achieve the goals and then refines the abstract operators by inserting preconditions of the operators that must hold before operators can be applied in the ground space. This approach, which requires a least-commitment problem solver, was developed in noah <ref> [ Sacerdoti, 1977 ] </ref> and later used in nonlin [ Tate, 1976 ] , molgen [ Stefik, 1981 ] , and sipe [ Wilkins, 1984 ] . 25 26 CHAPTER 3. <p> If is a refinement of A , then we say that A refines to . This formal definition captures the notion of plan refinement used in many different planners, including abstrips [ Sacerdoti, 1974 ] , noah <ref> [ Sacerdoti, 1977 ] </ref> , sipe [ Wilkins, 1984 ] , and abtweak [ Yang and Tenenberg, 1990 ] . 4.1.3 Monotonic Abstraction Hierarchies In Lemma 4.1, the relationship between and its justifications at successive levels of abstraction reveals that not only are operators being eliminated from a plan in ascending <p> This approach has been used extensively in least-commitment problem solvers and the systems that employ this approach include noah <ref> [ Sacerdoti, 1977 ] </ref> , molgen [ Stefik, 1981 ] , and nonlin [ Tate, 1976 ] . In all of these problem solvers, the abstractions must be hand-crafted for each problem domain. <p> Least-Commmitment Hierarchical Problem Solving The model of hierarchical problem solving described in Chapter 3 is based on a state-space problem solver. An alternative is to use a least-commitment approach to problem solving <ref> [ Sacerdoti, 1977, Chapman, 1987 ] </ref> , which searches through the space of plan refinements instead of searching through the state space. This approach is referred to as a least-commitment approach because ordering commitments are delayed as long as possible.
Reference: [ Segre et al., 1991 ] <author> Alberto Segre, Charles Elkan, and Alex Russell. </author> <title> A critical look at experimental evaluations of EBL. </title> <journal> Machine Learning, </journal> <volume> 6(2) </volume> <pages> 183-195, </pages> <year> 1991. </year>
Reference: [ Shell and Carbonell, 1989 ] <author> Peter Shell and Jaime Carbonell. </author> <title> Towards a general framework for composing disjunctive and iterative macro-operators. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 596-602, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference: [ Simon, 1977 ] <author> Herbert A. Simon. </author> <title> The theory of problem solving. </title> <editor> In Herbert A. Simon, editor, </editor> <booktitle> Models of Discovery, chapter 4.3, </booktitle> <pages> pages 214-244. </pages> <address> D. </address> <publisher> Reidel, </publisher> <address> Boston, MA, </address> <year> 1977. </year>
Reference-contexts: Thus, the partitioning and ordering imposed by H could not prevent a problem from being solved. 2 The decomposability restriction on a problem is no stronger than the usual assumptions that are made to show that the complexity of a problem can be reduced by identifying intermediate states <ref> [ Minsky, 1963, Simon, 1977 ] </ref> . These analyses always assume that the problem can be divided into a number of smaller subproblems. As shown in the next section, dividing up the problem into independent subproblems is central to reducing the complexity of a problem.
Reference: [ Stallman and Sussman, 1977 ] <author> R.M. Stallman and G.J. Sussman. </author> <title> Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 9(2) </volume> <pages> 135-196, </pages> <year> 1977. </year>
Reference-contexts: The backtracking across subproblems and across abstraction levels, which I call hierarchical backtracking, exploits the structure of hierarchical problem solving to implement a simple form of dependency-directed backtracking <ref> [ Stallman and Sussman, 1977 ] </ref> and to avoid replanning when possible. Hierarchical backtracking avoids backtracking to choices in the search space that could not be relevant to a problem solving failure.
Reference: [ Stefik, 1981 ] <author> Mark Stefik. </author> <title> Planning with constraints (MOLGEN: Part 1). </title> <journal> Artificial Intelligence, </journal> <volume> 16(2) </volume> <pages> 111-140, </pages> <year> 1981. </year>
Reference-contexts: Abstraction has been used successfully to reduce search in a number of problem solvers including gps [ Newell and Simon, 1972 ] , abstrips [ Sacerdoti, 1974 ] , noah [ Sacerdoti, 1977 ] , nonlin [ Tate, 1976 ] molgen <ref> [ Stefik, 1981 ] </ref> and sipe [ Wilkins, 1984 ] . These systems use abstraction to focus attention on the difficult parts of the problem, leaving the details or less critical parts of a problem to be filled in later. <p> Since these early efforts, there have been a number of systems that use abstractions for problem solving. These systems include noah [ Sacerdoti, 1977 ] , molgen <ref> [ Stefik, 1981 ] </ref> , nonlin [ Tate, 1976 ] , and sipe [ Wilkins, 1984 ] . However, all of these systems must be provided with abstractions that are hand-crafted for the individual domains. <p> Chapman [ 1987 ] identified a complete set of plan modification operators and implemented them in a planner called tweak. Other least-commitment problem solvers include nonlin [ Tate, 1976 ] , molgen <ref> [ Stefik, 1981 ] </ref> , and sipe [ Wilkins, 1984 ] . 2.2 Tower of Hanoi Example This section presents an example of problem solving in the Tower of Hanoi puzzle, which is then used in the following chapters to illustrate the techniques for both hierarchical problem solving and generating abstractions. <p> This approach, which requires a least-commitment problem solver, was developed in noah [ Sacerdoti, 1977 ] and later used in nonlin [ Tate, 1976 ] , molgen <ref> [ Stefik, 1981 ] </ref> , and sipe [ Wilkins, 1984 ] . 25 26 CHAPTER 3. <p> This approach has been used extensively in least-commitment problem solvers and the systems that employ this approach include noah [ Sacerdoti, 1977 ] , molgen <ref> [ Stefik, 1981 ] </ref> , and nonlin [ Tate, 1976 ] . In all of these problem solvers, the abstractions must be hand-crafted for each problem domain.
Reference: [ Subramanian and Genesereth, 1987 ] <author> Devika Subramanian and Michael R. Gene-sereth. </author> <title> The relevance of irrelevance. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <year> 1987. </year>
Reference: [ Subramanian, 1989 ] <author> Devika Subramanian. </author> <title> A Theory of Justified Reformulations. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1989. </year>
Reference: [ Tate, 1976 ] <author> Austin Tate. </author> <title> Project planning using a hierarchic non-linear planner. </title> <type> Research Report 25, </type> <institution> Department of Artificial Intelligence, University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <year> 1976. </year>
Reference-contexts: Abstraction has been used successfully to reduce search in a number of problem solvers including gps [ Newell and Simon, 1972 ] , abstrips [ Sacerdoti, 1974 ] , noah [ Sacerdoti, 1977 ] , nonlin <ref> [ Tate, 1976 ] </ref> molgen [ Stefik, 1981 ] and sipe [ Wilkins, 1984 ] . These systems use abstraction to focus attention on the difficult parts of the problem, leaving the details or less critical parts of a problem to be filled in later. <p> Since these early efforts, there have been a number of systems that use abstractions for problem solving. These systems include noah [ Sacerdoti, 1977 ] , molgen [ Stefik, 1981 ] , nonlin <ref> [ Tate, 1976 ] </ref> , and sipe [ Wilkins, 1984 ] . However, all of these systems must be provided with abstractions that are hand-crafted for the individual domains. <p> Chapman [ 1987 ] identified a complete set of plan modification operators and implemented them in a planner called tweak. Other least-commitment problem solvers include nonlin <ref> [ Tate, 1976 ] </ref> , molgen [ Stefik, 1981 ] , and sipe [ Wilkins, 1984 ] . 2.2 Tower of Hanoi Example This section presents an example of problem solving in the Tower of Hanoi puzzle, which is then used in the following chapters to illustrate the techniques for both <p> This approach, which requires a least-commitment problem solver, was developed in noah [ Sacerdoti, 1977 ] and later used in nonlin <ref> [ Tate, 1976 ] </ref> , molgen [ Stefik, 1981 ] , and sipe [ Wilkins, 1984 ] . 25 26 CHAPTER 3. <p> This approach has been used extensively in least-commitment problem solvers and the systems that employ this approach include noah [ Sacerdoti, 1977 ] , molgen [ Stefik, 1981 ] , and nonlin <ref> [ Tate, 1976 ] </ref> . In all of these problem solvers, the abstractions must be hand-crafted for each problem domain.
Reference: [ Tenenberg, 1988 ] <author> Josh D. Tenenberg. </author> <title> Abstraction in Planning. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of Rochester, </institution> <year> 1988. </year> <note> 196 BIBLIOGRAPHY </note>
Reference-contexts: This section first reviews the upward and downward solution properties <ref> [ Tenenberg, 1988 ] </ref> , which relate a problem space to the abstractions of the problem space. While both properties are useful, the downward solution property is too strong to require that it hold for every abstraction. <p> The proof of an analogous lemma can be found in <ref> [ Tenenberg, 1988, pg.69 ] </ref> . The idea is that since conditions involving certain literals are eliminated in ascending the abstraction hierarchy, one can eliminate from plans those operators included solely to satisfy these eliminated conditions.
Reference: [ Unruh and Rosenbloom, 1989 ] <author> Amy Unruh and Paul S. Rosenbloom. </author> <title> Abstraction in problem solving and learning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 681-687, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference: [ Unruh and Rosenbloom, 1990 ] <author> Amy Unruh and Paul S. Rosenbloom. </author> <title> Two new weak method increments for abstraction. </title> <booktitle> In Proceedings of the Workshop on Automatic Generation of Approximations and Abstractions, </booktitle> <pages> pages 78-86, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference: [ VanLehn, 1989 ] <author> Kurt VanLehn. </author> <title> Discovering problem solving strategies: What humans do and machines don't (yet). </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 215-217, </pages> <address> Ithaca, NY, </address> <year> 1989. </year>
Reference-contexts: To illustrate this point, consider a variant of the Tower of Hanoi problem that has the additional restriction that no disk can be moved twice in a row alpine produces modest improvements in both search time and solution quality. 92 CHAPTER 5. EMPIRICAL RESULTS <ref> [ Anzai and Simon, 1979, Amarel, 1984, VanLehn, 1989 ] </ref> . This constrains the problem considerably since the suboptimal plans in the previous graph were caused by moving a disk to the wrong peg and then moving the same disk again.
Reference: [ Veloso and Carbonell, 1990 ] <author> Manuela M. Veloso and Jaime G. Carbonell. </author> <title> Integrating analogy into a general problem-solving architecture. In Intelligent Systems. </title> <publisher> Ellis Horwood Limited, </publisher> <address> West Sussex, England, </address> <year> 1990. </year>
Reference-contexts: In addition to the basic problem solver, prodigy consists of a number of learning modules, including modules for explanation-based learning [ Minton, 1988a ] , static 1.2. HIERARCHICAL PROBLEM SOLVING 3 learning [ Etzioni, 1990 ] , learning by analogy <ref> [ Veloso and Carbonell, 1990 ] </ref> , learning by experimentation [ Carbonell and Gil, 1990 ] , graphical knowledge acquisition [ Joseph, 1989 ] , and abstraction generation. <p> Thus, the emphasis is on an elegant and simple problem solving architecture that can produce sophisticated behavior by learning control knowledge specific to a problem space. Control knowledge is acquired through experience as in EBL [ Minton, 1988a ] and derivational analogy <ref> [ Veloso and Carbonell, 1990 ] </ref> or through problem-space analysis as in static [ Etzioni, 1990 ] and alpine (described in the following chapters). 24 CHAPTER 2. PROBLEM SOLVING Chapter 3 Hierarchical Problem Solving Abstraction has been used to reduce search in a variety of problem solvers. <p> However, the combination of the two approaches can both eliminate any search from the problem and produce the optimal solution. Learning by Analogy Analogy can also used to guide problem solving in prodigy <ref> [ Veloso and Carbonell, 1990 ] </ref> . The analogy engine stores problem solving episodes in a case library and then retrieves them to guide the search in similar problems. There are several difficulties that arise in the use of analogy in problem solving.
Reference: [ Weld and Addanki, 1990 ] <author> Daniel S. Weld and Sanjaya Addanki. </author> <title> Task-driven model abstraction. </title> <booktitle> In Proceedings of the Fourth International Workshop on Qualitative Physics, Lugano, </booktitle> <address> Switzerland, </address> <year> 1990. </year>
Reference-contexts: Since any solution at the more constrained ground level will also be a solution in any of the less constrained models, it is clear that an abstraction space will exhibit the upward solution property. The contrapositive of this property is the downward failure property <ref> [ Weld and Addanki, 1990 ] </ref> , which states that if there is no solution in the abstract space, then there is no solution in the ground space.
Reference: [ Wilkins, 1984 ] <author> David E. Wilkins. </author> <title> Domain-independent planning: Representation and plan generation. </title> <journal> Artificial Intelligence, </journal> <volume> 22(3) </volume> <pages> 269-301, </pages> <year> 1984. </year>
Reference-contexts: Abstraction has been used successfully to reduce search in a number of problem solvers including gps [ Newell and Simon, 1972 ] , abstrips [ Sacerdoti, 1974 ] , noah [ Sacerdoti, 1977 ] , nonlin [ Tate, 1976 ] molgen [ Stefik, 1981 ] and sipe <ref> [ Wilkins, 1984 ] </ref> . These systems use abstraction to focus attention on the difficult parts of the problem, leaving the details or less critical parts of a problem to be filled in later. <p> Since these early efforts, there have been a number of systems that use abstractions for problem solving. These systems include noah [ Sacerdoti, 1977 ] , molgen [ Stefik, 1981 ] , nonlin [ Tate, 1976 ] , and sipe <ref> [ Wilkins, 1984 ] </ref> . However, all of these systems must be provided with abstractions that are hand-crafted for the individual domains. <p> Chapter 2 Problem Solving Problem solving is a process that has been widely studied in AI from the early days of gps [ Newell et al., 1962, Ernst and Newell, 1969 ] and strips [ Fikes and Nilsson, 1971 ] to more recent planners such as sipe <ref> [ Wilkins, 1984 ] </ref> , soar [ Laird et al., 1987 ] and prodigy [ Minton et al., 1989b, Minton et al., 1989a, Carbonell et al., 1991 ] . <p> Chapman [ 1987 ] identified a complete set of plan modification operators and implemented them in a planner called tweak. Other least-commitment problem solvers include nonlin [ Tate, 1976 ] , molgen [ Stefik, 1981 ] , and sipe <ref> [ Wilkins, 1984 ] </ref> . 2.2 Tower of Hanoi Example This section presents an example of problem solving in the Tower of Hanoi puzzle, which is then used in the following chapters to illustrate the techniques for both hierarchical problem solving and generating abstractions. <p> This approach, which requires a least-commitment problem solver, was developed in noah [ Sacerdoti, 1977 ] and later used in nonlin [ Tate, 1976 ] , molgen [ Stefik, 1981 ] , and sipe <ref> [ Wilkins, 1984 ] </ref> . 25 26 CHAPTER 3. HIERARCHICAL PROBLEM SOLVING The third approach, abstract problem solving using macros, takes a problem and maps it into an abstract space defined by a set of macro operators and then solves the problem in the macro space. <p> If is a refinement of A , then we say that A refines to . This formal definition captures the notion of plan refinement used in many different planners, including abstrips [ Sacerdoti, 1974 ] , noah [ Sacerdoti, 1977 ] , sipe <ref> [ Wilkins, 1984 ] </ref> , and abtweak [ Yang and Tenenberg, 1990 ] . 4.1.3 Monotonic Abstraction Hierarchies In Lemma 4.1, the relationship between and its justifications at successive levels of abstraction reveals that not only are operators being eliminated from a plan in ascending the abstraction hierarchy, but that for <p> In general, reachieving the deleted conditions or finding another way to solve the problem that does not violate the conditions is a difficult problem. There is nothing inherent in least-commitment problem solvers that prevents them from using action reductions to implement abstract problem spaces. sipe <ref> [ Wilkins, 1984, Wilkins, 1986 ] </ref> uses a more explicit encoding of the abstractions where the domain is partitioned into literals at different abstraction levels and operators for achieving those literals.
Reference: [ Wilkins, 1986 ] <author> David E. Wilkins. </author> <title> High-level planning in a mobile robot domain. </title> <type> Technical Report 388, </type> <institution> Artificial Intelligence Center, SRI International, </institution> <year> 1986. </year>
Reference-contexts: In general, reachieving the deleted conditions or finding another way to solve the problem that does not violate the conditions is a difficult problem. There is nothing inherent in least-commitment problem solvers that prevents them from using action reductions to implement abstract problem spaces. sipe <ref> [ Wilkins, 1984, Wilkins, 1986 ] </ref> uses a more explicit encoding of the abstractions where the domain is partitioned into literals at different abstraction levels and operators for achieving those literals.
Reference: [ Wilkins, 1988 ] <author> David E. Wilkins. </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: The use of object hierarchies is a bit more complex because objects are often a limited resource. To exploit object hierarchies requires the capability of reasoning about resources. Such a capability is provided in sipe, as described in <ref> [ Wilkins, 1988 ] </ref> , but is not yet available in prodigy. 7.3.3 Using Abstract Problem Spaces for Learning Since the abstractions of a problem space are abstract problem spaces, the abstractions can be used for learning as well as problem solving.
Reference: [ Wilkins, 1989 ] <author> David E. Wilkins. </author> <title> Can AI planners solve practical problems? Technical Report 468R, </title> <booktitle> Artificial Intelligence Center, SRI International, </booktitle> <year> 1989. </year>
Reference-contexts: a variety of domains including the blocks world [ Nilsson, 1980 ] , the strips domain [ Fikes and Nilsson, 1971 ] , an augmented version of the strips domain [ Minton, 1988a ] , discrete machine-shop planning and scheduling domain [ Minton, 1988a ] , a brewery scheduling domain <ref> [ Wilkins, 1989 ] </ref> , and a computer configuration domain [ McDermott, 1982, Rosenbloom et al., 1985 ] . The section below presents an overview of the basic prodigy problem solver.
Reference: [ Yang and Tenenberg, 1990 ] <author> Qiang Yang and Josh D. Tenenberg. Abtweak: </author> <title> Abstracting a nonlinear, least commitment planner. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 204-209, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: This formal definition captures the notion of plan refinement used in many different planners, including abstrips [ Sacerdoti, 1974 ] , noah [ Sacerdoti, 1977 ] , sipe [ Wilkins, 1984 ] , and abtweak <ref> [ Yang and Tenenberg, 1990 ] </ref> . 4.1.3 Monotonic Abstraction Hierarchies In Lemma 4.1, the relationship between and its justifications at successive levels of abstraction reveals that not only are operators being eliminated from a plan in ascending the abstraction hierarchy, but that for those preconditions still present at a given
Reference: [ Yang, 1989 ] <author> Qiang Yang. </author> <title> Improving the Efficiency of Planning. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland, </institution> <year> 1989. </year>
Reference-contexts: The refinement is done using a set of action reductions <ref> [ Yang, 1989 ] </ref> , which specify the relationship between an abstract operator and the refinements of that operator. This approach differs from the previ 6.1.
Reference: [ Yang, 1990 ] <author> Qiang Yang. </author> <title> Solving the problem of hierarchical inaccuracy in planning. </title> <booktitle> In Proceedings of the Eighth Biennial Conference of the Canadian Society for Computational Studies of Intelligence, </booktitle> <pages> pages 140-145, </pages> <address> Ottawa, Canada, </address> <year> 1990. </year>
Reference-contexts: However, Wilkins [ 1986 ] identified another problem that can arise with least-commitment problem solvers even when using abstraction spaces as in sipe. The problem (called hierarchical inaccuracy <ref> [ Yang, 1990 ] </ref> ) is that since the planner can expand the operators in a plan to different levels of detail, it may expand one part 114 CHAPTER 6.
References-found: 93

