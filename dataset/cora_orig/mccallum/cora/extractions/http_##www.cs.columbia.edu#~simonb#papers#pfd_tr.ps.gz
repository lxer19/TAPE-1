URL: http://www.cs.columbia.edu/~simonb/papers/pfd_tr.ps.gz
Refering-URL: http://www.cs.columbia.edu/~simonb/pub.html
Root-URL: http://www.cs.columbia.edu
Email: Email: fnayar,simonbg@cs.columbia.edu  Email: murase@siva.ntt.jp  
Title: Parametric Feature Detection CUCS-028-95  
Author: Shree K. Nayar Simon Baker and Hiroshi Murase Morinosato Wakamiya, Atsugi-shi 
Address: New York, NY 10027, U.S.A.  243-01, Japan  
Affiliation: Department of Computer Science Columbia University  NTT Basic Research Laboratory  Kanagawa  
Abstract-found: 0
Intro-found: 1
Reference: [Abdou and Pratt 79] <author> I.E. Abdou and W.K. Pratt, </author> <title> "Quantitative Design and Evaluation of Enhancement/Thresholding Edge Detectors," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 67 </volume> <pages> 753-763, </pages> <year> 1979. </year>
Reference-contexts: 5 Experimental Results Upon surveying the literature, we found a number of methods that have been used to compare the performance of feature detectors: * Examine the rates of occurrence of false positives and false negatives when applied to synthetically generated feature instances. (See, for example, [Fram and Deutsch 75], <ref> [Abdou and Pratt 79] </ref>, and [Nalwa and Binford 86].) * Study the accuracy of parameter estimation, either using statistical tests or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], [Abdou and Pratt 79], [Berzins 84], and [Nalwa and Binford 86].) * Evaluate measures that combine <p> negatives when applied to synthetically generated feature instances. (See, for example, [Fram and Deutsch 75], <ref> [Abdou and Pratt 79] </ref>, and [Nalwa and Binford 86].) * Study the accuracy of parameter estimation, either using statistical tests or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], [Abdou and Pratt 79], [Berzins 84], and [Nalwa and Binford 86].) * Evaluate measures that combine feature detection rates with parameter estimation ac curacy. (One example is Pratt's Figure of Merit [Abdou and Pratt 79] [Pratt 90].) * Subjectively analyze detector outputs when applied to real or synthetic images. (Almost all <p> either using statistical tests or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], <ref> [Abdou and Pratt 79] </ref>, [Berzins 84], and [Nalwa and Binford 86].) * Evaluate measures that combine feature detection rates with parameter estimation ac curacy. (One example is Pratt's Figure of Merit [Abdou and Pratt 79] [Pratt 90].) * Subjectively analyze detector outputs when applied to real or synthetic images. (Almost all feature detection papers do this.) We begin this experimental section by presenting the results of a sequence of statistical tests.
Reference: [Baker and Nayar 96] <author> S. Baker and S.K. Nayar, </author> <title> "Pattern Rejection," </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> San Francisco, </address> <year> 1996. </year>
Reference-contexts: Further, we do not need to perform the search at every pixel in the image. Amongst other techniques, we use a recently developed rejection algorithm <ref> [Baker and Nayar 96] </ref> to quickly eliminate a vast majority of pixels without even needing to project fully into the low dimensional subspace. Such a rejection scheme is feasible and effective since most pixels in an image do not represent features of interest. <p> Since the distance from the subspace is (approximately) a lower bound on the distance from the manifold, if the distance is too large, we can immediately decide that the pixel does not contain the feature. Using the techniques in <ref> [Baker and Nayar 96] </ref>, we can even avoid most of the cost of computing the distance from the K-L subspace. Parallel Implementation: Feature detection is inherently a parallelizable task.
Reference: [Barbe 80] <editor> D.F. Barbe, editor, Charge-Coupled Devices, </editor> <publisher> Springer-Verlag, </publisher> <year> 1980. </year>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular <ref> [Barbe 80] </ref> [Norton 82], the averaging function is simply the rectangular function [Bracewell 78]: a (x; y) = w x w y 1 x; w y where, w x and w y are the x and y dimensions of the pixel, respectively.
Reference: [Berzins 84] <author> V. Berzins, </author> <title> "Accuracy of Laplacian Edge Detectors," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 27 </volume> <pages> 195-210, </pages> <year> 1984. </year>
Reference-contexts: synthetically generated feature instances. (See, for example, [Fram and Deutsch 75], [Abdou and Pratt 79], and [Nalwa and Binford 86].) * Study the accuracy of parameter estimation, either using statistical tests or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], [Abdou and Pratt 79], <ref> [Berzins 84] </ref>, and [Nalwa and Binford 86].) * Evaluate measures that combine feature detection rates with parameter estimation ac curacy. (One example is Pratt's Figure of Merit [Abdou and Pratt 79] [Pratt 90].) * Subjectively analyze detector outputs when applied to real or synthetic images. (Almost all feature detection papers do
Reference: [Born and Wolf 65] <author> M. Born and E. Wolf, </author> <title> Principles of Optics, </title> <publisher> Permagon Press, </publisher> <year> 1965. </year>
Reference-contexts: Moreover, the level of defocus is not constant across the image and so we will develop an approach that can handle spatially varying blur. The defocus factor can be approximated by a pillbox function <ref> [Born and Wolf 65] </ref>, the optical transfer function by the square of the first-order Bessel func 5 tion of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian [Koenderink 84]. <p> The defocus factor can be approximated by a pillbox function <ref> [Born and Wolf 65] </ref>, the optical transfer function by the square of the first-order Bessel func 5 tion of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian [Koenderink 84].
Reference: [Bracewell 78] <author> R.N. Bracewell, </author> <title> The Fourier Transform and Its Applications, Second Edition, </title> <publisher> McGraw-Hill Book Co., </publisher> <year> 1978. </year>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular [Barbe 80] [Norton 82], the averaging function is simply the rectangular function <ref> [Bracewell 78] </ref>: a (x; y) = w x w y 1 x; w y where, w x and w y are the x and y dimensions of the pixel, respectively. <p> g : s (x; y) (4) where fl is the 2-D convolution operator. (Note that g (x; y), a (x; y), and s (x; y) are all unit volume and so the feature image is not scaled.) Since the above image is simply a weighted sum of Kronecker delta functions <ref> [Bracewell 78] </ref>, it can also be written as F (m; n; q), where (m; n) 2 S are the (integer valued) pixel coordinates. It is important to note that the blurring, averaging, and sampling functions vary from sensor to sensor.
Reference: [Canny 86] <author> J. Canny, </author> <title> "A Computational Approach to Edge Detection," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 679-698, </pages> <year> 1986. </year>
Reference-contexts: Further, we focus on detectors that fit parametric feature models to the image intensities rather than detectors based on the gradient (e.g. [Prewitt 70]), Laplacian (e.g. [Marr and Hildreth 80]), second directional derivatives (e.g. <ref> [Canny 86] </ref> [Haralick 84]), Hessian determinant (e.g. [Deriche and Giraudon 93]), or other differential invariants. A concise description of one-dimensional image features (e.g. step edges, roof edges, and lines) and a survey of step edge detectors can be found in [Nalwa 93]. <p> In Section 4, the detection algorithm is presented in detail. In particular, we describe manifold sampling, efficient search, and the use of rejection techniques. In Section 5, our experimental results are presented, which include comparisons with the Canny <ref> [Canny 86] </ref> and Nalwa-Binford [Nalwa and Binford 86] step edge detectors. We conclude in Section 6 with a discussion of several issues arising from our work. 2 Parametric Feature Representation We begin by presenting the theoretical basis of our approach to feature detection. <p> In Section 5.1 we study feature detection rates, and then move on to investigate parameter estimation accuracy in Section 5.2. In both cases, we compare our step edge detector with those of Canny <ref> [Canny 86] </ref> and Nalwa-Binford [Nalwa and Binford 86]. In this, our aim is to demonstrate that the parametric manifold method performs comparably to these well-known step edge detectors. <p> In Sections 5.3 and 5.4 we present the results of applying our feature detectors to a number of real and synthetic images. 22 5.1 Feature Detection Rates We first statistically compare our step edge detector with the Canny <ref> [Canny 86] </ref> and Nalwa-Binford [Nalwa and Binford 86] detectors. For reasons of consistency with previous work, we follow the approach taken in [Nalwa and Binford 86]. The statistical analysis consists of two phases. <p> This implementation computes the Gaussian smoothed gradient which we then immediately threshold to detect edges. For simplicity, we do not find the zero crossing of the second directional derivative. Neither do we perform hysteresis <ref> [Canny 86] </ref> since this uses information derived from neighboring windows. 23 against false negatives. For each detector and S.N.R., the result is a curve parameterized by the threshold inherent in that detector. The closer a curve lies to the origin, the better the performance. <p> For the same reasons as before, we again used our feature models to generate the synthetic features. In Figure 9 we compare the performance of our step edge detector with that of the Canny detector <ref> [Canny 86] </ref> and the Nalwa-Binford [Nalwa and Binford 86] detector. For fairness, as before, we used the parametric step edge detector computed for a 5fi5 square window, and with the blurring parameter fixed at 0:6 pixels. <p> The original images are all taken from [MOMA 84] and were digitized using an Envisions 6600S scanner at 200dpi. Feature detection was accomplished by thresholding on the distance from the feature manifold. No further post-processing or sophisticated thresholding techniques (e.g. hysteresis <ref> [Canny 86] </ref>) were applied. One slight change was made to the raw feature maps for clarity.
Reference: [Deriche and Giraudon 93] <author> R. Deriche and G. Giraudon, </author> <title> "A Computational Approach for Corner and Vertex Detection," </title> <journal> International Journal of Computer Vision, </journal> <volume> 10 </volume> <pages> 101-124, </pages> <year> 1993. </year>
Reference-contexts: Further, we focus on detectors that fit parametric feature models to the image intensities rather than detectors based on the gradient (e.g. [Prewitt 70]), Laplacian (e.g. [Marr and Hildreth 80]), second directional derivatives (e.g. [Canny 86] [Haralick 84]), Hessian determinant (e.g. <ref> [Deriche and Giraudon 93] </ref>), or other differential invariants. A concise description of one-dimensional image features (e.g. step edges, roof edges, and lines) and a survey of step edge detectors can be found in [Nalwa 93]. The papers by Rohr [Rohr 92] and Deriche and Giraudon [Deriche and Giraudon 93] cover most <p> [Haralick 84]), Hessian determinant (e.g. <ref> [Deriche and Giraudon 93] </ref>), or other differential invariants. A concise description of one-dimensional image features (e.g. step edges, roof edges, and lines) and a survey of step edge detectors can be found in [Nalwa 93]. The papers by Rohr [Rohr 92] and Deriche and Giraudon [Deriche and Giraudon 93] cover most of the previous work concerning the two-dimensional problems of corner detection and junction detection. 1 to make any simplifications for analytic or efficiency reasons, but instead use realistic multi--parameter feature models. <p> Most existing approaches to corner detection are based upon differential geometric measures of curvature such as the determinant of the Hessian or the second directional derivative orthogonal to the gradient <ref> [Deriche and Giraudon 93] </ref>. Recently, Rohr [Rohr 92] proposed a parametric model fitting approach to detect corners. The simplest way to think about a corner is as the intersection point of two non-parallel lines.
Reference: [Deutsch and Fram 78] <author> E.S. Deutsch and J.R. Fram, </author> <title> "A Quantitative Study of the Orientation Bias of Some Edge Detector Schemes," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 27 </volume> <pages> 205-213, </pages> <year> 1978. </year>
Reference-contexts: false positives and false negatives when applied to synthetically generated feature instances. (See, for example, [Fram and Deutsch 75], [Abdou and Pratt 79], and [Nalwa and Binford 86].) * Study the accuracy of parameter estimation, either using statistical tests or through an analytical investigation of systematic biases. (See, for example, <ref> [Deutsch and Fram 78] </ref>, [Abdou and Pratt 79], [Berzins 84], and [Nalwa and Binford 86].) * Evaluate measures that combine feature detection rates with parameter estimation ac curacy. (One example is Pratt's Figure of Merit [Abdou and Pratt 79] [Pratt 90].) * Subjectively analyze detector outputs when applied to real or
Reference: [Fram and Deutsch 75] <author> J.R. Fram and E.S. Deutsch, </author> <title> "On the Quantitative Evaluation of Edge Detection Schemes and Their Comparison with Human Performance," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 24 </volume> <pages> 616-628, </pages> <year> 1975. </year>
Reference-contexts: proposed detectors in real-time. 5 Experimental Results Upon surveying the literature, we found a number of methods that have been used to compare the performance of feature detectors: * Examine the rates of occurrence of false positives and false negatives when applied to synthetically generated feature instances. (See, for example, <ref> [Fram and Deutsch 75] </ref>, [Abdou and Pratt 79], and [Nalwa and Binford 86].) * Study the accuracy of parameter estimation, either using statistical tests or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], [Abdou and Pratt 79], [Berzins 84], and [Nalwa and Binford 86].) *
Reference: [Fukunaga 90] <author> K. Fukunaga, </author> <title> Introduction to Statistical Pattern Recognition, </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference: [O'Gorman 78] <author> F. O'Gorman, </author> <title> "Edge Detection Using Walsh Functions," </title> <journal> Artificial Intelligence, </journal> <volume> 10 </volume> <pages> 215-233, </pages> <year> 1978. </year> <month> 36 </month>
Reference-contexts: On the other hand, if the nearest manifold point is too far away from the novel point, we declare the absence of the feature. This statement of the feature detection problem was first introduced by Hueckel [Hueckel 71], and was subsequently used by O'Gorman <ref> [O'Gorman 78] </ref>, Hummel [Hummel 79], Hartley [Hartley 85], and Nalwa and Binford [Nalwa and Binford 86] for the detection of step edges. Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners.
Reference: [Haralick 84] <author> R.M. Haralick, </author> <title> "Digital Step Edges from Zero Crossing of Second Directional Derivatives," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 58-68, </pages> <year> 1984. </year>
Reference-contexts: Further, we focus on detectors that fit parametric feature models to the image intensities rather than detectors based on the gradient (e.g. [Prewitt 70]), Laplacian (e.g. [Marr and Hildreth 80]), second directional derivatives (e.g. [Canny 86] <ref> [Haralick 84] </ref>), Hessian determinant (e.g. [Deriche and Giraudon 93]), or other differential invariants. A concise description of one-dimensional image features (e.g. step edges, roof edges, and lines) and a survey of step edge detectors can be found in [Nalwa 93].
Reference: [Hartley 85] <author> R. </author> <title> Hartley, "A Guassian-Weighted Multiresolution Edge Detector," Computer Vision, Graphics, </title> <booktitle> Image Processing, </booktitle> <volume> 30 </volume> <pages> 70-83, </pages> <year> 1985. </year>
Reference-contexts: This statement of the feature detection problem was first introduced by Hueckel [Hueckel 71], and was subsequently used by O'Gorman [O'Gorman 78], Hummel [Hummel 79], Hartley <ref> [Hartley 85] </ref>, and Nalwa and Binford [Nalwa and Binford 86] for the detection of step edges. Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners.
Reference: [Horn 86] <author> B. K. P. Horn, </author> <title> Robot Vision, </title> <publisher> McGraw Hill, </publisher> <year> 1986. </year>
Reference-contexts: It is known that image brightness is proportional to scene radiance <ref> [Horn 86] </ref>. The image feature is therefore the continuous radiance function of the scene feature. It can be written as F c (x; y; q) where (x; y) 2 S are image points within a finite feature window, S, and q are the parameters of the feature.
Reference: [Hueckel 71] <author> M.H. Hueckel, </author> <title> "An Operator Which Locates Edges in Digitized Pictures," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 18 </volume> <pages> 113-125, </pages> <year> 1971. </year>
Reference-contexts: On the other hand, if the nearest manifold point is too far away from the novel point, we declare the absence of the feature. This statement of the feature detection problem was first introduced by Hueckel <ref> [Hueckel 71] </ref>, and was subsequently used by O'Gorman [O'Gorman 78], Hummel [Hummel 79], Hartley [Hartley 85], and Nalwa and Binford [Nalwa and Binford 86] for the detection of step edges. Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners. <p> The same approach generalizes to three-dimensional image data as was used by Zucker and Hummel [Zucker and Hummel 81] and also by Lenz [Lenz 87] in the detection of three-dimensional step edges. Hueckel <ref> [Hueckel 71] </ref> and Hummel [Hummel 79] both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest manifold point. To make their derivations possible, they used simplified feature models and neglected sensing effects. <p> The techniques are not restricted to brightness images, but may also be applied to features found in data produced by most other types of sensors. 3.1 Step Edge Our first example feature is the familiar step edge. Parametric models for edges date back to the work of Hueckel <ref> [Hueckel 71] </ref>. Since then, the edge has been studied in more detail than any other visual feature (see [Nalwa 93]). Figures 1 (a) and 1 (b) show the isometric and plan views of the step edge model which we use. This model is a generalization of those used in [Hueckel 71], <p> Hueckel <ref> [Hueckel 71] </ref>. Since then, the edge has been studied in more detail than any other visual feature (see [Nalwa 93]). Figures 1 (a) and 1 (b) show the isometric and plan views of the step edge model which we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87]. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing effects. <p> This figure is by no means the best we can do in terms of efficiency. Rejection: We do not need to apply the coarse-to-fine search at every pixel in the image. This observation is almost as old as edge detection itself and is explicitly mentioned in <ref> [Hueckel 71] </ref>. Combining a variety of techniques, we have already reduced the time to process a 512 fi 480 image to less than a minute. In particular, we currently threshold on the magnitude, -, obtained during normalization.
Reference: [Hueckel 73] <author> M.H. Hueckel, </author> <title> "A Local Visual Operator Which Recognizes Edges and Lines," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20 </volume> <pages> 634-647, </pages> <year> 1973. </year>
Reference-contexts: This statement of the feature detection problem was first introduced by Hueckel [Hueckel 71], and was subsequently used by O'Gorman [O'Gorman 78], Hummel [Hummel 79], Hartley [Hartley 85], and Nalwa and Binford [Nalwa and Binford 86] for the detection of step edges. Hueckel <ref> [Hueckel 73] </ref> applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners. The same approach generalizes to three-dimensional image data as was used by Zucker and Hummel [Zucker and Hummel 81] and also by Lenz [Lenz 87] in the detection of three-dimensional step edges. <p> The projection onto the first two eigenvectors is similar; it is approximately a circle. 3.3 Line The line consists of a pair of parallel step edges separated by a short distance, namely, the width w of the line <ref> [Hueckel 73] </ref>. Our line model is illustrated in Figure 3 (a). In our definition, we assume that the intensity steps are both of the same magnitude. <p> Our line model is illustrated in Figure 3 (a). In our definition, we assume that the intensity steps are both of the same magnitude. It is possible to generalize the model to lines with different intensities on either side of the line with the addition of one extra parameter <ref> [Hueckel 73] </ref>.
Reference: [Hummel 79] <author> R.A. Hummel, </author> <title> "Feature Detection Using Basis Functions," </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9 </volume> <pages> 40-55, </pages> <year> 1979. </year>
Reference-contexts: On the other hand, if the nearest manifold point is too far away from the novel point, we declare the absence of the feature. This statement of the feature detection problem was first introduced by Hueckel [Hueckel 71], and was subsequently used by O'Gorman [O'Gorman 78], Hummel <ref> [Hummel 79] </ref>, Hartley [Hartley 85], and Nalwa and Binford [Nalwa and Binford 86] for the detection of step edges. Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners. <p> The same approach generalizes to three-dimensional image data as was used by Zucker and Hummel [Zucker and Hummel 81] and also by Lenz [Lenz 87] in the detection of three-dimensional step edges. Hueckel [Hueckel 71] and Hummel <ref> [Hummel 79] </ref> both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest manifold point. To make their derivations possible, they used simplified feature models and neglected sensing effects. Our view of feature detection is radically different. <p> Dramatic dimension reduction is possible because most features of interest have significant structure and inherent symmetries. In practice, d 3 turns out to be in the range 5-15. Dimension reduction was first used in feature detection by Hummel <ref> [Hummel 79] </ref> and a similar compressed representation was proposed for 3-D object recognition and pose estimation in [Murase and Nayar 95]. During the search itself, we use a coarse-to-fine algorithm that exploits the local smoothness of the feature manifolds to quickly find the closest sample point. <p> Further, the dramatic dimension reduction produced by the K-L expansion together with the parameter elimination achieved through the brightness normalization described in Section 2.4 allow us to compactly represent features and detect them efficiently. 2 This idea was first explored by Hummel <ref> [Hummel 79] </ref> and later by Lenz [Lenz 87]. Whereas Hummel derived closed-form solutions for the optimal subspace based upon simplified feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality [Nayar et al. 96]. <p> Since then, the edge has been studied in more detail than any other visual feature (see [Nalwa 93]). Figures 1 (a) and 1 (b) show the isometric and plan views of the step edge model which we use. This model is a generalization of those used in [Hueckel 71], <ref> [Hummel 79] </ref>, and [Lenz 87]. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing effects. <p> The results of applying the Karhunen-Loeve expansion are displayed in Figures 1 (c) and 1 (d). In Figure 1 (c) we display the 8 most important eigenvectors, ordered by their eigenvalues. The similarity between the first 4 eigenvectors and the ones derived analytically by Hummel in <ref> [Hummel 79] </ref> is immediate. On closer inspection, we notice that while Hummel's eigenvectors are radially symmetric, the ones we computed are not. This is to be expected since the introduction of the parameters and breaks the radial symmetry that Hummel's edge model assumes. <p> To reduce the residue to 10% we need to use 3 eigenvectors. To reduce it further to 2% we need 8 eigenvectors. These results illustrate a significant data compression factor of 5-15 times. As a result, the efficiency of feature detection and parameter estimation is greatly enhanced. Hummel <ref> [Hummel 79] </ref> predicts that for his continuous step edge model, the eigenvalues should decay like 1=n 2 . Our results are consistent with this. <p> Our results are consistent with this. By plotting n against n on logarithmic scales and analyzing 11 the slope of the curve, we found that our eigenvalues initially decay like 1=n 2 . Because we are working in &lt; N rather than the infinite dimensional Hilbert Space of <ref> [Hummel 79] </ref>, the rate of decay increases somewhat with increasing n. The step edge manifold is displayed in Figure 1 (e). Naturally, we are only able to display a 3-D projection of it into a subspace. This subspace is spanned by the 3 most important eigenvectors.
Reference: [Knuth 81] <author> D.E. Knuth, </author> <title> The Art of Computer Programming, Volume II: Seminumerical Algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> 1981. </year>
Reference-contexts: column for each feature and consists of the sampling interval determined for each parameter. 4.2 Search for the Closest Manifold Point Finding the nearest neighbor amongst a fixed set of points to a given novel point is a well studied problem in computational geometry, and was first posed by Knuth <ref> [Knuth 81] </ref>. The more recent paper [Yianilos 93] contains a pretty comprehensive bibliography of algorithms developed since then. Our problem has more structure than the general nearest neighbor problem since we know that the points lie on a parametric manifold.
Reference: [Koenderink 84] <author> J.J. Koenderink, </author> <title> "The Structure of Images," </title> <journal> Biological Cybernetics,' </journal> <volume> 50 </volume> <pages> 363-370, </pages> <year> 1984. </year>
Reference-contexts: The defocus factor can be approximated by a pillbox function [Born and Wolf 65], the optical transfer function by the square of the first-order Bessel func 5 tion of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian <ref> [Koenderink 84] </ref>.
Reference: [Krumm 96] <author> J. Krumm, </author> <title> "Eigenfeatures for Planar Pose Measurement of Partially Occluded Objects," </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> San Francisco, </address> <year> 1996. </year>
Reference-contexts: Combining the outputs of a number of such detectors, 5 Recent work <ref> [Krumm 96] </ref> uses this approach to detect planar patterns with unknown rotation. 32 (a) Original image (564 fi 611 pixels) (b) Grey-coded distance to step edge manifold (c) Grey-coded distance to corner manifold (d) Grey-coded distance to line manifold House," by Gerrit Rietveld, 1924.
Reference: [Lenz 87] <author> R. Lenz, </author> <title> "Optimal Filters for the Detection of Linear Patterns in 2-D and Higher Dimensional Images," </title> <journal> Pattern Recognition, </journal> <volume> 20 </volume> <pages> 163-172, </pages> <year> 1987. </year>
Reference-contexts: Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners. The same approach generalizes to three-dimensional image data as was used by Zucker and Hummel [Zucker and Hummel 81] and also by Lenz <ref> [Lenz 87] </ref> in the detection of three-dimensional step edges. Hueckel [Hueckel 71] and Hummel [Hummel 79] both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest manifold point. <p> Further, the dramatic dimension reduction produced by the K-L expansion together with the parameter elimination achieved through the brightness normalization described in Section 2.4 allow us to compactly represent features and detect them efficiently. 2 This idea was first explored by Hummel [Hummel 79] and later by Lenz <ref> [Lenz 87] </ref>. Whereas Hummel derived closed-form solutions for the optimal subspace based upon simplified feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality [Nayar et al. 96]. <p> Figures 1 (a) and 1 (b) show the isometric and plan views of the step edge model which we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and <ref> [Lenz 87] </ref>. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86] in terms of the number and type of parameters, but differs slightly in its treatment of smoothing effects.
Reference: [Marr and Hildreth 80] <author> D. Marr and E. Hildreth, </author> <title> "Theory of edge detection," </title> <journal> Proceedings of the Royal Society of London, Series B, </journal> <volume> 207 </volume> <pages> 187-217, </pages> <year> 1980. </year>
Reference-contexts: In our discussion we will provide examples of existing detectors without attempting to mention all of them. Further, we focus on detectors that fit parametric feature models to the image intensities rather than detectors based on the gradient (e.g. [Prewitt 70]), Laplacian (e.g. <ref> [Marr and Hildreth 80] </ref>), second directional derivatives (e.g. [Canny 86] [Haralick 84]), Hessian determinant (e.g. [Deriche and Giraudon 93]), or other differential invariants. A concise description of one-dimensional image features (e.g. step edges, roof edges, and lines) and a survey of step edge detectors can be found in [Nalwa 93].
Reference: [MOMA 84] <institution> The Museum of Modern Art New York: </institution> <note> The History and the Collection, </note> <author> Harry N. Abrams, Inc., </author> <year> 1984. </year>
Reference-contexts: The original images are all taken from <ref> [MOMA 84] </ref> and were digitized using an Envisions 6600S scanner at 200dpi. Feature detection was accomplished by thresholding on the distance from the feature manifold. No further post-processing or sophisticated thresholding techniques (e.g. hysteresis [Canny 86]) were applied. One slight change was made to the raw feature maps for clarity.
Reference: [Moravec 77] <author> H.P. Moravec, </author> <title> "Towards Automatic Visual Obstacle Avoidance," </title> <booktitle> In Proceedings of the Fifth Internation Joint Conference on Artificial Intelligence, </booktitle> <year> 1977. </year>
Reference-contexts: Combining a variety of techniques, we have already reduced the time to process a 512 fi 480 image to less than a minute. In particular, we currently threshold on the magnitude, -, obtained during normalization. This technique is similar to Moravec's interest operator <ref> [Moravec 77] </ref> used to predict the usefulness of potential stereo correspondence matches. We also threshold on the distance of the novel point from the K-L subspace.
Reference: [Murase and Nayar 95] <author> H. Murase and S.K. Nayar, </author> <title> "Visual Learning and Recognition of 3-D Objects from Appearance," </title> <journal> International Journal of Computer Vision, </journal> <volume> 14 </volume> <pages> 5-24, </pages> <year> 1995 </year> <month> 37 </month>
Reference-contexts: In practice, d 3 turns out to be in the range 5-15. Dimension reduction was first used in feature detection by Hummel [Hummel 79] and a similar compressed representation was proposed for 3-D object recognition and pose estimation in <ref> [Murase and Nayar 95] </ref>. During the search itself, we use a coarse-to-fine algorithm that exploits the local smoothness of the feature manifolds to quickly find the closest sample point. Further, we do not need to perform the search at every pixel in the image.
Reference: [Nalwa 93] <author> V.S. Nalwa, </author> <title> A Guided Tour of Computer Vision, </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: A concise description of one-dimensional image features (e.g. step edges, roof edges, and lines) and a survey of step edge detectors can be found in <ref> [Nalwa 93] </ref>. The papers by Rohr [Rohr 92] and Deriche and Giraudon [Deriche and Giraudon 93] cover most of the previous work concerning the two-dimensional problems of corner detection and junction detection. 1 to make any simplifications for analytic or efficiency reasons, but instead use realistic multi--parameter feature models. <p> Parametric models for edges date back to the work of Hueckel [Hueckel 71]. Since then, the edge has been studied in more detail than any other visual feature (see <ref> [Nalwa 93] </ref>). Figures 1 (a) and 1 (b) show the isometric and plan views of the step edge model which we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87]. <p> If we were able to visualize a higher dimensional projection, the singularities would disappear. 3.2 Roof Edge The roof edge is similar to the step edge. However, unlike the step edge, it has not been explored much in the past despite having been acknowledged as a pertinent feature <ref> [Nalwa 93] </ref>. The difference between the two edge models is that the step discontinuity is replaced by a uniform intensity gradient as shown in Figure 2 (a). <p> Hence, we used a square window containing N = 25 pixels for our detector, rather than the 49 pixel disc window presented in Figure 1. Another issue is the lack of a model for a window not containing an edge <ref> [Nalwa 93] </ref>. We resolve this, as in [Nalwa and Binford 86], by taking a constant intensity window as our characteristic non-edge. Finally, we need to be able to measure the amount of noise in a consistent way across the five features.
Reference: [Nalwa and Binford 86] <author> V.S. </author> <title> Nalwa and T.O. Binford, "On Detecting Edges," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 699-714, </pages> <year> 1986. </year>
Reference-contexts: This statement of the feature detection problem was first introduced by Hueckel [Hueckel 71], and was subsequently used by O'Gorman [O'Gorman 78], Hummel [Hummel 79], Hartley [Hartley 85], and Nalwa and Binford <ref> [Nalwa and Binford 86] </ref> for the detection of step edges. Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners. <p> Typically, this sampling will result in the order of 10 5 points, which lie in a space of dimension, N = 25-100. Further, the search for the closest manifold point must be repeated for each window (centered around each pixel) in the image. Nalwa and Binford <ref> [Nalwa and Binford 86] </ref> and Rohr [Rohr 92] used more complex feature models than Hueckel and Hummel and also used numerical methods to find the best-fit parameters of their models to the image data. <p> In Section 4, the detection algorithm is presented in detail. In particular, we describe manifold sampling, efficient search, and the use of rejection techniques. In Section 5, our experimental results are presented, which include comparisons with the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> step edge detectors. We conclude in Section 6 with a discussion of several issues arising from our work. 2 Parametric Feature Representation We begin by presenting the theoretical basis of our approach to feature detection. First, the notion of a parameterized scene feature is introduced. <p> Figures 1 (a) and 1 (b) show the isometric and plan views of the step edge model which we use. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87]. It is closest to the one used by Nalwa and Binford <ref> [Nalwa and Binford 86] </ref> in terms of the number and type of parameters, but differs slightly in its treatment of smoothing effects. <p> The blurring parameter, , is drawn from [0:3; 1:5]. As described in <ref> [Nalwa and Binford 86] </ref>, substantially larger values of could be used, but really represent an edge at a much higher magnification. Such cases require the use of a larger image window. The intensity parameters A and B are free to take any value. <p> the literature, we found a number of methods that have been used to compare the performance of feature detectors: * Examine the rates of occurrence of false positives and false negatives when applied to synthetically generated feature instances. (See, for example, [Fram and Deutsch 75], [Abdou and Pratt 79], and <ref> [Nalwa and Binford 86] </ref>.) * Study the accuracy of parameter estimation, either using statistical tests or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], [Abdou and Pratt 79], [Berzins 84], and [Nalwa and Binford 86].) * Evaluate measures that combine feature detection rates with parameter <p> instances. (See, for example, [Fram and Deutsch 75], [Abdou and Pratt 79], and <ref> [Nalwa and Binford 86] </ref>.) * Study the accuracy of parameter estimation, either using statistical tests or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], [Abdou and Pratt 79], [Berzins 84], and [Nalwa and Binford 86].) * Evaluate measures that combine feature detection rates with parameter estimation ac curacy. (One example is Pratt's Figure of Merit [Abdou and Pratt 79] [Pratt 90].) * Subjectively analyze detector outputs when applied to real or synthetic images. (Almost all feature detection papers do this.) We begin <p> In Section 5.1 we study feature detection rates, and then move on to investigate parameter estimation accuracy in Section 5.2. In both cases, we compare our step edge detector with those of Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref>. In this, our aim is to demonstrate that the parametric manifold method performs comparably to these well-known step edge detectors. <p> In Sections 5.3 and 5.4 we present the results of applying our feature detectors to a number of real and synthetic images. 22 5.1 Feature Detection Rates We first statistically compare our step edge detector with the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detectors. For reasons of consistency with previous work, we follow the approach taken in [Nalwa and Binford 86]. The statistical analysis consists of two phases. <p> applying our feature detectors to a number of real and synthetic images. 22 5.1 Feature Detection Rates We first statistically compare our step edge detector with the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detectors. For reasons of consistency with previous work, we follow the approach taken in [Nalwa and Binford 86]. The statistical analysis consists of two phases. In the first phase we generate a number of ideal step edges, add zero-mean Gaussian noise to them, and then apply the three step edge detectors. <p> Hence, we used a square window containing N = 25 pixels for our detector, rather than the 49 pixel disc window presented in Figure 1. Another issue is the lack of a model for a window not containing an edge [Nalwa 93]. We resolve this, as in <ref> [Nalwa and Binford 86] </ref>, by taking a constant intensity window as our characteristic non-edge. Finally, we need to be able to measure the amount of noise in a consistent way across the five features. <p> is that for an step edge with no blur in a window and where half of the pixels are on each side of the edge, the value of the S.N.R. is the size of the step (i.e. the value of parameter B), which is the measure of S.N.R. used in <ref> [Nalwa and Binford 86] </ref> 3 We used an implementation of the Canny operator provided by Geoff West of Curtin University, Western Australia, which is publically available from URL http://www.cs.curtin.edu.au/ geoff/. This implementation computes the Gaussian smoothed gradient which we then immediately threshold to detect edges. <p> The closer a curve lies to the origin, the better the performance. We see that the Canny detector and the parametric manifold technique perform comparably. The results for the Nalwa-Binford detector are consistent with those presented in <ref> [Nalwa and Binford 86] </ref> but are of a fundamentally different nature. See text for a discussion of this. In Figure 7 we compare the detection performance of the three edge detectors. Inherent in each of the three detectors is a threshold. <p> Further, we note that the two detectors perform comparably, with our algorithm doing very marginally better 4 . 4 These results differ slightly from the ones presented in [Nayar et al. 96] as they reflect refinements made 24 The results for the Nalwa-Binford detector are consistent with those presented in <ref> [Nalwa and Binford 86] </ref>. (We did not use step 2)' of the algorithm.) Independently of the S.N.R., the percentage of false positives in Figure 7 never exceeds 32%. This validates Figure 8 of [Nalwa and Binford 86]. <p> they reflect refinements made 24 The results for the Nalwa-Binford detector are consistent with those presented in <ref> [Nalwa and Binford 86] </ref>. (We did not use step 2)' of the algorithm.) Independently of the S.N.R., the percentage of false positives in Figure 7 never exceeds 32%. This validates Figure 8 of [Nalwa and Binford 86]. Secondly, for a S.N.R. of 1.0, the number of false negatives in Figure 7 never drops below 56%, whereas in Figure 9 of [Nalwa and Binford 86] its lowest level is 77%. <p> This validates Figure 8 of <ref> [Nalwa and Binford 86] </ref>. Secondly, for a S.N.R. of 1.0, the number of false negatives in Figure 7 never drops below 56%, whereas in Figure 9 of [Nalwa and Binford 86] its lowest level is 77%. These two numerical results are slightly different because (a) we use a different model to generate the ideal step edges, and (b) our definition of S.N.R. yields a slightly lower value than the definition in [Nalwa and Binford 86] due to blurred <p> 56%, whereas in Figure 9 of <ref> [Nalwa and Binford 86] </ref> its lowest level is 77%. These two numerical results are slightly different because (a) we use a different model to generate the ideal step edges, and (b) our definition of S.N.R. yields a slightly lower value than the definition in [Nalwa and Binford 86] due to blurred and off center edges. Comparing our results with those in Figure 9 of [Nalwa and Binford 86], we see that our curve for S.N.R. 1.0 lies somewhere between the two curves for S.N.R. 1.0 and 2.0. <p> slightly different because (a) we use a different model to generate the ideal step edges, and (b) our definition of S.N.R. yields a slightly lower value than the definition in <ref> [Nalwa and Binford 86] </ref> due to blurred and off center edges. Comparing our results with those in Figure 9 of [Nalwa and Binford 86], we see that our curve for S.N.R. 1.0 lies somewhere between the two curves for S.N.R. 1.0 and 2.0. <p> The reason that the Nalwa-Binford performs qualitatively differently to the Canny and Parametric Manifold detectors in Figure 7 is its inherent conservatism in detecting edges, as enforced by steps 4) and 5) of the Nalwa-Binford algorithm (see page 704 of <ref> [Nalwa and Binford 86] </ref>). In Figure 8 we compare the detection rates of our five example features. In the figure, the curves are all plotted for S.N.R. 1.0, and for a disc shaped window containing 49 pixels. <p> For S.N.R. above about 3.0, all the detectors perform almost without error. 5.2 Parameter Estimation Accuracy Assessing the performance of parameter estimation is relatively straightforward when compared to that of feature detection robustness. Again, generalizing the procedure used in <ref> [Nalwa and Binford 86] </ref>, we randomly generate a vector of feature parameters, synthesize a feature with those parameters, add a known amount of zero-mean white Gaussian noise, apply the detector, and then measure the accuracy of the estimated parameters. <p> For the same reasons as before, we again used our feature models to generate the synthetic features. In Figure 9 we compare the performance of our step edge detector with that of the Canny detector [Canny 86] and the Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detector. For fairness, as before, we used the parametric step edge detector computed for a 5fi5 square window, and with the blurring parameter fixed at 0:6 pixels. In the figure, we plot the R.M.S. error in the estimate of the orientation against the S.N.R. <p> In the figure, we plot the R.M.S. error in the estimate of the orientation against the S.N.R. The plot is consistent with the performance figures for the Nalwa-Binford detector presented in <ref> [Nalwa and Binford 86] </ref>, after allowing for the different feature models used and definition of S.N.R. We see that for low S.N.R. the performance of all detectors is severely limited by the noise. However, for all noise levels, the parametric manifold detector marginally outperforms both of the other detectors.
Reference: [Nayar et al. 96] <author> S. K. Nayar, S. Baker, and H. Murase, </author> <title> "Parametric Feature Detection," </title> <booktitle> In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> San Fransisco, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Whereas Hummel derived closed-form solutions for the optimal subspace based upon simplified feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality <ref> [Nayar et al. 96] </ref>. A similar approach has been adopted by Nandy et al. [Nandy et al. 96] in concurrent work. 8 3 Example Features We now illustrate the manifold representations of 5 parametric features. <p> We see that both the Canny detector and our detector do increasingly well as the S.N.R. increases. Further, we note that the two detectors perform comparably, with our algorithm doing very marginally better 4 . 4 These results differ slightly from the ones presented in <ref> [Nayar et al. 96] </ref> as they reflect refinements made 24 The results for the Nalwa-Binford detector are consistent with those presented in [Nalwa and Binford 86]. (We did not use step 2)' of the algorithm.) Independently of the S.N.R., the percentage of false positives in Figure 7 never exceeds 32%.
Reference: [Nandy et al. 96] <author> D. Nandy, Z. Wang, J. Ben-Arie, K.R. Rao, N. Jojic, </author> <title> "A Generalized Feature Extractor using Expansion Matching and the Karhunen-Loeve Transform," </title> <booktitle> In Proceedings of the ARPA Image Understanding Workshop, </booktitle> <address> Palm Springs, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Whereas Hummel derived closed-form solutions for the optimal subspace based upon simplified feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality [Nayar et al. 96]. A similar approach has been adopted by Nandy et al. <ref> [Nandy et al. 96] </ref> in concurrent work. 8 3 Example Features We now illustrate the manifold representations of 5 parametric features. For each feature, we provide a definition of the feature, list its parameters, discuss the effects of brightness normalization, and present the results of dimension reduction.
Reference: [Nayar et al. 96] <author> S.K. Nayar, S. Baker, and H. Murase, </author> <title> "Parametric Feature Detection," </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> San Francisco, </address> <year> 1996. </year>
Reference-contexts: Whereas Hummel derived closed-form solutions for the optimal subspace based upon simplified feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality <ref> [Nayar et al. 96] </ref>. A similar approach has been adopted by Nandy et al. [Nandy et al. 96] in concurrent work. 8 3 Example Features We now illustrate the manifold representations of 5 parametric features. <p> We see that both the Canny detector and our detector do increasingly well as the S.N.R. increases. Further, we note that the two detectors perform comparably, with our algorithm doing very marginally better 4 . 4 These results differ slightly from the ones presented in <ref> [Nayar et al. 96] </ref> as they reflect refinements made 24 The results for the Nalwa-Binford detector are consistent with those presented in [Nalwa and Binford 86]. (We did not use step 2)' of the algorithm.) Independently of the S.N.R., the percentage of false positives in Figure 7 never exceeds 32%.
Reference: [Nobel 88] <author> J.A. Nobel, </author> <title> "Finding corners," </title> <journal> Image and Vision Computing, </journal> <volume> 6 </volume> <pages> 121-127, </pages> <year> 1988. </year>
Reference-contexts: By this measure the line is a more complex feature than an edge. The line manifold is displayed for fixed values of and w. It has the structure of a Mobius band. 15 3.4 Corner The corner is a common and hence important image feature <ref> [Nobel 88] </ref>. Most existing approaches to corner detection are based upon differential geometric measures of curvature such as the determinant of the Hessian or the second directional derivative orthogonal to the gradient [Deriche and Giraudon 93]. Recently, Rohr [Rohr 92] proposed a parametric model fitting approach to detect corners.
Reference: [Norton 82] <author> H.N. Norton, </author> <title> Sensor and Analyzer Handbook, </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: First, the light flux falling on each sensor element is averaged, or integrated. If the pixels are rectangular [Barbe 80] <ref> [Norton 82] </ref>, the averaging function is simply the rectangular function [Bracewell 78]: a (x; y) = w x w y 1 x; w y where, w x and w y are the x and y dimensions of the pixel, respectively.
Reference: [Oja 83] <author> E. Oja, </author> <title> Subspace Methods of Pattern Recognition, </title> <publisher> Research Studies Press, </publisher> <year> 1983. </year>
Reference-contexts: These normalizations cause no significant loss of information or reduction in the signal-to-noise ratio. Next, we apply the Karhunen-Loeve expansion <ref> [Oja 83] </ref>, as a dimension reduction technique. This enables us to improve efficiency by projecting the feature manifold into a subspace of dimension, d t N . Dramatic dimension reduction is possible because most features of interest have significant structure and inherent symmetries. <p> If correlation be-tween feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion <ref> [Oja 83] </ref>[Fukunaga 90] yields the optimal subspace. The covariance matrix R = E [(F E [F ])(F E [F ]) T ] represents the correlation between corresponding pixels in the different feature instances.
Reference: [Pratt 90] <author> W.K. Pratt, </author> <title> Digital Image Processing, </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: or through an analytical investigation of systematic biases. (See, for example, [Deutsch and Fram 78], [Abdou and Pratt 79], [Berzins 84], and [Nalwa and Binford 86].) * Evaluate measures that combine feature detection rates with parameter estimation ac curacy. (One example is Pratt's Figure of Merit [Abdou and Pratt 79] <ref> [Pratt 90] </ref>.) * Subjectively analyze detector outputs when applied to real or synthetic images. (Almost all feature detection papers do this.) We begin this experimental section by presenting the results of a sequence of statistical tests.
Reference: [Prewitt 70] <author> J.M. Prewitt, </author> <title> "Object enhancement and extraction," In Picture Processing and Psychopictorics, </title> <editor> B.S. Lipkin and A. Rosenfeld, Eds, </editor> <publisher> Academic Press, </publisher> <year> 1970. </year>
Reference-contexts: In our discussion we will provide examples of existing detectors without attempting to mention all of them. Further, we focus on detectors that fit parametric feature models to the image intensities rather than detectors based on the gradient (e.g. <ref> [Prewitt 70] </ref>), Laplacian (e.g. [Marr and Hildreth 80]), second directional derivatives (e.g. [Canny 86] [Haralick 84]), Hessian determinant (e.g. [Deriche and Giraudon 93]), or other differential invariants. <p> It is also interesting to note that the first two eigenvectors resemble first-order spatial derivative operators that constitute the basis of many popular edge detectors (for instance the Sobel operator <ref> [Prewitt 70] </ref>). The window chosen for our edge model includes 49 pixels. To avoid unnecessary nonlinearities induced by a square window we used a disc shaped one. In Figure 1 (d), the decay of the Karhunen-Loeve residue is plotted as a function of the number of eigenvectors.
Reference: [Rohr 92] <author> K. Rohr, </author> <title> "Recognizing Corners by Fitting Parametric Models," </title> <journal> International Journal of Computer Vision, </journal> <volume> 9 </volume> <pages> 213-230, </pages> <year> 1992. </year>
Reference-contexts: A concise description of one-dimensional image features (e.g. step edges, roof edges, and lines) and a survey of step edge detectors can be found in [Nalwa 93]. The papers by Rohr <ref> [Rohr 92] </ref> and Deriche and Giraudon [Deriche and Giraudon 93] cover most of the previous work concerning the two-dimensional problems of corner detection and junction detection. 1 to make any simplifications for analytic or efficiency reasons, but instead use realistic multi--parameter feature models. <p> Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr <ref> [Rohr 92] </ref> used it to detect corners. The same approach generalizes to three-dimensional image data as was used by Zucker and Hummel [Zucker and Hummel 81] and also by Lenz [Lenz 87] in the detection of three-dimensional step edges. <p> Further, the search for the closest manifold point must be repeated for each window (centered around each pixel) in the image. Nalwa and Binford [Nalwa and Binford 86] and Rohr <ref> [Rohr 92] </ref> used more complex feature models than Hueckel and Hummel and also used numerical methods to find the best-fit parameters of their models to the image data. At first glance, applying a high dimensional search for every pixel in an image seems inefficient to the point of impracticality. <p> Most existing approaches to corner detection are based upon differential geometric measures of curvature such as the determinant of the Hessian or the second directional derivative orthogonal to the gradient [Deriche and Giraudon 93]. Recently, Rohr <ref> [Rohr 92] </ref> proposed a parametric model fitting approach to detect corners. The simplest way to think about a corner is as the intersection point of two non-parallel lines.
Reference: [Rosenfeld et al. 76] <author> A. Rosenfeld, R.A. Hummel, </author> <title> and S.W. Zucker, "Scene Labeling by Relaxation Operations," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 6 </volume> <pages> 420-433, </pages> <year> 1976. </year>
Reference-contexts: outputs (b), (c), and (d), together with parameter estimates, could serve as the basis for an effective relaxation scheme that produces a descriptive primal sketch. 33 each designed for a different feature, yields a large amount of information that would be valuable to a higher level algorithm such as relaxation <ref> [Rosenfeld et al. 76] </ref>. While existing relaxation algorithms assume a single feature in the image, often the step edge, powerful constraints result from the use of multiple feature detectors. For instance, a corner cannot exist in isolation, but instead must have edges in its vicinity.
Reference: [Yianilos 93] <author> P.N. Yianilos, </author> <title> "Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces," </title> <booktitle> Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1993. </year>
Reference-contexts: The more recent paper <ref> [Yianilos 93] </ref> contains a pretty comprehensive bibliography of algorithms developed since then. Our problem has more structure than the general nearest neighbor problem since we know that the points lie on a parametric manifold.
Reference: [Zucker and Hummel 81] <author> S.W. Zucker and R.A. Hummel, </author> <title> "A Three-Dimensional Edge Operator," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 3 </volume> <pages> 324-331, </pages> <year> 1981. </year>
Reference-contexts: Hueckel [Hueckel 73] applied the same formulation to line detection and Rohr [Rohr 92] used it to detect corners. The same approach generalizes to three-dimensional image data as was used by Zucker and Hummel <ref> [Zucker and Hummel 81] </ref> and also by Lenz [Lenz 87] in the detection of three-dimensional step edges. Hueckel [Hueckel 71] and Hummel [Hummel 79] both argued that to achieve the required efficiency, a closed form solution must be found for the parameters of the closest manifold point.
References-found: 40

