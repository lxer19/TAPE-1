URL: http://www.cs.rochester.edu/u/bayliss/tmp/nips98.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/bayliss/tmp/
Root-URL: 
Email: fbayliss,danag@cs.rochester.edu  
Title: Single Trial P300 Recognition in a Virtual Environment  
Author: Jessica D. Bayliss and Dana H. Ballard 
Keyword: Recognition, Evoked Potential, Virtual Environment. Preference: Oral presentation.  
Address: Rochester, NY 14627  
Affiliation: Department of Computer Science University of Rochester  
Note: Category: Applications.  Corr. Author: J.D. Bayliss; this work has not appeared elsewhere.  
Abstract: Virtual reality (VR) provides immersive and controllable experimental environments. It expands the bounds of possible evoked potential (EP) experiments by providing complex, dynamic environments in order to study cognition without sacrificing environmental control. The addition of quick, on-line analysis enables feed-back to subjects, making the system we present ideal for safe Brain Computer Interface (BCI) research. In this context, we describe an experiment to recognize the existence of P300 EP epochs at red stoplights and the absence of this signal at yellow stoplights in a virtual driving environment. In order to determine the plausibility of single trial on-line P300 epoch analysis in the artifact ridden driving environment, we have compared the use of Independent Component Analysis (ICA), a Kalman filter, a robust Kalman filter, and correlation with the stoplight averages for recognition ability off-line. We report that while all methods perform better than correlation, the robust Kalman filter gives the highest recognition accuracy and discuss future work in this context.
Abstract-found: 1
Intro-found: 1
Reference: [Bayliss and Ballard, 1998] <author> J.D. Bayliss and D.H. Ballard, </author> <title> The Effects of Eye Tracking in a VR Helmet on EEG Recording, </title> <type> TR 685, </type> <institution> University of Rochester National Resource Laboratory for the Study of Brain and Behavior, </institution> <month> May </month> <year> 1998. </year>
Reference-contexts: We tested the effects of wearing a VR4 virtual reality (VR) helmet containing an ISCAN eye tracker and discovered that the noise levels inside of the VR helmet were comparable to noise levels while watching a laptop screen <ref> [Bayliss and Ballard, 1998] </ref>. 3 THE STOPLIGHT EXPERIMENT Previous P300 research has concentrated primarily on static environments such as the continuous performance task [Rosvold et al., 1956].
Reference: [Farwell and Donchin, 1988] <author> L.A. Farwell and E. Donchin, </author> <title> Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials, </title> <journal> Electroen-ceph. Clin. </journal> <volume> Neurophysiol., </volume> <pages> pages 510523, </pages> <year> 1988. </year>
Reference-contexts: In the future, we expect to look at methods such as DSLVQ [Pregenzer et al., 1996] for further comparisons. This result suggests that building a brain computer interface using the P300 EP as in <ref> [Farwell and Donchin, 1988] </ref> would prove feasible in the dynamic VR environment.
Reference: [Jung et al., 1997] <author> T.P. Jung, C. Humphries, T. Lee, S. Makeig, M.J. McKeown, V. Iragui, and T.J. Sejnowski, </author> <note> Extended ICA Removes Artifacts from Electroencephalographic Recordings, to Appear in Advances in Neural Information Processing Systems, 10, </note> <year> 1997. </year>
Reference-contexts: This matrix W performs component separation. All data was sphered in order to speed convergence time. ICA has successfully been used in order to minimize artifacts in EEG data <ref> [Jung et al., 1997; Makeig et al., 1995; Vigario, 1997] </ref> and has also proven useful in separating P300 component data from an averaged waveform [Makeig et al., 1997]. The next experiment used ICA in order to try to separate the background EEG signal from the P300 signal.
Reference: [Makeig et al., 1995] <author> S. Makeig, A. Bell, T. Jung, and T. Sejnowski, </author> <title> Independent Component Analysis of Electroencephalographic Data, </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <address> 8:145151, </address> <year> 1995. </year>
Reference-contexts: This matrix W performs component separation. All data was sphered in order to speed convergence time. ICA has successfully been used in order to minimize artifacts in EEG data <ref> [Jung et al., 1997; Makeig et al., 1995; Vigario, 1997] </ref> and has also proven useful in separating P300 component data from an averaged waveform [Makeig et al., 1997]. The next experiment used ICA in order to try to separate the background EEG signal from the P300 signal.
Reference: [Makeig et al., 1997] <author> S. Makeig, T. Jung, A.J. Bell, D. Ghahremani, and T.J. Sejnowski, </author> <title> Blind Separation of Auditory Event-related Brain Responses into Independent Components, </title> <booktitle> Proc. </booktitle> <institution> Nat'l Acad. Sci. USA, 94:1097910984, </institution> <year> 1997. </year>
Reference-contexts: Independent component analysis (ICA) assumes that n EEG data channels x are a linear combination of n statistically independent signals s: x = As (2) where x and s are n fi 1 vectors. We used the matlab package mentioned in <ref> [Makeig et al., 1997] </ref> with default learning values, which finds a matrix W by stochastic gradient descent. This matrix W performs component separation. All data was sphered in order to speed convergence time. <p> All data was sphered in order to speed convergence time. ICA has successfully been used in order to minimize artifacts in EEG data [Jung et al., 1997; Makeig et al., 1995; Vigario, 1997] and has also proven useful in separating P300 component data from an averaged waveform <ref> [Makeig et al., 1997] </ref>. The next experiment used ICA in order to try to separate the background EEG signal from the P300 signal.
Reference: [McFarland et al., 1993] <editor> D.J. McFarland, G.W. Neat, R.F. Read, and J.R. Wolpaw, </editor> <title> An EEG-based method for graded cursor control, </title> <address> Psychobiology, 21(1):7781, </address> <year> 1993. </year>
Reference: [Nelson et al., 1997] <author> W.T. Nelson, L.J. Hettinger, J.A. Cunningham, </author> <title> and M.M. Roe, Navigating through virtual flight environments using brain-body-actuated control, </title> <booktitle> Proceedings. IEEE 1997 Virtual Reality Annual Intern. Symposium, </booktitle> <pages> pages 3037, </pages> <year> 1997. </year>
Reference-contexts: We have integrated use of a Neuro Scan acquisition system with eye tracking inside of a VR helmet in order to obtain multiple indicators of cognitive state in a dynamic driving environment. While we are not the first to use the EEG signal in VR (see <ref> [Nelson et al., 1997] </ref> for another example), we are the first to classify the P300 EP reliably in subjects performing in an immersive, dynamic VR world.
Reference: [Pfurtscheller et al., 1996] <author> G. Pfurtscheller, D. Flotzinger, M. Pregenzer, J. Wolpaw, and D. McFarland, </author> <title> EEG-based Brain Computer Interface (BCI), Medical Progress through Technology, </title> <address> 21:111121, </address> <year> 1996. </year>
Reference: [Polich, 1998] <author> J. Polich, </author> <title> P300 Clinical Utility and Control of Variability, </title> <journal> J. of Clinical Neurophysiology, </journal> <volume> 15(1):1433, </volume> <year> 1998. </year>
Reference-contexts: The dynamic nature of the VR environment encourages eye and head movement. In order to test the feasibility of on-line recognition in such a noisy environment, we recognized the P300 EP, discovered by [Sutton et al., 1965] and extensively studied (see <ref> [Polich, 1998] </ref> for a literature review). It is a positive waveform occuring approximately 300 ms after an infrequent task-relevant stimulus. We show that requiring subjects to stop at red stoplights elicited this EP.
Reference: [Pregenzer et al., 1996] <author> M. Pregenzer, D.M. Flotzinger, and G. Pfurtscheller, </author> <title> Automated feature selection with a distinction sensitive learning vector quantizer, </title> <address> Neurocom-puting, 11:1929, </address> <year> 1996. </year>
Reference-contexts: While the best performing algorithm was the robust Kalman filter, ICA showed strong promise if a way could be devised for it to avoid incorrectly labeling non-P300 signals. In the future, we expect to look at methods such as DSLVQ <ref> [Pregenzer et al., 1996] </ref> for further comparisons. This result suggests that building a brain computer interface using the P300 EP as in [Farwell and Donchin, 1988] would prove feasible in the dynamic VR environment.
Reference: [Rao, 1997] <author> R. P.N. Rao, </author> <title> Visual Attention during Recognition, </title> <booktitle> to Appear in Advances in Neural Information Processing Systems, </booktitle> <volume> 10, </volume> <year> 1997. </year>
Reference-contexts: The third experiment used the Kalman filter framework formulated by Rao <ref> [Rao, 1997] </ref>. The Kalman filter assumes a linear model similar to the one of ICA in equa tion refeq:icamodel, but assumes the EEG output x is the observable output of a generative or measurement matrix A and an internal state vector s of Gaussian sources. <p> The learning rule for the measurement matrix may be derived in a manner similar to the rule for the internal state vector. In addition, a decay term is often needed in order to avoid overfitting the data set. See <ref> [Rao, 1997] </ref> for details. In our experiments both the internal state matrix s and the measurement matrix A were learned by training them on the average red light signal (as a single 500 fi 1 input vector) and the average yellow light signal.
Reference: [Rosvold et al., 1956] <author> H.E. Rosvold, </author> <title> A.F. </title> <editor> Mirsky, I. Sarason, E.D. Bransome Jr., and L.H. Beck, </editor> <title> A Continuous Performance Test of Brain Damage, </title> <journal> J. Consult. Psychol., </journal> <volume> 20, </volume> <year> 1956. </year>
Reference-contexts: helmet containing an ISCAN eye tracker and discovered that the noise levels inside of the VR helmet were comparable to noise levels while watching a laptop screen [Bayliss and Ballard, 1998]. 3 THE STOPLIGHT EXPERIMENT Previous P300 research has concentrated primarily on static environments such as the continuous performance task <ref> [Rosvold et al., 1956] </ref>. In the visual continuous performance task, static images are flashed on a screen and the subject is told to press a button when a rare stimulus occurs or to count the number of occurances of a rare stimulus.
Reference: [Semlitsch et al., 1986] <author> H.V. Semlitsch, P. Anderer, P Schuster, and O. Presslich, </author> <title> A solution for reliable and valid reduction of ocular artifacts applied to the P300 ERP, </title> <address> Psychophys., 23:695703, </address> <year> 1986. </year>
Reference-contexts: As expected, the data obtained while driving contained many movement-related artifacts. In order to reduce these artifacts before averaging, we preprocessed the data and subtracted a combination of eye and head movement artifact using the linear regression technique described in <ref> [Semlitsch et al., 1986] </ref>. We also found it helpful to reduce head movement artifact by removing frequencies under 2 Hz.
Reference: [Sutton et al., 1965] <author> S. Sutton, M. Braren, J. Zublin, and E. John, </author> <title> Evoked potential correlates of stimulus uncertainty, </title> <booktitle> Science, </booktitle> <address> 150:11871188, </address> <year> 1965. </year>
Reference-contexts: The dynamic nature of the VR environment encourages eye and head movement. In order to test the feasibility of on-line recognition in such a noisy environment, we recognized the P300 EP, discovered by <ref> [Sutton et al., 1965] </ref> and extensively studied (see [Polich, 1998] for a literature review). It is a positive waveform occuring approximately 300 ms after an infrequent task-relevant stimulus. We show that requiring subjects to stop at red stoplights elicited this EP.
Reference: [Vaughn et al., 1996] <author> T.M. Vaughn, J.R. Wolpaw, and E. Donchin, </author> <title> EEG-Based Communication: Prospects and Problems, </title> <journal> IEEE Trans. on Rehabilitation Engineering, </journal> <volume> 4(4):425430, </volume> <year> 1996. </year>
Reference: [Vigario, 1997] <author> R. Vigario, </author> <title> Extraction of ocular artifacts from eeg using independent component analysis, </title> <address> Electroenceph. Clin. Neurophysiol., 103:395404, </address> <year> 1997. </year>
Reference-contexts: This matrix W performs component separation. All data was sphered in order to speed convergence time. ICA has successfully been used in order to minimize artifacts in EEG data <ref> [Jung et al., 1997; Makeig et al., 1995; Vigario, 1997] </ref> and has also proven useful in separating P300 component data from an averaged waveform [Makeig et al., 1997]. The next experiment used ICA in order to try to separate the background EEG signal from the P300 signal.
References-found: 16

