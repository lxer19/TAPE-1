URL: http://trantor.cse.psu.edu/~coulston/speed.ps
Refering-URL: http://www.cse.psu.edu/~coulston/vitae.html
Root-URL: http://www.cse.psu.edu
Title: Speed is More Powerful than Clairvoyance  
Author: Piotr Berman Chris Coulston 
Address: Park, PA 16802, USA  
Affiliation: Department of Computer Science and Engineering The Pennsylvania State University, University  
Abstract: We consider the problem of preemptive non-clairvoyant scheduling on a single machine. In this model a scheduler receives a number of jobs at different times without prior knowledge of the future jobs or the required processing time of jobs that are not yet completed. We want to minimize the total response time, i.e. the sum of times each job takes from its release to completion. One particular algorithm, Balance, always schedules the job that was least processed so far. A comparison of an on-line scheduler running Balance against the optimal off-line shows a very large competitive ratio if both algorithms use machines of the same speed. However, it has been shown if Balance is run on a v times faster machine than it clairvoyant competitor then the competitive ratio drops to at most v=(v 1). This result showed that speed can almost be as good as clairvoyance. We show for v 2 the competitive ratio of Balance is 2=v. In other words, sufficiently high speed is more powerful than clairvoyance. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Albers, </author> <title> Better bounds for online scheduling, </title> <booktitle> STOC (1997), </booktitle> <pages> 130-139. </pages>
Reference: 2. <author> S. Irani and A. Karlin, </author> <title> Online Computation, </title> <editor> in D. Hochbaum (ed.), </editor> <title> Approximation Algorithms for N P Hard Problems, </title> <publisher> PWS Publishing, </publisher> <address> Boston MA, </address> <year> 1997, </year> <pages> 521-563. </pages>
Reference-contexts: The quality of the solutions generated by an on-line algorithm are generally measured using the competitive ratio <ref> [2] </ref> i.e. the worst case ratio of the cost of the solution generated by the on-line algorithm to the cost of an optimal off-line solution The lower bound on the competitive ratio of any deterministic scheduler is O (n 1=3 ) [5].
Reference: 3. <author> B. Kalyanasundaram and K. </author> <title> Pruhs Speed is as powerful as clairvoyance, </title> <booktitle> FOCS (1995), </booktitle> <pages> 214-221. </pages>
Reference-contexts: Obviously, this algorithm requires foreknowledge about the sizes of the jobs. In our analysis we will assume that our Adversary uses this algorithm, denoted A. The second algorithm is Balance <ref> [3] </ref> denoted B. Balance runs the job was has the minimum p j . <p> In spite of this dismal performance, scheduling algorithms perform quite well in practice. This observation has motivated Kalyanasundaram and Pruhs <ref> [3] </ref> to find an alternative means to measure the quality of on-line solutions. Under their paradigm the on-line algorithm is "enhanced" by being run on a machine that is faster by a factor of 1 + * than the adversaries machine. <p> The resulting competitive ratio is called the *-weak competitive ratio. Phillips et. al. [6] generalized this approach calling it resource augmentation; in their point of view the system designer is given some specific performance requirements and must compute the necessary amount of resource, like processor speed. Kalyanasundaram and Pruhs <ref> [3] </ref> showed the *-weak competitive ratio of the balance algorithm is at most (1 + *)=*.
Reference: 4. <author> T. Matsumoto, </author> <title> Competitive analysis of the round robin algorithm, </title> <booktitle> International Symposium on Algorithms and Computation (1992), </booktitle> <pages> 71-77. </pages>
Reference: 5. <author> R. Motwani, S. Phillips and E. Torng, </author> <title> Non-clairvoyant scheduling, </title> <booktitle> SODA (1993), </booktitle> <pages> 422-431. </pages>
Reference-contexts: on-line algorithm are generally measured using the competitive ratio [2] i.e. the worst case ratio of the cost of the solution generated by the on-line algorithm to the cost of an optimal off-line solution The lower bound on the competitive ratio of any deterministic scheduler is O (n 1=3 ) <ref> [5] </ref>. In spite of this dismal performance, scheduling algorithms perform quite well in practice. This observation has motivated Kalyanasundaram and Pruhs [3] to find an alternative means to measure the quality of on-line solutions.
Reference: 6. <author> C. Phillips, C. Stein, E. Torng and J. Wein, </author> <title> Optimal time-critical scheduling via resource augmentation, </title> <booktitle> STOC (1997), </booktitle> <pages> 140-149. </pages>
Reference-contexts: Under their paradigm the on-line algorithm is "enhanced" by being run on a machine that is faster by a factor of 1 + * than the adversaries machine. The resulting competitive ratio is called the *-weak competitive ratio. Phillips et. al. <ref> [6] </ref> generalized this approach calling it resource augmentation; in their point of view the system designer is given some specific performance requirements and must compute the necessary amount of resource, like processor speed.
Reference: 7. <author> W. Smith, </author> <title> Various optimizers for single-stage production, </title> <journal> Naval Research Logistics Quarterly (1956), </journal> <pages> 59-66. </pages>
Reference-contexts: If our computer were clairvoyant it would know the required execution times of all the jobs. It is well known <ref> [7] </ref> that with such information one can minimize the total response time. In this paper we will use the following notation and terminology. <p> We also define p j = s j r j as the processing time that j has received up to the present time. This paper will compare two well known algorithms for the scheduling problem. The optimal algorithm <ref> [7, 8] </ref> at each point in time runs the job j which currently has the minimum remaining processing time. Obviously, this algorithm requires foreknowledge about the sizes of the jobs. In our analysis we will assume that our Adversary uses this algorithm, denoted A.
Reference: 8. <author> A. Tannenbaum and A. Woodhull, </author> <title> Operating Systems, </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1997. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: We also define p j = s j r j as the processing time that j has received up to the present time. This paper will compare two well known algorithms for the scheduling problem. The optimal algorithm <ref> [7, 8] </ref> at each point in time runs the job j which currently has the minimum remaining processing time. Obviously, this algorithm requires foreknowledge about the sizes of the jobs. In our analysis we will assume that our Adversary uses this algorithm, denoted A.
References-found: 8

