URL: ftp://ftp.cis.ohio-state.edu/pub/anish/papers/lowcost.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~anish/pub.html
Root-URL: 
Title: Low-cost Fault-tolerance in Barrier Synchronizations  
Author: Sandeep S. Kulkarni Anish Arora 
Keyword: fault-tolerance, multitolerance, detectable and undetectable faults, synchronization, concurrency.  
Address: Columbus, OH 43210 USA  
Affiliation: Department of Computer and Information Science 1 The Ohio State University  
Abstract: In this paper, we show how fault-tolerance can be effectively added to several types of faults in program computations that use barrier synchronization. We divide the faults that occur in practice into two classes, detectable and undetectable, and design a fully distributed program that tolerates the faults in both classes. Our program guarantees that every barrier is executed correctly even if detectable faults occur, and that eventually every barrier is executed correctly even if undetectable faults occur. Via analytical as well as simulation results we show that the cost of adding fault-tolerance is low, in part by comparing the times required by our program with that required by the corresponding fault-intolerant counterpart. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Scott and J. Mellor-Crummey. </author> <title> Fast, contention-free combining barriers. </title> <journal> International Journal of Parallel Programming, </journal> <month> August </month> <year> 1994. </year>
Reference: [2] <author> R. Gupta and C. R. Hill. </author> <title> A scalable implementation of barrier synchronization using an adaptive combining tree. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 18(3), </volume> <year> 1989. </year>
Reference-contexts: Based on the discussion in Section 7, the user could specify that the program should recover from correctable faults in an appropriate manner and abort in case of uncorrectable faults. Finally, we note that our program can be systematically extended to deal with fuzzy barriers <ref> [2] </ref>. In particular, the transition from execute to success is the same as entering the barrier, and the transition from ready to execute is the same as leaving the barrier.
Reference: [3] <author> D. N. Jayasimha. </author> <title> Distributed synchronizers. </title> <booktitle> International Conference on Parallel Processing, </booktitle> <pages> pages I 23-27, </pages> <year> 1988. </year>
Reference: [4] <author> S. K. S. Gupta and D. N. Jayasimha. </author> <title> A generalized dynamic barrier synchronization scheme. </title> <booktitle> International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1992. </year>
Reference: [5] <author> Maurice Herlihy. </author> <title> Wait-free synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 124-149, </pages> <month> January </month> <year> 1991. </year>
Reference: [6] <author> R. Sivaram, C. B. Stunkel, and D. K. Panda. </author> <title> A reliable hardware barrier synchronization scheme. </title> <booktitle> International Parallel Processing Symposium, </booktitle> <pages> pages 274-280, </pages> <year> 1997. </year>
Reference-contexts: Despite the existence of these multiple types of faults in practice and an extensive literature on barrier synchronization [1-9, to cite but a few], we are aware of little research that has considered fault-tolerance in this context. Among the exceptions are <ref> [6] </ref>, which deals with message loss and corruption only, and [9], which relies upon high atomicity shared memory access. We are therefore led to designing and analyzing a fully distributed program for barrier synchronization computations that provides tolerance to most of the faults discussed above.
Reference: [7] <author> H. Xu, P.K. McKinley, and L. Ni. </author> <title> Efficient implementation of barrier synchronization in wormhole route hypercube multicomputers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <pages> pages 172-184, </pages> <year> 1992. </year>
Reference: [8] <author> D. Johnson, D. Lilja, J. Riedl, and J. Anderson. </author> <title> Low-cost, high-performance barrier synchronization on networks of workstations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 40(1) </volume> <pages> 131-137, </pages> <month> January </month> <year> 1997. </year>
Reference: [9] <author> S. S. Kulkarni and A. Arora. </author> <title> Multitolerant barrier synchronization. </title> <journal> Information Processing Letters, </journal> <volume> 64(1) </volume> <pages> 29-36, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: Among the exceptions are [6], which deals with message loss and corruption only, and <ref> [9] </ref>, which relies upon high atomicity shared memory access. We are therefore led to designing and analyzing a fully distributed program for barrier synchronization computations that provides tolerance to most of the faults discussed above. Issues in dealing with multiple types of faults.
Reference: [10] <author> A. Arora and S. S. Kulkarni. </author> <title> Component based design of multitolerance. </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> January </month> <year> 1998. </year>
Reference-contexts: undetectable in the next section, we note that 1 the former fault-class includes faults such as message loss, unexpected message reception, fail--stop, repair, and rebooting of a processor; and the latter includes faults such as internal/design errors, hanging processes, memory corruption, and memory leaks. (The interested reader is referred to <ref> [10] </ref> for heuristics for the selection of fault-classes.) A second issue is whether to differentiate between the mechanisms used to achieve the same type of tolerance for the different types of faults within the same fault-class. <p> It follows that we will superpose the refined barrier synchronization upon an underlying multitolerant token ring program. Next, we briefly recall such a token ring program, which we have formally derived and proven correct elsewhere <ref> [10] </ref>. Underlying token ring program. Each process j maintains a sequence number, sn:j, which is in the domain f0::K 1g for some K &gt; N in the absence of detectable faults. <p> If a fault is uncorrectable, it may be impossible to guarantee that Progress is satisfied. Still, if the fault is at least immediately detectable, it is possible to ensure that Safety is always satisfied. Thus, an appropriate tolerance to faults in this class is fail-safe tolerance <ref> [10] </ref>, whereby the program guarantees that it never reports a completion of a barrier incorrectly. But the program may not always report (a successful) completion in the presence of faults. <p> We ensured that in the presence of detectable faults alone, the specification of barrier synchronization was always satisfied, and in the presence of undetectable faults, the program eventually reached a state from where the specification of barrier synchronization was (re)satisfied. Thus, our program was multitolerant <ref> [10] </ref> in that it provided appropriate tolerances with respect to multiple classes of faults. (The interested reader is referred to [10] for a formal method for the design of multitolerant programs.) We are not aware of work by others that has addressed multitolerance of barrier synchronization. <p> Thus, our program was multitolerant <ref> [10] </ref> in that it provided appropriate tolerances with respect to multiple classes of faults. (The interested reader is referred to [10] for a formal method for the design of multitolerant programs.) We are not aware of work by others that has addressed multitolerance of barrier synchronization. We also presented analytical and simulation results for the overhead incurred by our program in tolerating faults.
Reference: [11] <author> M. G. Gouda. </author> <title> The triumph and tribulation of system stabilization. </title> <booktitle> In Helary and Raynal [18], </booktitle> <pages> pages 1-18. </pages>
Reference-contexts: And, in the presence of the latter fault-class, we will ensure that even if the program reaches an arbitrary state, it eventually recovers to a state from where each barrier is executed correctly, i.e., stabilizing tolerance will be exhibited with respect to the undetectable fault-class <ref> [11] </ref>.
Reference: [12] <author> MPI: </author> <title> A message-passing interface standard, </title> <month> June </month> <year> 1995. </year> <note> Version 1.1. </note>
Reference-contexts: Hardware implementation. Barrier synchronization programs are sometimes implemented in hardware, for reasons of efficiency. One of our goals, therefore, is to design a program that is simple and that uses small data structures, to enable easy implementation in hardware. MPI implementation. Currently, MPI <ref> [12] </ref> provides users with two alternatives for dealing with faults: (i) to abort the program in the event of a fault, and (ii) to return an error code in the event of a fault, so that the user may be able to effect a recovery. <p> Sometimes, even if faults are detectable in principle, there may be factors that limit the ability of systems to detect them, e.g., the cost of detection <ref> [12] </ref>; such faults may instead be classified as undetectable. In the presence of undetectable faults, the program may be perturbed to a state where processes are executing in different phases. It follows that the specification of barrier synchronization cannot be satisfied in the presence of such faults.
Reference: [13] <author> J. Gray and A. Reuter. </author> <title> Transaction Processing : Concepts and Techniques. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference-contexts: As such, our program can tolerate all the above fault-classes in a manner that is appropriate with respect to each fault-class. Instantiations to solve other problems. Our barrier synchronization program can be instantiated to obtain fault-tolerant programs for other problems such as atomic commitment <ref> [13, 14] </ref>, clock unison [15, 16] and phase synchronization [17]. Atomic commitment. In atomic commitment, a program executes one or more transactions such that each transaction completes successfully only if all of its subtransactions complete successfully and, ideally, transaction j +1 is executed only after transaction j completes successfully.
Reference: [14] <author> Y. Zhao and F. B. Bastani. </author> <title> A self-adjusting algorithm for Byzantine agreement. </title> <journal> Distributed Computing, </journal> <volume> 5 </volume> <pages> 219-226, </pages> <year> 1992. </year>
Reference-contexts: As such, our program can tolerate all the above fault-classes in a manner that is appropriate with respect to each fault-class. Instantiations to solve other problems. Our barrier synchronization program can be instantiated to obtain fault-tolerant programs for other problems such as atomic commitment <ref> [13, 14] </ref>, clock unison [15, 16] and phase synchronization [17]. Atomic commitment. In atomic commitment, a program executes one or more transactions such that each transaction completes successfully only if all of its subtransactions complete successfully and, ideally, transaction j +1 is executed only after transaction j completes successfully.
Reference: [15] <author> T. Herman and S. Ghosh. </author> <title> Stabilizing phase-clocks. </title> <journal> Information Processing Letters, </journal> <volume> 54 </volume> <pages> 259-265, </pages> <year> 1995. </year>
Reference-contexts: As such, our program can tolerate all the above fault-classes in a manner that is appropriate with respect to each fault-class. Instantiations to solve other problems. Our barrier synchronization program can be instantiated to obtain fault-tolerant programs for other problems such as atomic commitment [13, 14], clock unison <ref> [15, 16] </ref> and phase synchronization [17]. Atomic commitment. In atomic commitment, a program executes one or more transactions such that each transaction completes successfully only if all of its subtransactions complete successfully and, ideally, transaction j +1 is executed only after transaction j completes successfully.
Reference: [16] <author> J. Couvreur, N. Francez, and M. Gouda. </author> <title> Asynchronous unison. </title> <booktitle> Proceedings of the Twelveth International Conference on Distributed Computing Systems, </booktitle> <address> Tokyo, </address> <year> 1992. </year>
Reference-contexts: As such, our program can tolerate all the above fault-classes in a manner that is appropriate with respect to each fault-class. Instantiations to solve other problems. Our barrier synchronization program can be instantiated to obtain fault-tolerant programs for other problems such as atomic commitment [13, 14], clock unison <ref> [15, 16] </ref> and phase synchronization [17]. Atomic commitment. In atomic commitment, a program executes one or more transactions such that each transaction completes successfully only if all of its subtransactions complete successfully and, ideally, transaction j +1 is executed only after transaction j completes successfully.
Reference: [17] <author> J. Misra. </author> <title> Phase synchronization. </title> <journal> Information Processing Letters, </journal> <volume> 38 </volume> <pages> 101-105, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Instantiations to solve other problems. Our barrier synchronization program can be instantiated to obtain fault-tolerant programs for other problems such as atomic commitment [13, 14], clock unison [15, 16] and phase synchronization <ref> [17] </ref>. Atomic commitment. In atomic commitment, a program executes one or more transactions such that each transaction completes successfully only if all of its subtransactions complete successfully and, ideally, transaction j +1 is executed only after transaction j completes successfully.
Reference: [18] <editor> Jean-Michel Helary and Michel Raynal, editors. </editor> <booktitle> Distributed Algorithms, 9th International Workshop, WDAG '95, volume 972 of Lecture Notes in Computer Science, </booktitle> <address> Le Mont-Saint-Michel, France,, 13-15 September 1995. </address> <publisher> Springer. </publisher> <pages> 24 </pages>
References-found: 18

