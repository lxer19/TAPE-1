URL: http://www.cs.huji.ac.il/~feit/parsched/p-97-11.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~feit/parsched/parsched97.html
Root-URL: http://www.cs.huji.ac.il
Email: feit@cs.huji.ac.il  jette@llnl.gov  
Phone: 2  
Title: Improved Utilization and Responsiveness with Gang Scheduling  
Author: Dror G. Feitelson and Morris A. Jette 
Address: 91904 Jerusalem, Israel  Livermore, CA 94550  
Affiliation: 1 Institute of Computer Science The Hebrew University of Jerusalem  Livermore Computing Lawrence Livermore National Laboratory  
Abstract: Most commercial multicomputers use space-slicing schemes in which each scheduling decision has an unknown impact on the future: should a job be scheduled, risking that it will block other larger jobs later, or should the processors be left idle for now in anticipation of future arrivals? This dilemma is solved by using gang scheduling, because then the impact of each decision is limited to its time slice, and future arrivals can be accommodated in other time slices. This added flexibility is shown to improve overall system utilization and responsiveness. Empirical evidence from using gang scheduling on a Cray T3D installed at Lawrence Livermore National Lab corroborates these results, and shows conclusively that gang scheduling can be very effective with current tech nology.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> G. Alverson, S. Kahan, R. Korry, C. McCann, and B. Smith, </author> <title> "Scheduling on the Tera MTA". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitel-son and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 19-44, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: A job will never be preempted before its do-not-disturb time is up. This allows the desire for timely response to be balanced against the cost of moving a job's state onto disk and back to memory (it is similar to the scheme proposed for the Tera MTA <ref> [1] </ref>). The do-not-disturb time multiplier should be set to a value substantially larger than the time required to move a job's state in one processor from memory to disk and back to memory. This time will vary with the disk configuration.
Reference: 2. <author> Cray Research, Inc., </author> <title> Cray T3D System Architecture Overview. Order number HR-04033, </title> <month> Sep </month> <year> 1993. </year>
Reference-contexts: The barrier wire assigned to a job cannot change if the job is relocated and, under some circumstances, two jobs sharing a single barrier wire may not be located adjacent to each other. The number of processors assigned to a job can not change during execution <ref> [2] </ref>. There are two fundamentally different ways of providing for timesharing of processors. The entire state of a job, including memory contents, register contents and switch state information can be written to disk. Alternately, the register and switch state information can be saved and the memory shared through paging.
Reference: 3. <author> D. Das Sharma and D. K. Pradhan, </author> <title> "Job scheduling in mesh multicomputers". </title> <booktitle> In Intl. Conf. Parallel Processing, </booktitle> <volume> vol. II, </volume> <pages> pp. 251-258, </pages> <month> Aug </month> <year> 1994. </year>
Reference: 4. <author> D. G. Feitelson, </author> <title> "Packing schemes for gang scheduling". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 89-110, </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science Vol. 1162. </note>
Reference-contexts: During non-prime time these restrictions are removed. Again, we assume the scheduler knows the runtimes of all jobs. Gang: gang scheduling with no information regarding runtimes. The jobs are packed into slots using the buddy scheme, including alternate scheduling <ref> [4] </ref>. <p> quantum of 10 seconds, so most jobs effectively run immediately, and the other has a time quantum of 10 minutes (600 seconds), so jobs may be queued for a certain time before getting to run. 3.2 Simulation Methodology The workload model is an improved version of the model used in <ref> [4] </ref>. It is based on workload analysis from a number of production systems [6,15,32], and is characterized as follows (Fig. 5): The distribution of job sizes emphasizes small jobs and powers of two.
Reference: 5. <author> D. G. Feitelson, </author> <title> A Survey of Scheduling in Multiprogrammed Parallel Systems. </title> <type> Research Report RC 19790 (87657), </type> <institution> IBM T. J. Watson Research Center, </institution> <month> Oct </month> <year> 1994. </year>
Reference: 6. <author> D. G. Feitelson and B. Nitzberg, </author> <title> "Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 337-360, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: It is well known that mean response time is reduced by the shortest-job-first discipline. In workloads with high variability this is approximated by time slicing, because chances are that a new job will have a short runtime [24,23]. As production workloads do indeed exhibit a high variability <ref> [6] </ref>, it follows that gang scheduling will reduce mean response time.
Reference: 7. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Distributed hierarchical control for parallel processing". </title> <booktitle> Computer 23(5), </booktitle> <pages> pp. 65-77, </pages> <month> May </month> <year> 1990. </year>
Reference: 8. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Evaluation of design choices for gang scheduling using distributed hierarchical control". </title> <journal> J. Parallel & Distributed Comput. </journal> <volume> 35(1), </volume> <pages> pp. 18-34, </pages> <month> May </month> <year> 1996. </year>
Reference: 9. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Gang scheduling performance benefits for fine--grain synchronization". </title> <journal> J. Parallel & Distributed Comput. </journal> <volume> 16(4), </volume> <pages> pp. 306-318, </pages> <month> Dec </month> <year> 1992. </year>
Reference-contexts: planned for the gang scheduling of jobs across a heterogeneous collection of computers. 5 Conclusions Gang scheduling has often been advocated based on its advantages of presenting jobs with an environment similar to that of a dedicated machine, thus allowing fine grain interactions based on user-level communication and busy waiting <ref> [9] </ref>, allowing jobs with extreme requirements to share the system: a job that requires all the nodes does not have to wait for all previous jobs to terminate, nor does it delay subsequent jobs, support for interactive work by using time slicing, which guarantees a rea- sonable response time for short
Reference: 10. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Parallel job scheduling: issues and approaches". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 1-18, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference: 11. <author> D. G. Feitelson, L. Rudolph, U. Schwiegelshohn, K. C. Sevcik, and P. Wong, </author> <title> "Theory and practice in parallel job scheduling". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer Verlag, </publisher> <year> 1997. </year> <note> Lecture Notes in Computer Science (this volume). </note>
Reference-contexts: In order to counter the effect of short jobs, we also plot the bounded slowdown <ref> [11] </ref>. For long running jobs, this is the same as the slowdown. But for short jobs, the denominator is taken as the "interactivity threshold" rather than as the actual (very short) runtime.
Reference: 12. <author> B. Gorda and R. Wolski, </author> <title> "Time sharing massively parallel machines". </title> <booktitle> In Intl. Conf. Parallel Processing, </booktitle> <volume> vol. II, </volume> <pages> pp. 214-217, </pages> <month> Aug </month> <year> 1995. </year>
Reference: 13. <author> B. C. Gorda and E. D. Brooks III, </author> <title> Gang Scheduling a Parallel Machine. </title> <type> Technical Report UCRL-JC-107020, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> Dec </month> <year> 1991. </year>
Reference: 14. <author> R. L. Henderson, </author> <title> "Job scheduling under the portable batch system". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 279-294, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: We assume the scheduler has perfect information when making such decisions, i.e. it knows the exact runtimes of all the jobs in the queue. Prime: this policy is a simplified version of a policy used on the SP2 machine at NASA Ames <ref> [14] </ref>. The idea is to distinguish between prime time and non-prime time 1 : during prime time, large jobs (more than 32 nodes) are restricted to 10 minutes, while small jobs are allowed up to 4 hours provided at least 32 nodes are available.
Reference: 15. <author> S. Hotovy, </author> <title> "Workload evolution on the Cornell Theory Center IBM SP2". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 27-40, </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science Vol. 1162. </note>
Reference: 16. <author> Intel Corp., </author> <title> iPSC/860 Multi-User Accounting, Control, and Scheduling Utilities Manual. Order number 312261-002, </title> <month> May </month> <year> 1992. </year>
Reference-contexts: Fig. 2. Runtime bounds on executing jobs allow reservations to be made for large jobs and then backfilling with smaller jobs to reduce fragmentation. The most common solution is to reorder the jobs in the queue so as to pack them more tightly <ref> [16] </ref>. One promising approach is to allow small jobs to move forward in the queue if they can be scheduled immediately. However, this may cause starvation of large jobs, so it is typically combined with allowing large jobs to make reservations of processors for some future time.
Reference: 17. <author> M. Jette, D. Storch, and E. Yim, </author> <title> "Timesharing the Cray T3D". </title> <booktitle> In Cray User Group, </booktitle> <pages> pp. 247-252, </pages> <month> Mar </month> <year> 1996. </year>
Reference: 18. <author> K. Li and K-H. Cheng, </author> <title> "A two-dimensional buddy system for dynamic resource allocation in a partitionable mesh connected system". </title> <journal> J. Parallel & Distributed Comput. </journal> <volume> 12(1), </volume> <pages> pp. 79-83, </pages> <month> May </month> <year> 1991. </year>
Reference: 19. <author> D. Lifka, </author> <title> "The ANL/IBM SP scheduling system". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 295-303, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: This scheme is expected to suffer from significant fragmentation. Backfill: backfilling was developed for the Argonne National Lab SP1 machine <ref> [19] </ref>, and has recently also been installed on the Cornell SP2 and other machines. It allows short jobs to move forward in the queue provided they do not cause delays for any other job. Only jobs that do not cause delay are moved forward.
Reference: 20. <author> C. McCann, R. Vaswani, and J. Zahorjan, </author> <title> "A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors". </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 11(2), </volume> <pages> pp. 146-178, </pages> <month> May </month> <year> 1993. </year>
Reference: 21. <author> C. McCann and J. Zahorjan, </author> <title> "Scheduling memory constrained jobs on distributed memory parallel computers". </title> <booktitle> In SIGMETRICS Conf. Measurement & Modeling of Comput. Syst., </booktitle> <pages> pp. 208-219, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: As production workloads do indeed exhibit a high variability [6], it follows that gang scheduling will reduce mean response time. Indeed, gang scheduling has even been advocated in conjunction with dynamic partitioning <ref> [21] </ref>. 3 Simulation Results 3.1 The Compared Scheduling Schemes In order to demonstrate the ideas described above, we simulate the performance of a multicomputer subjected to a realistic workload and using one of a set of different scheduling schemes. these are: FCFS: the base case we use for comparison is variable
Reference: 22. <author> J. K. Ousterhout, </author> <title> "Scheduling techniques for concurrent systems". </title> <booktitle> In 3rd Intl. Conf. Distributed Comput. Syst., </booktitle> <pages> pp. 22-30, </pages> <month> Oct </month> <year> 1982. </year>
Reference: 23. <author> E. W. Parsons and K. C. Sevcik, </author> <title> "Multiprocessor scheduling for high-variability service time distributions". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 127-145, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference: 24. <author> R. C. Regis, </author> <title> "Multiserver queueing models of multiprocessing systems". </title> <journal> IEEE Trans. Comput. </journal> <volume> C-22(8), </volume> <pages> pp. 736-745, </pages> <month> Aug </month> <year> 1973. </year>
Reference: 25. <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson, </author> <title> "Robust partitioning schemes of multiprocessor systems". </title> <booktitle> Performance Evaluation 19(2-3), </booktitle> <pages> pp. 141-165, </pages> <month> Mar </month> <year> 1994. </year>
Reference: 26. <author> E. Rosti, E. Smirni, G. Serazzi, and L. W. Dowdy, </author> <title> "Analysis of non-work-conserving processor partitioning policies". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 165-181, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: Thus using variable partitioning may lead to significant loss of computing power [18,33], either because jobs do not fit together, or because processors are intentionally left idle in anticipation of future arrivals <ref> [26] </ref>. Fig. 2. Runtime bounds on executing jobs allow reservations to be made for large jobs and then backfilling with smaller jobs to reduce fragmentation. The most common solution is to reorder the jobs in the queue so as to pack them more tightly [16].
Reference: 27. <author> B. Schnor, </author> <title> "Dynamic scheduling of parallel applications". </title> <booktitle> In Parallel Computing Technologies, </booktitle> <publisher> V. Malyshkin (ed.), </publisher> <pages> pp. 109-116, </pages> <publisher> Springer-Verlag, </publisher> <month> Sep </month> <year> 1995. </year> <note> Lecture Notes in Computer Science vol. 964. </note>
Reference: 28. <author> K. C. Sevcik, </author> <title> "Application scheduling and processor allocation in multipro-grammed parallel processing systems". </title> <booktitle> Performance Evaluation 19(2-3), </booktitle> <pages> pp. 107-140, </pages> <month> Mar </month> <year> 1994. </year>
Reference: 29. <author> K. C. Sevcik, </author> <title> "Characterization of parallelism in applications and their use in scheduling". </title> <booktitle> In SIGMETRICS Conf. Measurement & Modeling of Comput. Syst., </booktitle> <pages> pp. 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference: 30. <author> A. Tucker and A. Gupta, </author> <title> "Process control and scheduling issues for multipro-grammed shared-memory multiprocessors". </title> <booktitle> In 12th Symp. Operating Systems Principles, </booktitle> <pages> pp. 159-166, </pages> <month> Dec </month> <year> 1989. </year>
Reference: 31. <author> M. Wan, R. Moore, G. Kremenek, and K. Steube, </author> <title> "A batch scheduler for the Intel Paragon with a non-contiguous node allocation algorithm". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 48-64, </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science Vol. 1162. </note>
Reference-contexts: The idea is that the user would choose the queue that best represents the application's needs, and the system would then be able to select jobs from the different queues to create a job mix that uses the system's resources effectively <ref> [31] </ref>. However, experience indicates that this information is unreliable, as shown by the distributions of queue-time utilization in Fig. 3. The graphs show that users tend to be extremely sloppy in selecting the queue, thus undermining the whole scheme. (The graphs show the distributions in buckets of 4 percentage points. <p> Thus, if only a few nodes are available, all jobs are restricted to 10 minutes, and responsiveness for short jobs is improved. This achieves a similar effect to setting aside a pool of nodes for interactive jobs <ref> [31] </ref>. During non-prime time these restrictions are removed. Again, we assume the scheduler knows the runtimes of all jobs. Gang: gang scheduling with no information regarding runtimes. The jobs are packed into slots using the buddy scheme, including alternate scheduling [4].
Reference: 32. <author> K. Windisch, V. Lo, R. Moore, D. Feitelson, and B. Nitzberg, </author> <title> "A comparison of workload traces from two production parallel machines". </title> <booktitle> In 6th Symp. Frontiers Massively Parallel Comput., </booktitle> <pages> pp. 319-326, </pages> <month> Oct </month> <year> 1996. </year>
Reference: 33. <author> Q. Yang and H. Wang, </author> <title> "A new graph approach to minimizing processor fragmentation in hypercube multiprocessors". </title> <journal> IEEE Trans. Parallel & Distributed Syst. </journal> <volume> 4(10), </volume> <pages> pp. 1165-1171, </pages> <month> Oct </month> <year> 1993. </year>
References-found: 33

