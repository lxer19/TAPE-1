URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96652-S.ps
Refering-URL: http://www.cs.rice.edu:80/~roth/papers.html
Root-URL: 
Title: A General Stencil Compilation Strategy for Distributed-Memory Machines  
Author: Gerald Roth Steve Carr John Mellor-Crummey Ken Kennedy 
Address: Houston, TX 77005 Houghton, MI 49931 Houston, TX 77005 Houston, TX 77005  
Affiliation: Dept of Comp Sci Dept of Comp Sci Dept of Comp Sci Dept of Comp Sci Rice University Michigan Tech Rice University Rice University  
Abstract: For many Fortran 90 programs performing dense matrix computations, the main computational portion of the program belongs to a class of kernels known as stencils. This paper describes a strategy for optimizing such stencil computations for execution on distributed- memory multiprocessors. The optimizations presented target the overhead of data movement that occurs between processors, within the local memory of the processors, and between the memory and registers of the processors. We focus on the application of this strategy on distributed-memory architectures, although it is more broadly applicable. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aiken and A. Nicolau. </author> <title> Loop quantization: An analysis and algorithm. </title> <type> Technical Report 87-821, </type> <institution> Dept. of Computer Science, Cornell University, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: This transformation is called scalar replacement and is described in detail elsewhere [7]. 6.3 Unroll-And-Jam Unroll-and-jam is a transformation that can be used in conjunction with scalar replacement to improve the performance of many memory-bound loops <ref> [1, 2, 6] </ref>. The transformation unrolls an outer loop and then jams the resulting inner loops back together. Using unroll-and-jam, more computation can be introduced into an innermost loop body without a proportional increase in memory references.
Reference: [2] <author> F.E. Allen and J. Cocke. </author> <title> A catalogue of optimizing transformations. </title> <booktitle> In Design and Optimization of Compilers, </booktitle> <pages> pages 1-30. </pages> <publisher> Prentice-Hall, </publisher> <year> 1972. </year>
Reference-contexts: This transformation is called scalar replacement and is described in detail elsewhere [7]. 6.3 Unroll-And-Jam Unroll-and-jam is a transformation that can be used in conjunction with scalar replacement to improve the performance of many memory-bound loops <ref> [1, 2, 6] </ref>. The transformation unrolls an outer loop and then jams the resulting inner loops back together. Using unroll-and-jam, more computation can be introduced into an innermost loop body without a proportional increase in memory references.
Reference: [3] <author> J. R. Allen. </author> <title> Dependence Analysis for Subscripted Variables and Its Application to Program Trans- formations. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Sci- ence, Rice University, </institution> <month> April </month> <year> 1983. </year>
Reference-contexts: Due to the nature of offset arrays we are presented with many opportunities to eliminate redundant and partially redundant data movement. Before discussing our strategy, we need to extend the definition of our offset shift routine. We add an optional fourth argument that takes a regular section descriptor (RSD) <ref> [3] </ref>. The RSD is used to specify which data elements in the overlap areas of other dimensions are to be transferred along with the specified subgrid elements. This extension allows us to include "corner" elements that are a part of multi- offset arrays.
Reference: [4] <author> R. G. Brickner, W. George, S. L. Johnsson, and A. Ruttenberg. </author> <title> A stencil compiler for the Connec- tion Machine models CM-2/200. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Paral- lel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: For a detailed discussion of this method, see [8]. 7 Related Work One of the first major efforts to specifically address stencil compilation for a distributed-memory machine was the stencil compiler for the CM-2 <ref> [4, 5] </ref>. Like our strategy, they eliminated the intraprocessor data movement. They also optimized the interprocessor data movement by exploiting the CM-2's polyshift communication [15]. The final computation was performed by hand-optimized library microcode that took advantage of different loop transformations. However, the CM-2 stencil compiler had many limitations.
Reference: [5] <author> M. Bromley, S. Heller, T. McNerney, and G. Steele, Jr. </author> <title> Fortran at ten gigaflops: The Con- nection Machine convolution compiler. </title> <booktitle> In Pro- ceedings of the SIGPLAN '91 Conference on Pro- gramming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: For a detailed discussion of this method, see [8]. 7 Related Work One of the first major efforts to specifically address stencil compilation for a distributed-memory machine was the stencil compiler for the CM-2 <ref> [4, 5] </ref>. Like our strategy, they eliminated the intraprocessor data movement. They also optimized the interprocessor data movement by exploiting the CM-2's polyshift communication [15]. The final computation was performed by hand-optimized library microcode that took advantage of different loop transformations. However, the CM-2 stencil compiler had many limitations.
Reference: [6] <author> D. Callahan, J. Cocke, and K. Kennedy. </author> <title> Estimat- ing interlock and improving balance for pipelined machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(4) </volume> <pages> 334-358, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Unfortunately, due to the large number of array references found in such a loop, this metric is insufficient. To better measure the performance of subgrid loops in relation to their memory accesses we will use the notion of balance as defined by Callahan, et al. <ref> [6] </ref>. <p> This transformation is called scalar replacement and is described in detail elsewhere [7]. 6.3 Unroll-And-Jam Unroll-and-jam is a transformation that can be used in conjunction with scalar replacement to improve the performance of many memory-bound loops <ref> [1, 2, 6] </ref>. The transformation unrolls an outer loop and then jams the resulting inner loops back together. Using unroll-and-jam, more computation can be introduced into an innermost loop body without a proportional increase in memory references.
Reference: [7] <author> David Callahan, Steve Carr, and Ken Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <journal> SIGPLAN Notices, </journal> <volume> 25(6) </volume> <pages> 53-65, </pages> <month> June </month> <year> 1990. </year> <booktitle> Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Our strategy involves the following compiler optimizations to improve data locality: 1. Improve the order of memory accesses through loop permutation [9]. 2. Improve loop balance through unroll-and-jam and scalar replacement <ref> [8, 7] </ref>. Note that strip-mine-and-interchange can be included here [27]. We have omitted it because of its relative instability and the large amount of cache reuse that already exists in stencil computations [22, 12]. <p> This transformation is called scalar replacement and is described in detail elsewhere <ref> [7] </ref>. 6.3 Unroll-And-Jam Unroll-and-jam is a transformation that can be used in conjunction with scalar replacement to improve the performance of many memory-bound loops [1, 2, 6]. The transformation unrolls an outer loop and then jams the resulting inner loops back together.
Reference: [8] <author> Steve Carr and Ken Kennedy. </author> <title> Improving the ratio of memory operations to floating-point operations in loops. </title> <journal> ACM Transactions on Program- ming Languages and Systems, </journal> <volume> 16(6) </volume> <pages> 1768-1810, </pages> <year> 1994. </year>
Reference-contexts: Our strategy involves the following compiler optimizations to improve data locality: 1. Improve the order of memory accesses through loop permutation [9]. 2. Improve loop balance through unroll-and-jam and scalar replacement <ref> [8, 7] </ref>. Note that strip-mine-and-interchange can be included here [27]. We have omitted it because of its relative instability and the large amount of cache reuse that already exists in stencil computations [22, 12]. <p> If the original loop were memory bound, the unroll-and-jammed loop would perform better as it has a lower balance. Carr and Kennedy describe an automatic method for applying unroll-and-jam <ref> [8] </ref>. Their method computes the unroll amount for a loop that best balances the nest with respect to a target architecture while limiting register pressure. For a detailed discussion of this method, see [8]. 7 Related Work One of the first major efforts to specifically address stencil compilation for a distributed-memory <p> Carr and Kennedy describe an automatic method for applying unroll-and-jam <ref> [8] </ref>. Their method computes the unroll amount for a loop that best balances the nest with respect to a target architecture while limiting register pressure. For a detailed discussion of this method, see [8]. 7 Related Work One of the first major efforts to specifically address stencil compilation for a distributed-memory machine was the stencil compiler for the CM-2 [4, 5]. Like our strategy, they eliminated the intraprocessor data movement.
Reference: [9] <author> Steve Carr, Kathryn McKinley, and Chau-Wen Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth Inter- national Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 252-262, </pages> <address> Santa Clara, California, </address> <year> 1994. </year>
Reference-contexts: Our strategy involves the following compiler optimizations to improve data locality: 1. Improve the order of memory accesses through loop permutation <ref> [9] </ref>. 2. Improve loop balance through unroll-and-jam and scalar replacement [8, 7]. Note that strip-mine-and-interchange can be included here [27]. We have omitted it because of its relative instability and the large amount of cache reuse that already exists in stencil computations [22, 12]. <p> The result will be fewer idle cycles waiting on main memory. For a more complete discussion of loop permutation see Wolf and Lam [27], Kennedy and McKin- ley [18] and Carr, et al. <ref> [9] </ref>. 6.2 Scalar Replacement Even with better cache performance through loop permutation, a loop may still not perform as well as possible. If a loop is memory bound, then its balance must be lowered.
Reference: [10] <author> G.J. Chaitin, M.A. Auslander, A.K. Chandra, J. Cocke, M.E. Hopkins, and P.W. Markstein. </author> <title> Register allocation via coloring. </title> <journal> Computer Lan- guages, </journal> <volume> 6 </volume> <pages> 45-57, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: B (I,J) = T0 + T1 Since the values held in scalar quantities will probably be in registers, the load of A (I,J) has been removed, resulting in a reduction in the memory cycle requirements of the loop (the register copy, T1 = T0, can be removed by unrolling I) <ref> [10] </ref>. This transformation is called scalar replacement and is described in detail elsewhere [7]. 6.3 Unroll-And-Jam Unroll-and-jam is a transformation that can be used in conjunction with scalar replacement to improve the performance of many memory-bound loops [1, 2, 6].
Reference: [11] <author> A. Choudhary, G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, S. Ranka, and C.-W. Tseng. </author> <title> Compiling Fortran 77D and 90D for MIMD distributed-memory machines. </title> <booktitle> In Frontiers '92: The 4th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The sum of products is calculated within a loop nest. The loop nest is a result of scalarization [28], where the array constructs are replaced by serial code, and the generation of SPMD code <ref> [11] </ref>, where the computation is partitioned and loop bounds are reduced. This loop nest is the subgrid loop nest which will be executed on each PE of the parallel machine such that the PE only computes the data which it owns.
Reference: [12] <author> Stephanie Coleman and Kathryn S. McKinley. </author> <title> Tile size selection using cache organization. </title> <journal> SIG- PLAN Notices, </journal> <volume> 30(6) </volume> <pages> 279-280, </pages> <month> June </month> <year> 1995. </year> <booktitle> Pro- ceedings of the ACM SIGPLAN '95 Conference on Programming Language Design and Imple- mentation. </booktitle>
Reference-contexts: Improve loop balance through unroll-and-jam and scalar replacement [8, 7]. Note that strip-mine-and-interchange can be included here [27]. We have omitted it because of its relative instability and the large amount of cache reuse that already exists in stencil computations <ref> [22, 12] </ref>. In the rest of this section we give an overview of loop permutation, unroll-and-jam and scalar replacement. 6.1 Loop Permutation Not all loops exhibit good cache locality, resulting in idle computational cycles while waiting for main memory to return data.
Reference: [13] <author> R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and K. Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: If one dimension is shifted multiple times the annotations for the shift amounts are simply added together. The algorithm that we have devised for verifying the stated criteria and for performing the above transformations is based upon the static single assignment (SSA) intermediate representation <ref> [13] </ref>. The algorithm, after validating the use of an offset array at a shift operation, transforms the program and propagates that information in an optimistic manner. The propagation continues until there are no more references to transform or one of the criteria have been violated.
Reference: [14] <author> R. Fatoohi. </author> <title> Performance analysis of four SIMD machines. </title> <booktitle> In Proceedings of the 1993 ACM Inter- national Conference on Supercomputing, </booktitle> <address> Tokyo, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: The cost of such a shift operation is described by the following model <ref> [14] </ref>: T shift = g (g d) t onpe + C onpe + g d t offpe + C offpe (1) where t onpe and t offpe represent the time to perform an intraprocessor and interprocessor copy respectively, and C onpe and C offpe represent the startup time (or latency) for
Reference: [15] <author> W. George, R. Brickner, and S. L. Johnsson. </author> <title> Polyshift communications software for the Con- nection Machine systems CM-2 and CM-200. </title> <booktitle> Sci- entific Programming, </booktitle> <address> 3(1):83, </address> <month> Spring </month> <year> 1994. </year>
Reference-contexts: Like our strategy, they eliminated the intraprocessor data movement. They also optimized the interprocessor data movement by exploiting the CM-2's polyshift communication <ref> [15] </ref>. The final computation was performed by hand-optimized library microcode that took advantage of different loop transformations. However, the CM-2 stencil compiler had many limitations. It could only handle single-statement stencils. The stencil had to be specified using the cshift intrinsic; no array-syntax stencils would be accepted.
Reference: [16] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Practice and Ex- perience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: If this is the case only the inter- processor data movement needs to occur. We exploit overlap areas <ref> [16] </ref> to receive the data that is copied between processors. After this has been accomplished, appropriate references to the destination array can be rewritten to refer to the source array with indexing offset by the shift amount. We call such a destination array an offset array [19].
Reference: [17] <author> High Performance Fortran Forum. </author> <title> High Perfor- mance Fortran language specification. </title> <booktitle> Scientific Programming, </booktitle> <address> 2(1-2):1-170, </address> <year> 1993. </year>
Reference: [18] <author> K. Kennedy and K. McKinley. </author> <title> Optimizing for parallelism and memory hierarchy. </title> <booktitle> In Proceed- ings of the 1992 International Conference on Su- percomputing, </booktitle> <pages> pages 323-334, </pages> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: In this case, we have attained locality of reference for B (I,J) and A (I+1,J) by moving reuse points closer together. The result will be fewer idle cycles waiting on main memory. For a more complete discussion of loop permutation see Wolf and Lam [27], Kennedy and McKin- ley <ref> [18] </ref> and Carr, et al. [9]. 6.2 Scalar Replacement Even with better cache performance through loop permutation, a loop may still not perform as well as possible. If a loop is memory bound, then its balance must be lowered.
Reference: [19] <author> K. Kennedy, J. Mellor-Crummey, and G. Roth. </author> <title> Optimizing Fortran 90 shift operations on distributed-memory multicomputers. </title> <booktitle> In Lan- guages and Compilers for Parallel Computing, Eighth International Workshop, </booktitle> <address> Columbus, OH, </address> <month> August </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: After this has been accomplished, appropriate references to the destination array can be rewritten to refer to the source array with indexing offset by the shift amount. We call such a destination array an offset array <ref> [19] </ref>. The principal challenge then is to determine when the source and destination arrays can share stor <p>- 3 An edge is determined by the dimension and direction specified in a shift operation. age. <p> When a criterion has been violated, it may be necessary to insert an array copy statement into the program to maintain its original semantics. The inserted copy statement performs the intraprocessor data movement that was avoided with the offset shift. The details of the algorithm are presented elsewhere <ref> [19] </ref>. It is important to note that due to the algorithm's optimistic nature, it is able to employ offset arrays in many difficult situations. In particular, it can determine when offset arrays can be exploited even when their definition and uses are separated by program control flow.
Reference: [20] <author> K. Kennedy and G. Roth. </author> <title> Context optimization for SIMD execution. </title> <booktitle> In Proceedings of the 1994 Scalable High Performance Computing Con- ference, </booktitle> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: First we reorder the statements within basic blocks so that offset shift calls are grouped into maximal sets; i.e., as many calls as possible are made adjacent. This is accomplished by applying our context partitioning optimization <ref> [20] </ref>. From this point on we then restrict our focus to the individual groups of offset shift calls.
Reference: [21] <author> K. Knobe, J. Lukas, and M. Weiss. </author> <title> Optimiza- tion techniques for SIMD Fortran compilers. </title> <journal> Con- currency: Practice and Experience, </journal> <volume> 5(7) </volume> <pages> 527-552, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: All stencil and stencil-like computations can be translated into this general form by factoring expressions and introducing temporary arrays. In fact, this is the intermediate form used by several distributed- memory compilers <ref> [21, 24] </ref>.
Reference: [22] <author> Monica S. Lam, Edward E. Rothberg, and Michael E. Wolf. </author> <title> The cache performance and optimizations of blocked algorithms. </title> <booktitle> In Pro- ceedings of the Fourth International Conference on Architectural Support for Programming Lan- guages and Operating Systems, </booktitle> <pages> pages 63-74, </pages> <address> Santa Clara, California, </address> <year> 1991. </year>
Reference-contexts: Improve loop balance through unroll-and-jam and scalar replacement [8, 7]. Note that strip-mine-and-interchange can be included here [27]. We have omitted it because of its relative instability and the large amount of cache reuse that already exists in stencil computations <ref> [22, 12] </ref>. In the rest of this section we give an overview of loop permutation, unroll-and-jam and scalar replacement. 6.1 Loop Permutation Not all loops exhibit good cache locality, resulting in idle computational cycles while waiting for main memory to return data.
Reference: [23] <author> J. R. Rice and J. Jing. </author> <title> Problems to test parallel and vector languages. </title> <type> Technical Report CSD-TR- 1016, </type> <institution> Dept. of Computer Science, Purdue Univer- sity, </institution> <year> 1990. </year>
Reference-contexts: Let's consider again the 9-point stencil above. If the programmer attempted to optimize the program by hand, or if the stencil was preprocessed by an optimization phase performing common subexpression elimination, we might be presented with the following (taken from Problem 9 of the Purdue Set <ref> [23] </ref>): TMP1 = CSHIFT (SRC,-1,1) TMP2 = CSHIFT (SRC,+1,1) DST = C1 * CSHIFT (TMP1,-1,2) & + C2 * TMP1 & + C3 * CSHIFT (TMP1,+1,2) & + C4 * CSHIFT (SRC,-1,2) & + C5 * SRC & + C6 * CSHIFT (SRC,+1,2) & + C7 * CSHIFT (TMP2,-1,2) & +
Reference: [24] <author> G. Sabot. </author> <title> A compiler for a massively parallel distributed memory MIMD computer. </title> <booktitle> In Fron- tiers '92: The 4th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: All stencil and stencil-like computations can be translated into this general form by factoring expressions and introducing temporary arrays. In fact, this is the intermediate form used by several distributed- memory compilers <ref> [21, 24] </ref>.
Reference: [25] <author> G. Sabot. </author> <title> Optimized CM Fortran compiler for the Connection Machine computer. </title> <booktitle> In Proceedings of the 25th Annual Hawaii International Conference on System Sciences, </booktitle> <address> Kauai, HI, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: (of size g), and an intraprocessor move of 2 For this reason most CM Fortran programmers use CSHIFTs explicitly in their stencil computations since array- syntax stencils produced the same CSHIFT intrinsic calls but then had the additional overhead of the vector masking operations required for handling the array subsections <ref> [25] </ref>. g d columns.
Reference: [26] <author> J. T. Schwartz. </author> <title> Optimization of very high level languages I. Value transmission and its corollaries. </title> <journal> Computer Languages, </journal> <volume> 1(2) </volume> <pages> 161-194, </pages> <year> 1975. </year>
Reference-contexts: From the work on copy elimination in functional and higher-order programming languages <ref> [26] </ref>, we know that the first two criteria are necessary and sufficient conditions for when the two objects can share the same storage. However, the sharing of storage may not always be profitable. To insure profitability, we added the remaining criteria.
Reference: [27] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A data locality optimizing algorithm. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(6) </volume> <pages> 30-44, </pages> <month> June </month> <year> 1991. </year> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on Programming Lan- guage Design and Implementation. </booktitle>
Reference-contexts: Our strategy involves the following compiler optimizations to improve data locality: 1. Improve the order of memory accesses through loop permutation [9]. 2. Improve loop balance through unroll-and-jam and scalar replacement [8, 7]. Note that strip-mine-and-interchange can be included here <ref> [27] </ref>. We have omitted it because of its relative instability and the large amount of cache reuse that already exists in stencil computations [22, 12]. <p> In this case, we have attained locality of reference for B (I,J) and A (I+1,J) by moving reuse points closer together. The result will be fewer idle cycles waiting on main memory. For a more complete discussion of loop permutation see Wolf and Lam <ref> [27] </ref>, Kennedy and McKin- ley [18] and Carr, et al. [9]. 6.2 Scalar Replacement Even with better cache performance through loop permutation, a loop may still not perform as well as possible. If a loop is memory bound, then its balance must be lowered.
Reference: [28] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Su- percomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: The sum of products is calculated within a loop nest. The loop nest is a result of scalarization <ref> [28] </ref>, where the array constructs are replaced by serial code, and the generation of SPMD code [11], where the computation is partitioned and loop bounds are reduced.
References-found: 28

