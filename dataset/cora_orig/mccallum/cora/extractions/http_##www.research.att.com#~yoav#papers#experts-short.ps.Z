URL: http://www.research.att.com/~yoav/papers/experts-short.ps.Z
Refering-URL: http://www.research.att.com/~yoav/publications.html
Root-URL: 
Title: How to Use Expert Advice (Extended Abstract)  
Author: Nicolo Cesa-Bianchi Yoav Freund David P. Helmbold David Haussler Robert E. Schapire Manfred K. Warmuth 
Address: Milano (Italy)  Santa Cruz  
Affiliation: Universita di  UC Santa Cruz  UC Santa Cruz  UC Santa Cruz  AT&T Bell Labs  UC  
Abstract: We analyze algorithms that predict a binary value by combining the predictions of several prediction strategies, called experts. Our analysis is for worst-case situations, i.e., we make no assumptions about the way the sequence of bits to be predicted is generated. We measure the performance of the algorithm by the difference between the expected number of mistakes it makes on the bit sequence and the expected number of mistakes made by the best expert on this sequence, where the expectation is taken with respect to the randomization in the predictions. We show that the minimum achievable difference is on the order of the square root of the number of mistakes of the best expert, and we give efficient algorithms that achieve this. Our upper and lower bounds have matching leading constants in most cases. We give implications of this result on the performance of batch learning algorithms in a PAC setting which improve on the best results currently known in this context. We also extend our analysis to the case in which log loss is used instead of the expected number of mistakes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. M. </author> <title> Cover. Behaviour of sequential predictors of binary sequences. </title> <booktitle> In Transactions of the Fourth Prague Conference on Information Theory, Statistical Decision Functions, Random Processes, </booktitle> <pages> pages 263-272. </pages> <publisher> Publishing House of the Czechoslovak Academy of Sciences, </publisher> <year> 1965. </year>
Reference-contexts: the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences <ref> [7, 24, 1, 2, 12, 36] </ref>, that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y ` of outcomes that is observed; the analysis is done in the worst case over all possible binary outcome sequences. <p> Based on this data, each expert returns a real number p between 0 and 1 that can be interpreted as his/her estimate of the probability that it will rain that day. After hearing the predictions of the experts, you also choose a number p 2 <ref> [0; 1] </ref> as your estimate of the probability of rain. Later in the day, nature sets the value of y t to either 1 or 0 by either raining or not raining. In the evening, you and the experts are scored. <p> Later in the day, nature sets the value of y t to either 1 or 0 by either raining or not raining. In the evening, you and the experts are scored. A person receives the loss jp yj for making prediction p 2 <ref> [0; 1] </ref> when the actual outcome is y 2 f0; 1g. To see why this is a reasonable measure of loss, 1 imagine that instead of returning p 2 [0; 1] you tossed a biased coin and predicted outcome 1 with probability p and outcome 0 with probability 1 p. <p> A person receives the loss jp yj for making prediction p 2 <ref> [0; 1] </ref> when the actual outcome is y 2 f0; 1g. To see why this is a reasonable measure of loss, 1 imagine that instead of returning p 2 [0; 1] you tossed a biased coin and predicted outcome 1 with probability p and outcome 0 with probability 1 p. Then jp yj is the probability that your prediction is incorrect when the actual outcome is y. <p> Imagine that the above prediction game is played for ` days, during which time you accumulate a total loss L (y) = P ` t=1 j t y t j, where t 2 <ref> [0; 1] </ref> is your prediction at time t. Each of the experts also accumulates a total loss based on his/her predictions. <p> It turns out that these bounds also give a tight lower bound on the expectation of the minimal distance between a random binary string uniformly chosen from f0; 1g ` and a set of N points in <ref> [0; 1] </ref> ` , which may be of independent interest from a combinatorial viewpoint. The remainder of this paper is organized as follows. In Section 2 we introduce some notation. <p> The prediction given by the expert E i at time t is denoted by ~ i;t 2 <ref> [0; 1] </ref>, and the prediction of the algorithm by t 2 [0; 1]. Side information that might be used as input by the experts is denoted by the sequence of instances x = x 1 ; : : : ; x ` . <p> The prediction given by the expert E i at time t is denoted by ~ i;t 2 <ref> [0; 1] </ref>, and the prediction of the algorithm by t 2 [0; 1]. Side information that might be used as input by the experts is denoted by the sequence of instances x = x 1 ; : : : ; x ` . <p> In this case Theorem 1 implies that the loss of the optimal algorithm A fl is worse than the loss of the best expert by the following amount : V = 2 ` i=0 ` minfi; ` ig ~ r 2 This result was previously proved by Cover <ref> [1] </ref>; we obtain it as a special case. Strategy A fl makes each prediction in terms of the expected loss of the best expert on the remaining trials (where the expectation is taken over the uniformly random choice of outcomes for these trials). <p> However their algorithm works for the more general setting when the outcome y t can be in <ref> [0; 1] </ref> as opposed to being binary. <p> Corollary 9 Let A be a finite set of points in <ref> [0; 1] </ref> ` , let y be in f0; 1g ` and let d (y; A) denote the l 1 distance between y and the closest point in A. <p> The proof of this is based on the case in which the predictions of the experts depend only on the time t. In this case E is isomorphic to a set of points in <ref> [0; 1] </ref> ` . The left inequality follows from Theorem 1 and the loss bound proven for P in Theorem 6. <p> In this section we will assume that each expert E i is a function from X into <ref> [0; 1] </ref>, i.e., the i th expert's prediction at time t, denoted ~ i;t , depends only on the instance x t , and not on previous outcomes or instances. We call such experts time independent. <p> Given this input, a hold-one-out prediction algorithm produces a prediction t 2 <ref> [0; 1] </ref>. The total loss of the hold-one-out prediction algorithm A on outcome sequence y is defined in analogy with the on-line prediction loss by L H P ` t=1 j t y t j. <p> The algorithm produces a prediction t for the held out outcome y t . g 1. Pick r 2 <ref> [0; 1] </ref> uniformly at random; 2. Compute L obs = min i j=1 jE i;j y j j + j=t+1 jE i;j y j j ; 3. Compute L est = (d p 4. <p> ` ; y ` ) of training examples is drawn from the product distribution D ` (i.e. each example is drawn independently according to D) and a PAC learning algorithm A takes these training examples as input and outputs a function h = A (s) that maps from X into <ref> [0; 1] </ref>. The function h is called a hypothesis. The error of the hypothesis h is defined by er D (h) = E (x;y)2D jh (x) yj, where E (x;y)2D denotes the expectation over (x; y) drawn randomly according to D. <p> In PAC learning, the goal is to minimize this error under the worst-case distribution D. This leads to a kind of L 1 regression problem (see also Kearns and Schapire [19]). The learning algorithm is given a set H of mappings from X into <ref> [0; 1] </ref>, which is called a hypothesis space. These play a role similar to that played by the experts above. Namely, let er D (H) = inf h2H er D (h). Thus er D (H) is the error of the best hypothesis in H for the particular distribution D.
Reference: [2] <author> T. M. Cover and A. Shanhar. </author> <title> Compound Bayes predictors for sequences with apparent Markov structure. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> SMC-7(6):421-424, </volume> <month> June </month> <year> 1977. </year>
Reference-contexts: the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences <ref> [7, 24, 1, 2, 12, 36] </ref>, that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y ` of outcomes that is observed; the analysis is done in the worst case over all possible binary outcome sequences.
Reference: [3] <author> A. Dawid. </author> <title> Prequential data analysis. Current Issues in Statistical Inference, </title> <note> to appear. </note>
Reference-contexts: Email addresses: fhaussler,manfred,yoavg@cse.ucsc.edu x Email address: schapire@research.att.com the information theory literature. We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability <ref> [4, 3, 5, 35] </ref>, Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual
Reference: [4] <author> A. P. Dawid. </author> <title> Statistical theory: The prequential approach. </title> <journal> Journal of the Royal Statistical Society, Series A, </journal> <pages> pages 278-292, </pages> <year> 1984. </year>
Reference-contexts: Email addresses: fhaussler,manfred,yoavg@cse.ucsc.edu x Email address: schapire@research.att.com the information theory literature. We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability <ref> [4, 3, 5, 35] </ref>, Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual
Reference: [5] <author> A. P. Dawid. </author> <title> Prequential analysis, stochastic complexity and Bayesian inference. Bayesian Statistics 4, </title> <note> to appear. </note>
Reference-contexts: Email addresses: fhaussler,manfred,yoavg@cse.ucsc.edu x Email address: schapire@research.att.com the information theory literature. We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability <ref> [4, 3, 5, 35] </ref>, Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual
Reference: [6] <author> A. DeSantis, G. Markowski, and M. N. Wegman. </author> <title> Learning probabilistic prediction functions. </title> <booktitle> In Proceedings of the 1988 Workshop on Computational Learning Theory, </booktitle> <pages> pages 312-328. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: known that for the log loss, for any set E of N experts (i.e., distributions) there is a prediction strategy A such that for any sequence y, L A (y) L E (y) log N; where L E (y) is the total log loss of the best expert for y <ref> [26, 6, 36, 13, 37] </ref>. The strategy is just the Bayes algo rithm with uniform prior on the distributions represented by the experts. We have done an exact minimax analysis of this case as well, and the result is quite simple.
Reference: [7] <author> M. Feder, N. Merhav, and M. Gutman. </author> <title> Universal prediction of individual sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 38 </volume> <pages> 1258-1270, </pages> <year> 1992. </year>
Reference-contexts: the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences <ref> [7, 24, 1, 2, 12, 36] </ref>, that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y ` of outcomes that is observed; the analysis is done in the worst case over all possible binary outcome sequences. <p> Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors [23, 22, 15, 29, 28, 13, 18], as well as the method developed by Feder, Merhav and Gut-man <ref> [7] </ref>. We show that P performs quite well in the sense defined above so that, for example, given any finite set E of weather forecasting experts, P is guaranteed not to perform much worse than the best expert in E, no matter what the actual weather turns out to be. <p> Previous work has shown how to construct an algorithm A such that the ratio L A (y)=L E (y) approaches 1 in the limit <ref> [34, 23, 7] </ref>. In fact, Vovk [34] described an algorithm with the same bound as the one we give in Theorem 2 for the algorithm P. This theorem leaves a parameter to be tuned. Vovk gives an implicit form of the optimum choice of the parameter. <p> However, as is clear from Figure 2, this function lies outside the allowable range for F fi (r), and this is no accident. The Bayes method does not perform well in the worst case for this prediction problem, as was shown in <ref> [17, 7] </ref>. Hence we must deviate from the Bayes method at this step. bounds on the possible values of the prediction function F fi for fi = 0 (Inequality (1)). <p> For the noise-free case (fi = 0), slightly weaker upper bounds have been proved for an algorithm known as the Gibbs algorithm [23, 17]. Also, Littlestone and Warmuth [23] prove a 5 A similar piecewise linear function was suggested by Feder et al. <ref> [7] </ref>, in a related context. 6 Vovk's algorithm generates its prediction according to the predic tion function t = P N ln i=1 w i;t fi ~ i;t + ln i=1 w i;t fi 1~ i;t where the weights are normalized so that they sum to one.
Reference: [8] <author> A. Fiat, D. Foster, H. Karloff, Y. Rabani, Y. Ravid, and S. Vishwanathan. </author> <title> Competitive algorithms for layered graph traversal. </title> <booktitle> In 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 288-297, </pages> <year> 1991. </year>
Reference-contexts: In Section 3, we char acterize exactly the performance of the best possible pre 2 This approach is also related to that taken in recent work on the competitive ratio of on-line algorithms, and in particular to work on combining on-line algorithms to obtain the best competitive ratio <ref> [9, 8, 10] </ref>, except that we look at the difference in performance rather than the ratio. diction strategy using a minimax analysis. Section 4 describes the algorithm P and shows that it achieves the optimal bound given above.
Reference: [9] <author> A. Fiat, R. Karp, M. Luby, L. McGeoch, D. Sleator, and N. Young. </author> <title> Competitive paging algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 12 </volume> <pages> 685-699, </pages> <year> 1991. </year>
Reference-contexts: In Section 3, we char acterize exactly the performance of the best possible pre 2 This approach is also related to that taken in recent work on the competitive ratio of on-line algorithms, and in particular to work on combining on-line algorithms to obtain the best competitive ratio <ref> [9, 8, 10] </ref>, except that we look at the difference in performance rather than the ratio. diction strategy using a minimax analysis. Section 4 describes the algorithm P and shows that it achieves the optimal bound given above.
Reference: [10] <author> A. Fiat, Y. Rabani, and Y. Ravid. </author> <title> Competitive k-server algorithms. </title> <booktitle> In 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 454-463, </pages> <year> 1990. </year>
Reference-contexts: In Section 3, we char acterize exactly the performance of the best possible pre 2 This approach is also related to that taken in recent work on the competitive ratio of on-line algorithms, and in particular to work on combining on-line algorithms to obtain the best competitive ratio <ref> [9, 8, 10] </ref>, except that we look at the difference in performance rather than the ratio. diction strategy using a minimax analysis. Section 4 describes the algorithm P and shows that it achieves the optimal bound given above.
Reference: [11] <author> J. Galambos. </author> <title> The Asymptotic Theory of Extreme Oreder Statistics. </title> <editor> R. E. Kreiger, </editor> <booktitle> second edition, </booktitle> <year> 1987. </year>
Reference-contexts: Then lim lim ` p = 2 The proof of the lemma is based on the central limit theorem and a theorem about the expected value of the minimum of a set of independent normally distributed random variables (see e.g. Galambos <ref> [11] </ref>). Proof of Theorem 7: We use the following random construction. Assume that each bit in the sequence y of length ` is chosen independently at random using a fair coin flip.
Reference: [12] <author> J. Hannan. </author> <title> Approximation to Bayes risk in repeated play. </title> <booktitle> In Contributions to the theory of games, </booktitle> <volume> volume 3, </volume> <pages> pages 97-139. </pages> <publisher> Princeton University Press, </publisher> <year> 1957. </year>
Reference-contexts: the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences <ref> [7, 24, 1, 2, 12, 36] </ref>, that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y ` of outcomes that is observed; the analysis is done in the worst case over all possible binary outcome sequences.
Reference: [13] <author> D. Haussler and A. Barron. </author> <title> How well do Bayes methods work for on-line prediction of f+1; 1g values? In Proceedings of the Third NEC Symposium on Computation and Cognition. </title> <note> SIAM, to appear. </note>
Reference-contexts: Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors <ref> [23, 22, 15, 29, 28, 13, 18] </ref>, as well as the method developed by Feder, Merhav and Gut-man [7]. <p> known that for the log loss, for any set E of N experts (i.e., distributions) there is a prediction strategy A such that for any sequence y, L A (y) L E (y) log N; where L E (y) is the total log loss of the best expert for y <ref> [26, 6, 36, 13, 37] </ref>. The strategy is just the Bayes algo rithm with uniform prior on the distributions represented by the experts. We have done an exact minimax analysis of this case as well, and the result is quite simple.
Reference: [14] <author> D. Haussler, M. Kearns, N. Littlestone, and M. K. Warmuth. </author> <title> Equivalence of models for polynomial learnability. </title> <journal> Information and Computation, </journal> <volume> 95 </volume> <pages> 129-161, </pages> <year> 1991. </year>
Reference-contexts: Our current methods do not provide these, but standard "confidence boosting" methods can be applied on top of them to achieve good tail bounds <ref> [14, 21] </ref>. More direct methods are given by Littlestone and Warmuth [23]. 8 Bounds given by Vapnik ([32], Equation (11)) imply a bound in the same form as the second bound in Theorem 16, but with an additional factor of 2 in the leading term.
Reference: [15] <author> D. Haussler, M. Kearns, and R. Schapire. </author> <title> Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension. </title> <journal> Machine Learning, </journal> <note> to appear. </note>
Reference-contexts: Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors <ref> [23, 22, 15, 29, 28, 13, 18] </ref>, as well as the method developed by Feder, Merhav and Gut-man [7].
Reference: [16] <author> D. Haussler, N. Littlestone, and M. Warmuth. </author> <title> Predicting f0; 1g-functions on randomly drawn points. </title> <type> Technical Report UCSC-CRL-90-54, </type> <institution> University of California Santa Cruz, Computer Research Laboratory, </institution> <month> Dec. </month> <year> 1990. </year> <note> To appear, Information and Computation. </note>
Reference-contexts: 1 Introduction A central problem in machine learning is the problem of predicting future events based on past observations. In computer science literature in particular, special attention has been given to the case in which the events are simple binary outcomes <ref> [16] </ref>. For example, in predicting today's weather, we may choose to consider only the possible outcomes 0 and 1, where 1 indicates that it rains today, and 0 indicates that it does not.
Reference: [17] <author> D. Helmbold and M. K. Warmuth. </author> <title> On weak learning. </title> <journal> In Proceedings of the Third NEC Research Symposium on Computational Learning and Cognition. </journal> <note> SIAM, to appear. </note>
Reference-contexts: However, as is clear from Figure 2, this function lies outside the allowable range for F fi (r), and this is no accident. The Bayes method does not perform well in the worst case for this prediction problem, as was shown in <ref> [17, 7] </ref>. Hence we must deviate from the Bayes method at this step. bounds on the possible values of the prediction function F fi for fi = 0 (Inequality (1)). <p> This parameterized bound was first proved by Vovk [34] for his version of F fi and the exponential update. For the noise-free case (fi = 0), slightly weaker upper bounds have been proved for an algorithm known as the Gibbs algorithm <ref> [23, 17] </ref>. <p> ) and any instance x, the value of the function h = B (s) on input x is defined by inserting x into a random position in the sequence s and running the hold-one-out prediction strategy A to predict the label of x, using the hypotheses in H as experts <ref> [17] </ref>.
Reference: [18] <author> D. P. Helmbold and M. K. Warmuth. </author> <title> Some weak learning results. </title> <booktitle> In Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 399-412, </pages> <year> 1992. </year>
Reference-contexts: Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors <ref> [23, 22, 15, 29, 28, 13, 18] </ref>, as well as the method developed by Feder, Merhav and Gut-man [7]. <p> Using a permutation argument <ref> [18, 33] </ref>, we are able to apply the bounds obtained in Section 6 for the hold-one-out variant of P to get distribution-independent bounds for the performance on this task as well.
Reference: [19] <author> M. J. Kearns and R. E. Schapire. </author> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 382-391, </pages> <year> 1990. </year>
Reference-contexts: In PAC learning, the goal is to minimize this error under the worst-case distribution D. This leads to a kind of L 1 regression problem (see also Kearns and Schapire <ref> [19] </ref>). The learning algorithm is given a set H of mappings from X into [0; 1], which is called a hypothesis space. These play a role similar to that played by the experts above. Namely, let er D (H) = inf h2H er D (h).
Reference: [20] <author> M. J. Kearns, R. E. Schapire, and L. M. Sellie. </author> <title> Toward efficient agnostic learning. </title> <booktitle> In Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 341-352, </pages> <year> 1992. </year>
Reference-contexts: We look at a special variant of the PAC model in which nothing is assumed about the "target concept" that generates the examples other than independence between examples (sometimes referred to as agnostic learning <ref> [20] </ref>), and in which the learning algorithm is not required to return a hypothesis in any specific form. Let X be any set and D any probability distribution on X fi f0; 1g. When X is uncountable, appropriate assumptions are made to insure measurability.
Reference: [21] <author> N. Littlestone. </author> <title> From on-line to batch learning. </title> <booktitle> In Proceedings of the Second Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 269-284. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Our current methods do not provide these, but standard "confidence boosting" methods can be applied on top of them to achieve good tail bounds <ref> [14, 21] </ref>. More direct methods are given by Littlestone and Warmuth [23]. 8 Bounds given by Vapnik ([32], Equation (11)) imply a bound in the same form as the second bound in Theorem 16, but with an additional factor of 2 in the leading term.
Reference: [22] <author> N. Littlestone, P. M. Long, and M. K. Warmuth. </author> <title> On-line learning of linear functions. </title> <booktitle> In Proceedings of the Twenty Third Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 465-475, </pages> <year> 1991. </year>
Reference-contexts: Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors <ref> [23, 22, 15, 29, 28, 13, 18] </ref>, as well as the method developed by Feder, Merhav and Gut-man [7]. <p> In both these cases, results by Littlestone, 9 Long and Warmuth <ref> [23, 22] </ref> can be applied to extend the methods we have presented here. We have also obtained some related results for the quadratic loss in these cases (see also Vovk [34]).
Reference: [23] <author> N. Littlestone and M. Warmuth. </author> <title> The weighted majority algorithm. </title> <booktitle> In 30th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 256-261, </pages> <year> 1989. </year> <title> Long version: </title> <type> UCSC tech. rep. </type> <institution> UCSC-CRL-91-28. </institution>
Reference-contexts: Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors <ref> [23, 22, 15, 29, 28, 13, 18] </ref>, as well as the method developed by Feder, Merhav and Gut-man [7]. <p> Previous work has shown how to construct an algorithm A such that the ratio L A (y)=L E (y) approaches 1 in the limit <ref> [34, 23, 7] </ref>. In fact, Vovk [34] described an algorithm with the same bound as the one we give in Theorem 2 for the algorithm P. This theorem leaves a parameter to be tuned. Vovk gives an implicit form of the optimum choice of the parameter. <p> The function U fi (q) is called the update function. Its lower bound is the exponential fi q and its upper bound is the linear function 1 (1 fi)q. In related work, Vovk uses the exponential update function [34], and Littlestone and Warmuth <ref> [23] </ref> use any update between the exponential and the linear update. <p> This parameterized bound was first proved by Vovk [34] for his version of F fi and the exponential update. For the noise-free case (fi = 0), slightly weaker upper bounds have been proved for an algorithm known as the Gibbs algorithm <ref> [23, 17] </ref>. <p> This parameterized bound was first proved by Vovk [34] for his version of F fi and the exponential update. For the noise-free case (fi = 0), slightly weaker upper bounds have been proved for an algorithm known as the Gibbs algorithm [23, 17]. Also, Littlestone and Warmuth <ref> [23] </ref> prove a 5 A similar piecewise linear function was suggested by Feder et al. [7], in a related context. 6 Vovk's algorithm generates its prediction according to the predic tion function t = P N ln i=1 w i;t fi ~ i;t + ln i=1 w i;t fi 1~ i;t <p> Our current methods do not provide these, but standard "confidence boosting" methods can be applied on top of them to achieve good tail bounds [14, 21]. More direct methods are given by Littlestone and Warmuth <ref> [23] </ref>. 8 Bounds given by Vapnik ([32], Equation (11)) imply a bound in the same form as the second bound in Theorem 16, but with an additional factor of 2 in the leading term. However, these bounds do hold in more general cases than the one we consider here. <p> In both these cases, results by Littlestone, 9 Long and Warmuth <ref> [23, 22] </ref> can be applied to extend the methods we have presented here. We have also obtained some related results for the quadratic loss in these cases (see also Vovk [34]).
Reference: [24] <author> N. Merhav and M. Feder. </author> <title> Universal sequential learning and decision from individual data sequences. </title> <booktitle> In Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 413-427, </pages> <year> 1992. </year>
Reference-contexts: the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences <ref> [7, 24, 1, 2, 12, 36] </ref>, that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y ` of outcomes that is observed; the analysis is done in the worst case over all possible binary outcome sequences.
Reference: [25] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Auto-matica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity <ref> [25, 27, 26, 37] </ref> and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y
Reference: [26] <author> J. Rissanen. </author> <title> Stochastic complexity and modeling. </title> <journal> The Annals of Statistics, </journal> <volume> 14(3) </volume> <pages> 1080-1100, </pages> <year> 1986. </year>
Reference-contexts: We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity <ref> [25, 27, 26, 37] </ref> and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y <p> known that for the log loss, for any set E of N experts (i.e., distributions) there is a prediction strategy A such that for any sequence y, L A (y) L E (y) log N; where L E (y) is the total log loss of the best expert for y <ref> [26, 6, 36, 13, 37] </ref>. The strategy is just the Bayes algo rithm with uniform prior on the distributions represented by the experts. We have done an exact minimax analysis of this case as well, and the result is quite simple.
Reference: [27] <author> J. Rissanen and G. G. Langdon, Jr. </author> <title> Universal modeling and coding. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-27(1):12-23, </volume> <month> Jan. </month> <year> 1981. </year>
Reference-contexts: We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity <ref> [25, 27, 26, 37] </ref> and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y
Reference: [28] <author> H. S. Seung, H. Sompolinsky, and N. Tishby. </author> <title> Statistical mechanics of learning from examples. </title> <journal> Physical Review A, </journal> <volume> 45(8) </volume> <pages> 6056-6091, </pages> <year> 1992. </year>
Reference-contexts: Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors <ref> [23, 22, 15, 29, 28, 13, 18] </ref>, as well as the method developed by Feder, Merhav and Gut-man [7].
Reference: [29] <author> H. Sompolinsky, N. Tishby, and H. Seung. </author> <title> Learning from examples in large neural networks. </title> <journal> Physical Review Letters, </journal> <volume> 65 </volume> <pages> 1683-1686, </pages> <year> 1990. </year>
Reference-contexts: Actually P is a family of algorithms that is related to the algorithm studied by Vovk [34] and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors <ref> [23, 22, 15, 29, 28, 13, 18] </ref>, as well as the method developed by Feder, Merhav and Gut-man [7].
Reference: [30] <author> M. Talagrand. </author> <title> Sharper bounds for Gaussian and empirical processes. </title> <journal> Annals of Probability, </journal> <note> to appear. </note>
Reference-contexts: These bounds are more robust and improve by constant factors some of the (more general) bounds obtained by Vapnik [33] and Talagrand <ref> [30] </ref> on the performance of an empirical loss minimization algorithm. The results presented in this paper contribute to an ongoing program in information theory and statistics to minimize the number of assumptions placed on the actual mechanism generating the observations through the development of robust procedures and strengthened worst-case analysis. <p> in H. 7 While we cannot provide a minimax solution to this problem, we can use the algorithm developed in the previous section to get good upper bounds on the minimax value in certain important cases, better than those obtained by the only other methods that we are aware of <ref> [32, 30] </ref>. 8 Before stating these bounds, we need to make a few definitions. Our first definition deals with the issue of optimizing the error on the training examples (called empirical error) versus optimizing er D , the error with respect to the underlying distribution D.
Reference: [31] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-42, </pages> <year> 1984. </year>
Reference-contexts: Email address: cesabian@imiucca.csi.unimi.it y Email address: dph@cse.ucsc.edu z Haussler, Warmuth and Freund are supported by ONR grant NO0014-91-J-1162 and NSF grant IRI-9123692. Email addresses: fhaussler,manfred,yoavg@cse.ucsc.edu x Email address: schapire@research.att.com the information theory literature. We then give applications of these results to the theory of PAC learning <ref> [31] </ref>. <p> x, any set E of N time independent experts, and any sequence y, L P H (y)L E (y) L E (y)( ln N+1)+3 ln N + ln 2 7 Relation to the PAC model for learning We now give an application of these results to a PAC learning framework <ref> [31] </ref>.
Reference: [32] <author> V. Vapnik. </author> <title> Principles of risk minimization for learning theory. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: in H. 7 While we cannot provide a minimax solution to this problem, we can use the algorithm developed in the previous section to get good upper bounds on the minimax value in certain important cases, better than those obtained by the only other methods that we are aware of <ref> [32, 30] </ref>. 8 Before stating these bounds, we need to make a few definitions. Our first definition deals with the issue of optimizing the error on the training examples (called empirical error) versus optimizing er D , the error with respect to the underlying distribution D.
Reference: [33] <author> V. N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <year> 1982. </year>
Reference-contexts: Using a permutation argument <ref> [18, 33] </ref>, we are able to apply the bounds obtained in Section 6 for the hold-one-out variant of P to get distribution-independent bounds for the performance on this task as well. <p> These bounds are more robust and improve by constant factors some of the (more general) bounds obtained by Vapnik <ref> [33] </ref> and Talagrand [30] on the performance of an empirical loss minimization algorithm.
Reference: [34] <author> V. G. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proceedings of the Third Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 371-383. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: However, we define an algorithm, called P for "Predict", that is simple and efficient, and performs essentially as well as the minimax strategy. Actually P is a family of algorithms that is related to the algorithm studied by Vovk <ref> [34] </ref> and the Bayesian, Gibbs and "weighted majority" methods studied by a number of authors [23, 22, 15, 29, 28, 13, 18], as well as the method developed by Feder, Merhav and Gut-man [7]. <p> Previous work has shown how to construct an algorithm A such that the ratio L A (y)=L E (y) approaches 1 in the limit <ref> [34, 23, 7] </ref>. In fact, Vovk [34] described an algorithm with the same bound as the one we give in Theorem 2 for the algorithm P. This theorem leaves a parameter to be tuned. Vovk gives an implicit form of the optimum choice of the parameter. <p> Previous work has shown how to construct an algorithm A such that the ratio L A (y)=L E (y) approaches 1 in the limit [34, 23, 7]. In fact, Vovk <ref> [34] </ref> described an algorithm with the same bound as the one we give in Theorem 2 for the algorithm P. This theorem leaves a parameter to be tuned. Vovk gives an implicit form of the optimum choice of the parameter. <p> In fact, different choices could be made at different times. The function U fi (q) is called the update function. Its lower bound is the exponential fi q and its upper bound is the linear function 1 (1 fi)q. In related work, Vovk uses the exponential update function <ref> [34] </ref>, and Littlestone and Warmuth [23] use any update between the exponential and the linear update. <p> the piecewise linear function 5 F fi (r) = &lt; 0 if r 1 1 (12r)(1fi) 1+fi ) if 1 2 + c 2 + c where c = (1 + fi) ln ( 2 2 (1 fi) Another possible choice for F fi is suggested by Vovk's work 6 <ref> [34] </ref> F fi (r) = ln (1 r + rfi) + ln ((1 r)fi + r) These functions, for fi = 0, along with the upper and lower bounds for F fi , given in Inequality (1), are shown in Algorithm P's performance is summarized by the following theorem. <p> This parameterized bound was first proved by Vovk <ref> [34] </ref> for his version of F fi and the exponential update. For the noise-free case (fi = 0), slightly weaker upper bounds have been proved for an algorithm known as the Gibbs algorithm [23, 17]. <p> In both these cases, results by Littlestone, 9 Long and Warmuth [23, 22] can be applied to extend the methods we have presented here. We have also obtained some related results for the quadratic loss in these cases (see also Vovk <ref> [34] </ref>). Acknowledgements We would like to thank Meir Feder, Yuval Peres, Nick Lit-tlestone and Michael Kearns for helpful suggestions and discussions of this material.
Reference: [35] <author> V. G. Vovk. </author> <title> Prequential probability theory. </title> <type> Unpublished manuscript, </type> <year> 1990. </year>
Reference-contexts: Email addresses: fhaussler,manfred,yoavg@cse.ucsc.edu x Email address: schapire@research.att.com the information theory literature. We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability <ref> [4, 3, 5, 35] </ref>, Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual
Reference: [36] <author> V. G. Vovk. </author> <title> Universal forcasting algorithms. </title> <journal> Information and Computation, </journal> <volume> 96(2) </volume> <pages> 245-277, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity [25, 27, 26, 37] and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences <ref> [7, 24, 1, 2, 12, 36] </ref>, that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y ` of outcomes that is observed; the analysis is done in the worst case over all possible binary outcome sequences. <p> known that for the log loss, for any set E of N experts (i.e., distributions) there is a prediction strategy A such that for any sequence y, L A (y) L E (y) log N; where L E (y) is the total log loss of the best expert for y <ref> [26, 6, 36, 13, 37] </ref>. The strategy is just the Bayes algo rithm with uniform prior on the distributions represented by the experts. We have done an exact minimax analysis of this case as well, and the result is quite simple.
Reference: [37] <author> K. Yamanishi. </author> <title> A loss bound model for on-line stochastic prediction strategies. </title> <booktitle> In Proceedings of the Fourth Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 290-302. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year> <month> 10 </month>
Reference-contexts: We then give applications of these results to the theory of PAC learning [31]. We take the extreme position, as advocated by Dawid and Vovk in the theory of Prequential Probability [4, 3, 5, 35], Rissanen in his theory of stochastic complexity <ref> [25, 27, 26, 37] </ref> and Cover, Lempel and Ziv, Feder and others in the theory of universal prediction and data compression of individual sequences [7, 24, 1, 2, 12, 36], that no assumptions whatsoever can be made about the actual sequence y = y 1 ; : : : ; y <p> known that for the log loss, for any set E of N experts (i.e., distributions) there is a prediction strategy A such that for any sequence y, L A (y) L E (y) log N; where L E (y) is the total log loss of the best expert for y <ref> [26, 6, 36, 13, 37] </ref>. The strategy is just the Bayes algo rithm with uniform prior on the distributions represented by the experts. We have done an exact minimax analysis of this case as well, and the result is quite simple.
References-found: 37

