URL: http://www.cs.cornell.edu/home/alexey/srds97.ps
Refering-URL: http://www.cs.cornell.edu/home/alexey/publications.html
Root-URL: 
Email: froy,alexeyg@cs.cornell.edu  
Title: Fast Replicated State Machines Over Partitionable Networks  
Author: Roy Friedman Alexey Vaysburd 
Affiliation: Department of Computer Science Cornell University  
Abstract: This paper presents an implementation of replicated state machines in asynchronous distributed environments prone to node failures and network partitions. This implementation has several appealing properties: It guarantees that progress will be made whenever a majority of replicas can communicate with each other; it allows minority partitions to continue providing service for idempotent requests; it offers the application the choice between optimistic or safe message delivery. Performance measurements have shown that our implementation incurs low latency and achieves high throughput while providing globally consistent replicated state machine semantics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Amir. </author> <title> Replication Using Group Communication Over a Partitioned Network. </title> <type> PhD thesis, </type> <institution> Institute of Computer Science, the Hebrew University of Jerusalem, </institution> <year> 1995. </year>
Reference-contexts: Performance analysis is presented in Section 6. We conclude with a discussion in Section 7. 2 Related Work Pessimistic implementations of global total ordering that can tolerate network partitions have been proposed in <ref> [1, 2, 12, 16] </ref>. Being pessimistic, they require more communication rounds to perform an operation. 2 Also, these solutions require all messages to be logged on stable storage, which adds a substantial overhead.
Reference: [2] <author> Y. Amir, D. Dolev, P. M. Melliar-Smith, and L. E. Moser. </author> <title> Robust and Efficient Replication Using Group Communication. </title> <type> Technical Report CS94-20, </type> <institution> Institute of Computer Science, the Hebrew University of Jerusalem, Jerusalem, Israel, </institution> <year> 1994. </year>
Reference-contexts: Optimistic implementations, e.g., [5, 14], tend to deliver messages fast, yielding good performance, although the local state of individual replicas may become invalid under certain failure scenarios as a result of delivering messages that never become authoritative. On the other hand, pessimistic implementations, e.g., <ref> [2, 4, 12] </ref>, deliver messages only when it is safe to do so, thereby avoiding the risk of having to invalidate the state of a replica. This is achieved at the cost of additional communication rounds. <p> Many existing implementations of replicated state machines ignore the issue of network partitions [6, 17]. Other implementations either have a limited support for partitions, but might block forever even after all partitions have been reconciled [4, 5], or are pessimistic <ref> [2, 12, 16] </ref>. A proper handling of partitions is vital for applications targeted for large scale or wide-area environments where partitions are common. However, the high communication cost associated with pessimistic approaches may be prohibitive for many applications. <p> Performance analysis is presented in Section 6. We conclude with a discussion in Section 7. 2 Related Work Pessimistic implementations of global total ordering that can tolerate network partitions have been proposed in <ref> [1, 2, 12, 16] </ref>. Being pessimistic, they require more communication rounds to perform an operation. 2 Also, these solutions require all messages to be logged on stable storage, which adds a substantial overhead. <p> Consequently, our protocols will block if a majority of processes in the group crash simultaneously, whereas the implementation 2 Note that <ref> [2] </ref> claims to deliver messages as soon as they arrive from the transport layer, without end-to-end acknowledgments, but it assumes that the transport layer provides total safe (uniform) delivery, which requires at least 2 communication rounds at the transport level. in Transis [12] can sustain any number of crashes (assuming that
Reference: [3] <author> O. Babaoglu, R. Davoli, L. Giachini, and M. Baker. Relacs: </author> <title> A Communication Infrastructure for Constructing Reliable Applications in Large-Scale Distributed Systems. </title> <type> Technical Report UBLCS-94-15, </type> <institution> Department of Computer Science, University of Bologna, </institution> <month> June </month> <year> 1994. </year> <note> Revised January 1995. </note>
Reference-contexts: However, the proposed approach can easily be applied to any group communication system that supports partitioned operation, including Tran-sis [9] and Relacs <ref> [3] </ref>. The rest of this paper is organized as follows: Section 2 discusses related work. Section 3 presents basic definitions and concepts. Section 4 describes how primary views are used to create a replicated state machine semantics in partitionable networks, and presents the protocol that we developed for this.
Reference: [4] <author> P. Bernstein, V. Hadzilacos, and H. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1987. </year>
Reference-contexts: Optimistic implementations, e.g., [5, 14], tend to deliver messages fast, yielding good performance, although the local state of individual replicas may become invalid under certain failure scenarios as a result of delivering messages that never become authoritative. On the other hand, pessimistic implementations, e.g., <ref> [2, 4, 12] </ref>, deliver messages only when it is safe to do so, thereby avoiding the risk of having to invalidate the state of a replica. This is achieved at the cost of additional communication rounds. <p> This is achieved at the cost of additional communication rounds. Many existing implementations of replicated state machines ignore the issue of network partitions [6, 17]. Other implementations either have a limited support for partitions, but might block forever even after all partitions have been reconciled <ref> [4, 5] </ref>, or are pessimistic [2, 12, 16]. A proper handling of partitions is vital for applications targeted for large scale or wide-area environments where partitions are common. However, the high communication cost associated with pessimistic approaches may be prohibitive for many applications.
Reference: [5] <author> K. Birman and T. Joseph. </author> <title> Reliable Communication in the Presence of Failures. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(1) </volume> <pages> 47-76, </pages> <month> February </month> <year> 1987. </year>
Reference-contexts: This research was supported by by ARPA/ONR grant N00014-96-1-1014 1 This is similar to the serializability requirement in databases and the sequential consistency requirement in distributed shared memories. whether they are optimistic or pessimistic. Optimistic implementations, e.g., <ref> [5, 14] </ref>, tend to deliver messages fast, yielding good performance, although the local state of individual replicas may become invalid under certain failure scenarios as a result of delivering messages that never become authoritative. <p> This is achieved at the cost of additional communication rounds. Many existing implementations of replicated state machines ignore the issue of network partitions [6, 17]. Other implementations either have a limited support for partitions, but might block forever even after all partitions have been reconciled <ref> [4, 5] </ref>, or are pessimistic [2, 12, 16]. A proper handling of partitions is vital for applications targeted for large scale or wide-area environments where partitions are common. However, the high communication cost associated with pessimistic approaches may be prohibitive for many applications.
Reference: [6] <author> T. Bressoud and F. Schneider. </author> <title> Hypervisor-base Fault Tolerance. </title> <booktitle> In Proc. of the 15th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 1-11, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: This is achieved at the cost of additional communication rounds. Many existing implementations of replicated state machines ignore the issue of network partitions <ref> [6, 17] </ref>. Other implementations either have a limited support for partitions, but might block forever even after all partitions have been reconciled [4, 5], or are pessimistic [2, 12, 16]. A proper handling of partitions is vital for applications targeted for large scale or wide-area environments where partitions are common.
Reference: [7] <author> T. Chandra, V. Hadzilacos, S. Toueg, and B. Charron-Bost. </author> <title> On the Impossibility of Group Membership. </title> <booktitle> In Proc. of the 15th ACM Symposium of Principles of Distributed Computing, </booktitle> <pages> pages 322-330, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: During state trans-fer, the partition with an older state adopts the state of the more up-to-date partition. The primary partition is always guaranteed to be the one with the most up-to-date state. Note that as indicated in <ref> [7] </ref>, we cannot guarantee that a primary partition will exist at all times, because link failures or communication delays are possible.
Reference: [8] <author> F. Cristian. </author> <title> Understanding Fault-Tolerant Distributed Systems. </title> <journal> Communications of the ACM, </journal> <volume> 34(2) </volume> <pages> 56-78, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: We follow a standard quorum-based dynamic replication paradigm <ref> [8] </ref> requiring a message to be delivered by a majority of group members in order to become authoritative. However, the optimistic implementation we present uses one phase communication for delivering messages, which yields good performance.
Reference: [9] <author> D. Dolev and D. Malki. </author> <title> The Transis Approach to High Availability Cluster Communication. </title> <journal> Communications of the ACM, </journal> <volume> 39(4) </volume> <pages> 64-70, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: However, the proposed approach can easily be applied to any group communication system that supports partitioned operation, including Tran-sis <ref> [9] </ref> and Relacs [3]. The rest of this paper is organized as follows: Section 2 discusses related work. Section 3 presents basic definitions and concepts.
Reference: [10] <author> R. Friedman and R. van Renesse. </author> <title> Strong and Weak Virtual Synchrony in Horus. </title> <booktitle> In Proc. of the 15th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 140-149, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: It is designed to reside on top of a system which provides totally ordered broadcast in a partitionable virtually synchronous environment <ref> [10, 15] </ref>, and below the application level. (See illustration in Figure 1.) In the specific example of Horus, totally ordered broadcast is implemented as a separate layer on top of the partitionable virtual synchrony layer.
Reference: [11] <author> R. Friedman and R. van Renesse. </author> <title> Packing Messages as a Tool for Boosting the Performance of Total Ordering Protocols. </title> <booktitle> In Proc. of the Sixth IEEE International Symposium on High Performance Distributed Computing, </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: The DYNSEQ layer implements the dynamic sequencer protocol, while the TOKEN layer is based on the rotating token protocol <ref> [11] </ref>. group size, while Figure 6 shows the measured throughput per member. Finally, the aggregate throughput for the whole group is shown in Figure 7.
Reference: [12] <author> I. Keidar. </author> <title> A Highly Available Paradigm for Consistent Object Replication. </title> <type> Master's thesis, </type> <institution> Institute of Computer Science, the Hebrew University of Jerusalem, </institution> <year> 1994. </year>
Reference-contexts: Optimistic implementations, e.g., [5, 14], tend to deliver messages fast, yielding good performance, although the local state of individual replicas may become invalid under certain failure scenarios as a result of delivering messages that never become authoritative. On the other hand, pessimistic implementations, e.g., <ref> [2, 4, 12] </ref>, deliver messages only when it is safe to do so, thereby avoiding the risk of having to invalidate the state of a replica. This is achieved at the cost of additional communication rounds. <p> Many existing implementations of replicated state machines ignore the issue of network partitions [6, 17]. Other implementations either have a limited support for partitions, but might block forever even after all partitions have been reconciled [4, 5], or are pessimistic <ref> [2, 12, 16] </ref>. A proper handling of partitions is vital for applications targeted for large scale or wide-area environments where partitions are common. However, the high communication cost associated with pessimistic approaches may be prohibitive for many applications. <p> Performance analysis is presented in Section 6. We conclude with a discussion in Section 7. 2 Related Work Pessimistic implementations of global total ordering that can tolerate network partitions have been proposed in <ref> [1, 2, 12, 16] </ref>. Being pessimistic, they require more communication rounds to perform an operation. 2 Also, these solutions require all messages to be logged on stable storage, which adds a substantial overhead. <p> crash simultaneously, whereas the implementation 2 Note that [2] claims to deliver messages as soon as they arrive from the transport layer, without end-to-end acknowledgments, but it assumes that the transport layer provides total safe (uniform) delivery, which requires at least 2 communication rounds at the transport level. in Transis <ref> [12] </ref> can sustain any number of crashes (assuming that failed processes are eventually restarted). Also, the protocols in [12] can make progress even if a majority view can never be formed due to link failures, which makes that approach suitable for WAN environments with very low quality of communication. <p> from the transport layer, without end-to-end acknowledgments, but it assumes that the transport layer provides total safe (uniform) delivery, which requires at least 2 communication rounds at the transport level. in Transis <ref> [12] </ref> can sustain any number of crashes (assuming that failed processes are eventually restarted). Also, the protocols in [12] can make progress even if a majority view can never be formed due to link failures, which makes that approach suitable for WAN environments with very low quality of communication. However, many important distributed applications (such as replicated databases) have rather demanding performance requirements that render message logging impractical.
Reference: [13] <author> L. Lamport. </author> <title> Time, Clocks and the Ordering of Event in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <year> 1978. </year>
Reference-contexts: A common requirement from a replicated system is that actions of all replicas be indistinguishable from those of a single fault-tolerant process. 1 The replicated state machine approach was suggested in <ref> [13, 18] </ref> as a way to provide such a consistent behavior: With this approach, all replicas run identical state machines, and all communication in the system is performed via totally ordered broadcasts. <p> The system consists of a group of application processes, each running a deterministic state machine <ref> [13] </ref>, and communicating by sending messages to each other. An application process' state machine is specified by a set of its internal configurations, or states, and a set of transitions between states. Each application process in the group runs the same state machine, starting in the same initial state.
Reference: [14] <author> C. Malloth, P. Felber, A. Schiper, and U. Wilhelm. </author> <title> Phoenix: A Tollkit for Building Fault-Tolerant Distributed Application in Large Scale. </title> <type> Technical report, </type> <institution> Department d'Informatique, Ecole Polytechnique Federale de Lausanne, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: This research was supported by by ARPA/ONR grant N00014-96-1-1014 1 This is similar to the serializability requirement in databases and the sequential consistency requirement in distributed shared memories. whether they are optimistic or pessimistic. Optimistic implementations, e.g., <ref> [5, 14] </ref>, tend to deliver messages fast, yielding good performance, although the local state of individual replicas may become invalid under certain failure scenarios as a result of delivering messages that never become authoritative.
Reference: [15] <author> L. E. Moser, Y. Amir, P. M. Melliar-Smith, and D. A. Agarwal. </author> <title> Extended Virtual Synchrony. </title> <booktitle> In Proc. of the 14 International Conference on distributed Computing Systems, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: It is designed to reside on top of a system which provides totally ordered broadcast in a partitionable virtually synchronous environment <ref> [10, 15] </ref>, and below the application level. (See illustration in Figure 1.) In the specific example of Horus, totally ordered broadcast is implemented as a separate layer on top of the partitionable virtual synchrony layer.
Reference: [16] <author> L. E. Moser, P. M. Melliar-Smith, and V. Agrawala. </author> <title> Asynchronous Fault-Tolerant Total Ordering Algorithm. </title> <journal> SIAM Journal of Computing, </journal> <volume> 22(4) </volume> <pages> 727-750, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Many existing implementations of replicated state machines ignore the issue of network partitions [6, 17]. Other implementations either have a limited support for partitions, but might block forever even after all partitions have been reconciled [4, 5], or are pessimistic <ref> [2, 12, 16] </ref>. A proper handling of partitions is vital for applications targeted for large scale or wide-area environments where partitions are common. However, the high communication cost associated with pessimistic approaches may be prohibitive for many applications. <p> Performance analysis is presented in Section 6. We conclude with a discussion in Section 7. 2 Related Work Pessimistic implementations of global total ordering that can tolerate network partitions have been proposed in <ref> [1, 2, 12, 16] </ref>. Being pessimistic, they require more communication rounds to perform an operation. 2 Also, these solutions require all messages to be logged on stable storage, which adds a substantial overhead.
Reference: [17] <author> F. Schneider. </author> <title> Paradigms for Distributed Programs. </title> <booktitle> In Distributed Systems Methods and Tools for Specification, </booktitle> <pages> pages 343-430. </pages> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Vol. 190, </volume> <publisher> Springer-Verlag, </publisher> <address> New-York, NY, </address> <year> 1985. </year>
Reference-contexts: This is achieved at the cost of additional communication rounds. Many existing implementations of replicated state machines ignore the issue of network partitions <ref> [6, 17] </ref>. Other implementations either have a limited support for partitions, but might block forever even after all partitions have been reconciled [4, 5], or are pessimistic [2, 12, 16]. A proper handling of partitions is vital for applications targeted for large scale or wide-area environments where partitions are common.
Reference: [18] <author> Fred B. Schneider. </author> <title> The state machine approach: a tutorial. </title> <type> Technical Report TR 86-800, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> December </month> <year> 1986. </year> <note> Revised June 1987. </note>
Reference-contexts: A common requirement from a replicated system is that actions of all replicas be indistinguishable from those of a single fault-tolerant process. 1 The replicated state machine approach was suggested in <ref> [13, 18] </ref> as a way to provide such a consistent behavior: With this approach, all replicas run identical state machines, and all communication in the system is performed via totally ordered broadcasts.
Reference: [19] <author> R. van Renesse, K. Birman, and S. Maffeis. Horus: </author> <title> A flexible Group Communication System. </title> <journal> Communications of the ACM, </journal> <volume> 39(4) </volume> <pages> 76-83, </pages> <month> April </month> <year> 1996. </year> <month> 8 </month>
Reference-contexts: However, the optimistic implementation we present uses one phase communication for delivering messages, which yields good performance. Finally, in order to keep the discussion in this paper focused, our solution is implemented in Horus <ref> [19] </ref>, and therefore our discussion sometimes deals with specific details of the Horus implementation. However, the proposed approach can easily be applied to any group communication system that supports partitioned operation, including Tran-sis [9] and Relacs [3]. <p> Thus, any two application processes that have delivered the same sequence of messages will be in the same state. 3.2 System Architecture Our implementation assumes a layered architecture, such as the one presented by Horus <ref> [19] </ref>. <p> A pseudocode description of the global-safety protocol appears in the full version of this paper. 6 Performance Analysis The protocol layers discussed in this paper have been implemented in the Horus system developed at Cornell <ref> [19] </ref>. Recall that Horus supports a layered architecture in which simple protocols are stacked on top of each other to obtain the desired functionality, as illustrated in Figure 1.
References-found: 19

