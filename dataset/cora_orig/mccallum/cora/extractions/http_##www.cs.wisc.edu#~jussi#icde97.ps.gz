URL: http://www.cs.wisc.edu/~jussi/icde97.ps.gz
Refering-URL: http://www.cs.wisc.edu/~jussi/jussi.html
Root-URL: 
Email: fjussi,mirong@cs.wisc.edu  
Title: Relational Joins for Data on Tertiary Storage  
Author: Jussi Myllymaki Miron Livny 
Address: Madison, WI 53706, USA  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: Despite the steady decrease in secondary storage prices, the data storage requirements of many organizations cannot be met economically using secondary storage alone. Tertiary storage offers a lower-cost alternative but is viewed as a second-class citizen in many systems. For instance, the typical solution in bringing tertiary-resident data under the control of a DBMS is to use operating system facilities to copy the data to secondary storage, and then to perform query optimization and execution as if the data had been in secondary storage all along. This approach fails to recognize the opportunities for saving execution time and storage space if the data were accessed directly on tertiary devices and in parallel with other I/Os. In this paper we explore how to join two DBMS relations stored on magnetic tapes. Both relations are assumed to be larger than available disk space. We show how Grace Hash Join can be modified to handle a range of tape relation sizes. The modified algorithms access data directly on tapes and exploit parallelism between disk and tape I/Os. We also provide performance results of an experimental implementation of the algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Blasgen and K. Eswaran. </author> <title> Storage and access in relational data bases. </title> <journal> IBM Systems Journal, </journal> <volume> 16(4) </volume> <pages> 363-377, </pages> <year> 1977. </year>
Reference-contexts: Joining two relations is one of the most common operations in a relational DBMS and one of the most costly if done naively. The database literature contains an extensive collection of work on optimizing joins, started by the seminal paper by Blasgen and Eswaran <ref> [1] </ref>. Most studies consider main memory and secondary storage as the only forms of storage, but few studies include tertiary storage in the system model. <p> Most studies consider main memory and secondary storage as the only forms of storage, but few studies include tertiary storage in the system model. Studies on disk-based joins typically employ a transfer-only cost model <ref> [4, 16, 2, 1, 9] </ref> where the number of pages transferred is the cost metric while the latency penalty of small I/O requests is disregarded. The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in [6]. <p> Therefore, the total cost of the join (response time) is roughly the same as I/O cost, like in most other cost models for joins. Join method analyses typically do not consider query output costs since they are deemed the same for all methods <ref> [1, 4, 16, 7, 6] </ref>. In our study, however, it seems necessary to include the output costs in the cost model because the input cost may be affected by the output cost.
Reference: [2] <author> K. Bratbergsengen. </author> <title> Hashing methods and relational algebra operations. </title> <booktitle> In Proc. Conf. Very Large Databases, </booktitle> <pages> pages 323-333, </pages> <address> Singapore, </address> <month> Aug. </month> <year> 1984. </year>
Reference-contexts: Most studies consider main memory and secondary storage as the only forms of storage, but few studies include tertiary storage in the system model. Studies on disk-based joins typically employ a transfer-only cost model <ref> [4, 16, 2, 1, 9] </ref> where the number of pages transferred is the cost metric while the latency penalty of small I/O requests is disregarded. The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in [6].
Reference: [3] <author> M. J. Carey, L. M. Haas, and M. Livny. </author> <title> Tapes hold data too: Challenges of tuples on tertiary store. </title> <booktitle> In Proc. ACM SIG-MOD, </booktitle> <pages> pages 413-417, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Only the most frequently used data is stored in secondary storage, for instance, meta-data, indices, small datasets, or subsets of larger datasets. Database management systems (DBMS) are typically not capable of operating on tertiary-resident data in the same manner as they handle secondary storage <ref> [3] </ref>. One reason is the wide variety and dissimilarity of tertiary storage devices, another is the difference in how tertiary storage and secondary storage are accessed at the device level. Magnetic tape storage, for instance, is inherently sequential with slow random-access capabilities. <p> The results of the experiments are described and analyzed in Sections 7 through 9. Section 10 concludes the paper. 2 Related Work Our investigation of database joins on tertiary storage was prompted by a SIGMOD Database Challenges paper <ref> [3] </ref> which pointed out that DBMS control of tertiary storage was becoming ever more important because of the large volumes of tertiary-resident data that are available for analysis and manipulation.
Reference: [4] <author> D. J. DeWitt, R. H. Katz, F. Olken, L. D. Shapiro, M. R. Stonebraker, and D. Wood. </author> <title> Implementation techniques for main memory database systems. </title> <booktitle> In Proc. ACM SIGMOD, </booktitle> <pages> pages 1-8, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: To join relations much larger than main memory or disk space, one has to employ hashing techniques. In this paper we present modifications to Grace Hash Join <ref> [4] </ref> to make it work on tape storage and to exploit parallel I/O and double-buffering techniques described in [12]. We describe and evaluate both disk-tape and tape-tape join methods based on Grace Hash Join. <p> Most studies consider main memory and secondary storage as the only forms of storage, but few studies include tertiary storage in the system model. Studies on disk-based joins typically employ a transfer-only cost model <ref> [4, 16, 2, 1, 9] </ref> where the number of pages transferred is the cost metric while the latency penalty of small I/O requests is disregarded. The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in [6]. <p> Therefore, the total cost of the join (response time) is roughly the same as I/O cost, like in most other cost models for joins. Join method analyses typically do not consider query output costs since they are deemed the same for all methods <ref> [1, 4, 16, 7, 6] </ref>. In our study, however, it seems necessary to include the output costs in the cost model because the input cost may be affected by the output cost. <p> Each R hash bucket is read back into memory in turn and joined with the corresponding S hash bucket by scanning it. Step II is iterated until S is exhausted. The number of hash buckets is B = jRj M where M &gt; p jRj (see <ref> [4] </ref>). We assume that hash values are uniformly distributed, that is, the hash buckets for R are equal-sized.
Reference: [5] <author> S. Ghandeharizadeh, A. Dashti, and C. Shahabi. </author> <title> Pipelin-ing mechanism to minimize the latency time in hierarchical multimedia storage managers. </title> <journal> Computer Communications, </journal> <volume> 18(3) </volume> <pages> 170-184, </pages> <month> Mar. </month> <year> 1995. </year> <note> Also available as Technical Report 94-584, </note> <institution> Computer Science Department, University of Southern California. </institution>
Reference-contexts: While multimedia systems such as video-on-demand servers have successfully integrated tertiary storage into their storage hierarchies <ref> [8, 5] </ref>, relational database systems still have little notion of incorporating tertiary storage as an integral part of the system. Joining two relations is one of the most common operations in a relational DBMS and one of the most costly if done naively.
Reference: [6] <author> L. M. Haas, M. J. Carey, and M. Livny. </author> <title> SEEKing the truth about ad hoc join costs. </title> <type> Technical Report 1148, </type> <institution> Department of Computer Science, University of Wisconsin at Madison, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in <ref> [6] </ref>. The optimization and execution of queries on tertiary-resident data in the Postgres database system is described in [14, 15]. In that architecture, a query on large tertiary relations is broken into smaller, independent subqueries on fragments of the relations. <p> Therefore, the total cost of the join (response time) is roughly the same as I/O cost, like in most other cost models for joins. Join method analyses typically do not consider query output costs since they are deemed the same for all methods <ref> [1, 4, 16, 7, 6] </ref>. In our study, however, it seems necessary to include the output costs in the cost model because the input cost may be affected by the output cost. <p> We assume that all disk accesses are multi-page I/O requests. The cost of a disk access is therefore derived by counting the number of blocks transferred. The seek cost and rotational latency are ignored. As shown in <ref> [6] </ref>, disk seeks and rotational latency play a relatively minor role compared to transfer cost when disk requests are at least moderately large. In our model, the size of all disk requests is assumed to be at least 30 blocks, making seek and latency costs negligible 1 .
Reference: [7] <author> R. B. Hagmann. </author> <title> An observation on database buffering performance metrics. </title> <booktitle> In Proc. Conf. Very Large Databases, </booktitle> <pages> pages 289-293, </pages> <address> Kyoto, Japan, </address> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: Studies on disk-based joins typically employ a transfer-only cost model [4, 16, 2, 1, 9] where the number of pages transferred is the cost metric while the latency penalty of small I/O requests is disregarded. The number of multi-page I/O requests was the cost metric in <ref> [7] </ref>, and a detailed cost model combining both cost models was developed in [6]. The optimization and execution of queries on tertiary-resident data in the Postgres database system is described in [14, 15]. <p> Therefore, the total cost of the join (response time) is roughly the same as I/O cost, like in most other cost models for joins. Join method analyses typically do not consider query output costs since they are deemed the same for all methods <ref> [1, 4, 16, 7, 6] </ref>. In our study, however, it seems necessary to include the output costs in the cost model because the input cost may be affected by the output cost.
Reference: [8] <author> M. G. Kienzle, A. Dan, D. Sitaram, and W. Tetzlaff. </author> <title> Using tertiary storage in video-on-demand servers. </title> <booktitle> In Proc. Com-pCon, </booktitle> <pages> pages 225-233, </pages> <address> San Francisco, CA, </address> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: While multimedia systems such as video-on-demand servers have successfully integrated tertiary storage into their storage hierarchies <ref> [8, 5] </ref>, relational database systems still have little notion of incorporating tertiary storage as an integral part of the system. Joining two relations is one of the most common operations in a relational DBMS and one of the most costly if done naively.
Reference: [9] <author> W. Kim. </author> <title> A new way to compute the product and join of relation. </title> <booktitle> In Proc. ACM SIGMOD, </booktitle> <pages> pages 179-187, </pages> <address> Santa Monica, CA, </address> <month> May </month> <year> 1980. </year>
Reference-contexts: In our earlier work [11], we have examined the case where one relation is stored on tape and the other on disk. Using an analytical model, we have shown that a parallel I/O variant of Nested Block Join <ref> [9] </ref> performs very well when at least half the smaller relation fits in main memory but very poorly when little main memory is available. To join relations much larger than main memory or disk space, one has to employ hashing techniques. <p> Most studies consider main memory and secondary storage as the only forms of storage, but few studies include tertiary storage in the system model. Studies on disk-based joins typically employ a transfer-only cost model <ref> [4, 16, 2, 1, 9] </ref> where the number of pages transferred is the cost metric while the latency penalty of small I/O requests is disregarded. The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in [6].
Reference: [10] <author> D. Knuth. </author> <title> The Art of Computer Programming, Vol. III: Sorting and Searching. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Redwood City, CA, </address> <year> 1973. </year>
Reference-contexts: On a historical note, Knuth also assumes bi-directional tape drives in his work on tape sorting <ref> [10] </ref>. S i half the original size. This in turn doubles the number of iterations needed and doubles the number of times R is scanned. Furthermore, the average utilization of available buffer space is only 50% assuming that the writer and reader processes operate at equal speeds.
Reference: [11] <author> J. Myllymaki and M. Livny. </author> <title> Disk-tape joins: Synchronizing disk and tape access. </title> <booktitle> In Proc. ACM SIGMETRICS, </booktitle> <pages> pages 279-290, </pages> <address> Ottawa, Canada, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: We focus on ways to join two relations stored on magnetic tapes, examining both methods that require the smaller relation to fit on disk (disk-tape joins) and methods that do not have this restriction (tape-tape joins). In our earlier work <ref> [11] </ref>, we have examined the case where one relation is stored on tape and the other on disk. <p> We describe and evaluate both disk-tape and tape-tape join methods based on Grace Hash Join. We also review algorithms developed in <ref> [11] </ref> and apply them in the context of two tape relations. For all tertiary join methods examined, we show what the resource requirements are and analyze the performance via an experimental implementation. This paper is organized as follows. <p> In our earlier work, we have reported on ways to join a tape relation with a disk relation when direct access to tertiary storage by the join methods is made possible <ref> [11] </ref>. The results indicated that significant savings in execution time and buffer space (both main memory and disk space) can be achieved by customizing existing relational join algorithms in two ways. <p> Main memory size and the speed ratio between the disk and tape devices were identified as the key components determining the performance of a join of a disk and tape relation. The buffering techniques discussed in <ref> [11] </ref> were applied in a more general context, extensible to data mining and data visualization applications, in [12]. The paper also provided an analysis of how the performance characteristics and interaction of main memory, process scheduling, I/O bus and storage devices affect parallel I/O throughput. <p> These two conditions guarantee that each R hash bucket fits into memory when read back from disk. 5.1.3 Concurrent Disk-Tape Nested Block Join Concurrent Disk-Tape Nested Block Join (CDT-NB) is a parallel I/O variant of DT-NB and was first described in <ref> [11] </ref>. As in DT-NB, relation R is first copied from tape to disk. CDT-NB performs the join by reading a chunk of S into a main memory or disk buffer and joining the previous chunk simultaneously with R. This method has two variations. <p> The aggregate disk speed was assumed to be twice the tape speed (X D = 2X T ). The response times were calculated using cost formulas derived for each join method. The derivation and the resulting formulas are based on <ref> [11] </ref> but are beyond the scope of this paper. In Figures 1 through 3 we examine three interesting ranges of jRj. Figure 1 shows the case where jRj is comparable to M (M appears at value 1). <p> We have presented modifications to Grace Hash Join to make it operate on tape-resident relations, and also reviewed Nested Block Join-based methods developed in our earlier work <ref> [11] </ref>. An experimental implementation and performance analysis with relation sizes ranging up to 10,000 MB allowed us to validate the strengths and weaknesses of these methods.
Reference: [12] <author> J. Myllymaki and M. Livny. </author> <title> Efficient buffering for concurrent disk and tape I/O. </title> <booktitle> In Proc. Performance '96, </booktitle> <pages> pages 453-471, </pages> <address> Lausanne, Switzerland, </address> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: To join relations much larger than main memory or disk space, one has to employ hashing techniques. In this paper we present modifications to Grace Hash Join [4] to make it work on tape storage and to exploit parallel I/O and double-buffering techniques described in <ref> [12] </ref>. We describe and evaluate both disk-tape and tape-tape join methods based on Grace Hash Join. We also review algorithms developed in [11] and apply them in the context of two tape relations. <p> The buffering techniques discussed in [11] were applied in a more general context, extensible to data mining and data visualization applications, in <ref> [12] </ref>. The paper also provided an analysis of how the performance characteristics and interaction of main memory, process scheduling, I/O bus and storage devices affect parallel I/O throughput. In our current studies we focus on joins between two tertiary-resident relations. <p> One particular technique join methods can use is double-buffering, in which a reader process reads S i from one memory or disk buffer and joins it with R while a writer process fetches S i+1 from tape and stores it in another buffer <ref> [12] </ref>.
Reference: [13] <author> J. Myllymaki and M. Livny. </author> <title> Relational joins for data on tertiary storage. </title> <type> Technical Report 1331, </type> <institution> Department of Computer Science, University of Wisconsin at Madison, </institution> <month> Jan. </month> <year> 1997. </year>
Reference-contexts: A 30% overhead, for instance, means that a join takes 30% longer than simply reading S from tape would take. Note that the join overhead measure normalizes the response time and expresses the performance of a join method for tape relations of arbitrary size. Also, as discussed in <ref> [13] </ref>, the metric is useful because it would allow us to compare results of experiments conducted with different tape technologies (different tape speeds) more easily. We begin the analysis by comparing the join methods' requirements for disk space and the total amount of disk traffic.
Reference: [14] <author> S. Sarawagi. </author> <title> Database systems for efficient access to tertiary memory. </title> <booktitle> In Proc. IEEE Symposium on Mass Storage Systems, </booktitle> <pages> pages 120-126, </pages> <address> Monterey, CA, </address> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in [6]. The optimization and execution of queries on tertiary-resident data in the Postgres database system is described in <ref> [14, 15] </ref>. In that architecture, a query on large tertiary relations is broken into smaller, independent subqueries on fragments of the relations. The system caches fragments in secondary storage and improves tape access efficiency by reordering the I/O requests resulting from the subqueries.
Reference: [15] <author> S. Sarawagi. </author> <title> Query processing in tertiary memory databases. </title> <booktitle> In Proc. Conf. Very Large Databases, </booktitle> <address> Zurich, Switzerland, </address> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in [6]. The optimization and execution of queries on tertiary-resident data in the Postgres database system is described in <ref> [14, 15] </ref>. In that architecture, a query on large tertiary relations is broken into smaller, independent subqueries on fragments of the relations. The system caches fragments in secondary storage and improves tape access efficiency by reordering the I/O requests resulting from the subqueries. <p> Our goal is to show how disk and main memory space affect the performance of these joins, and demonstrate how parallel I/O helps them save execution time as well as memory and disk space. The distinction between our line of work and that presented in <ref> [15] </ref> is that our join algorithms access data directly on tertiary devices, using available disk space both as a speed-matching buffer and as a cache. Our performance results are from an experimental implementation rather than a simulation. Whereas [15] considers different types of queries, our focus is on joins without indices. <p> The distinction between our line of work and that presented in <ref> [15] </ref> is that our join algorithms access data directly on tertiary devices, using available disk space both as a speed-matching buffer and as a cache. Our performance results are from an experimental implementation rather than a simulation. Whereas [15] considers different types of queries, our focus is on joins without indices. 3 System Model for Tertiary Joins 3.1 System Configuration and Notation The task of a tertiary join method is to compute the join of two tape relations R and S.
Reference: [16] <author> L. Shapiro. </author> <title> Join processing in database systems with large main memories. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(3) </volume> <pages> 239-264, </pages> <month> Sept. </month> <year> 1986. </year>
Reference-contexts: Most studies consider main memory and secondary storage as the only forms of storage, but few studies include tertiary storage in the system model. Studies on disk-based joins typically employ a transfer-only cost model <ref> [4, 16, 2, 1, 9] </ref> where the number of pages transferred is the cost metric while the latency penalty of small I/O requests is disregarded. The number of multi-page I/O requests was the cost metric in [7], and a detailed cost model combining both cost models was developed in [6]. <p> Therefore, the total cost of the join (response time) is roughly the same as I/O cost, like in most other cost models for joins. Join method analyses typically do not consider query output costs since they are deemed the same for all methods <ref> [1, 4, 16, 7, 6] </ref>. In our study, however, it seems necessary to include the output costs in the cost model because the input cost may be affected by the output cost.
Reference: [17] <author> J.-B. Yu and D. J. DeWitt. </author> <title> Query pre-execution and batch-ing in Paradise: A two-pronged approach to the efficient processing of queries on tape-resident data sets. </title> <note> Document available at http://www.cs.wisc.edu/ jiebing/tape.ps. </note>
Reference-contexts: The system caches fragments in secondary storage and improves tape access efficiency by reordering the I/O requests resulting from the subqueries. A similar reordering of tape I/O requests is performed by the tertiary storage interface of the Paradise database system <ref> [17] </ref>. The system pre-executes queries, collects and reorders the tape I/O references, and then re-executes the queries. As in the Postgres system, the ordering and batching of tape I/O requests yields improved tape data transfer efficiency.
References-found: 17

