URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-836/CS-TR-89-836.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-89-836/
Root-URL: http://www.cs.wisc.edu
Title: A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment  
Author: Donovan A. Schneider David J. DeWitt 
Note: This research was partially supported by the Defense Advanced Research Projects Agency under contract N00039-86-C-0578, by the National Science Foundation under grants DCR-8512862, MCS82-01870, and MCS81-05904, and by a Digital Equipment Corporation External Research Grant.  
Address: Wisconsin  
Affiliation: Computer Sciences Department University of  
Abstract-found: 0
Intro-found: 1
Reference: [BABB79] <author> Babb, E., </author> <title> Implementing a Relational Database by Means of Specialized Hardware ACM Transactions on Database Systems, </title> <journal> Vol. </journal> <volume> 4, No. 1, </volume> <month> March, </month> <year> 1979. </year>
Reference-contexts: We also considered how effectively the different join algorithms could utilize processors without disks. Finally, bit vector filtering techniques <ref> [BABB79, VALD84] </ref> were evaluated for each of the parallel join algorithms. hhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 This set of experiments can also be viewed as predicting the relative performance of the various algorithms when the size of memory is constant and the algorithms are required to process relations larger than the the size of <p> If the result of a query is a new relation, the operators at the root of the query tree distribute the result tuples on a round-robin basis to store operators at each disk site. To enhance the performance of certain operations, an array of bit vector filters <ref> [BABB79, VALD84] </ref> is inserted into the split table. In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation [BRAT84, DEWI84, DEWI85, VALD84]. <p> Obviously these results demonstrate that a tradeoff exists between being pessimistic and increasing the number of buckets and being optimistic and counting on Simple hash-join to resolve any memory overflow. 4.2. Multiprocessor Bit Vector Filtering In the next set of experiments we ran the joinABprime tests using bit filters <ref> [BABB79, VALD84] </ref>. In each of the parallel join algorithms, bit filtering of tuples is only applied during the joining phase. With sort-merge joins, a bit filter is built at each disk site as the inner (smaller) relation is partitioned across the network and stored in temporary files.
Reference: [BARU87] <author> Baru, C., O. Frieder, D. Kandlur, and M. Segal, </author> <title> Join on a Cube: Analysis, Simulation, and Implementation, Database Machines and Knowledge Base Machines, </title> <editor> M. Kitsuregawa and H. Tanaka (eds), </editor> <publisher> Kluwer Academic Publishers, </publisher> <year> 1987. </year>
Reference-contexts: Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. In fact, several researchers, including <ref> [BARU87, BRAT87, DEWI87, DEWI88, KITS88] </ref>, have presented performance timings for a variety of distributed join algorithms. However, the more popular parallel join algorithms have never been compared in a common hardware/software environment.
Reference: [BITT83] <author> Bitton, D., D.J. DeWitt, and C. Turbyfill, </author> <title> Benchmarking Database Systems A Systematic Approach, </title> <booktitle> Proceedings of the 1983 Very Large Database Conference, </booktitle> <month> October, </month> <year> 1983. </year>
Reference-contexts: Third, the use of diskless processors by each of the hash-based algorithms is explored. Finally, the impact on non-uniformily distributed join attribute values on the performance of each of the algorithms is studied. The benchmark relations are based on the standard Wisconsin Benchmark <ref> [BITT83] </ref>. Each relation consists of thirteen 4-byte integer values and three 52-byte string attributes. Thus, each tuple is 208 bytes long. Except where noted otherwise, hashing on the unique1 attribute was used to determine each tuple's destination site during loading of the database.
Reference: [BORA88] <author> Boral, H. </author> <title> Parallelism in Bubba, </title> <booktitle> Proceddings of the International Symposium on Databases in Parallel and Distributed Systems, </booktitle> <address> Austin, Texas, </address> <month> December, </month> <year> 1988. </year>
Reference-contexts: We feel that Gamma is a good choice for the experimental vehicle because it incorporates a shared-nothing architecture with commercially available components. This basic design is becoming increasingly popular, both in research, for example, Bubba at MCC <ref> [COPE88, BORA88] </ref> and in the commercial arena, with products from Tera-data [TERA83] and Tandem [TAND88]. The experiments were designed to test the performance of each of the join algorithms under several different conditions.
Reference: [BRAT84] <author> Bratbergsengen, Kjell, </author> <title> Hashing Methods and Relational Algebra Operations Proceedings of the 1984 Very Large Database Conference, </title> <month> August, </month> <year> 1984. </year>
Reference-contexts: 1. Introduction During the last 10 years, a significant amount of effort has been focused on developing efficient join algorithms. Initially, nested loops and sort-merge were the algorithms of choice. However, work by <ref> [KITS83, BRAT84, DEWI84] </ref> demonstrated the potential of hash-based join methods. Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. <p> In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI84, DEWI85, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of July 10, 1992 4 the join.
Reference: [BRAT87] <author> Bratbergsengen, Kjell, </author> <title> Algebra Operations on a Parallel Computer -- Performance Evaluation, Database Machines and Knowledge Base Machines, </title> <editor> M. Kitsuregawa and H. Tanaka (eds), </editor> <publisher> Kluwer Academic Publishers, </publisher> <year> 1987. </year>
Reference-contexts: Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. In fact, several researchers, including <ref> [BARU87, BRAT87, DEWI87, DEWI88, KITS88] </ref>, have presented performance timings for a variety of distributed join algorithms. However, the more popular parallel join algorithms have never been compared in a common hardware/software environment.
Reference: [CHOU85] <author> Chou, H-T, DeWitt, D. J., Katz, R., and T. Klug, </author> <title> Design and Implementation of the Wisconsin Storage System (WiSS) Software Practices and Experience, </title> <journal> Vol. </journal> <volume> 15, No. 10, </volume> <month> October, </month> <year> 1985. </year>
Reference-contexts: Messages between two processes on the same processor are short-circuited by the communications software. File services in Gamma are based on the Wisconsin Storage System (WiSS) <ref> [CHOU85] </ref>. These services include structured sequential files, B + indices, byte-stream files as in UNIX, long data items, a sort utility, and a scan mechanism. 3. Parallel Join Algorithms We implemented parallel versions of four join algorithms: sort-merge, Grace [KITS83], Simple hash [DEWI84], and Hybrid hash-join [DEWI84].
Reference: [COPE88] <author> Copeland, G., W. Alexander, E. Boughter, and T. Keller, </author> <title> "Data Placement in Bubba", </title> <booktitle> Proceedings of the 1988 SIGMOD Conference, </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: We feel that Gamma is a good choice for the experimental vehicle because it incorporates a shared-nothing architecture with commercially available components. This basic design is becoming increasingly popular, both in research, for example, Bubba at MCC <ref> [COPE88, BORA88] </ref> and in the commercial arena, with products from Tera-data [TERA83] and Tandem [TAND88]. The experiments were designed to test the performance of each of the join algorithms under several different conditions.
Reference: [DEWI84] <author> DeWitt, D. J., Katz, R., Olken, F., Shapiro, D., Stonebraker, M. and D. Wood, </author> <title> Implementation Techniques for Main Memory Database Systems, </title> <booktitle> Proceedings of the 1984 SIGMOD Conference, </booktitle> <address> Boston, MA, </address> <month> June, </month> <year> 1984. </year>
Reference-contexts: 1. Introduction During the last 10 years, a significant amount of effort has been focused on developing efficient join algorithms. Initially, nested loops and sort-merge were the algorithms of choice. However, work by <ref> [KITS83, BRAT84, DEWI84] </ref> demonstrated the potential of hash-based join methods. Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. <p> However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. In this paper we present a performance evaluation of parallel versions of the sort-merge, Grace [KITS83], Simple <ref> [DEWI84] </ref>, and Hybrid [DEWI84] join algorithms within the context of the Gamma database machine [DEWI86, DEWI88, GERB86]. These algorithms cover the spectrum from hashing, to looping with hashing, and finally to sorting. <p> However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. In this paper we present a performance evaluation of parallel versions of the sort-merge, Grace [KITS83], Simple <ref> [DEWI84] </ref>, and Hybrid [DEWI84] join algorithms within the context of the Gamma database machine [DEWI86, DEWI88, GERB86]. These algorithms cover the spectrum from hashing, to looping with hashing, and finally to sorting. <p> In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI84, DEWI85, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of July 10, 1992 4 the join. <p> These services include structured sequential files, B + indices, byte-stream files as in UNIX, long data items, a sort utility, and a scan mechanism. 3. Parallel Join Algorithms We implemented parallel versions of four join algorithms: sort-merge, Grace [KITS83], Simple hash <ref> [DEWI84] </ref>, and Hybrid hash-join [DEWI84]. Each of the algorithms share a data partitioning stage in which tuples from the joining relations are distributed across the available processors for joining. <p> These services include structured sequential files, B + indices, byte-stream files as in UNIX, long data items, a sort utility, and a scan mechanism. 3. Parallel Join Algorithms We implemented parallel versions of four join algorithms: sort-merge, Grace [KITS83], Simple hash <ref> [DEWI84] </ref>, and Hybrid hash-join [DEWI84]. Each of the algorithms share a data partitioning stage in which tuples from the joining relations are distributed across the available processors for joining. <p> R ggg hash split table R Disk #l Disk #2 Disk #k R R Partitioning of relation R across K disk drives for sort-merge. July 10, 1992 6 3.2. Simple Hash A centralized version of the Simple hash-join <ref> [DEWI84] </ref> operates as follows. First, the smaller joining relation, R, is read from disk and staged in an in-memory hash table (which is formed by hashing on the join attribute of each tuple of R). <p> Hybrid Hash-Join A centralized Hybrid hash-join algorithm <ref> [DEWI84] </ref> also operates in three phases. In the first phase, the algorithm uses a hash function to partition the inner relation, R, into N buckets. The tuples of the first bucket are used to build an in-memory hash table while the remaining N-1 buckets are stored in temporary files. <p> It is important to point out that the trends observed in these graphs and their general shape are very similar to the analytical results reported in <ref> [DEWI84] </ref> and the experimental results in [DEWI85] for single-processor versions of the same algorithms. There are several reasons why we find this similarity encouraging. First, it demonstrates that each of the algorithms parallelizes well.
Reference: [DEWI85] <author> DeWitt, D., and R. Gerber, </author> <title> Multiprocessor Hash-Based Join Algorithms, </title> <booktitle> Proceedings of the 1985 VLDB Conference, </booktitle> <address> Stockholm, Sweden, </address> <month> August, </month> <year> 1985. </year>
Reference-contexts: In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI84, DEWI85, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of July 10, 1992 4 the join. <p> It is important to point out that the trends observed in these graphs and their general shape are very similar to the analytical results reported in [DEWI84] and the experimental results in <ref> [DEWI85] </ref> for single-processor versions of the same algorithms. There are several reasons why we find this similarity encouraging. First, it demonstrates that each of the algorithms parallelizes well. Second, it serves to verify that our parallel implementation of each algorithm was done in a fair and consistent fashion.
Reference: [DEWI86] <author> DeWitt, D., Gerber, B., Graefe, G., Heytens, M., Kumar, K. and M. Muralikrishna, </author> <title> GAMMA A High Performance Dataflow Database Machine, </title> <booktitle> Proceedings of the 1986 VLDB Conference, </booktitle> <address> Japan, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. In this paper we present a performance evaluation of parallel versions of the sort-merge, Grace [KITS83], Simple [DEWI84], and Hybrid [DEWI84] join algorithms within the context of the Gamma database machine <ref> [DEWI86, DEWI88, GERB86] </ref>. These algorithms cover the spectrum from hashing, to looping with hashing, and finally to sorting. We feel that Gamma is a good choice for the experimental vehicle because it incorporates a shared-nothing architecture with commercially available components. <p> Section 4 contains the results of the experiments that we conducted. Our conclusions appear in Section 5. 2. Overview of the Gamma Database Machine In this section we present a brief overview of the Gamma database machine. For a complete description of Gamma see <ref> [DEWI86, GERB86] </ref>. A performance analysis of Gamma can be found in [DEWI88]. 2.1. Hardware Configuration Currently 2 , Gamma consists of 17 VAX 11/750 processors, each with two megabytes of memory.
Reference: [DEWI87] <author> DeWitt, D., Smith, M., and H. Boral, </author> <title> A Single-User Performance Evaluation of the Teradata Database Machine, </title> <type> MCC Technical Report Number DB-081-87, </type> <month> March 5, </month> <year> 1987. </year>
Reference-contexts: Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. In fact, several researchers, including <ref> [BARU87, BRAT87, DEWI87, DEWI88, KITS88] </ref>, have presented performance timings for a variety of distributed join algorithms. However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. <p> Sort-Merge Our parallel version of the sort-merge join algorithm is a straightforward adaptation of the traditional single processor version of the algorithm and is essentially identical to the algorithm employed by the Teradata machine <ref> [TERA83, DEWI87] </ref>. The smaller of the two joining relations, R, is first partitioned through a split table that contains an entry for each processor with an attached disk. A hash function is applied to the join attribute of each tuple to determine the appropriate disk site.
Reference: [DEWI88] <author> DeWitt, D., Ghandeharizadeh, S., and D. Schneider, </author> <title> "A Performance Analysis of the Gamma Database Machine", </title> <booktitle> Proceedings of the 1988 SIGMOD Conference, </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. In fact, several researchers, including <ref> [BARU87, BRAT87, DEWI87, DEWI88, KITS88] </ref>, have presented performance timings for a variety of distributed join algorithms. However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. <p> However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. In this paper we present a performance evaluation of parallel versions of the sort-merge, Grace [KITS83], Simple [DEWI84], and Hybrid [DEWI84] join algorithms within the context of the Gamma database machine <ref> [DEWI86, DEWI88, GERB86] </ref>. These algorithms cover the spectrum from hashing, to looping with hashing, and finally to sorting. We feel that Gamma is a good choice for the experimental vehicle because it incorporates a shared-nothing architecture with commercially available components. <p> Our conclusions appear in Section 5. 2. Overview of the Gamma Database Machine In this section we present a brief overview of the Gamma database machine. For a complete description of Gamma see [DEWI86, GERB86]. A performance analysis of Gamma can be found in <ref> [DEWI88] </ref>. 2.1. Hardware Configuration Currently 2 , Gamma consists of 17 VAX 11/750 processors, each with two megabytes of memory. An 80 megabit/second token ring [PROT85] connects the processors to each other and to another VAX 11/750 running Berkeley UNIX. <p> The sort-merge algorithm has been excluded from this section because our current implementation of this algorithm cannot utilize diskless processors. Although Gamma is capable of executing a join operation on a mix of processors with and without disks, earlier tests for the simple hash-join algorithm <ref> [DEWI88] </ref> indicated the performance of such a configuration was almost always 1/2 way between that of the "local" and "remote" configurations. Thus, for the following experiments, 8 processors with disks were used for storing the relations and 8 diskless processors performed the actual join computation. <p> The crossover occurs because as more overflows occur, the Simple hash-join becomes more and more like a non-partitioning attribute join and hence performance degrades. These results support those reported in <ref> [DEWI88] </ref> for Gamma using 4 kbyte disk pages. Local vs. Remote Joins: Non-Partitioning Attributes When non-partitioning attribute joins are used as the joining attribute, the results presented in the previous sub-section no longer hold.
Reference: [GERB86] <author> Gerber, R., </author> <title> Dataflow Query Processing using Multiprocessor Hash-Partitioned Algorithms, </title> <type> PhD Thesis and Computer Sciences Technical Report #672, </type> <institution> University of Wisconsin-Madison, </institution> <month> October </month> <year> 1986. </year>
Reference-contexts: However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. In this paper we present a performance evaluation of parallel versions of the sort-merge, Grace [KITS83], Simple [DEWI84], and Hybrid [DEWI84] join algorithms within the context of the Gamma database machine <ref> [DEWI86, DEWI88, GERB86] </ref>. These algorithms cover the spectrum from hashing, to looping with hashing, and finally to sorting. We feel that Gamma is a good choice for the experimental vehicle because it incorporates a shared-nothing architecture with commercially available components. <p> Section 4 contains the results of the experiments that we conducted. Our conclusions appear in Section 5. 2. Overview of the Gamma Database Machine In this section we present a brief overview of the Gamma database machine. For a complete description of Gamma see <ref> [DEWI86, GERB86] </ref>. A performance analysis of Gamma can be found in [DEWI88]. 2.1. Hardware Configuration Currently 2 , Gamma consists of 17 VAX 11/750 processors, each with two megabytes of memory.
Reference: [JARK84] <author> Jarke, M. and J. Koch, </author> <title> Query Optimization in Database System, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 16, No. 2, </volume> <month> June, </month> <year> 1984. </year>
Reference-contexts: July 10, 1992 3 Query Execution Gamma uses traditional relational techniques for query parsing, optimization <ref> [SELI79, JARK84] </ref>, and code generation. Queries are compiled into a tree of operators with predicates compiled into machine language. After being parsed, optimized, and compiled, the query is sent by the host software to an idle scheduler process through a dispatcher process.
Reference: [KITS88] <author> Kitsuregawa, M. </author> <title> Query Execution for Large Relation On Functional Disk System, </title> <note> to appear, 1989 Data Engineering Conference. </note>
Reference-contexts: Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. In fact, several researchers, including <ref> [BARU87, BRAT87, DEWI87, DEWI88, KITS88] </ref>, have presented performance timings for a variety of distributed join algorithms. However, the more popular parallel join algorithms have never been compared in a common hardware/software environment.
Reference: [KITS83] <author> Kitsuregawa, M., Tanaka, H., and T. Moto-oka, </author> <title> Apllication of Hash to Data Basae Machine and Its Architecture, </title> <journal> New Generation Computing, </journal> <volume> Vol. 1, No. 1, </volume> <year> 1983. </year> <month> July 10, </month> <year> 1992 </year> <month> 31 </month>
Reference-contexts: 1. Introduction During the last 10 years, a significant amount of effort has been focused on developing efficient join algorithms. Initially, nested loops and sort-merge were the algorithms of choice. However, work by <ref> [KITS83, BRAT84, DEWI84] </ref> demonstrated the potential of hash-based join methods. Besides being faster under most conditions these hash-based join algorithms have the property of being easy to parallelize. Thus, with the trend towards multiprocessor database machines, these algorithms have received a lot of attention. <p> However, the more popular parallel join algorithms have never been compared in a common hardware/software environment. In this paper we present a performance evaluation of parallel versions of the sort-merge, Grace <ref> [KITS83] </ref>, Simple [DEWI84], and Hybrid [DEWI84] join algorithms within the context of the Gamma database machine [DEWI86, DEWI88, GERB86]. These algorithms cover the spectrum from hashing, to looping with hashing, and finally to sorting. <p> These services include structured sequential files, B + indices, byte-stream files as in UNIX, long data items, a sort utility, and a scan mechanism. 3. Parallel Join Algorithms We implemented parallel versions of four join algorithms: sort-merge, Grace <ref> [KITS83] </ref>, Simple hash [DEWI84], and Hybrid hash-join [DEWI84]. Each of the algorithms share a data partitioning stage in which tuples from the joining relations are distributed across the available processors for joining. <p> Additionally, the Grace and Hybrid join algorithms first partition the two relations being joined into additional fragments when the inner relation is larger than the amount of available main memory. This is referred to as the bucket-forming phase <ref> [KITS83] </ref>. The degree of interaction between the bucket-forming phase and the joining phase differs between the Grace and Hybrid algorithms, though. More details on each algorithm are presented in the following sections. In the following discussion, R and S refer to the relations being joined. <p> Relation S is then processed in the same manner. Since the same hash function is used to redistribute both relations, only tuples within fragments at a particular site have the possibility of joining <ref> [KITS83] </ref>. Thus, a local merge performed in parallel across the disk sites will fully compute the join. Of course, if we were required to present a sorted relation to a user, a final merge of the locally merged relation fragments would be necessary. <p> Until very recently, Simple hash was the only join algorithm employed by Gamma and is currently used as the overflow resolution method for our parallel implementations of the Grace and Hybrid algorithms. 3.3. Grace Hash-Join A centralized Grace join algorithm <ref> [KITS83] </ref> works in three phases. In the first phase, the algorithm partitions relation R into N disk buckets by hashing on the join attribute of each tuple in R. In phase 2, relation S is partitioned into N buckets using the same hash function. <p> In the event that the buckets are much smaller than main memory, several will be combined during the third phase to form more optimal size join buckets (referred to as bucket tuning in <ref> [KITS83] </ref>). The Grace algorithm differs fundamentally from the sort-merge and simple-hash join algorithms in that data partitioning occurs at two different stages during bucket-forming and during bucket-joining. Parallelizing the algorithm thus must address both these data partitioning stages.
Reference: [PROT85] <author> Proteon Associates, </author> <title> Operation and Maintenance Manual for the ProNet Model p8000, </title> <address> Waltham, Mass, </address> <year> 1985. </year>
Reference-contexts: For a complete description of Gamma see [DEWI86, GERB86]. A performance analysis of Gamma can be found in [DEWI88]. 2.1. Hardware Configuration Currently 2 , Gamma consists of 17 VAX 11/750 processors, each with two megabytes of memory. An 80 megabit/second token ring <ref> [PROT85] </ref> connects the processors to each other and to another VAX 11/750 running Berkeley UNIX. This processor acts as the host machine for Gamma. 333 megabyte Fujitsu disk drives (8") provide database storage at eight of the processors. One diskless processor is reserved for query scheduling and global deadlock detection.
Reference: [RIES78] <author> Ries, D. and R. Epstein, </author> <title> Evaluation of Distribution Criteria for Distributed Database Systems, </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May, </month> <year> 1978. </year>
Reference-contexts: One diskless processor is reserved for query scheduling and global deadlock detection. The remaining diskless processors execute join, projection, and aggregate operations. Selection and update operations execute only on the processors with attached disk drives. 2.2. Software Overview Physical Database Design In Gamma, all relations are horizontally partitioned <ref> [RIES78] </ref> across all disk drives in the system. Four alternative ways of distributing the tuples of a relation are provided: round-robin, hashed, range partitioned with user-specified placement by key value, and range partitioned with uniform distribution.
Reference: [SELI79] <author> Selinger,P. G., et. al., </author> <title> Access Path Selection in a Relational Database Management System, </title> <booktitle> Proceedings of the 1979 SIGMOD Conference, </booktitle> <address> Boston, MA., </address> <month> May </month> <year> 1979. </year>
Reference-contexts: July 10, 1992 3 Query Execution Gamma uses traditional relational techniques for query parsing, optimization <ref> [SELI79, JARK84] </ref>, and code generation. Queries are compiled into a tree of operators with predicates compiled into machine language. After being parsed, optimized, and compiled, the query is sent by the host software to an idle scheduler process through a dispatcher process.
Reference: [TANE81] <author> Tanenbaum, A. S., </author> <title> Computer Networks, </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: Operating and Storage System The operating system on which Gamma is constructed provides lightweight processes with shared memory and reliable, datagram communication services using a multiple bit, sliding window protocol <ref> [TANE81] </ref>. Messages between two processes on the same processor are short-circuited by the communications software. File services in Gamma are based on the Wisconsin Storage System (WiSS) [CHOU85].
Reference: [TAND88] <author> Tandem Performance Group, </author> <title> A Benchmark of Non-Stop SQL on the Debit Credit Transaction, </title> <booktitle> Proceedings of the 1988 SIGMOD Conference, </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: This basic design is becoming increasingly popular, both in research, for example, Bubba at MCC [COPE88, BORA88] and in the commercial arena, with products from Tera-data [TERA83] and Tandem <ref> [TAND88] </ref>. The experiments were designed to test the performance of each of the join algorithms under several different conditions. First, we compare the algorithms when the join attributes are also the attributes used to distribute the relations during loading.
Reference: [TERA83] <institution> Teradata Corp., DBC/1012 Data Base Computer Concepts & Facilities, Teradata Corp. </institution> <note> Document No. C02-0001-00, </note> <year> 1983. </year>
Reference-contexts: We feel that Gamma is a good choice for the experimental vehicle because it incorporates a shared-nothing architecture with commercially available components. This basic design is becoming increasingly popular, both in research, for example, Bubba at MCC [COPE88, BORA88] and in the commercial arena, with products from Tera-data <ref> [TERA83] </ref> and Tandem [TAND88]. The experiments were designed to test the performance of each of the join algorithms under several different conditions. First, we compare the algorithms when the join attributes are also the attributes used to distribute the relations during loading. <p> Sort-Merge Our parallel version of the sort-merge join algorithm is a straightforward adaptation of the traditional single processor version of the algorithm and is essentially identical to the algorithm employed by the Teradata machine <ref> [TERA83, DEWI87] </ref>. The smaller of the two joining relations, R, is first partitioned through a split table that contains an entry for each processor with an attached disk. A hash function is applied to the join attribute of each tuple to determine the appropriate disk site.
Reference: [VALD84] <author> Valduriez, P., and G. Gardarin, </author> <title> Join and Semi-Join Algorithms for a Multiprocessor Database Machine ACM Transactions on Database Systems, </title> <journal> Vol. </journal> <volume> 9, No. 1, </volume> <month> March, </month> <year> 1984. </year> <month> July 10, </month> <year> 1992 </year>
Reference-contexts: We also considered how effectively the different join algorithms could utilize processors without disks. Finally, bit vector filtering techniques <ref> [BABB79, VALD84] </ref> were evaluated for each of the parallel join algorithms. hhhhhhhhhhhhhhhhhhhhhhhhhhhhh 1 This set of experiments can also be viewed as predicting the relative performance of the various algorithms when the size of memory is constant and the algorithms are required to process relations larger than the the size of <p> If the result of a query is a new relation, the operators at the root of the query tree distribute the result tuples on a round-robin basis to store operators at each disk site. To enhance the performance of certain operations, an array of bit vector filters <ref> [BABB79, VALD84] </ref> is inserted into the split table. In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation [BRAT84, DEWI84, DEWI85, VALD84]. <p> In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI84, DEWI85, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of July 10, 1992 4 the join. <p> Obviously these results demonstrate that a tradeoff exists between being pessimistic and increasing the number of buckets and being optimistic and counting on Simple hash-join to resolve any memory overflow. 4.2. Multiprocessor Bit Vector Filtering In the next set of experiments we ran the joinABprime tests using bit filters <ref> [BABB79, VALD84] </ref>. In each of the parallel join algorithms, bit filtering of tuples is only applied during the joining phase. With sort-merge joins, a bit filter is built at each disk site as the inner (smaller) relation is partitioned across the network and stored in temporary files.
References-found: 24

