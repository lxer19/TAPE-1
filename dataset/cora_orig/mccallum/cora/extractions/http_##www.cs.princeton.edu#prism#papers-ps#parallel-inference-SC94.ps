URL: http://www.cs.princeton.edu/prism/papers-ps/parallel-inference-SC94.ps
Refering-URL: http://www.cs.princeton.edu/prism/html/all-papers.html
Root-URL: http://www.cs.princeton.edu
Title: A Parallel Lauritzen-Spiegelhalter Algorithm for Probabilistic Inference  
Author: Alexander V. Kozlov Jaswinder Pal Singh 
Address: Stanford, CA 94305-4090 Stanford, CA 94305  
Affiliation: Department of Applied Physics Computer Systems Laboratory Stanford University Stanford University  
Abstract: Probabilistic inference in belief networks is a promising technique for diagnosis, forecasting and decision analysis tasks. Unfortunately, exact inference can be very expensive computationally. In this paper, we examine whether probabilistic inference can be sped up effectively through parallel computation on real multiprocessors. Our experiments are performed on a 32-processor Stanford DASH multiprocessor, a cache-coherent shared-address-space machine with physically distributed main memory. We find that the major part of the calculation can be moved outside the actual propagation through the network, and yields good speedups. Speedups for the propagation itself depend on the structure of the network and the size of the cliques that the algorithm creates. We demonstrate good speedup on a CPCS subnetwork used for medical diagnosis. This result as well as a tendency for the speedup to increase with the size of the network invites practical application of parallel techniques for large Bayesian networks in expert systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. S. Lauritzen and D. J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 50:253 - 258, </volume> <year> 1988. </year>
Reference-contexts: Two types of approaches are taken to find the desired conditional probabilities. The first is exact algorithms, among which the two dominant ones are the Lauritzen-Spiegelhalter (LS) algorithm <ref> [1, 2, 3, 4] </ref> and Symbolic Probabilistic Inference (SPI) [5]. For a general query and network, the probabilistic inference problem is NP-hard [6] and exact algorithms are computationally very expensive. The second approach is based on approximate search algorithms or Monte-Carlo simulations. <p> Section 7 presents our results. Finally, Section 8 provides a discussion of the results and possible future avenues for experimentation. 2 An Example Belief Network A simple example of a belief network is the "Asia" network <ref> [1] </ref> (see Fig. 1), which consists of 8 nodes. We assume that each node can take two values: true or false. An edge in the network represents a probabilistic dependence expressed in terms of conditional probabilities.
Reference: [2] <author> Richard E Neapolitan. </author> <title> Probabilistic Reasoning in Expert Systems. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Two types of approaches are taken to find the desired conditional probabilities. The first is exact algorithms, among which the two dominant ones are the Lauritzen-Spiegelhalter (LS) algorithm <ref> [1, 2, 3, 4] </ref> and Symbolic Probabilistic Inference (SPI) [5]. For a general query and network, the probabilistic inference problem is NP-hard [6] and exact algorithms are computationally very expensive. The second approach is based on approximate search algorithms or Monte-Carlo simulations.
Reference: [3] <author> F. V. Jensen, S. L. Lauritzen, and K. G. Olesen. </author> <title> Bayesian updating in causal probabilistic networks by local computations. </title> <journal> Computational Statistics Quarterly, </journal> <volume> 4:269 - 282, </volume> <year> 1990. </year>
Reference-contexts: Two types of approaches are taken to find the desired conditional probabilities. The first is exact algorithms, among which the two dominant ones are the Lauritzen-Spiegelhalter (LS) algorithm <ref> [1, 2, 3, 4] </ref> and Symbolic Probabilistic Inference (SPI) [5]. For a general query and network, the probabilistic inference problem is NP-hard [6] and exact algorithms are computationally very expensive. The second approach is based on approximate search algorithms or Monte-Carlo simulations. <p> A join tree is a tree of sets in which if a node is in set 1 and set 2, it is also in all sets between these sets <ref> [3] </ref>. One of the exact algorithms that does probabilistic inference in a multiply connected network is the LS algorithm, which we shall outline in the next section. 3 Lauritzen-Spiegelhalter Algorithm The LS algorithm first converts a multiply connected network into a tree of clusters, or sets of nodes.
Reference: [4] <author> F. V. Jensen, K. Gand Olesen, and S. K. Ander-sen. </author> <title> An algebra of bayesian bilief universes for knowledge-based systems. Networks, </title> <address> 20:637 - 659, </address> <year> 1990. </year>
Reference-contexts: Two types of approaches are taken to find the desired conditional probabilities. The first is exact algorithms, among which the two dominant ones are the Lauritzen-Spiegelhalter (LS) algorithm <ref> [1, 2, 3, 4] </ref> and Symbolic Probabilistic Inference (SPI) [5]. For a general query and network, the probabilistic inference problem is NP-hard [6] and exact algorithms are computationally very expensive. The second approach is based on approximate search algorithms or Monte-Carlo simulations.
Reference: [5] <author> Zhaoyu Li and Bruce D'Ambrosio. </author> <title> Efficient inference in bayes networks as a combinatorial optimization problem. </title> <journal> International Journal of Approximate Reasoning, </journal> <note> 1994. to be published. </note>
Reference-contexts: Two types of approaches are taken to find the desired conditional probabilities. The first is exact algorithms, among which the two dominant ones are the Lauritzen-Spiegelhalter (LS) algorithm [1, 2, 3, 4] and Symbolic Probabilistic Inference (SPI) <ref> [5] </ref>. For a general query and network, the probabilistic inference problem is NP-hard [6] and exact algorithms are computationally very expensive. The second approach is based on approximate search algorithms or Monte-Carlo simulations. <p> The structure of the join tree is by and large determined by the problem. In many cases load balance can be improved by constructing the join tree can be constructed with the view of parallelization ahead. In general the problem is analogous to construction an optimal evaluation tree <ref> [5] </ref> and is computationally expensive. In the current implementation, we have chosen a simple way to construct a tree which facilitates speedup. Each clique was prescribed a computational cost.
Reference: [6] <author> G. Cooper. </author> <title> The computational complexity of probabilistic inference using bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42:393 - 405, </volume> <year> 1990. </year>
Reference-contexts: The first is exact algorithms, among which the two dominant ones are the Lauritzen-Spiegelhalter (LS) algorithm [1, 2, 3, 4] and Symbolic Probabilistic Inference (SPI) [5]. For a general query and network, the probabilistic inference problem is NP-hard <ref> [6] </ref> and exact algorithms are computationally very expensive. The second approach is based on approximate search algorithms or Monte-Carlo simulations. For the precision needed by practitioners in many applications, search methods take much less time than exact methods.
Reference: [7] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of plausible inference. </title> <publisher> Mor-gan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1988. </year>
Reference-contexts: Any query can be calculated by factoring out probabilities. Different factoring strategies represent different algorithms for exact probabilistic inference. In one of them, calculation of a query is represented by message passing up and down the network <ref> [7] </ref>. <p> = 0; i &lt; gp-&gt;clique.numChildren; i++) f gc = &globTree-&gt;globCliques [gp-&gt;clique.childCliqueIndices [i]]; if (gc-&gt;clique.numSeps) f if (gc-&gt;msgIndices) for (j = from; j &lt; to; j++) gp-&gt;clique.potentials [j] *= gc-&gt;clique.msg [gc-&gt;msgIndices [j]]; else for (j = from; j &lt; to; j++) gp-&gt;clique.potentials [j] *= gc-&gt;clique.msg [MsgIndex (j, gp, gc)]; g In <ref> [7] </ref> the evaluation of a query in a tree network consists of sending so-called messages from the bottom of the tree to the top and messages from the top to the bottom, modifying and accumulating node properties along the way.
Reference: [8] <author> Dan Lenoski, James Laudon, Kourosh Gharachor-loo, Anoop Gupta, and John Hennessy. </author> <title> The directory-based cache coherence protocol for the DASH multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 148 - 159, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Before we discuss our parallel implementation that exploits both types of parallelism (in both cases with and without index preevaluation), let us describe the multiprocessor that we run our experiments on. 4 The Stanford DASH multiprocessor The DASH machine <ref> [8] </ref> is a state-of-the-art, experimental multiprocessor built at Stanford University. It supports an implicit shared address space communication abstraction in hardware (as opposed to explicit message-passing as in the Intel iPSC's and Paragon or the Connection Machine CM-5), with hardware-supported cache-coherence as well.
Reference: [9] <author> M. Yannakakis. </author> <title> Computing the minimum fill-in is NP-complete. </title> <journal> Journal of Algebraic and Discrete Methods, </journal> <volume> 2(1):77 - 79, </volume> <year> 1981. </year>
Reference-contexts: The drawback of this approach is the memory requirement for storing the precomputed indices. The array of message indices is 2 Although finding the triangulation which adds the minimum number of arcs in CTG has been known to be NP-complete <ref> [9] </ref>, heuristic algorithms with O (n + e) computation time exist, where n and e are the number of nodes and edges in the network. Accepted for the Supercomputing'94 coference, November 14-18, 1994 5 stored with the relevant clique.
References-found: 9

