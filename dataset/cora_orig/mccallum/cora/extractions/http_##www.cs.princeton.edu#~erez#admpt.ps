URL: http://www.cs.princeton.edu/~erez/admpt.ps
Refering-URL: http://theory.lcs.mit.edu/~karger/library.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Linear Hashing finite field F has n elements then there is a bad set S
Author: Noga Alon Martin Dietzfelbinger Peter Bro Miltersen Erez Petrank Gabor Tardos p n. p 
Keyword: O(2  
Note: If the  (This is  1 the image of S will cover all elements in the range.  
Abstract: Consider the set H of all linear (or affine) transformations between two vector spaces over a finite field F . We study how good H is as a class of hash functions, namely we consider hashing a set S of size n into a range having the same cardinality n by a randomly chosen function from H and look at the expected size of the largest hash bucket. H is a universal class of hash functions for any finite field, but with respect to our measure different fields behave differently. If, however, we consider the field of two elements then we get much better bounds. The best previously known upper bound on the expected size of the largest bucket for this class was log n ). We reduce this upper bound to O(log n log log n). Note that this is not far from the guarantee for a random function. There, the average largest bucket would be fi(log n= log log n). In the course of our proof we develop a tool which may be of independent interest. Suppose we have a subset S of a vector space D over Z 2 , and consider a random linear mapping of D to a smaller vector space R. If the cardinality of S is larger than c * jRj log jRj then with probability 
Abstract-found: 1
Intro-found: 1
Reference: [ABI86] <author> N. Alon, L. Babai and A. Itai, </author> <title> A fast and simple randomized parallel algorithm for the maximal independent set problem. </title> <journal> J. </journal> <note> Algorithms 7 (1986) 567-583. </note>
Reference-contexts: One immediate such result is obtained by looking at the class of d-degree polynomials over finite fields, where d = c log n= log log n (see, e.g., <ref> [ABI86] </ref>.) It is easy to see that this class maps each d elements of the domain independently to the range, and thus, the bound that applies to the class of all functions also applies to this class.
Reference: [ABM87] <author> N. Alon, A. Barak and U. Manber, </author> <title> On disseminating information reliably without broadcasting, </title> <booktitle> in: Proc. 7th International Conference on Distributed Computing Systems (ICDS), </booktitle> <address> Berlin, </address> <year> 1987, </year> <pages> pp. 74-81. </pages>
Reference-contexts: Imagine the vectors v 1 ; : : : ; v s being chosen one by one and consider v 1 ; : : : ; v i fixed and thus ff i determined. By Lemma 2.1 E (ff i+1 ) = ff 2 Following the (simple) idea in <ref> [ABM87] </ref>, we want to say that the choice of v i+1 is successful if ff i+1 is small enough with respect to ff i . The decrease of ff i is different depending on ff i being greater or less than 1=2.
Reference: [AS92] <author> N. Alon and J. H. Spencer, </author> <title> The Probabilistic Method, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Then, we check the probability that in the remaining s s 0 steps we get that ff s &lt; 2 m . Applying Chernoff's bound (similarly to Corollary A.7 in Appendix A of <ref> [AS92] </ref>) implies that the probability that we do not have at least 9 log C successful choices out of the choices of v 1 ; : : : ; v s 0 is at most *=3.
Reference: [AHNR95] <author> A. Andersson, T. Hagerup, S. Nilsson, and R. Raman, </author> <title> Sorting in linear time?, </title> <booktitle> in: Proc. 27th ACM Symposium on Theory of Computing, </booktitle> <year> 1995, </year> <pages> pp. 427-436. </pages>
Reference-contexts: Tighter bounds should be possible. Another question is which fine-grained property other well known hash families have. Examples of the families we have in mind include: Arithmetic over Z p [CW79, FKS84] (with h a;b (x) = (ax + b mod p) mod n), integer multiplication <ref> [DHKP93, AHNR95] </ref> (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace). 13 An example of a natural non-linear scheme for which the assertion of Theorem 6 fails is the scheme that
Reference: [CW79] <author> J. L. Carter and M. N. Wegman, </author> <title> Universal classes of hash functions, </title> <institution> J. Comput. Syst. Sci. </institution> <month> 18 </month> <year> (1979) </year> <month> 143-154. </month>
Reference-contexts: The families from [S89] and [DM90] are somewhat complex to implement while the class of linear maps requires only very basic bit operations (as discussed already in <ref> [CW79] </ref>). It is therefore desirable to study this class, and this is the main purpose of the present paper. 1.3 Notation If S is a subset of the domain D of a function h we use h (S) to denote fh (s) j s 2 Sg. <p> Tighter bounds should be possible. Another question is which fine-grained property other well known hash families have. Examples of the families we have in mind include: Arithmetic over Z p <ref> [CW79, FKS84] </ref> (with h a;b (x) = (ax + b mod p) mod n), integer multiplication [DHKP93, AHNR95] (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace). 13 An example of
Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: for the class of linear maps over Z 2 , i.e., is it as good as O (log s= log log s)? We leave this as an open question. 3 1.1 Motivation There is no doubt that the method of implementing a dictionary by hashing with chaining, recommended in textbooks <ref> [CLR90, GBY90] </ref> especially for situations with many update operations, is a practically important scheme.
Reference: [DHKP93] <author> M. Dietzfelbinger, T. Hagerup, J. Katajainen, and M. Penttonen, </author> <title> A reliable randomized algorithm for the closest-pair problem, </title> <type> Technical Report 513, </type> <institution> Fachbereich Informatik, Universitat Dortmund, </institution> <year> 1993. </year> <month> 14 </month>
Reference-contexts: Tighter bounds should be possible. Another question is which fine-grained property other well known hash families have. Examples of the families we have in mind include: Arithmetic over Z p [CW79, FKS84] (with h a;b (x) = (ax + b mod p) mod n), integer multiplication <ref> [DHKP93, AHNR95] </ref> (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace). 13 An example of a natural non-linear scheme for which the assertion of Theorem 6 fails is the scheme that
Reference: [DM90] <editor> M. Dietzfelbinger and F. Meyer auf der Heide, </editor> <title> Dynamic hashing in real time, </title> <editor> in: J. Buchmann, H. Ganzinger, W. J. Paul (Eds.): </editor> <booktitle> Informatik Festschrift zum 60. </booktitle> <editor> Geburt-stag von Gunter Hotz, </editor> <title> Teubner-Texte zur Informatik, Band 1, </title> <editor> B. G. </editor> <publisher> Teubner, </publisher> <year> 1992, </year> <pages> pp. </pages> <month> 95-119. </month> <title> (A preliminary version appeared under the title "A New Universal Class of Hash Functions and Dynamic Hashing in Real Time" in ICALP'90.) </title>
Reference-contexts: For other simple hash classes such bounds on the worst case bucket size are not available or are even wrong (see Theorem 8); other, more sophisticated hash families <ref> [S89, DM90, DGMP92] </ref> that do guarantee small maximal bucket sizes consist of functions with higher evaluation time. <p> time for certain operations is absolutely necessary, the known two-level hashing schemes can be used, e. g., the FKS scheme [FKS84] for static dictionaries; dynamic perfect hashing [DKMHRT94] for the dynamic case with constant time lookups and expected time O (n) for n update operations; and the "real-time dictionaries" from <ref> [DM90] </ref> that perform each operation in constant time, with high probability. <p> More efficient (but much larger) families where given by Siegel [S89] and by Dietzfelbinger and Meyer auf der Heide <ref> [DM90] </ref>. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] are somewhat complex to implement while the class of <p> [S89] and by Dietzfelbinger and Meyer auf der Heide <ref> [DM90] </ref>. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] are somewhat complex to implement while the class of linear maps requires only very basic bit operations (as discussed already in [CW79]).
Reference: [DKMHRT94] <author> M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer Auf Der Heide, H. Rohnert, R.E. Tarjan, </author> <title> Dynamic perfect hashing: upper and lower bounds, </title> <journal> SIAM J. Comput. </journal> <month> 23 </month> <year> (1994) </year> <month> 738-761. </month>
Reference-contexts: Of course, if worst case constant time for certain operations is absolutely necessary, the known two-level hashing schemes can be used, e. g., the FKS scheme [FKS84] for static dictionaries; dynamic perfect hashing <ref> [DKMHRT94] </ref> for the dynamic case with constant time lookups and expected time O (n) for n update operations; and the "real-time dictionaries" from [DM90] that perform each operation in constant time, with high probability.
Reference: [DGMP92] <author> M. Dietzfelbinger, J. Gil, Y. Matias, and N. Pippenger, </author> <title> Polynomial hash functions are reliable, </title> <publisher> ICALP'92, Springer LNCS 623, </publisher> <pages> pp. 235-246. </pages>
Reference-contexts: For other simple hash classes such bounds on the worst case bucket size are not available or are even wrong (see Theorem 8); other, more sophisticated hash families <ref> [S89, DM90, DGMP92] </ref> that do guarantee small maximal bucket sizes consist of functions with higher evaluation time.
Reference: [FKS84] <author> M. L. Fredman, J. Komlos, and E. Szemeredi, </author> <title> Storing a sparse table with O(1) worst case access time, </title> <journal> J. Ass. Comput. Mach. </journal> <month> 31 </month> <year> (1984) </year> <month> 538-544. </month>
Reference-contexts: Of course, if worst case constant time for certain operations is absolutely necessary, the known two-level hashing schemes can be used, e. g., the FKS scheme <ref> [FKS84] </ref> for static dictionaries; dynamic perfect hashing [DKMHRT94] for the dynamic case with constant time lookups and expected time O (n) for n update operations; and the "real-time dictionaries" from [DM90] that perform each operation in constant time, with high probability. <p> Tighter bounds should be possible. Another question is which fine-grained property other well known hash families have. Examples of the families we have in mind include: Arithmetic over Z p <ref> [CW79, FKS84] </ref> (with h a;b (x) = (ax + b mod p) mod n), integer multiplication [DHKP93, AHNR95] (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace). 13 An example of
Reference: [GBY90] <author> G. Gonnet and R. Baeza-Yates, </author> <title> Handbook of Algorithms and Data Structures, </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: for the class of linear maps over Z 2 , i.e., is it as good as O (log s= log log s)? We leave this as an open question. 3 1.1 Motivation There is no doubt that the method of implementing a dictionary by hashing with chaining, recommended in textbooks <ref> [CLR90, GBY90] </ref> especially for situations with many update operations, is a practically important scheme.
Reference: [GR90] <author> S. W. Graham and C. J. Ringrose, </author> <title> Lower bounds for least quadratic nonresidues, in: Analytic Number Theory: </title> <booktitle> Proceedings of a Conference in Honor of P.T. </booktitle> <editor> Bateman, B. C. Berndt et al. (Eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: Note that for every nonzero element a 2 Z p , the set aS ( mod p) is either the set of all quadratic residues or the set of all quadratic non-residues modulo p. The main result of Graham and Ringrose <ref> [GR90] </ref> asserts that for infinitely many primes p, the smallest quadratic nonresidue modulo p is at least (log p log log log p) (this result holds for primes p 3 ( mod 4) as well, as follows from the remark at the end of [GR90]). <p> main result of Graham and Ringrose <ref> [GR90] </ref> asserts that for infinitely many primes p, the smallest quadratic nonresidue modulo p is at least (log p log log log p) (this result holds for primes p 3 ( mod 4) as well, as follows from the remark at the end of [GR90]).
Reference: [MCW78] <author> G. Markowsky, J. L. Carter, and M. N. Wegman, </author> <title> Analysis of a universal class of hash functions, </title> <booktitle> in: Proc. 7th Conference on Math. Found. of Computer Science (MFCS), 1978, </booktitle> <publisher> Springer LNCS 64, </publisher> <pages> pp. 345-354. </pages>
Reference-contexts: Markowsky, Carter and Wegman <ref> [MCW78] </ref> showed that for this case L s s (H) = O (s 1=4 ). Mehlhorn and Vishkin [MV84] improved on this result (although this is implicit in their paper) and showed that L s s (H) = p log s ).
Reference: [MV84] <author> K. Mehlhorn and U. Vishkin, </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories., </title> <note> Acta Informatica 21 (1984) 339-374. </note>
Reference-contexts: Markowsky, Carter and Wegman [MCW78] showed that for this case L s s (H) = O (s 1=4 ). Mehlhorn and Vishkin <ref> [MV84] </ref> improved on this result (although this is implicit in their paper) and showed that L s s (H) = p log s ).
Reference: [MNT93] <author> Y. Mansour, N. Nisan, and P. Tiwari, </author> <title> The computational complexity of universal hashing. </title> <note> Theoretical Computer Science 107 (1993) 121-133. </note>
Reference-contexts: Examples of the families we have in mind include: Arithmetic over Z p [CW79, FKS84] (with h a;b (x) = (ax + b mod p) mod n), integer multiplication [DHKP93, AHNR95] (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution <ref> [MNT93] </ref> (with h a (x) = a ffi x projected to some subspace). 13 An example of a natural non-linear scheme for which the assertion of Theorem 6 fails is the scheme that maps integers between 1 and p, for some large prime p, to integers between 0 and n 1
Reference: [PA95] <author> J. Pach and P. K. Agarwal, </author> <title> Combinatorial Geometry, </title> <publisher> Wiley 1995. </publisher>
Reference-contexts: Clearly jS 0 j &lt; n. It is well known that each of the n most popular lines contains at least m n 1=3 =3 points of S 0 . This is usually proved for the same grid in the Euclidean plane (see e.g. <ref> [PA95] </ref>, pp. 178-179) but that result implies the same for our grid in F 2 . Now let n = p k and let F 0 be the subfield in F of p elements.
Reference: [S89] <author> A. Siegel, </author> <title> On universal classes of fast high performance hash functions, their time-space tradeoff, and their application, </title> <booktitle> in: Proc. 30th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 20-25. </pages>
Reference-contexts: For other simple hash classes such bounds on the worst case bucket size are not available or are even wrong (see Theorem 8); other, more sophisticated hash families <ref> [S89, DM90, DGMP92] </ref> that do guarantee small maximal bucket sizes consist of functions with higher evaluation time. <p> More efficient (but much larger) families where given by Siegel <ref> [S89] </ref> and by Dietzfelbinger and Meyer auf der Heide [DM90]. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] <p> by Siegel <ref> [S89] </ref> and by Dietzfelbinger and Meyer auf der Heide [DM90]. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] are somewhat complex to implement while the class of linear maps requires only very basic bit operations (as discussed already in [CW79]).
Reference: [VC71] <author> V. A. Vapnik and A. Y. Chervonenkis, </author> <title> On the uniform convergence of relative frequencies of events to their probabilities, </title> <journal> Theory of Prob. </journal> <note> Applications 16 (1971) 264-280. 15 </note>
Reference-contexts: Thus, the probability of E 1 must be small. We remark here that a somewhat similar line of reasoning was used in the seminal paper of Vapnik and Chervonenkis <ref> [VC71] </ref>. For the proof we fix the domain to be D = Z m 2 , the range (the buckets) to be B = Z log n S D of size jSj = n log n.
References-found: 19

