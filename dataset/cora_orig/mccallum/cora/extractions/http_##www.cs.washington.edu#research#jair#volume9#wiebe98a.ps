URL: http://www.cs.washington.edu/research/jair/volume9/wiebe98a.ps
Refering-URL: http://www.cs.washington.edu/research/jair/contents/v9.html
Root-URL: http://www.cs.washington.edu
Email: wiebe@cs.nmsu.edu  tomohara@cs.nmsu.edu  sandgren@lucent.com  kmckeeve@redwood.dn.hac.com  
Title: An Empirical Approach to Temporal Reference Resolution  
Author: Janyce M. Wiebe Thomas P. O'Hara Thorsten Ohrstrom-Sandgren Kenneth J. McKeever 
Address: Las Cruces, NM 88003  
Affiliation: Department of Computer Science and the Computing Research Laboratory New Mexico State University  
Note: Journal of Artificial Intelligence Research 9 (1998) 247-293 Submitted 5/98; published 11/98  
Abstract: Scheduling dialogs, during which people negotiate the times of appointments, are common in everyday life. This paper reports the results of an in-depth empirical investigation of resolving explicit temporal references in scheduling dialogs. There are four phases of this work: data annotation and evaluation, model development, system implementation and evaluation, and model evaluation and analysis. The system and model were developed primarily on one set of data, and then applied later to a much more complex data set, to assess the generalizability of the model for the task being performed. Many different types of empirical methods are applied to pinpoint the strengths and weaknesses of the approach. Detailed annotation instructions were developed and an intercoder reliability study was performed, showing that naive annotators can reliably perform the targeted annotations. A fully automatic system has been developed and evaluated on unseen test data, with good results on both data sets. We adopt a pure realization of a recency-based focus model to identify precisely when it is and is not adequate for the task being addressed. In addition to system results, an in-depth evaluation of the model itself is presented, based on detailed manual annotations. The results are that few errors occur specifically due to the model of focus being used, and the set of anaphoric relations defined in the model are low in ambiguity for both data sets. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alexandersson, J., Reithinger, N., & Elisabeth, M. </author> <year> (1997). </year> <title> Insights into the dialogue processing of Verbmobil. </title> <booktitle> In Proc. 5th Conference on Applied Natural Language Processing, </booktitle> <pages> pp. 33-40. </pages> <institution> Association for Computational Linguistics. </institution>
Reference: <author> Allen, J. </author> <year> (1984). </year> <title> Toward a general theory of action and time. </title> <journal> Artificial Intelligence, </journal> <volume> 23, </volume> <pages> 123-154. </pages>
Reference: <author> Allen, J., & Perrault, C. </author> <year> (1980). </year> <title> Analyzing intention in utterances. </title> <journal> Artificial Intelligence, </journal> <volume> 15, </volume> <pages> 143-178. </pages>
Reference: <author> Arhenberg, L., Dahlback, N., & Jonsson, A. </author> <year> (1995). </year> <title> Coding schemes for natural language dialogues. </title> <booktitle> In Working Notes of AAAI Spring Symposium: Empirical Methods in Discourse Interpretation and Generation, </booktitle> <pages> pp. 8-13. </pages>
Reference: <author> Busemann, S., Declerck, T., Diagne, A. K., Dini, L., Klein, J., & Schmeier, S. </author> <year> (1997). </year> <title> Natural language dialogue service for appointment scheduling agents. </title> <booktitle> In Proc. 5th Conference on Applied Natural Language Processing, </booktitle> <pages> pp. 25-32. </pages> <institution> Association for Computational Linguistics. </institution>
Reference-contexts: It would be desirable to enter completely resolved dates and times, rather than incomplete components such as the day or time alone. A specific application for which temporal reference resolution is important is appointment scheduling in natural language between human and machine agents <ref> (Busemann, Declerck, Diagne, Dini, Klein, & Schmeier, 1997) </ref>. To fully participate, the machine agent must be able to understand the many references to times that occur in scheduling dialogs. Maintaining the temporal context can aid in other aspects of understanding.
Reference: <author> Carletta, J. </author> <year> (1996). </year> <title> Assessing agreement on classification tasks: the kappa statistic. </title> <journal> Computational Linguistics, </journal> <volume> 22(2), </volume> <pages> 249-254. </pages>
Reference: <author> Clark, H. H. </author> <year> (1977). </year> <title> Bridging. In Johnson-Laird, </title> <editor> P. N., & Wason, P. C. (Eds.), Thinking: </editor> <booktitle> Readings in Cognitive Science. </booktitle> <publisher> Cambridge University Press. </publisher>
Reference: <author> Condon, S., & Cech, C. </author> <year> (1995). </year> <title> Problems for reliable discourse coding schemes. </title> <booktitle> In Proc. AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, </booktitle> <pages> pp. 27-33. </pages>
Reference: <author> Grosz, B., Joshi, A., & Weinstein, S. </author> <year> (1995). </year> <title> Centering: A framework for modeling the local coherence of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 21(2), </volume> <pages> 203-225. </pages>
Reference: <author> Grosz, B., & Sidner, C. </author> <year> (1986). </year> <title> Attention, intention, and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12(3), </volume> <pages> 175-204. </pages>
Reference-contexts: Assume: Monday 19 August How about 2? (co-reference relation) 2pm, Monday 19 August Hmm, how about 4? (modify relation) 4pm, Monday 19 August 4.3 Focus Models The focus model, or model of attentional state <ref> (Grosz & Sidner, 1986) </ref>, is a model of which entities the dialog is most centrally about at each point in the dialog. It determines which previously mentioned entities are the candidate antecedents of anaphoric references. <p> However, if the current utterance resumes a previous discourse segment, the intervening focus spaces are popped off. This allows anaphoric reference to an earlier entity, even if more recently mentioned entities are possible antecedents <ref> (for more details, see Grosz & Sidner, 1986) </ref>.
Reference: <author> Hays, W. L. </author> <year> (1988). </year> <title> Statistics (Fourth edition). Holt, Rinehart, and Winston. 290 An Empirical Approach to Temporal Reference Resolution Heim, </title> <editor> I. </editor> <year> (1982). </year> <title> The Semantics of Definite and Indefinite Noun Phrases. </title> <type> Ph.D. thesis, </type> <institution> University of Massachusetts at Amherst. </institution>
Reference-contexts: maximum possible agreement for one object: S i = j=1 n ij ! K ! Finally, P a is the average agreement over objects: P a = N i=1 is 0.0 when the agreement is what one would expect under independence, and it is 1.0 when the agreement is exact <ref> (Hays, 1988) </ref>. A value of 0.8 or greater indicates a high level of reliability among raters, with values between 0.67 and 0.8 indicating only moderate agreement (Hirschberg & Nakatani, 1996; Carletta, 1996).
Reference: <author> Hirschberg, J., & Nakatani, C. </author> <year> (1996). </year> <title> A prosodic analysis of discourse segments in direction-giving monologues. </title> <booktitle> In Proc. 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 286-293. </pages>
Reference: <author> Hobbs, J. </author> <year> (1978). </year> <title> Resolving pronoun references. </title> <journal> Lingua, </journal> <volume> 44, </volume> <pages> 311-338. </pages>
Reference: <author> Hwang, C., & Schubert, L. </author> <year> (1992). </year> <title> Tense trees as the "fine structure" of discourse. </title> <booktitle> In Proc. 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 232-240. </pages>
Reference: <author> Isard, A., & Carletta, J. </author> <year> (1995). </year> <title> Replicability of transaction and action coding in the map task corpus. </title> <booktitle> In Working Notes of AAAI Spring Symposium: Empirical Methods in Discourse Interpretation and Generation, </booktitle> <pages> pp. 60-66. </pages>
Reference: <author> Kameyama, M., Passonneau, R., & Poesio, M. </author> <year> (1993). </year> <title> Temporal centering. </title> <booktitle> In Proc. of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 70-77. </pages>
Reference: <author> Kamp, H., & Reyle, U. </author> <year> (1993). </year> <title> From Discourse to Logic. </title> <publisher> Kluwer Academic Publisher, </publisher> <address> Dordrecht, The Netherlands. </address>
Reference-contexts: In the second example, the beginning day of the interval representing the 3rd week of August is used as the frame of reference. Note that tense can influence the choice of whether to calculate a forward or backward time from a frame of reference <ref> (Kamp & Reyle, 1993) </ref>, but this is not accounted for because there is not much tense variation in the CMU corpus on which the algorithm was developed. However, errors can occur because backward calculations are not covered.
Reference: <author> Lascarides, A., Asher, N., & Oberlander, J. </author> <year> (1992). </year> <title> Inferring discourse relations in context. </title> <booktitle> In Proc. 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 1-8. </pages>
Reference: <author> Lavie, A., & Tomita, M. </author> <year> (1993). </year> <title> GLR* an efficient noise skipping parsing algorithm for context free grammars. </title> <booktitle> In Proc. 3rd International Workshop on Parsing Technologies. </booktitle>
Reference: <author> Levin, L., Glickman, O., Qu, Y., Gates, D., Lavie, A., Rose, C., Van Ess-Dykema, C., & Waibel, A. </author> <year> (1995). </year> <title> Using context in the machine translation of spoken language. </title> <booktitle> In Proc. Theoretical and Methodological Issues in Machine Translation (TMI-95). </booktitle>
Reference: <author> Litman, D., & Passonneau, R. </author> <year> (1995). </year> <title> Combining multiple knowledge sources for discourse segmentation. </title> <booktitle> In Proc. 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 130-143. </pages>
Reference: <author> Mann, W., & Thompson, S. </author> <year> (1988). </year> <title> Rhetorical Structure Theory: Toward a functional theory of text organization. </title> <booktitle> Text, </booktitle> <volume> 8(3), </volume> <pages> 243-281. </pages>
Reference: <author> Mitkov, R., & Stys, M. </author> <year> (1997). </year> <title> Robust reference resolution with limited knowledge: high precision genre-specific approach for English and Polish. </title> <booktitle> In Recent Advances in Natural Language Processing (RANLP-97), </booktitle> <pages> pp. 74-81. </pages> <note> European Commission, DG XIII. </note>
Reference-contexts: We perform experiments without each component in turn, and then with none of them, to observe the impact on the system's performance. Such studies have been useful in developing practical methods for other kinds of anaphora resolution as well <ref> (see, for example, Mitkov & Stys, 1997) </ref>. Specifically, an experiment was performed testing each of the following variations. 1. The certainty factors of all of the rules are set to 1.
Reference: <author> Moser, M., & Moore, J. </author> <year> (1995). </year> <title> Investigating cue selection and placement in tutorial discourses. </title> <booktitle> In Proc. 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 130-143. </pages>
Reference: <author> Nakhimovsky, A. </author> <year> (1988). </year> <title> Aspect, aspectual class, and the temporal structure of narrative. </title> <journal> Computational Linguistics, </journal> <volume> 14(2), </volume> <pages> 29-43. </pages> <note> 291 Wiebe, </note> <author> O'Hara, Ohrstr om-Sandgren, & McKeever O'Hara, T., Wiebe, J., & Payne, K. </author> <year> (1997). </year> <title> Instructions for annotating temporal information in scheduling dialogs. </title> <type> Tech. rep. </type> <institution> MCCS-97-308, Computing Research Laboratory, New Mexico State University. </institution>
Reference: <author> Passonneau, R., & Litman, D. </author> <year> (1993). </year> <title> Intention-based segmentation: human reliability and correlation with linguistic cues. </title> <booktitle> In Proc. of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 148-155. </pages>
Reference: <author> Poesio, M., Vieira, R., & Teufel, S. </author> <year> (1997). </year> <title> Resolving bridging references in unrestricted text. In Proc. Workshop on Operational Factors in Practical, Robust Anaphora Resolution for Unrestricted Texts. </title> <booktitle> Association for Computational Linguistics. </booktitle>
Reference: <author> Qu, Y., Eugenio, B. D., Lavie, A., Levin, L., & Rose, C. </author> <year> (1996). </year> <title> Minimizing cumulative error in discourse context. </title> <booktitle> In ECAI Workshop Proceedings on Dialogue Processing in Spoken Language Systems. </booktitle>
Reference-contexts: Specifically, it produces a sequence of Augmented ILTs for each input sequence, and then chooses the best sequence as its final interpretation of the corresponding utterances. In this way, the input ambiguity is resolved as a function of finding the best temporal interpretations of the utterance sequences in context <ref> (as suggested by Qu et al., 1996) </ref>. However, the number of alternative sequences of ILTs for a set of utterances can be prohibitively large for our system.
Reference: <author> Rose, C., Eugenio, B. D., Levin, L., & Van Ess-Dykema, C. </author> <year> (1995). </year> <title> Discourse processing of dialogues with multiple threads. </title> <booktitle> In Proc. 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pp. 31-38. </pages>
Reference-contexts: All of the ILT representations produced for an utterance are input to the discourse processor, which produces the final, unambiguous representation of that utterance. This representation is called an augmented ILT. The discourse processor can be configured to be our system alone, a plan-based discourse processor developed at CMU <ref> (Rose et al., 1995) </ref>, or the two working together in integrated mode. The main results, presented in Tables 2 and 3 in Section 6, are for our system working alone, taking as input the ambiguous output of the semantic parser. <p> me. (12) How is the next week? (13) If all else fails there is always video conferencing. (14) S1: Monday, Tuesday, and Wednesday I am out of town. (15) But Thursday and Friday are both good. (16) How about Thursday at twelve? (17) S2: Sounds good. (18) See you then. <ref> (Rose et al., 1995, p. 32) </ref> interpret T U 4 . There are no realizations of this structure, in terms of our model, in either the NMSU or CMU training data set. <p> Figure 16 is an extended example, and Figure 17 contains a simplified example which they analyze in greater detail. The passage in Figure 16 would be processed by our algorithm as follows. The dialog date is not given in <ref> (Rose et al., 1995) </ref>. For concreteness, let us suppose that the dialog date is Friday 11 April. Then, next week is Monday 14 April through Friday 18 April (the dialog does not mention weekend days, so we exclude them for ease of discussion). <p> Simple Stack Based Structure DS4 DS2 DS0 1. When can you meet next week? 2. Tuesday afternoon looks good. 3. I could do it Wednesday morning too. 4. Tuesday I have a class from 12:00-1:30. 5. But the other day sounds good. B. Graph-Structured Stack Structure DSE DSC DSA <ref> (Rose et al., 1995, p. 33) </ref> 280 An Empirical Approach to Temporal Reference Resolution (i.e., "the other" "day"j"month"j"year"; see Anaphoric Rule 7 in Online Appendix 1). In this case, the second most recent day, month, or year, as appropriate, is the candidate antecedent.
Reference: <author> Shum, B., Levin, L., Coccaro, N., Carbonell, J., Horiguchi, K., Isotani, H., Lavie, A., Mayfield, L., Rose, C., Van Ess-Dykema, C., & Waibel, A. </author> <year> (1994). </year> <title> Speech-language integration in a multi-lingual speech translation system. </title> <booktitle> In Proceedings of the AAAI Workshop on Integration of Natural Language and Speech Processing. </booktitle>
Reference-contexts: In fact, the Enthusiast researchers have already developed better techniques for resolving the semantic ambiguity in these dialogs <ref> (Shum et al., 1994) </ref>. Because the ILT representation was designed to support various projects in discourse, semantic interpretation, and machine translation, the representation produced by the semantic parser is much richer than is required for our temporal reference resolution algorithm. <p> The only information we use to perform semantic disambiguation is the temporal context. The Enthusiast researchers have 288 An Empirical Approach to Temporal Reference Resolution already developed better techniques for resolving the semantic ambiguity in these dialogs <ref> (Shum et al., 1994) </ref>, which could be used to improve performance. Thus, in the model evaluation and analysis phase, we performed extensive additional evaluation of the algorithm itself. We focus on the relations and the focus model, because they are the main contributions of this work.
Reference: <author> Sidner, C. </author> <year> (1979). </year> <title> Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. </title> <type> Ph.D. thesis, </type> <institution> MIT. </institution>
Reference: <author> Sidner, C. </author> <year> (1983). </year> <title> Focusing in the comprehension of definite anaphora. </title> <editor> In Brady, M., & Berwick, R. C. (Eds.), </editor> <booktitle> Computational Models of Discourse, </booktitle> <pages> pp. 267-330. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Siegel, S., & Castellan, Jr., N. J. </author> <year> (1988). </year> <title> Nonparametric Statistics for the Behavioral Sciences (Second edition). </title> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference-contexts: Pa and Pe are calculated as follows <ref> (Siegel & Castellan, 1988) </ref>. Suppose that there are N objects, M classes, and K taggers. We have the following definitions. * n ij is the number of assignments of object i to category j. Thus, for each i, P M K.
Reference: <author> Song, F., & Cohen, R. </author> <year> (1991). </year> <title> Tense interpretation in the context of narrative. </title> <booktitle> In Proc. 9th National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> pp. 131-136. </pages>
Reference: <author> Villa, D. </author> <year> (1994). </year> <title> Effects of protocol on discourse internal and external illocutionary markers in Spanish dialogs. </title> <booktitle> In Linguistic Association of the Southwest Conference XXIII. </booktitle>
Reference-contexts: This results in less dynamic interaction and longer turns <ref> (Villa, 1994) </ref>.
Reference: <author> Walker, L., & Moore, J. </author> <year> (1997). </year> <title> Empirical studies in discourse. </title> <journal> Computational Linguistics, </journal> <volume> 23(1), </volume> <pages> 1-12. </pages>
Reference-contexts: Recently, many in computational discourse processing have turned to empirical studies of discourse, with a goal to develop general theories by analyzing specific discourse phenomena and systems that process them <ref> (Walker & Moore, 1997) </ref>. We contribute to this general enterprise. We performed many different evaluations, on the CMU data upon which the model was developed, and on the more complex NMSU data. The task and model components were explicitly specified to facilitate evaluation and comparison.
Reference: <author> Walker, M. </author> <year> (1996). </year> <title> Limited attention and discourse structure. </title> <journal> Computational Linguistics, </journal> <volume> 22(2), </volume> <pages> 255-264. </pages>
Reference-contexts: An important discourse feature of the dialogs is the degree of redundancy of the times mentioned <ref> (Walker, 1996) </ref>. This limits the ambiguity of the times specified, and it also leads to a higher level of robustness, since additional Temporal Units with the same time are placed on the focus list and previously mentioned times are reintroduced. Table 6 presents measures of redundancy. <p> While the NMSU data is more complex, there are few cases in which the last mentioned time is not an appropriate antecedent, highlighting the importance of recency <ref> (Walker, 1996) </ref>; see Section 8.1. We characterized those cases along a number of dimensions, to identify the particular types of challenges they pose (see Figure 10).
Reference: <author> Webber, B. L. </author> <year> (1983). </year> <title> So what can we talk about now?. </title> <editor> In Brady, M., & Berwick, R. (Eds.), </editor> <title> Computational Models of Discourse. MIT Press, Cambridge. 292 An Empirical Approach to Temporal Reference Resolution Webber, </title> <editor> B. </editor> <year> (1988). </year> <title> Tense as discourse anaphor. </title> <journal> Computational Linguistics, </journal> <volume> 14(2), </volume> <pages> 61-73. </pages>
Reference-contexts: Examples are co-reference ("John saw Mary. He: : :"), part-whole ("John bought a car. The engine: : :"), and individual-class ("John bought a truck. They are good for hauling: : :") <ref> (see, for example, Webber, 1983) </ref>. The latter two involve bridging descriptions (see, for example, Clark, 1977; Heim, 1982; Poesio, Vieira, & Teufel, 1997): some reasoning is required to infer the correct interpretation.
Reference: <author> Wiebe, J., Farwell, D., Villa, D., Chen, J.-L., Sinclair, R., Sandgren, T., Stein, G., Zarazua, D., & O'Hara, T. </author> <year> (1996). </year> <title> Artwork: Discourse processing in machine translation of dialog. </title> <type> Tech. rep. </type> <institution> MCCS-96-294, Computing Research Laboratory, New Mexico State University. </institution> <month> 293 </month>
References-found: 39

