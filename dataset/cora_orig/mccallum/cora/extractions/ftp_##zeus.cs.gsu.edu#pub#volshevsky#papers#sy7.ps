URL: ftp://zeus.cs.gsu.edu/pub/volshevsky/papers/sy7.ps
Refering-URL: http://www.cs.gsu.edu/~matvro/papers.html
Root-URL: http://www.cs.gsu.edu
Title: Bunch-Kaufman Pivoting for Partially Reconstructible Cauchy-like Matrices, with Applications to Toeplitz-like Linear Equations and to
Author: Thomas Kailath and Vadim Olshevsky 
Abstract: In an earlier paper [GKO95] we exploited the displacement structure of Cauchy-like matrices to derive for them a fast O(n 2 ) implementation of Gaussian elimination with partial pivoting. One application is to the rapid and numerically accurate solution of linear systems with Toeplitz-like coefficient matrices, based on the fact that the latter can be transformed into Cauchy-like matrices by using the Fast Fourier, Sine or Cosine Transforms. However symmetry is lost in the process, and the algorithm of [GKO95] is not optimal for Hermitian coefficient matrices. In this paper we present a new fast O(n 2 ) implementation of symmetric Gaussian elimination with partial diagonal pivoting for Hermitian Cauchy-like matrices, and show how to transform Hermitian Toeplitz-like matrices to Hermitian Cauchy-like matrices, obtaining algorithms that are now twice as fast as those in [GKO95]. Numerical experiments indicate that in order to obtain not only fast but also numerically accurate methods, it is advantageous to explore the important case in which the corresponding displacement operators have nontrivial kernels; this situation gives rise to what we call partially reconstructible matrices, which are introduced and studied in the present paper. We extend the transformation technique and the generalized Schur algorithms ( i.e., fast displacement-based implementations of Gaussian elimination ) to partially reconstructible matrices. We show by a variety of computed examples that the incorporation of diagonal pivoting methods leads to high accuracy. We focused in this paper on the design of new numerically reliable algorithms for Hermitian Toeplitz-like matrices. However, the proposed algorithms have other important applications; in particular, we briefly describe how they recursively solve a boundary interpolation problem for J-unitary rational matrix functions. 
Abstract-found: 1
Intro-found: 1
Reference: [AG90] <author> G.Ammar and P.Gader, </author> <title> New decompositions of the inverse of a Toeplitz matrix, Signal processing, Scattering and Operator Theory, and Numerical Methods, </title> <booktitle> Proc. Int. Symp. MTNS-89, </booktitle> <volume> vol. III, </volume> <pages> 421-428, </pages> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: We showed how partially reconstructible Toeplitz-like matrices can be efficiently transformed to partially reconstructible 1 Such a displacement equation was mentioned in the concluding remarks of the first "displacement" papers [KKM79a],[KKM79b] and it was recently closely studied in <ref> [AG90] </ref> and in [GO92]. In [GO94b] we used it to transform Cauchy-like matrices and Vandermonde-like matrices to Toeplitz-like matrices to speed-up matrix-vector multiplication. See also [BP94], p. 199, 200 for the presentation of these results of [GO94b]. 3 Cauchy-like matrices, while preserving a Hermitian structure.
Reference: [B71] <author> J.R.Bunch, </author> <title> Analysis of the diagonal pivoting method, </title> <note> SIAM J. Num. Anal., 8 (1971), 656 -680. </note>
Reference-contexts: so (P R 1 P fl ) 1;1 = r t;t else m = 2 and choose P so (P R 1 P fl ) 2;1 = r t;p end end The value of the constant ff = (1 + p 17)=8 is determined to bound the element growth [BK77], <ref> [B71] </ref>; this method was has been recently proven to be backward stable in [Hig95].
Reference: [B85] <author> J.Bunch, </author> <title> Stability of methods for solving Toeplitz systems of equations, </title> <journal> SIAM J. of Matrix Analysis, </journal> <volume> 6 (1985), </volume> <pages> 349-364. </pages>
Reference-contexts: 1 Introduction Toeplitz linear systems. Linear systems of equations with Hermitian Toeplitz coefficient ma trices of the form T = h i appear in a variety of applications in the sciences and engi neering; a partial list can be found in <ref> [B85] </ref>. They can be rapidly solved in only O (n 2 ) operations by the well-known Levinson and Schur algorithms, which however often produce very inaccurate results for indefinite matrices.
Reference: [BBHS95] <author> A.W.Bojanczyk, R.P.Brent, F.R. de Hoog and D.R.Sweet, </author> <title> On the stability of the Bareiss and related Toeplitz factorization algorithms, </title> <journal> SIAM J. on Matrix Analysis Appl., </journal> <month> 16No.1 </month> <year> (1995). </year>
Reference-contexts: disc-C+BKP 1.2e-07 8.5e-08 1.6e-07 2.7e-07 7.2e-07 3.1e-07 9.3e-07 cont-C+SP 8.8e-08 5.2e-08 1.8e-07 1.6e-07 3.0e-07 3.3e-07 4.3e-07 disc-C+SP 1.5e-07 5.4e-08 2.0e-07 2.8e-07 1.1e-07 6.1e-07 7.1e-07 The analysis of the data in Tables 6-9 suggests the following conclusions for positive definite Toeplitz matrices. * Tables 6, 8 confirm the analytical results of <ref> [BBHS95] </ref> on the backward stability of the classical Schur algorithm 4 . <p> Moreover the data on the Levinson algorithm in Table 6 for n &gt; 130 and in Table 8 suggest that if the reflection coefficients are of both signs, 4 See also [GKO95] for a numerical example showing some limitations of the results of <ref> [BBHS95] </ref>, which in fact are only valid for not extremely ill-conditioned matrices. 21 then not only the residual, but also the corresponding backward error, for this algorithm is larger than the one of the standard GEPP and SGEBKP.
Reference: [BGR90] <author> J. Ball, I.Gohberg and L.Rodman, </author> <title> Interpolation of rational matrix functions, </title> <publisher> OT45, Birkhauser Verlag, </publisher> <address> Basel, </address> <year> 1990. </year>
Reference: [BGR91] <author> J. Ball, I.Gohberg and L.Rodman, </author> <title> Boundary Nevanlinna-Pick Interpolation for Rational Matrix Functions, </title> <journal> J. of Mathematical Systems, Estimation and Control, </journal> <volume> 1 No 2. </volume> <year> (1991), </year> <pages> 131-164. </pages>
Reference-contexts: For example, partially reconstructible Cauchy-like matrices appear in the context of the boundary homogeneous interpolation problem for J -unitary rational matrix functions, which in turn parameterizes all solutions for boundary non-homogeneous interpolation problems with norm constraints, including the classical boundary Nevanlinna-Pick matricial interpolation problem, see <ref> [BGR91] </ref>. The fast SGEBKP algorithms for Cauchy-like matrices of this paper suggest a recursive and computationally efficient solution to the above interpolation problems, over the right-half plane and over the unit disk. Contents. The paper is structured as follows. <p> However these algorithms also have other important applications in the framework of rational matrix interpolation theory. We shall pursue the full details elsewhere, but it seems to be important and instructive to reveal these connections and to briefly outline the main points here. It is known ( see <ref> [BGR91] </ref> ) that many boundary rational matrix interpolation problems with norm constraints, including the celebrated boundary matrix Nevanlinna-Pick interpolation problem, can be reduced to the construction of a rational matrix function fi (z) that is J -unitary on the imaginary axis, i.e., for those z 2 iR that are not poles <p> In this situation fi (z) is no longer analytic at fa k g, so the interpolation conditions have to be captured by the more delicate and more general formulation used in (7.2). The solution of the above boundary homogeneous matrix interpolation problem ( as given, e.g., in <ref> [BGR91] </ref> ), can be formulated in our language as follows. <p> The solution is now reduced to finding a rational matrix function (z) that is now J -unitary on the unit circle, i.e., 26 for those jzj = 1 that are not poles of fi (z). The solution for such problem is given by the global state-space formula <ref> [BGR91] </ref> (z) = [I J G fl 1 F fl where D ff = I J G fl 1 (I ffF fl ff is any number on the unit circle such that (I ffF fl 1 ) is nonsingular, and R 1 is a nonsingular partially reconstructable Cauchy-like matrix, satisfying a
Reference: [BH94] <author> A.Bojanczyk and G.Heinig, </author> <title> A multi-step algorithm for Hankel matrices, </title> <journal> J. of Complexity, </journal> <year> 1994. </year>
Reference-contexts: Recently look-ahead approaches have been suggested to overcome the above difficulty by exploring (look-ahead) steps in which one jumps from one well-conditioned submatrix to another; several versions of look-ahead Levinson and Schur algorithms have been designed, see, e.g. [CH92], [FZ93], [GH94], <ref> [BH94] </ref> and references therein. However the arithmetic complexity of these algorithms depends upon the number of ill-conditioned leading submatrices, and in the worst case one has to perform O (n 3 ) arithmetic operations, thus losing superiority in speed over the standard algorithms.
Reference: [BK77] <author> J.R.Bunch and L.Kaufman, </author> <title> Some stable methods for calculating inertia and solving symmetric linear systems, </title> <journal> Math. Comp., </journal> <volume> 31, 162 - 179. </volume>
Reference-contexts: OE G) J (F D OE G) fl : (1.7) Then instead of fast GEPP ( exploited in the GKO algorithm ), which would destroy the Hermitian character of F D OE RD fl OE F fl , we could now implement a (symmetric) Gaussian elimination algorithm with Bunch-Kaufman pivoting <ref> [BK77] </ref>. The Bunch-Kaufman scheme is a symmetry-preserving partial pivoting technique for general Hermitian matrices, and it is the algorithm of choice in LAPACK, which is renowned for the numerical reliability of the algorithms recommended. <p> P so (P R 1 P fl ) 1;1 = r t;t else m = 2 and choose P so (P R 1 P fl ) 2;1 = r t;p end end The value of the constant ff = (1 + p 17)=8 is determined to bound the element growth <ref> [BK77] </ref>, [B71]; this method was has been recently proven to be backward stable in [Hig95].
Reference: [BP71] <author> J.R.Bunch and B.Parlett, </author> <title> Direct methods for solving symmetric indefinite systems of linear equations, </title> <journal> SIAM J. Num. Anal., </journal> <volume> 8(1971), 639 - 655. </volume>
Reference-contexts: The key question here is how many entries of R 1 have to be examined to decide on the permutation. For example, in the Bunch-Parlett scheme <ref> [BP71] </ref> one has to scan all n (n + 1)=2 entries of the n fi n symmetric matrix, so the overall complexity of the algorithm would jump to O (n 3 ) operations.
Reference: [BP94] <author> D.Bini and V.Pan, </author> <title> Polynomial and Matrix Computations, Volume 1, </title> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1994. </year>
Reference-contexts: In [GO94b] we used it to transform Cauchy-like matrices and Vandermonde-like matrices to Toeplitz-like matrices to speed-up matrix-vector multiplication. See also <ref> [BP94] </ref>, p. 199, 200 for the presentation of these results of [GO94b]. 3 Cauchy-like matrices, while preserving a Hermitian structure.
Reference: [C80] <author> G.Cybenko, </author> <title> The numerical stability of Levinson-Durbin algorithm for Toeplitz systems of equations, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 1 (1980), 303 - 319. </volume>
Reference-contexts: Cybenko proved in <ref> [C80] </ref> that if the reflection coefficients belong to the smaller interval (0,1) then the Levinson algorithm is guaranteed to produce a residual comparable to the one of stable Cholesky factorization.
Reference: [C88] <author> T.Chan, </author> <title> An optimal circulant preconditioner for Toeplitz systems, </title> <journal> SIAM J. Sci. Stat. Comput. </journal> <volume> 9 (4) (1988), 166 - 771. </volume>
Reference-contexts: Such approximants are often used as preconditioners in iterative methods. For example, when R = t ij is a Toeplitz matrix, then (2.10) reduces to the well-known example <ref> [C88] </ref> : c i = n 2.4. Partially reconstructible Cauchy-like matrices.
Reference: [CH92] <author> T.Chan and P.Hansen, </author> <title> A look-ahead Levinson algorithm for indefinite l Toeplitz systems, </title> <journal> SIAM J. on Matrix Anal. and Appl., </journal> <volume> 13(1992), </volume> <pages> 1079-1090. </pages>
Reference-contexts: Recently look-ahead approaches have been suggested to overcome the above difficulty by exploring (look-ahead) steps in which one jumps from one well-conditioned submatrix to another; several versions of look-ahead Levinson and Schur algorithms have been designed, see, e.g. <ref> [CH92] </ref>, [FZ93], [GH94], [BH94] and references therein. However the arithmetic complexity of these algorithms depends upon the number of ill-conditioned leading submatrices, and in the worst case one has to perform O (n 3 ) arithmetic operations, thus losing superiority in speed over the standard algorithms.
Reference: [CK91] <author> J.Chun and T.Kailath, </author> <title> Displacement structure for Hankel, Vandermonde and related (derived) matrices, </title> <journal> Linear Algebra Appl., </journal> <volume> 151(1991), </volume> <pages> 199-227. </pages>
Reference-contexts: In the literature on displacement structure, the operator r F () in (2.1) is generally assumed to be invertible, so that the r F -generator fG; Jg contains all the information on R. However, displacement equations with a kernel (nullspace) of low dimension appear in certain problems, see, e.g., <ref> [CK91] </ref>, [GO94a]. The task addressed in the present paper, i.e., a fast and accurate implementation of symmetric Gaussian elimination with diagonal pivoting for Cauchy-like matrices, which can be then utilized for Toeplitz-like matrices, exhibits another case where one gains by considering a displacement equation with a nontrivial kernel.
Reference: [CKLA87] <author> J.Chun, T.Kailath and H.Lev-Ari, </author> <title> Fast parallel algorithms for QR and triangular factorization, </title> <journal> SIAM J. Sci.Stat. Comput., </journal> <volume> 8 (1987), 899 - 913. </volume>
Reference-contexts: Some concluding remarks are presented in the last section. 2 Discrete-time Lyapunov displacement operators 2.1. Displacement structure. Let F be a given n fi n matrix. Following <ref> [CKLA87] </ref>, introduce in the linear space C nfin of all nfin complex matrices the displacement operator r F () : C nfin ! C nfin by where the superscript fl stands for conjugate transpose.
Reference: [D79] <author> P. Davis, </author> <title> Circulant Matrices, </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: As is well known, any circulant matrix is diagonalized by the Discrete Fourier matrix, and moreover, diag (d) = F Circ (c) F fl , see, e.g. , <ref> [D79] </ref>.
Reference: [DD84] <author> P.Dewilde and H.Dym, </author> <title> Lossless inverse scattering, digital filters, and estimation theory, </title> <journal> IEEE Transactions on Information Theory, IT-30, </journal> <volume> No. 4 (1984), 644 - 661. </volume> <pages> 29 </pages>
Reference-contexts: fl 1 ae 1 The quantities fa 1 ; ' 1 ; ae 1 g appearing in (7.11) are simply borrowed from (7.5), so that a 1 2 iR, and ' 1 is a J -neutral vector; such factors (7.11) are called Brune sections in the engineering literature, see, e.g., <ref> [DD84] </ref>.
Reference: [FZ93] <author> R.Freund and H.Zha, </author> <title> A look-ahead strategy for the solution of general Hankel systems, </title> <journal> Numerische Mathematik, </journal> <volume> 64, </volume> <year> (1993), </year> <pages> 295-322. </pages>
Reference-contexts: Recently look-ahead approaches have been suggested to overcome the above difficulty by exploring (look-ahead) steps in which one jumps from one well-conditioned submatrix to another; several versions of look-ahead Levinson and Schur algorithms have been designed, see, e.g. [CH92], <ref> [FZ93] </ref>, [GH94], [BH94] and references therein. However the arithmetic complexity of these algorithms depends upon the number of ill-conditioned leading submatrices, and in the worst case one has to perform O (n 3 ) arithmetic operations, thus losing superiority in speed over the standard algorithms.
Reference: [G95] <author> Ming Gu, </author> <title> Stable and efficient algorithms for structured systems of linear equations, </title> <type> preprint, </type> <year> 1995. </year>
Reference-contexts: However current experiments do not reveal actual examples of Toeplitz matrices for which such generator growth does indeed occur; finding such an example would indicate that the bound of [SB95] is tight. Moreover in <ref> [G95] </ref>, Ming Gu showed how potential generator growth can be suppressed by incorporation into the GKO algorithm of steps consisting of QR factorization of the generator, at the expense of O (n 2 ) additional operations. <p> Finally we note that it is likely that the results of [SB95] ( which contains a general methodology for the error analysis of the GKO-like algorithms ) and of <ref> [G95] </ref> can be extended to partially reconstructable matrices and to the new Toeplitz solvers proposed in the present paper, a useful topic for further investigation. Acknowledgment.
Reference: [GH94] <author> M.Gutknecht and M.Hochbruck, </author> <title> Look-ahead Levinson and Schur recurrences in the Pad'e table, </title> <journal> Electronic Transactions on Numerical Analysis, </journal> <volume> 2 (1994), </volume> <pages> 104-129. </pages>
Reference-contexts: Recently look-ahead approaches have been suggested to overcome the above difficulty by exploring (look-ahead) steps in which one jumps from one well-conditioned submatrix to another; several versions of look-ahead Levinson and Schur algorithms have been designed, see, e.g. [CH92], [FZ93], <ref> [GH94] </ref>, [BH94] and references therein. However the arithmetic complexity of these algorithms depends upon the number of ill-conditioned leading submatrices, and in the worst case one has to perform O (n 3 ) arithmetic operations, thus losing superiority in speed over the standard algorithms.
Reference: [GO92] <author> I.Gohberg and V.Olshevsky, Circulants, </author> <title> displacements and decompositions of matrices, Integral Equations and Operator Theory, </title> <journal> 15, </journal> <volume> No. </volume> <month> 5 </month> <year> (1992), </year> <note> 730 -743. </note>
Reference-contexts: We showed how partially reconstructible Toeplitz-like matrices can be efficiently transformed to partially reconstructible 1 Such a displacement equation was mentioned in the concluding remarks of the first "displacement" papers [KKM79a],[KKM79b] and it was recently closely studied in [AG90] and in <ref> [GO92] </ref>. In [GO94b] we used it to transform Cauchy-like matrices and Vandermonde-like matrices to Toeplitz-like matrices to speed-up matrix-vector multiplication. See also [BP94], p. 199, 200 for the presentation of these results of [GO94b]. 3 Cauchy-like matrices, while preserving a Hermitian structure. <p> As is well known ( see, e.g., <ref> [GO92] </ref> ), the kernel of r Z 1 () in (2.6) is the subspace of all circulants, i.e., C = fCirc (c) : c 2 C n nfin where Circ (c) = 2 6 6 c 0 c n1 c 2 c 1 . . . . . . . .
Reference: [GO94a] <author> I.Gohberg and V.Olshevsky, </author> <title> Fast state space algorithms for matrix Nehari and Nehari-Takagi interpolation problems, Integral Equations and Operator Theory, </title> <journal> 20, </journal> <volume> No. 1 (1994), 44 - 83. </volume>
Reference-contexts: However, displacement equations with a kernel (nullspace) of low dimension appear in certain problems, see, e.g., [CK91], <ref> [GO94a] </ref>. The task addressed in the present paper, i.e., a fast and accurate implementation of symmetric Gaussian elimination with diagonal pivoting for Cauchy-like matrices, which can be then utilized for Toeplitz-like matrices, exhibits another case where one gains by considering a displacement equation with a nontrivial kernel. <p> For our purposes in the present paper the numbers f i are assumed to be on the unit circle ( the case of arbitrary f i is studied, for example, in [HR84], <ref> [GO94a] </ref>, [GKO95] ). It is a trivial exercise to check that the kernel of r D f () in (2.12) ) is the subspace D = fdiag (f ) : f 2 C n nfin of all diagonal matrices 2 . <p> With these notations the following statement holds. 2 Partially reconstructible Cauchy-like matrices appear in certain tangential rational matrix interpolation problems, where the presence of nontrivial kernel of r F () means that the corresponding ff fi ff rational matrix function shares poles and zeros at the same points; see, e.g., <ref> [GO94a] </ref>. 7 Lemma 2.5 Let Z 1 ; D 1 2 C nfin be as in (2.14), and let R = h i 2 C nfin be a partially reconstructible Toeplitz-like matrix, given by a r Z 1 -generator fG r Z 1 ; J; Circ (c)g, i.e., r Z 1 <p> In the next two subsections these steps are specified for continuous-time Lyapunov and discrete-time Lyapunov displacement operators. 4.2. Generalized Schur algorithms for partially reconstructable matrices, defined via continuous-time Lyapunov displacement equation. The following lemma from <ref> [GO94a] </ref>, [GKO95] is the basis for generalized Schur algorithms corresponding to partially reconstructable matrices, defined via continuous-time Lyapunov displacement operators. <p> At each step the Bunch-Kaufman algorithm scans only two columns of the matrix R 1 = h i to determine the size m ( i.e., 1 or 2 ) of R 11 and the permutation matrix P 1 in (4.1)). To understand 3 In <ref> [GO94a] </ref> an interpretation of partial and diagonal pivoting techniques is given in terms of a reordering of the interpolation points ( i.e., the poles and zeros) for a rational ff fi ff matrix function corresponding to the partially reconstructable Cauchy-like matrix, cf., e.g., the footnote in section 2.2. 17 the Bunch-Kaufman <p> To this end recall that the continuous-Cauchy algorithm in both cases m = 1 and m = 2 computes the 4 A 2 -generator fG 2 ; J; d 2 g of the Schur complement R 2 . As was shown in <ref> [GO94a] </ref>, the J-unitary quotient W 1 (z) is given by W 1 (z) = I J G fl 2 G 2 ; (7.13) Since fG 2 ; J; d 2 g is an input of the second recursive step of the continuous-Cauchy algorithm, the latter further computes the factorization W 1 <p> Though all theoretically equivalent, these decompositions have different numerical properties. Moreover, because the reordering of interpolation data fa k ; ' k ; ae k g is equivalent to row and column permutation of a partially reconstructable Cauchy-like matrix R 1 P R 1 P T ( cf. with <ref> [GO94a] </ref> ), the continuous-Cauchy algorithm combined with Bunch-Kaufman pivoting suggests not only a recursive, but also an accurate, solution for the above boundary homogeneous interpolation problem for J -unitary rational matrix function. 7.4. Discrete-time case.
Reference: [GO94b] <author> I.Gohberg and V.Olshevsky, </author> <title> Complexity of multiplication with vectors for structured matrices, </title> <journal> Linear Algebra Appl., </journal> <volume> 202 (1994), 163 - 192. </volume>
Reference-contexts: An alternative fast and stable algorithm was recently developed in [GKO95], based on the transformation of a Toeplitz-like matrix to a Cauchy-like matrix (cf. [P90], <ref> [GO94b] </ref>, [H95a]), followed by a fast implementation of Gaussian elimination with partial pivoting ( fast GEPP ) for the resulting Cauchy-like matrix. A large set of numerical experiments in [GKO95] showed that the GKO algorithm has reliable numerical behavior, and can be recommended for solving large indefinite Toeplitz-like systems. <p> The development of the GKO algorithm is based on the well-known fact that Z OE is diagonalized by the (scaled) Discrete Fourier transform matrix F , i.e., Z OE = D 1 2 where fl OE and D OE are certain diagonal matrices. Therefore the transformation ( cf. [P90], <ref> [GO94b] </ref>, [H95a], [GKO95] ) of a Toeplitz-like matrix R in (1.2) into a Cauchy-like matrix F RD 1 F fl is reduced to just performing 2ff FFT's on the columns of fG; Bg : fl 1 (F RD 1 1 F fl ) fl 1 = (F G) (F D 1 <p> We showed how partially reconstructible Toeplitz-like matrices can be efficiently transformed to partially reconstructible 1 Such a displacement equation was mentioned in the concluding remarks of the first "displacement" papers [KKM79a],[KKM79b] and it was recently closely studied in [AG90] and in [GO92]. In <ref> [GO94b] </ref> we used it to transform Cauchy-like matrices and Vandermonde-like matrices to Toeplitz-like matrices to speed-up matrix-vector multiplication. See also [BP94], p. 199, 200 for the presentation of these results of [GO94b]. 3 Cauchy-like matrices, while preserving a Hermitian structure. <p> In <ref> [GO94b] </ref> we used it to transform Cauchy-like matrices and Vandermonde-like matrices to Toeplitz-like matrices to speed-up matrix-vector multiplication. See also [BP94], p. 199, 200 for the presentation of these results of [GO94b]. 3 Cauchy-like matrices, while preserving a Hermitian structure.
Reference: [GKO95] <author> I.Gohberg, T.Kailath and V.Olshevsky, </author> <title> Fast Gaussian elimination with partial pivoting for matrices with displacement structure, </title> <journal> Math. of Computation, </journal> <volume> 64 (1995), </volume> <pages> 1557-1576. </pages>
Reference-contexts: However the arithmetic complexity of these algorithms depends upon the number of ill-conditioned leading submatrices, and in the worst case one has to perform O (n 3 ) arithmetic operations, thus losing superiority in speed over the standard algorithms. An alternative fast and stable algorithm was recently developed in <ref> [GKO95] </ref>, based on the transformation of a Toeplitz-like matrix to a Cauchy-like matrix (cf. [P90], [GO94b], [H95a]), followed by a fast implementation of Gaussian elimination with partial pivoting ( fast GEPP ) for the resulting Cauchy-like matrix. A large set of numerical experiments in [GKO95] showed that the GKO algorithm has <p> stable algorithm was recently developed in <ref> [GKO95] </ref>, based on the transformation of a Toeplitz-like matrix to a Cauchy-like matrix (cf. [P90], [GO94b], [H95a]), followed by a fast implementation of Gaussian elimination with partial pivoting ( fast GEPP ) for the resulting Cauchy-like matrix. A large set of numerical experiments in [GKO95] showed that the GKO algorithm has reliable numerical behavior, and can be recommended for solving large indefinite Toeplitz-like systems. Because of its importance in the sequel, we shall briefly review the GKO algorithm here; however before doing so we introduce the necessary notations, see, e.g., the recent review [KS95]. <p> Therefore the transformation ( cf. [P90], [GO94b], [H95a], <ref> [GKO95] </ref> ) of a Toeplitz-like matrix R in (1.2) into a Cauchy-like matrix F RD 1 F fl is reduced to just performing 2ff FFT's on the columns of fG; Bg : fl 1 (F RD 1 1 F fl ) fl 1 = (F G) (F D 1 B) fl <p> For our purposes in the present paper the numbers f i are assumed to be on the unit circle ( the case of arbitrary f i is studied, for example, in [HR84], [GO94a], <ref> [GKO95] </ref> ). It is a trivial exercise to check that the kernel of r D f () in (2.12) ) is the subspace D = fdiag (f ) : f 2 C n nfin of all diagonal matrices 2 . <p> It turns out that Toeplitz-like, Hankel-like, Toeplitz-plus-Hankel-like, Vandermonde-like and Chebyshev-Vandermonde-like matrices can all be transformed into Cauchy-like matrices by applying the Fast Fourier, Cosine or Sine transforms to the columns of their generators, see, e.g., <ref> [GKO95] </ref>, [KO95] for the details. In particular, the transformation to a Cauchy-like matrix allowed us to design in [GKO95] a new fast and accurate Toeplitz solver. However the symmetry of the matrix was lost in the process. <p> that Toeplitz-like, Hankel-like, Toeplitz-plus-Hankel-like, Vandermonde-like and Chebyshev-Vandermonde-like matrices can all be transformed into Cauchy-like matrices by applying the Fast Fourier, Cosine or Sine transforms to the columns of their generators, see, e.g., <ref> [GKO95] </ref>, [KO95] for the details. In particular, the transformation to a Cauchy-like matrix allowed us to design in [GKO95] a new fast and accurate Toeplitz solver. However the symmetry of the matrix was lost in the process. <p> In the next two subsections these steps are specified for continuous-time Lyapunov and discrete-time Lyapunov displacement operators. 4.2. Generalized Schur algorithms for partially reconstructable matrices, defined via continuous-time Lyapunov displacement equation. The following lemma from [GO94a], <ref> [GKO95] </ref> is the basis for generalized Schur algorithms corresponding to partially reconstructable matrices, defined via continuous-time Lyapunov displacement operators. <p> Levinson O (n 2 ) The classical Levinson algorithm. Schur O (n 2 ) The classical Schur algorithm for positive definite Toeplitz matrices, or its immediate modification to compute the LDL fl factorization for indefinite Toeplitz matrices. GKO O (n 2 ) The algorithm of <ref> [GKO95] </ref>; transformation to a Cauchy-like matrix, and then running a fast GEPP. 18 Table 3. <p> Varah observed in [V93] that the Prolate matrix is an example where the reflection coefficients are of both signs ( so the Cybenko results are not applicable ), and where the Levinson algorithm produces a residual about 10 3 times larger than with the standard numerically stable algorithms. In <ref> [GKO95] </ref> we presented two more such examples with positive definite Toeplitz matrices with sign-alternating reflection coefficients, for which the Levinson algorithm pro duced large residuals. <p> The coefficient matrix in one of these examples was a Gaussian Toeplitz matrix, and the data in Table 9 on the residual error of the Levinson algorithm reinforce the conclusions of [V93] ( see also <ref> [GKO95] </ref> ). Moreover the data on the Levinson algorithm in Table 6 for n &gt; 130 and in Table 8 suggest that if the reflection coefficients are of both signs, 4 See also [GKO95] for a numerical example showing some limitations of the results of [BBHS95], which in fact are only <p> 9 on the residual error of the Levinson algorithm reinforce the conclusions of [V93] ( see also <ref> [GKO95] </ref> ). Moreover the data on the Levinson algorithm in Table 6 for n &gt; 130 and in Table 8 suggest that if the reflection coefficients are of both signs, 4 See also [GKO95] for a numerical example showing some limitations of the results of [BBHS95], which in fact are only valid for not extremely ill-conditioned matrices. 21 then not only the residual, but also the corresponding backward error, for this algorithm is larger than the one of the standard GEPP and SGEBKP. <p> 1.7e-06 1.1e-05 1.7e-06 4.1e-05 2.3e-04 2.5e-05 The analysis of the data in Table 10 suggest the following conclusions * Although the classical Levinson and Schur algorithms are much faster than GEPP and SGE BKP, they cannot provide the same accuracy for indefinite matrices. * The data confirm the observation of <ref> [GKO95] </ref> that the accuracy shown in practice by the GKO algorithm is about the same as the one of standard numerically stable methods. * Pivoting plays a profound role in achieving high accuracy with the disc-C and cont-C algorithms for indefinite Toeplitz matrices. <p> and discrete-Cauchy algorithms compute essentially the same cascade decompositions, which are related to each other via an appropriate change of variable ( i.e., via the Mobius transformation of the interior of the unit disk onto the right half plane, see Sec. 3 ). 8 Concluding remarks In an earlier paper <ref> [GKO95] </ref> we designed a fast O (n 2 ) Gaussian elimination with partial pivoting algorithm for Cauchy-like matrices, and as an application suggested a new fast Toeplitz-like solver GKO.
Reference: [GVL89] <author> G. Golub and C, Van Loan, </author> <title> Matrix Computations, </title> <note> second edition, </note> <author> John Hopkins U. P., Baltimore, </author> <year> 1989. </year>
Reference-contexts: Symmetric pivoting technique is useful with positive definite matrices, for which it is equivalent to complete pivoting <ref> [GVL89] </ref>, but clearly this method fails with indefinite matrices in the case of a zero main diagonal.
Reference: [H95a] <author> Heinig G. </author> <title> Inversion of generalized Cauchy matrices and other classes of structured matrices, </title> <booktitle> in : Linear Algebra in Signal Processing ( Proc. of IMA-92 Workshop on linear algebra in signal processing ), IMA volumes in Mathematics and its Applications, </booktitle> <volume> vol. 69 (1995), 95 - 114. </volume>
Reference-contexts: An alternative fast and stable algorithm was recently developed in [GKO95], based on the transformation of a Toeplitz-like matrix to a Cauchy-like matrix (cf. [P90], [GO94b], <ref> [H95a] </ref>), followed by a fast implementation of Gaussian elimination with partial pivoting ( fast GEPP ) for the resulting Cauchy-like matrix. A large set of numerical experiments in [GKO95] showed that the GKO algorithm has reliable numerical behavior, and can be recommended for solving large indefinite Toeplitz-like systems. <p> Therefore the transformation ( cf. [P90], [GO94b], <ref> [H95a] </ref>, [GKO95] ) of a Toeplitz-like matrix R in (1.2) into a Cauchy-like matrix F RD 1 F fl is reduced to just performing 2ff FFT's on the columns of fG; Bg : fl 1 (F RD 1 1 F fl ) fl 1 = (F G) (F D 1 B)
Reference: [H95b] <author> G.Heinig, </author> <title> Private communication, </title> <year> 1995. </year>
Reference-contexts: This allows us to incorporate the Bunch-Kaufman pivoting procedure, and to propose a group of algorithms applicable to indefinite Toeplitz-like matrices. Recently Georg Heinig informed us that Adam Bojanczyk and he are also pursuing a symmetry-exploiting transformation-and-pivoting algorithm <ref> [H95b] </ref>. 28
Reference: [HR84] <author> Heinig,G., Rost, K. </author> <year> (1984), </year> <title> Algebraic methods for Toeplitz-like matrices and operators, </title> <journal> Operator Theory, </journal> <volume> vol. 13, </volume> <publisher> Birkauser Verlag, Basel. </publisher>
Reference-contexts: For our purposes in the present paper the numbers f i are assumed to be on the unit circle ( the case of arbitrary f i is studied, for example, in <ref> [HR84] </ref>, [GO94a], [GKO95] ). It is a trivial exercise to check that the kernel of r D f () in (2.12) ) is the subspace D = fdiag (f ) : f 2 C n nfin of all diagonal matrices 2 .
Reference: [Hig95] <author> N.Higham, </author> <title> Stability of the diagonal pivoting method with partial pivoting, </title> <type> Preprint, </type> <year> 1995. </year>
Reference-contexts: = 2 and choose P so (P R 1 P fl ) 2;1 = r t;p end end The value of the constant ff = (1 + p 17)=8 is determined to bound the element growth [BK77], [B71]; this method was has been recently proven to be backward stable in <ref> [Hig95] </ref>.
Reference: [Hu95] <author> T.Huckle, </author> <title> Symmetric Gaussian elimination for Cauchy-like matrices with application to positive definite Toeplitz matrices, </title> <type> preprint, </type> <year> 1995. </year>
Reference-contexts: Acknowledgment. After the first 5 sections of this paper were finished, and we had performed numerical tests, the authors received from Thomas Huckle a preprint <ref> [Hu95] </ref>, which also presents a symmetry-preserving variant of the GKO algorithm. The scheme of [Hu95] transforms a symmetric Toeplitz ( but not any Toeplitz-like ) matrix to a Hermitian Cauchy-like matrix, for which it implements scalar elimination steps only. <p> Acknowledgment. After the first 5 sections of this paper were finished, and we had performed numerical tests, the authors received from Thomas Huckle a preprint <ref> [Hu95] </ref>, which also presents a symmetry-preserving variant of the GKO algorithm. The scheme of [Hu95] transforms a symmetric Toeplitz ( but not any Toeplitz-like ) matrix to a Hermitian Cauchy-like matrix, for which it implements scalar elimination steps only. For this reason, Huckle's algorithm is limited to positive definite Toeplitz matrices.
Reference: [K80] <author> T.Kailath, </author> <title> Linear systems, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1980. </year>
Reference-contexts: Proof. Both assertions follow from the identity 2 (o I F ) 1 (R F R F fl ) (o fl I F fl ) 1 = 2 This Lemma originates in the Mobius transformations between the unit disk and the right half plane, see, e.g., <ref> [K80] </ref>, p.180.
Reference: [KKM79a] <author> T.Kailath, S.Kung and M.Morf, </author> <title> Displacement ranks of matrices and linear equations, </title> <journal> J. Math. Anal. and Appl., </journal> <volume> 68 (1979), </volume> <pages> 395-407. </pages>
Reference: [KKM79b] <author> T.Kailath, S.Kung and M.Morf, </author> <title> Displacement ranks of matrices and linear equations, </title> <journal> Bull. Amer. Math. Society 1 (1979), </journal> <pages> 769-773. </pages>
Reference: [KO95] <author> T.Kailath and V.Olshevsky, </author> <title> Displacement structure approach to Chebyshev-Vander-monde and related matrices, Integral Equations and Operator Theory,22 (1995), </title> <publisher> 65-92.. </publisher>
Reference-contexts: It turns out that Toeplitz-like, Hankel-like, Toeplitz-plus-Hankel-like, Vandermonde-like and Chebyshev-Vandermonde-like matrices can all be transformed into Cauchy-like matrices by applying the Fast Fourier, Cosine or Sine transforms to the columns of their generators, see, e.g., [GKO95], <ref> [KO95] </ref> for the details. In particular, the transformation to a Cauchy-like matrix allowed us to design in [GKO95] a new fast and accurate Toeplitz solver. However the symmetry of the matrix was lost in the process.
Reference: [KS92] <author> T. Kailath and A.H.Sayed, </author> <title> Fast algorithms for generalized displacement structures, </title> <booktitle> in Recent advances in mathematical theory of systems, control, networks and signal processing II, Proc. of the MTNS-91 (H.Kimura, </booktitle> <editor> S.Kodama, Eds.), </editor> <publisher> Mita Press, </publisher> <address> Japan, </address> <year> 1992, </year> <pages> 27 - 32. </pages>
Reference: [KS95b] <author> T.Kailath and A.H.Sayed, </author> <title> A look-ahead block Schur algorithm for Toeplitz-like matrices, </title> <journal> SIAM J. of Matrix Analysis Appl., </journal> <volume> 16 (1995), </volume> <pages> 388-414. </pages>
Reference-contexts: The Lemma is now proved. 15 2 Formula (4.9) is a generalization of the result in <ref> [KS95b] </ref>, where it appeared for the case of invertible displacement operators r F (). 4.5. Generalized Schur algorithm for partially reconstructable Cauchy-like matrices, defined via a discrete-time Lyapunov displacement equation.
Reference: [KS95] <author> T.Kailath and A.H.Sayed, </author> <title> Displacement structure : Theory and Applications, </title> <journal> SIAM Review, </journal> <volume> 37 No.3 (1995), </volume> <pages> 297-386. </pages>
Reference-contexts: Because of its importance in the sequel, we shall briefly review the GKO algorithm here; however before doing so we introduce the necessary notations, see, e.g., the recent review <ref> [KS95] </ref>. Displacement structure. <p> We also showed that the displacement structure of partially reconstructible matrices is inherited by their Schur complements, and extended to partially reconstructible matrices the generalized Schur algorithms ( corresponding to discrete-time and continuous-time Lyapunov displacement operators, defined in Sec. 2 below ), for the usual theory see the review <ref> [KS95] </ref>. We showed that for partially reconstructible Cauchy-like matrices symmetric and Bunch-Kaufman pivoting can be adopted by these fast triangularization algorithms, thus leading to fast O (n 2 ) implementation of symmetric Gaussian elimination with Bunch-Kaufman pivoting ( fast SGEBKP ) for these matrices. <p> Algorithms of this type have been called generalized Schur algorithms, because the classical Schur algorithm [S17] belongs to the class (see <ref> [KS95] </ref>). In this section we allow the displacement equation to have a nontrivial kernel, and show that also in this case Schur complements inherit a displacement structure. We further extend the generalized Schur algorithms to partially reconstructable matrices defined via discrete-time (section 4.2), and continuous-time (section 4.1) Lyapunov displacement operators.
Reference: [LAPACK] <author> E.Anderson, Z.Bai, C.Bishof, J.Demmel, J.Dongarra, J. Du Croz, A.Greenbaum, S.Hammarling, A.McKenney, S.Ostrouchov and D.Sorensen, </author> <title> LAPACK User's Guide, Release 2.0, </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, USA, </address> <note> second edition, </note> <year> 1995. </year>
Reference-contexts: Moreover, even if the main diagonal will never become zero during elimination, symmetric pivoting cannot ensure stability, so the continuous-Cauchy and discrete-Cauchy algorithms with symmetric pivoting will likely break down numerically for indefinite matrices. 5.3. Bunch-Kaufman pivoting. This method is the one of choice in LAPACK <ref> [LAPACK] </ref>. At each step the Bunch-Kaufman algorithm scans only two columns of the matrix R 1 = h i to determine the size m ( i.e., 1 or 2 ) of R 11 and the permutation matrix P 1 in (4.1)).
Reference: [P90] <author> V.Pan, </author> <title> On computations with dense structured matrices, </title> <journal> Math. of Computation, </journal> <volume> 55, No. 191 (1990), 179 - 190. </volume>
Reference-contexts: An alternative fast and stable algorithm was recently developed in [GKO95], based on the transformation of a Toeplitz-like matrix to a Cauchy-like matrix (cf. <ref> [P90] </ref>, [GO94b], [H95a]), followed by a fast implementation of Gaussian elimination with partial pivoting ( fast GEPP ) for the resulting Cauchy-like matrix. A large set of numerical experiments in [GKO95] showed that the GKO algorithm has reliable numerical behavior, and can be recommended for solving large indefinite Toeplitz-like systems. <p> The development of the GKO algorithm is based on the well-known fact that Z OE is diagonalized by the (scaled) Discrete Fourier transform matrix F , i.e., Z OE = D 1 2 where fl OE and D OE are certain diagonal matrices. Therefore the transformation ( cf. <ref> [P90] </ref>, [GO94b], [H95a], [GKO95] ) of a Toeplitz-like matrix R in (1.2) into a Cauchy-like matrix F RD 1 F fl is reduced to just performing 2ff FFT's on the columns of fG; Bg : fl 1 (F RD 1 1 F fl ) fl 1 = (F G) (F D
Reference: [PD92] <author> J. Pasupathy and R.A. Damodar, </author> <title> The Gaussian Toeplitz matrix, </title> <journal> Linear Algebra and Appl., </journal> <volume> 171 (1992),133 - 147. </volume>
Reference-contexts: Example 2. Gaussian Toeplitz matrix. This matrix has the form T n = h i where t k = a k 2 0 &lt; a &lt; 1, with a close to 1. Background on such matrices can be found in <ref> [PD92] </ref>.
Reference: [SKLAC94] <author> A.H.Sayed, T.Kailath, H. Lev-Ari and T.Constantinescu, </author> <title> Recursive Solutions of Rational Interpolation Problems via Fast Matrix Factorization, Integral Equations and Operator Theory, </title> <booktitle> 20 (1994), </booktitle> <pages> 84-118. </pages>
Reference: [S17] <author> I.Schur, </author> <title> Uber potenzreihen die im Inneren des Einheitskreises beschrankt sind, </title> <journal> Journal fur die Reine und Angewandte Mathematik, </journal> <volume> 147 (1917), 205 - 232. </volume> <booktitle> English translation in Operator Theory : Advances and Applications (I.Gohberg. </booktitle> <editor> ed.), </editor> <volume> vol. 18, 31 - 88, </volume> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1986. </year>
Reference-contexts: Algorithms of this type have been called generalized Schur algorithms, because the classical Schur algorithm <ref> [S17] </ref> belongs to the class (see [KS95]). In this section we allow the displacement equation to have a nontrivial kernel, and show that also in this case Schur complements inherit a displacement structure.
Reference: [SB95] <author> D.Sweet and R.Brent, </author> <title> Error analysis of a partial pivoting method for structured matrices, </title> <booktitle> Advanced Signal processing algorithms, Proc of SPIE-1995, </booktitle> <volume> vol. 2563, </volume> <pages> 266-280. </pages>
Reference-contexts: A backward error analysis for the GKO algorithm appeared in <ref> [SB95] </ref>, where the bound for the backward error involved ( along with the usual element growth term ) a so-called generator growth term. <p> However current experiments do not reveal actual examples of Toeplitz matrices for which such generator growth does indeed occur; finding such an example would indicate that the bound of <ref> [SB95] </ref> is tight. Moreover in [G95], Ming Gu showed how potential generator growth can be suppressed by incorporation into the GKO algorithm of steps consisting of QR factorization of the generator, at the expense of O (n 2 ) additional operations. <p> An application of these algorithms combined with Bunch-Kaufman pivoting to accurate recursive solution of certain boundary homogeneous interpolation problem was described in Section 7. Finally we note that it is likely that the results of <ref> [SB95] </ref> ( which contains a general methodology for the error analysis of the GKO-like algorithms ) and of [G95] can be extended to partially reconstructable matrices and to the new Toeplitz solvers proposed in the present paper, a useful topic for further investigation. Acknowledgment.
Reference: [V93] <author> J.M. Varah, </author> <title> The Prolate Matrix, </title> <journal> Linear Algebra and Appl., </journal> <volume> 187 (1993), 269 - 278. </volume> <pages> 31 </pages>
Reference-contexts: Example 1. The prolate Toeplitz matrix. The prolate matrix is defined by T n = t ij 1n where t k = ( sin (2!k) k otherwise; (0 ! 2 Background on the prolate matrix can be found in <ref> [V93] </ref>; we mention here only that it possesses remarkable spectral and conditioning properties. For small !, its eigenvalues are clustered around 0 and 1, which makes it extremely ill-conditioned. <p> Cybenko proved in [C80] that if the reflection coefficients belong to the smaller interval (0,1) then the Levinson algorithm is guaranteed to produce a residual comparable to the one of stable Cholesky factorization. Varah observed in <ref> [V93] </ref> that the Prolate matrix is an example where the reflection coefficients are of both signs ( so the Cybenko results are not applicable ), and where the Levinson algorithm produces a residual about 10 3 times larger than with the standard numerically stable algorithms. <p> The coefficient matrix in one of these examples was a Gaussian Toeplitz matrix, and the data in Table 9 on the residual error of the Levinson algorithm reinforce the conclusions of <ref> [V93] </ref> ( see also [GKO95] ).
References-found: 44

