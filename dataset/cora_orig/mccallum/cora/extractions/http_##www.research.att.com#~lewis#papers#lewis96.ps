URL: http://www.research.att.com/~lewis/papers/lewis96.ps
Refering-URL: http://www.research.att.com/~lewis/chronobib.html
Root-URL: 
Title: Natural language processing for information retrieval  
Author: David D. Lewis Karen Sparck Jones 
Date: 92-101, January 1996.  
Note: A revised version of this manuscript appeared in Communications of the ACM, Vol. 39, No. 1, pp.  
Address: Cambridge  
Affiliation: AT&T Bell Laboratories  Computer Laboratory, University of  
Abstract: The paper summarizes the essential properties of document retrieval and reviews both conventional practice and research findings, the latter suggesting that simple statistical techniques can be effective. It then considers the new opportunities and challenges presented by the user's ability to search full text directly (rather than e.g. titles and abstracts), and suggests appropriate approaches to doing this, with a focus on the potential role of natural language processing. The paper also comments on possible connections with data and knowledge retrieval, and concludes by emphasizing the importance of rigorous performance testing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Buckley, C. </author> <title> The importance of proper weighting methods. </title> <booktitle> In ARPA Workshop on Human Language Technology (March 21-24, </booktitle> <address> Plainsboro, NJ). </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993, </year> <pages> pp. 349-352. </pages>
Reference-contexts: Weighing for phrases must be done differently than for single word terms, to allow for their lower frequency and different distributional characteristics, and is less well understood than for words <ref> [1, 7, 10] </ref>. Secondly, we have stressed the importance of late binding and sensitivity to the uncertainty of evidence. Compound terms will not be identified as definitely occurring or not occurring in a document. Rather, each document will provide some amount of evidence for the presence of each known concept. <p> Thus, NLP techniques are faced with the challenge that the basic methods of statistical IR have picked some of the easy fruit off the tree. The result is that, to date, choices among alternate statistical retrieval methods have had much more impact than choices among alternate text representations <ref> [1] </ref>. This should not discourage research into NLP applications in IR, but does suggest careful examination of where NLP is likely to have the most impact. Data retrieval Within IR we distinguish DR from other forms of retrieval.
Reference: [2] <author> Callan, J. P. and Croft, W. B. </author> <title> An evaluation of query processing strategies using the TIPSTER collection. </title> <booktitle> In Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (June 27 - July 1, </booktitle> <address> Pittsbrugh, PA). ACM/SIGIR, New York, </address> <year> 1993, </year> <pages> pp. 347-355. </pages>
Reference: [3] <author> Chinchor, N., Hirschman, L., and Lewis, D. D. </author> <title> Evaluating message understanding systems: An analysis of the Third Message Understanding Conference (MUC-3). </title> <booktitle> Computational Linguistics 19, 3 (1993), </booktitle> <pages> 409-449. </pages>
Reference-contexts: Some beginnings have been made in this area <ref> [3, 13, 18] </ref>, but chiefly in limited domains, and by taxing current NLP capabilities to their limits. Processing itself is also knowledge-heavy so for wider and larger files bootstrapping the lexicon, for instance, is needed.
Reference: [4] <author> Church, K. W. </author> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Second Conference on Applied Natural Language Processing (Feb. </booktitle> <pages> 9-12, </pages> <address> Austin, TX). </address> <publisher> ACL, </publisher> <address> Morristown, NJ, </address> <year> 1988, </year> <pages> pp. 136-143. </pages>
Reference-contexts: New approaches are also possible. Accurate and highly efficient syntactic taggers are available, and some compound terms, for instance head nouns and premodifiers, are easily extractable from tagged text <ref> [4] </ref>. A variety of strategies for finding important collocations in large corpora have been developed [29], and may provide an improvement over traditional IR methods for statistical phrase formation. Compound terms must not only be generated, but also selected among and weighted.
Reference: [5] <author> Copestake, A. and Sparck Jones, K. </author> <title> Natural language interfaces to databases. </title> <journal> The Knowledge Engineering Review 5, </journal> <volume> 4 (1990), </volume> <pages> 225-249. </pages>
Reference-contexts: Natural language access to databases, replacing the use of formal query languages, has been investigated for three decades and there are well-established commercial systems <ref> [5, 8] </ref>. Natural language clearly offers advantages in convenience and flexibility, but there are correspondingly major challenges in query interpretation, precisely because query expression is decoupled from search formulation.
Reference: [6] <author> Croft, W. B. and Das, R. </author> <title> Experiments with query acquisition and use in document retrieval systems. </title> <booktitle> In Proceedings of the Thirteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Sep. </booktitle> <pages> 5-7, </pages> <address> Brussels). ACM/SIGIR, New York, </address> <year> 1990, </year> <pages> pp. 349-365. </pages>
Reference-contexts: Thirdly and most important, many end users have little skill or experience in formulating initial search requests, or in modifying their requests after observing failures. Even when relevance feedback is available, it still needs to be leveraged from a sensible starting point <ref> [6] </ref>. Thus, while established research results show that natural language indexing and searching is effective to a degree, it is natural to ask whether it is possible to improve on the very simple strategies described earlier without increasing the load on the user.
Reference: [7] <author> Croft, W. B., Turtle, H. R., and Lewis, D. D. </author> <title> The use of phrases and structured queries in information retrieval. </title> <booktitle> In Proceedings of the Fourteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Oct. </booktitle> <pages> 13-16, </pages> <address> Chicago, IL). ACM/SIGIR, New York, </address> <year> 1991, </year> <pages> pp. 32-45. </pages>
Reference-contexts: Weighing for phrases must be done differently than for single word terms, to allow for their lower frequency and different distributional characteristics, and is less well understood than for words <ref> [1, 7, 10] </ref>. Secondly, we have stressed the importance of late binding and sensitivity to the uncertainty of evidence. Compound terms will not be identified as definitely occurring or not occurring in a document. Rather, each document will provide some amount of evidence for the presence of each known concept. <p> The occurrence of the two words in separate paragraphs would provide much less evidence, but more than the amount given by the presence of just one of the words, or of a related word <ref> [7, 32] </ref>. Thirdly, basic compound units of the type described above would not typically be further combined into frames, templates, or other structured units (unless knowledge retrieval, as discussed later, is to be supported). The description of a document would be an unordered set of `phrase' units and individual words.
Reference: [8] <author> Engelien, B. and McBryde, R. </author> <title> Natural Language Markets: Commercial Strategies. </title> <publisher> Ovum Ltd, </publisher> <address> 7 Rathbone Street, London, </address> <year> 1991. </year>
Reference-contexts: Natural language access to databases, replacing the use of formal query languages, has been investigated for three decades and there are well-established commercial systems <ref> [5, 8] </ref>. Natural language clearly offers advantages in convenience and flexibility, but there are correspondingly major challenges in query interpretation, precisely because query expression is decoupled from search formulation.
Reference: [9] <author> Evans, D. A. and Lefferts, R. G. </author> <title> Design and evaluation of the CLARIT-TREC-2 system. </title> <booktitle> In [15], </booktitle> <pages> pp. 137-150. </pages>
Reference-contexts: First, given the proven value of statistical weighting, any units that NLP produces should be filtered and weighted by the statistics of their occurrences in the database searched and perhaps in other textbases as well <ref> [9, 20] </ref>. Weighing for phrases must be done differently than for single word terms, to allow for their lower frequency and different distributional characteristics, and is less well understood than for words [1, 7, 10].
Reference: [10] <author> Fagan, J. L. </author> <title> Experiments in Automatic Phrase Indexing for Document Retrieval: A Comparison of Syntactic and Non-Syntactic Methods. </title> <type> PhD dissertation, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> Sept. </month> <year> 1987. </year>
Reference-contexts: Many controlled languages allow this, and it has been found effective to a degree when done `statistically', i.e. on a simple co-location basis within a text window. While compounds uncovered by grammatical analysis have typically been less effective than those found by statistical means <ref> [10] </ref>, this may change in a TR context, and in any case grammatical and statistical methods are increasingly combined. <p> Weighing for phrases must be done differently than for single word terms, to allow for their lower frequency and different distributional characteristics, and is less well understood than for words <ref> [1, 7, 10] </ref>. Secondly, we have stressed the importance of late binding and sensitivity to the uncertainty of evidence. Compound terms will not be identified as definitely occurring or not occurring in a document. Rather, each document will provide some amount of evidence for the presence of each known concept.
Reference: [11] <author> Fuhr, N. </author> <title> Models for retrieval with probabilistic indexing. </title> <journal> Inf. Process. Manage., </journal> <volume> 25, 1 (1989), </volume> <pages> 55-72. </pages>
Reference-contexts: TR, even more than DR, is tolerant with respect to errors in document representations. In addition, ambiguities in NLP system output (for instance, alternative decompositions of a sentence into phrases) can be assigned probabilities of correctness in a probabilistic indexing method <ref> [11] </ref>. On the other hand, NLP applied to documents must cope with vast amounts of variable quality text from broad domains. User requests present smaller amounts of text, but even more variability in form and content.
Reference: [12] <author> Furnas, G. W., Landauer, T. K., Gomez, L. M., and Dumais, S. T. </author> <title> The vocabulary problem in human-system communication. </title> <journal> Commun. ACM, </journal> <volume> 30, 11 (1987), </volume> <pages> 964-971. </pages>
Reference-contexts: Second, there are problems imposed by the internal constraints of the task itself, which are responsible for the characteristic uncertainty that the retrieval system has to overcome. The first constraint is the variability in ways that a concept may be expressed <ref> [12] </ref>. This is partly a matter of language, e.g. prefabricated vs unit construction, where the underlying notion of prefabrication is the same, and partly one of perspective, e.g. prefabricated vs factory made, 2 where there are different views of how prefabrication is done.
Reference: [13] <author> Hahn, U. </author> <title> Topic parsing: accounting for text macro structures in full-text analysis. </title> <journal> Inf. Process. Manage., </journal> <volume> 26, 1 (1990), </volume> <pages> 135-170. 14 </pages>
Reference-contexts: Some beginnings have been made in this area <ref> [3, 13, 18] </ref>, but chiefly in limited domains, and by taxing current NLP capabilities to their limits. Processing itself is also knowledge-heavy so for wider and larger files bootstrapping the lexicon, for instance, is needed.
Reference: [14] <editor> Harman, D. K., ed. </editor> <booktitle> The First Text REtrieval Conference (TREC-1). National Institute of Standards and Technology Special Publication 500-207, </booktitle> <address> Gaithersburg, MD 20899, </address> <year> 1993. </year>
Reference-contexts: Test collections of this sort have only very recently become available and experiments with them, while verifying a reasonable 5 level of efficacy for standard techniques, have revealed many surprises and problems <ref> [14, 15] </ref>. Thirdly and most important, many end users have little skill or experience in formulating initial search requests, or in modifying their requests after observing failures. Even when relevance feedback is available, it still needs to be leveraged from a sensible starting point [6]. <p> Thus it is in particular necessary to show whether NLP-derived compound terms are significantly, and usefully, better than e.g. simple collocational compounds. From this point of view, the present surge of activity in TR, stimulated by the ARPA-sponsored Text Retrieval Conferences (TREC) <ref> [14, 15] </ref>, is to be welcomed. This is a major evaluation study, with much more data than previous experiments and comparing many different strategies, with and without NLP. It is far too soon to draw conclusions on relative merits, especially since tailoring to the particular retrieval application must be discounted.
Reference: [15] <editor> Harman, D. K., ed. </editor> <booktitle> The Second Text REtrieval Conference (TREC-2). National Institute of Standards and Technology Special Publication 500-215, </booktitle> <address> Gaithersburg, MD 20899, </address> <year> 1994. </year>
Reference-contexts: Test collections of this sort have only very recently become available and experiments with them, while verifying a reasonable 5 level of efficacy for standard techniques, have revealed many surprises and problems <ref> [14, 15] </ref>. Thirdly and most important, many end users have little skill or experience in formulating initial search requests, or in modifying their requests after observing failures. Even when relevance feedback is available, it still needs to be leveraged from a sensible starting point [6]. <p> Thus it is in particular necessary to show whether NLP-derived compound terms are significantly, and usefully, better than e.g. simple collocational compounds. From this point of view, the present surge of activity in TR, stimulated by the ARPA-sponsored Text Retrieval Conferences (TREC) <ref> [14, 15] </ref>, is to be welcomed. This is a major evaluation study, with much more data than previous experiments and comparing many different strategies, with and without NLP. It is far too soon to draw conclusions on relative merits, especially since tailoring to the particular retrieval application must be discounted.
Reference: [16] <author> Hindle, D. </author> <title> Noun classification from predicate-argument structures. </title> <booktitle> In 28th Annual Meeting of the Association for Computational Linguistics (June 6-9, </booktitle> <address> Pittsburgh, PA). </address> <publisher> ACL, </publisher> <address> Morristown, NJ, </address> <year> 1990, </year> <pages> pp. 268-275. </pages>
Reference-contexts: Automated formation of clusters of related words is again attracting attention, despite the historical lack of success of this technique in DR. More linguistically motivated approaches, such as clustering based on syntactic context, may prove an improvement on traditional strategies <ref> [16, 17] </ref>. Leveraging of hand-coded resources, such as inducing semantic information from labelled training data or from machine-readable dictionaries, may be a more effective, if less general, approach. Finally, the type of NLP that is done constrains what forms of matching are possible.
Reference: [17] <author> Hirschman, L., Grishman, R., and Sager, N. </author> <title> Grammatically-based automatic word class formation. </title> <institution> Inf. Process. Manage., </institution> <month> 11 </month> <year> (1975), </year> <pages> 39-57. </pages>
Reference-contexts: Automated formation of clusters of related words is again attracting attention, despite the historical lack of success of this technique in DR. More linguistically motivated approaches, such as clustering based on syntactic context, may prove an improvement on traditional strategies <ref> [16, 17] </ref>. Leveraging of hand-coded resources, such as inducing semantic information from labelled training data or from machine-readable dictionaries, may be a more effective, if less general, approach. Finally, the type of NLP that is done constrains what forms of matching are possible.
Reference: [18] <author> Jacobs, P. S. and Rau, L. F. SCISOR: </author> <title> Extracting information from on-line news. </title> <journal> Commun. ACM, </journal> <volume> 33, 11 (1990), </volume> <pages> 88-97. </pages>
Reference-contexts: Some beginnings have been made in this area <ref> [3, 13, 18] </ref>, but chiefly in limited domains, and by taxing current NLP capabilities to their limits. Processing itself is also knowledge-heavy so for wider and larger files bootstrapping the lexicon, for instance, is needed.
Reference: [19] <author> Krovetz, R. and Croft, W. B. </author> <title> Lexical ambiguity and information retrieval. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 10, 2 (1992), </volume> <pages> 115-141. </pages>
Reference-contexts: Methods very similar to request/document matching in IR have been used, for instance, for word sense disambiguation. It is not surprising, then, that when a document and request match on several words, it is likely that individual matching words have the same word sense <ref> [19] </ref>. The matching process itself has provided a kind of disambiguation. As another example, words tend to be accompanied by paradigmatically related words in documents, and relevance feedback may add these words to the request, much as a paradigmatic knowledge base would.
Reference: [20] <author> Lewis, D. D. </author> <title> An evaluation of phrasal and clustered representations on a text categorization task. </title> <booktitle> In Proceedings of the Fifteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (June 21-24, </booktitle> <address> Copenhagen). ACM/SIGIR, New York, </address> <year> 1992, </year> <pages> pp. 37-50. </pages>
Reference-contexts: First, given the proven value of statistical weighting, any units that NLP produces should be filtered and weighted by the statistics of their occurrences in the database searched and perhaps in other textbases as well <ref> [9, 20] </ref>. Weighing for phrases must be done differently than for single word terms, to allow for their lower frequency and different distributional characteristics, and is less well understood than for words [1, 7, 10].
Reference: [21] <author> Milstead, J. L. </author> <title> Subject Access Systems. </title> <publisher> Academic Press, </publisher> <address> Orlando, </address> <year> 1984. </year>
Reference-contexts: The result is that variations in indexing that raise precision more often than not lower recall, and vice versa. Beating this tradeoff and raising both recall and precision is the fundamental goal in constructing an index language. There are many possibilities for indexing languages <ref> [21] </ref>. <p> These intermediaries generally believe a controlled language is superior to natural language, though the controlled languages used illustrate many different design options, with no clear winners <ref> [21] </ref>. The searching of well-cared-for bibliographic databases is no longer all DR must deal with, however. A DR session today may involve a personal computer user scanning their hard disk for a missing file or a student searching thousands of Internet servers for an archived Usenet posting.
Reference: [22] <author> Parsaye, K., Chignell, M., Khoshafian, S., and Wong, H. </author> <title> Intelligent Databases. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Going further and using a propositional knowledge base would give a unified, high-level collection model which would allow more intensive inference. Many conventional approaches to DR, for example using facetted indexing, and also hypertext <ref> [22] </ref>, can be seen as gestures in this direction: the putative difference would be in the explicit and thorough provision of automatic inference. EP-X, for instance [22], a search intermediary system using a concept frame hierarchy, is an advance along these lines, but it is based on a controlled language and <p> Many conventional approaches to DR, for example using facetted indexing, and also hypertext <ref> [22] </ref>, can be seen as gestures in this direction: the putative difference would be in the explicit and thorough provision of automatic inference. EP-X, for instance [22], a search intermediary system using a concept frame hierarchy, is an advance along these lines, but it is based on a controlled language and its knowledge base is still manually constructed.
Reference: [23] <author> Pritchard-Schoch, T. </author> <title> Natural language comes of age. </title> <journal> Online, </journal> <volume> 17, 3, </volume> <year> (1993), </year> <pages> 33-43. </pages>
Reference-contexts: The fruits of IR research have been brought to bear against this flood of both traditional and nontraditional data, with some success [28]. Statistical text retrieval systems of the sort suggested by DR research now span the range from personal computers to 100-gigabyte service databases <ref> [23] </ref>. Still, the situation is far from satisfactory, with at least three classes of problems. First, the penetration of the best methods into operational practice is uneven. Many systems still require Boolean logic or other user-befuddling query syntax.
Reference: [24] <author> Salton, G. and McGill, M. </author> <title> Introduction to Modern Information Retrieval McGraw-Hill, </title> <address> New York, </address> <year> 1983. </year>
Reference: [25] <author> Salton, G. </author> <title> Another look at automatic text-retrieval systems. </title> <journal> Commun. ACM, </journal> <volume> 29, 7 (1986), </volume> <pages> 648-656. </pages>
Reference-contexts: In contrast, statistical DR methods, which ease and enhance the use of representations based on single terms, have provided significant improvements over alternative approaches, such as boolean querying <ref> [25] </ref>. Statistical DR methods rank documents based on their similarity to the query, or on an estimate of their probability of relevance to the query, where both query and document are treated as collections of numerically weighted terms. <p> Still, with typical effectiveness results in the range of 30 to 60% recall or precision <ref> [25] </ref>, there is considerable room for improvement, even if DR is an intrinsically coarse process.
Reference: [26] <author> Salton, G. and Buckley, C. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> J. American Society for Information Science, </journal> <volume> 41, 4 (1990), </volume> <pages> 288-297. </pages>
Reference-contexts: In addition, if the user indicates that certain retrieved documents are relevant, this information can be used to reweight and alter the set of query terms, in a process called relevance feedback <ref> [26, 30] </ref>. The focus in this baseline statistical DR strategy is on tuning the representation to the current user request, rather than on anticipating user requests in the document descriptions. The strategy has three major benefits. First, it allows for late binding.
Reference: [27] <author> Salton, G. and Buckley, C. </author> <title> Global text matching for information retrieval. </title> <booktitle> Science, 253 (1991), </booktitle> <pages> 1012-1015. </pages>
Reference-contexts: One could restrict terms to being drawn from particular portions of the text or, better, take into account both the global and local structure of the document in matching <ref> [27] </ref>. In either case, statistical control in unit choice and weighting is again required.
Reference: [28] <author> Schwartz, M. F., Emtage, A., Kahle, B., and Neuman, B. C. </author> <title> A comparison of Internet resource discovery approaches. </title> <journal> Computing Systems, </journal> <volume> 5, </volume> <month> 4 </month> <year> (1992). </year>
Reference-contexts: The fruits of IR research have been brought to bear against this flood of both traditional and nontraditional data, with some success <ref> [28] </ref>. Statistical text retrieval systems of the sort suggested by DR research now span the range from personal computers to 100-gigabyte service databases [23]. Still, the situation is far from satisfactory, with at least three classes of problems. First, the penetration of the best methods into operational practice is uneven.
Reference: [29] <author> Smadja, F. A. </author> <title> From n-grams to collocations: An evaluation of Xtract. </title> <booktitle> In 29th Annual Meeting of the Association for Computational Linguistics (June 18-21, </booktitle> <address> Berkeley, CA). </address> <publisher> ACL, </publisher> <address> Morristown, NJ, </address> <year> 1991, </year> <pages> pp. 279-284. 15 </pages>
Reference-contexts: New approaches are also possible. Accurate and highly efficient syntactic taggers are available, and some compound terms, for instance head nouns and premodifiers, are easily extractable from tagged text [4]. A variety of strategies for finding important collocations in large corpora have been developed <ref> [29] </ref>, and may provide an improvement over traditional IR methods for statistical phrase formation. Compound terms must not only be generated, but also selected among and weighted.
Reference: [30] <author> Sparck Jones, K. </author> <title> Search term relevance weighting|some recent results. </title> <editor> J. </editor> <booktitle> Information Science 1 (1980), </booktitle> <pages> 325-332. </pages>
Reference-contexts: In addition, if the user indicates that certain retrieved documents are relevant, this information can be used to reweight and alter the set of query terms, in a process called relevance feedback <ref> [26, 30] </ref>. The focus in this baseline statistical DR strategy is on tuning the representation to the current user request, rather than on anticipating user requests in the document descriptions. The strategy has three major benefits. First, it allows for late binding.
Reference: [31] <author> Sparck Jones, K. </author> <title> Information Retrieval Experiment. </title> <publisher> Butterworths, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: `natural language' in this sense of drawing indexing terms from the document itself, and use `NLP' when referring to natural language processing. 3 Past research Tests of a wide range of indexing languages over the last three decades have shown fairly consistent (if not wholly expected) results ([24], ch. 3; <ref> [31] </ref>, pt. 3; [36]). These tests have shown that indexing of documents by individual terms corresponding to words or word stems produces results at least as good as those obtained when indexing by controlled vocabularies, whether simple or complex, and whether produced by manual effort or automatic language processing. <p> However there are major challenges first in making this technology operate efficiently and effectively on the necessary scale, and second in conducting the evaluation tests that are essential to discover whether the whole approach, and what specific form of it, works <ref> [31] </ref>, especially when these tests must be for interactive searching and with large files. Thus it is in particular necessary to show whether NLP-derived compound terms are significantly, and usefully, better than e.g. simple collocational compounds.
Reference: [32] <author> Sparck Jones, K. and Tait, J. I. </author> <title> Automatic search term variant generation. </title> <journal> J. Documentation, </journal> <volume> 40, 1 (1984), </volume> <pages> 50-66. </pages>
Reference-contexts: The occurrence of the two words in separate paragraphs would provide much less evidence, but more than the amount given by the presence of just one of the words, or of a related word <ref> [7, 32] </ref>. Thirdly, basic compound units of the type described above would not typically be further combined into frames, templates, or other structured units (unless knowledge retrieval, as discussed later, is to be supported). The description of a document would be an unordered set of `phrase' units and individual words. <p> NLP might be completely restricted to queries, with evidence that the resulting compound terms apply to a document determined solely by testing for proximity of words <ref> [32] </ref>. Besides the obvious efficiency advantages of avoiding NL analysis of the document file, an interface which applied NLP to queries only can enhance access to an operational system without requiring changes in that system. <p> DR techniques might on the other hand be applied in data retrieval to provide `relaxed' queries automatically if initial ones do not provide an answer. They might also be used to generate substitute or `partner' queries for searching accompanying text files <ref> [32, 37] </ref>.
Reference: [33] <author> Sparck Jones, K. </author> <title> Fashionable trends and feasible strategies in information management. </title> <journal> Inf. Process. Manage., </journal> <volume> 24, 6 (1988), </volume> <pages> 703-711. </pages>
Reference-contexts: the same type of structure as a means of linking different bases and types of base within global systems: different bases within such hybrid systems would all be treated as if they were document (i.e. text) collections and tied together, to support `travels in information space', through associative lexical indexing <ref> [33] </ref>. Conclusion We have seen that while conventional DR services continue to make heavy use of strongly-controlled indexing languages (like the National Library of Medicine's Medical Subject Headings), increasing use is being made of indexing where terms are drawn from the natural language of documents.
Reference: [34] <author> Strzalkowski, T. and Carballo, J. P. </author> <title> Recent developments in natural language text retrieval. </title> <booktitle> In [15], </booktitle> <pages> pp. 123-136. </pages>
Reference-contexts: We left open what syntagmatic relationships between terms in text would suffice for those terms to form a compound term. Strategies for traditional, if partial, syntactic analysis allowing processing of hundreds of megabytes of text have been tested for TR <ref> [34] </ref>, but traditional semantic analysis on a large scale remains to be demonstrated. New approaches are also possible. Accurate and highly efficient syntactic taggers are available, and some compound terms, for instance head nouns and premodifiers, are easily extractable from tagged text [4].
Reference: [35] <author> Turtle, H. R. and Croft, W. B. </author> <title> Evaluation of an inference network-based retrieval model. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 9, 3 (1991), </volume> <pages> 187-222. </pages>
Reference-contexts: The assumption again is that statistics will be applied as a further guide or control, in iterative searching, through selection and weighting. Explicit probabilistic models may be favored over alternative matching schemes for their ability to combine a wide variety of evidence <ref> [35] </ref>, but admittedly all current models find it difficult to deal appropriately with complex descriptions and their elements.
Reference: [36] <author> Willett, P. </author> <title> Document Retrieval Systems Taylor Graham, </title> <address> London, </address> <year> 1988. </year>
Reference-contexts: this sense of drawing indexing terms from the document itself, and use `NLP' when referring to natural language processing. 3 Past research Tests of a wide range of indexing languages over the last three decades have shown fairly consistent (if not wholly expected) results ([24], ch. 3; [31], pt. 3; <ref> [36] </ref>). These tests have shown that indexing of documents by individual terms corresponding to words or word stems produces results at least as good as those obtained when indexing by controlled vocabularies, whether simple or complex, and whether produced by manual effort or automatic language processing.
Reference: [37] <author> Woods, W. A. </author> <title> Progress in natural language understanding | an application in lunar geology. </title> <booktitle> Proceedings of the 1973 National Computer Conference, AFIPS Conference Proceedings, </booktitle> <volume> Vol 42, </volume> <pages> 441-450, </pages> <year> 1973. </year>
Reference-contexts: DR techniques might on the other hand be applied in data retrieval to provide `relaxed' queries automatically if initial ones do not provide an answer. They might also be used to generate substitute or `partner' queries for searching accompanying text files <ref> [32, 37] </ref>.
Reference: [38] <author> Young, S. R. and Hayes, P. J. </author> <title> Automatic classification and summarization of banking telexes. </title> <booktitle> In Second Conference on Artificial Intelligence Applications (Dec. </booktitle> <pages> 11-13, </pages> <address> Miami Beach, FL). </address> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1985, </year> <pages> pp. 402-408. 16 </pages>
Reference-contexts: This could be useful in some contexts, and has been done, though with high start-up effort, for some very limited types of texts, for instance banking telexes <ref> [38] </ref>. But it is still desirable to be able to get at the writer's own presentation of information, which is one aspect of document content. Presentation becomes more important with longer text, and complete replacement by a knowledge base version is also much less feasible here.
References-found: 38

