URL: http://www.cs.virginia.edu/~vision/papers/camp93.ps
Refering-URL: http://www.cs.virginia.edu/~vision/papers/
Root-URL: http://www.cs.virginia.edu
Email: email: olson@virginia.edu  
Title: Programming a Pipelined Image Processor  
Author: Thomas J. Olson, Robert J. Lockwood, and John R. Taylor 
Address: Charlottesville, VA, 22903, USA  
Affiliation: Dept. of Computer Science University of Virginia  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Blanford and S. Tanimoto, </author> <title> The PyramidCalc system for research in pyramid machine algorithms, </title> <booktitle> in Proc. Second International Workshop on Visual Languages, Dallas, </booktitle> <pages> pages 138-142, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS [8] and VIVA [13]. Other graphical interfaces to early vision hardware include PyramidCalc <ref> [1] </ref>, the Aspex PIPE editor [5], and Zebra/ZED [14]. The latter system, like VEIL, is targeted at DataCube hardware, but operates at a much lower level. In particular, it requires the programmer to map the computation to specific hardware resources and construct the execution schedule.
Reference: [2] <author> Datacube, Inc. </author> <title> MaxVideo 20 Hardware Reference Manual, </title> <publisher> Datacube, Inc., </publisher> <address> Danvers, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: Unfortunately, as these machines have become more powerful and sophisticated they have also become more difficult to program. This paper describes a software system that we have developed to simplify the task of programming the DataCube MV20 image processor <ref> [2] </ref>. The system presents an abstract view of the hardwares capabilities, allowing the programmer to focus on the computation to be performed rather than the manipulations needed to map the computation onto the hardware. <p> recode an application from scratch in order to make it run faster; rather, they should be encouraged to prototype their applications using standard primitives and then incrementally improve them by optimizing those parts of the computation that consume the bulk of the time. 3 The Hardware The Datacube MaxVideo 20 <ref> [2] </ref> is a general purpose real-time image processing system. Figure 1 shows a block diagram. The MV20 consists of five modular hardware devices and a set of smart memories connected by a large programmable switch.
Reference: [3] <author> Datacube, Inc. </author> <title> ImageFlow Reference Manual, </title> <publisher> Datacube, Inc., </publisher> <address> Danvers, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: and point, pairwise point and neighborhood operations. 32 x 32 Crosspoint Switch AS Device (A/D) Image Memories AP Device (convolution & statistics) AU Device (arithmetic & logical) analog VME to host analog AG Device (D/A) in out Lookup Tables (6 x 1Mb) The MV20 is programmed using the Imageow library <ref> [3] </ref>. Imageow allows the programmer to specify connections between the processing elements inside each device, as well as between ports on the crosspoint switch. It transparently configures the MV20s internal FIFOs and delay lines so that the various image streams arrive at the right places at the right times.
Reference: [4] <author> Ian D. Horswill and Rodney A. Brooks, </author> <title> Situated Vision in a Dynamic World: Chasing Objects, </title> <publisher> AAAI 88, </publisher> <address> St. Paul, MN, </address> <year> 1988, </year> <pages> pp 796-800. </pages>
Reference-contexts: This feature allows graphs to be developed in the interactive MERLIN environment and later incorporated into embedded, non-interactive VEIL applications. A sample MERLIN screen is shown in figure 2. The graph displayed in the work area performs the image processing described by Horswill and Brooks in <ref> [4] </ref> The two nodes at the top of the graph digitize the camera input and subsample it by a factor of four in each dimension, producing a 128x128 image. The graph then splits into two separate streams. The left stream approximates a temporal derivative by backward differencing. <p> Finally, the scheduler is responsible for mapping the computation described by a VEIL graph onto the hardware, building an execution schedule, and allowing user programs to control the computation as desired. the filtered and thresholded gradient magnitude, as described in <ref> [4] </ref>. The VEIL scheduler builds execution schedules in three steps. First, it partitions the input graph into subgraphs, each of which can be run on the MV20 as a single ImageFlow pipe. Second, it constructs the pipes corresponding to each subgraph.
Reference: [5] <author> E. W. Kent, M. O. Shneier, R. Lumia, </author> <title> PIPE - pipelined image processing engine, </title> <journal> Journal of Parallel and Distributed Computing 2, </journal> <year> 1985, </year> <pages> 50-78. </pages>
Reference-contexts: The functionality that they provide is similar to that of a system proposed by Stewart and Dyer [10] as an interface to the Aspex PIPE <ref> [5] </ref>, and to the proposed programming environment for the SYDAMA-2 vision engine [15]. The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS [8] and VIVA [13]. Other graphical interfaces to early vision hardware include PyramidCalc [1], the Aspex PIPE editor [5], and Zebra/ZED [14]. <p> the Aspex PIPE <ref> [5] </ref>, and to the proposed programming environment for the SYDAMA-2 vision engine [15]. The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS [8] and VIVA [13]. Other graphical interfaces to early vision hardware include PyramidCalc [1], the Aspex PIPE editor [5], and Zebra/ZED [14]. The latter system, like VEIL, is targeted at DataCube hardware, but operates at a much lower level. In particular, it requires the programmer to map the computation to specific hardware resources and construct the execution schedule. <p> The fundamental assumption made by the scheduler is that each functions build method can reliably construct a network that performs the appropriate computation, and that the inputs and outputs to that network will be found on a reasonably exible and homogeneous interconnection network. We believe that the Aspex PIPE <ref> [5] </ref>, with its six broadcast buses and its array of homogeneous processing elements, could be supported by a scheduler similar in structure to the one we have written for the MV20.
Reference: [6] <author> Robert J. Lockwood, </author> <title> Heuristic scheduling in VEIL, </title> <type> MS Thesis, </type> <institution> Department of Computer Science, University of Virginia, </institution> <address> Charlottesville, </address> <publisher> (forthcoming). </publisher>
Reference-contexts: This makes the search relatively fast, but may produce more subgraphs than would be required in an optimal schedule. Experiments have shown <ref> [6] </ref> that the number of subgraphs weighted by the maximum number of pixels (i.e. the size of the largest rectangle) passing through any node in the subgraph accounts almost perfectly for the running time of a graph. <p> It is thus reasonable to suppose that heuristic search methods [7] might be capable of producing optimal or near-optimal schedules reasonably quickly. This possibility is the subject of our current work on VEIL <ref> [6] </ref>. 7 Conclusion VEIL and MERLIN provide a powerful environment for developing real-time vision systems. VEILs coarse-grained dataow model allows the programmer to concentrate on the image processing task at hand, rather than the details of resource management, scheduling and synchronization.
Reference: [7] <author> Nils J. Nilsson, </author> <booktitle> Principles of Artificial Intelligence, </booktitle> <publisher> Tioga, </publisher> <address> Palo Alto, </address> <year> 1980. </year>
Reference-contexts: It is thus reasonable to suppose that heuristic search methods <ref> [7] </ref> might be capable of producing optimal or near-optimal schedules reasonably quickly. This possibility is the subject of our current work on VEIL [6]. 7 Conclusion VEIL and MERLIN provide a powerful environment for developing real-time vision systems.
Reference: [8] <author> Thomas J. Olson, Nicholas G. Klop, Mark R. Hyett, Shawn M. Carnell, MAVIS: </author> <title> A Visual Environment for Active Computer Vision, </title> <booktitle> IEEE Workshop on Visual Languages, </booktitle> <month> September, </month> <year> 1992. </year>
Reference-contexts: The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS <ref> [8] </ref> and VIVA [13]. Other graphical interfaces to early vision hardware include PyramidCalc [1], the Aspex PIPE editor [5], and Zebra/ZED [14]. The latter system, like VEIL, is targeted at DataCube hardware, but operates at a much lower level.
Reference: [9] <author> Randy Pausch, Nathaniel Young, III, Robert Deline, SUIT, </author> <title> The Pascal of User Interface Toolkits, </title> <booktitle> Proceedings of UIST: the Annual ACM SIGGRAPH Symposium on User Interface Software and Technology, </booktitle> <month> November, </month> <year> 1991. </year>
Reference-contexts: The MERLIN application is written in C++ and sits on top of both the VEIL library and the SUIT user interface toolkit <ref> [9] </ref>. The user manipulates graphs in the MERLIN work area by adding or deleting functions (nodes) and connections (arcs), and by specifying attributes for functions that require them.
Reference: [10] <author> Charles V. Stewart, Charles R. Dyer, </author> <title> Heuristic Scheduling Algorithms for PIPE, </title> <booktitle> IEEE Computer Architecture for Pattern Analysis and Machine Intelligence, </booktitle> <month> October, </month> <year> 1987. </year>
Reference-contexts: They differ from the earlier system in separating the visual language interface from the underlying computational engine, and in the fact that they are easily extensible. The functionality that they provide is similar to that of a system proposed by Stewart and Dyer <ref> [10] </ref> as an interface to the Aspex PIPE [5], and to the proposed programming environment for the SYDAMA-2 vision engine [15]. The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS [8] and VIVA [13].
Reference: [11] <author> Michael J. Swain and Markus Stricker, </author> <title> editors. Promising directions in active vision, written by the attendees of the NSF Active Vision Workshop, </title> <month> August </month> <year> 1991. </year> <institution> University of Chicago Technical Report CS 91-27, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: We are particularly concerned with problems in active vision, in which vision is tightly integrated into the behavior of an autonomous agent, i.e. a robot. The philosophy underlying this approach to vision is summarized in <ref> [11] </ref>. Active vision is inherently a real-time problem. The computational demands of real-time vision led us (in common with many other researchers) to the use of pipelined image processing hardware. Unfortunately, the difficulty of programming that hardware has proven to be a major obstacle to progress.
Reference: [12] <author> John R. Taylor, Robert J. Lockwood, Thomas J. Olson and Scott A. Gietler, </author> <title> A Visual Programming System for Pipelined Image Processors, </title> <booktitle> In SPIE Machine Vision Applications, Architectures, and Systems Integration, </booktitle> <address> Boston, </address> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: MERLIN allows users to create, run, and modify VEIL graphs by drawing them on the workstation screen. Graphs constructed using MERLIN can be loaded into VEIL applications and controlled in the same manner as any other VEIL graph. VEIL and MERLIN are outgrowths of our earlier attempt <ref> [12] </ref> to write a visual programming language for the MV20. They differ from the earlier system in separating the visual language interface from the underlying computational engine, and in the fact that they are easily extensible. <p> The computational demands of real-time vision led us (in common with many other researchers) to the use of pipelined image processing hardware. Unfortunately, the difficulty of programming that hardware has proven to be a major obstacle to progress. Our first attempt at a solution to the problem <ref> [12] </ref> was only partially successful, because it did not take into account the need for extensibility and for close coupling between vision computations (performed on the image processing engine) and robot control computations.
Reference: [13] <author> Steven L. Tanimoto, VIVA: </author> <title> A visual language for image processing, </title> <journal> Journal of Visual Languages and Computing, v. </journal> <volume> 1 no. 2, </volume> <year> 1990. </year>
Reference-contexts: The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS [8] and VIVA <ref> [13] </ref>. Other graphical interfaces to early vision hardware include PyramidCalc [1], the Aspex PIPE editor [5], and Zebra/ZED [14]. The latter system, like VEIL, is targeted at DataCube hardware, but operates at a much lower level.
Reference: [14] <author> David G. Tilley, </author> <title> ZEBRA for MaxVideo: An application of object oriented microprogramming to register level devices, </title> <institution> University of Rochester Department of Computer Science Tech. </institution> <type> Rep. no. 315, </type> <year> 1990. </year>
Reference-contexts: The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS [8] and VIVA [13]. Other graphical interfaces to early vision hardware include PyramidCalc [1], the Aspex PIPE editor [5], and Zebra/ZED <ref> [14] </ref>. The latter system, like VEIL, is targeted at DataCube hardware, but operates at a much lower level. In particular, it requires the programmer to map the computation to specific hardware resources and construct the execution schedule.
Reference: [15] <author> M. Zeltner, B. Schneuwly, and W. GuggenBhl, </author> <title> How to Program and Configure a Heterogeneous Multiprocessor, </title> <booktitle> in Proceedings of the 1991 Workshop on Computer Architecture for Machine Perception, </booktitle> <address> Paris, </address> <month> December </month> <year> 1991, </year> <pages> 111-122. </pages>
Reference-contexts: The functionality that they provide is similar to that of a system proposed by Stewart and Dyer [10] as an interface to the Aspex PIPE [5], and to the proposed programming environment for the SYDAMA-2 vision engine <ref> [15] </ref>. The MERLIN graphical user interface draws heavily on work in dataow visual programming languages, particularly MAVIS [8] and VIVA [13]. Other graphical interfaces to early vision hardware include PyramidCalc [1], the Aspex PIPE editor [5], and Zebra/ZED [14].
References-found: 15

