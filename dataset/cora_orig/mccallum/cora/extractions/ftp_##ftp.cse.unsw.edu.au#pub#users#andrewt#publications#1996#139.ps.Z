URL: ftp://ftp.cse.unsw.edu.au/pub/users/andrewt/publications/1996/139.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/publications/1996/SCSE_publications.html
Root-URL: 
Email: Email: -debbier, vija, compton-@cse.unsw.edu.au  
Title: The Reuse of Ripple Down Rule Knowledge Bases: Using Machine Learning to Remove Repetition  
Author: Debbie Richards, Vijaletchmee Chellen and Paul Compton 
Address: Sydney, Australia  
Affiliation: Department of Artificial Intelligence School of Computer Science and Engineering University of New South Wales  
Abstract: Ripple down rules (RDR) is a knowledge acquisition technique that addresses the bottleneck problem by allowing rapid development of knowledge bases (KB) by experts, without the need for lengthy analysis or intervention of a knowledge engineer. This is achieved through the use of an exception structure and the storing of cornerstone cases. The exception structure avoids the problem of side-effects that occur when traditional rule-based ES are maintained, as knowledge in an RDR KB is never deleted or changed, only added. This can lead to repetitious knowledge. While studies have shown that the repetition problem is small, the concern of this study is the impact of repetition on reuse of the knowledge base for purposes such as explanation, modeling or tutoring. This paper reports on work that has been done using two different machine learning techniques, Induct and Rough Sets, to compact various ripple down rule knowledge bases by removing repetitious or redundant knowledge. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Catlett, J. </author> <title> (1992) RippleDown-Rules as a Mediating Representation in Interactive Induction Proceedings of the Second Japanese Knowledge Acquisition for Knowledge-Based Systems Workshop, </title> <address> Kobe, Japan, </address> <month> Nov 9-13 </month> <year> 1992, </year> <note> pp:155-170. Chellen, Vijaletchmee (1995) Induct/RDR and Knowledge Base Compaction BE Computer Engineering 1995 Honours Thesis, </note> <institution> University of New South Wales. </institution>
Reference-contexts: It has also been shown that the expert enters new concepts that do not exist in the historical data (Compton et al 1991a) and the rules output by ML techniques, such as C4.5 are not as comprehensible to experts as the RDR exception structure <ref> (Catlett 1992) </ref> 2 . One alternative proposed by Gaines and Compton (1992) is to use manual RDR to build an initial KBS and when the KB becomes large, use ML, Induct in particular, to minimise the size of the rule base. This study pursues Gaines proposal. <p> Catlett (1992) has developed the Ghidora algorithm which converts knowledge in a decision tree to RDR format. An importance ranking (IR) is computed which gives the "expected benefit of the rule to the accuracy of the ruleset" <ref> (Catlett 1992, p.162) </ref>. This IR measure is used to determine the order in which rules should be added. A similar concern to how to treat the false branches is how to handle negation. Cases usually have one or no value for each attribute.
Reference: <author> Colomb, Robert.M. </author> <title> (1993) Decision Tables, Decision Trees and Cases: Propositional Knowledge-Based Systems Technical Report No. 266 Key Centre for Software Technology, </title> <institution> Department of Compter Science, The University of Queensland, Australia. </institution>
Reference: <author> Colomb, R.M. and Sienkiewicz, J. </author> <booktitle> (1995) Analysis of Redundancy in Expert Systems Case Data Xin Yao (ed) Proceeding of the Eighth Joint Conference on Artificial Intelligence AI'95 13-17 November 1995, </booktitle> <address> Canberra, </address> <publisher> World Scientific, Singapore. </publisher>
Reference: <author> Compton, P. and Jansen, R., </author> <title> (1988) Knowledge in context: a strategy for expert system maintenance , AI88: </title> <booktitle> Proceedings of the second Australian Conference in Artificial Intelligence , Adelaide, </booktitle> <pages> pp: </pages> <note> 283-297 Compton, </note> <author> P. and Jansen, R., </author> <title> (1989) A philosophical basis for knowledge acquisition , Proceedings for the Third European Knowledge Acquisition for knowledge-based Systems Workshop , Paris pp,75-89 Compton, </title> <note> P., </note> <author> Horn, R., Quinlan, and Lazarus, </author> <title> L (1989)Maintaining an Expert System In R. </title> <editor> Quinlan (ed), </editor> <booktitle> Applications of Expert Systems, </booktitle> <publisher> Addison Wesley, </publisher> <pages> 366-385. </pages>
Reference-contexts: Whilst maintaining a mediumsized medical ES, Garvan-ES1, it was found that experts tend to offer justifications related to the context of the current case for their decisions rather than general rules or heuristics <ref> (Compton and Janson 1988) </ref>. Experts were good at picking the features in a case that justified why they had reached that conclusion. <p> Manual RDR is a rapid method of KA, approximately 40 times faster than traditional KA techniques <ref> (Compton and Jansen 1988) </ref>. The compactness of manual RDR and it's exception structure prompted Brian Gaines to modify his Induct algorithm to produce Induct/RDR (Gaines 1991).
Reference: <author> Compton, P., Edwards, G., Kang, B., Lazarus, L., Malor, R., Menzies, T., Preston, P., Srinivasan, A. and Sammut, C. </author> <title> (1991a) Ripple Down Rules: </title> <booktitle> Possibilities and Limitations 6th Bannf AAAI Knowledge Acquisition for Knowledge Based Systems Workshop , Bannf (1991) 6.1 - 6.18. </booktitle>
Reference-contexts: While experts appear to add very simple general rules that result in minimal repetition <ref> (Compton et al 1991a) </ref>, it was the aim of this study to review the repetition and redundancy that does exist and see if their removal improves the clarity of the knowledge base and its suitability for reuse. <p> As noted above manual RDR outperforms ML techniques when only a small number of cases are available. It has also been shown that the expert enters new concepts that do not exist in the historical data <ref> (Compton et al 1991a) </ref> and the rules output by ML techniques, such as C4.5 are not as comprehensible to experts as the RDR exception structure (Catlett 1992) 2 . <p> We can use this idea of differences and similarities as a way of analysing our knowledge. The use of a discernability matrix in RST has much in common with the use of difference lists RDR <ref> (Compton et al 1991a) </ref> and repertory grids (Gaines and Shaw 1989) which are based on personal construct theory (PCT) (Kelly 1955).
Reference: <author> Compton, P., Srinivasan, A., Edwards, G., Malor, R. and Lazarus, L., </author> <title> (1991b) Knowledge Base Maintenance Without a Knowledge Engineer Proceedings World Congress on Expert Systems , Pergmon Press, </title> <publisher> pp:668-675. </publisher>
Reference-contexts: This task can be easily performed by an expert without the need for a knowledge engineer (KE) to model or encode the knowledge <ref> (Compton et al 1991b) </ref> and is a proven way of reducing the KA bottleneck problem (Edwards et al 1993). Each time a rule is added in response to an erroneous conclusion, the case that prompted the rule is stored and is known as the cornerstone case. <p> It has been claimed that the rule trace provided by an RDR KBS offers better explanation facility than conventional rule based systems <ref> (Compton et al 1991b) </ref>.
Reference: <author> Compton, P., Preston, P. and Kang, B., </author> <title> (1994) Local Patching Produces Compact Knowledge Bases A Future in Knowledge Acquisition Eds L. </title> <editor> Steels, G. Schreiber and W. Van de Velde, </editor> <publisher> Berlin, Springer Verlag, pp:104-117. </publisher>
Reference: <author> Compton, P., Preston, P. and Kang, B. </author> <title> (1995) The Use of Simulated Experts in Evaluating Knowledge Acquisition, Proceedings 9th Banff Knowledge Acquisition for Knowledge Based Systems Workshop Banff. </title> <month> Feb 26 - March 3 </month> <year> 1995, </year> <note> Vol 1: </note> <author> Edwards, G., Compton, P., Malor, R, Srinivasan, A. and Lazarus, L. </author> <year> (1993) </year> <month> PEIRS: </month> <title> a Pathologist Maintained Expert System for the Interpretation of Chemical Pathology Reports Pathology 25 : 27-34. </title>
Reference-contexts: e C a s e 2 I f b T h e n C l s 7 C o r n e r s t o n e C a s e 3 I f b T h e n C l s 7 T T T the repetition removed <ref> (Kang, Compton and Preston 1995) </ref> The next section gives an overview of the two machine learning (ML) algorithms which were employed. Section three describes the experimental method used in this study and Section four looks at the results of the experiments. <p> A different synthetic expert was built for each of the domains, using machine learning techniques. The whole dataset were used as the training set so as to provide maximum expertise. The three datasets were then randomised prior to the construction of the expert systems to avoid lumpiness <ref> (Compton, Preston and Kang 1995) </ref>. The Garvan dataset was randomised to produce four different datasets. Both the Chess and TicTacToe dataset were randomised to produce nine different dataset. For each dataset 25% was kept as the test set, while the other 75% was used as the training set.
Reference: <author> Edwards, G., Kang, B., Preston, P. and Compton, P. </author> <title> (1995) Prudent Expert Systems with Credentials: Managing the expertise of Decision Support Systems Int. </title> <journal> Journal Biomedical Computing 40: </journal> <pages> 125-132. </pages>
Reference: <author> Fibak, J., Slowinski, K. and Slowinki, R. </author> <title> (1986) Rough Sets Based Decision Algorithm for Treatment of Duodenal Ulcer by HSV Proceedings of 6th Internal Workshop on Expert Systems and their Applications Avignon, </title> <address> France, pp:587-599. </address>
Reference-contexts: RST has been used successfully to support the classification of uncertain or incomplete data in a range of domains <ref> (Fibak et al 1986, Krysinski 1990 and Slowinski et al 1988) </ref>. Pawlak defines a knowledge base to be a family of classifications 3 in the universe of objects being investigated. Each family member forms a subset or category.
Reference: <author> Gaines, B.R. </author> <title> (1989) An Ounce of Knowledge is Worth a Tone of Data: Quantitative Studies of the Trade Off Between Expertise and Data Based on Statistically Well-Founded Empirical Inducation. </title> <booktitle> Proceedings of the 6th International Workshop on Machine Learning San Mateo, </booktitle> <address> California, </address> <publisher> Morgan Kaufmann, </publisher> <month> June </month> <year> 1989, </year> <month> pp:156-159. </month>
Reference-contexts: This study pursues Gaines proposal. The ML algorithms chosen for this study were Induct <ref> (Gaines 1989) </ref> and rough set theory (RST) (Pawlak 1991). The use of Induct/RDR was an obvious choice due to its compatibility to RDR. The use of RST for compaction was also tested due to the similarity of the underlying concepts with RDR philosophy. <p> We can use this idea of differences and similarities as a way of analysing our knowledge. The use of a discernability matrix in RST has much in common with the use of difference lists RDR (Compton et al 1991a) and repertory grids <ref> (Gaines and Shaw 1989) </ref> which are based on personal construct theory (PCT) (Kelly 1955). An overview of both Induct and RST follows. 2.1 An Overview of Induct Induct uses induction to build a knowledge base in terms of classes, attributes, attribute values and rules (Gaines 1989). <p> An overview of both Induct and RST follows. 2.1 An Overview of Induct Induct uses induction to build a knowledge base in terms of classes, attributes, attribute values and rules <ref> (Gaines 1989) </ref>. Figure 2 below reveals the basis of the statistical tests underpinning Inducts rule generation. The aim is to find a measure, r, which determines how good is a selector S (attribute-value combination). <p> The advantage of selecting r as a measure of the correctness of a rule is that it is easily understood, as the probability that the rule could be this good at random. Furthermore, it involves no assumptions about the problem such as sampling distributions <ref> (Gaines 1989) </ref>. We chose to reimplement the Induct algorithm on the Unix platform with some modifications to handle compaction. <p> When we are dealing with rules we have many more missing values than we would expect to find in a set of cases. For Induct, a selection based on missing values are allowed to contribute to false positives but not to correct positives <ref> (Gaines 1989) </ref>. Thus when measure r, is being calculated for a selector S, those cases having missing values for any of the clauses in S, are considered to belong to S if and only if they have a classification other than the Target class Q.
Reference: <editor> Gaines, B. R. and Shaw, M.L.G. </editor> <booktitle> (1989) Comparing the Conceptual Systems of Experts The 11th International Joint Conference on Artificial Intelligence :633-638. </booktitle>
Reference-contexts: This study pursues Gaines proposal. The ML algorithms chosen for this study were Induct <ref> (Gaines 1989) </ref> and rough set theory (RST) (Pawlak 1991). The use of Induct/RDR was an obvious choice due to its compatibility to RDR. The use of RST for compaction was also tested due to the similarity of the underlying concepts with RDR philosophy. <p> We can use this idea of differences and similarities as a way of analysing our knowledge. The use of a discernability matrix in RST has much in common with the use of difference lists RDR (Compton et al 1991a) and repertory grids <ref> (Gaines and Shaw 1989) </ref> which are based on personal construct theory (PCT) (Kelly 1955). An overview of both Induct and RST follows. 2.1 An Overview of Induct Induct uses induction to build a knowledge base in terms of classes, attributes, attribute values and rules (Gaines 1989). <p> An overview of both Induct and RST follows. 2.1 An Overview of Induct Induct uses induction to build a knowledge base in terms of classes, attributes, attribute values and rules <ref> (Gaines 1989) </ref>. Figure 2 below reveals the basis of the statistical tests underpinning Inducts rule generation. The aim is to find a measure, r, which determines how good is a selector S (attribute-value combination). <p> The advantage of selecting r as a measure of the correctness of a rule is that it is easily understood, as the probability that the rule could be this good at random. Furthermore, it involves no assumptions about the problem such as sampling distributions <ref> (Gaines 1989) </ref>. We chose to reimplement the Induct algorithm on the Unix platform with some modifications to handle compaction. <p> When we are dealing with rules we have many more missing values than we would expect to find in a set of cases. For Induct, a selection based on missing values are allowed to contribute to false positives but not to correct positives <ref> (Gaines 1989) </ref>. Thus when measure r, is being calculated for a selector S, those cases having missing values for any of the clauses in S, are considered to belong to S if and only if they have a classification other than the Target class Q.
Reference: <author> Gaines, B.R. </author> <title> (1991) Induction and Visualisation of rules with exceptions 6th Banff AAAi Knowledge Acquisition for Knowledge Based SystemsWorkshop Banff, 1991 7.1-7.17 Gaines, B.R. and Compton. P, </title> <booktitle> (1992) Induction of RippleDown Rules Proceedings of the 5th Australian Joint Conference on Artificial Intelligence , Hobart, Tasmania, World Scientific, Singapore, </booktitle> <pages> 349-354, </pages> <editor> Gawrys, M. and Sienkiewicz, J. </editor> <title> (1993) Rough Set Library Users Manual Institute of Computer Science, </title> <institution> Warsaw University of Technology, Warswar, Poland. </institution>
Reference-contexts: Manual RDR is a rapid method of KA, approximately 40 times faster than traditional KA techniques (Compton and Jansen 1988). The compactness of manual RDR and it's exception structure prompted Brian Gaines to modify his Induct algorithm to produce Induct/RDR <ref> (Gaines 1991) </ref>.
Reference: <author> Kang, B., Compton, P. and Preston, </author> <title> P (1995) Multiple Classification Ripple Down Rules: Evaluation and Possibilities Proceedings 9th Banff Knowledge Acquisition for Knowledge Based Systems Workshop Banff. </title> <month> Feb 26 - March 3 </month> <year> 1995, </year> <title> Vol 1,pp:17.1-17.20 Kelly, G.A, (1955) The Psychology of Personal Constructs New York, </title> <publisher> Norton. </publisher>
Reference-contexts: e C a s e 2 I f b T h e n C l s 7 C o r n e r s t o n e C a s e 3 I f b T h e n C l s 7 T T T the repetition removed <ref> (Kang, Compton and Preston 1995) </ref> The next section gives an overview of the two machine learning (ML) algorithms which were employed. Section three describes the experimental method used in this study and Section four looks at the results of the experiments. <p> A different synthetic expert was built for each of the domains, using machine learning techniques. The whole dataset were used as the training set so as to provide maximum expertise. The three datasets were then randomised prior to the construction of the expert systems to avoid lumpiness <ref> (Compton, Preston and Kang 1995) </ref>. The Garvan dataset was randomised to produce four different datasets. Both the Chess and TicTacToe dataset were randomised to produce nine different dataset. For each dataset 25% was kept as the test set, while the other 75% was used as the training set.
Reference: <author> Krysinski, J. </author> <title> (1990) Rough Sets Approach to Analysis of Relationship Between Structure and Activity of Quaternary Imidazolium Compounds. </title> <journal> ArzeneimittelForschung Drug Research, </journal> <volume> 40 , pp:795-799. </volume>
Reference: <author> Mansuri, Y., Kim, J.G., Compton, P. and Sammut, C. </author> <year> (1991). </year> <title> A comparison of a manual knowledge acquisition method and an inductive learning method Australian Workshop on Knowledge Acquisition for Knowledge Based Systems , Pokolbin (1991) pp:114-132. Pawlak, </title> <journal> Zdzislaw (1982) Rough Sets International Journal of Information and Computer Sciences, </journal> <volume> 11, </volume> <month> pp:341-356. </month> <title> Pawlak, Zdzislaw (1991) Rough Sets: Theoretical Aspects of Reasoning about Data Kluwer Academic Publishers, </title> <publisher> Dordrecht. </publisher>
Reference-contexts: using manual RDR is not as quick as with a ML technique it has been found to produce rule bases of similar size to those built using ML techniques such as ID3, C4.5 and Induct and matures more quickly, requiring a small number of cases to achieve high accuracy levels <ref> (Mansuri et al 1991) </ref>. Manual RDR is a rapid method of KA, approximately 40 times faster than traditional KA techniques (Compton and Jansen 1988). The compactness of manual RDR and it's exception structure prompted Brian Gaines to modify his Induct algorithm to produce Induct/RDR (Gaines 1991).
Reference: <author> Richards, D., Gambetta, W. and Compton, P. </author> <title> (1996) Using Rough Set Theory to Verify Production Rules and Support Reuse Verification and Validation Workshop PRICAI'96 August 26th1996, </title> <institution> Griffith University. </institution>
Reference-contexts: An algorithm was developed and applied to a subset of the rule base for AusVit, the Australian Viticulture Expert System <ref> (Richards, Gambetta and Compton 1996) </ref>. This algorithm has been applied to the Garvan, TicTacToe and Chess datasets to verify consistency and remove redundancy. 6. Further Research and Conclusion The ultimate goal of this research is to find how knowledge in an RDR KB can be used to solve different problems.
Reference: <author> Slowinski, R., Slowinski, K. and Stefanowski, J. </author> <title> (1988) Rough Set Approach to Analysis of Data from Peritoneal Lavage in Acute Pancreatitis Medical Information, </title> <booktitle> 13, </booktitle> <pages> pp: 143-159. </pages>
References-found: 18

