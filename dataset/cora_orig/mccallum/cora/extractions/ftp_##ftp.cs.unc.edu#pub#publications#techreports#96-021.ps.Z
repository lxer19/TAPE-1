URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/96-021.ps.Z
Refering-URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/FILE.html
Root-URL: http://www.cs.unc.edu
Email: welchg@cs.unc.edu,  
Title: One-Step-at-a-Time Tracking orientation. The method, which is applicable to a wide variety of virtual-environment tracking
Author: Greg Welch and Gary Bishop 
Note: tion and  
Web: http://www.cs.unc.edu/~welchg  
Address: Chapel Hill  
Affiliation: University of North Carolina at  
Abstract: gb@cs.unc.edu, http://www.cs.unc.edu/~gb CB 3175, Sitterson Hall, Chapel Hill, NC, 27599-3175 Abstract We introduce a new mathematical method for tracking posi the previous estimate. By incorporating an ongoing sequence of individual sensor measurements in this way we can track position and orientation, one step at a time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jacobs, O. L. R. </author> <year> 1993. </year> <title> Introduction to Control Theory, </title> <publisher> 2nd Edition ford University Press. </publisher>
Reference-contexts: In section 4 we present simulations of a onestep-at-a-time tracking system, including results with sensor autocalibration. Finally in section 5 we offer some concluding thoughts about the method. 2 Motivation 2.1 Estimate Rates and Latencies Per Shannons sampling theorem <ref> [1] </ref> the measurement pling frequency should be at least twice the true target motion bandwidth, or an estimator may track an alias of the true motion.
Reference: [2] <author> Neilson, P.D. </author> <year> 1972. </year> <title> Speed of Response or Bandwidth of Voluntary System Controlling Elbow Position in Intact Man, Medical and Biological Engineering </title>
Reference: [3] <author> Fischer, P., R. Daniel and K. Siva. </author> <year> 1990. </year> <title> Specification and Design of Input Devices for Teleoperation, </title> <booktitle> Proceedings of the IEEE Conference on Robotics and Automation (Cincinnati, </booktitle> <address> OH), </address> <pages> pp. 540-545. </pages>
Reference: [4] <author> Foxlin, E. </author> <year> 1993. </year> <title> Inertial Head Tracking, </title> <type> Masters Thesis, </type> <institution> Electrical Engineering and Computer Science, Massachusetts Institute of Technology. </institution>
Reference-contexts: To maintain more consistent performance throughout a working environment, across the frequency spectrum, and over a wide range of dynamics, researchers have sought to develop hybrid tracking systems . For example, Foxlin has developed a system that is primarily inertial, but aided by angular position sensors <ref> [4] </ref>, both Canadian Aerospace Electronics [16] and the University of North Carolina [13] have pursued systems that are primarily optical, but aided by inertial sensors (for prediction), and researchers at the University of Tokyo have sought to improve the data rate of the Polhemus tracker by augmenting it with rate gyros
Reference: [5] <author> Mine, Mark. </author> <year> 1993. </year> <title> Characterization of End-to-End Delays in Head-Mounted Display Systems, </title> <institution> The University of North Carolina at Chapel Hill, TR93-001. </institution>
Reference-contexts: In addition to increasing the estimate rate, we want to reduce the latency associated with generating an improved estimate, thus reducing the overall latency between target motion and visual feedback in virtual environment systems <ref> [5] </ref>. If too high, such latency can impair adaptation and the illusion of presence [6], and can cause motion discomfort or sickness. Increased latency also contributes to problems with head-mounted display registration [7] and with motion prediction [8,9,10].
Reference: [6] <author> Held, R. and N. Durlach. </author> <year> 1987. </year> <title> Telepresence, Time Delay, </title> <booktitle> and Adaptation . NASA Conference Publication 10023. </booktitle>
Reference-contexts: In addition to increasing the estimate rate, we want to reduce the latency associated with generating an improved estimate, thus reducing the overall latency between target motion and visual feedback in virtual environment systems [5]. If too high, such latency can impair adaptation and the illusion of presence <ref> [6] </ref>, and can cause motion discomfort or sickness. Increased latency also contributes to problems with head-mounted display registration [7] and with motion prediction [8,9,10]. With these requirements in mind, let us examine the effect of the measurements on the estimate latency and rate.
Reference: [7] <author> Holloway, Richard L. </author> <year> 1995. </year> <title> Registration Errors in Augmented Reality Systems, </title> <type> Ph.D. dissertation, </type> <institution> The University of North Carolina at Chapel Hill, TR95-016. </institution>
Reference-contexts: If too high, such latency can impair adaptation and the illusion of presence [6], and can cause motion discomfort or sickness. Increased latency also contributes to problems with head-mounted display registration <ref> [7] </ref> and with motion prediction [8,9,10]. With these requirements in mind, let us examine the effect of the measurements on the estimate latency and rate.
Reference: [8] <author> Liang, J., C. Shaw and M. Green. </author> <year> 1991. </year> <title> On Temporal-spatial Realism in the Virtual Reality Environment, </title> <booktitle> Fourth Annual Symposium on User Interface Software and Technology </booktitle>
Reference: [9] <author> Friedman, M., T. Starner and A. Pentland. </author> <year> 1992. </year> <title> Synchronization in Virtual Realities, Presence: </title> <booktitle> Teleoperators and Virtual Environments, </booktitle> <volume> 1 </volume> <pages> 139-144. </pages>
Reference: [10] <author> Azuma, Ronald and Gary Bishop. </author> <year> 1994. </year> <title> Improving Static and Dynamic Registration in an Optical See-Through HMD, </title> <booktitle> Proceedings of ACM SIGGRAPH '94 (Orlando, </booktitle> <address> FL, </address> <month> July </month> <year> 1994), </year> <title> Computer Graphics, </title> <booktitle> Annual Conference Series. </booktitle>
Reference: [11] <author> Woltring, H. J. </author> <year> 1974. </year> <title> New possibilities for human motion studies by real-time light spot position measurement , Biotelemetry, </title> <journal> Vol. </journal> <volume> 1. </volume>
Reference-contexts: Then the estimate latency and rate are As the number of measurements increases, (1) shows how the estimate latency and rate increase and decrease respectively. For the Selspot optical tracking system, beacons are observed sequentially per estimate (for position and orientation of a single target) <ref> [11] </ref>. For the Polhemus Fastrak magnetic tracking system, sequential excitations are performed and sensed per estimate [12]. For the University of North Carolina (UNC) wide-area optoelectronic tracking system, beacons are observed sequentially per estimate [13,14].
Reference: [12] <author> Raab, F. H., E. B. Blood, T. O. Steiner, and H. R. Jones. </author> <year> 1979. </year> <title> Magnetic Position and Orientation Tracking System, </title> <journal> IEEE Transactions on Aerospace and Electronic Systems , Vol. </journal> <volume> AES-15, </volume> <pages> 709-718. </pages>
Reference-contexts: For the Selspot optical tracking system, beacons are observed sequentially per estimate (for position and orientation of a single target) [11]. For the Polhemus Fastrak magnetic tracking system, sequential excitations are performed and sensed per estimate <ref> [12] </ref>. For the University of North Carolina (UNC) wide-area optoelectronic tracking system, beacons are observed sequentially per estimate [13,14]. The onestep-at-a-time method seeks to improve the latencies and data rates of such sys tems by updating the current estimate with each new (individual) sensor measurement, i.e. by fixing at 1. <p> Each estimate occurs only after sensing an excitation pattern composed of three linearly inde pendent excitation vectors . The complete excitation pattern contains information sufficient to determine the 3D position and orientation of the target <ref> [12] </ref>. A diagram depicting the timing of a (hypothetically) modified onestep-at-a-time Polhemus Fastrak is given in Figure 2. In this case an estimate is available after sensing each individual excitation vector. <p> For example, purely inertial trackers suffer from drift, optical trackers require a clear line of sight, and magnetic trackers are affected by ferromagnetic materials in the environment <ref> [12] </ref>. To maintain more consistent performance throughout a working environment, across the frequency spectrum, and over a wide range of dynamics, researchers have sought to develop hybrid tracking systems .
Reference: [13] <author> Ward, Mark, Ronald Azuma, Robert Bennett, Stefan Gottschalk, and Henry Fuchs. </author> <year> 1992. </year> <title> A Demonstrated Optical Tracker With Scalable Work Area for Head-Mounted Display Systems, </title> <booktitle> Proceedings of 1992 Symposium on Interactive 3D Graphics (Cambridge, </booktitle> <address> MA, </address> <month> 29 March - 1 April </month> <year> 1992), </year> <pages> pp. 43-52. </pages>
Reference-contexts: For example, Foxlin has developed a system that is primarily inertial, but aided by angular position sensors [4], both Canadian Aerospace Electronics [16] and the University of North Carolina <ref> [13] </ref> have pursued systems that are primarily optical, but aided by inertial sensors (for prediction), and researchers at the University of Tokyo have sought to improve the data rate of the Polhemus tracker by augmenting it with rate gyros [21]. <p> The system would thus be calibrated with respect to the selected elements (devices or parameters). 4 Simulations We have simulated a onestep-at-a-time wide-area optoelec-tronic position and orientation tracking system similar to <ref> [13] </ref>. The simulated system consists of a rigid cluster of 6 user-mounted cameras that look outward toward a ceiling-mounted 2D array of approximately 3000 electronic beacons . The cameras provide a single 2D measurement vector that represents the image coordinates of the beacon as seen by the camera. <p> To evaluate the filter performance we needed some reference data. Our solution was to collect motion data from real-user sions with a conventional tracking system, and then to filter the Selspot [15] generates measurements at a rate of 10,000 Hz, the UNC wide-area optoelectronic tracker <ref> [13] </ref> can activate beacons at a rate of 5000 Hz.
Reference: [14] <author> Azuma, Ronald and Mark Ward. </author> <year> 1991. </year> <note> Space-Resection by Collinear-ity: Mathematics Behind the Optical Ceiling Head-Tracker, UNC Chapel Hill Department of Computer Science technical report TR 91-048 (Novem-ber 1991). </note>
Reference: [15] <author> Selspot Technical Specifications, </author> <title> Selcom Laser Measurements, obtained from Innovision Systems, </title> <publisher> Inc. (Warren, </publisher> <address> MI). </address>
Reference-contexts: To evaluate the filter performance we needed some reference data. Our solution was to collect motion data from real-user sions with a conventional tracking system, and then to filter the Selspot <ref> [15] </ref> generates measurements at a rate of 10,000 Hz, the UNC wide-area optoelectronic tracker [13] can activate beacons at a rate of 5000 Hz.
Reference: [16] <institution> National Research Council. </institution> <year> 1994. </year> <title> Virtual Reality, Scientific and Technological Challenges, </title> <publisher> National Academy Press (Washington, </publisher> <address> DC). </address>
Reference-contexts: For example, Foxlin has developed a system that is primarily inertial, but aided by angular position sensors [4], both Canadian Aerospace Electronics <ref> [16] </ref> and the University of North Carolina [13] have pursued systems that are primarily optical, but aided by inertial sensors (for prediction), and researchers at the University of Tokyo have sought to improve the data rate of the Polhemus tracker by augmenting it with rate gyros [21].
Reference: [17] <author> Kuipers, J. B. </author> <title> 1980 SPASYNAn Electromagnetic Relative Position and Orientation Tracking System, </title> <journal> IEEE Transactions on Instrumentation and Measurement , Vol. IM-29, </journal> <volume> No. 4, </volume> <pages> pp. 462-466. </pages>
Reference: [18] <author> Atkeson, C.G., and J.M. Hollerbach. </author> <year> 1985. </year> <title> Kinematic features of unrestrained vertical arm movements, </title> <journal> Journal of Neuroscience, </journal> <volume> 5 </volume> <pages> 2318-2330. </pages>
Reference-contexts: If the target is moving, the assumption is clearly violated. But when does violation of the assumption result in significant error? Typical arm and wrist motion can occur in as little as 1/2 sec ond, with typical fast wrist tangential motion occurring at 3 m/s <ref> [18] </ref>. For the current versions of the systems listed in Table 1, such fast motion corresponds to approximately 2 to 6 centimeters of translation throughout the sequence of measurements required for a single estimate.
Reference: [19] <author> Meyer, K., H. Applewhite and F. Biocca. </author> <year> 1992. </year> <title> A Survey of Position Trackers. Presence, a publication of the Center for Research in Journalism and Mass Communication, </title> <institution> The University of North Carolina at Chapel Hill. </institution>
Reference: [20] <author> Azuma, Ronald. </author> <year> 1995. </year> <title> Predictive Tracking for Augmented Reality, </title> <type> Ph.D. dissertation, </type> <institution> University of North Carolina at Chapel Hill, TR95-007. </institution>
Reference: [21] <author> Emura, S. and S. Tachi. </author> <year> 1994. </year> <title> Sensor Fusion based Measurement of Human Head Motion, </title> <booktitle> Proceedings 3rd IEEE International Workshop on Robot and Human Communication, </booktitle> <address> RO-MAN94 NAGOYA (Nagoya University, Nagoya, Japan). </address>
Reference-contexts: both Canadian Aerospace Electronics [16] and the University of North Carolina [13] have pursued systems that are primarily optical, but aided by inertial sensors (for prediction), and researchers at the University of Tokyo have sought to improve the data rate of the Polhemus tracker by augmenting it with rate gyros <ref> [21] </ref>. The process of blending data from heterogeneous sensors is often referred to as data fusion multi-sensor data fusion example [22]). The Kalman filter [23] has been widely used for data fusion. The true position (shown in red) resembles as would be expected when integrating a sinusoidal velocity.
Reference: [22] <author> Crowley, J. L. and Y. Demazeau. </author> <year> 1993. </year> <title> Principles and Techniques for Sensor Data Fusion, </title> <booktitle> Signal Processing (EURASIP) Vol. </booktitle> <volume> 32. </volume> <pages> pp. 5-27. </pages>
Reference-contexts: The process of blending data from heterogeneous sensors is often referred to as data fusion multi-sensor data fusion example <ref> [22] </ref>). The Kalman filter [23] has been widely used for data fusion. The true position (shown in red) resembles as would be expected when integrating a sinusoidal velocity.
Reference: [23] <author> Kalman, R. E. </author> <year> 1960. </year> <title> A New Approach to Linear Filtering and Prediction Problems, </title> <booktitle> Transaction of the ASMEJournal of Basic Engineering, </booktitle> <pages> pp. </pages> <month> 35-45 (March </month> <year> 1960). </year>
Reference-contexts: The process of blending data from heterogeneous sensors is often referred to as data fusion multi-sensor data fusion example [22]). The Kalman filter <ref> [23] </ref> has been widely used for data fusion. The true position (shown in red) resembles as would be expected when integrating a sinusoidal velocity.
Reference: [24] <author> Geier, G. J., P. V. W. Loomis and A. Cabak. </author> <year> 1987. </year> <title> Guidance Simulation and Test Support for Differential GPS (Global Positioning System) Flight Experiment, </title> <institution> National Aeronautics and Space Administration (Washington, DC) NAS 1.26:177471. </institution>
Reference: [25] <author> Mahmoud, R., O. Loffeld and K. Hartmann. </author> <year> 1994. </year> <title> Multisensor Data Fusion for Automated Guided Vehicles, </title> <booktitle> Proceedings of SPIE - The Interna tional Society for Optical Engineering , Vol. </booktitle> <volume> 2247, </volume> <pages> pp. 85-96. </pages>
Reference: [26] <author> P. Grandjean, A Robert De Saint Vincent. </author> <year> 1989. </year> <title> 3-D Modeling of In door Scenes by Fusion of Noisy Range and Stereo Data, </title> <booktitle> IEEE Internation al Conference on Robotics and Automation (Scottsdale, AZ), </booktitle> <volume> 2 </volume> <pages> 681-687. </pages>
Reference: [27] <author> Van Pabst J. V. L. and Paul F. C. Krekel. </author> <title> Multi Sensor Data Fusion of Points, Line Segments and Surface Segments in 3D Space, </title> <journal> TNO Physics and Electronics Laboratory, The Hague, The Netherlands. </journal> <note> [cited 19 Novem-ber 1995]. Available from http://www.bart.nl/~lawick/index.html. </note>
Reference: [28] <author> Wang, J., R. Azuma, G. Bishop, V. Chi, J. Eyles, and H. Fuchs. </author> <year> 1990. </year> <title> Tracking a head-mounted display in a room-sized environment with head mounted cameras, </title> <booktitle> Proceeding: SPIE'90 Technical Symposium on Optical Engineering & Photonics in Aerospace Sensing (Orlando, </booktitle> <address> FL). </address>
Reference: [29] <author> Gottschalk, Stefan and John F. Hughes. </author> <year> 1993. </year> <title> Autocalibration for Virtual Environments Tracking Hardware, </title> <booktitle> Proceedings of ACM SIGGRAPH '93 (Anaheim, </booktitle> <address> CA, </address> <year> 1993), </year> <title> Computer Graphics, </title> <booktitle> Annual Conference Series. </booktitle>
Reference-contexts: The error introduced by the simultaneity assumption is of even greater concern when attempting any form of autocalibration. Gottschalk et al. state that motion during autocalibration must be severely restricted in order to avoid such errors <ref> [29] </ref>. In a multiple-measurement system with 30 ms total measurement time, motion would have to be restricted to approximately 1.5 cm/s to confine translation (throughout a measurement sequence) to 0.5 mm. For complete calibration of a large (wide-area) tracking system, this restriction results in lengthy specialized autocalibration sessions.
Reference: [30] <author> Maybeck, Peter S. </author> <year> 1979. </year> <title> Stochastic Models, Estimation, and Control, </title> <publisher> Volume 1 , Academic Press, Inc. </publisher>
Reference-contexts: The extended Kalman filter is a variation of the Kalman filter that supports esti mation of nonlinear systems, e.g. 3D position and orientation tracking systems. A very friendly introduction to the Kalman filter can be found in Chapter 1 of <ref> [30] </ref>, while a more complete introductory discussion can be found in [31], which also contains some interesting historical narrative. More extensive references can be found in [1,30,32,33,34,35].
Reference: [31] <author> Sorenson, H. W. </author> <year> 1970. </year> <title> Least-Squares estimation: from Gauss to Kal man, </title> <journal> IEEE Spectrum , Vol. </journal> <volume> 7, </volume> <pages> pp. 63-68, </pages> <month> July </month> <year> 1970. </year>
Reference-contexts: A very friendly introduction to the Kalman filter can be found in Chapter 1 of [30], while a more complete introductory discussion can be found in <ref> [31] </ref>, which also contains some interesting historical narrative. More extensive references can be found in [1,30,32,33,34,35].
Reference: [32] <author> Gelb, A. </author> <year> 1974. </year> <title> Applied Optimal Estimation , MIT Press, </title> <address> Cambridge, MA. </address>
Reference: [33] <author> Lewis, Richard. </author> <year> 1986. </year> <title> Optimal Estimation with an Introduction to Sto chastic Control Theory , John Wiley & Sons, </title> <publisher> Inc. </publisher>
Reference: [34] <author> Brown, R. G. and P. Y. C. Hwang. </author> <year> 1992. </year> <title> Introduction to Random Sig nals and Applied Kalman Filtering, </title> <publisher> 2nd Edition , John Wiley & Sons, Inc. </publisher>
Reference-contexts: This matrix is used to predict the state (3). The dimensional process noise vector normally-distributed zero-mean sequence that represents the uncertainty in the target state over any time interval . The corre sponding process noise covariance matrix is given by We follow the method provided by <ref> [34] </ref> (pp. 221-222) to com pute the elements of which for our model are The parameter has been omitted for clarity. for , where is the derivative counterpart to from (3). The in (7) represents the variance of the (assumed constant) linear and angular accelerations .
Reference: [35] <author> Welch, G. and G. Bishop. </author> <year> 1995. </year> <title> An Introduction to the Kalman Filter, </title> <institution> University of North Carolina, Department of Computer Science, </institution> <type> TR 95-041. </type>
Reference: [36] <author> Deyst J. J. and C. F. Price. </author> <year> 1968. </year> <title> Conditions for Asymptotic Stability of the Discrete Minimum-Variance Linear Estimator, </title> <journal> IEEE Transactions on Automatic Control , December, </journal> <year> 1968. </year>
Reference-contexts: Stability Because the onestep-at-a-time method uses individual measurements with insufficient information, one might be concerned about the potential for instability or divergence. Per the work of Deyst et al. <ref> [36] </ref> we claim that if there are real numbers and such that the conditions Consider repeating the same insufficient measurement indefinitely.

References-found: 36

