URL: ftp://eng.bu.edu/pub/idea/IncRef/flex-dsp.ps.gz
Refering-URL: http://dis.cs.umass.edu/research/ipus/ipus-pubs.html
Root-URL: 
Title: Flexible Systems for Digital Signal Processing  
Author: Joseph M. Winograd, Jeffrey T. Ludwig, S. Hamid Nawab, Alan V. Oppenheim, and Anantha P. Chandrakasan 
Date: Nov. 1996  
Note: From AAAI Fall Symposium on Flexible Computation, Cambridge, MA,  
Address: Boston, MA 02215  Cambridge, MA 02139  
Affiliation: ECE Department, Boston University,  RLE, Massachusetts Institute of Technology,  
Abstract: This research summary outlines several general characteristics of digital signal processing algorithms that distinguish them as a class of computational methods and discusses the relevance of these characteristics to flexible system design. The manner in which these characteristics are manifested in several important signal processing applications is illustrated in brief descriptions of results from the authors' recent work. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Garvey, A., and Lesser, V. </author> <year> 1994. </year> <title> A survey of research in deliberative real-time artificial intelligence. </title> <journal> J. Real-Time Sys. </journal> <volume> 6(3) </volume> <pages> 317-347. </pages>
Reference-contexts: For various applications there exist both formal and informal approaches to managing these tradeoffs, and over the last decade there has been a growing interest in the development of more general, formal, and structured approaches <ref> (Garvey & Lesser 1994) </ref> (Liu et al. 1994) (Zilberstein & Russell 1995). This work has been motivated primarily by a desire to realize flexible systems that can perform demanding tasks in dynamically evolving environments.
Reference: <author> Horvitz, E. J. </author> <year> 1987. </year> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Third Workhsop on Uncertainty in Artificial Intelligence, </booktitle> <pages> 429-439. </pages>
Reference-contexts: The use of formal approaches offers the possibility of developing systems that can continuously optimize their performance within the constraints imposed by currently available resources. Various authors have used the terms approximate processing (Lesser, Pavlin, & Durfee 1988), imprecise computation (Liu et al. 1994), and flexible computation <ref> (Horvitz 1987) </ref> to describe this basic approach to system design. A significant direction in our recent work has been the consideration of these approaches in the context of applications of digital signal processing (DSP).
Reference: <author> Lee, E. A., and Messerschmitt, D. G. </author> <year> 1987. </year> <title> Synchronous data flow. </title> <booktitle> Proc. IEEE 75(9) </booktitle> <pages> 1235-1245. </pages>
Reference-contexts: For example, the importance of obtaining an optimal allocation of resources in real-time systems composed of interrelated flexible tasks has been recognized for some time. The structure of many composite DSP applications can be naturally described using formal, hierarchical models such as the synchronous dataflow paradigm <ref> (Lee & Messerschmitt 1987) </ref>. The success with which the composition problem has been addressed in other structured contexts, such as the compilation of functional expressions (Zilberstein & Russell 1995), suggests that the presence of DSP system models of this kind may be advantageous.
Reference: <author> Lesser, V. R.; Pavlin, J.; and Durfee, E. </author> <year> 1988. </year> <title> Approximate processing in real-time problem solving. </title> <journal> AI Magazine 9(1) </journal> <pages> 49-61. </pages>
Reference-contexts: The use of formal approaches offers the possibility of developing systems that can continuously optimize their performance within the constraints imposed by currently available resources. Various authors have used the terms approximate processing <ref> (Lesser, Pavlin, & Durfee 1988) </ref>, imprecise computation (Liu et al. 1994), and flexible computation (Horvitz 1987) to describe this basic approach to system design. A significant direction in our recent work has been the consideration of these approaches in the context of applications of digital signal processing (DSP).
Reference: <author> Levinson, N. </author> <year> 1947. </year> <title> The Wiener RMS error criterion in filter design and prediction. </title> <journal> J. Math. Phys. </journal> <volume> 25 </volume> <pages> 261-278. </pages>
Reference: <author> Liu, J. W. S.; Shih, W. K.; Lin, K. J.; Bettati, R.; and Chung, J. Y. </author> <year> 1994. </year> <title> Imprecise computations. </title> <booktitle> Proc. IEEE 82(1) </booktitle> <pages> 83-93. </pages>
Reference-contexts: For various applications there exist both formal and informal approaches to managing these tradeoffs, and over the last decade there has been a growing interest in the development of more general, formal, and structured approaches (Garvey & Lesser 1994) <ref> (Liu et al. 1994) </ref> (Zilberstein & Russell 1995). This work has been motivated primarily by a desire to realize flexible systems that can perform demanding tasks in dynamically evolving environments. <p> The use of formal approaches offers the possibility of developing systems that can continuously optimize their performance within the constraints imposed by currently available resources. Various authors have used the terms approximate processing (Lesser, Pavlin, & Durfee 1988), imprecise computation <ref> (Liu et al. 1994) </ref>, and flexible computation (Horvitz 1987) to describe this basic approach to system design. A significant direction in our recent work has been the consideration of these approaches in the context of applications of digital signal processing (DSP). <p> The impact of most DSP operations on these metrics has been studied in depth. Thus, the information required to obtain a performance profile (Zilberstein & Russell 1995) (or error function <ref> (Liu et al. 1994) </ref>) describing a given algorithm is often readily available and can, in many instances, be obtained analytically. DSP algorithms are also notable in the regularity of their internal structure.
Reference: <author> Ludwig, J. T.; Nawab, S. H.; and Chandrakasan, A. </author> <year> 1996. </year> <title> Low-power digital filtering using approximate processing. </title> <journal> IEEE J. Solid State Circ. </journal> <volume> 31(3) </volume> <pages> 395-400. </pages>
Reference-contexts: The control mechanism employs performance profiles that have been developed for several classes of frequency-selective filters <ref> (Ludwig, Nawab, & Chandrakasan 1996) </ref>. Conclusions The general characteristics held by typical applications of DSP suggest that they present a suitable domain for applying formal methodologies for managing tradeoffs between the quality of system performance and the utilization of system resources.
Reference: <author> Nawab, S. H.; Oppenheim, A. V.; Chandrakasan, A. P.; Winograd, J. M.; and Ludwig, J. T. </author> <year> 1996. </year> <title> Approximate signal processing. </title> <journal> J. VLSI Sig. Proc. Forthcoming. </journal>
Reference-contexts: In the context of detecting sinusoids in noise, the FFT possesses the incremental refinement property. By considering the performance of the maximum-likelihood (ML) detection strategy applied after successive FFT stages, we have shown <ref> (Winograd, Nawab, & Oppenheim 1996) </ref> that the performance of the resulting suboptimal detector improves incrementally, converging ultimately to that of the exact ML detector. <p> The arithmetic complexity of each stage, however, depends upon the nature of the input signal. The performance of the members of this class of algorithms have been characterized with performance distribution profiles, based on the assumption of stationary Gaussian-distributed input signals <ref> (Winograd & Nawab 1996) </ref>. Low-power Digital Filtering The increasing demand for battery operated portable electronic devices has caused power dissipation to become a critical design parameter for many practical applications. Typically, optimization to lower the power dissipation is done statically at design time. <p> Our approach employs an efficient control mechanism for the run-time adaptation of the number of stages performed with the aim of keeping it as small as possible while ensuring that the ratio of the in-band power to the out-of-band power for the filter output is kept above a specified threshold <ref> (Nawab et al. 1996) </ref>. The control mechanism employs performance profiles that have been developed for several classes of frequency-selective filters (Ludwig, Nawab, & Chandrakasan 1996). <p> The control mechanism employs performance profiles that have been developed for several classes of frequency-selective filters <ref> (Ludwig, Nawab, & Chandrakasan 1996) </ref>. Conclusions The general characteristics held by typical applications of DSP suggest that they present a suitable domain for applying formal methodologies for managing tradeoffs between the quality of system performance and the utilization of system resources.
Reference: <editor> Oppenheim, A. V., and Nawab, S. H., eds. </editor> <booktitle> 1992. Symbolic and Knowledge-Based Signal Processing. </booktitle> <address> Engle-wood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: DSP algorithms perform stream processing; that is, they can be considered to compute infinite length output sequences from infinite length input sequences. 1 Flexible computing methods are also of relevance for many non-traditional signal processing systems, such as those that incorporate non-numeric processing <ref> (Oppenheim & Nawab 1992) </ref>. These applications typically have structures similar to those considered in previous studies of flexible computing. Since typical applications employ fixed sampling rates at their inputs and outputs, situated DSP systems must meet real-time processing constraints or face eventual buffer overflow.
Reference: <author> Vetterli, M., and Herley, C. </author> <year> 1992. </year> <title> Wavelets and filter banks: Theory and design. </title> <journal> IEEE Trans. Sig. Proc. </journal> <volume> 40(9) </volume> <pages> 2207-2232. </pages>
Reference-contexts: For example, Levin-son's recursion algorithm for linear prediction (Levin-son 1947), which is widely used in speech processing and other applications, produces signal models in successive iterations with successively increasing model order. As another example, the wavelet signal decomposition <ref> (Vetterli & Herley 1992) </ref> can be implemented using a tree-structured filter bank in which each branch of the tree produces successively more detailed analyses of the time-frequency composition of the signal. Our work has explored some of the less obvious methods for obtaining incremental refinement behavior in DSP applications.
Reference: <author> Winograd, J. M., and Nawab, S. H. </author> <year> 1995. </year> <title> Incremental refinement of DFT and STFT approximations. </title> <journal> IEEE Sig. Proc. Letters 2(2) </journal> <pages> 25-28. </pages>
Reference-contexts: The development of incremental refinement approaches to spectral analysis using the DFT can therefore be expected to have a significant impact on the applicability of flexible computing techniques for those systems. We have developed a new class of approximate DFT algorithms <ref> (Winograd & Nawab 1995) </ref> which have the incremental refinement property. The quality of the DFT approximation obtained after each stage can be characterized in terms of commonly used input-independent metrics for spectral quality: SNR, frequency resolution, and frequency coverage.
Reference: <author> Winograd, J. M., and Nawab, S. H. </author> <year> 1996. </year> <title> Probabilistic complexity analysis for a class of approximate DFT algorithms. </title> <journal> J. VLSI Sig. Proc. Forthcoming. </journal>
Reference-contexts: In the context of detecting sinusoids in noise, the FFT possesses the incremental refinement property. By considering the performance of the maximum-likelihood (ML) detection strategy applied after successive FFT stages, we have shown <ref> (Winograd, Nawab, & Oppenheim 1996) </ref> that the performance of the resulting suboptimal detector improves incrementally, converging ultimately to that of the exact ML detector. <p> The arithmetic complexity of each stage, however, depends upon the nature of the input signal. The performance of the members of this class of algorithms have been characterized with performance distribution profiles, based on the assumption of stationary Gaussian-distributed input signals <ref> (Winograd & Nawab 1996) </ref>. Low-power Digital Filtering The increasing demand for battery operated portable electronic devices has caused power dissipation to become a critical design parameter for many practical applications. Typically, optimization to lower the power dissipation is done statically at design time.
Reference: <author> Winograd, J. M.; Nawab, S. H.; and Oppenheim, A. V. </author> <year> 1996. </year> <title> FFT-based incremental refinement of suboptimal detection. </title> <booktitle> In Proc. IEEE Int. Conf. Acoust., Speech, and Sig. Processing, </booktitle> <pages> 2479-2482. </pages>
Reference-contexts: In the context of detecting sinusoids in noise, the FFT possesses the incremental refinement property. By considering the performance of the maximum-likelihood (ML) detection strategy applied after successive FFT stages, we have shown <ref> (Winograd, Nawab, & Oppenheim 1996) </ref> that the performance of the resulting suboptimal detector improves incrementally, converging ultimately to that of the exact ML detector. <p> The arithmetic complexity of each stage, however, depends upon the nature of the input signal. The performance of the members of this class of algorithms have been characterized with performance distribution profiles, based on the assumption of stationary Gaussian-distributed input signals <ref> (Winograd & Nawab 1996) </ref>. Low-power Digital Filtering The increasing demand for battery operated portable electronic devices has caused power dissipation to become a critical design parameter for many practical applications. Typically, optimization to lower the power dissipation is done statically at design time.
Reference: <author> Zilberstein, S., and Russell, S. </author> <year> 1995. </year> <title> Optimal composition of real-time systems. Artif. Intel. </title> <publisher> 82(1-2):181-213. </publisher>
Reference-contexts: For various applications there exist both formal and informal approaches to managing these tradeoffs, and over the last decade there has been a growing interest in the development of more general, formal, and structured approaches (Garvey & Lesser 1994) (Liu et al. 1994) <ref> (Zilberstein & Russell 1995) </ref>. This work has been motivated primarily by a desire to realize flexible systems that can perform demanding tasks in dynamically evolving environments. <p> The impact of most DSP operations on these metrics has been studied in depth. Thus, the information required to obtain a performance profile <ref> (Zilberstein & Russell 1995) </ref> (or error function (Liu et al. 1994)) describing a given algorithm is often readily available and can, in many instances, be obtained analytically. DSP algorithms are also notable in the regularity of their internal structure. <p> The structure of many composite DSP applications can be naturally described using formal, hierarchical models such as the synchronous dataflow paradigm (Lee & Messerschmitt 1987). The success with which the composition problem has been addressed in other structured contexts, such as the compilation of functional expressions <ref> (Zilberstein & Russell 1995) </ref>, suggests that the presence of DSP system models of this kind may be advantageous. Acknowledgment This work was sponsored in part by the Department of the Navy, Office of the Chief of Naval Research, contract number N00014-93-1-0686 as part of the Advanced Research Projects Agency's RASSP program.
References-found: 14

