URL: http://www.cs.purdue.edu/coast/archive/clife/EP/papers/ep93.ps.gz
Refering-URL: http://www.cs.purdue.edu/coast/archive/clife/EP/papers/
Root-URL: http://www.cs.purdue.edu
Title: Evolutionary Programming and Evolution Strategies: Similarities and Differences  
Author: Thomas Back Gunter Rudolph Hans-Paul Schwefel 
Address: P.O. Box 50 05 00 4600 Dortmund 50 Germany  
Affiliation: University of Dortmund Department of Computer Science Chair of Systems Analysis  
Abstract: Evolutionary Programming and Evolution Strategies, rather similar representatives of a class of probabilistic optimization algorithms gleaned from the model of organic evolution, are discussed and compared to each other with respect to similarities and differences of their basic components as well as their performance in some experimental runs. Theoretical results on global convergence, step size control for a strictly convex, quadratic function and an extension of the convergence rate theory for Evolution Strategies are presented and discussed with respect to their implications on Evolutionary Programming. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.H. Ackley. </author> <title> A Connectionist Machine for Genetic Hillclimbing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1987. </year>
Reference-contexts: representatively for the object variables: x 0 8 &gt; &gt; &gt; &gt; : x S;i or x T;i (2) x S i ;i or x T i ;i (4) (6) Indices S and T denote two arbitrarily selected parent individuals, and u is a uniform random variable on the interval <ref> [0; 1] </ref>. Besides completely missing recombination (1), the different variants indicated are discrete recombination (2), intermediate recombination (3) and the global versions (4), (5) of the latter two, respectively. <p> However, nothing is known theoretically about recombination up to now. 5 Experimental Comparison Just to achieve a first assessment of the behaviour of both algorithms, experiments were run on the sphere model f 2 (x) = kxk 2 and the generalized variant of a multimodal function by Ackley (see <ref> [1] </ref>, pp. 13-14): f 9 (x) = 20 exp @ 0:2 u t 1 n X x 2 1 exp 1 n X cos (2x i ) + 20 + e ; test functions that represent the class of strictly convex, unimodal as well as highly multimodal topologies, respectively.
Reference: [2] <author> N. Baba. </author> <title> Convergence of random optimization methods for constrained optimization methods. </title> <journal> Journal of Optimization Theory and Aplications, </journal> <volume> 33 </volume> <pages> 451-461, </pages> <year> 1981. </year>
Reference: [3] <editor> Thomas Back, Frank Hoffmeister, and Hans-Paul Schwefel. </editor> <title> Applications of evolutionary algorithms. Report of the Systems Analysis Research Group (LS XI) SYS-2/92, </title> <institution> University of Dortmund, Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings [11, 12, 26, 4, 9, 31, 17] or to the annotated bibliography <ref> [3] </ref>). Until recently, development of these main streams was completely independent from each other.
Reference: [4] <editor> Richard K. Belew and Lashon B. Booker, editors. </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms and their Applications, </booktitle> <institution> University of California, </institution> <address> San Diego, USA, 1991. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: and several applications of these al fl baeck@ls11.informatik.uni-dortmund.de y rudolph@ls11.informatik.uni-dortmund.de z schwefel@ls11.informatik.uni-dortmund.de gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings <ref> [11, 12, 26, 4, 9, 31, 17] </ref> or to the annotated bibliography [3]). Until recently, development of these main streams was completely independent from each other.
Reference: [5] <author> Joachim Born. </author> <title> Evolutionsstrategien zur nu-merischen Losung von Adaptationsaufgaben. Dissertation A, Humboldt-Universitat, </title> <address> Berlin, </address> <year> 1978. </year>
Reference: [6] <author> K.-T. Fang, S. Kotz, and K.-W. Ng. </author> <title> Symmetric Multivariate and Related Distributions, </title> <booktitle> volume 36 of Monographs on Statistics and Applied Probability. </booktitle> <publisher> Chapman and Hall, </publisher> <address> London and New York, </address> <year> 1990. </year>
Reference-contexts: In fact, if z is multinormally distributed with zero mean and covariance matrix C = 2 I, then the step size r has a n ()-distribution (see Fang et al. <ref> [6] </ref> for more details).
Reference: [7] <author> David B. Fogel. </author> <title> An analysis of evolutionary programming. </title> <booktitle> In Fogel and Atmar [9], </booktitle> <pages> pages 43-51. </pages>
Reference-contexts: Empirically, discrete recombination on object variables and intermediate recombination on strategy parameters have been observed to give best results. 3 Evolutionary Programming Following the description of an EP algorithm as given by Fogel <ref> [7] </ref> and using the notational style from the previous section, an EP algorithm is formulated as follows: Algorithm 3 (EP) t := 0; initialize P (0) := fx 1 (0); : : : ; x (0)g 2 I where I = IR n ; evaluate P (0): F (x k (0)) <p> 1:224 (see fig. 1) such that E [V + ] = 0:404=n and fl = n jjxjj (13) = n f (x) (14) 0:612 jjrf (x)jj ; (15) where (13) is the value also given by Rechenberg [23] which is converted to (14) and (15) in the notation of Fogel <ref> [7] </ref> and Rappl [20], respectively. Obviously, if we modify f to f a (x) = jjxjj 2 + 1 then control (14) will fail to provide geometrical convergence. One has to subtract some constant from (14) which depends on the value of the (unknown) global minimum.
Reference: [8] <author> David B. Fogel. </author> <title> Evolving Artificial Intelligence. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: To overcome these difficulties, D. B. Fogel developed an extension called meta-EP that self-adapts n variances c 1 ; : : : ; c n per individual quite similar to ESs (see <ref> [8] </ref>, p. 157). <p> It is surely interesting to perform an experimental investigation on strengths and weaknesses of both self-adaptation mechanisms. In addition to standard deviations, the Rmeta-EP al gorithm as proposed by D. B. Fogel (see <ref> [8] </ref>, pp. 287-289) also incorporates the complete vector of n (n 1)=2 correlation coefficients ij = c ij = p f1; : : :; n1g, j 2 fi+1; : : : ; ng), representing the covari-ance matrix A 1 , into the genotype for self-adaptation quite similar to correlated mutations in <p> as follows: * Evolution Strategy: (30,200)-ES with self-adaptation of 30 standard deviations, no correlated mutations, discrete recombination on object variables and global intermediate recombination on standard deviations. * Evolutionary Programming: Meta-EP with self-adaptation of 30 variances, population size = 200, tournament size q = 10 for selection, = 6 (see <ref> [8] </ref>, p. 168). All results were obtained by running ten independent experiments per algorithm and averaging the resulting data, and 40000 functions evaluations were performed for each run on the sphere model in contrast to 200000 function evaluations on Ackley's function.
Reference: [9] <editor> David B. Fogel and Wirt Atmar, editors. </editor> <booktitle> Proceedings of the First Annual Conference on Evolutionary Programming, </booktitle> <address> La Jolla, CA, </address> <month> February 21-22, </month> <year> 1992. </year> <booktitle> Evolutionary Programming Society. </booktitle>
Reference-contexts: and several applications of these al fl baeck@ls11.informatik.uni-dortmund.de y rudolph@ls11.informatik.uni-dortmund.de z schwefel@ls11.informatik.uni-dortmund.de gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings <ref> [11, 12, 26, 4, 9, 31, 17] </ref> or to the annotated bibliography [3]). Until recently, development of these main streams was completely independent from each other.
Reference: [10] <author> L. J. Fogel, A. J. Owens, and M. J. Walsh. </author> <title> Artificial Intelligence through Simulated Evolution. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: 1 Introduction Developed independently from each other, three main streams of so-called Evolutionary Algorithms, i.e. algorithms based on the model of natural evolution as an optimization process, can nowadays be identified: Evolutionary Programming (EP), developed by L. J. Fogel et al. in the U.S. <ref> [10] </ref>, Genetic Algorithms (GAs), developed by J. Holland also in the U.S. [15], and Evolution Strategies (ESs), developed in Germany by I. Rechen-berg [23] and H.-P. Schwefel [29].
Reference: [11] <editor> J. J. Grefenstette, editor. </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms and Their Applications, </booktitle> <address> Hillsdale, New Jersey, 1985. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: and several applications of these al fl baeck@ls11.informatik.uni-dortmund.de y rudolph@ls11.informatik.uni-dortmund.de z schwefel@ls11.informatik.uni-dortmund.de gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings <ref> [11, 12, 26, 4, 9, 31, 17] </ref> or to the annotated bibliography [3]). Until recently, development of these main streams was completely independent from each other.
Reference: [12] <editor> J. J. Grefenstette, editor. </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms and Their Applications, </booktitle> <address> Hillsdale, New Jersey, 1987. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: and several applications of these al fl baeck@ls11.informatik.uni-dortmund.de y rudolph@ls11.informatik.uni-dortmund.de z schwefel@ls11.informatik.uni-dortmund.de gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings <ref> [11, 12, 26, 4, 9, 31, 17] </ref> or to the annotated bibliography [3]). Until recently, development of these main streams was completely independent from each other.
Reference: [13] <author> H. Haario and E. Saksman. </author> <title> Simulated annealing process in general state space. </title> <journal> Adv. Appl. Prob., </journal> <volume> 23 </volume> <pages> 866-893, </pages> <year> 1991. </year>
Reference-contexts: A possible way to avoid nonconvergence may be achieved by restricting the probability of accepting a worse point. In fact, if this probability is decreasing with a certain rate over time global convergence can be assured under some conditions (see Haario and Saksman <ref> [13] </ref>). With this additional feature a (; )-ES (without recombination) is equivalent to special variants of so-called Simulated Annealing algorithms that are designed for optimizing in IR n . This relationship is investigated in Rudolph (preprint 92).
Reference: [14] <author> Frank Hoffmeister and Thomas Back. </author> <title> Genetic algorithms and evolution strategies: Similarities and differences. </title> <booktitle> In Schwefel and Manner [31], </booktitle> <pages> pages 455-470. </pages>
Reference-contexts: Contact between the EP-community and the ES-community, however, has been established for the first time just in 1992. For algorithms bearing so much similarities as ESs and EP do, this is a surprising fact. Similar to a paper comparing ES and GA approaches <ref> [14] </ref>, the aim of this article is to give an introduction to ESs and EP and to look for similarities and differences between both approaches. A brief overview of the historical development of ESs as well as an explanation of the basic algorithm are given in section 2.
Reference: [15] <author> John H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: J. Fogel et al. in the U.S. [10], Genetic Algorithms (GAs), developed by J. Holland also in the U.S. <ref> [15] </ref>, and Evolution Strategies (ESs), developed in Germany by I. Rechen-berg [23] and H.-P. Schwefel [29]. These algorithms are based on an arbitrarily initialized population of search points, which by means of randomized processes of selection, mutation, and (sometimes) recombination evolves towards better and better regions in the search space.
Reference: [16] <author> N.L. Johnson and S. Kotz. </author> <title> Distributions in Statistics: Continuous Distributions - 2. </title> <publisher> Houghton Mif-flin, </publisher> <address> Boston, </address> <year> 1970. </year>
Reference-contexts: Using the fact that <ref> [16, p. 135] </ref> n () (n + ) 2 (n + 2) for n ! 1 the limiting distribution of the normalized variation of objective function values V becomes V := f (x t ) 2 2 2 ! 1 jjx t jj p = n s 2 r n 4
Reference: [17] <editor> Reinhard Manner and Bernard Manderick, editors. </editor> <title> Parallel Problem Solving from Nature, 2. </title> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: and several applications of these al fl baeck@ls11.informatik.uni-dortmund.de y rudolph@ls11.informatik.uni-dortmund.de z schwefel@ls11.informatik.uni-dortmund.de gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings <ref> [11, 12, 26, 4, 9, 31, 17] </ref> or to the annotated bibliography [3]). Until recently, development of these main streams was completely independent from each other.
Reference: [18] <author> N.R. Patel, R.L. Smith, and Z.B. Zabinsky. </author> <title> Pure adaptive search in monte carlo optimization. </title> <journal> Mathematical Programming, </journal> <volume> 43(3) </volume> <pages> 317-328, </pages> <year> 1988. </year>
Reference-contexts: Rappl [20] has shown that the conditions of theorem 2 can be weaken such that the objective function is required to be only almost everywhere differentiable and that the level sets possess a "bounded asphericity", especially close to the minimizer. The algorithm of Patel et al. <ref> [18] </ref> called pure adaptive search requires only convexity to assure geometrical convergence. However, this algorithm uses a uniform distribution over the lower level sets for sampling a new point. Naturally, this distribution is unknown in general.
Reference: [19] <author> J. Pinter. </author> <title> Convergence properties of stochastic optimization procedures. </title> <journal> Math. Operat. Stat. , Ser. Optimization, </journal> <volume> 15 </volume> <pages> 405-427, </pages> <year> 1984. </year>
Reference-contexts: However, if condition (12) is not fulfilled then one may conclude that the probability to obtain the global minimum for any start ing point x 0 2 M with increasing t is zero as pointed out by Pinter <ref> [19] </ref>. 4.3 Convergence rates The attempt to determine the convergence rate of algorithms of type (11) was initiated by Rastrigin [22] and continued by Schumer and Steiglitz [28] and Rechenberg [23].
Reference: [20] <author> G. Rappl. </author> <title> Konvergenzraten von Random Search Verfahren zur globalen Optimierung. </title> <type> Dissertation, </type> <institution> HSBw Munchen, Germany, </institution> <year> 1984. </year>
Reference-contexts: Moreover, Rappl <ref> [20, p. 102-143] </ref> has shown that the step size can be adapted via a success/failure control similar to the proposal of [23]. <p> 1) such that E [V + ] = 0:404=n and fl = n jjxjj (13) = n f (x) (14) 0:612 jjrf (x)jj ; (15) where (13) is the value also given by Rechenberg [23] which is converted to (14) and (15) in the notation of Fogel [7] and Rappl <ref> [20] </ref>, respectively. Obviously, if we modify f to f a (x) = jjxjj 2 + 1 then control (14) will fail to provide geometrical convergence. One has to subtract some constant from (14) which depends on the value of the (unknown) global minimum. <p> It can be shown that this asymptotic bound cannot be improved by a (1 + )-ES. 2 4.6 Open questions Theorem 2 provides convergence rate results and step size adjustment rules for strongly convex problems. Rappl <ref> [20] </ref> has shown that the conditions of theorem 2 can be weaken such that the objective function is required to be only almost everywhere differentiable and that the level sets possess a "bounded asphericity", especially close to the minimizer.
Reference: [21] <author> G. Rappl. </author> <title> On linear convergence of a class of random search algorithms. </title> <journal> Zeitschrift f. angew. Math. Mech. (ZAMM), </journal> <volume> 69(1) </volume> <pages> 37-45, </pages> <year> 1989. </year>
Reference: [22] <author> L.A. Rastrigin. </author> <title> The convergence of the random search method in the extremal control of a many-parameter system. </title> <journal> Automation and Remote Corn-trol, </journal> <volume> 24 </volume> <pages> 1337-1342, </pages> <year> 1963. </year>
Reference-contexts: one may conclude that the probability to obtain the global minimum for any start ing point x 0 2 M with increasing t is zero as pointed out by Pinter [19]. 4.3 Convergence rates The attempt to determine the convergence rate of algorithms of type (11) was initiated by Rastrigin <ref> [22] </ref> and continued by Schumer and Steiglitz [28] and Rechenberg [23]. Each of them calculated the expected progress w.r.t. the objective value or distance to the minimizer of special convex functions.
Reference: [23] <author> Ingo Rechenberg. </author> <title> Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biolo-gischen Evolution. </title> <publisher> Frommann-Holzboog Verlag, Stuttgart, </publisher> <year> 1973. </year>
Reference-contexts: J. Fogel et al. in the U.S. [10], Genetic Algorithms (GAs), developed by J. Holland also in the U.S. [15], and Evolution Strategies (ESs), developed in Germany by I. Rechen-berg <ref> [23] </ref> and H.-P. Schwefel [29]. These algorithms are based on an arbitrarily initialized population of search points, which by means of randomized processes of selection, mutation, and (sometimes) recombination evolves towards better and better regions in the search space. <p> Finally, an overview of similarities and differences of both approaches is summarized in section 6. 2 Evolution Strategies Similar to EP, ESs are also based on real-valued object variables and normally distributed random modifications with expectation zero. According to Rechenberg <ref> [23] </ref>, first experimental applications to parameter optimization, performed during the middle of the sixties at the Technical University of Berlin, dealt with hydrodynam-ical problems like shape optimization of a bended pipe and a flashing nozzle. <p> The variation of , i.e. the step-size control of the algorithm, is done according to a theoretically supported rule which is due to Rechenberg <ref> [23] </ref>. <p> This forms the basis of Rechen berg's 1=5 success rule <ref> [23] </ref>: The ratio of successful mutations to all mutations should be 1=5. If it is greater, increase; if it is less, decrease the standard deviation . <p> minimum for any start ing point x 0 2 M with increasing t is zero as pointed out by Pinter [19]. 4.3 Convergence rates The attempt to determine the convergence rate of algorithms of type (11) was initiated by Rastrigin [22] and continued by Schumer and Steiglitz [28] and Rechenberg <ref> [23] </ref>. Each of them calculated the expected progress w.r.t. the objective value or distance to the minimizer of special convex functions. <p> Moreover, Rappl [20, p. 102-143] has shown that the step size can be adapted via a success/failure control similar to the proposal of <ref> [23] </ref>. The idea is to decrease the step size with a factor fl 1 2 (0; 1) if there was a failure and to increase the step size by a factor fl 2 &gt; 1 if there was a success. <p> The expectation becomes maximal for s fl = 1:224 (see fig. 1) such that E [V + ] = 0:404=n and fl = n jjxjj (13) = n f (x) (14) 0:612 jjrf (x)jj ; (15) where (13) is the value also given by Rechenberg <ref> [23] </ref> which is converted to (14) and (15) in the notation of Fogel [7] and Rappl [20], respectively. Obviously, if we modify f to f a (x) = jjxjj 2 + 1 then control (14) will fail to provide geometrical convergence.
Reference: [24] <author> S.L. Resnick. </author> <title> Extreme values, regular variation, and point processes, volume 4 of Applied Probability. </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Then M := maxfX 1 ; : : : ; X g is a random variable with c.d.f. P fM xg = F (x) = (x). Consequently, c 1; = E [M ]. According to Resnick <ref> [24, pp. 71-72] </ref> we have: P fM a x + b g = F (a x + b ) for ! 1 with a = (2 log ) 2 1 log log + log (4) p Let Y have c.d.f.
Reference: [25] <author> Gunter Rudolph. </author> <title> On correlated mutations in evolution strategies. </title> <booktitle> In Manner and Manderick [17], </booktitle> <pages> pages 105-114. </pages>
Reference-contexts: For corre lated mutations in ESs, the feasibility of the correlation procedure has recently been shown by Rudolph <ref> [25] </ref>. 4 Theoretical Properties of Evo lution Strategies 4.1 Problem statement and method for mulation Before summarizing convergence results of ES-type op timization methods some basic definitions and assump tions are to be made.
Reference: [26] <editor> J. David Schaffer, editor. </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms and Their Applications, </booktitle> <address> San Mateo, California, June 1989. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: and several applications of these al fl baeck@ls11.informatik.uni-dortmund.de y rudolph@ls11.informatik.uni-dortmund.de z schwefel@ls11.informatik.uni-dortmund.de gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings <ref> [11, 12, 26, 4, 9, 31, 17] </ref> or to the annotated bibliography [3]). Until recently, development of these main streams was completely independent from each other.
Reference: [27] <author> A. Scheel. </author> <title> Beitrag zur Theorie der Evolutionsstrate-gie. </title> <type> Dissertation, </type> <institution> TU Berlin, </institution> <address> Berlin, </address> <year> 1985. </year>
Reference-contexts: This relationship is investigated in Rudolph (preprint 92). Despite the lack of a theoretical guarantee of global convergence it is possible to calculate the convergence rates for some special problems. This has been done by Schwefel [29][30] and Scheel <ref> [27] </ref> for the same problem as in the previous example using a (1; )-ES: Example 2 Similarly to example 1 for large n the optimal setting of can be calculated fl = 2n Then, the expected improvement is E [V ] = c 2 1; =n with c 1; = p <p> example 1 for large n the optimal setting of can be calculated fl = 2n Then, the expected improvement is E [V ] = c 2 1; =n with c 1; = p 1 Z u exp 2 (u) du (16) The value of c 1; has been tabularized in <ref> [27] </ref>. However, a closer look at (16) reveals that this expression is equivalent with the expected value of the maximum of i.i.d. unit normal random variables: Let X i ~ N (0; 1) for i = 1; : : :; .
Reference: [28] <author> M.A. Schumer and K. Steiglitz. </author> <title> Adaptive step size random search. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 13 </volume> <pages> 270-276, </pages> <year> 1968. </year>
Reference-contexts: obtain the global minimum for any start ing point x 0 2 M with increasing t is zero as pointed out by Pinter [19]. 4.3 Convergence rates The attempt to determine the convergence rate of algorithms of type (11) was initiated by Rastrigin [22] and continued by Schumer and Steiglitz <ref> [28] </ref> and Rechenberg [23]. Each of them calculated the expected progress w.r.t. the objective value or distance to the minimizer of special convex functions.
Reference: [29] <editor> Hans-Paul Schwefel. </editor> <title> Numerische Optimierung von Computer-Modellen mittels der Evolutionsstrategie, </title> <booktitle> volume 26 of Interdisciplinary systems research. </booktitle> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1977. </year>
Reference-contexts: J. Fogel et al. in the U.S. [10], Genetic Algorithms (GAs), developed by J. Holland also in the U.S. [15], and Evolution Strategies (ESs), developed in Germany by I. Rechen-berg [23] and H.-P. Schwefel <ref> [29] </ref>. These algorithms are based on an arbitrarily initialized population of search points, which by means of randomized processes of selection, mutation, and (sometimes) recombination evolves towards better and better regions in the search space.
Reference: [30] <editor> Hans-Paul Schwefel. </editor> <title> Numerical Optimization of Computer Models. </title> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1981. </year>
Reference-contexts: This forms the basis of Rechen berg's 1=5 success rule [23]: The ratio of successful mutations to all mutations should be 1=5. If it is greater, increase; if it is less, decrease the standard deviation . For this algorithm, Schwefel <ref> [30] </ref> suggested to measure the success probability p by observing this ratio during the search and to adjust = (t) according to (t) = &lt; (t 1) c ; if p &gt; 1=5 (t) ; if p = 1=5 For the constant c, he proposed to use c = 0:85 1=n
Reference: [31] <editor> Hans-Paul Schwefel and Reinhard Manner, editors. </editor> <booktitle> Parallel Problem Solving from Nature | Proc. 1st Workshop PPSN I, volume 496 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: and several applications of these al fl baeck@ls11.informatik.uni-dortmund.de y rudolph@ls11.informatik.uni-dortmund.de z schwefel@ls11.informatik.uni-dortmund.de gorithms to real-world problems have clearly demonstrated their capability to yield good approximate solutions even in case of complicated multimodal topological surfaces of the fitness landscape (for overviews of applications, the reader is referred to the conference proceedings <ref> [11, 12, 26, 4, 9, 31, 17] </ref> or to the annotated bibliography [3]). Until recently, development of these main streams was completely independent from each other.
Reference: [32] <author> F.J. Solis and R.J.-B. Wets. </author> <title> Minimization by random search techniques. </title> <journal> Math. Operations Research, </journal> <volume> 6 </volume> <pages> 19-30, </pages> <year> 1981. </year>
Reference: [33] <author> A. Torn and A. Zilinskas. </author> <title> Global Optimization, </title> <booktitle> volume 350 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin and Heidelberg, </address> <year> 1989. </year>
Reference-contexts: The last assumption skips those problems where optimization is a hopeless task (see <ref> [33, p. 7] </ref>).
Reference: [34] <author> J. Vogelsang. </author> <title> Theoretische Betrachtungen zur Schrittweitensteuerungen in Evolutionsstrategien. </title> <type> Diploma thesis, </type> <institution> University of Dortmund, Chair of System Analysis, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Obviously, convergence rates are closely connected to the adaptation of the sampling distribution. Incorporating distribution parameters within the evolutionary process may be a possible solution. This technique can be subsumed under the term self-adaptation. First attempts to analyse this technique have been done by Vo-gelsang <ref> [34] </ref>. In this context recombination may play an important role because it can be seen as an operation that connects the more or less local mutation distributions of single individuals to a more global mutation distribution of the whole population.
Reference: [35] <author> Y. Wardi. </author> <title> Random search algorithms with sufficient descent for minimization of functions. </title> <journal> Mathematics of Operations Research, </journal> <volume> 14(2) </volume> <pages> 343-354, </pages> <year> 1989. </year>
Reference-contexts: However, as pointed out by Schwefel [29][30] there are some differences concerning the convergence rates: The larger the number of offspring the better the convergence rate. We shall discuss the relationship in the next subsection. Wardi <ref> [35] </ref> proposed a (1 + )-ES where is a random variable depending on the amount of improvement, i.e. new offspring are generated as long as the improvement is below a certain decreasing limit which is used to adjust the step sizes as well. 4.5 (; )-Evolution Strategies For this type of
Reference: [36] <author> Z.B. Zabinsky and R.L. Smith. </author> <title> Pure adaptive search in global optimization. </title> <journal> Mathematical Programming, </journal> <volume> 53 </volume> <pages> 323-338, </pages> <year> 1992. </year>
Reference-contexts: The algorithm of Patel et al. [18] called pure adaptive search requires only convexity to assure geometrical convergence. However, this algorithm uses a uniform distribution over the lower level sets for sampling a new point. Naturally, this distribution is unknown in general. Recently Zabinsky and Smith <ref> [36] </ref> have given the impressive result that this algorithm converges geometri cally even for lipshitz-continuous functions with several local minima. This rises hope to design an Evolutionary Algorithm that converges to the global optimum of certain nonconvex problem classes with a reasonable rate.
Reference: [37] <author> A.A. Zhigljavsky. </author> <title> Theory of global random search, volume 65 of Mathematics and its applications (Soviet Series). </title> <publisher> Kluwer, </publisher> <address> AA Dordrecht, The Nether-lands, </address> <year> 1991. </year>
References-found: 37

