URL: ftp://ftp.cs.dartmouth.edu/TR/TR94-243.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR94-243/
Root-URL: http://www.cs.dartmouth.edu
Title: ViC*: A Preprocessor for Virtual-Memory C*  
Author: Thomas H. Cormen Alex Colvin 
Affiliation: Dartmouth College Computer Science  Dartmouth College Department of Computer Science  
Pubnum: Technical Report PCS-TR94-243  
Abstract: This paper describes the functionality of ViC*, a compiler-like preprocessor for out-of-core C*. The input to ViC* is a C* program but with certain shapes declared outofcore, which means that all parallel variables of these shapes reside on disk. The output is a standard C* program with the appropriate I/O and library calls added for efficient access to out-of-core parallel variables.
Abstract-found: 1
Intro-found: 1
Reference: [ANS92] <institution> American National Standards Institute, Inc. X3.198-1992 Fortran|Extended, </institution> <year> 1992. </year>
Reference-contexts: This execution context determines which positions initiate parallel operations. Context is implicit in all parallel operations, including those in function calls. This use of a current context is one of the distinguishing features of C*, in contrast to FORTRAN 90 <ref> [ANS92, MR90] </ref>, where context has static scope and may be applied only to parallel operations. Like the with statement, a where statement saves state and restores it. ViC* replaces out-of-core where statements with operations on out-of-core boolean variables and the current context pointer, ViC__context.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: To translate out-of-core operations, ViC* decomposes a program into basic blocks. A basic block <ref> [ASU86] </ref> is a maximal sequence of statements with linear control flow.
Reference: [BTC94] <author> Rajesh Bordawekar, Rajeev Thakur, and Alok Choudhary. </author> <title> Efficient compilation of out-of-core data parallel programs. </title> <type> Technical report, </type> <institution> NPAC, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: We want a language in use at several sites and for which there is existing code because we hope that scientific programmers and others will really use ViC*. And we wish to sidestep HPF because there are already two out-of-core HPF projects that we know of, at Syracuse University <ref> [BTC94, TBC94] </ref> and Rice University [KKP94], and because C* presents different implementation challenges from HPF. In particular, HPF uses arrays for parallelism and C* uses shapes, HPF has a much more restricted notion of context than C*, and HPF's style of data distribution differs from that of C*.
Reference: [CGG + 94] <author> Yi-Jen Chiang, Michael T. Goodrich, Edward F. Grove, Roberto Tamassia, Dar-ren Erik Vengroff, and Jeffrey Scott Vitter. </author> <title> External-memory graph algorithms (extended abstract). </title> <note> Submitted to SODA '95, </note> <month> July </month> <year> 1994. </year> <month> 14 </month>
Reference: [CK93] <author> Thomas H. Cormen and David Kotz. </author> <title> Integrating theory and practice in parallel file systems. </title> <booktitle> In Proceedings of the DAGS '93 Symposium, </booktitle> <pages> pages 64-74, </pages> <month> June </month> <year> 1993. </year> <note> Also available as Dartmouth College Computer Science Technical Report PCS-TR93-188. </note>
Reference-contexts: In addition, we expect ViC* to serve as a testbed for parallel I/O research. Because I/O is under the ViC*'s control, we can experiment with parallel I/O algorithms and implementations. Areas of investigation include tradeoffs between synchronous and asynchronous I/O [KKP94], out-of-core algorithms [Cor92], and parallel file systems <ref> [CK93] </ref>. Other extensions to ViC* may include optimizations of elemental functions [KF93]|those which require no parallel communication. We can evaluate an elemental function on an in-core strip, calling it within the body of a sectioning loop.
Reference: [Cor92] <author> Thomas H. Cormen. </author> <title> Virtual Memory for Data-Parallel Computing. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <year> 1992. </year> <note> Available as Technical Report MIT/LCS/TR-559. </note>
Reference-contexts: Variables of the form ViC__name_file and ViC__name_strip reference open file descriptors and in-core data. ViC* also introduces temporary variables beginning ViC__number to hold stacked context information and intermediate results. Other library functions implement out-of-core parallel communication, with versions for a number of special cases <ref> [Cor92] </ref>. 4 Processing of declarations This section describes how ViC* processes out-of-core shape and data declarations. ViC* identifies out-of-core shape declarations by the outofcore modifier and replaces them with ViC__shape declarations. It scans variable declarations for these shapes to identify out-of-core data and replaces them with ViC__data declarations. <p> Function overloading in C* allows both versions to coexist. ViC* processes all communication that involves out-of-core variables (accomplished by parallel left indexing) by generating calls to run-time library functions. This run-time library is an integral part of the virtual-memory package and implements efficient algorithms for special cases of communication <ref> [Cor92] </ref>. The ViC* library implements left indexing of out-of-core variables where the index is scalar, in-core parallel, or out-of-core. It also implements left indexing of in-core parallel variables when the index is out-of-core. <p> In addition, we expect ViC* to serve as a testbed for parallel I/O research. Because I/O is under the ViC*'s control, we can experiment with parallel I/O algorithms and implementations. Areas of investigation include tradeoffs between synchronous and asynchronous I/O [KKP94], out-of-core algorithms <ref> [Cor92] </ref>, and parallel file systems [CK93]. Other extensions to ViC* may include optimizations of elemental functions [KF93]|those which require no parallel communication. We can evaluate an elemental function on an in-core strip, calling it within the body of a sectioning loop. <p> We can evaluate an elemental function on an in-core strip, calling it within the body of a sectioning loop. For arbitrary communications using left indexing, we expect to categorize index values where possible by communications topology, such as grid, torus, transpose, and general permutation. There are special algorithms <ref> [Cor92] </ref> for these communication patterns. File systems normally support persistent data. Program data, such as ViC* out-of-core data, is transient and disappears on program exit. ViC* ensures that such data is properly deleted on scope exit. Global out-of-core data must be deleted specially.
Reference: [Cor93] <author> Thomas H. Cormen. </author> <title> Fast permuting in disk arrays. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 17(1-2):41-57, January and February 1993. </note>
Reference: [CSW94] <author> Thomas H. Cormen, Thomas Sundquist, and Leonard F. Wisniewski. </author> <title> Asymptotically tight bounds for performing BMMC permutations on parallel disk systems. </title> <type> Technical Report PCS-TR94-223, </type> <institution> Dartmouth College Department of Computer Science, </institution> <month> July </month> <year> 1994. </year> <note> Submitted to IEEE Transactions on Parallel and Distributed Systems. Preliminary version appeared in Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures. </note>
Reference: [Den70] <author> Peter J. Denning. </author> <title> Virtual memory. </title> <journal> ACM Computing Surveys, </journal> <volume> 2(3) </volume> <pages> 153-189, </pages> <month> September </month> <year> 1970. </year>
Reference-contexts: Over thirty years ago, computer architects devised virtual memory to solve this problem for sequential machines <ref> [Den70] </ref>. We see two approaches in today's parallel machines: * Have no built-in support for virtual memory. Without built-in virtual-memory support, applications whose memory requirements exceed the available memory typically keep their data on a disk system and perform explicit disk accesses.
Reference: [GTVV93] <author> Michael T. Goodrich, Jyh-Jong Tsay, Darren E. Vengroff, and Jeffrey Scott Vitter. </author> <title> External-memory computational geometry. </title> <booktitle> In Proceedings of the 34th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 714-723, </pages> <month> November </month> <year> 1993. </year>
Reference: [KF93] <author> Alexander C. Klaiber and James L. Frankel. </author> <title> Comparing data-parallel and message-passing paradigms. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <pages> pages II:11-II:20, </pages> <month> August </month> <year> 1993. </year>
Reference: [KKP94] <author> Ken Kennedy, Charles Koelbel, and Mike Paleczny. </author> <title> Scalable I/O for out-of-core structures. </title> <type> Technical Report CRPC-TR93357-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: And we wish to sidestep HPF because there are already two out-of-core HPF projects that we know of, at Syracuse University [BTC94, TBC94] and Rice University <ref> [KKP94] </ref>, and because C* presents different implementation challenges from HPF. In particular, HPF uses arrays for parallelism and C* uses shapes, HPF has a much more restricted notion of context than C*, and HPF's style of data distribution differs from that of C*. <p> In addition, we expect ViC* to serve as a testbed for parallel I/O research. Because I/O is under the ViC*'s control, we can experiment with parallel I/O algorithms and implementations. Areas of investigation include tradeoffs between synchronous and asynchronous I/O <ref> [KKP94] </ref>, out-of-core algorithms [Cor92], and parallel file systems [CK93]. Other extensions to ViC* may include optimizations of elemental functions [KF93]|those which require no parallel communication. We can evaluate an elemental function on an in-core strip, calling it within the body of a sectioning loop.
Reference: [Kot94] <author> David Kotz. </author> <title> Disk-directed I/O for MIMD multiprocessors. </title> <booktitle> In Proceedings of the 1994 Symposiumn on Operating Systems Design and Implementation, </booktitle> <month> November </month> <year> 1994. </year> <note> Available as Dartmouth College Department of Computer Science Technical Report PCS-TR94-226. </note>
Reference: [MR90] <author> Michael Metcalf and John Reid. </author> <title> Fortran 90 Explained. </title> <publisher> Oxford University Press, </publisher> <year> 1990. </year>
Reference-contexts: This execution context determines which positions initiate parallel operations. Context is implicit in all parallel operations, including those in function calls. This use of a current context is one of the distinguishing features of C*, in contrast to FORTRAN 90 <ref> [ANS92, MR90] </ref>, where context has static scope and may be applied only to parallel operations. Like the with statement, a where statement saves state and restores it. ViC* replaces out-of-core where statements with operations on out-of-core boolean variables and the current context pointer, ViC__context.
Reference: [NV91] <author> Mark H. Nodine and Jeffrey Scott Vitter. </author> <title> Large-scale sorting in parallel memories. </title> <booktitle> In Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 29-39, </pages> <month> July </month> <year> 1991. </year>
Reference: [NV92] <author> Mark H. Nodine and Jeffrey Scott Vitter. </author> <title> Optimal deterministic sorting on parallel disks. </title> <type> Technical Report CS-92-08, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1992. </year>
Reference: [TBC94] <author> Rajeev Thakur, Rajesh Bordawekar, and Alok Choudhary. </author> <title> Compilation of out-of-core data parallel programs for distributed memory machines. </title> <booktitle> In IPPS '94 Workshop on Parallel I/O, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: We want a language in use at several sites and for which there is existing code because we hope that scientific programmers and others will really use ViC*. And we wish to sidestep HPF because there are already two out-of-core HPF projects that we know of, at Syracuse University <ref> [BTC94, TBC94] </ref> and Rice University [KKP94], and because C* presents different implementation challenges from HPF. In particular, HPF uses arrays for parallelism and C* uses shapes, HPF has a much more restricted notion of context than C*, and HPF's style of data distribution differs from that of C*.
Reference: [TMC93] <institution> Thinking Machines Corporation. </institution> <note> C* Programming Guide, </note> <month> May </month> <year> 1993. </year> <month> 15 </month>
Reference-contexts: Yet, programmers would not need specialized knowledge of I/O-optimal algorithms in order to avoid huge performance penalties. This paper describes a linguistic step toward such a solution. Our approach is based on the data-parallel language C* <ref> [TMC93] </ref>. A preprocessor, ViC* (Virtual-memory C*), transforms a C* program with parallel variables so large that they must reside on disk into a C* program with all parallel variables fitting in memory and explicit I/O and library calls added. <p> Finally, Appendix A shows the C* code generated by a sample program. 2 Background concepts and overview of ViC* This section introduces the parallel programming model and the language features of C* and ViC* that implement it. More information about the C* language appears in <ref> [TMC93] </ref>. C*, and hence ViC*, support data-parallel programming, in which a sequential program operates on parallel arrays of data, with each virtual processor operating on one parallel data element. The underlying computer multiplexes a set of physical processors among the virtual processors to support the parallel model.
Reference: [VS94] <author> Jeffrey Scott Vitter and Elizabeth A. M. Shriver. </author> <title> Algorithms for parallel memory I: Two-level memories. </title> <journal> Algorithmica, </journal> 12(2/3):110-147, August and September 1994. 
Reference: [WGWR93] <author> David Womble, David Greenberg, Stephen Wheat, and Rolf Riesen. </author> <title> Beyond core: Making parallel computer I/O practical. </title> <booktitle> In DAGS '93, </booktitle> <month> June </month> <year> 1993. </year>
Reference: [ZC90] <author> Hans Zima and Barbara Chapman. </author> <title> Supercompilers for Parallel and Vector Computers. </title> <publisher> ACM Press and Addison-Wesley, </publisher> <year> 1990. </year> <month> 16 </month>
Reference-contexts: Basic blocks are further divided into simple blocks. A simple block is a subset of a basic block delimited by subroutine calls or communication within out-of-core shapes. Each simple block results in a sectioning loop in the C* program produced by ViC*. A simple block strip-mines <ref> [ZC90] </ref> out-of-core data by iterating over in-core sections or strips of the data. To improve performance, ViC* uses dataflow analysis to determine which out-of-core data is required from each simple block in subsequent execution. Such data is live. A variable for which there are no further references is dead.
References-found: 21

