URL: http://www.cse.ogi.edu/~walidt/docs/publications/submitted.ps.gz
Refering-URL: http://www.cse.ogi.edu/~walidt/
Root-URL: http://www.cse.ogi.edu
Email: fwalidt,sheardg@cse.ogi.edu  
Title: MetaML: Multi-Stage Programming with Explicit Annotations  
Author: Walid Taha Tim Sheard 
Affiliation: Oregon Graduate Institute of Science and Technology  
Abstract: We introduce MetaML, a practically-motivated, statically-typed multi-stage programming language. MetaML allows the programmer to construct, combine, and execute code fragments in a type-safe manner. Code fragments can contain free variables, but we ensure that the language obeys the static-scoping principle. MetaML performs type-checking for all stages once and for all before the execution of the first stage. From a software engineering point of view, this means that our programs never generate untypable programs. A thesis of this paper is that multi-stage languages are useful as programming languages in their own right, that they supply a sound basis for high-level program generation technology, and that they should support features that make it possible for programmers to write staged computations without significantly changing their normal programming style. To illustrate this we provide a simple three stage example, and an extended two-stage example elaborating a number of practical issues. The design of MetaML was based on two main principles that we identified as fundamental for high-level program generation, namely, cross-stage persistence and cross-stage safety. We present these principles, explain the technical problems they give rise to, and how we deal with these problems in our implementation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Charles Consel and Olivier Danvy. </author> <title> For a better support of static data flow. </title> <editor> In J. Hughes, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <address> Cambridge, Massachusetts, </address> <booktitle> August 1991 (Lecture Notes in Computer Science, </booktitle> <volume> vol. 523), </volume> <pages> pages 496-519. </pages> <address> New York: </address> <publisher> ACM, Berlin: Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [2] <author> Charles Consel and Olivier Danvy. </author> <title> Tutorial notes on partial evaluation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Following the annotations, the specializer either performs a computation, or produces text for inclusion in the output (residual) program. The relationship between partial-evaluation and multistage programming is that the intermediate data structure between the two steps is a two-stage annotated program <ref> [2, 35] </ref>, and that the specialization phase is (the first stage in) the execution of the two-stage annotated program produced by BTA. Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization [10, 11].
Reference: [3] <author> Charles Consel and Fran~cois Noel. </author> <title> A general approach for run-time specialization and its application to C. </title> <booktitle> In Conference Record of POPL '96: The 23 rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 145-156, </pages> <address> St. Petersburg Beach, Florida, </address> <month> 21-24 January </month> <year> 1996. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [4] <author> Olivier Danvy. </author> <title> Type-directed partial evaluation. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 242-257, </pages> <address> Florida, January 1996. New York: </address> <publisher> ACM. </publisher>
Reference-contexts: On the other hand, the problem of cross-platform portability is similar to that of lifting functional values in partial evaluation, and type-directed partial evaluation may provide a solution to this problem <ref> [4, 44] </ref>. 7.2 Cross-Stage Safety. Even in MetaML, it will not be possible to stage every expression in the language.
Reference: [5] <author> Olivier Danvy, Karoline Malmkjaer, and Jens Pals-berg. </author> <title> The essence of eta-expansion in partial evaluation. </title> <journal> LISP and Symbolic Computation, </journal> <volume> 1(19), </volume> <year> 1995. </year>
Reference-contexts: Our experience is that such functions have considerably fewer annotations, and are easier to think about. This is illustrated in the following section. Finally, we should mention that there is another reason for our interest in back and forth: they are similar to two-level -expansion <ref> [5] </ref>.
Reference: [6] <author> Rowan Davies. </author> <title> A temporal-logic approach to binding time analysis. </title> <booktitle> In Proceedings, 11 th Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 184-195, </pages> <address> New Brunswick, New Jersey, 27-30 July 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: This seems to have been the case in all multi-stage languages known to us to date <ref> [35, 7, 14, 10, 11, 6] </ref>. Intuitively, they use the following monolithic rule for variables: Var (Monolithic): ( x) = t n 0 n when n 0 = n We allow the more general condition n 0 n (assume programs contain no Run). <p> Sheard and Shields [46] investigate a dynamic type systems for multi-staged programs where some type obligations of staged computations can be put off till run-time. Davies and Pfenning present a statically-typed multistage language Mini-ML 2 , motivated by constructive modal logic <ref> [6] </ref>. A formal proof is presented for the equivalence of binding-time correctness and modal correctness. MetaML type-system was motivated primarily by operational considerations. Their language has two constructs, box and let-box, which correspond roughly to Brackets and Run. Mini-ML 2 's 2 type constructor is similar to code. <p> Mini-ML 2 's 2 type constructor is similar to code. Mini-ML 2 can simulate Lift, a stage-zero function, for example, cannot be made persistent. Finally, functions like back are not expressible in Mini-ML 2 . The multi-stage language Mini-ML fl <ref> [6] </ref> is motivated by a linear-time constructive modal logic. The language allows staged expressions to contain monolithic free variables. The two constructs of Mini-ML fl ; next and prev, correspond quite closely to MetaML's Brackets and escape. The type constructor fl also corresponds (roughly) to code.
Reference: [7] <author> Rowan Davies and Frank Pfenning. </author> <title> A modal analysis of staged computation. </title> <booktitle> In 23rd Annual ACM Symposium on Principles of Programming Languages (POPL'96), </booktitle> <address> St.Petersburg Beach, Florida, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation <ref> [7] </ref>. However, there has generally been little support for writing multi-stage programs directly in high level programming languages such as SML or Haskell. 1.2 MetaML MetaML is an SML-like language with special constructs for multi-stage programming. <p> This seems to have been the case in all multi-stage languages known to us to date <ref> [35, 7, 14, 10, 11, 6] </ref>. Intuitively, they use the following monolithic rule for variables: Var (Monolithic): ( x) = t n 0 n when n 0 = n We allow the more general condition n 0 n (assume programs contain no Run).
Reference: [8] <author> Nachum Dershowitz. </author> <title> Computing with rewrite systems. </title> <journal> Information and Control, </journal> <volume> 65 </volume> <pages> 122-157, </pages> <year> 1985. </year>
Reference: [9] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Efficient multilevel generating extensions for program specialization. </title> <editor> In S. D. Swierstra and M. Hermenegildo, editors, </editor> <booktitle> Programming Languages: Implementations, Logics and Programs (PLILP'95), volume 982 of Lecture Notes in Computer Science, </booktitle> <pages> pages 259-278. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [10] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Efficient multilevel generating extensions for program specialization. </title> <booktitle> In Programming Languages, Implementations, Logics and Programs (PLILP'95), volume 982 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: This is the purpose of program staging and it can be highly effective as demonstrated in many studies [3, 18, 17, 9, 13, 26, 38, 51]. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation <ref> [14, 10, 11] </ref>, and a formal foundation for run-time code generation [7]. However, there has generally been little support for writing multi-stage programs directly in high level programming languages such as SML or Haskell. 1.2 MetaML MetaML is an SML-like language with special constructs for multi-stage programming. <p> Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization <ref> [10, 11] </ref>. Their underlying annotated language is closely related to MetaML, but without static-typing. 3 Relationship to LISP MetaML has three annotations, Brackets, Escape, and Run, that are analogous to LISP's back-quote, comma, and eval constructs. This analogy is useful if the reader is familiar with LISP. <p> This is exactly the case when computing the multiplication of 2 matrixes. For each row in the first matrix, the dot product of that row will be taken with each column of the second. This example has appeared in several other works <ref> [10, 25] </ref> and we give our version below. We give three versions of the inner product function. One (iprod) with no staging annotations, the second (iprod2) with two levels of annotations, and the third (iprod3) with two levels of annotations but constructed with the back2 function. <p> This seems to have been the case in all multi-stage languages known to us to date <ref> [35, 7, 14, 10, 11, 6] </ref>. Intuitively, they use the following monolithic rule for variables: Var (Monolithic): ( x) = t n 0 n when n 0 = n We allow the more general condition n 0 n (assume programs contain no Run). <p> This language is the basis for many BTAs. The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type. Our treatment of variables in the implementation semantics is inspired by their work. Gluck and Jtrgensen <ref> [10] </ref> present the novel idea of multilevel BTA (MBTA), as an efficient and effective alternate to multiple self-application. An untyped multi-level language based on Scheme is used for the presentation. <p> When debugging, it is important for users to observe the code produced by their pro grams. This implies a display mechanism (pretty-printer) for values of type code. Facility Example Nielson & Niel son [35] Gomard & Jones [12] Gluck & Jtrgensen <ref> [10] </ref> Thiemann [52] Hatcliff & Gluck [14] Stages &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Var. &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection Run or eval N N N Y N Y N Y
Reference: [11] <author> Robert Gluck and Jesper Jtrgensen. </author> <title> Fast binding-time analysis for multi-level specialization. </title> <booktitle> In PSI-96: An-drei Ershov Second International Memorial Conference, Perspectives of System Informatics, volume 1181 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: This is the purpose of program staging and it can be highly effective as demonstrated in many studies [3, 18, 17, 9, 13, 26, 38, 51]. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation <ref> [14, 10, 11] </ref>, and a formal foundation for run-time code generation [7]. However, there has generally been little support for writing multi-stage programs directly in high level programming languages such as SML or Haskell. 1.2 MetaML MetaML is an SML-like language with special constructs for multi-stage programming. <p> Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization <ref> [10, 11] </ref>. Their underlying annotated language is closely related to MetaML, but without static-typing. 3 Relationship to LISP MetaML has three annotations, Brackets, Escape, and Run, that are analogous to LISP's back-quote, comma, and eval constructs. This analogy is useful if the reader is familiar with LISP. <p> This seems to have been the case in all multi-stage languages known to us to date <ref> [35, 7, 14, 10, 11, 6] </ref>. Intuitively, they use the following monolithic rule for variables: Var (Monolithic): ( x) = t n 0 n when n 0 = n We allow the more general condition n 0 n (assume programs contain no Run). <p> While this is very convenient for run-time code generation, it makes the proper specification of MetaML more difficult. For example, we can't use their "Generic Code Generation functions" to define the language. A second paper by Gluck and Jtrgensen <ref> [11] </ref> demonstrates the impressive efficiency of MBTA, and the use of constraint-solving methods to perform the analysis. The MBTA is type-based, but underlying language is dynamically typed.
Reference: [12] <author> Carsten K. Gomard and Neil D. Jones. </author> <title> A partial evaluator for untyped lambda calculus. </title> <journal> Journal of Functional Programming, </journal> <volume> 1(1) </volume> <pages> 21-69, </pages> <year> 1991. </year>
Reference-contexts: The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set. Recently, Nielson and Niel-son proposed an algebraic framework for the specification of multi-level type systems [36, 37]. Gomard and Jones <ref> [12] </ref> use a statically-typed two-level language for partial evaluation of the untyped -calculus. This language is the basis for many BTAs. The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type. <p> This is crucial when debugging multi-stage programs. * Display of code. When debugging, it is important for users to observe the code produced by their pro grams. This implies a display mechanism (pretty-printer) for values of type code. Facility Example Nielson & Niel son [35] Gomard & Jones <ref> [12] </ref> Gluck & Jtrgensen [10] Thiemann [52] Hatcliff & Gluck [14] Stages &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Var. &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection Run or eval N N N Y
Reference: [13] <author> Brian Grant, Markus Mock, Matthai Philipose, Craig Chambers, and Susan J. Eggers. </author> <title> Annotation-directed run-time specialization in C. </title> <booktitle> In Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 163-178, </pages> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [14] <author> John Hatcliff and Robert Gluck. </author> <title> Reasoning about hierarchies of online specialization systems. </title> <editor> In Olivier Danvy, Robert Gluck, and Peter Thiemann, editors, </editor> <title> Partial Evaluation, </title> <booktitle> volume 1110 of Lecture Notes in Computer Science, </booktitle> <pages> pages 161-182. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: This is the purpose of program staging and it can be highly effective as demonstrated in many studies [3, 18, 17, 9, 13, 26, 38, 51]. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation <ref> [14, 10, 11] </ref>, and a formal foundation for run-time code generation [7]. However, there has generally been little support for writing multi-stage programs directly in high level programming languages such as SML or Haskell. 1.2 MetaML MetaML is an SML-like language with special constructs for multi-stage programming. <p> This seems to have been the case in all multi-stage languages known to us to date <ref> [35, 7, 14, 10, 11, 6] </ref>. Intuitively, they use the following monolithic rule for variables: Var (Monolithic): ( x) = t n 0 n when n 0 = n We allow the more general condition n 0 n (assume programs contain no Run). <p> Thiemann also deals with the issue of variable-arity functions, a practical problem when dealing with eval in Scheme. Hatcliff and Gluck studied a multi-stage flow-chart language called S-Graph-n, and thoroughly investigated the issues involved in the implementation of such a language <ref> [14] </ref>. The syntax of S-Graph-n explicitly captures all the information necessary for specifying the staging of a computation: each construct is annotated with a number indicating the stage during which it is to be executed, and all variables are annotated with a number indicating the stage of their availability. <p> When debugging, it is important for users to observe the code produced by their pro grams. This implies a display mechanism (pretty-printer) for values of type code. Facility Example Nielson & Niel son [35] Gomard & Jones [12] Gluck & Jtrgensen [10] Thiemann [52] Hatcliff & Gluck <ref> [14] </ref> Stages &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Var. &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection Run or eval N N N Y N Y N Y Persistence f.&lt;x.f x&gt; N N N
Reference: [15] <author> Fritz Henglein and Christian Mossin. </author> <title> Polymorphic binding-time analysis. </title> <editor> In Donald Sannella, editor, </editor> <booktitle> Programming Languages and Systems - ESOP 94 5th Euro-pean Symposium on Programming, volume 788 of Lecture Notes in Computer Science, </booktitle> <pages> pages 287-301, </pages> <address> Edin-burgh, U.K., April 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: We expect that the works of Nielson and Nielson, and Moggi, will serve as a good basis for as signing such a semantics to MetaML. 3. MetaML admits the analog of polyvariant specialization <ref> [15] </ref> by annotating differently copies of the same program. It is not yet clear how to make this task easier for the programmer. 4. The Term-rewriting example (Appendix A) shows that further optimizations on the generated code can be useful.
Reference: [16] <author> James Hook and Tim Sheard. </author> <title> A semantics of compile-time reflection. </title> <type> Technical Report CSE 93-019, </type> <institution> Oregon Graduate Institute, </institution> <year> 1993. </year>
Reference-contexts: MetaML is a descendent of CRML <ref> [42, 43, 16] </ref>, which in turn was greatly influenced by TRPL [40, 41]. All three of these languages support linguistic reflection. Both CRML and TRPL were two stage languages that allowed users to provide compile-time functions (much like macro's) which directed the compiler to perform compile-time reductions.
Reference: [17] <author> Luke Hornof, Charles Consel, and Jacques Noye. </author> <title> Effective specialization of realistic programs via use sensitivity. </title> <booktitle> In SAS 1997, </booktitle> <pages> pages 293-314, </pages> <address> Paris, France, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [18] <author> Luke Hornof and Jacques Noye. </author> <title> Accurate binding-time analysis for imperative languages: Flow, context, and return sensitivity. </title> <booktitle> In Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 63-73, </pages> <address> Amsterdam, The Netherlands, </address> <month> 12-13 June </month> <year> 1997. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [19] <author> Neil D. Jones. </author> <title> Mix ten years later. In Partial Evaluation and Semantics-Based Program Manipulation, New Haven, </title> <journal> Connecticut (Sigplan Notices, </journal> <volume> vol. 26, no. 9, </volume> <month> September </month> <year> 1991), </year> <pages> pages 24-38. </pages> <address> New York: </address> <publisher> ACM, </publisher> <address> New York: </address> <publisher> ACM, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: The subtlety of the semantics of annotated programs warrants studying them in relative isolation, and without the added complexity of other partial evaluation issues such as BTA. Pedagogical tool. It has been observed that it is sometimes hard for users to understand the workings of partial evaluation systems <ref> [19] </ref>. New users often lack a good mental model of how partial evaluation systems work. Although BTA is an involved process, requiring special expertise, the annotations it produces are relatively simple and easy to understand.
Reference: [20] <author> Neil D. Jones. </author> <title> What not to do when writing an interpreter for specialisation. </title> <editor> In Olivier Danvy, Robert Gluck, and Peter Thiemann, editors, </editor> <title> Partial Evaluation, </title> <booktitle> volume 1110 of Lecture Notes in Computer Science, </booktitle> <pages> pages 216-237. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Controlling Evaluation Order. Whenever performance is an issue, control of evaluation order is important. BTA optimizes the evaluation order given the time of arrival of inputs, but sometimes it is just easier to say what is wanted, rather than to force a BTA to discover it <ref> [20] </ref>. Automatic analyses like BTA are necessarily incomplete, and can only approximate the knowledge of the programmer. By using explicit annotations the programmer can exploit his full knowledge of the program domain.
Reference: [21] <author> Neil D. Jones, Carsten K Gomard, and Peter Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: be available in futures stages. * Cross-stage safety: An input first available in a par ticular stage cannot be used at an earlier stage. * Static scoping of variables in code fragments. 2 Relationship to Partial Evaluation Today, the most sophisticated automatic staging techniques are found in partial evaluation systems <ref> [21] </ref>. Partial evaluation optimizes a program using a priori information about some of that program's inputs. The goal is to identify and perform as many computations as possible in a program before run-time. O*ine partial evaluation has two distinct steps, binding-time analysis (BTA) and specialization. <p> Having a programming language with explicit staging annotations would help users of partial evaluation understand more of the issues involved in staged computation, and, hopefully, reduce the steep learning curve currently associated with learning to use a partial evaluator effectively <ref> [21] </ref>. Controlling Evaluation Order. Whenever performance is an issue, control of evaluation order is important. BTA optimizes the evaluation order given the time of arrival of inputs, but sometimes it is just easier to say what is wanted, rather than to force a BTA to discover it [20].
Reference: [22] <author> Simon L. Peyton Jones and John Launchbury. </author> <title> Unboxed values as first class citizens in a non-strict functional language. </title> <booktitle> In Functional Programming and Computer Architecture, </booktitle> <month> September 91. </month>
Reference-contexts: We believe that MetaML helps us in understanding and communicating ideas about multi-stage programs, partial evaluation, and the complex process of BTA in much the same way that the boxed/unboxed (#) distinction provides a language for understanding boxing optimizations as source-to-source transformations <ref> [22] </ref>. We have found the following features essential when writing multi-stage programs: * Cross-stage persistence. The ability to use variables from any past stage is crucial to writing staged programs in the manner to which programmers are accustomed.
Reference: [23] <author> Richard B. Kieburtz, Francoise Bellegarde, Jef Bell, James Hook, Jeffrey Lewis, Dino Oliva, Tim Sheard, Lisa Walton, and Tong Zhou. </author> <title> Calculating software generators from solution specifications. </title> <booktitle> In TAPSOFT'95, volume 915 of LNCS, </booktitle> <pages> pages 546-560. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: 1 Introduction High-level program generators can increase the efficiency, productivity, reliability, and quality of software systems <ref> [27, 23, 24] </ref>. Despite the numerous examples of program generators, almost all these systems deal with the construction of program fragments using ad-hoc techniques. Our thesis is that a well-designed multi-stage programming language supplies a sound basis for high-level program generation technology.
Reference: [24] <author> Richard B. Kieburtz, Laura McKinney, Jeffrey Bell, James Hook, Alex Kotov, Jeffrey Lewis, Dino Oliva, Tim Sheard, Ira Smith, and Lisa Walton. </author> <title> A software engineering experiment in software component generation. </title> <booktitle> In 18th International Conference in Software Engineering, </booktitle> <month> March </month> <year> 1996. </year>
Reference-contexts: 1 Introduction High-level program generators can increase the efficiency, productivity, reliability, and quality of software systems <ref> [27, 23, 24] </ref>. Despite the numerous examples of program generators, almost all these systems deal with the construction of program fragments using ad-hoc techniques. Our thesis is that a well-designed multi-stage programming language supplies a sound basis for high-level program generation technology.
Reference: [25] <author> Mark Leone and Peter Lee. </author> <title> Deferred compilation: The automation of run-time code generation. </title> <type> Technical Report CMU-CS-93-225, </type> <institution> Carnegie Mellon University, </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: This is exactly the case when computing the multiplication of 2 matrixes. For each row in the first matrix, the dot product of that row will be taken with each column of the second. This example has appeared in several other works <ref> [10, 25] </ref> and we give our version below. We give three versions of the inner product function. One (iprod) with no staging annotations, the second (iprod2) with two levels of annotations, and the third (iprod3) with two levels of annotations but constructed with the back2 function.
Reference: [26] <author> Mark Leone and Peter Lee. </author> <title> A declarative approach to run-time code generation. </title> <booktitle> In Workshop on Compiler Support for System Software (WCSSS), </booktitle> <month> February </month> <year> 1996. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [27] <author> Michael Lowry, Andrew Philpot, Thomas Pressburger, and Ian Underwood. Amphion: </author> <title> Automatic programming for scientific subroutine libraries. </title> <journal> NASA Science Information Systems Newsletter, </journal> <volume> 31 </volume> <pages> 22-25, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction High-level program generators can increase the efficiency, productivity, reliability, and quality of software systems <ref> [27, 23, 24] </ref>. Despite the numerous examples of program generators, almost all these systems deal with the construction of program fragments using ad-hoc techniques. Our thesis is that a well-designed multi-stage programming language supplies a sound basis for high-level program generation technology.
Reference: [28] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <year> 1978. </year>
Reference-contexts: first stage, while the value of b will be available only in the second stage! Therefore, MetaML's type system was designed to ensure that "well-typed programs won't go wrong", where going wrong now includes the violation of the cross-stage safety condition, as well as the standard notions of going wrong <ref> [28] </ref> in statically-typed languages.
Reference: [29] <author> Robin Milner, Mads Tofte, Robert Harper, and David MacQueen. </author> <title> The Definition of Standard ML (Revised). </title> <publisher> The MIT Press, </publisher> <year> 1997. </year>
Reference-contexts: This is an efficiency concern. The second, more pragmatic reason, is that we wanted to make sure that our semantics can be implemented using compilation technology such as that of the SML/NJ compiler <ref> [29] </ref>. In particular, in such compiled systems, it is not reasonable to assume that the intentional representation of an arbitrary (especially functional) value will be available at run-time. To solve this problem, bindings in environments come in two flavors: real (Real (v)) and symbolic (Sym (x)).
Reference: [30] <author> Eugenio Moggi. </author> <title> A categorical account of two-level languages. </title> <booktitle> In MFPS 1997, </booktitle> <year> 1997. </year>
Reference-contexts: The two constructs of Mini-ML fl ; next and prev, correspond quite closely to MetaML's Brackets and escape. The type constructor fl also corresponds (roughly) to code. Unfortunately, eval is no longer expressible in the language. Moggi advocates a categoric approach to two-level languages <ref> [30] </ref>. He also points out that the use of stateful functions such as gensym or newname in the semantics makes their use for formal reasoning hard.
Reference: [31] <author> Flemming Nielson. </author> <title> Program transformations in a de-notational setting. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 359-379, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: In our experience, the resulting smaller, simpler programs, are easier to understand and seemed to make the optimizations worthwhile. 13 Discussion and Related Works Nielson and Nielson pioneered the investigation of multilevel languages with their work on two-level functional languages <ref> [31, 35, 32, 33] </ref>. They have developed an extensive theory for the denotational semantics of two-level languages, including a framework for abstract interpretation has been developed [34]. The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set.
Reference: [32] <author> Flemming Nielson. </author> <title> Correctness of code generation from a two-level meta-language. </title> <editor> In B. Robinet and R. Wil-helm, editors, </editor> <booktitle> Proceedings of the European Symposium on Programming (ESOP 86), volume 213 of LNCS, </booktitle> <pages> pages 30-40, </pages> <address> Saarbrucken, FRG, March 1986. </address> <publisher> Springer. </publisher>
Reference-contexts: In our experience, the resulting smaller, simpler programs, are easier to understand and seemed to make the optimizations worthwhile. 13 Discussion and Related Works Nielson and Nielson pioneered the investigation of multilevel languages with their work on two-level functional languages <ref> [31, 35, 32, 33] </ref>. They have developed an extensive theory for the denotational semantics of two-level languages, including a framework for abstract interpretation has been developed [34]. The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set.
Reference: [33] <author> Flemming Nielson. </author> <title> Two-level semantics and abstract interpretation. </title> <journal> Theoretical Computer Science, </journal> <volume> 69(2) </volume> <pages> 117-242, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: In our experience, the resulting smaller, simpler programs, are easier to understand and seemed to make the optimizations worthwhile. 13 Discussion and Related Works Nielson and Nielson pioneered the investigation of multilevel languages with their work on two-level functional languages <ref> [31, 35, 32, 33] </ref>. They have developed an extensive theory for the denotational semantics of two-level languages, including a framework for abstract interpretation has been developed [34]. The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set.
Reference: [34] <author> Flemming Nielson and Hanne Riis Nielson. </author> <title> Two-level semantics and code generation. </title> <journal> Theoretical Computer Science, </journal> <volume> 56(1) </volume> <pages> 59-133, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: They have developed an extensive theory for the denotational semantics of two-level languages, including a framework for abstract interpretation has been developed <ref> [34] </ref>. The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set. Recently, Nielson and Niel-son proposed an algebraic framework for the specification of multi-level type systems [36, 37].
Reference: [35] <author> Flemming Nielson and Hanne Riis Nielson. </author> <title> Two-Level Functional Languages. </title> <booktitle> Number 34 in Cambridge Tracts in Theoretical Computer Science. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Following the annotations, the specializer either performs a computation, or produces text for inclusion in the output (residual) program. The relationship between partial-evaluation and multistage programming is that the intermediate data structure between the two steps is a two-stage annotated program <ref> [2, 35] </ref>, and that the specialization phase is (the first stage in) the execution of the two-stage annotated program produced by BTA. Recently, Gluck and Jtrgensen proposed multi-level BTA and showed that it is an efficient alternative to multiple specialization [10, 11]. <p> This seems to have been the case in all multi-stage languages known to us to date <ref> [35, 7, 14, 10, 11, 6] </ref>. Intuitively, they use the following monolithic rule for variables: Var (Monolithic): ( x) = t n 0 n when n 0 = n We allow the more general condition n 0 n (assume programs contain no Run). <p> In our experience, the resulting smaller, simpler programs, are easier to understand and seemed to make the optimizations worthwhile. 13 Discussion and Related Works Nielson and Nielson pioneered the investigation of multilevel languages with their work on two-level functional languages <ref> [31, 35, 32, 33] </ref>. They have developed an extensive theory for the denotational semantics of two-level languages, including a framework for abstract interpretation has been developed [34]. The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set. <p> This is crucial when debugging multi-stage programs. * Display of code. When debugging, it is important for users to observe the code produced by their pro grams. This implies a display mechanism (pretty-printer) for values of type code. Facility Example Nielson & Niel son <ref> [35] </ref> Gomard & Jones [12] Gluck & Jtrgensen [10] Thiemann [52] Hatcliff & Gluck [14] Stages &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Var. &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection Run or eval
Reference: [36] <author> Flemming Nielson and Hanne Riis Nielson. </author> <title> Multi-level lambda-calculi: An algebraic description. </title> <editor> In O. Danvy, R. Gluck, and P. Thiemann, editors, </editor> <title> Partial Evaluation. </title> <address> Dagstuhl Castle, Germany, </address> <month> February </month> <year> 1996, </year> <booktitle> volume 1110 of Lecture Notes in Computer Science, </booktitle> <pages> pages 338-354. </pages> <address> Berlin: </address> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set. Recently, Nielson and Niel-son proposed an algebraic framework for the specification of multi-level type systems <ref> [36, 37] </ref>. Gomard and Jones [12] use a statically-typed two-level language for partial evaluation of the untyped -calculus. This language is the basis for many BTAs. The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type.
Reference: [37] <author> Flemming Nielson and Hanne Riis Nielson. </author> <title> A prescriptive framework for designing multi-level lambda-calculi. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Amster-dam, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: The framework developed is for a general ("B-level") language, where B is an arbitrary, possibly partially-ordered set. Recently, Nielson and Niel-son proposed an algebraic framework for the specification of multi-level type systems <ref> [36, 37] </ref>. Gomard and Jones [12] use a statically-typed two-level language for partial evaluation of the untyped -calculus. This language is the basis for many BTAs. The language allows the treatment of expressions containing monolithic free variables. They use a "const" construct only for constants of ground type.
Reference: [38] <author> Calton Pu and Jonathan Walpole. </author> <title> A study of dynamic optimization techniques: Lessons and directions in kernel design. </title> <type> Technical Report OGI-CSE-93-007, </type> <institution> Oregon Graduate Institute of Science and Technology, </institution> <year> 1993. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [39] <author> Amr Sabry and Philip Wadler. </author> <title> A reflection on call-by-value. </title> <booktitle> In Proceedings of the 1996 ACM SIGPLAN International Conference on Functional Programming, </booktitle> <pages> pages 13-24, </pages> <address> Philadelphia, Pennsylvania, </address> <month> 24-26 May </month> <year> 1996. </year>
Reference-contexts: It may be possible, through the use of v , to produce the optimal results without having the user rewrite the program in CPS. The work of Sabry and Wadler suggests that the use of Moggi's c may also be beneficial in dealing with this problem <ref> [39] </ref>. 5. Empirical measurement are still needed to assess the relative benefits of annotation strategies. 15 Conclusion We have described a multi-stage programming language which we call MetaML. MetaML was designed as a programming language. Our primary purpose was to support the writing of multi-stage programs.
Reference: [40] <author> Tim Sheard. </author> <title> A user's guide to trpl, a compile-time reflective programming language. </title> <type> Technical Report COINS Tech. Rep. 90-109, </type> <institution> Dept. of Computer and Information Science, University of Massachusetts, </institution> <year> 1990. </year>
Reference-contexts: MetaML is a descendent of CRML [42, 43, 16], which in turn was greatly influenced by TRPL <ref> [40, 41] </ref>. All three of these languages support linguistic reflection. Both CRML and TRPL were two stage languages that allowed users to provide compile-time functions (much like macro's) which directed the compiler to perform compile-time reductions. Both emphasized the use of computations over representations of a program's datatype definitions.
Reference: [41] <author> Tim Sheard. </author> <title> Automatic generation and use of abstract structure operators. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 531-557, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: MetaML is a descendent of CRML [42, 43, 16], which in turn was greatly influenced by TRPL <ref> [40, 41] </ref>. All three of these languages support linguistic reflection. Both CRML and TRPL were two stage languages that allowed users to provide compile-time functions (much like macro's) which directed the compiler to perform compile-time reductions. Both emphasized the use of computations over representations of a program's datatype definitions. <p> Both emphasized the use of computations over representations of a program's datatype definitions. By generating functions from datatype definitions, it was possible to create specific instances of generic functions like equality functions, pretty printers, and parsers <ref> [41] </ref>. This provided an abstraction mechanism not available in traditional languages.
Reference: [42] <author> Tim Sheard. </author> <title> Guide to using crml, </title> <note> cmopile-time reflective ml. (Available from author's home-page), </note> <month> October </month> <year> 1993. </year>
Reference-contexts: MetaML is a descendent of CRML <ref> [42, 43, 16] </ref>, which in turn was greatly influenced by TRPL [40, 41]. All three of these languages support linguistic reflection. Both CRML and TRPL were two stage languages that allowed users to provide compile-time functions (much like macro's) which directed the compiler to perform compile-time reductions.
Reference: [43] <author> Tim Sheard. </author> <title> Type parametric programming. </title> <type> Technical Report CSE 93-018, </type> <institution> Oregon Graduate Institute, </institution> <year> 1993. </year>
Reference-contexts: MetaML is a descendent of CRML <ref> [42, 43, 16] </ref>, which in turn was greatly influenced by TRPL [40, 41]. All three of these languages support linguistic reflection. Both CRML and TRPL were two stage languages that allowed users to provide compile-time functions (much like macro's) which directed the compiler to perform compile-time reductions.
Reference: [44] <author> Tim Sheard. </author> <title> A type-directed, on-line partial evaluator for a polymorphic language. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <address> Amsterdam, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: On the other hand, the problem of cross-platform portability is similar to that of lifting functional values in partial evaluation, and type-directed partial evaluation may provide a solution to this problem <ref> [4, 44] </ref>. 7.2 Cross-Stage Safety. Even in MetaML, it will not be possible to stage every expression in the language.
Reference: [45] <author> Tim Sheard and Neal Nelson. </author> <title> Type safe abstractions using program generators. </title> <type> Technical Report OGI-TR-95-013, </type> <institution> Oregon Graduate Institute of Science and Technology, </institution> <year> 1995. </year>
Reference-contexts: In their work, Hatcliff and Gluck identified language-independence of the internal representation of "code" as an important characteristic of any multi-stage language. Sheard and Nelson investigate a two-stage language for the purpose of program generation <ref> [45] </ref>. The base language was statically typed, and dependent types were used to generate a wider class of programs than is possible by MetaML restricted to two stages.
Reference: [46] <author> Mark Shields, Tim Sheard, and Simon Peyton Jones. </author> <title> Dynamic typing through staged type inference. </title> <booktitle> In Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <month> Jan-uary </month> <year> 1998. </year>
Reference-contexts: Sheard and Nelson investigate a two-stage language for the purpose of program generation [45]. The base language was statically typed, and dependent types were used to generate a wider class of programs than is possible by MetaML restricted to two stages. Sheard and Shields <ref> [46] </ref> investigate a dynamic type systems for multi-staged programs where some type obligations of staged computations can be put off till run-time. Davies and Pfenning present a statically-typed multistage language Mini-ML 2 , motivated by constructive modal logic [6].
Reference: [47] <author> Brian Cantwell Smith. </author> <title> Reflection and Semantics in a Procedural Language. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> January </month> <year> 1982. </year>
Reference-contexts: We view this as an important feature of MetaML. We view MetaML's semantics as a concise formalization of the semantics of LISP's three constructs, but with static scoping. This is similar in spirit to Brian Smith's semantically motivated LISP <ref> [47, 48] </ref> Finally, whereas LISP is dynamically typed, MetaML is statically typed. The annotations can also be viewed as a providing a simple but statically-typed macro-expansion system. This will become clear as we introduce and demonstrate the use of these constructs. <p> Note how the looping overhead has been removed from the generated code. 6.1 Roles Having Run in the language implies introducing a kind of reflection <ref> [47] </ref>, and allows a delayed computation to be performed now.
Reference: [48] <author> Brian Cantwell Smith. </author> <title> Reflection and semantics in lisp. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1984. </year>
Reference-contexts: We view this as an important feature of MetaML. We view MetaML's semantics as a concise formalization of the semantics of LISP's three constructs, but with static scoping. This is similar in spirit to Brian Smith's semantically motivated LISP <ref> [47, 48] </ref> Finally, whereas LISP is dynamically typed, MetaML is statically typed. The annotations can also be viewed as a providing a simple but statically-typed macro-expansion system. This will become clear as we introduce and demonstrate the use of these constructs.
Reference: [49] <author> D. Stemple, R. B. Stanton, T. Sheard, P. Philbrow, R. Morrison, G. N. C. Kirby, L. Fegaras, R. L. Cooper, R. C. H. Connor, M. P. Atkinson, and S. Alagic. </author> <title> Type-safe linguistic reflection: A generator technology. </title> <type> Technical Report FIDE/92/49, ESPRIT BRA Project 3070 FIDE, </type> <year> 1992. </year>
Reference-contexts: note that the annotations don't allow the definition of new language constructs or binding mechanisms, as is sometimes expected from macro-expansion systems. 4 Relationship to Linguistic Reflection "Linguistic reflection is defined as the ability of a program to generate new program fragments and to integrate these into its own execution" <ref> [49] </ref>. MetaML is a descendent of CRML [42, 43, 16], which in turn was greatly influenced by TRPL [40, 41]. All three of these languages support linguistic reflection.
Reference: [50] <author> Walid Taha, Zine-El-Abidine Benaissa, and Tim Sheard. </author> <title> Multi-stage programming: Axiomatization and type safety. </title> <type> Technical Report CSE 98-002, </type> <institution> Oregon Graduate Institute, </institution> <year> 1998. </year>
Reference-contexts: The formal proof of the soundness of this type system with respect to the natural semantics has been carried out in collaboration with Zine El-Abidine Benaissa, and is presented in <ref> [50] </ref>. 11.3.1 Going Wrong There are three main kinds of errors related to staging annotations that can occur at run-time: * A variable is used in a stage before it is available, or * Run or escape are passed values having a non-code type, or * Run is passed a code-type <p> He also points out that the use of stateful functions such as gensym or newname in the semantics makes their use for formal reasoning hard. The semantics presented in this paper uses a gensym, but we have recently been able to devise a simpler semantics that does not (See <ref> [50] </ref>). mean it is a two-level language, and "+" means multi-level. <p> An axiomatic semantics is needed as a practical basis for formal reasoning about MetaML programs, and for verifying the correctness of the implementation. (One axiomatic semantics is proposed in <ref> [50] </ref>). 2. A denotational semantics assigns an abstract, mathematical meaning to a language. In this sense, mathematics serves as a common ground that would allow us to relate features of MetaML to features of other languages.
Reference: [51] <author> Walid Taha and Tim Sheard. </author> <title> Multi-stage programming with explicit annotations. </title> <booktitle> In Proceedings of the ACM-SIGPLAN Symposium on Partial Evaluation and semantic based program manipulations PEPM'97, Ams-terdam, </booktitle> <pages> pages 203-217. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: Multi-stage languages express multi-stage programs. Multi-stage programming is important because it addresses the need for general purpose solutions which do not pay run-time interpretive overheads. This is the purpose of program staging and it can be highly effective as demonstrated in many studies <ref> [3, 18, 17, 9, 13, 26, 38, 51] </ref>. Recently, multi-stage languages have also been proposed as intermediate representations for partial evaluation [14, 10, 11], and a formal foundation for run-time code generation [7].
Reference: [52] <author> Peter Thiemann. </author> <title> Towards partial evaluation of full Scheme. </title> <editor> In Gregor Kiczales, editor, </editor> <volume> Reflection 96, </volume> <pages> pages 95-106, </pages> <address> San Francisco, CA, USA, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: For example, we can't use their "Generic Code Generation functions" to define the language. A second paper by Gluck and Jtrgensen [11] demonstrates the impressive efficiency of MBTA, and the use of constraint-solving methods to perform the analysis. The MBTA is type-based, but underlying language is dynamically typed. Thiemann <ref> [52] </ref> studies a two-level language with eval, apply, and call/cc in the context of studying the partial evaluation of a larger subset of scheme than had been pre viously studied. A BTA based on constraint-solving is pre-sented. <p> When debugging, it is important for users to observe the code produced by their pro grams. This implies a display mechanism (pretty-printer) for values of type code. Facility Example Nielson & Niel son [35] Gomard & Jones [12] Gluck & Jtrgensen [10] Thiemann <ref> [52] </ref> Hatcliff & Gluck [14] Stages &lt;x.x&gt; 2 2 + 2 + + + + Strong Typing Y 1 N N N Y Y Y Monolithic Var. &lt;x.~(f &lt;x&gt;)&gt; Y Y Y Y Y N Y Y Reflection Run or eval N N N Y N Y N Y Persistence f.&lt;x.f
References-found: 52

