URL: http://ftp.cs.yale.edu/pub/technical-reports/tr875.ps.gz
Refering-URL: http://ftp.cs.yale.edu/pub/technical-reports/
Root-URL: http://www.cs.yale.edu
Title: Decision Making in the Presence of Noise  
Author: Michael J. Fischer Sophia A. Paleologou 
Note: This research was supported in part by National Science Foundation grant IRI-9015570.  
Date: October 1991  
Affiliation: Yale University Department of Computer Science  
Pubnum: YALEU/DCS/TR-875  
Abstract-found: 0
Intro-found: 1
Reference: [GG91a] <author> John Geanakoplos and Larry Gray, </author> <month> June </month> <year> 1991. </year> <type> Personal communication. </type>
Reference-contexts: Thus, we assume exactly one leaf is labelled 1. However, the techniques we use in this paper to analyze Games I and II can be extended so as to handle arbitrary probability distributions (see <ref> [GG91a] </ref>). Let X be a subtree of T and let L and R be the left and right subtrees of X. <p> We also assume a uniform error probability p at each node of the tree and binary node labels in the corrupted view. Geanakoplos and Gray show that these assumptions can be removed and similar results can still be obtained <ref> [GG91a, GG91b] </ref>. On the other hand, certain other assumptions in our probabilistic setting are difficult to eliminate. For example, the independence of errors among the nodes can be easily characterized as unrealistic, yet removing it entirely makes the problem seem intractable.
Reference: [GG91b] <author> John Geanakoplos and Larry Gray. </author> <title> When seeing further is not seeing better. </title> <type> Manuscript, </type> <month> July </month> <year> 1991. </year>
Reference-contexts: If the evaluations were 100% accurate, this would lead to optimal play, but it is unclear how good a move this produces in real chess programs. In a recent conference for Learning, Rationality, and Games at the Santa Fe Institute, John Geanakoplos and Larry Gray <ref> [GG91b] </ref> gave examples of simple one-person games in which the Shannon algorithm was provably non-optimal and in which its performance actually deteriorated as the amount of permitted look-ahead (and hence the amount of data upon which to base one's decision) increased. 1 In this paper, we investigate the structure of the <p> We also assume a uniform error probability p at each node of the tree and binary node labels in the corrupted view. Geanakoplos and Gray show that these assumptions can be removed and similar results can still be obtained <ref> [GG91a, GG91b] </ref>. On the other hand, certain other assumptions in our probabilistic setting are difficult to eliminate. For example, the independence of errors among the nodes can be easily characterized as unrealistic, yet removing it entirely makes the problem seem intractable.
Reference: [Pea83] <author> Judea Pearl. </author> <title> On the nature of pathology in game searching. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 427-453, </pages> <year> 1983. </year>
Reference-contexts: Rather surprisingly, the optimal decision can be expressed This research was supported in part by National Science Foundation grant IRI-9015570. 1 Judea Pearl has also noted such phenomena in chess and given probabilistic game models in which reaching deeper consistently degrades the quality of the Shannon algorithm's decision <ref> [Pea83] </ref>. 1 by compact, closed-form formulas of low computational complexity. From these formulas, we gain qualitative insights into the Bayesian optimal decision.
Reference: [Ros76] <author> Sheldon Ross. </author> <title> A first course in Probability. </title> <publisher> Macmillan, </publisher> <address> New York, NY, </address> <year> 1976. </year>
Reference-contexts: We show that, in many cases, seemingly intractable computations can be reduced to efficient algoritms for computing Bayesian optimal decisions. (For a general introduction to probability theory, see <ref> [Ros76] </ref>.) 3 Game I: Choose a Subtree We first consider a one-player, one-move game played on a MaxTree. The current state of the game is modelled by the root node, and the player is asked to choose one move|Left or Right, that takes her closer to a winning leaf.
Reference: [Shu82] <author> Martin Shubik. </author> <title> Game Theory in the social sciences. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1982. </year>
Reference-contexts: This recursive node-labelling process is widely known in game theory as backward induction (see <ref> [Shu82] </ref>). An example of a MaxTree T of uniform depth k = 3 is given in Figure 1. In this paper, we generally consider MaxTrees with exactly one leaf labelled 1 and all other leaves labelled 0.
References-found: 5

