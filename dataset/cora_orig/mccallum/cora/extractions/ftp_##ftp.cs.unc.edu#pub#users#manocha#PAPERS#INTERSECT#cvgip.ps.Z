URL: ftp://ftp.cs.unc.edu/pub/users/manocha/PAPERS/INTERSECT/cvgip.ps.Z
Refering-URL: http://www.cs.unc.edu/Research/graphics/pubs.html
Root-URL: http://www.cs.unc.edu
Email: manocha@cs.unc.edu  
Title: Algorithms for Intersecting Parametric and Algebraic Curves II: Multiple Intersections  
Author: Dinesh Manocha Sitterson Hall, CB # ()-. James Demmel 
Note: 1 Supported by IBM Fellowship, David and Lucile Packard Fellowship, National Science Founda tion grant ASC-900593k and a Junior Faculty Award. 2 Supported in part by National Science Foundation grant ASC-9005933 and Subcontract ORA4466.02 to the University of Tennessee (ARPA contract number DAAL03-91-C-0047).  
Address: Chapel Hill, NC 27599-3175  Berkeley, CA 94720  
Affiliation: Department of Computer Science  University of North Carolina  Computer Science Division and Mathematics Department University of California at Berkeley  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C.M. Hoffmann. </author> <title> Geometric and Solid Modeling. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1989. </year>
Reference-contexts: In particular, intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials, computing singular points etc. <ref> [1, 2, 3, 4, 5] </ref>. There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization [6], Bezier subdivision [7] and interval arithmetic [8]. <p> In particular, the curve has two or more places at a node or loop and one place at a cusp. More on places and their representation as branches is given in <ref> [22, 1, 23, 21] </ref>. A rational parametric curve P (t) is properly parametrized if it has one-to-one relationship between the parameter t and points on the curve, except for a finite number of exceptional points. Let S be one of these exceptional points. <p> s = u 1u and to get the new polynomial M (s) = M n s n + M n1 s n1 + . . . + M 0 : (14) In the original problem we were interested in the roots of Determinant (M (u)) = 0 in the range <ref> [0; 1] </ref>. However, after reparametrizing we want to compute the roots of P (s) Determinant (M (s)) = 0 in the domain [0; 1]. This can result in scaling or overflow problems if the original system has a root u 1. <p> + . . . + M 0 : (14) In the original problem we were interested in the roots of Determinant (M (u)) = 0 in the range <ref> [0; 1] </ref>. However, after reparametrizing we want to compute the roots of P (s) Determinant (M (s)) = 0 in the domain [0; 1]. This can result in scaling or overflow problems if the original system has a root u 1. In such cases M n is nearly singular or ill-conditioned. Our algorithm takes care of such cases by performing linear transformations or using projective coordinates [16]. <p> The cubic curve has a loop at the origin. We are interesting in all intersection points corresponding to the domain t fi u = [2; 2] fi <ref> [1; 1] </ref>. 25 The implicit representation of P (t) is a matrix determinant of the form M = B @ y x 0 1 C After substituting and reducing the problem to an eigenvalue problem we obtain a 6 fi 6 matrix C = B B B B B @ 0
Reference: [2] <author> T.W. Sederberg and S.R. Parry. </author> <title> Comparison of three curve intersection algorithms. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 18(1) </volume> <pages> 58-63, </pages> <year> 1986. </year>
Reference-contexts: In particular, intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials, computing singular points etc. <ref> [1, 2, 3, 4, 5] </ref>. There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization [6], Bezier subdivision [7] and interval arithmetic [8]. <p> The implicitization approach is based on reducing the problem to finding roots of a univariate polynomials, while Bezier subdivision and interval arithmetic proceed by using the geometric properties of the control polygon of a Bezier curve. The relative performance and accuracy of these algorithms is highlighted in <ref> [2] </ref>. In particular, implicitization based approaches are considered faster than other intersection algorithms for curves of degree up to four. However, their relative performance degrades for higher degree curves. <p> The cubic curve has a loop at the origin. We are interesting in all intersection points corresponding to the domain t fi u = <ref> [2; 2] </ref> fi [1; 1]. 25 The implicit representation of P (t) is a matrix determinant of the form M = B @ y x 0 1 C After substituting and reducing the problem to an eigenvalue problem we obtain a 6 fi 6 matrix C = B B B B
Reference: [3] <author> G. Elber and E. Cohen. </author> <title> Hidden curve removal for free form surfaces. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 95-104, </pages> <year> 1990. </year> <month> 40 </month>
Reference-contexts: In particular, intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials, computing singular points etc. <ref> [1, 2, 3, 4, 5] </ref>. There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization [6], Bezier subdivision [7] and interval arithmetic [8].
Reference: [4] <author> G.E. Collins and W. Krandick. </author> <title> An efficient algorithm for infallible polynomial complex root isolation. </title> <booktitle> In Proceedings of International Symposium on Symbolic and Algebraic Computation, </booktitle> <pages> pages 189-194, </pages> <address> Berkeley, California, </address> <year> 1992. </year>
Reference-contexts: In particular, intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials, computing singular points etc. <ref> [1, 2, 3, 4, 5] </ref>. There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization [6], Bezier subdivision [7] and interval arithmetic [8].
Reference: [5] <author> R.T. Farouki and T. Sakkalis. </author> <title> Singular points of algebraic curves. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 9(4) </volume> <pages> 457-483, </pages> <year> 1990. </year>
Reference-contexts: In particular, intersection is a primitive operation in the computation of a boundary representation from a CSG (constructive solid geometry) model in a CAD system. Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials, computing singular points etc. <ref> [1, 2, 3, 4, 5] </ref>. There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization [6], Bezier subdivision [7] and interval arithmetic [8].
Reference: [6] <author> T.W. </author> <title> Sederberg. Implicit and Parametric Curves and Surfaces. </title> <type> PhD thesis, </type> <institution> Purdue University, </institution> <year> 1983. </year>
Reference-contexts: Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials, computing singular points etc. [1, 2, 3, 4, 5]. There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization <ref> [6] </ref>, Bezier subdivision [7] and interval arithmetic [8]. The implicitization approach is based on reducing the problem to finding roots of a univariate polynomials, while Bezier subdivision and interval arithmetic proceed by using the geometric properties of the control polygon of a Bezier curve. <p> As far as geometric and solid modeling are concerned, the use of resultants was resurrected by Sederberg for implicitizing parametric curves and surfaces <ref> [6] </ref>. The problem of curve intersection is reduced to solving two polynomial equations simultaneously and therefore we use resultant formulations of two polynomials in one unknown. Surveys on various formulations of resultants are given in [6, 27] and effective techniques for computing and applying them are presented in [14]. <p> The problem of curve intersection is reduced to solving two polynomial equations simultaneously and therefore we use resultant formulations of two polynomials in one unknown. Surveys on various formulations of resultants are given in <ref> [6, 27] </ref> and effective techniques for computing and applying them are presented in [14]. Three methods are known in the literature for computing the resultant, owing to Bezout or Cayley and Sylvester [26]. Each of them expresses the resultant as the determinant of a matrix.
Reference: [7] <author> J.M. Lane and R.F. Riesenfeld. </author> <title> A theoretical development for the computer generation and display of piecewise polynomial surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2(1) </volume> <pages> 150-159, </pages> <year> 1980. </year>
Reference-contexts: Other applications of intersection include hidden curve removal for free form surfaces, finding complex roots of polynomials, computing singular points etc. [1, 2, 3, 4, 5]. There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization [6], Bezier subdivision <ref> [7] </ref> and interval arithmetic [8]. The implicitization approach is based on reducing the problem to finding roots of a univariate polynomials, while Bezier subdivision and interval arithmetic proceed by using the geometric properties of the control polygon of a Bezier curve.
Reference: [8] <author> P.A. Koparkar and S. P. Mudur. </author> <title> A new class of algorithms for the processing of parametric curves. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 15(1) </volume> <pages> 41-45, </pages> <year> 1983. </year>
Reference-contexts: There are three major algorithms for computing the intersection of rational parametric curves. They are based on implicitization [6], Bezier subdivision [7] and interval arithmetic <ref> [8] </ref>. The implicitization approach is based on reducing the problem to finding roots of a univariate polynomials, while Bezier subdivision and interval arithmetic proceed by using the geometric properties of the control polygon of a Bezier curve. The relative performance and accuracy of these algorithms is highlighted in [2].
Reference: [9] <author> J.H. Wilkinson. </author> <title> The evaluation of the zeros of ill-conditioned polynomials. parts i and ii. </title> <journal> Numer. Math., </journal> <volume> 1 </volume> <pages> 150-166 and 167-180, </pages> <year> 1959. </year>
Reference-contexts: For curves of degree greater than three the resulting polynomial has degree at least 16. The problem of computing real roots of such high degree polynomials is frequently ill-conditioned <ref> [9] </ref>. As a result subdivision based approaches perform better. The algorithms for algebraic curve intersection are analogous to those of intersecting parametric curves. Resultants are used to eliminate one variable from the two equations corresponding to the curves.
Reference: [10] <author> T.W. </author> <title> Sederberg. Algorithms for algebraic curve intersection. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 21(9) </volume> <pages> 547-555, </pages> <year> 1989. </year>
Reference-contexts: The problem of intersection corresponds to computing roots of the resulting univariate polynomial. This approach causes numerical problems for higher degree curves (greater than four). A robust algorithm based on subdivision has been presented in <ref> [10] </ref>. However, resultant based algorithms are considered to be the fastest for lower degree curves. The problems of computing the intersection of parametric and algebraic curves correspond to computing common solutions of a system of algebraic equations. <p> Special techniques for computing first order tangential contacts of parametric curves are given in [15]. Sederberg presents a modification of his algorithm for computing all double points of an algebraic curve in a triangular domain <ref> [10] </ref>. However, no efficient and accurate techniques are known for computing higher order intersections. An efficient and robust algorithm for intersecting parametric and algebraic curves using matrix computations in presented in [16, 17]. For parametric curve intersection, one of the curves is implicitized and represented as a matrix determinant.
Reference: [11] <author> B. </author> <title> Buchberger. Groebner bases: An algorithmic method in ideal theory. In N.K. Bose, editor, </title> <booktitle> Multidimensional Systems Theory, </booktitle> <pages> pages 184-232. </pages> <address> D. </address> <publisher> Reidel Publishing Co., </publisher> <year> 1985. </year>
Reference-contexts: The problems of computing the intersection of parametric and algebraic curves correspond to computing common solutions of a system of algebraic equations. Some general purpose methods to compute the system of algebraic equations can be used to solve intersection problems as well. These include Gr-obner bases algorithms <ref> [11] </ref>, homotopy methods [12] and interval arithmetic [13]. However, Gr-obner bases algorithms need exact arithmetic and homotopy methods and interval arithmetic methods are slow as compared to algorithm highlighted above [14]. In many applications, the intersection may be of higher order involving tangen-cies and singular points.
Reference: [12] <author> C.B. Garcia and W.I. Zangwill. </author> <title> Finding all solutions to polynomial systems and other systems of equations. </title> <journal> Math. Prog., </journal> <volume> 16 </volume> <pages> 159-176, </pages> <year> 1979. </year>
Reference-contexts: Some general purpose methods to compute the system of algebraic equations can be used to solve intersection problems as well. These include Gr-obner bases algorithms [11], homotopy methods <ref> [12] </ref> and interval arithmetic [13]. However, Gr-obner bases algorithms need exact arithmetic and homotopy methods and interval arithmetic methods are slow as compared to algorithm highlighted above [14]. In many applications, the intersection may be of higher order involving tangen-cies and singular points.
Reference: [13] <author> J. Snyder. </author> <title> Interval arithmetic for computer graphics. </title> <booktitle> In Proceedings of ACM Siggraph, </booktitle> <pages> pages 121-130, </pages> <year> 1992. </year>
Reference-contexts: Some general purpose methods to compute the system of algebraic equations can be used to solve intersection problems as well. These include Gr-obner bases algorithms [11], homotopy methods [12] and interval arithmetic <ref> [13] </ref>. However, Gr-obner bases algorithms need exact arithmetic and homotopy methods and interval arithmetic methods are slow as compared to algorithm highlighted above [14]. In many applications, the intersection may be of higher order involving tangen-cies and singular points. Such instances are rather common in industrial applications [15].
Reference: [14] <author> D. Manocha. </author> <title> Algebraic and Numeric Techniques for Modeling and Robotics. </title> <type> PhD thesis, </type> <institution> Computer Science Division, Department of Electrical Engineering and Computer Science, University of California, Berkeley, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: These include Gr-obner bases algorithms [11], homotopy methods [12] and interval arithmetic [13]. However, Gr-obner bases algorithms need exact arithmetic and homotopy methods and interval arithmetic methods are slow as compared to algorithm highlighted above <ref> [14] </ref>. In many applications, the intersection may be of higher order involving tangen-cies and singular points. Such instances are rather common in industrial applications [15]. Most algorithms require special handling for tangencies and therefore require 2 additional computation for detecting them. <p> The problem of curve intersection is reduced to solving two polynomial equations simultaneously and therefore we use resultant formulations of two polynomials in one unknown. Surveys on various formulations of resultants are given in [6, 27] and effective techniques for computing and applying them are presented in <ref> [14] </ref>. Three methods are known in the literature for computing the resultant, owing to Bezout or Cayley and Sylvester [26]. Each of them expresses the resultant as the determinant of a matrix. The order of the matrix is different for different methods.
Reference: [15] <author> R.P. Markot and R. L. Magedson. </author> <title> Solutions of tangential surface and curve intersections. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 21(7) </volume> <pages> 421-427, </pages> <year> 1989. </year>
Reference-contexts: However, Gr-obner bases algorithms need exact arithmetic and homotopy methods and interval arithmetic methods are slow as compared to algorithm highlighted above [14]. In many applications, the intersection may be of higher order involving tangen-cies and singular points. Such instances are rather common in industrial applications <ref> [15] </ref>. Most algorithms require special handling for tangencies and therefore require 2 additional computation for detecting them. In fact algorithms based on subdivision and Newton-type techniques often fail to accurately compute the intersections in such cases. Special techniques for computing first order tangential contacts of parametric curves are given in [15]. <p> <ref> [15] </ref>. Most algorithms require special handling for tangencies and therefore require 2 additional computation for detecting them. In fact algorithms based on subdivision and Newton-type techniques often fail to accurately compute the intersections in such cases. Special techniques for computing first order tangential contacts of parametric curves are given in [15]. Sederberg presents a modification of his algorithm for computing all double points of an algebraic curve in a triangular domain [10]. However, no efficient and accurate techniques are known for computing higher order intersections.
Reference: [16] <author> D. Manocha and J. Demmel. </author> <title> Algorithms for intersecting parametric and algebraic curves. </title> <type> Technical Report UCB/CSD 92/698, </type> <institution> Computer Science Division, University of California at Berkeley, </institution> <year> 1992. </year> <month> 41 </month>
Reference-contexts: However, no efficient and accurate techniques are known for computing higher order intersections. An efficient and robust algorithm for intersecting parametric and algebraic curves using matrix computations in presented in <ref> [16, 17] </ref>. For parametric curve intersection, one of the curves is implicitized and represented as a matrix determinant. After substituting the other parametrization the problem of intersection is reduced to computing the eigenvalues and eigenvectors of a matrix. <p> After substituting the other parametrization the problem of intersection is reduced to computing the eigenvalues and eigenvectors of a matrix. The advantages of this technique lie in its efficiency, robustness and numerical accuracy. The algorithm for algebraic curve intersection is similar. In this paper we extend the algorithm of <ref> [16] </ref> to handle multiple intersections. Such intersections are obtained due to tangential intersections or multiple points on one of the curve. It is rather difficult to detect such cases using the geometric properties of the control polygon of the curves. <p> Each of them expresses the resultant as the determinant of a matrix. The order of the matrix is different for different methods. We use Cayley's formulation of Bezout resultant as it results in a matrix of lower order. It has been explained in detail in <ref> [16] </ref> and specifically applied to the polynomials corresponding to the intersection of parametric and algebraic curves. We are given two polynomials, F (x) and G (x), of degree m and n, respectively. 8 Without loss of generality we assume that m n. <p> The implicit representation corresponds to the resultant of (6). An efficient algorithm to compute the entries of the resultant matrix, M, is presented in <ref> [16] </ref>. It involves purely numeric computation on the coefficients of the parametric curves. The entries of M are linear polynomials in X and Y . The algorithm for computing the entries of the matrix assumes that the polynomials x (t); y (t); w (t) are expressed in power basis. <p> Let us denote the m fi m matrix by M (x). The problem of intersection corresponds to computing roots of Determinant (M (x)) = 0: (9) More details on computing the resultant corresponding to the intersection of algebraic curves are given in <ref> [16] </ref>. The kernel of M (x 0 ), where x 0 is a root of the polynomial given above, has properties similar to that of the matrix corresponding to the implicit representation of the parametric equations. <p> This can result in scaling or overflow problems if the original system has a root u 1. In such cases M n is nearly singular or ill-conditioned. Our algorithm takes care of such cases by performing linear transformations or using projective coordinates <ref> [16] </ref>. Let us consider the case when M n is a nonsingular and well conditioned matrix. As a result computation of M 1 n does not introduce severe numerical errors. <p> Furthermore, the eigenvector of C corresponding to the eigenvalue s = s 0 are of the form: [v s 0 v s 2 0 v] T ; where v is the vector in the kernel of L (s 0 ) as shown in (15). Proof: <ref> [16] </ref>. The relationship between the eigenvalues of C and the roots of P (s) has been proved using similarity transformations in [37]. Many times the leading matrix M n is singular or close to being singular (due to high condition number). Some techniques based on linear transformations are highlighted in [16] <p> <ref> [16] </ref>. The relationship between the eigenvalues of C and the roots of P (s) has been proved using similarity transformations in [37]. Many times the leading matrix M n is singular or close to being singular (due to high condition number). Some techniques based on linear transformations are highlighted in [16] such that the problem of finding roots of determinant of matrix polynomial can be reduced to an eigenvalue problem. However, there are cases where they do not work. In such cases, we reduce the intersection problem to a generalized eigenvalue problem. <p> I m 3 7 7 7 7 ; where 0 and I m are m fi m null and identity matrices, respectively. Proof: <ref> [16, 37] </ref>. 3.9 Eigenvalue Formulation In the previous section, we have shown how the problem of intersection can be reduced to an eigenvalue problem. This is based on eliminating variables and matrix computations.
Reference: [17] <author> D. Manocha and J. Demmel. </author> <title> Algorithms for intersecting parametric and algebraic curves. </title> <booktitle> In Graphics Interface '92, </booktitle> <pages> pages 232-241, </pages> <year> 1992. </year>
Reference-contexts: However, no efficient and accurate techniques are known for computing higher order intersections. An efficient and robust algorithm for intersecting parametric and algebraic curves using matrix computations in presented in <ref> [16, 17] </ref>. For parametric curve intersection, one of the curves is implicitized and represented as a matrix determinant. After substituting the other parametrization the problem of intersection is reduced to computing the eigenvalues and eigenvectors of a matrix.
Reference: [18] <author> D. Manocha. </author> <title> Robust techniques for curve and surface intersections. </title> <booktitle> In Proceedings of SPIE Conference on Curves and Surfaces in Computer Vision and Graphics III, </booktitle> <pages> pages 58-69, </pages> <year> 1992. </year>
Reference-contexts: In case the higher order intersections are not geometrically isolated, we present some heuristics to compute the higher order intersections. Their accuracy is a function of the sensitivity of the problem to perturbation. Some of the results presented in this paper have also appeared in <ref> [18] </ref>. The rest of the paper is organized in the following manner. In Section 2 we present our notation, review techniques from elimination theory and reduce the problems of intersecting parametric and algebraic curves to computing roots of polynomials expressed as matrix determinants.
Reference: [19] <author> R.H. Bartels, J.C. Beatty, and B.A. Barsky. </author> <title> An Introduction to Splines for use in Computer Graphics & Geometric Modeling. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1987. </year>
Reference-contexts: We also present our algorithm for computing the intersection multiplicity, intersection points and the nature of intersection. 2 Parametric and Algebraic Curves A rational Bezier curve is of the form <ref> [19] </ref>: P (t) = (X (t); Y (t)) = i=0 w i P i B i;n (t) i=0 w i B i;n (t) where P i = (X i ; Y i ) are the coordinates of a control point, w i is the weight of the control point and B <p> Other rational formulations like B-splines can be converted into a series of Bezier curves by knot insertion algorithms <ref> [19] </ref>. Thus, the problem of intersecting rational curves can be reduced to intersecting Bezier curves. Algebraic plane curves are generally expressed in standard power basis: F (x; y) = i+jn c ij x i y j = 0: They can also be represented in Bernstein basis.
Reference: [20] <author> R.J. Walker. </author> <title> Algebraic Curves. </title> <publisher> Princeton University Press, </publisher> <address> New Jersey, </address> <year> 1950. </year>
Reference-contexts: The problem of intersection corresponds to computing the common points on such curves in a particular domain. The set of rational parametric curves is a proper subset of algebraic plane curves <ref> [20] </ref>. In the following paragraphs we will highlight some algebraic properties of algebraic curves and they are applicable to parametric curves as well. 2.1 Multiple Points A point on a curve is a regular point unless it satisfies the following definition [20]: Definition: A multiple point of order k (or k-fold <p> curves is a proper subset of algebraic plane curves <ref> [20] </ref>. In the following paragraphs we will highlight some algebraic properties of algebraic curves and they are applicable to parametric curves as well. 2.1 Multiple Points A point on a curve is a regular point unless it satisfies the following definition [20]: Definition: A multiple point of order k (or k-fold point, k &gt; 1) of a degree n curve, is a point p of the curve such that a generic line through p meets the curve in at most n k further points. 4 Let us investigate the behavior of an <p> Thus, t 1 ; t 2 ; . . . ; t k are the common roots of the two equations. Q.E.D. A simple version of Bezout's theorem is used for determining the number of intersections between a curve of degree m and that of degree n <ref> [20] </ref>. It is assumed that the curves have no component in common. <p> Simple eigenvalues of the resulting matrix correspond to simple intersections. In this section, we present algorithms to robustly compute geometrically isolated higher order intersections. According to Bezout's theorem two rational or algebraic curves of degree m and n intersect in mn points (counted properly) <ref> [20] </ref>.
Reference: [21] <author> J.G. Semple and G.T. Kneebone. </author> <title> Algebraic Curves. </title> <publisher> Oxford University Press, </publisher> <address> London, </address> <year> 1959. </year>
Reference-contexts: For example, (X (t); Y (t)) can be expressed as a power se ries representation in the neighborhood of q. The formal power series or the local parametrization is called a place of P (t) at q and exists because of Newton's theorem <ref> [21] </ref>. The notion of a place is more specific than that of a curve point. Corresponding to every curve point the curve has a place. The curve may have more than one place 5 at a singular point and has one place at every non-singular point. <p> In particular, the curve has two or more places at a node or loop and one place at a cusp. More on places and their representation as branches is given in <ref> [22, 1, 23, 21] </ref>. A rational parametric curve P (t) is properly parametrized if it has one-to-one relationship between the parameter t and points on the curve, except for a finite number of exceptional points. Let S be one of these exceptional points. <p> At such points, the curve has more than one place. The exact relationship between the number of parameter values corresponding to a point and the number of places at the same point is given by the following lemma <ref> [21] </ref>: Lemma 2.2 The number of values of t that give rise to a point q on a properly parametrized curve P (t) is the number of places on the curve at q.
Reference: [22] <author> S. S. Abhyankar. </author> <title> What is the difference between a parabola and a hyperbola. </title> <journal> The Mathematical Intelligencer, </journal> <volume> 10(4), </volume> <year> 1988. </year>
Reference-contexts: In particular, the curve has two or more places at a node or loop and one place at a cusp. More on places and their representation as branches is given in <ref> [22, 1, 23, 21] </ref>. A rational parametric curve P (t) is properly parametrized if it has one-to-one relationship between the parameter t and points on the curve, except for a finite number of exceptional points. Let S be one of these exceptional points.
Reference: [23] <author> D. Manocha and J.F. Canny. </author> <title> Rational curves with polynomial parametrization. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 23(9) </volume> <pages> 645-652, </pages> <year> 1991. </year>
Reference-contexts: In particular, the curve has two or more places at a node or loop and one place at a cusp. More on places and their representation as branches is given in <ref> [22, 1, 23, 21] </ref>. A rational parametric curve P (t) is properly parametrized if it has one-to-one relationship between the parameter t and points on the curve, except for a finite number of exceptional points. Let S be one of these exceptional points.
Reference: [24] <author> D. Manocha and J.F. Canny. </author> <title> Detecting cusps and inflection points in curves. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 9 </volume> <pages> 1-24, </pages> <year> 1992. </year>
Reference-contexts: For our algorithm we assume that the curve P (t) is properly parametrized. As a result all the singular points having more than one place have more than one preimage (according to lemma 2.2). The cusps on a curve can be identified according to the following theorem from <ref> [24] </ref>: Theorem 2.4 Given a rational curve P (t) = (X (t); Y (t)) with a proper parametrization, the curve has a cusp at q = (X (t 1 ); Y (t 1 )) if and only if (X (t 1 ); Y (t 1 )) = (0; 0): The singular <p> Algorithms to compute the proper parametrizations of curves have been described in <ref> [28, 24, 29] </ref>. To implicitize the curve we consider the following system of equations F 1 (t) : Xw (t) x (t) = 0 Consider them as polynomials in t and X; Y are treated as symbolic coefficients. The implicit representation corresponds to the resultant of (6).
Reference: [25] <author> F.S. </author> <title> Macaulay. On some formula in elimination. </title> <booktitle> Proceedings of London Mathematical Society, </booktitle> <pages> pages 3-27, </pages> <month> May </month> <year> 1902. </year>
Reference-contexts: That is: Two curves of degree m and n intersect at mn points, counted properly with respect to multiplicity. 2.2 Elimination Theory Elimination theory is a branch of classical algebraic geometry dealing with conditions under which sets of polynomials have common roots. Its results were known a century ago <ref> [25, 26] </ref>. The main result is the construction of a single resultant polynomial such that the vanishing of the resultant is the necessary and sufficient condition for the given system of equations to have a non-trivial solution.
Reference: [26] <author> G. Salmon. </author> <title> Lessons Introductory to the Modern Higher Algebra. G.E. </title> <publisher> Stechert & Co., </publisher> <address> New York, </address> <month> 1885. </month>
Reference-contexts: That is: Two curves of degree m and n intersect at mn points, counted properly with respect to multiplicity. 2.2 Elimination Theory Elimination theory is a branch of classical algebraic geometry dealing with conditions under which sets of polynomials have common roots. Its results were known a century ago <ref> [25, 26] </ref>. The main result is the construction of a single resultant polynomial such that the vanishing of the resultant is the necessary and sufficient condition for the given system of equations to have a non-trivial solution. <p> Surveys on various formulations of resultants are given in [6, 27] and effective techniques for computing and applying them are presented in [14]. Three methods are known in the literature for computing the resultant, owing to Bezout or Cayley and Sylvester <ref> [26] </ref>. Each of them expresses the resultant as the determinant of a matrix. The order of the matrix is different for different methods. We use Cayley's formulation of Bezout resultant as it results in a matrix of lower order.
Reference: [27] <author> B. Sturmfels. </author> <title> Sparse elimination theory. </title> <editor> In D. Eisenbud and L. Robbiano, editors, </editor> <title> Computational Algebraic Geometry and Commutative Algebra. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: The problem of curve intersection is reduced to solving two polynomial equations simultaneously and therefore we use resultant formulations of two polynomials in one unknown. Surveys on various formulations of resultants are given in <ref> [6, 27] </ref> and effective techniques for computing and applying them are presented in [14]. Three methods are known in the literature for computing the resultant, owing to Bezout or Cayley and Sylvester [26]. Each of them expresses the resultant as the determinant of a matrix.
Reference: [28] <author> D. Manocha. </author> <title> Regular curves and proper parametrizations. </title> <booktitle> In Proceedings of International Symposium on Symbolic and Algebraic Computations, </booktitle> <pages> pages 271-276, </pages> <year> 1990. </year>
Reference-contexts: Algorithms to compute the proper parametrizations of curves have been described in <ref> [28, 24, 29] </ref>. To implicitize the curve we consider the following system of equations F 1 (t) : Xw (t) x (t) = 0 Consider them as polynomials in t and X; Y are treated as symbolic coefficients. The implicit representation corresponds to the resultant of (6).
Reference: [29] <author> T.W. </author> <title> Sederberg. Improperly parametrized rational curves. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 3 </volume> <pages> 67-75, </pages> <year> 1986. </year>
Reference-contexts: Algorithms to compute the proper parametrizations of curves have been described in <ref> [28, 24, 29] </ref>. To implicitize the curve we consider the following system of equations F 1 (t) : Xw (t) x (t) = 0 Consider them as polynomials in t and X; Y are treated as symbolic coefficients. The implicit representation corresponds to the resultant of (6).
Reference: [30] <author> R.T. Farouki and V.T. Rajan. </author> <title> On the numerical condition of polynomials in bernstein form. </title> <booktitle> Computer Aided Geometric Design, </booktitle> <volume> 4 </volume> <pages> 191-216, </pages> <year> 1987. </year> <month> 42 </month>
Reference-contexts: The entries of M are linear polynomials in X and Y . The algorithm for computing the entries of the matrix assumes that the polynomials x (t); y (t); w (t) are expressed in power basis. However, converting from Bezier to power basis can introduce numerical errors <ref> [30] </ref>. To circumvent this problem we perform a reparametrization.
Reference: [31] <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> John Hopkins Press, </publisher> <address> Baltimore, </address> <year> 1989. </year>
Reference-contexts: This completes the reduction of the problem of intersecting algebraic curves to a nonlinear eigenvalue problem (9). The reduction to a standard eigenvalue problem will be complete in section 3.8. 3 Matrix Computations In this section we review some techniques from linear algebra and numerical analysis <ref> [31, 35, 34] </ref>. We also reduce the problem of computing the intersection of parametric and algebraic curves to eigenvalue problems. We also discuss the numerical accuracy of the problems in terms of their condition number and the algorithms used to solve those problems. <p> The i 's are called the singular values and the columns of U and V, denoted as u i 's and v j 's, are known as the left and right singular vectors, respectively <ref> [31] </ref>. The singular values give accurate information about the rank of the matrix. The matrix A has rank k &lt; n if k 6= 0 and k+1 = = n = 0. <p> Furthermore, the singular values tell exactly how close A is to a rank deficient matrix: the closest matrix to A of rank at most k is A k P k i , and kA A k k 2 = k+1 (k k 2 is the spectral norm of a matrix) <ref> [31] </ref>. <p> The eigenvalues of a matrix are the roots of its characteristic polynomial, Determinant (A sI). Efficient serial algorithms for computing all the eigenvalues and eigenvectors are well known <ref> [31] </ref>, and their implementations are available as part of packages EISPACK [32] and LA-PACK [34]. Most algorithms use similarity transformations of the form A 0 = QAQ 1 , where Q is a nonsingular n fi n matrix. <p> Algorithms choose Q so that A 0 is (nearly) upper triangular, which makes its eigenvalues and eigenvectors easy to compute. The standard algorithm is QR iteration, which chooses Q to be an orthogonal matrix, which guarantees that the entire algorithm is numerically stable <ref> [31] </ref>. One QR step of iteration goes as follows. We first (implicitly) factorize A I = UR; (10) where is a scalar referred to as a shift, U is an orthogonal matrix and R is an upper triangular matrix. <p> R mm C C C ; (11) where each R ii is either a 1 fi 1 matrix or a 2 fi 2 matrix having complex conjugate eigenvalues. Given the real Schur decomposition, computing the eigenvalues is a trivial operation. More details are given in <ref> [31] </ref>. <p> Algorithms for the generalized eigenvalue problem implicitly apply the algorithm of the last section to B 1 A without forming B 1 A. In particular, we use the QZ algorithm for computing the eigenvalues and eigenvectors for this problem <ref> [31] </ref>. Its running time is still O (n 3 ), but the constant can be as high as 75. <p> A problem is ill-conditioned if its condition number is large, and ill-posed if its condition number is infinite. These condition numbers are used to bound errors in computed solutions of numerical problems. More details on condition numbers are given in <ref> [31, 35] </ref>. The implementations of these condition number computations are available as part of LAPACK [36]. In our intersection algorithm, we will be performing computations like matrix inversion and computing eigenvalues and eigenvectors of a matrix. <p> Computing k P k 2 is expensive and a cheaper overestimate is obtained as k P k 0 F ) 1=2 ; where k R k F is the Frobenius norm R <ref> [31] </ref>. Let E be the perturbation of A and * 2 =k E k 2 . Let s 0 be the average of the perturbed eigenvalues.
Reference: [32] <author> B.S. Garbow, J.M. Boyle, J. Dongarra, and C.B. Moler. </author> <title> Matrix Eigensystem Routines - EISPACK Guide Extension, </title> <booktitle> volume 51 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1977. </year>
Reference-contexts: The eigenvalues of a matrix are the roots of its characteristic polynomial, Determinant (A sI). Efficient serial algorithms for computing all the eigenvalues and eigenvectors are well known [31], and their implementations are available as part of packages EISPACK <ref> [32] </ref> and LA-PACK [34]. Most algorithms use similarity transformations of the form A 0 = QAQ 1 , where Q is a nonsingular n fi n matrix. This transformation leaves the eigenvalues of A unchanged, and changes eigenvectors y of A into eigenvectors Qy of A 0 .
Reference: [33] <author> J. Demmel. </author> <title> LAPACK: A portable linear algebra library for supercomputers. </title> <booktitle> In Proceedings of the 1989 IEEE Control Systems Society Workshop on Computer-Aided Control System Design, </booktitle> <address> Tampa, FL, </address> <month> Dec </month> <year> 1989. </year> <note> IEEE. </note>
Reference: [34] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Green-baum, S. Hammarling, and D. Sorensen. </author> <title> LAPACK User's Guide, Release 1.0. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: This completes the reduction of the problem of intersecting algebraic curves to a nonlinear eigenvalue problem (9). The reduction to a standard eigenvalue problem will be complete in section 3.8. 3 Matrix Computations In this section we review some techniques from linear algebra and numerical analysis <ref> [31, 35, 34] </ref>. We also reduce the problem of computing the intersection of parametric and algebraic curves to eigenvalue problems. We also discuss the numerical accuracy of the problems in terms of their condition number and the algorithms used to solve those problems. <p> The eigenvalues of a matrix are the roots of its characteristic polynomial, Determinant (A sI). Efficient serial algorithms for computing all the eigenvalues and eigenvectors are well known [31], and their implementations are available as part of packages EISPACK [32] and LA-PACK <ref> [34] </ref>. Most algorithms use similarity transformations of the form A 0 = QAQ 1 , where Q is a nonsingular n fi n matrix. This transformation leaves the eigenvalues of A unchanged, and changes eigenvectors y of A into eigenvectors Qy of A 0 .
Reference: [35] <author> J.H. Wilkinson. </author> <title> The algebraic eigenvalue problem. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1965. </year>
Reference-contexts: This completes the reduction of the problem of intersecting algebraic curves to a nonlinear eigenvalue problem (9). The reduction to a standard eigenvalue problem will be complete in section 3.8. 3 Matrix Computations In this section we review some techniques from linear algebra and numerical analysis <ref> [31, 35, 34] </ref>. We also reduce the problem of computing the intersection of parametric and algebraic curves to eigenvalue problems. We also discuss the numerical accuracy of the problems in terms of their condition number and the algorithms used to solve those problems. <p> A problem is ill-conditioned if its condition number is large, and ill-posed if its condition number is infinite. These condition numbers are used to bound errors in computed solutions of numerical problems. More details on condition numbers are given in <ref> [31, 35] </ref>. The implementations of these condition number computations are available as part of LAPACK [36]. In our intersection algorithm, we will be performing computations like matrix inversion and computing eigenvalues and eigenvectors of a matrix. <p> If = 0, the upper left block is a 10 fi 10 Jordan block <ref> [35] </ref>. As a result, it has a single eigenvalue, s = 0, of algebraic multiplicity 10 and geometric multiplicity 1. The corresponding eigenvector is v = [1 0 0 . . . 0] T . <p> Without loss of generality we assume that f n = 1. It is a well known fact in linear algebra that the roots of f (t) are exactly 27 the eigenvalues of the companion matrix <ref> [35] </ref>: F = B B B B @ 0 0 1 0 . . . 0 . . . . . . . . . f 0 f 1 f 2 . . . f n2 f n1 C C C C A A similar matrix G can be formulated corresponding
Reference: [36] <author> Z. Bai, J. Demmel, and A. McKenney. </author> <title> On the conditioning of the nonsymmetric eigenproblem: Theory and software. </title> <institution> Computer Science Dept. </institution> <type> Technical Report 469, </type> <institution> Courant Institute, </institution> <address> New York, NY, </address> <month> October </month> <year> 1989. </year> <note> (LAPACK Working Note #13). </note>
Reference-contexts: These condition numbers are used to bound errors in computed solutions of numerical problems. More details on condition numbers are given in [31, 35]. The implementations of these condition number computations are available as part of LAPACK <ref> [36] </ref>. In our intersection algorithm, we will be performing computations like matrix inversion and computing eigenvalues and eigenvectors of a matrix. <p> We highlight the problem with a classic example from matrix computations <ref> [36] </ref>.
Reference: [37] <author> I. Gohberg, P. Lancaster, and L. Rodman. </author> <title> Matrix Polynomials. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Proof: [16]. The relationship between the eigenvalues of C and the roots of P (s) has been proved using similarity transformations in <ref> [37] </ref>. Many times the leading matrix M n is singular or close to being singular (due to high condition number). Some techniques based on linear transformations are highlighted in [16] such that the problem of finding roots of determinant of matrix polynomial can be reduced to an eigenvalue problem. <p> I m 3 7 7 7 7 ; where 0 and I m are m fi m null and identity matrices, respectively. Proof: <ref> [16, 37] </ref>. 3.9 Eigenvalue Formulation In the previous section, we have shown how the problem of intersection can be reduced to an eigenvalue problem. This is based on eliminating variables and matrix computations.
Reference: [38] <author> J.H. Wilkinson. </author> <title> Rounding Errors in Algebraic Processes. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, New Jersey, </address> <year> 1963. </year>
Reference-contexts: This is based on eliminating variables and matrix computations. For higher degree curve intersections, the roots can also be computed by expanding the determinant and finding the roots of the resulting problem. However, the roots of high degree polynomials can be very ill-conditioned and hard to find <ref> [38] </ref>. Therefore, we use more reliable matrix computations to compute the roots. <p> Similar properties hold for the higher multiplicity roots of polynomial equations. That is, although the higher multiplicity roots are ill-conditioned, the average of a cluster of roots of the perturbed polynomial is stable <ref> [38] </ref>. 4 This is due to the fact that the sensitivity of the eigenvalue is not proportional to the norm of the perturbation , but the tenth root of . 24 We may apply this idea to computing accurate multiple curve intersections as follows.
Reference: [39] <author> T. Kato. </author> <title> Perturbation Theory for Linear Operators. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, 2 edition, </address> <year> 1980. </year>
Reference-contexts: The arithmetic mean of a cluster of eigenvalues can be much less sensitive to small perturbations than the individual eigenvalues <ref> [39] </ref>; explicit expressions are given in equation (13). In particular, if a cluster arises from the perturbation of a single multiple eigenvalue, the mean may be a much more more accurate approximation of the multiple eigenvalue than any of the computed eigenvalues. Consider example (18).
Reference: [40] <author> Tony D. Derose. </author> <title> Geometric Continuity: A Parametrization independent measure of continuity for computer aided geometric design. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1985. </year>
Reference-contexts: The number of common roots of these two equations is computed by the algorithm described in the previous section. If p is not a singular point with respect to either of the curves, the two curves intersect tangentially (or with higher order continuity) <ref> [40] </ref>. Let us now consider the case when the geometric multiplicity of s is greater than one (say k). As a result there are k linearly independent vectors spanning the eigenspace corresponding to s.
Reference: [41] <author> T. Riabokin. </author> <type> Technical Report Research Report #86, </type> <institution> Department of Aero Engineering, Univ. of Minnesota, Institute of Technology, </institution> <year> 1952. </year> <title> Dewey Decimal Call Number 516.54 R35 O. </title>
Reference-contexts: The two points of intersection are (x; y) = (0:516329456; 0:0258250860) (x; y) = (0:516329456; 0:0258250860): They are also regular points. We highlight the performance of the algorithm on some high degree curves. Example 4.4 5 Let us consider the curve F (x; y) = 0 defined in <ref> [41] </ref>: F (x; y) = 27x+14x 3 7x 5 +x 7 +(742x 2 +35x 4 7x 6 )y+(16+42x70x 3 +21x 5 )y 2 + and let G (x; y) = F y (x; y) be: 4 (20 35x + 35x 3 )y 3 + 5 (7 21x 2 )y 4 +
Reference: [42] <author> Z. Bai and J. Demmel. </author> <title> Design of a parallel nonsymmetric eigenroutine toolbox, Part I. </title> <booktitle> in Proceedings of the Sixth SIAM Conference on Parallel Proceesing for Scientific Computing, </booktitle> <publisher> SIAM, </publisher> <year> 1993. </year> <month> 43 </month>
Reference-contexts: In most applications we are only interested in eigenvalues in a given domain. Until recently, there were no reliable algorithms other than QR, which must find all the eigenvalues, wanted or not. These recent algorithms <ref> [42] </ref> generally take more floating point operation than QR, but have the advantage of being easy to parallelize, which QR is not. Another class of parallel eigenvalue algorithm applies homotopy continuation to Determinant ( L (s)) [43, 44].
Reference: [43] <author> T.-Y. Li and Z. Zeng. </author> <title> Homotopy-determinant algorithm for solving nonsymmetric eigenvalue problems. </title> <journal> Math. Comp. </journal> <volume> 59 </volume> <pages> 483-502, </pages> <year> 1992. </year>
Reference-contexts: These recent algorithms [42] generally take more floating point operation than QR, but have the advantage of being easy to parallelize, which QR is not. Another class of parallel eigenvalue algorithm applies homotopy continuation to Determinant ( L (s)) <ref> [43, 44] </ref>. These algorithms, while parallelizable and often accurate, have the same drawbacks as homotopy methods applied directly to the polynomial systems: the difficulty of guaranteeing that all desired roots are computed exactly once, without taking arbitrarily small steps.
Reference: [44] <author> T.-Y. Li, Z. Zeng and L. Cong. </author> <title> Solving eigenvalue problems of nonsymmetric matrices with real homotopies. </title> <journal> SIAM J. Num. Anal. </journal> <volume> 29 </volume> <pages> 229-248, </pages> <year> 1992. </year>
Reference-contexts: These recent algorithms [42] generally take more floating point operation than QR, but have the advantage of being easy to parallelize, which QR is not. Another class of parallel eigenvalue algorithm applies homotopy continuation to Determinant ( L (s)) <ref> [43, 44] </ref>. These algorithms, while parallelizable and often accurate, have the same drawbacks as homotopy methods applied directly to the polynomial systems: the difficulty of guaranteeing that all desired roots are computed exactly once, without taking arbitrarily small steps.
Reference: [45] <author> J. Demmel. </author> <title> Nearest Defective Matrices and the Geometry of Ill-Conditioning. in Reliable Numerical Computation, </title> <editor> M. Cox and S. Hammarling eds., </editor> <publisher> Clarendon Press, </publisher> <year> 1990. </year>
Reference-contexts: So the underlying problem is to cluster eigenvalues. This problem has been worked on for a long time, and is known to be very difficult to solve in general <ref> [45, 46] </ref>. For example, in example (18), setting = 1=1024 means that one of the eigenvalues in the "cluster" around zero equals .5.
Reference: [46] <author> L. Reichel and L. N. Trefethen. </author> <title> Eigenvalues and pseudo-eigenvalues of Toeplitz matrices. </title> <journal> Lin. Alg. Appl., </journal> <volume> 162-164:153-185, </volume> <year> 1992. </year>
Reference-contexts: So the underlying problem is to cluster eigenvalues. This problem has been worked on for a long time, and is known to be very difficult to solve in general <ref> [45, 46] </ref>. For example, in example (18), setting = 1=1024 means that one of the eigenvalues in the "cluster" around zero equals .5.
Reference: [47] <author> P. Van Dooren and P. Dewilde. </author> <title> The eigenstructure of an arbitrary polynomial matrix: </title> <journal> computational aspects. Lin. Alg. Appl., </journal> <volume> 50 </volume> <pages> 545-579, </pages> <year> 1983. </year>
Reference-contexts: One can show this is equivalent to finding one copy of each root of a polynomial differing very slightly from the polynomial in the bottom row <ref> [47, 48] </ref>. In most applications we are only interested in eigenvalues in a given domain. Until recently, there were no reliable algorithms other than QR, which must find all the eigenvalues, wanted or not.
Reference: [48] <author> A. Edelman and H. Murakami. </author> <title> Polynomial roots from companion matrix eigen-values. </title> <note> submitted to Math. Comp., </note> <year> 1993. </year>
Reference-contexts: One can show this is equivalent to finding one copy of each root of a polynomial differing very slightly from the polynomial in the bottom row <ref> [47, 48] </ref>. In most applications we are only interested in eigenvalues in a given domain. Until recently, there were no reliable algorithms other than QR, which must find all the eigenvalues, wanted or not.
Reference: [49] <author> J. Demmel, M. Heath and H. van der Vorst. </author> <title> Parallel Numerical Linear Algebra. </title> <journal> in Acta Numerica, </journal> <volume> volume 2, </volume> <editor> ed. A. Iserles, </editor> <publisher> Cambridge University Press, </publisher> <year> 1993. </year> <month> 44 </month>
Reference-contexts: These algorithms, while parallelizable and often accurate, have the same drawbacks as homotopy methods applied directly to the polynomial systems: the difficulty of guaranteeing that all desired roots are computed exactly once, without taking arbitrarily small steps. See <ref> [49] </ref> for a discussion of parallel eigenvalue algorithms. 4 Higher Order Intersections In the previous sections, we have shown how the problem of curve intersection can be reduced to eigendecomposition. Simple eigenvalues of the resulting matrix correspond to simple intersections.
References-found: 49

