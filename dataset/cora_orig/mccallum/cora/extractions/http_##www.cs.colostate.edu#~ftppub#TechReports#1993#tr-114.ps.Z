URL: http://www.cs.colostate.edu/~ftppub/TechReports/1993/tr-114.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Title: Serial and Parallel Genetic Algorithms as Function Optimizers  
Note: Published in ICGA-93: The 5th International Conference on Genetic Algorithms, Urbana Champaign 1993, pp 177-183. Morgan-Kaufmann (ed. Stephanie Forrest)  
Affiliation: Department of Computer Science  Colorado State University  
Abstract: V. Scott Gordon and Darrell Whitley Technical Report CS-93-114 September 16, 1993 
Abstract-found: 1
Intro-found: 1
Reference: <author> A. Bohm and G. </author> <title> Egan (1992). Five Ways to Fill Your Knapsack. </title> <institution> Colorado State Univ tech report CS-92-127. </institution>
Reference-contexts: Thus we do not attempt to optimize the algorithms, and we do not examine hybrid versions that include local optimization. All algorithms are coded in a functional language (Sisal) to facilitate a concurrent study of the dataflow parallelism in the algorithms <ref> (Gordon, Whitley, and Bohm 1992) </ref>. 2 PARALLEL GENETIC ALGORITHM MODELS Current literature on parallel genetic algorithm implementations can be separated into three categories: global, island, and cellular genetic algorithms. <p> It can be shown that this type of cellular genetic algorithm is a finite cellular automaton with probabilistic rewrite rules, where the alphabet of the cellular automaton is equal to the number of strings in the search space (Whitley 1993). Other details of these implementations were previously reported <ref> (Gordon, Whitley, and Bohm 1992) </ref>. 3 PERFORMANCE MEASUREMENT In order for performance comparisons to be meaningful across the nine genetic algorithm implementations, normalization is done so that the amount of work expressed per time unit is comparable.
Reference: <author> K. </author> <title> DeJong (1975). An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> U. of Michigan. </institution>
Reference-contexts: Thus in one generation it performs twice the number of function evaluations as SGA. Therefore we multiply the number of generations performed by the cellular genetic algorithm by two. 4 TEST SUITE The following optimization problems have been coded: DeJong's original test suite F1-F5 <ref> (DeJong 1975) </ref>; Rastrigin, Schwefel, and Griewangk functions (Muhlenbein, Schomisch, and Born 1991); Ugly 3 and 4-bit deceptive functions; and zero-one knapsack problems of various sizes. We perform no local optimizations, as we only wish to compare the effectiveness of the genetic algorithms. <p> Swap intervals for the island models are set to 5 generations for easy problems and 50 generations for hard ones. All functions are converted to minimization problems. 4.1 DeJONG TEST SUITE DeJong's suite contains five test functions <ref> (DeJong 1975) </ref>. F1 is a unimodal function known to be easy for genetic algorithms. F2 is a harder multimodal function. F3 is a discontinuous "step ladder". F4 involves a large solution space (2 240 ) plus gaussian noise.
Reference: <author> L. </author> <title> Eshelman (1991). The CHC Adaptive Search Algorithm. Foundations of Genetic Algorithms and Classifier Systems, </title> <publisher> Morgan-Kaufmann. </publisher>
Reference: <author> D. </author> <title> Goldberg (1989). Genetic Algorithms in Search, Optimization and Machine Learning Addison-Wesley. </title>
Reference-contexts: We have encoded four global models, four island models, and one cellular model: Global Models: SGA, Elitist-SGA, pCHC, Genitor Island Models: I-SGA, I-Elitist-SGA, I-pCHC, I-Genitor Massively Parallel: Cellular-GA SGA and Elitist SGA. Our implementation of Gold-berg's Simple Genetic Algorithm (SGA) <ref> (Goldberg 1989) </ref> uses tournament selection (Goldberg and Deb 1991) to facilitate parallelism. Every two slots of each new generation are filled by the offspring of two selected parents from the previous generation. <p> The original ugly deceptive problems <ref> (Goldberg, Korb, and Deb 1989) </ref> were used to test genetic algorithm implementations that use no mutation and a 100% probability of crossover.
Reference: <author> D. Goldberg, B. Korb, and K. </author> <title> Deb (1989). Messy Genetic Algorithms: Motivation, Analysis, and First Results. </title> <journal> Complex Systems 3 </journal> . 
Reference-contexts: We have encoded four global models, four island models, and one cellular model: Global Models: SGA, Elitist-SGA, pCHC, Genitor Island Models: I-SGA, I-Elitist-SGA, I-pCHC, I-Genitor Massively Parallel: Cellular-GA SGA and Elitist SGA. Our implementation of Gold-berg's Simple Genetic Algorithm (SGA) <ref> (Goldberg 1989) </ref> uses tournament selection (Goldberg and Deb 1991) to facilitate parallelism. Every two slots of each new generation are filled by the offspring of two selected parents from the previous generation. <p> The original ugly deceptive problems <ref> (Goldberg, Korb, and Deb 1989) </ref> were used to test genetic algorithm implementations that use no mutation and a 100% probability of crossover.
Reference: <author> D. Goldberg and K. </author> <title> Deb (1991). A Comparative Analysis of Selection Schemes used in Genetic Algorithms. Foundations of Genetic Algorithms, </title> <editor> ed. G. Rawlins, </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We have encoded four global models, four island models, and one cellular model: Global Models: SGA, Elitist-SGA, pCHC, Genitor Island Models: I-SGA, I-Elitist-SGA, I-pCHC, I-Genitor Massively Parallel: Cellular-GA SGA and Elitist SGA. Our implementation of Gold-berg's Simple Genetic Algorithm (SGA) (Goldberg 1989) uses tournament selection <ref> (Goldberg and Deb 1991) </ref> to facilitate parallelism. Every two slots of each new generation are filled by the offspring of two selected parents from the previous generation. Thus n=2 processes are utilized (where n is the population size), each of which generates two members of the next generation.
Reference: <author> V. Gordon, D. Whitley, and A. </author> <title> Bohm (1992). Dataflow Parallelism in Genetic Algorithms. Parallel Problem Solving from Nature 2, </title> <publisher> North Holland. </publisher>
Reference-contexts: Thus we do not attempt to optimize the algorithms, and we do not examine hybrid versions that include local optimization. All algorithms are coded in a functional language (Sisal) to facilitate a concurrent study of the dataflow parallelism in the algorithms <ref> (Gordon, Whitley, and Bohm 1992) </ref>. 2 PARALLEL GENETIC ALGORITHM MODELS Current literature on parallel genetic algorithm implementations can be separated into three categories: global, island, and cellular genetic algorithms. <p> It can be shown that this type of cellular genetic algorithm is a finite cellular automaton with probabilistic rewrite rules, where the alphabet of the cellular automaton is equal to the number of strings in the search space (Whitley 1993). Other details of these implementations were previously reported <ref> (Gordon, Whitley, and Bohm 1992) </ref>. 3 PERFORMANCE MEASUREMENT In order for performance comparisons to be meaningful across the nine genetic algorithm implementations, normalization is done so that the amount of work expressed per time unit is comparable.
Reference: <author> J. </author> <booktitle> Holland (1975). Adaption in Natural and Artificial Systems. </booktitle> <publisher> Univ of Michigan Press. </publisher>
Reference: <author> H. Muhlenbein, M. Schomisch, and J. </author> <title> Born (1991). The Parallel Genetic Algorithm as Function Optimizer. </title> <booktitle> Parallel Computing 7 . North-Holland. </booktitle>
Reference-contexts: Therefore we multiply the number of generations performed by the cellular genetic algorithm by two. 4 TEST SUITE The following optimization problems have been coded: DeJong's original test suite F1-F5 (DeJong 1975); Rastrigin, Schwefel, and Griewangk functions <ref> (Muhlenbein, Schomisch, and Born 1991) </ref>; Ugly 3 and 4-bit deceptive functions; and zero-one knapsack problems of various sizes. We perform no local optimizations, as we only wish to compare the effectiveness of the genetic algorithms. We run all nine genetic algorithms across the test suite of functions for 30 runs.
Reference: <author> H. </author> <title> Muhlenbein (1992). How Genetic Algorithms Really Work I: Mutation and Hillclimbing. Parallel Problem Solving from Nature 2, </title> <publisher> North Holland. </publisher>
Reference: <author> D. Whitley and T. </author> <title> Starkweather (1990). GENITOR II: a Distributed Genetic Algorithm. </title> <journal> J. Expt. Theor. </journal> <volume> Artif. </volume> <pages> Intell 2 pp 189-214. </pages>
Reference-contexts: In other implementations of Genitor, one of the two possible offsprings is chosen randomly before evaluation. In the implementation used here both offspring are evaluated and the best of the two offspring is retained. Otherwise, Genitor <ref> (Whitley and Starkweather 1990) </ref> is coded in its original form. Island SGA and Elitist Island-SGA. The Island model involves running several single population genetic algorithms in parallel. Each "island" is an SGA with its own subpopulation. <p> Island-pCHC and Island-Genitor. These are straightforward insertions of pCHC and Genitor into the Island model (in place of SGA). Migration is the same as in I-SGA. The Island-Genitor model is analogous to Genitor-II <ref> (Whitley and Starkweather 1990) </ref>. Cellular Genetic Algorithms. Cellular Genetic Algorithms assign one individual per processor, and mating is limited to a deme (neighborhood) near the individual. Each individual is processed in parallel at each generation.
Reference: <author> D. </author> <title> Whitley (1991). Fundamental Principles of Deception in Genetic Search. </title> <booktitle> Foundations of Genetic Algorithms, </booktitle> <publisher> ed. </publisher>
Reference-contexts: In general, the three bits of each subproblem X appear in positions X, 10+X, and 20+X. The ugly 4-bit problem (D4) is a similarly constructed 40-bit problem in which ten fully-deceptive 4-bit subproblems are interleaved <ref> (Whitley 1991) </ref>. Ugly deceptive problems have very often been misunderstood. These problems isolate interactions in the hyperplane sampling abilities of a genetic algorithm as well as the linkage between bits. This linkage is related to the disruptive effects of crossover.
Reference: <editor> G. Rawlins, </editor> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> D. Whitley, R. Das, and C. </author> <month> Crabb </month> <year> (1992). </year> <title> Tracking Primary Hyperplane Competitors During Genetic Search. </title> <note> to appear in Annals of Mathematics and Artificial Intell.. </note>
Reference-contexts: Thus we do not attempt to optimize the algorithms, and we do not examine hybrid versions that include local optimization. All algorithms are coded in a functional language (Sisal) to facilitate a concurrent study of the dataflow parallelism in the algorithms <ref> (Gordon, Whitley, and Bohm 1992) </ref>. 2 PARALLEL GENETIC ALGORITHM MODELS Current literature on parallel genetic algorithm implementations can be separated into three categories: global, island, and cellular genetic algorithms. <p> It can be shown that this type of cellular genetic algorithm is a finite cellular automaton with probabilistic rewrite rules, where the alphabet of the cellular automaton is equal to the number of strings in the search space (Whitley 1993). Other details of these implementations were previously reported <ref> (Gordon, Whitley, and Bohm 1992) </ref>. 3 PERFORMANCE MEASUREMENT In order for performance comparisons to be meaningful across the nine genetic algorithm implementations, normalization is done so that the amount of work expressed per time unit is comparable.
Reference: <author> D. </author> <booktitle> Whitley (1993). Cellular Genetic Algorithms. Genetic Algorithms: Proceedings of the Fifth International Conference (GA93), </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Cellular genetic algorithms have sometimes been called massively parallel genetic algorithms or fine grain genetic algorithms, but it can be shown that these algorithms are in fact a subclass of cellular automata <ref> (Whitley 1993) </ref>. We have encoded four global models, four island models, and one cellular model: Global Models: SGA, Elitist-SGA, pCHC, Genitor Island Models: I-SGA, I-Elitist-SGA, I-pCHC, I-Genitor Massively Parallel: Cellular-GA SGA and Elitist SGA. <p> Edge elements wrap around, forming a torus. It can be shown that this type of cellular genetic algorithm is a finite cellular automaton with probabilistic rewrite rules, where the alphabet of the cellular automaton is equal to the number of strings in the search space <ref> (Whitley 1993) </ref>. Other details of these implementations were previously reported (Gordon, Whitley, and Bohm 1992). 3 PERFORMANCE MEASUREMENT In order for performance comparisons to be meaningful across the nine genetic algorithm implementations, normalization is done so that the amount of work expressed per time unit is comparable.
References-found: 15

