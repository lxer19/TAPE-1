URL: http://now.cs.berkeley.edu/AM/am-spec-2.0.ps
Refering-URL: http://now.cs.berkeley.edu/AM/active_messages.html
Root-URL: 
Email: -alanm, culler-@cs.berkeley.edu  
Title: Active Message Applications Programming Interface and Communication Subsystem Organization  
Author: Alan Mainwaring and David Culler 
Affiliation: Computer Science Division University of California at Berkeley  
Pubnum: Draft Technical Report  
Abstract: This document specifies a new active message communications interface for these networks. Its primitives, in essence an instruction set for communications, map efficiently onto underlying network hardware and compose effectively into higher-level protocols and applications. For high-performance implementations, the interface enables direct application-network interface interactions. In the common case, for applications exhibiting locality in communication, these interactions bypass the operating system. To enable the construction of large-scale, general-purpose systems, the interface supports the protected multiprogramming of many users onto finite network resources.This document also describes a prototype system that uses the virtual-memory facilities of the Solaris operating system to implement virtual networks that support protected, network multiprogramming. The system caches the active communication endpoints in network-interface memory and demand-pages them between the host and network-interface memories. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. von Eicken, D. Culler, S. Goldstein, and K. Schauser, </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation, </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1992., </year> <title> Gold Coast, Qld., </title> <booktitle> Australia, </booktitle> <pages> pp. 256-266. </pages>
Reference-contexts: It is worth considering generating events when messages arrive with bad tags, offsets outside of virtual-memory regions, or invalid active message handler-table indices. 14 Active Message API: Concurrency and Synchronization 3.1 Scenario 1: one thread and one endpoint 3.1.1 Explanation This scenario formalizes previous active message systems <ref> [1, 2] </ref> in which each process has a single, logical network endpoint. These previous active message systems supported single-threaded applications only (or multi-threaded applications where only one thread used active messages in an ad hoc manner). <p> These previous active message systems supported single-threaded applications only (or multi-threaded applications where only one thread used active messages in an ad hoc manner). In part, this is because these systems either lacked support for event-driven application execution <ref> [1, 3] </ref> or supported primitive but nonstandard interrupting message facilities [2, 6]. In these systems, events were also de-coupled from thread and process scheduling systems. Experience showed that message polling mechanisms alone inadequately supported server-like applications and computational-intensive code. Moreover, inserting polling points complicated algorithms and degraded performance.
Reference: [2] <author> L. Tucker and A. Mainwaring, </author> <title> CMMD: Active messages on the CM-5, </title> <booktitle> Parallel Computing, </booktitle> <month> August </month> <year> 1994, </year> <note> vol.20, (no.4):481-496. </note>
Reference-contexts: It is worth considering generating events when messages arrive with bad tags, offsets outside of virtual-memory regions, or invalid active message handler-table indices. 14 Active Message API: Concurrency and Synchronization 3.1 Scenario 1: one thread and one endpoint 3.1.1 Explanation This scenario formalizes previous active message systems <ref> [1, 2] </ref> in which each process has a single, logical network endpoint. These previous active message systems supported single-threaded applications only (or multi-threaded applications where only one thread used active messages in an ad hoc manner). <p> These previous active message systems supported single-threaded applications only (or multi-threaded applications where only one thread used active messages in an ad hoc manner). In part, this is because these systems either lacked support for event-driven application execution [1, 3] or supported primitive but nonstandard interrupting message facilities <ref> [2, 6] </ref>. In these systems, events were also de-coupled from thread and process scheduling systems. Experience showed that message polling mechanisms alone inadequately supported server-like applications and computational-intensive code. Moreover, inserting polling points complicated algorithms and degraded performance.
Reference: [3] <author> R. Martin, HPAM: </author> <title> An Active Message Layer for a Network of HP Workstations, </title> <booktitle> In Proceedings of Hot Interconnects II, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Component #4:A virtual-memory segment that receives memory transfers. Network Process Bulk Data Source Send Pool Active Message Arguments Translation Table Translation Table Index Route To Destination Endpoint Name+Tag VM Segment Endpoint Tag Receive Pool (Returned msg: (Returned msg: pool full or bad handler) Handler Table Send AM to EP <ref> [3] </ref> Active Message Handler Index handler arguments handler function EP Network Message (Returned msg: bad offset or length) (1234) (1) (4) (6) Arriving Message 8 Active Message API: Endpoints and Bundles Each endpoint has one application-specified, virtual-memory segment for receiving bulk transfers. <p> These previous active message systems supported single-threaded applications only (or multi-threaded applications where only one thread used active messages in an ad hoc manner). In part, this is because these systems either lacked support for event-driven application execution <ref> [1, 3] </ref> or supported primitive but nonstandard interrupting message facilities [2, 6]. In these systems, events were also de-coupled from thread and process scheduling systems. Experience showed that message polling mechanisms alone inadequately supported server-like applications and computational-intensive code. Moreover, inserting polling points complicated algorithms and degraded performance.
Reference: [4] <author> L. Liu, </author> <title> An Evaluation of the Intel Paragon Communication Architecture, M.S. </title> <type> Project Report, </type> <institution> Com puter Science Division, University of California at Berkeley, </institution> <month> July </month> <year> 1995. </year>
Reference: [5] <author> D. Culler, K. Keeton. L. Liu, A. Mainwaring, R. Martin, S. Rodrigues, and K. Wright, </author> <title> Generic Active Message Specification, </title> <institution> Computer Science Division, University of California at Berkeley, White Paper, </institution> <month> August </month> <year> 1994. </year>
Reference: [6] <author> K. Schauser and C. Scheiman, </author> <title> Experiences with Active Messages on the Meiko CS-2, </title> <booktitle> In Proceedings of the 9th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1995. </year> <note> 33 References </note>
Reference-contexts: These previous active message systems supported single-threaded applications only (or multi-threaded applications where only one thread used active messages in an ad hoc manner). In part, this is because these systems either lacked support for event-driven application execution [1, 3] or supported primitive but nonstandard interrupting message facilities <ref> [2, 6] </ref>. In these systems, events were also de-coupled from thread and process scheduling systems. Experience showed that message polling mechanisms alone inadequately supported server-like applications and computational-intensive code. Moreover, inserting polling points complicated algorithms and degraded performance.
Reference: [7] <author> T. von Eicken, A. Basu, and V. </author> <title> Buch, Low-latency communication over ATM networks using Active Messages, </title> <booktitle> In Proceedings of Hot Interconnects II, </booktitle> <month> August </month> <year> 1994. </year>
Reference: [8] <author> T. Anderson, D. Culler, and D. Patterson, </author> <title> A Case for NOW (Networks of Workstations), </title> <booktitle> IEEE Micro, </booktitle> <month> February </month> <year> 1995, </year> <note> vol.15, (no.1):54-64. </note>
Reference-contexts: Membership in the NOW relinquishes complete local control over a workstation and permits local machine resources to be managed by and used for the benefit of the larger collective. The constituent workstations can be personal computers (PCs); the distinguishing feature <ref> [8] </ref> is the presence of a full-functionality, time-shared operating system such as UNIX. The Berkeley NOW uses single and multiprocessor SPARC workstations running Solaris 2.5. The workstations reside in machine rooms and in laboratory workspaces. At a high-level, the machines have homogeneous operating systems and network interface implementations.
Reference: [9] <author> N. Boden, D. Cohen, R. Felderman, A. Kulawik, C. Seitz, J. Seizovic, and Wen-King Su, Myrinet: </author> <title> A Gigabit-per-Second Local Area Network, </title> <booktitle> IEEE Micro, </booktitle> <month> February </month> <year> 1995, </year> <note> vol.15, (no.1):29-36. </note>
Reference-contexts: Additionally, endpoints in host memory can send and receive messages, though with less performance compared to endpoints cached in the network interface. 6.3 Hewlett Packards Hamlyn project The HP Hamlyn [37] Project is building a multicomputer network interface, which is currently being emulated on the Myrinet LANai network interface <ref> [9] </ref>; a set of communication protocols, RATS, provide communication services. The Hamlyn paper discusses both the network interfaces macro-architecture and the communication protocols that use the interface.
Reference: [10] <author> R. Horst, TNet: </author> <title> A Reliable System Area Network, </title> <booktitle> IEEE Micro, </booktitle> <month> February </month> <year> 1995, </year> <note> vol.15, (no.1):37-45. </note>
Reference: [11] <author> J. D. Tygar and Bennet S. Yee, Strongbox: </author> <title> A System for Self-Securing Programs, </title> <booktitle> CMU Computer Science: A 25th Anniversary Commemorative, </booktitle> <editor> ed. R. </editor> <address> Rashid (New York: </address> <publisher> ACM Press, </publisher> <year> 1991). </year>
Reference: [12] <author> Bennet Yee, </author> <title> Using Secure Coprocessors, </title> <type> Ph.D. Thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1994. </year>
Reference: [13] <author> O. Babaoglu and A. Schiper, </author> <title> On Group Communication in Large-Scale Distributed Systems, </title> <booktitle> Operating Systems Review, </booktitle> <month> January </month> <year> 1995, </year> <note> vol.29, (no.1):62-67. </note>
Reference-contexts: Whereas in connection models, endpoints instantiate the ends of a logical communication channel and channel identifiers name the channels endpoints. The best naming model is application- and protocol-specific. For example, using groups <ref> [13, 14] </ref> to name an aggregate of N endpoints can be more convenient and efficient than using N 2 connection identifiers. Because of these sorts of issues, the interface provides a primitive naming mechanism on top of which more specialized naming models can be constructed.
Reference: [14] <author> R. van Renesse, T. M. Hickey, and K. P. Birman, </author> <title> Design and Performance of Horus: A Lightweight Group Communication System, </title> <type> Technical Report TR94-1442, </type> <institution> Computer Science Department, Cornell Univ., </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: Whereas in connection models, endpoints instantiate the ends of a logical communication channel and channel identifiers name the channels endpoints. The best naming model is application- and protocol-specific. For example, using groups <ref> [13, 14] </ref> to name an aggregate of N endpoints can be more convenient and efficient than using N 2 connection identifiers. Because of these sorts of issues, the interface provides a primitive naming mechanism on top of which more specialized naming models can be constructed.
Reference: [15] <author> Internet Protocol. </author> <title> DARPA Internet Program. Protocol Specification. Prepared for Defense Advanced Research Projects Agency, </title> <booktitle> Information Processing Techniques Office by the Information Science Institute, </booktitle> <institution> University of Southern California. </institution> <month> September </month> <year> 1981, </year> <pages> pp. 6-7. </pages>
Reference-contexts: With the support of a global operating system layer, it might represent them as -GLOBAL pid, Endpoint Number-. The former representation supports endpoint migration less readily because IP addresses are bound to specific network interfaces of hosts <ref> [15] </ref>. The latter supports endpoint migration more readily because the endpoint names are not bound to specific physical resources.
Reference: [16] <author> Message Passing Interface Forum, </author> <title> MPI: A Message-Passing Interface Standard, </title> <institution> Computer Science Department Technical Report CS-94-320, University of Tennessee, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Applications can use tags to identify aggregates of endpoints unambiguously. Therefore, tags complement the endpoint naming mechanism in two ways: they identify aggregates of endpoints and provide a simple message authentication model. This approach differs from interfaces such as MPI <ref> [16, 17, 18, 19, 20] </ref> where data structures represent groups and contexts. Each entry in a translation table associates its integer index with a global-endpoint name and a tag.
Reference: [17] <author> P. Bangalore, N. Doss, and A. Skjellum, </author> <title> MPI++: Issues and Features, </title> <institution> Department of Computer Science, Mississippi State University, </institution> <address> White Papers, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: Applications can use tags to identify aggregates of endpoints unambiguously. Therefore, tags complement the endpoint naming mechanism in two ways: they identify aggregates of endpoints and provide a simple message authentication model. This approach differs from interfaces such as MPI <ref> [16, 17, 18, 19, 20] </ref> where data structures represent groups and contexts. Each entry in a translation table associates its integer index with a global-endpoint name and a tag.
Reference: [18] <author> A. Skjellum, N. Doss. K. Viswanathan, A. Chowdappa, and P. </author> <title> Bangalore, Extending the Message Passing Interface (MPI), </title> <institution> Department of Computer Science, Mississippi State University, White Paper, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Applications can use tags to identify aggregates of endpoints unambiguously. Therefore, tags complement the endpoint naming mechanism in two ways: they identify aggregates of endpoints and provide a simple message authentication model. This approach differs from interfaces such as MPI <ref> [16, 17, 18, 19, 20] </ref> where data structures represent groups and contexts. Each entry in a translation table associates its integer index with a global-endpoint name and a tag.
Reference: [19] <author> A. Skjellum, N. Doss, and K. Viswanathan, </author> <title> Inter-communicator Extensions to MPI in the MPIX (MPI eXtension) Library, </title> <note> Submitted to ICAE Journal special issue on Distributed Computing, </note> <month> July </month> <year> 1994. </year>
Reference-contexts: Applications can use tags to identify aggregates of endpoints unambiguously. Therefore, tags complement the endpoint naming mechanism in two ways: they identify aggregates of endpoints and provide a simple message authentication model. This approach differs from interfaces such as MPI <ref> [16, 17, 18, 19, 20] </ref> where data structures represent groups and contexts. Each entry in a translation table associates its integer index with a global-endpoint name and a tag.
Reference: [20] <author> A. Skjellum, S. Smith, N. Doss, A. Leung, and M. Morari, </author> <title> The Design and Evolution of Zipcode, </title> <booktitle> Parallel Computing, </booktitle> <month> April </month> <year> 1994, </year> <note> vol.20, (no.4):565-96. </note>
Reference-contexts: Applications can use tags to identify aggregates of endpoints unambiguously. Therefore, tags complement the endpoint naming mechanism in two ways: they identify aggregates of endpoints and provide a simple message authentication model. This approach differs from interfaces such as MPI <ref> [16, 17, 18, 19, 20] </ref> where data structures represent groups and contexts. Each entry in a translation table associates its integer index with a global-endpoint name and a tag.
Reference: [21] <author> Marvin Theimer, </author> <type> personal communication, </type> <month> 13 February </month> <year> 1995. </year>
Reference-contexts: Effective protection from errant messages relies on the use of a sufficiently large and sparse tag space. This makes it highly unlikely that such messages have a matching tag or that correct tag values can be guessed. Other systems use similar authentication mechanisms <ref> [21, 22] </ref>. At any time, the process that created an endpoint may change its tag. For example, a process may want to prevent messages from a suspect peer from being delivered. <p> Although additional security mechanisms could be added, researching physically-secure networks was not of highest priority. There was a lack of evidence that system security overall would improve with minor changes to lightweight mechanisms; endpoint tags are adequate for current purposes. Similar protection mechanisms using were successfully used in V <ref> [21] </ref> and Amoeba [22]. 3. Shared memory support for endpoint virtual-memory segments. Consideration has been given to integrating the BlizzardS [27] shared memory technology from the University of Wisconsin with endpoint virtual-memory segments. The idea here is to allow groups of endpoints to keep specially-tagged endpoint virtual-memory segments cache-coherent.
Reference: [22] <author> A. S. Tanenbaum, S. J. Jullender, and R. van Renesse, </author> <title> Using Sparse Capabilities in a Distributed Operating System, </title> <type> Technical Report, </type> <institution> Department of Mathematics and Computer Science, Vrije Universiteit. </institution>
Reference-contexts: Effective protection from errant messages relies on the use of a sufficiently large and sparse tag space. This makes it highly unlikely that such messages have a matching tag or that correct tag values can be guessed. Other systems use similar authentication mechanisms <ref> [21, 22] </ref>. At any time, the process that created an endpoint may change its tag. For example, a process may want to prevent messages from a suspect peer from being delivered. <p> There was a lack of evidence that system security overall would improve with minor changes to lightweight mechanisms; endpoint tags are adequate for current purposes. Similar protection mechanisms using were successfully used in V [21] and Amoeba <ref> [22] </ref>. 3. Shared memory support for endpoint virtual-memory segments. Consideration has been given to integrating the BlizzardS [27] shared memory technology from the University of Wisconsin with endpoint virtual-memory segments. The idea here is to allow groups of endpoints to keep specially-tagged endpoint virtual-memory segments cache-coherent.
Reference: [23] <author> M. L. Powell, S. R. Kleiman, S. Barton, D. Shah, D. Stein, M. Weeks, </author> <title> SunOS 5.0 Multi-thread Architecture, </title> <booktitle> In Proceedings of the Winter 1991 USENIX Conference, </booktitle> <month> January </month> <year> 1991. </year> <title> [24] pthreads and Solaris threads: A Comparison of two user-level threads APIs, </title> <institution> SunSoft Corporation, </institution> <year> 1994. </year> <note> On-line at http://www.Sun.COM:80/cgi-bin/show?sunsoft/Developer-products/sig/threads/ posix.html. </note>
Reference-contexts: For multi-threaded applications, the interface requires support for basic thread operations and scheduling, as well as for blocking on binary semaphores. The facilities in the POSIX P1003.4A/D8 subset of Solaris <ref> [23, 24] </ref> are adequate. The communication subsystem notifies applications of communication events by using the binary semaphores 3 in endpoint bundles.
Reference: [25] <author> A. Basu, V. Buch, W. Vogels, and T. von Eicken, U-Net: </author> <title> A User-Level Network Interface for Parallel and Distributed Computing, </title> <booktitle> In Proceedings of the 15th Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: Exposing the entries will allow applications to specialize the contents and interpretation of entries. Others <ref> [25] </ref>, [26] advocate and have implemented atomic remote message queue functions. But for the time being, equivalent functionality can be constructed using the current active message operations. 2. Using alternative schemes to authenticate messages and protect endpoints.
Reference: [26] <author> E. Brewer, F. Chong, L. Liu, J. Kubiatowicz, and S. Sharma, </author> <title> Remote Queues: Exposing Network Queues for Atomicity and Optimization, </title> <booktitle> In 7th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1995. </year> <note> 34 References </note>
Reference-contexts: Thus, applications cannot control which messages are received into which buffers. In this respect, the model of buffer management is similar to Osiris use of fbufs chains. It also resembles remote queue models such as <ref> [26] </ref>. The new active message interface specifically addresses the need for composing independent software packages into programs and maintaining their independence, although removing tags from the message passing library complicates this issue. <p> Exposing the entries will allow applications to specialize the contents and interpretation of entries. Others [25], <ref> [26] </ref> advocate and have implemented atomic remote message queue functions. But for the time being, equivalent functionality can be constructed using the current active message operations. 2. Using alternative schemes to authenticate messages and protect endpoints.
Reference: [27] <author> I. Schoinas, B. Falsafi, A. R. Lebeck, S. K. Reinhardt, J. R. Larus, D. A. Wood, </author> <title> Fine-grain Access Control for Distributed Shared Memory, </title> <booktitle> In 6th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: Similar protection mechanisms using were successfully used in V [21] and Amoeba [22]. 3. Shared memory support for endpoint virtual-memory segments. Consideration has been given to integrating the BlizzardS <ref> [27] </ref> shared memory technology from the University of Wisconsin with endpoint virtual-memory segments. The idea here is to allow groups of endpoints to keep specially-tagged endpoint virtual-memory segments cache-coherent.
Reference: [28] <author> Kirk L. Johnson, M. Frans Kaashoek, and Deborah A. Wallach, </author> <title> CRL: High-Performance All-Software Distributed Shared Memory, </title> <type> Technical Report LCS-TM-517, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: Consideration has been given to integrating the BlizzardS [27] shared memory technology from the University of Wisconsin with endpoint virtual-memory segments. The idea here is to allow groups of endpoints to keep specially-tagged endpoint virtual-memory segments cache-coherent. Similarly, it appears at first glance, that the C Region Library <ref> [28] </ref> could be easily incorporated into the exiting structures of the endpoints and associated memory segments. 4. Provide unreliable versions of the request and reply transport functions. In certain application contexts (multimedia is the fashionable buzzword), the delivery guarantees of the current interface may be unnecessarily strong.
Reference: [29] <author> P. Druschel and L. Peterson, Fbufs: </author> <title> A High-Bandwidth Cross-Domain Transfer Facility, </title> <booktitle> In Proceedings of the 14th Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: Without a thoughtful study, the simplistic approach of replicating and then specializing existing functions for double-precision oat-ing point values and for 64-bit integers could easily result in an unfortunate interface bloat. 32 Acknowledgments 6. Using fbufs <ref> [29] </ref> or similar functionality for managing the storage for bulk transfers.
Reference: [30] <author> K. Keeton, T. Anderson, and D. Patterson, </author> <title> LogP Quantified: The Case for Low-Overhead Local Area Networks, </title> <booktitle> In Proceedings of Hot Interconnects III, </booktitle> <month> August </month> <year> 1995. </year>
Reference: [31] <author> J. Beecroft, M. Hornewoord, and M. McLaren, </author> <title> Meiko CS-2 Interconnect Elan-Elite Design, </title> <booktitle> Parallel Computing, </booktitle> <month> November </month> <year> 1994, </year> <note> vol.20, (no.10-11):1627-38. </note>
Reference: [32] <institution> Fore Systems, Inc., 200-Series ATM Adapter - Design and Architecture, </institution> <month> January </month> <year> 1994. </year>
Reference: [33] <author> M. Blumrich, K. Li, R. Alpert, C. Dubnicki, et. al,. </author> <title> Virtual Memory Mapped Network Interface for the SHRIMP Multicomputer, </title> <booktitle> In Proceedings of the 21st International Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: the experience of specifying the organization of and interface to the new active message system, it is often a challenge to specify fully and to define clearly a communications system (particularly one under development) such that readers will understand its various nuances. 6.1 Princetons SHRIMP multicomputer The Princeton SHRIMP Multicomputer <ref> [33] </ref>, [34] uses reective memory as a communications resource. The idea behind reective memory is to establish associations between virtual-memory regions in different processes and on different processors. Once setup, stores into local pages of reective memory are automatically published to the other associated pages.
Reference: [34] <author> M. Blumrich, C. Dubnicki, E. Felten, K. Li and M. Mesarina, </author> <title> Two Virtual Memory Mapped Network Interface Designs, </title> <booktitle> In Proceedings of Hot Interconnects II, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: experience of specifying the organization of and interface to the new active message system, it is often a challenge to specify fully and to define clearly a communications system (particularly one under development) such that readers will understand its various nuances. 6.1 Princetons SHRIMP multicomputer The Princeton SHRIMP Multicomputer [33], <ref> [34] </ref> uses reective memory as a communications resource. The idea behind reective memory is to establish associations between virtual-memory regions in different processes and on different processors. Once setup, stores into local pages of reective memory are automatically published to the other associated pages.
Reference: [35] <institution> The SBL Programming Model, SRIMP Project Document, Department of Computer Science, Prince-ton University. </institution> <note> On-line at http://www.cs.princeton.edu/shrimp/htMan/SBLmodel.html. </note>
Reference-contexts: The host operating system assists with caching and paging endpoints on and off the network interface. The endpoint segment driver manages data structures that are equivalent to the network-interface page-tables in SHRIMP. The SHRIMP Base Library (SBL) document <ref> [35] </ref> describes how applications control which memory updates generate events and call user-specified handler functions. The notification events are queued in the system, but surprisingly, the SBL document asks programmers to be careful about how long the handlers execute because the event queues have a finite length.
Reference: [36] <author> P. Druschel, L. Peterson, and B. Davie, </author> <title> Experiences with a High-Speed Network Adaptor: A Software Perspective, </title> <booktitle> In Proceedings of the SIGCOMM 94 Symposium, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Both systems face the challenge of providing fast event up-calls. In SHRIMP they are needed to execute handlers and in active messages to post synchronization variables. 6.2 The Arizona Osiris project The Osiris Project <ref> [36] </ref> investigates the integration of high-performance ATM host adaptors into the Mach operating system. The principal focus in this work is on integration strategies that deliver low latencies, high bandwidths, and optimal end-to-end performance. A key contribution to this effort is prototyping and evaluating application device channels (ADCs).
Reference: [37] <author> Greg Buzzard, David Jacobson, Scott Marovich, and John Wilkes, Hamlyn: </author> <title> a high-performance network interface with sender-based memory management, </title> <type> Technical Report HPL-95-86, </type> <institution> Hewlett-Pack-ard Laboratories, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: The implementation is now at a stage where the feasibility of paged application device channels can be demonstrated. Additionally, endpoints in host memory can send and receive messages, though with less performance compared to endpoints cached in the network interface. 6.3 Hewlett Packards Hamlyn project The HP Hamlyn <ref> [37] </ref> Project is building a multicomputer network interface, which is currently being emulated on the Myrinet LANai network interface [9]; a set of communication protocols, RATS, provide communication services. The Hamlyn paper discusses both the network interfaces macro-architecture and the communication protocols that use the interface.
Reference: [38] <author> B. Traversat, </author> <title> Distributed-Memory OS for Highly Parallel Systems: Experiences and Lessons from Paragon OSF/1 and SUNMOS, </title> <type> Technical Report RND-94-015, </type> <institution> NASA Ames Research Center, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: Hamlyn, RATS, and this document speak at different levels of abstraction. Lastly, the paper is incorrect in stating that the active message model requires application gang scheduling. Gang scheduling is a performance optimization that will benefit both latency-sensitive Hamlyn and active message applications alike. 6.4 SUNMOS SUNMOS <ref> [38] </ref> divides a set of computing nodes on a high-performance network into ones running a fully-general operating system, as well as ones running a bare-bones micro kernel. It explores the potential performance of a specialized micro-kernel operating system.
Reference: [39] <author> B. Bryant, A. Langerman, S. Sears and D. Black, </author> <title> A Task-to-Task Communication System for Multi-computer Systems, </title> <type> Draft Technical Report, </type> <institution> OSF Research Institute, </institution> <month> October </month> <year> 1993. </year> <title> 35 Active Message API </title>
Reference-contexts: However, their problem domains are significantly different, largely because the intent of the new active message specification is to provide a portable, general-purpose communications API that supports a much broader range of applications than just parallel programs. 6.5 NORMA IPC NORMA (NO Remote Memory Access) IPC <ref> [39] </ref> is an extension of the Mach IPC mechanisms for multicom-puters. It is a kernel-based communications facility for protected, multi-programmed, task-to-task communications. Mach tasks communicate using ports that have distinct send rights and receive rights.
References-found: 38

