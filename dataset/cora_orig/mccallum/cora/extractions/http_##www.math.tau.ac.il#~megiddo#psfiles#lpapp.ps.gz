URL: http://www.math.tau.ac.il/~megiddo/psfiles/lpapp.ps.gz
Refering-URL: http://www.math.tau.ac.il/~megiddo/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: On Solving the Linear Programming Problem Approximately  
Author: Nimrod Megiddo 
Date: (Revised; July 1988)  
Abstract: This paper studies the complexity of some approximate solutions of linear programming problems with real coefficients.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Chvatal, </author> <title> Linear Programming, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: An approximation algorithm should be expected sometimes to fail in classifying the input into the categories FF, FI, IF and II. Interestingly, the existence of a strongly polynomial algorithm for the classification problem implies the existence of one for the problem itself (see p. 445 in <ref> [ 1 ] </ref> ). So far we have discussed the subject of approximation under the assumption that the result should be "close" to the true one. However, a different approach can sometimes be useful. We may allow the algorithm to be totally wrong in a small number of cases.
Reference: [2] <author> D. M. Gay, </author> <title> "A variant of Karmarkar's linear programming algorithm for problems in standard form," </title> <note> Mathematical Programming 37 (1987) 81-90. </note>
Reference-contexts: By our assumption, the set of optimal solutions of F B (A; b) is bounded. Several interior point algorithms are now known (e.g., <ref> [ 2; 10 ] </ref> ) which can start from any interior point and reduce the value of the objective function to a value not greater than t fl + * in a polynomial number of iterations in terms m; n and , where each iteration takes a polynomial number of operations
Reference: [3] <author> G. H. Golub and C. Van Loan, </author> <title> Matrix computations, </title> <publisher> Johns Hopkins University Press, </publisher> <year> 1983. </year>
Reference-contexts: Finally, if only A 11 is slightly increased then an instance in FI is obtained. We note that most of the numerical difficulties with solving linear programming problems are due the fact that many such problems are ill-posed. It is well-known in numerical analysis (see, e.g., <ref> [ 3 ] </ref> ) that near-singularities in the matrix A can cause problems. However, in this paper we also discuss intrinsic aspects of approximate solutions which arise even when exact arithmetic is used.
Reference: [4] <author> C. C. Gonzaga, </author> <title> "Polynomial affine algorithms for linear programming," </title> <note> Mathematical Programming , to appear. </note>
Reference: [5] <author> M. Grotschel, L. Lovasz and A. Schrijver, </author> <title> "The ellipsoid method and its consequences in combinatorial optimization," </title> <note> Combinatorica 1 (1981) 169-197; Corrigendum: Com-binatorica 4 (1984) 291-295. </note>
Reference: [6] <author> L. G. Khachiyan, </author> <title> "A polynomial algorithm in linear programming," </title> <journal> Soviet. Math. Dokl. </journal> <month> 20 </month> <year> (1979) </year> <month> 191-194. </month>
Reference: [7] <author> L. Lovasz, </author> <title> An algorithmic theory of numbers, graphs and convexity, </title> <publisher> SIAM, </publisher> <address> Philadel-phia, </address> <year> 1986. </year>
Reference-contexts: feasible, close to an optimal solution. (iv) A point which approximately satisfies every constraint, and whose objective func tion value is close to the optimal value. (v) A point close to the feasible domain, whose objective function value is close to the optimal value (called the "weak optimization problem" in <ref> [ 7 ] </ref> ). (vi) A basis where the simplex algorithm (using exact arithmetic) terminates, but the numerical values of variables are only approximate. (vii) A basis where the simplex algorithm terminates due to a prescribed tolerance. The choice of the right definition depends very much on the practical situation. <p> If indeed it is required to decide these questions then in the worst-case sense this approximation problem is trivially equivalent to the exact problem. The consequences of the ellipsoid algorithm with respect to approximation problems on convex sets are studied in <ref> [ 7 ] </ref> . It is not clear whether these results can be applied to achieve the type of results we seek here. The reason is that over the real numbers it seems difficult to obtain estimates of the radii of a circumscribing sphere and an inscribed sphere. <p> The reason is that over the real numbers it seems difficult to obtain estimates of the radii of a circumscribing sphere and an inscribed sphere. The main complexity result on convex minimization in <ref> [ 7 ] </ref> (Theorem 2.2.15) assumes the convex set is given with estimates of such radii. Our main interest here is the question of what is a reasonable sense of approximation when the algorithm fails to classify the instance correctly as feasible, unbounded, etc.
Reference: [8] <author> N. Megiddo, </author> <title> "Combinatorial optimization with rational objective functions," </title> <note> Mathematics of Operations Research 4 (1979) 414-424. </note>
Reference: [9] <author> J. H. Wilkinson, </author> <title> "Error analysis of floating-point computation," </title> <journal> Numer. Math. </journal> <month> 2 </month> <year> (1960) </year> <month> 219-340. </month>
Reference-contexts: Thus a different approach to approximation may be proposed for a general situation, where there is some natural metric on the input space, but there does not seem to exist one for the output space. The following definition is similar to backward analysis of errors in numerical analysis <ref> [ 9 ] </ref> . Definition 2.2. Let M = (S; d) be a metric space and let f be a mapping from S into some set T which does not necessarily have any metric associated with it.
Reference: [10] <author> Y. Ye and M. Kojima, </author> <title> "Recovering optimal dual solutions in Karmarkar's polynomial algorithm for linear programming," </title> <note> Mathematical Programming 39 (1987) 305-317. 18 </note>
Reference-contexts: By our assumption, the set of optimal solutions of F B (A; b) is bounded. Several interior point algorithms are now known (e.g., <ref> [ 2; 10 ] </ref> ) which can start from any interior point and reduce the value of the objective function to a value not greater than t fl + * in a polynomial number of iterations in terms m; n and , where each iteration takes a polynomial number of operations
References-found: 10

