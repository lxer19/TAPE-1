URL: http://www.research.microsoft.com/~philtorr/Papers/IVC96/m.ps.gz
Refering-URL: http://www.research.microsoft.com/~philtorr/paper.html
Root-URL: http://www.research.microsoft.com
Email: Email: phst,az@robots.oxford.ac.uk  
Title: Robust Parametrization and Computation of the Trifocal Tensor  
Author: P H S Torr, A Zisserman 
Keyword: Trifocal tensor, robust estimation, matching, maximum likelihood estimation.  
Address: Oxford University, Parks Road, Oxford, OX1 3PJ, UK.  
Affiliation: Robotics Research Group Department of Engineering Science  
Abstract: This paper presents an algorithm for computing a Maximum Likelihood Estimate (MLE) of the trifocal tensor. The input to the algorithm is three images of the same scene, and the output is the estimated tensor and corner and line feature matches across the three images that are consistent with this estimate. Particular novelties of the algorithm are the computation of a trifocal tensor from six point correspondences, and a parametrization of the trifocal tensor which enforces the constraints between the tensor elements. The algorithm uses techniques from robust statistics and is fully automatic. Results are presented for synthetic and real image triplets. The proposed parametrization is compared to other existing methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Armstrong, A. Zisserman, and R. </author> <title> Hartley. Self-calibration from image triplets. </title> <editor> In B. Buxton and Cipolla R., editors, </editor> <booktitle> Proc. 4th European Conference on Computer Vision, </booktitle> <publisher> LNCS 1064, Cambridge, </publisher> <pages> pages 3-16. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: It is the culmination of developments by a number of researchers including [7, 12, 21, 22, 30, 31, 33, 34]. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration <ref> [1] </ref>, and motion segmentation [29]. Given correspondences for points in two images, the trifocal tensor determines the position of the point in the third (this is known as transfer).
Reference: [2] <author> P. Beardsley, P. H. S. Torr, and A. Zisserman. </author> <title> 3d model aquisition from extended image sequences. </title> <editor> In B. Buxton and Cipolla R., editors, </editor> <booktitle> Proc. 4th European Conference on Computer Vision, </booktitle> <publisher> LNCS 1065, Cambridge, </publisher> <pages> pages 683-695. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <title> 2 The reason that the variety has dimension three can be seen from the fact that each point on the variety also corresponds to a unique 3D line in the world; each of which has four degrees of freedom. </title> <address> IVC: </address> <month> May 6, </month> <year> 1997 </year> <month> 24 </month>
Reference-contexts: It is the culmination of developments by a number of researchers including [7, 12, 21, 22, 30, 31, 33, 34]. Recently the trifocal tensor has been used for applications in structure from motion including tracking <ref> [2] </ref>, camera calibration [1], and motion segmentation [29]. Given correspondences for points in two images, the trifocal tensor determines the position of the point in the third (this is known as transfer). <p> The threshold for match acceptance is deliberately conservative at this stage to minimise incorrect matches. Similarly cross correlation is used to generate initial matches between the second and third images. Full details of this matching, and the similar approach for line segments, are given in <ref> [2] </ref>. The second stage of the algorithm obtains an estimate of the trifocal tensor based on these correspondences. Because the matching process is only based on proximity and similarity, mismatches will often occur. These are sufficient to render standard least squares estimators useless.
Reference: [3] <author> J. Canny. </author> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 679-698, </pages> <year> 1986. </year>
Reference-contexts: In the first stage corners and line segments are extracted independently in each image. Corners are detected to sub-pixel accuracy using the Harris corner detector [11]. Lines are detected by the standard procedure of: Canny edge detection <ref> [3] </ref>; edge linking; segmentation of the chain at high curvature points; and finally, straight line fitting to the resulting chain segments. The straight line fitting is by orthogonal regression, with a tight tolerance to ensure that only actual line segments are extracted, i.e. that curves are not piecewise linear approximated.
Reference: [4] <author> J. C. Clarke. </author> <title> First order error propagation: A primer. </title> <type> OUEL report. </type>
Reference-contexts: Each line may be parametrized as l 1 = (l 1 1 ; l 1 2 ; 1) (for ease of exposition we shall temporarily ignore the singularity|lines through the origin) with covariance matrix <ref> [4, 6] </ref> 1 l etc. Then l 1;2;3 may written as a 6 vector of the homogeneous coordinates.
Reference: [5] <author> R. Deriche, Z. Zhang, Q. T. Luong, and O. Faugeras. </author> <title> Robust recovery of the epipolar geometry for an uncalibrated stereo rig. </title> <editor> In J. O. Eckland, editor, </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, LNCS 800/801, Stockholm, </booktitle> <pages> pages 567-576. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: The tensor can be computed linearly from a minimum of 7 points or 13 lines or a combination of the two. As in the case of the fundamental matrix <ref> [5, 25] </ref>, the tensor can be estimated from more than the minimum number of correspondences by minimising a cost function e.g. a solution may be computed by eigenvector methods finding the eigenvector with least eigenvalue of a 27 fi 27 matrix.
Reference: [6] <author> O.D. Faugeras. </author> <title> Three-Dimensional Computer Vision: A Geometric Viewpoint. </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Each line may be parametrized as l 1 = (l 1 1 ; l 1 2 ; 1) (for ease of exposition we shall temporarily ignore the singularity|lines through the origin) with covariance matrix <ref> [4, 6] </ref> 1 l etc. Then l 1;2;3 may written as a 6 vector of the homogeneous coordinates.
Reference: [7] <author> O.D. Faugeras and B. Mourrain. </author> <title> On the geometry and algebra of the point and line correspondences between n images. </title> <booktitle> In Proc. 5th Int'l Conf. on Computer Vision, Boston, </booktitle> <pages> pages 951-962, </pages> <year> 1995. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29]. <p> In the case of the fundamental matrix only the ratio of the elements is significant and there is one cubic constraint that the determinant is zero. For the trifocal tensor the 8 constraints have been investigated <ref> [7, 17] </ref> but are not as yet thoroughly understood. In the case of the fundamental matrix if the constraint is not imposed then the epipolar lines do not all intersect in a single epipole [18]. <p> Alternatively, the trifocal tensor elements can be computed directly from the determinants of 4fi4 matrices constructed from the rows of the camera matrices <ref> [7] </ref>, without requiring the first camera to have a canonical form.
Reference: [8] <author> O.D. Faugeras and L. Robert. </author> <title> What can two images tell us about a third one. </title> <editor> In J. O. Eckland, editor, </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, LNCS 800/801, Stockholm, </booktitle> <pages> pages 485-492. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Similarly, given correspondences for IVC: May 6, 1997 2 lines in two images, the same tensor determines the position of the line in the third image. Unlike point epipolar transfer <ref> [8, 36] </ref>, transfer based on the trifocal tensor does not fail for 3D points lying on, or close to, the trifocal plane (the plane defined by the three optical centres of the cameras), or when the three optical centres are collinear.
Reference: [9] <author> M. A. Fischler and R. C. Bolles. </author> <title> Random sample consensus: a paradigm for model fitting with application to image analysis and automated cartography. </title> <journal> Commun. Assoc. Comp. Mach., </journal> <volume> vol. 24 </volume> <pages> 381-95, </pages> <year> 1981. </year>
Reference-contexts: Consequently robust methods must be adopted, which can provide a good estimate of the tensor even if some of the data are mismatches (outliers). An early example of a robust algorithm is the random sample consensus paradigm (RANSAC) of Fischler and Bolles <ref> [9] </ref>. Given that a large proportion the data may be outlying, the approach is the opposite to conventional smoothing techniques. <p> The number of samples required, and hence the computation required, rises exponentially with the number of data points in the sample <ref> [9] </ref>. Thus the novel six point solution used here is markedly faster than the seven point method presented in Torr et al [29] to achieve the same level of accuracy. <p> The issue of constraints is explored further in Section 5. For the RANSAC algorithm a decision needs to be made as to how many samples should be taken. As pointed out by Fischler and Bolles <ref> [9] </ref> this should be dependent on the expected number of outliers within the data, and they provide a suitable formula for deciding the number of samples.
Reference: [10] <author> P. E. Gill and W. Murray. </author> <title> Algorithms for the solution of the nonlinear least-squares problem. </title> <journal> SIAM J Num Anal, </journal> <volume> 15(5) </volume> <pages> 977-992, </pages> <year> 1978. </year>
Reference-contexts: A non linear gradient descent minimization of the Huber cost function, using the six point basis provided by the last step as the initial solution and parametrization. The non-linear minimization is conducted using the method described in Gill and Mur-ray <ref> [10] </ref>, which is a modification of the Gauss-Newton method. An advantage of the method of Gill and Murray is that is does not require the calculation of any second order derivatives or Hessians.
Reference: [11] <author> C. Harris and M. Stephens. </author> <title> A combined corner and edge detector. </title> <booktitle> In Proc. Alvey Conf., </booktitle> <pages> pages 189-192, </pages> <year> 1987. </year>
Reference-contexts: In the first stage corners and line segments are extracted independently in each image. Corners are detected to sub-pixel accuracy using the Harris corner detector <ref> [11] </ref>. Lines are detected by the standard procedure of: Canny edge detection [3]; edge linking; segmentation of the chain at high curvature points; and finally, straight line fitting to the resulting chain segments.
Reference: [12] <author> R. I. </author> <title> Hartley. Lines and points in three views a unified approach. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <address> Monterey, </address> <year> 1994. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29]. <p> This parametrization is not consistent and not minimal. Finally as a bench mark to all the methods Hartley's <ref> [12] </ref> linear method will be tested on the data sets and dubbed M7. 6 Algorithm Summary and Implementation Details A brief summary of the algorithm is as follows: 1. Putative matching of points and lines over the three images using proximity and sim ilarity measures. 2.
Reference: [13] <author> R. I. </author> <title> Hartley. Projective reconstruction from line correspondences. </title> <booktitle> In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <year> 1994. </year>
Reference-contexts: The numerical optimisation requires a parametrization of the tensor which enforces the relations between the tensor elements. Section 5 describes this parametrization which is based on the minimal point set provided by RANSAC. The relation to other parametrizations proposed for the tensor by <ref> [13, 17, 29] </ref> is discussed. The algorithm is summarised and implementation details are given in Section 6. Section 7 compares and assesses the various parametrizations, giving results on both real and synthetic data. <p> This is not appropriate here for two reason, firstly the reconstruction is projective hence distance in 3D is meaningless. Secondly the noise introduced into the location of the features is an artifact of the feature detectors and hence is essentially image based. Hartley <ref> [13] </ref> used an overdetermined linear fit for the trifocal tensor, using eigenvector methods without minimising a statistically meaningful quantity. Neither of these approaches enforce the constraints between the tensor elements, a point we return to in Section 5. <p> This error measure, e is similar to the heuristic measures used in <ref> [13, 34] </ref>.
Reference: [14] <author> R. I. </author> <title> Hartley. In defence of the 8-point algorithm. </title> <booktitle> In Proc. 5th Int'l Conf. on Computer Vision, Boston, </booktitle> <pages> pages 1064-1075, </pages> <year> 1995. </year>
Reference-contexts: Hartley [13] used an overdetermined linear fit for the trifocal tensor, using eigenvector methods without minimising a statistically meaningful quantity. Neither of these approaches enforce the constraints between the tensor elements, a point we return to in Section 5. However, both Hartley <ref> [14] </ref> when estimating the rigidity constraint (fundamental matrix) from point correspondences over two images, and Weng et. al. [34] when estimating the rigidity constraint from line correspondences over three images consider a cost function which is equivalent to MLE given Gaussian noise, but the formulation is not made explicit. 4.1 MLE
Reference: [15] <author> P. J. Huber. </author> <title> Robust Statistics. </title> <publisher> John Willey and Sons, </publisher> <year> 1981. </year>
Reference-contexts: However, to take account of outliers, a robust version of this cost function is employed D = i + k l (8) where d and e are point and line errors and fl (x) is a robust Huber function <ref> [15] </ref>: fl (x) = x 2 x &lt; 1:96 (9) The value 1.96 corresponds to the 95% confidence level. This means that an inlier will only be incorrectly rejected (a Type II error) 5% of the time.
Reference: [16] <author> K. Kanatani. </author> <title> Statistical Optimization for Geometric Computation: Theory and Practice. </title> <address> El-sevier Science, Amsterdam, </address> <year> 1996. </year>
Reference-contexts: Both this correspondence ^ x 1;2;3 and the minimum distance d can be obtained as a first order approximation. This approximation is based on the works of Taubin [23] and Kanatani <ref> [16] </ref> on parametric surface fitting. Consider the space R 6 formed by joining together the three images with coordinate system (x 1 2 ; x 2 2 ; x 3 2 ). The trifocal tensor T can be thought of as a dimension three 1 variety in R 6 . <p> In general noisy lines l 1;2;3 do not lie on the variety Y and an error measure for the MLE results from the Mahalanobis distance: e 2 j l 1;2;3 1;2;3 1 ^ l l 1;2;3 following a general formulation given in Kanatani <ref> [16] </ref>. A first order approximation to both the line errors can be obtained in a similar manner to that given for the point errors.
Reference: [17] <author> S. Laveau. </author> <title> Geometry of a system of N cameras. Theory, estimation and applications. </title> <type> PhD thesis, </type> <institution> INRIA, </institution> <year> 1996. </year>
Reference-contexts: The numerical optimisation requires a parametrization of the tensor which enforces the relations between the tensor elements. Section 5 describes this parametrization which is based on the minimal point set provided by RANSAC. The relation to other parametrizations proposed for the tensor by <ref> [13, 17, 29] </ref> is discussed. The algorithm is summarised and implementation details are given in Section 6. Section 7 compares and assesses the various parametrizations, giving results on both real and synthetic data. <p> In the case of the fundamental matrix only the ratio of the elements is significant and there is one cubic constraint that the determinant is zero. For the trifocal tensor the 8 constraints have been investigated <ref> [7, 17] </ref> but are not as yet thoroughly understood. In the case of the fundamental matrix if the constraint is not imposed then the epipolar lines do not all intersect in a single epipole [18]. <p> Similarly, if the constraints are not imposed IVC: May 6, 1997 4 on the trifocal tensor elements, not only may the epipoles not be defined but the various linear methods of transfer in equation (1) will give different results for the transferred point position <ref> [17] </ref>. It might be thought that since the tensor has only 18 independent elements it could be computed from five point correspondences, together with the polynomial constraints discussed above, since each point correspondence contributes four linearly independent equations and 5 fi 4 &gt; 18. This is not the case. <p> Existing consistent parametrizations generally proceed by initially computing the three 3 fi 4 projection matrices, and computing the tensor from these <ref> [17] </ref>. In the following section the 6 point parametrization, with varying numbers of free variables, is compared to: 1.
Reference: [18] <author> Q. T. Luong, R. Deriche, O. D. Faugeras, and T. Papadopoulo. </author> <title> On determining the fundamental matrix: analysis of different methods and experimental results. </title> <type> Technical Report 1894, </type> <institution> INRIA (Sophia Antipolis), </institution> <year> 1993. </year>
Reference-contexts: For the trifocal tensor the 8 constraints have been investigated [7, 17] but are not as yet thoroughly understood. In the case of the fundamental matrix if the constraint is not imposed then the epipolar lines do not all intersect in a single epipole <ref> [18] </ref>. Similarly, if the constraints are not imposed IVC: May 6, 1997 4 on the trifocal tensor elements, not only may the epipoles not be defined but the various linear methods of transfer in equation (1) will give different results for the transferred point position [17].
Reference: [19] <author> J. Mundy and A. Zisserman. </author> <title> Geometric Invariance in Computer Vision. </title> <publisher> MIT press, </publisher> <year> 1992. </year>
Reference-contexts: value decomposition (SVD) thus the square of the distance is given by d 2 = jj ^ x 1;2;3 x 1;2;3 jj 2 = r &gt; (JJ &gt; ) + r If the set of trilinearities are linear, which is the case under orthographic projection [21, 24] or under affine <ref> [19] </ref> viewing conditions, then this approximation is exact. C General Covariances Within this appendix the maximum likelihood arguments for points and lines are generalized to arbitrary covariance matrices on the data.
Reference: [20] <author> L. Quan. </author> <title> Invariants of 6 points from 3 uncalibrated images. </title> <editor> In J. O. Eckland, editor, </editor> <booktitle> Proc. 3rd European Conference on Computer Vision, LNCS 800/801, Stockholm, </booktitle> <pages> pages 459-469. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year> <month> IVC: May 6, </month> <year> 1997 </year> <month> 25 </month>
Reference-contexts: The best solution is that which maximizes the number of feature (corner and line) correspondences whose error is below a threshold. This second stage of the algorithm is summarized in Table 1. The method for finding the trifocal tensor from six points uses the theory of Quan <ref> [20] </ref> for computing an invariant of six points from 3 views, and is described in Appendix A. The method involves the solution of a cubic, and correspondingly provides one or three real solutions for the trifocal tensor. <p> Financial support was provided by ACTS Project Vanguard. A Computation of the trifocal tensor from six point correspondences In this appendix the method for finding the trifocal tensor from six points is detailed, the method is inspired by the method of Quan <ref> [20] </ref> the derivation follows that given in Weinshall et al. [32]. The algorithm requires six space points in general position, otherwise the trifocal tensor cannot be uniquely determined. <p> w 5 x 5 (i) (i) (i) (i) w 6 X 0 x 6 Z w 6 W x 6 W (i) (i) (i) (i) 3 7 7 5 B B ff (i) fl (i) 1 C A The 4 fi 4 matrix on the left is has rank 3 <ref> [20] </ref> and is given purely in terms of the image coordinates and the sixth space point.
Reference: [21] <author> A. Shashua. </author> <title> Trilinearity in visual recognition by alignment. </title> <booktitle> In Proc. 3rd European Conference on Computer Vision, LNCS 800/801, Stockholm, </booktitle> <volume> volume 1, </volume> <pages> pages 479-484, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29]. <p> J returned by a singular value decomposition (SVD) thus the square of the distance is given by d 2 = jj ^ x 1;2;3 x 1;2;3 jj 2 = r &gt; (JJ &gt; ) + r If the set of trilinearities are linear, which is the case under orthographic projection <ref> [21, 24] </ref> or under affine [19] viewing conditions, then this approximation is exact. C General Covariances Within this appendix the maximum likelihood arguments for points and lines are generalized to arbitrary covariance matrices on the data.
Reference: [22] <author> M. Spetsakis and J. Aloimonos. </author> <title> A multi-frame approach to visual motion perception. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6 </volume> <pages> 245-255, </pages> <year> 1991. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29]. <p> A similar notation is used for lines. There have been several previous algorithms to estimate the rigidity constraint over three views each proposing a different error metric. Spetsakis and Aloimonos <ref> [22] </ref>, working with a calibrated equivalent of the trifocal tensor, propose a noise model on the 3D features; minimizing distances in 3D. This is not appropriate here for two reason, firstly the reconstruction is projective hence distance in 3D is meaningless.
Reference: [23] <author> G. Taubin. </author> <title> Estimation of planar curves, surfaces, and nonplanar space curves defined by implicit equations with applications to edge and range image segmentation. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> vol.PAMI-13,no.11:1115-1138, </volume> <year> 1991. </year>
Reference-contexts: Both this correspondence ^ x 1;2;3 and the minimum distance d can be obtained as a first order approximation. This approximation is based on the works of Taubin <ref> [23] </ref> and Kanatani [16] on parametric surface fitting. Consider the space R 6 formed by joining together the three images with coordinate system (x 1 2 ; x 2 2 ; x 3 2 ).
Reference: [24] <author> P. H. S. Torr. </author> <title> Outlier Detection and Motion Segmentation. </title> <type> PhD thesis, </type> <institution> University of Oxford, Engineering Dept., </institution> <year> 1995. </year>
Reference-contexts: J returned by a singular value decomposition (SVD) thus the square of the distance is given by d 2 = jj ^ x 1;2;3 x 1;2;3 jj 2 = r &gt; (JJ &gt; ) + r If the set of trilinearities are linear, which is the case under orthographic projection <ref> [21, 24] </ref> or under affine [19] viewing conditions, then this approximation is exact. C General Covariances Within this appendix the maximum likelihood arguments for points and lines are generalized to arbitrary covariance matrices on the data.
Reference: [25] <author> P. H. S. Torr, P. A. Beardsley, and D. W. Murray. </author> <title> Robust vision. </title> <editor> In J. Illingworth, editor, </editor> <booktitle> Proc. 5th British Machine Vision Conference, </booktitle> <address> York, </address> <pages> pages 145-155. </pages> <publisher> BMVA Press, </publisher> <year> 1994. </year>
Reference-contexts: The tensor can be computed linearly from a minimum of 7 points or 13 lines or a combination of the two. As in the case of the fundamental matrix <ref> [5, 25] </ref>, the tensor can be estimated from more than the minimum number of correspondences by minimising a cost function e.g. a solution may be computed by eigenvector methods finding the eigenvector with least eigenvalue of a 27 fi 27 matrix.
Reference: [26] <author> P. H. S. Torr and D. W. Murray. </author> <title> Outlier detection and motion segmentation. </title> <editor> In P. S. Schenker, editor, </editor> <booktitle> Sensor Fusion VI, </booktitle> <pages> pages 432-443. </pages> <booktitle> SPIE volume 2059, 1993. </booktitle> <address> Boston. </address>
Reference-contexts: This is equivalent to the automatic algorithms developed for computing the fundamental matrix from two images in Torr and Murray <ref> [26] </ref> and Zhang et. al. [35]. The third stage of the algorithm, described in Section 4 uses this initial robust estimate of the tensor as a starting point for the MLE. In the first stage corners and line segments are extracted independently in each image.
Reference: [27] <author> P. H. S. Torr and A Zisserman. </author> <title> Computing multiple view relations. </title> <type> OUEL Report, </type> <year> 1997. </year>
Reference-contexts: The general method (of minimal parametrization in terms of basis points found from RANSAC) could be used for any other estimation problem in vision, for instance estimating the fundamental matrix, projectivities, camera matrices etc. Such extensions are explored in Torr and Zisserman <ref> [27] </ref>. Rather than using RANSAC to estimate the starting parameters the random sample that minimises the Huber cost function could be selected. This has the advantage that the robust estimator would then be minimizing the MLE cost function that we have derived in this paper as the optimal cost function. <p> This has the advantage that the robust estimator would then be minimizing the MLE cost function that we have derived in this paper as the optimal cost function. This method has been implemented and is reported in <ref> [27] </ref>. In conclusion, the methodology is general and could be used outside of vision in any problem where minimal parametrizations are not immediately obvious, and the constraints may be determined from some minimal number of points.
Reference: [28] <author> P. H. S. Torr, A Zisserman, and S. Maybank. </author> <title> Robust detection of degenerate configurations for the fundamental matrix. </title> <note> Accepted to CVIU, </note> <year> 1996. </year>
Reference-contexts: In the second case, should the data as a whole be degenerate then the algorithm will fail to converge to a suitable result, the discussion of degeneracy is beyond the scope of this paper and is considered further in Torr et. al. <ref> [28] </ref>. 7 Results We have rigorously tested the various parametrizations on real and synthetic data. Two measures are compared: The first assesses the accuracy of the solution. The second measure is the number of cost function evaluations made i.e. the number of times D is evaluated.
Reference: [29] <author> P. H. S. Torr, A. Zisserman, and D. W. Murray. </author> <title> Motion clustering using the trilinear constraint over three views. </title> <editor> In R. Mohr and C. Wu, editors, </editor> <booktitle> Europe-China Workshop on Geometrical Modelling and Invariants for Computer Vision, </booktitle> <pages> pages 118-125. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: It is the culmination of developments by a number of researchers including [7, 12, 21, 22, 30, 31, 33, 34]. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation <ref> [29] </ref>. Given correspondences for points in two images, the trifocal tensor determines the position of the point in the third (this is known as transfer). <p> The numerical optimisation requires a parametrization of the tensor which enforces the relations between the tensor elements. Section 5 describes this parametrization which is based on the minimal point set provided by RANSAC. The relation to other parametrizations proposed for the tensor by <ref> [13, 17, 29] </ref> is discussed. The algorithm is summarised and implementation details are given in Section 6. Section 7 compares and assesses the various parametrizations, giving results on both real and synthetic data. <p> The number of samples required, and hence the computation required, rises exponentially with the number of data points in the sample [9]. Thus the novel six point solution used here is markedly faster than the seven point method presented in Torr et al <ref> [29] </ref> to achieve the same level of accuracy. Furthermore for computational efficiency we are discouraged from using lines to initialize an estimate since many more lines are needed than points to minimally estimate the tensor. <p> Table 2: The DOF, average number of evaluations of the total cost function D (given in Equation (8)) in the gradient descent algorithm, and the standard deviation p (10) for the perfect synthetic point data. trifocal tensor from 7 points linearly as an eigenvector of a 27 fi 27 matrix <ref> [29] </ref>, but it is not consistent. Synthetic data were randomly generated in three space; 100 sets of 100 corresponding triples were generated. The image data were perturbed by Gaussian noise, standard deviation 1:0, and then quantized to the nearest 0.1 pixel.
Reference: [30] <author> B. Triggs. </author> <title> The geometry of projective reconstruction i: Matching constraints and the joint image. </title> <booktitle> In Proc. 5th Int'l Conf. on Computer Vision, Boston, </booktitle> <pages> pages 338-343, </pages> <year> 1995. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29].
Reference: [31] <author> T. Vieville and Q-T. Luong. </author> <title> Motion of points and lines in the uncalibrated case. </title> <type> Technical Report 2054, </type> <institution> INRIA, </institution> <year> 1993. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29].
Reference: [32] <author> D. Weinshall, M. Werman, and A. Shashua. </author> <title> Duality of multi-point and multi-frame geometry: Fundamental shape matrices and tensors. </title> <editor> In B. Buxton and Cipolla R., editors, </editor> <booktitle> Proc. 4th European Conference on Computer Vision, </booktitle> <publisher> LNCS 1065, Cambridge, </publisher> <pages> pages 217-227. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: A Computation of the trifocal tensor from six point correspondences In this appendix the method for finding the trifocal tensor from six points is detailed, the method is inspired by the method of Quan [20] the derivation follows that given in Weinshall et al. <ref> [32] </ref>. The algorithm requires six space points in general position, otherwise the trifocal tensor cannot be uniquely determined.
Reference: [33] <author> J. Weng, N. Ahuja, and T. Huang. </author> <title> Optimal motion and structure estimation. </title> <journal> IEEE PAMI, </journal> <volume> vol.15(9):864-884, </volume> <year> 1993. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29].
Reference: [34] <author> J. Weng, T. Huang, and N. Ahuja. </author> <title> Motion and structure from line correspondences: Closed-form solution, uniqueness and optimization. </title> <journal> IEEE PAMI, </journal> <volume> vol.14(3):318-336, </volume> <year> 1992. </year>
Reference-contexts: The tensor only depends on the motion between views and the internal parameters of the cameras, but it can be computed from image correspondences alone without requiring knowledge of the motion or calibration. It is the culmination of developments by a number of researchers including <ref> [7, 12, 21, 22, 30, 31, 33, 34] </ref>. Recently the trifocal tensor has been used for applications in structure from motion including tracking [2], camera calibration [1], and motion segmentation [29]. <p> Neither of these approaches enforce the constraints between the tensor elements, a point we return to in Section 5. However, both Hartley [14] when estimating the rigidity constraint (fundamental matrix) from point correspondences over two images, and Weng et. al. <ref> [34] </ref> when estimating the rigidity constraint from line correspondences over three images consider a cost function which is equivalent to MLE given Gaussian noise, but the formulation is not made explicit. 4.1 MLE for Point Data In the following for simplicity it is assumed and without loss of generality that the <p> This error measure, e is similar to the heuristic measures used in <ref> [13, 34] </ref>.
Reference: [35] <author> Z. Zhang, R. Deriche, O. Faugeras, and Q. T. Luong. </author> <title> A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry. </title> <journal> AI Journal, </journal> <volume> vol.78:87-119, </volume> <year> 1994. </year>
Reference-contexts: This is equivalent to the automatic algorithms developed for computing the fundamental matrix from two images in Torr and Murray [26] and Zhang et. al. <ref> [35] </ref>. The third stage of the algorithm, described in Section 4 uses this initial robust estimate of the tensor as a starting point for the MLE. In the first stage corners and line segments are extracted independently in each image.
Reference: [36] <author> A. Zisserman and Maybank S. </author> <title> A case against epipolar geometry. </title> <editor> In J. Mundy, A. Zisserman, and D. Forsyth, editors, </editor> <booktitle> Applications of Invariance in Computer Vision LNCS 825. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Similarly, given correspondences for IVC: May 6, 1997 2 lines in two images, the same tensor determines the position of the line in the third image. Unlike point epipolar transfer <ref> [8, 36] </ref>, transfer based on the trifocal tensor does not fail for 3D points lying on, or close to, the trifocal plane (the plane defined by the three optical centres of the cameras), or when the three optical centres are collinear.
References-found: 36

