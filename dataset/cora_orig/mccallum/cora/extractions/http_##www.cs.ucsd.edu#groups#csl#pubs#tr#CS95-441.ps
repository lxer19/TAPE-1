URL: http://www.cs.ucsd.edu/groups/csl/pubs/tr/CS95-441.ps
Refering-URL: http://www.cs.ucsd.edu/groups/csl/pubs/author.html
Root-URL: http://www.cs.ucsd.edu
Email: -ewa, pasquale-@cs.ucsd.edu  
Title: The Performance of the Container Shipping I/O System  
Author: Eric Anderson Joseph Pasquale 
Note: August  
Date: htpp://www-CSL.ucsd.edu  1995  
Abstract: Technical Report CS95-441 Department of Computer Science and Engineering University of California, San Diego Abstract I/O subsystems, and the APIs used to access them, have long been designed with two basic assumptions. First, I/O is performed to relatively slow disks or terminals, so processor time for I/O operations is available while waiting for devices. Second, optimization is done by guessing the users needs, such as a filesystem cache does by assuming locality. This traditional design causes I/O performance problems for modern devices such as video displays and high-speed networks, where the above assumptions are no longer valid. We have designed a high-performance I/O subsystem, and a uniform API through which it is accessed, that gives a user-level programmer greater control, which allows operations to be performed more efficiently, and often optimally. Speedups from 30 to over 700 percent can be demonstrated with our technique. Our API is fully uniform, and yields gains for any form of device, including disks, networks, frame buffers, and even IPC performed through the I/O system. This paper describes our implementation of this mechanism, called Container Shipping, and its measured performance for different kinds of I/O. 
Abstract-found: 1
Intro-found: 1
Reference: [BCD72] <author> A. Bensoussan, C. T. Clingen, and R. C. Daley, </author> <title> The Multics Virtual Memory: Concepts and Design, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 15, No. 5, </volume> <month> May </month> <year> 1972, </year> <pages> pp. 308-318. </pages>
Reference-contexts: Furthermore, the kernel must contain data structures and mechanisms to support the special page faults which trigger memory copies. An alternative approach to copy-free I/O is to use memory-mapped files. This technique has its roots in Multics <ref> [BCD72] </ref> and Pilot [Red+80]. Memory-mapped file services are found in several modern Unix systems, and can be used to allow simple file I/O without copies [Kri+94]. This technique is particularly convenient if a kernel already provides a memory layer between processes and disks, such as the Unix buffer cache.
Reference: [Bob+72] <author> D. G. Bobrow et al., Tenex, </author> <title> A Paged Time Sharing System for the PDP-10, </title> <journal> Comm. ACM, </journal> <volume> Vol. 15, No. 3, </volume> <month> Mar. </month> <year> 1972, </year> <pages> pp. 135-143. 16 </pages>
Reference-contexts: In this section we review the relevant differences between Container Shipping and other related work. Numerous systems use virtual transfer techniques to avoid the performance penalty of physical copying. Tenex <ref> [Bob+72] </ref> was one of the first systems to use virtual copying, which allowed pages to be shared with a copy-on-write behavior. Accent [RR81] and later Mach [Ras+88] generalized this concept by integrating virtual memory and IPC so that messages could be virtually copied, providing a more structured communication service.
Reference: [Dru94] <author> Peter Druschel, </author> <title> Operating System Support for High-speed Networking, </title> <type> Ph.D. Dissertation, </type> <institution> University of Arizona, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: Sustained copy rates include TLB misses and imperfect cache behavior, plus interrupt overhead from a running, though otherwise idle, Unix kernel. Burst transfer rates are higher [Dut+92] <ref> [Dru94] </ref>. 3 Container Shipping is a fast I/O system suitable for use with any operating system. Container Shipping includes a user-level API (Application Programming Interface) for copy-free I/O.
Reference: [DP93] <author> Peter Druschel and Larry Peterson, Fbufs: </author> <title> A High-Bandwidth Cross-Domain Transfer Facility, </title> <booktitle> Proceedings of the 14th Symposium on Operating System Principles, </booktitle> <pages> pp. 189-202, </pages> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Another difference is that DASH remaps pages unconditionally, although the machine-dependent level of page table updates can be deferred. However, it is acknowledged in the DASH literature that the page fault required to perform a deferred map is expensive. The Fbufs system <ref> [DP93] </ref> is fast buffering system with a particular focus on network I/O, that uses VM techniques similar to those used in DASH.
Reference: [Dut+92] <author> T. A. Dutton et al., </author> <title> The Design of the DEC 3000 AXP Systems, Two High-performance Workstations, </title> <journal> Digital Technical Journal, </journal> <volume> Vol. 4, No. 4, </volume> <year> 1992. </year>
Reference-contexts: Sustained copy rates include TLB misses and imperfect cache behavior, plus interrupt overhead from a running, though otherwise idle, Unix kernel. Burst transfer rates are higher <ref> [Dut+92] </ref> [Dru94]. 3 Container Shipping is a fast I/O system suitable for use with any operating system. Container Shipping includes a user-level API (Application Programming Interface) for copy-free I/O.
Reference: [Fall94] <author> Kevin R. </author> <month> Fall, </month> <title> A Peer-to-Peer I/O System in Support of I/O Intensive Workloads, </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science and Engineering, University of California, </institution> <address> San Diego, </address> <year> 1994. </year>
Reference-contexts: For more general approaches such as fbufs, the performance improvements may depend on specific devices. Fbufs demonstrates good performance for a network interface which autonomously demultiplexes packets based on a VCI (Virtual Circuit Identifier). Finally, Container shipping differs from systems that support inter-device streaming <ref> [Fall94] </ref> which also achieve high performance by eliminating data copying. Bypassing the user level by moving data directly from one device to another limits what can be accomplished in a user-level program, contrary to our goal of general-purpose computing.
Reference: [HP90] <author> John L. Hennessy and David A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1990. </year>
Reference-contexts: The repeated duplication of data within system memory during I/O operations consumes time, increasing latency while reducing throughput. Each year, processor speeds increase from 50 to 100 percent, while memory speeds increase by only 7 to 15 percent <ref> [HP90] </ref>. Relative to overall system performance, the cost of in-memory copies rises annually. Memory 2 speeds we have measured in a modern RISC workstation are shown in Figure 1.
Reference: [Kri+94] <author> O. Krieger et al., </author> <title> The Alloc Stream Facility: A Redesign of Application-Level Stream I/O, </title> <journal> IEEE Computer, </journal> <volume> Vol. 27, No. 3, </volume> <month> March </month> <year> 1994, </year> <pages> pp. 75-83. </pages>
Reference-contexts: An alternative approach to copy-free I/O is to use memory-mapped files. This technique has its roots in Multics [BCD72] and Pilot [Red+80]. Memory-mapped file services are found in several modern Unix systems, and can be used to allow simple file I/O without copies <ref> [Kri+94] </ref>. This technique is particularly convenient if a kernel already provides a memory layer between processes and disks, such as the Unix buffer cache.
Reference: [RR81] <author> R. Rashid and G. Robertson, </author> <title> Accent: A Communication-Oriented Network Operating System Kernel, </title> <booktitle> Proc. 8th Symp. Operating System Principles, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1981, </year> <pages> pp. 64-85. </pages>
Reference-contexts: Numerous systems use virtual transfer techniques to avoid the performance penalty of physical copying. Tenex [Bob+72] was one of the first systems to use virtual copying, which allowed pages to be shared with a copy-on-write behavior. Accent <ref> [RR81] </ref> and later Mach [Ras+88] generalized this concept by integrating virtual memory and IPC so that messages could be virtually copied, providing a more structured communication service. We will call these virtual copying systems.
Reference: [Ras+88] <author> R. Rashid et al., </author> <title> Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures, </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37, 8, </volume> <pages> pp. 896-908, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Numerous systems use virtual transfer techniques to avoid the performance penalty of physical copying. Tenex [Bob+72] was one of the first systems to use virtual copying, which allowed pages to be shared with a copy-on-write behavior. Accent [RR81] and later Mach <ref> [Ras+88] </ref> generalized this concept by integrating virtual memory and IPC so that messages could be virtually copied, providing a more structured communication service. We will call these virtual copying systems.
Reference: [Red+80] <author> David D. Redell et al., </author> <title> Pilot: An Operating System for a Personal Computer, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 23, No. 2, </volume> <pages> pp. 81-92, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: Furthermore, the kernel must contain data structures and mechanisms to support the special page faults which trigger memory copies. An alternative approach to copy-free I/O is to use memory-mapped files. This technique has its roots in Multics [BCD72] and Pilot <ref> [Red+80] </ref>. Memory-mapped file services are found in several modern Unix systems, and can be used to allow simple file I/O without copies [Kri+94]. This technique is particularly convenient if a kernel already provides a memory layer between processes and disks, such as the Unix buffer cache.
Reference: [TA91] <author> Shin-Yuan Tzou and David. P. Anderson, </author> <title> The Performance of Message-Passing Using Restricted Virtual Memory Remapping, </title> <journal> Software -- Practice and Experience, </journal> <volume> Volume 21, Number 3, </volume> <pages> pp. 251-267, </pages> <month> March </month> <year> 1991. </year> <note> Visit the Computer Systems Laboratory web site: http://www-CSL.ucsd.edu Also visit the UCSD Computer Science Department web site: http://www-cse.ucs.edu </note>
Reference-contexts: By measuring the speed of I/O operations which used no actual device, this experiment demonstrated results consistent with earlier work, such as DASH, which showed that VM remapping was very effective for IPC <ref> [TA91] </ref>. However, we also demonstrated additional savings when mapping was avoided, as can be seen in the half-map and no-map cases. The FDDI experiment tested the practicality of Container Shipping for a very complicated device. The device driver for DECs DEFTA FDDI interface contains over 8000 lines of code. <p> The closest systems to Container Shipping in their use of page remapping to transfer data between domains, without necessarily using copy-on-write, are DASH and Fbufs. DASH <ref> [TA91] </ref> provides high performance inter-process communication, with fast local IPC via page remapping 14 that allows processes to exclusively own regions of a restricted area of a shared address space. DASH differs from Container Shipping in several key areas.
References-found: 12

