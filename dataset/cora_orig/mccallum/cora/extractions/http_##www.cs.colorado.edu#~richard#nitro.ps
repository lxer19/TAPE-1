URL: http://www.cs.colorado.edu/~richard/nitro.ps
Refering-URL: http://www.cs.colorado.edu/~richard/Home.html
Root-URL: http://www.cs.colorado.edu
Title: An Interior Point Algorithm for Large Scale Nonlinear Programming  
Author: Richard H. Byrd Mary E. Hribar Jorge Nocedal 
Keyword: Key words: constrained optimization, interior point method, large-scale optimization, nonlinear programming, primal method, primal-dual method, successive quadratic programming, trust region method.  
Note: 80309. This author was supported by ARO grant DAAH04-94-0228, and AFOSR grant F49620-94-1-0101.  77005. This author was supported by Department of Energy grant DE-FG02-87ER25047-A004.  60208. This author was supported by National Science Foundation grant CCR-9625613 and by Department of Energy grant DE-FG02-87ER25047-A004.  
Address: Boulder CO  Houston TX  Evanston Il  
Affiliation: Computer Science Department, University of Colorado,  CAAM Department, Rice University,  ECE Department, Northwestern University,  
Date: July 27, 1997  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K.M. Anstreicher and J.P. Vial. </author> <title> On the convergence of an infeasible primal-dual interior point method for convex programming. </title> <journal> Optimization Methods and Software, </journal> <volume> 3, </volume> <pages> pp. 273-283, </pages> <year> 1994. </year>
Reference-contexts: The special case when the problem is a convex program can be handled by line search methods that are, in a sense, direct extensions of interior point methods for linear programming (see e.g. <ref> [1] </ref>). In the convex case, the step generated by the solution of the primal-dual equations can be shown to be a descent direction for several merit functions, and this allows one to establish fairly satisfactory convergence results. <p> ) * , where E measures the optimality conditions of the barrier problem and is defined by E (x; s; ) = max (krf (x) + A h (x) h + A g (x) g k 1 ; kS g ek 1 ; kh (x)k 1 ; Here e = <ref> [1; :::; 1] </ref> T , S = diag (s 1 ; :::; s m ), with superscripts indicating components of a vector, and A h (x) = [rh 1 (x); : : : ; rh t (x)]; A g (x) = [rg 1 (x); : : : ; rg m (x)]
Reference: [2] <author> M. Argaez. </author> <title> Exact and inexact Newton linesearch interior-point Algorithms for nonlinear programming problems, </title> <institution> TR97-13, Department of Computational and Applied Mathematics, Rice University, Houston, Texas, </institution> <year> 1997. </year>
Reference-contexts: These algorithms can also be viewed as a 1 direct extension of linear programming methods, in that they do not make provisions for the case when the problems is non-convex. Several line search algorithms designed for non-convex problems have recently been proposed <ref> [41, 20, 14, 21, 2, 34] </ref>. An important feature of many of these methods is a strategy for modifying the KKT system used in the computation of the search direction.
Reference: [3] <author> R.H. Byrd. </author> <title> Robust trust region methods for constrained optimization, </title> <booktitle> Third SIAM Conference on Optimization, </booktitle> <address> Houston, Texas, </address> <year> 1987. </year>
Reference-contexts: The technique used to solve the subproblems has a great impact on the efficiency and robustness of the algorithm; we use an adaptation of the trust region method of Byrd and Omojokun <ref> [3, 33] </ref> which has proved to be effective for solving large equality constrained problems [30]. Our numerical results suggest that the new algorithm holds much promise: it appears to be robust and efficient (in terms of function evaluations), and can make effective use of second derivative information. <p> The challenge is to perform this step efficiently, even when is small, while forcing the slack variables to remain positive. To do this we apply an adaptation of the equality constrained SQP iteration with trust regions proposed by Byrd <ref> [3] </ref> and Omojokun [33] and developed by Lalee, Nocedal and Plantenga [30] for large-scale equality constrained optimization. <p> This non-differentiable merit function has been successfully used in the SQP algorithm of Byrd and Omojokun <ref> [3, 33, 30] </ref>, and has been analyzed in the context of interior point methods in [8]. We summarize this SQP trust region approach as follows. <p> This vector will be determined during the course of solving the quadratic subproblem, as discussed next. 3.2. Solution of the Quadratic Subproblem We will use the decomposition proposed by Byrd and Omojokun <ref> [3, 33] </ref> to find an approximate solution of the subproblem (2.4)-(2.7).
Reference: [4] <author> P.T. Boggs and J.W. Tolle. </author> <title> Sequential Quadratic Programming, </title> <booktitle> Acta Numerica 1995, </booktitle> <publisher> Cambridge University Press, </publisher> <pages> 1-51, </pages> <year> 1995. </year>
Reference-contexts: We follow an SQP approach because it is known to be effective for solving equality constrained 3 problems, even when the problem is ill-conditioned and the constraints are highly nonlinear <ref> [4, 23, 19, 22] </ref>, and choose to use trust region strategies to globalize the SQP iteration because they facilitate the use of second derivative information when the problem is non-convex.
Reference: [5] <author> I. Bongartz, A.R. Conn, N.I.M. Gould and Ph.L. Toint. CUTE: </author> <title> Constrained and Unconstrained Testing Environment, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 21, </volume> <pages> pp. 123-160, </pages> <year> 1995. </year>
Reference-contexts: We use the following initial values: * = 0:1, = 0:1 and 0 = 1. 4. Numerical Tests We have tested our algorithm on a set of problems from the CUTE collection <ref> [5] </ref> whose characteristics are described in Table 1. There n denotes the number of variables and m the total number of constraints, including equalities, bounds and general inequalities. We also state what kinds of conditions are imposed on the variables (fixed, free, bounds).
Reference: [6] <author> J.F. Bonnans and C. Pola. </author> <title> A trust region interior point algorithm for linearly constrained optimization, </title> <institution> Rapport de recherche 1948, INRIA, </institution> <address> France 1993. </address>
Reference-contexts: Since these algorithms are quite recent, it is difficult to assess at this point whether they will lead to robust general-purpose codes. The use of trust region strategies in interior point methods for linear and nonlinear problems is not new <ref> [6, 32] </ref>. Coleman and Li [11, 12] proposed a primal method for bound constrained nonlinear optimization; see also [26].
Reference: [7] <author> R.H. Byrd, G. Liu and J. Nocedal. </author> <title> Improving the efficiency of an interior point method for nonlinear programming, </title> <booktitle> to appear in the Proceedings of the 1997 Dundee Biennial Conference on Numerical Analysis. </booktitle>
Reference-contexts: We will, however, not consider this question here and defer its study, in the context of our algorithm, to a future article <ref> [7] </ref>. Most of the work of Algorithm I lies clearly in step 1, in the approximate solution of an equality constrained problem with an implicit lower bound on the slack variables. <p> The algorithm presented here is not as rapidly convergent as it can be. We are currently developing <ref> [7] </ref> various mechanisms to accelerate the iteration; these include the use of higher-order corrections and rules for decreasing the barrier parameter at a superlinear rate.
Reference: [8] <author> R.H. Byrd, J.C. Gilbert, and J. Nocedal. </author> <title> A trust region method based on interior point techniques for nonlinear programming. </title> <type> Report OTC 96/02, </type> <institution> Optimization Technology Center, Northwestern University, </institution> <year> 1996. </year>
Reference-contexts: Interior point methods provide an alternative to active set methods for the treatment of inequality constraints. Our algorithm, which is based on the framework proposed by Byrd, Gilbert and Nocedal <ref> [8] </ref>, incorporates within the interior point method two powerful tools for solving nonlinear problems: sequential quadratic programming and trust region techniques. Sequential quadratic programming (SQP) ideas are used to efficiently handle nonlinearities in the constraints. <p> The test results also indicate that the primal-dual version of the algorithm is superior to the primal version. The new algorithm has a solid theoretical foundation, since it follows the principles of the globally convergent primal method developed in <ref> [8] </ref>. There has been much research in using interior point methods for nonlinear programming; most of it concerns line search methods. <p> This non-differentiable merit function has been successfully used in the SQP algorithm of Byrd and Omojokun [3, 33, 30], and has been analyzed in the context of interior point methods in <ref> [8] </ref>. We summarize this SQP trust region approach as follows. <p> The first choice is to define k = r 2 ss L k , which gives k = S 2 The general algorithm studied in Byrd, Gilbert and Nocedal <ref> [8] </ref> defines k in this manner. <p> 6 4 xx L k 0 A h (x k ) A g (x k ) A T A T 3 7 5 6 6 d x + + 3 7 5 2 6 4 S 1 h (x k ) 3 7 5 It is well known (see e.g. <ref> [17, 43, 8] </ref>) and easy to verify that, if k is defined by (3.1), the system (3.2) is equivalent to a Newton iteration on the KKT conditions of the barrier problem (2.1), which are given by rf (x) + A h (x) h + A g (x) g = 0 (3.3) <p> Combining this inequality, which can be rephrased as d s t s k , with (3.16) we obtain the final form of the trust region, k (d x ; S 1 The trust region (3.18) does not precisely match with the model algorithm analyzed by Byrd, Gilbert and Nocedal <ref> [8] </ref>, but it is not difficult to extend that analysis to our case. We have experimented with other forms of the trust region, in particular with box-shaped trust regions defined by an ` 1 norm, but so far (3.18) appears to be the most appropriate for our algorithm. <p> The definition (3.49) is motivated and analyzed in <ref> [8] </ref>, and is similar to that used in other trust region algorithms for constrained optimization. (Since m measures the sums of squares of the changes in the constraints, by taking its square root, the predicted reduction is compatible with the merit function which includes the norm of the constraints.) We demand <p> We see from (3.49) that we can enforce inequality (3.50) by choosing the penalty pa rameter -k so that -k (1 ) m (~v) As has been argued in <ref> [8] </ref>, if m (~v) = 0, then ~v = 0, which implies q (~v + ~w) 0, and so (3.50) is satisfied for any value of -k . In this case -k can be defined as its value in the previous iteration of Algorithm II. <p> Using essentially the same argument as in <ref> [8] </ref> it can be shown that (3.53) will be satisfied if the trust region radius is sufficiently small.
Reference: [9] <author> M.R. Celis, J.E. Dennis and R.A. Tapia. </author> <title> A trust region strategy for nonlinear equality constrained optimization, </title> <note> in Numerical Optimization 1984, </note> <author> P.T. Boggs, R.H. Byrd and R.B. Schnabel, </author> <booktitle> eds., </booktitle> <pages> pp. 71-82, </pages> <publisher> SIAM, </publisher> <year> 1985. </year>
Reference-contexts: A step d of the algorithm is computed by minimizing the quadratic model, subject to satisfying a linear approximation to the constraints, and subject to a trust region bound on this step; <ref> [9, 39] </ref>. If the step d gives a sufficient reduction in the merit function , then it is accepted; otherwise the step is rejected, the trust region is reduced and a new step is computed.
Reference: [10] <author> R. M. Chamberlain, C. Lemarechal, H. C. Pedersen and M. J. D. Powell. </author> <title> The watchdog technique for forcing convergence in algorithms for constrained optimization, </title> <journal> Mathematical Programming Studies, </journal> <volume> 16, </volume> <pages> pp. 1-17, </pages> <year> 1982. </year>
Reference-contexts: However, because of the non-differentiability of the merit function, it can occur that a step that approaches the solution point does not satisfy (3.53) and is rejected. (This is sometimes referred to as the Maratos effect; see e.g. <ref> [31, 10] </ref>.) Since this problem is caused by an increase in the norm of the constraints due to their nonlinearity, one way to rectify the situation is to add a second order correction step y when (3.53) fails [19].
Reference: [11] <author> T. F. Coleman and Y. Li. </author> <title> An interior trust region approach for nonlinear minimization subject to bounds, </title> <journal> SIAM Journal on Optimization, </journal> <pages> 6 pp. 418-445, </pages> <year> 1996. </year>
Reference-contexts: Since these algorithms are quite recent, it is difficult to assess at this point whether they will lead to robust general-purpose codes. The use of trust region strategies in interior point methods for linear and nonlinear problems is not new [6, 32]. Coleman and Li <ref> [11, 12] </ref> proposed a primal method for bound constrained nonlinear optimization; see also [26].
Reference: [12] <author> T. F. Coleman and Y. Li. </author> <title> On the convergence of reflective Newton methods for large-scale nonlinear minimization subject to bounds, </title> <journal> Mathematical Programming, </journal> <volume> 67, </volume> <pages> pp. 189-224, </pages> <year> 1994. </year>
Reference-contexts: Since these algorithms are quite recent, it is difficult to assess at this point whether they will lead to robust general-purpose codes. The use of trust region strategies in interior point methods for linear and nonlinear problems is not new [6, 32]. Coleman and Li <ref> [11, 12] </ref> proposed a primal method for bound constrained nonlinear optimization; see also [26].
Reference: [13] <author> T. F. Coleman and A.R. Conn. </author> <title> On the local convergence of a quasi-Newton method for the nonlinear programming problem, </title> <journal> Mathematical Programming, </journal> <volume> 21, </volume> <pages> pp. 755-769, </pages> <year> 1984. </year>
Reference: [14] <author> A.R. Conn, N.I.M. Gould and Ph.L. Toint. </author> <title> A primal-dual algorithm for minimizing a non-convex function subject to bound and linear equality constraints, </title> <type> Report RC 20639, </type> <institution> IBM T.J. Watson Research Center, </institution> <address> Yorktown Heights, New York, </address> <year> 1997. </year>
Reference-contexts: These algorithms can also be viewed as a 1 direct extension of linear programming methods, in that they do not make provisions for the case when the problems is non-convex. Several line search algorithms designed for non-convex problems have recently been proposed <ref> [41, 20, 14, 21, 2, 34] </ref>. An important feature of many of these methods is a strategy for modifying the KKT system used in the computation of the search direction.
Reference: [15] <author> A.R. Conn, N.I.M. Gould and Ph.L. Toint. </author> <title> A note on using alternative second-order models for the subproblems arising in barrier function methods for minimization, </title> <journal> Nu-mer. Math. </journal> <volume> 68, </volume> <pages> pp 17-33, </pages> <year> 1994. </year>
Reference-contexts: Several authors, including Jarre and S. Wright [29], M. Wright [40] and Conn, Gould and Toint <ref> [15] </ref> have given arguments suggesting that the primal search direction will often cause the slack variables to become negative, and can be inefficient.
Reference: [16] <author> A.R. Conn, N.I.M. Gould and Ph.L. Toint. </author> <title> LANCELOT : A Fortran Package for Large-Scale Nonlinear Optimization (Release A), </title> <booktitle> Springer Series in Computational Mathematics, </booktitle> <volume> 17, </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: In Table 2 we present the results for the primal-dual version of our new algorithm, NITRO. For comparison we also solved the problems with LANCELOT <ref> [16] </ref> using second derivatives and all its default settings.
Reference: [17] <author> A.S. El-Bakry, R.A. Tapia, T. Tsuchiya, and Y. Zhang. </author> <title> On the formulation and theory of the Newton interior-point method for nonlinear programming. </title> <journal> J. Optim. Theory. Appl., </journal> <volume> 89, </volume> <pages> pp. 507-5451, </pages> <year> 1996. </year>
Reference-contexts: In the convex case, the step generated by the solution of the primal-dual equations can be shown to be a descent direction for several merit functions, and this allows one to establish fairly satisfactory convergence results. Other research <ref> [17, 42] </ref> has focused on the local behavior of interior point line search methods for nonlinear programming. Conditions have been given that guarantee superlinear and quadratic rates of convergence. <p> Set ; * * ; x x + ; s s + : To obtain a rapidly convergent algorithm, it is necessary to carefully control the rate at which the barrier parameter and the convergence tolerance * are decreased <ref> [17, 42] </ref>. We will, however, not consider this question here and defer its study, in the context of our algorithm, to a future article [7]. <p> 6 4 xx L k 0 A h (x k ) A g (x k ) A T A T 3 7 5 6 6 d x + + 3 7 5 2 6 4 S 1 h (x k ) 3 7 5 It is well known (see e.g. <ref> [17, 43, 8] </ref>) and easy to verify that, if k is defined by (3.1), the system (3.2) is equivalent to a Newton iteration on the KKT conditions of the barrier problem (2.1), which are given by rf (x) + A h (x) h + A g (x) g = 0 (3.3)
Reference: [18] <author> A.V. </author> <title> Fiacco and G.P. McCormick. Nonlinear Programming: Sequential Unconstrained Minimization Techniques. </title> <publisher> Wiley & Sons, </publisher> <year> 1968. </year>
Reference-contexts: By letting converge to zero, the sequence of approximate solutions to (2.1) will normally converge to a minimizer of the original nonlinear program (1.1). As in some interior point methods for linear programming, and in contrast with the barrier methods of Fiacco and McCormick <ref> [18] </ref>, our algorithm does not require feasibility of the iterates with respect to the inequality constraints, but only forces the slack variables to remain positive.
Reference: [19] <author> R. Fletcher. </author> <title> Practical Methods of Optimization, Second Edition, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1990 </year>
Reference-contexts: We follow an SQP approach because it is known to be effective for solving equality constrained 3 problems, even when the problem is ill-conditioned and the constraints are highly nonlinear <ref> [4, 23, 19, 22] </ref>, and choose to use trust region strategies to globalize the SQP iteration because they facilitate the use of second derivative information when the problem is non-convex. <p> The numerical tests described in x4 confirm that the solution by the CG method does not become significantly more difficult as tends to zero. The conjugate gradient iteration computes estimates to the solution of (3.40) by the recursion (see e.g. <ref> [19] </ref>) u + = u + ff~p; (3.44) where the parameter ff is chosen to minimize the quadratic objective q along the direction ~p. <p> rejected. (This is sometimes referred to as the Maratos effect; see e.g. [31, 10].) Since this problem is caused by an increase in the norm of the constraints due to their nonlinearity, one way to rectify the situation is to add a second order correction step y when (3.53) fails <ref> [19] </ref>. This is essentially a Newton-like step on the constraints, and amounts to computing (3.24) at the point x + d. In our implementation the second order correction is applied only when the vertical component is small relative to the horizontal component of the step. 16 Procedure SOC.
Reference: [20] <author> A. Forsgren and P.E. Gill. </author> <title> Primal-dual interior methods for nonconvex nonlinear programming, </title> <type> Technical Report, </type> <institution> University of California at San Diego, </institution> <year> 1996. </year>
Reference-contexts: These algorithms can also be viewed as a 1 direct extension of linear programming methods, in that they do not make provisions for the case when the problems is non-convex. Several line search algorithms designed for non-convex problems have recently been proposed <ref> [41, 20, 14, 21, 2, 34] </ref>. An important feature of many of these methods is a strategy for modifying the KKT system used in the computation of the search direction.
Reference: [21] <author> D.M. Gay, M.L. Overton and M.H. Wright. </author> <title> A primal-dual interior point method for non-convex nonlinearly constrained optimization, </title> <note> to appear. </note>
Reference-contexts: These algorithms can also be viewed as a 1 direct extension of linear programming methods, in that they do not make provisions for the case when the problems is non-convex. Several line search algorithms designed for non-convex problems have recently been proposed <ref> [41, 20, 14, 21, 2, 34] </ref>. An important feature of many of these methods is a strategy for modifying the KKT system used in the computation of the search direction.
Reference: [22] <author> P.E. Gill, W. Murray, and M.A. Saunders. </author> <title> An SQP algorithm for large-scale optimization. </title> <type> Technical Report SOL 96-0, </type> <institution> Department of Operations Research, Stanford University, </institution> <year> 1996. </year>
Reference-contexts: We follow an SQP approach because it is known to be effective for solving equality constrained 3 problems, even when the problem is ill-conditioned and the constraints are highly nonlinear <ref> [4, 23, 19, 22] </ref>, and choose to use trust region strategies to globalize the SQP iteration because they facilitate the use of second derivative information when the problem is non-convex.
Reference: [23] <author> P.E. Gill, W. Murray, and M.H. Wright. </author> <title> Practical Optimization, </title> <publisher> Academic Press, Inc., </publisher> <year> 1981. </year>
Reference-contexts: We follow an SQP approach because it is known to be effective for solving equality constrained 3 problems, even when the problem is ill-conditioned and the constraints are highly nonlinear <ref> [4, 23, 19, 22] </ref>, and choose to use trust region strategies to globalize the SQP iteration because they facilitate the use of second derivative information when the problem is non-convex.
Reference: [24] <author> N.I.M. Gould, M.E. Hribar and J. Nocedal. </author> <title> On the solution of equality constrained quadratic problems arising in optimization, </title> <note> to appear. </note>
Reference-contexts: We use MA27 [25] to factor the coefficient matrix in (3.55) and (3.56). We prefer working with this augmented system, rather than factoring the normal equations matrix ^ A T ^ A, because our numerical experience and the analysis given by Gould, Hribar and Nocedal <ref> [24] </ref> shows that it is more accurate and robust in the context of our algorithm. Our code includes an option for detecting errors in the solution of the linear systems, and applying iterative refinement, when necessary. A detailed description of this procedure is given in [24]. 3.5. <p> by Gould, Hribar and Nocedal <ref> [24] </ref> shows that it is more accurate and robust in the context of our algorithm. Our code includes an option for detecting errors in the solution of the linear systems, and applying iterative refinement, when necessary. A detailed description of this procedure is given in [24]. 3.5. Full Description of the New Interior Point Method Having gone over all the details of our approach we can now present a complete description of the new algorithm for solving the nonlinear programming problem (1.1). <p> More efficient techniques for detecting errors and refining the solution of linear systems are the subject of current investigation <ref> [24] </ref>. Acknowledgments.
Reference: [25] <author> Harwell Subroutine Library, </author> <title> A catalogue of subroutines (release 12), </title> <booktitle> AEA Technology, </booktitle> <address> Harwell, Oxfordshire, England, </address> <year> 1995. </year>
Reference-contexts: We use MA27 <ref> [25] </ref> to factor the coefficient matrix in (3.55) and (3.56).
Reference: [26] <author> J.E. Dennis, M. Heinkenschloss and L.N. Vicente. </author> <title> Trust-region interior-point algorithms for a class of nonlinear programming problems, </title> <type> Technical Report TR94-45, </type> <institution> Dept. of Computational and Applied Mathematics, Rice University, </institution> <year> 1994. </year> <month> 25 </month>
Reference-contexts: The use of trust region strategies in interior point methods for linear and nonlinear problems is not new [6, 32]. Coleman and Li [11, 12] proposed a primal method for bound constrained nonlinear optimization; see also <ref> [26] </ref>.
Reference: [27] <author> M.E. Hribar. </author> <title> Large-scale constrained optimization, </title> <type> Ph.D. Dissertation, </type> <institution> EECS, Depart--ment, Northwestern University, </institution> <year> 1996. </year>
Reference-contexts: An alternative to the dogleg method is to compute the vertical step by means of Stei-haug's implementation of the conjugate gradient method [37]. This is described in detail in <ref> [27] </ref> (see also [30]), and is certainly a viable option. We prefer the dogleg method in this study because it allows us to compute the vertical step using a direct linear algebra solver, thereby avoiding the difficulties that can arise when applying the conjugate gradient method to ill-conditioned systems.
Reference: [28] <author> W. Hock and K. Schittkowski. </author> <title> Test Examples for Nonlinear Programming Codes, </title> <booktitle> Lecture Notes in Economics and Mathematical Systems, </booktitle> <volume> 187, </volume> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Total number of CG iterations divided by the dimension of the linear system, n t, and the type of step taken. 21 problems from the Hock and Schittkowski collection <ref> [28] </ref>, as programmed in CUTE. The results are given in Table 5, and include all the problems that we tested. Since these problems contain a very small number of variables, we do not report CPU time. It is reassuring to observe that NITRO failed on very few of these problems.
Reference: [29] <author> F. Jarre and S.J. Wright. </author> <title> On the role of the objective function in barrier methods. </title> <type> Technical Report MCS-P485-1294, </type> <institution> MCS Division, Argonne National Laboratory, </institution> <year> 1994. </year>
Reference-contexts: Several authors, including Jarre and S. Wright <ref> [29] </ref>, M. Wright [40] and Conn, Gould and Toint [15] have given arguments suggesting that the primal search direction will often cause the slack variables to become negative, and can be inefficient. <p> In fact, analysis of the primal-dual step, as well as computational experience with linear programs, has shown that it overcomes the drawbacks of the primal step: it does not tend to violate the constraints on the slacks, and usually makes excellent progress towards the solution (see e.g. <ref> [29, 40, 43, 38] </ref>). These observations suggest that the primal-dual model in which k is given by (3.11) is likely to perform better than the primal choice (3.1).
Reference: [30] <author> M. Lalee, J. Nocedal, and T. Plantenga. </author> <title> On the implementation of an algorithm for large-scale equality constrained optimization, </title> <note> 1993. To appear in SIAM J. Optimization. </note>
Reference-contexts: The technique used to solve the subproblems has a great impact on the efficiency and robustness of the algorithm; we use an adaptation of the trust region method of Byrd and Omojokun [3, 33] which has proved to be effective for solving large equality constrained problems <ref> [30] </ref>. Our numerical results suggest that the new algorithm holds much promise: it appears to be robust and efficient (in terms of function evaluations), and can make effective use of second derivative information. <p> To do this we apply an adaptation of the equality constrained SQP iteration with trust regions proposed by Byrd [3] and Omojokun [33] and developed by Lalee, Nocedal and Plantenga <ref> [30] </ref> for large-scale equality constrained optimization. <p> This non-differentiable merit function has been successfully used in the SQP algorithm of Byrd and Omojokun <ref> [3, 33, 30] </ref>, and has been analyzed in the context of interior point methods in [8]. We summarize this SQP trust region approach as follows. <p> An alternative to the dogleg method is to compute the vertical step by means of Stei-haug's implementation of the conjugate gradient method [37]. This is described in detail in [27] (see also <ref> [30] </ref>), and is certainly a viable option. We prefer the dogleg method in this study because it allows us to compute the vertical step using a direct linear algebra solver, thereby avoiding the difficulties that can arise when applying the conjugate gradient method to ill-conditioned systems.
Reference: [31] <author> N. Maratos. </author> <title> Exact penalty function algorithms for finite dimensional and control optimization problems, </title> <type> Ph.D. Dissertation, </type> <institution> University of London, </institution> <year> 1978. </year>
Reference-contexts: However, because of the non-differentiability of the merit function, it can occur that a step that approaches the solution point does not satisfy (3.53) and is rejected. (This is sometimes referred to as the Maratos effect; see e.g. <ref> [31, 10] </ref>.) Since this problem is caused by an increase in the norm of the constraints due to their nonlinearity, one way to rectify the situation is to add a second order correction step y when (3.53) fails [19].
Reference: [32] <author> R.D.C. Monteiro and Y. Wang. </author> <title> Trust region affine scaling algorithms for linearly constrained convex and concave programs, </title> <note> (1995), to appear in Mathematical Programming. </note>
Reference-contexts: Since these algorithms are quite recent, it is difficult to assess at this point whether they will lead to robust general-purpose codes. The use of trust region strategies in interior point methods for linear and nonlinear problems is not new <ref> [6, 32] </ref>. Coleman and Li [11, 12] proposed a primal method for bound constrained nonlinear optimization; see also [26].
Reference: [33] <author> E. Omojokun. </author> <title> Trust region algorithms for optimization with nonlinear equality and inequality constraints, </title> <type> Ph.D. Dissertation, </type> <institution> Dept. of Computer Science, University of Colorado, </institution> <year> 1989. </year>
Reference-contexts: The technique used to solve the subproblems has a great impact on the efficiency and robustness of the algorithm; we use an adaptation of the trust region method of Byrd and Omojokun <ref> [3, 33] </ref> which has proved to be effective for solving large equality constrained problems [30]. Our numerical results suggest that the new algorithm holds much promise: it appears to be robust and efficient (in terms of function evaluations), and can make effective use of second derivative information. <p> The challenge is to perform this step efficiently, even when is small, while forcing the slack variables to remain positive. To do this we apply an adaptation of the equality constrained SQP iteration with trust regions proposed by Byrd [3] and Omojokun <ref> [33] </ref> and developed by Lalee, Nocedal and Plantenga [30] for large-scale equality constrained optimization. <p> This non-differentiable merit function has been successfully used in the SQP algorithm of Byrd and Omojokun <ref> [3, 33, 30] </ref>, and has been analyzed in the context of interior point methods in [8]. We summarize this SQP trust region approach as follows. <p> This vector will be determined during the course of solving the quadratic subproblem, as discussed next. 3.2. Solution of the Quadratic Subproblem We will use the decomposition proposed by Byrd and Omojokun <ref> [3, 33] </ref> to find an approximate solution of the subproblem (2.4)-(2.7).
Reference: [34] <author> Z. Parada. </author> <title> A Modified Augmented Lagrangian Merit Function and Q-Superlinear Characterization Results for Primal-Dual Quasi-Newton Interior-Point Methods for Nonlinear Programming, </title> <institution> TR97-12, Department of Computational and Applied Mathematics, Rice University, Houston, Texas, </institution> <year> 1997. </year>
Reference-contexts: These algorithms can also be viewed as a 1 direct extension of linear programming methods, in that they do not make provisions for the case when the problems is non-convex. Several line search algorithms designed for non-convex problems have recently been proposed <ref> [41, 20, 14, 21, 2, 34] </ref>. An important feature of many of these methods is a strategy for modifying the KKT system used in the computation of the search direction.
Reference: [35] <author> T. Plantenga. </author> <title> Large-scale nonlinear constrained optimization using trust regions. </title> <type> PhD thesis, </type> <institution> EECS Department, Northwestern University, </institution> <year> 1994. </year>
Reference-contexts: The use of trust region strategies in interior point methods for linear and nonlinear problems is not new [6, 32]. Coleman and Li [11, 12] proposed a primal method for bound constrained nonlinear optimization; see also [26]. Plantenga <ref> [35] </ref> developed an algorithm for general nonlinear programming that has some features in common with our algorithm; the main differences lie in his treatment of the trust region, in the purely primal nature of this step, and in the fact that his algorithm reverts to an active set method near the <p> To determine the exact fraction of contraction in we use linear or quadratic interpolation; the details are given in <ref> [35] </ref>. We also adjust when the barrier parameter is reduced. In order to achieve fast convergence, it is important that near the solution the trust region be inactive so that the algorithm can take full Newton steps.
Reference: [36] <author> M.J.D. Powell. </author> <title> A hybrid method for nonlinear equations, in Numerical Methods for Nonlinear Algebraic Equations, </title> <editor> P. Rabinowitz, ed., Gordon and Breach, </editor> <address> London, </address> <year> 1970. </year>
Reference-contexts: m (~v) 2 h T (g + s) T ^ A T v x # h x ~v T i " ~v s (3.20) subject to k~vk 2 (3.21) ~v s t: (3.22) We compute an approximate solution of this problem by means of an adaptation of Powell's dogleg method <ref> [36] </ref>, which provides a relatively inexpensive solution that is good enough to allow our algorithm to be robust and rapidly convergent. We first calculate the Cauchy point ~v CP for problem (3.20)-(3.21), which is obtained by minimizing the quadratic (3.20) along the steepest descent direction, starting from v = 0.
Reference: [37] <author> T. Steihaug. </author> <title> The conjugate gradient method and trust regions in large scale optimization. </title> <journal> SIAM J. Numer. Anal, </journal> <volume> 20, </volume> <pages> pp. 626-637, </pages> <year> 1983. </year>
Reference-contexts: For future reference we note that the step ~v lies in the range space of ~ A; see (3.23) and (3.24). An alternative to the dogleg method is to compute the vertical step by means of Stei-haug's implementation of the conjugate gradient method <ref> [37] </ref>. This is described in detail in [27] (see also [30]), and is certainly a viable option. <p> To take into account the trust region and the possibility of indefiniteness in the model, we will terminate the CG iteration using the stopping tests of Steihaug <ref> [37] </ref>. We will also precondition the CG iteration. <p> The reason for this is that it can be shown <ref> [37] </ref> that the norm of the iterates k ~wk 2 increases during the conjugate gradient iteration, so that once an iterate violates (3.37), all subsequent iterates will also violate this constraint. It is therefore sensible to stop iterating when (3.37) is violated.
Reference: [38] <author> R.J. Vanderbei. </author> <title> Linear Programming, </title> <publisher> Kluwer, </publisher> <year> 1996. </year>
Reference-contexts: In fact, analysis of the primal-dual step, as well as computational experience with linear programs, has shown that it overcomes the drawbacks of the primal step: it does not tend to violate the constraints on the slacks, and usually makes excellent progress towards the solution (see e.g. <ref> [29, 40, 43, 38] </ref>). These observations suggest that the primal-dual model in which k is given by (3.11) is likely to perform better than the primal choice (3.1). <p> This scaled trust region will be defined as k (d x ; S 1 The second objective of our trust region is to ensure that the slack variables remain positive. For this purpose we impose the well-known <ref> [43, 38] </ref> fraction to the boundary rule s k + d s (1 t )s k ; (3.17) where t 2 (0; 1); in our tests we use t = 0:995.
Reference: [39] <author> A. Vardi. </author> <title> A trust region algorithm for equality constrained minimization: convergence properties and implementation. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 22, </volume> <pages> pp. 575-591, </pages> <year> 1985. </year>
Reference-contexts: A step d of the algorithm is computed by minimizing the quadratic model, subject to satisfying a linear approximation to the constraints, and subject to a trust region bound on this step; <ref> [9, 39] </ref>. If the step d gives a sufficient reduction in the merit function , then it is accepted; otherwise the step is rejected, the trust region is reduced and a new step is computed. <p> Throughout this section we omit the iteration subscript, and write s k as s, A h (x k ) as A h , etc. Vertical Step It is clear <ref> [39] </ref> that restricting the size of the step d by means of the trust region bounds (3.18) may preclude d from satisfying the linearized constraints (2.5)-(2.6) with r = 0.
Reference: [40] <author> M. Wright. </author> <title> Why a pure primal Newton barrier step may be infeasible. </title> <journal> SIAM J. Optimization, </journal> <volume> 5, </volume> <pages> pp. 1-12, </pages> <year> 1995. </year> <month> 26 </month>
Reference-contexts: Several authors, including Jarre and S. Wright [29], M. Wright <ref> [40] </ref> and Conn, Gould and Toint [15] have given arguments suggesting that the primal search direction will often cause the slack variables to become negative, and can be inefficient. <p> In fact, analysis of the primal-dual step, as well as computational experience with linear programs, has shown that it overcomes the drawbacks of the primal step: it does not tend to violate the constraints on the slacks, and usually makes excellent progress towards the solution (see e.g. <ref> [29, 40, 43, 38] </ref>). These observations suggest that the primal-dual model in which k is given by (3.11) is likely to perform better than the primal choice (3.1).
Reference: [41] <author> H. Yamashita. </author> <title> A globally convergent primal-dual interior point method for constrained optimization. </title> <type> Technical Report, </type> <institution> Mathematical Systems Institute Inc., </institution> <address> Tokyo, Japan. </address> <note> (Revised in March 1994) </note>
Reference-contexts: These algorithms can also be viewed as a 1 direct extension of linear programming methods, in that they do not make provisions for the case when the problems is non-convex. Several line search algorithms designed for non-convex problems have recently been proposed <ref> [41, 20, 14, 21, 2, 34] </ref>. An important feature of many of these methods is a strategy for modifying the KKT system used in the computation of the search direction. <p> The algorithm proposed in this paper makes use of successive quadratic programming techniques, and in this sense is related to the line search algorithm of Yamashita <ref> [41] </ref>. But the way in which our algorithm combines trust region strategies, interior point approaches and successive quadratic programming techniques leads to an iteration that is different from those proposed in the literature. 2.
Reference: [42] <author> H. Yamashita and H. Yabe, </author> <title> Superlinear and quadratic convergence of some primal-dual interior point methods for constrained optimization, </title> <journal> Mathematical Programming, </journal> <volume> 75, </volume> <pages> pp. 377-397, </pages> <year> 1996. </year>
Reference-contexts: In the convex case, the step generated by the solution of the primal-dual equations can be shown to be a descent direction for several merit functions, and this allows one to establish fairly satisfactory convergence results. Other research <ref> [17, 42] </ref> has focused on the local behavior of interior point line search methods for nonlinear programming. Conditions have been given that guarantee superlinear and quadratic rates of convergence. <p> Set ; * * ; x x + ; s s + : To obtain a rapidly convergent algorithm, it is necessary to carefully control the rate at which the barrier parameter and the convergence tolerance * are decreased <ref> [17, 42] </ref>. We will, however, not consider this question here and defer its study, in the context of our algorithm, to a future article [7].
Reference: [43] <author> S.J. Wright. </author> <title> Primal-Dual Interior Point Methods, </title> <publisher> SIAM, </publisher> <year> 1997. </year> <month> 27 </month>
Reference-contexts: 6 4 xx L k 0 A h (x k ) A g (x k ) A T A T 3 7 5 6 6 d x + + 3 7 5 2 6 4 S 1 h (x k ) 3 7 5 It is well known (see e.g. <ref> [17, 43, 8] </ref>) and easy to verify that, if k is defined by (3.1), the system (3.2) is equivalent to a Newton iteration on the KKT conditions of the barrier problem (2.1), which are given by rf (x) + A h (x) h + A g (x) g = 0 (3.3) <p> In fact, analysis of the primal-dual step, as well as computational experience with linear programs, has shown that it overcomes the drawbacks of the primal step: it does not tend to violate the constraints on the slacks, and usually makes excellent progress towards the solution (see e.g. <ref> [29, 40, 43, 38] </ref>). These observations suggest that the primal-dual model in which k is given by (3.11) is likely to perform better than the primal choice (3.1). <p> In primal-dual interior point methods for linear programming, the initial Lagrange multiplier estimate is chosen to be positive, and in subsequent iterations a backtracking line search ensures that all new multiplier estimates remain safely positive (see e.g. <ref> [43] </ref>). 7 Here we follow a different approach, not enforcing the positivity of the multipliers g , but ensuring that the quadratic model remains convex in the slack variables. <p> This scaled trust region will be defined as k (d x ; S 1 The second objective of our trust region is to ensure that the slack variables remain positive. For this purpose we impose the well-known <ref> [43, 38] </ref> fraction to the boundary rule s k + d s (1 t )s k ; (3.17) where t 2 (0; 1); in our tests we use t = 0:995.
References-found: 43

