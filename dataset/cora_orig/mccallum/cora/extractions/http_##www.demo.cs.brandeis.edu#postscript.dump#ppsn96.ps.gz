URL: http://www.demo.cs.brandeis.edu/postscript.dump/ppsn96.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~darwen/publications.html
Root-URL: http://www.cs.brandeis.edu
Title: Every Niching Method has its Niche: Fitness Sharing and Implicit Sharing Compared  
Author: Paul Darwen and Xin Yao 
Address: Canberra ACT 2600 AUSTRALIA  
Affiliation: School of Computer Science, University College UNSW Australian Defence Force Academy  
Abstract: Various extensions to the Genetic Algorithm (GA) attempt to find all or most optima in a search space containing several optima. Many of these emulate natural speciation. For co-evolutionary learning to succeed in a range of management and control problems, such as learning game strategies, such methods must find all or most optima. However, suitable comparison studies are rare. We compare two similar GA specia-tion methods, fitness sharing and implicit sharing. Using a realistic letter classification problem, we find they have advantages under different circumstances. Implicit sharing covers optima more comprehensively, when the population is large enough for a species to form at each optimum. With a population not large enough to do this, fitness sharing can find the optima with larger basins of attraction, and ignore the peaks with narrow bases, while implicit sharing is more easily distracted. This indicates that for a speciated GA trying to find as many near-global optima as possible, implicit sharing works well only if the population is large enough. This requires prior knowledge of how many peaks exist.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Axelrod. </author> <title> The evolution of strategies in the iterated prisoner's dilemma. </title> <booktitle> In Genetic Algorithms and Simulated Annealing, </booktitle> <pages> pages 32-41. </pages> <publisher> Morgan Kauffman, </publisher> <year> 1987. </year>
Reference-contexts: 1 Motivation 1.1 Speciation in Co-evolutionary Learning In a co-evolutionary GA, individuals are evaluated by how they perform against individuals in the same GA population, or perhaps another GA running in parallel. This is a promising way to learn game strategies <ref> [1] </ref> [3] [17] [21]. Without speciation, a GA will converge to only one high-fitness solution, due to genetic drift. So a co-evolutionary GA will converge and overspecialise to only one strategy for the game being learned.
Reference: 2. <author> P. Darwen and X. Yao. </author> <title> A dilemma for fitness sharing with a scaling function. </title> <booktitle> In 1995 IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 166-171, </pages> <year> 1995. </year>
Reference-contexts: Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling [11], although scaling is not perfect <ref> [2] </ref>. So new GA speciation methods proliferate [15] [16] [18] without proper comparison of earlier methods. This paper helps fill that gap. We find that implicit sharing works better when the population is large enough to form a species at each peak. <p> Secondly, to set s , you need to know a priori how far apart optima are, and their (unshared) fitness. This important flaw is often overlooked by assuming there is perfect discrimination between peaks [13, pages 106, 158]. Also, scaling can cause problems <ref> [2] </ref>. To overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius [20] [22]. 2.2 Implicit Fitness Sharing Implicit sharing [8] [20] modifies the fitness function according to Table 1. Individuals bid for the payoff of discrete objects. <p> In a previous study on a massively multimodal space with many suboptimal peaks, fitness sharing worked well [11] (although it relied on scaling, which can cause problems for fitness sharing <ref> [2] </ref>). We conjecture that implicit sharing would not work as well in such a search space.
Reference: 3. <author> P. Darwen and X. Yao. </author> <title> On evolving robust strategies for iterated prisoner's dilemma. </title> <booktitle> In Progress in Evolutionary Computation, </booktitle> <pages> pages 276-292. </pages> <publisher> Springer, </publisher> <year> 1995. </year>
Reference-contexts: 1 Motivation 1.1 Speciation in Co-evolutionary Learning In a co-evolutionary GA, individuals are evaluated by how they perform against individuals in the same GA population, or perhaps another GA running in parallel. This is a promising way to learn game strategies [1] <ref> [3] </ref> [17] [21]. Without speciation, a GA will converge to only one high-fitness solution, due to genetic drift. So a co-evolutionary GA will converge and overspecialise to only one strategy for the game being learned. This generalises poorly, and is navely vulnerable to novel strategies not in the converged population [3]. <p> <ref> [3] </ref> [17] [21]. Without speciation, a GA will converge to only one high-fitness solution, due to genetic drift. So a co-evolutionary GA will converge and overspecialise to only one strategy for the game being learned. This generalises poorly, and is navely vulnerable to novel strategies not in the converged population [3]. To overcome this problem, speciation can greatly delay genetic drift [12], and prevent the convergence and overspecialisation that can otherwise happen in coevolutionary learning [3]. Speciation with co-evolution can also find a repertoire of high-quality strategies for a game, giving improved generalisation [4]. <p> This generalises poorly, and is navely vulnerable to novel strategies not in the converged population <ref> [3] </ref>. To overcome this problem, speciation can greatly delay genetic drift [12], and prevent the convergence and overspecialisation that can otherwise happen in coevolutionary learning [3]. Speciation with co-evolution can also find a repertoire of high-quality strategies for a game, giving improved generalisation [4]. However, this approach relies heavily on the speciated GA to find all (or most) good strategies | as speciation finds more high-quality strategies, generalisation ability improves [4, page 92].
Reference: 4. <author> P. Darwen and X. Yao. </author> <title> Automatic modularization with speciation. </title> <booktitle> In 1996 IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 88-93, </pages> <year> 1996. </year>
Reference-contexts: To overcome this problem, speciation can greatly delay genetic drift [12], and prevent the convergence and overspecialisation that can otherwise happen in coevolutionary learning [3]. Speciation with co-evolution can also find a repertoire of high-quality strategies for a game, giving improved generalisation <ref> [4] </ref>. However, this approach relies heavily on the speciated GA to find all (or most) good strategies | as speciation finds more high-quality strategies, generalisation ability improves [4, page 92]. <p> Speciation with co-evolution can also find a repertoire of high-quality strategies for a game, giving improved generalisation [4]. However, this approach relies heavily on the speciated GA to find all (or most) good strategies | as speciation finds more high-quality strategies, generalisation ability improves <ref> [4, page 92] </ref>. <p> Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20]. Another use is in learning a game: a strategy receives payoff when it has the best score against a test strategy <ref> [4] </ref> [17]. For each data point i to be matched, do the following C times: 1. From the GA population, select a sample of individuals. 2. Find the individual in that sample which achieves the highest match score against the single data point i. 3. <p> Consider our original problem of using co-evolution to learn a game. We want to obtain a full repertoire of strategies, to generalise well against any expert opponent <ref> [4] </ref>. With enough population, implicit sharing would be best. Attempts to learn game strategies from a co-evolutionary GA with implicit sharing had some success [4] [17]. <p> We want to obtain a full repertoire of strategies, to generalise well against any expert opponent <ref> [4] </ref>. With enough population, implicit sharing would be best. Attempts to learn game strategies from a co-evolutionary GA with implicit sharing had some success [4] [17]. However, if the game has more strategies than we expected or our population is too small, then implicit sharing could get side-tracked and miss strategies it should have found, and we will generalise poorly.
Reference: 5. <author> K. Deb and D. E. Goldberg. </author> <title> An investigation of niche and species formation in genetic function optimization. </title> <booktitle> In ICGA-3, </booktitle> <pages> pages 42-50, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: So knowing what GA speciation method covers more peaks is important for co-evolutionary learning, not only for games but for other management and control tasks. 1.2 This paper We compare two GA speciation methods, fitness sharing <ref> [5] </ref> and implicit sharing [20], in their ability to find as many peaks as possible. More comparative results are needed. Some studies evaluate GA speciation only on simple functions [18] [22], even though parallel hill-climbing is usually better on these [13, page 202]. <p> In Section 3, we describe the experimental setup, whose results are shown in Section 4, and discussed in Section 5. Section 6 concludes the paper. 2 Speciation Methods Based on Sharing Many extensions to the GA let it locate multiple optima [13, pages 64-90]. Until recently, fitness sharing <ref> [5] </ref> was the only success [13, page 84], and is widely used. We study fitness sharing and its extension, implicit sharing [20]. 2.1 Fitness Sharing Fitness sharing modifies a search landscape by reducing payoff in densely-populated regions. This encourages search in unexplored regions, and causes subpopulations to form. <p> Population size was 50 for all runs. Other parameters were set as follows: 1. Sharing radius s was 5, and the metric is Euclidean. 2. We used assortative crossover, so only similar individuals mate. This can improve a speciated GA <ref> [5, page 49] </ref>. Also, incest prevention [6] was used. 3. Mutation rate was 0.01, so a 64-bit genotype has a 53% chance of escaping unmutated. This is high, but assortative crossover reduces disruption. 4. The crossover rate was 1, and elitism was used. 5. Linear ranked selection was used.
Reference: 6. <editor> L. J. Eshelman and J. D. Schaffer. </editor> <title> Preventing premature confergence in genetic algorithms by preventing incest. </title> <booktitle> In ICGA-4, </booktitle> <pages> pages 115-122, </pages> <year> 1991. </year>
Reference-contexts: Population size was 50 for all runs. Other parameters were set as follows: 1. Sharing radius s was 5, and the metric is Euclidean. 2. We used assortative crossover, so only similar individuals mate. This can improve a speciated GA [5, page 49]. Also, incest prevention <ref> [6] </ref> was used. 3. Mutation rate was 0.01, so a 64-bit genotype has a 53% chance of escaping unmutated. This is high, but assortative crossover reduces disruption. 4. The crossover rate was 1, and elitism was used. 5. Linear ranked selection was used.
Reference: 7. <author> T. C. Fogarty. </author> <title> First nearest neighbor classification problem on Frey and Slate's letter recognition problem. </title> <journal> Machine Learning, </journal> <volume> 9(4) </volume> <pages> 387-388, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: We want the speciated GA to form a species at each cluster of same-letter data points. If the data contains a group of "A" points, close together with few non-A points intermingled, then want a species to "cover" this cluster, as in on this data <ref> [7] </ref>. The test phase classifies points by what species covers them. Consider a subset of the data, by randomly taking only 2 letters out of 26. Table 2 shows how scattered this data is. <p> As the problem grows larger, the population needs to increase. Note that the number of clusters is different from the number of classes of data points. Many methods can "cluster" data: a Holland-style classifier [9] gave worse accuracy (82.7%) than a simple nearest neighbour classifier (95.4%) <ref> [7] </ref> or several other non-GA classifiers [14, pages 140-142]. Again, we are less interested in classification accuracy as in comparing two GA speciation methods. For this reason, we will not follow the usual approach of separating learning and testing data.
Reference: 8. <author> S. Forrest, B. Javornik, R. E. Smith, and A. S. Perelson. </author> <title> Using genetic algorithms to explore pattern recognition in the immune system. </title> <journal> Evolutionary Computation, </journal> <volume> 1(3) </volume> <pages> 191-211, </pages> <year> 1993. </year>
Reference-contexts: This important flaw is often overlooked by assuming there is perfect discrimination between peaks [13, pages 106, 158]. Also, scaling can cause problems [2]. To overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius [20] [22]. 2.2 Implicit Fitness Sharing Implicit sharing <ref> [8] </ref> [20] modifies the fitness function according to Table 1. Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20]. <p> To overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius [20] [22]. 2.2 Implicit Fitness Sharing Implicit sharing <ref> [8] </ref> [20] modifies the fitness function according to Table 1. Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20]. Another use is in learning a game: a strategy receives payoff when it has the best score against a test strategy [4] [17]. For each data point i to be matched, do the following C times: 1. From the GA population, select a sample of individuals. 2.
Reference: 9. <author> P. Frey and D. </author> <title> Slate. Letter recognition using Holland-style adaptive classifiers. </title> <journal> Machine Learning, </journal> <volume> 6(2) </volume> <pages> 161-182, </pages> <month> Mar. </month> <year> 1991. </year>
Reference-contexts: Surprisingly, they share the same theoretical basis [20]. The sample size resembles the sharing radius s : both control species size, and regulate the number of individuals who obtain payoff by specialising to the same part of the search space. 3 Experimental Setup 3.1 The Data Frey and Slate's <ref> [9] </ref> letter recognition data has about 770 examples each of 26 capital letters. Each consists of a class (out of 26 letters), plus 16 integer values between 0 and 15 inclusive. What these measure is not important here. <p> This requires more species (and thus a larger population) to successfully cover clusters. As the problem grows larger, the population needs to increase. Note that the number of clusters is different from the number of classes of data points. Many methods can "cluster" data: a Holland-style classifier <ref> [9] </ref> gave worse accuracy (82.7%) than a simple nearest neighbour classifier (95.4%) [7] or several other non-GA classifiers [14, pages 140-142]. Again, we are less interested in classification accuracy as in comparing two GA speciation methods.
Reference: 10. <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: This encourages search in unexplored regions, and causes subpopulations to form. Consider an individual i with fitness f i . Its niche count m i measures the number of other individuals with whom i shares fitness <ref> [10, page 191] </ref>. Shared fitness is f s i = f i =m i .
Reference: 11. <author> D. E. Goldberg, K. Deb, and J. Horn. </author> <title> Massive multimodality, deception, </title> <booktitle> and genetic algorithms. In PPSN2, </booktitle> <pages> pages 37-46. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Some studies evaluate GA speciation only on simple functions [18] [22], even though parallel hill-climbing is usually better on these [13, page 202]. Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling <ref> [11] </ref>, although scaling is not perfect [2]. So new GA speciation methods proliferate [15] [16] [18] without proper comparison of earlier methods. This paper helps fill that gap. We find that implicit sharing works better when the population is large enough to form a species at each peak. <p> Parameter ff changes the sharing function's shape: ff = 1 gives a linear sharing function. More important is s , the sharing radius or cutoff distance. sh (d ij ) = 1 d ij ff 0 for d ij s Fitness sharing has performed well in difficult search problems <ref> [11] </ref>, but has flaws. Firstly, s is fixed, so all optima in the search space must be equidistant or nearly so [20]. Secondly, to set s , you need to know a priori how far apart optima are, and their (unshared) fitness. <p> Fitness sharing is not so easily sidetracked when there are too many peaks for the population size, and gives a higher classification rate for 6 and 7 letters in Table 6. In a previous study on a massively multimodal space with many suboptimal peaks, fitness sharing worked well <ref> [11] </ref> (although it relied on scaling, which can cause problems for fitness sharing [2]). We conjecture that implicit sharing would not work as well in such a search space.
Reference: 12. <author> S. W. Mahfoud. </author> <title> Genetic drift in sharing methods. </title> <booktitle> In First IEEE Conference on Evolutionary Computation, </booktitle> <volume> volume 1, </volume> <pages> pages 67-72, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: So a co-evolutionary GA will converge and overspecialise to only one strategy for the game being learned. This generalises poorly, and is navely vulnerable to novel strategies not in the converged population [3]. To overcome this problem, speciation can greatly delay genetic drift <ref> [12] </ref>, and prevent the convergence and overspecialisation that can otherwise happen in coevolutionary learning [3]. Speciation with co-evolution can also find a repertoire of high-quality strategies for a game, giving improved generalisation [4].
Reference: 13. <author> S. W. Mahfoud. </author> <title> Niching Methods for Genetic Algorithms. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1995. </year>
Reference-contexts: More comparative results are needed. Some studies evaluate GA speciation only on simple functions [18] [22], even though parallel hill-climbing is usually better on these <ref> [13, page 202] </ref>. Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling [11], although scaling is not perfect [2]. So new GA speciation methods proliferate [15] [16] [18] without proper comparison of earlier methods. <p> More comparative results are needed. Some studies evaluate GA speciation only on simple functions [18] [22], even though parallel hill-climbing is usually better on these [13, page 202]. Another comparison forbids fitness sharing from using a scaling function <ref> [13, pages 206-207] </ref>: this may be unfair, as it worked well with scaling [11], although scaling is not perfect [2]. So new GA speciation methods proliferate [15] [16] [18] without proper comparison of earlier methods. This paper helps fill that gap. <p> In Section 3, we describe the experimental setup, whose results are shown in Section 4, and discussed in Section 5. Section 6 concludes the paper. 2 Speciation Methods Based on Sharing Many extensions to the GA let it locate multiple optima <ref> [13, pages 64-90] </ref>. Until recently, fitness sharing [5] was the only success [13, page 84], and is widely used. We study fitness sharing and its extension, implicit sharing [20]. 2.1 Fitness Sharing Fitness sharing modifies a search landscape by reducing payoff in densely-populated regions. <p> Section 6 concludes the paper. 2 Speciation Methods Based on Sharing Many extensions to the GA let it locate multiple optima [13, pages 64-90]. Until recently, fitness sharing [5] was the only success <ref> [13, page 84] </ref>, and is widely used. We study fitness sharing and its extension, implicit sharing [20]. 2.1 Fitness Sharing Fitness sharing modifies a search landscape by reducing payoff in densely-populated regions. This encourages search in unexplored regions, and causes subpopulations to form. <p> Secondly, to set s , you need to know a priori how far apart optima are, and their (unshared) fitness. This important flaw is often overlooked by assuming there is perfect discrimination between peaks <ref> [13, pages 106, 158] </ref>. Also, scaling can cause problems [2]. To overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius [20] [22]. 2.2 Implicit Fitness Sharing Implicit sharing [8] [20] modifies the fitness function according to Table 1.
Reference: 14. <author> D. Michie, D. J. Spiegelhalter, and C. C. Taylor. </author> <title> Machine Learning, Neural and Statistical Classification. </title> <publisher> Ellis Horwood, </publisher> <year> 1994. </year>
Reference-contexts: Note that the number of clusters is different from the number of classes of data points. Many methods can "cluster" data: a Holland-style classifier [9] gave worse accuracy (82.7%) than a simple nearest neighbour classifier (95.4%) [7] or several other non-GA classifiers <ref> [14, pages 140-142] </ref>. Again, we are less interested in classification accuracy as in comparing two GA speciation methods. For this reason, we will not follow the usual approach of separating learning and testing data. We will learn on the same data that we test with.
Reference: 15. <author> A. Petrowski. </author> <title> A clearing procedure as a niching method for genetic algorithms. </title> <booktitle> In 1996 IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 798-803, </pages> <year> 1996. </year>
Reference-contexts: Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling [11], although scaling is not perfect [2]. So new GA speciation methods proliferate <ref> [15] </ref> [16] [18] without proper comparison of earlier methods. This paper helps fill that gap. We find that implicit sharing works better when the population is large enough to form a species at each peak.
Reference: 16. <author> S. Ronald. </author> <title> Finding multiple solutions with an evolutionary algorithm. </title> <booktitle> In 1995 IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 641-646, </pages> <year> 1995. </year>
Reference-contexts: Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling [11], although scaling is not perfect [2]. So new GA speciation methods proliferate [15] <ref> [16] </ref> [18] without proper comparison of earlier methods. This paper helps fill that gap. We find that implicit sharing works better when the population is large enough to form a species at each peak. With too many peaks, fitness sharing is less distracted by peaks with small basins of attraction.
Reference: 17. <author> C. D. Rosin and R. K. Belew. </author> <title> Methods for competitive co-evolution: Finding opponents worth beating. </title> <booktitle> In ICGA-6, </booktitle> <pages> pages 373-380, </pages> <year> 1995. </year>
Reference-contexts: 1 Motivation 1.1 Speciation in Co-evolutionary Learning In a co-evolutionary GA, individuals are evaluated by how they perform against individuals in the same GA population, or perhaps another GA running in parallel. This is a promising way to learn game strategies [1] [3] <ref> [17] </ref> [21]. Without speciation, a GA will converge to only one high-fitness solution, due to genetic drift. So a co-evolutionary GA will converge and overspecialise to only one strategy for the game being learned. This generalises poorly, and is navely vulnerable to novel strategies not in the converged population [3]. <p> Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20]. Another use is in learning a game: a strategy receives payoff when it has the best score against a test strategy [4] <ref> [17] </ref>. For each data point i to be matched, do the following C times: 1. From the GA population, select a sample of individuals. 2. Find the individual in that sample which achieves the highest match score against the single data point i. 3. <p> We want to obtain a full repertoire of strategies, to generalise well against any expert opponent [4]. With enough population, implicit sharing would be best. Attempts to learn game strategies from a co-evolutionary GA with implicit sharing had some success [4] <ref> [17] </ref>. However, if the game has more strategies than we expected or our population is too small, then implicit sharing could get side-tracked and miss strategies it should have found, and we will generalise poorly.
Reference: 18. <author> C. Ryan. </author> <title> Racial harmony and function optimization in genetic algorithms. </title> <booktitle> In 1995 Evolutionary Programming Conference, </booktitle> <pages> pages 296-307, </pages> <year> 1995. </year>
Reference-contexts: More comparative results are needed. Some studies evaluate GA speciation only on simple functions <ref> [18] </ref> [22], even though parallel hill-climbing is usually better on these [13, page 202]. Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling [11], although scaling is not perfect [2]. <p> Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling [11], although scaling is not perfect [2]. So new GA speciation methods proliferate [15] [16] <ref> [18] </ref> without proper comparison of earlier methods. This paper helps fill that gap. We find that implicit sharing works better when the population is large enough to form a species at each peak. With too many peaks, fitness sharing is less distracted by peaks with small basins of attraction.
Reference: 19. <author> S. L. Salzberg. </author> <title> On comparing classifiers: A critique of current research and methods. </title> <type> Technical Report CS-1995-06, </type> <institution> John Hopkins University, </institution> <year> 1995. </year>
Reference-contexts: The best cutoff values are asterisked. Using their best cutoff values, Table 6 shows which method classified better. Are the differences in Table 6 significant? We use a binomial test (as each set of letters are drawn randomly from the alphabet) <ref> [19] </ref>, requiring the number of times one method is better, and ignoring ties. We try two different definitions of a tie in Table 6. The first: a method is better even if it classifies only one extra letter correctly.
Reference: 20. <author> R. E. Smith, S. Forrest, and A. S. Perelson. </author> <title> Searching for diverse, cooperative populations with genetic algorithms. </title> <journal> Evolutionary Computation, </journal> <volume> 1 </volume> <pages> 127-149, </pages> <year> 1992. </year>
Reference-contexts: So knowing what GA speciation method covers more peaks is important for co-evolutionary learning, not only for games but for other management and control tasks. 1.2 This paper We compare two GA speciation methods, fitness sharing [5] and implicit sharing <ref> [20] </ref>, in their ability to find as many peaks as possible. More comparative results are needed. Some studies evaluate GA speciation only on simple functions [18] [22], even though parallel hill-climbing is usually better on these [13, page 202]. <p> Section 6 concludes the paper. 2 Speciation Methods Based on Sharing Many extensions to the GA let it locate multiple optima [13, pages 64-90]. Until recently, fitness sharing [5] was the only success [13, page 84], and is widely used. We study fitness sharing and its extension, implicit sharing <ref> [20] </ref>. 2.1 Fitness Sharing Fitness sharing modifies a search landscape by reducing payoff in densely-populated regions. This encourages search in unexplored regions, and causes subpopulations to form. Consider an individual i with fitness f i . <p> Firstly, s is fixed, so all optima in the search space must be equidistant or nearly so <ref> [20] </ref>. Secondly, to set s , you need to know a priori how far apart optima are, and their (unshared) fitness. This important flaw is often overlooked by assuming there is perfect discrimination between peaks [13, pages 106, 158]. Also, scaling can cause problems [2]. <p> This important flaw is often overlooked by assuming there is perfect discrimination between peaks [13, pages 106, 158]. Also, scaling can cause problems [2]. To overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius <ref> [20] </ref> [22]. 2.2 Implicit Fitness Sharing Implicit sharing [8] [20] modifies the fitness function according to Table 1. Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20]. <p> This important flaw is often overlooked by assuming there is perfect discrimination between peaks [13, pages 106, 158]. Also, scaling can cause problems [2]. To overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius <ref> [20] </ref> [22]. 2.2 Implicit Fitness Sharing Implicit sharing [8] [20] modifies the fitness function according to Table 1. Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20]. <p> overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius <ref> [20] </ref> [22]. 2.2 Implicit Fitness Sharing Implicit sharing [8] [20] modifies the fitness function according to Table 1. Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20]. Another use is in learning a game: a strategy receives payoff when it has the best score against a test strategy [4] [17]. For each data point i to be matched, do the following C times: 1. From the GA population, select a sample of individuals. 2. <p> Find the individual in that sample which achieves the highest match score against the single data point i. 3. The best in the sample receives payoff. In the case of a tie, payoff is shared equally among the tie-breakers. Table 1. Payoff function for implicit sharing <ref> [20] </ref>. At first glance, Table 1 looks completely different to fitness sharing. Surprisingly, they share the same theoretical basis [20]. <p> The best in the sample receives payoff. In the case of a tie, payoff is shared equally among the tie-breakers. Table 1. Payoff function for implicit sharing <ref> [20] </ref>. At first glance, Table 1 looks completely different to fitness sharing. Surprisingly, they share the same theoretical basis [20]. <p> Fig. 2. Consider two similar individuals near a peak. Recall Table 1: under implicit sharing, the probability that w individuals from this subset (of two individuals) are in a sample of size taken without replacement, from a population of size N , is given by <ref> [20] </ref>: p (w; ; N; 2) = w C N2 C N (6) In these experiments, N = 50 and = 38.
Reference: 21. <author> R. E. Smith and B. Gray. </author> <title> Co-adaptive genetic algorithms: An example in Othello strategy. </title> <booktitle> In 1994 Florida AI Research Symposium, </booktitle> <pages> pages 259-264, </pages> <year> 1994. </year>
Reference-contexts: 1 Motivation 1.1 Speciation in Co-evolutionary Learning In a co-evolutionary GA, individuals are evaluated by how they perform against individuals in the same GA population, or perhaps another GA running in parallel. This is a promising way to learn game strategies [1] [3] [17] <ref> [21] </ref>. Without speciation, a GA will converge to only one high-fitness solution, due to genetic drift. So a co-evolutionary GA will converge and overspecialise to only one strategy for the game being learned. This generalises poorly, and is navely vulnerable to novel strategies not in the converged population [3].
Reference: 22. <author> W. M. Spears. </author> <title> Simple subpopulation schemes. </title> <booktitle> In 1994 Evolutionary Programming Conference, </booktitle> <pages> pages 296-307. </pages> <publisher> World Scientific, </publisher> <year> 1994. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: More comparative results are needed. Some studies evaluate GA speciation only on simple functions [18] <ref> [22] </ref>, even though parallel hill-climbing is usually better on these [13, page 202]. Another comparison forbids fitness sharing from using a scaling function [13, pages 206-207]: this may be unfair, as it worked well with scaling [11], although scaling is not perfect [2]. <p> This important flaw is often overlooked by assuming there is perfect discrimination between peaks [13, pages 106, 158]. Also, scaling can cause problems [2]. To overcome these flaws, some fitness sharing extensions do not use a fixed sharing radius [20] <ref> [22] </ref>. 2.2 Implicit Fitness Sharing Implicit sharing [8] [20] modifies the fitness function according to Table 1. Individuals bid for the payoff of discrete objects. Originally, those were antigens in an immune system simulation [8] [20].
References-found: 22

