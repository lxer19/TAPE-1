URL: http://www.ee.ogi.edu/~ericwan/PUBS/wan_nnsp97.ps
Refering-URL: 
Root-URL: 
Title: NEURAL DUAL EXTENDED KALMAN FILTERING: APPLICATIONS IN SPEECH ENHANCEMENT AND MONAURAL BLIND SIGNAL SEPARATION  
Author: Eric A. Wan and Alex T. Nelson 
Address: P.O. Box 91000 Portland, OR 97291  
Affiliation: Department of Electrical Engineering, Oregon Graduate Institute,  
Abstract: The removal of noise from speech signals has applications ranging from speech enhancement for cellular communications, to front ends for speech recognition systems. A nonlinear time-domain method called dual extended Kalman filtering (DEKF) is presented for removing nonstationary and colored noise from speech. We further generalize the algorithm to perform the blind separation of two speech signals from a single recording.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Avendano, H. Hermansky, M. Vis, A. Bayya. </author> <title> Adaptive speech enhancement based on frequency-specific SNR estimation. </title> <booktitle> Proc. IVTTA 1996, </booktitle> <address> Basking Ridge, NJ, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Nonstationary white noise was generated artificially and added to the speech to create the noisy signal y. with an SNR improvement of 8.50 dB. In comparison, available state-of-the-art techniques of spectral subtraction [3] and adaptive RASTA processing <ref> [1] </ref> achieve SNR improvements of only .65 and 1.26 dB, respectively. Colored Noise For most real-world speech applications, we cannot assume the noise is white. For colored noise, the state-space equations 3 and 4 need to be adjusted before Kalman filtering techniques can be employed.
Reference: [2] <author> A. Bell, T. Sejnowski. </author> <title> An information-maximization approach to blind separation and blind deconvolution. </title> <journal> Neural Computation, </journal> <volume> 7, </volume> <pages> 1129-1159, </pages> <year> 1995. </year>
Reference-contexts: We simply treat the noise itself as an additional signal that must be estimated. This is a form of blind signal separation, in which, for example, the signals result from the mixing of speakers. The problem differs from recent methods in the literature <ref> [2] </ref> for blind signal separation in which M signals must be separated from M observations by learning a fixed inverse weighting matrix. Instead, we are interested in separating two or more signals from a single (monaural) observation.
Reference: [3] <author> S.F. Boll. </author> <title> Suppression of acoustic noise in speech using spectral subtraction. </title> <journal> IEEE ASSP-27, </journal> <pages> pp. 113-120, </pages> <month> April </month> <year> 1979. </year>
Reference-contexts: Nonstationary white noise was generated artificially and added to the speech to create the noisy signal y. with an SNR improvement of 8.50 dB. In comparison, available state-of-the-art techniques of spectral subtraction <ref> [3] </ref> and adaptive RASTA processing [1] achieve SNR improvements of only .65 and 1.26 dB, respectively. Colored Noise For most real-world speech applications, we cannot assume the noise is white. For colored noise, the state-space equations 3 and 4 need to be adjusted before Kalman filtering techniques can be employed.
Reference: [4] <author> J. Connor, R. Martin, L. </author> <title> Atlas. Recurrent neural networks and robust time series prediction. </title> <journal> IEEE Tr. on Neural Networks. </journal> <month> March </month> <year> 1994. </year>
Reference: [5] <author> P.N. Denbigh, J. Zhao. </author> <title> Pitch extraction and separation of overlapping speech. Speech Communication, </title> <address> vol.11, pp.119-25. </address> <year> 1992. </year>
Reference-contexts: Instead, we are interested in separating two or more signals from a single (monaural) observation. Previous work on monaural signal separation has primarily been based on harmonic selection and pitch tracking in the frequency domain <ref> [5] </ref>. In contrast, we estimate each signal by learning a set of short-term models which best separate the signals. Extension of the DEKF framework is straightforward.
Reference: [6] <author> Y. Ephraim. </author> <title> Statistical model-based speech enhancement systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 80, </volume> <month> October </month> <year> 1992. </year>
Reference-contexts: In the speech literature, the method is most closely related to Lim and Oppenheim's approach to fitting LPC models to degraded speech [10]. It also relates to Ephraim's model-based approach <ref> [6] </ref>, but uses nonlinear estimation to fit the given data instead of using a fixed number of prespecified linear models. Nonstationary White Noise Experiment The result of applying the DEKF to a speech signal corrupted with simulated nonstationary bursting noise is shown in Figure 2.
Reference: [7] <author> G. Goodwin, </author> <title> K.S. Sin. Adaptive Filtering Prediction and Control. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ. </address> <year> 1994. </year>
Reference-contexts: For finite data sets, the algorithm is run iteratively over the data until the weights converge. This approach to dual estimation is related to work done by Nelson [12] in the linear case, and to Matthews' neural approach [11] to the recursive prediction error algorithm <ref> [7] </ref> 2 . In the speech literature, the method is most closely related to Lim and Oppenheim's approach to fitting LPC models to degraded speech [10]. <p> We also ran the experiment when 2 n and v were estimated using only the noisy signal. This also produced impressive results, 2 An alternative approach is to concatenate both w and x into a joint state vector, and apply the EKF to the resulting nonlinear state equations (see <ref> [7] </ref> for the linear case, [17] for application to recurrent neural networks). This algorithm, however, has been known to have convergence problems. 3 A normalized Hamming window was used to emphasizes data in the center of the window, and deem-phasize data in the periphery.
Reference: [8] <author> H.G. Hirsch. </author> <title> Estimation of noise spectrum and its application to SNR-estimation and speech enhancement. </title> <type> Technical Report TR-93-012, </type> <institution> International Computer Science Institute. </institution> <year> 1993. </year>
Reference-contexts: For slow variations in the noise statistics, Hirsch <ref> [8] </ref> has proposed an approach based on histograms of spectral magnitudes which does not require explicit segmentation of the data into speech and non-speech segments.
Reference: [9] <author> F. Lewis. </author> <title> Optimal Estimation. </title> <publisher> John Wiley & Sons, Inc. </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Methods for estimating the noise variances directly from the noisy data are described later in this paper. Extended Kalman Filter State Estimation For a linear model with known parameters, the Kalman filter (KF) algorithm can be readily used to estimate the states <ref> [9] </ref>. At each time step, the filter computes the linear least squares estimate ^x (k) and prediction ^x (k), as well as their error covariances, P X (k) and P X (k). In the linear case with Gaussian statistics, the estimates are the minimum mean square estimates.
Reference: [10] <author> J. Lim, A. Oppenheim. </author> <title> All-pole modeling of degraded speech. </title> <journal> IEEE Trans. Acoust., Speech, Signal Process., </journal> <volume> vol. 26, </volume> <month> June </month> <year> 1978. </year>
Reference-contexts: In the speech literature, the method is most closely related to Lim and Oppenheim's approach to fitting LPC models to degraded speech <ref> [10] </ref>. It also relates to Ephraim's model-based approach [6], but uses nonlinear estimation to fit the given data instead of using a fixed number of prespecified linear models. <p> A new ^ 2 n is then re-estimated for each short-term window. This technique was used for the results given with the nonstationary white noise experiment. Process Noise Variance: To estimate 2 v (assuming an LPC model for the signal), Lim and Oppenheim <ref> [10] </ref> used an expression for the inverse Fourier transform of the signal power (which is a function of 2 v ).
Reference: [11] <author> M. B. Matthews and G. S. Moschytz. </author> <title> The identification of nonlinear discrete-time fading-memory systems using neural network models. </title> <journal> IEEE Transactions on Circuits and Systems-II, </journal> <volume> 41(11) </volume> <pages> 740-51, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: For finite data sets, the algorithm is run iteratively over the data until the weights converge. This approach to dual estimation is related to work done by Nelson [12] in the linear case, and to Matthews' neural approach <ref> [11] </ref> to the recursive prediction error algorithm [7] 2 . In the speech literature, the method is most closely related to Lim and Oppenheim's approach to fitting LPC models to degraded speech [10].
Reference: [12] <author> L. Nelson, E. Stear. </author> <title> The simultaneous on-line estimation of parameters and states in linear systems. </title> <journal> IEEE Tr. on Automatic Control. </journal> <month> February </month> <year> 1976. </year>
Reference-contexts: For finite data sets, the algorithm is run iteratively over the data until the weights converge. This approach to dual estimation is related to work done by Nelson <ref> [12] </ref> in the linear case, and to Matthews' neural approach [11] to the recursive prediction error algorithm [7] 2 . In the speech literature, the method is most closely related to Lim and Oppenheim's approach to fitting LPC models to degraded speech [10].
Reference: [13] <author> G. Puskorious, L. Feldkamp. </author> <title> Neural control of nonlinear dynamic systems with Kalman filter trained recurrent networks. </title> <journal> IEEE Trn. on NN, </journal> <volume> vol. 5, no. 2, </volume> <year> 1994. </year>
Reference-contexts: At each time point, the Kalman filter provides an optimal estimation by combining a prior prediction with a new observation. Connor et al.[4], proposed using an extended Kalman filter with a neural network to perform state estimation alone. Puskorious and Feldkamp <ref> [13] </ref> and others have posed the weight estimation in a state-space framework to allow for efficient Kalman training of a neural network.
Reference: [14] <author> G. Seber, C. Wild. </author> <title> Nonlinear Regression. </title> <publisher> John Wiley & Sons. </publisher> <year> 1989. </year>
Reference-contexts: An additional aspect that is currently under consideration is the minimization of both prediction and estimation errors by the weight filter. While the current implementation minimizes only prediction error of the model, the full errors in variables cost function <ref> [14, 15] </ref> can be minimized by a two-observation form of the weight filter. This refinement will be discussed in a future paper. Acknowledgments: This work was sponsored by the NSF under grant ECS-9410823, and by ARPA/AASERT Grant DAAH04-95-1-0485. We would like to thank C.
Reference: [15] <author> E. Wan, A. Nelson. </author> <title> Dual Kalman filtering methods for nonlinear prediction, estimation, and smoothing. </title> <booktitle> In NIPS96 Proceedings, </booktitle> <year> 1997. </year>
Reference-contexts: In prior work, we extended these ideas to include the dual Kalman estimation of both states and weights for efficient maximum-likelihood optimization (in the context of robust nonlinear prediction, estimation, and smoothing) <ref> [15] </ref>. The work presented here develops these ideas in the context of speech processing. <p> An additional aspect that is currently under consideration is the minimization of both prediction and estimation errors by the weight filter. While the current implementation minimizes only prediction error of the model, the full errors in variables cost function <ref> [14, 15] </ref> can be minimized by a two-observation form of the weight filter. This refinement will be discussed in a future paper. Acknowledgments: This work was sponsored by the NSF under grant ECS-9410823, and by ARPA/AASERT Grant DAAH04-95-1-0485. We would like to thank C.
Reference: [16] <author> P. Werbos. </author> <title> Backpropagation through time: what it does and how to do it. </title> <booktitle> Proc. IEEE, special issue on neural networks 2. </booktitle> <pages> 1550-1560. </pages> <year> 1990. </year>
Reference-contexts: ^ w (k) = ^ w (k) + K ^w (k)(y (k) CF ( ^ x (k 1); ^ w (k))) ; (17) where H (k) = C@F [ ^ x; ^ w] fi fi ^ w (k 1) The linearization in (18) can be computed as a dynamic derivative <ref> [16] </ref> to account for the recurrent nature of the state-estimation filter, including the dependence of the Kalman gain K (k) on the weights. <p> The use of the full derivatives is currently being investigated by the authors. 1 This is equivalent to a single-step of backpropagation through time <ref> [16] </ref>. the states and the weights, respectively. We now have EKFs for estimating both the states x and the weights w, resulting in a pair of dual extended Kalman filters (DEKF) run in parallel (see Figure 1).
Reference: [17] <author> R. Williams. </author> <title> Training recurrent networks using extended Kalman filter. </title> <booktitle> International Joint Conference on Neural Networks, Baltimore, vol. IV, </booktitle> <year> 1992. </year>
Reference-contexts: This also produced impressive results, 2 An alternative approach is to concatenate both w and x into a joint state vector, and apply the EKF to the resulting nonlinear state equations (see [7] for the linear case, <ref> [17] </ref> for application to recurrent neural networks). This algorithm, however, has been known to have convergence problems. 3 A normalized Hamming window was used to emphasizes data in the center of the window, and deem-phasize data in the periphery.
References-found: 17

