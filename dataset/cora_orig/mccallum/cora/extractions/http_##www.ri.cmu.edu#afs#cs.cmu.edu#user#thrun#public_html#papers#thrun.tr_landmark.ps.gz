URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/thrun/public_html/papers/thrun.tr_landmark.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/thrun/public_html/papers/full.html
Root-URL: 
Title: A Bayesian Approach to Landmark Discovery and Active Perception in Mobile Robot Navigation  
Author: Sebastian Thrun 
Note: The author is also affiliated with the  where part of this research was carried out.  
Address: Pittsburgh, PA 15213  Germany,  
Affiliation: School of Computer Science Carnegie Mellon University  Computer Science Department III of the University of Bonn,  
Date: May 1996  
Abstract: To operate successfully in indoor environments, mobile robots must be able to localize themselves. Over the past few years, localization based on landmarks has become increasingly popular. Virtually all existing approaches to landmark-based navigation, however, rely on the human designer to decide what constitutes appropriate landmarks. This paper presents an approach that enables mobile robots to select their landmarks by themselves. Landmarks are chosen based on their utility for localization. This is done by training neural network landmark detectors so as to minimize the a posteriori localization error that the robot is expected to make after querying its sensors. An empirical study illustrates that self-selected landmarks are superior to landmarks carefully selected by a human. The Bayesian approach is also applied to control the direction of the robot's camera, and empirical data demonstrates the appropriateness of this approach for active perception. This research is sponsored in part by the National Science Foundation under award IRI-9313367, and by the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Defense Advanced Research Projects Agency (DARPA) under grant number F33615-93-1-1330. The views and conclusions contained in this document are those of the author and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of NSF, Wright Laboratory or the United States Government. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Betke, M. and Gurvits, L. </author> <title> Mobile Robot Localization using Landmarks. no. </title> <institution> SCR-94-TR-474, Siemens Corporate Research, Pinceton, </institution> <month> December </month> <year> 1993. </year> <note> will also appear in the IEEE Transactions on Robotics and Automation. </note>
Reference-contexts: In recent years, landmark-based localization has been successfully employed in numerous mobile robot systems (see e.g., <ref> [1, 4, 14, 18, 19, 25, 26, 31, 33, 35, 42] </ref>). A recent paper by Feng and colleagues [10] provides an excellent overview of different approaches to landmark-based localization. <p> Such examples are easy to obtain by driving the robot around and recording its location. Neural network landmark detectors will be denoted by g i : S ! <ref> [0; 1] </ref> for i = 1; : : : ; n : (21) They map sensor measurements s (camera image, sonar scan) to landmark values in [0; 1]. <p> Neural network landmark detectors will be denoted by g i : S ! <ref> [0; 1] </ref> for i = 1; : : : ; n : (21) They map sensor measurements s (camera image, sonar scan) to landmark values in [0; 1].
Reference: [2] <author> Borenstein, J. </author> <title> The Nursing Robot System. </title> <institution> Technion, Haifa, Israel, </institution> <month> June </month> <year> 1987. </year>
Reference-contexts: Many of the approaches reviewed there require special landmarks such as bar-code reflectors [9], reflecting tape, ultrasonic beacons, or visual patterns that are easy to recognize such as, e.g., black rectangles with white dots <ref> [2] </ref>. Some of the more recent approaches use more natural landmarks for localization, which do not require special modifications of the environment. For example, landmarks in [19] correspond to certain gateways, doors and other vertical objects, detected with sonar sensors and pairs of camera images.
Reference: [3] <author> Buhmann, J., Burgard, W., Cremers, A. B., Fox, D., Hofmann, T., Schneider, F., Strikos, J., and Thrun, S. </author> <title> The Mobile Robot Rhino. </title> <journal> AI Magazine, </journal> <volume> vol. </volume> <month> 16 </month> <year> (1995) </year>
Reference-contexts: The probability P (f jl) is usually learned from examples, unless an exact model of the robot's environment and its sensors is available. P (f jl) is often represented by a piecewise constant function <ref> [3, 4, 5, 18, 24, 26, 35, 38, 39] </ref>, or a parameterized density such as a Gaussian or a mixture thereof [12, 30, 36, 37]. 6 Sebastian Thrun of the robot is unknownthus, P (l) is uniformly distributed (Figure 1a).
Reference: [4] <author> Burgard, W., Fox, D., Hennig, D., and Schmidt, T. </author> <title> Estimating the Absolute Position of a Mobile Robot Using Position Probability Grids. </title> <booktitle> in: Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <publisher> AAAI. AAAI Press/MIT Press, </publisher> <address> Menlo Park, </address> <year> 1996. </year>
Reference-contexts: In recent years, landmark-based localization has been successfully employed in numerous mobile robot systems (see e.g., <ref> [1, 4, 14, 18, 19, 25, 26, 31, 33, 35, 42] </ref>). A recent paper by Feng and colleagues [10] provides an excellent overview of different approaches to landmark-based localization. <p> For each robot motion a do: P (l) L This algorithmic scheme subsumes various probabilistic algorithms published in the recent literature on landmark-based localization and navigation (see e.g., <ref> [4, 26, 35] </ref>). Notice that it requires knowledge about three probability densities: P (l), P a (lj l), and P (f jl). Recall that the initial estimate P (l) is usually the uniform probability distribution. <p> The probability P (f jl) is usually learned from examples, unless an exact model of the robot's environment and its sensors is available. P (f jl) is often represented by a piecewise constant function <ref> [3, 4, 5, 18, 24, 26, 35, 38, 39] </ref>, or a parameterized density such as a Gaussian or a mixture thereof [12, 30, 36, 37]. 6 Sebastian Thrun of the robot is unknownthus, P (l) is uniformly distributed (Figure 1a). <p> Others have used parameterized densities such as Kalman filters [37], or more coarse-grained models of densities such as evenly spaced grids, where the size of each grid cell might be 10 centimeters <ref> [4] </ref> or as much as 1 meter [18, 35]. Such representations are computationally easier to handle, yet they impose intrinsic limitations in the resolution of densities (which in turn introduces an intrinsic error into the fine-grain localization).
Reference: [5] <author> Burgard, W., Fox, D., Hennig, D., and Schmidt, T. </author> <title> Position Tracking with Position Probability Grids. </title> <institution> University of Bonn, Computer Science Department III, Bonn, Germany, </institution> <year> 1996. </year> <type> internal report. </type>
Reference-contexts: The probability P (f jl) is usually learned from examples, unless an exact model of the robot's environment and its sensors is available. P (f jl) is often represented by a piecewise constant function <ref> [3, 4, 5, 18, 24, 26, 35, 38, 39] </ref>, or a parameterized density such as a Gaussian or a mixture thereof [12, 30, 36, 37]. 6 Sebastian Thrun of the robot is unknownthus, P (l) is uniformly distributed (Figure 1a).
References-found: 5

