URL: http://www.cs.indiana.edu/~asengupt/asengupt/papers/thesis.ps
Refering-URL: http://www.cs.indiana.edu/~asengupt/
Root-URL: http://www.cs.indiana.edu
Title: DOCBASE ADATABASE ENVIRONMENT FOR STRUCTURED DOCUMENTS  
Author: by Arijit Sengupta 
Degree: Submitted to the faculty of the University Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the  
Date: December, 1997  
Affiliation: Department of Computer Science Indiana University  
Abstract-found: 0
Intro-found: 1
Reference: [AB95] <author> Serge Abiteboul and Catriel Beeri. </author> <title> The power of languages for the manipulation of complex values. </title> <journal> VLDB Journal, </journal> <volume> 4(4) </volume> <pages> 727-794, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: This not only makes subsequent query processing difficult, but also makes the schema vastly different from the natural representation of the structure. To get around this problem, various forms of "complex-object" models have been proposed. One of the most prominent complex-object models is the nested relational model <ref> [TF86, AB95] </ref>, in which the attributes in a relation are allowed to be of composite type (e.g., sets, lists or other relations), thus making the actual representation of the data in this model closer to its conceptual structure.
Reference: [AC75] <author> M. M. Astrahan and D. Chamberlin. </author> <title> Implementation of a structured english query language. </title> <journal> Communications of the ACM, </journal> <volume> 18(10), </volume> <month> October </month> <year> 1975. </year> <title> Also published in/as: </title> <booktitle> 19 ACM SIGMOD Conf. on the Management of Data, </booktitle> <address> King(ed), May.1975. </address>
Reference-contexts: SQL is based on tuple relational calculus, and the syntactic nature of the language has its roots in the original SEQUEL language <ref> [AC75] </ref>. SQL is more expressive than the core relational calculus since it supports extra functionality such as grouping and ordering mechanisms, aggregate functions (e.g., count, sum and average), and arithmetic operations.
Reference: [ACM93] <author> Serge Abiteboul, Sophie Cluet, and Tova Milo. </author> <title> Querying and updating the file. </title> <booktitle> Proceedings, 19th Intl. Conference on Very Large Data Bases, </booktitle> <pages> pages 73-84, </pages> <year> 1993. </year>
Reference-contexts: However, by letting a query language quantify over complex sorts inherently introduces the possibility of explosive complexity. In another variation of the complex-object approach, Abiteboul et al. <ref> [ACM93] </ref> and Christophides et al. [CACS94] used an object-oriented database to model textual data, particularly data encoded in the SGML [Gol90, ISO86] format. <p> In this section, we describe the types of queries we intend to solve and the basic properties of query languages that we can use. In Chapter 3, we described some current systems and techniques applied for providing database querying functionality for text documents. Among these, the research at INRIA <ref> [ACM93, CACS94] </ref> provides the most complete method of querying, owing to the use of an object-oriented query language for data modeled and stored using an object-oriented database.
Reference: [AHV95] <author> Serge Abiteboul, Richard Hull, and Victor Vianu. </author> <title> Foundations of Databases. </title> <address> Reading, Mass. </address> : <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: Although relational databases became the standard in database systems, the simplicity of the flat table model was often proving to be too restrictive to model complex structures without causing excessive fragmentation in Chapter 1. Introduction 6 the data. <ref> [AHV95, Chapter 20] </ref> Third generation database systems, consisting of Object-Oriented and Object-Relational database systems, accommodate complex structures in the data model, thus improving the expressive power of the model. However, the increased expressive power also implied an increased complexity of the query languages.
Reference: [AV97] <author> Serge Abiteboul and Victor Viannu. </author> <title> Regular path queries with constraints. </title> <booktitle> In Proceedings: ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 122-133, </pages> <address> Tucson, Arizona, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: Traditional PEs in Graphs Path expressions in graphs are typically used in navigation-oriented queries. This technique has been applied in hypertext data as well as object-oriented languages. Typically, such queries are expressed using regular expressions denoting paths in the graph representing the data <ref> [AV97] </ref>. In this setting, the data is organized in the form of nodes linked by labeled edges. A notion of path queries can be built using a similar approach for defining regular expressions [HU79]. Abiteboul and Viannu [AV97] describe their path queries in terms of regular path queries, and then generalize <p> are expressed using regular expressions denoting paths in the graph representing the data <ref> [AV97] </ref>. In this setting, the data is organized in the form of nodes linked by labeled edges. A notion of path queries can be built using a similar approach for defining regular expressions [HU79]. Abiteboul and Viannu [AV97] describe their path queries in terms of regular path queries, and then generalize them to general path queries as follows: Regular path queries A regular path query is defined as a regular expression over some finite alphabet consisting of the set of labels in the graph. <p> An extension to the above regular path queries can be expressed by allowing string regular expressions inside the labels in the path. Abiteboul and Vianu <ref> [AV97] </ref> term such path expressions as general path queries. Examples of such path queries include: "doc" ("[sS]ections?" "text" + "[pP]aragraph") "section" (".*")* "caption" General path expressions allow perl-style regular expressions inside the labels of the path.
Reference: [BBB + 88] <author> F. Bancilhon, G. Barbedette, V. Benzaken, C. Delobel, S. Gamerman, C. Lecluse, P. Pfeffer, P. Richard, and F. Velez. </author> <title> The design and implementation of O2, an object-oriented database system. </title> <editor> In K. R. Dittrich, editor, </editor> <booktitle> Advances in Object-Oriented Database Sys., volume 334 of Lecture Notes in CS, </booktitle> <pages> page 1. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1988. </year> <note> 195 BIBLIOGRAPHY 196 </note>
Reference-contexts: Context 30 models have also been proposed <ref> [BBB + 88] </ref>. One of the primary aspects of the object-oriented model is the use of abstract data types and inheritance. In the object-oriented model, the schema may include user-defined complex types (also known as Abstract Data Type or ADT) having both data and procedural attributes (or methods). <p> They used a mapping procedure to map the Data Type Definition (DTD) for the document into an object-oriented class definition in the language CO 2 , which is the programming language in the object-oriented database environment O 2 <ref> [BBB + 88] </ref>. In this mapping procedure, the document written in SGML was mapped to an instance of the class schema declared from the DTD. The query language associated with O 2 is then used to query the data.
Reference: [BCM96] <author> Tim Bienz, Richard Cohn, and James R. Meehan. </author> <title> Portable Document Format Reference Manual. Adobe Systems Incorporated, </title> <note> version 1.2 edition, </note> <month> November 27 </month> <year> 1996. </year>
Reference-contexts: However, it is practically the only way information can be interchanged between systems and platforms without modification. Although other document formats such as plain text, word processor formats, postscript [Sys85], PDF (portable document format) <ref> [BCM96] </ref> have been used for document publication and distribution, none of them has been able to deliver the full capability of electronic documents. As discussed in Chapter 1, although plain text is possibly the most portable method of interchanging documents, its applicability is quite limited.
Reference: [BGBG95] <author> Ronald M. Baecker, Jonathan Grudin, William A. S. Buxton, and Saul Greenberg. </author> <title> Readings in Human-Computer Interaction: </title> <booktitle> Toward the Year 2000, chapter 2. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Francisco, California, </address> <year> 1995. </year>
Reference-contexts: Designers frequently need to "augment these intuitions with evidence obtained from observing [our] artifacts being utilized by real users, which is known as usability testing and user testing." <ref> [BGBG95] </ref> Usability testing primarily involves letting members of the targeted users use the system for realistic tasks and collecting information based on feedback from these users for the purpose of validating the design or redesigning problem areas.
Reference: [BHG87] <author> Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman. </author> <title> Con-currency control and recovery in database systems. </title> <address> Reading, Mass.: </address> <publisher> Addison-Wesley Publishing Co., </publisher> <year> 1987. </year>
Reference-contexts: The most prominent database features include: * Concurrency control and recovery. When a document repository is not fixed and is constantly being changed by authors and maintainers, it is necessary to control concurrent access to the documents so that data is not lost from conflicting operations <ref> [BHG87] </ref>. Moreover, in case of a system crash during an update operation to the database, the system needs to gracefully recover from the crash and retain consistency of the data. * Version control and collaborative authoring.
Reference: [BLC95] <author> T. Berners-Lee and D. Connolly. </author> <title> Hypertext Markup Language - 2.0. MIT/W3C: HTML Working Group, RFC: </title> <address> 1866 edition, </address> <month> November 22 </month> <year> 1995. </year> <note> Available on-line from http://www.w3.org/pub/WWW/MarkUp/html-spec. </note>
Reference-contexts: These tags normally use the same encoding as the rest of the document, so that the document is readable without any formatting information and is easily interchangeable between platforms. The concept of these tags first arose with HTML (HyperText Markup Language) <ref> [BLC95] </ref> | the language for the World Wide 1 Chapter 1. Introduction 2 Web, and SGML (Standard Generalized Markup Language) [ISO86] | a generalized language for creating documents with arbitrary structure. <p> The main emphasis of this dissertation is on SGML, although all the concepts will be fully applicable to HTML, since HTML can be considered to be an application of SGML <ref> [BLC95] </ref>. The primary goal of SGML was to create documents that are freely interchangeable between multiple systems and platforms. In addition to making documents portable, the SGML tags introduce structural information in the documents, information that can be used by applications for purposes other than formatting. <p> The current structure of the web is based on HTML. Although HTML uses a mixed markup model, most of the HTML tags are generic and semantics are only associated to them by the browsers. Moreover, HTML has already been incorporated as an SGML DTD <ref> [BLC95] </ref>, so the current research can be easily applied for building complex SQL-capable search engines for the Internet. * XML Search Engines. With the advent of XML [W3C97], custom user-defined tags are becoming standard.
Reference: [Boo89] <author> Paul Booth. </author> <title> An Introduction to Human-computer Interaction. </title> <publisher> Laurence ErlBaum Associates Publishers, </publisher> <year> 1989. </year>
Reference-contexts: We use this idea to generalize QBE for databases where each data instance, albeit complex, has a simple visual model. We base this assumption on the fact that human beings form a mental model for the tasks that they intend to perform <ref> [Boo89] </ref>. For example, users performing a search in a dictionary may not know the internal structure and representation of each definition, but they usually have an idea about a visual structure of a dictionary entry, assuming they have used dictionaries in print. <p> Subsequent sections will describe implementation and analysis of the QBT interface. 7.1.1 Rationale The main rationale for the idea of querying using templates comes from the fact that users tend to form a distinctive mental model for tasks they perform <ref> [Boo89] </ref>. Simply described, a mental model is a mental image of the expected task (both the process of performing the task as well as the result on completion of the task) that the users conceive of before they actually begin any task. <p> Forms always look the same, whether the underlying database is a poem, a dictionary, a quotation collection, or even a relational database. However, templates can be custom-designed for different types of databases. This way, templates can provide a direct reflection of the users' mental models <ref> [Boo89, Chap. 6] </ref>, Chapter 7. User Interface Design 188 a significant factor in the design of good user-interfaces. Moreover, templates use the principle of familiarity [Nor90], which is demonstrated to work well for novice users.
Reference: [Bro95] <author> Bill Brogden. </author> <title> Hierarchical browser in java. </title> <note> available on the WWW at http://www.bga.com/ wbrogden/javatest.html, </note> <year> 1995. </year>
Reference-contexts: Chapter 7. User Interface Design 174 1. SGMLQuery. This package serves as the main package and the driver of the basic user interface, query generator and catalog manager. 2. Hier. This is the hierarchical structure browser, originally developed by Brogden <ref> [Bro95] </ref> and adapted for the prototype project. 3. ImageMap. This is the primary template screen module. This was originally developed by Sun Microsystems as a demonstration module for Java. This source was used as a starting point with added functionality for the template module.
Reference: [Bur92] <author> Forbes J. Burkowski. </author> <title> An algebra for hierarchically organized text-dominated databases. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 28(3) </volume> <pages> 333-348, </pages> <year> 1992. </year>
Reference-contexts: Open Text Corporation uses this structure in their commercial structured search product for very efficient document searches [Ope94]. 3.2.2.2 Concordance Lists Burkowski <ref> [Bur92] </ref> proposed a concordance list structure for modeling hierarchically organized textual data. A concordance list is a special structure to keep track of the position and nesting properties of the various static contiguous extents, such as words and text elements. <p> Table 5: A sample of the concordance list for the example document Burkowski <ref> [Bur92] </ref> proposed an algebra based on this concordance list structure. The algebra consists of functions that take one or two concordance lists as operands and produce a new concordance list as a result. The language included operations for union, intersection and negation of the concordance lists.
Reference: [BYG89] <author> Ricardo A. Baeza-Yates and Gaston H. Gonnet. </author> <title> Efficient text searching of regular expressions. </title> <booktitle> Proceedings, 16th International Colloquium on Automata, Languages, and Programming, </booktitle> <pages> pages 46-62, </pages> <year> 1989. </year>
Reference-contexts: In this section, we describe two prominent data structures that fall under this type of approach. 3.2.2.1 Patricia Trees Patricia trees are based on the semi-infinite string (sistring) model of textual data <ref> [GBY91, BYG89] </ref>. In this model, textual data (whether structured or unstructured) is viewed as a string starting at each position of the text and continuing indefinitely Chapter 3. Related Work 52 to the right. <p> For example, the Patricia tree for the string 01100100010111 when the first eight sistrings have been inserted looks like Figure 7 (Figure taken from <ref> [BYG89] </ref>). eight sistrings In Figure 7, the numbers in the leaves represent the position of the sistring at that node (e.g., the leftmost leaf represents the seventh sistring 00010111 in the input starting at bit 7). <p> In addition, the query language uses the operation fby to denote interposition of fl :. Thus, a f by b is the same as a: fl :b. <ref> [BYG89] </ref> Using a Patricia tree to encode all sistrings in text, Gonnet showed that many types of queries can be performed very efficiently. <p> Two primary types of index structures are created by Pat when used on a document repository structured by SGML. The first index structure, called the "main index" or the "word index", is based on the Patricia tree structure <ref> [BYG89] </ref>. A short description of this structure is given in Chapter 2. The second structure, called the region index, is a similar structure created using only the meta-data information contained in the SGML tags in the document. The Pat query language. <p> The second structure, called the region index, is a similar structure created using only the meta-data information contained in the SGML tags in the document. The Pat query language. Pat provides a query language that reflects the capabilities of the Patricia tree structure <ref> [BYG89, GBY91] </ref> (the basic building block of Pat indices) and allows efficient computation of various kinds of searches, most common among them being prefix searches. Every operation in the Pat query language returns a set of offsets (positions in the documents) where a match is found.
Reference: [CACS94] <author> V. Christophides, S. Abiteboul, S. Cluet, and M. Scholl. </author> <title> From structured documents to novel query facilities. </title> <booktitle> SIGMOD RECORD, </booktitle> <volume> 23(2) </volume> <pages> 313-324, </pages> <month> June </month> <year> 1994. </year> <note> BIBLIOGRAPHY 197 </note>
Reference-contexts: It is extremely difficult to model hierarchically structured documents using relational databases since the flat structure of the relational model causes excessive fragmentation in the document structure. Complex object and Object-oriented databases seem to better match document structures, and a significant number of efforts <ref> [CACS94, Zha95, Hol95, D'A95] </ref> have been devoted towards mapping SGML documents in an Object-oriented or Object-Relational database and using the database for processing the queries. <p> However, by letting a query language quantify over complex sorts inherently introduces the possibility of explosive complexity. In another variation of the complex-object approach, Abiteboul et al. [ACM93] and Christophides et al. <ref> [CACS94] </ref> used an object-oriented database to model textual data, particularly data encoded in the SGML [Gol90, ISO86] format. <p> Some current document database systems [Inf95, Hol95] translate structured documents into a standard database model. Queries are performed against this database, and the results are presented in the format of the host database system, thus violating closure. Some similar systems (such as in <ref> [CACS94] </ref>) can translate the query results back to the original format by performing a reverse mapping method. Although this method achieves closure, in many Chapter 4. Objectives and Requirements 66 cases the resulting documents do not retain the complete structural information in the original documents. <p> In this section, we describe the types of queries we intend to solve and the basic properties of query languages that we can use. In Chapter 3, we described some current systems and techniques applied for providing database querying functionality for text documents. Among these, the research at INRIA <ref> [ACM93, CACS94] </ref> provides the most complete method of querying, owing to the use of an object-oriented query language for data modeled and stored using an object-oriented database. <p> Chapter 4. Objectives and Requirements 69 * Integrated authoring and database functionality. Document database systems that use a standard database system for storing documents (such as in <ref> [CACS94, Hol95, Inf95] </ref>) need to provide a mechanism for authoring the documents in a transparent manner so that users do not realize that the documents are stored in a database in fragments and only presented to them as a whole. <p> as lists and allows the selection of particular instances of labels among a set of such labels. (e.g., the expression Book.Chapter [1].title refers to the title of the first chapter of a book.) PEs in Document Structure Path expression for document structures have also been considered by Christophides et al. <ref> [CACS94, CCM96] </ref>. These approaches allow variables on paths, which instantiate over paths in the current domain. In this scenario, it is possible to formulate such expressions as node1:X = node2:Y where node1 and node2 represent tree nodes, and X; Y represent path variables. <p> The GIs within parenthesis are the children of thisgi, and are said to be in thisgi's content group. Chapter 5. Conceptual Design 76 similar to the partial path specification in [dBV93] and the ".." operator in <ref> [CACS94] </ref>, described above.
Reference: [CCB95] <author> Charles L.A. Clarke, G.V. Cormack, and F.J. Burkowski. </author> <title> An algebra for structured text search and a framework for its implementation. </title> <journal> The Computer Journal, </journal> <volume> 38(1) </volume> <pages> 43-56, </pages> <year> 1995. </year>
Reference-contexts: The algebra consists of functions that take one or two concordance lists as operands and produce a new concordance list as a result. The language included operations for union, intersection and negation of the concordance lists. Clarke, Cormack and Burkowski <ref> [CCB95] </ref> generalized the concordance list structure to include nested and overlapping extents.
Reference: [CCM96] <author> Vassilis Christophides, Sophie Cluet, and Guido Moerkotte. </author> <title> Evaluating queries with generalized path expressions. </title> <editor> In H.V. Jagadish and Inderpal Singh Mumick, editors, </editor> <booktitle> Proceedings, ACM SIGMOD 1996, </booktitle> <volume> volume 25, </volume> <pages> pages 418-422. </pages> <institution> Association of Computing Machinery, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: as lists and allows the selection of particular instances of labels among a set of such labels. (e.g., the expression Book.Chapter [1].title refers to the title of the first chapter of a book.) PEs in Document Structure Path expression for document structures have also been considered by Christophides et al. <ref> [CACS94, CCM96] </ref>. These approaches allow variables on paths, which instantiate over paths in the current domain. In this scenario, it is possible to formulate such expressions as node1:X = node2:Y where node1 and node2 represent tree nodes, and X; Y represent path variables.
Reference: [CDF + 86] <author> Michael J. Carey, David J. DeWitt, Daniel Frank, Goetz Graefe, M. Mu-ralikrishna, Joel E. Richardson, and Eugene J. Shikita. </author> <title> The architecture of the EXODUS extensible DBMS. </title> <editor> In Klaus R. Dittrich and Umesh-war Dayal, editors, </editor> <booktitle> Proceedings, 1996 International Workshop on Object-Oriented Database Ssytems, </booktitle> <pages> pages 52-65, </pages> <address> Pacific Grove, California, USA, </address> <month> September 23-26 </month> <year> 1986. </year> <pages> IEEE-CS. </pages>
Reference-contexts: Query processing capabilities were built into clients of the storage management system. Figure 13 shows exactly where these applications are used in the architecture of DocBase. Details on these applications are presented next. 6.1.1 Storage Management Applications The Exodus storage manager <ref> [CDF + 86] </ref> was the primary storage management server used in this prototype. Exodus is a storage manager developed at the University of Wisconsin which is frequently used in the management of extremely large volumes of data. <p> A server having the essential functionality of a storage manager (e.g., concurrency control, recovery) runs continuously and waits for connections from clients. Clients attempting to perform storage management tasks send requests to the server as necessary. In DocBase, the storage management functions are implemented using Exodus <ref> [CDF + 86, Uni93] </ref>, a popular storage manager developed at the University of Wisconsin. Exodus has a client-server architecture; it acts as a server for DocBase, which is an application built using the library of functions provided by the Exodus Application Programming Interface (API).
Reference: [Cha94] <author> Chadwyck-Healey. </author> <title> The English Poetry Full-Text Database, </title> <note> 1994. The works of more than 1,250 poets from 600 to 1900. </note>
Reference-contexts: As an interesting illustration of the problem, let us consider an electronic document collection, such as the ChadWyck-Healey English poetry database <ref> [Cha94] </ref>, a collection of over 160,000 poems from the Anglo-Saxon period to the late 19th century. If this collection were on paper, at an average of one poem per page, this document will have 160,000 pages.
Reference: [Che76] <author> Peter Pin-Shan Chen. </author> <title> The Entity-Relationship model toward a unified view of data. </title> <journal> ACM Transactions on Database Systems (TODS), </journal> <volume> 1(1) </volume> <pages> 9-36, </pages> <month> March </month> <year> 1976. </year>
Reference-contexts: The second generation also witnessed better theoretical foundations in database models and query languages and better visual query formulation using the QBE (Query By Example) query language [Zlo77]. The Entity-Relationship (ER) Model <ref> [Che76] </ref>, also introduced during this generation, better supported conceptual modeling of data, from which the database schema could be conveniently generated. <p> DTDs Prentice Hall 1996 Auth info Book number Author 0198537379 Charles Goldfarb 079230635X Eric Van Herwijnen 0133098818 Eve Maler 0133098818 Jeanne El Andaloussi Table 1: A sample relational database instance In the example schema (Table 1), the information on books include a book number, 1 The Entity Relationship (ER) model <ref> [Che76] </ref> is a method for viewing data conceptually using distinct objects (entities) and the relationships between them. The ER diagram is a method for visually describing an ER model, and is a great tool for specifying a conceptual data model. Chapter 2.
Reference: [CLR89] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: The algorithm to derive the logical expression from its graphical representation is very similar to a minimal spanning tree algorithm Chapter 7. User Interface Design 164 <ref> [CLR89, Chapter 24] </ref>. The algorithm is initiated with one of the nodes which does not have any incoming arrows, and a minimal spanning tree is built with all the nodes reachable from the starting node that have not been included in the expression.
Reference: [Cod70] <author> E.F. Codd. </author> <title> A relational model for large shared data banks. </title> <journal> Communications of the ACM, </journal> <volume> 6(13) </volume> <pages> 377-387, </pages> <month> June </month> <year> 1970. </year>
Reference-contexts: Moreover, changes to the organization of the data needed major changes to the processing applications. The early IMS (Information Management System) [McG77] and its DL/1 language fall in this category. Second generation database systems included the relational model <ref> [Cod70] </ref>, which first introduced the concept of data independence. This makes the conceptual organization of the data independent of the way the data is internally stored and processed. <p> One of the primary reasons behind the success of this model is its simplicity, which is also the reason behind its limitations. The relational data model is based on a strong theoretical foundation proposed by Codd <ref> [Cod70] </ref>. The primary idea in relational model is that the data is represented in tables with a fixed number of columns, and each row represents a single record. A relational database consists of a set of tables, or relations; the relations consist of a set of tuples within a domain.
Reference: [D'A95] <author> Al D'Andrea. </author> <title> Improved database technology for document management. </title> <editor> In Yuri Rubinsky, editor, </editor> <booktitle> Proceedings, </booktitle> <volume> SGML '95, </volume> <pages> pages 113-122. </pages> <booktitle> Graphic Communications Association, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: It is extremely difficult to model hierarchically structured documents using relational databases since the flat structure of the relational model causes excessive fragmentation in the document structure. Complex object and Object-oriented databases seem to better match document structures, and a significant number of efforts <ref> [CACS94, Zha95, Hol95, D'A95] </ref> have been devoted towards mapping SGML documents in an Object-oriented or Object-Relational database and using the database for processing the queries.
Reference: [Dat89] <author> C.J. Date. </author> <title> A guide to the SQL Standard: A user's guide to the standard relational language SQL. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <year> 1989. </year> <note> BIBLIOGRAPHY 198 </note>
Reference: [Day87] <author> Umeshwar Dayal. </author> <title> Of nests and trees: A unified approach to processing queries that contain nested subqueries, aggregates, and quantifiers. </title> <editor> In Peter M Stocker and William Kent, editors, </editor> <booktitle> Proceedings: International Conference on Very Large Data Bases (VLDB), </booktitle> <pages> pages 197-208, </pages> <address> Brighton, England, September 1-4 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In particular, processing of nested queries can be performed using a tuple-substitution method [SAC + 79]. Further research is necessary to evaluate application of advanced techniques such as in <ref> [Day87] </ref> for nested query processing, grouping, ordering and aggregation operations. * Query optimization. As described in Chapter 6, query optimization issues were considered during the processing and evaluation of queries, and some optimization techniques were implicit in the evaluation algorithms presented earlier.
Reference: [dBV93] <author> Jan Van den Bussche and Gottfried Vossen. </author> <title> An extension of path expressions to simplify navigation in object-oriented queries. In Stefano Ceri, Katsumi Tanaka, </title> <editor> and Shalom Tsur, editors, </editor> <booktitle> Proceedings of the third international conference on Deductive and Object-Oriented Databases (DOOD), number 760 in Lecture Notes in Computer Science, </booktitle> <pages> pages 267-282, </pages> <address> Phoenix, Arizona, </address> <month> December </month> <year> 1993. </year> <note> Springer-Verlag. </note>
Reference-contexts: PEs in Object-Oriented Databases The concept of path expressions in object-oriented query languages started with the necessity for abbreviating expressions involving long chains of membership or inheritance relationships <ref> [KKS92, dBV93] </ref>. Traditionally, a path expression over a given OODB schema is an expression of the form Chapter 5. <p> This definition of path expressions leads to several unnecessarily long expressions describing paths, even between object pairs for which only one unique path exists. Generalizations of the above path expressions have also been proposed [KKS92]. In one such approach, Van den Bussche and Vossen <ref> [dBV93] </ref> simplified the fully expanded path expressions to partial path expressions without any change in the syntax, extending the syntax of the "." operator to incorporate an unspecified path. During computation, the paths are expanded to a minimal path between the object instances. <p> The GIs within parenthesis are the children of thisgi, and are said to be in thisgi's content group. Chapter 5. Conceptual Design 76 similar to the partial path specification in <ref> [dBV93] </ref> and the ".." operator in [CACS94], described above. <p> This was necessary to ensure that individual components of queries could be extracted from the query. General path expressions (such as in <ref> [dBV93] </ref>), however, allow positional notations on labels in the path expressions (e.g., book.chapter [1].section [2].title, denoting the titles of the second sections of the first chapters of books). Typically, these positional expressions can be variables, thus increasing the expressiveness of the language.
Reference: [DGS86] <author> B.C. Desai, P. Goyal, and F. Sadri. </author> <title> A data model for use with formatted and textual data. </title> <address> JASIS, </address> <year> 1986. </year>
Reference-contexts: The ongoing work using this approach can be further divided into two broad categories based on the underlying theory behind the work: (1) complex-object approach and (2) grammar-based approach. 3.2.1.1 Complex-object Approach Desai et al. <ref> [DGS86] </ref> and Guting et al. [GZC89] used an algebraic approach with constructs for specifying queries in algebraic form, and with complex-object constructs like set, unnest, project and group-by. The algebraic approach gave the possibility of Chapter 3. Related Work 50 optimization and rewriting or rephrasing queries.
Reference: [DR93] <author> Joseph S. Dumas and Janice C. </author> <title> Redish. A practical guide to usability testing. </title> <publisher> Ablex publishing corporation, </publisher> <year> 1993. </year>
Reference-contexts: Testing for usability should be, in fact, a prominent milestone by itself in the system design process. Chapter 2. Context 40 The usability testing phase usually includes a phase for evaluating the testing method itself. This phase is often called a "pilot test" <ref> [DR93, Chapter 17] </ref>. Although, technically, this is just a prototype of the usability analysis itself, it can assist immensely in determining the possible problems with the testing method.
Reference: [Ebe94] <author> Ray E. Eberts. </author> <title> User Interface Design. </title> <publisher> Prentice Hall, </publisher> <year> 1994. </year>
Reference-contexts: Usability tests are usually carried out using one of the following two strategies <ref> [Ebe94, Chapter 5] </ref>: * Within-users tests. In a "within-users" analysis, all users are exposed to all the independent variables. For example, if two different systems are being compared, all users are asked to use both systems, and the results are collected based on this use. * Between-users tests. <p> The goal of the analysis process is to determine if any of the independent variables affect the dependent variables to a statistically significant extent. The test of significance is usually measured using several statistical methods, the most common among them being the ANOVA (Analysis of Variance) technique <ref> [Ebe94, Chapter 5] </ref>. The type of analysis varies depending on the type of the experiment and the number of independent variables. Common variations of ANOVA measures are one-way ANOVA, two-way ANOVA, repeated measures and randomized blocks.
Reference: [Emb89] <author> D.W. Embley. NFQL: </author> <title> The natural forms query language. </title> <journal> ACM Transaction on Database Systems, </journal> <volume> 14(2) </volume> <pages> 168-211, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: An example of the use of forms for formulating queries is shown in Figure 6. Although forms usually require ad-hoc application-specific design, there have been attempts to formalize the querying process using forms. The Natural Forms Query Language (NFQL) <ref> [Emb89] </ref> is a language for specifying queries using forms. It allows queries to be specified using a "universal relation" from which the database relations are derived. A filled-in form in this language can be thought of as a "view". It allows Chapter 2.
Reference: [GBY91] <author> Gaston H. Gonnet and R. Baeza-Yates. </author> <title> Lexicographical indices for text: Inverted files vs pat trees. </title> <type> Technical Report TR-OED-91-01, </type> <institution> University of Waterloo, </institution> <year> 1991. </year>
Reference-contexts: In this section, we describe two prominent data structures that fall under this type of approach. 3.2.2.1 Patricia Trees Patricia trees are based on the semi-infinite string (sistring) model of textual data <ref> [GBY91, BYG89] </ref>. In this model, textual data (whether structured or unstructured) is viewed as a string starting at each position of the text and continuing indefinitely Chapter 3. Related Work 52 to the right. <p> Patricia trees thus present a very efficient means for string searching in text documents. In addition to prefix searches, Pat trees can be used for proximity searching, range searching, longest repetition searching, "most frequent" searching as well as regular expression searching <ref> [GBY91] </ref>. Open Text Corporation uses this structure in their commercial structured search product for very efficient document searches [Ope94]. 3.2.2.2 Concordance Lists Burkowski [Bur92] proposed a concordance list structure for modeling hierarchically organized textual data. <p> The second structure, called the region index, is a similar structure created using only the meta-data information contained in the SGML tags in the document. The Pat query language. Pat provides a query language that reflects the capabilities of the Patricia tree structure <ref> [BYG89, GBY91] </ref> (the basic building block of Pat indices) and allows efficient computation of various kinds of searches, most common among them being prefix searches. Every operation in the Pat query language returns a set of offsets (positions in the documents) where a match is found.
Reference: [GNU92] <author> GNU Project. </author> <title> Unix Commands Refernece Manual, </title> <month> Sep </month> <year> 1992. </year>
Reference-contexts: Although the complexity of simple keyword search in a document is only linear to the size of the document, for very large documents this complexity turns out to be considerably expensive. For example, a simple "grep" search <ref> [GNU92] </ref> for the word "tyger" in the Chadwyck-Healey poetry database mentioned earlier takes about 6 minutes (62.9 seconds system CPU time) running on a Sun Ultra Sparc 2 with 124MB of main memory. <p> The actual search method to retrieve document components based on keywords depends on the underlying application that performs the search. This may simply consist of a sequential scan of the documents as performed in the popular Unix T M utility "grep" <ref> [GNU92] </ref>. More often, manual and automatic indexing techniques are used to create indices on keywords found in the documents, and these index structures are used to quickly find the positions of matched keywords in the documents.
Reference: [Gol90] <author> Charles F. Goldfarb. </author> <title> The SGML Handbook. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1990. </year>
Reference-contexts: The existence of markup symbols is interpreted by applications to perform some procedure for handling that area of the document. This added information serves two purposes: <ref> [Gol90] </ref> a) separating the logical elements of the document; b) specifying the processing functions performed on these elements. Although SGML is the standard in markup languages, many other document preparation and typesetting systems and languages (such as nroff, L A T E X) share this same idea. <p> For instance, a document may be a draft of a paper and may have version number information. This information is useful to the author but it cannot be characterized as the content of the document. According to Goldfarb <ref> [Gol90] </ref>, The GI is normally a noun; the attributes are nouns or adjectives that describe significant characteristics of the GI. Attributes are specified using the ATTLIST specifier in the DTD. Each element may have only one attribute list specifier, containing unlimited number of attributes. Chapter 2. <p> However, by letting a query language quantify over complex sorts inherently introduces the possibility of explosive complexity. In another variation of the complex-object approach, Abiteboul et al. [ACM93] and Christophides et al. [CACS94] used an object-oriented database to model textual data, particularly data encoded in the SGML <ref> [Gol90, ISO86] </ref> format. They used a mapping procedure to map the Data Type Definition (DTD) for the document into an object-oriented class definition in the language CO 2 , which is the programming language in the object-oriented database environment O 2 [BBB + 88].
Reference: [Gou95] <author> John D. Gould. </author> <title> How to design usable systems. </title> <editor> In Ronald M. Baecker, Jonathan Grudin, William A. S. Buxton, and Saul Greenberg, editors, </editor> <title> BIBLIOGRAPHY 199 Readings in Human-Computer Interaction: </title> <booktitle> Toward the Year 2000, chapter 2, </booktitle> <pages> pages 93-121. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, Cali-fornia, </address> <year> 1995. </year>
Reference-contexts: In the early phase of the design process, a designer should (i) identify the target users, (ii) have direct communication with the users, (iii) visit user locations and (iv) observe the users working, and if possible, record their actions <ref> [Gou95] </ref>. The knowledge of users' abilities and behavior is an essential component of the design process, and the earlier this knowledge is acquired the better. <p> Performing tasks in the target environment is usually more effective. This is achieved by performing the tasks in the environment the system will be used. In the case the target environment is not available during testing, a mock-up <ref> [Gou95] </ref> of this environment can be used. Recording users' behavior can be done using several different techniques. Some of the most common techniques are: * Videotaping. Videotaping the users in action is very useful for the purposes of measuring time, errors, and user attitudes [Gou95]. <p> not available during testing, a mock-up <ref> [Gou95] </ref> of this environment can be used. Recording users' behavior can be done using several different techniques. Some of the most common techniques are: * Videotaping. Videotaping the users in action is very useful for the purposes of measuring time, errors, and user attitudes [Gou95]. Watching videotapes of users unable to use the system for apparently simple tasks often serves as evidence of unusability. * Thinking aloud. In this method, the participants of the usability test talk out loud as they try to perform certain tasks.
Reference: [GPG89] <author> M. Gyssens, J. Paredaens, and D. Van Gucht. </author> <title> A grammar based approach toward unifying hierarchical data models. </title> <booktitle> SIGMOD, </booktitle> <pages> pages 263-272, </pages> <year> 1989. </year>
Reference-contexts: Gonnet et al. focus on dictionaries (e.g., the New Oxford English Dictionary database), news clippings, legal documents, and other documents whose high degree of structuring makes them very difficult to represent in table format. In another similar work, Gyssens et al. <ref> [GPG89] </ref> elaborate on the mathematical fundamentals of grammar-based models.
Reference: [GT87] <author> Gaston H. Gonnet and Frank W. Tompa. </author> <title> Mind your grammar: a new approach to modeling text. </title> <editor> In Peter M. Stocker, William Kent, and Peter Hammersley, editors, </editor> <booktitle> Proceedings: 13th International Conference on Very Large Data Bases, </booktitle> <pages> pages 339-346, </pages> <address> Brighton, England, September 1-4 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A recent work by Zhang [Zha95] for building a dictionary system using an object-oriented database system can also be classified under this category. 3.2.1.2 Grammar-based Approach This approach involves describing the database schema using Context Free Grammars (CFGs) or Attribute Grammars [Knu68]. Gonnet et al. <ref> [GT87] </ref> view the data model as a limited context-free grammar, and any database based on the model is formulated as a parse-tree of the grammar. The data model built on the grammar involves the use of ordered tuples and sets, lists, and union sorts.
Reference: [GZC89] <author> Guting, Zicari, and Choy. </author> <title> An algebra for structured office documents. </title> <booktitle> ACM TOIS, </booktitle> <year> 1989. </year>
Reference-contexts: The ongoing work using this approach can be further divided into two broad categories based on the underlying theory behind the work: (1) complex-object approach and (2) grammar-based approach. 3.2.1.1 Complex-object Approach Desai et al. [DGS86] and Guting et al. <ref> [GZC89] </ref> used an algebraic approach with constructs for specifying queries in algebraic form, and with complex-object constructs like set, unnest, project and group-by. The algebraic approach gave the possibility of Chapter 3. Related Work 50 optimization and rewriting or rephrasing queries.
Reference: [Hel88] <author> Martin Helander. </author> <title> Handbook of Human-Computer Interaction. </title> <publisher> North Holland, </publisher> <year> 1988. </year>
Reference-contexts: Some of the primary HCI concepts that we use in the subsequent chapters include the following: Cognitive artifact A cognitive tool or a cognitive artifact is a replacement for human deficiency <ref> [Hel88, Chapter 1] </ref>. If humans could perform all the necessary tasks rapidly, we would not require additional tools. The primary reason of using a tool is that it enhances human ability. <p> When a goal is identified, it is necessary to decide whether it is within the limits of normal human capabilities, and a tool becomes necessary if it is either impossible or inefficient to perform the task by a human. Mental models A mental model is the users' mental architecture <ref> [Hel88, Chapter 2] </ref>. At the time of performing a task, a user may already have some knowledge regarding the actual method by which the task is performed. <p> This approach increases the initial familiarity of the actions, procedures and concepts of a system by making them similar to those already known to the user <ref> [Hel88, Chapter 3] </ref>. The "desktop metaphor" of graphical operating systems is an example of metaphors commonly used in interface design. <p> Systems designed for usability need to be properly checked with users with varying levels of knowledge and experience if they are to be used by such users <ref> [Hel88, Chapter 6] </ref>. 1.2 Research Issues In Section 1.1.2.2, we looked at techniques for information retrieval from text documents without any structural information. This type of search, often called "full-text Chapter 1.
Reference: [Hol95] <author> Sebastian Holst. </author> <title> Database evolution: the view from over here (a document-centric perspective). </title> <editor> In Yuri Rubinsky, editor, </editor> <booktitle> Proceedings, </booktitle> <volume> SGML '95, </volume> <pages> pages 217-223. </pages> <booktitle> Graphic Communications Association, </booktitle> <month> De-cember 4-7 </month> <year> 1995. </year>
Reference-contexts: It is extremely difficult to model hierarchically structured documents using relational databases since the flat structure of the relational model causes excessive fragmentation in the document structure. Complex object and Object-oriented databases seem to better match document structures, and a significant number of efforts <ref> [CACS94, Zha95, Hol95, D'A95] </ref> have been devoted towards mapping SGML documents in an Object-oriented or Object-Relational database and using the database for processing the queries. <p> However, this also restricts the presentation of the results, since different ways of presenting the results individually or collectively need to be designed. Some current document database systems <ref> [Inf95, Hol95] </ref> translate structured documents into a standard database model. Queries are performed against this database, and the results are presented in the format of the host database system, thus violating closure. <p> Chapter 4. Objectives and Requirements 69 * Integrated authoring and database functionality. Document database systems that use a standard database system for storing documents (such as in <ref> [CACS94, Hol95, Inf95] </ref>) need to provide a mechanism for authoring the documents in a transparent manner so that users do not realize that the documents are stored in a database in fragments and only presented to them as a whole.
Reference: [HU79] <author> J.E. Hopcroft and J.D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison-Wesley, </publisher> <year> 1979. </year>
Reference-contexts: Typically, such queries are expressed using regular expressions denoting paths in the graph representing the data [AV97]. In this setting, the data is organized in the form of nodes linked by labeled edges. A notion of path queries can be built using a similar approach for defining regular expressions <ref> [HU79] </ref>.
Reference: [Inf95] <author> Inc. Inforium. </author> <title> Livepage T M : A system for open information exchange, </title> <booktitle> 1995. Software Information Brochure. </booktitle>
Reference-contexts: However, this also restricts the presentation of the results, since different ways of presenting the results individually or collectively need to be designed. Some current document database systems <ref> [Inf95, Hol95] </ref> translate structured documents into a standard database model. Queries are performed against this database, and the results are presented in the format of the host database system, thus violating closure. <p> Chapter 4. Objectives and Requirements 69 * Integrated authoring and database functionality. Document database systems that use a standard database system for storing documents (such as in <ref> [CACS94, Hol95, Inf95] </ref>) need to provide a mechanism for authoring the documents in a transparent manner so that users do not realize that the documents are stored in a database in fragments and only presented to them as a whole.
Reference: [ISO86] <author> International Organization for Standardization, </author> <title> Geneva, Switzerland. ISO 8879: Information Processing Text and Office Systems Standard Generalized Markup Language (SGML), 1986. BIBLIOGRAPHY 200 </title>
Reference-contexts: The concept of these tags first arose with HTML (HyperText Markup Language) [BLC95] | the language for the World Wide 1 Chapter 1. Introduction 2 Web, and SGML (Standard Generalized Markup Language) <ref> [ISO86] </ref> | a generalized language for creating documents with arbitrary structure. The main emphasis of this dissertation is on SGML, although all the concepts will be fully applicable to HTML, since HTML can be considered to be an application of SGML [BLC95]. <p> Here, we introduce SGML and its key concepts and features, describe the current trend in standard database systems with respect to modeling and query formulation, and discuss relevant areas of Human-Computer Interaction (HCI). 2.1 SGML and Structured Documents SGML (Standard Generalized Markup Language: <ref> [ISO86] </ref>) is an international standard for document representation. The original purpose of SGML was to standardize and thereby facilitate the encoding of documents in a platform and system independent manner by embedding a textual representation of the logical structure information in the documents. <p> However, by letting a query language quantify over complex sorts inherently introduces the possibility of explosive complexity. In another variation of the complex-object approach, Abiteboul et al. [ACM93] and Christophides et al. [CACS94] used an object-oriented database to model textual data, particularly data encoded in the SGML <ref> [Gol90, ISO86] </ref> format. They used a mapping procedure to map the Data Type Definition (DTD) for the document into an object-oriented class definition in the language CO 2 , which is the programming language in the object-oriented database environment O 2 [BBB + 88]. <p> Relational database systems follow the relational model in which the conceptual structure is represented as a set of tables. In this research, the data model is based on SGML <ref> [ISO86] </ref>. In SGML, the schema of the data is initially defined in terms of a DTD (Document Type Definition), and documents are then created based on the defined schema. <p> It is usually possible to map a document structure into a database schema, but such mappings are not always one-to-one, and often result in loss of information contained in the original documents as a result of the mapping operation. The SGML standard <ref> [ISO86] </ref> provides a uniform system-independent and paltform-independent method of encoding documents with a complex hierarchical structure. The process of modeling documents in SGML resembles that of modeling databases, using a DTD as a schema and conforming documents as instances.
Reference: [ISO94] <author> International Organization for Standardization and International Elec-trotechnical Commission, </author> <title> Geneva, Switzerland. ISO/IEC DIS 10179: Document Style Semantics and Specification Language: </title> <address> DSSSL, </address> <year> 1994. </year>
Reference-contexts: addition, a ".." operator is introduced, which is used to construct an abbreviated path from a listed path. 3 Note that DSQL (or Document SQL) is different from SDQL (Standard Document Query Language, which is a part of the ISO 10179 DSSSL (Document Style Semantics and Specification Lan guage) standard <ref> [ISO94] </ref>. Chapter 5. Conceptual Design 105 2. Complex selections. Standard SQL deals with flat tables as primary objects, and hence specifies the output as a number of columns that constitute the output table. In DSQL, the primary objects on which queries are built are documents.
Reference: [Jav95] <author> Sun Microsystems. </author> <title> The Java T M Language Specification: Version 1.0 Beta, </title> <year> 1995. </year>
Reference-contexts: power necessary to generalize the querying method to accommodate all types of queries supported by the formal query languages and, hence, add to the expressive power of the language. 7.2 Prototype Implementation of QBT We built a prototype 1 of the QBT interface using the Java T M programming language <ref> [Jav95] </ref>. We chose Java over other similar user-interface development languages because of its object-oriented nature and its widespread availability and use on the Web.
Reference: [JK96] <author> Jani Jaakkola and Pekka Kilpelainen. </author> <note> The sgrep online manual. Available online at http://www.cs.helsinki.fi/ jaakkol/sgrepman.html, </note> <year> 1996. </year>
Reference-contexts: The language included operations for union, intersection and negation of the concordance lists. Clarke, Cormack and Burkowski [CCB95] generalized the concordance list structure to include nested and overlapping extents. The freely available Sgrep (Structured grep) system implemented by Jaakkola and Kilpelainen <ref> [JK96] </ref> includes an extension of this GC-list structure and the associated algebra. 3.3 Semistructured Data With the advent of the World Wide Web, the necessity of text document repositories has greatly increased. The documents on the web usually conform to a well-established structure defined by the HyperText Markup Language (HTML).
Reference: [JMG95] <author> Manoj Jain, Anurag Mendhekar, and Dirk Van Gucht. </author> <title> A uniform data model for relational data and meta-data query processing. </title> <booktitle> In Proceedings of the Seventh International Conference on Management of Data (COMAD), </booktitle> <pages> pages 146-165. </pages> <publisher> Tata McGraw-Hill Press, </publisher> <month> December </month> <year> 1995. </year>
Reference-contexts: Queries on such stored queries can be used for future performance tuning. Moreover, the capability of treating queries as data gives a means for adding reflection properties to a query language <ref> [JMG95] </ref>. Traditional information retrieval systems deal with unstructured text. In this case, the idea of closure does not have much importance, since the query results do not need to follow any structure of the input documents. <p> Conceptual Design 110 data as queries. This ability is commonly known as "reflection" in programming languages, and gives a language a higher expressive power and the capability of performing meta-data queries. Many attempts of providing reflection support in query languages have been researched <ref> [JMG95] </ref>, and the use of SGML as a query language for SGML databases provides a natural way to achieve this property. * Queries formulated and stored in SGML can easily be converted into any other query language (including visual query languages) without much effort. * Users posing queries in SGML can
Reference: [JW83] <author> Barry E. Jacobs and Cynthia A. Wasczak. </author> <title> A generalized query-by-example data manipulation language based on database logic. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-9(1):40-56, </volume> <month> January </month> <year> 1983. </year>
Reference-contexts: There have been other attempts at generalizing QBE for complex structures. Notable among them is the Generalized Query By Example (GQBE) <ref> [JW83] </ref> which uses an interface very similar to QBE for application for databases with complex hierarchical structures. This method uses nested tables, similar to the one shown in Figure 2, for composing queries as well as specifying insertion, deletion and update commands to the database.
Reference: [KKS92] <author> Michael Kifer, Won Kim, and Yehoshua Sagiv. </author> <title> Querying object-oriented databases. </title> <editor> In Michael Stonebraker, editor, </editor> <booktitle> Proceedings of the 1992 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 393-402, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: PEs in Object-Oriented Databases The concept of path expressions in object-oriented query languages started with the necessity for abbreviating expressions involving long chains of membership or inheritance relationships <ref> [KKS92, dBV93] </ref>. Traditionally, a path expression over a given OODB schema is an expression of the form Chapter 5. <p> This definition of path expressions leads to several unnecessarily long expressions describing paths, even between object pairs for which only one unique path exists. Generalizations of the above path expressions have also been proposed <ref> [KKS92] </ref>. In one such approach, Van den Bussche and Vossen [dBV93] simplified the fully expanded path expressions to partial path expressions without any change in the syntax, extending the syntax of the "." operator to incorporate an unspecified path. <p> During computation, the paths are expanded to a minimal path between the object instances. Another approach by Kifer et al. <ref> [KKS92] </ref> uses the path labels as lists and allows the selection of particular instances of labels among a set of such labels. (e.g., the expression Book.Chapter [1].title refers to the title of the first chapter of a book.) PEs in Document Structure Path expression for document structures have also been considered
Reference: [Knu68] <author> Donald E. Knuth. </author> <title> Semantics of context-free languages. </title> <journal> Mathematical Systems Theory, </journal> <volume> 2(2) </volume> <pages> 127-145, </pages> <year> 1968. </year>
Reference-contexts: Related Work 51 CONCUR, SUBDOC) is used. A recent work by Zhang [Zha95] for building a dictionary system using an object-oriented database system can also be classified under this category. 3.2.1.2 Grammar-based Approach This approach involves describing the database schema using Context Free Grammars (CFGs) or Attribute Grammars <ref> [Knu68] </ref>. Gonnet et al. [GT87] view the data model as a limited context-free grammar, and any database based on the model is formulated as a parse-tree of the grammar. The data model built on the grammar involves the use of ordered tuples and sets, lists, and union sorts.
Reference: [Knu86] <author> Donald E. Knuth. </author> <title> The T E Xbook. </title> <publisher> Addison Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Word processors, such as Microsoft Word T M , primarily use tags specific to the system, using encoding that only particular word processors can decipher. Text processing systems, such as roff [Oss76] and T E X <ref> [Knu86] </ref>, use special codes that can be entered using a computer keyboard. After a document is created, it can be processed by software programs to replace the codes with presentation information for viewing on screen or printing on paper.
Reference: [KR96] <author> T. Alan Keahey and Edward L. Robertson. </author> <title> Techniques for non-linear magnification transformations. </title> <booktitle> In Proceedings, Visualisation '96 Information Visualization Symposium. IEEE, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: For complex hierarchies, the focus can also be concentrated in the regions of interest using advanced methods like differential magnification <ref> [KR96] </ref>. Another advantage of the template method is its direct relationship to the internal structure of the database. Forms always look the same, whether the underlying database is a poem, a dictionary, a quotation collection, or even a relational database. However, templates can be custom-designed for different types of databases.
Reference: [Lam94] <author> Leslie Lamport. </author> <title> L A T E X A Document Preparation System. </title> <publisher> Addison Wesley, </publisher> <address> 2nd edition, </address> <month> November </month> <year> 1994. </year> <note> BIBLIOGRAPHY 201 </note>
Reference-contexts: Other than the two types of tags described above, there can be a mixed type of tagging, where both generic and specific tagging are involved. Tags can also be procedural, indicating some action to be performed where used. Documents in L A T E X <ref> [Lam94] </ref> format contain logical tags such as sections and chapters as well as font, size and spacing tags. A few of the HTML tags can also be seen under this mixed category. In addition, tags can also procedural, used primarily for giving instructions to the processing application.
Reference: [LMB92] <author> John R. Levine, Tony Mason, and Doug Brown. </author> <title> Lex & yacc. </title> <publisher> O'Reilly & Associates, 2nd ed. </publisher> <address> edition, </address> <year> 1992. </year>
Reference-contexts: Appendix B gives a detailed description of the source files used for these purposes. 6.4.1 The Parser and Translator The query parser for the DSQL language was implemented using lex and yacc <ref> [LMB92] </ref>. The parser supported the entire DSQL language described earlier in Chapter 5 and implemented all the productions shown in the BNF presented there. Three parsers based on the same grammar were created during the implementation stage. The first Chapter 6.
Reference: [McG77] <author> W. McGee. </author> <title> The information management system IMS/VS, part I: General structure and operation. </title> <journal> IBM Systems Journal, </journal> <volume> 16(2), </volume> <month> June </month> <year> 1977. </year>
Reference-contexts: The drawback of this method was that one needed to know the internal representation of the link structure in order to pose queries on the data. Moreover, changes to the organization of the data needed major changes to the processing applications. The early IMS (Information Management System) <ref> [McG77] </ref> and its DL/1 language fall in this category. Second generation database systems included the relational model [Cod70], which first introduced the concept of data independence. This makes the conceptual organization of the data independent of the way the data is internally stored and processed.
Reference: [MK76] <author> O. L. Madsen and B. B. Kristensen. </author> <title> LR-parsing of extended context free grammars. </title> <journal> Acta Informatica, </journal> <volume> 7(1) </volume> <pages> 61-73, </pages> <year> 1976. </year>
Reference-contexts: Content Models Content models describe the contents of composite elements. The SGML DTD specifies the grammar using an Extended Context-Free Grammar <ref> [MK76] </ref> (context-free grammar where the right side of a production can have regular expressions). The expansion of an element, referred to as "content models" in SGML, may consist of only character data (data content), only constituent elements (structure content) or both (mixed content). <p> The design was motivated primarily from a linguistic and publishing point of view, and hence, the language does not directly conform to a single known formal model. One close match is the extended context-free grammar by Madsen <ref> [MK76] </ref>, but it fails to model all the features and properties of SGML. However, because of the standardized nature of SGML and the years of research based on SGML, the absence of a formal model for SGML does not cause problems in building formal models based on SGML.
Reference: [MW93] <author> Udi Manber and San Wu. Glimpse: </author> <title> A tool to search through entire file systems. </title> <type> Technical Report TR 93-34, </type> <institution> University of Arizona, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: The searching applications can use the indices first to determine exact location of the file in which matches could potentially be found, and retrieve data by directly accessing the document in that location. As an illustration, the same search as above using Glimpse <ref> [MW93] </ref>, with Chapter 1. Introduction 9 only a small index file on the same machine takes about 67 seconds (4.19 second system CPU time), an improvement of around a factor of 15 on CPU usage. Note that this improvement is even more apparent if the search keyword appears less often.
Reference: [MW95] <author> A.O. Mendelzon and P.T. Wood. </author> <title> Finding regular simple paths in graph databases. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(6) </volume> <pages> 1235-1258, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: We then define the language by defining the terms, operators, predicates, formulas, and finally, queries in the language. 5.1.1.1 Path Expressions The notion of path expressions (PEs) came from two different areas: (i)graph query language s and (ii) object-oriented query languages. For graph query languages (e.g., <ref> [MW95] </ref>), a path expression defines a path from one node in the graph to another in terms of intermediate node and edge labels. For object-oriented query languages, a path expression defines a path from one object to another using membership and inheritance relationships.
Reference: [Nor90] <author> Donald Norman. </author> <title> The Design of Everyday things. </title> <publisher> Doubleday Currency, </publisher> <year> 1990. </year>
Reference-contexts: It is futile to expend resources and efforts in developing systems that can only be used by a handful of people. Some of the most important concepts necessary for designing usable interfaces are <ref> [Nor90, Chap. 1] </ref>: * Provision of a useful Conceptual Model. It is important for interfaces to provide a good conceptual model to the users. A good conceptual model allows the users to predict the effect of the actions. <p> However, templates can be custom-designed for different types of databases. This way, templates can provide a direct reflection of the users' mental models [Boo89, Chap. 6], Chapter 7. User Interface Design 188 a significant factor in the design of good user-interfaces. Moreover, templates use the principle of familiarity <ref> [Nor90] </ref>, which is demonstrated to work well for novice users. The only disadvantage of templates is that good templates require expensive graphics terminals, while forms work quite well with terminals without graphics capabilities.
Reference: [NP93] <author> J. Nielsen and V. Phillips. </author> <title> Estimating the relative usability of two interfaces: Heuristic, formal, and empirical methods compared. </title> <booktitle> In Proceedings: INTERCHI'93, </booktitle> <pages> pages 214-221. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Nielsen <ref> [NP93] </ref> terms the process of usability testing by setting performance goals or metrics as usability engineering. Testing for usability should be, in fact, a prominent milestone by itself in the system design process. Chapter 2. <p> However, statistical significance is not always warranted if the number of users involved in a usability analysis is too few <ref> [NP93] </ref>. Chapter 3 Related Work The main goal of this dissertation is to provide database support for text databases, and in particular, to investigate and develop methods for better query formulation and processing on databases that primarily contain textual data.
Reference: [Ope94] <institution> Open Text Corporation, Waterloo, Ontario, Canada. Open Text 5.0, </institution> <year> 1994. </year>
Reference-contexts: This dissertation describes DocBase, a prototype system for posing queries in a document database. The queries can be posed using either SQL or the visual interface described above. Instead of starting from scratch, this prototype uses the Open Chapter 1. Introduction 15 Text software <ref> [Ope94] </ref> for simple searches and uses special indices we designed for joins and other complex searches. 6. A generalized method for current SGML systems to support SQL-like queries. The prototype system demonstrates how a current commercial system can be given the capability of querying using the proposed query language. <p> In addition to prefix searches, Pat trees can be used for proximity searching, range searching, longest repetition searching, "most frequent" searching as well as regular expression searching [GBY91]. Open Text Corporation uses this structure in their commercial structured search product for very efficient document searches <ref> [Ope94] </ref>. 3.2.2.2 Concordance Lists Burkowski [Bur92] proposed a concordance list structure for modeling hierarchically organized textual data. A concordance list is a special structure to keep track of the position and nesting properties of the various static contiguous extents, such as words and text elements. <p> For example, a relational database system can be used Chapter 6. Implementation 117 to store and retrieve the storage objects 1 . 6.1.2 Index Management Applications The primary index management application used in this prototype is the Pat system from Open Text <ref> [Ope94] </ref>. Pat was developed at the University of Waterloo as a full-text searching and indexing system for text repositories. Pat uses the Patricia tree structure (discussed in Chapter 3) for its internal index representation. <p> The engine generates its output in HTML which is displayed by the clients. We wrote this engine in C/C++, using the API (Application Programming Interface) provided by the Pat <ref> [Ope94] </ref> software. More details on the implementation of the query engine are presented in Chapter 6. 7.2.1 GUI Implementation with Java T M This section presents an overview of the implementation of a prototype of the QBT interface. This prototype is built using the Java T M programming language.
Reference: [Oss76] <author> J.F. Ossanna. </author> <title> Nroff/troff user's manual. </title> <type> Technical Report Comp. </type> <institution> Sci. </institution> <type> Tech. Rep. 54, </type> <institution> Bell Laboratories, </institution> <address> Murray Hill, NJ, </address> <month> October </month> <year> 1976. </year>
Reference-contexts: Introduction 7 simply some extra information embedded in the document using either a text editor or a word-processor. Word processors, such as Microsoft Word T M , primarily use tags specific to the system, using encoding that only particular word processors can decipher. Text processing systems, such as roff <ref> [Oss76] </ref> and T E X [Knu86], use special codes that can be entered using a computer keyboard. After a document is created, it can be processed by software programs to replace the codes with presentation information for viewing on screen or printing on paper.
Reference: [OW93] <author> Gultekin Ozsoyoglu and Huaqing Wang. </author> <title> Example-based graphical database query languages. </title> <journal> Computer, </journal> <volume> 26(5) </volume> <pages> 25-38, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: This method uses nested tables, similar to the one shown in Figure 2, for composing queries as well as specifying insertion, deletion and update commands to the database. There are a few other attempts at generalizing and extending QBE | a survey on these methods can be found in <ref> [OW93] </ref>. 2.2.2.4 Fill-out Forms to Express Queries Although QBE is a formally accepted visual language for relational databases, few relational database systems fully implement QBE, possibly because of the complexity of implementation. Some commonly used relational database systems implement variations of QBE.
Reference: [Paw82] <author> Z. Pawlak. </author> <title> Rough sets. </title> <journal> International Journal of Computer and Information Sciences, </journal> <volume> 11 </volume> <pages> 341-356, </pages> <year> 1982. </year> <note> BIBLIOGRAPHY 202 </note>
Reference-contexts: The result of queries can now be presented in descending order of the relevance probability. Another technique for information retrieval has been proposed using "rough sets." [Sri89] This method uses the rough set concept by Pawlak <ref> [Paw82] </ref>. Index terms are used to create equivalence relations, each equivalence class containing semantically identical (or synonymous) terms. Searches using this type of indices can use the rough equivalence to intelligently find matches for keywords that are approximately equivalent to the search keywords and, hence, increase the probability of recall.
Reference: [PGMW95] <author> Y. Papakonstantinou, H. Garcia-Molina, and J. Widom. </author> <title> Object exchange across heterogeneous information sources. </title> <booktitle> In Proceedings of the International Conference on Data Engineering, </booktitle> <pages> pages 251-260, </pages> <address> Taipei, Taiwan, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: In most cases, the best way to treat such a structure is as a labeled graph, while using languages associated with graphs to formulate queries. One of the most common formats for representing such data is the OEM model <ref> [PGMW95] </ref>. Recent work on extracting structure from such semistructured data, on designing query languages and on processing techniques has primarily been inspired by the recent growth of the WWW and by the presence of enormous quantities of data with little structure.
Reference: [PT86] <author> P. Pistor and R. Traunmueller. </author> <title> A database language for sets, lists, and tables. </title> <journal> Information Systems, </journal> <volume> 11(4) </volume> <pages> 323-336, </pages> <year> 1986. </year>
Reference-contexts: The algebraic approach gave the possibility of Chapter 3. Related Work 50 optimization and rewriting or rephrasing queries. This method reflects the complex-object nature of documents, in which there are various instances of list, set, and bag-like structures. Pistor et al. <ref> [PT86] </ref> used a declarative approach in which they extended the Structured Query Language (SQL) with complex sorts to formulate queries involving complex objects. In this work, the complex nature of the database was handled using different complex-object operators, embedded clauses, grouping objects, and other similar query constructs.
Reference: [Rub94] <author> Jeffrey Rubin. </author> <title> Handbook of Usability Testing: How to plan, design and conduct effective tests. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1994. </year>
Reference-contexts: Designers may also have different notions of intuitiveness. This often results in systems that are usable by designers but not the target users. Thus it is imperative that users be part of the design process as early as possible and continue throughout the process of design and development. Rubin <ref> [Rub94] </ref> argues that the three principles of user-centered design are: (i) an early focus on users and tasks, (ii) empirical measurement of product usage, and (iii) iterative design whereby a product is designed, modified and tested repeatedly. <p> The rest of this section refers to the final usability analysis experiment. Twenty subjects participated in the final usability analysis. We structured the study using a "between-users" strategy <ref> [Rub94] </ref>, where two distinct groups of users use the two platforms. In our experiment, ten subjects were given the Java-based interface (see Figure 25), while the other ten users were given the form-based interface (see Figure 33).
Reference: [SAC + 79] <author> Patricia G. Selinger, Moton M. Astrahan, Donald D. Chamberlin, Ray-mond A. Lorie, and Thomas G. Price. </author> <title> Access path selection in a relational database management system. </title> <editor> In Philip A. Bernstein, editor, </editor> <booktitle> Proceedings: Special Interest Group on Management of Data (SIGMOD), </booktitle> <pages> pages 23-34, </pages> <address> Boston, MA, May 30-June 1 1979. </address> <publisher> ACM. </publisher>
Reference-contexts: Since the infrastructure is very similar to the relational query implementations, techniques used in relational databases for evaluating nested queries (such as tuple substitution Chapter 6. Implementation 135 <ref> [SAC + 79] </ref>) can also be used in this setting. Moreover, grouping, ordering and aggregate operations can be implemented using filters on the result of the queries. <p> In particular, processing of nested queries can be performed using a tuple-substitution method <ref> [SAC + 79] </ref>. Further research is necessary to evaluate application of advanced techniques such as in [Day87] for nested query processing, grouping, ordering and aggregation operations. * Query optimization.
Reference: [Sal91] <author> Gerard Salton. </author> <title> Developments in automatic text retrieval. </title> <journal> Science, </journal> <volume> 253 </volume> <pages> 974-980, </pages> <year> 1991. </year>
Reference-contexts: Efficient storage of large amounts of data is not of much use if the data cannot be efficiently retrieved from the storage. A popular method for extracting portion of information sources is using searches involving boolean combination of search keywords. This problem of "information retrieval" <ref> [Sal91] </ref> forms the basis for research in automated text extraction from a repository of documents. Information retrieval is virtually a sub-discipline in its own right within Information Science. In its simplest form, primitive information retrieval techniques extract lines containing specified keywords from a document. <p> Fortunately, research on the issue of extracting information from large volumes of text has uncovered techniques for "information retrieval" we look at a few of these techniques in this section. The most common method for searching information in a document repository is by using boolean searches <ref> [Sal91] </ref>. In this type of search, a number of keywords combined with boolean operators (such as "and", "or", "not") are specified, and the result consists of the documents that satisfy the given boolean expression. <p> We also discuss retrieval strategies based on the indexing techniques. Chapter 3. Related Work 45 3.1.1 Conventional Retrieval Methods In conventional information retrieval methods, documents are stored as a sequence of words or phrases often referred to as terms <ref> [Sal91] </ref>. Searches usually consist of boolean combinations of keywords, (i.e., keywords combined with the operators and, or, not). The retrieval system is designed to extract, from the repository, fragments of documents that match the request. <p> However, this method still depends on boolean logic and has similar limitations of boolean logic. Extending this weighted model with "strictness indicators" alleviates the rigidity of boolean logic. Another alternative approach is to use vector spaces for the purpose of information retrieval <ref> [Sal91] </ref>. In the vector space method, documents are identified by sets of terms like the boolean method. In addition, term weights indicate the importance of terms. Thus a document is conceptually represented by a multi-dimensional vector of hterm; weighti pairs. <p> Queries are also represented using weighted term sets similar to the document representation. Retrieval is performed using mathematical measures of similarity between the document vector and the query vector. This method provides for simple and parallel treatments for queries and documents. Probabilistic methods for performing information retrieval <ref> [Sal91, p.975] </ref> have also been proposed. In these methods, a quantity for relevance of a query Q j for a document D i is determined. The result of queries can now be presented in descending order of the relevance probability. <p> There are a number of techniques for selecting the terms to be indexed, some of which are described below. 3.1.3.1 Automatic Indexing techniques The simplest type of automatic indexing consists of assigning single-term indexing units to represent text content <ref> [Sal91] </ref>. This is frequently performed by identifying the individual words that occur in the documents. The index size can be reduced by omitting words from a set of common function words (such as "and", "of", "the", "but"), known as stop words.
Reference: [SB88] <author> Gerard Salton and Christopher Buckley. </author> <title> Term-weighting approaches in automatic text retrieval. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 24 </volume> <pages> 513-523, </pages> <year> 1988. </year>
Reference-contexts: Term weights for the indices are calculated from the various factors such as frequency of occurrence of the terms (term frequency) and the inverse document frequency (a measure of the probability of a term occurring in a document) <ref> [SYY75, SB88] </ref>. Chapter 3. Related Work 48 Other ways of automatically selecting terms for indexing purposes includes linguistic and knowledge-based approaches. Common practice includes the use of a thesaurus and phrases. A thesaurus combines the words closely related in meaning into groups.
Reference: [Sch97] <author> Bruce R. Schatz. </author> <title> Information retrieval in digital libraries: Bringing search to the net. </title> <journal> Science, </journal> <volume> 275 </volume> <pages> 327-334, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: In summary, most of these techniques use the full text of the documents to build smaller auxiliary structure that can be searched faster than the actual documents. Worldwide availability of these documents are now possible using the WWW, which in turn is developing the concept of digital libraries <ref> [Sch97] </ref> containing not only text, but also images, sound and other multimedia objects. In Chapter 3, we discuss in more detail recent research on information retrieval techniques for document searches Chapter 1.
Reference: [Sen96] <author> Arijit Sengupta. </author> <title> Demand more from your SGML database! bringing SQL under the SGML limelight. </title> <journal> &lt;TAG&gt;, </journal> <volume> 9(4) </volume> <pages> 1-7, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Hence, the proof follows by induction. 5.2 Practical Query Languages 5.2.1 DSQL An SQL-like Language This section describes DSQL (Document SQL) 3 , an extended version of SQL which is a user-friendly pseudo-natural language form of DC. An informal introduction and examples of this SQL can be found in <ref> [Sen96] </ref>. The primary motivations behind having such a language is to provide users of database systems with a simple means for expressing queries using a natural language form.
Reference: [Sha84] <author> B. Shackel. </author> <title> The concept of usability. </title> <editor> In J. Bennett, D. Case, J. Sandelin, and M. Smith, editors, </editor> <title> Visual Display Terminals: </title> <booktitle> Usability Issues and Health Concerns, </booktitle> <pages> pages 45-87. </pages> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1984. </year> <note> BIBLIOGRAPHY 203 </note>
Reference-contexts: Although most interaction principles are quite flexible, proper incorporation of such concepts in user interfaces makes a significant difference between an intuitive and a non-intuitive cumbersome interface. 2.3.2 Ensuring Usability Simply implementing the HCI principles indicated above does not guarantee the usability of an interface. According to Shackel <ref> [Sha84] </ref>, there is no manual for effectively Chapter 2. Context 39 incorporating human factors in computer systems. System designers usually have different capabilities and strengths compared to the users of the systems. Designers may also have different notions of intuitiveness.
Reference: [Shn87] <author> Ben Shneiderman. </author> <title> Designing the user interface : strategies for effective human-computer interaction. </title> <address> Reading, Mass. </address> : <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: In addition, the interface provides continuous feedback to the user on the status of the system <ref> [Shn87] </ref>. Individual differences One very important consideration, which is often ignored during the design of user-interfaces, is the difference between the users of the interface.
Reference: [SQL86a] <institution> American National Standards Institute, New York. ANSI X3.135-1986, Database Language SQL, </institution> <year> 1986. </year>
Reference-contexts: Chapter 2. Context 33 nested relational algebra [TF86] that uses operations such as set construction (nest) and set decomposition (unnest) to handle the complex-valued attributes. 2.2.2.2 Structured Query Language (SQL) SQL <ref> [SQL86a] </ref> has been the standard query language for relational databases for over ten years. SQL is based on tuple relational calculus, and the syntactic nature of the language has its roots in the original SEQUEL language [AC75].
Reference: [SQL86b] <author> ANSI X3.135-1986, </author> <title> Database Language SQL, </title> <year> 1986. </year>
Reference-contexts: Also, since SQL is widely accepted as a standard query language for relational databases, it was a natural choice as a document database query language. DSQL is designed as an extension to the standard SQL-86 <ref> [SQL86b] </ref>. Conceptually DSQL supports SGML documents as the objects for constructing queries. From the language point of view, however, there are only two major differences from the standard SQL, which are the following: 1. Path Expressions.
Reference: [SR90] <author> Tengku M.T. Sembok and C.J. Van Rusbergen. SILOL: </author> <title> A simple logical-linguistic document retrieval system. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 26(1) </volume> <pages> 111-134, </pages> <year> 1990. </year>
Reference-contexts: While indexing, it is often useful not to create separate index entries for all forms of the same word (such as various verb forms, tenses and numbers) and only include the root word in the indices. Some advanced indexing mechanisms use various forms of linguistic analysis <ref> [SR90] </ref> and thesauruses to determine the important words for indexing. In summary, most of these techniques use the full text of the documents to build smaller auxiliary structure that can be searched faster than the actual documents. <p> This type of search, often called "full-text Chapter 1. Introduction 12 search" has its limitations, and Sembok <ref> [SR90] </ref> argue that the efficiency of keyword searching has reached its theoretical limit. Thus, adding structural information in documents and using this extra information for restricting searches provides an interesting alternative to full-text keyword searches. <p> A number of methods involving simple techniques (e.g., word frequencies and co-occurrence characteristics) and complex techniques (e.g., automatic syntactic analysis) have been proposed to perform phrase grouping [SYY75]. In more advanced linguistic approaches (such as in <ref> [SR90] </ref>), semantic translation of natural language is used in document retrieval systems. In this technique, document and query texts are translated into sets of first order predicates which are used as their content indicators or indices.
Reference: [Sri89] <author> P. Srinivasan. </author> <title> Intelligent information retrieval using rough set approxi-matioins. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 25(4) </volume> <pages> 347-361, </pages> <year> 1989. </year>
Reference-contexts: In these methods, a quantity for relevance of a query Q j for a document D i is determined. The result of queries can now be presented in descending order of the relevance probability. Another technique for information retrieval has been proposed using "rough sets." <ref> [Sri89] </ref> This method uses the rough set concept by Pawlak [Paw82]. Index terms are used to create equivalence relations, each equivalence class containing semantically identical (or synonymous) terms.
Reference: [Sri90a] <author> P. Srinivasan. </author> <title> A comparison of two-poisson, inverse document frequency and discrimination value models of document representation. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 26(2) </volume> <pages> 269-278, </pages> <year> 1990. </year>
Reference-contexts: The Poisson Distribution is usually considered to be a good method for identifying how a term is distributed over one or more documents. Commonly used models in this method include the Two-Poisson model (see <ref> [Sri90a] </ref> for a comparison of this model with the inverse document frequency method described above). In this method, the distribution of a term is described by two Poisson distributions, thereby specifying the manner in which an index term differs from a non-index term.
Reference: [Sri90b] <author> P. Srinivasan. </author> <title> On generalizing the two-poisson model. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(1) </volume> <pages> 61-66, </pages> <year> 1990. </year>
Reference-contexts: Attempts at generalizing these models to more than two Poisson distributions have also been Chapter 3. Related Work 49 made <ref> [Sri90b] </ref>. 3.2 Structured Document Databases This section describes approaches taken for query formulation and processing with document collections. As described in an earlier section (Section 1.1.2.2), traditional information retrieval techniques are directed primarily towards unstructured text using indexing techniques involving various linguistic and statistical analysis.
Reference: [Suc97] <editor> D. Suciu, editor. </editor> <booktitle> Proceedings on the Workshop on Semistructured Data, </booktitle> <address> Tucson, Arizona, USA, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: A collection of such recent work can be obtained from <ref> [Suc97] </ref>. Although the object of the current work is to give database support for documents for which the structure is already well-established, the research on semistructured data provides us with the support necessary when we encounter documents that do not follow a well-defined structure.
Reference: [Syb94] <author> Sybase, Inc., </author> <title> Emeryville, CA. SYBASE SQL Server T M Reference Manual: Volume 1. Commands, Functions and Topics, </title> <year> 1994. </year>
Reference-contexts: In the following example (Figure 1), we define a DTD corresponding to a document set containing information on books and publishers (adapted from the pubs2 database that comes with the Sybase T M relational database system <ref> [Syb94, Appendix C] </ref>). &lt;!ELEMENT pubs2 O O (publisher+, author+)&gt; &lt;!ELEMENT publisher - O (pubname, city, state, book+)+&gt; &lt;!ATTLIST publisher pubid ID #REQUIRED&gt; &lt;!ELEMENT (pubname | city | state) - O (#PCDATA)&gt; &lt;!ELEMENT book - O (title, type, price, advance, totalsales, notes, pubdate, contract, authors)&gt; &lt;!ATTLIST book titleid ID #REQUIRED&gt; &lt;!ELEMENT (title|
Reference: [Sys85] <author> Adobe Systems. </author> <title> Postscript language reference manual. </title> <address> Reading, Mass. </address> : <publisher> Addison-Wesley, </publisher> <year> 1985. </year>
Reference-contexts: However, it is practically the only way information can be interchanged between systems and platforms without modification. Although other document formats such as plain text, word processor formats, postscript <ref> [Sys85] </ref>, PDF (portable document format) [BCM96] have been used for document publication and distribution, none of them has been able to deliver the full capability of electronic documents. As discussed in Chapter 1, although plain text is possibly the most portable method of interchanging documents, its applicability is quite limited.
Reference: [SYY75] <author> G. Salton, C.S. Yang, and C.T. Yu. </author> <title> A theory of term importance in automatic text analysis. </title> <journal> Journal of the American Society of Information Science, </journal> <volume> 26(1) </volume> <pages> 33-44, </pages> <year> 1975. </year> <note> BIBLIOGRAPHY 204 </note>
Reference-contexts: Term weights for the indices are calculated from the various factors such as frequency of occurrence of the terms (term frequency) and the inverse document frequency (a measure of the probability of a term occurring in a document) <ref> [SYY75, SB88] </ref>. Chapter 3. Related Work 48 Other ways of automatically selecting terms for indexing purposes includes linguistic and knowledge-based approaches. Common practice includes the use of a thesaurus and phrases. A thesaurus combines the words closely related in meaning into groups. <p> A number of methods involving simple techniques (e.g., word frequencies and co-occurrence characteristics) and complex techniques (e.g., automatic syntactic analysis) have been proposed to perform phrase grouping <ref> [SYY75] </ref>. In more advanced linguistic approaches (such as in [SR90]), semantic translation of natural language is used in document retrieval systems. In this technique, document and query texts are translated into sets of first order predicates which are used as their content indicators or indices.
Reference: [TF86] <author> S.J. Thomas and P.C. Fischer. </author> <title> Nested relational structures. In P.C. </title> <editor> Kanellakis, editor, </editor> <booktitle> Advances in Computing Research III, The Theory of databases, </booktitle> <pages> pages 269-307. </pages> <publisher> JAI Press, </publisher> <year> 1986. </year>
Reference-contexts: This not only makes subsequent query processing difficult, but also makes the schema vastly different from the natural representation of the structure. To get around this problem, various forms of "complex-object" models have been proposed. One of the most prominent complex-object models is the nested relational model <ref> [TF86, AB95] </ref>, in which the attributes in a relation are allowed to be of composite type (e.g., sets, lists or other relations), thus making the actual representation of the data in this model closer to its conceptual structure. <p> The equivalence only holds when we consider a "safe" version of the calculus, in which all variables need to be properly bounded before they can be used in a query. Chapter 2. Context 33 nested relational algebra <ref> [TF86] </ref> that uses operations such as set construction (nest) and set decomposition (unnest) to handle the complex-valued attributes. 2.2.2.2 Structured Query Language (SQL) SQL [SQL86a] has been the standard query language for relational databases for over ten years.
Reference: [Tic85] <author> Walter F. Tichy. </author> <title> Rcs a system for version control. </title> <journal> Software Practice & Experience, </journal> <volume> 15(7) </volume> <pages> 637-654, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: One essential feature of a document repository is the ability to track versions of different documents. This is even more important when multiple users are given the task of authoring the same document. Revision tracking mechanisms for program code and plain text authoring systems (such as RCS <ref> [Tic85] </ref>) are often not powerful enough to track revisions on structured documents. Systems like SGML Editor from Grif S.A. (http://www.grif.fr) have been designed to track revisions between the actual document structures, not just the text. Chapter 4. Objectives and Requirements 69 * Integrated authoring and database functionality.
Reference: [Ull88] <author> Jeffrey D. Ullman. </author> <booktitle> Principles of Database and Knowledge-Base Systems, </booktitle> <volume> volume Vol 1. </volume> <publisher> Computer Science Press, </publisher> <address> Rockvill, MD, </address> <year> 1988. </year>
Reference-contexts: The evolution of database systems is marked by three generations of database systems and models. <ref> [Ull88] </ref> First generation database systems included the hierarchical and network data models. These models were strongly influenced by the physical implementation of the data and used pointers and links for storage and retrieval. <p> However, flattening a complex structure introduces redundancy in the data and also introduces the possibility of anomalies (such as insertion, deletion and update anomalies) resulting from database operations <ref> [Ull88, Chapter 7] </ref>. To avoid these anomalies, the flat schema is fragmented into a set of smaller relations. This process of breaking a schema into multiple flat relations is called normalization. <p> Equivalence of Relational Query Languages One important property of the two relational languages is that they have the same expressive power. It can be formally proved that any query expressed in relational calculus 2 has an equivalent relational algebra query and vice-versa <ref> [Ull88] </ref>. Other query languages such as SQL, which we describe later (in Section 2.2.2.2), are also designed to implement all queries of relational calculus with carefully controlled extensions. <p> To achieve this information hiding, the design of any database system involves multiple levels of abstraction. A standard way of leveled design includes three levels of abstraction: (1) physical, (2) conceptual and (3) external (views), as shown in Figure 9 <ref> [Ull88, Chapter 1] </ref>. At the topmost external or view level, users interact with different "views" of the data presented to them by the system. This level provides the possibility of creating views or subschemes.
Reference: [Uni93] <institution> University of Wisconsin, Madison. Using the Exodus Storage Manager V3.1, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: A server having the essential functionality of a storage manager (e.g., concurrency control, recovery) runs continuously and waits for connections from clients. Clients attempting to perform storage management tasks send requests to the server as necessary. In DocBase, the storage management functions are implemented using Exodus <ref> [CDF + 86, Uni93] </ref>, a popular storage manager developed at the University of Wisconsin. Exodus has a client-server architecture; it acts as a server for DocBase, which is an application built using the library of functions provided by the Exodus Application Programming Interface (API).
Reference: [W3C97] <author> W3C. </author> <note> Extensible Markup Language (XML) W3C Working Draft 07-Aug-97, August 7 1997. Available on-line from http://www.w3.org/TR/WD-xml-lang. </note>
Reference-contexts: Moreover, HTML has already been incorporated as an SGML DTD [BLC95], so the current research can be easily applied for building complex SQL-capable search engines for the Internet. * XML Search Engines. With the advent of XML <ref> [W3C97] </ref>, custom user-defined tags are becoming standard. This work has the advantage of using structured documents in their native format and process queries based on tags in the documents. Moreover, XML has been proposed as a subset of SGML and backwards compatible to HTML.
Reference: [WW90] <author> Thomas H. Wonnacott and Ronald J. Wonnacott. </author> <title> Introductory Statistics. </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: We used a statistical measure to determine whether or not the data gathered had enough information to sufficiently support any claim for significance. A common statistical method used in determining significance results is ANOVA or Analysis of Variance (for an introduction to ANOVA, see <ref> [WW90, Chapter 10] </ref>). The ANOVA technique analyzes variance within samples and provides a method for determining whether two or more samples showing significant difference based on one factor (simple ANOVA) or multiple factors (multivariate ANOVA).
Reference: [Zha95] <author> Jian Zhang. </author> <title> Oodb and sgml techniques in text database: An electronic dictionary system. </title> <booktitle> SIGMOD RECORD, </booktitle> <volume> 24(1) </volume> <pages> 3-8, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: It is extremely difficult to model hierarchically structured documents using relational databases since the flat structure of the relational model causes excessive fragmentation in the document structure. Complex object and Object-oriented databases seem to better match document structures, and a significant number of efforts <ref> [CACS94, Zha95, Hol95, D'A95] </ref> have been devoted towards mapping SGML documents in an Object-oriented or Object-Relational database and using the database for processing the queries. <p> This procedure is prone to loss of information contained in the original SGML documents, when any advanced SGML feature (e.g., marked sections, Chapter 3. Related Work 51 CONCUR, SUBDOC) is used. A recent work by Zhang <ref> [Zha95] </ref> for building a dictionary system using an object-oriented database system can also be classified under this category. 3.2.1.2 Grammar-based Approach This approach involves describing the database schema using Context Free Grammars (CFGs) or Attribute Grammars [Knu68].
Reference: [Zlo77] <author> M. M. Zloof. </author> <title> Query by example: A database language. </title> <journal> IBM Systems Journal, </journal> <volume> 16(4), </volume> <year> 1977. </year>
Reference-contexts: The second generation also witnessed better theoretical foundations in database models and query languages and better visual query formulation using the QBE (Query By Example) query language <ref> [Zlo77] </ref>. The Entity-Relationship (ER) Model [Che76], also introduced during this generation, better supported conceptual modeling of data, from which the database schema could be conveniently generated. <p> Design of a generalized visual language for query formulation. In spite of all the advances in graphics and visualization, interfaces for querying databases are still limited to forms. This dissertation proposes a query interface based on QBE (Query By Example) <ref> [Zlo77] </ref> that simplifies the querying process and, at the same time, incorporates most of the power in the query language referred to above. 4. Design of a query processing infrastructure for document databases:. <p> Chapter 2. Context 34 2.2.2.3 Query By Example (QBE) Query By Example <ref> [Zlo77] </ref> is a high-level visual language that provides the user with a unified interface to query and update relational databases. This language has a simple interface composed of tabular skeletons representing tables in the database. Users specify queries by entering sample values in appropriate areas of the table skeleton. <p> As illustrated earlier, users express their queries by indicating the search keywords in the appropriate regions of the template. In this section, we show all the different types of possible searches that can be performed with QBT. One can treat QBE <ref> [Zlo77] </ref> as a special case of QBT where the templates used are table skeletons that instantiate tables in the database. In QBE, queries are specified by entering values in proper positions of the tables. <p> Although QBE uses two-dimensional tables for querying, the meta-data (attributes of the relations) only appear along the horizontal axis as column headings of the tables. QBE uses the rows along the vertical axis to specify multiple search conditions and logical operations between the search conditions (see examples in <ref> [Zlo77] </ref>). In QBT, the regions (meta-data) are distributed along both dimensions of the template, utilizing the whole template plane for visualizing the structure. Logical operations between regions can be expressed by physically connecting two or more regions via a logical operator.
References-found: 91

