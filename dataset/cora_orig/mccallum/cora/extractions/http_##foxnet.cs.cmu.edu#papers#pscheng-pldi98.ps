URL: http://foxnet.cs.cmu.edu/papers/pscheng-pldi98.ps
Refering-URL: http://foxnet.cs.cmu.edu/papers.html
Root-URL: 
Email: pscheng@cs.cmu.edu.  
Title: Generational Stack Collection and Profile-Driven Pretenuring  
Author: Perry Cheng Robert Harper Peter Lee 
Note: The primary author may be contacted at  
Address: 5000 Forbes Avenue Pittsburgh, PA 15213-3891  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: This paper presents two techniques for improving garbage collection performance: generational stack collection and profile-driven pretenuring. The first is applicable to stack-based implementations of functional languages while the second is useful for any generational collector. We have implemented both techniques in a generational collector used by the TIL compiler (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996), and have observed decreases in garbage collection times of as much as 70% and 30%, respectively. Functional languages encourage the use of recursion which can lead to a long chain of activation records. When a collection occurs, these activation records must be scanned for roots. We show that scanning many activation records can take so long as to become the dominant cost of garbage collection. However, most deep stacks unwind very infrequently, so most of the root information obtained from the stack remains unchanged across successive garbage collections. Generational stack collection greatly reduces the stack scan cost by reusing information from previous scans. Generational techniques have been successful in reducing the cost of garbage collection (Ungar 1984). Various complex heap arrangements and tenuring policies have been proposed to increase the effectiveness of generational techniques by reducing the cost and frequency of scanning and copying. In contrast, we show that by using profile information to make lifetime predictions, pretenuring can avoid copying data altogether. In essence, this technique uses a refinement of the generational hypothesis (most data die young) with a locality principle concerning the age of data: most allocations sites produce data that immediately dies, while a few allocation sites consistently produce data that survives many collections. This research was sponsored in part by the Advanced Research Projects Agency CSTO under the title "The Fox Project: Advanced Languages for Systems Software," ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. The views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies, either expressed or implied, of the Advanced Research Projects Agency or the U.S. Government. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aiken, A., M. Fahndrich, and R. </author> <title> Levien (1995). Better static memory management: Improving region-based analysis of higher-order languages. </title> <type> Technical Report CSD-95-866, </type> <institution> University of California at Berkeley. </institution>
Reference: <author> Allen, F. and J. </author> <title> Cocke (1970). A program data flow analysis procedure. </title> <booktitle> In Communications of the ACM, </booktitle> <pages> pp. 137-147. </pages>
Reference: <author> Appel, A. W. </author> <year> (1989, </year> <month> February). </month> <title> Simple generational garbage collection and fast allocation. </title> <booktitle> In Software Practice and Experience, </booktitle> <pages> pp. 171-183. </pages>
Reference-contexts: Large arrays are not allocated in the nursery and promoted to the tenured area; instead, they reside in a region managed by a mark-sweep algorithm. Finally, we use a simple write barrier technique, a sequential store buffer <ref> (Appel 1989) </ref>, to handle pointer updates that may create intergenerational references. fl 2.2 TIL TIL (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996) is an optimizing compiler for Standard ML (SML) that exploits several key technologies: intensional polymorphism, fl If a reference from an older generation is created to a younger <p> using iterators 10,000 times FFT 246 Fast Fourier transform, multiplying polynomials up to degree 65,536 Color 110 Brute-force graph coloring Grobner 904 Compute Grobner basis of a set of polynomials up to degree 7 (Yan 1996) Knuth-Bendix 618 An implementation of the Knuth-Bendix completion algorithm Lexgen 1123 A lexical-analyzer generator <ref> (Appel, Mattson, and Tarditi 1989) </ref>, processing the lexical description of Standard ML Life 146 The game of Life implemented using lists (Reade 1989) Peg 458 Solving a peg-jumping game, using the output of a Prolog to ML transla tor (Hornof 1992) Nqueen 73 The N-queens problem for n=10 PIA 2065 The
Reference: <author> Appel, A. W. </author> <year> (1992). </year> <title> Compiling with Continuations. </title> <address> Cambridge, Massachusetts: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: The particular machine used has 96MB of main memory and runs OSF/1 v2.0. The sampled data is taken from runs of eleven SML (Mil-ner, Tofte, and Harper 1990) programs (many are de facto standard benchmarks <ref> (Appel 1992) </ref>) compiled with TIL. Table 1 describes the benchmark programs, which range in size from 73 lines to about 2000 lines of code. They cover a range of application areas including scientific computing, list-processing, systems programming, and compilers. <p> Further, in a compiler that supports callee-save registers, the state of the registers cannot be determined from the most recent frame. Thus, either a generational technique like the one presented here would have to be added or the mutator must bear some runtime cost by maintaining a mask register <ref> (Appel 1992) </ref>.
Reference: <author> Appel, A. W., J. S. Mattson, and D. </author> <title> Tarditi (1989). A lexical analyzer generator for Standard ML. Distributed with Standard ML of New Jersey. </title>
Reference-contexts: Large arrays are not allocated in the nursery and promoted to the tenured area; instead, they reside in a region managed by a mark-sweep algorithm. Finally, we use a simple write barrier technique, a sequential store buffer <ref> (Appel 1989) </ref>, to handle pointer updates that may create intergenerational references. fl 2.2 TIL TIL (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996) is an optimizing compiler for Standard ML (SML) that exploits several key technologies: intensional polymorphism, fl If a reference from an older generation is created to a younger <p> using iterators 10,000 times FFT 246 Fast Fourier transform, multiplying polynomials up to degree 65,536 Color 110 Brute-force graph coloring Grobner 904 Compute Grobner basis of a set of polynomials up to degree 7 (Yan 1996) Knuth-Bendix 618 An implementation of the Knuth-Bendix completion algorithm Lexgen 1123 A lexical-analyzer generator <ref> (Appel, Mattson, and Tarditi 1989) </ref>, processing the lexical description of Standard ML Life 146 The game of Life implemented using lists (Reade 1989) Peg 458 Solving a peg-jumping game, using the output of a Prolog to ML transla tor (Hornof 1992) Nqueen 73 The N-queens problem for n=10 PIA 2065 The
Reference: <author> Barrett, D. and B. </author> <title> Zorn (1993). Using lifetime predictors to improve memory allocation performance. </title> <booktitle> In ACM Programming Languages Design and Implementation (PLDI), </booktitle> <pages> pp. 187-196. </pages>
Reference-contexts: Zorn investigated the GC cost of eight large programs using a commercial Common Lisp system and found that simulated GC times should be between 10% to 20% (Zorn 1989). Barrett and Zorn <ref> (Barrett and Zorn 1993) </ref> used lifetime predictors to improve memory overhead and reference locality in the context of explicit memory management. They also studied a mechanism that allows effective reclamation of tenured garbage through a process of untenuring (Barrett and Zorn 1995). <p> The usefulness of heap pretenuring rests largely on the predictability of object lifetimes based on allocation sites. Barrett and Zorn observed this predictability for four substantial C programs in <ref> (Barrett and Zorn 1993) </ref>. One might speculate that this condition is more likely to hold for languages that allocate heavily such as Haskell, LISP, and Java.
Reference: <author> Barrett, D. and B. </author> <title> Zorn (1995). Garbage collection using a dynamic threatening boundary. </title> <booktitle> In ACM SIGPLAN, </booktitle> <pages> pp. 301-314. </pages>
Reference-contexts: Barrett and Zorn (Barrett and Zorn 1993) used lifetime predictors to improve memory overhead and reference locality in the context of explicit memory management. They also studied a mechanism that allows effective reclamation of tenured garbage through a process of untenuring <ref> (Barrett and Zorn 1995) </ref>. Diwan and Tarditi (Tarditi and Diwan 1994) found the overall cost of automatic storage management under SML/NJ to be between 22% to 40%. They found that allocation and root processing can be a significant fraction of the total cost.
Reference: <author> Biagioni, E., R. Harper, P. Lee, and B. </author> <title> Milnes (1994). Signatures for a network protocol stack: A systems application of Standard ML. </title> <booktitle> In LFP, </booktitle> <pages> pp. 55-64. </pages>
Reference-contexts: Program lines Description Checksum 241 Checksum fragment from the Foxnet <ref> (Biagioni, Harper, Lee, and Milnes 1994) </ref>, 16Kb possibly unaligned arrays are created and checksummed using iterators 10,000 times FFT 246 Fast Fourier transform, multiplying polynomials up to degree 65,536 Color 110 Brute-force graph coloring Grobner 904 Compute Grobner basis of a set of polynomials up to degree 7 (Yan 1996) Knuth-Bendix
Reference: <author> Birkedal, L., M. Tofte, and M. </author> <month> Vejlstrup </month> <year> (1996). </year> <title> From region inference to von neumann machines via region representation inference. </title> <booktitle> In Proc. of Principles of Programming Languages (POPL). </booktitle>
Reference: <author> Cheney, C. </author> <year> (1970). </year> <title> A nonrecursive list compacting algorithm. </title> <booktitle> In Communication of the ACM, </booktitle> <pages> pp. 677-678. </pages> <month> DEC </month> <year> (1994a). </year> <title> DEC 3000 300/400/500/600/700/800/900 AXP Models: System Programmer's Manual. </title> <institution> May-nard, Massachusetts: Digital Equipment Corporation. </institution> <month> DEC </month> <year> (1994b). </year> <institution> DECchip 21064 and DECchip 21064A Alpha AXP Microprocessors. Maynard, Massachusetts: Digital Equipment Corporation. </institution>
Reference-contexts: The area vacated by the live data is known to contain only garbage and may be reclaimed. A simple kind of copying garbage collector is the semispace collector (Fenichel and Yochelson 1969) using Cheney's algorithm <ref> (Cheney 1970) </ref>. Unfortunately, semispace collectors cannot usually attain efficient memory usage and good performance.(Ungar 1984) Using the observation that most objects die quickly (Ungar 1984), generational collectors can arrange heap areas and schedule collections to improve performance. Generational collection successfully reduces the cost of copying data. <p> Finally, the hardware, the benchmarks, and the measurement techniques are given. 2.1 Semispace and Generational Collection Our semispace collector (Fenichel and Yochelson 1969) uses Cheney's copy algorithm <ref> (Cheney 1970) </ref>. The resizing strategy is parameterized over a target liveness ratio r. In particular, if the liveness ratio after a collection was r 0 , then the heap is resized by the factor r 0 =r. In our tests, a target ratio value of r = 0:10 was used.
Reference: <author> Ekanadham, K. </author> <title> and Arvind (1987). SIMPLE: An exercise in future scientific programming. Technical Report Computation Structures Group Memo 273, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> July </month> <year> 1987. </year> <note> Simultaneously published as IBM/T. J. </note> <institution> Watson Research Center Research Report 12686, Yorktown Heights, NY. </institution>
Reference-contexts: a peg-jumping game, using the output of a Prolog to ML transla tor (Hornof 1992) Nqueen 73 The N-queens problem for n=10 PIA 2065 The Perspective Inversion Algorithm (Waugh, McAndrew, and Michaelson 1990) deciding the location of an object in a perspective video image Simple 870 A spherical fluid-dynamics program <ref> (Ekanadham and Arvind 1987) </ref>, run for 4 iterations with grid size of 200.
Reference: <author> Fateman, R. </author> <year> (1983, </year> <month> August). </month> <title> Garbage collection overhead. Provate communication. </title> <editor> cited in D. Un-gar, </editor> <title> The Design and Evaluation of a High Performance Smalltalk System, </title> <type> Ph.D. Thesis, </type> <institution> UC Merkeley, </institution> <address> UCN/CSE 86/287, </address> <month> March </month> <year> 1986. </year>
Reference-contexts: Underestimations of the correct generation would lead to extra data copying while overestimations would lead to overtenuring (which unnecessarily ties up memory until the next sufficiently major collection). 8 Related Work Fateman found that some Franz Lisp programs spend from 25% to 40% of their time in garbage collection <ref> (Fateman 1983) </ref>. Of the 300 or so combinations of LISP systems and benchmarks that could report GC times, the average was 38%. Ungar (Ungar 1984) showed the effectiveness of generational garbage collection in reducing pause times and improving overall performance.
Reference: <author> Fenichel, R. R. and J. C. </author> <title> Yochelson (1969). A LISP garbage-collector for virtual memory computer systems. </title> <booktitle> In Communications of the ACM, </booktitle> <pages> pp. 4611-612. </pages>
Reference-contexts: The area vacated by the live data is known to contain only garbage and may be reclaimed. A simple kind of copying garbage collector is the semispace collector <ref> (Fenichel and Yochelson 1969) </ref> using Cheney's algorithm (Cheney 1970). Unfortunately, semispace collectors cannot usually attain efficient memory usage and good performance.(Ungar 1984) Using the observation that most objects die quickly (Ungar 1984), generational collectors can arrange heap areas and schedule collections to improve performance. <p> The explanation of tracing the stack will reinforce the notion that scanning the stack is relatively costly as a result of the optimizing technology. Finally, the hardware, the benchmarks, and the measurement techniques are given. 2.1 Semispace and Generational Collection Our semispace collector <ref> (Fenichel and Yochelson 1969) </ref> uses Cheney's copy algorithm (Cheney 1970). The resizing strategy is parameterized over a target liveness ratio r. In particular, if the liveness ratio after a collection was r 0 , then the heap is resized by the factor r 0 =r.
Reference: <author> Hornof, L. </author> <year> (1992, </year> <month> May). </month> <title> Compiling Prolog to Standard ML: Some optimizations. </title> <type> Undergraduate honors thesis, </type> <institution> Carnegie Mellon University. </institution> <note> Available as Technical Report CMU-CS-92-166, </note> <month> September </month> <year> 1992. </year>
Reference-contexts: implementation of the Knuth-Bendix completion algorithm Lexgen 1123 A lexical-analyzer generator (Appel, Mattson, and Tarditi 1989), processing the lexical description of Standard ML Life 146 The game of Life implemented using lists (Reade 1989) Peg 458 Solving a peg-jumping game, using the output of a Prolog to ML transla tor <ref> (Hornof 1992) </ref> Nqueen 73 The N-queens problem for n=10 PIA 2065 The Perspective Inversion Algorithm (Waugh, McAndrew, and Michaelson 1990) deciding the location of an object in a perspective video image Simple 870 A spherical fluid-dynamics program (Ekanadham and Arvind 1987), run for 4 iterations with grid size of 200.
Reference: <author> Jones, R. and R. </author> <title> Lins (1996). Garbage Collection: Algorithms for Automatic Dynamic Memory Management. </title> <address> New York, NY: </address> <publisher> John Wiley and Sons. </publisher>
Reference: <author> Kennedy, K. </author> <year> (1981). </year> <title> A survey of data flow analysis techniques. </title> <editor> In S. Munchnick and N. Jones (Eds.), </editor> <title> Program Flow Analysis: </title> <booktitle> Theory and Applications, </booktitle> <pages> pp. 5-54. </pages> <publisher> Prentice-Hall. </publisher>
Reference: <author> Knuth, D. </author> <year> (1969). </year> <booktitle> The Art of Computer Programming, </booktitle> <volume> Vol. 1: </volume> <booktitle> Fundamental Algorithms. </booktitle> <address> Reading, Mas-sachusetts: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> McCarthy, J. </author> <year> (1960). </year> <title> Recursive funtions of symbolic expressions and their computation by machine. </title> <booktitle> In Communications of the ACM, </booktitle> <pages> pp. 184-195. </pages>
Reference: <author> Milner, R., M. Tofte, and R. </author> <title> Harper (1990). The Defini--tion of Standard ML. </title> <address> Cambridge, Massachusetts: </address> <publisher> The MIT Press. </publisher>
Reference: <author> Reade, C. </author> <year> (1989). </year> <title> Elements of Functional Programming. </title> <address> Reading, Massachusetts: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: 904 Compute Grobner basis of a set of polynomials up to degree 7 (Yan 1996) Knuth-Bendix 618 An implementation of the Knuth-Bendix completion algorithm Lexgen 1123 A lexical-analyzer generator (Appel, Mattson, and Tarditi 1989), processing the lexical description of Standard ML Life 146 The game of Life implemented using lists <ref> (Reade 1989) </ref> Peg 458 Solving a peg-jumping game, using the output of a Prolog to ML transla tor (Hornof 1992) Nqueen 73 The N-queens problem for n=10 PIA 2065 The Perspective Inversion Algorithm (Waugh, McAndrew, and Michaelson 1990) deciding the location of an object in a perspective video image Simple 870
Reference: <author> Rojemo, N. and C. </author> <title> Runciman (1996). Lag, drag, void and use heap profiling and space-efficient compilation revisited. </title> <booktitle> In ACM SIGPLAN International Conference on Functional Programming, </booktitle> <pages> pp. 34-41. </pages>
Reference-contexts: Diwan and Tarditi (Tarditi and Diwan 1994) found the overall cost of automatic storage management under SML/NJ to be between 22% to 40%. They found that allocation and root processing can be a significant fraction of the total cost. Rojemo and Runciman <ref> (Rojemo and Runciman 1996) </ref> used heap profiling to study the the lifetime behavior of data in the context of Haskell.
Reference: <author> Shaw, R. </author> <year> (1988, </year> <month> February). </month> <title> Empirical Analysis of a LISP System. </title> <type> Ph. D. thesis, </type> <institution> Stanford University. </institution>
Reference-contexts: Ungar (Ungar 1984) showed the effectiveness of generational garbage collection in reducing pause times and improving overall performance. Shaw analyzed extensively four programs running on a commercial Common Lisp system and found that generation checks alone can cost as much as 15% of total execution time <ref> (Shaw 1988) </ref>. Zorn investigated the GC cost of eight large programs using a commercial Common Lisp system and found that simulated GC times should be between 10% to 20% (Zorn 1989).
Reference: <author> Shivers, O. </author> <year> (1991, </year> <month> May). </month> <title> Control Flow Analysis of Higher Order Languages. </title> <type> Ph. D. thesis, </type> <institution> Carnegie Mellon University. </institution>
Reference-contexts: Some useful techniques that may help with this problem are region inference (Tofte and Talpin 1993; Tofte and Talpin 1994; Aiken, Fahndrich, and Levien 1995; Birkedal, Tofte, and Vejlstrup 1996), dataflow analysis (Allen and Cocke 1970; Kennedy 1981), and control flow analysis <ref> (Shivers 1991) </ref>. For the remaining objects which may point to the nursery, another optimization is possible. We pretenure data from different allocation sites into separate areas. Then, some areas may require no scanning because they contain no pointers. Other areas may permit specialized scans.
Reference: <author> Sobalvarro, P. </author> <year> (1988, </year> <month> February). </month> <title> A lifetime-based garbage collector for LISP systems on general-purpose computers. </title> <type> Master's thesis, </type> <institution> MIT. </institution>
Reference-contexts: This is quite apparent from the last column of Table 2 which shows Peg having 4 orders of magnitude more updates than any other benchmark. The simple sequential store list records a mutated site repeatedly, causing a great overhead in root processing. A more realistic approach such as card-marking <ref> (Sobalvarro 1988) </ref> would probably ameliorate most of the problems. As for Knuth-Bendix, Color, and Lexgen, all three are characterized by deep stacks and will be analyzed in section 5.
Reference: <author> Tarditi, Morrisett, Cheng, Stone, Harper, and Lee (1996). </author> <title> TIL: A type-directed optimizing compiler for ML. </title> <booktitle> In ACM Programming Languages Design and Implementation (PLDI), </booktitle> <pages> pp. 181-192. </pages>
Reference-contexts: Finally, we use a simple write barrier technique, a sequential store buffer (Appel 1989), to handle pointer updates that may create intergenerational references. fl 2.2 TIL TIL <ref> (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996) </ref> is an optimizing compiler for Standard ML (SML) that exploits several key technologies: intensional polymorphism, fl If a reference from an older generation is created to a younger generation with a pointer update, then simply collecting the younger generation could lead to a <p> Roots are directly accessible values such as registers and stack slots. The difficulty with accurately determining the root set stems from the presence of callee-save registers and poly-morphism <ref> (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996) </ref>. First, with callee-save registers, the contents of a register or stack slot may come from caller frames so stack frames cannot be decoded in isolation.
Reference: <author> Tarditi, D. and A. </author> <title> Diwan (1994). Measuring the cost of storage management. </title> <type> Technical Report CMU-CS-94-201, </type> <institution> Carnegie Mellon University. </institution>
Reference-contexts: The heap resizing policy for the tenured generation is based on deviations from a preset target liveness ratio of 0.3. The nursery is never made larger than the secondary cache (512K for our setup), following the advice of several researchers including Diwan and Tarditi <ref> (Tarditi and Diwan 1994) </ref>. For benchmarking reasons, the nursery is sometimes made significantly smaller. At each minor collection, we immediately promote all live objects from the nursery to the tenured generation. <p> Barrett and Zorn (Barrett and Zorn 1993) used lifetime predictors to improve memory overhead and reference locality in the context of explicit memory management. They also studied a mechanism that allows effective reclamation of tenured garbage through a process of untenuring (Barrett and Zorn 1995). Diwan and Tarditi <ref> (Tarditi and Diwan 1994) </ref> found the overall cost of automatic storage management under SML/NJ to be between 22% to 40%. They found that allocation and root processing can be a significant fraction of the total cost.
Reference: <author> Tofte, M. and J.-P. </author> <month> Talpin </month> <year> (1993, </year> <month> July). </month> <title> A theory of stack allocation in polymorphically typed languages. </title> <institution> Technical Report Computer Science 93/15, University of Copenhagen. </institution>
Reference: <author> Tofte, M. and J.-P. </author> <title> Talpin (1994). Implementation of the typed call-by-value -calculus using a stack of regions. </title> <booktitle> In Proc. of Principles of Programming Languages (POPL). </booktitle>
Reference: <author> Ungar, D. M. </author> <year> (1984). </year> <title> Generation scavenging: A nondisruptive high-performance storage reclamation algorithm. </title> <booktitle> In ACM SIGSOFT/SIGPLAN, </booktitle> <pages> pp. 157-167. </pages>
Reference-contexts: A simple kind of copying garbage collector is the semispace collector (Fenichel and Yochelson 1969) using Cheney's algorithm (Cheney 1970). Unfortunately, semispace collectors cannot usually attain efficient memory usage and good performance.<ref> (Ungar 1984) </ref> Using the observation that most objects die quickly (Ungar 1984), generational collectors can arrange heap areas and schedule collections to improve performance. Generational collection successfully reduces the cost of copying data. However, for programs with deep call chains, the cost of scanning the stack for roots can be high. <p> In particular, if the liveness ratio after a collection was r 0 , then the heap is resized by the factor r 0 =r. In our tests, a target ratio value of r = 0:10 was used. The generational collector we use is similar to the one used in <ref> (Ungar 1984) </ref>. There are many parameters that can be explored with generational collection. For simplicity, our collector has two generations, a nursery and a tenured generation. The heap resizing policy for the tenured generation is based on deviations from a preset target liveness ratio of 0.3. <p> Of the 300 or so combinations of LISP systems and benchmarks that could report GC times, the average was 38%. Ungar <ref> (Ungar 1984) </ref> showed the effectiveness of generational garbage collection in reducing pause times and improving overall performance. Shaw analyzed extensively four programs running on a commercial Common Lisp system and found that generation checks alone can cost as much as 15% of total execution time (Shaw 1988).
Reference: <author> Waugh, K. G., P. McAndrew, and G. </author> <title> Michaelson (1990, August). Parallel implementations from function prototypes: a case study. </title> <institution> Technical Report Computer Science 90/4, Heriot-Watt University, Edinburgh. </institution>
Reference-contexts: 1989), processing the lexical description of Standard ML Life 146 The game of Life implemented using lists (Reade 1989) Peg 458 Solving a peg-jumping game, using the output of a Prolog to ML transla tor (Hornof 1992) Nqueen 73 The N-queens problem for n=10 PIA 2065 The Perspective Inversion Algorithm <ref> (Waugh, McAndrew, and Michaelson 1990) </ref> deciding the location of an object in a perspective video image Simple 870 A spherical fluid-dynamics program (Ekanadham and Arvind 1987), run for 4 iterations with grid size of 200.
Reference: <author> Wilson, P. </author> <year> (1994). </year> <title> Uniprocessor garbage collection techniques. </title> <type> In Technical report, </type> <institution> University of Texas. </institution> <note> Expanded version to appear in ACM Computing Surveys. </note>
Reference-contexts: They found that allocation and root processing can be a significant fraction of the total cost. Rojemo and Runciman (Rojemo and Runciman 1996) used heap profiling to study the the lifetime behavior of data in the context of Haskell. Wilson <ref> (Wilson 1994) </ref> pointed out the importance of keeping root scanning costs low in incremental garbage collection techniques. 9 Conclusions and Future Work Generally, even a simple generational collector outperforms a semispace collector by a factor of two or more in terms of z generated by monomorphic code garbage collection time, often
Reference: <author> Yan, T. </author> <year> (1996). </year> <title> Grobner basis computation. </title> <type> Personal communications. </type>
Reference-contexts: the Foxnet (Biagioni, Harper, Lee, and Milnes 1994), 16Kb possibly unaligned arrays are created and checksummed using iterators 10,000 times FFT 246 Fast Fourier transform, multiplying polynomials up to degree 65,536 Color 110 Brute-force graph coloring Grobner 904 Compute Grobner basis of a set of polynomials up to degree 7 <ref> (Yan 1996) </ref> Knuth-Bendix 618 An implementation of the Knuth-Bendix completion algorithm Lexgen 1123 A lexical-analyzer generator (Appel, Mattson, and Tarditi 1989), processing the lexical description of Standard ML Life 146 The game of Life implemented using lists (Reade 1989) Peg 458 Solving a peg-jumping game, using the output of a Prolog
Reference: <author> Zorn, B. </author> <year> (1989, </year> <month> December). </month> <title> Comparative Performance Evaluation of Garbage Collection Algorithms. </title> <type> Ph. D. thesis, </type> <institution> University of California at Berkeley. </institution>
Reference-contexts: Of course, pointer mutations also break this invariant and we could deal with these new intergener-ational references in the same way. This write barrier approach would be correct but too slow <ref> (Zorn 1989) </ref>. One might suggest relaxing the tenuring condition for such objects so that they are promoted at every minor collection. Unfortunately, particularly for young generations, survival of even one collection indicates long-lived-ness. <p> Zorn investigated the GC cost of eight large programs using a commercial Common Lisp system and found that simulated GC times should be between 10% to 20% <ref> (Zorn 1989) </ref>. Barrett and Zorn (Barrett and Zorn 1993) used lifetime predictors to improve memory overhead and reference locality in the context of explicit memory management. They also studied a mechanism that allows effective reclamation of tenured garbage through a process of untenuring (Barrett and Zorn 1995).
References-found: 33

