URL: http://www.eecs.umich.edu/~shchoi/papers/eaea.ps
Refering-URL: http://www.eecs.umich.edu/~shchoi/resume.html
Root-URL: http://www.cs.umich.edu
Email: E-mail: wkn@sentosa.sas.ntu.ac.sg  E-mail: fshchoi,ravig@eecs.umich.edu  
Title: Lossless and Lossy Data Compression  
Author: Wee Keong Ng Sunghyun Choi Chinya V. Ravishankar 
Address: Avenue, Singapore 639798, SINGAPORE  Ann Arbor, MI 48109-2122  
Affiliation: School of Applied Science, Nanyang Technological University Nanyang  Department of Electrical Engineering and Computer Science The University of Michigan,  
Abstract: Data compression (or source coding) is the process of creating binary representations of data which require less storage space than the original data [7; 14; 15]. Lossless compression is used where perfect reproduction is required while lossy compression is used where perfect reproduction is not possible or requires too many bits. Achieving optimal compression with respect to resource constraints is a difficult problem. For instance, in lossless compression, it has been shown to be NP-complete [13]. In this paper, we present genetic algorithms for performing lossless and lossy compressions respectively on text data and Gaussian-Markov sources. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. C. Bell, J. G. Cleary, I. H. Witten. </author> <title> Text Compression. </title> <publisher> Prentice Hall Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1990. </year> <month> 16 </month>
Reference-contexts: We conclude this paper with a summary of our work and directions for future research. 1 2 Lossless Data Compression Lossless compression arises frequently in the context of textual compression <ref> [1] </ref>. Due to its lossless requirement, the primary paradigm for lossless data compression is string substitution. Frequently occurring strings in the text are detected and substituted by shorter codes to achieve compression. These codes permit perfect reproduction of the original text. <p> Our study showed that in most cases, the genetic approach yields better solutions than the conventional algorithms. With respect to lossless compression, the technique we have examined belongs to a class of techniques called the semi-adaptive compression techniques <ref> [1] </ref>. As part of our future work, we plan to extend the genetic algorithmic approach to completely adaptive compression techniques; these are techniques that build a dictionary incrementally at the same time as coding progresses in one single pass. Many design alternatives remain to be explored.
Reference: [2] <author> K. A. DeJong, W. M. Spears. </author> <title> Using Genetic Algorithms to Solve NP--Complete Problems. </title> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Finding the optimal way to compress data with respect to resource constraints remains one of the most challenging problems in the field of source coding. As genetic algorithms [5, 8] are becoming a widely-used and accepted method for very difficult problems <ref> [2] </ref>, we present a variety of genetic algorithms for performing both lossless and lossy data compressions in this paper. Our presentation is divided into two parts.
Reference: [3] <author> A. Gersho. </author> <title> On the Structure of Vector Quantizers. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> Vol. 28, No. 2, </volume> <pages> pp. 157-166, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: VQ is a lossy source coding technique that maps a sequence of continuous or discrete k-dimensional vectors into a digital sequence suitable for communication over or storage in a digital channel <ref> [3, 6] </ref>. The goal is data compression: to reduce the bit rate so as to minimize communication channel capacity or digital 10 memory requirements while maintaining the necessary fidelity of the data.
Reference: [4] <author> A. Gersho, R. M. Gray. </author> <title> Vector Quantization and Signal Compression. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: This problem is known to be difficult and there are no known closed-form solutions <ref> [4] </ref>. The conventional technique for designing a codebook works through a process of iterative refinements of an initial codebook [10]. A brief description is given in Section 7. This technique does not guarantee optimality, it sometimes yield locally optimal codebooks.
Reference: [5] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Finding the optimal way to compress data with respect to resource constraints remains one of the most challenging problems in the field of source coding. As genetic algorithms <ref> [5, 8] </ref> are becoming a widely-used and accepted method for very difficult problems [2], we present a variety of genetic algorithms for performing both lossless and lossy data compressions in this paper. Our presentation is divided into two parts.
Reference: [6] <author> R. M. Gray. </author> <title> Vector Quantization. </title> <journal> IEEE ASSP Magazine, </journal> <volume> Vol. 1, </volume> <pages> pp. 4-29, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: VQ is a lossy source coding technique that maps a sequence of continuous or discrete k-dimensional vectors into a digital sequence suitable for communication over or storage in a digital channel <ref> [3, 6] </ref>. The goal is data compression: to reduce the bit rate so as to minimize communication channel capacity or digital 10 memory requirements while maintaining the necessary fidelity of the data.
Reference: [7] <author> R. M. Gray. </author> <title> Source Coding Theory. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Massachusetts, </address> <year> 1990. </year>
Reference: [8] <author> J. H. Holland. </author> <title> Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Finding the optimal way to compress data with respect to resource constraints remains one of the most challenging problems in the field of source coding. As genetic algorithms <ref> [5, 8] </ref> are becoming a widely-used and accepted method for very difficult problems [2], we present a variety of genetic algorithms for performing both lossless and lossy data compressions in this paper. Our presentation is divided into two parts.
Reference: [9] <author> D. A. Huffman. </author> <title> A Method for the Construction of Minimum-Redundancy Codes. </title> <booktitle> Proceedings of the I.R.E., </booktitle> <volume> Vol. 40, No. 9, </volume> <pages> pp. 1098-1101, </pages> <year> 1952. </year>
Reference-contexts: Examples of such coding techniques include Huffman coding <ref> [9] </ref> and arithmetic coding [16]. The Huffman tree for dictionary D in Example 1 is shown in Figure 1.
Reference: [10] <author> S. P. Lloyd. </author> <title> Least Squares Quantization in PCM. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> Vol. 28, No. 2, </volume> <pages> pp. 127-135, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: This problem is known to be difficult and there are no known closed-form solutions [4]. The conventional technique for designing a codebook works through a process of iterative refinements of an initial codebook <ref> [10] </ref>. A brief description is given in Section 7. This technique does not guarantee optimality, it sometimes yield locally optimal codebooks. <p> In Sections 7 to 9, we present a genetic algorithm to approximate a solution to the optimal codebook design problem and evaluate its performance. 7 Generalized Lloyd Algorithm A widely used technique for codebook design is the Generalized Lloyd Algorithm (GLA) <ref> [10] </ref> as shown in Figure 3. The algorithm begins with a set of input vectors and an initial codebook. For each input vector, a codeword from the codebook is chosen that yields the minimum distortion.
Reference: [11] <author> W. K. Ng, C. V. Ravishankar. </author> <title> A Preliminary Study of Genetic Data Compression. </title> <booktitle> Proceedings of the 6th International Conference on Genetic Algorithms, </booktitle> <editor> L. Eshelman (ed.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1995. </year>
Reference: [12] <author> W. K. Ng, S. Choi, C. V. Ravishankar. </author> <title> An Evolutionary Approach to Vector Quantizer Design. </title> <booktitle> Proceedings of the 2nd IEEE International Conference on Evolutionary Computing, </booktitle> <address> Perth, Western Australia, </address> <month> November 29-December 1, </month> <year> 1995. </year>
Reference: [13] <author> J. A. Storer, T. G. Szymanski. </author> <title> Data Compression via Textual Substitution. </title> <journal> Journal of the ACM , Vol. </journal> <volume> 29, No. 4, </volume> <pages> pp. 928-951, </pages> <year> 1982. </year>
Reference-contexts: It then performs the actual coding using the dictionary during the second pass. The dictionary affects the compression efficiency because it determine not only which strings in the text to substitute but their lengths as well. Since the construction of an optimal dictionary for a given text is NP-complete <ref> [13] </ref>, optimal text compression is hard. Let A be a finite set of symbols or alphabet . A + is the set of all non-empty, finite strings w = a 1 a 2 a n , n 0, a i 2 A, composed of symbols from A.
Reference: [14] <author> R. Veldhuis. </author> <title> An Introduction to Source Coding. </title> <publisher> Prentice-Hall, </publisher> <address> New York, New York, </address> <year> 1993. </year>
Reference: [15] <author> R. N. Williams. </author> <title> Adaptive Data Compression. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Massachusetts, </address> <year> 1991. </year>
Reference: [16] <author> I. H. Witten, R. M. Neal, J. G. Cleary. </author> <title> Arithmetic Coding for Data Compression. </title> <journal> Communications of the ACM , Vol. </journal> <volume> 30, No. 6, </volume> <pages> pp. 520-540, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: Examples of such coding techniques include Huffman coding [9] and arithmetic coding <ref> [16] </ref>. The Huffman tree for dictionary D in Example 1 is shown in Figure 1.
References-found: 16

