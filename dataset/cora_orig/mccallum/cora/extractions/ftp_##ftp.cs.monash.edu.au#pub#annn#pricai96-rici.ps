URL: ftp://ftp.cs.monash.edu.au/pub/annn/pricai96-rici.ps
Refering-URL: http://www.cs.monash.edu.au/~annn/cv/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: njitnah,annn@cs.monash.edu.au.  
Phone: Tel: (+61) 3 9905 5775  
Title: Belief Network Algorithms: a Study of Performance Using Domain Characterisation  
Author: N. Jitnah, A. E. Nicholson 
Note: Extended Abstract  
Address: 3168, Australia  
Affiliation: Department of Computer Science, Monash University, Clayton, VIC  
Abstract: In this abstract we give an overview of the work described in [15]. Belief networks provide a graphical representation of causal relationships together with a mechanism for probabilistic inference, allowing belief updating based on incomplete and dynamic information. We present a survey of Belief Network belief updating algorithms and propose a domain characterisation system which is used as a basis for algorithm comparison. We give experimental comparative results of algorithm performance using the proposed framework. We show how domain characterisation may be used to predict algorithm performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Beinlich, H. Suermondt, R. Chavez, and G. Cooper. </author> <title> The alarm monitoring system: A case study with two probabilistic inference techniques for belief networks. </title> <booktitle> In Proc. of the 2nd European Conf. on Artificial Intelligence in medicine, </booktitle> <pages> pages 689-693, </pages> <year> 1992. </year>
Reference-contexts: For the set of queried nodes, we record the size of the set with respect to the network size, the distribution of queries, the overall skewness of the CPDs and the total number of states. Implementation and Results A range of problems are defined using various networks (Alarm <ref> [1] </ref> and randomly-generated) and various types of evidence. We compare the time and accuracy of the LW algorithm this range of problems. We also apply some model approximation procedures to the networks and evaluate the performance of LW on the resulting models.
Reference: [2] <author> Homer L. Chin and Gregory F. Cooper. </author> <title> Bayesian belief network inference using simulation. </title> <booktitle> In Uncertainty in Artificial Intelligence 3, </booktitle> <pages> pages 129-147, </pages> <year> 1989. </year>
Reference-contexts: Model Approximation Another approach to complexity reduction is to approximate the model by preprocessing the network. Methods have been proposed which do this by one of the following methods: removal of weak links [10], state-space abstraction [12], replacing small probabilities with zero, graph pruning and node merging <ref> [2] </ref>. These procedures may be applied individually or in combination. It is possible to use such procedures as anytime algorithms to obtain results that improve as more time, memory or information are available. For example we can iteratively replace deleted weak edges and re-evaluate the network.
Reference: [3] <author> Thomas Dean and Michael P. Wellman. </author> <title> Planning and control. </title> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, Ca., </address> <year> 1991. </year>
Reference-contexts: In some sense this use of belief networks handles information that changes over time. More recently researchers have used belief networks in dynamic domains, where the world changes and the focus is reasoning over time <ref> [3, 9, 13, 14] </ref>. For such applications the network grows over time, as the state of each domain variable at different times is represented by a series of nodes. A number of exact and approximate algorithms exist for updating beliefs in Bayesian networks.
Reference: [4] <author> Denise L. Draper and Steve Hanks. </author> <title> Localized partial evaluation of a belief network. </title> <booktitle> In Proceedings of the 10th Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 170-177, </pages> <year> 1994. </year>
Reference-contexts: The convergence rate of simulation algorithms can be improved using certain 1 techniques; for example Markov blanket scoring allows faster convergence of likelihood weighting simulation. Bounding algorithms, such as Localized Partial Evaluation <ref> [4] </ref>, reduce the cost of updating by restricting the problem to its most relevant characteristics and ignoring features whose inclusion would only provide a limited improvement in the accuracy of updated beliefs. Model Approximation Another approach to complexity reduction is to approximate the model by preprocessing the network.
Reference: [5] <author> M. Henrion. </author> <title> Propagating uncertainty in bayesian networks by logic sampling. </title> <editor> In J. Lemmer and L. Kanal, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence Vol 2, </booktitle> <pages> pages 149-163. </pages> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: However, exact updating is too computationally expensive to be useful in most real-life situations. Approximate updating is usually based on stochastic simulation techniques [16] which are less costly than exact methods. The variants include logic sampling <ref> [5] </ref>, likelihood weighting (LW) [17], evidence reversal, survival-of-the-fittest [8] and Markov Chain Monte Carlo methods [6]. The convergence rate of simulation algorithms can be improved using certain 1 techniques; for example Markov blanket scoring allows faster convergence of likelihood weighting simulation.
Reference: [6] <author> M. Hulme. </author> <title> Improved sampling for diagnostic reasoning in bayesian networks. </title> <booktitle> In Proceedings of the Eleventh Conference on Uncertainty in AI, </booktitle> <pages> pages 315-322, </pages> <year> 1995. </year>
Reference-contexts: Approximate updating is usually based on stochastic simulation techniques [16] which are less costly than exact methods. The variants include logic sampling [5], likelihood weighting (LW) [17], evidence reversal, survival-of-the-fittest [8] and Markov Chain Monte Carlo methods <ref> [6] </ref>. The convergence rate of simulation algorithms can be improved using certain 1 techniques; for example Markov blanket scoring allows faster convergence of likelihood weighting simulation.
Reference: [7] <author> Finn Jensen, Steffen Lauritzen, and Kristian Olesen. </author> <title> Bayesian updating in recursive graphical models by local computations. </title> <type> Technical Report R 89-15, </type> <institution> Institute for Electronic Systems, Dept of Mathematics and Computer Scence, University of Aalborg, </institution> <year> 1989. </year>
Reference-contexts: Belief Updating Algorithms Belief updating in singly-connected networks is carried out by the polytree algorithm. For multiply-connected networks, exact updating can be done using clustering, conditioning [16] or the Jensen tree method <ref> [7] </ref>. However, exact updating is too computationally expensive to be useful in most real-life situations. Approximate updating is usually based on stochastic simulation techniques [16] which are less costly than exact methods.
Reference: [8] <author> Koller D. Kanazawa, K. and S. Russell. </author> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <booktitle> In Proceedings of the Eleventh Conference on Uncertainty in AI, </booktitle> <pages> pages 346-351, </pages> <year> 1995. </year>
Reference-contexts: However, exact updating is too computationally expensive to be useful in most real-life situations. Approximate updating is usually based on stochastic simulation techniques [16] which are less costly than exact methods. The variants include logic sampling [5], likelihood weighting (LW) [17], evidence reversal, survival-of-the-fittest <ref> [8] </ref> and Markov Chain Monte Carlo methods [6]. The convergence rate of simulation algorithms can be improved using certain 1 techniques; for example Markov blanket scoring allows faster convergence of likelihood weighting simulation.
Reference: [9] <author> U. Kjrulff. </author> <title> A computational scheme for reasoning in dynamic probabilistic networks. </title> <booktitle> In Proceedings of the 8th Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 121-129, </pages> <year> 1992. </year>
Reference-contexts: In some sense this use of belief networks handles information that changes over time. More recently researchers have used belief networks in dynamic domains, where the world changes and the focus is reasoning over time <ref> [3, 9, 13, 14] </ref>. For such applications the network grows over time, as the state of each domain variable at different times is represented by a series of nodes. A number of exact and approximate algorithms exist for updating beliefs in Bayesian networks.
Reference: [10] <author> U. Kjaerulff. </author> <title> Reduction of computational complexity in bayesian networks through removal of weak dependeces. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in AI, </booktitle> <pages> pages 374-382, </pages> <year> 1994. </year>
Reference-contexts: Model Approximation Another approach to complexity reduction is to approximate the model by preprocessing the network. Methods have been proposed which do this by one of the following methods: removal of weak links <ref> [10] </ref>, state-space abstraction [12], replacing small probabilities with zero, graph pruning and node merging [2]. These procedures may be applied individually or in combination. It is possible to use such procedures as anytime algorithms to obtain results that improve as more time, memory or information are available.
Reference: [11] <author> T.S. Levitt, J. M. Agosta, </author> <title> and T.O. Binford. Model-based influence diagrams for machine vision. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 233-244, </pages> <year> 1989. </year>
Reference-contexts: That is, belief networks can readily handle incomplete information. This evidence is propagated through the network affecting the overall joint distribution (as represented by the conditional probabilities). Belief networks have been been used in various applications, such as medical diagnosis [18] and model-based vision <ref> [11] </ref>, which initially were more static, i.e. essentially the nodes and links do not change over time.
Reference: [12] <author> C. Liu and M. Wellman. </author> <title> On state-space abstraction for anytime evaluation of bayesian networks. </title> <booktitle> In IJCAI 95: Anytime Algorithms and Deliberation Scheduling Workshop, </booktitle> <pages> pages 91-98, </pages> <year> 1995. </year>
Reference-contexts: Model Approximation Another approach to complexity reduction is to approximate the model by preprocessing the network. Methods have been proposed which do this by one of the following methods: removal of weak links [10], state-space abstraction <ref> [12] </ref>, replacing small probabilities with zero, graph pruning and node merging [2]. These procedures may be applied individually or in combination. It is possible to use such procedures as anytime algorithms to obtain results that improve as more time, memory or information are available.
Reference: [13] <author> A. E. Nicholson and J. M. Brady. </author> <title> Dynamic belief networks for discrete monitoring. </title> <journal> IEEE Systems, Man and Cybernetics, </journal> <volume> 24(11), </volume> <year> 1994. </year>
Reference-contexts: In some sense this use of belief networks handles information that changes over time. More recently researchers have used belief networks in dynamic domains, where the world changes and the focus is reasoning over time <ref> [3, 9, 13, 14] </ref>. For such applications the network grows over time, as the state of each domain variable at different times is represented by a series of nodes. A number of exact and approximate algorithms exist for updating beliefs in Bayesian networks.
Reference: [14] <author> A.E. Nicholson. </author> <title> Fall diagnosis using dynamic belief networks. </title> <booktitle> In Proc. of the 4th Pacific Rim International Conf. on Artificial Intelligence (PRICAI-96), </booktitle> <year> 1996. </year>
Reference-contexts: In some sense this use of belief networks handles information that changes over time. More recently researchers have used belief networks in dynamic domains, where the world changes and the focus is reasoning over time <ref> [3, 9, 13, 14] </ref>. For such applications the network grows over time, as the state of each domain variable at different times is represented by a series of nodes. A number of exact and approximate algorithms exist for updating beliefs in Bayesian networks.
Reference: [15] <author> A.E. Nicholson and N. Jitnah. </author> <title> Belief network algorithms: a study of performance using domain characterisation. </title> <type> Technical Report 96/249, </type> <note> in preparation, </note> <institution> Department of Computer Science, Monash University, </institution> <year> 1996. </year>
Reference: [16] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, Ca., </address> <year> 1988. </year>
Reference-contexts: Belief Updating Algorithms Belief updating in singly-connected networks is carried out by the polytree algorithm. For multiply-connected networks, exact updating can be done using clustering, conditioning <ref> [16] </ref> or the Jensen tree method [7]. However, exact updating is too computationally expensive to be useful in most real-life situations. Approximate updating is usually based on stochastic simulation techniques [16] which are less costly than exact methods. <p> For multiply-connected networks, exact updating can be done using clustering, conditioning <ref> [16] </ref> or the Jensen tree method [7]. However, exact updating is too computationally expensive to be useful in most real-life situations. Approximate updating is usually based on stochastic simulation techniques [16] which are less costly than exact methods. The variants include logic sampling [5], likelihood weighting (LW) [17], evidence reversal, survival-of-the-fittest [8] and Markov Chain Monte Carlo methods [6]. <p> We also apply some model approximation procedures to the networks and evaluate the performance of LW on the resulting models. The distance of the updated beliefs to the true posteriors is assessed using the Kullback-Leibler (KL) <ref> [16] </ref> measure. The system is implemented using the Lisp-based IDEAL belief network development environment [19], run on a GNU Common Lisp platform.
Reference: [17] <author> R. Shachter and M. Peot. </author> <title> Simulation approaches to general probabilistic inference on belief networks. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 311-318, </pages> <year> 1989. </year> <note> 3 4 = 0.2. Below: skew = 0.4. 5 </note>
Reference-contexts: However, exact updating is too computationally expensive to be useful in most real-life situations. Approximate updating is usually based on stochastic simulation techniques [16] which are less costly than exact methods. The variants include logic sampling [5], likelihood weighting (LW) <ref> [17] </ref>, evidence reversal, survival-of-the-fittest [8] and Markov Chain Monte Carlo methods [6]. The convergence rate of simulation algorithms can be improved using certain 1 techniques; for example Markov blanket scoring allows faster convergence of likelihood weighting simulation.
Reference: [18] <author> D. Spiegelhalter, R. Franklin, and K. Bull. </author> <title> Assessment criticism and improvement of imprecise subject probabilities for a medical expert system. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 335-342, </pages> <year> 1989. </year>
Reference-contexts: That is, belief networks can readily handle incomplete information. This evidence is propagated through the network affecting the overall joint distribution (as represented by the conditional probabilities). Belief networks have been been used in various applications, such as medical diagnosis <ref> [18] </ref> and model-based vision [11], which initially were more static, i.e. essentially the nodes and links do not change over time.
Reference: [19] <author> Sampath Srinivas and Jack Breese. </author> <title> Ideal: Influence diagram evaluation and analysis in lisp. </title> <type> Technical Report Technical Memorandum No. 23, </type> <institution> Rockwell International Science Center, </institution> <year> 1989. </year> <month> 6 </month>
Reference-contexts: The distance of the updated beliefs to the true posteriors is assessed using the Kullback-Leibler (KL) [16] measure. The system is implemented using the Lisp-based IDEAL belief network development environment <ref> [19] </ref>, run on a GNU Common Lisp platform.
References-found: 19

