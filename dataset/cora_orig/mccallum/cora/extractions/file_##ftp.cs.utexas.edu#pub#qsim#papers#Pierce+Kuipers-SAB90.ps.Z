URL: file://ftp.cs.utexas.edu/pub/qsim/papers/Pierce+Kuipers-SAB90.ps.Z
Refering-URL: http://net.cs.utexas.edu/users/qr/robotics/papers.html
Root-URL: 
Email: (dmpierce@cs.utexas.edu)  (kuipers@cs.utexas.edu)  
Title: Learning Hill-Climbing Functions as a Strategy for Generating Behaviors in a Mobile Robot  
Author: David Pierce Benjamin Kuipers 
Address: Austin, TX 78712  Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  Department of Computer Sciences University of Texas at Austin  
Note: In From Animals to Animats: Proceedings of The First International Conference on Simulation of Adaptive Behavior Cambridge, MA: MIT Press/Bradford Books, 1991.  
Abstract: We consider the problem of a robot with uninterpreted sensors and effectors which must learn, in an unknown environment, behaviors (i.e., sequences of actions) which can be taken to achieve a given goal. This general problem involves a learning agent interacting with a reactive environment: the agent produces actions that affect the environment and in turn receives sensory feedback from the environment. The agent must learn, through experimentation, behaviors that consistently achieve the goal. The difficulty lies in the fact that the robot does not know a priori what its sensors mean, nor what effects its motor apparatus has on the world. We propose a method by which the robot may analyze its sensory information in order to derive (when possible) a function defined in terms of the sensory data which is maximized at the goal and which is suitable for hill-climbing. Given this function, the robot solves its problem by learning a behavior that maximizes the function thereby resulting in motion to the goal.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jones, D.S. </author> <year> (1979). </year> <title> Elementary Information Theory. </title> <publisher> Oxford: Clarendon Press. </publisher>
Reference-contexts: We will represent this object in different ways depending on the context. The actual representation is not important as long as it contains all the information we need. The history may be represented as a function of type 1 HIST = Z + 0 ! <ref> [1; 1] </ref> ns : 0 ; s t ns1 ): Here, h is a function whose value at t is the sense vector seen by the critter at time t. <p> The history may also be represented as a function of type (Z + 0 fi [0 : : : ns 1] ! <ref> [1; 1] </ref>) where h (t; c) gives the value of component c at time t. Thus, for example, h (t; 0) is the value of the at-food or reward sense at time t. <p> In analyzing a sense component, we have found the frequency distribution to be a helpful tool it abstracts away time and reduces a very large history to an object of manageable size. The distribution of a sense component, c, partitions the range of c (i.e., <ref> [1; 1] </ref>) into a number of subintervals (which are called "class intervals" in some statistics texts, and which we will be calling "boxes") and associates with each subinter-val the number of times in the history that the value of component c lay in that subinterval. <p> We will want, for example, to speak of relative frequency distributions where we scale the distribution so that P 1 Some notation: Z + 0 is the set of nonnegative integers. [a; b] is the set of reals between a and b inclusive. <ref> [1; 1] </ref> ns is the set of ns-component vectors whose components are real valued and lie between -1 and 1 inclusive. R + 0 is the set of nonnegative reals. [0 : : : n] is the set of integers between 0 and n inclusive. <p> The operator D is of type HIST ! DIST. We define D c as follows: D c fhg (i) = t b i (h (t; c)) where b i (x) = 0; otherwise Here, box i is the ith subinterval in the distribution's partition of the interval <ref> [1; 1] </ref>. The summation is taken over all values of t for which h is defined. The frequency distribution, as we will see, captures a good deal of useful information about sense components. <p> Thus @ t fhg (t) = h (t) h (t 1); t &gt; 0 A Language for Analyzing Sense Histories Two Basic Data Types History (HIST): h : Z + 0 ! <ref> [1; 1] </ref> ns Dist'n (DIST): p : [0 : : : (nb 1)] ! R + 0 Operators on Histories Time Derivative: @ t : HIST ! HIST Filter: F P : HIST ! HIST Dist'n Operator: D c : HIST ! DIST Operators on Distributions Mean: : DIST ! R <p> P : HIST ! HIST Dist'n Operator: D c : HIST ! DIST Operators on Distributions Mean: : DIST ! R Standard Dev.: : DIST ! R + 0 Division: Q : (DIST fi DIST) ! DIST Miscellaneous Functions Box midpoint: - : [0 : : : (nb 1)] ! <ref> [1; 1] </ref> In-box: b i : [1; 1] ! f0; 1g Threshold: th l : Z ! f0; 1g for analyzing sense histories. The basic data types are the history and the distribution. A history maps time into the space of sense vectors. <p> Operator: D c : HIST ! DIST Operators on Distributions Mean: : DIST ! R Standard Dev.: : DIST ! R + 0 Division: Q : (DIST fi DIST) ! DIST Miscellaneous Functions Box midpoint: - : [0 : : : (nb 1)] ! <ref> [1; 1] </ref> In-box: b i : [1; 1] ! f0; 1g Threshold: th l : Z ! f0; 1g for analyzing sense histories. The basic data types are the history and the distribution. A history maps time into the space of sense vectors. <p> To eliminate components like at-food from consideration in the goal sense vector, we require that a component's range cover a good percentage of the interval <ref> [1; 1] </ref>. For example, the x position sense component takes on values between 0 and 1 and thus its range would have one half the extent of the total interval [1; 1]. <p> from consideration in the goal sense vector, we require that a component's range cover a good percentage of the interval <ref> [1; 1] </ref>. For example, the x position sense component takes on values between 0 and 1 and thus its range would have one half the extent of the total interval [1; 1]. The extent of the at-food component would be very small (or zero, depending on how the extent is defined). With these examples as motivation, we define the measure E in terms of the sense components' distributions of values. <p> The measure P will allow us to determine whether this target value is useful with respect to the goal of being at the food. The conditional probability or expected reward, P, is calculated approximately using a component's overall distribution and its reward distribution. The distributions, remember, divide the interval <ref> [1; 1] </ref> into 100 subintervals or boxes. One of these, the "target box," contains the component's target value. In this calculation, we count the number of samples in the target box and two boxes on each side of it.
Reference: [2] <author> Kuipers, Benjamin, & Byun, </author> <month> Yung-tai </month> <year> (1988). </year> <title> A robust, qualitative method for robot spatial learning. </title> <booktitle> Proc. AAAI-88, St. Paul/Minneapolis, </booktitle> <pages> pp 774-779. </pages>
Reference: [3] <author> McClelland, James L., and Rumelhart, David E. </author> <title> (1988) Explorations in Parallel Distributed Processing. </title> <publisher> Cam-bridge: MIT Press. </publisher>
References-found: 3

