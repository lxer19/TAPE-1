URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/SchLinKroGro94.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: &lt;krose@fwi.uva.nl&gt;  
Title: Predictive Robot Control with Neural Networks  
Author:  G. Schram F.X. van der Linden B.J.A. Krose F.C.A. Groen 
Address: Kruislaan 403, NL-1098 SJ Amsterdam.  
Affiliation: Faculty of Mathematics and Computer Science, University of Amsterdam  
Abstract: Neural controllers are able to position the hand-held camera of the (3DOF) anthropomorphic OSCAR-robot manipulator above an object which is arbitrary placed on a table. The desired camera-joint mapping is approximated by feedforward neural networks. However, if the object is moving, the manipulator lags behind because of the required time to preprocess the visual information and to move the manipulator. Through the use of time derivatives of the position of the object and of the manipulator, the controller can inherently predict the next position of the object. In this paper several `predictive' controllers are proposed, and successfully applied to track a moving object.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Smagt PP van der, </author> <month> Krose BJA </month> <year> (1991). </year> <title> A real-time learning neural robot controller. </title> <booktitle> In Proc. ICANN-91. </booktitle> <editor> Eds Kohonen T, Makisara K, Simula O, Kangas J. </editor> <address> Espoo, Finland. </address> <pages> pp 351-356. </pages>
Reference-contexts: 1 Introduction In <ref> [1] </ref> a real-time learning neural controller is described for the control of the (3DOF) anthropomorphic OSCAR-robot manipulator. An object, which is arbitrary placed on a table, is observed by a hand-held camera. Figure 1 shows a line drawing representation of the robot arm.
Reference: [2] <author> Krose BJA, van der Korst MJ, </author> <month> Groen FCA </month> <year> (1990). </year> <title> Learning strategies for a vision based neural controller for a robot arm. </title> <booktitle> In: IEEE international workshop on intelligent motor control. </booktitle> <editor> Eds Kaynak O. </editor> <booktitle> Istanbul. </booktitle> <pages> pp 199-203. </pages>
Reference-contexts: Figure 1 shows a line drawing representation of the robot arm. In order to position the camera above the object, a feedforward network learns the camera-joint mapping. During operation, learning samples, one for each move, are obtained by the `input-adjustment-method' <ref> [2] </ref>. The learning samples are used to adapt the neural network. The task is restricted to 2D movements with the camera always looking down from a constant altitude. With this restriction just two joints angles, ~ = ( 1 ; 2 ), have to be controlled. <p> In order to build up a set of training samples for the networks, the `input-adjustment-method' <ref> [2] </ref> is used. The idea of the input-adjustment-method is to reconstruct those inputs that should have resulted in the desired performance. Suppose that one of the (not-perfect) networks F 0 , F 1 and F 2 generates the output ~ k at time step k.
Reference: [3] <editor> Smagt PP van der (1994). Simderella: </editor> <title> a robot simulator for neuro-controller design. </title> <journal> Neuro-computing, </journal> <volume> vol 6, no 2. </volume>
Reference-contexts: For the simulations the test-environment `Simderella' is used <ref> [3] </ref>. Two object movements on the table serve as test cases; one follows the `daisy'-trajectory and one a random trajectory. The daisy is a `epicyclical' trajectory: two super posed circular movements.
Reference: [4] <editor> Smagt PP van der (1994). </editor> <title> Minimisation methods for training feed-forward neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> vol 7, no 1. </volume> <pages> pp 1-11. </pages>
Reference-contexts: The weights of the networks are adapted on-line by a conjugate gradient optimisation technique <ref> [4] </ref>. The algorithm is performed over the set of training examples which is build up using the input-adjustment-method. Simulations are done for 1000 moves of the manipulator. Each move lasts 0.5 seconds. The manipulator is in principle fast enough to follow the object.
Reference: [5] <author> Widrow B, </author> <title> Stearns SD (1985), Adaptive Signal Processing. </title> <publisher> Prentice-Hall Inc, </publisher> <address> Englewood Cliffs. </address>
Reference-contexts: F 5 relative to F 3 and for F 6 relative to F 4 . The fast convergence can be explained by the decorrelation of the inputs of the network. In general, decorrelating the inputs results in faster convergence for linear combiners <ref> [5] </ref>. This can be understood by noting that, if the inputs are strongly correlated, the combiner has to linearly combine a lot of redundant information, and will be slow in learning the statistics of the input data.
Reference: [6] <author> Orfanidis SJ (1990). </author> <title> Gram-Schmidt Neural Nets. </title> <journal> Neural Computation, </journal> <volume> vol 2, </volume> <pages> pp 116-126. </pages>
Reference-contexts: Since the units in the first layer of our network are linear combiners followed by a sigmoid function, this theory holds also for our findings <ref> [6] </ref>. A measure of correlation is the spread of the eigenvalues max = min of the correlation matrix R = E [~u~u T ] of the input vector ~u. The smaller the spread, the faster the network adapts.
References-found: 6

