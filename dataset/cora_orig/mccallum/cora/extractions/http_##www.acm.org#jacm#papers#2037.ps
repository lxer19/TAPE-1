URL: http://www.acm.org/jacm/papers/2037.ps
Refering-URL: http://www.acm.org/jacm/Upcoming.html
Root-URL: 
Email: feige@wisdom.weizmann.ac.il.  
Title: A threshold of ln n for approximating set cover  
Author: Uriel Feige 
Date: April 2, 1998  
Address: Rehovot 76100, Israel  
Affiliation: Department of Applied Math and Computer Science The Weizmann Institute  
Abstract: Given a collection F of subsets of S = f1; : : :; ng, set cover is the problem of selecting as few as possible subsets from F such that their union covers S, and max k-cover is the problem of selecting k subsets from F such that their union has maximum cardi-nality. Both these problems are NP-hard. We prove that (1 o(1)) ln n is a threshold below which set cover cannot be approximated efficiently, unless NP has slightly su-perpolynomial time algorithms. This closes the gap (up to low order terms) between the ratio of approximation achievable by the greedy algorithm (which is (1 o(1)) ln n), and previous results of Lund and Yannakakis, that showed hardness of approximation within a ratio of (log 2 n)=2 ' 0:72 ln n. For max k-cover we show an approximation threshold of (1 1=e) (up to low order terms), under the assumption that P 6= N P .
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, M. Szegedy. </author> <title> "Proof verification and hardness of approximation problems". </title> <booktitle> In Proc. of 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> 14-23, </pages> <year> 1992. </year>
Reference-contexts: The results and techniques in <ref> [1, 28] </ref> imply that there is a constant ffi &lt; 1 such that it is NP-hard to approximate max k-cover within a ration better than ffi. <p> The relevance of interactive proofs for proving hardness of approximation results was demonstrated in [9], and further developments in <ref> [2, 1] </ref> led to the PCP notion as stated below. Informally, a PCP for an NP language is a method of encoding NP witnesses, coupled with a verifier a very efficient randomized method for verifying the validity of the witness. <p> The gap between the probabilities that the verifier accepts inputs in the NP-language and inputs not in the NP-language is a key property that makes PCPs useful in proving hardness of approximation results. As shown by Arora et.al. <ref> [1] </ref>, the above PCP characterization of NP-languages (the "PCP theorem") is equivalent to the statement that it is NP-hard to approximate MAX 3SAT, meaning that for some ffi &lt; 1, it is NP hard to distinguish between satisfiable 3CNF formulas and 3CNF formulas in which at most a ffi-fraction of the <p> Output: The maximum number of clauses that can be satisfied simultaneously by some assignment to the variables. The following well known theorem appears in <ref> [1, 28] </ref>. Theorem 1 It is MAX-SNP hard to approximate MAX 3SAT-B: for some * &gt; 0, it is NP-hard to distinguish between satisfiable 3CNF-B formulas, and 3CNF-B formulas in which at most an (1 *)-fraction of the clauses can be satisfied simultaneously.
Reference: [2] <author> S. Arora, S. Safra. </author> <title> "Probabilistic checking of proofs: a new characterization of NP". </title> <booktitle> In Proc. of 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> 2-13, </pages> <year> 1992. </year>
Reference-contexts: The relevance of interactive proofs for proving hardness of approximation results was demonstrated in [9], and further developments in <ref> [2, 1] </ref> led to the PCP notion as stated below. Informally, a PCP for an NP language is a method of encoding NP witnesses, coupled with a verifier a very efficient randomized method for verifying the validity of the witness.
Reference: [3] <author> L. Babai, L. Fortnow, C. Lund, </author> <title> "Non-deterministic exponential time has two-prover interactive protocols", </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 3-40, </pages> <year> 1991. </year> <month> 20 </month>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs [14, 4, 6, 13] (parts of which we will review shortly) and from major breakthroughs in understanding their power <ref> [25, 32, 3] </ref>. The relevance of interactive proofs for proving hardness of approximation results was demonstrated in [9], and further developments in [2, 1] led to the PCP notion as stated below.
Reference: [4] <author> L. Babai, S. Moran. </author> <title> "Arthur-Merlin games: a randomized proof system, and a hierarchy of complexity classes." </title> <journal> J. Computer and Sys. Sci. </journal> <volume> 36 (1988), </volume> <pages> 254-276. </pages>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs <ref> [14, 4, 6, 13] </ref> (parts of which we will review shortly) and from major breakthroughs in understanding their power [25, 32, 3].
Reference: [5] <author> M. Bellare, S. Goldwasser, C. Lund, A. Russell. </author> <title> "Efficient probabilistically checkable proofs and applications to approximation". </title> <booktitle> In Proc. of 25th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> 294-304, </pages> <year> 1993. </year>
Reference-contexts: Bellare et.al. <ref> [5] </ref> constructed four prover proof systems that implied that unless P=NP set cover cannot be approximated within any constant ratio, and unless N P T IM E (n O (loglog n) ) then set cover cannot be approximated within a ratio of log n=8. <p> Again, a construction based on random subsets of size m=k will with high probability have properties as described above. To make use of the above setting, we design a new k-prover proof system for satisfiability. We remark that already in <ref> [5] </ref> hardness results for set cover were proved using k-prover proof system, where k = 4. However, these hardness results gave poorer bounds on the ratio of approximation than those obtainable from two prover proof systems.
Reference: [6] <author> M. Ben-Or, S. Goldwasser, J. Kilian, A. Wigderson. </author> <title> "Multi-prover interactive proofs: how to remove intractability assumptions". </title> <booktitle> In Proc. of 20th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> 113-131, </pages> <year> 1988. </year>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs <ref> [14, 4, 6, 13] </ref> (parts of which we will review shortly) and from major breakthroughs in understanding their power [25, 32, 3]. <p> Their proof was based on a reduction from efficient two prover proof systems for NP <ref> [6] </ref>. For our purposes, a two prover proof system can be described as a PCP with some special properties. The alphabet in which 3 the PCP witness is encoded is no longer binary, and its cardinality may depend on the input size. The PCP witness is partitioned into two segments. <p> More generally, one may view k-prover proof systems as PCPs in which the PCP witness is partitioned into k segments, and the verifier reads one character from each segment. In the terminology of multiprover proof systems <ref> [6] </ref>, each segment of the PCP witness is thought of as being controlled by one prover. The contents of the segment are called the strategy of the prover. <p> As each prover is queried only once, our description corresponds to one round multiprover proof systems. More general multiround proof systems are also described in <ref> [6] </ref>, but are beyond the scope of the current paper. Lund and Yannakakis obtained their hardness results for approximating set cover under complexity assumptions that are stronger than P 6= N P .
Reference: [7] <author> V. Chvatal. </author> <title> "A greedy heuristic for the set covering problem". </title> <journal> Math. Oper. Res., </journal> <volume> 4, </volume> <year> 1979, </year> <pages> 233-235. </pages>
Reference-contexts: Our proof technique extends that of [26]. 1.1 Related work Set cover was among the first problems for which approximation algorithms were analysed. Johnson [23] showed that the greedy algorithm gives an approximation ratio of ln n. (This was extended by Chvatal <ref> [7] </ref> to the weighted version of set cover.) Lovasz [24] showed that a linear programming relaxation approximates set cover within a ratio of ln n. In both cases, the authors were interested mainly in the leading term of the approximation ratio.
Reference: [8] <author> M. Dyer, A. Frieze. </author> <title> "A simple heuristic for the p-center problem". </title> <journal> Oper. Res. Lett., </journal> <volume> 3, </volume> <year> 1985, </year> <pages> 285-288. </pages>
Reference-contexts: A very sharp example is the minimum p-center problem, for which Hsu and Nemhauser [22] showed that it is NP-hard to obtain approximation ratios below 2, whereas Hochbaum and Shmoys [21], and Dyer 4 and Frieze <ref> [8] </ref>, showed how to approximate minimum p-center within a factor of 2. For the minimum maximal independent set problem, Halldorsson [16] shows that it cannot be approximated within a ratio of n 1* , for any * &gt; 0, which is tight up to multiplicative low order terms.
Reference: [9] <author> U. Feige, S. Goldwasser, L. Lovasz, S. Safra, S. Szegedy. </author> <title> "Interactive proofs and the hardness of approximating cliques". </title> <journal> Journal of the ACM, </journal> <volume> Vol. 43, No. 2, </volume> <year> 1996, </year> <pages> 268-292. </pages>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs [14, 4, 6, 13] (parts of which we will review shortly) and from major breakthroughs in understanding their power [25, 32, 3]. The relevance of interactive proofs for proving hardness of approximation results was demonstrated in <ref> [9] </ref>, and further developments in [2, 1] led to the PCP notion as stated below. Informally, a PCP for an NP language is a method of encoding NP witnesses, coupled with a verifier a very efficient randomized method for verifying the validity of the witness.
Reference: [10] <author> U. Feige, J. Kilian. </author> <title> "Impossibility results for recycling random bits in two prover proof systems". </title> <booktitle> Proc. of 27th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> 457-468, </pages> <year> 1995. </year>
Reference-contexts: Moreover, it may not even be a sufficient requirement, since current techniques require that the proof systems have very regular structure. Some of the difficulties involved in reducing the number of random bits in two prover proof systems are discussed in <ref> [10] </ref>. Acknowledgements I thank Moni Naor, Leonard Shulman, and Aravind Srinivasan for a preview of [27], and Mihir Bellare for his comments on an earlier version of this manuscript.
Reference: [11] <author> U. Feige, J. Kilian. </author> <title> "Zero knowledge and the chromatic number". </title> <booktitle> Proc. of 11th Annual IEEE Conference on Computational Complexity, </booktitle> <year> 1996. </year>
Reference-contexts: Since then, several other thresholds for approximation were discovered. Essentially tight O (n 1* ) hardness of approximation results where obtained for clique and independent set [17], and for chromatic number <ref> [11] </ref>. Tight constant factor hardness of approximation results were obtain for several problems in [18], including a threshold of 7=8 for MAX 3SAT.
Reference: [12] <author> U. Feige, L. Lovasz. </author> <title> "Two prover one round proof systems: their power and their problems". </title> <booktitle> In Proc. of 24th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> 733-744, </pages> <year> 1992. </year>
Reference-contexts: In Section 2 we describe our k-prover proof system. It is fortunate that we can invoke a recent theorem of Raz [30] regarding reduction of error by parallel repetition. In contrast, Lund and Yannakakis used the more complicated two prover proof system of Feige and Lovasz <ref> [12] </ref> (the result of [30] was not available at the time), without actually describing it. In Section 3 we explain how to construct the partition systems mentioned above. In Section 4 we describe the reduction from our k-prover proof system to set cover.
Reference: [13] <author> L. Fortnow, J. Rompel, M. Sipser, </author> <title> "On the Power of Multi-Prover Interactive Protocols", </title> <booktitle> Theoretical Computer Science 134, </booktitle> <pages> 545-557, </pages> <year> 1994. </year>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs <ref> [14, 4, 6, 13] </ref> (parts of which we will review shortly) and from major breakthroughs in understanding their power [25, 32, 3]. <p> Unfortunately, this is in general not true, due to subtle reasons that are best explained by explicit counter examples <ref> [13] </ref>. However, it is true that parallel repetition reduces the error at an exponential rate. The following theorem was proven by Raz [30].
Reference: [14] <author> S. Goldwasser, S. Micali, C. Rackoff. </author> <title> "The knowledge complexity of interactive proof-systems." </title> <journal> SIAM J. Comp. </journal> <volume> 18 (1989), </volume> <pages> 186-208. </pages>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs <ref> [14, 4, 6, 13] </ref> (parts of which we will review shortly) and from major breakthroughs in understanding their power [25, 32, 3].
Reference: [15] <author> S. Guha, S. Khuller. </author> <title> "Greedy strikes back: improved facility location algorithms". </title> <booktitle> In Proc. Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1998. </year>
Reference-contexts: This has also been observed by others (see <ref> [15] </ref>, for example). 16 Proposition 12 If max k-cover can be constructively approximated in polynomial time within a ratio of (1 1=e + *) for some * &gt; 0, then N P T IM E (n O (loglog n) ).
Reference: [16] <author> M. Halldorsson. </author> <title> "Approximating the minimum maximal independence number". </title> <journal> Inform. Process. Lett. </journal> <volume> 46 (1993) 169-172. </volume> <pages> 21 </pages>
Reference-contexts: For the minimum maximal independent set problem, Halldorsson <ref> [16] </ref> shows that it cannot be approximated within a ratio of n 1* , for any * &gt; 0, which is tight up to multiplicative low order terms. Another example of a well characterized approximation problem is presented in [19].
Reference: [17] <author> J. H-astad. </author> <title> "Clique is hard to approximate within n 1* ." In Proc. </title> <booktitle> 37th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> 627-636, </pages> <year> 1996. </year>
Reference-contexts: Since then, several other thresholds for approximation were discovered. Essentially tight O (n 1* ) hardness of approximation results where obtained for clique and independent set <ref> [17] </ref>, and for chromatic number [11]. Tight constant factor hardness of approximation results were obtain for several problems in [18], including a threshold of 7=8 for MAX 3SAT.
Reference: [18] <author> J. H-astad. </author> <title> "Some optimal inapproximability results". </title> <booktitle> In proc. 29th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> 1-10, </pages> <year> 1997. </year>
Reference-contexts: Since then, several other thresholds for approximation were discovered. Essentially tight O (n 1* ) hardness of approximation results where obtained for clique and independent set [17], and for chromatic number [11]. Tight constant factor hardness of approximation results were obtain for several problems in <ref> [18] </ref>, including a threshold of 7=8 for MAX 3SAT.
Reference: [19] <author> J. Hastad, S. Phillips, S. Safra. </author> <title> "A well characterized approximation problem". </title> <booktitle> Proc. 2nd Israel Symp. on Theory of Computing and Systems, </booktitle> <pages> 261-265, </pages> <year> 1993. </year>
Reference-contexts: For the minimum maximal independent set problem, Halldorsson [16] shows that it cannot be approximated within a ratio of n 1* , for any * &gt; 0, which is tight up to multiplicative low order terms. Another example of a well characterized approximation problem is presented in <ref> [19] </ref>. Our work shows that also set cover and max k-cover have a threshold of a nontrivial nature.
Reference: [20] <editor> D. Hochbaum (editor). </editor> <title> Approximation Algorithms for NP-hard Problems. </title> <publisher> PWS Publishing Company, </publisher> <address> Boston, </address> <year> 1997. </year>
Reference-contexts: Analysis of the low order terms of the approximation ratio was provided by Srinivasan [34] (for the linear programming approach) and by Slavik [33] (for the greedy algorithm). For max k-cover, the greedy algorithm gives an approximation ratio of 1 1=e (up to low order terms). See <ref> [20] </ref> and references therein, and also Proposition 11. (A similar approximation ratio can be obtained via a linear programming relaxation, though the author is not aware of an explicit reference for this.) The first hardness of approximation results for set cover followed from work on probabilistically checkable proof systems (PCPs). <p> A survey of hardness of approximation results and the techniques involved is provided by Arora and Lund in <ref> [20] </ref>. Remark: A preliminary version of this paper, without the results on max k-cover, appeared in the Proceedings of the 28th Annual ACM Symposium on the Theory of Computing, 1996. Since then, several other thresholds for approximation were discovered.
Reference: [21] <author> D. Hochbaum, D. Shmoys. </author> <title> "A best possible approximation algorithm for the k-center problem". </title> <journal> Math. Oper. Res., </journal> <volume> 10, </volume> <year> 1985, </year> <pages> 180-184. </pages>
Reference-contexts: A very sharp example is the minimum p-center problem, for which Hsu and Nemhauser [22] showed that it is NP-hard to obtain approximation ratios below 2, whereas Hochbaum and Shmoys <ref> [21] </ref>, and Dyer 4 and Frieze [8], showed how to approximate minimum p-center within a factor of 2.
Reference: [22] <author> W. Hsu, G. Nemhauser. </author> <title> "Easy and hard bottleneck location problems". </title> <journal> Discrete Applied Math., </journal> <volume> 1, </volume> <year> 1979, </year> <pages> 209-216. </pages>
Reference-contexts: There are only few NP optimization problems that are known to have a threshold of nontrivial nature (e.g., not located at approximation ratio 1). A very sharp example is the minimum p-center problem, for which Hsu and Nemhauser <ref> [22] </ref> showed that it is NP-hard to obtain approximation ratios below 2, whereas Hochbaum and Shmoys [21], and Dyer 4 and Frieze [8], showed how to approximate minimum p-center within a factor of 2.
Reference: [23] <author> D. Johnson. </author> <title> "Approximation algorithms for combinatorial problems". </title> <journal> J. Comput. System Sci. </journal> <volume> 9, </volume> <year> 1974, </year> <pages> 256-278. </pages>
Reference-contexts: Our results are based on a reduction from a new multi-prover proof system for NP (see Section 2), designed specifically for this purpose. Our proof technique extends that of [26]. 1.1 Related work Set cover was among the first problems for which approximation algorithms were analysed. Johnson <ref> [23] </ref> showed that the greedy algorithm gives an approximation ratio of ln n. (This was extended by Chvatal [7] to the weighted version of set cover.) Lovasz [24] showed that a linear programming relaxation approximates set cover within a ratio of ln n.
Reference: [24] <author> L. Lovasz. </author> <title> "On the ratio of the optimal integral and fractional covers". </title> <note> Discrete Mathematics 13 (1975) 383-390. </note>
Reference-contexts: Johnson [23] showed that the greedy algorithm gives an approximation ratio of ln n. (This was extended by Chvatal [7] to the weighted version of set cover.) Lovasz <ref> [24] </ref> showed that a linear programming relaxation approximates set cover within a ratio of ln n. In both cases, the authors were interested mainly in the leading term of the approximation ratio.
Reference: [25] <author> C. Lund, L. Fortnow, H. Karloff, N. Nisan. </author> <title> "Algebraic Methods for Interactive Proof Systems." </title> <journal> J. ACM, </journal> <volume> 39 (1992), </volume> <pages> 859-868. </pages>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs [14, 4, 6, 13] (parts of which we will review shortly) and from major breakthroughs in understanding their power <ref> [25, 32, 3] </ref>. The relevance of interactive proofs for proving hardness of approximation results was demonstrated in [9], and further developments in [2, 1] led to the PCP notion as stated below.
Reference: [26] <author> C. Lund, M. Yannakakis. </author> <title> "On the hardness of approximating minimization problems". </title> <type> JACM 41(5), </type> <year> 1994, </year> <pages> 960-981. </pages>
Reference-contexts: The results and techniques in [1, 28] imply that there is a constant ffi &lt; 1 such that it is NP-hard to approximate max k-cover within a ration better than ffi. Lund and Yannakakis <ref> [26] </ref> showed (under a complexity assumption that will be presented in Section 1.1) that it is hard to approximate set cover within a ratio of (log n)=2, where log denotes logarithms in base 2. <p> Our results are based on a reduction from a new multi-prover proof system for NP (see Section 2), designed specifically for this purpose. Our proof technique extends that of <ref> [26] </ref>. 1.1 Related work Set cover was among the first problems for which approximation algorithms were analysed. <p> We shall ignore low order terms in the approximation ratios presented below. Lund and Yannakakis <ref> [26] </ref> showed that set cover cannot be approximated within a ratio of log n=4 unless N P T IM E (n O (polylog n) ), and that set cover cannot be approximated within a ratio of log n=2 unless N P ZT IM E (n O (polylog n) ). <p> This can be extended to other problems as well, as the same threshold of ln n holds for all problems that are equivalent to set cover in terms of approximation ratio, such as dominating set (see [29] and <ref> [26] </ref> for more details). A survey of hardness of approximation results and the techniques involved is provided by Arora and Lund in [20]. <p> the following table to translate from our notation to that of [27]: a point in set B ! a function h in collection H, m ! jHj, L ! n, k ! b, d ! k.) 4 The reduction to set cover Our reduction extends that of Lund and Yannakakis <ref> [26] </ref>. The verifier of the k-prover proof system of Section 2.3 uses its randomness, which we assume that is given in form of a random string r, to select ` clauses and a distinguished variable in each clause. We call these ` distinguished variables the sequence of distinguished variables. <p> Finally, recall that for the proof of Lemma 7 we required that 4f (k)=(k ln m) 2 &gt; k 2 2 c` , which indeed holds when ` is a sufficiently large multiple of log n. 2 An open question that is "traditionally" (ever since <ref> [26] </ref>) associated with the hardness of approximating set cover is that of constructing two prover one round proof systems for NP, in which the amount of randomness used by the verifier is logarithmic, the answer length of the provers is logarithmic, and the error is polynomially small.
Reference: [27] <author> M. Naor, L. Schulman, A. Srinivasan. </author> <title> "Splitters and near-optimal derandomization". </title> <booktitle> Proc. of 36th Annual Symposium of Foundations of Computer Science, </booktitle> <pages> 182-191, </pages> <year> 1995. </year>
Reference-contexts: Improved deterministic constructions by Naor et.al. <ref> [27] </ref> closed the gap (up to low order terms) between the consequences achievable under the assumption that NP is not contained in a deterministic time class and the assumption that NP is not contained in a probabilistic time class. <p> The expected number of times the randomized construction needs to be tried until it succeeds is less than 2. 2 The randomized construction can be replaced by a deterministic construction using techniques developed in <ref> [27] </ref>. There, partition systems are called anti-universal sets. Theorem 9 in [27] says that for any k one can in time linear in m construct a partition system for which m = ( k k1 ) d d O (log d) log L. (Here k is assumed to be an arbitrary <p> The expected number of times the randomized construction needs to be tried until it succeeds is less than 2. 2 The randomized construction can be replaced by a deterministic construction using techniques developed in <ref> [27] </ref>. There, partition systems are called anti-universal sets. Theorem 9 in [27] says that for any k one can in time linear in m construct a partition system for which m = ( k k1 ) d d O (log d) log L. (Here k is assumed to be an arbitrary constant, and m grows as a function of L and d.) <p> This will hold when we use partition systems in Section 4. (The reader may use the following table to translate from our notation to that of <ref> [27] </ref>: a point in set B ! a function h in collection H, m ! jHj, L ! n, k ! b, d ! k.) 4 The reduction to set cover Our reduction extends that of Lund and Yannakakis [26]. <p> Now follow the reduction to set cover described above, with k sufficiently large so that f (k) in Lemma 7 is smaller than *=4, and with m = (5n) 2`=* . Using the deterministic construction of partition systems described in <ref> [27] </ref>, and observing that m, R and Q are bounded by n O (log log n) , the time to perform this reduction is n O (log log n) . <p> Some of the difficulties involved in reducing the number of random bits in two prover proof systems are discussed in [10]. Acknowledgements I thank Moni Naor, Leonard Shulman, and Aravind Srinivasan for a preview of <ref> [27] </ref>, and Mihir Bellare for his comments on an earlier version of this manuscript.
Reference: [28] <author> C. Papadimitriou, M. Yannakakis. </author> <title> "Optimization, approximation, and complexity classes". </title> <journal> JCSS, </journal> <volume> 43, </volume> <year> 1991, </year> <pages> 425-440. </pages>
Reference-contexts: The results and techniques in <ref> [1, 28] </ref> imply that there is a constant ffi &lt; 1 such that it is NP-hard to approximate max k-cover within a ration better than ffi. <p> This immediately implies constant factor hardness of approximation results for a variety of other problems all those that are MAX SNP-hard <ref> [28] </ref>. One of these problems is minimum vertex cover in bounded degree graphs, that is, selecting as few as possible vertices in a graph of bounded degree such that for each edge, at least one of its endpoints is selected. <p> Output: The maximum number of clauses that can be satisfied simultaneously by some assignment to the variables. The following well known theorem appears in <ref> [1, 28] </ref>. Theorem 1 It is MAX-SNP hard to approximate MAX 3SAT-B: for some * &gt; 0, it is NP-hard to distinguish between satisfiable 3CNF-B formulas, and 3CNF-B formulas in which at most an (1 *)-fraction of the clauses can be satisfied simultaneously.
Reference: [29] <author> A. Paz, S. Moran. </author> <title> "Nondeterministic polynomial optimization problems and their approximations", </title> <booktitle> Theoretical Computer Science, </booktitle> <month> 15 </month> <year> (1981) </year> <month> 251-277. </month>
Reference-contexts: This can be extended to other problems as well, as the same threshold of ln n holds for all problems that are equivalent to set cover in terms of approximation ratio, such as dominating set (see <ref> [29] </ref> and [26] for more details). A survey of hardness of approximation results and the techniques involved is provided by Arora and Lund in [20].
Reference: [30] <author> R. Raz. </author> <title> "A parallel repetition theorem". </title> <booktitle> Proc. of 27th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> 447-456, </pages> <year> 1995. </year>
Reference-contexts: Improved analysis of two prover proof systems by Raz <ref> [30] </ref> implies that unless N P T IM E (n O (loglog n) ) then set cover cannot be approximated within a ratio of log n=4, and that unless N P ZT IM E (n O (loglog n) ) then set cover cannot be approximated within a ratio of log n=2. <p> In Section 2 we describe our k-prover proof system. It is fortunate that we can invoke a recent theorem of Raz <ref> [30] </ref> regarding reduction of error by parallel repetition. In contrast, Lund and Yannakakis used the more complicated two prover proof system of Feige and Lovasz [12] (the result of [30] was not available at the time), without actually describing it. <p> It is fortunate that we can invoke a recent theorem of Raz <ref> [30] </ref> regarding reduction of error by parallel repetition. In contrast, Lund and Yannakakis used the more complicated two prover proof system of Feige and Lovasz [12] (the result of [30] was not available at the time), without actually describing it. In Section 3 we explain how to construct the partition systems mentioned above. In Section 4 we describe the reduction from our k-prover proof system to set cover. <p> Unfortunately, this is in general not true, due to subtle reasons that are best explained by explicit counter examples [13]. However, it is true that parallel repetition reduces the error at an exponential rate. The following theorem was proven by Raz <ref> [30] </ref>.
Reference: [31] <author> R. Raz, S. Safra. </author> <title> "A sub-constant error-probability low-degree test, and sub-constant error-probability PCP characterization of NP". </title> <booktitle> Proc. of 29th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> 475-484, </pages> <year> 1997. </year> <month> 22 </month>
Reference-contexts: Tight constant factor hardness of approximation results were obtain for several problems in [18], including a threshold of 7=8 for MAX 3SAT. As for set cover, Raz and Safra <ref> [31] </ref> constructed new low error constant prover proof systems and used them to show that for some constant c &gt; 0, it is NP-hard to approximate set cover within a ratio of c log n.
Reference: [32] <author> A. Shamir. </author> <title> "IP=PSPACE". </title> <journal> Journal of the ACM, </journal> <volume> 39 </volume> <pages> 869-877, </pages> <year> 1992. </year>
Reference-contexts: The notion of PCPs grew out of the theory 2 of interactive proofs [14, 4, 6, 13] (parts of which we will review shortly) and from major breakthroughs in understanding their power <ref> [25, 32, 3] </ref>. The relevance of interactive proofs for proving hardness of approximation results was demonstrated in [9], and further developments in [2, 1] led to the PCP notion as stated below.
Reference: [33] <author> P. Slavik. </author> <title> "A tight analysis of the greedy algorithm for set cover". </title> <booktitle> Proc. of 28th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> 435-439, </pages> <year> 1996. </year>
Reference-contexts: In both cases, the authors were interested mainly in the leading term of the approximation ratio. Analysis of the low order terms of the approximation ratio was provided by Srinivasan [34] (for the linear programming approach) and by Slavik <ref> [33] </ref> (for the greedy algorithm). For max k-cover, the greedy algorithm gives an approximation ratio of 1 1=e (up to low order terms). <p> To make * as small as possible, we strengthen the N P 62 T IM E (n loglog n ) assumption. Observe that the low order terms in Proposition 15 are not far from optimal, as the greedy algorithm approximates set cover within ln nln ln n+O (1) <ref> [33] </ref>. 18 Proposition 15 If for some &gt; 0, N P 6 ZT IM E (2 n ), then for some constant c 0 &gt; 0, there is no polynomial time algorithm that approximates set cover within ln n c 0 (ln ln n) 2 .
Reference: [34] <author> A. Srinivasan. </author> <title> "Improved approximations of packing and covering problems". </title> <booktitle> Proc. of 27th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> 268-276, </pages> <year> 1995. </year> <month> 23 </month>
Reference-contexts: In both cases, the authors were interested mainly in the leading term of the approximation ratio. Analysis of the low order terms of the approximation ratio was provided by Srinivasan <ref> [34] </ref> (for the linear programming approach) and by Slavik [33] (for the greedy algorithm). For max k-cover, the greedy algorithm gives an approximation ratio of 1 1=e (up to low order terms).
References-found: 34

