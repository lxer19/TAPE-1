URL: ftp://utstat.toronto.edu/pub/tibs/cvboot.ps
Refering-URL: http://utstat.toronto.edu:80/tibs/research.html
Root-URL: 
Title: Cross-Validation and the Bootstrap: Estimating the Error Rate of a Prediction Rule  
Author: Bradley Efron and Robert Tibshirani 
Abstract: A training set of data has been used to construct a rule for predicting future responses. What is the error rate of this rule? The traditional answer to this question is given by cross-validation. The cross-validation estimate of prediction error is nearly unbiased, but can be highly variable. This article discusses bootstrap estimates of prediction error, which can be thought of as smoothed versions of cross-validation. A particular bootstrap method, the 632+ rule, is shown to substantially outperform cross-validation in a catalog of 24 simulation experiments. Besides providing point estimates, we also consider estimating the variability of an error rate estimate. All of the results here are nonparametric, and apply to any possible prediction rule: however we only study classification problems with 0-1 loss in detail. Our simulations include "smooth" prediction rules like Fisher's Linear Discriminant Function, and unsmooth ones like Nearest Neighbors.
Abstract-found: 1
Intro-found: 1
Reference: <author> Breiman, L. </author> <year> (1994). </year> <title> Bagging predictors. </title> <type> Technical Report, </type> <institution> University of California, Berke-ley. </institution>
Reference: <author> Breiman, L. and Spector, P. </author> <year> (1992). </year> <title> "Submodel selection and evaluation in regression: the x-random case," </title> <journal> International Statistical Review 60, </journal> <pages> 291-319. </pages>
Reference: <author> Breiman, L., Friedman, J., Olshen, R. and Stone, C. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Pacific Grove, California. </address>
Reference: <author> Chernick, M., Murthy, V. and Nealy, C. </author> <year> (1985). </year> <title> "Application of bootstrap and other resampling methods: evaluation of classifier performance," </title> <journal> Pattern Recognition Letters 4, </journal> <pages> 167-178. </pages>
Reference: <author> Chernick, M. Murthy, V. and Nealy, C. </author> <year> (1986). </year> <title> "Correction note to Application of bootstrap and other esampling methods: evaluation of classifier performance". </title> <journal> Pattern Recognition Letters 4, </journal> <pages> 133-142. </pages>
Reference: <author> Cosman, P., Perlmutter, K., Perlmutter, S., Olshen, R. and Gray, R. </author> <year> (1991). </year> <title> "Training sequence size and vector quantizer performance," </title> <booktitle> In 25th Asilomar Conference on Signals, Systems, and Computers, </booktitle> <month> Nov. </month> <pages> 4-6, </pages> <year> 1991, </year> <editor> by Ray R. Chen, </editor> <publisher> IEE Computer Society Press, Los Alamitos, CA, </publisher> <pages> pp. 434-348. </pages>
Reference: <author> Dawid, A., Hinkley, D. and Schechtman, E. </author> <year> (1986). </year> <title> "Efficient bootstrap simulations," </title> <type> Biometrika 73 555-566. </type>
Reference: <author> Efron, B. </author> <year> (1979). </year> <title> "Bootstrap methods: another look at the jackknife," </title> <journal> Annals Statistics 7, </journal> <pages> 1-26. </pages> <month> Efron </month> <year> (1983). </year> <title> "Estimating the error rate of a prediction rule: some improvements on cross-validation," </title> <journal> Journal Amerian Statistical Association 78, </journal> <pages> 316-331. </pages>
Reference: <author> Efron, B. </author> <year> (1992). </year> <title> "Jackknife-after-bootstrap standard errors and influence functions" (with Discussion), </title> <journal> J. Royal Statist. Society, B, </journal> <pages> 83-111. </pages>
Reference: <author> Efron, B. and Tibshirani, R. </author> <year> (1993). </year> <title> An Introduction to the Bootstrap. </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Efron, B. and Tibshirani, R. </author> <year> (1995). </year> <title> Cross-Validation and the Bootstrap: Estimating the Error Rate of a Prediction Rule. </title> <type> Technical report 176, </type> <institution> Dept of Statistics, Stanford Univ. </institution>
Reference: <author> Friedman, J. </author> <year> (1994). </year> <title> Flexible metric nearest neighbour classification. </title> <type> Technical Report, </type> <institution> Stanford University. </institution>
Reference: <author> Geisser, S. </author> <year> (1975). </year> <title> "The predictive sample reuse method with applications," </title> <journal> Journal American Statistical Association 70, </journal> <pages> 320-328. </pages>
Reference: <author> Jain, A., Dubes, R. P. and Chen, C. </author> <year> (1987). </year> <title> "Bootstrap techniques for error estimation," </title> <journal> IEEE Trans. On Pattern Analysis and Mach. Intell. </journal> <volume> 9, </volume> <pages> 628-633. </pages>
Reference: <author> Kohavi, R. </author> <year> (1995). </year> <title> "A study of cross-validation and bootstrap for accuracy assessment and model selection, </title> " <type> Technical Report, </type> <institution> Stanford University. </institution>
Reference: <author> Mallows, C. </author> <year> (1973). </year> <title> "Some comments on Cp," </title> <journal> Technometrics, </journal> <pages> 661-675. </pages>
Reference: <author> McLachlan, G. </author> <year> (1992). </year> <title> Discriminant Analysis and Statistical Pattern Recognition. </title> <publisher> Wiley, </publisher> <address> New York. </address> <note> 26 Stone, </note> <author> M. </author> <year> (1974). </year> <title> "Cross-validatory choice and assessment of statistical predictions," </title> <journal> Jour- nal Royal Statistical Society 36, </journal> <pages> 111-147. </pages>

References-found: 17

