URL: ftp://iridia.ulb.ac.be/pub/dorigo/conferences/IC.21-PPSN96.ps.gz
Refering-URL: http://iridia.ulb.ac.be/dorigo/pub_x_subj.html
Root-URL: 
Email: dorigo@idsia.ch, luca@idsia.ch  
Title: Dorigo and Gambardella A study of some properties of Ant-Q 1 A STUDY OF SOME
Author: Marco Dorigo and Luca Maria Gambardella H.M. Voigt, W. Ebeling, I. Rechenberg and H.S. 
Note: Published in the Proceedings of PPSN IVFourth International Conference on Parallel  Schwefel (Eds.), Springer-Verlag, Berlin, 656665.  
Address: Belgium  Corso Elvezia 36, CH-6900 Lugano, Switzerland  
Affiliation: Universit Libre de Bruxelles  IDSIA,  
Pubnum: TR/IRIDIA/1996-4  
Abstract: Ant-Q is an algorithm belonging to the class of ant colony based methods, that is, of combinatorial optimization methods in which a set of simple agents, called ants, cooperate to find good solutions to combinatorial optimiza tion problems. The main focus of this article is on the experimental study of the sensitivity of the Ant-Q algorithm to its parameters and on the investigation of synergistic effects when using more than a single ant. We conclude comparing Ant-Q with its ancestor Ant System, and with other heuristic algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bersini H., C. Oury and M. Dorigo, </author> <year> 1995. </year> <title> Hybridization of genetic algorithms. </title> <type> Tech. Rep. </type> <institution> No. IRIDIA/95-22, IRIDIA, Universit Libre de Bruxelles, Belgium. </institution>
Reference-contexts: In Table 3 we report the best integer tour length, the best real tour length (in parentheses) and the number of tours re quired to find the best integer tour length (in square brackets). Results using EP are from (Fogel, 1993) and those using GA are from <ref> (Bersini, Oury and Dorigo, 1995) </ref> for KroA100, and from (Whitley, Starkweather and Fuquay, 1989) for Eil50, and Eil75. Results using SA are from (Lin, Kao and Hsu, 1993).
Reference: <author> Colorni A., M. Dorigo and V. Maniezzo, </author> <year> 1991. </year> <title> Distributed Optimization by Ant Colonies. </title> <booktitle> Proceedings of ECAL91 - European Conference on Artificial Life , Paris, France, </booktitle> <editor> F.Varela and P.Bourgine (Eds.), </editor> <publisher> Elsevier Publishing, </publisher> <pages> 134142. </pages>
Reference: <author> Colorni A., M. Dorigo and V. Maniezzo, </author> <year> 1992. </year> <title> An Investigation of some Properties of an Ant Algorithm. </title> <booktitle> Proceedings of the Parallel Problem Solving from Nature Conference (PPSN 92), </booktitle> <address> Brussels, </address> <publisher> Belgium, </publisher> <editor> R.Mnner and B.Manderick (Eds.), </editor> <publisher> Elsevier Publishing, </publisher> <pages> 509520. </pages>
Reference: <author> Dorigo M., </author> <year> 1992. </year> <title> Optimization, Learning and Natural Algorithms . Ph.D.Thesis, </title> <institution> Politecnico di Milano, Italy. </institution> <note> (In Italian.) </note> <editor> Dorigo M., V.Maniezzo and A.Colorni, </editor> <year> 1996. </year> <title> The Ant System: Optimization by a colony of cooperating agents. </title> <journal> IEEE Transactions on Systems, Man, and CyberneticsPart B, </journal> <volume> 26, 2, </volume> <pages> 2941. </pages>
Reference: <author> Eilon S., C.D.T. Watson-Gandy and N. Christofides, </author> <year> 1969. </year> <title> Distribution management: math - emati cal modeling and practical analysis. </title> <journal> Operational Research Quarterly, </journal> <volume> 20, </volume> <pages> 3753. </pages>
Reference-contexts: Results using EP are from (Fogel, 1993) and those using GA are from (Bersini, Oury and Dorigo, 1995) for KroA100, and from (Whitley, Starkweather and Fuquay, 1989) for Eil50, and Eil75. Results using SA are from (Lin, Kao and Hsu, 1993). Eil50 and Eil75 are from <ref> (Eilon, Watson-Gandy and Christofides, 1969) </ref>, and are included in TSPLIB with an addi tional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB.
Reference: <author> Fischetti M. and P.Toth, </author> <year> 1992. </year> <title> An Additive Bounding Procedure for the Asymmetric Travelling Salesman Problem. </title> <journal> Mathematical Programming, </journal> <volume> 53, </volume> <pages> 173197. </pages>
Reference: <author> Fischetti M. and P.Toth, </author> <year> 1994. </year> <title> A polyhedral approach for the exact solution of hard ATSP instances. </title> <type> Tech. Rep. </type> <institution> OR-94, DEIS, Universit di Bologna, Italy, </institution> <month> April </month> <year> 1994. </year>
Reference: <author> Fogel D., </author> <year> 1993. </year> <title> Applying evolutionary programming to selected traveling salesman problems. </title> <journal> Cybernetics and Systems: An International Journal, </journal> <volume> 24, </volume> <pages> 2736. </pages>
Reference-contexts: In Table 3 we report the best integer tour length, the best real tour length (in parentheses) and the number of tours re quired to find the best integer tour length (in square brackets). Results using EP are from <ref> (Fogel, 1993) </ref> and those using GA are from (Bersini, Oury and Dorigo, 1995) for KroA100, and from (Whitley, Starkweather and Fuquay, 1989) for Eil50, and Eil75. Results using SA are from (Lin, Kao and Hsu, 1993).
Reference: <author> Gambardella L. and M. Dorigo, </author> <year> 1995. </year> <title> Ant-Q: A Reinforcement Learning approach to the travel ing salesman problem. </title> <booktitle> Proceedings of ML-95, Twelfth International Conference on Machine Learning, </booktitle> <address> Tahoe City, </address> <publisher> CA, </publisher> <editor> A. Prieditis and S. Russell (Eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <pages> 252260. </pages>
Reference-contexts: 1 Introduction In this paper we study some properties of Ant-Q, a novel distributed approach to combi - natorial optimization based on reinforcement learning. Ant-Q <ref> (Gambardella and Dorigo, 1995) </ref> finds its ground in one of the authors previous work on the socalled Ant System (Colorni, Dorigo and Maniezzo, 1991; 1992; Dorigo, 1992; Dorigo, Maniezzo and Colorni, 1996), and in the Q-learning algorithm (Watkins, 1989). <p> The Ant-Q algorithm used in this paper is shown in Fig. 1 (the detailed algorithm can be found in <ref> (Gambardella and Dorigo, 1995) </ref>). 1 The form of this updating rule, which is very similar to the updating rule used by Q-learning, is the most relevant difference between Ant System and Ant-Q. <p> Experiments reported in <ref> (Gambardella and Dorigo, 1995) </ref> have shown that the pseudorandom-proportional action choice is by far the best choice for Ant-Q algorithms. (ii ) A result of our experiments is that the heuristic function HE is fundamental in making the algorithm find good solutions in a reasonable time. <p> In previous work on Ant System all the ants contributed to the global reinforcement: the contribution of each ant was proportional to how short was its tour. This and other ways to provide rein forcement are discussed in <ref> (Gambardella and Dorigo, 1995) </ref>. 4 Ant-Q: Experimental Study In this section we experimentally study the functioning of the Ant-Q algorithm. Tests were run on the following problems: 6x6 grid and Oliver30, two TSP problems, and ry48p, an ATSP problem.
Reference: <author> Lin F.T., C.Y. Kao and C.C. Hsu, </author> <year> 1993. </year> <title> Applying the genetic approach to simulated annealing in solving some NP-hard problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23, </volume> <pages> 17521767. </pages>
Reference-contexts: Results using EP are from (Fogel, 1993) and those using GA are from (Bersini, Oury and Dorigo, 1995) for KroA100, and from (Whitley, Starkweather and Fuquay, 1989) for Eil50, and Eil75. Results using SA are from <ref> (Lin, Kao and Hsu, 1993) </ref>. Eil50 and Eil75 are from (Eilon, Watson-Gandy and Christofides, 1969), and are included in TSPLIB with an addi tional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB.
Reference: <author> Watkins C.J.C.H., </author> <year> 1989. </year> <title> Learning with delayed rewards. </title> <publisher> Ph. </publisher> <address> D. </address> <institution> dissertation , Psychology Department, University of Cambridge, </institution> <address> England. </address>
Reference-contexts: Ant-Q (Gambardella and Dorigo, 1995) finds its ground in one of the authors previous work on the socalled Ant System (Colorni, Dorigo and Maniezzo, 1991; 1992; Dorigo, 1992; Dorigo, Maniezzo and Colorni, 1996), and in the Q-learning algorithm <ref> (Watkins, 1989) </ref>. Ant System (AS), which will not be discussed here, is a distribu ted algorithm loosely based on the observa tion of ant colonies behavior, hence its name.
Reference: <author> Whitley D., T. Starkweather and D. Fuquay, </author> <year> 1989. </year> <title> Scheduling Problems and Traveling Salesman: the Genetic Edge Recombination Operator. </title> <booktitle> Proc. of the Third International Conference on Genetic Algorithms, </booktitle> <publisher> Morgan Kaufmann, </publisher> <pages> 133140. </pages>
Reference-contexts: Each of the parameters was optimized using Ant-Q applied to a set of benchmark problems: grid prob lems 2 , Oliver30 <ref> (see for example Whitley, Starkweather and Fuquay, 1989) </ref>, ry48p (see TSPLIB, in Reinelt, 1994). The experi mentally determined best values are d=1, b= 2 , q 0 =0.9, a=0.1, g=0.20.6, W=10, AQ 0 =1/(average_length_of_edgesn). <p> Results using EP are from (Fogel, 1993) and those using GA are from (Bersini, Oury and Dorigo, 1995) for KroA100, and from <ref> (Whitley, Starkweather and Fuquay, 1989) </ref> for Eil50, and Eil75. Results using SA are from (Lin, Kao and Hsu, 1993). Eil50 and Eil75 are from (Eilon, Watson-Gandy and Christofides, 1969), and are included in TSPLIB with an addi tional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB.
References-found: 12

