URL: http://www.cs.bu.edu/techreports/97-002-prefetcheff.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Email: fcrovella,barfordg@cs.bu.edu  
Title: The Network Effects of Prefetching  
Author: Mark Crovella and Paul Barford 
Date: July 10, 1997  
Address: 111 Cummington St, Boston, MA 02215  
Affiliation: Computer Science Department Boston University  
Abstract: Prefetching has been shown to be an effective technique for reducing user perceived latency in distributed systems. In this paper we show that even when prefetching adds no extra traffic to the network, it can have serious negative performance effects. Straightforward approaches to prefetching increase the burstiness of individual sources, leading to increased average queue sizes in network switches. However, we also show that applications can avoid the undesirable queueing effects of prefetching. In fact, we show that applications employing prefetching can significantly improve network performance, to a level much better than that obtained without any prefetching at all. This is because prefetching offers increased opportunities for traffic shaping that are not available in the absence of prefetching. Using a simple transport rate control mechanism, a prefetching application can modify its behavior from a distinctly ON/OFF entity to one whose data transfer rate changes less abruptly, while still delivering all data in advance of the user's actual requests.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Arlitt and C. Williamson. </author> <title> Web server workload characterization: The search for invarients. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 126-138, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Therefore in this section we concentrate on determining the feasibility of predicting necessary transfer rates. The best transfer rate for the purpose of prefetching is dependent on the predicted time between document requests (OFF times). OFF times in network traffic have been analyzed in <ref> [3, 16, 1] </ref>; however these studies have not related OFF times to an independent variable which can be used for predictive purposes.
Reference: [2] <author> Azer Bestavros. </author> <title> Using speculation to reduce server load and service time on the www. In Proceedings of CIKM'95: </title> <booktitle> The 4 th ACM International Conference on Information and Knowledge Management, </booktitle> <address> Baltimore, Maryland, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Prefetching is an important technique for reducing latency in distributed systems. In distributed information systems like the World Wide Web, prefetching techniques attempt to predict the future requests of users based on past history, as observed at the client, server, or proxy <ref> [2, 12] </ref>. These techniques are speculative, in the sense that if predictions are incorrect then additional useless traffic 1 is added to the network. <p> In that work, Markov chains are proposed as a mechanism for determining which files to prefetch. The Markov chains are constructed based on prior access patterns of individual users. Simulations suggest that this method can also provide relatively high prefetching hit rates|between 80% and 90%. In <ref> [2] </ref> the notion of speculative prefetching by Web servers is presented in the context of replication services. This work shows that server information can also be profitably be used to increase prefetching hit rate.
Reference: [3] <author> Mark E. Crovella and Azer Bestavros. </author> <title> Self-similarity in world wide web traffic: Evidence and possible causes. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 160-169, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Recent evidence indicates that the Web in particular seems to exhibit heavy-tailed ON periods, and that this may be due to the sizes of files transferred via the Web <ref> [3] </ref>. We show evidence that the effect of prefetching in distributed information systems with heavy-tailed ON times is to lengthen the ON and OFF periods, resulting in increased burstiness at a wide range of scales. <p> Our results suggest that while simple prefetching (as is likely to be implemented in Web browsers) can degrade network performance, rate-controlled prefetching has the potential to significantly smooth traffic due to the World Wide Web. Since such traffic appears to be quite bursty without such controls <ref> [3] </ref>, an understanding of the effects of prefetching on burstiness is important, and in particular methods that allow Web applications to smooth their network demand are of considerable interest. 3 2 Background and Related Work The literature on prefetching is large; a good example article is [15]. <p> However, none of these proposals for Web prefetching consider the increase in burstiness of traffic caused by prefetching. Web traffic has been shown to be bursty at a wide range of scales ("self-similar") <ref> [3] </ref> and so this is an important issue. A number of previous papers have shown that the effects of self-similarity on network performance is primarily to increase queueing delays [5, 13] and so that is the network performance metric that we focus on in this paper. <p> As discussed in Section 2, the superimposition of heavy-tailed ON/OFF sources can produce self-similar traffic that is bursty at a wide range of scales. Previous work has suggested that the sessions present in these traces show heavy-tailed ON/OFF behavior <ref> [3] </ref>. Thus we expect that distribution plots of ON and OFF time will show long, power-law tails. In fact, these are evident in Figure 5. sets of files (when prefetching) correspond to ON times in the ON/OFF framework, idle periods when no transfers are taking place correspond to OFF times. <p> Therefore in this section we concentrate on determining the feasibility of predicting necessary transfer rates. The best transfer rate for the purpose of prefetching is dependent on the predicted time between document requests (OFF times). OFF times in network traffic have been analyzed in <ref> [3, 16, 1] </ref>; however these studies have not related OFF times to an independent variable which can be used for predictive purposes.
Reference: [4] <author> C. R. Cunha. </author> <title> Trace Analysis and its Applications to Performance Enhancements of Distributed Information Systems. </title> <type> PhD thesis, </type> <institution> Boston University, Boston, Massachusetts, </institution> <year> 1997. </year> <month> 21 </month>
Reference-contexts: The high hit rate obtainable suggests that our rate-contolled prefetching policies could have significant payoff in practice. A number of authors have presented prefetching methods specifically for the Web. In <ref> [4] </ref> the notion of prefetching by Web clients is presented. In that work, Markov chains are proposed as a mechanism for determining which files to prefetch. The Markov chains are constructed based on prior access patterns of individual users.
Reference: [5] <author> A. Erramilli, O. Narayan, and W. Willinger. </author> <title> Experimental queueing analysis with long-range dependent packet traffic. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 4(2) </volume> <pages> 209-223, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Web traffic has been shown to be bursty at a wide range of scales ("self-similar") [3] and so this is an important issue. A number of previous papers have shown that the effects of self-similarity on network performance is primarily to increase queueing delays <ref> [5, 13] </ref> and so that is the network performance metric that we focus on in this paper. There have been a number of studies of smoothing techniques for video streams, which are also bursty sources [7].
Reference: [6] <author> Sally Floyd. </author> <title> Simulator tests. </title> <note> Available at ftp://ftp.ee.lbl.gov/papers/simtests.ps.Z. ns is available at http://www-nrg.ee.lbl.gov/nrg., July 1995. </note>
Reference-contexts: In this section we describe these two tools. 3.1 Simulated Network In order to assess the network effects of document transfers, we used the ns network simulator (version 1.0), developed at LBNL <ref> [6] </ref>. Ns is an event-driven simulator that simulates individual packets flowing over a network of hosts, links, and gateways. It provides endpoint agents that can use any of several types of TCP as their transport protocols; we used TCP Reno. <p> In particular, ns simulates TCP Reno's flow control features: Slow Start, Congestion Avoidance, and Fast Retransmit/Recovery. A test suite describing validation results from the simulator can be found in <ref> [6] </ref>. This study used the simple network shown in Figure 1. The network nodes consist of 64 clients (C0 through C63), two routers (R0 and R1), and two servers (S0 and S1).
Reference: [7] <author> M. Garrett and W. Willinger. </author> <title> Analysis, modeling and generation of self-similar vbr video traffic. </title> <booktitle> In ACM SIGCOMM, </booktitle> <pages> pages 269-280, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: There have been a number of studies of smoothing techniques for video streams, which are also bursty sources <ref> [7] </ref>. In particular [14] presents an effective method for reducing the variability of transmitted bit rates for stored video.
Reference: [8] <author> Internet Town Hall. </author> <title> The internet traffic archives. </title> <note> Available at http://town.hall.org /Archives/pub/ITA/. </note>
Reference-contexts: Some simulations vary the payload size, but all packets have 24 byte headers. 3.2 Workload Characteristics The workload used to simulate user requests from the Web was a set of traces of Web sessions made at Boston University and available from the Internet Traffic Archives <ref> [8] </ref>. Each line of a trace file contains a session ID, the size of the file transferred, the start and finish time of transfer (measured to 10ms accuracy), and the URL of the file requested (which was not used in our simulation).
Reference: [9] <author> Leonard Kleinrock. </author> <title> Queueing Systems, volume I. Theory. </title> <publisher> John Wiley & Sons, </publisher> <year> 1975. </year>
Reference-contexts: This is because prefetching will increase the length of long packet interarrivals while increasing the number of short packet interarrivals. Increasing the coefficient of variation naturally increases queueing delays <ref> [9] </ref>. We focus on the World Wide Web as our application of interest; prefetching for the Web is an active area of study that has considerable practical value.
Reference: [10] <author> Hui Lei and Dan Duchamp. </author> <title> An analytical approach to file prefetching. </title> <booktitle> In USENIX Annual Technical Conference, </booktitle> <address> Anaheim CA, </address> <month> January </month> <year> 1997. </year>
Reference-contexts: That article points out the performance risks of prefetching due to increased data transfer traffic. More recent work on file prefetching <ref> [10] </ref> presents a method which uses access trees to represent file usage patterns. Using that approach, measurements show that future file accesses can be predicted with an accuracy of around 90%.
Reference: [11] <author> W.E. Leland, M.S. Taqqu, W. Willinger, and D.V. Wilson. </author> <title> On the self-similar nature of ethernet traffic (extended version). </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 2 </volume> <pages> 1-15, </pages> <year> 1994. </year>
Reference-contexts: Our simulations indicate that aggressive prefetching can increase average packet delays by a factor of two to four, depending on network configuration. For the case of the Web, these effects can be understood more precisely using the analytic framework provided by self-similar traffic models <ref> [11] </ref>.
Reference: [12] <author> Venkata N. Padmanabhan. </author> <title> Improving world wide web latency. </title> <type> Technical Report CSD-95-875, </type> <institution> Computer Science Department, University of California at Berkeley, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Prefetching is an important technique for reducing latency in distributed systems. In distributed information systems like the World Wide Web, prefetching techniques attempt to predict the future requests of users based on past history, as observed at the client, server, or proxy <ref> [2, 12] </ref>. These techniques are speculative, in the sense that if predictions are incorrect then additional useless traffic 1 is added to the network. <p> In [2] the notion of speculative prefetching by Web servers is presented in the context of replication services. This work shows that server information can also be profitably be used to increase prefetching hit rate. In addition, <ref> [12] </ref> simulates prefetching for the Web and shows that it can be effective in reducing latency. However, none of these proposals for Web prefetching consider the increase in burstiness of traffic caused by prefetching.
Reference: [13] <author> Kihong Park, Gi Tae Kim, and Mark E. Crovella. </author> <title> On the relationship between file sizes, transport protocols, and self-similar network traffic. </title> <booktitle> In Proceedings of the Fourth International Conference on Network Protocols (ICNP'96), </booktitle> <pages> pages 171-180, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Web traffic has been shown to be bursty at a wide range of scales ("self-similar") [3] and so this is an important issue. A number of previous papers have shown that the effects of self-similarity on network performance is primarily to increase queueing delays <ref> [5, 13] </ref> and so that is the network performance metric that we focus on in this paper. There have been a number of studies of smoothing techniques for video streams, which are also bursty sources [7].
Reference: [14] <author> James Salehi, Zhi-Li Zhang, James Kurose, and Don Towsley. </author> <title> Supporting stored video: Reducing rate variability and ene-to-end resource requirements through optimal smoothing. </title> <booktitle> In ACM SIGMETRICS, </booktitle> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: There have been a number of studies of smoothing techniques for video streams, which are also bursty sources [7]. In particular <ref> [14] </ref> presents an effective method for reducing the variability of transmitted bit rates for stored video.
Reference: [15] <author> A. Smith. </author> <title> Disk cache miss ratio analysis and design considerations. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 161-203, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: bursty without such controls [3], an understanding of the effects of prefetching on burstiness is important, and in particular methods that allow Web applications to smooth their network demand are of considerable interest. 3 2 Background and Related Work The literature on prefetching is large; a good example article is <ref> [15] </ref>. That article points out the performance risks of prefetching due to increased data transfer traffic. More recent work on file prefetching [10] presents a method which uses access trees to represent file usage patterns.
Reference: [16] <author> Walter Willinger, Murad S. Taqqu, Robert Sherman, and Daniel V. Wilson. </author> <title> Self-similarity through high-variability: Statistical analysis of ethernet lan traffic at the source level. </title> <booktitle> In Proceedings of ACM SIGCOMM '95, </booktitle> <pages> pages 100-113, </pages> <year> 1995. </year> <month> 22 </month>
Reference-contexts: Such models have shown that if individual applications exhibit ON/OFF behavior in generating traffic, such that either ON or OFF periods are drawn from a heavy-tailed distribution with ff &lt; 2, then the aggregate traffic can be expected to show self-similar scaling properties with scaling parameter H &gt; 1=2 <ref> [16] </ref>. Recent evidence indicates that the Web in particular seems to exhibit heavy-tailed ON periods, and that this may be due to the sizes of files transferred via the Web [3]. <p> during an ON period and are silent during an OFF period, and if either ON or OFF periods (or both) are drawn from 4 a heavy-tailed distribution (one whose tail follows a power-law with exponent less than 2) then the aggregation of many such sources will lead to self-similar traffic <ref> [16] </ref>. <p> Therefore in this section we concentrate on determining the feasibility of predicting necessary transfer rates. The best transfer rate for the purpose of prefetching is dependent on the predicted time between document requests (OFF times). OFF times in network traffic have been analyzed in <ref> [3, 16, 1] </ref>; however these studies have not related OFF times to an independent variable which can be used for predictive purposes.
References-found: 16

