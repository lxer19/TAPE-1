URL: ftp://dimacs.rutgers.edu/pub/dimacs/TechnicalReports/TechReports/1998/98-15.ps.gz
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1998.html
Root-URL: http://www.cs.rutgers.edu
Email: muchnik@dimacs.rutgers.edu  mottl@atm.tsu.tula.ru  
Title: Functions on Trees for Segmentation, Generalized Smoothing, Matching and Multi-Alignment in Massive Data Sets  
Author: by Ilya Muchnik Vadim Mottl 
Address: P.O. Box 5062 New Brunswick, NJ 08903-5062 USA  Lenin Ave. 92 300600 Tula Russia  
Affiliation: DIMACS, Rutgers University,  Tula State University  
Note: Bellman  DIMACS is a partnership of Rutgers University, Princeton University, AT&T Labs-Research, Bell Labs and Bellcore. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology.  
Abstract: DIMACS Technical Report 98-15 February 1998 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Besag, </author> <title> J.E. On the statistical analysis of dirty pictures (with discussion). </title> <journal> Journ. Royal Statist. Soc., </journal> <volume> B 48, </volume> <year> 1986, </year> <pages> pp. 259-302. </pages>
Reference-contexts: There are two basic principles which may be regarded as underlying the known algorithms of iterative optimization of separable functions. The first of them, usually referred to as ICM (iterated conditional modes) <ref> [1, 2, 3] </ref>, consists in improving the values of the goal variables x t at each t 2 T in turn, starting with an initial approximation. Each improvement is to be made so that the objective function would not decrease. <p> It is common practice to take the local conditional densities of the Markov random field from the class of the so-called Gibbs probability distributions <ref> [1, 4] </ref>, in which the density formula already contains 1=t in the exponent. Thus, the variety of known algorithmical means of finding the global optimum of a separable function of general kind is limited to the procedures of iterative random search.
Reference: [2] <author> Kittler, J., and Foglein, J. </author> <title> Contextual classification of multispectral pixel data. Image Vision Comput., </title> <booktitle> 1984, </booktitle> <volume> 2, </volume> <pages> 13-29. </pages>
Reference-contexts: There are two basic principles which may be regarded as underlying the known algorithms of iterative optimization of separable functions. The first of them, usually referred to as ICM (iterated conditional modes) <ref> [1, 2, 3] </ref>, consists in improving the values of the goal variables x t at each t 2 T in turn, starting with an initial approximation. Each improvement is to be made so that the objective function would not decrease.
Reference: [3] <author> Ripley, </author> <title> B.D. Statistics, images and pattern recognition (with discussion). </title> <journal> Canad. J. Statist., 1986, </journal> <volume> 14, </volume> <pages> pp. 83-111. </pages>
Reference-contexts: There are two basic principles which may be regarded as underlying the known algorithms of iterative optimization of separable functions. The first of them, usually referred to as ICM (iterated conditional modes) <ref> [1, 2, 3] </ref>, consists in improving the values of the goal variables x t at each t 2 T in turn, starting with an initial approximation. Each improvement is to be made so that the objective function would not decrease.
Reference: [4] <author> Geman, S., and Geman, D. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Trans. on PAMI, </journal> <volume> Vol. 6, </volume> <month> November </month> <year> 1984, </year> <pages> pp. 721-741. </pages>
Reference-contexts: In general, the search for the global optimum, let it be maximum, can be reported as combination of two principal ideas. The first idea is known under the name of stochastic relaxation <ref> [4] </ref>. Let the variety of combinations of argument values X = (x t ; t 2 T ) be considered as a random field, such that the greater the objective function J (X), the greater the logarithmic probability density log p (X) is assumed to be at realization X. <p> Such an idea is brought into reality by a procedure named Gibbs sampler <ref> [4, 7, 8, 9] </ref>. <p> It is common practice to take the local conditional densities of the Markov random field from the class of the so-called Gibbs probability distributions <ref> [1, 4] </ref>, in which the density formula already contains 1=t in the exponent. Thus, the variety of known algorithmical means of finding the global optimum of a separable function of general kind is limited to the procedures of iterative random search.
Reference: [5] <author> Smith, A.F.M., and Roberts, </author> <title> G.O. Bayesian computation via the Gibbs sampler and related Markov Chain Monte Carlo methods. </title> <journal> J. R. Statist. Soc., 1993, B55, </journal> <volume> No.1, </volume> <pages> pp. 3-23. </pages>
Reference-contexts: Such a method of simulating random realizations of random fields or processes is known under the abbreviation MCMC (Markov Chain Monte Carlo) <ref> [5, 6] </ref>. The second idea, that procured the name of simulated annealing, consists in gradual decreasing the randomness degree when simulating new values of the random field elements, with the purpose to make the random sequence of random field realizations converge to the non-random most likely realization.
Reference: [6] <author> Tierney, L. </author> <title> Markov chains for exploring posterior distributions. </title> <journal> The Annals of Statistics, 1994, </journal> <volume> Vol. 22, No. 4, </volume> <pages> pp. 1701-1762. </pages>
Reference-contexts: Such a method of simulating random realizations of random fields or processes is known under the abbreviation MCMC (Markov Chain Monte Carlo) <ref> [5, 6] </ref>. The second idea, that procured the name of simulated annealing, consists in gradual decreasing the randomness degree when simulating new values of the random field elements, with the purpose to make the random sequence of random field realizations converge to the non-random most likely realization.
Reference: [7] <author> Pincus, M. </author> <title> A closed form solution of certain programming problems. </title> <journal> Oper. Res., 1968, </journal> <volume> 16, </volume> <pages> pp. 690-694. </pages>
Reference-contexts: Such an idea is brought into reality by a procedure named Gibbs sampler <ref> [4, 7, 8, 9] </ref>.
Reference: [8] <author> Pincus, M. </author> <title> A Monte-Carlo method for the approximate solution of certain types of constrained optimization problems. </title> <journal> Oper. Res., 1970, </journal> <volume> 18, </volume> <pages> 1225-1228. </pages>
Reference-contexts: Such an idea is brought into reality by a procedure named Gibbs sampler <ref> [4, 7, 8, 9] </ref>.
Reference: [9] <author> Kirkpatrick, S., Gelatt, </author> <title> C.D., and Vecchi, M.P. Optimization by simulated annealing. </title> <booktitle> Science, 1983, </booktitle> <volume> 220, </volume> <pages> 671-680. </pages>
Reference-contexts: Such an idea is brought into reality by a procedure named Gibbs sampler <ref> [4, 7, 8, 9] </ref>.
Reference: [10] <author> Bellman, R. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, N.J., </address> <year> 1957. </year>
Reference-contexts: (x t1 )+fl t (x t1 ; x t ) x 0 h t1 )+fl t (x 0 i ; (3.17) Such an algorithm of finding the optimal values ^x 1 ; : : : ; ^x N is nothing else than a version of the classical dynamic programming procedure <ref> [10] </ref> widely adopted as a means of optimization of multi-stage processes.
Reference: [11] <author> Waterman, M.S., Smith, T.F., and Beyer, </author> <title> W.A. Some biological sequence metrics. </title> <booktitle> Advanced Mathematics, </booktitle> <volume> 20, </volume> <year> 1976, </year> <pages> pp. 367-387. </pages>
Reference: [12] <author> Taylor, W.R. </author> <title> Identification of protein sequence homology by consensus template alignment. </title> <journal> Journal of Molecular Biology, </journal> <volume> 188, </volume> <year> 1986, </year> <pages> pp. 233-258. </pages>
Reference-contexts: The elements of the pattern sequence take values from an appropriate set c i 2 C that may be different from the set Y of the original amino-acids and have the sense, for instance, of frequency distributions over Y or Y <ref> [12, 15] </ref>, functional descriptions of amino acid properties [12, 17], or subclasses of amino acids [16]. In accordance with the pattern-based strategy, the score of the mutual similarity of amino acids in a column should take into account the totality of their individual similarities to the respective pattern sequence element. <p> The elements of the pattern sequence take values from an appropriate set c i 2 C that may be different from the set Y of the original amino-acids and have the sense, for instance, of frequency distributions over Y or Y [12, 15], functional descriptions of amino acid properties <ref> [12, 17] </ref>, or subclasses of amino acids [16]. In accordance with the pattern-based strategy, the score of the mutual similarity of amino acids in a column should take into account the totality of their individual similarities to the respective pattern sequence element.
Reference: [13] <author> Taylor, W.R. </author> <title> A flexible method to align large numbers of biological sequences. </title> <journal> Journal of Molecular Evolution, </journal> <volume> 28, </volume> <year> 1988, </year> <pages> pp. 161-169. </pages>
Reference: [14] <author> Mirkin, B., and Roberts, </author> <title> F.S. Consensus functions and patterns in molecular sequences. </title> <type> Technical Report 92-37. </type> <institution> DIMACS, Rutgers University, </institution> <month> August, </month> <year> 1992. </year> <month> - 60 </month> - 
Reference: [15] <author> Gribskov, M., McLachlan A.D., and Eisenberg, D. </author> <title> Profile analysis: detection of distantly related proteins. </title> <booktitle> Proc. </booktitle> <institution> Nat. Acad. Sci. </institution> <address> USA, 84, </address> <year> 1987, </year> <pages> pp. 4355-4358. </pages>
Reference-contexts: The elements of the pattern sequence take values from an appropriate set c i 2 C that may be different from the set Y of the original amino-acids and have the sense, for instance, of frequency distributions over Y or Y <ref> [12, 15] </ref>, functional descriptions of amino acid properties [12, 17], or subclasses of amino acids [16]. In accordance with the pattern-based strategy, the score of the mutual similarity of amino acids in a column should take into account the totality of their individual similarities to the respective pattern sequence element.
Reference: [16] <author> Smith, R.F., and Smith, T.F. </author> <title> Pattern-induced multi-sequence alignment (PIMA) algorithm employing secondary structure-dependent gap penalties for use in comparative protein modeling. </title> <journal> Protein Engineering, </journal> <volume> 5, </volume> <year> 1992, </year> <pages> pp. 35-41. </pages>
Reference-contexts: underlaid by the supposition that the particular proteins in set Y are homologous to each other, i.e. have their origin in a common progenitor from which they diverged, through the natural course of evolution, by different chains of amino acid substitutions, deletions and insertions without, however, affecting the basic structure <ref> [16] </ref>. <p> take values from an appropriate set c i 2 C that may be different from the set Y of the original amino-acids and have the sense, for instance, of frequency distributions over Y or Y [12, 15], functional descriptions of amino acid properties [12, 17], or subclasses of amino acids <ref> [16] </ref>. In accordance with the pattern-based strategy, the score of the mutual similarity of amino acids in a column should take into account the totality of their individual similarities to the respective pattern sequence element. <p> But a more reasonable way of forming a discrete set of pattern elements is to interpret them as fuzzy subclasses of amino acids possessing some common properties c Y <ref> [16] </ref>. - 53 - In the latter case, the dissimilarity function '(c; y) should be chosen so that it takes the greater value the smaller is the membership degree y 2 c measured, for instance, by fuzzy membership index 0 I (y 2 c) 1.
Reference: [17] <author> Bashford, D., Chothia, C., and Lesk, </author> <title> A.M. Determinants of a protein fold. </title> <journal> Journal of Molecular Biology, </journal> <volume> 196, </volume> <year> 1987, </year> <pages> pp. 199-216. </pages>
Reference-contexts: The elements of the pattern sequence take values from an appropriate set c i 2 C that may be different from the set Y of the original amino-acids and have the sense, for instance, of frequency distributions over Y or Y [12, 15], functional descriptions of amino acid properties <ref> [12, 17] </ref>, or subclasses of amino acids [16]. In accordance with the pattern-based strategy, the score of the mutual similarity of amino acids in a column should take into account the totality of their individual similarities to the respective pattern sequence element.
Reference: [18] <author> Mottl, V.V., Kopylov, </author> <title> A.V., Blinov, A.B., and Zheltov, S.Yu. Quasi-statistical approach to the problem of stereo image matching. </title> <booktitle> Proceedings SPIE, </booktitle> <volume> 2363, </volume> <year> 1994, </year> <pages> pp. 50-61. </pages>
Reference-contexts: It is convenient to allow x t to take values from the two-dimensional real space X = R 2 , and, thereby, permit inter-pixel interpolation in the discrete image grid T <ref> [18] </ref>. The geophysical explorative data sets, seismic sections and cubes, are a class of, respectively, two- and three-dimensional data arrays, which are analyzed in the course of gas and oil reserves prospecting with the purpose of studying the structure of the underground rock mass. <p> The problem of matching is another example of image analysis problem for that the quadratic form of node and edge functions is completely consistent with the nature of the designed result of processing <ref> [18, 20, 21] </ref>. But the structure of the node functions required for mining the data-dependent information from the original image pair is inevitably much more complicated than in the case of smoothing. <p> As a rule, the horizontal axis is assumed to coincide, maybe, only approximately, with the so-called epipolar line, i.e. the line at which the two cameras having taken the pictures were located <ref> [18] </ref>.
Reference: [19] <author> Mottl, V.V., Muchnik, </author> <title> I.B., Ivanova, T.O., and Blinov, A.B. Automatic classification of local peculiarities in data fields with the use of hidden Markov models. In: Mathematical Problems of Classification, A.P. </title> <journal> Kovalenko, and B.G. Mirkin (Ed.). Survey of Applied and Industrial Mathematics, </journal> <volume> 3, No. </volume> <month> 1. </month> <title> Moscow, Publishing House "Probability Theory and its Applications", </title> <booktitle> 1996 (in Russian). </booktitle>
Reference-contexts: The simplest statement of the segmentation problem we consider here consists in the requirement to partition the pixel grid into an appropriate number of sufficiently prolonged regions of m classes each of which is associated with a known kind of texture <ref> [19, 20, 21] </ref>.
Reference: [20] <author> Mottl, V.V., Muchnik, </author> <title> I.B., Blinov, A.B., and Kopylov, A.V. Hidden tree-like quasi-Markov model and generalized technique for a class of image processing problems. </title> <booktitle> 13th International Conference on Pattern Recognition. </booktitle> <address> Vienna, Austria, </address> <month> August 25-29, </month> <year> 1996. </year> <booktitle> Track B, </booktitle> <pages> pp. 715-719. </pages>
Reference-contexts: image processing problems that the desired result of processing is meant as another function X = (x t ; t 2 T ) which would be defined on the same pixel grid t 2 T and take values x t 2 X from a set specific for each particular problem <ref> [20] </ref>. <p> The simplest statement of the segmentation problem we consider here consists in the requirement to partition the pixel grid into an appropriate number of sufficiently prolonged regions of m classes each of which is associated with a known kind of texture <ref> [19, 20, 21] </ref>. <p> It is just this algorithm by which the segmentation of the texture image in Fig. 2.1 was obtained. The problem of smoothing appears to be the simplest example of a data analysis problem for which quadratic node and edge functions are evidently suitable bases of its variational mathematical statement <ref> [20] </ref>. If the image darkness is represented by real numbers y t 1 t 2 2 Y = R, the result of smoothing will consist of real numbers, too, x t 1 t 2 2 X = R. <p> The problem of matching is another example of image analysis problem for that the quadratic form of node and edge functions is completely consistent with the nature of the designed result of processing <ref> [18, 20, 21] </ref>. But the structure of the node functions required for mining the data-dependent information from the original image pair is inevitably much more complicated than in the case of smoothing.
Reference: [21] <editor> Mottl, V.V., Blinov, A.B., Kopylov, A.V., and Kostin, A.A. </editor> <title> Optimization techniques on pixel neighborhood graphs for image processing. </title> <booktitle> Proceedings of the International Workshop on Graph-Based Representations. </booktitle> <address> Lyon, France, </address> <month> April 17-18, </month> <note> 1997 (to appear). </note>
Reference-contexts: The simplest statement of the segmentation problem we consider here consists in the requirement to partition the pixel grid into an appropriate number of sufficiently prolonged regions of m classes each of which is associated with a known kind of texture <ref> [19, 20, 21] </ref>. <p> The problem of matching is another example of image analysis problem for that the quadratic form of node and edge functions is completely consistent with the nature of the designed result of processing <ref> [18, 20, 21] </ref>. But the structure of the node functions required for mining the data-dependent information from the original image pair is inevitably much more complicated than in the case of smoothing.
Reference: [22] <author> Box, G.E.P., and Jenkins, G.M. </author> <title> Time Series Analysis. Forecasting and Control. </title> <publisher> Holden-Day, </publisher> <year> 1970. </year>
Reference-contexts: It is well known that the autore-gression model of a random process is completely equivalent to its frequency spectrum, or, in other terms, spectral density of its variance <ref> [22] </ref>.
References-found: 22

