URL: http://www.cs.kuleuven.ac.be/~wimv/Docs/icl_alt95_final.ps.gz
Refering-URL: http://www.cs.kuleuven.ac.be/~wimv/ICL/papers.html
Root-URL: 
Email: Email:fLuc.DeRaedt,Wim.VanLaerg@cs.kuleuven.ac.be  
Title: Inductive Constraint Logic  
Author: Luc De Raedt and Wim Van Laer 
Address: Celestijnenlaan 200A, B-3001 Heverlee, Belgium  
Affiliation: Department of Computer Science, Katholieke Universiteit Leuven  
Abstract: A novel approach to learning first order logic formulae from positive and negative examples is presented. Whereas present inductive logic programming systems employ examples as true and false ground facts (or clauses), we view examples as interpretations which are true or false for the target theory. This viewpoint allows to reconcile the inductive logic programming paradigm with classical attribute value learning in the sense that the latter is a special case of the former. Because of this property, we are able to adapt AQ and CN2 type algorithms in order to enable learning of full first order formulae. However, whereas classical learning techniques have concentrated on concept representations in disjunctive normal form, we will use a clausal representation, which corresponds to a conjuctive normal form where each conjunct forms a constraint on positive examples. This representation duality reverses also the role of positive and negative examples, both in the heuristics and in the algorithm. The resulting theory is incorporated in a system named ICL (Inductive Constraint Logic).
Abstract-found: 1
Intro-found: 1
Reference: [ Ade et al., 1995 ] <author> H. Ade, L. De Raedt, and M. Bruynooghe. </author> <title> Declarative Bias for Specific-To-General ILP Systems. </title> <booktitle> Machine Learning, </booktitle> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: As in CN2, we use beam search as search strategy. A classical refinement operator under -subsumption (Plokin 70, Shapiro 83) is used together with CLAUDIEN's mechanism to specify the declarative bias (i.e. the syntax of well-formed clauses in hypotheses), cf. <ref> [ Van Laer et al., 1994; Ade et al., 1995 ] </ref> and below. (Notice that whenever a clause c is true in an interpretation I, all refinements of c are also true in I.) The search starts with the most general clause of the refinement graph (namely false true, for wich <p> The declarative bias is the same as that in the CLAUDIEN system [ Van Laer et al., 1994 ] and in NINA <ref> [ Ade et al., 1995 ] </ref> . Basically, clause models are used to define the syntax of clauses that can appear in hypotheses. From the models, one can automatically derive a refinement operator that only generates clauses that are allowed by the syntax. <p> From the models, one can automatically derive a refinement operator that only generates clauses that are allowed by the syntax. A full discussion of this declarative bias mechanism is outside the scope of this paper, but see <ref> [ Ade et al., 1995; Van Laer et al., 1994 ] </ref> for more details. 4 Experiments In this section, we report on an experiment in the King-Rook-King domain of [ Mug-gleton et al., 1989 ] .
Reference: [ Clark and Niblett, 1989 ] <author> P. Clark and T. Niblett. </author> <title> The CN2 algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-284, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see <ref> [ Quinlan, 1986; Michalski, 1983; Clark and Niblett, 1989 ] </ref> , etc.) or the inductive logic programming paradigm [ Mug-gleton and De Raedt, 1994; Muggleton, 1992 ] . The differences between the two paradigms are due to the representation formalism employed. <p> Furthermore, as examples are interpre-tations, the heuristics will count interpretations. This contrasts ICL from other ILP algorithms (such as FOIL [ Quinlan, 1990 ] ) where one counts facts and/or substitutions. The ICL algorithm derived from CN2 <ref> [ Clark and Niblett, 1989 ] </ref> by exploiting this duality is shown in Figures 4 and 5 a set of positive examples P and negative examples N , the algorithm produces a theory H. <p> The second evaluation function tests whether a clause is statistically significant, to ensure that the clause represents a genuine regularity in the examples and not a regularity which is due to chance (see <ref> [ Lavrac and Dzeroski, 1994; Clark and Niblett, 1989 ] </ref> ). The statistical significance test is based on the likelihood ratio statistic, which is also employed in CN2.
Reference: [ De Raedt and Dzeroski, 1994 ] <author> L. De Raedt and S. Dzeroski. </author> <title> First order jk-clausal theories are pac-learnable. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 375-392, </pages> <year> 1994. </year>
Reference-contexts: A possible explanation for this comes from the fact that in attribute value learning examples are true and false interpretations (models and non-models, or positive and negative examples) of a target theory, whereas in inductive logic programming, examples are true and false facts (or clauses). Recently, <ref> [ De Raedt and Dzeroski, 1994 ] </ref> have suggested this is as a possible explanation why PAC-learning results for inductive logic programming are so hard to obtain and mostly negative. <p> However, when interpretations may be infinite (f.i. in the presence of functor symbols), testing for coverage is no longer decidable. A (rather technical) approach to circumventing this problem based on [ Rouveirol, 1994 ] , is given in <ref> [ De Raedt and Dzeroski, 1994 ] </ref> . Another point of difference is that in ICL 11 Fig. 7. Results of the King-Rook-King experiment all clauses are considered independent constraints, whereas in ILP clauses may be mutually dependent, complicating coverage tests [ De Raedt et al., 1993 ] .
Reference: [ De Raedt et al., 1993 ] <author> L. De Raedt, N. Lavrac, and S. Dzeroski. </author> <title> Multiple predicate learning. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1037-1042. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Another point of difference is that in ICL 11 Fig. 7. Results of the King-Rook-King experiment all clauses are considered independent constraints, whereas in ILP clauses may be mutually dependent, complicating coverage tests <ref> [ De Raedt et al., 1993 ] </ref> . Fourth, the clausal logic we employ allows to easily express some concepts which are hard (or impossible) to express using the normal inductive logic programming paradigm and definite clauses.
Reference: [ Dietterich and Michalski, 1985 ] <author> T.G. Dietterich and R.S. Michalski. </author> <title> Discovering patterns in sequences of events. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 257-294, </pages> <year> 1985. </year>
Reference-contexts: This can also be read as : if a figure has a circle inside another object, it is of class . Example 3. A well known problem in the context of inductive logic programming is the card game of Eleusis. The problem was first decribed by Dietterich and Michalski <ref> [ Dietterich and Michalski, 1985 ] </ref> , and later employed by Quinlan [ Quinlan, 1990 ] , and Lavrac and Dzeroski [ Lavrac and Dzeroski, 1994 ] . There are two players.
Reference: [ Genesereth and Nilsson, 1987 ] <author> M. Genesereth and N. Nilsson. </author> <booktitle> Logical foundations of artificial intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: the ICL algorithm for inducing clausal theories, in Section 4, we report on some preliminary experiments, and in Section 5 we discuss related and further work and finally conclude in Section 6. 2 Inductive constraint logic: definitions and framework We assume familiarity with first order logic and model theory (see <ref> [ Lloyd, 1987; Genesereth and Nilsson, 1987 ] </ref> for an introduction). A first order alphabet is a set of predicate symbols, constant symbols and functor symbols.
Reference: [ Haussler, 1988 ] <author> D. Haussler. </author> <title> Quantifying inductive bias : AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36:177 - 221, </volume> <year> 1988. </year>
Reference-contexts: The duality between CNF and DNF can easily be exploited by inversing well-known algorithms (such as AQ and CN2) that learn disjunctive normal forms to learn CNF formula (cf. also <ref> [ Haussler, 1988 ] </ref> ). It is because of this property that we will pursue a covering approach on the negatives instead of the positives, and also generally invert the role of positives and negatives. Also, in the heuristics the role 7 of positives and negatives will be swapped. <p> Secondly, some of the ideas on reversing the role of positives and negatives when going from CNF to DNF or vice versa, were presented in <ref> [ Haussler, 1988 ] </ref> and in [ Mooney, 1995 ] . Given Haussler's results it was relatively easy to turn ideas of Clark and Niblett's CN2 into ICL.
Reference: [ King et al., 1992 ] <author> R.D. King, S. Muggleton, R.A. Lewis, and M.J.E. Sternberg. </author> <title> Drug design by machine learning: the use of inductive logic programming to model the structure-activity relationships of trimethoprim analogues binding to dihydrofolate reductase. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 89(23), </volume> <year> 1992. </year>
Reference-contexts: Furthermore, for many complex and structural induction problems the 6 view that examples are interpretations is a very natural one, cf. for instance the drug activity problem <ref> [ King et al., 1992 ] </ref> the mutagenicity [ Srinivasan et al., 1994 ] and Michalski's classical eastbound westbound train problem [ Michalski and Stepp, 1983 ] that was recently used as the basis for a machine learning competition. 3 Inductive Constraint Logic: a first algorithm The key observation to arrive
Reference: [ Lavrac and Dzeroski, 1994 ] <author> N. Lavrac and S. Dzeroski. </author> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <year> 1994. </year>
Reference-contexts: Example 3. A well known problem in the context of inductive logic programming is the card game of Eleusis. The problem was first decribed by Dietterich and Michalski [ Dietterich and Michalski, 1985 ] , and later employed by Quinlan [ Quinlan, 1990 ] , and Lavrac and Dzeroski <ref> [ Lavrac and Dzeroski, 1994 ] </ref> . There are two players. <p> Two Eleusis layouts 5 Two example sequences can be found in figure 3 (from <ref> [ Lavrac and Dzeroski, 1994 ] </ref> ). Two consecutive cards on the main line satifies the secret rule. These can be used as positive examples. Each card on a side line is an illegal successor of the corresponding card on the main line. <p> The quality of a clause c is determined by the probability that an example interpretation is negative, given that clause c is false in the interpretation, i.e. p (jc). Notice the difference with classical attribute value learning, where p (jc) is used (see <ref> [ Lavrac and Dzeroski, 1994 ] </ref> ). <p> The second evaluation function tests whether a clause is statistically significant, to ensure that the clause represents a genuine regularity in the examples and not a regularity which is due to chance (see <ref> [ Lavrac and Dzeroski, 1994; Clark and Niblett, 1989 ] </ref> ). The statistical significance test is based on the likelihood ratio statistic, which is also employed in CN2. <p> Secondly, we can stop refining a clause when it's not possibly statistically significant (cfr. mFoil <ref> [ Lavrac and Dzeroski, 1994 ] </ref> ). Notice that the refinement operator in ICL is a classical one based on Plotkin's -subsumption [ Plotkin, 1970 ] . <p> The experiment mainly serves to demonstrate the performance of ICL on a larger domain involving noise. The same experimental setting and the same data as <ref> [ Lavrac and Dzeroski, 1994 ] </ref> was employed. The significance level of ICL was set to 99 per cent. There were for all different noise levels, 5 runs of 100 examples (60 positive examples and 40 negatives), whereas the testset contained 5000 examples.
Reference: [ Lloyd, 1987 ] <author> J.W. Lloyd. </author> <title> Foundations of logic programming. </title> <publisher> Springer-Verlag, </publisher> <address> 2nd edition, </address> <year> 1987. </year>
Reference-contexts: the ICL algorithm for inducing clausal theories, in Section 4, we report on some preliminary experiments, and in Section 5 we discuss related and further work and finally conclude in Section 6. 2 Inductive constraint logic: definitions and framework We assume familiarity with first order logic and model theory (see <ref> [ Lloyd, 1987; Genesereth and Nilsson, 1987 ] </ref> for an introduction). A first order alphabet is a set of predicate symbols, constant symbols and functor symbols.
Reference: [ Michalski and Stepp, 1983 ] <author> R.S. Michalski and R.E. Stepp. </author> <title> Learning from observation: conceptual clustering. </title> <editor> In R.S Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: an artificial intelligence approach, </booktitle> <volume> volume 1. </volume> <publisher> Tioga Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: Furthermore, for many complex and structural induction problems the 6 view that examples are interpretations is a very natural one, cf. for instance the drug activity problem [ King et al., 1992 ] the mutagenicity [ Srinivasan et al., 1994 ] and Michalski's classical eastbound westbound train problem <ref> [ Michalski and Stepp, 1983 ] </ref> that was recently used as the basis for a machine learning competition. 3 Inductive Constraint Logic: a first algorithm The key observation to arrive at the ICL algorithm is the following.
Reference: [ Michalski, 1983 ] <author> R.S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In R.S Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: an artificial intelligence approach, </booktitle> <volume> volume 1. </volume> <publisher> Morgan Kaufmann, </publisher> <year> 1983. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see <ref> [ Quinlan, 1986; Michalski, 1983; Clark and Niblett, 1989 ] </ref> , etc.) or the inductive logic programming paradigm [ Mug-gleton and De Raedt, 1994; Muggleton, 1992 ] . The differences between the two paradigms are due to the representation formalism employed. <p> Given Haussler's results it was relatively easy to turn ideas of Clark and Niblett's CN2 into ICL. Finally, we believe ICL is also similar in spirit as Michalski's work <ref> [ Michalski, 1983 ] </ref> on learning structural concept definitions, in that it addresses the same learning task. However, the use of a formal logical framework as well as more advanced attribute value learning techniques distinguishes ICL from AQ.
Reference: [ Mooney, 1995 ] <author> R.J. Mooney. </author> <title> Encouraging experimental results on learning cnf. </title> <journal> Machine Learning, </journal> <volume> 19 </volume> <pages> 79-92, </pages> <year> 1995. </year>
Reference-contexts: Furthermore, as examples are interpretations, most of the other attribute value learning techniques, such as noise handling heuristics, will nicely upgrade towards our framework. Some of these ideas (like the swapping of positives and negatives) can also be found in <ref> [ Mooney, 1995 ] </ref> . However, our approach is more general, as we work with a first order logic representation and with examples as interpretations. <p> Secondly, some of the ideas on reversing the role of positives and negatives when going from CNF to DNF or vice versa, were presented in [ Haussler, 1988 ] and in <ref> [ Mooney, 1995 ] </ref> . Given Haussler's results it was relatively easy to turn ideas of Clark and Niblett's CN2 into ICL.
Reference: [ Muggleton and De Raedt, 1994 ] <author> S. Muggleton and L. De Raedt. </author> <title> Inductive logic programming : Theory and methods. </title> <journal> Journal of Logic Programming, </journal> <volume> 19,20:629-679, </volume> <year> 1994. </year>
Reference-contexts: First, notice that ICL is meant to learn binary concepts from examples. As such it addresses the same task as propositional learners (but in a more expressive framework) and it does not learn logic programs from examples as many ILP systems do cf. <ref> [ Muggleton and De Raedt, 1994 ] </ref> . In ILP, examples are usually true and false ground facts of a target predicate, and the result is a logic program.
Reference: [ Muggleton et al., 1989 ] <author> S. Muggleton, M. Bain, J. Hayes-Michie, and D. Michie. </author> <title> An experimental comparison of human and machine learning formalisms. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pages 113-118. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [ Muggleton, 1992 ] <editor> S. Muggleton, editor. </editor> <booktitle> Inductive Logic Programming. </booktitle> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see [ Quinlan, 1986; Michalski, 1983; Clark and Niblett, 1989 ] , etc.) or the inductive logic programming paradigm <ref> [ Mug-gleton and De Raedt, 1994; Muggleton, 1992 ] </ref> . The differences between the two paradigms are due to the representation formalism employed.
Reference: [ Plotkin, 1970 ] <author> G. Plotkin. </author> <title> A note on inductive generalization. </title> <booktitle> In Machine Intelligence, </booktitle> <volume> volume 5, </volume> <pages> pages 153-163. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1970. </year>
Reference-contexts: Secondly, we can stop refining a clause when it's not possibly statistically significant (cfr. mFoil [ Lavrac and Dzeroski, 1994 ] ). Notice that the refinement operator in ICL is a classical one based on Plotkin's -subsumption <ref> [ Plotkin, 1970 ] </ref> .
Reference: [ Quinlan, 1986 ] <author> J.R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see <ref> [ Quinlan, 1986; Michalski, 1983; Clark and Niblett, 1989 ] </ref> , etc.) or the inductive logic programming paradigm [ Mug-gleton and De Raedt, 1994; Muggleton, 1992 ] . The differences between the two paradigms are due to the representation formalism employed.
Reference: [ Quinlan, 1990 ] <author> J.R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Example 3. A well known problem in the context of inductive logic programming is the card game of Eleusis. The problem was first decribed by Dietterich and Michalski [ Dietterich and Michalski, 1985 ] , and later employed by Quinlan <ref> [ Quinlan, 1990 ] </ref> , and Lavrac and Dzeroski [ Lavrac and Dzeroski, 1994 ] . There are two players. <p> Also, in the heuristics the role 7 of positives and negatives will be swapped. Furthermore, as examples are interpre-tations, the heuristics will count interpretations. This contrasts ICL from other ILP algorithms (such as FOIL <ref> [ Quinlan, 1990 ] </ref> ) where one counts facts and/or substitutions.
Reference: [ Rouveirol, 1994 ] <author> C. </author> <title> Rouveirol. Flattening and saturation: Two representation changes for generalization. </title> <journal> Machine Learning, </journal> <volume> 14 </volume> <pages> 219-232, </pages> <year> 1994. </year>
Reference-contexts: However, when interpretations may be infinite (f.i. in the presence of functor symbols), testing for coverage is no longer decidable. A (rather technical) approach to circumventing this problem based on <ref> [ Rouveirol, 1994 ] </ref> , is given in [ De Raedt and Dzeroski, 1994 ] . Another point of difference is that in ICL 11 Fig. 7.
Reference: [ Shapiro, 1983 ] <author> E.Y. Shapiro. </author> <title> Algorithmic Program Debugging. </title> <publisher> The MIT Press, </publisher> <year> 1983. </year>
Reference-contexts: Notice that the refinement operator in ICL is a classical one based on Plotkin's -subsumption [ Plotkin, 1970 ] . Though a complete refinement operator for clausal logic could be employed by ICL (as is given in for instance in <ref> [ Shapiro, 1983; van der Laag and Nienhuys-Cheng, 1993 ] </ref> , we choose to enhance ICL with a declarative bias mechanism for restricting the search space.
Reference: [ Srinivasan et al., 1994 ] <author> A. Srinivasan, S.H. Muggleton, R.D. King, and M.J.E. Sternberg. Mutagenesis: </author> <title> Ilp experiments in a non-determinate biological domain. </title> <editor> In S. Wrobel, editor, </editor> <booktitle> Proceedings of the 4th International Workshop on Inductive Logic Programming, volume 237 of GMD-Studien, </booktitle> <pages> pages 217-232. </pages> <institution> Gesellschaft fur Mathematik und Datenver-arbeitung MBH, </institution> <year> 1994. </year>
Reference-contexts: Furthermore, for many complex and structural induction problems the 6 view that examples are interpretations is a very natural one, cf. for instance the drug activity problem [ King et al., 1992 ] the mutagenicity <ref> [ Srinivasan et al., 1994 ] </ref> and Michalski's classical eastbound westbound train problem [ Michalski and Stepp, 1983 ] that was recently used as the basis for a machine learning competition. 3 Inductive Constraint Logic: a first algorithm The key observation to arrive at the ICL algorithm is the following.
Reference: [ van der Laag and Nienhuys-Cheng, 1993 ] <author> P.R.J. van der Laag and S.-H. Nienhuys-Cheng. </author> <title> Subsumption and refinement in model inference. </title> <editor> In P. Brazdil, editor, </editor> <booktitle> Proceedings of the 6th European Conference on Machine Learning, volume 667 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 95-114. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Notice that the refinement operator in ICL is a classical one based on Plotkin's -subsumption [ Plotkin, 1970 ] . Though a complete refinement operator for clausal logic could be employed by ICL (as is given in for instance in <ref> [ Shapiro, 1983; van der Laag and Nienhuys-Cheng, 1993 ] </ref> , we choose to enhance ICL with a declarative bias mechanism for restricting the search space.
Reference: [ Van Laer et al., 1994 ] <author> W. Van Laer, L. Dehaspe, and L. De Raedt. </author> <title> Applications of a logical discovery engine. </title> <booktitle> In Proceedings of the AAAI Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 263-274, </pages> <year> 1994. </year> <title> This article was processed using the L A T E X macro package with LLNCS style 15 </title>
Reference-contexts: These can be used as positive examples. Each card on a side line is an illegal successor of the corresponding card on the main line. So these two cards can be seen as a negative example. Each example (a set of two cards) is translated (as in <ref> [ Van Laer et al., 1994 ] </ref> ) into one fact of the form: canfollow (R 2 ; S 2 ; R 1 ; S 1 ), which states that a card of rank R 2 and suit S 2 can follow a sequence ending with a card of rank R <p> As in CN2, we use beam search as search strategy. A classical refinement operator under -subsumption (Plokin 70, Shapiro 83) is used together with CLAUDIEN's mechanism to specify the declarative bias (i.e. the syntax of well-formed clauses in hypotheses), cf. <ref> [ Van Laer et al., 1994; Ade et al., 1995 ] </ref> and below. (Notice that whenever a clause c is true in an interpretation I, all refinements of c are also true in I.) The search starts with the most general clause of the refinement graph (namely false true, for wich <p> The declarative bias is the same as that in the CLAUDIEN system <ref> [ Van Laer et al., 1994 ] </ref> and in NINA [ Ade et al., 1995 ] . Basically, clause models are used to define the syntax of clauses that can appear in hypotheses. <p> From the models, one can automatically derive a refinement operator that only generates clauses that are allowed by the syntax. A full discussion of this declarative bias mechanism is outside the scope of this paper, but see <ref> [ Ade et al., 1995; Van Laer et al., 1994 ] </ref> for more details. 4 Experiments In this section, we report on an experiment in the King-Rook-King domain of [ Mug-gleton et al., 1989 ] .
References-found: 24

