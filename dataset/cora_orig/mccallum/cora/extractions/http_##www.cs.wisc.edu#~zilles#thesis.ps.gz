URL: http://www.cs.wisc.edu/~zilles/thesis.ps.gz
Refering-URL: http://www.cs.wisc.edu/~zilles/zilles.html
Root-URL: 
Title: Haptic Rendering with the Toolhandle Haptic Interface  Principle Research Scientist  
Author: by Craig B. Zilles J. Kenneth Salisbury 
Degree: Submitted to the Department of Mechanical Engineering in partial fulfillment of the requirements for the degrees of Master of Science and Bachelor of Science in  All rights reserved. Author  Certified by  Thesis Supervisor Accepted by Ain A. Sonin Chairman, Departmental Committee on Graduate Students  
Date: May 1995  May 12, 1995  
Affiliation: Mechanical Engineering at the MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1995.  Department of Mechanical Engineering  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Haruhiko Asada and Jean-Jacques E. Slotine. </author> <title> Robot Analysis and Control. </title> <publisher> John Wiley and Sons, </publisher> <year> 1985. </year>
Reference-contexts: The pivots where the horizontal links meet the vertical link are not in line with the first gimbal axis. The kinematics are presented using Denavit-Hartenberg notation. 3 <ref> [1] </ref> The Denavit-Hartenberg notation provides a sequence of transformations using a minimum of parameters to completely describe the kinematics. Six 4x4 matrices are used to transform both orientation and location.
Reference: [2] <author> J. F. </author> <title> Blinn. Simulation of wrinkled surfaces. </title> <booktitle> In SIGGRAPH, </booktitle> <pages> pages 286-292, </pages> <year> 1978. </year>
Reference-contexts: These small displacements give rise to a new shape and this new shape means that the surface has new surface normals. A good approximation to the new normal is: <ref> [2] </ref> N new = N + fi fi (4.11) where N is the surface normal, B u and B v are the partial derivatives of the bump map with respect to the u and v directions, and P s and P t are the partial derivatives of the equation P =
Reference: [3] <author> Fredrick P. Brooks, Ming Ouh-Young, James J. Batter, and P. Jerome Kilpatrick. </author> <title> Project GROPE - haptic displays for scientific visualization. </title> <journal> In Computer Graphics, </journal> <volume> volume 24-4, </volume> <pages> pages 177-185, </pages> <address> Dallas, Texas, </address> <month> August </month> <year> 1990. </year> <note> ACM. </note>
Reference-contexts: Noll expected that haptic interfaces could replace graphic interfaces for 3D visualization. Around the same time, Project GROPE was started at U.N.C. Chapel Hill to create a system for better scientific visualization. <ref> [3] </ref> Argonne National Labs donated a 7-DOF (6 + grip) remote manipulator they no longer needed. Their first simulated world consisted of a table and a number of blocks which could be manipulated by the user; only forces, no torques, were provided as haptic feedback.
Reference: [4] <author> G. Burdia, J. Zhuang, E. Roskos, D. Silver, and N. Langrana. </author> <title> A portable dextrous master with force feedback. </title> <journal> Presence, </journal> <volume> 1(1) </volume> <pages> 18-28, </pages> <year> 1992. </year>
Reference-contexts: Single DOF interfaces avoid the problems associated with complex geometry and allow concentration on the individual haptic effects. Grigore Burdia's research group has been developing a non-ground-based force feedback glove at Rutgers University. <ref> [4] </ref> Using pneumatic cylinders and LVDT's, the Rutgers Dextrous Master can provide forces against grasping objects. Although quite an improvement over traditional (passive) data gloves, the glove displays only grasp forces and cannot display net forces.
Reference: [5] <author> J. Edward Colgate and J. Michael Brown. </author> <title> Factors affecting the Z-range of a haptic display. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 3205-3210, </pages> <year> 1994. </year>
Reference-contexts: The work covers both point-object interactions and object-object interactions. At Northwestern University, J. Edward Colgate has been investigating passivity in the human-machine control loop and the hardware and software requirements for stiff virtual walls. <ref> [5] </ref> Much of this work involves single degree of freedom haptic interfaces. Single DOF interfaces avoid the problems associated with complex geometry and allow concentration on the individual haptic effects. <p> These control limitations put even more pressure on the mechanical designer to remove inertia and friction from the design. Some of the literature in haptic interfaces concentrates on the development of control techniques to increase the stiffness of walls. <ref> [5, 17] </ref> Although we've found that high haptic stiffness is not necessary for the perception of solid objects, the research in this field seems to be orthogonal to research into rendering methods. <p> When the gain is set too high a natural mode of the device is excited and the device begins to vibrate. Future revisions should probably replace the injection molded plastic parts with aluminum, and use larger diameter carbon fiber tubing 18 ness <ref> [5] </ref>, but could have disastrous effects on the force bandwidth. To overcome the physical damping, negative damping could be supplied in software. As was pointed out in Section 2.1.6 we can really only trade viscosity for inertia, and either of these will reduce the force bandwidth of the device.
Reference: [6] <editor> Nat Durlach et al., editors. </editor> <title> Virtual Reality: Scientific and Technological Challenges, </title> <type> chapter 4: </type> <institution> Haptic Interfaces. National Academy of Sciences, </institution> <address> Washington D.C., </address> <month> December </month> <year> 1994. </year> <note> Report produced for the National Research Council. </note>
Reference-contexts: The following is an over-simplification of the issues, but contains some good guidelines and rules of thumb. For a more rigorous treatment of psychophysics, we recommend reading the literature in that field. <ref> [6, 20] </ref> 2.1.1 Touch modalities The major goal of a haptic interface is to provide the sensations a user would experience if he/she were to touch a virtual environment. This problem has a number of issues, the most notable of which involve how humans sense. <p> Given a reference to compare against the human does much better. A pinch grasp to gauge length has a JND around 5-10 percent of the reference length. <ref> [6] </ref> It will be important to have the virtual objects correctly registered with respect to each other, especially if the user has multiple fingers in the virtual environment. <p> Humans are competent, but not astonishing, at comparing force magnitudes; the JND's for force magnitude are around 5-15 percent of the reference force. Characterization of compliance is still rather lacking. JND's for compliance can range from 5-99 percent. <ref> [6] </ref> "For deformable objects with rigid surfaces held in a pinch grasp, the JND for compliance is about 5-15 percent when the displacement range is fixed, increases to 22 percent when it is varied randomly, and can be as high as 99 percent when cues arising out of mechanical work done <p> Due to their presence humans can "distinguish vibration sequences of up to 1 kHz through the tactile sense." <ref> [6] </ref> It is important that our haptic system not have spurious vibrations below this frequency or they will eclipse the signal trying to be transmitted. <p> This is one of the reasons that our high performance haptic systems run their servo loops above 1kHz. The cognitive interpretation of forces appears not to be taking place at such a high frequency. "The bandwidth of the kinesthetic sensing system has been estimated to be 20-30Hz." <ref> [6] </ref> This means that the positions of objects in the virtual environment might not have to be updated as often as the force on the haptic interface as long as it does not induce vibration. <p> range, bandwidth, and stiffness are highly coupled in their dependencies on the device and on the servo rate of the simulation. 2.1.6 Control methods Some researchers have postulated that "in order to achieve such high performance without mechanical instabilities, robust and adaptive closed loop control of the devices is necessary." <ref> [6] </ref> We have not found this to be the case. Our devices do not sense force, are open loop (they use a human to close the loop), and utilize simple control laws (Hooke's Law (F=kx) or single sided PD control).
Reference: [7] <author> Paul Dworkin and David Zeltzer. </author> <title> A new model for efficient dynamic simulation. </title> <booktitle> In Proceedings Fourth Eurographics Workshop on Animation and Simulation, </booktitle> <pages> pages 135-147, </pages> <year> 1993. </year>
Reference-contexts: The term god-object has been previously used in a similar spirit to describe a virtual object controlled by a human user in physical simulations. <ref> [7] </ref> Using the history (the god-object location calculated in the previous servo cycle) and the current haptic interface point, a set of surfaces currently impeding motion can be found. A discussion of constraints is given in Section 3.2.2.
Reference: [8] <author> James Foley, Andries van Dam, Steven Feiner, and John Hughes. </author> <title> Computer Graphics: </title> <booktitle> Principles and Practice. </booktitle> <publisher> Addison Wesley, </publisher> <year> 1992. </year>
Reference-contexts: With virtual objects there is no such constraint; the surface normal can be decoupled from the shape of the object. Our smoothing algorithm is very reminiscent of Phong shading used in graphics. <ref> [8] </ref> A surface normal is associated with each node in each polygon. The appropriate surface normal can then be computed for any location (point D) in the polygon by interpolating between the normals at its three nodes (A, B, and C).
Reference: [9] <author> Tetsuo Kotoku, Kiyoshi Komoriya, and Kazuo Tanie. </author> <title> A robot simulator with force generating function configuration space approach. </title> <booktitle> SICE, </booktitle> <year> 1992. </year>
Reference-contexts: There are far too many projects to mention all of them. The following represents a cross-section of the work being done. In the early 90's, the Mechanical Engineering Laboratory in Japan started what could be the first work in simulating complex surface geometry. <ref> [9] </ref> They seem to have modeled reasonably simple objects, but they took a surface representation approach which is portable to higher complexity objects. The work covers both point-object interactions and object-object interactions. At Northwestern University, J.
Reference: [10] <author> Ming C. Lin, D. Manocha, and John Canny. </author> <title> Fast collision detection between geometric models. </title> <type> Tech Report TR93-004, </type> <institution> Department of Computer Science, University of North Carolina, </institution> <year> 1993. </year>
Reference-contexts: With our point among objects paradigm, collision detection is straight forward, but can still be computationally intensive. The human haptic system requires a servo loop on the order of 1 kHz; if complex models are to be simulated then sophisticated collision detection algorithms are needed. <ref> [10] </ref> The rendering algorithms themselves are very local in nature and can be decoupled from the complex collision detection algorithms, as they are in this thesis. One difficulty in haptic rendering is due to the inherent mechanical compliance of haptic interface devices.
Reference: [11] <author> Thomas Massie. </author> <title> Design of a force reflecting fingertip stimulator. </title> <type> Bachelor's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, MIT, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Our group at the A.I. Lab has used the PHANToM to approach issues including surface effects, arbitrary shaped objects, and the complex impedance blending methods which sophisticated surgical simulations and other training aides will require. <ref> [11, 18] </ref> 1.2 Thesis Overview This thesis endeavors to illuminate two areas of active research in haptic displays: haptic interface design and haptic rendering. <p> These haptically challenged subjects seem not to be able to interpret a spatial distribution forces as a shape. 2.1.5 Design Issues for Ground-based Haptic Interfaces We can categorize our knowledge of human perceptions into design criteria for designing haptic interfaces. <ref> [11] </ref> We'd like to be able to simulate the spectrum of forces between static contact and instantaneous impact. We'll see that a large force range, a high force bandwidth, and a high maximum stiffness will be needed to attain those goals. <p> When both fields become mature they should be easy to integrate. 2.2 MIT-Toolhandle The MIT-Toolhandle is an extension of the PHANToM <ref> [11] </ref> haptic interface using the tool handle paradigm (described in Section 2.1.1).
Reference: [12] <author> Thomas Massie and J. Kenneth Salisbury. </author> <title> The PHANToM haptic interface: A device for probing virtual objects. In Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, </title> <address> Chicago, IL, </address> <month> November </month> <year> 1994. </year> <booktitle> Proceedings of the ASME Winter Annual Meeting. </booktitle> <pages> 45 </pages>
Reference-contexts: In fact, often subjects are so immersed that they are startled when the simulation is turned off; "the feeling is similar to sitting down in a chair only to find that it has been pulled out from beneath you." <ref> [12] </ref> 1.1 A Brief History of Haptics Some of the first applications for haptic interfaces were in the 1960's and 1970's. 1 A. <p> These methods use volumes to compute forces rather than the more physically real effects of interacting with surfaces. One method handles the location ambiguity (mentioned above) by subdividing the object volume and associating a sub-volume with each surface. <ref> [12] </ref> In two dimensions, the vector field method subdivides the square's area and assumes that the user entered from the closest edge (Figure 3-2.b). The force vectors are normal to the edge and proportional to distance penetrated. <p> For example, spheres display a feedback force in the direction of the vector pointing from the sphere's center to the haptic interfaces point with a magnitude that is a function of the distance the point has penetrated the sphere's surface. <ref> [12] </ref> The inherent simplicity of these methods has allowed interesting work in dynamic objects and surface effects, [18] but the methods are not flexible enough to allow arbitrary geometries. The drawbacks of vector field methods are: 1.
Reference: [13] <author> Margaret Minsky. </author> <title> Computational Haptics: The Sandpaper System for Synthesizing Texture for a Force-Feedback Display. </title> <type> PhD thesis, </type> <institution> Media Lab, MIT, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: This was an important step for the acceptance of haptics, but the task was too specialized to have provided research into a broad cross-section of haptic effects. A more complete set of haptic effects was studied by Margaret Minsky using the Sandpaper system. <ref> [13, 14] </ref> The Sandpaper system consisted of a 2-DOF joystick with force feedback for simulating 1 Margaret Minsky's PhD thesis [13] includes a more complete, yet terse list of the research of haptic interfaces. 8 texture. <p> A more complete set of haptic effects was studied by Margaret Minsky using the Sandpaper system. [13, 14] The Sandpaper system consisted of a 2-DOF joystick with force feedback for simulating 1 Margaret Minsky's PhD thesis <ref> [13] </ref> includes a more complete, yet terse list of the research of haptic interfaces. 8 texture. Multiple subjects arranged the textures by roughness in a consistent manner, suggesting that users were able to recognize the textures enough to discriminate and classify them. <p> The neurons we are trying to stimulate are perceptive to high frequencies (10-1000Hz); if the "period" of this variation is too large then it will be hard to perceive. Extensive work on texture has been done with a two degree-of-freedom haptic interface including an attempt to categorize textures. <ref> [13] </ref> This work is important for understanding the types of texture that can be simulated, but it is not directly applicable to 3-dimensional objects.
Reference: [14] <author> Margaret Minsky, Ming Ouh-Young, Oliver Steele, Fredrick P. Brooks, and Max Behensky. </author> <title> Feeling and seeing: Issues in force display. </title> <booktitle> In Symposium on Interactive 3D Graphics, </booktitle> <volume> volume 24-2, </volume> <pages> pages 235-270. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> March </month> <year> 1990. </year>
Reference-contexts: This was an important step for the acceptance of haptics, but the task was too specialized to have provided research into a broad cross-section of haptic effects. A more complete set of haptic effects was studied by Margaret Minsky using the Sandpaper system. <ref> [13, 14] </ref> The Sandpaper system consisted of a 2-DOF joystick with force feedback for simulating 1 Margaret Minsky's PhD thesis [13] includes a more complete, yet terse list of the research of haptic interfaces. 8 texture.
Reference: [15] <author> Michael E. Mortenson. </author> <title> Geometric Modeling. </title> <publisher> John Wiley and Sons, </publisher> <year> 1985. </year>
Reference-contexts: This section will describe a smoothing algorithm that has been used with the constraint-based god-object method. In the best of worlds, we'd like to be able to model objects using curved surfaces, but these options are computationally intensive. <ref> [15] </ref> Non-Uniform Rational B-Splines (NURBS) surfaces would be a pretty obvious candidate due to their wide acceptance in the design and geometric modeling industries. Collision detection with such a surface is expensive.
Reference: [16] <author> A. Michael Noll. </author> <title> Man-machine tactile communication. </title> <journal> Society for Information Display Journal, </journal> <note> July/August 1972. reprinted in the Jul/Aug 1978 issue of Creative Computing. </note>
Reference-contexts: Michael Noll recognized that haptic modalities of man-machine communication had advantages over graphic modalities for some applications. <ref> [16] </ref> He designed a Cartesian three degree-of-freedom haptic interface and wrote some simple haptic software to demonstrate the device. Noll's software simulated the 3D contact forces which a user could expect from a point interacting with simple frictionless objects.
Reference: [17] <author> S. E. Salcudean and T. D. Vlaar. </author> <title> On the emulation of stiff walls and static friction with a magnetically levitated input/output device. </title> <booktitle> In Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, </booktitle> <pages> pages 303-309. </pages> <booktitle> Proceedings of the ASME Winter Annual Meeting, </booktitle> <year> 1994. </year>
Reference-contexts: Magnetic levitation permits a low-inertia and low friction design, but the workspace of the joystick will probably limit its utility as a mainstream haptic interface. S. E. Salcudean has been researching the emulation of stiff walls and surface effects (including friction). <ref> [17] </ref> In 1993, Thomas Massie and Ken Salisbury developed the PHANToM, a 3-DOF finger controller with a moderate workspace and good force bandwidth. Our group at the A.I. <p> These control limitations put even more pressure on the mechanical designer to remove inertia and friction from the design. Some of the literature in haptic interfaces concentrates on the development of control techniques to increase the stiffness of walls. <ref> [5, 17] </ref> Although we've found that high haptic stiffness is not necessary for the perception of solid objects, the research in this field seems to be orthogonal to research into rendering methods. <p> One published friction model uses viscous friction in the kinetic state. <ref> [17] </ref> Their two state friction model makes the transition back to the stiction state at a certain velocity threshold (Figure 4-2). Since position is descritized it is difficult to accurately determine the direction of the velocity vector when the velocity is small.
Reference: [18] <author> J. Kenneth Salisbury, David Brock, Thomas Massie, Nitish Swarup, and Craig Zilles. </author> <title> Haptic rendering: Programming touch interaction with virtual objects. </title> <booktitle> In Proceedings of the ACM 1995 Symposium on Interactive 3D Graphics, </booktitle> <address> Monterey CA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Our group at the A.I. Lab has used the PHANToM to approach issues including surface effects, arbitrary shaped objects, and the complex impedance blending methods which sophisticated surgical simulations and other training aides will require. <ref> [11, 18] </ref> 1.2 Thesis Overview This thesis endeavors to illuminate two areas of active research in haptic displays: haptic interface design and haptic rendering. <p> in the direction of the vector pointing from the sphere's center to the haptic interfaces point with a magnitude that is a function of the distance the point has penetrated the sphere's surface. [12] The inherent simplicity of these methods has allowed interesting work in dynamic objects and surface effects, <ref> [18] </ref> but the methods are not flexible enough to allow arbitrary geometries. The drawbacks of vector field methods are: 1. It is often unclear which piece of internal volume should be associated with which surface. 2. Force discontinuities can be encountered when traversing volume boundaries. 3.
Reference: [19] <author> K. B. Shimoga. </author> <title> A survey of perceptual feedback issues in dexterous telemanipulation: Part ii. finger touch feedback. </title> <booktitle> In Proceedings of VRAIS, </booktitle> <pages> pages 271-279, </pages> <address> Seattle, WA, </address> <year> 1993. </year>
Reference-contexts: Attempts to stimulate this modality have proliferated in designs of tactile display arrays. These arrays usually consist of closely arranged groups of "pins" which can be individually actuated. <ref> [19] </ref> The kinesthetic system refers to the collection of receptors in the muscles, tendons, and joints which allow perception of the motion and forces upon ones limbs. The brain interprets the signals from these receptors to estimate the position and contact force at the end of the limb.
Reference: [20] <author> Mandayam A. Srinivasan. </author> <title> Virtual haptic environments: Facts behind the fiction. </title> <booktitle> In Proceedings of the Eighth Yale Workshop on Adaptive and Learning Systems, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: The following is an over-simplification of the issues, but contains some good guidelines and rules of thumb. For a more rigorous treatment of psychophysics, we recommend reading the literature in that field. <ref> [6, 20] </ref> 2.1.1 Touch modalities The major goal of a haptic interface is to provide the sensations a user would experience if he/she were to touch a virtual environment. This problem has a number of issues, the most notable of which involve how humans sense. <p> The location of the hands are computed in the brain from the joint angles in the arm and wrist. "The just noticeable difference (JND) is about 2.5 degrees for finger joints, 2 degrees for wrist and elbow and about 0.8 degrees for the shoulder." <ref> [20] </ref> These uncertainties mean that throughout an arm's range of motion a human can really only discriminate position to within about an inch without an external reference. Given a reference to compare against the human does much better.
Reference: [21] <author> Mandayam A. Srinivasan, David L. Brock, G. Lee Beauregard, and Hugh B. Morgenbesser. </author> <title> Visual-haptic illusions in the perception of stiffness of virtual haptic objects. </title> <note> Manuscript in preparation, </note> <year> 1995. </year>
Reference-contexts: Our meaning 14 haptic feedback. Experiments have shown that if visual feedback is different than haptic feedback, subjects tend to rely on the visual feedback. The perceived stiffness of a button can be changed by only varying the visual response. <ref> [21] </ref> Without force cues the kinesthetic system can't accurately position the limbs, so the brain has come to rely on the vision system for fine positioning.
Reference: [22] <author> Nitish Swarup. </author> <title> work in progess. </title> <type> Master's thesis, </type> <institution> Department of Mechanical Engineering, MIT, </institution> <note> Expected August 1995. </note>
Reference-contexts: The impedance at any point on the object can be interpolated in exactly the same way the surface normals were. One subtle thing we will miss with such a simple implementation of impedance blending is energy conservation. <ref> [22] </ref> It will be possible to press in at a location with a small stiffness, move laterally, and then let the object push you back out at a location where the stiffness is greater. We have allowed "passive" objects to do work on the user. <p> With friction, texture, and surface shading, it will be very difficult to evaluate the work done through a closed loop path. A more pure approach is currently being undertaken to assure that the net work around a loop will be zero. <ref> [22] </ref> 4.3 Surface Mapping Algorithms For effects that vary greatly over a small range of motion, interpolation between nodal values is not sufficient. Texture is such an effect. Our haptic representation of texture can take much of its form from the graphics method of texture mapping.
Reference: [23] <author> Hong Tan, X. D. Pang, and Nat Durlach. </author> <title> Manual resolution of length, force, and compliance. </title> <booktitle> In Advances in Robotics, </booktitle> <pages> pages 13-18. </pages> <booktitle> Proceedings of the ASME Winter Annual Meeting, </booktitle> <year> 1992. </year>
Reference-contexts: objects with rigid surfaces held in a pinch grasp, the JND for compliance is about 5-15 percent when the displacement range is fixed, increases to 22 percent when it is varied randomly, and can be as high as 99 percent when cues arising out of mechanical work done are eliminated." <ref> [23] </ref> The mechanism which humans use to sense compliance is not well understood.
Reference: [24] <author> Hong Tan, Mandayam Srinivasan, Brian Eberman, and B. Chang. </author> <title> Human factors for the design of force-reflecting haptic interfaces. In Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, </title> <address> Chicago, IL, </address> <month> November </month> <year> 1994. </year> <booktitle> Proceedings of the ASME Winter Annual Meeting. </booktitle>
Reference-contexts: One study found that the minimum stiffness which humans can't distinguish from a solid surface was around 25N/mm. <ref> [24] </ref> We've found that when subjects use less than a few pounds (about 10N) of force they are willing to "believe" that surfaces which are less stiff (by an order of magnitude) are solid.
Reference: [25] <author> Craig Zilles and J. Kenneth Salisbury. </author> <title> A constraint-based god-object method for haptic display. </title> <booktitle> In Proceedings of the IROS conference on Robotics. IROS, </booktitle> <year> 1995. </year> <month> 46 </month>
Reference-contexts: We know the haptic interface point cannot be stopped from penetrating the virtual objects, but we are free to define additional variables to represent the virtual location of the haptic interface. This location is what we will call the god-object. <ref> [25] </ref> We have complete control over the god-object; we can prevent it from penetrating any of the virtual objects and force it to follow the laws of physics in the virtual environment.
References-found: 25

