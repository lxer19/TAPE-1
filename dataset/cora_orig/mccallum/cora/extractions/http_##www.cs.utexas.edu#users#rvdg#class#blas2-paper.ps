URL: http://www.cs.utexas.edu/users/rvdg/class/blas2-paper.ps
Refering-URL: http://www.cs.utexas.edu/users/rvdg/class/CS378.97/assignment/node2.html
Root-URL: 
Title: An Extended Set of Fortran Basic Linear Algebra Subprograms  
Phone: 60439  
Author: Jack J. Dongarra, Jeremy Du Croz, Sven Hammarling, and Richard J. Hanson 
Date: September, 1986  
Address: 9700 South Cass Avenue Argonne, Illinois  
Affiliation: ARGONNE NATIONAL LABORATORY  Mathematics and Computer Science Division  
Pubnum: Technical Memorandum No. 41 (Revision 3)  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D.S. Dodson and J.G. Lewis, </author> <title> "Issues relating to extension of the Basic Linear Algebra Subprograms", </title> <journal> ACM SIGNUM Newsletter, </journal> <volume> vol 20, no 1, </volume> <year> (1985), </year> <pages> 2-18. </pages>
Reference-contexts: In particular they are an aid to clarity, portability, modularity and maintenance of software and they have become a de facto standard for the elementary vector operations. An excellent discussion of the raison d' etre of the BLAS is given in Dodson and Lewis <ref> [1] </ref>. Special versions of the BLAS, in some cases machine code versions, have been implemented on a number of computers, thus improving the efficiency of the BLAS.
Reference: [2] <author> J.J. Dongarra and S.C. Eisenstat, </author> <title> ``Squeezing the Most out of an Algorithm in CRAY Fortran,'' </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> Vol. 10, No. 3, </volume> <year> (1984), </year> <pages> 221-230. </pages>
Reference: [3] <author> J.J. Dongarra, </author> <title> Increasing the Performance of Mathematical Software through High-Level Modularity. </title> <booktitle> Proceedings of the Sixth International Symposium on Computing Methods in Engineering and Applied Sciences. </booktitle> <address> (Versailles, France). </address> <publisher> North-Holland (1984), </publisher> <pages> pp 239-248. </pages>
Reference: [4] <author> J.J. Dongarra, J.R. Bunch, C.B. Moler, and G.W. Stewart, </author> <title> LINPACK Users' Guide, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference-contexts: The original basic linear algebra subprograms, now commonly referred to as the BLAS and fully described in Lawson, Hanson, Kincaid, and Krogh [9,10], have been very successful and have been used in a wide range of software including LINPACK <ref> [4] </ref> and many of the algorithms published by the ACM Transactions on Mathematical Software. In particular they are an aid to clarity, portability, modularity and maintenance of software and they have become a de facto standard for the elementary vector operations.
Reference: [5] <author> J.J. Dongarra, L. Kaufman, and S. Hammarling, </author> <title> Squeezing the Most out of Eigenvalue Solvers on High-Performance Computers, </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 77, </volume> <pages> pp 113-136, </pages> <year> (1986). </year> <month> - 15 </month> - 
Reference-contexts: We considered the possibility of generalizing the rank-1 and rank-2 updates to rank-k updates. Rank-k updates with k &gt; 1 (but k &lt;&lt; n ) can achieve significantly better performance on some machines than rank-1 <ref> [5] </ref>. But to take advantage of this usually requires complicating the calling algorithm; and moreover rank-k updates with k ~ ~ n would allow an even higher level operation such as matrix multipli cation `in by the back door'.
Reference: [6] <author> J.J. Dongarra, J.J. Du Croz, S. Hammarling, R.J. Hanson, </author> <title> A Proposal for an Extended Set of Fortran Basic Linear Algebra Subprograms, </title> <journal> ACM SIGNUM Newsletter, </journal> <volume> vol. 20, no. 1, </volume> <year> 1985. </year>
Reference-contexts: Earlier, a modified proposal was printed in the SIGNUM Newletter, <ref> [6] </ref>. In that document we invited readers to send us their views and suggestions for changes to the design of the extended BLAS. Thus we have appealed to a wide audience within the mathematical software community.
Reference: [7] <author> J.J. Dongarra, J.J. Du Croz, S. Hammarling, R.J. Hanson, </author> <title> Model Implementation and Test Package for the Extended BLAS, </title> <note> Argonne National Laboratory Report, ANL MCS-TM 81, </note> <month> August </month> <year> 1986. </year>
Reference-contexts: These could be programmed by a series of calls to the Level 1 BLAS, though we do not recommend that they be implemented in that way. Hence, in a natural sense, the Level 2 BLAS are performing basic operations at one level higher than the Level 1 BLAS. In <ref> [7] </ref> we present a model implementation of the Level 2 BLAS in Fortran 77 (extended to include a COMPLEX*16 data type), and also a set of rigorous test progra ms. - 3 - 2. <p> The only case that can be realized is where the matrix is real single precision and the extended precision vectors are real double precision. Code for these routines is not included in <ref> [7] </ref>. 3. Naming Conventions The name of a Level 2 BLAS is in the LINPACK style and consists of five characters, the last of which may be blank. <p> INCX = 0 INCY = 0 If a routine is called with an invalid value for any of its arguments, then it must report the fact and terminate execution of the program. In the model implementation (see <ref> [7] </ref>), each routine, on detecting an error, calls a common error handling routine XERBLA, passing to it the name of the routine and the number of the first argument which is in error. <p> Specialized implementations may call system-specific exception-handling and diagnostic facilities, either via an auxiliary routine XERBLA or directly from the routines. One advantage of using XERBLA is that the test program can then test that all errors are detected (see <ref> [7] </ref>). 5. Storage Conventions Unless otherwise stated it is assumed that matrices are stored c onventionally in a 2-dimensional array with matrix-element a ij stored in arra yelement A (I,J).
Reference: [8] <author> B.S. Garbow, J.M. Boyle, J.J. Dongarra, C.B. Moler, </author> <title> Matrix Eigensystem Routines - EISPACK Guide Extension, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Vol. 51, </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1977. </year>
Reference: [9] <author> C. Lawson, R. Hanson, D. Kincaid, and F. Krogh, </author> <title> ``Basic Linear Algebra Subprograms for Fortran Usage,'' </title> <journal> ACM Transactions on Mathematical Software 5 (1979), </journal> <pages> 308-323. </pages>
Reference: [10] <author> C. Lawson, R. Hanson, D. Kincaid, and F. Krogh, </author> <title> ``Algorithm 539: Basic Linear Algebra Subprograms for Fortran Usage,'' </title> <journal> ACM Transactions on Mathematical Software 5 (1979), </journal> <pages> 324-325. </pages>
Reference: [11] <author> B.T. Smith, J.M. Boyle, J.J. Dongarra, B.S. Garbow, Y. Ikebe, V.C. Klema, and C.B. Moler, </author> <title> Matrix Eigensystem Routines - EISPACK Guide, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Vol. 6, </volume> <booktitle> 2nd edition, </booktitle> <address> Springe r-Verlag, Berlin, </address> <year> 1976. </year>
Reference: [12] <institution> IEEE Standard for Binary Floating-Point Arithmetic, </institution> <address> ANSI/IEEE Std 754-1985, </address> <publisher> The IEEE Inc., </publisher> <address> New York, </address> <year> (1985). </year> <month> - 16 </month> - 
Reference-contexts: This proposal is aimed at machines with extended precision arithmetic registers; for example machines performing IEEE arithmetic <ref> [12] </ref>. We propose these routines as an optional extension to the Level 2 BLAS because it is not possible to specify a complete set within the confines of ANSI Fortran 77.
References-found: 12

