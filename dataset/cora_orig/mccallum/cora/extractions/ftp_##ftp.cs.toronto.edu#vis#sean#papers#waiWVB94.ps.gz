URL: ftp://ftp.cs.toronto.edu/vis/sean/papers/waiWVB94.ps.gz
Refering-URL: http://www.cs.toronto.edu/vis/publications/abstracts/waiWVB94.html
Root-URL: 
Email: winky@vis.toronto.edu tsotsos@vis.toronto.edu  
Title: Directing Attention to Onset and Offset of Image Events for Eye-Head Movement Control  
Author: Winky Y. K. Wai John K. Tsotsos 
Address: Toronto, Ont., Canada M5S 1A4  
Affiliation: Department of Computer Science University of Toronto  
Abstract: This paper proposes a model that investigates a new avenue for attention control based on dynamic scenes. We have derived a computational model, based on the difference of Gaussian (DOG) model, to detect abrupt changes. On and off-DOG operators are used to detect "on" and "off" events respectively. The response of these operators is examined over various temporal window sizes so that changes at different rates can be found. The most salient "on" and "off" events are determined from the corresponding winner-take-all (WTA) network. With such a model, we explore the possibility of an attentional mechanism, in part guided by abrupt changes, for gaze control. The model has been tested with image sequences which have changes caused by brightness or motion and the results are satisfactory. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Culhane, S. M., </author> <title> "Implementation of an Attentional Prototype for Early Vision", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1992. </year>
Reference-contexts: Empirically, setting = 10 and fi = 1:3 (as suggested by Culhane <ref> [1] </ref>) seems to yield satisfactory results for our experiments. 5 Extending the temporal window We now consider a temporal window of size T , where (T &gt; 2). By enlarging the temporal window, our model would be looking for changes that occur at different rates as well.
Reference: [2] <author> Culhane, S. M. and Tsotsos, J. K., </author> <title> "An Attentional Prototype for Early Vision", </title> <booktitle> ECCV, p. </booktitle> <pages> 551-560, </pages> <year> 1992. </year>
Reference-contexts: Therefore, a mechanism has to be found to take a balance between the difference in size and response. The normalization function we use in our model is the one suggested by Culhane and Tsotsos <ref> [2] </ref>. It can be expressed as a function of : W () = + fi (2m+1) (3) The parameter will affect the asymptote of the function, while fi will affect the steepness of the first part of the function.
Reference: [3] <author> Fleet, D. J., </author> <title> "The Early Processing of Spatio-Temporal Visual Information", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1984. </year>
Reference-contexts: These Gaussian functions are weighted by integrated sensitivities ff c (for the centre) and ff s (for the surround). A detailed analysis of how the shape of the DOG operator is affected by varying the ratio c s and ff s is given in <ref> [3] </ref>. <p> Return to step 1 for the next set of images. 6 Determining parameter values The main parameters for the DOG operator are c , s , ff c and ff s . As Fleet <ref> [3] </ref> pointed out, by keeping the ratio s c fixed and varying c (when s &gt; c ), the peak spatial frequency that the operator can detect is shifted.
Reference: [4] <author> Posner, M. I. and Cohen, Y., </author> <title> "Components of Attention", in Attention and Performance X, </title> <booktitle> p. </booktitle> <pages> 531-556, </pages> <year> 1984. </year>
Reference-contexts: First of all, we take for granted that there is perfect image registration from the device through which images are obtained. Second, the correspondence problem is not addressed by the model if the images are acquired from a moving sensor. Finally, the issue of inhibition of return <ref> [4] </ref> is not addressed in our model. More experiments in the psychology area to study how receptive fields are inhibited when attention is guided by abrupt changes may help to suggest a way to deal with this problem in our model.
Reference: [5] <author> Tsotsos, J. K., </author> <title> "An Inhibitory Beam for Attentional Selection", in Spatial Vision for Humans and Robots, </title> <publisher> Cam-bridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: Units in each WTA network represent the response from all locations and spatial scales of the corresponding event. A winner is determined from each WTA network using the updating rule described by Tsotsos <ref> [5] </ref>. But before the WTA processes are initiated, the response from different operator sizes are normalized. When the spatial extent of an operator increases, a greater area will contribute to the operator. Therefore, a mechanism has to be found to take a balance between the difference in size and response. <p> The output from Algorithm 1 is treated as one of the attentional features for the input level of the processing hierarchy in Tsot-sos' inhibitory attentional beam model <ref> [5] </ref>. The most conspicuous "on" and "off" events will compete with other attention attracting image events (e.g., events that deserve attention according to some task-driven guidance) and a higher order decision process is assumed to choose the winner in this competition.
Reference: [6] <author> Wai, W. Y. K., </author> <title> "A Computational Model for Detecting Image Changes", </title> <type> Master's Thesis, </type> <institution> University of Toronto, </institution> <year> 1994. </year>
Reference-contexts: Figure 2 shows how the model would behave when the values of p 1 , p 2 , p 3 , p 4 and p 5 are changed. 3 The derivation of this relation is described in <ref> [6] </ref>. (a) (b) (c) (d) (e) errors as the value of p 1 , p 2 and p 4 increases respectively. Data are obtained from experiments where the change is 5%, 20%, 35%, 50%, 65%, 80% and 95% of the maximum intensity. <p> A detailed analysis of the sensitivities of the thresholds, as well as the derivation of z n , s nc , s ns , z f , s fc and s fs are described in <ref> [6] </ref>. 8 Integration to an attentional model The computational model described above can be used to direct attention to abrupt changes for eye-head movement control.
Reference: [7] <author> Yantis, S. and Jones, E., </author> <title> "Mechanisms of Attention Selection: Temporally Modulated Priority Tags", </title> <journal> Perception and Psychophysics, </journal> <volume> 50(2), p.166-178, </volume> <year> 1991. </year>
Reference-contexts: 1 Introduction Recently, Yantis and several co-authors revealed from psychological experiments that the abrupt appearance of an object in the visual field draws visual attention, e.g., <ref> [7] </ref>, [8]. Inspired by this novel idea of attentional capture, we derive a computational model to find abrupt changes from a sequence of images.

References-found: 7

