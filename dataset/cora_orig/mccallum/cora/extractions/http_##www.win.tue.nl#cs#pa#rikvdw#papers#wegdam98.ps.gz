URL: http://www.win.tue.nl/cs/pa/rikvdw/papers/wegdam98.ps.gz
Refering-URL: http://www.win.tue.nl/cs/pa/rikvdw/bibl.html
Root-URL: http://www.win.tue.nl
Title: Compact Code Generation through Custom Instruction Sets  
Author: Maarten Wegdam. Revised by Rik van de Wiel 
Address: TN 417/96  
Affiliation: of  
Note: Date of issue: 09/98  Unclassified version  c Philips Electronics 1998  
Pubnum: Unclassified Report  
Abstract: Nat.Lab. Unclassified Report 822/98 
Abstract-found: 1
Intro-found: 1
Reference: [DG87] <author> Jack W. Davidson and Joseph V. Gresh. Cint: </author> <title> A RISC interpreter for the C programming language. </title> <journal> Sigplan '87, </journal> <volume> 22(7), </volume> <year> 1987. </year>
Reference: [Ert96] <author> Martin Anton Ertl. </author> <title> Implementation of Stack-Based Languages on Register Machines. </title> <type> PhD thesis, </type> <institution> Technischen Universitat Wien, </institution> <year> 1996. </year>
Reference: [FH91a] <author> C.W. Fraser and D.R. Hanson. </author> <title> A code generation interface for ANSI C. </title> <journal> Software Practice& Experience, </journal> <volume> 21(9) </volume> <pages> 963-988, </pages> <month> September </month> <year> 1991. </year>
Reference: [FH91b] <author> C.W. Fraser and D.R. Hanson. </author> <title> A retargetable compiler for ANSI C. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(10) </volume> <pages> 29-43, </pages> <month> October </month> <year> 1991. </year>
Reference: [FH95] <author> Christopher W. Fraser and David R. Hanson. </author> <title> A Retargetable C Compiler: Design and Implementation. </title> <publisher> Addison Wesley, </publisher> <year> 1995. </year>
Reference: [FHP92a] <author> C.W. Fraser, D.R. Hanson, and T.A. Proebsting. </author> <title> Engineering a simple, efficient code generator generator. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(3) </volume> <pages> 213-226, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The Intermediate Representation of lcc is in the form of trees, where each tree matches about one C-instruction. lburg The code generator generator lburg (a variant of iburg <ref> [FHP92a] </ref>) will be used. lburg reads a machine description and writes a code generator which uses tree matching and dynamic programming to compute a least-cost cover for a given input tree. The code generator is used as back end for lcc and has as input the Intermediate Representation trees. <p> When a tree fragment includes a constant, a variant of this tree fragment is generated to infer instructions with immediate operands as well as instructions with hardwired constants, e.g. an instruction that assigns zero to a variable. III A variant of the code generator generator iburg <ref> [FHP92a] </ref> reads the tree fragments produced above and generates a code generator, which in turn uses tree matching and dynamic programming to compute a least-cost cover for a given input tree.
Reference: [FHP92b] <author> C.W. Fraser, R.R. Henry, and T.A. Proebsting. </author> <title> BURG fast optimal instruction selection and tree parsing. </title> <journal> SIGPLAN Notices, </journal> <volume> 27(4) </volume> <pages> 68-76, </pages> <month> April </month> <year> 1992. </year> <note> BURG is available by anonymous ftp from kaese.cs.wisc.edu, file /pub/burg.shar.Z. </note>
Reference: [FMW84] <author> Christopher W. Fraser, Eugene W. Myers, and Alan L. Wendt. </author> <title> Analyzing and compressing assembly code. </title> <booktitle> In Proceedings of the ACM SIGPLAN '84 Symposium on Compiler Construction, </booktitle> <volume> volume 19, </volume> <pages> pages 117-121, </pages> <month> june </month> <year> 1984. </year>
Reference-contexts: In those cases one has to rely instead on the original 32-bit instruction set. The resulting code density improvement is 25-35% compared to ARM code. <ref> [FMW84] </ref> claims that the two most important optimizations that save space are procedural abstraction and cross-jumping. Procedural abstraction turns repeated code fragments into procedures, either at Intermediate Representation level or at source level. Cross-jumping reuses the common tail of two merging code sequences.
Reference: [FP95] <author> Christopher W. Fraser and Todd A. Proebsting. </author> <title> Custom instruction sets for code compression. Unpublished, </title> <address> URL:http://www.cs.arizona.edu/people/todd/papers/pldi2.ps, </address> <year> 1995. </year>
Reference-contexts: One step further in this direction is to construct a custom instruction set specially for a certain program. The chosen instruction set defines a Virtual Machine (VM), which can be implemented by using an interpreter. This technique is described in [Pro95] and the unpublished <ref> [FP95] </ref>. The idea is to automatically construct the VM in such a manner that the size of the (interpretive) code for a certain program is minimal. The second article describes an improvement of the first, so I will only elaborate on the second. <p> Philips intends to market MIPS processors for embedded systems, this means that the target machine will be a MIPS R3000. This has consequences for the way the compression ratio is measured. Proebsting/Fraser Proebsting/Fraser used custom instruction sets and obtained promising results in <ref> [FP95] </ref> (and [Pro95]). Therefore this article will act as a starting point. lcc The (front end of the) retargetable C-compiler lcc, version 3.5 ([FH91b]), will be used. lcc is a well documented, relatively small C-compiler which has an, again relatively, strict separation of front end and back end. <p> Only those techniques that are described in <ref> [FP95] </ref> were implemented. We will refer to the version of the compiler described in this section as the basic compiler. We give a general overview of the compiler in Section 2.1. <p> For practical reasons a maximum of one wildcard for a constant is imposed. In this we follow <ref> [FP95] </ref>. Example 2.4 This is an example of the tree patterns that the tree pattern algorithm generates. <p> Note that only one '*' can appear in a pattern, and that this wildcard can only appear as child of the root-node of that pattern, conform <ref> [FP95] </ref>. Modern code generator generators such as lburg (used in the lcc compiler) model the instruction set of the target machine (a concrete or virtual machine), by a set of rules that map IR tree fragments on target machine instructions. <p> The resulting code compaction doesn't depend signifi cantly on whether or not such an instruction is unqualified as a candidate. It is therefore unqualified and thus prevents a lot of useless computing. In <ref> [FP95] </ref> a small program is used to recreate the IR trees instead of rerunning the entire front end for each try. This seemed not so simple to implement, so we haven't done it. Generation of the interpretive code The generation of the interpretive code is done in two stages.
Reference: [Fra94] <author> Michael S.O. Franz. </author> <title> Code-Generation On-the-Fly:A key to Portable Software. </title> <type> PhD thesis, </type> <institution> Swiss Federal Institute of Technology Zurich, </institution> <year> 1994. </year>
Reference-contexts: For such programs, interpretive overhead can be less important than program size. * Optimizing linkers and loaders that generate code on the fly <ref> [Fra94] </ref> incur i/o and code-generation costs that rise with the number of operators that they read. Compressing the input improves performance. 1.2 Related work Since compilers usually are made to optimize for minimal execution time, far more research is done in that area than in optimizing for minimal space. <p> This doesn't mean that no research is done when it comes to code compression. Franz describes in <ref> [Fra94] </ref> a technique for representing programs abstractly and independently of the eventual target architecture. This representation is twice as compact as machine code for a CISC processor. The code generation is deferred until the time of loading, at which native code is created on the fly by a code-generating loader.
Reference: [Kli81] <author> Paul Klint. </author> <title> Interpretation techniques. </title> <journal> Software Practice& Experience, </journal> <volume> 11 </volume> <pages> 963-973, </pages> <year> 1981. </year>
Reference-contexts: No energy or time has been invested in making it fast (or small). Three common interpretation techniques can be distinguished: 1. Classical interpreter with opcode table 2. Direct threaded code 3. Indirect threaded code For an overview of these techniques and some benchmark results, see <ref> [Kli81] </ref>. The classical interpreter is chosen, mainly because it is the most straightforward to implement. It is implemented in C, not in assembly. The interpreter is basically a switch with at most 256 cases of a few statements each.
Reference: [KW94] <author> Michael Kozuch and Andrew Wolfe. </author> <title> Compression of embedded systems programs. </title> <booktitle> In Proceedings of the IEEE International Conference on Computer Design: VLSI in Computers and Processors, </booktitle> <volume> volume 10, </volume> <pages> pages 270-277, 94. </pages> <address> c fl Philips Electronics N.V. </address> <note> 1998 43 822/98 Unclassified Report </note>
Reference-contexts: The resulting 2 c fl Philips Electronics N.V. 1998 Unclassified Report 822/98 compression ratios varied between 0-39%, with an average of 7%. The compressed code took 1-5% more CPU time, but (on non-embedded systems) as much as 11% less real time, presumably because it loads faster. <ref> [KW94] </ref> and the earlier [WC94] describe a method whereby embedded programs are stored in compressed form but executed from the instruction cache in the standard format. The system consists of a standard RISC processor core augmented with a special code-expanding instruction cache.
Reference: [LDK + 96] <author> Stan Liao, Srinivas Devadas, Kurt Keutzer, Steven Tjang, and Albert Wang. </author> <title> Storage assignment to decrease code size. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 18(3) </volume> <pages> 235-253, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Modern compilers therefore often try to save time, even at the expense of space (e.g. inlining). This is not desirable for all applications. For embedded systems in printers, game controllers, appliances and the like a small, fixed-size memory is often the limiting design constraint. In <ref> [LDK + 96] </ref> two trends are mentioned in the design of embedded systems. First, considerations for cost, power, and reliability are forcing designers to incorporate all the electronics microprocessor, program ROM, RAM, and application-specific circuit components into a single integrated circuit. <p> In this article the obvious, but still true, observation is made that since embedded systems are highly cost sensitive and typically only execute a single program, it is not possible to include temporary storage for the uncompressed version of a program. In <ref> [LDK + 96] </ref> a data-layout algorithm is described that decreases code size. The technique takes advantage of special architectural features of embedded processors. The storage allocation of variables is moved from the front-end to the code generation step that selects addressing modes, thereby increasing opportunities to use efficient autoincrement/autodecrement modes.
Reference: [Lia96] <author> Liao. </author> <title> Code Generation and Optimization for Embedded Digital Signal Processors. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1996. </year>
Reference: [Lim95] <institution> Advanced RISC Machines Limited. </institution> <note> Introduction to Thumb, 1995. URL:http://www.armltd.co.uk/Documentation/Overviews/Thumb intro/. </note>
Reference: [Phi89] <author> Philip Koopman, Jr. </author> <title> Stack Computers. </title> <publisher> Ellis Horwood Limited, </publisher> <year> 1989. </year>
Reference: [Pro95] <author> Todd A. Proebsting. </author> <title> Optimizing an ANSI C interpreter with superoper-ators. </title> <booktitle> In POPL '95, </booktitle> <pages> pages 322-332, </pages> <year> 1995. </year>
Reference-contexts: One step further in this direction is to construct a custom instruction set specially for a certain program. The chosen instruction set defines a Virtual Machine (VM), which can be implemented by using an interpreter. This technique is described in <ref> [Pro95] </ref> and the unpublished [FP95]. The idea is to automatically construct the VM in such a manner that the size of the (interpretive) code for a certain program is minimal. The second article describes an improvement of the first, so I will only elaborate on the second. <p> Philips intends to market MIPS processors for embedded systems, this means that the target machine will be a MIPS R3000. This has consequences for the way the compression ratio is measured. Proebsting/Fraser Proebsting/Fraser used custom instruction sets and obtained promising results in [FP95] (and <ref> [Pro95] </ref>). Therefore this article will act as a starting point. lcc The (front end of the) retargetable C-compiler lcc, version 3.5 ([FH91b]), will be used. lcc is a well documented, relatively small C-compiler which has an, again relatively, strict separation of front end and back end.
Reference: [Tau91] <author> Mark Taunton. </author> <title> Compressed executables: an exercise in thinking small. </title> <booktitle> USENIX, </booktitle> <address> Summer/91:385-403, </address> <year> 1991. </year>
Reference: [Tur95] <author> James L. Turley. </author> <title> Thumb squeezes ARM code size. </title> <type> Microprocessor Report, 9(4), </type> <year> 1995. </year>
Reference-contexts: This method bears some resemblance to commonly used data compression schemes ([Wel84]). Advanced RISC Machines Limited (UK) has extended their architecture to reduce code size by developing a new instruction set, named Thumb ([Lim95] and <ref> [Tur95] </ref>). Thumb contains 16-bit wide opcodes which are a subset from the standard 32-bit ARM instruction set with a compact encoding. On execution these new 16-bit Thumb opcodes are decompressed by an instruction predecoder to their ARM instruction set equivalents.
Reference: [WC94] <author> Andrew Wolfe and Alex Chanin. </author> <title> Executing compressed programs on an embedded RISC architecture. </title> <booktitle> In Proceedings of the 25th Annual International Symposium on Microarchitecture (MICRO), </booktitle> <volume> volume 25, </volume> <pages> pages 81-91, </pages> <month> 12 </month> <year> 1994. </year>
Reference-contexts: The compressed code took 1-5% more CPU time, but (on non-embedded systems) as much as 11% less real time, presumably because it loads faster. [KW94] and the earlier <ref> [WC94] </ref> describe a method whereby embedded programs are stored in compressed form but executed from the instruction cache in the standard format. The system consists of a standard RISC processor core augmented with a special code-expanding instruction cache.
Reference: [Wel84] <author> Terry A. Welch. </author> <title> A technique for high-performance data compression. </title> <journal> IEEE Computer, </journal> <volume> 17(6) </volume> <pages> 8-19, </pages> <month> June 84. </month>
Reference: [Wie] <author> Rik van de Wiel. </author> <title> The `Code Compaction' Bibliography. </title> <address> http://www.win.tue.nl/cs/pa/rikvdw/bibl.html. 44 c fl Philips Electronics N.V. </address> <note> 1998 Unclassified Report 822/98 </note>
References-found: 22

