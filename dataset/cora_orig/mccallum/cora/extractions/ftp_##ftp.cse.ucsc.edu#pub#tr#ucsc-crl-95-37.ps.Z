URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-95-37.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Efficient Learning with Virtual Threshold Gates  
Author: Wolfgang Maass Manfred K. Warmuth 
Note: Address: Institute for Theoretical  Address:  Supported by NSF grant IRI-9123692.  
Address: Santa Cruz, CA 95064 USA  32/2, A-8010 Graz, Austria.  Santa Cruz, CA 95064.  
Affiliation: Baskin Center for Computer Engineering Information Sciences University of California, Santa Cruz  Computer Science, Technische Universitaet Graz, Klosterwiesgasse  Department of Computer Sciences, University of California,  
Pubnum: UCSC-CRL-95-37  
Email: E-mail: maass@igi.tu-graz.ac.at.  E-mail: manfred@cis.ucsc.edu.  
Date: July 28, 1995  
Abstract: We reduce learning simple geometric concept classes to learning disjunctions over exponentially many variables. We then apply an on-line algorithm called Winnow whose number of prediction mistakes grows only logarithmically with the number of variables. The hypotheses of Winnow are linear threshold functions with one weight per variable. We find ways to keep the exponentially many weights of Winnow implicitly so that the time for the algorithm to compute a prediction and update its "virtual" weights is polynomial. Our method can be used to learn d-dimensional axis-parallel boxes when d is variable, and unions of d-dimensional axis-parallel boxes when d is constant. The worst-case number of mistakes of our algorithms for the above classes is optimal to within a constant factor, and our algorithms inherit the noise robustness of Winnow. We think that other on-line algorithms with multiplicative weight updates whose loss bounds grow logarithmically with the dimension are amenable to our methods. 
Abstract-found: 1
Intro-found: 1
Reference: [AHU74] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference: [Ang88] <author> Dana Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: This model can easily be shown to be the same as Angluin's model for on-line learning with equivalence queries <ref> [Ang88] </ref> where each mistake corresponds to a query that is answered negatively (we refer to [MT92] for a survey of these and related formal models for on-line learning).
Reference: [AKMW95] <author> P. Auer, S. Kwek, W. Maass, and M. K. Warmuth. </author> <title> On-line learning of small threshold-circuits. </title> <note> In preparation. </note>
Reference-contexts: We expect that further applications will be found where these algorithm can be simulated for exponentially many "virtual variables". In parallel work such applications have been found in <ref> [HW95, HS95, AKMW95] </ref>. A more challenging goal is to apply this family of algorithms to continuously many variables. See Cover [Cov91] for an example problem for which this was done. Acknowledgements We would like to thank Sally Goldman for valuable discussions.
Reference: [AL94] <author> P. </author> <title> Auer and P.M Long. Simulating access to hidden information while learning. </title> <booktitle> In Proceedings of the 26th ACM Symposium on the Theory of Computation. </booktitle> <publisher> ACM Press, </publisher> <year> 1994. </year> <pages> pp. 263-272. </pages>
Reference-contexts: This gives an overall lower bound for the class BOX d n of 2dblog (n=2)c mistakes. The mistake bound for a concept class is always one less than the maximum number of equivalence queries required for learning the class [Lit88]. By a result from <ref> [AL94] </ref> it immediately follows that even if membership queries are allowed then the total number of equivalence and membership queries is still (d log n).
Reference: [AW95] <author> P. Auer and M.K. Warmuth. </author> <title> Tracking Shifting Disjunctions. </title> <booktitle> To appear in 36th Annual Symposium on Foundations of Computer Science, </booktitle> <month> Fall </month> <year> 1995. </year> <note> 14 References </note>
Reference-contexts: One can also take the route of using more information for tuning the algorithms and let the tunings of the parameters ff and fi depend on k as well as an upper bound Z of the number of attribute errors of the target disjunction <ref> [AW95] </ref>. In this case it is possible to obtain mistake bounds of the type 2z + (2 p p Ak ln (n=k), where z Z is the number of attribute errors of some target disjunction from C k;v . <p> We chose Winnow since for the purpose of learning disjunctions it is the most studied of the group. Winnow is robust against malicious attribute noise and our reductions preserve these properties. Slight modifications of Winnow have shown to give good mistake bounds in relation to the best shifting disjunction <ref> [AW95] </ref>. By combining these recent results with the findings of this paper one immediately obtains an algorithm with a small mistake bound compared to the best shifting box. Mistake bounds for Winnow have also been developed for j-of-k threshold functions.
Reference: [Aue93] <author> Peter Auer. </author> <title> On-line learning of rectangles in noisy environments. </title> <booktitle> In Proceedings of the Sixth Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> pages 253-261, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: By using balanced trees the algorithm for learning BOX d n can be made very efficient. It is interesting to compare our algorithm with a previous algorithm due to Auer which also learns the class BOX d n in the presence of noise <ref> [Aue93] </ref>. The hypotheses of the latter algorithm are required to lie in target class BOX d n , whereas the hypotheses of our algorithm usually lie outside of the target class. The additional requirement leads to larger mistake bounds (at least cubic in the dimension d for Auer's algorithm).
Reference: [BEHW89] <author> Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. War-muth. </author> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 36(4) </volume> <pages> 929-965, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: In these concept classes each concept may be viewed as a union of concepts from a simpler concept class and hence learning can be reduced to learning disjunctions of concepts from these simpler concept classes. The standard PAC-algorithm for learning disjunctions is a simple greedy covering algorithm <ref> [BEHW89, Hau89, KV94] </ref>. This algorithm has the advantage that its hypothesis is a disjunction (but not of minimal size).
Reference: [BGGM94] <author> Nader H. Bshouty, Paul W. Goldberg, Sally A. Goldman, and H. David Mathias. </author> <title> Exact learning of discretized concepts. </title> <type> Technical Report WUCS-94-19, </type> <institution> Wash-ington University, </institution> <year> 1994. </year>
Reference-contexts: The mistake bound and computation time of this algorithm is polynomial if either the number of boxes k or the dimension d is fixed. In this introduction we only state the results for unions of boxes when the dimension is fixed. This concept class has received considerable attention recently <ref> [CH95, FGMP94, BCH94, BGGM94] </ref>. We can learn S n with a mistake bound of O (kd log n) and O ((kd log n) 2d ) time for computing a prediction and updating the hypothesis after a mistake occurs. <p> We can learn S n with a mistake bound of O (kd log n) and O ((kd log n) 2d ) time for computing a prediction and updating the hypothesis after a mistake occurs. The best previous bounds <ref> [BGGM94] </ref> were O ((kd log n) d ) mistakes and total computation time. Note that algorithms with mistake or time bounds that have the dimension d in the exponent are of limited interest. <p> The improved time bound of O (d (log d + log log n)) which uses balanced trees is given in the appendix. By using Winnow2 instead of Winnow1 it is easy to generalize the above theorem to the noisy case. (See <ref> [BGGM94] </ref> for earlier results on learning similar geometric objects in the presence of noise.) For this purpose the notion of attribute error is generalized in the straightforward way: An example hx; bi 2 X d n fi f0; 1g contains z attribute errors w.r.t. a target box C T in BOX
Reference: [BCH94] <author> Nader H. Bshouty, Zhixiang Chen, and Steve Homer. </author> <title> On learning discretized geometric concepts. </title> <booktitle> To appear in 35th Annual Symposium on Foundations of Computer Science, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: The mistake bound and computation time of this algorithm is polynomial if either the number of boxes k or the dimension d is fixed. In this introduction we only state the results for unions of boxes when the dimension is fixed. This concept class has received considerable attention recently <ref> [CH95, FGMP94, BCH94, BGGM94] </ref>. We can learn S n with a mistake bound of O (kd log n) and O ((kd log n) 2d ) time for computing a prediction and updating the hypothesis after a mistake occurs. <p> Instead we could have defined boxes and other geometric objects corresponding to S n in terms of an arbitrary set of directions D 2 R d (see e.g. <ref> [BCH94] </ref>).
Reference: [CH95] <author> Zhixiang Chen and Steven Homer. </author> <title> The bounded injury priority method and the learnability of unions of rectangles. </title> <note> To appear in Annals of Pure and Applied Logic. </note>
Reference-contexts: The mistake bound and computation time of this algorithm is polynomial if either the number of boxes k or the dimension d is fixed. In this introduction we only state the results for unions of boxes when the dimension is fixed. This concept class has received considerable attention recently <ref> [CH95, FGMP94, BCH94, BGGM94] </ref>. We can learn S n with a mistake bound of O (kd log n) and O ((kd log n) 2d ) time for computing a prediction and updating the hypothesis after a mistake occurs.
Reference: [CM92] <author> Zhixiang Chen and Wolfgang Maass. </author> <title> On-line learning of rectangles. </title> <booktitle> In Proceedings of the Fifth Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 16-27. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1992. </year>
Reference-contexts: This algorithm uses at most O (d (log d + log log n)) time for predicting and for updating its data structures after a mistake. Before we prove this theorem, we would like to note that this learning algorithm is optimal in a rather strong sense <ref> [CM92] </ref>: using a simple adversary argument one can show that any on-line learning algorithm can be forced to make (d log n) mistakes on some sequence of examples labeled consistently with a target in BOX d n .
Reference: [Cov91] <author> T. </author> <title> Cover. Universal portfolios. </title> <journal> Mathematical Finance, </journal> <volume> 1(1) </volume> <pages> 1-29, </pages> <year> 1991. </year>
Reference-contexts: We expect that further applications will be found where these algorithm can be simulated for exponentially many "virtual variables". In parallel work such applications have been found in [HW95, HS95, AKMW95]. A more challenging goal is to apply this family of algorithms to continuously many variables. See Cover <ref> [Cov91] </ref> for an example problem for which this was done. Acknowledgements We would like to thank Sally Goldman for valuable discussions.
Reference: [DK95] <author> E. Dichterman and R. Khardon. </author> <title> A tight bound for the VC dimension of k-term DNF. </title> <type> Private communication. </type>
Reference: [FGMP94] <author> Mike Frazier, Sally Goldman, Nina Mishra, and Leonard Pitt. </author> <title> Learning from a consistently ignorant teacher. </title> <booktitle> In Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: The mistake bound and computation time of this algorithm is polynomial if either the number of boxes k or the dimension d is fixed. In this introduction we only state the results for unions of boxes when the dimension is fixed. This concept class has received considerable attention recently <ref> [CH95, FGMP94, BCH94, BGGM94] </ref>. We can learn S n with a mistake bound of O (kd log n) and O ((kd log n) 2d ) time for computing a prediction and updating the hypothesis after a mistake occurs.
Reference: [Hau89] <author> David Haussler. </author> <title> Learning Conjunctive Concepts in Structural Domains. </title> <booktitle> Machine Learning 4(1) </booktitle> <pages> 7-40, </pages> <year> 1989. </year>
Reference-contexts: In these concept classes each concept may be viewed as a union of concepts from a simpler concept class and hence learning can be reduced to learning disjunctions of concepts from these simpler concept classes. The standard PAC-algorithm for learning disjunctions is a simple greedy covering algorithm <ref> [BEHW89, Hau89, KV94] </ref>. This algorithm has the advantage that its hypothesis is a disjunction (but not of minimal size).
Reference: [HKW94] <author> D. Haussler, J. Kivinen, and M. K. Warmuth. </author> <title> Tight worst-case loss bounds for predicting with expert advice. </title> <type> Technical Report UCSC-CRL-94-36, </type> <institution> University of California Computer Research Laboratory, Santa Cruz, CA. </institution> <note> An extended abstract appeared in the Proceedings of the Second European Conference, </note> <editor> Euro-COLT'95, Springer Verlag, </editor> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <volume> Vol. 904, </volume> <pages> pp. 69-83. </pages>
Reference-contexts: There is a large family of on-line algorithms (besides Winnow and its relatives) with multiplicative weight updates whose loss bounds grow logarithmically with the dimension of the problem <ref> [Vov90, HKW94, KW94] </ref>. We expect that further applications will be found where these algorithm can be simulated for exponentially many "virtual variables". In parallel work such applications have been found in [HW95, HS95, AKMW95]. A more challenging goal is to apply this family of algorithms to continuously many variables.
Reference: [HS95] <author> D. P. Helmbold and R. E. Schapire. </author> <title> Predicting nearly as well as the best pruning of a decision tree. </title> <booktitle> To appear in the Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <address> Santa Cruz, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: We expect that further applications will be found where these algorithm can be simulated for exponentially many "virtual variables". In parallel work such applications have been found in <ref> [HW95, HS95, AKMW95] </ref>. A more challenging goal is to apply this family of algorithms to continuously many variables. See Cover [Cov91] for an example problem for which this was done. Acknowledgements We would like to thank Sally Goldman for valuable discussions.
Reference: [HSW90] <author> D. P. Helmbold, R. Sloan and Manfred K. Warmuth. </author> <title> Learning Nested Differences of Intersection-Closed Concept Classes. </title> <journal> Machine Learning, </journal> <volume> vol. 5, </volume> <pages> pp. 165-196, </pages> <year> 1990. </year>
Reference-contexts: The class of axis-parallel boxes is a simple example of an intersection-closed concept class and nested differences of concepts from this class are efficiently learnable in the PAC model <ref> [HSW90] </ref>.
Reference: [HW95] <author> M. Herbster and M. K. Warmuth. </author> <title> Tracking shifting experts. </title> <booktitle> To appear in the Proceedings of Twelfth International Conference on Machine Learning, </booktitle> <address> Taos, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: We expect that further applications will be found where these algorithm can be simulated for exponentially many "virtual variables". In parallel work such applications have been found in <ref> [HW95, HS95, AKMW95] </ref>. A more challenging goal is to apply this family of algorithms to continuously many variables. See Cover [Cov91] for an example problem for which this was done. Acknowledgements We would like to thank Sally Goldman for valuable discussions.
Reference: [KV94] <author> M. J. Kearns and U. V. Vazirani. </author> <title> An Introduction to Computational Learning Theory. </title> <publisher> MIT Press, </publisher> <address> Cambridge Massachusetts, </address> <year> 1994. </year> <note> References 15 </note>
Reference-contexts: In these concept classes each concept may be viewed as a union of concepts from a simpler concept class and hence learning can be reduced to learning disjunctions of concepts from these simpler concept classes. The standard PAC-algorithm for learning disjunctions is a simple greedy covering algorithm <ref> [BEHW89, Hau89, KV94] </ref>. This algorithm has the advantage that its hypothesis is a disjunction (but not of minimal size). <p> The standard PAC-algorithm for learning disjunctions is a simple greedy covering algorithm [BEHW89, Hau89, KV94]. This algorithm has the advantage that its hypothesis is a disjunction (but not of minimal size). The best sample size bound obtained for learning k-literal monotone disjunctions over v variables in the PAC model <ref> [KV94] </ref> with the greedy algorithm is O ((1=*)(k log (v) log (1=*) + 1=ffi). Winnow together with the conversion of [Lit89b] leads to the better bound of O ((1=*)(k + k log (v=k) + 1=ffi).
Reference: [KW94] <author> Kivinen, J., Warmuth, M. K.: </author> <title> Exponentiated gradient versus gradient descent for linear predictors. </title> <type> Technical Report UCSC-CRL-94-16, </type> <institution> Univ. of Calif. Computer Research Lab, </institution> <address> Santa Cruz, CA, </address> <month> June </month> <year> 1994. </year> <booktitle> To appear in the Proceeding of the Twenty Seventh Annual ACM Symposium on Theory of Computing, </booktitle> <address> Las Vegas, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: There is a large family of on-line algorithms (besides Winnow and its relatives) with multiplicative weight updates whose loss bounds grow logarithmically with the dimension of the problem <ref> [Vov90, HKW94, KW94] </ref>. We expect that further applications will be found where these algorithm can be simulated for exponentially many "virtual variables". In parallel work such applications have been found in [HW95, HS95, AKMW95]. A more challenging goal is to apply this family of algorithms to continuously many variables.
Reference: [KW95] <author> J. Kivinen and M. K. Warmuth. </author> <title> The Perceptron algorithm vs. Winnow: linear vs. logarith mic mistake bounds when few input variables are relevant. </title> <booktitle> To appear in the Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <address> Santa Cruz, </address> <month> July </month> <year> 1995. </year>
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: Furthermore the virtual variables are maintained as blocks as done in this paper. Other learning models: So far we have used the most common formal model for on-line learning introduced by Nick Littlestone <ref> [Lit88] </ref> where the algorithm is to predict on unseen examples with the goal of minimizing the number of prediction mistakes. <p> Let C k;v denote the class of all such formulas. Since the indices are not required to be distinct, C k;v also contains all disjunctions with less than k literals. We now state some mistake bounds for the Winnow algorithms <ref> [Lit88, Lit89a, Lit91] </ref>. They were proven for certain tunings of the parameters ff and fi. In the bounds we give here we let fi depend on the size of the disjunction k. Only slightly worse bounds can be obtained when the tuning is not allowed to depend on k. <p> For example fi can be set to the number of variables v and if ff is adjusted appropriately then the main change in the above bounds is that the log (v=k) terms are replaced by log v terms and the constants before the summands change <ref> [Lit88] </ref>. One can also take the route of using more information for tuning the algorithms and let the tunings of the parameters ff and fi depend on k as well as an upper bound Z of the number of attribute errors of the target disjunction [AW95]. <p> This gives an overall lower bound for the class BOX d n of 2dblog (n=2)c mistakes. The mistake bound for a concept class is always one less than the maximum number of equivalence queries required for learning the class <ref> [Lit88] </ref>. By a result from [AL94] it immediately follows that even if membership queries are allowed then the total number of equivalence and membership queries is still (d log n).
Reference: [Lit89a] <author> N. Littlestone. </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, Technical Report UCSC-CRL-89-11, </type> <institution> University of California Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: Let C k;v denote the class of all such formulas. Since the indices are not required to be distinct, C k;v also contains all disjunctions with less than k literals. We now state some mistake bounds for the Winnow algorithms <ref> [Lit88, Lit89a, Lit91] </ref>. They were proven for certain tunings of the parameters ff and fi. In the bounds we give here we let fi depend on the size of the disjunction k. Only slightly worse bounds can be obtained when the tuning is not allowed to depend on k. <p> can force at least 2k blog n 2k c + 2 (d 1)kblog n 2 c mistakes, which is (kd log n) when n 2k. 7 Conclusions There are a number of algorithms that can learn k-literal monotone disjunctions with roughly the same mistake bound as Winnow: the Balanced algorithm <ref> [Lit89a] </ref> and the Weighted Majority algorithm [Lit95, LW94]. All of them maintain a linear threshold function and do multiplicative weight updates. It is likely that the results of this paper can also be obtained if we use these other algorithms for the reductions of this paper in place of Winnow.
Reference: [Lit89b] <author> N. Littlestone. </author> <title> From on-line to batch learning. </title> <booktitle> In Proceedings of the Second Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 269-284. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: The hypotheses of the algorithms developed in this paper are efficiently evaluatable but they are always more general than the target class and thus when translated to Angluin's model they correspond to generalized equivalence queries. There are standard conversion methods <ref> [Lit89b] </ref> for translating an on-line algorithm with a worst-case mistake bound to a learning algorithm for the PAC-model [Val84]: If the mistake bound is M then the corresponding PAC-algorithm has sample complexity O ((1=*)(M + log (1=ffi)). <p> The best sample size bound obtained for learning k-literal monotone disjunctions over v variables in the PAC model [KV94] with the greedy algorithm is O ((1=*)(k log (v) log (1=*) + 1=ffi). Winnow together with the conversion of <ref> [Lit89b] </ref> leads to the better bound of O ((1=*)(k + k log (v=k) + 1=ffi).
Reference: [Lit91] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages </pages>
Reference-contexts: Let C k;v denote the class of all such formulas. Since the indices are not required to be distinct, C k;v also contains all disjunctions with less than k literals. We now state some mistake bounds for the Winnow algorithms <ref> [Lit88, Lit89a, Lit91] </ref>. They were proven for certain tunings of the parameters ff and fi. In the bounds we give here we let fi depend on the size of the disjunction k. Only slightly worse bounds can be obtained when the tuning is not allowed to depend on k.
Reference: [Lit95] <author> N. Littlestone. </author> <title> Private communication. </title>
Reference-contexts: The additional requirement leads to larger mistake bounds (at least cubic in the dimension d for Auer's algorithm). His algorithm also applies a simple on-line algorithm related to Winnow called the Weighted Majority algorithm <ref> [Lit95, LW94] </ref> and uses the same set of virtual variables as our application of Winnow for learning BOX d n . Furthermore the virtual variables are maintained as blocks as done in this paper. <p> n 2k c + 2 (d 1)kblog n 2 c mistakes, which is (kd log n) when n 2k. 7 Conclusions There are a number of algorithms that can learn k-literal monotone disjunctions with roughly the same mistake bound as Winnow: the Balanced algorithm [Lit89a] and the Weighted Majority algorithm <ref> [Lit95, LW94] </ref>. All of them maintain a linear threshold function and do multiplicative weight updates. It is likely that the results of this paper can also be obtained if we use these other algorithms for the reductions of this paper in place of Winnow.
Reference: [LW94] <author> N. Littlestone and M. K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: The additional requirement leads to larger mistake bounds (at least cubic in the dimension d for Auer's algorithm). His algorithm also applies a simple on-line algorithm related to Winnow called the Weighted Majority algorithm <ref> [Lit95, LW94] </ref> and uses the same set of virtual variables as our application of Winnow for learning BOX d n . Furthermore the virtual variables are maintained as blocks as done in this paper. <p> n 2k c + 2 (d 1)kblog n 2 c mistakes, which is (kd log n) when n 2k. 7 Conclusions There are a number of algorithms that can learn k-literal monotone disjunctions with roughly the same mistake bound as Winnow: the Balanced algorithm [Lit89a] and the Weighted Majority algorithm <ref> [Lit95, LW94] </ref>. All of them maintain a linear threshold function and do multiplicative weight updates. It is likely that the results of this paper can also be obtained if we use these other algorithms for the reductions of this paper in place of Winnow.
Reference: [MT94] <author> Wolfgang Maass and Gyorgy Turan. </author> <title> Algorithms and lower bounds for on-line learning of geometrical concepts. </title> <booktitle> Machine Learning 14, </booktitle> <pages> 251-269, </pages> <year> 1994. </year>
Reference: [MT92] <author> Wolfgang Maass and Gyorgy Turan. </author> <title> Lower bound methods and separation results for on-line learning models. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 107-145, </pages> <year> 1992. </year>
Reference-contexts: This model can easily be shown to be the same as Angluin's model for on-line learning with equivalence queries [Ang88] where each mistake corresponds to a query that is answered negatively (we refer to <ref> [MT92] </ref> for a survey of these and related formal models for on-line learning).
Reference: [Ros58] <author> F. Rosenblatt. </author> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psych. Rev., </journal> <volume> 65 </volume> <pages> 386-407, </pages> <year> 1958. </year> <note> (Reprinted in Neurocomputing (MIT Press, 1988).). </note>
Reference: [Val84] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Commun. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: There are standard conversion methods [Lit89b] for translating an on-line algorithm with a worst-case mistake bound to a learning algorithm for the PAC-model <ref> [Val84] </ref>: If the mistake bound is M then the corresponding PAC-algorithm has sample complexity O ((1=*)(M + log (1=ffi)). However when all examples are given to the learning algorithm at once (as in the PAC-model), then there exists an alternative simple method for learning 4 2.
Reference: [VC71] <author> V. N. Vapnik and A. Y. Chervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference: [Vov90] <author> Vovk, V.: </author> <title> Aggregating strategies. </title> <booktitle> In Proc. 3rd Workshop on Computational Learning Theory, </booktitle> <pages> pages 371-383. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: There is a large family of on-line algorithms (besides Winnow and its relatives) with multiplicative weight updates whose loss bounds grow logarithmically with the dimension of the problem <ref> [Vov90, HKW94, KW94] </ref>. We expect that further applications will be found where these algorithm can be simulated for exponentially many "virtual variables". In parallel work such applications have been found in [HW95, HS95, AKMW95]. A more challenging goal is to apply this family of algorithms to continuously many variables.
References-found: 34

