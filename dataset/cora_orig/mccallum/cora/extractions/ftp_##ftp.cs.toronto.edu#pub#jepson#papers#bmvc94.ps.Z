URL: ftp://ftp.cs.toronto.edu/pub/jepson/papers/bmvc94.ps.Z
Refering-URL: http://www.cs.toronto.edu/vis/publications/abstracts/bmvcIMO.html
Root-URL: 
Title: Recovery of Egomotion and Segmentation of Independent Object Motion Using the EM Algorithm  
Author: W. James MacLean, Allan D. Jepson Richard C. Frecker 
Address: Toronto, Toronto, Canada M5S 1A1  
Affiliation: University of  
Abstract: This paper examines the use of the EM algorithm to perform motion segmentation on image sequences that contain independent object motion. The input data are linear constraints on 3-D translational motion and bilinear constraints on 3-D translation and rotation, derived from computed optical flow using subspace methods. The problems of outlier detection, deciding how many processes, and the initial guesses for the EM algorithm are considered. Results obtained from an image sequence are presented.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adiv G. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. IEEE Trans Pattern Analysis & Machine Intelligence, PAMI-7(4):384-401 1985 5 This is necessary since the flow from a single patch is described by a first-order polynomial in ~x and as such will not generate a constraint. The floor patch was paired once with each other patch. </title> <booktitle> British Machine Vision Conference </booktitle>
Reference-contexts: The segmentation was achieved using a K-means approach. These methods do segmentation in 2-D, and attempt to solve the problem of proper integration of constraints. There have also been attempts at segmentation based on 3-D motion. Adiv <ref> [1] </ref> identified regions in the image whose motion was consistent with the movement of a planar surface, and grouped these according to their mutual consistency for various 3-D motions.
Reference: [2] <author> Darell T, Pentland A. </author> <title> Robust estimation of a multi-layered motion representation. </title> <booktitle> Proc of the IEEE Workshop on Visual Motion, </booktitle> <month> October 7-9 </month> <year> 1991. </year> <institution> Princeton, </institution> <address> New Jersey 173-177 </address>
Reference-contexts: Some work has already been done on the problem of motion segmentation. We first consider work done on the problem of 2-D segmentation. Darell & Pent-land <ref> [2] </ref> used a method that assigned 2-D constraints to different regions using a competitive and iterative algorithm, but only for the case of translational motion.
Reference: [3] <author> Dempster AP, Laird NM, Rubin DB. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 39 </volume> <pages> 1-38 </pages>
Reference-contexts: We expect outliers to arise due to constraints being generated across independently moving object boundaries, as well as from errors in recovered optic flow. A number of researchers have used the EM algorithm to estimate the parameters of mixture models <ref> [12, 3] </ref>. The EM-algorithm is an iterative, 2-step method where "EM" stands for expectation & maximization, the two basic steps involved. The algorithm starts with an initial guess for the motion parameters.
Reference: [4] <author> Gibson JJ. </author> <title> The perception of the visual world. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, Ma. </address> <year> 1950 </year>
Reference-contexts: It is possible to recover both the observer's motion relative to its environment and a relative depth map for the environment from the captured images <ref> [5, 4] </ref>. The recovery of correct 3-D motion parameters relies on segmenting the optic flow into distinct regions that correspond to unique 3-D motions.
Reference: [5] <author> Helmholtz H. </author> <title> Treatise on physiological optics. </title> <publisher> Dover, </publisher> <address> New York 1910 </address>
Reference-contexts: It is possible to recover both the observer's motion relative to its environment and a relative depth map for the environment from the captured images <ref> [5, 4] </ref>. The recovery of correct 3-D motion parameters relies on segmenting the optic flow into distinct regions that correspond to unique 3-D motions.
Reference: [6] <author> Horn BKP. </author> <title> Robot vision. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts 1986 </address>
Reference-contexts: At each "E"-step in the EM algorithm the ownership probability s ij of con straint i by process j is calculated as well as the mixture proportions j = ff P N 3 This is a feature inherent in the problem itself <ref> [6] </ref>. British Machine Vision Conference where ff is determined by the fact that the j sum to 1.
Reference: [7] <author> Jepson AD, Heeger, </author> <title> DJ. A fast subspace algorithm for recovering rigid motion. </title> <booktitle> Proc. of IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, NJ (Oct. </address> <year> 1991), </year> <month> 124-131 </month> <year> 1991 </year>
Reference-contexts: Both are functions of ~x, and ~a is also a function of ~u. It is possible to derive a linear constraint on ~ T from 7 or more bilinear constraints <ref> [7] </ref>. Given optic flow sampled at K discrete points in the image, f~x k g K we construct a constraint vector w i ~t i = P K k=1 c ik [~u (~x k ) fi ~x k ].
Reference: [8] <author> Jepson AD, Heeger, </author> <title> DJ. Linear subspace methods for recovering translational direction, in Spatial Vision in Humans and Robots, </title> <editor> Eds. L. Harris and M. Jenkin, </editor> <publisher> Cambridge Univ. Press 1993 </publisher>
Reference: [9] <author> Jepson AD, Heeger, </author> <title> DJ. Subspace methods for recovering rigid motion, II: </title> <journal> Theory. </journal> <note> In preparation. </note>
Reference-contexts: The motion field at the image of this point, namely ~x = (x 1 ; x 2 ; f) = f ~ X, can be defined in terms of the motion parameters <ref> [9] </ref>: ~u (~x) = 1 0 x 1 =f X 3 (~x) where ~ T and ~ are motion of the background with respect to the observer, f is the focal length of the system, and X 3 (~x) = X 3 is the projection of ~ X onto the optical <p> Therefore, any discontinuities in the optic flow field must be due to variations in depth, 1 a fact exploited by Rieger & Lawton [15] in their method for recovering translational motion. It is also exploited by the subspace methods. A simple algebraic manipulation of Eqn. 1 <ref> [9] </ref> allows us to derive the following bilinear constraint on ~ T and ~ : ~ T T (~x fi ~u (~x)) + ( ~ T fi ~x)(~x fi ~ ) = 0 (2) This is an exact constraint on the motion field, although it is non-linear in the motion parameters.
Reference: [10] <author> Jepson A, Black MJ. </author> <title> Mixture models for optical flow computation. </title> <booktitle> Proceedings 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. </booktitle> <address> June 15-18 1993, New York City, New York 760-761 </address>
Reference-contexts: We first consider work done on the problem of 2-D segmentation. Darell & Pent-land [2] used a method that assigned 2-D constraints to different regions using a competitive and iterative algorithm, but only for the case of translational motion. Jepson & Black <ref> [10] </ref> used a mixture-model approach to cluster component fl Institute of Biomedical Engineering, Department of Electrical & Computer Engineering y Department of Computer Science & Canadian Institute for Advanced Research British Machine Vision Conference The forklift and its driver are translating to the right. <p> Gaussian modified for the unit sphere, p (~t i j ~ T j ; j ) = 3 4 (2+expf1=2 2 j g) exp i ~ T j ) 2 j p 0 = constant where p 0 is a uniform distribution meant to model outliers in the data [cf. <ref> [10] </ref>]. Once parameters are known or estimated, each observed constraint can be assigned an ownership probability to each process, j = 0 . . .
Reference: [11] <author> Jenkin M, Jepson A. </author> <title> Detecting Floor Anomalies. </title> <booktitle> Proceedings of the British Machine Vision Conference, </booktitle> <year> 1994 </year>
Reference-contexts: British Machine Vision Conference the sequence using a method that fits flow in image regions (patches) to functions that are either affine or rational in image coordinates ~x <ref> [11] </ref>. The ~t were recovered by considering patches in a pair-wise manner 5 : 6 flow samples were generated for each patch, using the 4 corners of each patch plus two interior points.
Reference: [12] <author> McLachlan GJ, Basford KE. </author> <title> Mixture models: Inference and applications to clustering. </title> <publisher> Marcel Dekker Inc, </publisher> <address> New York 1988 </address>
Reference-contexts: i coefficients is straightforward once the sampling geometry is known 3 Mixture Models When a set of data has more than one underlying process, i.e., any given data point in the set will have been generated by one of several processes, the concept of a mixture of distributions is useful <ref> [12] </ref>. Each process 2 will have its own distribution and parameters. Our task is to i) estimate the parameters for each process, and ii) determine the probability that a given data point is the result of a given process. <p> We assume in advance that we know the number of underlying processes and the form of each corresponding distribution. Testing for the number of processes in a mixture is a difficult and, in general, unsolved problem <ref> [12] </ref>. Part ii) of this objective is commonly referred to as clustering. We can consider our linear and bilinear constraints on relative motion as observations arising from one of several underlying motion processes. We first consider mixtures involving linear constraints and translational motions. <p> We expect outliers to arise due to constraints being generated across independently moving object boundaries, as well as from errors in recovered optic flow. A number of researchers have used the EM algorithm to estimate the parameters of mixture models <ref> [12, 3] </ref>. The EM-algorithm is an iterative, 2-step method where "EM" stands for expectation & maximization, the two basic steps involved. The algorithm starts with an initial guess for the motion parameters.
Reference: [13] <author> Neal RM, Hinton GE. </author> <title> A new view of the EM algorithm that justifies incremental and other variants. </title> <note> Submitted to Biometrika, </note> <year> 1993 </year>
Reference-contexts: The case in which the likelihood function is left unchanged corresponds to having found a local maximum in the likelihood function. No results are given for the rate of convergence to a maximum likelihood point, although methods for improving the convergence rate have been proposed <ref> [13] </ref>. The existence, in general, of local maxima in the likelihood function leads to the importance of a good initial guess for the algorithm. A poor choice of initial guess may lead to slow convergence, or convergence to a local, not global, maximum.
Reference: [14] <author> Nelson RC. </author> <title> Qualitative detection of motion by a moving observer. </title> <journal> International Journal of Computer Vision 7(1) </journal> <month> 33-46 </month> <year> 1991 </year>
Reference-contexts: This method also requires identifying planar surfaces in the image. Both of these methods require the existence (and identification) of planar surfaces in the image. Nelson <ref> [14] </ref> describes a method which could properly be thought of as a 3-D method. Given the observer motion, he compares the expected motion field against measured component velocities, and where significant deviation is found assumes independent object motion.
Reference: [15] <author> Rieger JH, Lawton DT. </author> <title> Processing differential image motion. </title> <journal> J Opt Soc Am A 2(2) </journal> <month> 354-359 </month> <year> 1985 </year>
Reference-contexts: Note that only the translational component is affected by the distance to points in the image. Therefore, any discontinuities in the optic flow field must be due to variations in depth, 1 a fact exploited by Rieger & Lawton <ref> [15] </ref> in their method for recovering translational motion. It is also exploited by the subspace methods.
Reference: [16] <author> Sinclair D. </author> <title> Motion segmentation and local structure. </title> <booktitle> Proceedings of the 4th International Conference on Computer Vision, </booktitle> <address> Berlin, </address> <month> May </month> <year> 1993 </year> <month> 366-373 </month>
Reference-contexts: There have also been attempts at segmentation based on 3-D motion. Adiv [1] identified regions in the image whose motion was consistent with the movement of a planar surface, and grouped these according to their mutual consistency for various 3-D motions. Sinclair <ref> [16] </ref> segments images by recovering the 3-D angular velocity field for the image, and using a simple clustering algorithm for identifying planes in angular velocity space. This method also requires identifying planar surfaces in the image.
Reference: [17] <author> Wang JYA, </author> <title> Adelson EH. Layered representation for motion analysis. </title> <booktitle> Proceedings 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. </booktitle> <address> June 15-18 1993, New York City, New York 361-366 </address>
Reference-contexts: The focus-of-expansion (FOE) of the background motion for each frame in the sequence have been indicated by a 'fi' (see Section 5) velocities, and hence achieve improved optic flow estimates. Their method allows shared ownership of constraints amongst regions. Wang & Adelson <ref> [17] </ref> segmented image regions into patches whose optic flow at any point could be modelled as an affine transformation of the image coordinates of that point. The segmentation was achieved using a K-means approach.
References-found: 17

