URL: http://suif.stanford.edu/papers/maydan92a.ps
Refering-URL: http://suif.stanford.edu/papers/papers.html
Root-URL: 
Title: Effectiveness of Data Dependence Analysis Parallelizing loops written in imperative languages requires the compiler to
Author: Dror E. Maydan John L. Hennessy Monica S. Lam 
Note: 1.1 Introduction  
Pubnum: a[i] a[i-10]+3  
Abstract: Data dependence testing is the basic step in detecting loop level parallelism in numerical programs. The problem is undecidable in the general case. Therefore, work has been concentrated on a simplified problem, affine memory disambiguation. In this simpler domain, array references and loops bounds are assumed to be linear integer functions of loop variables. Dataflow information is ignored. For this domain, we have shown that in practice the problem can be solved accurately and efficiently[9]. This paper studies empirically the effectiveness of this domain restriction, how many real references are affine and flow insensitive. We use Larus's llpp system[5] to find all the data dependences dynamically. We compare these to the results given by our affine memory disambiguation system. This system is exact for all the cases we see in practice. We show that while the affine approximation is reasonable, memory disambiguation is not a sufficient approximation for data dependence analysis. We propose extensions to improve the analysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Aca demic, </publisher> <year> 1988. </year>
Reference: [2] <author> M. Berry et al. </author> <title> The PERFECT Club benchmarks: effective performance evaluation of supercomputers. </title> <type> Technical Report UIUCSRD Rep. No. 827, </type> <institution> University of Illinois Urbana-Champaign, </institution> <year> 1989. </year>
Reference-contexts: Hennessy, Monica S. Lam In this case, every iteration can safely be run in parallel without any modifications. An output dependence occurs when a location being written is overwritten in a later iteration. For example: for i = 10 to 20 do b [i] = b [i] + a <ref> [2] </ref> If f () has no side effects, we can replace this loop with for i = 10 to 20 do end for which can safely be run in parallel. <p> Theoretically, there could exist inputs for which we fail, inputs where we must either use an expensive general integer programming solver or assume dependence. We have tested our compiler on the PERFECT Club Benchmarks, a set of real scientific programs ranging from 500 to 18,500 lines <ref> [2] </ref>, and have found no such cases. We are able to be exact at an inexpensive cost in all cases. Solving the affine memory disambiguation problem exactly enables us to study the effectiveness of the domain restrictions.
Reference: [3] <author> P. Feautrier. </author> <title> Array expansion. </title> <booktitle> In International Conference on Supercom puting, </booktitle> <pages> pages 429-442, </pages> <year> 1988. </year>
Reference-contexts: To differentiate the two cases requires dataflow information. Even if one can differentiate the two cases, the first case can not simply be run in parallel. There is an output dependence which has to eliminated. This can be accomplished using array privatization or array expansion <ref> [3] </ref>. Each processor can be given its own private copy of the work array.
Reference: [4] <author> M. R. Haghighat. </author> <title> Symbolic dependence analysis for high performance parallelizing compilers. </title> <booktitle> In 3rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <year> 1990. </year>
Reference: [5] <author> James R. Larus. </author> <title> Estimating the potential parallelism in programs. </title> <editor> In Aland David Padua, editor, </editor> <booktitle> Proceedings of the Third Workshop on Languages and Compilers for Parallel Computing, chapter 17, </booktitle> <pages> pages 331-349, </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Solving this problem exactly allows us to empirically investigate the effectiveness of the domain restrictions. We use a trace-based dynamic system developed by Larus to dynamically find all the data dependences for a given input set <ref> [5] </ref>. We compare his results to the ones generated by our system and show that affine memory disambiguators find many false data dependences. We propose some extensions which we feel overcome these limitations. 1.2 Types of Data Dependences There are several different types of dependences. <p> Our goal is to show whether or not most pairs in practice are decidable in the domain. We use llpp, a system developed by Larus, to dynamically find all the true dependences in a program for a given input set <ref> [5] </ref>. This system was developed to dynamically estimate the amount of parallelism in a program. It modifies a standard compiler, gcc, to add tracing code to the sequential program.
Reference: [6] <author> Z. Li and P. Yew. </author> <title> Practical methods for exact data dependency analysis. </title> <booktitle> In Proceedings of the Second Workshop on Languages and Compilers for Parallel Computing, </booktitle> <year> 1989. </year>
Reference: [7] <author> Z. Li, P. Yew, and C. Zhu. </author> <title> An efficient data dependence analysis for parallelizing compilers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 26-34, </pages> <month> Jan </month> <year> 1990. </year>
Reference: [8] <author> A. Lichnewsky and F. Thomasset. </author> <title> Introducing symbolic problem solving techniques in dependence testing phases of a vectorizer. </title> <booktitle> In Proceedings of Supercomputing 88, </booktitle> <pages> pages 396-406, </pages> <year> 1988. </year>
Reference: [9] <author> D.E. Maydan, J.L. Hennessy, and M.S. Lam. </author> <title> Efficient and exact data dependence analysis. </title> <booktitle> In Proceedings of the SIGPLAN 1991 PLDI, </booktitle> <pages> pages 1-14, </pages> <year> 1991. </year> <note> 18 Dror E. </note> <author> Maydan , John L. Hennessy, Monica S. </author> <note> Lam </note>
Reference-contexts: This domain is decidable, but solving it exactly can be very expensive. Almost all traditional algorithms make further approximations to improve compiler efficiency [1][6][7][10][11]. 1. Effectiveness of Data Dependence Analysis 3 We have recently developed a system which in practice solves the affine memory disambiguation problem exactly and efficiently <ref> [9] </ref>. Solving this problem exactly allows us to empirically investigate the effectiveness of the domain restrictions. We use a trace-based dynamic system developed by Larus to dynamically find all the data dependences for a given input set [5]. <p> disambiguation system, we have to assume that there are two true dependences since the location being written by both writes is the same location being read in a later iteration. 1.4 Experimental System We have developed a system which in practice solves the affine memory disambiguation problem exactly and efficiently <ref> [9] </ref>. Affine memory disambiguation is exactly equivalent to solving the satisfiability problem in integer programming.
Reference: [10] <author> D. R. Wallace. </author> <title> Dependence of multi-dimensional array references. </title> <booktitle> In Proceedings of 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 418-428, </pages> <year> 1988. </year>
Reference: [11] <author> M. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <year> 1989. </year>
References-found: 11

