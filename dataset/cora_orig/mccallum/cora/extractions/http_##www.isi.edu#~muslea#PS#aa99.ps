URL: http://www.isi.edu/~muslea/PS/aa99.ps
Refering-URL: http://www.isi.edu/~muslea/RISE/wOKRA/__Source__.html
Root-URL: http://www.isi.edu
Email: fmuslea, minton, knoblockg@isi.edu  
Title: A Hierarchical Approach to Wrapper Induction  
Author: Ion Muslea, Steve Minton, and Craig Knoblock 
Date: October 3, 1998  
Address: 4676 Admiralty Way Marina del Rey, CA 90292-6695  
Affiliation: University of Southern California  
Abstract: With the tremendous amount of information that becomes available on the Web on a daily basis, the ability to quickly develop information agents has become a crucial problem. A vital component of any Web-based information agent is a set of wrappers that can extract the relevant data from semistructured information sources. Our novel approach to wrapper induction is based on the idea of hierarchical information extraction, which turns the hard problem of extracting data from an arbitrarily complex document into a series of easier extraction tasks. We introduce an inductive algorithm, stalker, that generates high accuracy extraction rules based on user-labeled training examples. Labeling the training data represents the major bottleneck in using wrapper induction techniques, and our experimental results show that stalker does significantly better then other approaches; on one hand, stalker requires up to two orders of magnitude fewer examples than other algorithms, while on the other hand it can handle information sources that could not be wrapped by existing techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [Ashish & Knoblock1997] <author> Ashish, N., and Knoblock, C. </author> <year> 1997. </year> <title> Semiautomatic wrapper generation for internet information sources. </title> <booktitle> Proceedings of Cooperative Information Systems. </booktitle>
Reference-contexts: In order to help the users cope with these difficulties, in <ref> [Ashish & Knoblock1997] </ref>, the authors proposed an expert system approach 17 that uses a fixed set of heuristics of the type "look for bold or italicized strings".
Reference: [Atzeni & Mecca1997] <author> Atzeni, P., and Mecca, G. </author> <year> 1997. </year> <title> Cut and paste. </title> <booktitle> Proceedings of 16th ACM SIGMOD Symposion on Principles of Database Systems. </booktitle> <pages> 19 </pages>
Reference-contexts: With the increasing interest in accessing Web-based information sources, a significant number of research projects depend on wrappers to retrieve the relevant data. A wide variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages <ref> [Atzeni & Mecca1997] </ref> and Perl scripts [Cohen1998] to pattern matching [Chawathe et al.1994] and LL (k) grammars [Chidlovskii, Borghoff, & Chevalier1997].
Reference: [Atzeni, Mecca, & Merialdo1997] <author> Atzeni, P.; Mecca, G.; and Merialdo, P. </author> <year> 1997. </year> <title> Semi-structured and structured data in the web: going back and forth. </title> <booktitle> Proceedings of ACM SIGMOD Workshop on Management of Semi-structured Data 1-9. </booktitle>
Reference-contexts: Each wrapper consists of a set of extraction rules and the code required to apply those rules. Some systems, such as tsimmis [Chawathe et al.1994] and ara-neus <ref> [Atzeni, Mecca, & Merialdo1997] </ref> depend on humans to write the necessary grammar rules. However, there are several reasons why this is undesirable. Writing extraction rules is tedious, time consuming and requires a high level of expertise.
Reference: [Califf & Mooney1997] <author> Califf, M., and Mooney, R. </author> <year> 1997. </year> <title> Relational learning of pattern-match rules for information extraction. </title> <booktitle> Working Papers of the ACL-97 Workshop in Natural Language Learning 9-15. </booktitle>
Reference-contexts: In contrast to information agents, most general purpose information extraction systems are focused on unstructured text, and therefore the extraction techniques text are based on linguistic constraints. However, there are three such systems that are somewhat related to stalker: WHISK [Soderland1998], Rapier <ref> [Califf & Mooney1997] </ref>, and SRV [Freitag1998]. The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks.
Reference: [Chawathe et al.1994] <author> Chawathe, S.; Garcia-Molina, H.; Hammer, J.; Ire-land, K.; Papakonstantinou, Y.; Ullman, J.; and Widom., J. </author> <year> 1994. </year> <title> The tsimmis project: integration of heterogeneous information sources. </title> <booktitle> 10th Meeting of the Information Processing Society of Japan 7-18. </booktitle>
Reference-contexts: Each wrapper consists of a set of extraction rules and the code required to apply those rules. Some systems, such as tsimmis <ref> [Chawathe et al.1994] </ref> and ara-neus [Atzeni, Mecca, & Merialdo1997] depend on humans to write the necessary grammar rules. However, there are several reasons why this is undesirable. Writing extraction rules is tedious, time consuming and requires a high level of expertise. <p> A wide variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages [Atzeni & Mecca1997] and Perl scripts [Cohen1998] to pattern matching <ref> [Chawathe et al.1994] </ref> and LL (k) grammars [Chidlovskii, Borghoff, & Chevalier1997]. Even though these systems offer fairly expressive extraction languages, the manual wrapper generation is a tedious, time consuming task that requires a high level of expertise; furthermore, the rules have to be rewritten whenever the sources suffer format changes.
Reference: [Chidlovskii, Borghoff, & Chevalier1997] <author> Chidlovskii, B.; Borghoff, U.; and Chevalier, P. </author> <year> 1997. </year> <title> Towards sophisticated wrapping of web-based information repositories. </title> <booktitle> Proceedings of 5th International RIAO Conf. </booktitle> <pages> 123-35. </pages>
Reference-contexts: A wide variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages [Atzeni & Mecca1997] and Perl scripts [Cohen1998] to pattern matching [Chawathe et al.1994] and LL (k) grammars <ref> [Chidlovskii, Borghoff, & Chevalier1997] </ref>. Even though these systems offer fairly expressive extraction languages, the manual wrapper generation is a tedious, time consuming task that requires a high level of expertise; furthermore, the rules have to be rewritten whenever the sources suffer format changes.
Reference: [Cohen1998] <author> Cohen, W. </author> <year> 1998. </year> <title> A web-based information system that reasons with structured collections of text. </title> <booktitle> Proceedings of Autonomous Agents AA-98 400-407. </booktitle>
Reference-contexts: However, the Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sources. The most recent generation of information agents (e.g., Ariadne [Knoblock et al.1998], WHIRL <ref> [Cohen1998] </ref>, or Information Manifold [Kirk et al.1995] ) address this problem by enabling information from pre-specified sets of Web sites to be accessed via database-like queries. For instance, consider the query "What seafood restaurants in L.A. have prices below $20 and accept the Visa credit-card?". <p> A wide variety of languages have been developed for manually writing wrappers (i.e., where the extraction rules are written by a human expert), from procedural languages [Atzeni & Mecca1997] and Perl scripts <ref> [Cohen1998] </ref> to pattern matching [Chawathe et al.1994] and LL (k) grammars [Chidlovskii, Borghoff, & Chevalier1997].
Reference: [Freitag1998] <author> Freitag, D. </author> <year> 1998. </year> <title> Information extraction from html: Application of a general learning approach. </title> <booktitle> Proceedings of the Fifteenth Conference on Artificial Intelligence AAAI-98 517-523. </booktitle>
Reference-contexts: In contrast to information agents, most general purpose information extraction systems are focused on unstructured text, and therefore the extraction techniques text are based on linguistic constraints. However, there are three such systems that are somewhat related to stalker: WHISK [Soderland1998], Rapier [Califf & Mooney1997], and SRV <ref> [Freitag1998] </ref>. The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks.
Reference: [Hsu1998] <author> Hsu, C. </author> <year> 1998. </year> <title> Initial results on wrapping semistructured web pages with finite-state transducers and contextual rules. </title> <booktitle> AAAI-98 Workshop on AI and Information Integration 66-73. </booktitle>
Reference-contexts: Second, wien cannot wrap sources in which some items are missing or appearing in various orders. Last but not least, stalker can handle EC trees of arbitrary depths, while wien's approach to nested documents turned out to be prohibitive in terms of CPU time. SoftMealy <ref> [Hsu1998] </ref> uses a wrapper induction algorithm that generates extraction rules expressed as finite transducers. The SoftMealy rules are more general than the wien ones because they use wildcards and they can handle both missing items and items appearing in various orders.
Reference: [Kirk et al.1995] <author> Kirk, T.; Levy, A.; SAgiv, Y.; and Srivastava, D. </author> <year> 1995. </year> <title> The information manifold. </title> <booktitle> AAAI Spring Symposium: Information Gathering from Heterogeneous Distributed Environments 85-91. </booktitle>
Reference-contexts: However, the Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sources. The most recent generation of information agents (e.g., Ariadne [Knoblock et al.1998], WHIRL [Cohen1998], or Information Manifold <ref> [Kirk et al.1995] </ref> ) address this problem by enabling information from pre-specified sets of Web sites to be accessed via database-like queries. For instance, consider the query "What seafood restaurants in L.A. have prices below $20 and accept the Visa credit-card?".
Reference: [Knoblock et al.1998] <author> Knoblock, C.; Minton, S.; Ambite, J.; Ashish, N.; Margulis, J.; Modi, J.; Muslea, I.; Philpot, A.; and Tejada, S. </author> <year> 1998. </year> <title> Modeling web sources for information integration. </title> <booktitle> Proceedings of the Fifteenth National Conference on ASrtificial Intelligence 211-218. </booktitle> <pages> 20 </pages>
Reference-contexts: However, the Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sources. The most recent generation of information agents (e.g., Ariadne <ref> [Knoblock et al.1998] </ref>, WHIRL [Cohen1998], or Information Manifold [Kirk et al.1995] ) address this problem by enabling information from pre-specified sets of Web sites to be accessed via database-like queries. For instance, consider the query "What seafood restaurants in L.A. have prices below $20 and accept the Visa credit-card?".
Reference: [Kushmerick1997] <author> Kushmerick, N. </author> <year> 1997. </year> <title> Wrapper induction for information extraction. </title> <type> PhD Thesis, </type> <institution> Dept. of Computer Science, U. of Washington, </institution> <note> TR UW-CSE-97-11-04. </note>
Reference-contexts: 4 252 3335 S2 BigBook 6 235 4299 S3 Address Finder 6 10 57 S4 Quote Server 18 10 22 Table 1: Illustrative information sources. 7 Experimental Results In Table 1, we present four illustrative information sources that were selected from the larger of set sources on which the wien <ref> [Kushmerick1997] </ref> system was tested 2 . S1 and S2 are the hardest sources that wien could wrap (i.e., they required the largest number of training examples), while S3 and S4 were beyond wien's capabilities because they have missing items and/or items that appear in various orders. <p> In order to help the users cope with these difficulties, in [Ashish & Knoblock1997], the authors proposed an expert system approach 17 that uses a fixed set of heuristics of the type "look for bold or italicized strings". The wrapper induction techniques introduced in wien <ref> [Kushmerick1997] </ref> are better fit to frequent format changes because they rely on learning techniques to generate the extraction rules. While Kushmerick's approach dramatically reduces the time required to wrap a source, his extraction language is significantly less expressive than the ones provided by the manual approaches.
Reference: [RISE1998] <author> RISE. </author> <year> 1998. </year> <title> Rise: A repository of online information sources used in information extraction tasks. </title> <institution> [http://www.isi.edu/ muslea/RISE/index.html] Information Sciences Institute / USC. </institution>
Reference-contexts: . . , and 10 training examples.As we will see later in this section by analyzing the learning curves in Figure 9, stalker usually requires less then 10 examples to obtain a 97% average accuracy over the 500 trials. 2 All the wien sources can be obtained from the RISE <ref> [RISE1998] </ref> repository. 14 SR Missing Various wien stalker Items Orders Exs CPU Exs CPU S1 - 46 0:05.02 4 0:19.4 S3 - 10 3:22.1 p Table 2: Experimental data.
Reference: [Soderland1998] <author> Soderland, S. </author> <year> 1998. </year> <title> Learning information extraction rules for semi-structured and free text. </title> <note> http://www.cs.washington.edu/homes/soderlan/WHISK.ps. 21 </note>
Reference-contexts: In contrast to information agents, most general purpose information extraction systems are focused on unstructured text, and therefore the extraction techniques text are based on linguistic constraints. However, there are three such systems that are somewhat related to stalker: WHISK <ref> [Soderland1998] </ref>, Rapier [Califf & Mooney1997], and SRV [Freitag1998]. The extraction rules induced by Rapier and SRV can use the landmarks that immediately precede and/or follow the item to be extracted, while WHISK is capable of using multiple landmarks.
References-found: 14

