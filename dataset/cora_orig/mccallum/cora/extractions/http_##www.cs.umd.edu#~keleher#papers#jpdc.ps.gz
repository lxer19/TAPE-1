URL: http://www.cs.umd.edu/~keleher/papers/jpdc.ps.gz
Refering-URL: http://www.cs.umd.edu/~hollings/cs818z/f96/readingList.htm
Root-URL: 
Title: An Evaluation of Software-Based Release Consistent Protocols  
Author: Pete Keleher Alan L. Cox, Sandhya Dwarkadas, Willy Zwaenepoel 
Note: This research was supported in part by the National Science Foundation under Grants CCR-9116343, CCR-9211004, CDA-9222911, and CDA-9310073, by the Texas Advanced Technology Program under Grant 003604014, and by a NASA Graduate Fellowship.  
Address: College Park, MD 20742  Houston, TX 77251-1892  
Affiliation: Department of Computer Science The University of Maryland  Department of Computer Science Rice University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Adve and M. Hill. </author> <title> Weak ordering: A new definition. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-14, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The execution of each process is divided into intervals, each denoted by an interval index. Every time a process executes a release or an acquire, a new interval begins and the interval index is incremented. Intervals of different processes are partially ordered <ref> [1] </ref>: (i) intervals on a single processor are totally ordered by program order, and (ii) an interval on processor p precedes an interval on processor q if the interval of q begins with the acquire corresponding to the release that concluded the interval of p.
Reference: [2] <author> D. Bailey, J. Barton, T. Lasinski, and H. Simon. </author> <title> The NAS parallel benchmarks. </title> <type> Tech nical Report TR RNR-91-002, </type> <institution> NASA Ames, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: SOR (Succes-sive Over-Relaxation) and TSP (Traveling Salesman Problem) are small programs, developed locally. Water and Barnes-Hut come from the Stanford Parallel Applications for Shared Memory (SPLASH) benchmark suite [15]. FFT (Fast Fourier Transform) and IS (Integer Sort) are taken from the NAS benchmark suite <ref> [2] </ref>. Finally, ILINK (genetic linkage) [7] and MIP (mixed integer programming) are large programs, each more than ten thousand lines of code. Parallel versions of both programs were developed locally. Table 2 summarizes the applications and their input sets.
Reference: [3] <author> T. Ball and J. Larus. </author> <title> Optimally profiling and tracing programs. </title> <booktitle> In POPL92, </booktitle> <pages> pages 59-70, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: LH performs the best because of its ability to reduce the number of remote misses without significantly increasing the amount of data sent across the network. 4.2 Execution Time Breakdown We used qpt <ref> [3] </ref> to break the execution time into several categories. Figure 3 shows the breakdown for each of our applications running on 8 processors under each of the protocols. <p> Therefore, we chose a method that allowed the execution of the actual protocol code on the simulator. To meet our objectives, we use vt <ref> [3] </ref>, a profiling tool that rewrites executable programs to incorporate instrumentation code that produces an estimated processor cycle count.
Reference: [4] <author> B.N. Bershad, M.J. Zekauskas, </author> <title> and W.A. </title> <booktitle> Sawdon. The Midway distributed shared mem ory system. In Proceedings of the '93 CompCon Conference, </booktitle> <pages> pages 528-537, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Our work improves on earlier comparisons of various software implementations of RC by comparing actual implementations on the same platform, and by using measurements from these systems to validate simulation results that vary various environment parameters. An interesting alternative to RC is entry consistency (EC) <ref> [4] </ref>. EC differs from RC in that it requires all shared data to be explicitly associated with some synchronization variable. On a lock acquisition EC only propagates the shared data associated with that lock. <p> On a lock acquisition EC only propagates the shared data associated with that lock. EC, however, requires the programmer to insert additional synchronization in shared memory programs to execute correctly on an EC memory. Typically, RC does not require additional synchronization. Bershad et al. <ref> [4] </ref> also use a different strategy to implement EC in the Midway DSM system.
Reference: [5] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Furthermore, given the large consistency units in DSM (virtual memory pages), false sharing was a serious problem for many applications. In order to address the performance problems with earlier DSM systems, relaxed memory models, such as release consistency (RC) [8], were introduced into DSM systems <ref> [5] </ref>. With very little change to the programming model, RC permits several runtime optimizations that reduce the amount of communication. In particular, it allows the protocol to aggregate the transmission of shared memory writes until a later synchronization point. Furthermore, it permits the use of multiple-writer protocols [5], allowing multiple, simultaneous <p> into DSM systems <ref> [5] </ref>. With very little change to the programming model, RC permits several runtime optimizations that reduce the amount of communication. In particular, it allows the protocol to aggregate the transmission of shared memory writes until a later synchronization point. Furthermore, it permits the use of multiple-writer protocols [5], allowing multiple, simultaneous writes by different processors to the same page, thereby reducing the impact of false sharing. This paper evaluates three different software implementations of RC on a network of workstations: an eager invalidate (EI) protocol, a lazy invalidate (LI) protocol, and a lazy hybrid (LH) protocol. <p> We discuss related work in Section 6, and conclude in Section 7. 2 Release Consistency Protocols Release consistency requires less communication than the canonical memory model, sequential consistency [11], but provides a very similar programming interface. An eager implementation <ref> [5] </ref> of release consistency enforces consistency when a synchronization variable is released. In contrast, lazy implementations of release consistency enforce consistency when synchronization variables are acquired. Strictly speaking, lazy protocols implement a slight weaker memory model than EI. <p> Given the small size of the cache line, false sharing is less of an issue, and a single-writer protocol is used. The first software implementation of RC was carried out in the Munin systems <ref> [5] </ref>. Munin also introduced the notion of a multiple-writer protocol to combat false sharing. Munin allowed a number of protocols to be used, but the primary protocol was an eager update implementation of release consistency. Later work [6] has shown that the performance of EI and eager update are comparable.
Reference: [6] <author> S. Dwarkadas, P. Keleher, A.L. Cox, and W. Zwaenepoel. </author> <title> Evaluation of release con sistent software distributed shared memory on emerging network technology. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 244-255, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Lazy protocols enforce RC when a synchronization variable is acquired. Both EI and LI invalidate remote copies of modified data, while LH uses a combination of invalidate and update. We do not consider eager update or pure lazy update protocols, because earlier work <ref> [6] </ref> has shown that eager update performs comparably to EI, and lazy update performs 3 substantially worse than LI or LH. We explore the trade-offs between these three protocols by measurement and simulation. <p> Munin also introduced the notion of a multiple-writer protocol to combat false sharing. Munin allowed a number of protocols to be used, but the primary protocol was an eager update implementation of release consistency. Later work <ref> [6] </ref> has shown that the performance of EI and eager update are comparable. Lazy release consistency was introduced in the TreadMarks system [10]. The default protocol in TreadMarks is LI, although Dwarkadas et al. [6] present simulation results for LH. <p> Later work <ref> [6] </ref> has shown that the performance of EI and eager update are comparable. Lazy release consistency was introduced in the TreadMarks system [10]. The default protocol in TreadMarks is LI, although Dwarkadas et al. [6] present simulation results for LH. Our work improves on earlier comparisons of various software implementations of RC by comparing actual implementations on the same platform, and by using measurements from these systems to validate simulation results that vary various environment parameters.
Reference: [7] <author> S. Dwarkadas, A.A. Schaffer, R.W. Cottingham Jr., A.L. Cox, P. Keleher, and W. Zwaenepoel. </author> <title> Parallelization of general linkage analysis problems. </title> <booktitle> Human Heredity, </booktitle> <volume> 44 </volume> <pages> 127-141, </pages> <year> 1994. </year>
Reference-contexts: SOR (Succes-sive Over-Relaxation) and TSP (Traveling Salesman Problem) are small programs, developed locally. Water and Barnes-Hut come from the Stanford Parallel Applications for Shared Memory (SPLASH) benchmark suite [15]. FFT (Fast Fourier Transform) and IS (Integer Sort) are taken from the NAS benchmark suite [2]. Finally, ILINK (genetic linkage) <ref> [7] </ref> and MIP (mixed integer programming) are large programs, each more than ten thousand lines of code. Parallel versions of both programs were developed locally. Table 2 summarizes the applications and their input sets. <p> Given a fixed value of the recombination vector, the outer loops of the likelihood evaluation iterate over all the pedigrees and each nuclear family (consisting of parents and child) within each pedigree to update the probabilities of each genotype (see <ref> [7] </ref>) for each individual, which is stored in an array genarray. A straightforward method of parallelizing this program is to split the iteration space among the processes and surround each addition with a lock to do it in place. <p> The eager protocol does the worst because of the larger number of messages and data (entire pages are sent instead of diffs). ILINK achieves less than linear speedup because of a combination of poor load balancing (this problem is inherent to the algorithm <ref> [7] </ref>) and sections of code that are executed serially.
Reference: [8] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year> <month> 37 </month>
Reference-contexts: Furthermore, given the large consistency units in DSM (virtual memory pages), false sharing was a serious problem for many applications. In order to address the performance problems with earlier DSM systems, relaxed memory models, such as release consistency (RC) <ref> [8] </ref>, were introduced into DSM systems [5]. With very little change to the programming model, RC permits several runtime optimizations that reduce the amount of communication. In particular, it allows the protocol to aggregate the transmission of shared memory writes until a later synchronization point. <p> Programs written for SC memory produce the same results on an RC memory, provided that (i) all synchronization operations use system-supplied primitives, and (ii) there is a release-acquire pair between conflicting ordinary accesses to the same memory location on different processors <ref> [8] </ref>. In practice, most shared memory programs require little or no modifications to meet these requirements. Although execution on an RC memory produces the same results as on an SC memory for the overwhelming majority of the programs, RC can be implemented more efficiently than SC. <p> Since pages are completely overwritten in each phase, the lazy protocols send at least as much data as EI, while still paying the overhead of creating and applying the diffs. 33 dark gray) 34 6 Related Work RC was first proposed in the context of the DASH project <ref> [8] </ref>. In DASH, RC is implemented in hardware, using an invalidate protocol on a cache line basis. Given the small size of the cache line, false sharing is less of an issue, and a single-writer protocol is used.
Reference: [9] <author> P. Keleher. </author> <title> Distributed Shared Memory Using Lazy Release Consistency. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Approximately 1200 lines are specific to the lazy protocols, and an additional 300 lines are specific to LH. EI is fully implemented in only 800 lines of code. For a more detailed discussion of the implementation of the three protocol, we refer the reader to Keleher's Ph.D. dissertation <ref> [9] </ref>. 3.2 Experimental Environment Our experimental environment consists of 8 DECstation-5000/240's running Ultrix V4.3. Each machine has a Fore ATM interface connected to a Fore ATM switch. The connection between the interface boards and the switch operates at 100-Mbps; the switch has an aggregate throughput of 1.2 Gbps.
Reference: [10] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Munin allowed a number of protocols to be used, but the primary protocol was an eager update implementation of release consistency. Later work [6] has shown that the performance of EI and eager update are comparable. Lazy release consistency was introduced in the TreadMarks system <ref> [10] </ref>. The default protocol in TreadMarks is LI, although Dwarkadas et al. [6] present simulation results for LH.
Reference: [11] <author> L. Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multipro cess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):690-691, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: Early DSM systems suffered from performance problems because they required large amounts of communication. These early designs implemented the shared memory abstraction by imitating consistency protocols used by bus-based hardware shared memory multiprocessors. The low latencies on these bus-based machines allowed them to implement sequential consistency (SC) <ref> [11] </ref>, but with the much higher latencies present on networks sequential consistency causes serious inefficiencies. Furthermore, given the large consistency units in DSM (virtual memory pages), false sharing was a serious problem for many applications. <p> We discuss related work in Section 6, and conclude in Section 7. 2 Release Consistency Protocols Release consistency requires less communication than the canonical memory model, sequential consistency <ref> [11] </ref>, but provides a very similar programming interface. An eager implementation [5] of release consistency enforces consistency when a synchronization variable is released. In contrast, lazy implementations of release consistency enforce consistency when synchronization variables are acquired. Strictly speaking, lazy protocols implement a slight weaker memory model than EI.
Reference: [12] <author> G.M. Lathrop, J.M. Lalouel, C. Julier, and J. Ott. </author> <title> Strategies for multilocus linkage analysis in humans. </title> <booktitle> Proceedings of National Academy of Science, </booktitle> <volume> 81 </volume> <pages> 3443-3446, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: ILINK searches for a maximum likelihood estimate of the multi-locus vector of recombination probabilities of several genes <ref> [12] </ref>.
Reference: [13] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Software distributed shared memory (DSM) <ref> [13] </ref> enables processes on different machines to share memory, even though the machines physically do not share memory.
Reference: [14] <editor> E. L. Lusk and R. A. Overbeek et al. </editor> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart and Winston, Inc, </publisher> <year> 1987. </year>
Reference-contexts: TreadMarks programs follow a conventional shared memory style, using threads to express parallelism and locks and barriers to synchronize. TreadMarks is entirely implemented as a C library, using an interface similar to the parmacs macros from Argonne National Laboratory <ref> [14] </ref> for thread and synchronization support. To provide for a fair comparison, the three protocols share as much code as possible. In particular, the same primitives are used for communication (sockets and SIGIO signals) and for memory management (mprotect and SIGSEGV signals).

References-found: 14

