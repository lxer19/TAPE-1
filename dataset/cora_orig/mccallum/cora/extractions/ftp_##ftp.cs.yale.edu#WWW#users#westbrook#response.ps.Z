URL: ftp://ftp.cs.yale.edu/WWW/users/westbrook/response.ps.Z
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/westbrook-jeffery.html
Root-URL: http://www.cs.yale.edu
Title: Load Balancing for Response Time  
Author: Jeffery Westbrook 
Date: July 11, 1995  
Abstract: A centralized scheduler must assign tasks to servers, processing on-line a sequence of task arrivals and departures. Each task runs for an unknown length of time, but comes with a weight that measures resource utilization per unit time. The response time of a server is the sum of the weights of the tasks assigned to it. The goal is to minimize the maximum response time, i.e., load, of any server. Previous papers on on-line load balancing have generally concentrated only on keeping the current maximum load bounded by some function of the maximum off-line load ever seen. Our goal is to keep the current maximum load on an on-line server bounded by a function of the current off-line load. Thus the loads are not permanently skewed by transient peaks, and the algorithm takes advantage of reductions in total weight. To achieve this, the scheduler must occasionally reassign tasks, in an attempt to decrease the maximum load. We study several variants of load balancing, including identical machines, related machines, restricted assignment tasks, and virtual circuit routing. In each case, only a limited amount of reassignment is used but the load is kept substantially lower than possible without reassignment.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Aspnes, Y. Azar, A. Fiat, S. Plotkin, and O. Waarts. </author> <title> On-line load balancing with applications to machine scheduling and virtual circuit routing. </title> <booktitle> In Proc. 25th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 623-631, </pages> <year> 1993. </year>
Reference-contexts: That is, the maximum load on an on-line server is no more than c times the maximum load in an optimal assignment of the currently active tasks. Almost all previous papers on competitive on-line load balancing have dealt only with peak load. In <ref> [1, 3, 5] </ref>, tasks never depart, in which case current and peak load are equivalent. In [2, 4], tasks may depart but the algorithms are competitive against peak load only. In this paper, we examine the design of algorithms that are competitive against current load. <p> Let W j (t) denote the sum of the weights of tasks assigned to server v j at time t. The load on server j at time t is given by W j (t)=cap j . An algorithm for the special case that tasks never depart is given in <ref> [1] </ref>. 3.1 Witness-based partitions. The paradigm used here and in the remaining sections of this paper is as follows. Assume the existence of a load-balancing algorithm, A, parameterized by , with the following properties. <p> If the total weight of all tasks ever accepted is W , then ONE-LEVEL reassigns a total weight of W (1 + 1=(fi 1)). This scheme is an adaptation of the algorithm of <ref> [1] </ref>. Recall W j (t) is the total weight assigned to processor v j at time t. We also define a quantity M j (t), which will roughly be the maximum weight ever on processor v j since it was last rebalanced.
Reference: [2] <author> B. Awerbuch, Y. Azar, S. Plotkin, and O. Waarts. </author> <title> Competitive routing of virtual circuits with unknown duration. </title> <booktitle> In Proc. ACM/SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 321-330, </pages> <year> 1994. </year>
Reference-contexts: Almost all previous papers on competitive on-line load balancing have dealt only with peak load. In [1, 3, 5], tasks never depart, in which case current and peak load are equivalent. In <ref> [2, 4] </ref>, tasks may depart but the algorithms are competitive against peak load only. In this paper, we examine the design of algorithms that are competitive against current load. The distinction between peak load and current load is quite significant. <p> Corollary 11 follows from setting q = (log n) 1c , and Corollary 12 from setting q = log n. This improves on the results of <ref> [2] </ref> in two ways: it works for all values of the optimum load and it is competitive against current rather than peak load. 12 5 Virtual Circuit Routing In the virtual circuit routing problem one is given a communication network modeled by an undi-rected graph. <p> The load on an edge is W e =cap e . Recall we assume that the restart cost, r u = c w u . This restriction can be eased using the method of Section 6. Azar et al. <ref> [2] </ref> give a one-level algorithm, parameterized by , that is O (log n) competitive and reassigns each task O (log n) times. We use this in a witness-based algorithm that is competitive against current load.
Reference: [3] <author> Y. Azar, B. Kalyanasundaram, S. Plotkin, K. Pruhs, and O. Waarts. </author> <title> Online load balancing of temporary tasks. </title> <booktitle> In Proc. 1993 Workshop on Algorithms and Data Structures (WADS 93), Lecture Notes in Computer Science 709. </booktitle> <publisher> Springer-Verlag, </publisher> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: That is, the maximum load on an on-line server is no more than c times the maximum load in an optimal assignment of the currently active tasks. Almost all previous papers on competitive on-line load balancing have dealt only with peak load. In <ref> [1, 3, 5] </ref>, tasks never depart, in which case current and peak load are equivalent. In [2, 4], tasks may depart but the algorithms are competitive against peak load only. In this paper, we examine the design of algorithms that are competitive against current load. <p> Previously, Azar et al. gave an algorithm for related machines that is 20-competitive against peak load <ref> [3] </ref>, but not competitive against current load. Their algorithm never reassigns a task. <p> Azar et al.[4] showed that when tasks both arrive and depart, no non-preemptive algorithm can be better than O ( n) competitive against peak load. An non-preemptive algorithm that is O ( p n) competitive against peak load is given in <ref> [3] </ref>. 9 In this section we give an eager algorithm for the case of unit weights. It is eager because tasks may be reassigned after both arrival and departure of other tasks. The previous lazy algorithms reassigned tasks only in response to other tasks being deleted from the system.
Reference: [4] <author> Y. Azar, A. Karlin, and A. Broder. </author> <title> On-line load balancing. </title> <booktitle> In Proc. 33nd Symp. of Foundations of Computer Science, </booktitle> <pages> pages 218-225, </pages> <year> 1992. </year>
Reference-contexts: Almost all previous papers on competitive on-line load balancing have dealt only with peak load. In [1, 3, 5], tasks never depart, in which case current and peak load are equivalent. In <ref> [2, 4] </ref>, tasks may depart but the algorithms are competitive against peak load only. In this paper, we examine the design of algorithms that are competitive against current load. The distinction between peak load and current load is quite significant. <p> In the identical machines problem, an adversary may generate n 2 unit cost tasks, after which some server v must have load at least n. The adversary then deletes all tasks except for those on v. On the other hand, as noted in <ref> [4] </ref>, Graham's [7] list processing heuristic for identical machines, which simply assigns each new task to the least loaded server, and never reassigns a task, is 2-competitive against peak load. To measure the cost of reassignment, we assume that each task u has an associated restart cost r u .
Reference: [5] <author> Y. Azar, J. Naor, and R. </author> <title> Rom. The competitiveness of on-line assignments. </title> <booktitle> In Proc. 3rd ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 203-210, </pages> <year> 1992. </year>
Reference-contexts: That is, the maximum load on an on-line server is no more than c times the maximum load in an optimal assignment of the currently active tasks. Almost all previous papers on competitive on-line load balancing have dealt only with peak load. In <ref> [1, 3, 5] </ref>, tasks never depart, in which case current and peak load are equivalent. In [2, 4], tasks may depart but the algorithms are competitive against peak load only. In this paper, we examine the design of algorithms that are competitive against current load. <p> It must be assigned to one server in that subset. If no tasks ever depart and tasks cannot be preempted, the best possible competitive ratio for both randomized and deterministic algorithms is (log n); this ratio is achievable with a simple greedy strategy <ref> [5] </ref>. Azar et al.[4] showed that when tasks both arrive and depart, no non-preemptive algorithm can be better than O ( n) competitive against peak load.
Reference: [6] <author> Y. Bartal, A. Fiat, H. Karloff, and R. Vohra. </author> <title> New algorithms for an ancient scheduling problem. </title> <booktitle> In Proc. 24nd ACM Symp. on Theory of Computing, </booktitle> <year> 1992. </year> <month> 15 </month>
Reference-contexts: There are several previous algorithms that are competitive against peak load with a ratio 2 * for a small constant * <ref> [6, 7, 8] </ref>. None of these reassign tasks, and none are better than n-competitive against current load. First, consider a particularly simple case: w u = ! for all u 2 U , ! a constant. It is easy to show that fl t = !djU (t)j=ne.
Reference: [7] <author> R. L. Graham. </author> <title> Bounds for certain multiprocessing anomalies. </title> <journal> Bell System Technical Journal, </journal> <volume> 45 </volume> <pages> 1563-1581, </pages> <year> 1966. </year>
Reference-contexts: In the identical machines problem, an adversary may generate n 2 unit cost tasks, after which some server v must have load at least n. The adversary then deletes all tasks except for those on v. On the other hand, as noted in [4], Graham's <ref> [7] </ref> list processing heuristic for identical machines, which simply assigns each new task to the least loaded server, and never reassigns a task, is 2-competitive against peak load. To measure the cost of reassignment, we assume that each task u has an associated restart cost r u . <p> There are several previous algorithms that are competitive against peak load with a ratio 2 * for a small constant * <ref> [6, 7, 8] </ref>. None of these reassign tasks, and none are better than n-competitive against current load. First, consider a particularly simple case: w u = ! for all u 2 U , ! a constant. It is easy to show that fl t = !djU (t)j=ne.
Reference: [8] <author> D. R. Karger, S. J. Phillips, and E. Torng. </author> <title> A better algorithm for an ancient scheduling problem. </title> <booktitle> In Proc. 1994 ACM/SIAM Symp. on Discrete Algorithms, </booktitle> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: There are several previous algorithms that are competitive against peak load with a ratio 2 * for a small constant * <ref> [6, 7, 8] </ref>. None of these reassign tasks, and none are better than n-competitive against current load. First, consider a particularly simple case: w u = ! for all u 2 U , ! a constant. It is easy to show that fl t = !djU (t)j=ne.
Reference: [9] <author> E. L. Lawler, J. K. Lenstra, A. H. Rinnooy Kan, and D. B. Shmoys. </author> <title> Sequencing and scheduling: Algorithms and complexity. </title> <editor> In S. C. Graves, A. Rinnooy Kan, and P. Zipkin, editors, </editor> <booktitle> Handbook of Operations Research and Management Science, Volume IV: Production Planning and Inventory, </booktitle> <pages> pages 445-522. </pages> <publisher> North-Holland, </publisher> <year> 1993. </year>
Reference-contexts: By constantly reassigning tasks, the algorithm can achieve the optimal maximum load, but all the server time will be taken up by restarts. Our results explore the tradeoff between restart cost and load balance. We consider the following specific load balancing problems. The survey paper by Lawler et al. <ref> [9] </ref> lists many others. * Identical Machines: Each task u has an associated weight w u and can be served by any one of the servers. All servers run at the same speed.
Reference: [10] <author> S. Phillips and J. Westbrook. </author> <title> On-line load balancing and network flow. </title> <booktitle> In Proc. 1993 Symp. on Theory of Computing, </booktitle> <pages> pages 402-411, </pages> <month> Apr. </month> <year> 1993. </year> <month> 16 </month>
Reference-contexts: The behavior of load-balancing algorithms that are competitive against current load cannot be skewed by an initial peak. The current load measure is also used in the application of load balancing to network flow described in <ref> [10] </ref>. Naturally, an algorithm that is c-competitive against current load is c-competitive against peak load. The video transmission example suggests that to be competitive against current load, the on-line scheduler must sometimes reassign tasks to different servers. This should not be done too often, 2 however. <p> In Section 4 we study the restricted assignment problem, and give a rebalancing scheme that is parameterizable to trade off competitive ratio against restart cost; its best competitive ratio is O (1) at a restart cost of O (S log n). Previously, Phillips and Westbrook <ref> [10] </ref> give a preemptive algorithm that is O ((log n)=)-competitive against current load while incurring restart cost S, where 0 &lt; 1 is a user-specified parameter. Their algorithm works for arbitrary weights. <p> All results follow by applying the lemma to algorithms presented herein, with the exception of the algorithm for general weights in the restricted subset case, which follows by applying the lemma to the algorithm in <ref> [10] </ref> While the bounds of this section are not ideal, in that they depend on the value of a ratio between input costs, they are independent of the number of tasks.
References-found: 10

