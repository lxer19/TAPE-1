URL: http://agents.www.media.mit.edu/groups/agents/Publications/Pattie/consci/consci.ps
Refering-URL: http://agents.www.media.mit.edu/groups/agents/publications/
Root-URL: 
Phone: tel: (617) 253 29 64  
Title: HOW TO DO THE RIGHT THING Send reprints to: Running head: "How To Do the
Author: Pattie Maes Pattie Maes Pleinlaan 
Address: 43 836 545 Technology Square Cambridge, MA 02139  2, B-1050 Brussels, Belgium 545 Technology Square, Cambridge, MA 02139, USA  
Affiliation: AI-Laboratory, Vrije Universiteit Brussel and AI-Laboratory, Massachusetts Institute of Technology  NE  
Abstract-found: 0
Intro-found: 1
Reference: <author> Agre, P. & Chapman, D. </author> <year> (1987) </year> <month> Pengi: </month> <title> An Implementation of aTheory of Activity. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, AAAI-87. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California. </address> <note> 49 Bond, </note> <editor> A. & Gasser, L. </editor> <booktitle> (1988) Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: A second implication is that all modules/operators of the domain have to be instantiated beforehand, which means that a node has to be created for every parameter. We try to avoid the need for variables altogether, by thinking about problems in an `Agre/Chapman' like way <ref> (Agre & Chapman, 1987) </ref>, i.e., using only so-called indexical-functional aspects to describe relevant properties of the immediate environment. The main idea here is that internal representations of objects in the environment are in terms of the purposes and circumstances of the agent. <p> The remainder of this section compares this work to so-called `reactive systems', to distributed AI and to other hybrid systems. 7.1 Reactive Systems The approach is related to the so-called `reactive systems' (Georgeff & Lansky, 1987) (Firby, 1987) (Kaelbling, 1987) (Rosenschein & Kaelbling, 1987) (Schoppers, 1987) <ref> (Agre & Chapman, 1987) </ref> (Sanborn & Hendler, 1987). The emphasis in these architectures is on a more direct coupling of perception to action, distributedness and decentralization, dynamic interaction with the environment and inherent mechanisms to cope with resource limitations and incomplete knowledge.
Reference: <author> Brooks, R. </author> <title> (1986) A Robust Layered Control System for a Mobile Robot. </title> <journal> IEEE Journal of Robotics and Automation. </journal> <volume> Volume RA-2, Number 1. </volume>
Reference-contexts: The paper studies this problem in the context of the Society of the Mind theory (Minsky, 1986) to which the Subsumption Architecture <ref> (Brooks, 1986) </ref> is also related. This theory suggests the building of an intelligent system as a society of interacting, mindless agents, each having their own specific competence. <p> Several solutions can be adopted. One approach is to hand-code (and by that hard-wire) the control flow among the competence modules <ref> (Brooks, 1986) </ref>. Another approach is to introduce a hierarchical structure to tell competence modules whether they are allowed to perform an action or not. This paper investigates yet another, entirely different type of solution. <p> Furthermore, modules do not have to share a global internal model or global blackboard. They are said to communicate `through the world' <ref> (Brooks, 1986) </ref>. 7.3 Hybrid Systems Finally, this algorithm is related to some of the hybrid systems that have been built for planning and decision making. Hendler (1988) describes a hybrid system in which 48 a massive parallel component is used to provide heuristic information to a classical AI planner.
Reference: <author> Chandrasekaran, B., Goel, A. & Allemang, D. </author> <title> (1988) Connectionism and Information Processing Abstractions, </title> <journal> AI-magazine, </journal> <volume> Vol. 9, No. </volume> <pages> 4. </pages>
Reference: <author> Charniak, E. & Mc Dermott, D. </author> <title> (1985) Introduction to Artificial Intelligence. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Later in the paper more interesting examples are discussed. The example is taken from the planning chapter of <ref> (Charniak & Mc Dermott, 1985) </ref>. It involves a robot with two hands which has to spray-paint itself and sand a board. The task has some complexity to it.
Reference: <author> Firby, R. </author> <title> (1987) An Investigation into Reactive Planning in Complex Domains. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, AAAI-87. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California. </address>
Reference-contexts: The remainder of this section compares this work to so-called `reactive systems', to distributed AI and to other hybrid systems. 7.1 Reactive Systems The approach is related to the so-called `reactive systems' (Georgeff & Lansky, 1987) <ref> (Firby, 1987) </ref> (Kaelbling, 1987) (Rosenschein & Kaelbling, 1987) (Schoppers, 1987) (Agre & Chapman, 1987) (Sanborn & Hendler, 1987).
Reference: <author> Georgeff, M. & Lansky, A. </author> <title> (1987) Reactive Reasoning and Planning. </title> <booktitle> Proceedings of the Sixth National Conference on Artificial Intelligence, AAAI-87. </booktitle> <publisher> Morgan Kauf-mann, </publisher> <address> Los Altos, California. </address>
Reference-contexts: The remainder of this section compares this work to so-called `reactive systems', to distributed AI and to other hybrid systems. 7.1 Reactive Systems The approach is related to the so-called `reactive systems' <ref> (Georgeff & Lansky, 1987) </ref> (Firby, 1987) (Kaelbling, 1987) (Rosenschein & Kaelbling, 1987) (Schoppers, 1987) (Agre & Chapman, 1987) (Sanborn & Hendler, 1987).
Reference: <author> Hayes-Roth, B. et. al. </author> <title> (1979) Modelling Planning as an Incremental Opportunistic Process. </title> <booktitle> Proceedings of IJCAI-79, </booktitle> <address> Tokyo, Japan. </address>
Reference: <author> Hendler, J. </author> <title> (1988) Integrating Marker-Passing and Problem Solving, A Spreading Activation Approach to Improved Choice in Planning. </title> <publisher> Lawrence Erlbaum Ass., </publisher> <address> Hills-dale, New Jersey. </address>
Reference: <author> Huberman, B. & Hogg, T. </author> <title> (1987) Phase Transitions in Aartificial Intelligence Systems. </title> <journal> AI-Journal, </journal> <volume> Volume 23, Number 2. </volume>
Reference-contexts: Nevertheless. impor tant qualitative results can be obtained, for example on possible phase transitions with the growth of parameters, such as the size of the network, the mean fanout of a node, etc <ref> (Huberman & Hogg, 1987) </ref>. We have evaluated the algorithm empirically by performing a wide series of experiments using several example applications.
Reference: <editor> Huhns, M. </editor> <booktitle> (1987) Distributed Artificial Intelligence. </booktitle> <publisher> Pitman, London. </publisher>
Reference-contexts: It therefore constitutes a simpler, more distributed and more general solution to the problem of action selection. 7.2 Distributed AI The difference between this work and the bulk of work in distributed planning (Bond & Gasser, 1988) <ref> (Huhns, 1987) </ref> as well as with the work on black-board systems (Hayes-Roth, 1979), is that in the latter planning modules communicate among themselves on a much higher level. They communicate using a language, sometimes debate and negotiate among one another or even reason about each other.
Reference: <author> Kaelbling, L. </author> <title> (1987) An Architecture for Intelligent Reactive Systems. Reasoning about Actions and Plans: </title> <booktitle> Proceedings of the 1986 Workshop. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California. </address>
Reference-contexts: The remainder of this section compares this work to so-called `reactive systems', to distributed AI and to other hybrid systems. 7.1 Reactive Systems The approach is related to the so-called `reactive systems' (Georgeff & Lansky, 1987) (Firby, 1987) <ref> (Kaelbling, 1987) </ref> (Rosenschein & Kaelbling, 1987) (Schoppers, 1987) (Agre & Chapman, 1987) (Sanborn & Hendler, 1987). The emphasis in these architectures is on a more direct coupling of perception to action, distributedness and decentralization, dynamic interaction with the environment and inherent mechanisms to cope with resource limitations and incomplete knowledge. <p> The remainder of this section compares this work to so-called `reactive systems', to distributed AI and to other hybrid systems. 7.1 Reactive Systems The approach is related to the so-called `reactive systems' (Georgeff & Lansky, 1987) (Firby, 1987) (Kaelbling, 1987) <ref> (Rosenschein & Kaelbling, 1987) </ref> (Schoppers, 1987) (Agre & Chapman, 1987) (Sanborn & Hendler, 1987). The emphasis in these architectures is on a more direct coupling of perception to action, distributedness and decentralization, dynamic interaction with the environment and inherent mechanisms to cope with resource limitations and incomplete knowledge.
Reference: <author> Laird, J., Rosenbloom, P. & Newell, A. </author> <title> (1986) Chunking in SOAR: The Anatomy of a General Learning Mechanism. </title> <journal> Machine Learning. </journal> <volume> Volume 1, Number 1. </volume> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Lehnert, W. </author> <title> (1987) Case-Based Problem Solving with a Large Knowledge-Base of Lear 50 ned Cases. </title> <booktitle> Proceedings of the AAAI-87 Conference, </booktitle> <address> Seattle, Washington. </address>
Reference-contexts: Hendler (1988) describes a hybrid system in which 48 a massive parallel component is used to provide heuristic information to a classical AI planner. A marker propagating network guides the classical planner towards more relevant plans. <ref> (Lehnert, 1987) </ref> describes a hybrid system that uses a stack and copy mechanism for control and numerical relaxation over a structured network for smooth decision making.
Reference: <author> Maes, P. </author> <title> (1989) The Dynamics of Action Selection. </title> <booktitle> Proceedings of the IJCAI-89 conference, </booktitle> <address> Detroit. </address>
Reference-contexts: The research questions that we study are how adequate these hypotheses are and which activation/inhibition dynamics is appropriate. To this end we are developing a series of algorithms and testing them in computer simulations. One such algorithm was discussed in <ref> (Maes, 1989) </ref>. This paper describes a variation on the algorithm which is simpler and produces more interesting results 1 . Experiments have been performed for several applications. The resulting systems do exhibit the desired properties of goal-orientedness, situation-orientedness, adaptivity, robustness, looking ahead, etc.
Reference: <author> Minsky, M. </author> <booktitle> (1986) The Society of the Mind. </booktitle> <publisher> Simon and Schuster, </publisher> <address> New York, New York. </address>
Reference-contexts: The paper studies this problem in the context of the Society of the Mind theory <ref> (Minsky, 1986) </ref> to which the Subsumption Architecture (Brooks, 1986) is also related. This theory suggests the building of an intelligent system as a society of interacting, mindless agents, each having their own specific competence.
Reference: <author> Rosenschein, S. & Kaelbling, L. </author> <title> (1987) The Synthesis of Digital Machines with Provable Epistemic Properties. </title> <editor> In J.F. Halpern (editor), </editor> <booktitle> Proceedings of the 1986 Conference on Theoretical Aspects of Reasoning about Knowledge. </booktitle> <publisher> Morgan-Kaufmann, </publisher> <address> Los Altos, California. </address>
Reference-contexts: The remainder of this section compares this work to so-called `reactive systems', to distributed AI and to other hybrid systems. 7.1 Reactive Systems The approach is related to the so-called `reactive systems' (Georgeff & Lansky, 1987) (Firby, 1987) (Kaelbling, 1987) <ref> (Rosenschein & Kaelbling, 1987) </ref> (Schoppers, 1987) (Agre & Chapman, 1987) (Sanborn & Hendler, 1987). The emphasis in these architectures is on a more direct coupling of perception to action, distributedness and decentralization, dynamic interaction with the environment and inherent mechanisms to cope with resource limitations and incomplete knowledge.
Reference: <author> Sanborn, J. and Hendler, J. </author> <title> (1988) A Model of Reaction for Planning in Dynamic Environments. </title> <journal> International Journal of AI in Engineering, </journal> <note> 1988. Special Issue on Planning. </note>
Reference: <author> Schoppers, M. </author> <title> (1987) Universal Plans for Reactive Robots in Unpredictable Environments. </title> <booktitle> Proceedings of IJCAI-87, </booktitle> <address> Milan, Italy. </address>
Reference-contexts: The remainder of this section compares this work to so-called `reactive systems', to distributed AI and to other hybrid systems. 7.1 Reactive Systems The approach is related to the so-called `reactive systems' (Georgeff & Lansky, 1987) (Firby, 1987) (Kaelbling, 1987) (Rosenschein & Kaelbling, 1987) <ref> (Schoppers, 1987) </ref> (Agre & Chapman, 1987) (Sanborn & Hendler, 1987). The emphasis in these architectures is on a more direct coupling of perception to action, distributedness and decentralization, dynamic interaction with the environment and inherent mechanisms to cope with resource limitations and incomplete knowledge.
Reference: <author> Simon, H. </author> <title> (1955) A Behavioral Model of Rational Choice. </title> <journal> Quarterly Journal of Economics, </journal> <volume> 69: </volume> <pages> 99-118. </pages>
Reference-contexts: This implies that the action selection cannot be completely `rational' or optimal. It should, however, be robust, fast, and make `good enough' decisions <ref> (Simon, 1955) </ref>.
Reference: <author> Steels, L. </author> <title> (1989) Connectionist Problem Solving, an AI Perspective. Connectionism in Perspective, </title> <editor> Eds: Pfeiffer R., Schreter Z., Fogelman F. and Steels L., </editor> <publisher> Elsevier, Ams-terdam. </publisher>
Reference: <author> Sussman, G. </author> <title> (1975) A Computer Model of Skill Acquisition. </title> <publisher> Elsevier Publishers. </publisher> <address> New York. </address> <month> 51 </month>
Reference-contexts: Every module decreases the activation level of modules that undo its true conditions. Again this results in an action selection behavior in which `subgoals' are protected and thereby goal conflicts are avoided. To illustrate how this happens, we reimplemented the classical anomalous situation example of the blocks world <ref> (Sussman, 1975) </ref>. Figure 11 illustrates the problem. Figure 12 shows some of the competence modules involved in this example. value as fl which is far greater than .
References-found: 21

