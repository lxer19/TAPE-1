URL: http://www.research.att.com/~lewis/papers/lewis98b.ps
Refering-URL: http://www.research.att.com/~lewis/chronobib.html
Root-URL: 
Email: lewis@research.att.com  
Title: Naive (Bayes) at Forty: The Independence Assumption in Information Retrieval  
Author: David D. Lewis 
Web: http://www.research.att.com/~lewis  
Address: 180 Park Avenue Florham Park, NJ 07932-0971 USA  
Affiliation: AT&T Labs Research  
Abstract: The naive Bayes classifier, currently experiencing a renaissance in machine learning, has long been a core technique in information retrieval. We review some of the variations of naive Bayes models used for text retrieval and classification, focusing on the distributional assump tions made about word occurrences in documents.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Abraham Bookstein and Don Kraft. </author> <title> Operations research applied to document indexing and retrieval decisions. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 24(3) </volume> <pages> 418-427, </pages> <year> 1977. </year>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons <ref> [1, 2, 22, 23, 36] </ref>, and the negative binomial (an infinite mixture of Poissons) [40]. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies.
Reference: 2. <author> Abraham Bookstein and Don R. Swanson. </author> <title> A decision theoretic foundation for indexing. </title> <journal> Journal of the American Society for Information Science, </journal> <pages> pages 45-50, </pages> <month> January-February </month> <year> 1975. </year>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons <ref> [1, 2, 22, 23, 36] </ref>, and the negative binomial (an infinite mixture of Poissons) [40]. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies.
Reference: 3. <author> Soumen Chakrabarti, Byron Dom, Rakesh Agrawal, and Prabhakar Raghavan. </author> <title> Using taxonomy, discriminants, and signatures for navigating in text databases. </title> <editor> In Matthias Jarke, Michael Carey, Klaus R. Dittrich, Fred Lochovsky, Pericles Loucopoulos, and Manfred A. Jeusfeld, editors, </editor> <booktitle> Proceedings of the 23rd VLDB Conference, </booktitle> <pages> pages 446-455, </pages> <year> 1997. </year>
Reference-contexts: The problem is somewhat less extreme for classification tasks, where we can in some cases arrange to compare posterior log odds of classes for each document individually, without comparisons across documents. Indeed, we know of many applications of multinomial models to text categorization <ref> [3, 14, 15, 25, 32, 34] </ref> but none to text retrieval. 5.3 Non-Distributional Approaches A variety of ad hoc approaches have been developed that more or less gracefully integrate term frequency and document length information into the BIM itself.
Reference: 4. <author> Kenneth Ward Church. </author> <title> One term or two? In Edward A. </title> <editor> Fox, Peter Ingwersen, and Raya Fidel, editors, </editor> <booktitle> SIGIR '95: Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 310-318, </pages> <address> New York, </address> <year> 1995. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures <ref> [4, 26] </ref>: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an infinite mixture of Poissons) [40]. <p> A multinomial model has the advantage that document length is accounted for very naturally in the model. The corresponding disadvantage is that it assumes independence not just between different words, but between multiple occurrences of the same word, an assumption which is strikingly violated for real data <ref> [4] </ref>. A multinomial therefore assigns extreme posterior log odds to long documents, and would presumedly be very poor for the purpose of ranking documents in a search engine. <p> Further, the nature of this impact is more complex than might be guessed, even for very simple techniques <ref> [4] </ref>. In any case, the effectiveness improvements yielded by these strategies have been small (with the possible selection of feature selection).
Reference: 5. <author> William W. Cohen and Yoram Singer. </author> <title> Context-sensitive learning methods for text categorization. </title> <booktitle> In SIGIR '96: Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 307-315, </pages> <year> 1996. </year>
Reference-contexts: In the yearly TREC evaluations [16-19, 52], numerous variations of naive Bayes models have been used, producing some of the best results. Recent comparisons of learning methods for text categorization have been somewhat less favorable to naive Bayes models <ref> [5, 25] </ref> while still showing them to achieve respectable effectiveness.
Reference: 6. <author> W. S. Cooper. </author> <title> Some inconsistencies and misidentified modeling assumptions in probabilistic information retrieval. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 13(1) </volume> <pages> 100-111, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Further, the nature of this impact is more complex than might be guessed, even for very simple techniques [4]. In any case, the effectiveness improvements yielded by these strategies have been small (with the possible selection of feature selection). IR's representative of the third strategy is Cooper <ref> [6] </ref>, who points out that in the case of a two-class naive Bayes model, the usual independence assumptions (Equation 4) can be replaced by a weaker "linked dependence" assumption: P (xjc 1 ) = j=1 P (x j jc 2 ) In machine learning, considerable theoretical and experimental evidence has been
Reference: 7. <author> W. B. Croft. </author> <title> Experiments with representation in a document retrieval system. </title> <journal> Information Technology: Research and Development, </journal> <volume> 2 </volume> <pages> 1-21, </pages> <year> 1983. </year>
Reference-contexts: The widely used probabilistic indexing approach assumes there is an ideal binary indexing of the document, for which the observed index term occurrences provide evidence <ref> [7, 13] </ref>. Retrieval or classification is based on computing (or approximating) the expected value of the posterior log odds. The expectation is taken with respect to the probabilities of various ideal indexings.
Reference: 8. <author> W. Bruce Croft. </author> <title> Boolean queries and term dependencies in probabilistic retrieval models. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 37(2) </volume> <pages> 71-77, </pages> <year> 1986. </year>
Reference-contexts: Whatever its successes in machine learning, the first strategy has not met with great success in IR. While interesting research on dependence models has been done <ref> [8, 11, 21, 49, 50] </ref>, these models are rarely used in practice. Even most work in the "inference net" approach to information retrieval has mostly used independence (or ad hoc) models. Results from the second strategy are hard to judge.
Reference: 9. <author> Pedro Domingos and Michael Pazzani. </author> <title> On the optimality of the simple bayesian classifier under zero-one loss. </title> <journal> Machine Learning, </journal> 29(2/3):103-130, November 1997. 
Reference-contexts: assumption: P (xjc 1 ) = j=1 P (x j jc 2 ) In machine learning, considerable theoretical and experimental evidence has been developed that a training procedure based on the naive Bayes assumptions can yield an optimal classifier in a variety of situations where the assumptions are wildly violated <ref> [9] </ref>. 7 Conclusion Naive Bayes models have been remarkably successful in information retrieval. In the yearly TREC evaluations [16-19, 52], numerous variations of naive Bayes models have been used, producing some of the best results.
Reference: 10. <author> Richard O. Duda and Peter E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: We end with a few thoughts on interesting research directions for naive Bayes at the intersection of machine learning and information retrieval. 2 The Naive Bayes Classifier A widely used framework for classification is provided by a simple theorem of probability <ref> [10, Sec 2.1] </ref> known as Bayes' rule, Bayes' theorem, or Bayes' formula: P (C = c k jX = x) = P (C = c k ) fi P (x) where P (X = x) = k 0 =1 We assume here that all possible events (in our case, documents) fall <p> omitting those random variables and instead writing Bayes' rule as: P (c k jx) = P (c k ) fi P (x) When we know the P (c k jx) exactly for a classification problem, classification can be done in an optimal way for a wide variety of effectiveness measures <ref> [10, 31] </ref>. For instance, the expected number of classification errors can be minimized by assigning a document with feature vector x to the class c k for which P (c k jx) is highest. <p> In the two class case, we have P (c 2 jx) = 1 P (c 1 jx), so that with some arithmetic manipulations we can replace the two functions that Equation 10 would give for the two-class case with a single function <ref> [10, Sec. 2.10] </ref>: 2 See [39, Sec. 12.4.3] or [10, Sec. 2.10], though in their derivations P (x) has already been dropped. log 1 P (c 1 jx) d X x j log (1 p j1 )p j2 d X log 1 p j2 P (c 1 ) : (11) Equation <p> the two class case, we have P (c 2 jx) = 1 P (c 1 jx), so that with some arithmetic manipulations we can replace the two functions that Equation 10 would give for the two-class case with a single function <ref> [10, Sec. 2.10] </ref>: 2 See [39, Sec. 12.4.3] or [10, Sec. 2.10], though in their derivations P (x) has already been dropped. log 1 P (c 1 jx) d X x j log (1 p j1 )p j2 d X log 1 p j2 P (c 1 ) : (11) Equation 11 has several properties that make it particularly convenient.
Reference: 11. <author> B. Del Favero and R. Fung. </author> <title> Bayesian inference with node aggregation for information retrieval. </title> <editor> In D. K. Harman, editor, </editor> <booktitle> The Second Text Retrieval Conference (TREC-2), </booktitle> <pages> pages 151-162, </pages> <address> Gaithersburg, MD, </address> <month> March </month> <year> 1994. </year> <institution> U. S. Dept. of Commerce, National Institute of Standards and Technology. </institution> <note> NIST Special Publication 500-215. </note>
Reference-contexts: Whatever its successes in machine learning, the first strategy has not met with great success in IR. While interesting research on dependence models has been done <ref> [8, 11, 21, 49, 50] </ref>, these models are rarely used in practice. Even most work in the "inference net" approach to information retrieval has mostly used independence (or ad hoc) models. Results from the second strategy are hard to judge.
Reference: 12. <author> William B. Frakes and Ricardo Baeza-Yates, </author> <title> editors. Information Retrieval: Data Structures and Algorithms. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference: 13. <author> Norbert Fuhr. </author> <title> Models for retrieval with probabilistic indexing. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 25(1) </volume> <pages> 55-72, </pages> <year> 1989. </year>
Reference-contexts: The widely used probabilistic indexing approach assumes there is an ideal binary indexing of the document, for which the observed index term occurrences provide evidence <ref> [7, 13] </ref>. Retrieval or classification is based on computing (or approximating) the expected value of the posterior log odds. The expectation is taken with respect to the probabilities of various ideal indexings.
Reference: 14. <author> William A. Gale, Kenneth W. Church, and David Yarowsky. </author> <title> A method for disambiguating word senses in a large corpus. </title> <journal> Computers and the Humanities, </journal> <volume> 26 </volume> <pages> 415-439, </pages> <year> 1993. </year>
Reference-contexts: The problem is somewhat less extreme for classification tasks, where we can in some cases arrange to compare posterior log odds of classes for each document individually, without comparisons across documents. Indeed, we know of many applications of multinomial models to text categorization <ref> [3, 14, 15, 25, 32, 34] </ref> but none to text retrieval. 5.3 Non-Distributional Approaches A variety of ad hoc approaches have been developed that more or less gracefully integrate term frequency and document length information into the BIM itself.
Reference: 15. <author> Louise Guthrie, Elbert Walker, and Joe Guthrie. </author> <title> Document classification by machine: Theory and practice. </title> <booktitle> In COLING 94: The 15th International Conference on Computational Linguistics. Proceedings, </booktitle> <volume> Vol. II., </volume> <pages> pages 1059-1063, </pages> <year> 1994. </year>
Reference-contexts: a naive Bayes model. 5.2 Multinomial Models An alternative approach to modeling term frequencies is to treat the bag of words for a length f document as resulting from f draws on a d-valued multinomial variable X, rather than as a single draw on a vector-valued variable of length d <ref> [15] </ref>. The naive Bayes assumption then is that the draws on X are independent| each word of the document is generated independently from every other. A multinomial model has the advantage that document length is accounted for very naturally in the model. <p> The problem is somewhat less extreme for classification tasks, where we can in some cases arrange to compare posterior log odds of classes for each document individually, without comparisons across documents. Indeed, we know of many applications of multinomial models to text categorization <ref> [3, 14, 15, 25, 32, 34] </ref> but none to text retrieval. 5.3 Non-Distributional Approaches A variety of ad hoc approaches have been developed that more or less gracefully integrate term frequency and document length information into the BIM itself.
Reference: 16. <editor> D. K. Harman, editor. </editor> <booktitle> The First Text REtrieval Conference (TREC-1), </booktitle> <address> Gaithers-burg, MD 20899, </address> <year> 1993. </year> <institution> National Institute of Standards and Technology. </institution> <note> Special Publication 500-207. </note>
Reference: 17. <editor> D. K. Harman, editor. </editor> <booktitle> The Second Text REtrieval Conference (TREC-2), </booktitle> <address> Gaithers-burg, MD 20899, </address> <year> 1994. </year> <institution> National Institute of Standards and Technology. </institution> <note> Special Publication 500-215. </note>
Reference: 18. <editor> D. K. Harman, editor. </editor> <booktitle> Overview of the Third Text REtrieval Conference (TREC-3), </booktitle> <address> Gaithersburg, MD 20899-0001, </address> <year> 1995. </year> <institution> National Institute of Standards and Technology. </institution> <note> Special Publication 500-225. </note>
Reference: 19. <editor> D. K. Harman, editor. </editor> <booktitle> The Fourth Text REtrieval Conference (TREC-3), </booktitle> <address> Gaithers-burg, MD 20899-0001, </address> <year> 1996. </year> <institution> National Institute of Standards and Technology. </institution> <note> Special Publication 500-236. </note>
Reference: 20. <author> Donna Harman. </author> <title> Relevance feedback and other query modification techniques. </title> <editor> In William B. Frakes and Ricardo Baeza-Yates, editors, </editor> <booktitle> Information Retrieval: Data Structures and Algorithms, </booktitle> <pages> pages 241-263. </pages> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: Robertson and Sparck Jones' particular interest in the binary independence model was its use in relevance feedback <ref> [20, 45] </ref>. In relevance feedback, a user query is given to a search engine, which produces an initial ranking of its document collection by some means. The user examines the initial top-ranked documents and gives feedback to the system on which are relevant to their interest and which are not.
Reference: 21. <author> D. J. Harper and C. J. van Rijsbergen. </author> <title> An evaluation of feedback in document retrieval using co-occurrence data. </title> <journal> Journal of Documentation, </journal> <volume> 34 </volume> <pages> 189-216, </pages> <year> 1978. </year>
Reference-contexts: Whatever its successes in machine learning, the first strategy has not met with great success in IR. While interesting research on dependence models has been done <ref> [8, 11, 21, 49, 50] </ref>, these models are rarely used in practice. Even most work in the "inference net" approach to information retrieval has mostly used independence (or ad hoc) models. Results from the second strategy are hard to judge.
Reference: 22. <author> Stephen P. Harter. </author> <title> A probabilistic approach to automatic keyword indexing. Part I. On the distribution of specialty words in a technical literature. </title> <journal> Journal of the American Society for Information Science, </journal> <pages> pages 197-206, </pages> <month> July-August </month> <year> 1975. </year>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons <ref> [1, 2, 22, 23, 36] </ref>, and the negative binomial (an infinite mixture of Poissons) [40]. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies.
Reference: 23. <author> Stephen P. Harter. </author> <title> A probabilistic approach to automatic keyword indexing. Part II. An algorithm for probabilistic indexing. </title> <journal> Journal of the American Society for Information Science, </journal> <pages> pages 280-289, </pages> <month> September-October </month> <year> 1975. </year>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons <ref> [1, 2, 22, 23, 36] </ref>, and the negative binomial (an infinite mixture of Poissons) [40]. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies.
Reference: 24. <author> David J. Ittner, David D. Lewis, and David D. Ahn. </author> <title> Text categorization of low quality images. </title> <booktitle> In Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pages 301-315, </pages> <address> Las Vegas, NV, </address> <year> 1995. </year> <institution> ISRI; Univ. of Nevada, </institution> <address> Las Vegas. </address>
Reference-contexts: Machine learning researchers tend to be aware of the large pattern recognition literature on naive Bayes, but may be less aware of an equally large information retrieval (IR) literature dating back almost forty years [37, 38]. In fact, naive Bayes methods, along with prototype formation methods <ref> [44, 45, 24] </ref>, accounted for most applications of supervised learning to information retrieval until quite recently. In this paper we briefly review the naive Bayes classifier and its use in information retrieval.
Reference: 25. <author> Thorsten Joachims. </author> <title> Text categorization with support vector machines: Learning with many relevant features. </title> <type> LS-8 Report 23, </type> <institution> University of Dortmund, Computer Science Dept., </institution> <address> Dortmund, Germany, </address> <month> 27 November </month> <year> 1997. </year>
Reference-contexts: The problem is somewhat less extreme for classification tasks, where we can in some cases arrange to compare posterior log odds of classes for each document individually, without comparisons across documents. Indeed, we know of many applications of multinomial models to text categorization <ref> [3, 14, 15, 25, 32, 34] </ref> but none to text retrieval. 5.3 Non-Distributional Approaches A variety of ad hoc approaches have been developed that more or less gracefully integrate term frequency and document length information into the BIM itself. <p> In the yearly TREC evaluations [16-19, 52], numerous variations of naive Bayes models have been used, producing some of the best results. Recent comparisons of learning methods for text categorization have been somewhat less favorable to naive Bayes models <ref> [5, 25] </ref> while still showing them to achieve respectable effectiveness.
Reference: 26. <author> S. Katz. </author> <title> Distribution of content words and phrases in text and language modelling. </title> <booktitle> Natural Language Engineering, </booktitle> <volume> 2(1) </volume> <pages> 15-59, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures <ref> [4, 26] </ref>: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an infinite mixture of Poissons) [40].
Reference: 27. <author> Ron Kohavi. </author> <title> Scaling up the accuracy of Naive-Bayes classifiers: a decision-tree hybrid. </title> <booktitle> In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 202-207, </pages> <year> 1996. </year>
Reference-contexts: This may be because the larger amount of training data available in text categorization data sets favors algorithms which produce more complex classifiers <ref> [27] </ref>, or may because the more elaborate representation and estimation tricks developed for retrieval and routing with naive Bayes have not been applied to categorization. There are many open research questions on the application of naive Bayes in information retrieval.
Reference: 28. <author> Robert R. Korfhage. </author> <title> Information Storage and Retrieval. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: A wide variety of statistical, linguistic, and knowledge-based techniques, involving various amounts of machine and/or manual processing, have been used to produce representations of text for information retrieval systems ([12, Chs. 7-9], <ref> [28, Ch. 5] </ref>, [29, Chs. 3-6] [46, Ch. 3], [51, Chs. 2-3]). An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as effective as any others [30, 33].
Reference: 29. <author> Gerald Kowalski. </author> <title> Information Retrieval Systems: Theory and Implementation. </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1997. </year>
Reference-contexts: A wide variety of statistical, linguistic, and knowledge-based techniques, involving various amounts of machine and/or manual processing, have been used to produce representations of text for information retrieval systems ([12, Chs. 7-9], [28, Ch. 5], <ref> [29, Chs. 3-6] </ref> [46, Ch. 3], [51, Chs. 2-3]). An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as effective as any others [30, 33].
Reference: 30. <author> David D. Lewis. </author> <title> Text representation for intelligent text retrieval: A classification-oriented view. </title> <editor> In Paul S. Jacobs, editor, </editor> <booktitle> Text-Based Intelligent Systems, </booktitle> <pages> pages 179-197. </pages> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1992. </year>
Reference-contexts: An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as effective as any others <ref> [30, 33] </ref>. We therefore make the common assumption that the preprocessing of the document produces a bag (multiset) of index terms which do not themselves have internal structure. This representation is sometimes called the bag of words model.
Reference: 31. <author> David D. Lewis. </author> <title> Evaluating and optimizing autonomous text classification systems. </title> <editor> In Edward A. Fox, Peter Ingwersen, and Raya Fidel, editors, </editor> <booktitle> SIGIR '95: Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 246-254, </pages> <address> New York, </address> <year> 1995. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: omitting those random variables and instead writing Bayes' rule as: P (c k jx) = P (c k ) fi P (x) When we know the P (c k jx) exactly for a classification problem, classification can be done in an optimal way for a wide variety of effectiveness measures <ref> [10, 31] </ref>. For instance, the expected number of classification errors can be minimized by assigning a document with feature vector x to the class c k for which P (c k jx) is highest.
Reference: 32. <author> David D. Lewis and William A. Gale. </author> <title> A sequential algorithm for training text classifiers. </title> <editor> In W. Bruce Croft and C. J. van Rijsbergen, editors, </editor> <booktitle> SIGIR 94: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 3-12, </pages> <address> London, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The problem is somewhat less extreme for classification tasks, where we can in some cases arrange to compare posterior log odds of classes for each document individually, without comparisons across documents. Indeed, we know of many applications of multinomial models to text categorization <ref> [3, 14, 15, 25, 32, 34] </ref> but none to text retrieval. 5.3 Non-Distributional Approaches A variety of ad hoc approaches have been developed that more or less gracefully integrate term frequency and document length information into the BIM itself.
Reference: 33. <author> David D. Lewis and Karen Sparck Jones. </author> <title> Natural language processing for information retrieval. </title> <journal> Communications of the ACM, </journal> <volume> 39(1) </volume> <pages> 92-101, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as effective as any others <ref> [30, 33] </ref>. We therefore make the common assumption that the preprocessing of the document produces a bag (multiset) of index terms which do not themselves have internal structure. This representation is sometimes called the bag of words model.
Reference: 34. <author> Hang Li and Kenji Yamanishi. </author> <title> Document classification using a finite mixture model, </title> <year> 1997. </year>
Reference-contexts: The problem is somewhat less extreme for classification tasks, where we can in some cases arrange to compare posterior log odds of classes for each document individually, without comparisons across documents. Indeed, we know of many applications of multinomial models to text categorization <ref> [3, 14, 15, 25, 32, 34] </ref> but none to text retrieval. 5.3 Non-Distributional Approaches A variety of ad hoc approaches have been developed that more or less gracefully integrate term frequency and document length information into the BIM itself.
Reference: 35. <author> Robert M. Losee. </author> <title> Parameter estimation for probabilistic document-retrieval models. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 39(1) </volume> <pages> 8-16, </pages> <year> 1988. </year>
Reference-contexts: Despite considerable study, explicit use of Poisson mixtures for text retrieval have not proven more effective than using the BIM <ref> [35, 42] </ref>. This failure has been variously blamed on the larger number of parameters these models require estimating, the choice of estimation methods, the difficulty of accounting for document length in these models, and the poor fit of the models to actual term frequencies.
Reference: 36. <author> E. L. Margulis. </author> <title> Modelling documents with multiple Poisson distributions. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 29 </volume> <pages> 215-227, </pages> <year> 1993. </year>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons <ref> [1, 2, 22, 23, 36] </ref>, and the negative binomial (an infinite mixture of Poissons) [40]. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies.
Reference: 37. <author> M. E. Maron. </author> <title> Automatic indexing: An experimental inquiry. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 8 </volume> <pages> 404-417, </pages> <year> 1961. </year>
Reference-contexts: Machine learning researchers tend to be aware of the large pattern recognition literature on naive Bayes, but may be less aware of an equally large information retrieval (IR) literature dating back almost forty years <ref> [37, 38] </ref>. In fact, naive Bayes methods, along with prototype formation methods [44, 45, 24], accounted for most applications of supervised learning to information retrieval until quite recently. In this paper we briefly review the naive Bayes classifier and its use in information retrieval. <p> Its use in the form of Equation 11 was promoted by Robertson and Sparck Jones in a paper [41] that did much to clarify and unify a number of related and partially ad hoc applications of naive Bayes dating back to Maron <ref> [37] </ref>. Robertson and Sparck Jones' particular interest in the binary independence model was its use in relevance feedback [20, 45]. In relevance feedback, a user query is given to a search engine, which produces an initial ranking of its document collection by some means.
Reference: 38. <author> M. E. Maron and J. L. Kuhns. </author> <title> On relevance, probabilistic indexing, and information retrieval. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 7(3) </volume> <pages> 216-244, </pages> <month> July </month> <year> 1960. </year>
Reference-contexts: Machine learning researchers tend to be aware of the large pattern recognition literature on naive Bayes, but may be less aware of an equally large information retrieval (IR) literature dating back almost forty years <ref> [37, 38] </ref>. In fact, naive Bayes methods, along with prototype formation methods [44, 45, 24], accounted for most applications of supervised learning to information retrieval until quite recently. In this paper we briefly review the naive Bayes classifier and its use in information retrieval.
Reference: 39. <author> Marvin Minsky and Seymour Papert. </author> <title> Perceptrons: An Introduction to Computational Geometry (Expanded Edition). </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: In the two class case, we have P (c 2 jx) = 1 P (c 1 jx), so that with some arithmetic manipulations we can replace the two functions that Equation 10 would give for the two-class case with a single function [10, Sec. 2.10]: 2 See <ref> [39, Sec. 12.4.3] </ref> or [10, Sec. 2.10], though in their derivations P (x) has already been dropped. log 1 P (c 1 jx) d X x j log (1 p j1 )p j2 d X log 1 p j2 P (c 1 ) : (11) Equation 11 has several properties that
Reference: 40. <author> Frederick Mosteller and David L. Wallace. </author> <title> Applied Bayesian and Classical Inference. </title> <publisher> Springer-Verlag, </publisher> <address> New York, 2nd edition, </address> <year> 1984. </year>
Reference-contexts: A variety of statistical distributions for term frequencies have been investi-gated, some in the context of naive Bayes classifiers and some for other purposes. The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself <ref> [40] </ref>, mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an infinite mixture of Poissons) [40]. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies. <p> The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself <ref> [40] </ref>, mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an infinite mixture of Poissons) [40]. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies. Rather than attempt to survey the variations here, we refer the reader to the above references, with the suggestion that the book by Mosteller and Wallace [40] <p> <ref> [40] </ref>. The details of the particular models can be complex, sometimes involving latent variables that intervene between the class label and the term frequencies. Rather than attempt to survey the variations here, we refer the reader to the above references, with the suggestion that the book by Mosteller and Wallace [40] is the most clear treatment from a classification standpoint. Despite considerable study, explicit use of Poisson mixtures for text retrieval have not proven more effective than using the BIM [35, 42].
Reference: 41. <author> S. E. Robertson and K. Sparck Jones. </author> <title> Relevance weighting of search terms. </title> <journal> Journal of the American Society for Information Science, </journal> <pages> pages 129-146, </pages> <month> May-June </month> <year> 1976. </year>
Reference-contexts: That is, if one sets the initial score of a document to be the constant term in Equation 11, the full score can be computed by adding up values involving only those words present in a document, not those absent from the document <ref> [41, 48] </ref>. Since most words do not occur in most documents, this is desirable from the standpoint of computational efficiency. The two-class, binary feature naive Bayes model has come to be known in information retrieval as the binary independence model. <p> The two-class, binary feature naive Bayes model has come to be known in information retrieval as the binary independence model. Its use in the form of Equation 11 was promoted by Robertson and Sparck Jones in a paper <ref> [41] </ref> that did much to clarify and unify a number of related and partially ad hoc applications of naive Bayes dating back to Maron [37]. Robertson and Sparck Jones' particular interest in the binary independence model was its use in relevance feedback [20, 45].
Reference: 42. <author> S. E. Robertson, C. J. van Rijsbergen, and M. F. Porter. </author> <title> Probabilistic models of indexing and searching. </title> <editor> In R. N. Oddy, S. E. Robertson, C. J. van Rijsbergen, and P. W. Williams, editors, </editor> <booktitle> Information Research and Retrieval, chapter 4, </booktitle> <pages> pages 35-56. </pages> <publisher> Butterworths, </publisher> <year> 1981. </year>
Reference-contexts: Despite considerable study, explicit use of Poisson mixtures for text retrieval have not proven more effective than using the BIM <ref> [35, 42] </ref>. This failure has been variously blamed on the larger number of parameters these models require estimating, the choice of estimation methods, the difficulty of accounting for document length in these models, and the poor fit of the models to actual term frequencies.
Reference: 43. <author> S. E. Robertson and S. Walker. </author> <title> Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval. </title> <editor> In W. Bruce Croft and C. J. van Rijsbergen, editors, </editor> <booktitle> SIGIR 94: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 232-241, </pages> <address> London, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: When all features have this property, increasing document length can only increase the estimate d P (c k jx), regardless of the actual content of the document. While a case can be made that longer documents are somewhat more likely to be of interest to any given user <ref> [43, 47] </ref>, the above effect is likely to be far stronger than appropriate. 5 Other Distributional Models In this section we look at a number of variations on the naive Bayes model that attempt to address the weaknesses of the BIM. 5.1 Distributions for Integer-Valued Features The most straightforward generalization of <p> In contrast, a recently proposed term weighting formula which rescales the BIM weight to in some ways approximate the behavior of a two-Poisson model has proven quite successful <ref> [43] </ref>.
Reference: 44. <author> J. J. Rocchio, Jr. </author> <title> Relevance feedback in information retrieval. </title> <editor> In Gerard Salton, editor, </editor> <booktitle> The SMART Retrieval System: Experiments in Automatic Document Processing, </booktitle> <pages> pages 313-323. </pages> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1971. </year>
Reference-contexts: Machine learning researchers tend to be aware of the large pattern recognition literature on naive Bayes, but may be less aware of an equally large information retrieval (IR) literature dating back almost forty years [37, 38]. In fact, naive Bayes methods, along with prototype formation methods <ref> [44, 45, 24] </ref>, accounted for most applications of supervised learning to information retrieval until quite recently. In this paper we briefly review the naive Bayes classifier and its use in information retrieval.
Reference: 45. <author> Gerard Salton and Chris Buckley. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(4) </volume> <pages> 288-297, </pages> <year> 1990. </year>
Reference-contexts: Machine learning researchers tend to be aware of the large pattern recognition literature on naive Bayes, but may be less aware of an equally large information retrieval (IR) literature dating back almost forty years [37, 38]. In fact, naive Bayes methods, along with prototype formation methods <ref> [44, 45, 24] </ref>, accounted for most applications of supervised learning to information retrieval until quite recently. In this paper we briefly review the naive Bayes classifier and its use in information retrieval. <p> Robertson and Sparck Jones' particular interest in the binary independence model was its use in relevance feedback <ref> [20, 45] </ref>. In relevance feedback, a user query is given to a search engine, which produces an initial ranking of its document collection by some means. The user examines the initial top-ranked documents and gives feedback to the system on which are relevant to their interest and which are not.
Reference: 46. <author> Gerard Salton and Michael J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: A wide variety of statistical, linguistic, and knowledge-based techniques, involving various amounts of machine and/or manual processing, have been used to produce representations of text for information retrieval systems ([12, Chs. 7-9], [28, Ch. 5], [29, Chs. 3-6] <ref> [46, Ch. 3] </ref>, [51, Chs. 2-3]). An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as effective as any others [30, 33].
Reference: 47. <author> Amit Singhal, Chris Buckley, and Mandar Mitra. </author> <title> Pivoted document length normalization. </title> <booktitle> In SIGIR '96: Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 21-29, </pages> <year> 1996. </year>
Reference-contexts: When all features have this property, increasing document length can only increase the estimate d P (c k jx), regardless of the actual content of the document. While a case can be made that longer documents are somewhat more likely to be of interest to any given user <ref> [43, 47] </ref>, the above effect is likely to be far stronger than appropriate. 5 Other Distributional Models In this section we look at a number of variations on the naive Bayes model that attempt to address the weaknesses of the BIM. 5.1 Distributions for Integer-Valued Features The most straightforward generalization of
Reference: 48. <author> Karen Sparck Jones. </author> <title> Search term relevance weighting given little relevance information. </title> <journal> Journal of Documentation, </journal> <volume> 35(1) </volume> <pages> 30-48, </pages> <month> March </month> <year> 1979. </year>
Reference-contexts: That is, if one sets the initial score of a document to be the constant term in Equation 11, the full score can be computed by adding up values involving only those words present in a document, not those absent from the document <ref> [41, 48] </ref>. Since most words do not occur in most documents, this is desirable from the standpoint of computational efficiency. The two-class, binary feature naive Bayes model has come to be known in information retrieval as the binary independence model.
Reference: 49. <author> Howard R. Turtle and W. Bruce Croft. </author> <title> Evaluation of an inference network-based retrieval model. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 9(3) </volume> <pages> 187-222, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Whatever its successes in machine learning, the first strategy has not met with great success in IR. While interesting research on dependence models has been done <ref> [8, 11, 21, 49, 50] </ref>, these models are rarely used in practice. Even most work in the "inference net" approach to information retrieval has mostly used independence (or ad hoc) models. Results from the second strategy are hard to judge.
Reference: 50. <author> C. J. van Rijsbergen. </author> <title> A theoretical basis for the use of co-occurrence data in information retrieval. </title> <journal> Journal of Documentation, </journal> <volume> 33(2) </volume> <pages> 106-119, </pages> <month> June </month> <year> 1977. </year>
Reference-contexts: Whatever its successes in machine learning, the first strategy has not met with great success in IR. While interesting research on dependence models has been done <ref> [8, 11, 21, 49, 50] </ref>, these models are rarely used in practice. Even most work in the "inference net" approach to information retrieval has mostly used independence (or ad hoc) models. Results from the second strategy are hard to judge.
Reference: 51. <author> C. J. van Rijsbergen. </author> <title> Information Retrieval. </title> <publisher> Butterworths, </publisher> <address> London, </address> <note> second edition, </note> <year> 1979. </year>
Reference-contexts: A wide variety of statistical, linguistic, and knowledge-based techniques, involving various amounts of machine and/or manual processing, have been used to produce representations of text for information retrieval systems ([12, Chs. 7-9], [28, Ch. 5], [29, Chs. 3-6] [46, Ch. 3], <ref> [51, Chs. 2-3] </ref>). An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as effective as any others [30, 33].
Reference: 52. <author> E. M. Voorhees and D. K. </author> <title> Harman, </title> <editor> editors. </editor> <booktitle> Information Technology: The Fifth Text REtrieval Conference (TREC-5), </booktitle> <address> Gaithersburg, MD 20899-0001, </address> <year> 1997. </year> <institution> National Institute of Standards and Technology. </institution> <note> Special Publication 500-238. </note>
Reference-contexts: In the yearly TREC evaluations <ref> [16-19, 52] </ref>, numerous variations of naive Bayes models have been used, producing some of the best results. Recent comparisons of learning methods for text categorization have been somewhat less favorable to naive Bayes models [5, 25] while still showing them to achieve respectable effectiveness.
Reference: 53. <author> Clement T. Yu and Hirotaka Mizuno. </author> <title> Two learning schemes in information retrieval. </title> <booktitle> In Eleventh International Conference on Research & Development in Information Retrieval, </booktitle> <pages> pages 201-215, </pages> <year> 1998. </year>
Reference-contexts: Another approach is to fit a distributional but nonparametric model (for instance a linear regression) to predict the probability that a given term frequency will be observed in a document of a particular length <ref> [53] </ref>.
References-found: 53

