URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P401.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts93.htm
Root-URL: http://www.mcs.anl.gov
Title: A Path-Following Interior-Point Algorithm for Linear and Quadratic Problems  
Author: Stephen J. Wright 
Affiliation: DIVISION, ARGONNE NATIONAL LABORATORY  
Note: PREPRINT MCS-P401-1293, MCS  
Date: December 1993 (revised January, 1995)  
Abstract: We describe an algorithm for the monotone linear complementarity problem (LCP) that converges from any positive, not necessarily feasible, starting point and exhibits polynomial complexity if some additional assumptions are made on the starting point. If the problem has a strictly complementary solution, the method converges sub-quadratically. We show that the algorithm and its convergence properties extend readily to the mixed monotone linear complementarity problem and, hence, to all the usual formulations of the linear programming and convex quadratic programming problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. W. Cottle, J.-S. Pang, and R. E. Stone, </author> <title> The Linear Complementarity Problem (Academic Press, </title> <year> 1992). </year>
Reference-contexts: solve " Y k X k u k # " X k Y k e + ~oe k e : (5) Choose ~ff = arg min k (ff) = (x k + ffu k ) T (y k + ffv k )=n; (6) where ^ff is the largest number in <ref> [0; 1] </ref> such that the following inequalities are satisfied for all ff 2 [0; ^ff): (x k i )(y k i ) (~fl=n)(x k + ffu k ) T (y k + ffv k ); i = 1; ; n: (7b) The search direction obtained from (5) is simply the Newton <p> Throughout the section, we make the following assumption. Assumption 1 The LCP (1) is feasible; that is, there is a pair (x; y) such that y = M x + q and (x; y) 0. Assumption 1 implies that S 6= ; (see, for example, <ref> [1, Theorem 3.1.2] </ref>). If we define the monotonically decreasing sequence f k g by 0 = 1; k+1 = (1 ff k ) k ; it is easy to see that r k = k r 0 . <p> Using the second part of (5), we find that (x k + ffu k ) T (y k + ffv k ) = (x k T v k (x k T Now since ff k 2 [0; ff k ] ae <ref> [0; 1] </ref>, the relations (11) and (12) can be satisfied simultaneously for ff = ff k only if ~oe = 0 and ff k = ff k = 1. Hence we are left with two possibilities. <p> Finally, we examine k (ff) from (6). For ff 2 <ref> [0; 1] </ref> we have 0 k = (1 C 7 k ) k : Now from (41), we clearly have C 7 k &lt; 1, and therefore 0 k (ff) &lt; 0. Hence the complementarity gap is certainly decreasing on the interval (44).
Reference: [2] <author> O. Guler, </author> <title> Generalized linear complementarity problems, </title> <type> Manuscript (1993). </type>
Reference-contexts: The crucial result here is due to Guler <ref> [2] </ref>, who showed that any generalized linear complementarity problem involving a maximal monotone operator can be reformulated as a standard LCP (1). The analysis in this section shows that the operator represented by (2a) is in fact maximal monotone and, hence, satisfies the assumptions of Theorem 3.2 in [2]. <p> to Guler <ref> [2] </ref>, who showed that any generalized linear complementarity problem involving a maximal monotone operator can be reformulated as a standard LCP (1). The analysis in this section shows that the operator represented by (2a) is in fact maximal monotone and, hence, satisfies the assumptions of Theorem 3.2 in [2]. The following extension of Assumption 1 is essential to our analysis. Assumption 3 The MLCP (2) is feasible; that is, there is a vector triple (x; y; z) with (x; y) 0 satisfying (2a). <p> It is not difficult to verify that a condition used by Guler to prove maximal monotonicity of T |namely, nonsingularity of F + G|is satisfied by (63). As shown in <ref> [2, Theorem 3.2] </ref> conversion of (63) to the form (1) can now be achieved by premultiplying F x Gy = a by a nonsingular operator and possibly swapping some components of x and y.
Reference: [3] <author> O. L. Mangasarian, </author> <title> Error bounds for nondegenerate monotone linear complementarity problems, </title> <journal> Math. </journal> <volume> Progr. </volume> <pages> 48(1990) 437-445. </pages>
Reference-contexts: q + r) (M x fl + q) = M (x x fl ) + r; and so from Lemma 3.1 k (x; y) (x fl ; y fl )k 1 (1 + kM k 1 )kx x fl k 1 + k kr 0 k 1 Now from Mangasarian <ref> [3, Theorem 2.6] </ref>, we have that there is a constant C 3 such that min kx x fl k 1 C 3 fl fl fl C 3 fl fl fl C 3 (krk 2 + x T y + kxk 1 krk 1 ) If we substitute from (13) and (9),
Reference: [4] <author> G. J. Minty, </author> <title> Monotone (nonlinear) operators in Hilbert space, </title> <journal> Duke J. Math. </journal> <pages> 29(1992) 341-346. </pages>
Reference-contexts: Our main result is the following. 20 Theorem 6.3 Suppose that Assumption 3 holds. Then the mapping T whose graph is given by (55) is maximal monotone. Proof. We prove the result by appealing to a theorem of Minty <ref> [4] </ref>, which states that T is maximal monotone if and only if R (I + T ) = IR n .
Reference: [5] <author> S. Mizuno, </author> <title> Polynomiality of Kojima-Meggido-Mizuno infeasible-interior-point algorithm for linear programming, </title> <type> Tech. Report 1006, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, </institution> <address> Ithaca, N.Y. </address> <year> (1993). </year>
Reference-contexts: The next lemma contains an inequality that is used in a number of places in the analysis. Similar results appear in Potra [8, Lemma 4.1], Mizuno <ref> [5, Lemma 3.3] </ref>, and Wright [9, Lemma 3.2]. 7 Lemma 3.3 Let (x fl ; y fl ) 2 S.
Reference: [6] <author> R. D. C. Monteiro and S. J. Wright, </author> <title> Superlinear primal-dual affine scaling algorithms for LCP, </title> <type> Preprint MCS-P360-0693, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill. </institution> <year> (1993). </year> <note> To appear in Math. </note> <editor> Progr., </editor> <publisher> Series A. </publisher>
Reference-contexts: The proof of the second inequality is similar. To obtain bounds on the remaining components of (u k ; v k ), we need the following two technical lemmas. Lemma 4.3 (Monteiro and Wright <ref> [6, Lemma 2.2] </ref>.) Let f 2 IR q and H 2 IR pfiq be given.
Reference: [7] <author> R. D. C. Monteiro and S. J. Wright, </author> <title> Local convergence of interior-point algorithms for degenerate monotone LCP, </title> <journal> Comput. </journal> <volume> Optim. </volume> <pages> Appls 3(1994) 131-155. </pages>
Reference-contexts: This assumption is always satisfied if the LCP is a reformulated linear programming problem and, as shown in Monteiro and Wright <ref> [7] </ref>, it is necessary for superlinear convergence of Newton-based primal-dual algorithms. The earlier paper [10] makes an additional assumption: existence of a strictly feasible point, that is, (x; y) such that y = M x+q, (x; y) &gt; 0.
Reference: [8] <author> F. A. Potra, </author> <title> An infeasible interior-point predictor-corrector algorithm for linear programming, </title> <type> Tech. Report 26, </type> <institution> Department of Mathematics, University of Iowa, Iowa City, Iowa (1992). </institution> <note> To appear in SIAM J. Optim. </note>
Reference-contexts: The next lemma contains an inequality that is used in a number of places in the analysis. Similar results appear in Potra <ref> [8, Lemma 4.1] </ref>, Mizuno [5, Lemma 3.3], and Wright [9, Lemma 3.2]. 7 Lemma 3.3 Let (x fl ; y fl ) 2 S.
Reference: [9] <author> S. J. Wright, </author> <title> A path-following infeasible-interior-point algorithm for linear complementarity problems, </title> <journal> Optim. Methods Softw. </journal> <pages> 2(1993) 79-106. </pages>
Reference-contexts: Hence we feel that the linear complementarity formulation is the best one to consider because of its generality, simplicity of notation, and practical efficiency of the algorithms on all its special cases. In two recent papers <ref> [10, 9] </ref>, we described algorithms for (1) that are globally convergent, have polynomial complexity when the starting point (x 0 ; y 0 ) satisfies certain assumptions, and exhibit subquadratic convergence of the complementarity gap k = (x k ) T y k =n to zero. <p> In both algorithms, most 2 of the work at each iteration consists of a single matrix factorization and between one and three triangular solves with the computed factors. These methods were the first interior-point methods with this desirable combination of properties. The local analysis in both [10] and <ref> [9] </ref> requires existence of a strictly complementary solution, that is, (x fl ; y fl ) solving (1) such that x fl + y fl &gt; 0. <p> The strict feasibility assumption is no longer required, technical arguments are streamlined, and R-subquadratic convergence of the iterates (x k ; y k ) to a strictly complementary solution is proved. The new algorithm is quite different from the one in <ref> [9] </ref>, where the ratio of complementarity gap to infeasibility norm krk is kept constant until the "fast" phase, when small variations are allowed. <p> To achieve this effect, a correction to the basic path-following step is computed (at a cost of one additional back-substitution) and a messy planar search procedure is performed. The complications in <ref> [9] </ref> made it possible to prove boundedness of the iteration sequence f (x k ; y k )g, which was a vital element in the asymptotic convergence analysis. Our use of a stronger technical result (Lemma 4.3) removes the dependence on boundedness. <p> If we define the monotonically decreasing sequence f k g by 0 = 1; k+1 = (1 ff k ) k ; it is easy to see that r k = k r 0 . We have the following simple result, whose proof follows that of <ref> [9, Lemma 3.1] </ref>. <p> The next lemma contains an inequality that is used in a number of places in the analysis. Similar results appear in Potra [8, Lemma 4.1], Mizuno [5, Lemma 3.3], and Wright <ref> [9, Lemma 3.2] </ref>. 7 Lemma 3.3 Let (x fl ; y fl ) 2 S. <p> As in the proof of <ref> [9, Lemma 3.2] </ref> we obtain the inequalities 0 2 k ((x 0 ) T y + (y 0 ) T x) (1 k )((x fl ) T y + x T y fl ) (16) k ((x 0 ) T y + (y 0 ) T x) 2 By defining C <p> (u; v) = (u; v) + (^u; ^v); where " M I # " v = 0 # and " Y X ^u # " 0 : (22) (Because of nonsingularity of the coefficient matrix in (21) and (22), both (u; v) and (^u; ^v) are well defined.) As in <ref> [9, Lemma 3.3] </ref>, we can show that kDuk 2n k 1=2 ; kD 1 vk 1=2 fl min For the other component (^u; ^v), we have from the second part of (22) that D^u + D 1 ^v = 0 ) ^v = D 2 ^u: Hence from the first part <p> The special result (20) is proved by analysis similar to that of Lemma 3.4 in Wright <ref> [9] </ref>. The key theorem of this section shows that there is a uniform lower bound on the step length ff k on each safe step. Theorem 3.5 If a safe step is taken at iteration k, then ff k 2! where ! is as defined in Lemma 3.4. Proof. <p> Note that the bound on the solution of (37) is independent of the positive diagonal matrix S. This feature is not present in the analysis of [10, Section 5] and <ref> [9, Section 5] </ref>, where estimates of the elements of D k B and D k N are used in the bound for (u k B ; v k [10], these estimates follow from boundedness of the iterates (x k ; y k ) which, in turn, follow from existence of a <p> Since the estimates are no longer required, the strict feasibility assumption is not required either. In <ref> [9] </ref>, the estimates are obtained by synchronizing reductions in k and kr k k, which complicates the algorithm considerably. <p> The treatment in this section follows that of Wright [10, Section 6] and <ref> [9, Section 6] </ref>. <p> Proof. See [10, Theorem 6.3 (ii)]. So far, we have used the term "convergence" to denote convergence of k and kr k k to zero. Fast convergence of the actual iterates (x k ; y k ) to a solution was not proved in Wright [10], <ref> [9] </ref>, but it is easy to show. A key result is a bound on the distance of (x k ; y k ) to the solution set S. Lemma 5.4 Suppose that Assumption 2 holds. Then there is a constant C 3 such that dist i j 4 (x;y)2S Proof.
Reference: [10] <author> S. J. Wright, </author> <title> An infeasible-interior-point algorithm for linear complementarity problems, </title> <journal> Math. </journal> <volume> Progr. </volume> <pages> 67(1994) 29-52. </pages>
Reference-contexts: Hence we feel that the linear complementarity formulation is the best one to consider because of its generality, simplicity of notation, and practical efficiency of the algorithms on all its special cases. In two recent papers <ref> [10, 9] </ref>, we described algorithms for (1) that are globally convergent, have polynomial complexity when the starting point (x 0 ; y 0 ) satisfies certain assumptions, and exhibit subquadratic convergence of the complementarity gap k = (x k ) T y k =n to zero. <p> In both algorithms, most 2 of the work at each iteration consists of a single matrix factorization and between one and three triangular solves with the computed factors. These methods were the first interior-point methods with this desirable combination of properties. The local analysis in both <ref> [10] </ref> and [9] requires existence of a strictly complementary solution, that is, (x fl ; y fl ) solving (1) such that x fl + y fl &gt; 0. <p> This assumption is always satisfied if the LCP is a reformulated linear programming problem and, as shown in Monteiro and Wright [7], it is necessary for superlinear convergence of Newton-based primal-dual algorithms. The earlier paper <ref> [10] </ref> makes an additional assumption: existence of a strictly feasible point, that is, (x; y) such that y = M x+q, (x; y) &gt; 0. This assumption is undesirable because it is usually not satisfied by large practical problems. <p> This assumption is undesirable because it is usually not satisfied by large practical problems. In this paper, we describe an algorithm that is quite similar to the one in <ref> [10] </ref>, except that it does not use the clumsy merit function OE (x; y) = x T y + ky M x qk and allows more flexibility in the choice of parameters and starting point. <p> As we mention at the end of Section 3, we can also allow more flexibility in the choice of steplength, bringing the algorithm close to current computational practice. The analysis here is considerably stronger than in <ref> [10] </ref>. The strict feasibility assumption is no longer required, technical arguments are streamlined, and R-subquadratic convergence of the iterates (x k ; y k ) to a strictly complementary solution is proved. <p> Besides omitting the threshold , the algorithm above differs from the one described in <ref> [10] </ref> in that the duality gap is used directly in place of the merit function OE, and the particular choices fl min = fl and fl max = 2fl are relaxed. 3 Global Convergence and Polynomial Complexity In this section, we show that the algorithm converges globally to the solution set <p> It is an extension of a result of Ye and Anstreicher [12, Lemma 3.5] and is proved in Wright <ref> [10] </ref>. We use D k B to denote the diagonal submatrix composed of the elements D k ii for i 2 B, and so on. <p> It is an extension of a result of Ye and Anstreicher [12, Lemma 3.5] and is proved in Wright [10]. We use D k B to denote the diagonal submatrix composed of the elements D k ii for i 2 B, and so on. Lemma 4.4 (Wright <ref> [10, Lemma 5.2] </ref>) The vector pair (u k B ; v k N ) solves the convex quadratic program min 1 B wk 2 oe k k e T B ) 1 w + 1 N ) 1 zk 2 oe k k e T N ) 1 z; (38) subject <p> Note that the bound on the solution of (37) is independent of the positive diagonal matrix S. This feature is not present in the analysis of <ref> [10, Section 5] </ref> and [9, Section 5], where estimates of the elements of D k B and D k N are used in the bound for (u k B ; v k [10], these estimates follow from boundedness of the iterates (x k ; y k ) which, in turn, follow <p> This feature is not present in the analysis of [10, Section 5] and [9, Section 5], where estimates of the elements of D k B and D k N are used in the bound for (u k B ; v k <ref> [10] </ref>, these estimates follow from boundedness of the iterates (x k ; y k ) which, in turn, follow from existence of a strictly feasible point. Since the estimates are no longer required, the strict feasibility assumption is not required either. <p> The treatment in this section follows that of Wright <ref> [10, Section 6] </ref> and [9, Section 6]. <p> The second inequality is an immediate consequence of (41). We can now state our asymptotic rate-of-convergence result. Theorem 5.3 The sequence f k g converges superlinearly to zero with Q-order 2. Proof. See <ref> [10, Theorem 6.3 (ii)] </ref>. So far, we have used the term "convergence" to denote convergence of k and kr k k to zero. <p> Proof. See [10, Theorem 6.3 (ii)]. So far, we have used the term "convergence" to denote convergence of k and kr k k to zero. Fast convergence of the actual iterates (x k ; y k ) to a solution was not proved in Wright <ref> [10] </ref>, [9], but it is easy to show. A key result is a bound on the distance of (x k ; y k ) to the solution set S. Lemma 5.4 Suppose that Assumption 2 holds.
Reference: [11] <author> X. Xu, P. Hung, and Y. Ye, </author> <title> A simplified homogeneous and self-dual linear programming algorithm and its implementation, </title> <type> Manuscript (1993). </type>
Reference-contexts: When (2) arises from an LP or QP, a feasible primal-dual point must exist. This requirement is a little troubling, since in practice many LPs are either primal or dual infeasible. Ye, Todd, and Mizuno [13] and Xu, Hung, and Ye <ref> [11] </ref> have alleviated this difficulty in the case of linear programming by describing augmentation/reformulation of an LP in standard form, which has the property that the resulting mixed LCP possesses both a feasible point and a strictly complementary solution.
Reference: [12] <author> Y. Ye and K. Anstreicher, </author> <title> On quadratic and O( p nL) convergence of a predictor-corrector algorithm for LCP, </title> <journal> Math. </journal> <note> Progr. Series A 62(1993) 537-551. </note>
Reference-contexts: It is an extension of a result of Ye and Anstreicher <ref> [12, Lemma 3.5] </ref> and is proved in Wright [10]. We use D k B to denote the diagonal submatrix composed of the elements D k ii for i 2 B, and so on.
Reference: [13] <author> Y. Ye, M. J. Todd, and S. Mizuno, </author> <title> An O( p nL)-iteration homogeneous and self-dual linear programming algorithm, </title> <type> Working Paper 92-11, </type> <institution> College of Business Administration, The University of Iowa (1992). </institution> <note> To appear in Math. </note> <institution> Oper. Res. </institution>
Reference-contexts: When (2) arises from an LP or QP, a feasible primal-dual point must exist. This requirement is a little troubling, since in practice many LPs are either primal or dual infeasible. Ye, Todd, and Mizuno <ref> [13] </ref> and Xu, Hung, and Ye [11] have alleviated this difficulty in the case of linear programming by describing augmentation/reformulation of an LP in standard form, which has the property that the resulting mixed LCP possesses both a feasible point and a strictly complementary solution.
Reference: [14] <author> Y. Zhang, </author> <title> On the convergence of a class of infeasible-interior-point methods for the horizontal linear complementarity problem, </title> <journal> SIAM J. Optim. </journal> <volume> 4(1994) 208-227. </volume> <pages> 24 </pages>
Reference-contexts: By adjusting ffi if necessary, the inequality (32) also holds for fast steps. The result follows from this inequality by a standard argument (see, for example, Zhang <ref> [14, Theorem 7.2] </ref>). We note in passing that the same global convergence and complexity results can be ob tained even if the exact minimizing ~ff is not found in (6). Instead, we can merely require ~ff to satisfy conditions like those often seen in line search methods for unconstrained minimization.
References-found: 14

