URL: http://www.cs.nyu.edu/phd_students/marinesc/pepm.ps
Refering-URL: http://www.cs.nyu.edu/phd_students/marinesc/index.html
Root-URL: http://www.cs.nyu.edu
Email: e-mail: fmarinesc,goldbergg@cs.nyu.edu  
Title: Partial-Evaluation Techniques for Concurrent Programs  
Author: Mihnea Marinescu Benjamin Goldberg 
Keyword: Partial evaluation, binding-time analysis, concurrency, CSP, nondeterminism.  
Address: New York University  
Affiliation: Department of Computer Science,  
Abstract: This paper presents an application of partial evaluation (program specialization) techniques to concurrent programs. The language chosen for this investigation is a very simple CSP-like language. A standard binding-time analysis for imperative languages is extended in order to deal with the basic concurrent constructs (synchronous communication and nondeterministic choice). Based on the binding-time annotations, a specialization transformation is defined and proved correct. In order to maintain a simple and clear presentation, the specialization algorithm addresses only the data transfer component of the communication; partial evaluation, the way it is defined here, always generates residual synchronizations. However, a simple approximate analysis for detecting and removing redundant synchronizations from the residual program (i.e. synchronizations whose removal does not increase the nonde-terminism of a program) can be performed. The paper also addresses pragmatic concerns such as improving the binding-time analysis, controlling loop unrolling and the consequences of lifting nondeterminism from run-time to specialization-time. Finally, the power of the newly developed technique is shown in several examples. 
Abstract-found: 1
Intro-found: 1
Reference: [AR89] <author> P. America and J. Rutten. </author> <title> A parallel object oriented language: Design and semantic foundations. </title> <editor> In J. W. de Bakker, editor, </editor> <booktitle> Languages for Parallel Architectures. </booktitle> <publisher> John Wil-ley, </publisher> <year> 1989. </year>
Reference-contexts: We believe that the results presented here are relevant for a wide variety of concurrent languages; for instance we think our methods can be applied to object oriented concurrent languages like POOL (see <ref> [AR89] </ref>). The performance of the post-specialization synchronization removal can be improved. On the other hand, we'd like to integrate an analysis of the synchronizations into the BTA; this involves a less precise synchronization analysis but the overall quality may be higher because a more powerful specializer may result.
Reference: [Ber90] <author> A. </author> <title> Berlin. Partial evaluation applied to numerical computation. </title> <booktitle> In The 1990 ACM Conference on LISP and Functional Programming, </booktitle> <pages> pages 139-150, </pages> <year> 1990. </year>
Reference: [CD93] <author> C. Consel and O. Danvy. </author> <title> Tutorial notes in partial evaluation. </title> <booktitle> In The 20th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 493-501, </pages> <year> 1993. </year>
Reference: [CL96] <author> C. Colby and P. Lee. </author> <title> Trace-based program analysis. </title> <booktitle> In The 23th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 195-207, </pages> <year> 1996. </year>
Reference-contexts: Note that if we lift this analysis to the specialization time we have to approximate the program point sets af ter; for trace-based abstract interpretations see <ref> [Col95, CL96] </ref>. The simplest synchronization removal algorithm is a naive greedy algorithm that removes one redundant synchronization at a time and updates the tagging of the remaining synchronizations. It computes a maximal set of synchronizations to be removed.
Reference: [Col95] <author> C. Colby. </author> <title> Analyzing the communication topology of concurrent programs. </title> <booktitle> In The ACM Symposium on Partial Evaluation and Semantic-Based Program Manipulation, </booktitle> <pages> pages 202-214, </pages> <year> 1995. </year>
Reference-contexts: Note that if we lift this analysis to the specialization time we have to approximate the program point sets af ter; for trace-based abstract interpretations see <ref> [Col95, CL96] </ref>. The simplest synchronization removal algorithm is a naive greedy algorithm that removes one redundant synchronization at a time and updates the tagging of the remaining synchronizations. It computes a maximal set of synchronizations to be removed.
Reference: [CPW93] <author> C. Consel, C. Pu, and J. Walpole. </author> <title> Incremental specialization: The key to high performance, modularity and portability in operating systems. </title> <booktitle> In The ACM Symposium on Partial Evaluation and Semantic-Based Program Manipulation, </booktitle> <pages> pages 44-46, </pages> <year> 1993. </year>
Reference: [dFS96] <author> N. de Francesco and A. Santone. </author> <title> Unfold/Fold Transformations of Concurrent Processes. </title> <booktitle> In LNCS nr. </booktitle> <volume> 1140, </volume> <pages> pages 167-181. </pages> <publisher> Springer Ver-lag, </publisher> <year> 1996. </year>
Reference: [FOF88] <author> H. Fujita, A. Okamura, and K. Furukawa. </author> <title> Partial evaluation of GHC programs based on the UR-set with constraints. </title> <booktitle> In Logic Programming 5th International Conference and Symposium, </booktitle> <pages> pages 924-941, </pages> <year> 1988. </year>
Reference: [GS96a] <author> R. Gluck and M. H. Strensen. </author> <title> A roadmap to metacomputation by supercompilation. In Partial Evaluation, </title> <publisher> LNCS nr. </publisher> <pages> 1110, pages 137-160. </pages> <publisher> Springer Verlag, </publisher> <year> 1996. </year>
Reference: [GS96b] <author> M. Gupta and E. Schonberg. </author> <title> Static analysis to reduce synchronization costs in data-parallel programs. </title> <booktitle> In The 23th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 322-332, </pages> <year> 1996. </year>
Reference-contexts: The relationship between PE and synchronization is complex; blindly lifting synchronization to the specialization time may increase the nondeterminism and is therefore incorrect. Research on removing synchronizations has been conducted for improving the performance of data-parallel languages <ref> [GS96b] </ref>. In these languages the nondeter-minism is a result of the use of global variables. In this paper, the problem is specified at the basic level: the relation between synchronization and choice.
Reference: [Hoa78] <author> C.A.R. Hoare. </author> <title> Communicating Sequential Processes. </title> <journal> CACM, </journal> <volume> 21(8) </volume> <pages> 666-677, </pages> <year> 1978. </year>
Reference: [Hoa85] <author> C.A.R. Hoare. </author> <title> Communicating Sequential Processes. </title> <publisher> Prentice Hall, </publisher> <year> 1985. </year>
Reference-contexts: introduction of the domain of threads. We have chosen this word rather then the word process because Milner's notion of a process is different; the threads here are more like the processes in <ref> [Hoa85] </ref> and [Plo83]. A thread denotes a sequential unit of execution and there is a unique thread identifier associated with each thread body. Because of this one-to-one correspondence between threads and thread identifiers we will often abuse notation and identify these two domains. <p> pair (trace, final state) where: * trace is an ordered, possibly infinite, sequence of events; these events will be of the form: ff!x with ff 2 CHAN such that O (ff) (i.e. the communica tion on that channel is observable) and x 2 V AL. 3 In his book Hoare <ref> [Hoa85] </ref> gives semantics in terms of traces, refusals and failures of events. 3 V AR the domain of variables V AL the domain of values EN V = V AR ! V AL the environment of variables T EN V = T ID ! T HREAD the environment of threads LABELS
Reference: [JGS93] <author> N. Jones, C. Gomard, and P. Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: Another useful language extension is allowing data structures such as arrays and structures. The problem is the binding-time separation and it is discussed in <ref> [JGS93] </ref>; see also Mogensen [Mog88] and Romanenko [Rom90]. <p> This is a very hard problem and research on this topic is described by Jones in <ref> [JGS93] </ref> and in a recent paper [Jon96]. We study here a problem that is specific to concurrent programs. In a sequential language the specialized program point captures all the information needed for folding (i.e. limiting the unrolling of) a loop.
Reference: [Jon96] <author> N. Jones. </author> <title> What not to do when writing an interpreter for specialization. In Partial Evaluation, </title> <publisher> LNCS nr. </publisher> <pages> 1110, pages 216-237. </pages> <publisher> Springer Verlag, </publisher> <year> 1996. </year>
Reference-contexts: This is a very hard problem and research on this topic is described by Jones in [JGS93] and in a recent paper <ref> [Jon96] </ref>. We study here a problem that is specific to concurrent programs. In a sequential language the specialized program point captures all the information needed for folding (i.e. limiting the unrolling of) a loop.
Reference: [Ltd84] <author> (INMOS Ltd.). </author> <title> Occam Programming Manual. </title> <publisher> Prentice Hall, </publisher> <year> 1984. </year>
Reference: [May83] <author> D. </author> <month> May. </month> <title> Occam. </title> <journal> Sigplan Notices, </journal> <volume> 13(4), </volume> <year> 1983. </year>
Reference: [Mer91] <author> N. Mercouroff. </author> <title> An algorithm for analyzing communicating processes. </title> <booktitle> In Mathematical Foundations of Programming Semantics, LNCS nr. </booktitle> <volume> 598, </volume> <pages> pages 312-325. </pages> <publisher> Springer Ver-lag, </publisher> <year> 1991. </year>
Reference-contexts: This folding must ensure the proper pairing of the static send and receive communications that are in the body of a statically controlled loop. We'll use counting arguments. The same idea was used by Mercouroff <ref> [Mer91] </ref> in his work. The differ ence is that our counting is more restricted, targeting only static communication and is precise. Mercouroff's analysis is used to detect deadlock and is approximate.
Reference: [Mey91] <author> U. Meyer. </author> <title> Techniques for partial evaluation of imperative languages. </title> <booktitle> In Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 94-105, </pages> <year> 1991. </year>
Reference: [Mil89] <author> R. Milner. </author> <title> Communication and Concurrency. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: Recursive threads are not allowed, the reason being to guarantee the existence of a finite number of threads 2 . Communication is performed via synchronized unidirectional message passing on channels. Channel declarations, which associate a channel with a unique pair 1 Introduced in [Par81]. See also Milner's work <ref> [Mil89] </ref>. 2 Hoare for instance forbids process generation inside a recursion. 2 Programs: P 2 P ROG Threads: t 2 T HREAD Thread Identifiers: tid 2 T ID Declarations of Threads: tdecl 2 T DECL Declarations of Channels: chdecl 2 CHDECL Declarations of Variables: d 2 DECL Channel names: ff 2 <p> Following the spirit of the CCS (see <ref> [Mil89] </ref>) we argue that a specification of a concurrent system should include, apart from the text of the program that describes the system, a partition of the communication channels into observable and non-observable. We use the predicate: O : CHAN ! ftrue; falseg to denote this partition. <p> CH ! val_N ===&gt; CH_N ! NO_VALUE CH ? val_N ===&gt; CH_N ? NO_VALUE This sequence of transformations is strikingly similar to the ones used by Milner (see <ref> [Mil89] </ref>) to translate the general CCS into pure CCS (having only pure communication with no exchange of values). Notice that here the transformation is used for a more pragmatic reason than Milner's: improving the binding-time properties and effectively specializing the continuation with respect to the concrete values. <p> This section proceeds as follows: we characterize the dependencies between program points of different 11 threads, then we present an analysis that tags redun-dant synchronizations (we may call them pure communications borrowing a term from Milner <ref> [Mil89] </ref>) and finally we sketch an algorithm for synchronization removal. Let's consider an example: --thread T0 --thread T1 --thread T2 start0: start1: start2: ALT i1:... i2:... b?Y -&gt; .. k1:... k2:... Assuming that i1 and k2 are synchronized, we can infer that thread T0 is deterministic (b?1 must be chosen).
Reference: [Mog88] <author> T. Mogensen. </author> <title> Partially static structures in a self-applicable partial evaluator. </title> <editor> In D. Bjtrner, A. Ershov, and N. Jones, editors, </editor> <booktitle> Partial Evaluation and Mixed Computation, </booktitle> <pages> pages 325-347. </pages> <publisher> North Holland, </publisher> <year> 1988. </year>
Reference-contexts: Another useful language extension is allowing data structures such as arrays and structures. The problem is the binding-time separation and it is discussed in [JGS93]; see also Mogensen <ref> [Mog88] </ref> and Romanenko [Rom90]. Finally, we may use commands executing in parallel without including them in threads as long as we can statically assign unique identifiers to these commands. 4.2 Controlling Loop Unrolling This section does not address the problem of analyzing and improving the termination properties of our special-izer.
Reference: [Mos90] <author> P.D. Mosses. </author> <title> Denotational semantics. </title> <editor> In van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science. </booktitle> <publisher> M.I.T. Press, </publisher> <year> 1990. </year>
Reference-contexts: Finally a minor detail that becomes important for PE: we explicitly associate program points with (most of) the commands in a program, as specified in Fig. 1. 2.2 Semantics This section presents an operational semantics of the language. We have chosen the operational view because, as Mosses writes in <ref> [Mos90] </ref> ": : : it is debatable whether the denotational treatment of concurrency is satisfactory : : : in contrast Structural Operational Semantics extends easily from sequential languages to concurrency".
Reference: [NN94] <author> H.R. Nielson and F. Nielson. </author> <title> Higher-order concurrent programs with finite communication topology. </title> <booktitle> In The 21st Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 84-97, </pages> <year> 1994. </year>
Reference-contexts: We are also investigating the possibility of extending our framework for languages that support dynamic communication topologies. An analysis of the communication topology of a rather complex concurrent language such as CML (see [Rep91]), was presented by Nielson and Nielson in <ref> [NN94] </ref> and we are looking into integrating this analysis into the binding-time analysis and exploiting the potential of bounded-static-variation-based techniques.
Reference: [NP92] <author> V. Nirkhe and W. Pugh. </author> <title> Partial evaluation of high-level imperative languages, with applications in hard real-time systems. </title> <booktitle> In The 19th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 269-280, </pages> <year> 1992. </year>
Reference-contexts: Therefore, communication on that channel will take place both at specialization time, when the data transfer is performed, and at run-time, because of the residual pure communication. The following specialization primitives are standard (see <ref> [NP92] </ref> for instance), so we omit their definitions: * for expressions: evaluate: S e : EXP R ! SEN V ! V AL residualize: S r : EXP R ! SEN V ! CODE * for declarations of variables: S d : DECL ! (SEN V fi CODE) What is non-standard <p> There is no problem in extending our framework to include the if and the while commands; they are control commands, so the BTA of their conditions will affect the BTA of the program points in their bodies, and their specialization is standard (see <ref> [NP92] </ref>). Another useful language extension is allowing data structures such as arrays and structures. The problem is the binding-time separation and it is discussed in [JGS93]; see also Mogensen [Mog88] and Romanenko [Rom90].
Reference: [Par81] <author> D. Park. </author> <title> Concurrency and automata on infinite sequences. </title> <booktitle> In LNCS nr. </booktitle> <volume> 104, </volume> <pages> pages 167-173. </pages> <publisher> Springer Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Recursive threads are not allowed, the reason being to guarantee the existence of a finite number of threads 2 . Communication is performed via synchronized unidirectional message passing on channels. Channel declarations, which associate a channel with a unique pair 1 Introduced in <ref> [Par81] </ref>.
Reference: [PC + 95] <author> C. Pu, C. Consel, et al. </author> <title> Optimistic incremental specialization: Steamlining a commercial operating system. </title> <booktitle> In ACM Symposium on Operating Systems Principles, </booktitle> <year> 1995. </year>
Reference: [Pep93] <author> P. Pepper. </author> <title> Deductive Derivation of Parallel Programs. In Parallel Algorithm Derivation and Program Transformation, </title> <address> pages 1-53. </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference: [Plo83] <author> G.D. Plotkin. </author> <title> An operational semantics for CSP. </title> <editor> In D. Bjtrner, editor, </editor> <booktitle> Formal Description of Programming Concepts II, </booktitle> <pages> pages 199-225. </pages> <publisher> North Holland, </publisher> <year> 1983. </year> <month> 13 </month>
Reference-contexts: introduction of the domain of threads. We have chosen this word rather then the word process because Milner's notion of a process is different; the threads here are more like the processes in [Hoa85] and <ref> [Plo83] </ref>. A thread denotes a sequential unit of execution and there is a unique thread identifier associated with each thread body. Because of this one-to-one correspondence between threads and thread identifiers we will often abuse notation and identify these two domains. <p> (denoted by ! 2 CHEN V ) * for threads (denoted by t 2 T EN V ) * for variables (denoted by 2 EN V ) The semantics of the commands is described in terms of a Labeled Transition System (LTS) similar to the one in [Win93] or in <ref> [Plo83] </ref>. For the ease of presentation, the specification of the LTS omits the channel environment and the thread environment. Notice that once the declarations have been processed these environments do not change. The LTS specified in Fig. 2 appears quite standard.
Reference: [Rep91] <author> J.H. Reppy. </author> <title> CML: A Higher-Order Concur--rent Language. </title> <booktitle> In ACM Symposium Programming Language Design and Implementation, </booktitle> <year> 1991. </year>
Reference-contexts: We are also investigating the possibility of extending our framework for languages that support dynamic communication topologies. An analysis of the communication topology of a rather complex concurrent language such as CML (see <ref> [Rep91] </ref>), was presented by Nielson and Nielson in [NN94] and we are looking into integrating this analysis into the binding-time analysis and exploiting the potential of bounded-static-variation-based techniques.
Reference: [Rom90] <author> S. Romanenko. </author> <title> Arity raiser and its use in program specialization. </title> <editor> In N. Jones, editor, ESOP'90, </editor> <publisher> LNCS nr. </publisher> <pages> 432, pages 341-360. </pages> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Another useful language extension is allowing data structures such as arrays and structures. The problem is the binding-time separation and it is discussed in [JGS93]; see also Mogensen [Mog88] and Romanenko <ref> [Rom90] </ref>. Finally, we may use commands executing in parallel without including them in threads as long as we can statically assign unique identifiers to these commands. 4.2 Controlling Loop Unrolling This section does not address the problem of analyzing and improving the termination properties of our special-izer.
Reference: [RS90] <author> J. Reif and S. Smolka. </author> <title> Data flow analysis of distributed communicating processes. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 19(1) </volume> <pages> 1-30, </pages> <year> 1990. </year>
Reference: [Tur93] <author> V.F. Turchin. </author> <title> Program transformations with metasystem transition. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(3) </volume> <pages> 283-313, </pages> <year> 1993. </year>
Reference: [Win93] <editor> G Winskel. </editor> <booktitle> The Formal Semantics of Programming Languages, </booktitle> <pages> pages 297-336. </pages> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: * for channels (denoted by ! 2 CHEN V ) * for threads (denoted by t 2 T EN V ) * for variables (denoted by 2 EN V ) The semantics of the commands is described in terms of a Labeled Transition System (LTS) similar to the one in <ref> [Win93] </ref> or in [Plo83]. For the ease of presentation, the specification of the LTS omits the channel environment and the thread environment. Notice that once the declarations have been processed these environments do not change. The LTS specified in Fig. 2 appears quite standard.
References-found: 32

