URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR97705-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: C++ Expression Templates Performance Issues in Scientific Computing  
Author: Federico Bassetti Kei Davis Dan Quinlan 
Abstract: Ever-increasing size and complexity of software applications and libraries in scientific computing is making implementation in the programming languages traditional for this field|FORTRAN 77 and C|impractical. The major impediment to the progression to a higher-level language such as C++ is attaining FORTRAN 77 or C performance, which is considered absolutely necessary by many practitioners. The use of template metaprogramming in C++, in the form of so-called expression templates to generate custom C++ code, holds great promise for getting C performance from C++ in the context of operations on array-like objects. Several sophisticated expression template implementations of array-class libraries exist, and in certain circumstances their promise of performance is realized. Unfortunately this is not uniformly the case; this paper explores the major reasons that this is so. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David Brown, Geoff Chesshire, William Henshaw, and Dan Quinlan. Overture: </author> <title> An object-oriented software system for solving partial differential equations in serial and 17 parallel environments. </title> <booktitle> In Proceedings of the SIAM Parallel Conference, </booktitle> <address> Minneapolis, MN, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: A++/P++ [5] and POOMA [6], often underneath higher-level C++ class libraries such as OVERTURE <ref> [1] </ref>, which add support for complex geometry, adaptive mesh refinement, moving grids, and other features to meet more sophisticated applications requirements. As such the performance of the latter libraries and the applications that use them is directly related to that of the underlying array-class libraries. <p> Emulated Expression Templates AA = A.DataPointer; joffset_0 = A.Stride [0]; BB_1 = B_1.DataPointer; joffset_1 = B_1.Stride [0]; BB_2 = B_2.DataPointer; joffset_2 = B_2.Stride [0]; BB_3 = B_3.DataPointer; joffset_3 = B_3.Stride [0]; do - auto int j = 0; do - auto int k = 2; koffset_0 = j * A.Stride <ref> [1] </ref> * A.Size [0]; koffset_1 = j * B_1.Stride [1] * B_1.Size [0]; koffset_2 = j * B_2.Stride [1] * B_2.Size [0]; koffset_3 = j * B_3.Stride [1] * B_3.Size [0]; for (; (k &lt; ksize_1); k += 1) AA [i * joffset_0 + koffset_0] = BB_1 [k * joffset_1 + <p> [0]; BB_1 = B_1.DataPointer; joffset_1 = B_1.Stride [0]; BB_2 = B_2.DataPointer; joffset_2 = B_2.Stride [0]; BB_3 = B_3.DataPointer; joffset_3 = B_3.Stride [0]; do - auto int j = 0; do - auto int k = 2; koffset_0 = j * A.Stride <ref> [1] </ref> * A.Size [0]; koffset_1 = j * B_1.Stride [1] * B_1.Size [0]; koffset_2 = j * B_2.Stride [1] * B_2.Size [0]; koffset_3 = j * B_3.Stride [1] * B_3.Size [0]; for (; (k &lt; ksize_1); k += 1) AA [i * joffset_0 + koffset_0] = BB_1 [k * joffset_1 + koffset_1] + BB_2 [(1 + k) * joffset_2 + <p> = B_2.DataPointer; joffset_2 = B_2.Stride [0]; BB_3 = B_3.DataPointer; joffset_3 = B_3.Stride [0]; do - auto int j = 0; do - auto int k = 2; koffset_0 = j * A.Stride <ref> [1] </ref> * A.Size [0]; koffset_1 = j * B_1.Stride [1] * B_1.Size [0]; koffset_2 = j * B_2.Stride [1] * B_2.Size [0]; koffset_3 = j * B_3.Stride [1] * B_3.Size [0]; for (; (k &lt; ksize_1); k += 1) AA [i * joffset_0 + koffset_0] = BB_1 [k * joffset_1 + koffset_1] + BB_2 [(1 + k) * joffset_2 + koffset_2] + BB_3 [((-1) + k) * joffset_3 + <p> joffset_3 = B_3.Stride [0]; do - auto int j = 0; do - auto int k = 2; koffset_0 = j * A.Stride <ref> [1] </ref> * A.Size [0]; koffset_1 = j * B_1.Stride [1] * B_1.Size [0]; koffset_2 = j * B_2.Stride [1] * B_2.Size [0]; koffset_3 = j * B_3.Stride [1] * B_3.Size [0]; for (; (k &lt; ksize_1); k += 1) AA [i * joffset_0 + koffset_0] = BB_1 [k * joffset_1 + koffset_1] + BB_2 [(1 + k) * joffset_2 + koffset_2] + BB_3 [((-1) + k) * joffset_3 + koffset_3]; j += 1; while (j &lt; jsize); i
Reference: [2] <author> S. Goedecker and A. Hoisie. </author> <title> Achieving high performance in numerical computations on risc workstations and parallel systems. </title> <address> June 1997. Mannheim, Germany. </address>
Reference-contexts: While most of these results are not reported the statistics were monitored to ensure that our explanations of execution times were correct. Some of the metrics reported are computed from combinations of counters <ref> [7, 4, 2] </ref>. All tests were for serial codes on a single processor within that processor's physical segment of the distributed shared memory, so details of the multi-processor environment are irrelevant. In is important to stress that problem sizes were chosen to be L1-cache resident to avoid cacheing issues.
Reference: [3] <author> James Laudon and Daniel Lenoski. </author> <title> The SGI Origin: A ccNUMA Highly Scalable Server. </title> <booktitle> In International Symposium on Computer Architecture, </booktitle> <address> June 1997. Denver, </address> <publisher> CO. </publisher>
Reference-contexts: In all cases the EET code gives an upper (best) bound on performance of actual ET code. Tests were performed on an SGI Origin 2000 system <ref> [3] </ref>. The Origin 2000 uses the MIPS R10000 microprocessor [11] which has built-in hardware performance counters for collecting run-time statistics for arbitrary sections of code.
Reference: [4] <author> O.Lubeck, Y. Luo, H. Wasserman, and F. Bassetti. </author> <title> Performance evaluation of the sgi origin2000: A memory-centric characterization of lanl asci applications. </title> <note> Submitted to Supercomputing97. </note>
Reference-contexts: While most of these results are not reported the statistics were monitored to ensure that our explanations of execution times were correct. Some of the metrics reported are computed from combinations of counters <ref> [7, 4, 2] </ref>. All tests were for serial codes on a single processor within that processor's physical segment of the distributed shared memory, so details of the multi-processor environment are irrelevant. In is important to stress that problem sizes were chosen to be L1-cache resident to avoid cacheing issues.
Reference: [5] <author> Dan Quinlan and Rebecca Parsons. </author> <title> A++/p++ array classes for architecture independent finite difference computations. </title> <booktitle> In Proceedings of the Second Annual Object-Oriented Numerics Conference, </booktitle> <month> April </month> <year> 1994. </year>
Reference-contexts: A++/P++ <ref> [5] </ref> and POOMA [6], often underneath higher-level C++ class libraries such as OVERTURE [1], which add support for complex geometry, adaptive mesh refinement, moving grids, and other features to meet more sophisticated applications requirements.
Reference: [6] <editor> J.V.W. Reynders et al. POOMA: </editor> <title> A Framework for Scientific Simulations on Parallel Architectures, volume Parallel Programming using C++ by Gregory V. </title> <editor> Wilson and Paul Lu, </editor> <volume> chapter 16, </volume> <pages> pages 553-594. </pages> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: A++/P++ [5] and POOMA <ref> [6] </ref>, often underneath higher-level C++ class libraries such as OVERTURE [1], which add support for complex geometry, adaptive mesh refinement, moving grids, and other features to meet more sophisticated applications requirements.
Reference: [7] <author> Silicon Graphics Inc. </author> <title> Performance Tuning for the Origin 2000, </title> <note> 1997. http://www.sgi.com/Technology/TechPubs/manuals/3000/007-3511-001/html/O2000Tuning.0.html. </note>
Reference-contexts: While most of these results are not reported the statistics were monitored to ensure that our explanations of execution times were correct. Some of the metrics reported are computed from combinations of counters <ref> [7, 4, 2] </ref>. All tests were for serial codes on a single processor within that processor's physical segment of the distributed shared memory, so details of the multi-processor environment are irrelevant. In is important to stress that problem sizes were chosen to be L1-cache resident to avoid cacheing issues.
Reference: [8] <author> Bjarne Stroustrup. </author> <title> The C++ Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> 3 edition, </address> <year> 1997. </year>
Reference-contexts: We are therefore heavily invested in its continued use and greater acceptance and so in realizing `optimal'|C or FORTRAN 77|performance. A current `hot' area is the use of the C++ templating mechanism <ref> [8] </ref> to implement so-called expression templates (ETs) [10] to get automatic code in-lining and fusion of the loops implicit in expressions denoting (multiple) array operations that would more traditionally be implemented using overloaded binary operators, in turn implemented by multiple function calls.
Reference: [9] <author> Todd Veldhuizen. </author> <note> Blitz++ users manual. </note>
Reference-contexts: This approach has much promise and quite sophisticated expression template implementations have been developed (e.g. <ref> [9] </ref>).
Reference: [10] <author> Todd Veldhuizen. </author> <title> Expression templates. </title> <type> Technical Report 5, C++ Report 7, </type> <month> June </month> <year> 1995. </year>
Reference-contexts: We are therefore heavily invested in its continued use and greater acceptance and so in realizing `optimal'|C or FORTRAN 77|performance. A current `hot' area is the use of the C++ templating mechanism [8] to implement so-called expression templates (ETs) <ref> [10] </ref> to get automatic code in-lining and fusion of the loops implicit in expressions denoting (multiple) array operations that would more traditionally be implemented using overloaded binary operators, in turn implemented by multiple function calls.
Reference: [11] <editor> Marco Zagha et al. </editor> <title> Performance Analysis Using the MIPS R10000 Performance Counters. </title> <booktitle> In Supercomputing96, </booktitle> <year> 1996. </year> <note> http://www.supercomp.org/sc96/proceedings/SC96PROC/ZAGHA/INDEX.HTM. 18 </note>
Reference-contexts: In all cases the EET code gives an upper (best) bound on performance of actual ET code. Tests were performed on an SGI Origin 2000 system [3]. The Origin 2000 uses the MIPS R10000 microprocessor <ref> [11] </ref> which has built-in hardware performance counters for collecting run-time statistics for arbitrary sections of code. Using these counters we measured the number of cycles executed, instructions executed, floating point operations, primary and secondary cache misses, load and store instructions executed, and several other parameters.
References-found: 11

