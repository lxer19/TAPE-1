URL: http://www.cs.ust.hk/faculty/dlee/Papers/ir/icde96-www.ps
Refering-URL: http://www.public.iastate.edu/~CYBERSTACKS/Aristotle.htm
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Search and Ranking Algorithms for Locating Resources on the World Wide Web  
Author: Budi Yuwono Dik L. Lee 
Address: Columbus, Ohio, U.S.A. Clear Water Bay, Hong Kong  
Affiliation: Department of Computer and Department of Computer Science Information Science Hong Kong University of Science The Ohio State University and Technology  
Abstract: Applying information retrieval techniques to the World Wide Web (WWW) environment is a unique challenge, mostly because of its hypertext/hypermedia nature and the richness of the meta-information it provides. We present four keyword-based search and ranking algorithms for locating relevant WWW pages with respect to user queries. The first algorithm, Boolean Spread Activation, extends the notion of word occurrence in Boolean retrieval model by propagating the occurrence of a query word in a page to other pages linked to it. The second algorithm, Most-cited, is based on the number of citing hyperlinks between potentially relevant WWW pages to increase the relevance scores of the referenced pages over the referencing pages. The third algorithm, TFxIDF or vector space model, is based on word distribution statistics. The last algorithm, Vector Spread Activation, combines vector space model and spread activation model. We conducted an experiment to evaluate the retrieval effectiveness of these algorithms. From the results of the experiment, we draw conclusions regarding the nature of the WWW environment with respect to document ranking strategies. Keywords: resource discovery, information retrieval, world wide web indexing, text database
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Berners-Lee, T., </author> <title> "Uniform Resource Locators," Internet Working Draft, </title> <month> 1 January </month> <year> 1994. </year>
Reference-contexts: We discuss some of the robot-based index servers in the Internet as of this writing, as compared to ours, in the last section of this paper. Our WWW index server 7 takes a query from a user and returns a list of URL's (Uniform Resource Locators <ref> [1] </ref> or WWW page addresses) along with their titles, ranked by relevance score. It supports Boolean query constructs which make use of & (logical AND), j (logical OR), and arch brackets (scope markers) notations.
Reference: 2. <author> Berners-Lee, T., </author> <title> "Hypertext Transfer Protocol," Internet Working Draft, </title> <month> 5 November </month> <year> 1993. </year>
Reference-contexts: Figure 2 illustrates the system architecture. 2.1 Index Builder The index builder is an autonomous WWW browser, also known as WWW robot, which communicates with WWW servers using HTTP (Hypertext Transfer Protocol <ref> [2] </ref>). <p> The latter is made possible by supplying the last access date and time into the HTTP request. 8 As specified in the HTTP specification <ref> [2] </ref>, the remote WWW server will not send the page content in response to the request if the page has not been modified since the specified time. Furthermore, the robot will not even send an HTTP request if the page was last accessed within the last 24 hours.
Reference: 3. <author> Berners-Lee, T., and Connolly, D., </author> <title> "Hypertext Markup Language," Internet Working Draft, </title> <month> 13 July </month> <year> 1993. </year>
Reference-contexts: Thus, efficiency is not a primary concern at this stage of the project. In extracting the keywords, we exclude high-frequency function words (stop-words), numbers, computer specific identifiers such as file-names, file directory paths, e-mail addresses, network host names, and HTML (Hypertext Markup Language <ref> [3] </ref>) tags. To reduce storage overhead, the index builder only indexes words enclosed by HTML tags indicating tokens such as page titles, headings, hyperlink anchor names, words in bold-face, words in italic, and words in the first sentence of every list item.
Reference: 4. <author> Berners-Lee, T., Cailliau, R., Groff, J., and Pollermann, B., </author> <title> "World Wide Web: The Information Universe," </title> <journal> Electronic Networking: Research, Applications and Policy, </journal> <volume> 1(2), </volume> <year> 1992. </year>
Reference-contexts: 1 Introduction The World Wide Web (WWW) <ref> [4] </ref> has become one of the fastest growing applications on the Internet today.
Reference: 5. <author> Eichmann, D., </author> <title> "The RBSE Spider - Balanching Effective Search against Web Load," </title> <booktitle> In Proceedings of the First International Conference on the World Wide Web, </booktitle> <address> Geneva, Switzerland, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: all of the algorithms showed good recalls. 5.2 Other Index Servers There are many robot-based WWW index and search services on the Internet today. 10 However, among the well known robots, only a few employ full-text indexing, e.g., WebCrawler 11 [13], the Repository Based Software Engineering Project Spider 12 (RBSE) <ref> [5] </ref>, and Lycos. 13 Other services index only page titles and first level headings (e.g., JumpStation 14 ), or titles, headings and anchor hypertexts (e.g., World Wide Web Worm or WWWW 15 ).
Reference: 6. <author> Gravano, L., Tomasic, A., and Garcia-Molina, H., </author> <title> "The Efficacy of GLOSS for the Text Database Discovery Problem," </title> <type> Technical Report STAN-CS-TR-93-2, </type> <institution> Stanford University, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: This approach is similar to that of other server indexing methods such as GLOSS <ref> [6] </ref> and directory of servers in WAIS [7]. Upon receiving a query, an index server checks whether it should process the query or redirect it to other index servers which can potentially give better results.
Reference: 7. <author> Kahle, B., and Medlar, A., </author> <title> "An Information System for Corporate Users: Wide Area InformatiON Servers," </title> <type> Technical Report TMC-199, </type> <institution> Thinking Machines, Inc., </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: This approach is similar to that of other server indexing methods such as GLOSS [6] and directory of servers in WAIS <ref> [7] </ref>. Upon receiving a query, an index server checks whether it should process the query or redirect it to other index servers which can potentially give better results. A simple communication protocol is used by the servers to exchange server keywords with each other.
Reference: 8. <author> Koster, M., "ALIWEB: </author> <title> Archie-like Indexing in the Web," </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 27(2), </volume> <pages> pp. 175-182, </pages> <year> 1994. </year>
Reference-contexts: Similar to the above scheme is that of Archie-like Web server (ALIWEB 6 ) <ref> [8] </ref>. Instead of users registering their WWW pages, ALIWEB retrieves index data from each of the participating WWW servers. This index data is prepared manually by the respective WWW server maintainers in a standard text format containing the description of information provided by the servers.
Reference: 9. <author> Krol, E., </author> <title> The Whole Internet User's Guide &Catalog, </title> <publisher> O'Reilly &Associates, </publisher> <address> Se-bastopol CA, </address> <year> 1992. </year>
Reference-contexts: In order to find interesting WWW pages, a user has to browse through many WWW sites. This is a very time consuming process. Methods to relief the users from this information overflow problem have been explored by others, from creating a special Usenet <ref> [9] </ref> newsgroup 1 for announcing new WWW sites, to sharing personal hotlists (accessible from the owner's home pages), compiled list and directories, to searchable full-text index databases. In this paper, we present a WWW index server designed to help users locate WWW pages using keyword search.
Reference: 10. <author> Meadow, C., </author> <title> Text Information Retrieval Systems, </title> <publisher> San Diego Academic Press, </publisher> <address> San Diego CA, </address> <year> 1992. </year>
Reference-contexts: We extend the Boolean model 7 so that documents can be ranked based on the number of query words they contain. This strategy can be considered as a simple fuzzy set retrieval model <ref> [10] </ref> in contrast to the rigorous set membership of the Boolean retrieval model. More formally, document i is assigned a relevance score, R i;q , with respect to query q. R i;q = j=1 Notice that term frequency is not used in the formula.
Reference: 11. <author> Nelson, P., </author> <title> "GDBM The GNU Database Manager," online manual pages, </title> <note> Version 1.7.3, </note> <year> 1990. </year>
Reference-contexts: The index builder and the WWW robot is written in the C language. All index files are implemented using the GNU GDBM Database Manager library package <ref> [11] </ref>. 2.2 Search Engine The user interface to the search engine is a HTML form which can be invoked by standard WWW clients such as Mosaic and Netscape. The user types in the keywords and clicks on a submit button to send the query to the search engine.
Reference: 12. <author> Pfeifer, U., Fuhr, N., and Huynh, T., </author> <title> "Searching Structured Documents with the Enhanced Retrieval Functionality of freeWais-sf and SFgate," </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 27(7), </volume> <pages> pp. 1027-1036, </pages> <year> 1995. </year>
Reference: 13. <author> Pinkerton, B., </author> <title> "Finding What People Want: Experiences with the WebCrawler," </title> <booktitle> In Proceedings of the First International Conference on the World Wide Web, </booktitle> <address> Geneva, Switzerland, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: phrases taken out from actual pages with some synonyms added, all of the algorithms showed good recalls. 5.2 Other Index Servers There are many robot-based WWW index and search services on the Internet today. 10 However, among the well known robots, only a few employ full-text indexing, e.g., WebCrawler 11 <ref> [13] </ref>, the Repository Based Software Engineering Project Spider 12 (RBSE) [5], and Lycos. 13 Other services index only page titles and first level headings (e.g., JumpStation 14 ), or titles, headings and anchor hypertexts (e.g., World Wide Web Worm or WWWW 15 ).
Reference: 14. <author> Salton, G., </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer, </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA, </address> <year> 1989. </year>
Reference-contexts: The first two algorithms rely on WWW meta-information, namely, the hyperlink structure, for ranking the WWW pages without considering term frequencies. The TFxIDF method is based on word occurrence statistics <ref> [14] </ref>, whereas the Vector Spread Activation method make use of both word occurrence statistics and the hyperlink structure in ranking. 3.1 Terminology and Notations In the WWW environment, a document is commonly referred to as a WWW page. In this paper, we use the term page and document interchangeably. <p> with respect to query q is defined as: N X (Li i;k j=1 The objective of this algorithm is to assign, among potentially relevant documents, larger scores to the referenced documents than to the referencing documents. 3.2.3 TFxIDF The TFxIDF algorithm is based on the well known vector space model <ref> [14] </ref>, which typically uses the cosine of the angle between the document and query vectors in a multi-dimensional space as the similarity measure. <p> of any attempt to quantitatively measure the retrieval effectiveness of search algorithms in the WWW environment as in the present work. 5.3 Future Work As part of an on-going research project, our next step in developing the WWW index server is to study the effectiveness of other information retrieval techniques <ref> [14] </ref>, including relevance feedback, automatic query expansion, and automatic categorization and clustering in the WWW environment. We are using methods based on word distribution statistics, which has been proven useful in this paper, to analyze and group WWW pages as well as keywords into conceptual clusters.
Reference: 15. <author> Salton, G., and Buckley, C., </author> <title> "Term-Weighting Approaches in Automatic Text Retrieval," </title> <booktitle> Information Processing &Management, </booktitle> <volume> 24(5), </volume> <pages> pp. 513-523, </pages> <year> 1988. </year> <month> 18 </month>
Reference-contexts: As described in <ref> [15] </ref>, vector-length normalization can be applied when computing the relevance score, R i;q , of page P i with respect to query q: R i;q = term j 2q (0:5 + 0:5 T F i;j q P term j 2P i (0:5 + 0:5 T F i;j (4) where: T F <p> RetRel (a; q) : the number of relevant pages retrieved by a on q. For each query q and algorithm a, we obtained a recall-precision curve using the following procedure which is commonly used in evaluating the precision and recall of ranking algorithms <ref> [15] </ref>. Let Rel (q) be the number of pages relevant to query q in the collection. First, we rank the pages using algorithm a based on q. We then identify the lowest ranked page which is relevant to q. Let the rank of the page be l. <p> Figure 4 shows the recall-precision of TFxIDF with and without such a normalization. According to Salton and Buckley <ref> [15] </ref>, vector-length normalization typically does not work well for short documents. This is consistent with our result since the average page length in the test collection is only 48.11 words (not including stop words and other words removed during the indexing process).
References-found: 15

