URL: http://www.isi.edu/~shen/mckey.ps
Refering-URL: http://www.isi.edu/~shen/selected.html
Root-URL: http://www.isi.edu
Title: Discovering Conceptual Object Models From Instances of Large Relational Databases  
Author: Wei-Min Shen, Weixiong Zhang, Xuejun Wang, and Yigal Arens 
Note: This research was funded in part by NSF grant IRI-9529615, by NSF grant IRI-9619554, by DARPA Cooperative Agreement No F30602-97-2-0238, administered by Air Force Rome Lab, and by DARPA's DMIF program.  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Department of Computer Science University of Southern California  
Abstract: A conceptual model of a database, such as an Entity-Relationship (ER) model, is a specification of objects, attributes, and their relationships. A conceptual model plays important roles in developing successful applications using the underlying data sets. Although critical in practice, a conceptual model may not be always available for lagacy databases, and constructing such a model based on data is a challenging problem. The most difficult task associated with model construction is to identify from the data, and from the data only, the underlying objects, their keys and relations. In this paper, we develop a novel approach to address model construction and object identification, by exploiting the interdependency between these two problems. Our approach has many favorable features, including its robustness in dealing with noise data and scalability to large databases and data sets. We implemented this approach in a system called McKey (Model Construction with Key identification) for discovering and building ER models from instances of legacy databases. We have applied McKey to three very large legacy databases, and obtained comprehensive models within hours, which gives many magnitudes of savings of manpower. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules in large databases. </title> <booktitle> In Proceedings of the 20-th Conference on Very Large Databases (VLDB-94), </booktitle> <pages> pages 487-499, </pages> <address> Santiago de Chile, Chile, </address> <month> Septem-ber 12-15 </month> <year> 1994. </year>
Reference-contexts: The second method is introduced to reduce the compuation cost of the first method by saving the numbers of the uniqueness of small sets of attributes for later use. The method is based on an idea similar to that of frequent sets <ref> [1] </ref> to incrementally compute the uniqueness of larger attribute sets with the uniqueness of smaller attribute sets. It is based on the fact that the uniqueness of an attribute set is a monotonic feature of its size. <p> The A B C 2 3 5 2 5 5 Table 2: An example table for computing uniqueness. uniqueness v (A) = 422+2 = 2 because there are two types of duplications in [A], i.e., <ref> [1] </ref> and [2], so that m = 2, and each duplication has a size of 2, i.e., d 1 (A) = d 2 (A) = 2. <p> Based on this definition, we represent the uniqueness of attribute set X, v (X), as frequent sets <ref> [1] </ref> found in X. In the above example, v (A) is represented as f [1] = 2; [2] = 2g, and v (A; C) is represented as f [2; 5] = 2g. <p> Based on this definition, we represent the uniqueness of attribute set X, v (X), as frequent sets <ref> [1] </ref> found in X. In the above example, v (A) is represented as f [1] = 2; [2] = 2g, and v (A; C) is represented as f [2; 5] = 2g. When calculating the uniqueness of a larger set of attributes, the uniqueness of subsets can be used to reduce the computation cost. <p> If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f <ref> [1; 4] </ref>; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. <p> If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; <ref> [1; 3] </ref>g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. <p> If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f <ref> [1; 4] </ref>; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. <p> If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; <ref> [1; 3] </ref>g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g.
Reference: [2] <author> Y. Arens, C. Y. Chee, C-N. Hsu, and C. A. Knoblock. </author> <title> Retrieving and integrating data from multiple information sources. </title> <journal> International Journal of Intelligent and Cooperative Information Systems, </journal> <volume> 2 </volume> <pages> 127-158, </pages> <year> 1993. </year> <month> 20 </month>
Reference-contexts: In addition to providing an understanding of a given data, a conceptual data model is critical in developing successful database applications. When integrating information from multiple heterogenous data sources, a commen model of the application domain is usually required <ref> [2, 3, 13] </ref>. Such a domain model can be typically built upon the conceptual models of individual data sources. In addition, a conceptual model of a data source is also needed to wrap the data source for translating queries in different query languages [12, 26]. <p> The A B C 2 3 5 2 5 5 Table 2: An example table for computing uniqueness. uniqueness v (A) = 422+2 = 2 because there are two types of duplications in [A], i.e., [1] and <ref> [2] </ref>, so that m = 2, and each duplication has a size of 2, i.e., d 1 (A) = d 2 (A) = 2. <p> Similarly, the uniqueness of v (A; C) = 4 2 + 1 = 3 because there is only one type of duplication in [A; C], i.e., <ref> [2; 5] </ref>, so that m = 1, and the size of that duplication is 2. Based on this definition, we represent the uniqueness of attribute set X, v (X), as frequent sets [1] found in X. <p> Based on this definition, we represent the uniqueness of attribute set X, v (X), as frequent sets [1] found in X. In the above example, v (A) is represented as f [1] = 2; <ref> [2] </ref> = 2g, and v (A; C) is represented as f [2; 5] = 2g. When calculating the uniqueness of a larger set of attributes, the uniqueness of subsets can be used to reduce the computation cost. <p> Based on this definition, we represent the uniqueness of attribute set X, v (X), as frequent sets [1] found in X. In the above example, v (A) is represented as f [1] = 2; [2] = 2g, and v (A; C) is represented as f <ref> [2; 5] </ref> = 2g. When calculating the uniqueness of a larger set of attributes, the uniqueness of subsets can be used to reduce the computation cost. Let Y be an immediate superset of X, i.e., Y has one more attribute than X. <p> For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f <ref> [2; 5] </ref>; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. Although this method is more efficient than the first one, it involves much elaborated data structures and management. <p> For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f <ref> [2; 5] </ref>; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. Although this method is more efficient than the first one, it involves much elaborated data structures and management. <p> Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f <ref> [2; 5] </ref>; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. Although this method is more efficient than the first one, it involves much elaborated data structures and management. In the end, we chose the first 12 method in our current implementation because it is much simpler to imple-ment.
Reference: [3] <author> Y. Arens, C. A. Knoblock, and W-M. Shen. </author> <title> Query reformulation for dy-namic information integration. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 6 </volume> <pages> 99-130, </pages> <year> 1996. </year>
Reference-contexts: In addition to providing an understanding of a given data, a conceptual data model is critical in developing successful database applications. When integrating information from multiple heterogenous data sources, a commen model of the application domain is usually required <ref> [2, 3, 13] </ref>. Such a domain model can be typically built upon the conceptual models of individual data sources. In addition, a conceptual model of a data source is also needed to wrap the data source for translating queries in different query languages [12, 26]. <p> If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; <ref> [1; 3] </ref>g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. <p> If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; <ref> [1; 3] </ref>g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g.
Reference: [4] <author> Y. Arens, W. Zhang, Y. Lee, J. Dukes-Schlossberg, and M. Zev. </author> <booktitle> Warfighter's information packager. In Proceedings of the 10-th Conference on Innovative Applications of Artificial Intelligence (IAAI-98), </booktitle> <pages> pages 1095-1100, </pages> <address> Madison, WI, </address> <month> July 26-30 </month> <year> 1998. </year>
Reference-contexts: If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f <ref> [1; 4] </ref>; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. <p> If yes, their size will be updated, otherwise, they will be eliminated. For example, to compute v (A; C), we expand the set f [1]g to f <ref> [1; 4] </ref>; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f [2; 5]; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. <p> These databases instances include data collected from some logistics applications. We need conceptual models of these database instances to build a large model of a domain for an application that integrates information from multiple sources <ref> [4] </ref>. All of these databases have the typical characteristics of legacy database: (1) Their underlying schema are complex, and they contain large amounts of data. ALPI has 67 tables, with maximum 60 attributes and 515,668 rows. CVI has 104 tables, with maximum 38 attributes and 99,264 rows.
Reference: [5] <author> D. Boulander and S. T. </author> <month> March. </month> <title> An approach to analyzing the information content of existing databases. </title> <booktitle> Database, </booktitle> <pages> pages 1-8, </pages> <year> 1989. </year>
Reference-contexts: Earlier approaches on schema translation such as <ref> [5] </ref>, [10], [24] and [25] also belong to this class, since they only consider schema information. Similar approaches have also been taken in the knowledge discovery and data mining (KDD) research community. <p> Similarly, the uniqueness of v (A; C) = 4 2 + 1 = 3 because there is only one type of duplication in [A; C], i.e., <ref> [2; 5] </ref>, so that m = 1, and the size of that duplication is 2. Based on this definition, we represent the uniqueness of attribute set X, v (X), as frequent sets [1] found in X. <p> Based on this definition, we represent the uniqueness of attribute set X, v (X), as frequent sets [1] found in X. In the above example, v (A) is represented as f [1] = 2; [2] = 2g, and v (A; C) is represented as f <ref> [2; 5] </ref> = 2g. When calculating the uniqueness of a larger set of attributes, the uniqueness of subsets can be used to reduce the computation cost. Let Y be an immediate superset of X, i.e., Y has one more attribute than X. <p> For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f <ref> [2; 5] </ref>; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. Although this method is more efficient than the first one, it involves much elaborated data structures and management. <p> For example, to compute v (A; C), we expand the set f [1]g to f [1; 4]; [1; 3]g. Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f <ref> [2; 5] </ref>; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. Although this method is more efficient than the first one, it involves much elaborated data structures and management. <p> Since f [1; 4]; [1; 3]g is not a frequent set, it is eliminated from v (A; C). We then expand f [2]g to f <ref> [2; 5] </ref>; [2; 5]g. Since this is a frequent set, we update the size and obtain v (A; C) = f [2; 5] = 2g. Although this method is more efficient than the first one, it involves much elaborated data structures and management. In the end, we chose the first 12 method in our current implementation because it is much simpler to imple-ment.
Reference: [6] <author> R. J. Brachman. </author> <title> "i lied about the trees" or, defaults and definitions in knowledge representation. </title> <journal> AI Magazine, </journal> <volume> 6 </volume> <pages> 80-93, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction A conceptual model is a specification of objects, attributes, and their relationships. Conceptual models include Entity-Relationship (ER) model [7, 15, 27] used in the database area, frames and semantic nets <ref> [6, 11, 18] </ref> developed in the artificial intelligence community, and their various extensions. A conceptual database model, such as an ER model, specifies objects and their relationships embeded in a database.
Reference: [7] <author> P. P. Chen. </author> <title> The entity relationship model toward a unified view of data. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 1 </volume> <pages> 9-36, </pages> <year> 1976. </year>
Reference-contexts: 1 Introduction A conceptual model is a specification of objects, attributes, and their relationships. Conceptual models include Entity-Relationship (ER) model <ref> [7, 15, 27] </ref> used in the database area, frames and semantic nets [6, 11, 18] developed in the artificial intelligence community, and their various extensions. A conceptual database model, such as an ER model, specifies objects and their relationships embeded in a database.
Reference: [8] <author> R. H. L. Chiang. </author> <title> A knowledge-based system for performing reverse engineering of relational databases. </title> <booktitle> Decision Support Systems, </booktitle> <volume> 13 </volume> <pages> 295-312, </pages> <year> 1995. </year>
Reference-contexts: The main concern of reverse engineering is how to construct a conceptual model when information about objects, their keys and relationships are known. For example, <ref> [8] </ref> and [9] describe an approach for extracting an Extended Entity-Relationship (EER) model from a relational database when the key attributes of objects are available, consistent, and having error-free values. [16] presents an algorithm for generating EER schema from relational schema when key dependencies and key-based inclusion dependencies are known.
Reference: [9] <author> R. H. L. Chiang, T. M. Barron, and V. C. Storey. </author> <title> Reverse engineering of relational databses: Extraction of an eer model from a relational database. </title> <journal> Data and Knowledge Engineering, </journal> <volume> 12 </volume> <pages> 107-142, </pages> <year> 1994. </year>
Reference-contexts: The main concern of reverse engineering is how to construct a conceptual model when information about objects, their keys and relationships are known. For example, [8] and <ref> [9] </ref> describe an approach for extracting an Extended Entity-Relationship (EER) model from a relational database when the key attributes of objects are available, consistent, and having error-free values. [16] presents an algorithm for generating EER schema from relational schema when key dependencies and key-based inclusion dependencies are known.
Reference: [10] <author> K. H. Davis and A. K. Arora. </author> <title> Converting a relational database model into an entity-relationship model. </title> <booktitle> In Proceedings of the 6-th International Conference on Entity-Relationship Approach, </booktitle> <pages> pages 271-283, </pages> <address> New York, NY, </address> <month> November 9-11 </month> <year> 1987. </year>
Reference-contexts: Earlier approaches on schema translation such as [5], <ref> [10] </ref>, [24] and [25] also belong to this class, since they only consider schema information. Similar approaches have also been taken in the knowledge discovery and data mining (KDD) research community.
Reference: [11] <editor> M. Ginsberg. </editor> <booktitle> Essentials of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction A conceptual model is a specification of objects, attributes, and their relationships. Conceptual models include Entity-Relationship (ER) model [7, 15, 27] used in the database area, frames and semantic nets <ref> [6, 11, 18] </ref> developed in the artificial intelligence community, and their various extensions. A conceptual database model, such as an ER model, specifies objects and their relationships embeded in a database.
Reference: [12] <author> T. Landers and R. L. Rosenberg. </author> <title> An overview of Multibase. </title> <editor> In H. J. Schneider, editor, </editor> <booktitle> Distributed Data Bases. </booktitle> <publisher> North-Holland, </publisher> <year> 1982. </year>
Reference-contexts: Such a domain model can be typically built upon the conceptual models of individual data sources. In addition, a conceptual model of a data source is also needed to wrap the data source for translating queries in different query languages <ref> [12, 26] </ref>. If it is not automated, howeverthe model construction process typically requires extensive experience of domain experts and intensive labor of knowledge engineers. Automatic construction of a conceptual model from a legacy database is, on the other hand, a nontrivial task.
Reference: [13] <author> A. Y. Levy, D. Srivastava, and T. Kirk. </author> <title> Data model and query evaluation in global information systems. </title> <journal> Journal of Intelligent Information Systems, </journal> <note> Special Issue on Networked Information Discovery and Retrieval, 5, </note> <year> 1995. </year>
Reference-contexts: In addition to providing an understanding of a given data, a conceptual data model is critical in developing successful database applications. When integrating information from multiple heterogenous data sources, a commen model of the application domain is usually required <ref> [2, 3, 13] </ref>. Such a domain model can be typically built upon the conceptual models of individual data sources. In addition, a conceptual model of a data source is also needed to wrap the data source for translating queries in different query languages [12, 26].
Reference: [14] <author> M. Manago and Y. Kodratoff. </author> <title> Construction of decision trees from com-plex structured data. </title> <editor> In Piatetsky-Shapiro and Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <pages> pages 289-308. </pages> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference-contexts: Earlier approaches on schema translation such as [5], [10], [24] and [25] also belong to this class, since they only consider schema information. Similar approaches have also been taken in the knowledge discovery and data mining (KDD) research community. For example, <ref> [14] </ref> applies an ID3-style algorithm to analyze frame-based data structures in the KATE system. [22] proposes a method for analyzing individual relations and combining the results across databases based on the known primary and foreign keys.
Reference: [15] <author> H. Mannila and K-J. Raiha. </author> <title> The Design of Relational Databases. </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction A conceptual model is a specification of objects, attributes, and their relationships. Conceptual models include Entity-Relationship (ER) model <ref> [7, 15, 27] </ref> used in the database area, frames and semantic nets [6, 11, 18] developed in the artificial intelligence community, and their various extensions. A conceptual database model, such as an ER model, specifies objects and their relationships embeded in a database. <p> We will only consider the concepts and definitions that will be used in the rest of the paper. Detailed information can be found in many database books, for example <ref> [15, 27] </ref>. 2.1 Entity-relationship model An entity-relationship model, or ER model for short, describes the conceptual schema or logical organization of the data under the consideration. It views the data as consisting of entities and relationships between the entities.
Reference: [16] <author> V. M. Markowitz and J. A. Makowsky. </author> <title> Identifying extended entity-relationship object structures in relational schemas. </title> <journal> IEEE Transaction on Software Engineering, </journal> <volume> 16, </volume> <year> 1990. </year>
Reference-contexts: For example, [8] and [9] describe an approach for extracting an Extended Entity-Relationship (EER) model from a relational database when the key attributes of objects are available, consistent, and having error-free values. <ref> [16] </ref> presents an algorithm for generating EER schema from relational schema when key dependencies and key-based inclusion dependencies are known. Earlier approaches on schema translation such as [5], [10], [24] and [25] also belong to this class, since they only consider schema information.
Reference: [17] <author> S. Mckearney and H. Roberts. </author> <title> Reverse engineering databases for knowledge discovery. </title> <booktitle> In Proceedings of the 2 nd International Conference on Knowledge Discovery & Data Mining (KDD-96), </booktitle> <pages> pages 375-378, </pages> <address> Port-land, Oregon, </address> <month> August, 2-4 </month> <year> 1996. </year>
Reference-contexts: However, the discussion in [21] remains at a proposal level with little detail on how their system was actually developed. <ref> [17] </ref> presents a reverse engineering approach to analyze the dependencies in a database for the background domain knowledge. This approach first searches unique or near-unique attributes as keys, and then groups relevant attributes to form 3 complex objects.
Reference: [18] <author> M. Minsky. </author> <title> A framework for representing knowledge. </title> <editor> In P. Winston, editor, </editor> <booktitle> The Psychology of Computer Vision, </booktitle> <pages> pages 211-277. </pages> <address> McGraw Hill, New York, </address> <year> 1975. </year>
Reference-contexts: 1 Introduction A conceptual model is a specification of objects, attributes, and their relationships. Conceptual models include Entity-Relationship (ER) model [7, 15, 27] used in the database area, frames and semantic nets <ref> [6, 11, 18] </ref> developed in the artificial intelligence community, and their various extensions. A conceptual database model, such as an ER model, specifies objects and their relationships embeded in a database.
Reference: [19] <author> J-M. Petit, J. Kauloumdjian, J-F. Boulicaut, and F. Toumani. </author> <title> Using queries to improve database reverse engineering. </title> <booktitle> In Proceedings of 13th International Conference on Entity-Relationship Approach, Lecture Notes in Computer Science, volume 881. </booktitle> <address> Manchester, UK, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: For example, [14] applies an ID3-style algorithm to analyze frame-based data structures in the KATE system. [22] proposes a method for analyzing individual relations and combining the results across databases based on the known primary and foreign keys. Another approach, taken by <ref> [19] </ref> and [20], is to analyze the data fetching statements embedded in application programs, such as SQl queries, to infer objects and their relations. The limitation of this approach is that not all application programs are available for such an analysis.
Reference: [20] <author> J-M. Petit, F. Toumani, J-F. Boulicaut, and J. Kauloumdjian. </author> <title> Towards the reverse engineering of denormalized relational databases. </title> <booktitle> In Proceedings of 12-th International Conference on Data Enginnering, </booktitle> <address> New Orleans, Louisiana, </address> <month> Febuary </month> <year> 1996. </year>
Reference-contexts: For example, [14] applies an ID3-style algorithm to analyze frame-based data structures in the KATE system. [22] proposes a method for analyzing individual relations and combining the results across databases based on the known primary and foreign keys. Another approach, taken by [19] and <ref> [20] </ref>, is to analyze the data fetching statements embedded in application programs, such as SQl queries, to infer objects and their relations. The limitation of this approach is that not all application programs are available for such an analysis.
Reference: [21] <author> W. J. Premerlani and M. R. Blaha. </author> <title> An approach for reverse engineering of relational databases. </title> <journal> Communications of the ACM, </journal> <volume> 37, </volume> <month> May </month> <year> 1994. </year>
Reference-contexts: This is a typical knowledge discovery and datamining task, and little work has been done on the topic. To our best knowledge, we are only aware of two previous work on discovering and constructing conceptual models from database instances. <ref> [21] </ref> lays out a general and complete approach for model discovering from relational databases. However, the discussion in [21] remains at a proposal level with little detail on how their system was actually developed. [17] presents a reverse engineering approach to analyze the dependencies in a database for the background domain <p> To our best knowledge, we are only aware of two previous work on discovering and constructing conceptual models from database instances. <ref> [21] </ref> lays out a general and complete approach for model discovering from relational databases. However, the discussion in [21] remains at a proposal level with little detail on how their system was actually developed. [17] presents a reverse engineering approach to analyze the dependencies in a database for the background domain knowledge.
Reference: [22] <author> J. S. Ribeiro, K. A. Kaufmann, and L. Kerschberg. </author> <title> Knowledge discovery from multiple databases. </title> <booktitle> In Proceedings of the 1 st International Conference on Knowledge Discovery & Data Mining (KDD-95), </booktitle> <pages> pages 240-245, </pages> <address> Montreal, Quebec, Canada, </address> <month> August 20-21 </month> <year> 1995. </year> <month> 22 </month>
Reference-contexts: Similar approaches have also been taken in the knowledge discovery and data mining (KDD) research community. For example, [14] applies an ID3-style algorithm to analyze frame-based data structures in the KATE system. <ref> [22] </ref> proposes a method for analyzing individual relations and combining the results across databases based on the known primary and foreign keys. Another approach, taken by [19] and [20], is to analyze the data fetching statements embedded in application programs, such as SQl queries, to infer objects and their relations.
Reference: [23] <author> W-M. Shen, W. Zhang, X. Wang, and Y. Arens. </author> <title> Model construction with key identification. </title> <booktitle> In Proceedings of SPIE Conference On Data Mining and Knowledge Discover Theory, Tools, And Technology, </booktitle> <address> Or-lando, Florida, </address> <month> 5-9 April </month> <year> 1999, </year> <note> to appear. </note>
Reference-contexts: Section 3 describes our approach and the McKey system in detail. Section 4 discusses the experimental 4 results of applying McKey to three large legacy databases. Finally, Section 5 concludes the paper with a discussion of future work. An extended abstract of this paper will appear in <ref> [23] </ref>. 2 Background In this section, we briefly describe the entity-relationship models and relational databases. We will only consider the concepts and definitions that will be used in the rest of the paper.
Reference: [24] <author> F. Springsteel and C. Kou. </author> <title> Reverse data engineering technology for visual databsae design. </title> <booktitle> Information and Technology, </booktitle> <year> 1992. </year>
Reference-contexts: Earlier approaches on schema translation such as [5], [10], <ref> [24] </ref> and [25] also belong to this class, since they only consider schema information. Similar approaches have also been taken in the knowledge discovery and data mining (KDD) research community.
Reference: [25] <author> Z. Tari, O. Bukhres, J. Stokes, and S. Hammoudi. </author> <title> The reengineering of relational databases based on key and data correlations. </title> <editor> In S. Spaccapi-etra and F. Maryanski, editors, </editor> <title> Searching for Semantics: Data Mining, Reverse Engineering, etc. </title> <publisher> Chapman & Hall, </publisher> <year> 1998. </year>
Reference-contexts: Earlier approaches on schema translation such as [5], [10], [24] and <ref> [25] </ref> also belong to this class, since they only consider schema information. Similar approaches have also been taken in the knowledge discovery and data mining (KDD) research community.
Reference: [26] <author> Z. Tari, K. Yetongnon W. Cheng, and I. Savnik. </author> <title> Towards cooperative databases: The dok approach. </title> <booktitle> In Proceedings of International Conference on Parallel and Distributed Computing Systems (PDCS-96), </booktitle> <pages> pages 595-600, </pages> <address> Dijon, </address> <year> 1996. </year>
Reference-contexts: Such a domain model can be typically built upon the conceptual models of individual data sources. In addition, a conceptual model of a data source is also needed to wrap the data source for translating queries in different query languages <ref> [12, 26] </ref>. If it is not automated, howeverthe model construction process typically requires extensive experience of domain experts and intensive labor of knowledge engineers. Automatic construction of a conceptual model from a legacy database is, on the other hand, a nontrivial task.
Reference: [27] <author> J. D. Ullman. </author> <title> Principles of Database and Knowledge-Base Systems, volume I. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1988. </year> <month> 23 </month>
Reference-contexts: 1 Introduction A conceptual model is a specification of objects, attributes, and their relationships. Conceptual models include Entity-Relationship (ER) model <ref> [7, 15, 27] </ref> used in the database area, frames and semantic nets [6, 11, 18] developed in the artificial intelligence community, and their various extensions. A conceptual database model, such as an ER model, specifies objects and their relationships embeded in a database. <p> We will only consider the concepts and definitions that will be used in the rest of the paper. Detailed information can be found in many database books, for example <ref> [15, 27] </ref>. 2.1 Entity-relationship model An entity-relationship model, or ER model for short, describes the conceptual schema or logical organization of the data under the consideration. It views the data as consisting of entities and relationships between the entities.
References-found: 27

