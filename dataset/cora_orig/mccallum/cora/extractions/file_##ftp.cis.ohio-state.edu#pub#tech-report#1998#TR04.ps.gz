URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1998/TR04.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: fyangy,singhalg@cis.ohio-state.edu  
Title: Join Techniques in Relational Databases  
Author: Yuping Yang and Mukesh Singhal 
Keyword: Key words: Relational database, query execution, join, equijoin, index, disk I/O, per  
Note: formance, survey.  
Address: Columbus, OH 43210  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: Equijoin between two relations is one of the basic operations in relational databases. Substantial research efforts are still underway to enhance its performance due to its extreme importance in the industry. However, in recent years, there has not been a study which comprehensively examines, under a common framework, the performance of a wide spectrum of equijoin techniques available today. Processor speed, memory size, speed of sequential disk access, as well as the time ratio of random to sequential disk accesses, all have increased drastically in the past decade. Results of many previous performance studies of join techniques no longer hold due to this progress. The main contribution of this paper is twofold. First, it surveys a wide spectrum of equijoin techniques available today. Second, it compares their performance under a common framework that reflects the reality of today's computing environments. Through this survey, we see a trend that indexed join methods are, in general, far better than non-indexed methods for low selectivity joins in large relational databases. Other conclusions of this survey are: (1) a proof that shows that rocking technique in the nested block join provides no speed up; (2) join executions in shared-memory parallel machines with a large number of parallelly operated I/O channels behave more like join executions in shared-nothing parallel machines than that in the shared-memory parallel machines with only a few I/O channels. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Knuth. </author> <title> The Art of Computer Programming: Sorting and Searching, </title> <journal> Vol. </journal> <volume> 3, </volume> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass, </address> <year> 1973. </year>
Reference-contexts: This expression is no longer valid since with today's large memory, usually sorting can be accomplished by two scans of each relation <ref> [1] </ref>. The drastic increase in the processor speed and considerable overlapping between CPU executions and disk accesses mean that the cost of CPU execution is no longer a substantial portion of the cost of the join execution. <p> Thus 2fffi jj R jj =p is the average size of the join result, i.e., number of pages of all matched tuples in the join. Let M be the size of the available memory on the computer. To allow a fast sorting algorithm <ref> [1] </ref> to be implemented for every sort based join technique to ensure a fair comparison among join techniques, we assume M &gt; q j S j =2. The fast algorithm needs two scans over the set to be sorted. <p> A fast sorting algorithm <ref> [1] </ref> is assumed to be used in the sort-merge join. Both R and S are first sorted into runs of approximately size of 2M by a sequential scan and runs are then merged. <p> of disk I/Os for the distributive join is: C distributive = (4 + runs )fl j R j +(2 + part )fl j S j (13) The first term includes the I/O cost of sorting R (costs (2 + runs + 1) j R j, using a fast sorting algorithm <ref> [1] </ref>. The sorted list is written back to the disk) and the second term includes the I/O cost of partitioning S (costs (1 + part ) j S j) using the distribution table.
Reference: [2] <author> L. R. Gotlieb, </author> <title> Computing Joins of Relations. </title> <booktitle> ACM SIGMOD Conf., </booktitle> <address> San Jose, California, </address> <month> May </month> <year> 1975. </year>
Reference-contexts: Nested loop join: In a nested loop join <ref> [2] </ref>, the tuples of R are read sequentially from the disk into the memory. For each tuple of R, all tuples of S are read into the memory once to have their join attribute values compared. R is called the outer relation and S is called the inner relation.
Reference: [3] <author> M. Blasgen, K. Eswaran. </author> <title> On the Evaluation of Queries in a Data Base System. </title> <institution> IBM Res. Lab., </institution> <address> San Jose, CA, </address> <institution> Res. Report RJ1745, </institution> <year> 1976. </year>
Reference-contexts: The above process is repeated until all tuples in one of the joining relations are finished and the merging phase stops because all the remaining tuples in the unfinished joining relation have no chance of forming joined tuples. A study by Blasgenm and Eswaran <ref> [3] </ref> shows that the sort-merge join can almost always outperform the nested loop join when no index is used. However, if there are too many duplicate join attribute values, the performance of the sort-merge join can degenerate to the performance of the nested block join [39].
Reference: [4] <author> M. Blasgen, and K. Eswaran. </author> <title> Storage and Access in Relational Databases. </title> <journal> IBM Systems Journal. </journal> <volume> Vol 16, No. 4, </volume> <year> 1977. </year>
Reference-contexts: Using an index to reduce I/O for inner relation: Indexes such as B+ tree can greatly reduce the number of disk I/Os to fetch a particular data value <ref> [4] </ref>. However, using an index means there is an additional cost of using extra disk storage space for the index itself and using extra disk I/Os for accessing the index. <p> The sorted relations are then used in the join and the join execution is expected to be faster due to sorting. Sort-merge join: This join technique <ref> [4, 17] </ref> sorts both joining relations on the join attributes and then merges two sorted lists. Joining is performed along with merging. In the merging phase, the tuples of R are read into the memory in sorted order, so are the tuples of S.
Reference: [5] <author> S. B. Yao. </author> <title> Approximating Block Accesses in Database Organizations. </title> <journal> Commun. ACM 20, </journal> <volume> 4(Apr. </volume> <year> 1977), </year> <pages> 260-261. </pages>
Reference-contexts: The formula Y ao (k; m; n) is the number of disk pages accessed for retriving k records randomly distributed in n records which reside in m disk pages, without any search overhead, and is given by Yao, S. B. <ref> [5] </ref>: Y ao (k; m; n) = m m fl i=1 n i + 1 Signature methods [15, 27, 30] can also be regarded as a type of index and can be used to speed up join executions by filtering out unmatchable tuples.
Reference: [6] <author> F. P. Preparata. </author> <title> New Parallel-Sorting Schemes. </title> <journal> IEEE. Trans. Comput. </journal> <month> C-27 (July </month> <year> 1978). </year>
Reference-contexts: This means the transmission capability of the network is not fully used. Our analytical result is supported by <ref> [6] </ref>, which shows that the parallel sort-merge join often perform inferior to the parallel nested block join because the parallel sort-merge join cannot fully utilize all processors and memories at the later stage of merging/joining.
Reference: [7] <author> T. Haerder. </author> <title> Implementing a Generalized Access Path Structure for a Relational Database System. </title> <journal> ACM TODS, Vol3, </journal> <volume> N3, </volume> <month> Sept. </month> <year> 1978, </year> <pages> p 285-298. </pages>
Reference-contexts: A domain based approach [13] stores all attribute values according to their data domains. This approach speeds up join execution by sacrificing the performance of other operations such as selection. A combined access path structure (CAPS) or a general access path structure (GAPS) <ref> [7] </ref> is an index that is implemented on a relation such that leaf nodes of the index contain pointers to matching tuples in different relations. A join index [26] is a two-attribute relation which stores join attribute values of both joining relations. <p> Join index technique is conceptually simpler than CAPS, GAPS and B c tree techniques. CAPS and GAPS are very similar to the B c tree technique. In [29], B c tree technique is presented in a simpler way than CAPS and GAPS <ref> [7] </ref>, and it is clearly stated [29] that a B c tree is created on each data domain of some join attributes. Strictly speaking, signature filtering method is not a join technique. <p> which creates an illusion to the programming interface that a shared-memory exists among processors) is a recommended way of solving this problem. 9 Special Structures for Join Executions 9.1 Access Path Structures (CAPS and GAPS) Ideas to design index structures specially for facilitating join executions came as early as 1978 <ref> [7] </ref> in the form of a binary link. A binary link connects together matching tuples from 38 both joining relations and is often implemented as a chain of TIDs or physical pointers (storage addresses). <p> A binary link reduces the execution cost of a join because a selection in the binary link can replace an expensive join execution between joining relations. In a sense, a binary link is a data structure embodying a pre-computed join. A combined access path structure (CAP S) <ref> [7] </ref> is an implementation of the binary index and is an index (e.g., a B+ tree) that is implemented on an attribute, with leaf nodes populated not only with TIDs or physical pointers of the tuples of this relation, but also with TIDs or physical pointers of matching tuples of other <p> A generalized access path structure (GAP S) <ref> [7] </ref>, in addition, stores values of the join attribute along with TIDs or physical pointers. These data structures can greatly speed up the join execution. However, these are very large data structures. <p> The main difference between access path structures and a join index is that in the access path structures, the connection between the matching tuples are, as claimed in <ref> [7] </ref>, implemented by chaining of TIDs or physical pointers while the join index implements the connection by simply making a two-attribute relation between each pair of joinable relations in the database. <p> However, this structure may favor the join execution at the expense of other operations. 9.4 Composite B+ Trees A composite B+ tree (B c tree) [29] can be regarded as an improvement of the access path structure approach <ref> [7] </ref> and the domain based internal schema approach. A B+ tree is created for each data domain of some join attributes. Many attributes in the database share the same data domain and values in these attributes are indexed by the same B+ tree.
Reference: [8] <author> E. Babb. </author> <title> Implementing a Relational Database by Means of Specialized Hardware. </title> <journal> ACM TODS, </journal> <volume> V4, </volume> <pages> N1, </pages> <month> March </month> <year> 1979, </year> <pages> pp. 1-29. </pages>
Reference-contexts: Summary for hash based joins: If tuples are initially fully or partially sorted, sort based joins may very well outperform hash based joins since in this case, sort based join execution reduces to one linear scan of each relation. Hash based joins can usually outperform sort based joins <ref> [8, 14, 17, 19, 22, 25] </ref>. How- ever, in most cases, the performance difference is not large [47]. <p> Bit vector filtering: Bit vector filtering <ref> [8, 16, 21, 24, 33] </ref> speeds up a join execution by discarding unmatchable tuples from the larger relation S. <p> The filtering can be done very fast if the bit vector is implemented in the hardware <ref> [8] </ref>. For a large relation, an array of bit vectors can be used to do the filtering and this array can be kept in the memory while scanning S. This method actually has another name, i.e., the signature method [12, 20]. <p> This method actually has another name, i.e., the signature method [12, 20]. A special type of the bit vector is called Babb array <ref> [8] </ref>. It is a boolean array that is built during the scan of R and each bit in the array corresponds to a hash bucket. A bit in the Babb array is set when there are tuples of R hashed into its corresponding bucket.
Reference: [9] <author> W. Kim. </author> <title> A New Way to Compute the Product and Join of Relations. </title> <booktitle> In Proc of the 1980 ACM SIGMOD Int'l Conf. on the Management of Data, </booktitle> <pages> pp. 179-187, </pages> <year> 1980. </year>
Reference-contexts: The first group of techniques are loop based. The simplest technique in this group is nested loop join. Nested block join significantly improves upon the nested loop join by fully utilizing available large memory space. Nested block with rocking <ref> [9, 50] </ref> tried to improve upon the nested block join by reusing a part of relation S that is already present in the memory. <p> However, beginning from the second time, when start reading pages of S, some tuples of S have already been in B s and these tuples do not have to be read again if reading is carefully arranged. An improvement is proposed in <ref> [9] </ref>: assuming the tuples of S are stored sequentially in a file; in the first pass, S is read forwardly from the top to the bottom of the file; in the second pass, S is read backwardly from the bottom to the top of the file, and tuples at the bottom <p> However, compared to sort based joins, hash based joins are much less robust, i.e., much more sensitive to data skews. Rocking <ref> [9, 50] </ref> in the nested block join is proved to have no effect on the performance of join execution. From our performance study, we observed that index based joins offer the best performance when the join result is small.
Reference: [10] <author> A. P. Bernstein, et al. </author> <title> Query Processing in a System for Distributed Databases (SDD1). </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 6, No. 4, </volume> <month> December </month> <year> 1981, </year> <pages> pp. 602-625. </pages>
Reference-contexts: During the scan of S, a tuple of S is discarded if its corresponding bit in the Babb array is not set. Semijoin: The semijoin was initially proposed in distributed database environments to reduce the cost of data transmission between sites when executing a join <ref> [10] </ref>. However, it can be applied to centralized systems as well. The following is a semijoin of R with S: 1. project R on its join attribute, obtain (R). 2. join (R) with S, obtain semi (S) R ( S).
Reference: [11] <author> J. R. Goodman. </author> <title> An Investigation of Multiprocessor Structures and Algorithms for Database Management. </title> <type> Technical Report ECB/ERL, </type> <institution> M81/33, University of California at Berkeley, </institution> <year> 1981. </year>
Reference-contexts: Hybrid join [41] uses sorting for R and selection index for S. The third group of techniques are hash based. Grace hash join <ref> [11, 14] </ref> hashes both R and S into pairs of buckets and thus transforms a join between two large relations into a series of joins between buckets in the same pair. Hybrid hash join [17] improves upon the Grace hash join when a large memory is available. <p> The performance of the simple hash join is slightly better than the nested block join because of the saving in CPU executions and in-memory moves of data. However, the disk I/O cost of the two techniques is the same. Grace hash join: Grace hash join <ref> [11, 14] </ref> clearly separates two phases of the hash join. In the first phase, each of R and S is partitioned into the same number (k) of buckets by hashing on the join attribute and using a same hash function. These buckets form k pairs.
Reference: [12] <author> G. H. Gonnet, P. A. Larson. </author> <title> External Hashing with Limited Internal Storage. </title> <booktitle> Proc. of the ACM Symposium on Principles of Database Systems, ACM, </booktitle> <address> New York, </address> <year> 1982, </year> <pages> pp. 256-261. </pages>
Reference-contexts: For a large relation, an array of bit vectors can be used to do the filtering and this array can be kept in the memory while scanning S. This method actually has another name, i.e., the signature method <ref> [12, 20] </ref>. A special type of the bit vector is called Babb array [8]. It is a boolean array that is built during the scan of R and each bit in the array corresponds to a hash bucket.
Reference: [13] <author> M. Missikoff. </author> <title> A Domain Based Internal Schema for Relational Database Machines. </title> <booktitle> In ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Orlando, Fla., June 2-4, 1982. </address> <publisher> ACM, </publisher> <address> New York, </address> <year> 1982, </year> <pages> pp. 215-224. </pages>
Reference-contexts: The last group of techniques, called "Miscellaneous" techniques, consists of those techniques that do not fall into either one of the above categories. A domain based approach <ref> [13] </ref> stores all attribute values according to their data domains. This approach speeds up join execution by sacrificing the performance of other operations such as selection. <p> Therefore a database corresponds to a set of data domains. Domain based internal schema stores each value along with pointers pointing to the tuples in the attributes that have this value <ref> [13] </ref>. This data structure can be expected to have a better performance of the join execution than a join index.
Reference: [14] <author> M. Kitsuregawa, H. Tanaka, and T. Moto-oka. </author> <title> Application of Hash to Data Base Machine and Its Architecture. </title> <journal> New Generation Computing, </journal> <volume> vol 1, No.1, </volume> <pages> pp. 66-74, </pages> <year> 1983. </year>
Reference-contexts: Hybrid join [41] uses sorting for R and selection index for S. The third group of techniques are hash based. Grace hash join <ref> [11, 14] </ref> hashes both R and S into pairs of buckets and thus transforms a join between two large relations into a series of joins between buckets in the same pair. Hybrid hash join [17] improves upon the Grace hash join when a large memory is available. <p> The performance of the simple hash join is slightly better than the nested block join because of the saving in CPU executions and in-memory moves of data. However, the disk I/O cost of the two techniques is the same. Grace hash join: Grace hash join <ref> [11, 14] </ref> clearly separates two phases of the hash join. In the first phase, each of R and S is partitioned into the same number (k) of buckets by hashing on the join attribute and using a same hash function. These buckets form k pairs. <p> Summary for hash based joins: If tuples are initially fully or partially sorted, sort based joins may very well outperform hash based joins since in this case, sort based join execution reduces to one linear scan of each relation. Hash based joins can usually outperform sort based joins <ref> [8, 14, 17, 19, 22, 25] </ref>. How- ever, in most cases, the performance difference is not large [47].
Reference: [15] <author> R. Sacks-Davis, K. Ramamohanarao. </author> <title> A Two Level Superimposed Coding Scheme for a Partial Match Retrieval. </title> <journal> Information Systems, </journal> <volume> Vol. 8, No. 4, </volume> <year> 1983, </year> <pages> pp. 273-280. </pages>
Reference-contexts: B. [5]: Y ao (k; m; n) = m m fl i=1 n i + 1 Signature methods <ref> [15, 27, 30] </ref> can also be regarded as a type of index and can be used to speed up join executions by filtering out unmatchable tuples. Instead of scanning entire S to find matches with the memory resident tuples of R, the search can start with signatures.
Reference: [16] <author> K. Bratbergsengen. </author> <title> Hashing Methods and Relational Algebra Operations. </title> <booktitle> Proc. of the 1984 Very Large Database Conf., </booktitle> <year> 1984. </year>
Reference-contexts: Bit vector filtering: Bit vector filtering <ref> [8, 16, 21, 24, 33] </ref> speeds up a join execution by discarding unmatchable tuples from the larger relation S.
Reference: [17] <author> D. J. DeWitt, R. Katz, F. Olken, L. Shapiro, M. Stonebraker, and D. Wood. </author> <title> Implementation Techniques for Main Memory Database Systems. </title> <booktitle> Proc of the 1984 ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <pages> pp. 1-8, </pages> <address> Boston, MA, USA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: The third group of techniques are hash based. Grace hash join [11, 14] hashes both R and S into pairs of buckets and thus transforms a join between two large relations into a series of joins between buckets in the same pair. Hybrid hash join <ref> [17] </ref> improves upon the Grace hash join when a large memory is available. It uses extra memory space (beyond what is needed for hash buffers) to execute join during the hashing phase. Hash based joins are very vulnerable to data skew. <p> The sorted relations are then used in the join and the join execution is expected to be faster due to sorting. Sort-merge join: This join technique <ref> [4, 17] </ref> sorts both joining relations on the join attributes and then merges two sorted lists. Joining is performed along with merging. In the merging phase, the tuples of R are read into the memory in sorted order, so are the tuples of S. <p> Simple hash join: Simple hash join is <ref> [17] </ref> a nested block join with the modification that hashing is used for the in-memory processing. Specifically, first as many pages of R as possible are read into the memory and built into a hash table. <p> Hybrid-hash join: Instead of using extra memory space to set up more buffers as in a Grace hash join, hybrid hash join <ref> [17] </ref> uses extra memory to execute a join during the hashing phase. R is hashed on the join attribute and partitioned into k buckets R i , 0 i k 1. <p> Summary for hash based joins: If tuples are initially fully or partially sorted, sort based joins may very well outperform hash based joins since in this case, sort based join execution reduces to one linear scan of each relation. Hash based joins can usually outperform sort based joins <ref> [8, 14, 17, 19, 22, 25] </ref>. How- ever, in most cases, the performance difference is not large [47].
Reference: [18] <author> W. Kiessling. </author> <title> Tunable Dynamic Filter Algorithms for High Performance Database Systems. </title> <booktitle> Proc. of the Int'l Workshop on High Level Computer Architecture, </booktitle> <month> May 84, 6.10-6.20. </month>
Reference-contexts: This is a similar but more generalized method than the semijoin. Other more general methods than the semijoin can be found in <ref> [18, 25] </ref>. Eliminating random I/O: A hash join has two phases: partitioning and joining. In [52], disk I/Os are divided into four phases: PR (partitioning phase read), PW (partitioning phase write), JR (joining phase read), JW (joining phase write). Hash buckets are comprised of bucket segments.
Reference: [19] <author> K. Bratbergsengen. </author> <title> Hashing Methods and Relational Algebra Operations. </title> <booktitle> In Proc. of the Tenth Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 323-333, </pages> <address> Singapore, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: Summary for hash based joins: If tuples are initially fully or partially sorted, sort based joins may very well outperform hash based joins since in this case, sort based join execution reduces to one linear scan of each relation. Hash based joins can usually outperform sort based joins <ref> [8, 14, 17, 19, 22, 25] </ref>. How- ever, in most cases, the performance difference is not large [47].
Reference: [20] <author> P. A. Larson, A. Kaila. </author> <title> File Organization: Implementation of a Method Guaranteeing Retrieval in One Access. </title> <journal> Commun. ACM 27, </journal> <volume> 7(1984), </volume> <pages> pp. 670-677. </pages>
Reference-contexts: For a large relation, an array of bit vectors can be used to do the filtering and this array can be kept in the memory while scanning S. This method actually has another name, i.e., the signature method <ref> [12, 20] </ref>. A special type of the bit vector is called Babb array [8]. It is a boolean array that is built during the scan of R and each bit in the array corresponds to a hash bucket.
Reference: [21] <author> P. Valduriez, G. Gardarin. </author> <title> Join and Semi-Join Algorithms for a Multiprocessor Database Machine, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol 9, No. 1, </volume> <year> 1984. </year>
Reference-contexts: Bit vector filtering: Bit vector filtering <ref> [8, 16, 21, 24, 33] </ref> speeds up a join execution by discarding unmatchable tuples from the larger relation S. <p> Each processor has its own local memory and disk <ref> [21] </ref> as shown in Figure 2, and the time spent on interprocessor data communication is significant enough to be considered in the overall time cost. <p> Both global and local M BR's are smaller than those in the other two types of parallel joins. In case the system tends to be communication bound, the parallel hash join perform even better <ref> [21] </ref>.
Reference: [22] <author> D. J. DeWitt, R. Gerber. </author> <title> Multiprocessor Hash-Based Join Algorithms. </title> <booktitle> Proc. of the 11th Int'l Conf. on Very Large Data Bases, </booktitle> <address> Stockholm, </address> <year> 1985, </year> <pages> pp. 151-164. </pages>
Reference-contexts: Summary for hash based joins: If tuples are initially fully or partially sorted, sort based joins may very well outperform hash based joins since in this case, sort based join execution reduces to one linear scan of each relation. Hash based joins can usually outperform sort based joins <ref> [8, 14, 17, 19, 22, 25] </ref>. How- ever, in most cases, the performance difference is not large [47].
Reference: [23] <author> G. M. Sacco. </author> <title> Fragmentation: A Technique for Efficient Query Processing. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 11, No. 2, </volume> <month> June </month> <year> 1986, </year> <pages> Pages 113-133. </pages>
Reference-contexts: Many past analyses of the performance of various join techniques are no longer valid due to the new progress. For example, in <ref> [23] </ref>, the cost of sorting was computed to be O (j R j log k1 j R j), where k is the number of pages in the memory buffer and j R j is the number of pages of R.
Reference: [24] <author> L. Mackert and G. Lohman. </author> <title> "R* Optimizer Validation and Performance Evaluation for Local Queries", </title> <booktitle> Proc. of 1986 ACM SIGMOD Conf., </booktitle> <address> Washington, DC, </address> <month> May </month> <year> 1986. </year> <month> 50 </month>
Reference-contexts: Bit vector filtering: Bit vector filtering <ref> [8, 16, 21, 24, 33] </ref> speeds up a join execution by discarding unmatchable tuples from the larger relation S.
Reference: [25] <author> L. D. Shapiro. </author> <title> Join Processing in Database Systems with Large Main Memories. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 11, No. 3, </volume> <month> September </month> <year> 1986, </year> <pages> pp. 239-264. </pages>
Reference-contexts: Summary for hash based joins: If tuples are initially fully or partially sorted, sort based joins may very well outperform hash based joins since in this case, sort based join execution reduces to one linear scan of each relation. Hash based joins can usually outperform sort based joins <ref> [8, 14, 17, 19, 22, 25] </ref>. How- ever, in most cases, the performance difference is not large [47]. <p> This is a similar but more generalized method than the semijoin. Other more general methods than the semijoin can be found in <ref> [18, 25] </ref>. Eliminating random I/O: A hash join has two phases: partitioning and joining. In [52], disk I/Os are divided into four phases: PR (partitioning phase read), PW (partitioning phase write), JR (joining phase read), JW (joining phase write). Hash buckets are comprised of bucket segments.
Reference: [26] <author> P. Valduriez. </author> <title> Join Indexes. </title> <journal> ACM TODS, V12, </journal> <volume> N2, </volume> <month> June </month> <year> 1987, </year>
Reference-contexts: A combined access path structure (CAPS) or a general access path structure (GAPS) [7] is an index that is implemented on a relation such that leaf nodes of the index contain pointers to matching tuples in different relations. A join index <ref> [26] </ref> is a two-attribute relation which stores join attribute values of both joining relations. A pair of matching attribute values from two joining relations is stored in the same tuple of the join index. <p> In the worst case, number of entries (pointers, TIDs, values) stored can be the cross product of the numbers of tuples in two joining relations. 9.2 Join Index The idea of access path structures reappeared in 1987 in the form of join index <ref> [26] </ref>. A join index is a two-attribute relation. Each tuple in a join index contains two TIDs of two matching tuples from two joining relations. A join index is also a pre-computed join and can turn a join execution into a selection.
Reference: [27] <author> R. Sacks-Davis, A. Kent, K. Ramamohanarao. </author> <title> Multikey Access Methods Based on Superimposed Coding Techniques. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 12, No.4, </volume> <year> 1987, </year> <pages> pp. 655-696. </pages>
Reference-contexts: B. [5]: Y ao (k; m; n) = m m fl i=1 n i + 1 Signature methods <ref> [15, 27, 30] </ref> can also be regarded as a type of index and can be used to speed up join executions by filtering out unmatchable tuples. Instead of scanning entire S to find matches with the memory resident tuples of R, the search can start with signatures.
Reference: [28] <author> M. Nakayama, M. Kitsuregawa, and M. Takagi. </author> <title> Hash-partitioned Join Method Using Dynamic Destaging Strategy. </title> <booktitle> In Proc of the 14th Int'l Conf. on Very Large Data Bases, </booktitle> <pages> pp. 468-478, </pages> <address> Los Angeles, California, USA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: This strategy could have problems since the anchor bucket may be too large to fit in the memory or too small to be effective. Because usually data distribution is unknown before a join, the decision to choose the anchor bucket should be delayed as much as possible <ref> [28] </ref>. In DDS, the intended bucket size is chosen to be much smaller than the intended partitions to avoid bucket overflows.
Reference: [29] <author> B. C. Desai. </author> <title> Performance of a Composite Attribute and Join Index. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. 15, No. 2, </volume> <year> 1989. </year>
Reference-contexts: Therefore, for most join techniques, there is no need to develop separate cost formulas for full and selective joins. Composite B+ tree (B c ) technique <ref> [29] </ref> is an exception and this will be discussed later. <p> Composite B+ tree (B c tree) method <ref> [29] </ref> improves upon the join index method by creating a B c tree, which is a modified B+ tree, on each data domain of the join attributes. Each leaf-node contains pointers pointing to matching tuples in joining relations. <p> Each leaf-node contains pointers pointing to matching tuples in joining relations. Join index technique is conceptually simpler than CAPS, GAPS and B c tree techniques. CAPS and GAPS are very similar to the B c tree technique. In <ref> [29] </ref>, B c tree technique is presented in a simpler way than CAPS and GAPS [7], and it is clearly stated [29] that a B c tree is created on each data domain of some join attributes. Strictly speaking, signature filtering method is not a join technique. <p> Join index technique is conceptually simpler than CAPS, GAPS and B c tree techniques. CAPS and GAPS are very similar to the B c tree technique. In <ref> [29] </ref>, B c tree technique is presented in a simpler way than CAPS and GAPS [7], and it is clearly stated [29] that a B c tree is created on each data domain of some join attributes. Strictly speaking, signature filtering method is not a join technique. <p> This data structure can be expected to have a better performance of the join execution than a join index. However, this structure may favor the join execution at the expense of other operations. 9.4 Composite B+ Trees A composite B+ tree (B c tree) <ref> [29] </ref> can be regarded as an improvement of the access path structure approach [7] and the domain based internal schema approach. A B+ tree is created for each data domain of some join attributes. <p> B c tree <ref> [29] </ref> approach improved upon the join index in that it uses a modified B+ tree to speed up disk accessing, and it drastically reduces (compared to the join index) the size of data structure used. Another group of index based joins is the pointer based joins.
Reference: [30] <author> D. L. Lee, C.-W. Leng. </author> <title> Partitioned Signature File: Design Issues and Performance Evaluation. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> Vol. 7, </volume> <pages> No.2, </pages> <month> April </month> <year> 1989, </year> <pages> pp. 158 - 180. </pages>
Reference-contexts: B. [5]: Y ao (k; m; n) = m m fl i=1 n i + 1 Signature methods <ref> [15, 27, 30] </ref> can also be regarded as a type of index and can be used to speed up join executions by filtering out unmatchable tuples. Instead of scanning entire S to find matches with the memory resident tuples of R, the search can start with signatures.
Reference: [31] <author> K. Li, P. Hudak. </author> <title> Memory Coherence in Shared Virtual Memory Systems. </title> <journal> ACM Transaction on Computer Systems, </journal> <volume> 7(4), </volume> <month> November </month> <year> 1989. </year>
Reference-contexts: with [36], this is not only because of the difference between the architectures of a SM and a SN , but also because of the fact that in [48], fewer processors are used in the parallel machine. 8.3 Shared Virtual Memory Machines Main reasons of using shared virtual memory machine <ref> [31, 40, 46] </ref> (SV M ) are the ease of coding and the ease of conceptualization of shared data structures.
Reference: [32] <author> M. S. Lakshmi, P. S. Yu. </author> <title> Limiting Factors of Join Performance on Parallel Processors. </title> <booktitle> IEEE. Proc. of 5th Int'l Conf. on Data Engineering, </booktitle> <year> 1989. </year>
Reference-contexts: Parallel joins constitute the fourth and fifth groups. The applicability of parallel joins depends on the underlying machine to be used. Shared-nothing parallel computer (SN ) <ref> [32, 33] </ref> is gaining popularity because of its scalability and modularity, but the performance of join executions on a SN is highly vulnerable to data skew (this is very similar to hash based serial joins). Shared-everything (shared memory) parallel computer (SM ) [48] is much less sensitive to data skew. <p> The interprocessor data com <p>- 29 munication time can be analyzed statically. The synchronization cost is sensitive to data skew and the stochastic nature of the join execution <ref> [32] </ref>. Comparison of three classes of parallel joins: We now compare the performance of three join techniques, i.e., parallel nested block join, parallel sort-merge join, and parallel hash join. <p> It was shown <ref> [32] </ref> that with 5% data skew, even if the collective processing power of a parallel machine is 10 times that of a single processor machine, there can be no performance advantage of using the parallel hash join. 32 The stochastical nature of the join processing time also exacts a similar penalty <p> However, one needs to be cautious about the conclusion in <ref> [32] </ref>. In [32], total of 300 processors with 2 MIPS each were used in a parallel machine and the performance is compared to that of a single processor machine of 60 MIPS. <p> However, one needs to be cautious about the conclusion in <ref> [32] </ref>. In [32], total of 300 processors with 2 MIPS each were used in a parallel machine and the performance is compared to that of a single processor machine of 60 MIPS. <p> On this type of parallel machines, parallel joins only have a very limited performance advantage over joins on single processor machines because join executions are most likely to be I/O bound. <ref> [32] </ref> concluded that the performance of the parallel hash join is very sensitive to data skew in a shared-nothing parallel machine while [48] claimed that the effect of data skew on parallel hash join is small in a shared-everything parallel machine. However, in [32], a large number (300) of processors were <p> are most likely to be I/O bound. <ref> [32] </ref> concluded that the performance of the parallel hash join is very sensitive to data skew in a shared-nothing parallel machine while [48] claimed that the effect of data skew on parallel hash join is small in a shared-everything parallel machine. However, in [32], a large number (300) of processors were used in the parallel machine while in [48], only 10 processors were used.
Reference: [33] <author> D. Schneider and D. J. DeWitt. </author> <title> A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <year> 1989. </year>
Reference-contexts: Parallel joins constitute the fourth and fifth groups. The applicability of parallel joins depends on the underlying machine to be used. Shared-nothing parallel computer (SN ) <ref> [32, 33] </ref> is gaining popularity because of its scalability and modularity, but the performance of join executions on a SN is highly vulnerable to data skew (this is very similar to hash based serial joins). Shared-everything (shared memory) parallel computer (SM ) [48] is much less sensitive to data skew. <p> Bit vector filtering: Bit vector filtering <ref> [8, 16, 21, 24, 33] </ref> speeds up a join execution by discarding unmatchable tuples from the larger relation S.
Reference: [34] <author> J. A. Blakeley, N. L. Martin. </author> <title> Join Index, Materialized View, and Hybrid-Hash Join: </title>
Reference-contexts: This means a large number of disk I/Os often need to be made during a join execution. Some previous studies such as <ref> [34] </ref> include CPU time and in-memory move time as part of their estimate of the cost of the join execution, and many others do not include the cost such as the 5 in-memory move time. This makes their results incomparable to each other. <p> n) = Y ao (k; m; n) + Y ao (k; n=F O; n) + T 3 (k; n); (7) T 3 (k; n) = Y ao (Y ao (k; n=F O; n); n=(F O fl F O); n=F O): (8) F O is the fan out of non-leaf nodes <ref> [34] </ref>. The formula Y ao (k; m; n) is the number of disk pages accessed for retriving k records randomly distributed in n records which reside in m disk pages, without any search overhead, and is given by Yao, S.
References-found: 34

