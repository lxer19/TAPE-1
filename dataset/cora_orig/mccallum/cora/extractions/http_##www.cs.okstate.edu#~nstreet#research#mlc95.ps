URL: http://www.cs.okstate.edu/~nstreet/research/mlc95.ps
Refering-URL: http://www.cs.okstate.edu/~nstreet/research/publications.html
Root-URL: 
Email: street@cs.wisc.edu  olvi@cs.wisc.edu  wolberg@eagle.surgery.wisc.edu  
Title: An Inductive Learning Approach to Prognostic Prediction  
Author: W. Nick Street O. L. Mangasarian W. H. Wolberg 
Address: 1210 West Dayton Street Madison, WI 53706  1210 West Dayton Street Madison, WI 53706  600 Highland Avenue Madison, WI 53792  
Affiliation: Departments of Surgery and Computer Sciences University of Wisconsin  Department of Computer Sciences University of Wisconsin  Department of Surgery University of Wisconsin  
Abstract: This paper introduces the Recurrence Surface Approximation, an inductive learning method based on linear programming that predicts recurrence times using censored training examples, that is, examples in which the available training output may be only a lower bound on the "right answer." This approach is augmented with a feature selection method that chooses an appropriate feature set within the context of the linear programming generalizer. Computational results in the field of breast cancer prognosis are shown. A straightforward translation of the prediction method to an artificial neural network model is also proposed.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., Kibler, D., and Albert, M. K. </author> <year> (1991). </year> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 37-66. </pages>
Reference: <author> Aitken, R. J., Gaze, M. N., Rodger, A., Chetty, U., and Forrest, A. P. M. </author> <year> (1989). </year> <title> Arm morbidity within a trial of mastectomy and either nodal sample with selective radiotherapy or axillary clearance. </title> <journal> British Journal of Surgery, </journal> <volume> 76 </volume> <pages> 568-571. </pages>
Reference: <author> Burke, H. B. </author> <year> (1994). </year> <title> Artificial neural networks for cancer research: Outcome prediction. </title> <journal> Seminars in Surgical Oncology, </journal> <volume> 10 </volume> <pages> 73-79. </pages>
Reference-contexts: Schenone et al. (Schenone et al., 1993) used a self-organizing neural network to find classes of cases with similar expected recurrence times. However, they did not directly address the problem of using censored data, that is, cases which have not been followed to recurrence / death. Burke <ref> (Burke, 1994) </ref> used artificial neural networks (ANNs) to approach prognosis as a separation problem, as was done in previous work at Wisconsin (Wolberg et al., 1992; Wolberg et al., 1994).
Reference: <author> Carter, C. L., Allen, C., and Henson, D. E. </author> <year> (1989). </year> <title> Relation of tumor size, lymph node status, and survival in 24,740 breast cancer cases. </title> <journal> Cancer, </journal> <volume> 63 </volume> <pages> 181-187. </pages>
Reference-contexts: We will re-examine this point in Section 3. 2.4 APPLICATION TO OTHER DATASETS 2.4.1 SEER Data The RSA prognostic prediction method was tested using the breast database from the Surveillance, Epidemiology, and End Results (SEER) Program of the National Cancer Institute <ref> (Carter et al., 1989) </ref>, which contains follow-up data for over 44,000 breast cancer patients. These cases contain five integer-valued input features, as follows: 1. Histological Grade: 1, 2, or 3. 2. Tumor Size: 1, 2, ..., or 11. 3. Tumor Extension: 1, 2, ..., or 5. 4.
Reference: <author> Cox, D. R. </author> <year> (1972). </year> <title> Regression models and life-tables. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 34 </volume> <pages> 187-202. </pages>
Reference-contexts: In particular, we are preparing an extensive set of tests comparing our approach to techniques from the statistical literature, such as Cox proportional hazards regression <ref> (Cox, 1972) </ref>. So far only linear models have been employed by the RSA method, which limits its representational power. We therefore plan to modify backpropagation artificial neural networks (ANN's) (Rumelhart et al., 1986) to predict recurrence time in the same manner as the RSA procedure.
Reference: <author> Dantzig, G. B. </author> <year> (1963). </year> <title> Linear Programming and Extensions. </title> <publisher> Princeton University Press, </publisher> <address> Princeton NJ. </address>
Reference-contexts: In this work we are concerned specifically with prognosis, that is, predicting the course of a disease. This paper introduces a new prognosis prediction method, based on linear programming <ref> (Dantzig, 1963) </ref>, which can be implemented using a backpropagation neural networks (Rumelhart et al., 1986) based on the same objective. These methods are applied to breast cancer prognosis, predicting how long after surgery we can expect the disease to recur.
Reference: <author> De Laurentiis, M. and Ravdin, P. M. </author> <year> (1994). </year> <title> A technique for using neural network analysis to perform survival analysis of censored data. </title> <journal> Cancer Letters, </journal> <volume> 77 </volume> <pages> 127-138. </pages>
Reference: <author> Hart, P. </author> <year> (1967). </year> <title> The condensed nearest neighbor rule. </title> <journal> Transactions on Information Theory, IT-14:515-516. </journal>
Reference: <author> John, G. H., Kohavi, R., and Pfleger, K. </author> <year> (1994). </year> <title> Irrelevant features and the subset selection problem. </title> <booktitle> In Proceedings of the 11th International Conference on Machine Learning, </booktitle> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Setting missing values to the mean is a common practice which is particularly appropriate here. Since we are building linear models, a missing value has no effect on the prediction for that case. Our approach is similar to John et al. <ref> (John et al., 1994) </ref> in that we employ a "wrapper model", incorporating the selection of features and evaluation of the resulting subset into the learning algorithm itself.
Reference: <author> Kaplan, E. L. and Meier, P. </author> <year> (1958). </year> <title> Nonparametric estimation from incomplete observations. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 53 </volume> <pages> 457-481. </pages>
Reference-contexts: The actual recurrence probabilities of these three groups were then constructed with the Kaplan-Meier <ref> (Kaplan and Meier, 1958) </ref> approximation, as shown in Figure 2. RSA predicted TTR. This plot clearly shows that the RSA predictions for these cases was consistent with the actual prognosis.
Reference: <author> Kissin, M. W., Querci della Rovere, G., Easton, D., and Westbury, G. </author> <year> (1986). </year> <title> Risk of lymphoedema following the treatment of breast cancer. </title> <journal> British Journal of Surgery, </journal> <volume> 73 </volume> <pages> 580-584. </pages>
Reference: <author> Kittler, J. </author> <year> (1986). </year> <title> Feature selection and extraction. In Fu, </title> <editor> Y. ., editor, </editor> <booktitle> Handbook of Pattern Recognition and Image Processing. </booktitle> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Lachenbruch, P. and Mickey, P. </author> <year> (1968). </year> <title> Estimation of error rates in discriminant analysis. </title> <journal> Technometrics, </journal> <volume> 10 </volume> <pages> 1-11. </pages>
Reference-contexts: This left 187 cases, 44 of which have recurred. The RSA procedure was tested with leave-one-out testing <ref> (Lachenbruch and Mickey, 1968) </ref> to evaluate its accuracy in predicting future outcomes. Table 1 shows the mean generalization errors of the RSA formulation compared with the following prediction methods: * Pooled RSA: All of the feature examples were weighted equally in the objective.
Reference: <author> Lang, K., Waibel, A., and Hinton, G. </author> <year> (1990). </year> <title> A time-delay neural network architecture for isolated word recognition. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 23-43. </pages>
Reference-contexts: The feature-selection procedure is a variation of the heuristic sequential backward elimination method (Kittler, 1986; Marill and Green, 1963), a top-down, greedy search through the space of feature sets. The procedure begins by setting aside a tuning or validation set <ref> (Lang et al., 1990) </ref>, that is, a surrogate testing set, in our case a randomly selected 20% of the training cases. The regular RSA procedure is then applied to the training set, finding the global minimum of the training objective using all the available features.
Reference: <author> Lee, E. T. </author> <year> (1992). </year> <title> Statistical Methods for Survival Data Analysis. </title> <publisher> John Wiley and Sons, </publisher> <address> New York. </address>
Reference: <author> Mangasarian, O. L. and Meyer, R. R. </author> <year> (1979). </year> <title> Nonlinear perturbation of linear programs. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 17 </volume> <pages> 745-752. </pages>
Reference-contexts: To reflect this, the v term in the objective is weighted by an appropriately small positive parameter ffi, forcing underestimated recurrent points closer to the surface. Based on a perturbation theorem <ref> (Mangasarian and Meyer, 1979) </ref>, for a sufficiently small positive ffi, that is 0 &lt; ffi ffi for some ffi, the objective minimizes the weighted term conditionally, i.e., of those possible variable values which minimize the first two terms of the objective, those values which minimize the third term are chosen.
Reference: <author> Mangasarian, O. L., Street, W. N., and Wolberg, W. H. </author> <year> (1994). </year> <title> Breast cancer diagnosis and prognosis via linear programming. </title> <type> Technical Report 94-10, </type> <institution> University of Wisconsin. </institution> <note> Operations Research, accepted. Available from ftp://ftp.cs.wisc.edu/math-prog/tech-reports/. </note>
Reference: <author> Marill, T. and Green, D. M. </author> <year> (1963). </year> <title> On the effectiveness of receptors in recognition systems. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 9 </volume> <pages> 11-17. </pages>
Reference: <author> Miller Jr., R. G. </author> <year> (1981). </year> <title> Survival Analysis. </title> <publisher> John Wiley and Sons, </publisher> <address> New York. </address>
Reference: <author> Mitze, M. </author> <year> (1992). </year> <type> Personal communication. </type>
Reference-contexts: This we attribute to the small amount of information available in an objectively graded, three-valued feature. 2.4.2 Gutenberg Data We also evaluated the RSA procedure on a third data set from the group at Gutenberg, Germany <ref> (Mitze, 1992) </ref>.
Reference: <author> Murtagh, B. and Saunders, M. </author> <year> (1983). </year> <title> MINOS 5.0 user's guide. </title> <type> Technical Report SOL 83.20, </type> <institution> Stanford University. </institution> <note> MINOS 5.4 Release Notes, </note> <month> December </month> <year> 1992. </year>
Reference-contexts: The objective averages the errors over their respective classes. (Note: e is a vector of 1's of appropriate dimension.) The linear program is implemented using the MINOS numerical optimization software <ref> (Murtagh and Saun-ders, 1983) </ref>. Because recurrences take place at some unknown time prior to their detection, we do not consider underestimated recurrent points to be as serious of an error as overestimated ones.
Reference: <author> Ravdin, P. M. and Clark, G. M. </author> <year> (1992). </year> <title> A practical application of neural network analysis for predicting outcome of individual breast cancer patients. </title> <journal> Breast Cancer Research and Treatment, </journal> <volume> 22 </volume> <pages> 285-293. </pages>
Reference: <author> Ravdin, P. M., Tandon, A. K., Allred, D. C., Clark, G. M., Fuqua, S. A. W., Hilsenbeck, S. H., Chamness, G. C., and Osborne, C. K. </author> <year> (1994). </year> <title> Cathepsin D by western blotting and immunohistochemistry: Failure to confirm correlations with prognosis in node-negative breast cancer. </title> <journal> Journal of Clinical Oncology, </journal> <volume> 12 </volume> <pages> 467-474. </pages>
Reference: <author> Rumelhart, D. E., Hinton, G. E., and Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E. and McClelland, J. L., editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 1, chapter 8. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: In this work we are concerned specifically with prognosis, that is, predicting the course of a disease. This paper introduces a new prognosis prediction method, based on linear programming (Dantzig, 1963), which can be implemented using a backpropagation neural networks <ref> (Rumelhart et al., 1986) </ref> based on the same objective. These methods are applied to breast cancer prognosis, predicting how long after surgery we can expect the disease to recur. <p> So far only linear models have been employed by the RSA method, which limits its representational power. We therefore plan to modify backpropagation artificial neural networks (ANN's) <ref> (Rumelhart et al., 1986) </ref> to predict recurrence time in the same manner as the RSA procedure. The output node of the network will use the identity function as its transfer function, so that it can learn any floating point number.
Reference: <author> Schenone, A., Andreucci, L., Sanguinetti, V., and Morasso, P. </author> <year> (1993). </year> <title> Neural networks for prognosis in breast cancer. </title> <journal> Physica Medica, </journal> <volume> IX(Supplement </volume> 1):175-178. 
Reference-contexts: Problems involving censored data are common to several fields. In engineering, one might be interested in the survival characteristics of electronic components, while sociologists might consider what factors lead to long-lasting marriages. However, the application of machine learning methods to these problems has been rare. Schenone et al. <ref> (Schenone et al., 1993) </ref> used a self-organizing neural network to find classes of cases with similar expected recurrence times. However, they did not directly address the problem of using censored data, that is, cases which have not been followed to recurrence / death.
Reference: <author> Street, W. N. </author> <year> (1994). </year> <title> Cancer Diagnosis and Prognosis via Linear-Programming-Based Machine Learning. </title> <type> PhD thesis, </type> <institution> University of Wisconsin-Madison. </institution> <note> Available as University of Wisconsin Mathematical Programming TR 94-14 from ftp://ftp.cs.wisc.edu/math-prog/tech-reports/. </note>
Reference: <author> Street, W. N., Wolberg, W. H., and Mangasarian, O. L. </author> <year> (1993). </year> <title> Nuclear feature extraction for breast tumor diagnosis. </title> <booktitle> In IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, </booktitle> <pages> pages 861-870, </pages> <address> San Jose, Cali-fornia. </address>
Reference: <author> Wolberg, W. H., Bennett, K. P., and Mangasarian, O. L. </author> <year> (1992). </year> <title> Breast cancer diagnosis and prognostic determination from cell analysis. </title> <type> Manuscript, </type> <institution> Departments of Surgery and Human Oncology and Computer Sciences, University of Wisconsin. </institution>
Reference: <author> Wolberg, W. H., Street, W. N., Heisey, D. H., and Mangasarian, O. L. </author> <year> (1995). </year> <title> Computer-derived nuclear grade and breast cancer prognosis. Analytical and Quantitative Cytology and Histology. </title> <note> accepted. </note>
Reference: <author> Wolberg, W. H., Street, W. N., Heisey, D. H., and Mangasarian, O. L. </author> <title> (accepted). Computer-derived nuclear features distinguish malignant from benign breast cytology. Human Pathology. </title>
Reference: <author> Wolberg, W. H., Street, W. N., and Mangasarian, O. L. </author> <year> (1993). </year> <title> Breast cytology diagnosis via digital image analysis. </title> <journal> Analytical and Quantitative Cytology and Histology, </journal> <volume> 15(6) </volume> <pages> 396-404. </pages>
Reference: <author> Wolberg, W. H., Street, W. N., and Mangasarian, O. L. </author> <year> (1994). </year> <title> Machine learning techniques to diagnose breast cancer from image-processed nuclear features of fine needle aspirates. </title> <journal> Cancer Letters, </journal> <volume> 77 </volume> <pages> 163-171. </pages>
References-found: 32

