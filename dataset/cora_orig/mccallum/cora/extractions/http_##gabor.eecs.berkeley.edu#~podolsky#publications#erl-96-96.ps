URL: http://gabor.eecs.berkeley.edu/~podolsky/publications/erl-96-96.ps
Refering-URL: http://www.cs.berkeley.edu/~chema/papers/WEC/references.html
Root-URL: http://www.cs.berkeley.edu
Title: A Study of Speech/Audio Coding on Packet Switched Networks  
Author: by Matthew George Podolsky 
Degree: Submitted in partial fulfillment of the requirements for the degree of Master of Science, Plan II in Electrical Engineering and Computer Sciences in the GRADUATE DIVISION of the  Committee in charge: Professor  Advisor Professor Steven McCanne  
Date: December 1996  
Affiliation: Research Project  UNIVERSITY of CALIFORNIA at BERKELEY  Martin Vetterli, Research  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Albanese, J. Blomer, J. Edmonds, and M. Luby. </author> <title> Priority encoding transmission. </title> <type> Technical Report TR-94-039, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <month> August </month> <year> 1994. </year> <note> Available on-line 1 </note> . 
Reference-contexts: Even without such a service, layered transmission is still possible. For example, the Priority Encoding Transmission (PET) system uses a multilevel forward-error-correction scheme to provide varying degrees of protection to priority-encoded data <ref> [1] </ref>. By segmenting the transmission data, as a layered coder automatically does, one can use PET to provide different degrees of packet protection to the different data segments. Another use for a layered encoding over the Internet is the receiver-driven layered multicast (RLM). <p> The current Internet is not capable of providing different qualities of service. If we wish to take advantage of the benefits priority transmission can provide, we should explore the application of techniques like Priority Encoding Transmission <ref> [1] </ref> to the transmission of layered audio over the Internet. Finally, the impact of f i and L P on end-to-end delay should be taken into account. 37 A minimal value restriction could be placed on f i so that there is an upper bound on the packetization delay.
Reference: [2] <author> K. Brandenburg and G. Stoll. </author> <title> ISO-MPEG-1 audio: A generic standard for coding of high-quality digital audio. </title> <journal> J. Audio Engr. Soc., </journal> <volume> 42(10) </volume> <pages> 780-92, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Various coders also exist for encoding general audio. The MUSICAM (Masking-pattern Universal Subband Integrated Coding and Multiplexing) audio coder used in the MPEG-I video standard is a high-quality, high-complexity coder that can provide near-CD quality sound <ref> [2, 18] </ref>. This coder is widely used for real-time audio transmissions in digital satellite systems, which use a transmission medium significantly different than the Internet. Existing audio coders are typically adapted for Internet transmission by simply pack-etizing the data produced by encoders.
Reference: [3] <author> P. J. Burt and E. H. Adelson. </author> <title> The Laplacian pyramid as a compact image code. </title> <journal> IEEE Trans. Comm., </journal> <volume> 31(4) </volume> <pages> 532-540, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: Finally, future directions to for improving and implementing a pyramid coding scheme are discussed in Section 2.6. 2.1 Background and Motivation Pyramid coding is a technique that is frequently employed in image coding and computer vision. First introduced by Burt and Adelson <ref> [3] </ref>, pyramid coding consists of an encoder which derives a "coarse" low-resolution version of a signal, predicts the original signal based on that coarse signal, and then takes the difference between the prediction and the original.
Reference: [4] <author> P. Clarkson. </author> <title> Optimal and Adaptive Signal Processing. </title> <publisher> CRC Press, </publisher> <address> Boca Raton, FL, </address> <year> 1993. </year>
Reference-contexts: For each layer, the quantization range is chosen so that no input level overloads the quantizer. Abbreviated "Max". * 4- quantizers. The overload regions are determined according to the common "4-" rule, which states that the quantization range should be chosen so that input levels in the range <ref> [4; 4] </ref> do not overload the quantizer, where refers to the input variance. Abbreviated "4-s". * Automatic- scaling quantizers. These quantizers use a simple heuristic to determine the overload region according to not only but also b i , the number of quantization bits used for Layer i. <p> In the diagram, the coefficients p k of P (z) have already been determined via an LPC analysis technique such as the Levinson or Durbin algorithm <ref> [4] </ref>. Such a system can be used to whiten the error signal, e (n), so that e (n) has lower power than x (n) and is thus better suited for quantization. If there is no quantization of e (n), perfect reconstruction is achieved.
Reference: [5] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley & Sons, </publisher> <year> 1991. </year>
Reference-contexts: The channel of interest is a packet switched, priority network. The separation principle states that the source and channel codings can be performed independently, but it holds only for a set of idealized circumstances <ref> [5] </ref> which are violated in the networks of interest. Therefore, we should be able to improve performance by employing joint source/channel coding design techniques. We have already taken the priority-transmission characteristics of the channel characteristics into account by choosing a layered, redundant-expansion coding scheme.
Reference: [6] <author> ETSI/GSM. </author> <title> GSM full rate transcoding. </title> <booktitle> In GSM 06.10, </booktitle> <month> July </month> <year> 1989. </year>
Reference-contexts: To date, we have studied only linear predictive coding as a transform technique. It is discussed in the following section. Linear Predictive Coding Linear predictive coding is a transform-coding technique employed in many standard speech coding algorithms, such as GSM <ref> [6] </ref> and LPC-10 [23]. A p th -order LPC analysis predicts the current sample of a signal x based on p previous ones.
Reference: [7] <author> M. Garrett. </author> <title> Contributions Toward Real-Time Services on Packet Switched Networks. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Specifically, our simulation determined the packet-loss rates for the three-layer, priority-encoded bit stream produced by the pyramid coder described in the previous chapter. Section 3.1 describes the source description we used to model the generation of network traffic, which is based on the model used in <ref> [7] </ref>. The queuing mechanism and loss discipline of our network model are explained in Section 3.2. In Section 3.3 we discuss the simulations of our source/network model and the data that resulted. <p> This leads to the Markov chain shown in Figure 3.2, which describes the total number of active sources. This Markov chain has often been used to model a group of packet voice sources with silence suppression <ref> [7, 12] </ref>. Note that we implicitly assume that our speech sources utilize silence suppression. To deal with continuous audio, a different model should be used. <p> Packets thus retain their order not only within each priority but across priorities as well. This scheme was chosen in contrast to the multiple-queue system explored in <ref> [7] </ref>, which|for a three priority system|employs priority service of three separate queues and a packet timeout loss mechanism. For purposes of comparison, we also simulated a network system which ignored packet priorities and simply dropped a packet at random when the queue filled up. <p> We assume a silence suppression scheme at the source and a uniform distribution p x , which is a good approximation for companded voice samples during periods of speaker activity <ref> [7] </ref>. We calculate the source power as: J s = x 1 2 b1 x=(2 b1 1) 2 2b + 6 Lost packets correspond to either partial or total losses of data.
Reference: [8] <author> A. Gersho and R. M. Gray. </author> <title> Vector Quantization and Signal Compression. </title> <publisher> Kluwer Acad. Pub., </publisher> <address> Boston, MA, </address> <year> 1992. </year>
Reference-contexts: Unlike other schemes, the quantizers used in pyramid coding cannot be designed independently to achieve minimum distortion. Consequently, quantizer design methods such as the Lloyd-Max algorithm <ref> [8] </ref> cannot be easily employed. The choice of a quantizer at layer L will affect the prediction ^x p L1 , and thus in turn the difference signal x d L1 , which is then quantized by Q L1 .
Reference: [9] <author> G. Grimmett and D. Stirzaker. </author> <title> Probability and Random Processes. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> 2nd edition, </address> <year> 1992. </year>
Reference-contexts: Section 3.4 describes methods to improve our model and simulation. 3.1 Source Model To simulate the source traffic of the network, we chose a system which features a variable total-rate source model. Individual sources are modeled as simple birth-death processes <ref> [9] </ref>, illustrated in Figure 3.1. 29 In this model, each source has exponentially distributed alternating periods of activity and inactivity with average durations of 1= and 1=, respectively.
Reference: [10] <author> V. Hardman, M. A. Sasse, M. Handley, and A. Watson. </author> <title> Reliable audio for use over the Internet. </title> <booktitle> In Proc. </booktitle> <address> INET'95, </address> <year> 1995. </year> <note> Proceedings 2 and paper 3 available on-line. 1 ftp://ftp.icsi.berkeley.edu/pub/techreports/1994/tr-94-039.ps.Z 2 http://info.isoc.org/HMP/index.html 3 http://www-mice.cs.ucl.ac.uk/mice/publications/inet95 paper/ 54 </note>
Reference-contexts: This substitution is commonly silence, synthetic noise, a repetition of the audio from the last received packet, or an 4 interpolation of known samples (see <ref> [10] </ref> or [11] for a discussion of receiver-only techniques). Though these latter methods reduce the degradation in audio quality as compared to silence substitution, they are still limited by the lack of any information about the missing packet. <p> One way of achieving this is to send extra information about one frame's audio data together with a nearby frame's data to help the receiver decode a missing packet. Hardman et al. <ref> [10] </ref> used this redundancy-based approach in the Robust-Audio Tool (RAT). Their scheme starts with frames consisting of either 64 Kbps raw data (PCM) or 32 Kbps encoded data (ADPCM).
Reference: [11] <author> V. Hardman, M. A. Sasse, and A. Watson. </author> <title> Successful voice reconstruction for packet networks using redundancy. Research Note, </title> <institution> Dept. of Computer Science, University College of London, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: This substitution is commonly silence, synthetic noise, a repetition of the audio from the last received packet, or an 4 interpolation of known samples (see [10] or <ref> [11] </ref> for a discussion of receiver-only techniques). Though these latter methods reduce the degradation in audio quality as compared to silence substitution, they are still limited by the lack of any information about the missing packet.
Reference: [12] <author> S.-Q. Li. </author> <title> A new performance measurement for packet voice transmission in burst and packet switching. </title> <journal> IEEE Trans. Comm., </journal> <volume> 35(10) </volume> <pages> 1083-94, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: This leads to the Markov chain shown in Figure 3.2, which describes the total number of active sources. This Markov chain has often been used to model a group of packet voice sources with silence suppression <ref> [7, 12] </ref>. Note that we implicitly assume that our speech sources utilize silence suppression. To deal with continuous audio, a different model should be used.
Reference: [13] <author> S. McCanne and S. Floyd. </author> <title> The LBNL Network Simulator. </title> <institution> Lawrence Berkeley Laboratory. </institution> <note> Software on-line 4 </note> . 
Reference-contexts: L = E [k] E [N ac ] : (3.7) Section 3.3 will show that the above is an excellent approximation. 3.3 Network Simulation and Results 3.3.1 Description of the Simulation The source and network models described in the preceding sections were combined and simulated using the software tool ns <ref> [13] </ref>. This is an event-driven, packet-level simulator embedded in the Tool Command Language, Tcl [16]. To simulate the priority queue, a new ns link object was created that implements the priority drop-tail queue behavior described in Section 3.2.
Reference: [14] <author> S. McCanne and V. Jacobson. </author> <title> The LBNL Visual Audio Tool. </title> <institution> Lawrence Berkeley Laboratory. </institution> <note> Software on-line 5 </note> . 
Reference-contexts: Many traditional coders have been adapted and implemented in Internet audio tools. For example, the "visual audio tool" vat supports standard coders such as the European cellular phone standard GSM, Linear Predictive Coding (LPC), and Adaptive Differential Pulse Code Modulation (ADPCM) <ref> [14] </ref>. These coders all use fixed-rate digital speech algorithms that were previously designed without the Internet in mind. Various coders also exist for encoding general audio.
Reference: [15] <author> S. McCanne, V. Jacobson, and M. Vetterli. </author> <title> Receiver-driven layered multicast. </title> <booktitle> In Proc. ACM SIGCOMM '96, </booktitle> <pages> pages 26-30, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: We could also explore the transmission of layered audio over the MBone via different multicast groups. Using the framework for layered multicast transmission described in <ref> [15] </ref>, we can allow receiver-based adaptation to local-network conditions by transmitting the audio layers across different multicast groups. Receivers can then adapt to network conditions by subscribing to as many groups as their local network's capacity allows. The current Internet is not capable of providing different qualities of service.
Reference: [16] <author> J. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: This is an event-driven, packet-level simulator embedded in the Tool Command Language, Tcl <ref> [16] </ref>. To simulate the priority queue, a new ns link object was created that implements the priority drop-tail queue behavior described in Section 3.2.
Reference: [17] <author> K. K. Paliwal and B. S. Atal. </author> <title> Efficient vector quantization of LPC parameters at 24 bits/frame. </title> <journal> IEEE Trans. Speech Audio Proc., </journal> <volume> 1(1) </volume> <pages> 3-14, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Note that in computing the rate for the LPC curve we did not take into account the added rate of transmitting the filter coefficients every frame. However, given the small number of coefficients, long frame length, and extensive existing research on efficient quantization of LPC parameters (see [26] or <ref> [17] </ref> for examples), we felt any additional rate overhead was negligible. 2.4.4 Entropy Coding We explored the effect of adding entropy coding to the quantizers by calculating the zero-order entropy of the quantized signals, and then substituting this entropy for b i in Equation 2.5 to recalculate the rate of a
Reference: [18] <author> D. Pan. </author> <title> An overview of the MPEG/audio compression algorithm. </title> <booktitle> Proc. SPIE, </booktitle> <volume> 2187 </volume> <pages> 260-73, </pages> <year> 1994. </year>
Reference-contexts: Various coders also exist for encoding general audio. The MUSICAM (Masking-pattern Universal Subband Integrated Coding and Multiplexing) audio coder used in the MPEG-I video standard is a high-quality, high-complexity coder that can provide near-CD quality sound <ref> [2, 18] </ref>. This coder is widely used for real-time audio transmissions in digital satellite systems, which use a transmission medium significantly different than the Internet. Existing audio coders are typically adapted for Internet transmission by simply pack-etizing the data produced by encoders.
Reference: [19] <author> K. Petty and N. McKeown. Xdistribute: </author> <title> A process distribution system. </title> <type> Technical Report M96/67, </type> <institution> UC-Berkeley/ERL, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: We thus ended up with a total of 2 fi 8 fi 81 = 1296 simulations. To run these in a reasonable amount of time, the Xdistribute <ref> [19] </ref> program was used to distribute individual ns simulations across a large number of workstations. Table 3.2 compares the theoretical and experimental average packet loss rates for the random-drop case. Theoretical loss rates were calculated using Equation 3.7.
Reference: [20] <author> S. Quackenbush, T. Barnwell III, and M. Clements. </author> <title> Objective Measures of Speech Quality. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: Other objective error measures were considered, including spectral distance, variations of SNR (such as segmental 11 SNR, granular segmental SNR, and frequency weighted segmental SNR), and the Speech Transmission Index. These were rejected due to their higher complexity <ref> [20] </ref>. "Segmental SNR" measures the SNR over short segments of long audio signal, and sums all constituent segments: SEG SNR = M m=0 P N m+N 1 P Nm+N1 ! N is the segment length and M is the number of segments in the signal. <p> It is not inherently much more complex than the classical SNR, but it suffers from the problem that if there are intervals of silence where the signal is of very low level, even a small amount of noise will produce a large negative SNR in that interval <ref> [20] </ref>. To effectively use segmental SNR one needs to identify silent segments and exclude them from the measurement, which leads to a more complex calculation. <p> SNR measures are appropriate only for coding systems that reproduce an estimate of the input signal such that the original and estimate signals can be time aligned and the noise can be accurately calculated <ref> [20] </ref>. Model-based LPC techniques generally fail to align their estimate with the original input. Furthermore, most existing LPC algorithms have been designed for a single input sampling rate; parameters such as the filter order p may not be appropriate or optimal for other rates.
Reference: [21] <author> L. Rabiner and R. Schafer. </author> <title> Digital Processing of Speech Signals. </title> <publisher> Prentice-Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1978. </year>
Reference-contexts: If there is no quantization of e (n), perfect reconstruction is achieved. Most speech coders use LPC for more than simply whitening a speech signal. Instead, they rely on the common speech production model <ref> [21] </ref> which represents the composite 20 A (z) 1 P (z)P (z) ^x 6 6 ...................................................................................................................... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <p> The LPC analysis to determine the coefficients was implemented using the autocorrelation method 21 <ref> [21] </ref>. For this framework, A (z) acts as the time-varying transform block T shown in Figure 2.2, and A (z) 1 is the time-varying inverse transform T 1 .
Reference: [22] <author> K. Ramchandran, A. Ortega, and M. Vetterli. </author> <title> Bit allocation for dependent quantization with applications to multiresolution and MPEG video coders. </title> <journal> IEEE Trans. Image Proc., </journal> <volume> 3(5) </volume> <pages> 533-545, </pages> <month> September </month> <year> 1994. </year> <note> 4 http://www-nrg.ee.lbl.gov/ns/ 5 http://www-nrg.ee.lbl.gov/vat/ 55 </note>
Reference-contexts: A discussion of more efficient ways to select dependent quantizers in a pyramid coding setting can be found in <ref> [22] </ref>. Uniform Quantizers Studied We studied three different types of symmetric uniform midrise quantizers, each employing different methods of determining the maximum range of input values that can be quantized without overload. <p> The next logical step would be to try to design Lloyd-Max quantizers, or closer approximations to them than the various uniform quantizers we used. We could do this via an exhaustive search, or by applying some of the techniques explained in <ref> [22] </ref>. A better distortion measurement should also produce a real-world gain in performance. One place to start would be implementing segmental SNR with a threshold to ignore silent regions.
Reference: [23] <author> T. Tremain. </author> <title> The government standard linear predictive coding algorithm: </title> <booktitle> LPC-10. Speech Technology, </booktitle> <pages> pages 40-49, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: To date, we have studied only linear predictive coding as a transform technique. It is discussed in the following section. Linear Predictive Coding Linear predictive coding is a transform-coding technique employed in many standard speech coding algorithms, such as GSM [6] and LPC-10 <ref> [23] </ref>. A p th -order LPC analysis predicts the current sample of a signal x based on p previous ones.
Reference: [24] <author> J. Tribolet, P. Noll, B. McDermott, and R. Crochiere. </author> <title> A study of complexity and quality of speech waveform coders. </title> <booktitle> In Proc. IEEE Int. Conf. Acoust., Speech, and Signal Proc., </booktitle> <pages> pages 586-90, </pages> <address> Tulsa, OK, </address> <month> April </month> <year> 1978. </year>
Reference-contexts: Consequently, it is well suited when a large number of experimental trials are performed. Unfortunately, it is a poor estimator of subjective quality for a broad range of distortions <ref> [24] </ref>. For example, substituting white noise instead of silence for the audio of a lost packet will almost certainly increase the error MSE, but the result can sound far better to human listeners [27].
Reference: [25] <author> M. Vetterli and J. Kovacevic. </author> <title> Wavelets and Subband Coding. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: Unlike subband coding, where filters must meet strict orthogonality or bi-orthogonality conditions to achieve perfect reconstruction, operators in pyramid coding can be linear or non-linear filters, median filters, etc. In practice they are typically zero-phase FIR anti-aliasing and interpolation filters <ref> [25] </ref>, but as long as the same interpolation operator is used at the encoder and decoder, perfect reconstruction can be achieved in the absence of quantization. <p> The multiplicative increase in rate of this oversampled representation is given below for an L-layer pyramid coder operating on N dimensional signals <ref> [25] </ref>: s = i=0 1 i 2 N : (2.2) Though this added overhead quickly decreases as the number of dimensions increases, our interest lies in one-dimensional audio signals, for which the above factor translates to a total rate 50-100% greater than the original. <p> For example, we could use a 32-band analysis as in MUSICAM to determine what bands contain the most critical information. We could then determine the 16 contiguous bands (taking up half of the input spectrum) containing the most information, and use a cosine-modulated filter <ref> [25] </ref> for D 0 (the decimation filter between Layers 0 and 1) to extract this portion of the spectrum and form c 1 .
Reference: [26] <author> R. Viswanathan and J. Makhoul. </author> <title> Quantization properties of transmission parameters in linear predictive systems. </title> <journal> IEEE Trans. Acoust. Speech Signal Proc., </journal> <volume> 23(3) </volume> <pages> 309-321, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: Note that in computing the rate for the LPC curve we did not take into account the added rate of transmitting the filter coefficients every frame. However, given the small number of coefficients, long frame length, and extensive existing research on efficient quantization of LPC parameters (see <ref> [26] </ref> or [17] for examples), we felt any additional rate overhead was negligible. 2.4.4 Entropy Coding We explored the effect of adding entropy coding to the quantizers by calculating the zero-order entropy of the quantized signals, and then substituting this entropy for b i in Equation 2.5 to recalculate the rate
Reference: [27] <author> R. Warren. </author> <title> Auditory Perception: A New Synthesis. </title> <publisher> Pergamon Press, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference-contexts: Unfortunately, it is a poor estimator of subjective quality for a broad range of distortions [24]. For example, substituting white noise instead of silence for the audio of a lost packet will almost certainly increase the error MSE, but the result can sound far better to human listeners <ref> [27] </ref>. Other objective error measures were considered, including spectral distance, variations of SNR (such as segmental 11 SNR, granular segmental SNR, and frequency weighted segmental SNR), and the Speech Transmission Index.
References-found: 27

