URL: http://www.cs.huji.ac.il/~feit/parsched/p-96-1.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~feit/parsched/parsched96.html
Root-URL: http://www.cs.huji.ac.il
Email: ffeit,rudolphg@cs.huji.ac.il  
Title: Toward Convergence in Job Schedulers for Parallel Supercomputers  
Author: Dror G. Feitelson and Larry Rudolph 
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science The Hebrew University,  
Abstract: The space of job schedulers for parallel supercomputers is rather fragmented, because different researchers tend to make different assumptions about the goals of the scheduler, the information that is available about the workload, and the operations that the scheduler may perform. We argue that by identifying these assumptions explicitly, it is possible to reach a level of convergence. For example, it is possible to unite most of the different assumptions into a common framework by associating a suitable cost function with the execution of each job. The cost function reflects knowledge about the job and the degree to which it fits the goals of the system. Given such cost functions, scheduling is done to maximize the system's profit.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> T. Agerwala, J. L. Martin, J. H. Mirza, D. C. Sadler, D. M. Dias, and M. Snir, </author> <title> "SP2 system architecture". </title> <journal> IBM Syst. J. </journal> <volume> 34(2), </volume> <pages> pp. 152-184, </pages> <year> 1995. </year>
Reference-contexts: It is especially common on large distributed memory machines [53,27,20,9,31]. The reason is that it gets the job done, albeit not optimally, but with relatively little investment in system development. In an industry where time-to-market is a crucial element of success, this is a true virtue <ref> [1] </ref>. As a result, users sometimes have to revert to signup sheets as the actual processor allocation mechanism. Because variable partitioning cannot run jobs immediately if the requested number of processors is not available, jobs often have to be queued.
Reference: 2. <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy, </author> <title> "Scheduler activations: effective kernel support for the user-level management of parallelism". </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 10(1), </volume> <pages> pp. 53-79, </pages> <month> Feb </month> <year> 1992. </year>
Reference-contexts: This research typically compares the cost of reconfiguration with the resulting improvement in overall performance. But such comparisons do not give a full picture. In many cases, changing the number of processors allocated to a job requires complex interactions between the operating system and the application's runtime system <ref> [2] </ref>. For example, if the thread running on a certain processor holds a lock and then the processor is taken away, there may be no way to free the lock. <p> When a job terminates, its processors are distributed among the other jobs, so as not to waste them [52,34,35]. A good implementation requires co-design of the operating system, the run-time system, and the programming environment <ref> [2] </ref>. Indeed, no production implementation for parallel machines have been reported so far, despite much research that shows the benefits of this approach in terms of efficiency.
Reference: 3. <author> J. M. Barton and N. Bitar, </author> <title> "A scalable multi-discipline, multiple-processor scheduling framework for IRIX". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 45-69, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: The only solution is to use gang scheduling. While gang scheduling and a shared queue seem to be in conflict with each other, a scheme that integrates both has been designed in the context of the IRIX operating system for SGI multiprocessor workstations <ref> [3] </ref>. Finally, it should be noted that this scheme benefits from similarity with runtime systems and thread packages that run within the confines of a single job. 5.4 Moldable Jobs and Adaptive Partitioning As noted above, variable partitioning is a simple but somewhat inefficient scheduling scheme.
Reference: 4. <author> P. Brinch Hansen, </author> <title> "An analysis of response ratio scheduling". </title> <booktitle> In IFIP Congress, Ljubljana, </booktitle> <pages> pp. </pages> <address> TA-3 150-154, </address> <month> Aug </month> <year> 1971. </year>
Reference-contexts: solution to this problem is to use the average slowdown as a metric instead, where slowdown is the ratio of the time it takes to run the job on a loaded system divided by the time it takes on a dedicated system (this is sometimes also called the "response ratio" <ref> [4] </ref>). This normalizes all jobs to the same scale. Another problem with this metric is its linear regard to time. Actually response time should be measured as perceived by those who are interested, e.g. human users.
Reference: 5. <author> N. Carriero, E. Freedman, D. Gelernter, and D. Kaminsky, </author> <title> "Adaptive parallelism and Piranha". </title> <booktitle> Computer 28(1), </booktitle> <pages> pp. 40-49, </pages> <month> Jan </month> <year> 1995. </year>
Reference: 6. <author> M-S. Chen and K. G. Shin, </author> <title> "Subcube allocation and task migration in hypercube multiprocessors". </title> <journal> IEEE Trans. Comput. </journal> <volume> 39(9), </volume> <pages> pp. 1146-1155, </pages> <month> Sep </month> <year> 1990. </year>
Reference: 7. <author> S-H. Chiang and M. Vernon, </author> <title> "Dynamic vs. static quantum-based parallel processor allocation". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 8. <author> M. Crovella, P. Das, C. Dubnicki, T. LeBlanc, and E. Markatos, </author> <title> "Multiprogramming on multiprocessors". </title> <booktitle> In 3rd IEEE Symp. Parallel & Distributed Processing, </booktitle> <pages> pp. 590-597, </pages> <year> 1991. </year>
Reference: 9. <author> D. Das Sharma and D. K. Pradhan, </author> <title> "A fast and efficient strategy for submesh allocation in mesh-connected parallel computers". </title> <booktitle> In IEEE Symp. Parallel & Distributed Processing, </booktitle> <pages> pp. 682-689, </pages> <month> Dec </month> <year> 1993. </year>
Reference: 10. <author> M. Devarakonda and A. Mukherjee, </author> <title> "Issues in implementation of cache-affinity scheduling". </title> <booktitle> In Proc. Winter USENIX Technical Conf., </booktitle> <pages> pp. 345-357, </pages> <month> Jan </month> <year> 1992. </year>
Reference: 11. <author> J. Edler, A. Gottlieb, C. P. Kruskal, K. P. McAuliffe, L. Rudolph, M. Snir, P. J. Teller, and J. Wilson, </author> <title> "Issues related to MIMD shared-memory computers: the NYU Ultracomputer approach". </title> <booktitle> In 12th Ann. Intl. Symp. Computer Architecture Conf. Proc., </booktitle> <pages> pp. 126-135, </pages> <year> 1985. </year>
Reference-contexts: Indeed, this was one of the driving forces in the design of the NYU Ultracomputer, and its support for fetch-and-add via a combining multistage network <ref> [11] </ref>. However, the idea of combining network has not caught on because of their added complexity and design costs. Migration occurs in this scheme because processes are typically executed on a different processor each time they arrive at the head of the queue.
Reference: 12. <author> D. G. Feitelson, </author> <title> "Packing schemes for gang scheduling". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference-contexts: The main drawbacks cited are interference with cache state, and possible loss of resources to fragmentation. As the first can be lessened by using long time quanta [23], and recent research suggests that the second is not so severe <ref> [12] </ref>, it seems that the advantages of gang scheduling generally outweigh its drawbacks. However, there are still some unresolved issues. The main one concerns the possible interaction between gang scheduling and over-committing memory resources. Time slicing between two active jobs requires more memory that execut ing these jobs sequentially.
Reference: 13. <author> D. G. Feitelson, </author> <title> A Survey of Scheduling in Multiprogrammed Parallel Systems. </title> <type> Research Report RC 19790 (87657), </type> <institution> IBM T. J. Watson Research Center, </institution> <month> Oct </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Both theoreticians and practitioners have been investigating and implementing various types of schedulers, and analyzing their performance over a wide range of workloads, leading to a large and varied body of knowledge <ref> [13] </ref>. However, many of the assumptions as to the type of workload and the goals of the scheduler are incompatible. We argue that the best features can and should be combined. The following principles are common features of all scheduling systems: The scheduler services all jobs that are submitted.
Reference: 14. <author> D. G. Feitelson and B. Nitzberg, </author> <title> "Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 337-360, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: In any case, knowledge about application characteristics is typically required [46]. Programs written using the SPMD style, e.g. with the MPI library package, are often moldable. Moreover, workload traces from real parallel systems show that indeed the same application may run several times using different partition sizes <ref> [14] </ref>. 3.4 Malleable Jobs The most flexible type of jobs are malleable ones that can adapt to changes in the number of processors during execution. The main programming styles that permits this flexibility consists of many short independent tasks that access shared data in a very stylized way. <p> On the other hand, time slicing in general reduces the average response time provided the distribution of execution times has a large variance [40], which in fact it typically occurs <ref> [14] </ref>. 4.3 Migration Migration refers to the ability of a scheduler to move an executing job or some of its components to other processors. As such it is an extension of preemption: a task stops running on a certain processor, and it restarts on another processor.
Reference: 15. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Distributed hierarchical control for parallel processing". </title> <booktitle> Computer 23(5), </booktitle> <pages> pp. 65-77, </pages> <month> May </month> <year> 1990. </year>
Reference: 16. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Evaluation of design choices for gang scheduling using distributed hierarchical control". </title> <journal> J. Parallel & Distributed Comput., </journal> <note> 1996. to appear. </note>
Reference-contexts: Throughput has the same problem as utilization: by focusing on the average values, the system may undermine the primary goal. A parallel job mix may be difficult to schedule and can cause significant fragmentation <ref> [16] </ref>. For example, a 27 node job on a 32 node parallel machine leaves an awkward 5 nodes free.
Reference: 17. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Gang scheduling performance benefits for fine-grain synchronization". </title> <journal> J. Parallel & Distributed Comput. </journal> <volume> 16(4), </volume> <pages> pp. 306-318, </pages> <month> Dec </month> <year> 1992. </year>
Reference-contexts: Had the machine been dedicated to the job, this wasted time would not occur. Thus, a user might be charged more CPU time, just because the scheduler decided to execute several jobs in an uncoordinated fashion (a simple solution for this case is therefore to use gang scheduling <ref> [17] </ref>). 2.7 Issues That Are Often Ignored An important observation is that most simple metrics have simple failure modes in which they cause starvation for a class of jobs that do not promote the predefined metric. <p> The reason is that with gang scheduling all the processes of a given job execute simultaneously on different processors, thus supporting the use of fine-grain interactions <ref> [17] </ref>. An interesting observation is that it is desirable to also preempt the network, i.e. to flush any traffic that belongs to the job that is being de-scheduled, so as to present a clean slate to the new job [26].
Reference: 18. <author> D. G. Feitelson and L. Rudolph, </author> <title> "Parallel job scheduling: issues and approaches". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 1-18, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: Actually response time should be measured as perceived by those who are interested, e.g. human users. For humans, the difference between a response of 1ms and 100ms is immeasurable, but the difference between 1s and 100s is very annoying <ref> [18] </ref>. Finally, it should be noted that not all jobs require the same level of service in terms of response time. Interactive jobs require interactive response times, preferably of not more than a couple of seconds.
Reference: 19. <author> M. Frank, V. Lee, W. Lee, K. Mackenzie, and L. Rudolph, </author> <title> "An online scheduler respecting job cost functions for parallel processors". Manuscript in preperation, </title> <publisher> M.I.T. </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: In what follows, we consider various components of a cost function. Real cost functions are expected to be developed in close collaboration with management personnel of the supercomputer center in order to address policy. The development follows the ideas found elsewhere <ref> [19] </ref>. The Importance of a Job It may be decided that the amount of parallelism of a job is important. Suppose a job is executed on p processors. <p> Example of scheduling rigid and malleable jobs under different cost functions. (a) characteristics of the jobs in the workload. (b) possible schedules. One suggested function <ref> [19] </ref> is: (deadline response time)=Importance This makes sense once one recalls that our definition of importance is based on the total use of resources. The suggested function therefore scales the delay according to the resources used.
Reference: 20. <author> J. Gehring and F. Ramme, </author> <title> "Architecture-independent request-scheduling with tight waiting-time estimations". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 21. <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam, </author> <title> PVM 3 User's Guide and Reference Manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Again, the scheduler knows nothing about the job except for its current requirement for processors. Although such jobs are not common, there is much activity in the community to define a standard for dynamic processor requests. Such facilities already exist in the PVM interface <ref> [21] </ref>, and they are also in the process of being incorporated into the MPI-2 standard. The reason for the interest in this feature is that many parallel jobs are composed of multiple phases, and each phase has different characteristics. In particular, different phases may contain different degrees of parallelism.
Reference: 22. <author> B. Gorda and R. Wolski, </author> <title> "Time sharing massively parallel machines". </title> <booktitle> In Intl. Conf. Parallel Processing, </booktitle> <month> Aug </month> <year> 1995. </year>
Reference: 23. <author> A. Gupta, A. Tucker, and S. Urushibara, </author> <title> "The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications". </title> <booktitle> In SIGMETRICS Conf. Measurement & Modeling of Comput. Syst., </booktitle> <pages> pp. 120-132, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Gang scheduling suffers the overhead of context switching and corrupts cache state, but for a large enough time quantum these overheads can be made insignificant <ref> [23] </ref>. <p> The main drawbacks cited are interference with cache state, and possible loss of resources to fragmentation. As the first can be lessened by using long time quanta <ref> [23] </ref>, and recent research suggests that the second is not so severe [12], it seems that the advantages of gang scheduling generally outweigh its drawbacks. However, there are still some unresolved issues. The main one concerns the possible interaction between gang scheduling and over-committing memory resources.
Reference: 24. <author> R. L. Henderson, </author> <title> "Job scheduling under the portable batch system". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 279-294, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference: 25. <author> A. Hori et al., </author> <title> "Time space sharing scheduling and architectural support". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 92-105, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference: 26. <author> A. Hori, H. Tezuka, Y. Ishikawa, N. Soda, H. Konaka, and M. Maeda, </author> <title> "Implementation of gang-scheduling on workstation cluster". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference-contexts: An interesting observation is that it is desirable to also preempt the network, i.e. to flush any traffic that belongs to the job that is being de-scheduled, so as to present a clean slate to the new job <ref> [26] </ref>. Gang scheduling suffers the overhead of context switching and corrupts cache state, but for a large enough time quantum these overheads can be made insignificant [23].
Reference: 27. <author> S. Hotovy, </author> <title> "Workload evolution on the Cornell Theory Center IBM SP2". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 28. <author> N. Islam, A. Prodromidis, and M. Squillante, </author> <title> "Dynamic partitioning in different distributed-memory environments". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 29. <author> Y. A. Khalidi, J. Bernabeu, V. Matena, K. Shirriff, and M. Thadani, </author> <title> "Solaris MC: a Multi Computer OS". </title> <booktitle> In Proc. USENIX Conf., </booktitle> <month> Jan </month> <year> 1996. </year>
Reference-contexts: In some machines, the operating system provides a single system image. That is, it does not matter from which processor an action is executed, they are all identical. Shared Memory Parallel Processors (SMPs) often have this feature and it is also being explored in some distributed systems <ref> [29] </ref>. When there is no single system image, it is difficult to migrate tasks. The machine architecture may impose restrictions on the types of processor partitions available and the ability to share access to the communication substrate.
Reference: 30. <author> A. A. Khokhar, V. K. Prasanna, M. E. Shaaban, and C-L. Wang, </author> <title> "Heterogeneous computing: challenges and opportunities". </title> <booktitle> Computer 26(6), </booktitle> <pages> pp. 18-27, </pages> <month> Jun </month> <year> 1993. </year>
Reference: 31. <author> P. Krueger, T-H. Lai, and V. A. Dixit-Radiya, </author> <title> "Job scheduling is more important than processor allocation for hypercube computers". </title> <journal> IEEE Trans. Parallel & Distributed Syst. </journal> <volume> 5(5), </volume> <pages> pp. 488-497, </pages> <month> May </month> <year> 1994. </year>
Reference: 32. <author> D. Lifka, </author> <title> "The ANL/IBM SP scheduling system". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 295-303, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference: 33. <author> W. Liu, V. Lo, K. Windisch, and B. Nitzberg, </author> <title> "Non-contiguous processor allocation algorithms for distributed memory multicomputers". </title> <booktitle> In Supercomputing '94, </booktitle> <pages> pp. 227-236, </pages> <month> Nov </month> <year> 1994. </year>
Reference: 34. <author> C. McCann, R. Vaswani, and J. Zahorjan, </author> <title> "A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors". </title> <journal> ACM Trans. Comput. Syst. </journal> <volume> 11(2), </volume> <pages> pp. 146-178, </pages> <month> May </month> <year> 1993. </year>
Reference: 35. <author> C. McCann and J. Zahorjan, </author> <title> "Processor allocation policies for message passing parallel computers". </title> <booktitle> In SIGMETRICS Conf. Measurement & Modeling of Comput. Syst., </booktitle> <pages> pp. 19-32, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: One common heuristic for dynamic partitioning is to strive for equal sized partitions (usually called "equipartitioning") <ref> [35] </ref>. The problem with this approach is that it might require all jobs to be interrupted whenever something changes. An alternative is to use folding [35]. With folding, the number of processors allocated to a job can only grow or shrink by factors of 2. <p> One common heuristic for dynamic partitioning is to strive for equal sized partitions (usually called "equipartitioning") <ref> [35] </ref>. The problem with this approach is that it might require all jobs to be interrupted whenever something changes. An alternative is to use folding [35]. With folding, the number of processors allocated to a job can only grow or shrink by factors of 2. That is, the partition size may be halved or doubled.
Reference: 36. <author> T. D. Nguyen, R. Vaswani, and J. Zahorjan, </author> <title> "Parallel application characterization for multiprocessor scheduling policy design". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 37. <author> T. D. Nguyen, R. Vaswani, and J. Zahorjan, </author> <title> "Using runtime measured workload characteristics in parallel processor scheduling". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference-contexts: An interesting benefit of malleable jobs is that the option for changes can be used to allow the system to collect information about the job at runtime, by trying several configurations and checking the resulting performance. This information can later be used to guide allocation decisions <ref> [37] </ref>. This approach has obvious advantages over requiring the information to be available in advance, as is needed for moldable jobs. 4 Assumptions About Permissible Actions A scheduler must execute in the environment of an existing operating system and machine architecture.
Reference: 38. <author> J. K. Ousterhout, </author> <title> "Scheduling techniques for concurrent systems". </title> <booktitle> In 3rd Intl. Conf. Distributed Comput. Syst., </booktitle> <pages> pp. 22-30, </pages> <month> Oct </month> <year> 1982. </year>
Reference: 39. <author> J. D. Padhye and L. W. Dowdy, </author> <title> "Preemptive versus non-preemptive processor allocation policies for message passing parallel computers: an empirical comparison". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 40. <author> E. W. Parsons and K. C. Sevcik, </author> <title> "Multiprocessor scheduling for high-variability service time distributions". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 127-145, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: Gang scheduling suffers the overhead of context switching and corrupts cache state, but for a large enough time quantum these overheads can be made insignificant [23]. On the other hand, time slicing in general reduces the average response time provided the distribution of execution times has a large variance <ref> [40] </ref>, which in fact it typically occurs [14]. 4.3 Migration Migration refers to the ability of a scheduler to move an executing job or some of its components to other processors.
Reference: 41. <author> J. Peterson and A. Silberschatz, </author> <title> Operating System Concepts. </title> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: While there is some debate about the exact definition of "response time", most researchers use it as a synonym for "turnaround time," i.e. from job submittal 1 to job completion time, rather than the time till when the first output is produced <ref> [41] </ref>). One problem with the usual response time metric is its use of absolute values. Consider a job J a that responds in one day and another job J b that responds in one minuite.
Reference: 42. <author> J. Pruyne and M. Livny, </author> <title> "Managing checkpoints for parallel programs". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference-contexts: As such it is an extension of preemption: a task stops running on a certain processor, and it restarts on another processor. Reasons for migration include packing in order to reduce fragmentation [6,12], and the need to withdraw from a workstation when its owner returns <ref> [42] </ref>. Migration is simple on shared memory machines, because threads do not have any state that is local to the processor except for their cache and TLB footprints. The challenge is to ensure that interacting threads map to distinct processors.
Reference: 43. <author> J. Pruyne and M. Livny, </author> <title> "Parallel processing on dynamic resources with CARMI". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 259-278, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: For example, if all the tasks have no side effects, then to reduce the number of processors, some tasks are terminated and restarted later on the remaining processors <ref> [43] </ref>. It is fairly well accepted to call changing the number of processors at runtime "dynamic partitioning". We prefer to call the jobs "malleable" rather than "dynamic" because the term "dynamic" does not indicate who is doing the dynamic allocation.
Reference: 44. <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson, </author> <title> "Robust partitioning schemes of multiprocessor systems". </title> <booktitle> Performance Evaluation 19(2-3), </booktitle> <pages> pp. 141-165, </pages> <month> Mar </month> <year> 1994. </year>
Reference-contexts: But, given a range of choices, the scheduler can set the number of processors based on knowledge about the system load and competing jobs, knowledge that is typically not available to the user. This has been called "adaptive partitioning" in the literature <ref> [44] </ref>. A moldable job can be made to execute over a wide range of processors. There is often a minimum number of processors on which it can execute, and above that number, additional processors can be used to improve performance, up to some saturation point. <p> The scheduler then creates a partition of that size and schedules the job to execute within that partition [53,32,20,1,9,31,33]. With moldable jobs, it is the scheduler that selects the partition size <ref> [44] </ref>. Evolving and malleable jobs require partitions that are not only flexible but can also change dynamically at runtime.
Reference: 45. <author> E. Rosti, E. Smirni, G. Serazzi, and L. W. Dowdy, </author> <title> "Analysis of non-work-conserving processor partitioning policies". In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pp. 165-181, </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: It has also been suggested that the system keep some processors idle on the side in anticipation of additional arrivals <ref> [45] </ref>.
Reference: 46. <author> K. C. Sevcik, </author> <title> "Application scheduling and processor allocation in multipro-grammed parallel processing systems". </title> <booktitle> Performance Evaluation 19(2-3), </booktitle> <pages> pp. 107-140, </pages> <month> Mar </month> <year> 1994. </year>
Reference-contexts: But since the scheduler cares about maximizing some overall system performance properties, it might be best if the job is executed at another point. In any case, knowledge about application characteristics is typically required <ref> [46] </ref>. Programs written using the SPMD style, e.g. with the MPI library package, are often moldable.
Reference: 47. <author> K. C. Sevcik, </author> <title> "Characterization of parallelism in applications and their use in scheduling". </title> <booktitle> In SIGMETRICS Conf. Measurement & Modeling of Comput. Syst., </booktitle> <pages> pp. 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference: 48. <author> J. Skovira, W. Chan, H. Zhou, and D. Lifka, </author> <title> "The EASY - LoadLeveler API project". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 49. <author> M. S. Squillante and E. D. Lazowska, </author> <title> "Using processor-cache affinity information in shared-memory multiprocessor scheduling ". IEEE Trans. </title> <journal> Parallel & Distributed Syst. </journal> <volume> 4(2), </volume> <pages> pp. 131-143, </pages> <month> Feb </month> <year> 1993. </year>
Reference: 50. <author> S. Thakkar, P. Gifford, and G. Fielland, </author> <title> "Balance: a shared memory multiprocessor system". </title> <booktitle> In 2nd Intl. Conf. Supercomputing, </booktitle> <volume> vol. I, </volume> <pages> pp. 93-101, </pages> <year> 1987. </year>
Reference: 51. <author> J. Torrellas, A. Tucker, and A. Gupta, </author> <title> "Evaluating the performance of cache--affinity scheduling in shared-memory multiprocessors". </title> <journal> J. Parallel & Distributed Comput. </journal> <volume> 24(2), </volume> <pages> pp. 139-151, </pages> <month> Feb </month> <year> 1995. </year>
Reference-contexts: However, it is not clear to what degree data indeed remains in the cache, and in any case, affinity scheduling is largely equivalent to just using longer time quanta <ref> [51] </ref>. The third issue, lack of coordinated scheduling, may cause problems for applications where the processes interact with each other frequently. The only solution is to use gang scheduling.
Reference: 52. <author> A. Tucker and A. Gupta, </author> <title> "Process control and scheduling issues for multipro-grammed shared-memory multiprocessors". </title> <booktitle> In 12th Symp. Operating Systems Principles, </booktitle> <pages> pp. 159-166, </pages> <month> Dec </month> <year> 1989. </year>
Reference: 53. <author> M. Wan, R. Moore, G. Kremenek, and K. Steube, </author> <title> "A batch scheduler for the Intel Paragon MPP system with a non-contiguous node allocation algorithm". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 54. <author> F. Wang, M. Papaefthymiou, M. Squillante, L. Rudolph, P. Pattnaik, and H. Franke, </author> <title> "A gang scheduling design for multiprogrammed parallel computing environments". In Job Scheduling Strategies for Parallel Processing II, </title> <editor> D. G. Fei-telson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference: 55. <author> J. Zahorjan and C. McCann, </author> <title> "Processor scheduling in shared memory multiprocessors". </title> <booktitle> In SIGMETRICS Conf. Measurement & Modeling of Comput. Syst., </booktitle> <pages> pp. 214-225, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Also, this type of jobs is commonly modeled by task graphs with changing widths <ref> [55] </ref>. Fig. 2. (a) Rigid jobs define a rectangle in processor-time space. (b) Moldable jobs use one out of a choice of such rectangles. (c) Evolving and malleable jobs both have a profile with a changing number of processors.
References-found: 55

