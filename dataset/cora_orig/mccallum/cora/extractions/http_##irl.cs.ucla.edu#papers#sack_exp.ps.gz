URL: http://irl.cs.ucla.edu/papers/sack_exp.ps.gz
Refering-URL: http://irl.cs.ucla.edu/publications.f.html
Root-URL: http://www.cs.ucla.edu
Email: bruyeron@cs.ucla.edu, bruno@cs.ucla.edu  
Title: Experimentations with TCP Selective Acknowledgment  
Author: Renaud Bruyeron, Bruno Hemon Advisor Lixia Zhang 
Web: http://irl.cs.ucla.edu  
Affiliation: UCLA Internet Research Laboratory  
Abstract: 1 Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jong Suk Ahn, Peter B. Danzig, Zhen Liu, and Limin Yan. </author> <title> Evaluation of tcp vegas: Emulation and experiment. </title> <type> Technical report, </type> <institution> USC, </institution> <year> 1995. </year> <note> http://excalibur.usc.edu/research/vegas/doc/. </note>
Reference-contexts: How much the current Congestion Algorithms should be altered to benefit from Selective Acknowledgment is still an open research issue. Several modifications have been proposed already ([9], [2], <ref> [1] </ref>). The Congestion Algorithms in the implementation we used is described extensively in [3]. It features the pipe algorithm from Sally Floyd's NS code, and is basically an adaptation of TCP-Reno to the new capabilities of Sack. Therefore, it is considered fairly conservative.
Reference: [2] <author> Lawrence S. Brakmo, Sean W. O'Malley, and Larry L. Peterson. </author> <title> Tcp vegas: New techniques for congestion detection and avoidance. </title> <booktitle> Proceedings of ACM SIG-COMM '94, </booktitle> <pages> pages 24-35, </pages> <month> May </month> <year> 1994. </year> <month> ftp://ftp.cs.arizona.edu/xkernel/Papers/vegas.ps. </month>
Reference-contexts: How much the current Congestion Algorithms should be altered to benefit from Selective Acknowledgment is still an open research issue. Several modifications have been proposed already ([9], <ref> [2] </ref>, [1]). The Congestion Algorithms in the implementation we used is described extensively in [3]. It features the pipe algorithm from Sally Floyd's NS code, and is basically an adaptation of TCP-Reno to the new capabilities of Sack. Therefore, it is considered fairly conservative. <p> Therefore, it is considered fairly conservative. New Congestion algorithms that are more aggressive were proposed recently, most notably 1 http://www.psc.edu/networking/tcp.html 2 Renaud Bruyeron, Bruno Hemon Experimentations with TCP Sack Forward Acknowledgment in [9] (which is explicitly designed to work together with Sack) and TCP-Vegas in <ref> [2] </ref>. In this study, we focused exclusively on TCP-Sack with the Pipe algorithm from NS. 3.2 Testbed The testbed consisted of two PCs running FreeBSD 2.1.5 and an UltraSparc workstation running Solaris 2.5. The UltraSparc was used as a store-delay-and-forward box at the IP level.
Reference: [3] <author> Kevin Fall et al. </author> <title> Simulation-based comparisons of reno, tahoe, and sack tcp. </title> <journal> Computer communications Review, </journal> <month> July </month> <year> 1996. </year>
Reference-contexts: It has been proposed as an Internet standard in RFC 2018. In [4], Sally Floyd addressed several issues concerning TCP-Sack, principally the behavior and performance of TCP-Sack. In <ref> [3] </ref>, Kevin Fall and Sally Floyd uses simulation to compare the behavior of TCP-Tahoe, TCP-Reno and TCP-Sack. Our work on TCP-Sack can be considered as an extension of the work of Sally Floyd and Kevin Fall. <p> How much the current Congestion Algorithms should be altered to benefit from Selective Acknowledgment is still an open research issue. Several modifications have been proposed already ([9], [2], [1]). The Congestion Algorithms in the implementation we used is described extensively in <ref> [3] </ref>. It features the pipe algorithm from Sally Floyd's NS code, and is basically an adaptation of TCP-Reno to the new capabilities of Sack. Therefore, it is considered fairly conservative.
Reference: [4] <author> Sally Floyd. </author> <title> Issues of tcp with sack. </title> <type> Technical report, </type> <institution> LBL Network Group, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: Therefore, in most TCP-Sack implementations, the data recovery mechanism is started after 3 duplicate ACKs (as suggested in the RFC [8]). 2.2 Previous work TCP Sack was first described in RFC 1072. It has been proposed as an Internet standard in RFC 2018. In <ref> [4] </ref>, Sally Floyd addressed several issues concerning TCP-Sack, principally the behavior and performance of TCP-Sack. In [3], Kevin Fall and Sally Floyd uses simulation to compare the behavior of TCP-Tahoe, TCP-Reno and TCP-Sack.
Reference: [5] <author> Janey C. Hoe. </author> <title> Improving the start-up behavior of a congestion control scheme for tcp. </title> <booktitle> Proceedings of ACM SIGCOMM '96, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: With higher drop rates, the slow-start phase results in a better estimate of ssthresh. This problem has been described in <ref> [5] </ref>, and solutions to it are being reviewed. 5.5 Conclusions over long delay The key to high performance when facing high delay-bandwidth product links is the use of the wscale option. Being able to "fill the pipe" during the transfer is what really matters.
Reference: [6] <author> V. Jacobson, R. Braden, and D. </author> <title> Borman. Tcp extensions for high performance. </title> <type> Technical Report RFC 1323, </type> <institution> IETF, </institution> <year> 1992. </year>
Reference-contexts: This means that 4 holes in the window can be advertised in the Sack option. Practically, because of the increasing use of the timestamp Renaud Bruyeron, Bruno Hemon Experimentations with TCP Sack option described in <ref> [6] </ref>, the number of Sack blocks carried by each ACK is limited to 3. On the sender's side, the Sack options are used to build a table of all correctly received packets. Therefore, the sender knows exactly what are the lost packets. <p> the results we could get from a very simple testbed can be extended to a real and complex network. 5 Long delay links One primary goal of our project was to study the behavior of TCP-Sack over long delay links, when used together with the Window Scale option defined in <ref> [6] </ref>. Our focus was mainly on the 500ms range, since that is a typical value for a Geosynchronous satellite. We ran several experiments with different loss rates and different scenarios.
Reference: [7] <author> Van Jacobson. </author> <title> Congestion avoidance and control. </title> <booktitle> In Proceedings of SIGCOMM'88, </booktitle> <year> 1988. </year> <note> 24 Renaud Bruyeron, Bruno Hemon Experimentations with TCP Sack </note>
Reference: [8] <author> M. Mathis, J. Mahdavi, S. Floyd, and A. Ro-manow. </author> <title> Tcp selective acknowledgement options. </title> <type> Technical Report RFC 2018, </type> <institution> IETF, </institution> <year> 1996. </year>
Reference-contexts: Finally, we studied the negative impact of TCP-Sack on TCP-Reno. We ran experiments with multiple connections and studied how TCP-Reno behaved when competing against TCP-Sack. 2 Introduction 2.1 TCP-Sack The selective acknowledgment option is a new option of TCP, which is described in the RFC 2018 <ref> [8] </ref>. The purpose of this option is to make TCP a Selective Repeat transport protocol, instead of the current Go-back-N protocol which uses cumulative acknowledgments. This allows TCP to recover from multiple losses within the same window more quickly. <p> But it is still considered a duplicate ACK by the sender. Therefore, in most TCP-Sack implementations, the data recovery mechanism is started after 3 duplicate ACKs (as suggested in the RFC <ref> [8] </ref>). 2.2 Previous work TCP Sack was first described in RFC 1072. It has been proposed as an Internet standard in RFC 2018. In [4], Sally Floyd addressed several issues concerning TCP-Sack, principally the behavior and performance of TCP-Sack. <p> Therefore, we could have TCP connections with or without Sack at the same time on any host, without having to reboot the machine. Two aspects of the implementation must be considered: the Selective Acknowledgment processing and generation, which must be compliant with the specification <ref> [8] </ref>, and the Congestion Algorithms. How much the current Congestion Algorithms should be altered to benefit from Selective Acknowledgment is still an open research issue. Several modifications have been proposed already ([9], [2], [1]). The Congestion Algorithms in the implementation we used is described extensively in [3]. <p> These plots are very interesting in that they show the frequency of slow start during a conversation. We also hacked LBNL's tcpdump 2 to make it compliant with the new specifications of TCP-Sack described in <ref> [8] </ref>. To process the output of tcpdump, we used both Shawn Ostermann's tcptrace [11] and our own scripts written in the AWK language. 3.5 Tests on the real Internet In order to confirm the results from our testbed, we ran similar experiments on the real Internet. <p> We see in this case that TCP-Sack improved the throughput by 12%. Finally, if the loss probability is even greater (P=9%), both TCP-Reno and TCP-Sack have poor performance. The main reason is that, according to RFC 2018 <ref> [8] </ref>, TCP-Sack has to time-out when a re-transmitted packet is lost again. We can note too 6 Renaud Bruyeron, Bruno Hemon Experimentations with TCP Sack that TCP-Sack will have also to time-out if a lot of acknowledgments are lost.
Reference: [9] <author> M. Mathis and M. Mahdavi. </author> <title> Forward acknowledgment: Refining tcp congestion control. </title> <journal> Computer Communication Review, </journal> <volume> 26(4), </volume> <year> 1996. </year>
Reference-contexts: Therefore, it is considered fairly conservative. New Congestion algorithms that are more aggressive were proposed recently, most notably 1 http://www.psc.edu/networking/tcp.html 2 Renaud Bruyeron, Bruno Hemon Experimentations with TCP Sack Forward Acknowledgment in <ref> [9] </ref> (which is explicitly designed to work together with Sack) and TCP-Vegas in [2]. In this study, we focused exclusively on TCP-Sack with the Pipe algorithm from NS. 3.2 Testbed The testbed consisted of two PCs running FreeBSD 2.1.5 and an UltraSparc workstation running Solaris 2.5. <p> We believe that Sack should not be viewed as Congestion Control Algorithm, but solely as a Data Recovery algorithm. We believe that there is now room for improvements in the Congestion Control Algorithms, as illustrated in <ref> [9] </ref>. 8 Acknowledgements We would like to thank the following people for their help and support throughout this project: Lixia Zhang, our advisor, for her insight and support. All members of the UCLA's Internet Research Laboratory, and especially Scott Michel for his help in setting up the testbed. Elliot L.
Reference: [10] <author> M. Mathis, M. Mahdavi, J. Semke, and T. Ott. </author> <title> The macroscopic behaviour of the tcp congestion avoidance algorithm. </title> <journal> Computer Communications Review, </journal> <year> 1997. </year>
Reference-contexts: This case is of course extremely favorable to TCP-Sack. The time-sequence diagram is at figure 25. Throughput TCP-Reno 32 KB/s TCP-Sack 55 KB/s 5.3 Sack and Reno vs. Theoretical bandwidth Next, we focused on the link utilization. In <ref> [10] </ref>, Mathis et al. defined a macroscopic behavior of 16 Renaud Bruyeron, Bruno Hemon Experimentations with TCP Sack | Link: 500ms RTT, 2 Mb/s, 0.18% drop rate, burstiness 3 the congestion avoidance algorithm. <p> Therefore, reaching the optimum cwin (i.e the optimum throughput) takes a long time. This is why one can expect the link utilization to be low for long delay. We compared the performance of TCP-Sack and TCP-Reno against the model, and confirmed the conclusion of <ref> [10] </ref> that TCP-Sack is indeed closer to the ideal congestion behavior. We also focused on the throughput increase brought by TCP-Sack when the burstiness of the drops is higher than one. In this experiment, we set the link propagation delay to 250ms, that is a RTT of about 500ms. <p> We used large windows (256 KB) and artificial losses in troduced at the end points. For the model, we took C = 3 2 since the ACKs in our implementation are not delayed (see <ref> [10] </ref>). Drop Rates Sack Reno 0.05 73 % 69 % 0.15 88 % 70.5 % 0.2 76 % 62 % 0.4 90 % 66 % 0.8 86 % 68 % In figure 26, we show the performance of Sack and Reno compared to the throughput according to the model from [10]. <p> <ref> [10] </ref>). Drop Rates Sack Reno 0.05 73 % 69 % 0.15 88 % 70.5 % 0.2 76 % 62 % 0.4 90 % 66 % 0.8 86 % 68 % In figure 26, we show the performance of Sack and Reno compared to the throughput according to the model from [10]. 100% would mean that TCP achieved the best possible throughput using the Congestion Algorithm. The reason why Sack and Reno do not achieve 100 % is because of time-outs and because of the start-up phase. TCP-Sack is closer to the model because there are less time-outs. <p> We 23 Renaud Bruyeron, Bruno Hemon Experimentations with TCP Sack found that as a result, TCP-Sack slow-starts less often than TCP-Reno, and it is therefore closer to the ideal TCP Congestion Avoidance behavior <ref> [10] </ref>. The improvement in throughput between UCLA and the two test hosts at NASA's GSFC and PSC ranged between 15% and 45%. On the testbed (using virtual links and emulating a long-delay link), we had throughput improvements ranging from 10% to 120%, mainly depending on the congestion pattern.
Reference: [11] <author> Shawn Ostermann. TcpTrace, </author> <title> a Trace Analyser. </title> <address> http://jarok.cs.ohiou.edu/software/tcptrace. </address>
Reference-contexts: These plots are very interesting in that they show the frequency of slow start during a conversation. We also hacked LBNL's tcpdump 2 to make it compliant with the new specifications of TCP-Sack described in [8]. To process the output of tcpdump, we used both Shawn Ostermann's tcptrace <ref> [11] </ref> and our own scripts written in the AWK language. 3.5 Tests on the real Internet In order to confirm the results from our testbed, we ran similar experiments on the real Internet.
Reference: [12] <author> Luigi Rizzo. </author> <title> Issues on the implementation of selective acknowledgement for tcp. </title> <type> Technical report, </type> <institution> Universita di Pisa, </institution> <year> 1996. </year>
Reference: [13] <author> W. Stevens. </author> <title> Tcp slow start, congestion avoidance, fast retransmit, and fast recovery algorithms. RFC 2001, </title> <type> IETF, </type> <month> January </month> <year> 1997. </year> <month> 25 </month>
Reference-contexts: This allows TCP to recover from multiple losses within the same window more quickly. With the current TCP implementation (TCP-Reno), the sender can recover from an isolated packet loss, using the fast retransmit and fast recovery mechanisms <ref> [13] </ref>. But, when multiple packets are lost, the sender will time-out most of the time and enter a slow-start phase ([7],[13]). This slow-start, which reduces the window size to one, is particularly damageable to the performance of TCP. The Sack option appears in the SYN segments during the conversation setup.
References-found: 13

