URL: http://www.icsi.berkeley.edu/~amnon/Papers/dsl.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/~amnon/
Root-URL: http://www.icsi.berkeley.edu
Title: SL L  
Author: Roy Armoni Amnon Ta-Shma Avi Wigderson Shiyu Zhou 
Abstract: We present a deterministic algorithm that computes st-connectivity in undirected graphs using O(log 4=3 n) space. This improves the previous O(log 3=2 n) bound of Nisan, Szemeredi and Wigderson [NSW92]. 
Abstract-found: 1
Intro-found: 1
Reference: [AKL + 79] <author> Romas Aleliu-nas, Richard M. Karp, Richard J. Lipton, Laszlo Lovasz, and Charles Rackoff. </author> <title> Random walks, universal traversal sequences and the complexity of maze problems. </title> <booktitle> In 20th Annual Symposium on Foundation of Computer Science, </booktitle> <pages> pages 218-223. </pages> <publisher> IEEE, </publisher> <year> 1979. </year>
Reference-contexts: Such a sequence is universal if it eventually leads the pebble to visit all nodes in every connected graph (of a given size). Alleliunas et al <ref> [AKL + 79] </ref> proved not only the existence of such a UTS of polynomial length, but did it via the probabilistic method, giving in particular a prob fl Institute of Computer Science, The Hebrew University of Jerusalem, Israel. E-mail: aroy@cs.huji.ac.il y Weizmann Institute, Rehovot, Israel.
Reference: [BF93] <author> Greg Barnes and Uriel Feige. </author> <title> Short random walks on graphs. </title> <booktitle> In Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 728-737. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Let us denote k = 2 m as was used in section 3. We start with the following Lemma of Barnes and Feige <ref> [BF93] </ref>. Lemma 7.1 Suppose G is a connected graph and s is an arbitrary vertex in G. Let k be an integer.
Reference: [BGG93] <author> Mihir Bellare, Oded Goldreich, and Shafi Goldwasser. </author> <title> Randomness in interactive proofs. </title> <journal> Computational Complexity, </journal> <volume> 3(4) </volume> <pages> 319-354, </pages> <year> 1993. </year>
Reference-contexts: To remove dependencies we approximate the average behavior of this set of functions (an object independent of any particular one function) with sufficient accuracy and high probability. This is achieved without space and random bit penalty via deterministic sampling of either <ref> [BGG93] </ref> or the recent extractor constructions of [Zuc96]. This technique for removing dependencies has potential for generalization, and may become a useful derandomization tool. The rest of the paper is organized as follows. In section 2 we give basic notation, definitions and preliminary tools. <p> Two optimal methods are known, <ref> [BGG93] </ref> and [Zuc96]. <p> The construction of APRX uses the oblivious sampler of [Zuc96] (we may as well use the sampler constructed in <ref> [BGG93] </ref>) and the perturbation and truncation scheme of [SZ95].
Reference: [BR94] <author> Mihir Bellare and John Rompel. </author> <title> Randomness-efficient oblivious sampling. </title> <booktitle> In Proceedings of the 32nd Symposium on Foundation of Computer Science, </booktitle> <pages> pages 276-287. </pages> <publisher> IEEE, </publisher> <year> 1994. </year>
Reference-contexts: Two optimal methods are known, [BGG93] and [Zuc96]. Definition 2.1 <ref> [BR94, Zuc96] </ref> An (*; fl) oblivious sampler (or sampler) A : f0; 1g r ! f0; 1g pl is a deterministic algorithm that on an input r-bit string y, outputs a sequence of p sample points A (y)[1]; : : : ; A (y)[p] 2 f0; 1g l subject to the
Reference: [Lin92] <author> Nati Linial. </author> <title> Private communication. </title> <type> Unpublished manuscript, </type> <year> 1992. </year>
Reference-contexts: We could equally use a slightly weaker Lemma with l = O (k 4 ) of <ref> [Lin92] </ref>.
Reference: [LP82] <author> Harry R. Lewis and Cristos H. Papadim-itriou. </author> <title> Symmetric space-bounded computation. </title> <journal> Theoretical Computer Science, </journal> <volume> 19 </volume> <pages> 161-187, </pages> <year> 1982. </year>
Reference-contexts: 1 Introduction Undirected st-connectivity (USTCON) is a fundamental computational problem, and algorithms for it serve as basic subroutines for more complex graph problems. It is complete for the class SL of symmetric nondeterministic log-space computations <ref> [LP82] </ref>, and is a subprob-lem of Directed st-connectivity, which captures the class N L of general nondeterministic computation. The combinatorics of USTCON, as well as its time complexity, are extremely well understood.
Reference: [Nis92] <author> Noam Nisan. </author> <title> Pseudorandom generators for space-bounded computation. </title> <journal> Combinator-ica, </journal> <volume> 12(4) </volume> <pages> 449-461, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The work was mainly done while visiting the Institute of Computer Science, The Hebrew University of Jerusalem, Israel. E-mail: shiyu@bell-labs.com abilistic log-space (RL) algorithm for USTCON. Thus they established SL RL. Unfortunately, it did not provide deterministic space-efficient algorithms to generate such short UTS. In a seminal paper, Nisan <ref> [Nis92] </ref> proved that a UTS can be constructed in L 2 . This construction was based on a pseudo-random generator that fools RL machines. In particular, it can be used to derandomize the above probabilistic algorithm. <p> The computation at each recursive level consists of computing two matrices N i and G i . N i is obtained by taking a walk on graph G i1 according to the universal traversal sequence constructed in <ref> [Nis92] </ref>, which takes space O (log 2 k + log n). The computation of G i is based on a matrix algorithm which we denote by SRNK for graph shrinking procedure. <p> In the second stage of our construction, by applying Nisan's pseudo-random generator for space-bounded computation <ref> [Nis92] </ref> to simulate short random walks on graphs, we construct an off-line randomized algorithm, which we call WALK for pseudo-random walks, that gives a "weak" version of the procedure NBRS in the following sense: given any graph G i1 , WALK takes O (log 2 k) random bits, runs in processing <p> Moreover, B q+1 (W q ) (W ). At this point, we wish to show that instead of taking a random walk of length l on G from s, we can take a pseudo-random walk using pseudo-random bits from the generator of Nisan <ref> [Nis92] </ref>, with log l hash functions, each of size O (log k). Unfortunately, such a generator is only known to fool automata of size polynomial in k. To this end, we will construct an automaton A of such a size. <p> To define the alphabet of this automaton, we need the following Lemma proved by Nisan <ref> [Nis92, Lemma 2] </ref>: Lemma 7.3 For every jSj = O (2 7m ) and l = O (2 3m ) there exists p = O (m) and a pseudo-random generator F : f0; 1g p fi (f0; 1g 2p ) log l ! (f0; 1g p ) l such that for
Reference: [Nis94] <author> Noam Nisan. </author> <title> RL SC. Computational Complexity, </title> <type> 4, </type> <year> 1994. </year>
Reference-contexts: This hierarchical generator requires log n universal hash functions of O (log n) bits each. While not directly improving the deterministic space bound for USTCON, Nisan's techniques were the basis of all subsequent progress, starting with his own paper <ref> [Nis94] </ref> proving RL SC (which in particular gives a (log n) 2 -space, polynomial time algorithm for USTCON). The first reduction in space for this problem was achieved by Nisan, Szemeredi and Wigderson [NSW92] who proved SL 2 L 3=2 . The key idea is to scale down Nisan's UTS.
Reference: [NSW92] <author> Noam Nisan, Endre Szemeredi, and Avi Wigderson. </author> <title> Undirected connectivity in O(log 1:5 n) space. </title> <booktitle> In Proc. 33th IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 24-29, </pages> <year> 1992. </year>
Reference-contexts: The first reduction in space for this problem was achieved by Nisan, Szemeredi and Wigderson <ref> [NSW92] </ref> who proved SL 2 L 3=2 . The key idea is to scale down Nisan's UTS. They use short (O (log 2 k) bits) UTS's from every vertex of the graph to visit large (size k) neighborhoods. <p> The bound of this paper, SL L 4=3 , requires a careful combination of the ingredients of both papers above, with some new ideas. We will follow the shrinking scheme of <ref> [NSW92] </ref>. However, we replace the UTS of [NSW92] by a pseudo-random walk using Nisan's gen 1 erator with short hash functions. <p> The bound of this paper, SL L 4=3 , requires a careful combination of the ingredients of both papers above, with some new ideas. We will follow the shrinking scheme of <ref> [NSW92] </ref>. However, we replace the UTS of [NSW92] by a pseudo-random walk using Nisan's gen 1 erator with short hash functions. <p> In particular, it implies that any bit in the output sequence is computable in space log O (1) (l + log 1 3 Motivation and Overview One common point of the algorithms presented in [Sav70] and <ref> [NSW92] </ref> for connectivity is that they both can be viewed as a recursive matrix algorithm such that on an input instance (G; s; t) of undirected st connectivity, it computes a sequence of graphs [G i ] r that satisfies the following properties which we call recursive connectivity properties (RCP): 1. <p> We can see that the space used at every recursive level (to compute G i given G i1 ) is O (log n) and r is log n. So the total space required is O (log 2 n) (by Proposition 2.2). The algorithm of <ref> [NSW92] </ref> computes a sequence of matrices [N i ; G i ] r depending on a parameter k which we call shrinking parameter. <p> To improve the result we adapt an idea of [SZ95]: we apply randomization in recursion and then reuse random bits at different recursive levels to achieve space savings. We replace the deterministic procedure of computing neighborhood matrices N i in <ref> [NSW92] </ref> by an off-line randomized procedure which we call NBRS for randomized neighborhood matrix approximations. This procedure NBRS takes O (log 2 k) random bits but uses only O (log n) processing space, and with high probability outputs a k-rich neighborhood matrix N i of any graph G i1 .
Reference: [Sak96] <author> Michael Saks. </author> <title> Randomization and deran-domization in space-bounded computation. </title> <booktitle> 11th Annual Conference on Computational Complexity, </booktitle> <year> 1996. </year>
Reference: [Sav70] <author> Walter J. Savitch. </author> <title> Relationships between nondeterministic and deterministic space complexities. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 4(2) </volume> <pages> 177-192, </pages> <year> 1970. </year>
Reference-contexts: However, its space complexity is still a mystery, which was a source of some beautiful discoveries in complexity theory. We adopt N C-style notations and let L ff = DSP ACE ((log n) ff ). Savitch's result <ref> [Sav70] </ref> from 1970, N L L 2 implies a deterministic (log n) 2 space bound for SL directly. Remarkably, since then, all progress went via probabilistic algorithms for USTCON and their derandomization. In the late 70's Cook suggested universal traversal sequences (UTS) as a basis for log-space algorithms for USTCON. <p> In particular, it implies that any bit in the output sequence is computable in space log O (1) (l + log 1 3 Motivation and Overview One common point of the algorithms presented in <ref> [Sav70] </ref> and [NSW92] for connectivity is that they both can be viewed as a recursive matrix algorithm such that on an input instance (G; s; t) of undirected st connectivity, it computes a sequence of graphs [G i ] r that satisfies the following properties which we call recursive connectivity properties <p> We say that a (recursive) matrix algorithm on input (G; s; t) computes connectivity if it computes a sequence of graphs that satisfies RCP. In <ref> [Sav70] </ref>, the algorithm computes the sequence of graphs [G i ] r such that G i = G 2 i1 = G 2 i .
Reference: [SZ95] <author> Michael Saks and Shiyu Zhou. </author> <booktitle> RSP ACE(S) DSP ACE(S 3 In Proc. 36th Annual IEEE Conference on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 344-353, </pages> <address> Milwaukee, Wisconsin, </address> <month> Oc-tober </month> <year> 1995. </year>
Reference-contexts: While it seems that the symmetric structure was essential for the above improvement, Saks and Zhou <ref> [SZ95] </ref> found a completely different way to obtain the stronger result RL L 3=2 . They showed that Nisan's generator can be replaced by a weaker process, an offline randomized algorithm, which uses only p log n hash functions, that are used repeatedly in p log n iterations. <p> Next we would like to repeatedly use the same hash functions of this pseudo-random walk in many iterations, in <ref> [SZ95] </ref> style. To remove dependencies we approximate the average behavior of this set of functions (an object independent of any particular one function) with sufficient accuracy and high probability. <p> We will need the following two approximation operators, perturbation and truncation, defined in <ref> [SZ95] </ref>. Let ffi be a nonnegative real number. The perturbation operator is a function mapping any nonnegative real number z 2 [0; 1] to z ffi = maxfz ffi; 0g. Let t be a positive integer. <p> P p We call such an algorithm F recursive matrix algorithm and we say that F on input (M; [z i ] p ) (recursively) computes a sequence of matrices [M i ] p . 2.3 Off-line Randomized Approximations We consider a class of randomized algorithms called offline randomized algorithms <ref> [SZ95] </ref>. They are sometimes called algorithms with 2-way random input. <p> error probability fi if Pr [kA (M; z; y) N k &gt; 2 a ] fi That is, for all but fi fraction of choices of y 2 f0; 1g R (jM;zj) , A (M; z; y) approximates N to within 2 a . 2.4 Perturbations and Truncations We follow <ref> [SZ95] </ref> to review some basic properties of the perturbation and truncation operators. First we have the following easy facts. Proposition 2.3 Suppose M; N are nonnegative real matrices of the same dimension, t is a positive integer and ffi is a positive real number. <p> positive integers a d, we define (a; d) to be the set of 2 d real numbers fq2 a j integer q 2 [0; 2 d 1]g. (Sometime we may identify f0; 1g d with [0; 2 d 1].) The proofs of the next two lemmas can be found in <ref> [SZ95] </ref> (Lemma 5.5 and Lemma 5.2, respectively). Lemma 2.1 Suppose M is an n fi n nonnegative real matrix and a d are positive integers. Let t = a d. <p> Thus the total space needed for the computation is O (log 2 n= log k + log n log k). By choosing log k = log 1=2 n the algorithm has space complexity O (log 3=2 n). To improve the result we adapt an idea of <ref> [SZ95] </ref>: we apply randomization in recursion and then reuse random bits at different recursive levels to achieve space savings. We replace the deterministic procedure of computing neighborhood matrices N i in [NSW92] by an off-line randomized procedure which we call NBRS for randomized neighborhood matrix approximations. <p> The construction of APRX uses the oblivious sampler of [Zuc96] (we may as well use the sampler constructed in [BGG93]) and the perturbation and truncation scheme of <ref> [SZ95] </ref>.
Reference: [Wig92] <author> Avi Wigderson. </author> <title> The complexity of graph connectivity. </title> <booktitle> In Mathematical Foundations of Computer Science: Proceedings, 17th Symposium, Lecture Notes in Computer Science, </booktitle> <volume> volume 629, </volume> <pages> pages 112-132, </pages> <year> 1992. </year>
Reference: [Zuc96] <author> David Zuckerman. </author> <title> Randomness-optimal sampling, extractors, and constructive leader election. </title> <booktitle> In ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 286-295, </pages> <address> Philadelphia, Pennsylvania, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: To remove dependencies we approximate the average behavior of this set of functions (an object independent of any particular one function) with sufficient accuracy and high probability. This is achieved without space and random bit penalty via deterministic sampling of either [BGG93] or the recent extractor constructions of <ref> [Zuc96] </ref>. This technique for removing dependencies has potential for generalization, and may become a useful derandomization tool. The rest of the paper is organized as follows. In section 2 we give basic notation, definitions and preliminary tools. <p> Two optimal methods are known, [BGG93] and <ref> [Zuc96] </ref>. <p> Two optimal methods are known, [BGG93] and [Zuc96]. Definition 2.1 <ref> [BR94, Zuc96] </ref> An (*; fl) oblivious sampler (or sampler) A : f0; 1g r ! f0; 1g pl is a deterministic algorithm that on an input r-bit string y, outputs a sequence of p sample points A (y)[1]; : : : ; A (y)[p] 2 f0; 1g l subject to the <p> Indeed, by using improved extractors, Zuckerman showed an explicit construction of such a randomness-efficient sampler ([Zuc96, Theorem 5.5]). We will use a special case of this sampler: Lemma 2.3 <ref> [Zuc96] </ref> For any constant - &lt; 1, any positive integer l and any * such that log 1 * l - , there is an (*; 1 2 l ) oblivious sampler A : f0; 1g 3l ! f0; 1g pl that runs in N C, where p = b (2l=*) <p> This is obtained from <ref> [Zuc96, Theorem 5.5] </ref> by setting m = l; d = p; ff = 1 2 l . <p> The construction of APRX uses the oblivious sampler of <ref> [Zuc96] </ref> (we may as well use the sampler constructed in [BGG93]) and the perturbation and truncation scheme of [SZ95].
References-found: 14

