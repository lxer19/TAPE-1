URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/thrun/public_html/papers/burgard.active.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/thrun/public_html/papers/burgard.active.html
Root-URL: 
Title: Active Mobile Robot Localization  
Author: Wolfram Burgard Dieter Fox Sebastian Thrun 
Address: D-53117 Bonn Germany  D-53117 Bonn Germany  Pittsburgh, PA U.S.A.  
Affiliation: Dept. of Computer Science III University of Bonn  Dept. of Computer Science III University of Bonn  Dept. of Computer Science Carnegie Mellon University  
Abstract: Localization is the problem of determining the position of a mobile robot from sensor data. Most existing localization approaches are passive, i.e., they do not exploit the opportunity to control the robot's effectors during localization. This paper proposes an active localization approach. The approach provides rational criteria for (1) setting the robot's motion direction (exploration), and (2) determining the pointing direction of the sensors so as to most efficiently localize the robot. Furthermore, it is able to deal with noisy sensors and approximative world models. The appropriateness of our approach is demonstrated empirically using a mobile robot in a structured office environment.
Abstract-found: 1
Intro-found: 1
Reference: [ Ballard and Brown, 1982 ] <author> D.H. Ballard and C.M. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: For example, choosing the right action during exploration can reduce exponential complexity to low-degree polynomial complexity, as for example shown in Koenig's and Thrun's work on exploration in heuristic search and learning control [ Koenig, 1992; Thrun, 1992 ] . Similarly, active vision (see e.g., <ref> [ Ballard and Brown, 1982 ] </ref> ) has also led to results superior to passive approaches to computer vision. In the context of mobile robot localization, actively controlling a robot is particularly beneficial when the environment possesses relatively few features that enable a robot to unambiguously determine its location.
Reference: [ Borenstein et al., 1996 ] <author> J. Borenstein, B. Everett, and L. Feng. </author> <title> Navigating Mobile Robots: Systems and Techniques. </title> <editor> A. K. Peters, </editor> <publisher> Ltd., </publisher> <address> Wellesley, MA, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction To navigate reliably in indoor environments, a mobile robot must know where it is. Over the last few years, there has been a tremendous scientific interest in algorithms for estimating a robot's location from sensor data. A recent book on this issue <ref> [ Borenstein et al., 1996 ] </ref> illustrates the importance of the localization problem and provides a unique description of the state-of-the-art. The majority of existing approaches to localization are passive. Passive localization exclusively addresses the estimation of the location based on an incoming stream of sensor data. <p> Our implementation assumes that initially, the robot is given a metric map of its environment, but it does not know where it is. Notice that this is a difficult localization problem; most existing approaches (see, e.g., <ref> [ Borenstein et al., 1996 ] </ref> ) concentrate on situations where the initial robot location is known and are not capable of localizing a robot from scratch. Our approach has been empirically tested using a mobile robot equipped with a circular array of 24 sonar sensors. <p> The key experimental result is that the efficiency of localization is improved drastically by actively controlling the robot's motion direction and by actively controlling its sensors. 2 Related Work While most research has concentrated on passive localization (see e.g., <ref> [ Borenstein et al., 1996 ] </ref> ), active localization has received considerably little attention in the mobile robotics community.
Reference: [ Buhmann et al., 1995 ] <author> J. Buhmann, W. Burgard, A.B. Cre-mers, D. Fox, T. Hofmann, F. Schneider, J. Strikos, and S. Thrun. </author> <title> The mobile robot Rhino. </title> <journal> AI Magazine, </journal> <volume> 16(2):3138, </volume> <month> Summer </month> <year> 1995. </year>
Reference-contexts: The collision avoidance then generates motion commands to safely guide the robot to these targets. An overview of the architecture of the navigation system is given in <ref> [ Buhmann et al., 1995; Thrun et al., to appear ] </ref> . Fig. 7. Belief Bel (l) at pos. 3 After reaching the end of the corridor (position 3) the belief state contained only two local maxima (see Fig. 7).
Reference: [ Burgard et al., 1996 ] <author> W. Burgard, D. Fox, D. Hennig, and T. Schmidt. </author> <title> Estimating the absolute position of a mobile robot using position probability grids. </title> <booktitle> In Proc. of the Fourteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 896901, </pages> <year> 1996. </year>
Reference-contexts: P (s j l), the map of the environment, is a crucial component of the update equations. It specifies the likelihood of observing s at location l, for any choice of s and l. In [ Moravec, 1988 ] and our previous work <ref> [ Burgard et al., 1996 ] </ref> , P (s j l) is obtained from a metric model of the environment, and a model of proximity sensors. <p> Costs are considered because they may vary drastically between different target points. 3.4 Efficient Implementation The active navigation and sensing methods described here have been implemented and tested using position probability grids <ref> [ Burgard et al., 1996 ] </ref> . This technique represents the location of the robot by a discrete three-dimensional grid.
Reference: [ Fox et al., 1997 ] <author> D. Fox, W. Burgard, and S. Thrun. </author> <title> The dynamic window approach to collision avoidance. </title> <journal> IEEE Robotics & Automation Magazine, </journal> <volume> 4(1):2333, </volume> <month> March </month> <year> 1997. </year>
Reference-contexts: E a [H] + v (a) at pos. 2 section 3.3 to generate a cost minimal path to the target location (see [ Thrun and Bucken, 1996 ] ). Intermediate target points on this path are sent to our reactive collision avoidance technique described in <ref> [ Fox et al., 1997 ] </ref> . The collision avoidance then generates motion commands to safely guide the robot to these targets. An overview of the architecture of the navigation system is given in [ Buhmann et al., 1995; Thrun et al., to appear ] . Fig. 7.
Reference: [ Kaelbling et al., 1995 ] <author> L.P. Kaelbling, </author> <title> M.L. Littman, and A.R. Cassandra. Planning and acting in partially observable stochastic domains. </title> <type> Technical report, </type> <institution> Brown University, </institution> <year> 1995. </year>
Reference-contexts: In [ Klein-berg, 1994 ] the problem of active localization is treated theoretically in finding critical directions within the environment under the assumption of perfect sensors. In <ref> [ Kaelbling et al., 1995 ] </ref> , acting in the environment is modeled as a partially observable Markov decision process (POMDP). This approach derives an optimal strategy for moving to a target location given that the position of the robot is not known perfectly.
Reference: [ Kaelbling et al., 1996 ] <author> L.P. Kaelbling, A.R. Cassandra, and J.A. Kurien. </author> <title> Acting under uncertainty: Discrete bayesian models for mobile-robot navigation. </title> <booktitle> In Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <year> 1996. </year>
Reference-contexts: However, both their approaches do not aim at actively localizing the robot. Localization occurs as a side effect when operating the robot under uncertainty. Moreover, as argued by Kaelbling <ref> [ Kaelbling et al., 1996 ] </ref> , there exist conditions under which the approach reported in [ Simmons and Koenig, 1995 ] can exhibit cyclic behavior due to uncertainty in localization. <p> In [ Kaelbling et al., 1995 ] , acting in the environment is modeled as a partially observable Markov decision process (POMDP). This approach derives an optimal strategy for moving to a target location given that the position of the robot is not known perfectly. In <ref> [ Kaelbling et al., 1996 ] </ref> this method is extended by actions allowing the robot to improve its position estimation. This is done by minimizing the expected entropy after the immediate next robot control action. <p> Fig. 9 shows the belief state at this final target point. Fig. 8. E a [H] + v (a) at pos. 3 Fig. 9. Final belief Bel (l) In addition to runs in our real office environment we did extensive testing in simulated hallway environments taken from <ref> [ Kaelbling et al., 1996 ] </ref> . Our active navigation system successfully localized the robot in every case by automatically detecting junctions of hallways and openings as crucial points for the localization task, and was uniformly superior to passive localization.
Reference: [ Kleinberg, 1994 ] <author> J. Kleinberg. </author> <title> The localization problem for mobile robots. </title> <booktitle> In Proc. of the 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1994. </year>
Reference: [ Koenig and Simmons, 1996 ] <author> S. Koenig and R. Simmons. </author> <title> Passive distance learning for robot navigation. </title> <editor> In L. Saitta, editor, </editor> <booktitle> Proc. of the Thirteenth International Conference on Machine Learning, </booktitle> <year> 1996. </year>
Reference: [ Koenig, 1992 ] <author> S. Koenig. </author> <title> The complexity of real-time search. </title> <type> Technical Report CMU-CS-92-145, </type> <institution> Carnegie Mel-lon University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: For example, choosing the right action during exploration can reduce exponential complexity to low-degree polynomial complexity, as for example shown in Koenig's and Thrun's work on exploration in heuristic search and learning control <ref> [ Koenig, 1992; Thrun, 1992 ] </ref> . Similarly, active vision (see e.g., [ Ballard and Brown, 1982 ] ) has also led to results superior to passive approaches to computer vision.
Reference: [ Kuipers and Byun, 1981 ] <author> B. Kuipers and Y.T. Byun. </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <month> 8 </month> <year> 1981. </year>
Reference-contexts: Moreover, as argued by Kaelbling [ Kaelbling et al., 1996 ] , there exist conditions under which the approach reported in [ Simmons and Koenig, 1995 ] can exhibit cyclic behavior due to uncertainty in localization. On the forefront of localization driven navigation, <ref> [ Kuipers and Byun, 1981 ] </ref> used a rehearsal procedure to check whether a location has been visited while learning a map. In [ Klein-berg, 1994 ] the problem of active localization is treated theoretically in finding critical directions within the environment under the assumption of perfect sensors.
Reference: [ Littman et al., 1995 ] <author> M.L. Littman, T.L. Dean, </author> <title> and L.P. Kaelbling. On the complexity of solving markov decision problems. </title> <booktitle> In Proc. of the Eleventh International Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: The result is the expected occupancy of a point a relative to the robot. Cost and cost-optimal paths: Based on P occ (a), the expected path length and the cost-optimal policy can be obtained through value iteration, a popular version of dynamic programming (see e.g., <ref> [ Littman et al., 1995 ] </ref> for details). Value iteration assigns to each location a a value v (a) that represents its distance to the robot.
Reference: [ Moravec, 1988 ] <author> H.P. Moravec. </author> <title> Sensor fusion in certainty grids for mobile robots. </title> <journal> AI Magazine, </journal> <month> Summer </month> <year> 1988. </year>
Reference-contexts: P (s j l), the map of the environment, is a crucial component of the update equations. It specifies the likelihood of observing s at location l, for any choice of s and l. In <ref> [ Moravec, 1988 ] </ref> and our previous work [ Burgard et al., 1996 ] , P (s j l) is obtained from a metric model of the environment, and a model of proximity sensors.
Reference: [ Nourbakhsh et al., 1995 ] <author> I. Nourbakhsh, R. Powers, and S. Birchfield. </author> <title> DERVISH an office-navigating robot. </title> <journal> AI Magazine, </journal> <volume> 16(2), </volume> <month> Summer </month> <year> 1995. </year>
Reference-contexts: In recent years, navigation under uncertainty has been addressed by a few researchers <ref> [ Nourbakhsh et al., 1995; Simmons and Koenig, 1995 ] </ref> , who developed the Markov navigation paradigm. However, both their approaches do not aim at actively localizing the robot. Localization occurs as a side effect when operating the robot under uncertainty.
Reference: [ Simmons and Koenig, 1995 ] <author> R. Simmons and S. Koenig. </author> <title> Probabilistic robot navigation in partially observable environments. </title> <booktitle> In Proc. International Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: In recent years, navigation under uncertainty has been addressed by a few researchers <ref> [ Nourbakhsh et al., 1995; Simmons and Koenig, 1995 ] </ref> , who developed the Markov navigation paradigm. However, both their approaches do not aim at actively localizing the robot. Localization occurs as a side effect when operating the robot under uncertainty. <p> However, both their approaches do not aim at actively localizing the robot. Localization occurs as a side effect when operating the robot under uncertainty. Moreover, as argued by Kaelbling [ Kaelbling et al., 1996 ] , there exist conditions under which the approach reported in <ref> [ Simmons and Koenig, 1995 ] </ref> can exhibit cyclic behavior due to uncertainty in localization. On the forefront of localization driven navigation, [ Kuipers and Byun, 1981 ] used a rehearsal procedure to check whether a location has been visited while learning a map.
Reference: [ Smith et al., 1990 ] <author> R. Smith, M. Self, and P. Cheeseman. </author> <title> Estimating uncertain spatial realtionships in robotics. </title> <editor> In I. Cox and G. Wilfong, editors, </editor> <title> Autonomous Robot Vehicles. </title> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: When sensing s, Bel (l) is updated according to the following rule: Bel (l) P (s) Here P (s) is a normalizer that ensures that the Bel (l) sum up to 1. In general, Bel (l) can be represented by Kalman filters <ref> [ Smith et al., 1990 ] </ref> or discrete approximation [ Burgard et al., 1996; Nourbakhsh et al., 1995; Simmons and Koenig, 1995; Kaelbling et al., 1996 ] . P (s j l), the map of the environment, is a crucial component of the update equations.
Reference: [ Thrun and B ucken, 1996 ] <author> S. Thrun and A. Bucken. </author> <title> Integrating grid-based and topological maps for mobile robot navigation. </title> <booktitle> In Proc. of the Fourteenth National Conference on Artificial Intelligence, </booktitle> <year> 1996. </year>
Reference: [ Thrun et al., to appear ] <author> S. Thrun, A. B ucken, W. Bur-gard, D. Fox, T. Frohlinghaus, D. Hennig, T. Hofmann, M. Krell, and T. Schimdt. </author> <title> Map learning and high-speed navigation in RHINO. </title> <editor> In D. Kortenkamp, R.P. Bonasso, and R. Murphy, editors, </editor> <title> AI-based Mobile Robots: Case studies of successful robot systems. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <note> to appear. </note>
Reference-contexts: For example, if disambiguating the robot's position requires the robot to move to a remote location, greedy single-step entropy minimization can fail to make the robot move there. In our own work <ref> [ Thrun et al., to appear ] </ref> , we have developed robot exploration techniques for efficiently mapping unknown environments. <p> The collision avoidance then generates motion commands to safely guide the robot to these targets. An overview of the architecture of the navigation system is given in <ref> [ Buhmann et al., 1995; Thrun et al., to appear ] </ref> . Fig. 7. Belief Bel (l) at pos. 3 After reaching the end of the corridor (position 3) the belief state contained only two local maxima (see Fig. 7).
Reference: [ Thrun, 1992 ] <author> S. Thrun. </author> <title> The role of exploration in learning control. </title> <editor> In D. A. White and D. A. Sofge, editors, </editor> <title> Handbook of intelligent control: neural, fuzzy and adaptive approaches. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> Florence, Ken-tucky 41022, </address> <year> 1992. </year>
Reference-contexts: For example, choosing the right action during exploration can reduce exponential complexity to low-degree polynomial complexity, as for example shown in Koenig's and Thrun's work on exploration in heuristic search and learning control <ref> [ Koenig, 1992; Thrun, 1992 ] </ref> . Similarly, active vision (see e.g., [ Ballard and Brown, 1982 ] ) has also led to results superior to passive approaches to computer vision.
References-found: 19

