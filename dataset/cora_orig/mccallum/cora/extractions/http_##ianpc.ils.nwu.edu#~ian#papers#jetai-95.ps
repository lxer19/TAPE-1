URL: http://ianpc.ils.nwu.edu/~ian/papers/jetai-95.ps
Refering-URL: http://www.ils.nwu.edu/~ian/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: ian@ils.nwu.edu  
Title: Visual architecture and cognitive architecture revolve around speed and time-scale. Planning, so the story goes,
Author: Ian Horswill epistemology. 
Note: To appear, JETAI special issue on agent architectures Many of the criticisms of traditional architecture  I believe the true issues are not speed in the sense of time-scale, but combinatorics and epistemology. The former has been extensively discussed, see  
Address: 1890 Maple Avenue Evanston, IL 60201  
Affiliation: The Institute for the Learning Sciences Northwestern University  
Abstract: Traditional architectures have fundamental epistemological problems. Perception is inherently resource limited so controlling perception involves all the same AI-complete problems of reasoning about time and resources as the full-scale planing problem. Allowing a planner to transparently assume that the information it needs will automatically be present and up-to-date in the model thus presupposes a solution to a problem at least as difficult as planning itself. Although one can imagine many possible solutions to this problem, such as allowing the planner to recurse on its own epistemological problems, there have been no convincing attempts at this. In this paper, I compare behavior-based and traditional systems in terms of their representational power and the strengths of their implicit epistemological theories. I argue that both have serious limitations and that those limitations are not addressed simply by joining the two into a hybrid. I discuss my work with using vision to support real-time activity and give an example of an interesting intermediate point between reactive and classical architectures that preserves the simplicity and parallelism of behavior-based systems while supporting "symbolic" representations. Traditionally, AI theories have assumed, either implicitly or explicitly, an architecture in which modules of the mind (perception, reasoning, motor control, etc.) are linked by way of some centralized database-like structure, often referred to as a world model ([26] for example). Recently, a number of alternative architectures have been proposed which, to greater or lesser degrees, claim to do away with world models or with representations entirely [8][3]. loops are fast but stupid. A common approach, both in this special issue and in the literature in general, is to adopt a hybrid which fuses a slow planner running on a long time-scale and a set of fast feedback loops running on a short time-scale. The problem with this argument is that planning isn't slow, it's combinato-rially explosive. Running an O(2 n ) algorithm on a time-scale ten times slower is the same as running it on a computer ten times faster: it simply lets you increase n by three. If time-scale were the true problem, faster CPUs would make tiered architectures obsolete in a few years. Clearly, if an agent architecture is to be successful it must take into account the capacities and limitations of perception. In this paper I discuss the influence of perceptual architecture on agent architecture, argue that the recent wave of tiered architecture do not adequately address these problems, and discuss my work on using vision to support real-time activity. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Harold Abelson, Gerald Jay Sussman, and Julie Sussman. </author> <title> The Structure and Interpretation of Computer Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1985. </year>
Reference-contexts: Variable binding within these systems is accomplished not by arranging pointers in binding-environment data structures <ref> [1] </ref> but by allocating visual attention [2]. Thus deic-tic systems also provide an epistemological theory to support their representational theory. Like straight propositional systems, they require the set of representations to be chosen at design time and fixed in hardware.
Reference: [2] <author> Philip E. Agre. </author> <title> The dynamic structure of everyday life. </title> <type> Technical Report 1085, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Lab, </institution> <month> October </month> <year> 1988. </year>
Reference-contexts: combination of arguments: STACK-A-ON-B, STACK-A-ON-C, etc. "Deictic" or "indexical-functional" systems [3]<ref> [2] </ref>[33] loosen this restriction by effectively allowing the introduction of variables and predicates, but no term expressions or quantifiers. Variable binding within these systems is accomplished not by arranging pointers in binding-environment data structures [1] but by allocating visual attention [2]. Thus deic-tic systems also provide an epistemological theory to support their representational theory. Like straight propositional systems, they require the set of representations to be chosen at design time and fixed in hardware.
Reference: [3] <author> Philip E. Agre and David Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 268-272, </pages> <year> 1987. </year>
Reference-contexts: But if they are to be frequently recapitulated, the had better be oftly simple. Let's assume, however, that we have somehow solved the problem of checking validity, say with a monstrously large TMS, and consider what happens when the robot operates in a rapidly changing world like Pengi's <ref> [3] </ref> video-game. In this case, cache entries are constantly being invalidated and the planner is constantly making calls to the perception system to move the eyeballs around, allocate perceptual resources, etc.
Reference: [4] <author> John Aloimonos. </author> <title> Purposive and qualitative active vision. </title> <booktitle> In DARPA Image Understanding Workshop, </booktitle> <year> 1990. </year>
Reference: [5] <editor> Ruzena Bajcsy. </editor> <title> Active perception vs. passive perception. </title> <booktitle> In Proc. Third IEEE Workshop on Computer Vision: Representation and Control, </booktitle> <pages> pages 55-59. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1985. </year>
Reference: [6] <author> Dana H. Ballard. </author> <title> Animate vision. </title> <journal> Artificial Intelligence, </journal> <volume> 48(1) </volume> <pages> 57-86, </pages> <year> 1991. </year>
Reference: [7] <author> Rodney A. </author> <title> Brook. Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47(1-3):139-159, </volume> <year> 1991. </year>
Reference-contexts: Researchers have used a wide range of characterizations and justifications for these architectures, ranging from the rejection of representation <ref> [7] </ref>, to neurophysiological plausibility [30], distributed control [24], emergence, and the importance of reactivity [22]. What all these architectures have in common, however is the use of propositional representations instead of structured predicate representations. I should say immediately, that this is an abuse of terminology.
Reference: [8] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automoation, </journal> <volume> 2(1) </volume> <pages> 14-23, </pages> <month> March </month> <year> 1986. </year>
Reference: [9] <author> David Chapman. </author> <title> Vision, instruction, and action. </title> <type> Technical Report 1204, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Lab, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: Ullman left the details of the registers and functional units unspecified. Chapman's simulated VRP <ref> [9] </ref> contained four types of state elements: markers, which held image locations; lines and rays; activation planes, which were general registers that could hold arbitrary binary images; and a return inhibition map. All state elements except the return inhibition map could be directly named and manipulated. <p> A pixel has the spatial attention feature iff it lies on the ray. The only directly-addressable memory in the VRP is a small collection of registers called "markers" <ref> [9] </ref> which can hold the centroid and bounding box of a segment.
Reference: [10] <author> W. F. Clocksin and C. S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1981. </year> <month> 11 </month>
Reference-contexts: loaded with the specifications of the currently attended region, compared to one another, or used to focus attention (see below). 2.2.3 A database-free logic programming system Bertrand includes a simple finite-state controller that is sufficient to find satisfying variable assignments for Horn clause logic queries, similar to a Prolog engine <ref> [10] </ref>. What is unusual about Bertrand is that it contains no database of true facts. Instead, Bertrand computes truth values and variable bindings on demand using the image-plane operations of the VRP. Logic variables are represented with markers that point to the image-plane objects to which they are bound.
Reference: [11] <author> Erann Gat. </author> <title> Integrating planning and reacting in a heterogeneous asynchronous architecture for controlling real-world mobile robots. </title> <booktitle> In Proceedings, AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: Indeed, it can simulate a limited Prolog interpreter. But it contains a set of simplifications that allows it to be grounded in a real-time vision system and implemented in connectionist-compatible hardware. I would also take as examples Gat's AT-LANTIS system <ref> [11] </ref> and at least some instantiations of the 3T architecture (Bonasso et al., this issue) as examples of useful intermediate points.
Reference: [12] <author> Andrew S. Gavin and Masaki Yamamoto. </author> <title> A fast, cheap, and easy system for outside vision on mars. </title> <booktitle> In Intelligent Robots and Computer Vision XI, </booktitle> <address> Cambridge, MA, </address> <month> September </month> <year> 1993. </year> <pages> SPIE. </pages>
Reference: [13] <author> J. J. Gibson. </author> <title> The Senses Considered as Perceptual Systems. </title> <address> Houghton-Mi*in, Boston, </address> <year> 1966. </year>
Reference-contexts: Polly subsets have been implemented on hardware as simple as low-end automobile microcontrollers [17]. Polly's vision computations are economical because they of their specialization to a specific task and environment <ref> [13] </ref>. Task specialization allows the system to use a fixed set of atomic percepts to represent the environment rather than building a general model and deriving the relevant percepts from that. Explicit environmental specialization is somewhat more unusual.
Reference: [14] <author> Takashi Gomi and Koh ichi Ide. </author> <title> Vision based navigation for an office messenger robot. </title> <editor> In V. Graefe, editor, </editor> <booktitle> Intelligent Robots '95. </booktitle> <address> Else-vier, </address> <year> 1995. </year>
Reference-contexts: In addition to having a relatively wide range of behaviors, it was also extremely reliable. Polly-based systems are now regularly run indoors at 2m/s in complex spaces without mishaps. They have been duplicated in other labs and productized by an outside company <ref> [14] </ref>. They have also been tested in more environments than any comparable system. Later generations of Polly have been run at several different universities, at hotels, a conference center, and even in grammar schools.
Reference: [15] <author> Ian Horswill. </author> <title> Specialization of perceptual processes. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Part of the original motivation for the Polly work was to develop analytical tools for characterizing environments and agents that are specialized to them. These tools are outside the scope of this paper. The interested reader is referred to <ref> [15] </ref> or [16]. 2.1.1 Architecture On each clock tick (66ms), the robot grabs a new 64 fi 48 image, runs each (simulated) parallel process in sequence. As the processes are run, each visual system output is recomputed, each intermediate inference is updated, and finally a motor command is generated. <p> Polly is successful because its assumptions fit well with its environment. Polly does have a number of failure modes, however. It has problems with strong shadows, low-contrast obstacles, and other cases that cause its edge detector to misfire. See <ref> [15] </ref> for more discussion. 2.2 Limited predicate representa tions: Bertrand and Ludwig Polly and its descendants are extremely limited in that they perform only low level sensory-motor tasks rather than cognitive or symbolic tasks.
Reference: [16] <author> Ian Horswill. </author> <title> Analysis of adaptation and environment. </title> <journal> Artificial Intelligence, </journal> <volume> 75 </volume> <pages> 1-30, </pages> <year> 1995. </year>
Reference-contexts: Part of the original motivation for the Polly work was to develop analytical tools for characterizing environments and agents that are specialized to them. These tools are outside the scope of this paper. The interested reader is referred to [15] or <ref> [16] </ref>. 2.1.1 Architecture On each clock tick (66ms), the robot grabs a new 64 fi 48 image, runs each (simulated) parallel process in sequence. As the processes are run, each visual system output is recomputed, each intermediate inference is updated, and finally a motor command is generated. <p> a binary image J to be a vector b (J), indexed by the x (horizontal) coordinate, whose x'th element is the height of the lowest marked pixel in the x'th column of J: b x (J) = min fy : J (x; y) = 1g (1) It can be shown <ref> [16] </ref> that b x (J) is equivalent to a radial depth map modulo a monotone function, provided that (1) the ground plane is textureless, (2) all obstacles rest on a ground plane, (4) the obstacles are textured or at least have a different albedo 4 than the floor, and (5) the
Reference: [17] <author> Ian Horswill and Masaki Yamamoto. </author> <title> A $1000 active stereo vision system. </title> <note> In Submitted to CVPR-94, </note> <year> 1994. </year>
Reference-contexts: The basic system requires very little hardware (an equivalent robot can now be built for around $10K using commercial hardware), and consists of less than a thousand lines of Scheme code. Polly subsets have been implemented on hardware as simple as low-end automobile microcontrollers <ref> [17] </ref>. Polly's vision computations are economical because they of their specialization to a specific task and environment [13]. Task specialization allows the system to use a fixed set of atomic percepts to represent the environment rather than building a general model and deriving the relevant percepts from that.
Reference: [18] <author> Katsushi Ikeuchi and Martial Herbert. </author> <title> Task oriented vision. </title> <booktitle> In DARPA Image Understanding Workshop, </booktitle> <year> 1990. </year>
Reference: [19] <author> John E. Laird, Allen Newell, and Paul S. Rosen-bloom. </author> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: In attempting to implement the details of our modularization between perception, planning, and execution, we have been forced to violate that modularization. Of course, it is always possible that the problem could be solved by some sort of recursive control structure like universal subgoaling <ref> [19] </ref>, whereby the planner recursively calls itself to plan the epistemic actions required for its own planning problem.
Reference: [20] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures. </title> <publisher> Morgan Kauf-man, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: Typical algorithms for those representations, such as depth-first search and unification are also known to be hard (and thought to be impossible) to parallelize because their P-completeness <ref> [20] </ref>. Again, it should be stressed that the issue here is not speed, at least not in the sense of time-scale, but combinatoric complexity.
Reference: [21] <author> Liana M. Lorigo. </author> <title> Visuall guided obstacle avoidance in unstructured environments. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: The result is that if an environment fails to satisfy constraint 1 (known as the background-texture constraint), but satisfies the other constraints (collectively called the ground-plane constraint), then another computation capable of detecting non-ground pixels can be substituted for the edge detector. For example, Lorigo <ref> [21] </ref> has used another texture detector to navigate around rocks in a simulated Martian surface.
Reference: [22] <editor> Pattie Maes. </editor> <title> Designing autonomous agents. </title> <editor> In Pattie Maes, editor, </editor> <booktitle> Designing Autonomous Agents, </booktitle> <pages> pages 1-2. </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Researchers have used a wide range of characterizations and justifications for these architectures, ranging from the rejection of representation [7], to neurophysiological plausibility [30], distributed control [24], emergence, and the importance of reactivity <ref> [22] </ref>. What all these architectures have in common, however is the use of propositional representations instead of structured predicate representations. I should say immediately, that this is an abuse of terminology. Wires in behavior-based systems carry not only truth values but analog measures such as distance.
Reference: [23] <author> David Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <year> 1982. </year>
Reference-contexts: Task specialization allows the system to use a fixed set of atomic percepts to represent the environment rather than building a general model and deriving the relevant percepts from that. Explicit environmental specialization is somewhat more unusual. Polly's design takes advantage of naturally occuring structures or constraints <ref> [23] </ref> that commonly hold within office buildings. These domain constraints allow it to compute percepts more efficiently and reliably than domain-independent technologies allow. Many authors have argued that simple machinery is often sufficient for performing intelligent behavior because of the special organizing structures of the environment (see, for example, [29][8][2]).
Reference: [24] <editor> Maja Mataric. </editor> <title> A distributed model for mobile robot environment-learning and navigation. </title> <type> Technical Report 1228, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Lab, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: Researchers have used a wide range of characterizations and justifications for these architectures, ranging from the rejection of representation [7], to neurophysiological plausibility [30], distributed control <ref> [24] </ref>, emergence, and the importance of reactivity [22]. What all these architectures have in common, however is the use of propositional representations instead of structured predicate representations. I should say immediately, that this is an abuse of terminology.
Reference: [25] <author> Drew McDermott and eds. James Hendler. </author> <title> Special volume on planning and scheduling. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 76(1-2), </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: If time-scale were the true problem, faster CPUs would make tiered architectures obsolete in a few years. I believe the true issues are not speed in the sense of time-scale, but combinatorics and epistemology. The former has been extensively discussed, see for example the studies of planning in <ref> [25] </ref>, so I will focus on epistemology. Clearly, if an agent architecture is to be successful it must take into account the capacities and limitations of perception.
Reference: [26] <author> Allen Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [27] <author> Douglas A. Reece and Steven Shafer. </author> <title> Using active vision to simplify perception for robot driving. </title> <type> CMU-CS 91-199, </type> <institution> Carnegie-Mellon University Computer Science Department, </institution> <year> 1991. </year>
Reference: [28] <author> Marc H. J. Romanycia. </author> <title> The design and control of visual routines for the computation of simple geometric properties and relations. </title> <type> Technical Report 87-34, </type> <institution> University of British Columbia, Van-couver, BC, </institution> <address> Canada V6T 1W5, </address> <month> October </month> <year> 1987. </year>
Reference: [29] <author> Stanley J. Rosenschein and Leslie Pack Kael-bling. </author> <title> The synthesis of machines with provable epistemic properties. </title> <editor> In Joseph Halpern, editor, </editor> <booktitle> Proc. Conf. on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 83-98. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Predicate representations, on the other hand, require the the dynamic generation and maintenance of tree structures in memory, with their attendant overhead and seriality. More to the point, atomic propositional representations allow a simple epistemological theory <ref> [29] </ref>: since the relevant propositions are enumerated in advance, sensors and other perceptual resources can also be allocated in advance to compute the values of all propositions continuously and in parallel and to drive their respective wires with the appropriate values.
Reference: [30] <author> D. E. Rumelhardt, J. L. McClelland, </author> <title> and the PDP Research Group, </title> <editor> editors. </editor> <booktitle> Parallel Distributed Processing: Explorations in the Mi-crostructure of Cognition. </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Researchers have used a wide range of characterizations and justifications for these architectures, ranging from the rejection of representation [7], to neurophysiological plausibility <ref> [30] </ref>, distributed control [24], emergence, and the importance of reactivity [22]. What all these architectures have in common, however is the use of propositional representations instead of structured predicate representations. I should say immediately, that this is an abuse of terminology.
Reference: [31] <author> Anne M. Treisman and Garry Gelade. </author> <title> A feature integration theory of attention. </title> <journal> Cognitive Psychology, </journal> <volume> 12 </volume> <pages> 97-136, </pages> <year> 1980. </year>
Reference-contexts: It supports predicates, variables, and existential quantification, but is easily implemented using parallel hardware in the style of behavior-based or connectionist systems. Bertrand includes a real-time implementation of Ullman's visual routine processor (VRP) theory [32] as it relates to visual search <ref> [31] </ref>. The visual routine processor is a hypothetical "vision computer" providing registers and instructions specialized to computing task-specific visual information.
Reference: [32] <author> Shimon Ullman. </author> <title> Visual routines. </title> <journal> Cognition, </journal> <volume> 18 </volume> <pages> 97-159, </pages> <year> 1984. </year>
Reference-contexts: The fundamental problem with the architecture is that sensory processes have inherent bandwidth limitations. Physiological limitations, such as the fact that your eye can only foveate one place at a time, and the inherent seri-ality of certain perceptual computations <ref> [32] </ref> forces any perceptual system to allocate its attention in a task-specific manner. 1.1 Implementing a world model Consider the standard blocks-world problem of forming a stack of blocks. <p> It supports predicates, variables, and existential quantification, but is easily implemented using parallel hardware in the style of behavior-based or connectionist systems. Bertrand includes a real-time implementation of Ullman's visual routine processor (VRP) theory <ref> [32] </ref> as it relates to visual search [31]. The visual routine processor is a hypothetical "vision computer" providing registers and instructions specialized to computing task-specific visual information. <p> It presents the illusion of a Prolog-like logic programming engine, complete with logic variables and automatic backtracking, but contains no traditional lisp-like pointer structures and has no persistent database of information. 1 2.2.1 The VRP model The visual routines model <ref> [32] </ref> claims that certain kinds of visual work are done by selecting relevant regions of the image and applying simple geometric operations to them such as drawing lines to connect them, searching along the lines for other regions, or checking whether a point lies within a closed curve 1 This perhaps
Reference: [33] <author> S. Whitehead and D. Ballard. </author> <title> Active perception and reinforcement learning. </title> <journal> Neural Computation, </journal> <volume> 2(4), </volume> <year> 1990. </year> <month> 12 </month>
References-found: 33

