URL: ftp://claret.psychology.mcmaster.ca/pub/becker/faces.ps.Z
Refering-URL: http://www.science.mcmaster.ca/Psychology/sb.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Implicit learning in 3D object recognition: The importance of temporal context  
Author: Suzanna Becker 
Note: To appear in Neural Computation Manuscript number  
Date: August 27, 1998  1591  
Affiliation: Department of Psychology McMaster University  
Abstract: A novel architecture and set of learning rules for cortical self-organization is proposed. The model is based on the idea that multiple information channels can modulate one another's plasticity. Features learned from bottom-up information sources can thus be influenced by those learned from contextual pathways, and vice versa. A maximum likelihood cost function allows this scheme to be implemented in a biologically feasible, hierarchical neural circuit. In simulations of the model, we first demonstrate the utility of temporal context in modulating plasticity. The model learns a representation that categorizes people's faces according to identity, independent of viewpoint, by taking advantage of the temporal continuity in image sequences. In a second set of simulations, we add plasticity to the contextual stream and explore variations in the architecture. In this case, the model learns a two-tiered representation, starting with a coarse view-based clustering and proceeding to a finer clustering of more specific stimulus features. This model provides a tenable account of how people may perform 3D object recognition in a hierarchical, bottom-up fashion. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Becker, S. </author> <year> (1993). </year> <title> Learning to categorize objects using temporal coherence. </title> <editor> In S. J. Hanson, J. D. Cowan, & C. L. Giles (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 5 (pp. </booktitle> <pages> 361-368). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Becker, S. </author> <year> (1997). </year> <title> Learning temporally persistent hierarchical representations. </title> <editor> In M. Mozer, M. Jordan, & T. Petsche (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 9 (pp. </booktitle> <pages> 824-830). </pages> <publisher> MIT Press. </publisher>
Reference-contexts: Several investigators (Seergobin, 1996; Wallis & Rolls, 1997; Stewart Bartlett & Sejnowski, 1998) have shown that Foldiak's model, when applied to faces, develops units with broad pose-tuning. Temporal smoothing has also been shown to broaden pose-tuning to faces in feed-forward back-propagation networks <ref> (Becker, 1997) </ref> and in Hopfield-style attractor networks (Stewart Bartlett & Sejnowski, 1997). O'Reilly and Johnson (1994) used feedback inhibition and excitation to achieve temporal smoothing and pose-invariance in a multi-layer model that is perhaps most similar to the one proposed here.
Reference: <author> Becker, S. & Hinton, G. E. </author> <year> (1992). </year> <title> A self-organizing neural network that discovers surfaces in random-dot stereograms. </title> <booktitle> Nature, </booktitle> <address> 355 :161-163. </address>
Reference-contexts: In their model, the outputs from one processing stream modulate the activity in another stream, while the mutual information between the two streams is maximized. They view this algorithm as a compromise between Imax <ref> (Becker & Hinton, 1992) </ref> and In-fomax (Linsker, 1988). A number of other unsupervised learning rules have been proposed based on the assumption of temporally coherent inputs. Becker (1993) and Stone (1996) proposed learning algorithms that maximize the mutual information in a neuron's output at nearby points in time.
Reference: <author> Bridle, J. S. </author> <year> (1990). </year> <title> Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters. </title> <editor> In D. S. Touretzky (Ed.), </editor> <booktitle> Neural Information Processing Systems, </booktitle> <volume> Vol. </volume> <pages> 2 (pp. 111-217). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The gating units receive the contextual stream of input, and produce outputs g i (ff) representing the probability of the ith submodel given the current context, C (ff) . For the simulations reported here, the gating units compute their outputs according to a "softmax function" <ref> (Bridle, 1990) </ref> of their weighted summed inputs x i (ff) : (ff) = P x i X C k where j indexes over all gating units in the network, and v ik is the weight on the connection from the kth contextual input to the ith gating unit.
Reference: <author> Bruce, V. </author> <year> (1997). </year> <title> Human face perception and identification. </title> <booktitle> In NATO ASI on Face Recognition. </booktitle>
Reference-contexts: Participants demonstrated a significant benefit in face-matching from the more coherent temporal context during study. 3 Given that there may be differences in the way humans process faces as compared to other types of objects <ref> (Bruce, 1997) </ref>, Seergobin et al. extended their results in a further set of experiments using static image sequences of novel, artificially generated bumpy objects resembling asteroids.
Reference: <author> Bruce, V. & Valentine, T. </author> <year> (1998). </year> <title> When a nod's as good as a wink. the role of dynamic information in facial recognition. </title> <editor> In M. Gruneberg, P. Morris, & R. Sykes (Eds.), </editor> <booktitle> Practical aspects of memory: Current research and issues (Volume 1) (pp. </booktitle> <pages> 169-174). </pages> <publisher> Wiley. </publisher>
Reference: <author> Cacciatore, T. W. & Nowlan, S. J. </author> <year> (1994). </year> <title> Mixtures of controllers for jump linear and nonlinear plants. </title> <editor> In J. D. Cowan, G. Tesauro, & J. Alspector (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 6 (pp. </booktitle> <pages> 719-726). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. 26 Calvin, </publisher> <editor> W. H. </editor> <year> (1995). </year> <title> Cortical columns, modules, and Hebbian cell assemblies. </title> <booktitle> In M. </booktitle>
Reference: <author> Arbib (Ed.), </author> <title> The handbook of brain theory and neural networks. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Christie, F. & Bruce, V. </author> <year> (1998). </year> <title> The role of dynamic information in the recognition of unfamiliar faces. </title> <journal> Memory and Cognition, </journal> <volume> 26 </volume> (4):780-790. 
Reference: <author> Cudeiro, J. & Sillito, A. M. </author> <year> (1996). </year> <title> Spatial frequency tuning of orientation -discontinuity-sensitive corticofugal feedback to the cat lateral geniculate nucleus. </title> <journal> Journal of physiology, 490.2 :481-492. </journal>
Reference-contexts: of area V1) have been found that are excited by an oriented stimulus in the centre of their receptive field, and show an enhanced response to a similarly oriented stimulus in the surrounding region; on the other hand, the response is suppressed by an orthogonally oriented stimulus in the surround <ref> (Cudeiro & Sillito, 1996) </ref>. In contrast, some cells show just the opposite pattern: they are antagonized by a similarly-oriented stimulus in the surround, and facilitated by an orthogonally-oriented stimulus (Sillito et al., 1995).
Reference: <author> Dayan, P., Hinton, G. E., Neal, R., & Zemel, R. S. </author> <year> (1995). </year> <title> The helmholtz machine. </title> <booktitle> Neural Computation, </booktitle> <address> 7 :1022-1037. </address>
Reference: <author> De Angelis, G. C., Ohzawa, I., & Freeman, R. D. </author> <year> (1995). </year> <title> Receptive-field dynamics in the central visual pathways. </title> <booktitle> Trends in Neurosciences, </booktitle> <volume> 18 </volume> (10):451-458. 
Reference: <author> Dempster, A. P., Laird, N. M., & Rubin, D. B. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Proceedings of the Royal Statistical Society, B-39 :1-38. </journal>
Reference-contexts: In MLCL, the Gaussian means, ~ w i , are obtained by maximizing over L, and the mixing coefficients are either fixed to equal values or alternatingly re-estimated after each update of the model parameters as in the EM algorithm <ref> (Dempster et al., 1977) </ref>. For simplicity, Nowlan typically used a single global variance parameter for all input dimensions, and allowed it to shrink during learning. <p> The variances of each of the Gaussians, 2 i , could be approximated by their maximum likelihood estimates under a mixture model, as in the EM algorithm <ref> (Dempster et al., 1977) </ref>. Instead, we used a simple online approximation to the true variance of the input vector about each 9 clustering unit's weight vector: i = k j w 2 j ) 2 (14) where k is a constant.
Reference: <author> Desimone, R., Albright, T. D., Gross, G., & Bruce, C. </author> <year> (1984). </year> <title> Stimulus-selective properties of inferior temporal neurons in the macaque. </title> <journal> The Journal of Neuroscience, </journal> <volume> 4 </volume> (8):2051-2062. 
Reference: <author> Dong, D. W. & Atick, J. J. </author> <year> (1995). </year> <title> Temporal decorrelation: a theory of lagged and nonlagged responses in the lateral geniculate nucleus. Network: </title> <booktitle> Computation in neural systems, </booktitle> <address> 6 :159-178. </address>
Reference: <author> Douglas, R. & Martin, K. </author> <year> (1990). </year> <editor> Neocortex. In G. M. Shepherd (Ed.), </editor> <booktitle> The Synaptic Organization of the Brain (pp. </booktitle> <pages> 389-438). </pages> <address> New York: </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: In this case, a similar advantage for coherent temporal context in implicit learning was shown. 7.2 Justification for a modular, hierarchical architecture The hierarchical, modular architecture shown in Figure 3 is motivated by several features widely considered to be ubiquitous throughout all regions of the neocortex: a laminar structure <ref> (see e.g. Douglas & Martin, 1990) </ref>, and a functional organization into "cortical clusters".
Reference: <author> Edelman, S. & Weinshall, D. </author> <year> (1991). </year> <title> A self-organizing multiple-view representation of 3D objects. </title> <journal> Biological Cybernetics, </journal> <volume> 64 </volume> (3):209-219. 
Reference: <author> Foldiak, P. </author> <year> (1991). </year> <title> Learning invariance from transformation sequences. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> (2):194-200. 
Reference: <author> Gilbert, C. D., Das, A., Ito, M., Kapadia, M., & Westheimer, G. </author> <year> (1996). </year> <title> Spatial integration and cortical dynamics. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <address> 93 :615-622. </address>
Reference-contexts: On the other hand, about 40% of complex cells (in the superficial layers of area V1) are facilitated by the conjunction of a line segment in their classical receptive field and a colinear line segment placed nearby, outside their classical receptive field <ref> (Gilbert et al., 1996) </ref>. Moreover, even in primary visual cortex, cells' tuning curves (in all cortical layers) are sensitive to the temporal history of the input signal and can show bimodal peaks and even complete reversals in tuning over time (Ringach et al., 1997).
Reference: <author> Gross, C. G., Rocha-Miranda, C. E., & Bender, D. B. </author> <year> (1971). </year> <title> Visual properties of neurons in inferotemporal cortex of the macaque. </title> <journal> Journal of Physiology, </journal> <note> 35 :96-111. 27 Hess, </note> <author> D. J., Foss, D. J., & Carroll, P. </author> <year> (1995). </year> <title> Effects of global and local context on lexical processing during language comprehension. </title> <journal> Journal of Experimental Psychology: General, </journal> <volume> 124 </volume> (1):62-82. 
Reference: <author> Hinton, G. E. & Zemel, R. S. </author> <year> (1994). </year> <title> Autoencoders, minimum description length, and helmholtz free energy. </title> <editor> In J. D. Cowan, G. Tesauro, & J. Alspector (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 6 (pp. </booktitle> <pages> 3-10). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. </author> <year> (1991). </year> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> (1):79-87. 
Reference-contexts: We chose the term "gating units" because their role here is analogous to that of the gating network in the "competing experts" model <ref> (Jacobs et al., 1991) </ref>. In fact, the model proposed here could be viewed as an unsupervised version of the mixture of competing experts architecture. Jacobs et al.'s competing experts network performs supervised learning, and can be interpreted as fitting a mixture of Gaussians model of the training signal.
Reference: <author> Kay, J. & Phillips, W. A. </author> <year> (1997). </year> <title> Activation functions, computational goals, and learning rules for local processors with contextual guidance. </title> <journal> Neural Computation, </journal> <volume> 9 </volume> (4):895-910. 
Reference: <author> Levitt, J. B., Kiper, D. C., & Movshon, J. A. </author> <year> (1994). </year> <title> Receptive fields and functional architecture of macaque v2. </title> <journal> Journal of neurophysiology, </journal> <volume> 71 </volume> (6):2517-2541. 
Reference-contexts: Calvin, 1995), including visual area V2 <ref> (Levitt et al., 1994) </ref>, and inferotemporal cortex (Tanaka et al., 1993). We experimented with two different means of inducing functional modularity in our model: In the first set of simulations, subsets of clustering units shared a common gating unit, and learned to predict similar regions of the contextual space.
Reference: <author> Linsker, R. </author> <year> (1988). </year> <title> Self-organization in a perceptual network. </title> <publisher> IEEE Computer, </publisher> <address> March, 21 :105-117. </address>
Reference-contexts: In their model, the outputs from one processing stream modulate the activity in another stream, while the mutual information between the two streams is maximized. They view this algorithm as a compromise between Imax (Becker & Hinton, 1992) and In-fomax <ref> (Linsker, 1988) </ref>. A number of other unsupervised learning rules have been proposed based on the assumption of temporally coherent inputs. Becker (1993) and Stone (1996) proposed learning algorithms that maximize the mutual information in a neuron's output at nearby points in time.
Reference: <author> MacDonald, J. & McGurk, H. </author> <year> (1978). </year> <title> Visual influences on speech perception processes. </title> <journal> Perception and Psychophysics, </journal> <volume> 24 </volume> (3):253-257. 
Reference: <author> McClelland, J. L., McNaughton, B. L., & O'Reilly, R. C. </author> <year> (1995). </year> <title> Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory. </title> <journal> Psychological Review, </journal> <volume> 102 </volume> (3):419-457. 
Reference-contexts: Finally, our model may be able to account for the interaction between multiple memory systems in the brain. For example, it is widely believed that memories are stored rapidly in the hippocampus and related brain structures, and more gradually stored in the parahippocampal and neocortical areas <ref> (McClelland et al., 1995) </ref>. The manner in which information is represented in the hippocampal system is undoubtedly very different from that of the cortex. A major question is how the two systems interact.
Reference: <author> McClelland, J. L. & Rumelhart, D. E. </author> <year> (1981). </year> <title> An interactive activation model of context effects in letter perception, part I: An account of basic findings. </title> <journal> Psychological Review, </journal> <volume> 88 :375-407. </volume>
Reference-contexts: The ability of context to influence perception has been demonstrated in many domains. For example, letters are recognized more quickly and accurately in the context of words <ref> (see e.g. McClelland & Rumelhart, 1981) </ref>, while words are recognized more efficiently when preceded by related isolated words (see e.g. Neely, 1991), sentences or passages (Hess et al., 1995).
Reference: <author> McGurk, H. & MacDonald, J. </author> <year> (1976). </year> <title> Hearing lips and seeing voices. </title> <booktitle> Nature, </booktitle> <address> 264 :746-748. </address>
Reference: <author> Mel, B. W. </author> <year> (1994). </year> <title> Information processing in dendritic trees. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> (6):1031-1085. 
Reference: <author> Miyashita, Y. </author> <year> (1988). </year> <title> Neuronal correlate of visual associative long-term memory in the primate temporal cortex. </title> <booktitle> Nature, </booktitle> <address> 335 :817-820. </address>
Reference: <author> Mundel, T., Dimitrov, A., & Cowan, J. D. </author> <year> (1997). </year> <title> Visual cortex circuitry and orientation tuning. </title> <booktitle> In Advances in Neural Information Processing Systems 9. </booktitle> <publisher> MIT Press. </publisher> <address> 28 Neely, J. </address> <year> (1991). </year> <title> Semantic priming effects in visual word recognition: A selective review of current findings and theories. </title> <editor> In D. Besner & G. W. Humphreys (Eds.), </editor> <title> Basic processes in reading: Visual Word Recognition (pp. </title> <address> 264-336). Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Nowlan, S. J. </author> <year> (1990). </year> <title> Maximum likelihood competitive learning. </title> <editor> In D. S. Touretzky (Ed.), </editor> <booktitle> Neural Information Processing Systems, </booktitle> <volume> Vol. </volume> <pages> 2 (pp. 574-582). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Third, by choosing an appropriate parametric form for the model, that is, the network architecture and associated statistical 4 assumptions, we can incorporate the added goal of allowing contextual input to modulate the learning. 2.1 Maximum Likelihood Competitive Learning (MLCL) In Maximum Likelihood Competitive Learning (MLCL) <ref> (Nowlan, 1990) </ref>, the units have Gaussian activations, y i , and the network forms a mixture-of-Gaussians model of the data. The result is a simple and elegant network implementation of a widely used statistical clustering algorithm.
Reference: <author> Nowlan, S. J. & Sejnowski, T. J. </author> <year> (1993). </year> <title> Filter selection model for generating visual motion signals. </title> <editor> In S. Hanson, J. D. Cowan, & L. Giles (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 5 (pp. </booktitle> <pages> 369-376). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Oram, M. & Perrett, D. </author> <year> (1994). </year> <title> Modeling visual recognition from neurobiological constraints. </title> <booktitle> Neural Networks, </booktitle> <volume> 7 </volume> (6/7):945-972. 
Reference: <author> O'Reilly, R. C. & Johnson, M. H. </author> <year> (1994). </year> <title> Objection recognition and sensitive periods: A computational analysis of visual imprinting. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> (3):357-389. 
Reference: <author> Perrett, D. I., Hietanen, J. K., Oram, M. W., & Benson, P. J. </author> <year> (1992). </year> <title> Organization and functions of cells responsive to faces in the temporal cortex. </title> <journal> Philosophical transactions of the royal society of London, B, </journal> <volume> 335 :23-30. </volume>
Reference-contexts: et al., 1988; Tanaka et al., 1991) these cells only rarely exhibit either viewpoint invariance or selectivity for a single individual; the vast majority of face cells are tuned to one of only four views (front, back, left and right) and respond roughly equally to the heads of different individuals <ref> (Perrett et al., 1992) </ref>. There are several reasons why it is unlikely that the brain uses a grandmother cell representation as a matter of course. For one, it is very expensive with respect to neural machinery.
Reference: <author> Perrett, D. I., Rolls, E. T., & Caan, W. </author> <year> (1982). </year> <title> Visual neurones responsive to faces in the monkey temporal cortex. </title> <journal> Experimental Brain Research, </journal> <volume> 47 :329-342. </volume>
Reference: <author> Phillips, W. A., Kay, J., & Smyth, D. </author> <year> (1995). </year> <title> The discovery of structure by multi-stream networks of local processors with contextual guidance. </title> <journal> Network, </journal> <volume> 6 :225-246. </volume>
Reference: <author> Pouget, A. & Sejnowski, T. J. </author> <year> (1997). </year> <title> Spatial transformations in the parietal cortex using basis functions. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 9 </volume> (2):222-237. 
Reference: <author> Rao, R. P. N. & Ballard, D. H. </author> <year> (1997). </year> <title> Dynamic model of visual recognition predicts neural response properties in the visual cortex. </title> <journal> Neural Computation, </journal> <volume> 9 </volume> (4):721-764. 
Reference-contexts: The work of Hinton and colleagues on the Helmholtz machine (Hinton & Zemel, 1994; Dayan et al., 1995) and Rao and Ballard's Extended Kalman Filter model <ref> (Rao & Ballard, 1997) </ref> provide two different solutions to this problem. 8 Conclusions A "contextual input" stream was implemented in the simplest possible way in the simulations reported here, using fixed delay lines and recurrent feedback.
Reference: <author> Ringach, D. L., Hawken, M. J., & Shapley, R. </author> <year> (1997). </year> <title> Dynamics of orientation tuning in macaque primary visual cortex. </title> <booktitle> Nature, </booktitle> <address> 387 :281-284. </address>
Reference-contexts: Moreover, even in primary visual cortex, cells' tuning curves (in all cortical layers) are sensitive to the temporal history of the input signal and can show bimodal peaks and even complete reversals in tuning over time <ref> (Ringach et al., 1997) </ref>. These examples demonstrate that neuronal responses can be modulated by secondary sources of information in complex ways. Why would contextual modulation be such a pervasive phenomenon? One obvious reason is that if context can influence processing, it can help in disambiguating or cleaning up noisy stimuli.
Reference: <author> Saul, L. K. & Jordan, M. I. </author> <year> (1996). </year> <title> Exploiting tractable substructures in intractable networks. </title> <editor> In D. Touretzky, M. Mozer, & M. Hasselmo (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 8 (pp. </booktitle> <pages> 486-492). </pages> <publisher> MIT Press. </publisher>
Reference: <author> Seergobin, K. </author> <year> (1996). </year> <title> Unsupervised learning: The impact of temporal and spatial coherence on the formation of visual representations. </title> <type> Master's thesis, </type> <institution> Department of Psychology, McMaster University. </institution> <note> 29 Sillito, </note> <author> A. M., Grieve, K. L., Jones, H. E., Cudeiro, J., & Davis, J. </author> <year> (1995). </year> <title> Visual cortical mechanisms detecting focal orientation discontinuities. </title> <booktitle> Nature, </booktitle> <address> 378 :492-496. </address>
Reference: <author> Stewart Bartlett, M. & Sejnowski, T. J. </author> <year> (1997). </year> <title> Viewpoint invariant face recognition using independent component analysis and attractor networks. </title> <editor> In M. Mozer, M. Jordan, & T. Petsche (Eds.), </editor> <booktitle> Neural Information Processing Systems 9 (pp. </booktitle> <pages> 817-823). </pages> <publisher> MIT Press. </publisher>
Reference-contexts: Several investigators (Seergobin, 1996; Wallis & Rolls, 1997; Stewart Bartlett & Sejnowski, 1998) have shown that Foldiak's model, when applied to faces, develops units with broad pose-tuning. Temporal smoothing has also been shown to broaden pose-tuning to faces in feed-forward back-propagation networks (Becker, 1997) and in Hopfield-style attractor networks <ref> (Stewart Bartlett & Sejnowski, 1997) </ref>. O'Reilly and Johnson (1994) used feedback inhibition and excitation to achieve temporal smoothing and pose-invariance in a multi-layer model that is perhaps most similar to the one proposed here.
Reference: <author> Stewart Bartlett, M. & Sejnowski, T. J. </author> <year> (1998). </year> <title> Learning viewpoint invariant face representations from visual experience by temporal association. In Face recognition: From theory to applications, </title> <booktitle> NATO ASI Series F. </booktitle> <publisher> Springer-Verlag. </publisher>
Reference: <author> Stone, J. </author> <year> (1996). </year> <title> Learning perceptually salient visual parameters using spatiotemporal smoothness constraints. </title> <booktitle> Neural Computation, </booktitle> <address> 8 :1463-1492. </address>
Reference: <author> Tanaka, K., Fujita, I., Kobatake, E., Cheng, K., & Ito, M. </author> <year> (1993). </year> <title> Serial processing of visual object-features in the posterior and anterior parts of the inferotemporal cortex. </title>
Reference-contexts: Calvin, 1995), including visual area V2 (Levitt et al., 1994), and inferotemporal cortex <ref> (Tanaka et al., 1993) </ref>. We experimented with two different means of inducing functional modularity in our model: In the first set of simulations, subsets of clustering units shared a common gating unit, and learned to predict similar regions of the contextual space.
Reference: <author> In T. Ono, L. R. Squire, M. E. Raichle, D. I. Perrett, & M. Fukuda (Eds.), </author> <title> Brain Mechanisms of Perception and Memory, From Neuron to Behavior (pp. </title> <address> 34-46). New York, NY: </address> <publisher> Oxford University Press. </publisher>
Reference: <author> Tanaka, K., Saito, H., Fukada, Y., & Moriya, M. </author> <year> (1991). </year> <title> Coding visual images of objects in the inferotemporal cortex of the macaque monkey. </title> <journal> Journal of Neurophysiology, </journal> <volume> 66 </volume> (1):170-189. 
Reference-contexts: Of particular relevance to the results reported here is their proposal for the organization of object recognition in the infero-temporal cortex (IT). A large body of physiological evidence supports the notion that IT cells are responsible for complex shape coding. After Tanaka and colleagues <ref> (Tanaka et al., 1991) </ref>, Oram and Perrett propose that object recognition is accomplished in a distributed network in IT (particularly area AIT) as follows: each module or column codes for a particular shape class. A given object activates many modules, corresponding to different complex visual features.
Reference: <author> Wallis, G. & Rolls, E. T. </author> <year> (1997). </year> <title> Invariant face and object recognition in the visual system. </title> <booktitle> Progress in Neurobiology, </booktitle> <volume> 51 </volume> (2):167-194. 
Reference: <author> Weinshall, D., Edelman, S., & Bulthoff, H. H. </author> <year> (1990). </year> <title> A self-organizing multiple-view representation of 3D objects. </title> <editor> In D. S. Touretzky (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2 (pp. </booktitle> <pages> 274-282). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Yamane, S., Kaji, S., & Kawano, K. </author> <year> (1988). </year> <title> What facial features activate face neurons in inferotemporal cortex of the monkey. </title> <journal> Experimental Brain Research, </journal> <volume> 73 :209-214. </volume> <pages> 30 </pages>
References-found: 53

