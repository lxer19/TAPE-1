URL: http://www.cs.berkeley.edu/~nir/Papers/tark94.ps
Refering-URL: http://http.cs.berkeley.edu/~nir/publications.html
Root-URL: 
Email: nir@cs.stanford.edu  halpern@almaden.ibm.com  
Title: A Knowledge-Based Framework for Belief Change Part I: Foundations  
Author: Nir Friedman Joseph Y. Halpern 
Address: Stanford, CA 94305-2140  650 Harry Road San Jose, CA 95120-6099  
Affiliation: Stanford University Dept. of Computer Science  IBM Almaden Research Center  
Abstract: We propose a general framework in which to study belief change. We begin by defining belief in terms of knowledge and plausibility: an agent believes ' if he knows that ' is true in all the worlds he considers most plausible. We then consider some properties defining the interaction between knowledge and plausibility, and show how these properties affect the properties of belief. In particular, we show that by assuming two of the most natural properties, belief becomes a KD45 operator. Finally, we add time to the picture. This gives us a framework in which we can talk about knowledge, plausibility (and hence belief), and time, which extends the framework of Halpern and Fagin [HF89] for modeling knowledge in multi-agent systems. We show that our framework is quite expressive and lets us model in a natural way a number of different scenarios for belief change. For example, we show how we can capture an analogue to prior probabilities, which can be updated by "conditioning". In a related paper, we show how the two best studied scenarios, belief revision and belief update, fit into the framework. 
Abstract-found: 1
Intro-found: 1
Reference: [AGM85] <author> C. E. Alchourron, P. Gardenfors, and D. Makinson. </author> <title> On the logic of theory change: partial meet functions for contraction and revision. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-530, </pages> <year> 1985. </year>
Reference-contexts: The focus of this research is to understand how an agent should revise his beliefs as a result of getting new information. In the literature, two instances of this general phenomenon have been studied in detail: Belief revision <ref> [AGM85, Gar88] </ref> attempts to describe how an agent should accommodate a new belief (possibly inconsistent with his other beliefs) about a static world. <p> Perhaps the most straightforward approach to belief change is to simply represent an agent's beliefs as a closed set of formulas in some language and then put constraints on how the beliefs can change. This is essentially the approach taken in <ref> [AGM85, Gar88] </ref>; as these papers show, much can be done with this framework. The main problem with this approach is that it does not provide a good semantics for belief. <p> The reader might wonder whether the framework is too expressive for the purposes of belief change. For example, do we really need a different plausibility space for each agent at each point? As we show in [FH93a], in order to capture the notion of belief revision <ref> [AGM85] </ref> in the most natural way, we do, precisely because the AGM theory puts so few constraints on how beliefs can be revised. On the other hand, it is clear that in many applications there are reasonable constraints on the plausibility spaces.
Reference: [Aum93] <author> R. J. Aumann. </author> <title> Backwards induction and common knowledge of rationality. </title> <booktitle> Presented at the Summer workshop of the Stanford Institute for Theoretical Economics, </booktitle> <year> 1993. </year>
Reference-contexts: More recently, there has been intense scrutiny of the assumption of common knowledge of rationality. Indeed, it has argued variously (a) that common knowledge of rationality is an inconsistent assumption [Bic89, Ren92], (b) that it is consistent and it indeed implies the backwards induction solution <ref> [Aum93] </ref>, and (c) that, while consistent, it does not necessarily imply the backwards induction solution [Ben92, Sta92].
Reference: [BBD91] <author> L. Blume, A. Brandenburger, and E. Dekel. </author> <title> Lexicographic probabilities and choice under uncertainty. </title> <journal> Econometrica, </journal> <volume> 59(1) </volume> <pages> 61-79, </pages> <year> 1991. </year>
Reference-contexts: we examine the relationship between ranked plausibility spaces and a number of other probabilistic approaches to dealing with the problem of conditioning on events of measure 0, including nonstandard probability functions that can assign infinitesimal values [LM92], Popper functions [Fra76], and the lexicographic probabilities approach of Blume, Brandenburger, and Dekel <ref> [BBD91] </ref>. 2.3 Combining knowledge and plausibility We now define a logic that combines knowledge and plausibility. Let L KP be the language obtained by starting with primitive propositions, and closing off under conjunction, negation, and the operators K i and ! i , i = 1; : : :; n. <p> we show how ranked plausibility spaces can be related to a number of probabilistic approaches to dealing with the problem of conditioning on events of measure 0, including nonstandard probability functions that can assign infinitesimal values [LM92], Popper functions [Fra76], and the lexicographic probability approach of Blume, Brandenburger, and Dekel <ref> [BBD91] </ref>. Popper functions take the notion of a conditional probability as primitive. Formally, a Popper function takes two arguments and returns a value in [0; 1], in a way that satisfies a number of axioms described below. <p> Blume, Brandenburger, and Dekel <ref> [BBD91] </ref> consider some related issues from a decision-theoretic viewpoint. Savage, in his seminal book [Sav54], gave a number of axioms characterizing preference order-ings, and showed that any preference ordering could, in a precise sense, be represented by a probability function. In [BBD91], one of Savage's axioms (the so-called Archimedian Axiom) is <p> Blume, Brandenburger, and Dekel <ref> [BBD91] </ref> consider some related issues from a decision-theoretic viewpoint. Savage, in his seminal book [Sav54], gave a number of axioms characterizing preference order-ings, and showed that any preference ordering could, in a precise sense, be represented by a probability function. In [BBD91], one of Savage's axioms (the so-called Archimedian Axiom) is replaced with a weaker axiom AX. <p> It is then shown that the resulting preference order can be represented in terms of a lexicographic probability system (LPS). (We omit the details of the definition here.) The key point is that, as shown in <ref> [BBD91] </ref>, the representation could have been done equally well using an extended probability function.
Reference: [Ben92] <author> E. Ben-Porath. </author> <title> Rationality, Nash equilibrium and backward induction in perfect information games. </title> <type> Working paper, </type> <institution> The Sackler Institute of Economic Studies, Tel-Aviv University, </institution> <year> 1992. </year>
Reference-contexts: Indeed, it has argued variously (a) that common knowledge of rationality is an inconsistent assumption [Bic89, Ren92], (b) that it is consistent and it indeed implies the backwards induction solution [Aum93], and (c) that, while consistent, it does not necessarily imply the backwards induction solution <ref> [Ben92, Sta92] </ref>. While a comparison of these arguments is beyond the scope of this paper, we note that the subtleties typically arise when knowledge is treated as "believed to hold with probability 1" (as is often the case in the game theory literature). <p> Thus, the distinction between knowledge and belief in our framework plays a crucial role here. We construct a system that distinguishes the knowledge and belief of the players during the game. This construction is similar in spirit to Ben-Porath's and Stalnaker's models <ref> [Ben92, Sta92] </ref>. We assume two players are playing n iterations of prisoners dilemma. We model this game as a a two agent system, where each player is an agent.
Reference: [BG93] <author> C. Boutilier and M. Goldszmidt. </author> <title> Revising by conditional beliefs. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> pages 648-654, </pages> <year> 1993. </year>
Reference-contexts: is one that chooses a dominating strategy if there is one, then it is clear that rational players playing a one-shot prisoner's 9 Of course, this only works if there are only countably many disjoint events of interest. 10 Such a change was also studied by Boutilier and Goldszmidt in <ref> [BG93] </ref>. However, since they do not have knowledge in their framework, their models are not expressive enough to represent the agent's beliefs. Rather, they have to use a set of models (i.e., orderings). 13 dilemma both defect.
Reference: [Bic88] <author> C. Bicchieri. </author> <title> Strategic behavior and counterfactuals. </title> <journal> Synthese, </journal> <volume> 76 </volume> <pages> 135-169, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction The study of belief change has been an active area in philosophy and in artificial intelligence [Gar88, KM91] and, more recently, in game theory <ref> [Bic88, Sta92] </ref>. The focus of this research is to understand how an agent should revise his beliefs as a result of getting new information.
Reference: [Bic89] <author> C. Bicchieri. </author> <title> Self refuting theories of strategic interaction: A paradox of common knowledge. </title> <journal> Erkenntnis, </journal> <volume> 30 </volume> <pages> 69-85, </pages> <year> 1989. </year>
Reference-contexts: More recently, there has been intense scrutiny of the assumption of common knowledge of rationality. Indeed, it has argued variously (a) that common knowledge of rationality is an inconsistent assumption <ref> [Bic89, Ren92] </ref>, (b) that it is consistent and it indeed implies the backwards induction solution [Aum93], and (c) that, while consistent, it does not necessarily imply the backwards induction solution [Ben92, Sta92].
Reference: [Bou92] <author> C. Boutilier. Normative, </author> <title> subjective and autoepistemic defaults: Adopting the Ramsey test. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proc. Third International Conference (KR '92), </booktitle> <year> 1992. </year>
Reference-contexts: Roughly speaking, a statement such as "' typically implies " is true at a given world if is true in the most plausible worlds where ' is true. Various authors <ref> [Spo87, KM91, Bou92] </ref> have then interpreted "the agent believes '" as "' is true in the most plausible worlds that the agent considers possible". <p> Under this interpretation, the agent believes ' if true typically implies '. 1 By modeling beliefs in this way, there is an assumption that the ordering is part of the agent's epistemic state. (This assumption is actually made explicitly in <ref> [KLM90, Bou92] </ref>.) This implies that the ordering is subjective, that is, it describes the agent's estimate of what the plausible states are. But actually, an even stronger assumption is being made: namely, that the agent's epistemic state is characterized by a single plausibility ordering. <p> One important feature of our 1 The technique of putting an ordering on worlds has also been used to model counterfactuals, conditionals and non monotonic inference [Lew73, Sho87, KLM90, Pea89]. We focus here on its application to modeling belief. 2 In fact, this issue is discussed by Boutilier <ref> [Bou92] </ref>, although his framework does not allow him to represent such a situation. 2 approach is that it gives us the tools to study how plausibility changes over time. <p> Note that if we assume SDP and that propositions do not change their values along the run, then this reduces to the conditional '! i . Interestingly, in several recent papers <ref> [Bou92, LS93] </ref>, this conditional is given semantics similar to ours but described as "given evidence ', is believed".
Reference: [Bur81] <author> J. Burgess. </author> <title> Quick completeness proofs for some logics of conditionals. </title> <journal> Notre Dame Journal of Formal Logic, </journal> <volume> 22 </volume> <pages> 76-84, </pages> <year> 1981. </year>
Reference-contexts: Unfortunately, if S is infinite it may not have any minimal points. We do not necessarily want S!T to hold if S has no minimal points (since this would give ! some properties not in accord with our intuitions). Thus, we follow the standard technique <ref> [Lew73, Bur81] </ref> of saying that a plausibility structure (; ) satisfies S!T if for every point s 2 S there is a point t 2 T " S such that t s, and there is no point u t such that u 2 S T . <p> The technical details are much in the spirit of the axiomatizations presented in [FH88] for knowledge and probability. Our complete axiomatization for M consists of two "modules": a complete axiomatization for knowledge (i.e., S5) and a complete axiomatization for conditionals (for example, the one given by Burgess in <ref> [Bur81] </ref>). There are no axioms connecting knowledge and plausibility in this case. In the other cases, for each of the conditions we consider, we provide an axiom that characterizes it. The axioms characterizing NORM, REF, RANK and UNIF are taken from [Lew73] and [Bur81], while the axioms for CONS and SDP <p> example, the one given by Burgess in <ref> [Bur81] </ref>). There are no axioms connecting knowledge and plausibility in this case. In the other cases, for each of the conditions we consider, we provide an axiom that characterizes it. The axioms characterizing NORM, REF, RANK and UNIF are taken from [Lew73] and [Bur81], while the axioms for CONS and SDP (and also UNIF) correspond directly to the axioms suggested in [FH88] for their probabilistic counterparts. <p> A Axiomatizing knowledge and plausibility We now describe a sound and complete axiomatization for the logic of knowledge and conditionals. The completeness proofs combine techniques used in epistemic logic [HM92] and conditional logics <ref> [Bur81, FH93b] </ref> are much in the spirit of those in [FH88], so we omit details here. 16 As in the case of probability [FH88], the axiom system can be modularized into components: propo-sitional reasoning, reasoning about knowledge and reasoning about conditionals. <p> The component for propositional reasoning consists of K1 and RK1 (from Section 2.4); the component for reasoning about knowledge consists of K2-K5 and RK2. The component for reasoning about conditionals consists of the following axioms and rule of inference, taken from <ref> [Bur81] </ref>: C1. '! i ' C3. ('! i ( 1 ^ 2 )) ) ('! i 1 ) C5. ((' 1 ! i ) ^ (' 2 ! i )) ) (' 1 _ ' 2 ! i ) RC1.
Reference: [Che80] <author> B. F. Chellas. </author> <title> Modal Logic. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, UK, </address> <year> 1980. </year>
Reference-contexts: M CON S;NORM ) be the structures satisfying CONS (resp. CONS and NORM). Work on belief and knowledge in the literature [Hin62, Lev84, HM92] has focused on the modal systems S5, KD45, D45, and K. We briefly describe these systems here; more details can be found in, for example <ref> [Che80, HM92] </ref>. The system S5 is composed of the following axioms K1-K5 and rules RK1 and RK2: K1. All substitution instances of propositional tautologies K2. K i ' ^ K i (' ) ) ) K i K4.
Reference: [DH88] <author> R. Davis and W. Hamscher. </author> <title> Model-based reasoning: troubleshooting. </title> <editor> In H. </editor> <booktitle> Shrobe and The American Association for Artificial Intelligence, </booktitle> <editor> editors, </editor> <booktitle> Exploring AI, </booktitle> <pages> pages 297-346. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA., </address> <year> 1988. </year> <month> 19 </month>
Reference-contexts: Example 2.1: The circuit diagnosis problem has been well studied in the literature (see <ref> [DH88] </ref> for an overview). Consider a circuit that contains n logical components c 1 ; : : : ; c n . Our target is to construct a plausibility ordering over the possible failures of the circuit. A failure is taken to be a set of faulty components.
Reference: [FH88] <author> R. Fagin and J. Y. Halpern. </author> <title> Reasoning about knowledge and probability: preliminary report. </title> <editor> In M. Y. Vardi, editor, </editor> <booktitle> Proc. Second Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 277-293. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year> <note> An expanded version of this paper appears as IBM Research Report RJ 6020, 1990; to appear in Journal of the ACM. </note>
Reference-contexts: We study these interactions, keeping in mind the interpretation of plausibility in terms of qualitative probability [Pea89]. In view of this interpretation, it is perhaps not surprising that many of the issues studied by Fagin and Halpern <ref> [FH88] </ref> when considering the interaction of knowledge and probability also arise in our framework. There are, however, a number of new issues that arise in our framework due to the interaction between knowledge and belief. <p> In the next section, we review the syntax and semantics of the standard approach to modeling knowledge using Kripke structures and show how plausibility can be added to the framework. Much of our technical discussion of axiomatizations and decision procedures is closely related to that of <ref> [FH88] </ref>. In Section 3, we present our full framework which adds plausibility to the framework of [HF89] for modeling knowledge (and time) in multi-agent systems. In Section 4 we introduce prior plausibilities and show how they can be used. <p> In particular, M 1 captures the assumptions made in [Kle90], while M 2 captures the assumptions made in [Rei87]. Kripke structures for knowledge and plausibility are quite similar to the Kripke structures for knowledge and probability introduced in <ref> [FH88] </ref>. The only difference is that in Kripke structures for knowledge and probability, P (w; i) is a probability space rather than a plausibility space. In [FH88], various natural restrictions on the interactions between the probability spaces P (w; i) and the accessibility relations K i are investigated. <p> Kripke structures for knowledge and plausibility are quite similar to the Kripke structures for knowledge and probability introduced in <ref> [FH88] </ref>. The only difference is that in Kripke structures for knowledge and probability, P (w; i) is a probability space rather than a plausibility space. In [FH88], various natural restrictions on the interactions between the probability spaces P (w; i) and the accessibility relations K i are investigated. Here we similarly investigate restrictions on the interaction between the plausibility spaces and the accessibility relations. <p> Here we similarly investigate restrictions on the interaction between the plausibility spaces and the accessibility relations. Not surprisingly, some of these conditions are exact analogues to conditions investigated in <ref> [FH88] </ref>. We also examine some conditions on plausibility ordering without regard to the knowledge. Such conditions were described before in [Lew73] and other works on conditionals. For consistency, we use a naming scheme similar to those used in [Lew73] and [FH88]. (w;i) consists of all worlds to which agent i assigns <p> of these conditions are exact analogues to conditions investigated in <ref> [FH88] </ref>. We also examine some conditions on plausibility ordering without regard to the knowledge. Such conditions were described before in [Lew73] and other works on conditionals. For consistency, we use a naming scheme similar to those used in [Lew73] and [FH88]. (w;i) consists of all worlds to which agent i assigns some degree of plausibility in world w. We would not expect the agent to place a positive probability on worlds that he considers impossible. <p> We would not expect the agent to place a positive probability on worlds that he considers impossible. Similarly, he would not want to consider as plausible (even remotely) a world he knows to be impossible. This intuition leads us to the following condition, called CONS for consistency (following <ref> [FH88] </ref>): 6 CONS: For all worlds w, (w;i) K i (w). 5 A consequence of assuming CONS is a stronger connection between knowledge and belief. <p> As we said in the introduction, many previous works using conditionals assumed (implicitly or explicitly) that the agent considers only one plausibility ordering possible. This is captured by an assumption called SDP (following <ref> [FH88] </ref>) for state determined plausibilities: SDP: For all w and w 0 , if (w; w 0 ) 2 K i then P (w; i) = P (w 0 ; i). It is easy to see that SDP implies that an agent knows his plausibility ordering. <p> If the agent does not know the value of these parameters, she will not necessarily know which conditionals are true at a given world (as was the case in the example above). This example motivates the condition called uniformity in <ref> [FH88] </ref>. UNIF: For all w, if w 0 2 (w;i) then P (w; i) = P (w 0 ; i). 6 Note that SDP and CONS together imply UNIF. <p> In Appendix A, we present sound and complete axiomatization for the full language L KP for each of the classes of structures described above. The technical details are much in the spirit of the axiomatizations presented in <ref> [FH88] </ref> for knowledge and probability. Our complete axiomatization for M consists of two "modules": a complete axiomatization for knowledge (i.e., S5) and a complete axiomatization for conditionals (for example, the one given by Burgess in [Bur81]). There are no axioms connecting knowledge and plausibility in this case. <p> In the other cases, for each of the conditions we consider, we provide an axiom that characterizes it. The axioms characterizing NORM, REF, RANK and UNIF are taken from [Lew73] and [Bur81], while the axioms for CONS and SDP (and also UNIF) correspond directly to the axioms suggested in <ref> [FH88] </ref> for their probabilistic counterparts. <p> A Axiomatizing knowledge and plausibility We now describe a sound and complete axiomatization for the logic of knowledge and conditionals. The completeness proofs combine techniques used in epistemic logic [HM92] and conditional logics [Bur81, FH93b] are much in the spirit of those in <ref> [FH88] </ref>, so we omit details here. 16 As in the case of probability [FH88], the axiom system can be modularized into components: propo-sitional reasoning, reasoning about knowledge and reasoning about conditionals. <p> The completeness proofs combine techniques used in epistemic logic [HM92] and conditional logics [Bur81, FH93b] are much in the spirit of those in <ref> [FH88] </ref>, so we omit details here. 16 As in the case of probability [FH88], the axiom system can be modularized into components: propo-sitional reasoning, reasoning about knowledge and reasoning about conditionals. The component for propositional reasoning consists of K1 and RK1 (from Section 2.4); the component for reasoning about knowledge consists of K2-K5 and RK2. <p> We now consider the complexity of the validity problem. Our results are based on a combination of results for complexity of epistemic logics [HM92] and conditional logics [FH93b]. Again, the technical details are much in the spirit of those in <ref> [FH88] </ref>. We presume that the reader is familiar with standard complexity-theoretic notions such as NP, co-NP, polynomial space, and exponential time (see [HU79] for details). Theorem A.3: Let C be a subset of f CONS, NORM, REF, SDP, UNIF, RANK g.
Reference: [FH93a] <author> N. Friedman and J. Y. Halpern. </author> <title> A knowledge-based framework for belief change. Part II: revision and update. </title> <type> Technical report, </type> <year> 1993. </year> <note> Submitted, KR'94. </note>
Reference-contexts: Belief revision and belief update describe only two of the many scenarios in which beliefs change. Our goal is to construct a framework to reason about belief change in general. This paper describes the details of that framework. In a companion paper <ref> [FH93a] </ref> we consider the special cases of belief revision and update in more detail. Perhaps the most straightforward approach to belief change is to simply represent an agent's beliefs as a closed set of formulas in some language and then put constraints on how the beliefs can change. <p> This is essentially the approach taken in [AGM85, Gar88]; as these papers show, much can be done with this framework. The main problem with this approach is that it does not provide a good semantics for belief. As we hope to show in this paper and in <ref> [FH93a] </ref>, such a semantics can give us a much deeper understanding of how and why beliefs change. fl To appear, Theoretical Aspects of Reasoning about Knowledge , 1994, Morgan Kaufmann One standard approach to giving semantics to belief is to put a plausibility ordering on a set of worlds (intuitively, the <p> While this question is far from trivial, it is analogous to a question that needs to be addressed by anyone using a Bayesian approach. Just as with probability theory, in many applications, there is a natural prior (or class of priors) we can use. Interestingly, as shown in <ref> [FH93a] </ref>, we can capture belief update [KM91] by considering systems in 8 A similar property of persistence also arises in belief revision; see [FH93a] for further discussion. 12 which the agent has a prior that satisfies certain restrictions. Thus, we can understand belief update by examining these restrictions. <p> Just as with probability theory, in many applications, there is a natural prior (or class of priors) we can use. Interestingly, as shown in <ref> [FH93a] </ref>, we can capture belief update [KM91] by considering systems in 8 A similar property of persistence also arises in belief revision; see [FH93a] for further discussion. 12 which the agent has a prior that satisfies certain restrictions. Thus, we can understand belief update by examining these restrictions. <p> The reader might wonder whether the framework is too expressive for the purposes of belief change. For example, do we really need a different plausibility space for each agent at each point? As we show in <ref> [FH93a] </ref>, in order to capture the notion of belief revision [AGM85] in the most natural way, we do, precisely because the AGM theory puts so few constraints on how beliefs can be revised.
Reference: [FH93b] <author> N. Friedman and J. Y. Halpern. </author> <title> On the complexity of conditional logics. </title> <type> Technical report, </type> <year> 1993. </year> <note> Submitted, KR'94. </note>
Reference-contexts: We also provide complete characterizations of the complexity of the validity problem for all the logics considered, based on complexity results for knowledge [HM92] and for conditionals <ref> [FH93b] </ref>. 3 Knowledge and plausibility in multi-agent systems Having a good model of knowledge and belief is not enough in order to study how beliefs change. <p> A Axiomatizing knowledge and plausibility We now describe a sound and complete axiomatization for the logic of knowledge and conditionals. The completeness proofs combine techniques used in epistemic logic [HM92] and conditional logics <ref> [Bur81, FH93b] </ref> are much in the spirit of those in [FH88], so we omit details here. 16 As in the case of probability [FH88], the axiom system can be modularized into components: propo-sitional reasoning, reasoning about knowledge and reasoning about conditionals. <p> Then AX [A is a sound and complete axiomatization with respect to the structures in M satisfying C. We now consider the complexity of the validity problem. Our results are based on a combination of results for complexity of epistemic logics [HM92] and conditional logics <ref> [FH93b] </ref>. Again, the technical details are much in the spirit of those in [FH88]. We presume that the reader is familiar with standard complexity-theoretic notions such as NP, co-NP, polynomial space, and exponential time (see [HU79] for details).
Reference: [Fra76] <author> B. C. van Fraasen. </author> <title> Representation of conditional probabilities. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 5 </volume> <pages> 417-430, </pages> <year> 1976. </year>
Reference-contexts: In Appendix B we examine the relationship between ranked plausibility spaces and a number of other probabilistic approaches to dealing with the problem of conditioning on events of measure 0, including nonstandard probability functions that can assign infinitesimal values [LM92], Popper functions <ref> [Fra76] </ref>, and the lexicographic probabilities approach of Blume, Brandenburger, and Dekel [BBD91]. 2.3 Combining knowledge and plausibility We now define a logic that combines knowledge and plausibility. <p> In this appendix, we show how ranked plausibility spaces can be related to a number of probabilistic approaches to dealing with the problem of conditioning on events of measure 0, including nonstandard probability functions that can assign infinitesimal values [LM92], Popper functions <ref> [Fra76] </ref>, and the lexicographic probability approach of Blume, Brandenburger, and Dekel [BBD91]. Popper functions take the notion of a conditional probability as primitive. Formally, a Popper function takes two arguments and returns a value in [0; 1], in a way that satisfies a number of axioms described below. <p> As we would expect, if we fix the context B then Pr B (A) = Pr (AjB) satisfies the usual properties of absolute probabilities (i.e., Kolmogorov axioms). Formally, a Popper function satisfies the following axioms <ref> [Fra76] </ref>: P1. 0 Pr (AjB) Pr (BjB) = 1 P2. If Pr ( BjB) 6= 1 then Pr (jB) is a probability function P3.
Reference: [Gar88] <author> P. Gardenfors. </author> <title> Knowledge in Flux. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, UK, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction The study of belief change has been an active area in philosophy and in artificial intelligence <ref> [Gar88, KM91] </ref> and, more recently, in game theory [Bic88, Sta92]. The focus of this research is to understand how an agent should revise his beliefs as a result of getting new information. <p> The focus of this research is to understand how an agent should revise his beliefs as a result of getting new information. In the literature, two instances of this general phenomenon have been studied in detail: Belief revision <ref> [AGM85, Gar88] </ref> attempts to describe how an agent should accommodate a new belief (possibly inconsistent with his other beliefs) about a static world. <p> Perhaps the most straightforward approach to belief change is to simply represent an agent's beliefs as a closed set of formulas in some language and then put constraints on how the beliefs can change. This is essentially the approach taken in <ref> [AGM85, Gar88] </ref>; as these papers show, much can be done with this framework. The main problem with this approach is that it does not provide a good semantics for belief.
Reference: [Gef92] <author> H. Geffner. </author> <title> Default Reasoning. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: As noted above, plausibility spaces can be viewed as a qualitative analogue of probability spaces (see <ref> [Pea89, Gef92] </ref>). The intuition is that s 1 s 2 holds if s 1 is much more probable than s 2 ; and that S!T holds whenever Pr (T jS) has high probability.
Reference: [Gin86] <author> M. L. Ginsberg. </author> <title> Counterfactuals. </title> <journal> Artificial Intelligence, </journal> <volume> 30 </volume> <pages> 35-79, </pages> <year> 1986. </year>
Reference-contexts: The RANK assumption is: RANK: For all w and i, P (w; i) is ranked. While ranked orders are quite natural, they have often been rejected as being too inexpressive <ref> [Gin86] </ref>. The standard argument for partial orders is as follows: In general, an agent may not be able to determine the relative plausibility of a and b. If the plausibility ordering is ranked, the agent is forced to make this determination; with a partial order, he is not.
Reference: [GMP93] <author> M. Goldszmidt, P. Morris, and J. Pearl. </author> <title> A maximum entropy approach to nonmonotonic reasoning. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15 </volume> <pages> 220-231, </pages> <year> 1993. </year>
Reference-contexts: In the literature a special class of plausibility spaces received special attention. A plausibility space is ranked if is a total pre-order, i.e., for any s 1 ; s 2 2 either s 1 s 2 or s 2 s 1 . It is known <ref> [GMP93] </ref> that P is ranked if and only if it corresponds to a family fPr * g such that for any S and T the limit lim *!0 Pr * (T jS) is defined.
Reference: [HF89] <author> J. Y. Halpern and R. Fagin. </author> <title> Modelling knowledge and action in distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 3(4) </volume> <pages> 159-179, </pages> <year> 1989. </year>
Reference-contexts: We want a framework that captures the beliefs of the agent before and after the change. This is achieved by introducing time explicitly into the framework. The resulting framework is an extension of the framework of <ref> [HF89] </ref> for modeling knowledge in multi-agent systems, and allows to to talk about knowledge, plausibility (and hence belief ), and time. As we show by example, with knowledge, plausibility and time represented explicitly in the framework we have a powerful and expressive framework for capturing belief change. <p> Much of our technical discussion of axiomatizations and decision procedures is closely related to that of [FH88]. In Section 3, we present our full framework which adds plausibility to the framework of <ref> [HF89] </ref> for modeling knowledge (and time) in multi-agent systems. In Section 4 we introduce prior plausibilities and show how they can be used. We conclude in Section 5 with some discussion of the general approach. <p> A straightforward approach to adding time is by introducing another relation among worlds that signifies which worlds temporally follow any given world (see for example [KL88]). We prefer to intro duce more structure into the description by adopting the framework of <ref> [HF89] </ref> for modeling multi-agent 7 Shoham and Moses also examine two variants of this definition. 10 systems. This structure gives a natural definition of knowledge and an intuitive way to describe agents' interactions with their environment. <p> P is a function that maps for each agent a point to a plausibility structure over points. We give semantics to sentences in interpreted systems just as in Kripke structures. We add to the language temporal modalities in the standard fashion (see <ref> [HF89] </ref>). These include fl' for "Next time step ' will be true" and 'U that stands for "' is true until the first time that is true". We call this language L KP T .
Reference: [Hin62] <author> J. Hintikka. </author> <title> Knowledge and Belief. </title> <publisher> Cornell University Press, </publisher> <address> Ithaca, NY, </address> <year> 1962. </year>
Reference-contexts: Let M be the set of all Kripke structures for knowledge and plausibility as defined in the previous section, and let M CON S (resp. M CON S;NORM ) be the structures satisfying CONS (resp. CONS and NORM). Work on belief and knowledge in the literature <ref> [Hin62, Lev84, HM92] </ref> has focused on the modal systems S5, KD45, D45, and K. We briefly describe these systems here; more details can be found in, for example [Che80, HM92]. The system S5 is composed of the following axioms K1-K5 and rules RK1 and RK2: K1.
Reference: [HM92] <author> J. Y. Halpern and Y. Moses. </author> <title> A guide to completeness and complexity for modal logics of knowledge and belief. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 319-379, </pages> <year> 1992. </year>
Reference-contexts: We say that ' is satisfiable in M K if there is a model M 2 M K and w, such that (M; w) j= '. It is well known (see, for example, <ref> [HM92] </ref>) that the valid formulas in L K over M K are characterized by the modal logic S5 (which is defined formally in Section 2.4). 2.2 Plausibility spaces We want to extend the logic of knowledge by adding plausibility. <p> Let M be the set of all Kripke structures for knowledge and plausibility as defined in the previous section, and let M CON S (resp. M CON S;NORM ) be the structures satisfying CONS (resp. CONS and NORM). Work on belief and knowledge in the literature <ref> [Hin62, Lev84, HM92] </ref> has focused on the modal systems S5, KD45, D45, and K. We briefly describe these systems here; more details can be found in, for example [Che80, HM92]. The system S5 is composed of the following axioms K1-K5 and rules RK1 and RK2: K1. <p> M CON S;NORM ) be the structures satisfying CONS (resp. CONS and NORM). Work on belief and knowledge in the literature [Hin62, Lev84, HM92] has focused on the modal systems S5, KD45, D45, and K. We briefly describe these systems here; more details can be found in, for example <ref> [Che80, HM92] </ref>. The system S5 is composed of the following axioms K1-K5 and rules RK1 and RK2: K1. All substitution instances of propositional tautologies K2. K i ' ^ K i (' ) ) ) K i K4. <p> We also provide complete characterizations of the complexity of the validity problem for all the logics considered, based on complexity results for knowledge <ref> [HM92] </ref> and for conditionals [FH93b]. 3 Knowledge and plausibility in multi-agent systems Having a good model of knowledge and belief is not enough in order to study how beliefs change. <p> A Axiomatizing knowledge and plausibility We now describe a sound and complete axiomatization for the logic of knowledge and conditionals. The completeness proofs combine techniques used in epistemic logic <ref> [HM92] </ref> and conditional logics [Bur81, FH93b] are much in the spirit of those in [FH88], so we omit details here. 16 As in the case of probability [FH88], the axiom system can be modularized into components: propo-sitional reasoning, reasoning about knowledge and reasoning about conditionals. <p> Then AX [A is a sound and complete axiomatization with respect to the structures in M satisfying C. We now consider the complexity of the validity problem. Our results are based on a combination of results for complexity of epistemic logics <ref> [HM92] </ref> and conditional logics [FH93b]. Again, the technical details are much in the spirit of those in [FH88]. We presume that the reader is familiar with standard complexity-theoretic notions such as NP, co-NP, polynomial space, and exponential time (see [HU79] for details).
Reference: [HT89] <author> J. Y. Halpern and M. R. Tuttle. </author> <title> Knowledge, probability, </title> <booktitle> and adversaries. In Proc. 8th ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 103-118, </pages> <year> 1989. </year> <note> To appear in Journal of the ACM. </note>
Reference-contexts: We would then expect the agent to modify his prior by conditioning on whatever information he has learned. This is essentially the approach taken in <ref> [HT89] </ref> to defining how the agents' probability distribution changes in a multi-agent system. Here we assume that the agents start with a prior plausibility ordering on runs. In this discussion, we assume for simplicity that we are dealing with synchronous systems.
Reference: [HU79] <author> J. E. Hopcroft and J. D. Ullman. </author> <title> Introduction to Automata Theory, Languages and Computation. </title> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Again, the technical details are much in the spirit of those in [FH88]. We presume that the reader is familiar with standard complexity-theoretic notions such as NP, co-NP, polynomial space, and exponential time (see <ref> [HU79] </ref> for details). Theorem A.3: Let C be a subset of f CONS, NORM, REF, SDP, UNIF, RANK g.
Reference: [HV89] <author> J. Y. Halpern and M. Y. Vardi. </author> <title> The complexity of reasoning about knowledge and time, I: lower bounds. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 38(1) </volume> <pages> 195-237, </pages> <year> 1989. </year>
Reference-contexts: Here we assume that the agents start with a prior plausibility ordering on runs. In this discussion, we assume for simplicity that we are dealing with synchronous systems. Intuitively, this means that the agents know what the time is. Following <ref> [HV89] </ref>, we model this by assuming (r; m) ~ i (r 0 ; m 0 ) only if 11 m = m 0 . <p> The conditioning process is especially natural in systems satisfying perfect recall <ref> [HV89] </ref>. A system satisfies prefect recall if the agents' local states encode all the information known in previous states.
Reference: [KL88] <author> S. Kraus and D. J. Lehmann. </author> <title> Knowledge, belief, and time. </title> <journal> Theoretical Computer Science, </journal> <volume> 58 </volume> <pages> 155-174, </pages> <year> 1988. </year>
Reference-contexts: Moreover, the interaction between knowledge and belief satisfies the standard properties considered by Kraus and Lehmann <ref> [KL88] </ref>. Although our major goal is not an abstract study of the properties of knowledge and belief, we view the fact that we have a concrete interpretation under which these properties can be studied to be an important side-benefit of our approach. <p> Theorem 2.4: K (resp., K45, KD45) is a sound and complete axiomatization for L B with respect to M (resp., M CON S , M CONS;N ORM ). Considering knowledge and belief together, Kraus and Lehmann <ref> [KL88] </ref> have argued that the following axioms are appropriate: KB1. B i ' ) K i B i ' KB1 holds in M and KB2 is a consequence of CONS. <p> As a corollary, we can show that there is a close relationship between our framework and that of <ref> [KL88] </ref>. Let KL be the logic of Kraus and Lehmann: Corollary 2.6: For any ' 2 L KB , KL j= ' if and only if M CONS;NORM j= '. Shoham and Moses [SM89] also view belief as being derived from knowledge. <p> As we shall see, this gives a reasonable notion of belief change. A straightforward approach to adding time is by introducing another relation among worlds that signifies which worlds temporally follow any given world (see for example <ref> [KL88] </ref>). We prefer to intro duce more structure into the description by adopting the framework of [HF89] for modeling multi-agent 7 Shoham and Moses also examine two variants of this definition. 10 systems.
Reference: [Kle90] <author> J. de Kleer. </author> <title> Using crude probability estimates to guide diagnosis. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 381-392, </pages> <year> 1990. </year>
Reference-contexts: In this process the plausibility ordering before the change dictates the plausibility ordering after the change. Thus, the prior encodes all the plausibility orderings that can arise in the system. As we show, many situations previously studied in the literature, such as diagnostic reasoning <ref> [Kle90] </ref> and the prisoner's dilemma from game theory, can be easily captured by using such prior plausibilities. The rest of this paper is organized as follows. <p> It is interesting to note that this description captures, albeit somewhat simplistically, the assumptions made in model-based diagnostics. In particular, M 1 captures the assumptions made in <ref> [Kle90] </ref>, while M 2 captures the assumptions made in [Rei87]. Kripke structures for knowledge and plausibility are quite similar to the Kripke structures for knowledge and probability introduced in [FH88]. <p> As before, the agent believes that the faulty components are one of the minimal explanations of his observations. As the agent performs more tests, his knowledge increases and his beliefs might change. This process is very similar to the use of Bayesian updating in diagnosis <ref> [Kle90] </ref>. Example 4.3: Our framework lets us easily capture the process of learning a conditional. Consider Alice of Example 2.3. Now, suppose Alice learns that Bob is a Leftfoot. This does not cause Alice to modify any of her orderings.
Reference: [KLM90] <author> S. Kraus, D. Lehmann, and M. Magidor. </author> <title> Nonmonotonic reasoning, preferential models and cumulative logics. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 167-207, </pages> <year> 1990. </year> <month> 20 </month>
Reference-contexts: Under this interpretation, the agent believes ' if true typically implies '. 1 By modeling beliefs in this way, there is an assumption that the ordering is part of the agent's epistemic state. (This assumption is actually made explicitly in <ref> [KLM90, Bou92] </ref>.) This implies that the ordering is subjective, that is, it describes the agent's estimate of what the plausible states are. But actually, an even stronger assumption is being made: namely, that the agent's epistemic state is characterized by a single plausibility ordering. <p> One important feature of our 1 The technique of putting an ordering on worlds has also been used to model counterfactuals, conditionals and non monotonic inference <ref> [Lew73, Sho87, KLM90, Pea89] </ref>. <p> Our target is to construct a plausibility ordering over the possible failures of the circuit. A failure is taken to be a set of faulty components. We assume that failures of individual components are independent of one another. If we 4 We follow the standard notion for plausibility <ref> [Lew73, KLM90, Pea89] </ref>, which uses the (perhaps confusing) convention of placing the more plausible event on the left of the operator. 4 also assume that the probability of each component failing is the same, we can construct a plausibility ordering as follows: Let * be the probability that a single component
Reference: [KM91] <author> H. Katsuno and A. Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proc. Second International Conference (KR '91), </booktitle> <pages> pages 387-394, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction The study of belief change has been an active area in philosophy and in artificial intelligence <ref> [Gar88, KM91] </ref> and, more recently, in game theory [Bic88, Sta92]. The focus of this research is to understand how an agent should revise his beliefs as a result of getting new information. <p> In the literature, two instances of this general phenomenon have been studied in detail: Belief revision [AGM85, Gar88] attempts to describe how an agent should accommodate a new belief (possibly inconsistent with his other beliefs) about a static world. Belief update <ref> [KM91] </ref>, on the other hand, attempts to describe how an agent should change his beliefs as a result of learning about a change in the world. Belief revision and belief update describe only two of the many scenarios in which beliefs change. <p> Roughly speaking, a statement such as "' typically implies " is true at a given world if is true in the most plausible worlds where ' is true. Various authors <ref> [Spo87, KM91, Bou92] </ref> have then interpreted "the agent believes '" as "' is true in the most plausible worlds that the agent considers possible". <p> Just as with probability theory, in many applications, there is a natural prior (or class of priors) we can use. Interestingly, as shown in [FH93a], we can capture belief update <ref> [KM91] </ref> by considering systems in 8 A similar property of persistence also arises in belief revision; see [FH93a] for further discussion. 12 which the agent has a prior that satisfies certain restrictions. Thus, we can understand belief update by examining these restrictions.
Reference: [KMRW82] <author> D. Kreps, P. Milgrom, J. Roberts, and R. Wilson. </author> <title> Rational cooperation in finitely repeated Prisoners' Dilemma. </title> <journal> Journal of Economic Theory, </journal> <volume> 27(2) </volume> <pages> 245-252, </pages> <year> 1982. </year>
Reference-contexts: How do we account for the fact that rational players do much worse in repeated prisoner's dilemma than supposedly irrational players who cooperate? There has been a great deal of effort in the game-theoretic literature to construct models of prisoner's dilemma where rational players can cooperate (see <ref> [KMRW82] </ref> for one of the best-known examples). More recently, there has been intense scrutiny of the assumption of common knowledge of rationality.
Reference: [Lev84] <author> H. J. Levesque. </author> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proc. National Conference on Artificial Intelligence (AAAI '84), </booktitle> <pages> pages 198-202, </pages> <year> 1984. </year>
Reference-contexts: Let M be the set of all Kripke structures for knowledge and plausibility as defined in the previous section, and let M CON S (resp. M CON S;NORM ) be the structures satisfying CONS (resp. CONS and NORM). Work on belief and knowledge in the literature <ref> [Hin62, Lev84, HM92] </ref> has focused on the modal systems S5, KD45, D45, and K. We briefly describe these systems here; more details can be found in, for example [Che80, HM92]. The system S5 is composed of the following axioms K1-K5 and rules RK1 and RK2: K1.
Reference: [Lew73] <author> D. K. Lewis. </author> <title> Counterfactuals. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA., </address> <year> 1973. </year>
Reference-contexts: One important feature of our 1 The technique of putting an ordering on worlds has also been used to model counterfactuals, conditionals and non monotonic inference <ref> [Lew73, Sho87, KLM90, Pea89] </ref>. <p> Unfortunately, if S is infinite it may not have any minimal points. We do not necessarily want S!T to hold if S has no minimal points (since this would give ! some properties not in accord with our intuitions). Thus, we follow the standard technique <ref> [Lew73, Bur81] </ref> of saying that a plausibility structure (; ) satisfies S!T if for every point s 2 S there is a point t 2 T " S such that t s, and there is no point u t such that u 2 S T . <p> Our target is to construct a plausibility ordering over the possible failures of the circuit. A failure is taken to be a set of faulty components. We assume that failures of individual components are independent of one another. If we 4 We follow the standard notion for plausibility <ref> [Lew73, KLM90, Pea89] </ref>, which uses the (perhaps confusing) convention of placing the more plausible event on the left of the operator. 4 also assume that the probability of each component failing is the same, we can construct a plausibility ordering as follows: Let * be the probability that a single component <p> Here we similarly investigate restrictions on the interaction between the plausibility spaces and the accessibility relations. Not surprisingly, some of these conditions are exact analogues to conditions investigated in [FH88]. We also examine some conditions on plausibility ordering without regard to the knowledge. Such conditions were described before in <ref> [Lew73] </ref> and other works on conditionals. For consistency, we use a naming scheme similar to those used in [Lew73] and [FH88]. (w;i) consists of all worlds to which agent i assigns some degree of plausibility in world w. <p> We also examine some conditions on plausibility ordering without regard to the knowledge. Such conditions were described before in <ref> [Lew73] </ref> and other works on conditionals. For consistency, we use a naming scheme similar to those used in [Lew73] and [FH88]. (w;i) consists of all worlds to which agent i assigns some degree of plausibility in world w. We would not expect the agent to place a positive probability on worlds that he considers impossible. <p> Otherwise, the agent does not have most plausible worlds and this amount to saying that the agent does not believe that any world is the real world. We call this condition NORM for normality (following <ref> [Lew73] </ref>): NORM: For all worlds w, (w;i) 6= ;. We can strengthen this condition somewhat to one that says that the agent always considers the real world possible. We call this condition REF for reflexiveness (following [Lew73]): REF: For all worlds w, w 2 (w;i) . <p> We call this condition NORM for normality (following <ref> [Lew73] </ref>): NORM: For all worlds w, (w;i) 6= ;. We can strengthen this condition somewhat to one that says that the agent always considers the real world possible. We call this condition REF for reflexiveness (following [Lew73]): REF: For all worlds w, w 2 (w;i) . As we said in the introduction, many previous works using conditionals assumed (implicitly or explicitly) that the agent considers only one plausibility ordering possible. <p> On the other hand, in structures satisfying SDP this formula is satisfiable only when tell (') is false in all the worlds Alice considers plausible. 5 We remark that CONS is inappropriate if we use ! to model, not plausibility, but counterfactual conditions, as is done by Lewis <ref> [Lew73] </ref>. If CONS holds, then it is easy to see that K i ' ) K i (:'! i ) is valid, for all . <p> All substitution instances of propositional tautologies K2. K i ' ^ K i (' ) ) ) K i K4. K i ' ) K i K i ' 6 Note that this condition is not the same as uniformity as defined in <ref> [Lew73] </ref>; rather, it corresponds in the Lewis terminology to absoluteness. 8 RK1. From ' and ' ) infer RK2. From ' infer K i ' The system KD45 for belief consists of axioms B1-B5 and rules of inference RB1 and RB2. <p> There are no axioms connecting knowledge and plausibility in this case. In the other cases, for each of the conditions we consider, we provide an axiom that characterizes it. The axioms characterizing NORM, REF, RANK and UNIF are taken from <ref> [Lew73] </ref> and [Bur81], while the axioms for CONS and SDP (and also UNIF) correspond directly to the axioms suggested in [FH88] for their probabilistic counterparts.
Reference: [LM92] <author> D. Lehmann and M. Magidor. </author> <title> What does a conditional knowledge base entail? Artificial Intelligence, </title> <booktitle> 55 </booktitle> <pages> 1-60, </pages> <year> 1992. </year>
Reference-contexts: In Appendix B we examine the relationship between ranked plausibility spaces and a number of other probabilistic approaches to dealing with the problem of conditioning on events of measure 0, including nonstandard probability functions that can assign infinitesimal values <ref> [LM92] </ref>, Popper functions [Fra76], and the lexicographic probabilities approach of Blume, Brandenburger, and Dekel [BBD91]. 2.3 Combining knowledge and plausibility We now define a logic that combines knowledge and plausibility. <p> In this appendix, we show how ranked plausibility spaces can be related to a number of probabilistic approaches to dealing with the problem of conditioning on events of measure 0, including nonstandard probability functions that can assign infinitesimal values <ref> [LM92] </ref>, Popper functions [Fra76], and the lexicographic probability approach of Blume, Brandenburger, and Dekel [BBD91]. Popper functions take the notion of a conditional probability as primitive. <p> The idea is to consider an extension R fl of the reals that satisfies all the properties of the reals. Then it is possible to define non-standard probability as a mapping into [0; 1] fl , the extended interval. Probability still satisfies the usual Kolmogorov axioms. Lehmann and Magidor <ref> [LM92] </ref> show the following correspondence: Theorem B.2: [LM92] For every non-standard probability function Pr fl , there is a ranked plausibility space P Pr fl such that S!T holds in P Pr fl if and only if 1 Pr fl (T jS) is infinitesimal. <p> Then it is possible to define non-standard probability as a mapping into [0; 1] fl , the extended interval. Probability still satisfies the usual Kolmogorov axioms. Lehmann and Magidor <ref> [LM92] </ref> show the following correspondence: Theorem B.2: [LM92] For every non-standard probability function Pr fl , there is a ranked plausibility space P Pr fl such that S!T holds in P Pr fl if and only if 1 Pr fl (T jS) is infinitesimal.
Reference: [LS93] <author> P. Lamarre and Y. Shoham. </author> <title> Knowledge, certainty, belief, </title> <editor> and conditionalizition. </editor> <year> 1993. </year>
Reference-contexts: Note that if we assume SDP and that propositions do not change their values along the run, then this reduces to the conditional '! i . Interestingly, in several recent papers <ref> [Bou92, LS93] </ref>, this conditional is given semantics similar to ours but described as "given evidence ', is believed".
Reference: [Pea89] <author> J. Pearl. </author> <title> Probabilistic semantics for nonmonotonic reasoning: A survey. </title> <editor> In R. J. Brachman, H. J. Levesque, and R. Reiter, editors, </editor> <booktitle> Proc. First International Conference on Principles of Knowledge Representation and Reasoning (KR '89), </booktitle> <pages> pages 505-516, </pages> <year> 1989. </year> <note> Reprinted in Readings in Uncertain Reasoning, </note> <editor> G. Shafer and J. Pearl (eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990, </year> <pages> pp. 699-710. </pages>
Reference-contexts: The properties of belief depend on how the plausibility ordering interacts with the accessibility relation that defines knowledge. We study these interactions, keeping in mind the interpretation of plausibility in terms of qualitative probability <ref> [Pea89] </ref>. In view of this interpretation, it is perhaps not surprising that many of the issues studied by Fagin and Halpern [FH88] when considering the interaction of knowledge and probability also arise in our framework. <p> One important feature of our 1 The technique of putting an ordering on worlds has also been used to model counterfactuals, conditionals and non monotonic inference <ref> [Lew73, Sho87, KLM90, Pea89] </ref>. <p> To do this, we must first introduce plausibility spaces, which can be viewed as a qualitative analogue of probability spaces <ref> [Pea89] </ref>. For now, we discuss these structures in the abstract; in the next section, we combine them with knowledge. A plausibility space describes a qualitative measure of plausibility over some set of alternatives (one can think of them as possible worlds). <p> As noted above, plausibility spaces can be viewed as a qualitative analogue of probability spaces (see <ref> [Pea89, Gef92] </ref>). The intuition is that s 1 s 2 holds if s 1 is much more probable than s 2 ; and that S!T holds whenever Pr (T jS) has high probability. <p> The problem is that, with this definition, we can easily construct examples where S!T holds, and yet Pr (T jS) can be arbitrarily small. The standard way to overcome this problem <ref> [Pea89] </ref> is to consider, not one *, but a sequence of *'s converging to 0. More formally, consider a family fPr * : * &gt; 0g of probability distributions on , parameterized by *. <p> Our target is to construct a plausibility ordering over the possible failures of the circuit. A failure is taken to be a set of faulty components. We assume that failures of individual components are independent of one another. If we 4 We follow the standard notion for plausibility <ref> [Lew73, KLM90, Pea89] </ref>, which uses the (perhaps confusing) convention of placing the more plausible event on the left of the operator. 4 also assume that the probability of each component failing is the same, we can construct a plausibility ordering as follows: Let * be the probability that a single component
Reference: [Rei87] <author> R. Reiter. </author> <title> A theory of diagnosis from first principles. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 57-95, </pages> <year> 1987. </year> <note> Reprinted in in Readings in Nonmonotonic Reasoning, </note> <editor> M. L. Ginsberg (ed.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA. </address> <year> 1987, </year> <pages> pp. 352-371. </pages>
Reference-contexts: It is interesting to note that this description captures, albeit somewhat simplistically, the assumptions made in model-based diagnostics. In particular, M 1 captures the assumptions made in [Kle90], while M 2 captures the assumptions made in <ref> [Rei87] </ref>. Kripke structures for knowledge and plausibility are quite similar to the Kripke structures for knowledge and probability introduced in [FH88]. The only difference is that in Kripke structures for knowledge and probability, P (w; i) is a probability space rather than a plausibility space.
Reference: [Ren92] <author> P. Reny. </author> <title> Rationality in extensive form games. </title> <journal> Journal of Economic Perspectives, </journal> <volume> 6 </volume> <pages> 103-118, </pages> <year> 1992. </year>
Reference-contexts: More recently, there has been intense scrutiny of the assumption of common knowledge of rationality. Indeed, it has argued variously (a) that common knowledge of rationality is an inconsistent assumption <ref> [Bic89, Ren92] </ref>, (b) that it is consistent and it indeed implies the backwards induction solution [Aum93], and (c) that, while consistent, it does not necessarily imply the backwards induction solution [Ben92, Sta92].
Reference: [Sav54] <author> L. J. Savage. </author> <title> Foundations of Statistics. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1954. </year>
Reference-contexts: Blume, Brandenburger, and Dekel [BBD91] consider some related issues from a decision-theoretic viewpoint. Savage, in his seminal book <ref> [Sav54] </ref>, gave a number of axioms characterizing preference order-ings, and showed that any preference ordering could, in a precise sense, be represented by a probability function. In [BBD91], one of Savage's axioms (the so-called Archimedian Axiom) is replaced with a weaker axiom AX.
Reference: [Sho87] <author> Y. Shoham. </author> <title> A semantical approach to nonmonotonic logics. </title> <booktitle> In Proc. 2nd IEEE Symp. on Logic in Computer Science, </booktitle> <pages> pages 275-279, </pages> <year> 1987. </year> <note> Reprinted in in Readings in Nonmonotonic Reasoning, </note> <editor> M. L. Ginsberg (ed.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA. </address> <year> 1987, </year> <pages> pp. 227-250. </pages>
Reference-contexts: One important feature of our 1 The technique of putting an ordering on worlds has also been used to model counterfactuals, conditionals and non monotonic inference <ref> [Lew73, Sho87, KLM90, Pea89] </ref>.
Reference: [SM89] <author> Y. Shoham and Y. Moses. </author> <title> Belief as defeasible knowledge. </title> <booktitle> In Proc. Eleventh International Joint Conference on Artificial Intelligence (IJCAI '89), </booktitle> <pages> pages 1168-1173, </pages> <year> 1989. </year>
Reference-contexts: Let KL be the logic of Kraus and Lehmann: Corollary 2.6: For any ' 2 L KB , KL j= ' if and only if M CONS;NORM j= '. Shoham and Moses <ref> [SM89] </ref> also view belief as being derived from knowledge. The intuition that they try to capture is that once the agent makes a defeasible assumption the rest of his beliefs should follow from his knowledge.
Reference: [Spo87] <author> W. Spohn. </author> <title> Ordinal conditional functions: a dynamic theory of epistemic states. </title> <editor> In W. Harper and B. Skyrms, editors, </editor> <title> Causation in Decision, </title> <journal> Belief Change and Statistics, </journal> <volume> volume 2, </volume> <pages> pages 105-134. </pages> <publisher> Reidel, Dordrecht, Holland, </publisher> <year> 1987. </year>
Reference-contexts: Roughly speaking, a statement such as "' typically implies " is true at a given world if is true in the most plausible worlds where ' is true. Various authors <ref> [Spo87, KM91, Bou92] </ref> have then interpreted "the agent believes '" as "' is true in the most plausible worlds that the agent considers possible".
Reference: [Sta92] <author> R. C. Stalnaker. </author> <title> Knowledge, belief and counterfactual reasoning in games. </title> <booktitle> Forthcoming in Proceedings of the Second Castiglioncello Conference, </booktitle> <editor> edited by C. Bicchieri and B. Skyrms., </editor> <year> 1992. </year>
Reference-contexts: 1 Introduction The study of belief change has been an active area in philosophy and in artificial intelligence [Gar88, KM91] and, more recently, in game theory <ref> [Bic88, Sta92] </ref>. The focus of this research is to understand how an agent should revise his beliefs as a result of getting new information. <p> Indeed, it has argued variously (a) that common knowledge of rationality is an inconsistent assumption [Bic89, Ren92], (b) that it is consistent and it indeed implies the backwards induction solution [Aum93], and (c) that, while consistent, it does not necessarily imply the backwards induction solution <ref> [Ben92, Sta92] </ref>. While a comparison of these arguments is beyond the scope of this paper, we note that the subtleties typically arise when knowledge is treated as "believed to hold with probability 1" (as is often the case in the game theory literature). <p> Thus, the distinction between knowledge and belief in our framework plays a crucial role here. We construct a system that distinguishes the knowledge and belief of the players during the game. This construction is similar in spirit to Ben-Porath's and Stalnaker's models <ref> [Ben92, Sta92] </ref>. We assume two players are playing n iterations of prisoners dilemma. We model this game as a a two agent system, where each player is an agent. <p> l The beginning of the ordering for t 2 l is the same, except that it does not include the type t 3 l+1 : 0 t 2 : : : t 1 t 2 l l t 2 : : : 11 This definition is similar to Stalnaker's definition <ref> [Sta92] </ref>, but has the advantage that it can be represented in our language without introducing counterfactuals.
Reference: [Voo92] <author> F. Voorbraak. </author> <title> Generalized Kripke models for epistemic logic. </title> <booktitle> In Theoretical Aspects of Reasoning about Knowledge: Proc. Fourth Conference, </booktitle> <pages> pages 214-228, </pages> <year> 1992. </year> <month> 21 </month>
Reference-contexts: Given w and i, suppose ff characterizes the most plausible worlds in P (w; i). Then (M; w) j= B i ' if and only if (M; w) j= B ff i '. Voorbraak <ref> [Voo92] </ref> distinguishes two notions of knowledge: objective and true justified belief . He then studies the interaction of both notions of knowledge with beliefs. The intuition we assign to knowledge is similar to his notion of objective knowledge.
References-found: 43

