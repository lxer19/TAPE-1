URL: ftp://kant.irmkant.rm.cnr.it/pub/econets/nolfi.learn-evo.ps.Z
Refering-URL: http://kant.irmkant.rm.cnr.it/public.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: stefano@kant.irmkant.rm.cnr.it elman@crl.ucsd.edu domenico@gracco.irmkant.rm.cnr.it  
Phone: voice: 0039-6-86894596 fax: 0039-6-824737  
Title: Learning and evolution in neural networks  
Author: Stefano Nolfi* Jeffrey L. Elman+ Domenico Parisi* 
Note: To appear in Adaptive Behavior.  
Date: June 1994  
Address: San Diego, La Jolla.  15, Viale Marx 00137 Rome Italy  
Affiliation: Institute of Psychology C.N.R. Rome  *Institute of Psychology, National Research Council, Rome, Italy +Department of Cognitive Science, University of California,  Department of Neural Systems and Artificial Life  
Pubnum: Technical Report 94-08  
Abstract-found: 0
Intro-found: 1
Reference: <author> Ackley, D.E. & Littman, </author> <title> M.L. (1991). Interactions between learning and evolution. In C.G. </title> <editor> Langton, </editor> <address> C. </address>
Reference: <editor> Taylor, J.D. Farmer, & S. Rasmussen (Eds.), </editor> <booktitle> Artificial Life II . Reading, </booktitle> <address> Mass.: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Baldwin, J.M. </author> <title> (1896). A new factor in evolution. </title> <publisher> American Naturalist , 30 , 441-451. </publisher>
Reference: <author> Belew, R.K. </author> <year> (1990). </year> <title> Evolution, learning, and culture: computational metaphors for adaptive algorithms. </title> <journal> Complex Systems , 4 , 11-49. </journal>
Reference: <author> Belew, R.K., McInerney, J., & Schraudolph, N. </author> <year> (1991). </year> <title> Evolving networks: using the genetic algorithm with connectionist learning. In C.G. </title> <editor> Langton, C. Taylor, J.D. Farmer, & S. Rasmussen (Eds.), </editor> <booktitle> Artificial Life II . Reading, </booktitle> <address> Mass.: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In some researches evolution selects good architectures for learning (Miller, Todd, & Hedge, 1989; Kitano, 1990; Nolfi & Parisi, in press). In other cases evolution can select good initial weights or good learning rates or momentums <ref> (Belew, McInerney, & Schraudolph, 1991) </ref>, or even good learning rules (Chalmers, 1990). But if the evolutionary task and the learning task are the same task, it is more difficult to investigate how learning can influence evolution.
Reference: <author> Chalmers, D.J. </author> <year> (1990). </year> <title> The evolution of learning: an experiment in genetic connectionism. </title> <editor> In D.S. Touretzky, J.L. Elman, T.J. Sejnowski, & G.E. Hinton (Eds.), </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School . San Matteo, </booktitle> <address> CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In some researches evolution selects good architectures for learning (Miller, Todd, & Hedge, 1989; Kitano, 1990; Nolfi & Parisi, in press). In other cases evolution can select good initial weights or good learning rates or momentums (Belew, McInerney, & Schraudolph, 1991), or even good learning rules <ref> (Chalmers, 1990) </ref>. But if the evolutionary task and the learning task are the same task, it is more difficult to investigate how learning can influence evolution.
Reference: <author> Kitano, H. </author> <year> (1990). </year> <title> Designing neural networks using genetic algorithms with graph generation system. </title> <journal> Complex Systems , 4 , 461-476. </journal>
Reference: <author> Kolen, J.F. & Pollack J.B. </author> <year> (1990). </year> <title> Back propagation is sensitive to initial conditions. </title> <journal> Complex Systems , 4 , 269-280. </journal>
Reference: <author> Hinton, G.E. & Nowlan S.J. </author> <year> (1987). </year> <title> How learning can guide evolution. </title> <journal> Complex Systems , 1 , 495-502. </journal>
Reference-contexts: Evolution can help learning by creating good conditions for learning to occur (e.g. good initial weights, good network architectures, good learning rates, etc.) and learning can guide evolution by exploring approximations to the solutions sought by evolution <ref> (Hinton & Nowlan, 1987) </ref>. However, it is not clear that it is legitimate to make in general the assumption that what is learned during life automatically increases the fitness of the individuals that are learning that particular task.
Reference: <author> Holland, J.J. </author> <year> (1975). </year> <title> Adaptation in natural and artificial systems . Ann Arbor, </title> <type> Mich.: </type> <institution> University of Michigan Press. </institution>
Reference-contexts: Evolutionary change occurs from one generation to the next while learning is change during the lifetime of a single individual. To study how evolution and learning may interact much research has been dedicated recently to applying genetic algorithms <ref> (Holland, 1975) </ref> to populations of neural networks that learn during life (Yao, 1993; Langton, Taylor, Farmer, & Rasmussen 1991). Neural networks reproduce selectively on the basis of some fitness criterion and offspring inherit some properties from their parent (s).
Reference: <author> Yao, X., </author> <year> (1993). </year> <title> Evolutionary artificial neural networks. </title> <note> International Journal of Neural Systems , 4 , 203-222 Jefferson, </note> <author> D., Collins, R., Cooper, C. Dyer, M., & Flowers, M. </author> <year> (1991). </year> <title> Evolution as a theme in Artificial Life: the genesys/tracker system. In C.G. </title> <editor> Langton, C. Taylor, J.D. Farmer, & S. Rasmussen (Eds.), </editor> <booktitle> Artificial Life II . Reading, </booktitle> <address> Mass.: </address> <publisher> Addison-Wesley. </publisher>
Reference: <editor> Langton, C.G.,Taylor, C., Farmer, J.D., & Rasmussen, S. (Eds.) </editor> <booktitle> (1991). Artificial Life II . Reading, </booktitle> <address> Mass.: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Menczer, F. & Parisi, D. </author> <year> (1992). </year> <title> Recombination and unsupervised learning: Effects of crossover on the genetic optimization of neural networks. </title> <type> Network , 3 , 423-442. </type>
Reference: <author> Miller, G.F., Todd, P.M., & Hedge, S.U. </author> <year> (1989). </year> <title> Designing neural networks using genetic algorithms. In. </title> <publisher> J.D. </publisher>
Reference: <editor> Schaffer (Ed.), </editor> <booktitle> Proceedings of the Third International. Conference on Genetic Algorithms . San Mateo, </booktitle> <address> CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Nolfi, S., & Parisi, D. </author> <year> (1993). </year> <title> Auto-teaching: networks that develop their own teaching input. In. </title> <publisher> J.L. </publisher>
Reference: <author> Deneubourg, H. Bersini, S. Goss, G. </author> <title> Nicolis, </title> & <editor> R. Dagonnier (Eds), </editor> <booktitle> Proceedings of the Second European Conference on Artificial Life . Brussels, </booktitle> <institution> Free University of Brussels. </institution>
Reference: <author> Nolfi, S., & Parisi, D. </author> <title> (in press). "Genotypes" for Neural Networks. </title> <editor> In M. A. Arbib (Ed.), </editor> <booktitle> The Handbook of Brain Theory and Neural Networks . Cambridge, </booktitle> <address> Mass.: </address> <publisher> MIT Press. </publisher>
Reference: <author> Parisi, D., Cecconi, F., & Nolfi, S. </author> <year> (1990). </year> <title> Econets: neural networks that learn in an environment. </title> <type> Network , 1 , 149-168. </type>
Reference: <author> Parisi, D., Nolfi, S., & Cecconi, </author> <title> F (1992). Learning, behavior, and evolution. </title> <editor> In F. Varela & P. Bourgine (Eds.), </editor> <booktitle> Toward a pratice of autonomous systems . Cambridge, </booktitle> <address> Mass.: </address> <publisher> MIT Press. 16 Rumelhart, </publisher> <editor> D.E., Hinton G.E., & Williams, </editor> <address> R.J. </address> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In D.E. Rumelhart & J.L. McClelland (Eds.), </editor> <booktitle> Parallel Distributed Processing. Vol.1: Foundations . Cambridge, </booktitle> <address> Mass.: </address> <publisher> MIT Press. </publisher>
Reference: <author> Waddington, C.H. </author> <year> (1942). </year> <title> Canalization of development and the inheritance of acquired characters. </title> <type> Nature , 150 , 563-565. </type>
Reference: <author> Williams, </author> <title> B.V., & Bounds, </title> <address> D.G. </address> <year> (1993). </year> <title> Learning and Evolution in Populations of Backprop Networks. </title> <booktitle> In. </booktitle>
Reference: <author> J.L. Deneubourg, H. Bersini, S. Goss, G. </author> <title> Nicolis, </title> & <editor> R. Dagonnier (Eds), </editor> <booktitle> Proceedings of the Second European Conference on Artificial Life . Brussels, Free University of Brussels. </booktitle> <volume> 17 18 19 20 21 22 23 24 </volume>
References-found: 23

