URL: http://www.cs.virginia.edu/~nr/cs655/readings/zorn-garbage.ps.gz
Refering-URL: http://www.cs.virginia.edu/~nr/cs655/readings/indexbody.html
Root-URL: http://www.cs.virginia.edu
Title: The Measured Cost of Conservative Garbage Collection  
Author: Benjamin Zorn 
Date: April 1992  
Address: Campus Box #430  Boulder 80309-0430  Boulder  
Affiliation: Department of Computer Science  University of Colorado,  ffi University of Colorado at  
Pubnum: CU-CS-573-92  
Abstract: Technical Report CU-CS-573-92 Department of Computer Science Campus Box 430 University of Colorado Boulder, Colorado 80309 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew W. Appel. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software|Practice and Experience, </journal> <volume> 19(2) </volume> <pages> 171-183, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: This increase occurs because only a small part of the program's address space is visited during a collection. Generation garbage collection has been successfully used in languages including Lisp [21], Smalltalk [26], and ML <ref> [1] </ref>. Because generation collection relies on the behavior that most objects live a relatively short time, generation collection will only be effective for C if C programs also display this behavior. Figure 8 shows the survival curves for objects in five of the applications used in this paper.
Reference: [2] <author> Joel Bartlett. </author> <title> Mostly-copying garbage collection picks up generations and C++. </title> <type> Technical Report TN-12, </type> <institution> Digital Equipment Corporation Western Research Labortory, </institution> <address> Palo Alto, CA, </address> <month> October </month> <year> 1989. </year>
Reference-contexts: Several different conservative collection algorithms have been implemented and described. These include early work by Caplinger [9], an unpublished implementation similar to the Boehm-Weiser collector by Doug McIlroy [6], another unpublished implementation by Paul Hilfinger [14], and a mostly-copying garbage collector by Bartlett <ref> [2, 4] </ref>. The conservative collection algorithm that is considered in this paper is the one described by Boehm and Weiser [5] (version 1.6 of the software) 3 . Of the implementations mentioned, this implementation is easy to obtain and requires the least effort to use. <p> Boehm et al. have a technique called "sticky-mark-bit," currently available in the Portable Common Runtime system, that adds generations to their conservative collection algorithm [11]. Bartlett also has extended a mostly-copying conservative collection algorithm for C++ to use generation techniques <ref> [2] </ref>. From these research initiatives and others 31 that may develop as the true potential of conservative garbage collection becomes clear, it is likely that much better conservative collection algorithms, with increased locality of reference and decreased address space needs, will be discovered.
Reference: [3] <author> Joel Bartlett. </author> <title> Comment on his experiences with software-caused total system failures. </title> <type> Private Communication, </type> <month> May </month> <year> 1992. </year>
Reference-contexts: In addition, storage management bugs that are not found can greatly contribute to the unreliability of software. Bartlett has noted that a large fraction of software-caused total system failures are caused by memory management errors <ref> [3] </ref>. While the advantages of freeing the programmer from explicit storage management are difficult to quantify, they are obvious and substantial.
Reference: [4] <author> Joel F. Bartlett. </author> <title> Compacting garbage collection with ambiguous roots. </title> <type> Technical Report 88/2, </type> <institution> Digital Equipment Corporation Western Research Labortory, </institution> <address> Palo Alto, CA, </address> <month> February </month> <year> 1988. </year>
Reference-contexts: Several different conservative collection algorithms have been implemented and described. These include early work by Caplinger [9], an unpublished implementation similar to the Boehm-Weiser collector by Doug McIlroy [6], another unpublished implementation by Paul Hilfinger [14], and a mostly-copying garbage collector by Bartlett <ref> [2, 4] </ref>. The conservative collection algorithm that is considered in this paper is the one described by Boehm and Weiser [5] (version 1.6 of the software) 3 . Of the implementations mentioned, this implementation is easy to obtain and requires the least effort to use.
Reference: [5] <author> H. Boehm and M. Weiser. </author> <title> Garbage collection in an uncooperative environment. </title> <journal> Software|Practice and Experience, </journal> <pages> pages 807-820, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: The conservative collection algorithm that is considered in this paper is the one described by Boehm and Weiser <ref> [5] </ref> (version 1.6 of the software) 3 . Of the implementations mentioned, this implementation is easy to obtain and requires the least effort to use. Their algorithm implements a mark-and-sweep garbage collector that does not relocate objects and follows pointers conservatively. <p> For this algorithm, the root set includes all data in the stack, data segment, and registers. Any potential pointer is followed and the object pointed to is marked (details about how ambiguous pointers are resolved are included in <ref> [5] </ref>). After visiting reachable objects, the sweep phase reclaims objects that are no longer in use and places them on the appropriate free list. One of the biggest differences between an explicit storage management algorithm and a garbage collection algorithm is the size and structure of the heap. <p> Boehm and Weiser note that their collector may result in extra cache misses because chunk headers, which are frequently accessed, are also page aligned, and thus contain the same least significant bits in their addresses <ref> [5] </ref>. My measurements confirm their observation. algorithm appears to be 3-10 times higher than the BSD algorithm. Figure 7 shows the cache miss rate as a function of cache size in the gawk application, assuming a direct-mapped cache.
Reference: [6] <author> Hans-J Boehm and Alan Demers. </author> <title> Conservative garbage collector implementation documentation. Reference to other implementations of conservative garbage collection. From documentation of version 1.6 of the software, </title> <year> 1989. </year>
Reference-contexts: Several different conservative collection algorithms have been implemented and described. These include early work by Caplinger [9], an unpublished implementation similar to the Boehm-Weiser collector by Doug McIlroy <ref> [6] </ref>, another unpublished implementation by Paul Hilfinger [14], and a mostly-copying garbage collector by Bartlett [2, 4]. The conservative collection algorithm that is considered in this paper is the one described by Boehm and Weiser [5] (version 1.6 of the software) 3 .
Reference: [7] <author> G. Bozman, W. Buco, T. P. Daly, and W. H. </author> <title> Tetzlaff. </title> <journal> Analysis of free-storage algorithms|revisited. IBM Systems Journal, </journal> <volume> 23(1) </volume> <pages> 44-64, </pages> <year> 1984. </year>
Reference-contexts: The Stephenson algorithm, while approaching the best-fit algorithms in space wasted, also had an execution time that was higher than many of the other algorithms. Bozman et al. measured the object allocation behavior of the operating system on two large IBM mainframes with hundreds of users <ref> [7] </ref>. In their paper, they compare a variety of algorithms, including several variations of buddy systems, first-fit, cartesian tree algorithms, and subpool caching algorithms. Subpool algorithms are much like Haertel's hybrid algorithm|pools of specific object sizes are maintained, and requests for larger objects are handled as a free-list search.
Reference: [8] <author> R. P. Brent. </author> <title> Efficient implemenation of a first-fit strategy for dynamic storage allocation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(3) </volume> <pages> 388-403, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Empirical information from actual systems has since been used by other researchers to investigate and compare the performance of their algorithms. In particular, Brent uses their data to compare the performance of a first-fit, balanced binary tree algorithm with Knuth's first-fit boundary tag algorithm <ref> [8] </ref>, and Oldehoeft and Allan also use empirical data to study the performance of an adaptive enhancement to standard storage management algorithms [22]. The research presented in this paper differs substantially from the related work in several ways.
Reference: [9] <author> Michael Caplinger. </author> <title> A memory allocator with garbage collection for C. </title> <booktitle> In Proceedings of the Winter 1988 USENIX Conference, </booktitle> <pages> pages 325-330, </pages> <address> Dallas, TX, </address> <month> February </month> <year> 1988. </year>
Reference-contexts: Furthermore, because these ambiguous pointers could potentially be integer variables, objects they point to cannot be relocated by the collector since doing so would require modifying the variable's value. Several different conservative collection algorithms have been implemented and described. These include early work by Caplinger <ref> [9] </ref>, an unpublished implementation similar to the Boehm-Weiser collector by Doug McIlroy [6], another unpublished implementation by Paul Hilfinger [14], and a mostly-copying garbage collector by Bartlett [2, 4].
Reference: [10] <author> Jacques Cohen. </author> <title> Garbage collection of linked data structures. </title> <journal> ACM Computing Surveys, </journal> <volume> 13(3) </volume> <pages> 341-367, </pages> <month> September </month> <year> 1981. </year> <month> 33 </month>
Reference-contexts: Because C is weakly typed, a pointer to an object can be stored in an integer variable. Thus, even if the locations of all pointer variables 2 For a complete discussion of the two approaches to automatic storage management, see the survey article by Cohen <ref> [10] </ref>. 8 were known to a garbage collector, the collector would still be unable to identify all heap pointers precisely.
Reference: [11] <author> Alan Demers, Mark Weiser, Barry Hayes, Hans Boehm, Daniel Bobrow, and Scott Shenker. </author> <title> Combining generational and conservative garbage collection: Framework and implementations. </title> <booktitle> In Conference Record of the Seventeenth ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 261-269, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Generation techniques have already been applied to conservative garbage collection algorithms. Boehm et al. have a technique called "sticky-mark-bit," currently available in the Portable Common Runtime system, that adds generations to their conservative collection algorithm <ref> [11] </ref>. Bartlett also has extended a mostly-copying conservative collection algorithm for C++ to use generation techniques [2].
Reference: [12] <author> Dirk Grunwald and Benjamin Zorn. </author> <title> CustoMalloc: Efficient synthesized memory al-locators. </title> <type> Technical Report CS-CS-602-92, </type> <institution> Department of Computer Science, University of Colorado, Boulder, Boulder, CO, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Garbage collection, however, has a tremendous advantage over explicit management methods because it is far easier for a programmer to 4 A colleague and I investigate the possibility of automatically generating an appropriate allocator in <ref> [12] </ref>. 29 use. With programs that do substantial explicit storage management, programmers spend a significant amount of time finding and eliminating storage management bugs (memory leaks and duplicate frees).
Reference: [13] <author> Mike Haertel. </author> <title> Description of GNU malloc implementation. </title> <type> Personal communication, </type> <month> August </month> <year> 1991. </year>
Reference-contexts: Haertel's Hybrid Algorithm In an effort to obtain the best of both worlds, Mike Haertel has implemented a hybrid of the first-fit and buddy-method algorithms <ref> [13] </ref>. This 7 implementation is available to the public as the Free Software Foundation implementation of malloc/free.
Reference: [14] <author> Paul N. Hilfinger. </author> <title> Experimental heuristic mark-and-sweep garbage collector for C. Documentation of unpublished implementation, </title> <year> 1989. </year>
Reference-contexts: Several different conservative collection algorithms have been implemented and described. These include early work by Caplinger [9], an unpublished implementation similar to the Boehm-Weiser collector by Doug McIlroy [6], another unpublished implementation by Paul Hilfinger <ref> [14] </ref>, and a mostly-copying garbage collector by Bartlett [2, 4]. The conservative collection algorithm that is considered in this paper is the one described by Boehm and Weiser [5] (version 1.6 of the software) 3 .
Reference: [15] <author> Mark D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1987. </year> <note> Also appears as tech report UCB/CSD 87/381. </note>
Reference-contexts: In these measurements, the cache miss rates are calculated using the all-associativity cache simulator tycho, written by Mark Hill <ref> [15] </ref>. Page fault rates were computed using a modified stack simulation algorithm [28], in which an LRU page replacement policy is assumed. 23 For these measurements, only data references were measured because the dynamic memory management algorithm used has little effect on instruction reference locality.
Reference: [16] <author> Chris Kingsley. </author> <title> Description of a very fast storage allocator. Documentation of 4.2 BSD Unix malloc implementation, </title> <month> February </month> <year> 1982. </year>
Reference-contexts: Kingsley's Powers-of-Two Buddy Algorithm As an alternative to a more conventional first-fit algorithm, Chris Kingsley implemented a very fast buddy algorithm that was distributed with the 4.2 BSD Unix release <ref> [16] </ref>. Kingsley's algorithm allocates objects in a limited number of different size classes, namely powers of two minus a constant. Allocation requests are rounded up to the nearest size class and a free list of objects of each size class is maintained.
Reference: [17] <author> Donald E. Knuth. </author> <title> Fundamental Algorithms, </title> <booktitle> volume 1 of The Art of Computer Programming, chapter 2, </booktitle> <pages> pages 435-451. </pages> <publisher> Addison Wesley, </publisher> <address> Reading, MA, 2nd edition, </address> <year> 1973. </year>
Reference-contexts: Knuth's Boundary-tag First-fit Algorithm This algorithm is a straightforward implementation of a first-fit strategy with several optimizations <ref> [17] </ref>. I measured a publicly available implementation of the classic Knuth algorithm written by Mark Moraes. In this algorithm, free blocks are connected together in a doubly-linked list. During allocation the list is scanned for the first free block that is large enough. <p> In Knuth's Fundamental Algorithms text <ref> [17] </ref>, he compares the time and space overhead of first-fit, best-fit and buddy system methods. The performance evaluation is based on a simulation where the object sizes and object lifetimes were calculated using probability distributions.
Reference: [18] <author> David G. Korn and Kiem-Phong Vo. </author> <title> In search of a better malloc. </title> <booktitle> In Proceedings of the Summer 1985 USENIX Conference, </booktitle> <pages> pages 489-506, </pages> <year> 1985. </year>
Reference-contexts: Empirical comparisons by Korn and Vo, however, suggest that the memory overhead of the Stephenson algorithm is close to that of best-fit algorithms <ref> [18] </ref>. Kingsley's Powers-of-Two Buddy Algorithm As an alternative to a more conventional first-fit algorithm, Chris Kingsley implemented a very fast buddy algorithm that was distributed with the 4.2 BSD Unix release [16]. <p> Knuth also compares the expected overhead of a mark-and-sweep algorithm, and concludes that under the best circumstances, garbage collection can be competitive with the other algorithms (an observation confirmed here). A more recent comparison of explicit management algorithms was conducted by Korn and Vo <ref> [18] </ref>. They implemented and tested 11 different storage management algorithms, including a doubly-linked first-fit algorithm, the BSD malloc and the Stephenson Cartesian 11 tree algorithm. Their results indicate that the BSD buddy algorithm consistently used the most space and the least time of all the algorithms compared.
Reference: [19] <author> James R. Larus. </author> <title> Abstract execution: A technique for efficiently tracing programs. </title> <journal> Software|Practice and Experience, </journal> 20(12) 1241-1258, December 1990. 
Reference-contexts: In addition to executing the programs and observing the CPU overhead and memory usage, the programs were instrumented with an address-trace extraction tool. The tool, AE (Abstract Execution) <ref> [19] </ref>, extracts all memory references the programs perform, allowing the memory system performance of the programs (and storage management implementations) to be studied using trace-driven simulation.
Reference: [20] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: Trends in garbage collection technology suggest that improvements to the Boehm-Weiser conservative collection algorithm are possible and likely in the near future. In particular generation techniques, already successfully applied in Lisp environments, can be applied to conservative collection algorithms. Generation techniques <ref> [20] </ref> focus the attention of garbage collection on the most recently allocated objects, which empirical evidence shows are the objects most likely to become 30 garbage. Focusing garbage collection on these younger objects serves three purposes.
Reference: [21] <author> David A. Moon. </author> <title> Garbage collection in a large Lisp system. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 235-246, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year>
Reference-contexts: This increase occurs because only a small part of the program's address space is visited during a collection. Generation garbage collection has been successfully used in languages including Lisp <ref> [21] </ref>, Smalltalk [26], and ML [1]. Because generation collection relies on the behavior that most objects live a relatively short time, generation collection will only be effective for C if C programs also display this behavior.
Reference: [22] <author> Rodney R. Oldehoeft and Stephen J. Allan. </author> <title> Adaptive exact-fit storage management. </title> <journal> Communications of the ACM, </journal> <volume> 28(5) </volume> <pages> 506-511, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: In particular, Brent uses their data to compare the performance of a first-fit, balanced binary tree algorithm with Knuth's first-fit boundary tag algorithm [8], and Oldehoeft and Allan also use empirical data to study the performance of an adaptive enhancement to standard storage management algorithms <ref> [22] </ref>. The research presented in this paper differs substantially from the related work in several ways. First, none of the papers discuss or compare the performance of a conservative garbage collection algorithm with explicit storage management algorithms.
Reference: [23] <author> Paul Rovner. </author> <title> On adding garbage collection and runtime types to a strongly-typed, statically checked, concurrent language. </title> <type> Technical Report CSL-84-7, </type> <institution> Xerox Palo Alto Research Center, Palo Alto, California, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: Rovner estimates that developers using the Mesa language spent 40% of the development time implementing memory management procedures and finding bugs related to explicit storage reclamation <ref> [23] </ref>. In addition, storage management bugs that are not found can greatly contribute to the unreliability of software. Bartlett has noted that a large fraction of software-caused total system failures are caused by memory management errors [3].
Reference: [24] <author> C. J. Stephenson. </author> <title> Fast fits: New methods for dynamic storage allocation. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 30-32, </pages> <address> Bretton Woods, NH, </address> <month> October </month> <year> 1983. </year> <month> 34 </month>
Reference-contexts: In practice, however, this algorithm is often efficient both in time and space. The other algorithms discussed attempt to improve on this simple, yet effective, approach. Stephenson's Cartesian Tree Algorithm This is the algorithm provided by the Sun Operating System library routines malloc and free <ref> [24, 25] </ref>. This algorithm, instead of placing the free blocks in a linear list, places them in a Cartesian tree [27].
Reference: [25] <institution> Sun Microsystems, Mountain View, CA. </institution> <note> Unix Manual Page for malloc, SunOS 4.1 edition, </note> <year> 1990. </year>
Reference-contexts: In practice, however, this algorithm is often efficient both in time and space. The other algorithms discussed attempt to improve on this simple, yet effective, approach. Stephenson's Cartesian Tree Algorithm This is the algorithm provided by the Sun Operating System library routines malloc and free <ref> [24, 25] </ref>. This algorithm, instead of placing the free blocks in a linear list, places them in a Cartesian tree [27].
Reference: [26] <author> David Ungar. </author> <title> Generation scavenging: A non-disruptive high performance storage reclamation algorithm. </title> <booktitle> In SIGSOFT/SIGPLAN Practical Programming Environments Conference, </booktitle> <pages> pages 157-167, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: This increase occurs because only a small part of the program's address space is visited during a collection. Generation garbage collection has been successfully used in languages including Lisp [21], Smalltalk <ref> [26] </ref>, and ML [1]. Because generation collection relies on the behavior that most objects live a relatively short time, generation collection will only be effective for C if C programs also display this behavior.
Reference: [27] <author> Jean Vuillemin. </author> <title> A unifying look at data structures. </title> <journal> Communications of the ACM, </journal> <volume> 23(4) </volume> <pages> 229-239, </pages> <month> April </month> <year> 1980. </year>
Reference-contexts: Stephenson's Cartesian Tree Algorithm This is the algorithm provided by the Sun Operating System library routines malloc and free [24, 25]. This algorithm, instead of placing the free blocks in a linear list, places them in a Cartesian tree <ref> [27] </ref>. Descendents in this tree are ordered both by address (left descendents have lower addresses than right descendents) and by size (descendents on the left are smaller than descendents on the right).
Reference: [28] <author> Benjamin Zorn. </author> <title> Comparative Performance Evaluation of Garbage Collection Algorithms. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1989. </year> <note> Also appears as tech report UCB/CSD 89/544. </note>
Reference-contexts: In these measurements, the cache miss rates are calculated using the all-associativity cache simulator tycho, written by Mark Hill [15]. Page fault rates were computed using a modified stack simulation algorithm <ref> [28] </ref>, in which an LRU page replacement policy is assumed. 23 For these measurements, only data references were measured because the dynamic memory management algorithm used has little effect on instruction reference locality.
Reference: [29] <author> Benjamin Zorn. </author> <title> The effect of garbage collection on cache performance. </title> <type> Technical Report CU-CS-528-91, </type> <institution> Department of Computer Science, University of Colorado, Boulder, Boulder, CO, </institution> <month> May </month> <year> 1991. </year> <month> 35 </month>
Reference-contexts: Second, because fewer objects are visited during each collection, program pauses associated with garbage collection are shortened. The final and most important purpose of generation garbage collection (based on my measurements) is that the reference locality of garbage collection is substantially increased <ref> [29] </ref>. This increase occurs because only a small part of the program's address space is visited during a collection. Generation garbage collection has been successfully used in languages including Lisp [21], Smalltalk [26], and ML [1].
References-found: 29

