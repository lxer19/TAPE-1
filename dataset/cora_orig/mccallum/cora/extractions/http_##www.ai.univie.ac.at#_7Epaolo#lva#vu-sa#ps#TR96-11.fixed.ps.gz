URL: http://www.ai.univie.ac.at/%7Epaolo/lva/vu-sa/ps/TR96-11.fixed.ps.gz
Refering-URL: http://www.ai.univie.ac.at/%7Epaolo/lva/vu-sa/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Adding a Collaborative Agent to Graphical User Interfaces  
Author: Charles Rich Candace L. Sidner 
Address: (UIST'96), Seattle, WA,  1996 201 Broadway, Cambridge, Massachusetts 02139  
Affiliation: and Technology  Mitsubishi Electric Information Technology Center America,  
Date: May 1996  November 1996.  
Web: http://www.merl.com  
Note: MERL AMITSUBISHI ELECTRIC RESEARCH LABORATORY  To appear in Ninth Annual Symposium on User Interface Software  Copyright c  Lotus Development Corporation  
Pubnum: TR-96-11  
Abstract: We have implemented a collaborative agent toolkit called Collagen and used it to build a software agent that collaborates with the user of a direct-manipulation graphical interface by following the rules and conventions of human discourse. One of the main results is an interaction history that is segmented according to the structure of the agent's and user's goals, without requiring the agent to understand natural language. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Information Technology Center America; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Information Technology Center America. All rights reserved. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R. Ahn et al. </author> <title> The DenK-architecture: A fundamental approach to user-interfaces. </title> <journal> Artificial Intelligence Review, </journal> <volume> 8 </volume> <pages> 431-445, 1994-5. </pages>
Reference-contexts: 21]) on applying human discourse principles to human-computer interaction have assumed that natural language under standing will be applied to the user's utterances. 9 The two systems we know of that are overall closest in spirit to our own are Stein et al.'s MERIT [18] and Ahn et al.'s DenK <ref> [1] </ref>. MERIT uses a different discourse theory and compiles it into a finite-state machine representation, which is less flexible and extensible.
Reference: 2. <author> M. E. Bratman, D. J. Israel, and M. E. Pollack. </author> <title> Plans and resource-bounded practical reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 4(4) </volume> <pages> 349-355, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Unfortunately, there is currently no generally accepted domain-independent theory of how people manage this interleaving. (The current best candidates for a generic theory are the so-called belief/desire/intention frameworks, such as <ref> [2] </ref>.) Collagen therefore does not currently provide a generic framework for execution. Another way of saying this is that we only provide a generic framework for recording the order in which planning and execution occur, but not for deciding how to interleave them.
Reference: 3. <author> P. Cohen. </author> <title> The role of natural language in a multimodal interface. </title> <booktitle> In Proc. ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 143-149, </pages> <address> Monterey, CA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Cohen [4] has also developed interface agents without collaborative discourse modelling. Ter-veen [19] has explored providing intelligent assistance through collaborative graphical manipulation without explicit invoking the agent paradigm. Cohen <ref> [3] </ref> and Jacob [9], among others, have explored discourse-related extensions to direct manipulation that incorporate anaphora and make previous context directly available.
Reference: 4. <author> P. Cohen et al. </author> <title> An open agent architecture. </title> <editor> In O. Et-zioni, editor, </editor> <booktitle> Software Agents, Papers from the 1994 Spring Symposium, SS-94-03, </booktitle> <pages> pages 1-8. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: It is unique, however, in its combination of goals and techniques. Our concept of an interface agent is closest to the work of Maes [14], although she uses the term "collaborative" to refer to the sharing of information between multiple software agents. Cohen <ref> [4] </ref> has also developed interface agents without collaborative discourse modelling. Ter-veen [19] has explored providing intelligent assistance through collaborative graphical manipulation without explicit invoking the agent paradigm. Cohen [3] and Jacob [9], among others, have explored discourse-related extensions to direct manipulation that incorporate anaphora and make previous context directly available.
Reference: 5. <author> B. J. Grosz and S. Kraus. </author> <title> Collaborative plans for complex group action. </title> <journal> Artificial Intelligence, </journal> <note> 1996. In publication. </note>
Reference-contexts: SharedPlans Much is known about the structure of human collaboration and discourse. In this work, we make use specifically of two interrelated theories due to Grosz and Sid-ner [6, 7] and extensions by Grosz and Kraus <ref> [5] </ref> and Lochbaum [12, 13]. Their theory predicts that, for successful collaboration, the participants need to have mutual beliefs 2 about the goals and actions to be performed and the capabilities, intentions, and commitments of the participants.
Reference: 6. <author> B. J. Grosz and C. L. Sidner. </author> <title> Attention, intentions, and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12(3) </volume> <pages> 175-204, </pages> <year> 1986. </year>
Reference-contexts: SharedPlans Much is known about the structure of human collaboration and discourse. In this work, we make use specifically of two interrelated theories due to Grosz and Sid-ner <ref> [6, 7] </ref> and extensions by Grosz and Kraus [5] and Lochbaum [12, 13]. Their theory predicts that, for successful collaboration, the participants need to have mutual beliefs 2 about the goals and actions to be performed and the capabilities, intentions, and commitments of the participants. <p> Since the goal of this work is to use well-established human discourse algorithms, readers are referred to the referenced literature for more details. Discourse processing in Grosz and Sidner's framework <ref> [6, 7] </ref> has three interacting components: * The linguistic structure of a discourse includes the grouping of utterances into segments, as well as the use of anaphora, tense, and cue words.
Reference: 7. <author> B. J. Grosz and C. L. Sidner. </author> <title> Plans for discourse. </title> <editor> In P. R. Cohen, J. L. Morgan, and M. E. Pollack, editors, </editor> <booktitle> Intentions and Communication, chapter 20, </booktitle> <pages> pages 417-444. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: SharedPlans Much is known about the structure of human collaboration and discourse. In this work, we make use specifically of two interrelated theories due to Grosz and Sid-ner <ref> [6, 7] </ref> and extensions by Grosz and Kraus [5] and Lochbaum [12, 13]. Their theory predicts that, for successful collaboration, the participants need to have mutual beliefs 2 about the goals and actions to be performed and the capabilities, intentions, and commitments of the participants. <p> Since the goal of this work is to use well-established human discourse algorithms, readers are referred to the referenced literature for more details. Discourse processing in Grosz and Sidner's framework <ref> [6, 7] </ref> has three interacting components: * The linguistic structure of a discourse includes the grouping of utterances into segments, as well as the use of anaphora, tense, and cue words.
Reference: 8. <author> B. J. Grosz [Deutsch]. </author> <title> The structure of task-oriented dialogs. </title> <booktitle> In IEEE Symp. on Speech Recognition: Contributed Papers, </booktitle> <pages> pages 250-253, </pages> <address> Pittsburgh, PA, </address> <year> 1974. </year>
Reference-contexts: As we will see in Section 7 below, automatic segmentation has there fore been our first milestone in adding discourse facilities to human-computer interaction. A simple example of segments in a human collaborative discourse is shown in Figure 4, which is adapted from <ref> [8] </ref>. In this discourse, participant A is instructing participant B how to repair an air compressor. The toplevel segment and three embedded segments are indicated by the brackets and indentation shown (further subsegments are elided).
Reference: 9. <author> R. J. K. Jacob. </author> <title> Natural dialogue in modes other than natural language. </title> <editor> In R.-J. Beun, M. Baker, and M. Reiner, editors, </editor> <booktitle> Dialogue and Instruction, </booktitle> <pages> pages 289-301. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: Cohen [4] has also developed interface agents without collaborative discourse modelling. Ter-veen [19] has explored providing intelligent assistance through collaborative graphical manipulation without explicit invoking the agent paradigm. Cohen [3] and Jacob <ref> [9] </ref>, among others, have explored discourse-related extensions to direct manipulation that incorporate anaphora and make previous context directly available.
Reference: 10. <author> H. Kautz. </author> <title> A circumscriptive theory of plan recognition. </title> <editor> In P. R. Cohen, J. L. Morgan, and M. E. Pollack, editors, </editor> <booktitle> Intentions and Communication, chapter 6, </booktitle> <pages> pages 105-133. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Further research is needed in this area. It is tempting to think of discourse interpretation as plan recognition, which is known to be exponential in the worst case <ref> [10] </ref>. However, this misses a key property of normal human discourse, namely that speakers work very hard (even to the extent of providing redundant information [20]) to make sure that their conversational partners understand their intentions without a large cognitive search.
Reference: 11. <author> L. Lambert and S. Carberry. </author> <title> A tripartite plan-based model of dialogue. </title> <booktitle> In Proc. 29th Annual Meeting of the ACL, </booktitle> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Ter-veen [19] has explored providing intelligent assistance through collaborative graphical manipulation without explicit invoking the agent paradigm. Cohen [3] and Jacob [9], among others, have explored discourse-related extensions to direct manipulation that incorporate anaphora and make previous context directly available. However, most work (e.g., <ref> [11, 21] </ref>) on applying human discourse principles to human-computer interaction have assumed that natural language under standing will be applied to the user's utterances. 9 The two systems we know of that are overall closest in spirit to our own are Stein et al.'s MERIT [18] and Ahn et al.'s DenK
Reference: 12. <author> K. E. Lochbaum. </author> <title> Using collaborative plans to model the intentional structure of discourse. </title> <type> Technical Report TR-25-94, </type> <institution> Harvard Univ., Ctr. for Res. in Computing Tech., </institution> <year> 1994. </year> <type> PhD thesis. </type>
Reference-contexts: SharedPlans Much is known about the structure of human collaboration and discourse. In this work, we make use specifically of two interrelated theories due to Grosz and Sid-ner [6, 7] and extensions by Grosz and Kraus [5] and Lochbaum <ref> [12, 13] </ref>. Their theory predicts that, for successful collaboration, the participants need to have mutual beliefs 2 about the goals and actions to be performed and the capabilities, intentions, and commitments of the participants. <p> We represent attentional state as a focus stack of discourse segments. * The intentional structure of a discourse corresponds to the current partial status of the participants' Shared-Plans. We represent this information as a recipe tree, which is a reimplementation of Lochbaum's rgraph structure <ref> [12] </ref>. Each node of a recipe tree is a common goal; the children of the node are acts that contribute to it. As can be seen in Figure 9, the agent currently uses only one focus stack and recipe tree, which represents mutually believed information. <p> When we start to work on negotiation, we will need to distinguish between mutual beliefs and the individual beliefs of the agent and user. Our key discourse processing algorithm, discourse interpretation, is a reimplementation of Lochbaum's rgraph augmentation algorithm <ref> [12] </ref>. The discourse generation algorithm is essentially the inverse of the interpretation algorithm. Discourse Intepretation The input to discourse interpretation is a (basic) manipulation or communication act that has been observed or received by the agent, i.e., queued in its input buffer.
Reference: 13. <author> K. E. Lochbaum. </author> <title> The use of knowledge preconditions in language processing. </title> <booktitle> In Proc. 14th Int. Joint Conf. Artificial Intelligence, </booktitle> <pages> pages 1260-1266, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: SharedPlans Much is known about the structure of human collaboration and discourse. In this work, we make use specifically of two interrelated theories due to Grosz and Sid-ner [6, 7] and extensions by Grosz and Kraus [5] and Lochbaum <ref> [12, 13] </ref>. Their theory predicts that, for successful collaboration, the participants need to have mutual beliefs 2 about the goals and actions to be performed and the capabilities, intentions, and commitments of the participants. <p> Furthermore, if this act completes the achievement of the current discourse segment purpose, the focus stack is popped. The last three cases above are instances of a larger class of explanations that Lochbaum <ref> [13] </ref> calls "knowledge preconditions." If the current act is a communication of the form PFA ( : : : , : : : , SHOULD ( : : : ), : : : ) it is interpreted as initiating a new segment which is pushed onto the focus stack regardless of
Reference: 14. <author> P. Maes. </author> <title> Agents that reduce work and information overload. </title> <journal> Comm. ACM, </journal> <volume> 37(17) </volume> <pages> 30-40, </pages> <month> July </month> <year> 1994. </year> <note> Special Issue on Intelligent Agents. </note>
Reference-contexts: It is unique, however, in its combination of goals and techniques. Our concept of an interface agent is closest to the work of Maes <ref> [14] </ref>, although she uses the term "collaborative" to refer to the sharing of information between multiple software agents. Cohen [4] has also developed interface agents without collaborative discourse modelling. Ter-veen [19] has explored providing intelligent assistance through collaborative graphical manipulation without explicit invoking the agent paradigm.
Reference: 15. <author> B. Meyers et al. Garnet: </author> <title> Comprehensive support for graphical, highly-interactive user interfaces. </title> <journal> IEEE Computer, </journal> <volume> 23(11) </volume> <pages> 71-85, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: content) representation of the communication between the user and agent, we use an artificial language developed by Sidner [17], and translate messages from this internal representation into English sentences for the user to read using simple string templates (see Section 8). 4 TEST APPLICATION system we implemented using the Garnet <ref> [15] </ref> graphics package. (For the discussion in this section, please ignore the two overlapping windows in the upper-right and lower-left corners.) The test application provides a direct-manipulation interface to an airline schedule database and a simple constraint checker.
Reference: 16. <author> C. Rich. </author> <title> Window sharing with collaborative interface agents. </title> <journal> ACM SIGCHI Bulletin, </journal> <volume> 28(1) </volume> <pages> 70-78, </pages> <month> January </month> <year> 1996. </year> <note> Also published as MERL Technical Report 95-12. </note>
Reference-contexts: This is achieved using a window-sharing layer implemented in the X Window System and described in detail elsewhere <ref> [16] </ref>. A key concept in this window-sharing layer is the home window. The user and software agent each have a small dedicated window that is used for communication between them. <p> input buffer of the agent process. * The user interacts with the application in the usual way, modifying the state of the application with her cursor and "querying" it with her eyes. * The agent modifies the state of the application with its cursor (see discussion of UnGUI module in <ref> [16] </ref>) and queries it using the programming interface (API) provided by the application. * The user observes the agent's actions by watching the agent's cursor. * The agent observes the user's actions by virtue of a generic layer in the application that mirrors all logical actions into the input buffer of
Reference: 17. <author> C. L. Sidner. </author> <title> An artificial discourse language for collaborative negotiation. </title> <booktitle> In Proc. 12th National Conf. on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: As the internal semantic (i.e., content) representation of the communication between the user and agent, we use an artificial language developed by Sidner <ref> [17] </ref>, and translate messages from this internal representation into English sentences for the user to read using simple string templates (see Section 8). 4 TEST APPLICATION system we implemented using the Garnet [15] graphics package. (For the discussion in this section, please ignore the two overlapping windows in the upper-right and <p> For example, the direct manipulations on the test application are basic acts. Sidner's artificial discourse language <ref> [17] </ref> defines a collection of constructors for basic communication acts, such as proposing, retracting, accepting, and rejecting proposals. This section provides a rough sketch of the language and our use of it.
Reference: 18. <author> A. Stein and E. Maier. </author> <title> Structuring collaborative information-seeking dialogues. Knowledge-Based Systems, </title> <address> 8(2-3):82-93, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: However, most work (e.g., [11, 21]) on applying human discourse principles to human-computer interaction have assumed that natural language under standing will be applied to the user's utterances. 9 The two systems we know of that are overall closest in spirit to our own are Stein et al.'s MERIT <ref> [18] </ref> and Ahn et al.'s DenK [1]. MERIT uses a different discourse theory and compiles it into a finite-state machine representation, which is less flexible and extensible.
Reference: 19. <author> G. Terveen, D. Wroblewski, and S. Tighe. </author> <title> Intelligent assistance through collaborative manipulation. </title> <booktitle> In Proc. 12th Int. Joint Conf. Artificial Intelligence, </booktitle> <pages> pages 9-14, </pages> <address> Sydney, Australia, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Our concept of an interface agent is closest to the work of Maes [14], although she uses the term "collaborative" to refer to the sharing of information between multiple software agents. Cohen [4] has also developed interface agents without collaborative discourse modelling. Ter-veen <ref> [19] </ref> has explored providing intelligent assistance through collaborative graphical manipulation without explicit invoking the agent paradigm. Cohen [3] and Jacob [9], among others, have explored discourse-related extensions to direct manipulation that incorporate anaphora and make previous context directly available.
Reference: 20. <author> M. A. Walker. </author> <title> Redundancy in collaborative dialogue. </title> <booktitle> In 14th Int. Conf. on Computational Linguistics, </booktitle> <year> 1992. </year>
Reference-contexts: It is tempting to think of discourse interpretation as plan recognition, which is known to be exponential in the worst case [10]. However, this misses a key property of normal human discourse, namely that speakers work very hard (even to the extent of providing redundant information <ref> [20] </ref>) to make sure that their conversational partners understand their intentions without a large cognitive search. Notice that the only search involved in the algorithm above is through the steps of the current recipe or all known recipes for the current discourse purpose (and this is not done recursively).
Reference: 21. <author> N. Yanklovich. </author> <title> Talking vs. taking: Speech access to remote computers. </title> <booktitle> In Proc. ACM SIGCHI Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 275-276, </pages> <address> Boston, MA, </address> <month> April </month> <year> 1994. </year> <month> 10 </month>
Reference-contexts: Ter-veen [19] has explored providing intelligent assistance through collaborative graphical manipulation without explicit invoking the agent paradigm. Cohen [3] and Jacob [9], among others, have explored discourse-related extensions to direct manipulation that incorporate anaphora and make previous context directly available. However, most work (e.g., <ref> [11, 21] </ref>) on applying human discourse principles to human-computer interaction have assumed that natural language under standing will be applied to the user's utterances. 9 The two systems we know of that are overall closest in spirit to our own are Stein et al.'s MERIT [18] and Ahn et al.'s DenK
References-found: 21

