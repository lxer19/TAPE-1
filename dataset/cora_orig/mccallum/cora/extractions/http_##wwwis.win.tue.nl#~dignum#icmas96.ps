URL: http://wwwis.win.tue.nl/~dignum/icmas96.ps
Refering-URL: http://wwwis.win.tue.nl/~dignum/papers.html
Root-URL: http://www.win.tue.nl
Email: e-mail: dignum@win.tue.nl  
Title: Autonomous Agents and Social Norms  
Author: F.Dignum 
Address: P.O. Box 513, 5600 MB Eindhoven, The Netherlands  
Affiliation: Fac. of Maths. Comp. Sc., Eindhoven University of Technology  
Abstract: In this paper we present concepts and their relations that are necessary for modeling autonomous agents in an environment that is governed by some (social) norms. We divide the norms over three levels: the private level the contract level and the convention level. We show how deontic logic can be used to model the concepts and how the theory of speech acts can be used to model the generation of (some of) the norms. Finally we give some idea about an agent architecture incorporating the social norms based on a BDI framework. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Asher and D. </author> <title> Bonevac. </title> <journal> Prima Facie Obligation Studia Logica, </journal> <volume> vol.57(1), </volume> <pages> pages 19-45, </pages> <year> 1996. </year>
Reference-contexts: Some mechanism is needed to determine which of the obligations should be followed in each actual situation. This mechanism determines the actual norms according to 10 which an agent should behave according to the convention level. In <ref> [1] </ref> such a mechanism is described in detail and we will not go deeper into this issue here.
Reference: [2] <author> C. Boutilier. </author> <title> Toward a Logic for Qualitative Decision Theory. </title> <editor> In Jon Doyle, Erik Sandewall and Pietro Torasso (eds.), </editor> <booktitle> Principles of Knowledge Representation and Reasoning, proceedings of the fourth international conference, </booktitle> <pages> pages 75-86, </pages> <address> 1994, </address> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, California. </address>
Reference-contexts: An agent might prefer to collect data from a large bibliography database on another continent at night and might prefer to collect its data from other sources during the day due to transport times and costs. The conditional preferences are modeled as described in <ref> [2, 12] </ref>. Conform these definitions we can define preferences as follows: P ref i (OEj ) iff agent i prefers OE to be true in every situation in which is true. For the private level we did not define a formal description language. <p> In order for the agent to be able to decide which goal it will pursue the goals should be ordered. This is done indirectly by ordering the states according to their (partial) fulfillment of all preferences. Like in <ref> [2, 12] </ref> we use a utility function on the states for this purpose. The utility function contains some metric to measure how close a state is to the fulfillment of a preference and also a weight of that preference.
Reference: [3] <author> P. Cohen and H. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> vol.42, </volume> <pages> pages 213-261, </pages> <year> 1990. </year>
Reference-contexts: I.e. it creates an obligation (towards itself or an agent for which it tries to achieve the goal) to perform the tasks. This has been formally described in [8]. It has an advantage over <ref> [3] </ref> in the fact that the commitment is made explicit in an obligation. The "weight" 13 of this obligations can be used to order the tasks on the agenda.
Reference: [4] <author> P. Cohen and H. Levesque. </author> <title> Teamwork Nous, </title> <booktitle> vol.35, </booktitle> <pages> pages 487-512, </pages> <year> 1991. </year>
Reference-contexts: Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. <ref> [4, 10, 20] </ref>). The conventions according to which the agents coordinate their behaviour is hard-wired into the protocols that the agents use to react to the behaviour (cq. messages) of other agents. This raises several issues.
Reference: [5] <author> R. Davis and R. Smith. </author> <title> Negotiation as a metaphor for distributed problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> vol.20, </volume> <pages> pages 63-109, </pages> <year> 1983. </year>
Reference-contexts: 1 Introduction In the area of Multi-Agent Systems much research is devoted to the coordination of the agents. Many papers have been written about protocols (like Contract-Net) that allow agents to negotiate and cooperate (e.g. <ref> [13, 5] </ref>). Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. [4, 10, 20]).
Reference: [6] <author> F. Dignum and R. Kuiper. </author> <title> Combining dynamic deontic logic and temporal logic for the specification of deadlines. </title> <booktitle> HICSS/Logic-Modeling, Hawaii, </booktitle> <month> January </month> <year> 1997. </year>
Reference-contexts: Usually obligations on actions carry a time aspect indicating that the action should be performed before a certain deadline. We abstract from this feature here, but have described it fully in <ref> [6] </ref>. For agent i the directed obligation means that it should perform some action to fulfill the obligation. Agent j has a conditional power or authorization to "repair" the situation in case i does not fulfill its obligation. <p> For instance, "the customer has to pay within 3 weeks" or "the passenger should be at the airport one hour before the flight leaves". This type of obligations can be modeled directly in a deontic logic with time as defined in <ref> [6] </ref>. These formulas can immediately be used by the agent to form goals and/or plans to fulfill the obligation. The abstract obligations define a (vague) class of situations or actions. For instance, "agent i should cooperate with agent j". Depending on the situation this can be done in different ways.
Reference: [7] <author> F. Dignum and H. Weigand. </author> <title> Modeling communication between cooperative systems In J. </title> <editor> Iivari, K. Lyytinen and M. Rossi, eds, </editor> <booktitle> Advanced information systems engineering, </booktitle> <pages> pages 140-153, </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: Obligations can also be created through sending messages, i.e. communication between agents. The communication between agents is modeled on the basis of speech act theory as described in [21, 22]. They describe five categories of speech acts with their own 7 characteristics. In <ref> [7] </ref> we give a formal semantics for the speech act types and show how they can be used to create obligations, believes and facts. At this place we only want to state that obligations can arise from a commitment of one agent to another. E.g. <p> With each role there are a number of standard authorizations. Besides these authorizations each agent can authorize any other agent to perform a directive towards itself. For more (formal) details about these authorizations see <ref> [7] </ref>. 4 Conventions The level of conventions between agents can be compared with the prima facie obligations that arise from the law. Prima facie obligations hold under normal circumstances, becoming actual unless some other moral consideration intervenes ([18, 1]).
Reference: [8] <author> F. Dignum, J.-J.Ch. Meyer, R. Wieringa and R. Kuiper. </author> <title> A modal approach to intentions, commitments and obligations: intention plus commitment yields obligation. </title> <editor> In M. Brown and J. </editor> <booktitle> Carmo (eds.),Deontic logic, agency and normative systems, Workshops in Computing, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pages 80-97, </pages> <year> 1996. </year>
Reference-contexts: The distinction has a practical reason. Actions that are obliged can be simply put on the "agenda", while for situations that are obliged a plan has to be devised to reach them. They can formally be reduced to only obligations on situations, as shown in <ref> [8] </ref>, by considering the obligation to perform ff to be the same as the fact that ff should have been performed at some point in the future. Usually obligations on actions carry a time aspect indicating that the action should be performed before a certain deadline. <p> At the moment the tasks are put on the agenda, the agent also commits itself to the tasks. I.e. it creates an obligation (towards itself or an agent for which it tries to achieve the goal) to perform the tasks. This has been formally described in <ref> [8] </ref>. It has an advantage over [3] in the fact that the commitment is made explicit in an obligation. The "weight" 13 of this obligations can be used to order the tasks on the agenda.
Reference: [9] <author> H. Herrestad and C. </author> <title> Krogh Deontic Logic relativised to bearers and counterparties. </title> <editor> In J. Bing and O. Torrund, eds, </editor> <booktitle> Anniversary Anthology in Computers and Law, </booktitle> <pages> pages 453-522, </pages> <note> Tano A.S., </note> <year> 1995. </year>
Reference-contexts: In [24] we describe more fully how the contracts can be implemented using a formal language CoLa. 3.1 Directed obligations The central notion that is used to model norms on the contract level is the directed obligation (see e.g. <ref> [9, 19] </ref>). It is defined as follows: O ij (p) means that agent i is obliged towards agent j (the counterparty) that p holds. O ij (ff) means that agent i is obliged towards agent j (the counterparty) that ff is performed.
Reference: [10] <author> N. Jennings. </author> <title> Commitments and Conventions: The foundation of coordination in Multi-Agent systems. </title> <journal> Knowledge Engineering Review, </journal> <volume> vol. 8(3), </volume> <pages> pages 223-250, </pages> <year> 1993. </year>
Reference-contexts: Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. <ref> [4, 10, 20] </ref>). The conventions according to which the agents coordinate their behaviour is hard-wired into the protocols that the agents use to react to the behaviour (cq. messages) of other agents. This raises several issues.
Reference: [11] <author> D. Kinny and M. Georgeff. </author> <title> Commitment and Effectiveness of Situated Agents. </title> <booktitle> In Proceedings International Joint Conference on Artificial Intelligence, </booktitle> <address> Sydney, Australia, </address> <pages> pages 82-88. </pages>
Reference-contexts: In the other hand the agent might give its personal obligations a low priority. This leads to agents that easily perform tasks for other agents in between of their own tasks. This way of modeling the agenda is very close to the work of Kinny and Georgeff in <ref> [11] </ref>. In this work they consider open and closed minded agents. Closed minded agents do not reconsider their goals after the plan has been put on the agenda. Open minded agents check after each step whether the goal is still reachable and whether more important goals appeared.
Reference: [12] <author> J. Lang. </author> <title> Conditional Desires and Utilities an alternative logical approach to qualitative decision theory. </title> <editor> In W. Wahlster, editor, </editor> <booktitle> Proceedings of ECAI-96, </booktitle> <pages> pages 318-327, </pages> <address> Budapest, Hungary, 1996, </address> <publisher> John Wiley & Sons Ltd. </publisher> <pages> 15 </pages>
Reference-contexts: An agent might prefer to collect data from a large bibliography database on another continent at night and might prefer to collect its data from other sources during the day due to transport times and costs. The conditional preferences are modeled as described in <ref> [2, 12] </ref>. Conform these definitions we can define preferences as follows: P ref i (OEj ) iff agent i prefers OE to be true in every situation in which is true. For the private level we did not define a formal description language. <p> In order for the agent to be able to decide which goal it will pursue the goals should be ordered. This is done indirectly by ordering the states according to their (partial) fulfillment of all preferences. Like in <ref> [2, 12] </ref> we use a utility function on the states for this purpose. The utility function contains some metric to measure how close a state is to the fulfillment of a preference and also a weight of that preference.
Reference: [13] <author> J. Muller. </author> <title> A cooperation model for autonomous agents. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III | Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction In the area of Multi-Agent Systems much research is devoted to the coordination of the agents. Many papers have been written about protocols (like Contract-Net) that allow agents to negotiate and cooperate (e.g. <ref> [13, 5] </ref>). Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. [4, 10, 20]).
Reference: [14] <author> P. Noriega and C. Sierra. </author> <title> Towards layered dialogical agents. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III | Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year>
Reference-contexts: Each of these operators are exponents of their own logic. It is still an open question how all these concepts fit into one logic. Maybe each level should have its own logic and some "bridge 14 rules" should be defined to connect the different levels. This is done in <ref> [14] </ref>. We are currently working on a first implementation of the agent architecture to check whether our ideas also work in practice.
Reference: [15] <author> T. J. Norman, N. R. Jennings, P. Faratin, and E. H. Mamdani. </author> <title> Designing and implementing a multi-agent architecture for business process management. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III | Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year>
Reference-contexts: The private part of this agent architecture can be seen as a variant of the classical BDI architecture [17]. It also resembles very closely the agent architecture of the ADEPT system described in <ref> [15] </ref>. Finally, in section 6, we give some first conclusions on the basis of our framework. 2 Agent Architecture In figure 1 we show how the different levels of social behaviour that we define can be incorporated into an agent architecture.
Reference: [16] <author> S. Ossowski, A. Garcia-Serrano and J. Cuena. </author> <title> Emergent cooperation of flow control actions through functional cooperation of social agents. </title> <editor> In W. Wahlster, editor, </editor> <booktitle> Proceedings of ECAI-96, </booktitle> <pages> pages 539-543, </pages> <address> Budapest, Hungary, 1996, </address> <publisher> John Wiley & Sons Ltd. </publisher>
Reference-contexts: For instance, "Agents should pay their debts" is modeled as: 8iO ip (pay debt) The generation of the conventions can be done in several ways. Most easy is to fix them when the system is started up. This is done in <ref> [16] </ref> where conventions are modeled explicitly but subsequently are hard-wired into the agent behaviour. There are two advantages of having the convention level instead of just incorporating the conventions in the communication protocols. The first is that the conventions are now explicit and can be more easily changed. <p> Although we have given a kind of procedural account of the private norm level of an agent we have not given an explicit architecture of the private level. Due to space limitations we suffice to point to <ref> [23, 16] </ref> for some global view of the architecture of agents in this framework. 6 Conclusions In this paper we have given an overview of the concepts that are used to model the social norms that govern the behaviour of autonomous agents.
Reference: [17] <author> A.S. Rao and M.P. Georgeff. </author> <title> Modeling rational agents within a BDI-architecture. </title> <editor> In J. Allen, R. Fikes and E. Sandewall, eds, </editor> <booktitle> Proceedings 2d Int. conference on principles of knowledge representation and reasoning, </booktitle> <pages> pages 473-484, </pages> <address> San Mateo CA, </address> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Before we describe the different levels of norms and their relations, we will describe an agent architecture, based on [23], in which the norms are implemented in different knowledge bases. The private part of this agent architecture can be seen as a variant of the classical BDI architecture <ref> [17] </ref>. It also resembles very closely the agent architecture of the ADEPT system described in [15].
Reference: [18] <author> W. Ross. </author> <title> The Right and the Good. </title> <publisher> Oxford University Press. </publisher> <year> 1930. </year>
Reference: [19] <author> L. Royakkers. </author> <title> Representing Legal Rules in Deontic Logic. </title> <type> Ph.D. Thesis, </type> <institution> Tilburg University, The Netherlands. </institution>
Reference-contexts: In [24] we describe more fully how the contracts can be implemented using a formal language CoLa. 3.1 Directed obligations The central notion that is used to model norms on the contract level is the directed obligation (see e.g. <ref> [9, 19] </ref>). It is defined as follows: O ij (p) means that agent i is obliged towards agent j (the counterparty) that p holds. O ij (ff) means that agent i is obliged towards agent j (the counterparty) that ff is performed.
Reference: [20] <author> G. Sandu. </author> <title> Reasoning about collective goals. </title> <editor> In J. Muller, M. Wooldridge and N. Jennings, eds, </editor> <booktitle> Proceedings ATAL-96, </booktitle> <pages> pages 35-47, </pages> <address> Budapest, Hungary, </address> <year> 1996. </year>
Reference-contexts: Most of the cooperation between agents is based on the assumption that they have some joint goal or intention. Such a joint goal enforces some type of cooperative behaviour on all agents (see e.g. <ref> [4, 10, 20] </ref>). The conventions according to which the agents coordinate their behaviour is hard-wired into the protocols that the agents use to react to the behaviour (cq. messages) of other agents. This raises several issues.
Reference: [21] <author> J.R. Searle. </author> <title> Speech Acts. </title> <publisher> Cambridge University Press. </publisher> <year> 1969. </year>
Reference-contexts: In terms of CoLa that is after the triggering (or "in") event of an obligation has occurred. Obligations can also be created through sending messages, i.e. communication between agents. The communication between agents is modeled on the basis of speech act theory as described in <ref> [21, 22] </ref>. They describe five categories of speech acts with their own 7 characteristics. In [7] we give a formal semantics for the speech act types and show how they can be used to create obligations, believes and facts.
Reference: [22] <author> J.R. Searle and D. Vanderveken. </author> <title> Foundations of illocutionary logic. </title> <publisher> Cambridge University Press. </publisher> <year> 1985. </year>
Reference-contexts: In terms of CoLa that is after the triggering (or "in") event of an obligation has occurred. Obligations can also be created through sending messages, i.e. communication between agents. The communication between agents is modeled on the basis of speech act theory as described in <ref> [21, 22] </ref>. They describe five categories of speech acts with their own 7 characteristics. In [7] we give a formal semantics for the speech act types and show how they can be used to create obligations, believes and facts.
Reference: [23] <author> E. Verharen, F. Dignum and H. Weigand. </author> <title> A Language/Action perspective on Cooperative Information Agents. </title> <editor> In E. Verharen, N. van der Rijst and J. Dietz, eds, </editor> <booktitle> Proceedings International Workshop on Communication Modeling (LAP-96), </booktitle> <pages> pages 40-53, </pages> <address> Oisterwijk, The Netherlands, </address> <year> 1996. </year>
Reference-contexts: But also "An agent should be cooperative (if possible)". The convention level is described in section 4. Before we describe the different levels of norms and their relations, we will describe an agent architecture, based on <ref> [23] </ref>, in which the norms are implemented in different knowledge bases. The private part of this agent architecture can be seen as a variant of the classical BDI architecture [17]. It also resembles very closely the agent architecture of the ADEPT system described in [15]. <p> Although we have given a kind of procedural account of the private norm level of an agent we have not given an explicit architecture of the private level. Due to space limitations we suffice to point to <ref> [23, 16] </ref> for some global view of the architecture of agents in this framework. 6 Conclusions In this paper we have given an overview of the concepts that are used to model the social norms that govern the behaviour of autonomous agents.
Reference: [24] <author> H. Weigand, E. Verharen and F. Dignum. </author> <title> Interoperable Transactions in Business Models: A Structured Approach. </title> <editor> In P. Constantopoulos, J. Mylopoulos and Y. Vas-siliou, eds, </editor> <booktitle> Advanced Information Systems Engineering (LNCS 1080), </booktitle> <pages> pages 193-209, </pages> <publisher> Springer, </publisher> <year> 1996. </year> <month> 16 </month>
Reference-contexts: Not only legal contracts but also cooperation and informal agreements between agents can be described in this way. The contract describes the type of relation that exists between the agents and their mutual expectations of the behaviour of the other agent. In <ref> [24] </ref> we describe more fully how the contracts can be implemented using a formal language CoLa. 3.1 Directed obligations The central notion that is used to model norms on the contract level is the directed obligation (see e.g. [9, 19]).
References-found: 24

