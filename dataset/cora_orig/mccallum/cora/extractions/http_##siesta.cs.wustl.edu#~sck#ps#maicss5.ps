URL: http://siesta.cs.wustl.edu/~sck/ps/maicss5.ps
Refering-URL: http://siesta.cs.wustl.edu/~sck/
Root-URL: 
Title: Identifying Language from Raw Speech An Application of Recurrent Neural Networks  
Author: Weilan Wu, Stan C. Kwasny, Barry L. Kalman, E. Maynard Engebretson 
Address: St. Louis, MO 63130  
Affiliation: Department of Computer Science Washington Unversity  
Note: 5th Midwest Artificial Intelligence and Cognitive Science Conference  
Abstract: People can differentiate spoken languages without understanding them, and, in some sense, this differentiation can only be done without understanding the language. When we consider a multi-lingual person trying to understand an utterance spoken in one of the languages with which they are familiar, they will first decide which language this utterance belongs to, before trying to interpret it. The language identification task is one example of high-level feature abstraction from raw speech. Speech samples are classified into categories according to what language was spoken. We conjecture that this classification can be performed reliably and in real time. To be successful, such a system should be speaker-independent as well as context-independent. A large amount of training is required to achieve a satisfactory level of performance. We present a continuation of previous work (Kwasny et al., 1992) which introduces two important improvements to the system: (1) replacement of the non-recurrent, feed-forward network with a recurrent one, which is smaller, but still classifies correctly; (2) development of a frontend processor on a Nextfi workstation to facilitate sample recording and data acquisition. This is important for large-scale data acquisition, training, and testing of the network. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abe, M., and Shikano, K. </author> <year> 1991. </year> <title> Statistical analysis of bilingual speaker's speech for cross-language voice conversion. </title> <journal> Journal of the Acoustic Society of America 90: </journal> <pages> 76-82. </pages>
Reference: <author> Abe, M.; Shikano, K.; and Kuwabara, H. </author> <year> 1990. </year> <title> Cross-language voice conversion. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> 345-348. </pages>
Reference: <author> Atkinson, K. </author> <year> 1968. </year> <title> Language identification from non-segmental cues. </title> <journal> Journal of the Acoustic Society of America 44, 378(A). </journal>
Reference: <author> Austin, S.; Zavaliagkos G.; Makhoul J.; and Schwartz R., </author> <year> 1991. </year> <title> A Hybrid Continuous Speech Recognition System Using Segmental Neural Nets with Hidden Markov Models. </title> <booktitle> Proceedings of the 1991 IEEE Workshop on Neural Networks for Signal Processing, </booktitle> <publisher> IEEE Press, </publisher> <address> New York, NY, </address> <year> 1991, </year> <pages> pp 347-356. </pages>
Reference-contexts: Bridle (1990) has shown some equivalence between the HMM and the recurrent neural network and a variety of hybrid HMM/network models have been proposed and evaluated <ref> (Austin et. al 1991) </ref>. Collection of Speech Samples For our preliminary experiments, we collected speech samples from two bilingual speakers, one male and one female. British English was the native language of one speaker while the other speaker was native French. Both speakers were uent in their non-native tongue.
Reference: <author> Bridle John S. </author> <year> 1990. </year> <title> Alpha-Nets: A Recurrent `Neural' Network Architecture with a Hidden Markov Model Interpretation, Speech Communication 9 (1990) 83-92 North-Holland. </title>
Reference: <editor> Denes, P.B. </editor> <year> 1963. </year> <title> On the statistics of spoken English. </title> <journal> Journal of the Acoustic Society of America 35, </journal> <pages> 892-904. </pages>
Reference-contexts: Given the proper experience, identifying familiar languages can be done easily and fairly accurately. However, if speech samples are examined by the computer, can a system be built to reliably identify the language being spoken in real time? Certainly, acoustic (Hanley et al., 1966) and phonetic <ref> (Denes, 1963) </ref> differences exist among languages.
Reference: <editor> Hanley, T.D., Snidecor, J.C., and Ringel, R.L. </editor> <year> 1966. </year> <title> Some acoustic difference among languages. </title> <type> Phonetica 14, </type> <pages> 97-107. </pages>
Reference-contexts: Given the proper experience, identifying familiar languages can be done easily and fairly accurately. However, if speech samples are examined by the computer, can a system be built to reliably identify the language being spoken in real time? Certainly, acoustic <ref> (Hanley et al., 1966) </ref> and phonetic (Denes, 1963) differences exist among languages.
Reference: <author> House, </author> <title> A.S., </title> <editor> and Neuberg, E.P. </editor> <year> 1977. </year> <title> Toward automatic identification of the language of an utterance. I. Preliminary methodological consideration. </title> <journal> Journal of the Acoustic Society of America 62(3), </journal> <pages> 708-713. </pages>
Reference: <author> Kwasny, S.C., Barry L. Kalman,Weilan Wu, and A. Maynard Engebretson, </author> <year> 1992. </year> <title> Identifying Language from Speech: An Example of High-Level, Statistically-Based Feature Extraction. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 909-913. </pages>
Reference-contexts: The complexity of interactions among these in the speech signal are impossible to capture in any simplistic model requiring the use of models such as Hidden Markov Models (HMM) and neural networks. In preliminary work <ref> (Kwasny et al., 1992) </ref>, we built a feed-forward network trained to distinguish between two languages: English and French. Only data from two speakers were used in training. The trained network showed the ability to differentiate between those two languages and some generalization capacity was observed. <p> Samples are transformed by the built-in CODEC (COder and DECoder) and fed to the DSP chip, which is programmed to perform the filtering and decimation algorithms shown in Figure 1. Data from the DSP can be divided into smaller samples and used as input to the neural network classifier <ref> (see Kwasny et al 1992) </ref>. Collecting samples is designed to be done in real-time, as compared with the time-consuming and unnatural method of using an anechoic chamber. Of course, recording in a computer room does introduce noise, but we expect training to overcome this problem. <p> Of course, recording in a computer room does introduce noise, but we expect training to overcome this problem. Network Design In our initial design, we succeeded in training a feed-forward network to correctly recognize bilingual speakers of English and French for virtually all samples. <ref> (Kwasny, et al., 1992) </ref>. In the design discussed here, we use a simple recurrent network (Elman, 1990), in which the activation of hidden units are copied back as additional input unit activations, as shown in Figure 2. <p> No votes are counted during this warm-up and no adjustments of the weights are performed during training. Training proceeded to settle at approximately 78.9 % correct on the test patterns. If we consider the individual votes to be independent and apply the binomial theorem <ref> (see Kwasny et al., 1992) </ref>, we can estimate the number of votes, or length of a speech sample, necessary to achieve a given level of identification accurary, based on the classification performance of the network.
Reference: <author> Kucera, H., and Monroe, G.K. </author> <year> 1968. </year> <title> A comparative quantitative phonology of Russian, Czech, and German. </title> <address> New York: </address> <publisher> American Elsevier. </publisher>
Reference: <author> Muthusamy, Y.K.; Cole, R.A.; and Gopalakrishnan, M. </author> <year> 1991. </year> <booktitle> A segment-based approach to automatic language identification In Proceedings of the 1991 IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> Toronto, Canada. </address> - <month> 5 </month> -
References-found: 11

