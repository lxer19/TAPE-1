URL: http://www.is.cs.cmu.edu/papers/speech/EUROSPEECH97/EUROSPEECH97-thomas.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Title: ESTIMATING CONFIDENCE USING WORD LATTICES  
Author: Thomas Kemp Thomas Schaaf 
Address: 76128 Karlsruhe, Germany  
Affiliation: Interactive Systems Laboratories, ILKD University of Karlsruhe  
Abstract: For many practical applications of speech recognition systems, it is desirable to have an estimate of confidence for each hypothesized word, i.e. to have an estimate which words of the speech recognizer's output are likely to be correct and which are not reliable. Many of today's speech recognition systems use word lattices as a compact representation of a set of alternative hypothesis. We exploit the use of such word lattices as information sources for the measure-of-confidence tagger JANKA [1]. In experiments on spontaneous human-to-human speech data the use of word lattice related information significantly improves the tagging accuracy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Schaaf, T. Kemp: </author> <title> Confidence measures for sponta-neous speech recognition, </title> <booktitle> in Proc. ICASSP 1997, </booktitle> <volume> Vol 2, </volume> <pages> pp. </pages> <address> 875 ff, Munich, </address> <month> April </month> <year> 1997 </year>
Reference-contexts: Then, the desired output of a measure of confidence (MOC) tagger would be "0.0, 1.0, 1.0, 1.0, 0.0, 1.0" where "0.0" stands for a recognition error and "1.0" for a correctly recognized word. Previous work has shown <ref> [1] </ref> [2] [3] that the representation of alternative hypothesis, like N-best-lists or word lattices, can be used estimate word-level confidence. Many state- of-the-art speech recognition systems output their result in the form of word lattices anyway. <p> It consists of high-quality recordings of human-to-human spontaneous German dialogs in the appointment scheduling domain, i.e. two persons try to schedule a meeting within the next month. A more detailed description of the database is given in <ref> [1] </ref>. For the evaluation of the word lattice features described in this paper, we used a subset of 1251 utterances from the GSST database. None of the speakers of this subset was used for the training of the acoustic models and the language model of the recognizer. <p> In the experiments described, we evaluated the system that was used for the required test of the 1996 VERBMOBIL evaluation. The baseline confidence accuracy on the MOC test set, when tagging all words with 'correct', was 85.3%. A detailed description of the JANUS-3 recognizer can be found in <ref> [1] </ref> [4]. 5. RESULTS 5.1. Evaluation of the new features To evaluate the performance of the six new features (nTa, nTe, nAve, nPre, nAfter and the forward-backward probability gamma), we built a set of linear classifiers basing on different combinations of the input features. <p> The linear classifiers made use of an LDA transformation based on the classes [correctly recognized, recognition error]. A more detailed description is given in <ref> [1] </ref>. The baseline confidence accuracy CA on the evaluation set was 85.3%. The results are summarized in table 3. As a comparison, the result achieved with 11 not lattice related features [1] is given. <p> A more detailed description is given in <ref> [1] </ref>. The baseline confidence accuracy CA on the evaluation set was 85.3%. The results are summarized in table 3. As a comparison, the result achieved with 11 not lattice related features [1] is given. The classifier relying solely on the output lattice performed very well in comparison to a classifier that made use of the full set of 18 features. 5.2. Classifier design The transformation based approach described in the previous section works well for linearly separable classes. <p> Performance of different feature sets linear classifier: a 3-layer neural network (described in detail in <ref> [1] </ref>) and a decision tree based classifier, as described in [11]. The results are summarized in table 4. As can be seen, the neural net classifier yields slightly better results, than the linear classifier. Features linear tree neural net lattice only 88.9% 88.5% 88.9% all 90.0% 89.6% 90.1% Table 4. <p> As can be seen, the neural net classifier yields slightly better results, than the linear classifier. Features linear tree neural net lattice only 88.9% 88.5% 88.9% all 90.0% 89.6% 90.1% Table 4. Performance of different classifiers 5.3. Adding contextual information It has been shown <ref> [1] </ref>, that the use of contextual information, i.e. the neighbouring words, improves recognition performance. Therefore, we added the feature vector of the left and the right neighbour of each word to the input of the neural net. <p> The performance of a confidence tagger which relied solely on the lattice was higher than that of a classical approach using 11 non-lattice related features <ref> [1] </ref>, which included normalized word scores, language model backoffs, word lengths, speaking rate, and others. 7. ACKNOWLEDGEMENTS This research was partly funded by grant 01 IV 701 U7 from the German Ministry of Science and Technology (BMBF) as a part of the VERBMOBIL project.
Reference: [2] <author> L. Gillick, Y. Ito, J. Young: </author> <title> A probabilistic approach to confidence estimation and evaluation, </title> <booktitle> in Proc. ICASSP 1997, </booktitle> <volume> Vol 2, </volume> <pages> pp. </pages> <address> 879 ff, Munich, </address> <month> April </month> <year> 1997 </year>
Reference-contexts: Then, the desired output of a measure of confidence (MOC) tagger would be "0.0, 1.0, 1.0, 1.0, 0.0, 1.0" where "0.0" stands for a recognition error and "1.0" for a correctly recognized word. Previous work has shown [1] <ref> [2] </ref> [3] that the representation of alternative hypothesis, like N-best-lists or word lattices, can be used estimate word-level confidence. Many state- of-the-art speech recognition systems output their result in the form of word lattices anyway.
Reference: [3] <author> M. Weintraub, F. Beaufays, Z. Rivlin, Y. Konig, A. Stolcke: </author> <title> Neural-network based measures of confidence for word recognition, </title> <booktitle> in Proc. ICASSP 1997, </booktitle> <volume> Vol 2, </volume> <pages> pp. </pages> <address> 887 ff, Munich, </address> <month> April </month> <year> 1997 </year>
Reference-contexts: Then, the desired output of a measure of confidence (MOC) tagger would be "0.0, 1.0, 1.0, 1.0, 0.0, 1.0" where "0.0" stands for a recognition error and "1.0" for a correctly recognized word. Previous work has shown [1] [2] <ref> [3] </ref> that the representation of alternative hypothesis, like N-best-lists or word lattices, can be used estimate word-level confidence. Many state- of-the-art speech recognition systems output their result in the form of word lattices anyway.
Reference: [4] <author> M. Finke, P. Geutner, H. Hild, T. Kemp, K. Ries, M. Westphal: </author> <title> The Karlsruhe-Verbmobil speech recognition engine, </title> <booktitle> in Proc. ICASSP 1997, </booktitle> <volume> Vol 1, </volume> <pages> pp. </pages> <address> 83 ff, Munich, </address> <month> April </month> <year> 1997 </year>
Reference-contexts: A standard statistical trigram-backoff language model is used. In the preprocessing stage, mel-cepstral LDA-transformed coefficients are computed with a frame rate of 10 ms. After the initial recognition run, vocal tract length normalization <ref> [4] </ref> is employed. The JANUS-3 decoder achieved a word error rate of 13.2% in the 1996 VERBMOBIL evaluation. This was the lowest error rate of the five participating institutions. In the experiments described, we evaluated the system that was used for the required test of the 1996 VERBMOBIL evaluation. <p> In the experiments described, we evaluated the system that was used for the required test of the 1996 VERBMOBIL evaluation. The baseline confidence accuracy on the MOC test set, when tagging all words with 'correct', was 85.3%. A detailed description of the JANUS-3 recognizer can be found in [1] <ref> [4] </ref>. 5. RESULTS 5.1. Evaluation of the new features To evaluate the performance of the six new features (nTa, nTe, nAve, nPre, nAfter and the forward-backward probability gamma), we built a set of linear classifiers basing on different combinations of the input features.
Reference: [5] <author> C.J. Legetter, </author> <title> P.C. Woodland: Maximum likelihood linear regression for speaker adaptation of continuous density hidden markov models, </title> <booktitle> Computer Speech and Language 9 (1995), </booktitle> <pages> 171-185 </pages>
Reference-contexts: 1. INTRODUCTION Current speech recognition systems are far from perfect. Unfortunately, number and location of the errors in their output is usually unknown. However, this information could be used in a number of applications. Examples are word selection for unsupervised adaptation schemes like MLLR <ref> [5] </ref>, automatic weighting of additional, non-speech knowledge sources like lip-reading, or aiding a NLP system towards generating repair dialogs in case a semantically important word has a low confidence. Consider the sentence "Mary loves her little child" and the corresponding speech recognizer output "Eight Mary loves her brittle child".
Reference: [6] <author> M. Finke, T. Zeppenfeld, M. Maier, L. Mayfield, K. Ries, P. Zhan, J. Lafferty, A. Waibel: </author> <title> Switchboard April 1996 Evaluation Report, </title> <booktitle> DARPA, </booktitle> <month> April </month> <year> 1996 </year>
Reference-contexts: To capture the effects of high or low confidence of the neighbouring words, we also computed the hypothesis density at the last frame of the predecessor word and the first frame of the successor word. This two features were named nPre and nAfter. 3.3. Acoustic stability For this feature <ref> [6] </ref> [7], a number (typically 100) of alternative hypotheses with different weighting between acoustic scores and language model scores is computed.
Reference: [7] <author> Haitao Qiu: </author> <title> Confidence Measure for Speech Recognition Systems, </title> <type> Masters Thesis, </type> <institution> Carnegie Mellon University Computational Linguistics Philosophy Department, </institution> <address> Pittsburgh, PA, </address> <month> April </month> <year> 1996 </year>
Reference-contexts: EVALUATING CONFIDENCE TAGGER Different methods for the evaluation of confidence measuring systems have been proposed [8] <ref> [7] </ref> [10]. However, the best method for scoring depends on the application for the confidence tags. In this work, confidence accuracy CA, defined as CA = Number of correctly assigned tags total number of tags (1) is used. <p> This two features were named nPre and nAfter. 3.3. Acoustic stability For this feature [6] <ref> [7] </ref>, a number (typically 100) of alternative hypotheses with different weighting between acoustic scores and language model scores is computed.
Reference: [8] <author> S. Cox, R. Rose: </author> <title> Confidence Measures for the Switchboard Database, </title> <booktitle> in Proc. ICASSP-96, </booktitle> <pages> pp 511 ff, </pages> <address> Atlanta, </address> <month> May </month> <year> 1996, </year> <note> ISBN 0-7803-3192-3 </note>
Reference-contexts: EVALUATING CONFIDENCE TAGGER Different methods for the evaluation of confidence measuring systems have been proposed <ref> [8] </ref> [7] [10]. However, the best method for scoring depends on the application for the confidence tags. In this work, confidence accuracy CA, defined as CA = Number of correctly assigned tags total number of tags (1) is used.
Reference: [9] <author> M. Woszczyna, M.Finke, D.Gates, M.Gavalda, T.Kemp, A.Lavie, A.McNair, L.Mayfield, M.Maier, I.Rogina, K.Shima, T.Sloboda, A.Waibel, P.Zhan, T.Zeppenfeld: </author> <title> Janus II advances in spontaneous speech translation, </title> <booktitle> in Proc. ICASSP-96, </booktitle> <pages> pp 409 ff, </pages> <address> Atlanta, </address> <month> May </month> <year> 1996, </year> <note> ISBN 0-7803-3192-3 </note>
Reference-contexts: Database composition 4.2. The JANUS-3 system The speech-to-speech translation system JANUS-3 <ref> [9] </ref> is a joint effort of the Interactive Systems Labs at Carnegie Mellon University, Pittsburgh, and the University of Karl- sruhe, Germany. The baseline speech recognition component of JANUS-3 uses mixture-gaussian, continuous density HMMs with a scalable amount of parameter tying as acoustic model.
Reference: [10] <author> Sheryl Young: </author> <title> Detecting misrecognitions and out-ofvocabulary words, </title> <booktitle> in Proc. ICASSP-94, </booktitle> <pages> pp. </pages> <address> II-21 ff., Adelaide, Australia, </address> <month> April </month> <year> 1994 </year>
Reference-contexts: EVALUATING CONFIDENCE TAGGER Different methods for the evaluation of confidence measuring systems have been proposed [8] [7] <ref> [10] </ref>. However, the best method for scoring depends on the application for the confidence tags. In this work, confidence accuracy CA, defined as CA = Number of correctly assigned tags total number of tags (1) is used.
Reference: [11] <author> J. R. Quinlan: C4.5: </author> <title> programs for machine learn-ing, </title> <publisher> Morgan Kaufman publishers Inc, </publisher> <address> San Mateo, CA, ISBN 1-55860-238-0 (1993) </address>
Reference-contexts: Performance of different feature sets linear classifier: a 3-layer neural network (described in detail in [1]) and a decision tree based classifier, as described in <ref> [11] </ref>. The results are summarized in table 4. As can be seen, the neural net classifier yields slightly better results, than the linear classifier. Features linear tree neural net lattice only 88.9% 88.5% 88.9% all 90.0% 89.6% 90.1% Table 4. Performance of different classifiers 5.3.
Reference: [12] <author> L. Rabiner: </author> <title> A tutorial on Hidden Markov Models and selected applications in speech recognition, in Readings in Speech Recognition, </title> <editor> Kai-Fu Lee and Alex Waibel (edts), </editor> <booktitle> pp 267 ff, </booktitle> <publisher> Morgan Kaufman Publishers, </publisher> <address> ISBN 1-55860-124-4 </address>
Reference-contexts: Link probability For a given word lattice, the probability of any link may be computed in very much the same way as in the standard forward-backward algorithm <ref> [12] </ref> for HMMs. Here, the lattice nodes can be viewed as HMM states, and the links of the lattice give the possible transitions.
References-found: 12

