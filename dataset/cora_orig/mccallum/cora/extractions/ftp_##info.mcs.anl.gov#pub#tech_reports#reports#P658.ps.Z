URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P658.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts97.htm
Root-URL: http://www.mcs.anl.gov
Title: Downdating a Rank-Revealing URV Decomposition  
Author: Yuan-Jye Jason Wu 
Date: November 6, 1996  
Abstract: The rank-revealing URV decomposition is a useful tool for the subspace-tracking problem in digital signal processing. Updating the decomposition is a stable process. However, downdating a rank-revealing URV decomposition can be unstable because the R factor is ill-conditioned. In this article, we review some existing downdating algorithms for the full-rank URV decomposition in the absence of the U factor and develop a new combined algorithm. The combined algorithm has the merits of low cost and no intermediate breakdown, so the downdate is always computable in floating-point arithmetic. For the rank-revealing URV decomposition, we develop a two-step method that applies full-rank downdating algorithms to the signal and noise parts separately without using hyperbolic rotations. We prove that Park and Elden's reduction algorithm and the combined algorithm have relational stabilities for both full-rank and rank-revealing cases. We demonstrate the efficiency and accuracy of our combined algorithm on ill-conditioned problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. W. Stewart. </author> <title> An updating algorithm for subspace tracking. </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 40 </volume> <pages> 1535-1541, </pages> <year> 1992. </year>
Reference-contexts: However, both methods require a large computational burden to update the estimates when the data matrix X incorporates fl This work was supported by NSF Grant CCR 91-15568. y Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL 60439. jwu@mcs.anl.gov an incoming data sample. Stewart <ref> [1] </ref> introduced a rank-revealing URV decomposition so that the data matrix can be expressed as X = U R # 2 4 0 G 3 5 [V s V n ] ; (1) where U and V are unitary matrices, R s is an upper triangular matrix of order d, G <p> We note that in the rank-revealing case, since one row is deleted from the original data matrix, the resulting triangular matrix T s can have numerical rank degeneracy. We examine the resulting matrix T s by applying the deflation algorithm defined in <ref> [1] </ref> after performing each downdate. <p> Some portions of the matrix K are multiplied by scalars fl and ffi to make varied numerical ranks. Then we multiply K on the right by a random unitary matrix. The size of the window function is 12. To estimate the numerical rank, we need a tolerance described in <ref> [1] </ref>. The tolerance is an upper bound for the sum of squares of the singular values in the noise part and works like a barrier that separates the signal and noise parts.
Reference: [2] <author> E. C. Boman, M. F. Griffen, and G. W. Stewart. </author> <title> Direction of arrival and the rank-revealing URV decomposition. </title> <booktitle> In Proceedings of ACASSP-91, </booktitle> <address> Washington, D.C., </address> <year> 1991. </year> <journal> IEEE. </journal> <volume> 16 </volume>
Reference-contexts: Several URV-based algorithms for finding a signal's direction-of-arrival have been proposed and have shown efficient and effective performance <ref> [2, 3] </ref>. However, in some applications the data matrix X is collected by the rectangular win-dowing method to reduce the effect of earlier data. As shown in Figure 1, the rectangular windowing method uses the most recent n samples of data.
Reference: [3] <author> K. J. Ray Liu, Dianne P. O'Leary, G. W. Stewart, and Yuan-Jye J. Wu. </author> <title> URV ESPRIT for tracking time-varying signals. </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 42 </volume> <pages> 3441-3448, </pages> <year> 1994. </year>
Reference-contexts: Several URV-based algorithms for finding a signal's direction-of-arrival have been proposed and have shown efficient and effective performance <ref> [2, 3] </ref>. However, in some applications the data matrix X is collected by the rectangular win-dowing method to reduce the effect of earlier data. As shown in Figure 1, the rectangular windowing method uses the most recent n samples of data. <p> The numerical rank d is chosen as the smallest integer such that the norm of the resulting matrix C is less than the tolerance. Suppose that the sizes of the noise collected in sensors are roughly the same. It has been shown in <ref> [3] </ref> that the sum of the squares of the (m d) smallest singular values of the data matrix sampled by the rectangular windowing method satisfies oe 2 m (m d)* 2 fl (window size) ; where * is the noise size.
Reference: [4] <author> P. E. Gill, G. H. Golub, W. Murray, and M. A. Saunders. </author> <title> Methods for modifying matrix factorizations. </title> <journal> Mathematics of Computation, </journal> <volume> 28 </volume> <pages> 505-535, </pages> <year> 1974. </year>
Reference-contexts: x H tn x H x H tn+1 x H . . . . . . t2 =) x H t2 t1 x H time t 2 x H t time t 1 time t Downdating algorithms when the matrix U is available are well studied and numerically stable (e.g., <ref> [4] </ref> and [5]). Unfortunately, without U , it is difficult to have a numerically stable downdating algorithm. The LINPACK algorithm [6], the CSNE algorithm [7], Chambers' algorithm [8], and the reduction algorithm [9] either break down or are sensitive to the condition number of R. <p> If T s is rank deficient, we repartition the matrix, reducing the dimension of T s . 4 Error Analysis In contrast to the methods in which the matrix U is available <ref> [4, 5] </ref>, none of the down-dating algorithms that we consider is backward stable in the classical sense [14]. In fact, Bjorck, Park, and Elden [7] state that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable.
Reference: [5] <author> S. J. Olszanskyj and A. W. Bojanczyk. </author> <title> Compact Givens representation of the orthogonal factor in recursive linear squares. </title> <editor> In John G. Lewis, editor, </editor> <booktitle> Proceedings of the Fifth SIAM Conference on Applied Linear Algebra. </booktitle> <publisher> SIAM, </publisher> <year> 1994. </year>
Reference-contexts: tn x H x H tn+1 x H . . . . . . t2 =) x H t2 t1 x H time t 2 x H t time t 1 time t Downdating algorithms when the matrix U is available are well studied and numerically stable (e.g., [4] and <ref> [5] </ref>). Unfortunately, without U , it is difficult to have a numerically stable downdating algorithm. The LINPACK algorithm [6], the CSNE algorithm [7], Chambers' algorithm [8], and the reduction algorithm [9] either break down or are sensitive to the condition number of R. <p> If T s is rank deficient, we repartition the matrix, reducing the dimension of T s . 4 Error Analysis In contrast to the methods in which the matrix U is available <ref> [4, 5] </ref>, none of the down-dating algorithms that we consider is backward stable in the classical sense [14]. In fact, Bjorck, Park, and Elden [7] state that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable.
Reference: [6] <author> G. W. Stewart. </author> <title> The effects of rounding error on an algorithm for downdating a Cholesky factorization. </title> <journal> J. Institute for Mathematics and Appl., </journal> <volume> 23 </volume> <pages> 203-213, </pages> <year> 1979. </year>
Reference-contexts: Unfortunately, without U , it is difficult to have a numerically stable downdating algorithm. The LINPACK algorithm <ref> [6] </ref>, the CSNE algorithm [7], Chambers' algorithm [8], and the reduction algorithm [9] either break down or are sensitive to the condition number of R. <p> The original problem can be restated as finding an upper triangular matrix T such that T H T = R H R zz H ; which amounts to downdating a Cholesky factorization. The method in the LINPACK package [10] analyzed by Stewart <ref> [6] </ref> is a popular choice for solving this problem. <p> In fact, Bjorck, Park, and Elden [7] state that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable. However, Stewart <ref> [6] </ref> found an special error property called relational or mixed stability for these algorithms. Furthermore, 10 Stewart [13] showed that relational stability can be preserved after a sequence of updates and downdates. <p> It has been shown in (14) that, * k m = m 2 =2 + 9m m + O (m); for the LINPACK algorithm <ref> [6] </ref>, * k m = 4m m; for Chambers' algorithm [12]. On the other hand, algorithms involving hyperbolic rotations do not have relational stability because the parameter k m in (14) is not bounded and depends on the tangents of rotation angles [12].
Reference: [7] <author> A. Bjorck, H. Park, and L. Elden. </author> <title> Accurate downdating of least squares solutions. </title> <journal> SIAM J. Matrix Anal. and Appl., </journal> <volume> 15 </volume> <pages> 549-568, </pages> <year> 1994. </year>
Reference-contexts: Unfortunately, without U , it is difficult to have a numerically stable downdating algorithm. The LINPACK algorithm [6], the CSNE algorithm <ref> [7] </ref>, Chambers' algorithm [8], and the reduction algorithm [9] either break down or are sensitive to the condition number of R. <p> Under floating-point arithmetic, a breakdown might occur in the LINPACK algorithm when there is a negative computed value under the square root at Step 2. To have a more accurate result, Bjorck, Park, and Elden <ref> [7] </ref> developed a method called corrected seminormal equations (CSNE), using the original data matrix in the refinement of [u 1 u m ] and ff. Let u H be the computed result at Step 1 in the LINPACK algorithm. <p> In fact, Bjorck, Park, and Elden <ref> [7] </ref> state that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable. However, Stewart [6] found an special error property called relational or mixed stability for these algorithms.
Reference: [8] <author> J. M. Chambers. </author> <title> Regression updating. </title> <journal> J. American Statistical Association, </journal> <pages> pages 744-748, </pages> <year> 1971. </year>
Reference-contexts: Unfortunately, without U , it is difficult to have a numerically stable downdating algorithm. The LINPACK algorithm [6], the CSNE algorithm [7], Chambers' algorithm <ref> [8] </ref>, and the reduction algorithm [9] either break down or are sensitive to the condition number of R. <p> Compute the downdated triangular matrix T by using (7). There are four linear triangular systems to solve and three matrix-vector multiplications. The CSNE algorithm needs 6mn + 7m 2 + O (m) flops. 2.2 Chambers' Algorithm Chambers' algorithm <ref> [8] </ref> is another method that does not apply right rotations. The idea is quite simple.
Reference: [9] <author> H. Park and L. Elden. </author> <title> Downdating the rank-revealing URV decomposition. </title> <journal> SIAM J. Matrix Anal. and Appl., </journal> <volume> 16 </volume> <pages> 138-155, </pages> <year> 1995. </year>
Reference-contexts: Unfortunately, without U , it is difficult to have a numerically stable downdating algorithm. The LINPACK algorithm [6], the CSNE algorithm [7], Chambers' algorithm [8], and the reduction algorithm <ref> [9] </ref> either break down or are sensitive to the condition number of R. <p> However, the algorithm breaks down when the argument of the square root at Step 1 is nonpositive for k &lt; m, and there is no way to recover. When the breakdown happens at k = m, this implies that t mm is quite small, and Park and Elden <ref> [9] </ref> suggest letting t mm = 0. Thus the matrix T possibly has rank one less than the matrix R. <p> Thus the matrix T possibly has rank one less than the matrix R. It will be proved in Section 4 that setting t mm to zero gives an acceptable relative error bound. 2.3 Reduction Algorithm We now introduce an algorithm described by Park and Elden <ref> [9] </ref> that applies right rotations. The reduction algorithm works on the problem (5) directly. <p> The LINPACK, CSNE, and Chambers' algorithms have no risk of mixing signal and noise but could produce an inaccurate result or a breakdown because R is ill-conditioned. Park and Elden <ref> [9] </ref> give a simple and direct method called the two-step procedure to solve this problem. They consider only the LINPACK, CSNE, and reduction algorithms. A similar method is also studied by Barlow and Zha [11].
Reference: [10] <author> J. J. Dongarra, J. R. Bunch, C. B. Moler, and G. W. Stewart. </author> <title> LINPACK User's Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference-contexts: The original problem can be restated as finding an upper triangular matrix T such that T H T = R H R zz H ; which amounts to downdating a Cholesky factorization. The method in the LINPACK package <ref> [10] </ref> analyzed by Stewart [6] is a popular choice for solving this problem.
Reference: [11] <author> J. L. Barlow and H. Zha. </author> <title> Stable algorithms for downdating two-sided orthogonal decompositions. </title> <type> Technical Report CSE-93-013, </type> <institution> Department of Computer Science and Engineering, The Pennsylvania State University, </institution> <year> 1993. </year>
Reference-contexts: Park and Elden [9] give a simple and direct method called the two-step procedure to solve this problem. They consider only the LINPACK, CSNE, and reduction algorithms. A similar method is also studied by Barlow and Zha <ref> [11] </ref>. They suggest applying one of the algorithms for the full-rank problem to compute the signal (T s ) and noise (C) parts separately. The only additional work required is a connection task: we have to compute B and modify z H n after computing T s .
Reference: [12] <author> A. W. Bojanczyk, R. P. Brent, P. Van Dooren, and F. R. De Hoog. </author> <title> A note on downdat-ing the Cholesky factorization. </title> <journal> SIAM J. Scientific and Statistical Computing, </journal> <volume> 8 </volume> <pages> 210-221, </pages> <year> 1987. </year>
Reference-contexts: Park and Elden choose hyperbolic rotations as the connection algorithm. For the LIN--PACK and CSNE algorithms, d hyperbolic rotations are required. Only one such rotation is needed for the reduction algorithm. However, the hyperbolic rotation is not recommended because it is not backward stable <ref> [12] </ref> [13]. In contrast to hyperbolic rotations, Equations (10) and (11) in Chambers' algorithm give an alternative way to perform the two-step method, computing [T s B] and modifying z H n simultaneously. Chambers' algorithm and the hyperbolic rotations differ only in the formula to modify z H n . <p> It has been shown in (14) that, * k m = m 2 =2 + 9m m + O (m); for the LINPACK algorithm [6], * k m = 4m m; for Chambers' algorithm <ref> [12] </ref>. On the other hand, algorithms involving hyperbolic rotations do not have relational stability because the parameter k m in (14) is not bounded and depends on the tangents of rotation angles [12]. Therefore, the two-step method using hyperbolic rotations is not relationally stable. <p> m + O (m); for the LINPACK algorithm [6], * k m = 4m m; for Chambers' algorithm <ref> [12] </ref>. On the other hand, algorithms involving hyperbolic rotations do not have relational stability because the parameter k m in (14) is not bounded and depends on the tangents of rotation angles [12]. Therefore, the two-step method using hyperbolic rotations is not relationally stable. Our next task is to prove that the reduction algorithm has relational stability. We adopt the notation in [14] that fl (a) represents the floating-point representation of a.
Reference: [13] <author> G. W. Stewart. </author> <title> On the stability of sequential updates and downdates. </title> <type> Technical report, </type> <institution> Inst. for Advanced Computer Studies Report TR-94-30, Computer Science Department Report TR-3238, University of Maryland, College Park, </institution> <year> 1994. </year>
Reference-contexts: Park and Elden choose hyperbolic rotations as the connection algorithm. For the LIN--PACK and CSNE algorithms, d hyperbolic rotations are required. Only one such rotation is needed for the reduction algorithm. However, the hyperbolic rotation is not recommended because it is not backward stable [12] <ref> [13] </ref>. In contrast to hyperbolic rotations, Equations (10) and (11) in Chambers' algorithm give an alternative way to perform the two-step method, computing [T s B] and modifying z H n simultaneously. Chambers' algorithm and the hyperbolic rotations differ only in the formula to modify z H n . <p> In fact, Bjorck, Park, and Elden [7] state that no algorithm using the matrix R only to compute the required entries of the matrix U can be backward stable. However, Stewart [6] found an special error property called relational or mixed stability for these algorithms. Furthermore, 10 Stewart <ref> [13] </ref> showed that relational stability can be preserved after a sequence of updates and downdates. He also proved that if the final leading principal matrix T s in the sequence is well conditioned, it will be computed accurately.

References-found: 13

