URL: ftp://borneo.gmd.de/pub/as/janus/ref95_1.ps
Refering-URL: http://borneo.gmd.de/AS/janus/publi/publi.html
Root-URL: 
Title: The Architectural Ingredients of the JANUS Robot Controller  
Abstract: Uwe Beyer Frank Smieja Report number: 1995/1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U. Beyer and F. J. Smieja. </author> <title> Learning from examples using reflective exploration. </title> <type> Technical Report 797, </type> <institution> Gesellschaft fur Mathe-matik und Datenverarbeitung, </institution> <address> St Augu-stin, Germany, </address> <month> October </month> <year> 1993. </year> <note> Submitted to Computational Statistics and Data Analysis. </note>
Reference-contexts: In the active case, the agent itself may explore its possibilities by asking questions. This is done in the form of choosing those m's which may provide the a-functions with unknown information <ref> [11, 1, 7] </ref>. The c of the JANUS master agent can be used as a trigger for including new agents or methods in the system.
Reference: [2] <author> U. Beyer and F. J. Smieja. </author> <title> Janus: A society of agents. </title> <type> Technical Report 840, </type> <institution> Ge-sellschaft fur Mathematik und Datenverar-beitung, </institution> <address> St Augustin, Germany, </address> <month> May </month> <year> 1994. </year> <note> Submitted for publication. </note>
Reference-contexts: Each of these problems can be solved extremely straightforwardly, without the need for mathematical gymnastics. The complex system behavior is generated from the combination of these simple agents into a "society of agents" architecture <ref> [6, 2] </ref>. The ambiguity that arises when different agents suggest different solutions for similar or overlapping tasks is not seen as a problem, it is seen as a key mechanism to achieving flexible behavior.
Reference: [3] <author> U. Beyer and F. J. Smieja. </author> <title> Learning from examples, agent teams and the concept of reflection. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <note> 1995. (to be published). </note>
Reference-contexts: On the one hand the number of possible methods one may employ is extremely large, but on the other hand everything seems to be highly dependent on the problem under investigation <ref> [3] </ref>. Therefore, we do not claim any generality for the facts we find out about single agent adaptation, but they may still be useful for related works in the field of robotics. <p> Our experiments in OCR showed that this idea works in general. But it produces no wonders: even if the single team members work well, the overall improvement is also limited by what we term the law of approximation inaccu racy <ref> [3] </ref>. * team structure adaptation Team members may be added or deleted or may give no answers to questions. This can be interpreted as a temporary shrinking/growing of the team. This is primarily an engineering aspect which reduces computation complexity for individual agents.
Reference: [4] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1), </volume> <year> 1986. </year>
Reference-contexts: This notion of a control loop connecting a system to the world is similar to the ideas described in <ref> [4, 5, 18] </ref>), but in our view A is not to be seen as a purely reactive entity. Even if A reacts with a high it may contain complex long range strategies.
Reference: [5] <author> R. A. Brooks. </author> <title> Intelligence without reason. </title> <booktitle> In IJCAI-91, </booktitle> <pages> pages 569-595, </pages> <year> 1991. </year>
Reference-contexts: This notion of a control loop connecting a system to the world is similar to the ideas described in <ref> [4, 5, 18] </ref>), but in our view A is not to be seen as a purely reactive entity. Even if A reacts with a high it may contain complex long range strategies.
Reference: [6] <author> M. Minsky. </author> <title> The Society of Mind. </title> <publisher> Simon and Schuster, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Each of these problems can be solved extremely straightforwardly, without the need for mathematical gymnastics. The complex system behavior is generated from the combination of these simple agents into a "society of agents" architecture <ref> [6, 2] </ref>. The ambiguity that arises when different agents suggest different solutions for similar or overlapping tasks is not seen as a problem, it is seen as a key mechanism to achieving flexible behavior.
Reference: [7] <author> M. C. Mozer and J. Bachrach. </author> <title> Discovering the structure of a reactive environment by exploration. </title> <type> Technical Report CU-CS-451-89, </type> <institution> Dept. of Computer Science, University of Colorado, Boulder, </institution> <month> November </month> <year> 1989. </year>
Reference-contexts: In the active case, the agent itself may explore its possibilities by asking questions. This is done in the form of choosing those m's which may provide the a-functions with unknown information <ref> [11, 1, 7] </ref>. The c of the JANUS master agent can be used as a trigger for including new agents or methods in the system.
Reference: [8] <author> H. Muhlenbein. </author> <title> Open worlds, reflective statistics and stochastic modelling. </title> <type> Technical report, </type> <institution> Gesellschaft fur Mathematik und Datenverarbeitung, </institution> <address> St Augustin, Germany, </address> <year> 1994. </year>
Reference-contexts: All components of the system are built upon this powerful and (by definition) complete model. The correct approach lies between these two extremes. Recent considerations cast doubt on the likelihood of ever being able to establish universal theoretical foundations for the construction of complex real world systems <ref> [8] </ref>, and a full mathematical description may even turn out to be fundamentally impossible [13, 12]. Nevertheless it is necessary to develop at least a small set of plausible ideas that may guide the conception of such systems.
Reference: [9] <author> H. Muhlenbein. Grenzen der kunstlichen in-telligenz. </author> <note> Kunstliche Intelligenz, to be published in. to be published. </note>
Reference-contexts: In other words one can never be absolutely sure about any prediction made in an open world [13, 12]. This contrasts radically with the expectation of models that are constructed on the assumption that facts are always verifiable and unchanging <ref> [9] </ref>. Once one has accepted that the environment of a system is an open world, then it seems fruitless 2 to try to prove its correctness classically using derivable proofs, since it is evidently impossible to postulate a set of axioms.
Reference: [10] <author> G. Paass. </author> <title> Assessing and improving neural network predictions by the bootstrap algorithm. </title> <editor> In S. Hanson, J. Cowan, and C. Gi-les, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5 (NIPS 5), </booktitle> <pages> pages 196-203. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Now we discuss the different types of adaptation in a bit more detail. 5.1 Single agent adaptation 5.1.1 Which method should be applied This is the focus of the current scientific work in the field of adaptation. Most work on neural networks and new work in statistics <ref> [10] </ref> are concerned with this topic. As mentioned above, the a-function adaptation can also be seen as function approximation: this problem has been covered quite thoroughly in the area numerical mathematics.
Reference: [11] <author> G. Paass and J. Kindermann. </author> <title> Bayesian query construction for neural networks. </title> <type> Technical Report 868, </type> <institution> GMD, </institution> <address> St. Augustin, Germany, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: In the active case, the agent itself may explore its possibilities by asking questions. This is done in the form of choosing those m's which may provide the a-functions with unknown information <ref> [11, 1, 7] </ref>. The c of the JANUS master agent can be used as a trigger for including new agents or methods in the system.
Reference: [12] <author> K. </author> <title> Popper. </title> <booktitle> The Logic of Scientific Discovery. </booktitle> <year> 1949. </year>
Reference-contexts: The correct approach lies between these two extremes. Recent considerations cast doubt on the likelihood of ever being able to establish universal theoretical foundations for the construction of complex real world systems [8], and a full mathematical description may even turn out to be fundamentally impossible <ref> [13, 12] </ref>. Nevertheless it is necessary to develop at least a small set of plausible ideas that may guide the conception of such systems. Without this every system constructed represents an isolated work of art, which does not help to a general understanding of the problem and form of solution. <p> The principle is expressed as follows: any model constructed through the evidence acquired from an open world may at any time be contradicted by a future event in this world. In other words one can never be absolutely sure about any prediction made in an open world <ref> [13, 12] </ref>. This contrasts radically with the expectation of models that are constructed on the assumption that facts are always verifiable and unchanging [9].
Reference: [13] <editor> K.R. Popper. Auf der Suche nach einer bes-seren Welt. Piper, </editor> <address> Munchen, Zurich, </address> <year> 1987. </year>
Reference-contexts: The correct approach lies between these two extremes. Recent considerations cast doubt on the likelihood of ever being able to establish universal theoretical foundations for the construction of complex real world systems [8], and a full mathematical description may even turn out to be fundamentally impossible <ref> [13, 12] </ref>. Nevertheless it is necessary to develop at least a small set of plausible ideas that may guide the conception of such systems. Without this every system constructed represents an isolated work of art, which does not help to a general understanding of the problem and form of solution. <p> The principle is expressed as follows: any model constructed through the evidence acquired from an open world may at any time be contradicted by a future event in this world. In other words one can never be absolutely sure about any prediction made in an open world <ref> [13, 12] </ref>. This contrasts radically with the expectation of models that are constructed on the assumption that facts are always verifiable and unchanging [9].
Reference: [14] <author> O. G. Selfridge. Pandemonium: </author> <title> a paradigm for learning. </title> <booktitle> In The Mechanisation of Thought Processes: Proceedings of a Symposium Held at the National Physical Laboratory, </booktitle> <month> November </month> <year> 1958, </year> <pages> pages 511-527, </pages> <address> Lon-don: HMSO, </address> <year> 1958. </year>
Reference-contexts: Each of these methods has its advantages and disadvantages. In a team the problem is presented before a set of team members. Each member uses a different method of solving the problem, very much like in Selfridge's Pandemonium system and its derivatives <ref> [14, 15] </ref>. Since a team output only one answer at a time the answers of the different team members must be combined by a team master. This integration process is one of the main problems in a team-like structure.
Reference: [15] <author> F. J. Smieja. </author> <title> The Pandemonium system of reflective agents. </title> <journal> IEEE Transactions on Neural Networks, </journal> <note> 1995. (to be published). </note>
Reference-contexts: Each of these methods has its advantages and disadvantages. In a team the problem is presented before a set of team members. Each member uses a different method of solving the problem, very much like in Selfridge's Pandemonium system and its derivatives <ref> [14, 15] </ref>. Since a team output only one answer at a time the answers of the different team members must be combined by a team master. This integration process is one of the main problems in a team-like structure.
Reference: [16] <author> F. J. Smieja and U. Beyer. </author> <title> JANUS: A robot manipulator system based on a blackboard 13 architecture. </title> <type> Technical Report 839, </type> <institution> Gesell--schaft fur Mathematik und Datenverarbei-tung, </institution> <address> St Augustin, Germany, </address> <month> April </month> <year> 1994. </year> <note> Poster presentation in AICS '94. </note>
Reference-contexts: Thus there are few (if any) possibilities for surprising interactions. This kind of connectivity is therefore too inflexi ble. To prevent our system from being caught in one of these scenarios we employ a blackboard archi tecture <ref> [16] </ref>. The main ideas behind this are: * tags The agents exchange structured messages. These messages are very much like a "structure" type definition in programming languages. The number of possible structures is fixed and the structure of a tag defines its type. * The agents are placed around blackboards.
Reference: [17] <author> F. J. Smieja, U. Beyer, and G. Richter. </author> <title> Adaptive control of a robot arm using driver programs. </title> <type> Technical Report 886, </type> <institution> Ge-sellschaft fur Mathematik und Datenverar-beitung, </institution> <address> St Augustin, Germany, </address> <month> December </month> <year> 1994. </year> <note> Submitted for publication. </note>
Reference-contexts: On switching to a new task it should likewise be able to re-adapt and, where possible, transfer its current knowledge to the new domain <ref> [17] </ref>. Such behavior requires a large number of individual sub-problems to be tackled. These are typically inverse kinematics, path planning, grab planning, place planning, collision prevention, motor and visual sensor processing, and so on.
Reference: [18] <author> L. </author> <title> Steels. </title> <journal> The artificial life roots of artificial intelligence. Artificial Life Journal, </journal> 1(1/2):89-125, 1994. 
Reference-contexts: This notion of a control loop connecting a system to the world is similar to the ideas described in <ref> [4, 5, 18] </ref>), but in our view A is not to be seen as a purely reactive entity. Even if A reacts with a high it may contain complex long range strategies.
References-found: 18

