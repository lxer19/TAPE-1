URL: http://osl.cs.uiuc.edu/~w-kim4/thesis-tr.ps
Refering-URL: http://osl.cs.uiuc.edu/
Root-URL: http://www.cs.uiuc.edu
Note: c flCopyright by Wooyoung Kim, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> G. Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Every actor is associated with a thread; however, the thread makes its presence manifest only when a message is scheduled. 2.3 Actor-Based Languages The Actor model was first introduced by Carl Hewitt [53], refined by many others [55, 54, 30, 56] and defined in its current standard form by Agha <ref> [1] </ref>. Particularly, since its introduction many actor-based languages [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. <p> The language also used futures for parallel computation and serializers for synchronization. Another actor language with Lisp-based implementation is Acore [89] which even borrowed the syntax of Lisp. Acore was the first language based on the Actor model defined in <ref> [1] </ref> so that a mutable actor implicitly serializes messages it receives and the expressions in a message handler may be evaluated concurrently. Cantor [11] is the first actor language that was implemented and executed on multicomputers. <p> = array (3,4,5); %% allocate 3 dimensional array and %% assign it to arr r1 &lt;- m1 (arr); %% send the entire array r2 &lt;- m2 (arr <ref> [1] </ref>[1][1]); %% send the first element r3 &lt;- m3 (arr [1][1]); %% send the first vector of size 5 r4 &lt;- m4 (arr [1]); %% send the first plane of size 4x5 r5 &lt;- m5 (arr [1]f1:3g); %% another way to send the entire array 3.4 Communication Abstractions Although point-to-point non-blocking asynchronous message passing is efficient as well as fundamental, it is inconvenient to use in some cases. <p> The compiler analyzes data dependence among requests in a method to identify those that may be executed concurrently. It isolates computation simultaneously dependent on the requests (i.e. a join continuation <ref> [1] </ref>) into a continuation actor and translates the requests to non-blocking asynchronous message sending expressions. A unique reply address represented as a triple is appended to each expression as an additional message argument. Use of non-blocking asynchronous message passing allows us to avoid expensive context switching. <p> The implementation iteratively traverses a global flow graph of a program to refine type information it gathers. The discussion of join continuation in the context of the Actor model appears in <ref> [1] </ref>. Extracting join continuation through a source-to-source transformation was attempted in other actor-based languages as well [89, 62]. Also, a similar transformation technique for explicitly message-passing programs was presented in [59].
Reference: [2] <author> G. Agha. </author> <title> Supporting Multiparadigm Programming on Actor Architectures. </title> <booktitle> In Proceedings of Parallel Architectures and Languages Europe, Vol. II: Parallel Languages (PARLE '89), </booktitle> <pages> pages 1-19. </pages> <address> Espirit, </address> <publisher> Springer-Verlag, </publisher> <year> 1989. </year> <note> LNCS 366. </note>
Reference: [3] <author> G. Agha. </author> <title> Concurrent Object-Oriented Programming. </title> <journal> Communications of the ACM, </journal> <volume> 33(9) </volume> <pages> 125-141, </pages> <month> September </month> <year> 1990. </year>
Reference: [4] <author> G. Agha, S. Frtlund, W. Kim, R. Panwar, A. Patterson, and D. Sturman. </author> <title> Abstraction and Modularity Mechanisms for Concurrent Computing. </title> <journal> IEEE Parallel and Distributed Technology: Systems and Applications, </journal> <volume> 1(2) </volume> <pages> 3-14, </pages> <month> May </month> <year> 1993. </year>
Reference: [5] <author> G. Agha, W. Kim, and R. Panwar. </author> <title> Actor Languages for Specification of Parallel Computations. </title> <editor> In G. E. Blelloch, K. Mani Chandy, and S. Jagannathan, editors, </editor> <booktitle> DIMACS. Series in Discrete Mathematics and Theoretical Computer Science. </booktitle> <volume> vol 18. </volume> <booktitle> Specification of Parallel Algorithms, </booktitle> <pages> pages 239-258. </pages> <publisher> American Mathematical Society, </publisher> <year> 1994. </year> <booktitle> Proceedings of DIMACS '94 Workshop. </booktitle>
Reference-contexts: Although object migration is yet to be supported, a programmer may mimic it by remotely creating an object and explicitly forwarding its associated code. 10 Chapter 3 THAL: A Tailored High-level Actor Language THAL is a high-level language based on actors; it is a descendant of HAL <ref> [63, 5] </ref>. THAL allows a programmer to create actors, initialize their behaviors, and send them messages. As the computation unfolds, new messages are generated, new actors are created, and existing actors undergo state change. <p> Examples of the concurrent call/return communication abstraction are ask [89], now [135], blocking send [29], and request <ref> [5] </ref>. THAL supports CCRC using two constructs, request and reply. They are represented with "." and reply, respectively. Execution of a request blocks the sender until a reply is sent back. <p> Out-of-order arrival of replies does not help because futures are touched sequentially conforming to the order of appearance of the requests in a method. In contrast to the future-based implementations, we employ a compiler-oriented approach <ref> [78, 5] </ref>. The compiler transforms a method containing CCRCs in such a way that a programmer would write a method with the same semantics if CCRC is not available. The compiler analyzes data dependence among requests in a method to identify those that may be executed concurrently.
Reference: [6] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison Wesley, </publisher> <year> 1986. </year>
Reference-contexts: After being modified, the method twoRsps looks as follows: method twoRsps () (1) t2 = r2.m2 (); (3) t4 = r4.m4 (); (5) r0 &lt;- m0 (t1, t3); With the transformed method m 0 , the compiler computes the def-use chain DU C d m <ref> [6] </ref> for each definition d 1 in m and constructs data dependence relation m 0 . <p> It is a directed graph F G = (V; E) where V = fb j b is a basic block in the methodg and E = f (b i ; b j ) j b j can immediately follow b i in some execution sequenceg <ref> [6] </ref>. One node is distinguished as the initial node: it is the block whose leader is the first statement of the method. The compiler traverses F G in a topological order starting from the initial node. <p> A basic block is a sequence of consecutive statements in which flow of control enters at the beginning and leaves at the end without halt or possibility of branching except at the end <ref> [6] </ref>. A basic block may have one or two successor blocks, jump-on-true (JOT) and jump-on-false (JOF). JOF is not defined for a simple block; only if block and for block have two successor blocks. <p> Certain local actors will never receive messages from remote actors and need not have location transparency. To get better performance, a cheaper implementation may be used when creating these actors. The compiler uses the def-use analysis and the constant propagation <ref> [6] </ref> to identify such actors.
Reference: [7] <author> J. Randy Allen. </author> <title> "Dependence Analysis for Subscripted Variables and Its Application to Program Transformations. </title> <type> Ph.D. dissertation, </type> <institution> Rice University, Dept. Mathematical Sciences, </institution> <month> April </month> <year> 1983. </year> <pages> (UMI 83-14916). </pages>
Reference-contexts: Also, a similar transformation technique for explicitly message-passing programs was presented in [59]. The common continuation region analysis extends the base join continuation transformation (Section 5.2.1 to restore concurrency across loop boundary by using data dependence analysis <ref> [7, 14, 15] </ref>. 69 Chapter 6 Performance Evaluation The runtime system has been running on the TMC CM-5 and porting it to other platforms, such as Cray T3D/T3E, SGI PowerChallenge array, and networks of workstations, is in progress.
Reference: [8] <author> T. E. Anderson, D. E. Culler, D. A. Patterson, </author> <title> and the NOW team. A Case for NOW (Networks of Workstations). </title> <journal> IEEE Micro, </journal> <volume> 15(1) </volume> <pages> 54-64, </pages> <month> February </month> <year> 1995. </year>
Reference: [9] <author> Arvind and R. A. </author> <title> Iannucci. Two Fundamental Issues in Multiprocessing. </title> <booktitle> In 4th International DFVLR Seminar on Foundations of Engineering Sciences, </booktitle> <pages> pages 61-88, </pages> <year> 1987. </year> <note> LNCS 295. </note>
Reference-contexts: The unpredictable remote creation time makes split-phase allocation (Figure 4.12.a) desirable on platforms with hardware support for context switch; context switch to another from a thread requesting remote creation while the latter waits for the mail address to be delivered, effectively hides the latency and saves idle cycles <ref> [9, 34] </ref>. However, it is less desirable in stock-hardware multicomputers where context switch is very costly (e.g., 52 sec in the TMC CM-5). We use aliases instead of relying on context switch.
Reference: [10] <author> M. Astley and G. Agha. </author> <title> A Visualization Model for Concurrent Systems. </title> <journal> Information Sciences, </journal> <volume> 93(1-2):107-132, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: Such systems include: multi-object synchronization and coordination in distributed environment [41], meta-level specification of interaction policies between distributed components [114], synchronization between distributed objects with real-time constraints [105], visualization of coordination patterns in concurrent algorithms <ref> [10] </ref>. All of these systems are based on asynchronous objects and thus are modeled with actors. Although the systems support different high-level linguistic abstractions, they share a property that the abstractions may be implemented in terms of primitive actor operators.
Reference: [11] <author> W. Athas and C. Seitz. </author> <title> Cantor User Report Version 2.0. </title> <type> Technical Report 5232:TR:86, </type> <institution> California Institute of Technology, Pasadena, </institution> <address> CA, </address> <month> January </month> <year> 1987. </year>
Reference-contexts: Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages. <p> Acore was the first language based on the Actor model defined in [1] so that a mutable actor implicitly serializes messages it receives and the expressions in a message handler may be evaluated concurrently. Cantor <ref> [11] </ref> is the first actor language that was implemented and executed on multicomputers. The "essential cantor" described in [11] preserved message order between pairs of directly communicating actors. It originally employed dynamic typing which was subsequently replaced with strong typing through the use of type declaration. <p> Cantor <ref> [11] </ref> is the first actor language that was implemented and executed on multicomputers. The "essential cantor" described in [11] preserved message order between pairs of directly communicating actors. It originally employed dynamic typing which was subsequently replaced with strong typing through the use of type declaration. Cantor version 2.2 also added vectors along with internal iteration.
Reference: [12] <author> W. Athas and C. Seitz. </author> <title> Multicomputers: Message-Passing Concurrent Computers. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 9-23, </pages> <month> August </month> <year> 1988. </year>
Reference: [13] <author> G. Attardi. </author> <title> Concurrent Strategy Execution in Omega. </title> <editor> In A. Yonezawa and M. Tokoro, editors, </editor> <booktitle> Object-Oriented Concurrent Programming, </booktitle> <pages> pages 259-276. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages.
Reference: [14] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: Also, a similar transformation technique for explicitly message-passing programs was presented in [59]. The common continuation region analysis extends the base join continuation transformation (Section 5.2.1 to restore concurrency across loop boundary by using data dependence analysis <ref> [7, 14, 15] </ref>. 69 Chapter 6 Performance Evaluation The runtime system has been running on the TMC CM-5 and porting it to other platforms, such as Cray T3D/T3E, SGI PowerChallenge array, and networks of workstations, is in progress.
Reference: [15] <author> U. Banerjee, R. Eigenmann, A. Nicolau, and D. A. Padua. </author> <title> Automatic Program Parallelization. </title> <booktitle> Proceedings of IEEE, </booktitle> <volume> 81(2) </volume> <pages> 211-243, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Also, a similar transformation technique for explicitly message-passing programs was presented in [59]. The common continuation region analysis extends the base join continuation transformation (Section 5.2.1 to restore concurrency across loop boundary by using data dependence analysis <ref> [7, 14, 15] </ref>. 69 Chapter 6 Performance Evaluation The runtime system has been running on the TMC CM-5 and porting it to other platforms, such as Cray T3D/T3E, SGI PowerChallenge array, and networks of workstations, is in progress.
Reference: [16] <author> B. M. Barry, J. Altoft, D. A. Thomas, and M. Wilson. </author> <title> Using Objects to Design and Build Radar ESM Systems. </title> <booktitle> In Proceedings of OOPSLA '87. SIGPLAN, ACM, </booktitle> <year> 1987. </year> <month> 81 </month>
Reference-contexts: Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages.
Reference: [17] <author> F. Baude and G. </author> <title> Vidal-Naquet. Actors as a Parallel Programming Model. </title> <booktitle> In Proceedings of 8th Symposium on Theoretical Aspects of Computer Science, </booktitle> <pages> pages 184-195, </pages> <year> 1991. </year> <note> LNCS 480. </note>
Reference: [18] <author> M. Ben-Ari. </author> <booktitle> Principles of Concurrent and Distributed Programming. International Series on Computer Science. </booktitle> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference: [19] <author> R. D. Blumofe, C. F. Joerg, B. C. Kuszmaul, C. E. Leiserson, K. H. Randall, A. Shaw, and Y. Zhou. Cilk: </author> <title> An Efficient Multithreaded Runtime System. </title> <booktitle> In Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming PPOPP, </booktitle> <year> 1994. </year>
Reference-contexts: Furthermore, quasi-dynamic scheduling allows the compiler to exploit temporal locality existing among logically related threads. Such temporal locality is utilized in our runtime system with coarser grain by collectively scheduling messages broadcast to a group of actors. Cilk <ref> [19] </ref> is a C-based runtime system for multithreaded parallel programming. The Cilk language is defined by extending C with an abstraction of threads in the explicit continuation-passing style. A Cilk program is a collection of Cilk procedures, each of which is broken into a sequence of threads. <p> Figure 6.4 compares performance of THAL versions computing Fibonacci of 33 on a single node of TMC CM-5 with that of an optimized C version on a single Sparc processor. The C version completes in 8.49 seconds. As a point of comparison, computing Fib (33) in the Cilk system <ref> [19] </ref> on a single Sparc processor takes 73.16 seconds. 72 Number of Processors 1 2 4 8 16 32 Without DLB 55.5 32.3 20.8 12.9 7.94 4.96 With DLB 60.7 37.9 24.1 8.98 3.84 1.87 Table 6.2: Execution times of the Fibonacci number generator.
Reference: [20] <author> F. Bodin, P. Beckman, D. Gannon, S. Yang, S. Kesavan, A. Malony, and B. Mohr. </author> <title> Implementing a Parallel C++ Runtime System for Scalable Parallel Systems. </title> <booktitle> In Supercomputing '93, </booktitle> <pages> pages 588-597, </pages> <year> 1993. </year>
Reference-contexts: Concurrent Aggregates (CA) [29] also supports a notion of groups but with a one-to-one-out-of-many type of communication where a message sent to a group (i.e., an aggregate) is processed by a unspecified member. pC++ <ref> [87, 20] </ref> has a notion of groups similar to that of CA but its use is limited to data parallel computation. The communication abstractions supported in THAL are found in other actor languages with different names.
Reference: [21] <author> Jean-Pierre Briot. Actalk: </author> <title> A Testbed for Classifying and Designing Actor Languages in the Smalltalk-80 Environment. </title> <editor> In S. Cook, editor, </editor> <booktitle> European Conference on Object-Oriented Programming (ECOOP'89), </booktitle> <pages> pages 109-129, </pages> <address> Nottingham, U.K., </address> <month> July </month> <year> 1989. </year> <title> Espirit, </title> <publisher> Cambridge University Press, </publisher> <address> United-Kingdom. </address> <booktitle> British Computer Society Workshop Series. </booktitle>
Reference-contexts: A different approach involves extending an existing sequential object-oriented language with the concurrency semantics of actors. In this approach, actors inherit their actions from a single Actor class which wraps sequential objects with actor semantics. Two examples following this approach are Actalk <ref> [21] </ref> and actra [124] which were built upon Smalltalk-80. Actalk implemented actors by augmenting ordinary Smalltalk objects with asynchronous message passing and message buffering. Actra was implemented by modifying the Smalltalk virtual machine. In contrast to the basic Actor model, communication between actors in Actra was synchronous.
Reference: [22] <author> Kim B. Bruce. </author> <title> Safe Type Checking in a Statically-Typed Object-Oriented Programming Language. </title> <booktitle> In Twentieth Symposium on Principles of Programming Languages, </booktitle> <pages> pages 285-298. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: If the compiler ascertains that the conditions will hold during the execution, it generates the codes that exploit the information. 5.5 Related Work A number of type inference mechanisms for object-oriented programming languages have been proposed <ref> [115, 46, 100, 22] </ref>. In particular, the type inference in the THAL compiler is implemented using a constraint-based type inference algorithm [100]. The implementation is similar to that of [99] but is extended to infer types for groups and member actors.
Reference: [23] <author> P. A. Buhr, G. Ditchfield, R. A. Stroobosscher, B. M. Younger, and C. R. Zaranke. </author> <title> C++: Concurrency in the Object-Oriented Language C++. </title> <journal> Software Practice and Experience, </journal> <volume> 22(2) </volume> <pages> 137-172, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors.
Reference: [24] <author> A. Burns. </author> <title> Concurrent Programming in Ada. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: Thus, the sender may not know if the recipient will be in a consistent state in which it can logically respond to an incoming message. This problem is addressed in some process-oriented languages with input guards on synchronous communication <ref> [24, 92, 136, 57] </ref>: the recipient refuses to accept a message from a given sender (or a specific channel) until it is in a state in which it can process that message. Thus, the sender must busy-wait until the recipient is ready to accept the message.
Reference: [25] <author> C. Callsen and G. Agha. </author> <title> Open Heterogeneous Computing in ActorSpace. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <pages> pages 289-300, </pages> <year> 1994. </year>
Reference-contexts: Sending a message to a group using a group identifier or mygrp denotes broadcasting. Semantically, the message is replicated and a copy is delivered to each member. Point-to-point communication among member actors is expressed by naming individual member actors. Some systems, such as <ref> [29, 25] </ref>, provides one to one-out-of-many type of communication mechanism [26] which sends a message to an indeterminate representative member. <p> HAL had been used as a test-bed for experimenting with new language constructs and dependability methods. A general framework for modeling groups may be found in the ActorSpace paradigm <ref> [25] </ref> which provides group abstractions as a key component of its semantics. ActorSpace adopts a pattern-based model of communication. Messages may be sent to groups of actors which are identified with patterns. Groups in THAL are a passive container as in the ActorSpace model, but have only flat structures.
Reference: [26] <author> N. Carriero and D. Gelernter. </author> <title> How to Write Parallel Programs: A Guide to the Perplexed. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 323-357, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Semantically, the message is replicated and a copy is delivered to each member. Point-to-point communication among member actors is expressed by naming individual member actors. Some systems, such as [29, 25], provides one to one-out-of-many type of communication mechanism <ref> [26] </ref> which sends a message to an indeterminate representative member.
Reference: [27] <author> R. Chandra, A. Gupta, and J. L. Hennessy. </author> <title> COOL: An Object-Based Language for Parallel Programming. </title> <journal> IEEE Computer, </journal> <volume> 27(8) </volume> <pages> 13-26, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. <p> We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL <ref> [27] </ref> is targeted for shared-memory multiprocessors. Invocation of a parallel function creates a thread which executes asynchronously. Threads communicate through shared data and synchronize using monitors and condition variables.
Reference: [28] <author> A. Chien, V. Karamcheti, and J. Plevyak. </author> <title> The Concert System Compiler and Runtime Support for Efficient Fine-Grained Concurrent Object-Oriented Programs. </title> <type> Technical Report UIUCDCS-R-93-1815, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: A message sent to the aggregates is processed by one and only one constituent but which constituent receives the message is left unspecified (i.e., one-to-one-of-many type of communication). Unlike the Actor model, every message send in CA expects a reply by default <ref> [28, 75] </ref>. All of the above-mentioned actor languages have been designed and implemented from scratch. A different approach involves extending an existing sequential object-oriented language with the concurrency semantics of actors. In this approach, actors inherit their actions from a single Actor class which wraps sequential objects with actor semantics. <p> When the message must be forwarded, the runtime system sees the packing information in packer and packs the message accordingly. Note that strings are treated as one-dimensional arrays of characters. 4.8 Related Work Among other systems the implementations of ABCL/onAP1000 [119, 120] and the Concert system <ref> [28, 75] </ref> have influenced the design of THAL most. ABCL/onAP1000 adopted an encapsulation approach to implement its runtime system. For example, the runtime system determines whether to use the stack-based or the queue-based scheduling mechanism for local messages. <p> The shaded actor is blocked after sending its very first message to self and unable to progress because it cannot process the message. A future-based implementation is no better than the naive implementation [118]. Some systems replace a message send to self with a function call <ref> [28, 75] </ref>. It may be successful in avoiding deadlock but may not be used with the atomic method execution because the replacement may alter the meaning of the program incorrectly, as shown in Figure 5.10. Further, it it serializes the sender's computation eliminating the possibility of dynamic load balancing. <p> The implementation is similar to that of [99] but is extended to infer types for groups and member actors. A more detailed discussion on constraint-based type inference for object-oriented programming languages may be found in [101]. A 68 similar constraint-based type inference mechanism was implemented on the Concert system <ref> [28, 75] </ref> and is presented in [104]. The implementation iteratively traverses a global flow graph of a program to refine type information it gathers. The discussion of join continuation in the context of the Actor model appears in [1].
Reference: [29] <author> A. A. Chien. </author> <title> Concurrent Aggregates: Supporting Modularity in Massively Parallel Programs. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: If it fails, it climbs up the inheritance tree to respond to the message. Delegation implements the prototype approach to sharing knowledge in object oriented systems. It appears in actor languages <ref> [88, 135, 29] </ref> and several Lisp-based object oriented systems such as Director [72], T [67], Orbit [113], and others. An object shares knowledge with a prototype by simply having the prototype as its acquaintance; the object may also keep its personal behavior idiosyncratic to itself. <p> Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages. <p> Examples of the concurrent call/return communication abstraction are ask [89], now [135], blocking send <ref> [29] </ref>, and request [5]. THAL supports CCRC using two constructs, request and reply. They are represented with "." and reply, respectively. Execution of a request blocks the sender until a reply is sent back. <p> Sending a message to a group using a group identifier or mygrp denotes broadcasting. Semantically, the message is replicated and a copy is delivered to each member. Point-to-point communication among member actors is expressed by naming individual member actors. Some systems, such as <ref> [29, 25] </ref>, provides one to one-out-of-many type of communication mechanism [26] which sends a message to an indeterminate representative member. <p> ActorSpace adopts a pattern-based model of communication. Messages may be sent to groups of actors which are identified with patterns. Groups in THAL are a passive container as in the ActorSpace model, but have only flat structures. Concurrent Aggregates (CA) <ref> [29] </ref> also supports a notion of groups but with a one-to-one-out-of-many type of communication where a message sent to a group (i.e., an aggregate) is processed by a unspecified member. pC++ [87, 20] has a notion of groups similar to that of CA but its use is limited to data parallel
Reference: [30] <author> W. Clinger. </author> <title> Foundations of Actor Semantics. </title> <type> Technical Report AI-TR-633, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> May </month> <year> 1981. </year>
Reference-contexts: objects is removed in actor languages because actors are active by definition. 7 Every actor is associated with a thread; however, the thread makes its presence manifest only when a message is scheduled. 2.3 Actor-Based Languages The Actor model was first introduced by Carl Hewitt [53], refined by many others <ref> [55, 54, 30, 56] </ref> and defined in its current standard form by Agha [1]. Particularly, since its introduction many actor-based languages [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp.
Reference: [31] <institution> Convex Computer Corporation, Richardson, Texas. Convex Exemplar Architecture, </institution> <month> November </month> <year> 1993. </year>
Reference: [32] <author> Cray Research, Inc. </author> <title> Cray T3D System Architecture Overview, </title> <month> March </month> <year> 1993. </year>
Reference: [33] <author> D. E. Culler, A. Dusseau, S. C. Goldstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Parallel Programming in Split-C. </title> <booktitle> In Proceedings of Supercomputing 93, </booktitle> <pages> pages 262-273, </pages> <year> 1993. </year>
Reference-contexts: After N iterations, the result is in matrix C. Unlike usual systolic implementations, no global synchronization is used to make computation march in lock-step fashion. Rather, per-actor-basis local synchronization is used to simulate the barrier synchronization. Local block matrix multiplication is implemented using the same assembly routine used in <ref> [33] </ref>. Table 6.3 shows the execution times of a THAL implementation on TMC CM-5. Results are comparable to those given in [33] (Figure 6.5). For example, the performance peaks at 434 MFlops for a 1024 by 1024 matrix on a 64 node partition of a CM-5. <p> Rather, per-actor-basis local synchronization is used to simulate the barrier synchronization. Local block matrix multiplication is implemented using the same assembly routine used in <ref> [33] </ref>. Table 6.3 shows the execution times of a THAL implementation on TMC CM-5. Results are comparable to those given in [33] (Figure 6.5). For example, the performance peaks at 434 MFlops for a 1024 by 1024 matrix on a 64 node partition of a CM-5.
Reference: [34] <author> D. E. Culler, A. Sah, K. E. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine. </title> <booktitle> In Proceedings of ASPLOS, </booktitle> <pages> pages 166-175, </pages> <year> 1991. </year>
Reference-contexts: The unpredictable remote creation time makes split-phase allocation (Figure 4.12.a) desirable on platforms with hardware support for context switch; context switch to another from a thread requesting remote creation while the latter waits for the mail address to be delivered, effectively hides the latency and saves idle cycles <ref> [9, 34] </ref>. However, it is less desirable in stock-hardware multicomputers where context switch is very costly (e.g., 52 sec in the TMC CM-5). We use aliases instead of relying on context switch. <p> Concert objects other than aggregates are allocated in a global space and subject to global name translation. THAL's locality check uses only locally available information which is made possible by our name management scheme which works efficiently with migration. Threaded Abstract Machine (TAM) supports multithreading at instruction level <ref> [34] </ref>. It defines an extension of a hybrid dataflow model with a multilevel scheduling hierarchy where synchronization, scheduling and storage management are explicit and under compiler control. In TAM, a thread executes to completion once successfully initiated, like our method execution.
Reference: [35] <author> O.-J. Dahl and K. Nygaard. </author> <title> SIMULA 67 Common Base Proposal. </title> <type> Technical report, NCC Doc., </type> <year> 1967. </year>
Reference-contexts: In this chapter, we survey some of these programming languages as well as other representative concurrent object-oriented programming languages. 2.1 Ob ject-Oriented Programming Object-oriented programming paradigm encourages modular design and knowledge sharing (in particular, code reuse). The concept of object-oriented programming has its root in SIMULA <ref> [35] </ref>. Since then, it has been developed as an important software engineering methodology through a series of breakthroughs in the field of programming language theory and practice. In object-oriented languages, computation is abstracted as communication between a collection of objects.
Reference: [36] <author> W. Dally. </author> <title> A VLSI Architecture for Concurrent Data Structures. </title> <publisher> Kluwer Academic Press, </publisher> <year> 1986. </year>
Reference: [37] <author> W. Dally. </author> <title> The J-Machine: System Support for Actors, </title> <booktitle> chapter 16, </booktitle> <pages> pages 369-408. </pages> <publisher> M.I.T. Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year> <month> 82 </month>
Reference: [38] <author> W. J. Dally and A. A. Chien. </author> <title> Object-Oriented Concurrent Programming in CST. </title> <editor> In G. Agha, P. Wegner, and A. Yonezawa, editors, </editor> <booktitle> The ACM SIGPLAN Workshop on Object-Based Concurrent Programming, </booktitle> <pages> pages 28-31, </pages> <address> San Diego, USA, </address> <month> September </month> <year> 1988. </year> <booktitle> The ACM SIGPLAN, </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: By contrast, Charm++ requires programmers take the responsibility of mapping of objects onto processing nodes. pC++ [87], C flfl [86], and pSather [95] are all C++-based COOP languages which are designed to support data parallelism. They differ in how to initiate data parallel execution. CST <ref> [61, 38] </ref> and DistributedConcurrentSmalltalk (DCS) [96] are two of many COOP languages which extended Smalltalk-80 [43]. CST supports concurrency using locks, asynchronous message passing, and distributed objects. Distributed objects are similar to aggregates in CA and are equipped with similar communication mechanisms.
Reference: [39] <author> J. H. Edmondson, P. Rubinfeld, R. Rreston, and V. Rajagopalan. </author> <title> Superscalar instruction Execution in the 21164 Alpha Microprocessor. </title> <journal> IEEE micro, </journal> <volume> 15(2), </volume> <month> April </month> <year> 1995. </year>
Reference: [40] <author> S. Frtlund. </author> <title> Inheritance of Synchronization Constraints in Concurrent Object-Oriented Programming Languages. </title> <editor> In O. Lehrmann Madsen, editor, </editor> <booktitle> ECOOP'92 European Conference on Object-Oriented Programming, </booktitle> <pages> pages 185-196. </pages> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1992. </year> <note> LNCS 615. </note>
Reference-contexts: In THAL, synchronization necessary for correct execution is specified using local synchronization constraints. Synchronization constraints are a language construct to specify a subset of an actor's states under which the specified method of the actor may be invoked <ref> [127, 70, 40] </ref>. Unlike input guards in conventional process oriented languages [58], they do not cause a sender to wait until such time when the recipient is in a state in which it can process the message. Thus, synchronization constraints ensure maximal overlap of computation and communication. <p> Processing a message which matches msg-expr is delayed if bool-expr evaluates to true. Such synchronization constraints are called disabling constraints. These constraints may be specified separated from their corresponding method definition [91]. Such separation facilitates code reuse <ref> [40] </ref>. Making synchronization constraints a disable condition and having them separated from corresponding method definitions are to avoid interference with inheritance [40] and a legacy from HAL. algorithm [82]. Systolic algorithms employ synchronized data movement in lock step. <p> Such synchronization constraints are called disabling constraints. These constraints may be specified separated from their corresponding method definition [91]. Such separation facilitates code reuse <ref> [40] </ref>. Making synchronization constraints a disable condition and having them separated from corresponding method definitions are to avoid interference with inheritance [40] and a legacy from HAL. algorithm [82]. Systolic algorithms employ synchronized data movement in lock step. <p> Synchronization constraints in THAL is also unique in that they are expressed as a disabling condition. Synchronization constraints in THAL are modeled after the work in <ref> [40] </ref>. Synchronization constraints in Rosette [127] are specified by using enabled sets. The ABCL family also has some provision for specifying synchronization constraints [90]. THAL is one of a few languages which make object locality visible to programmers.
Reference: [41] <author> Svend Frtlund. </author> <title> Coordinating Distributed Objects: An Actor-Based Approach to Synchronization. </title> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: The implementation techniques of the runtime system and the compile-time analyses developed in the thesis may serve as a basis on which to implement high-level actor-based systems efficiently. Such systems include: multi-object synchronization and coordination in distributed environment <ref> [41] </ref>, meta-level specification of interaction policies between distributed components [114], synchronization between distributed objects with real-time constraints [105], visualization of coordination patterns in concurrent algorithms [10]. All of these systems are based on asynchronous objects and thus are modeled with actors.
Reference: [42] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM: Parallel Virtual Machine. A Users' Guide and Tutorial for Networked Parallel Computing. </title> <publisher> The MIT Press, </publisher> <year> 1994. </year>
Reference: [43] <author> A. Goldberg and D. Robson. </author> <title> Smalltalk-80: The Language and its Implementation. </title> <publisher> Addison Wesley, </publisher> <year> 1983. </year>
Reference-contexts: They differ in how to initiate data parallel execution. CST [61, 38] and DistributedConcurrentSmalltalk (DCS) [96] are two of many COOP languages which extended Smalltalk-80 <ref> [43] </ref>. CST supports concurrency using locks, asynchronous message passing, and distributed objects. Distributed objects are similar to aggregates in CA and are equipped with similar communication mechanisms. DCS is an extension of ConcurrentSmalltalk [96] to a distributed interpersonal environment.
Reference: [44] <author> G. Golub and C. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <year> 1983. </year>
Reference-contexts: Consider an actor implementation of the Cholesky Decomposition algorithm for dense matrices. For a given symmetric positive definite matrix A of size n fi n the algorithm computes a lower triangular matrix L, of size n fi n such that A = LL T <ref> [44] </ref>. In the implementation, each row of a matrix is abstracted as an actor and the matrix itself is represented as a group of actors. Factorization proceeds as row actors send messages to actors representing lower rows.
Reference: [45] <author> J. Gosling and H. McGilton. </author> <title> The Java Language Environment: A White Paper. </title> <type> Technical report, </type> <institution> Sun Microsystems Comptuer Company, </institution> <year> 1995. </year>
Reference-contexts: SOS supports a notion of groups called Fragmented Objects (FO) and object migration which involves both data and code migration. SOS objects communication with one another using synchronous, asynchronous, or multicast communication. Another language that supports code migration is Java <ref> [45] </ref> which promotes architectural neutrality, the property of "write-once, run-anywhere." Java is designed as a simplified derivative of C++ and supports a limited form of concurrency through lightweight threads and remote method invocation.
Reference: [46] <author> Justin O. Graver and Ralph E. Johnson. </author> <title> A Type System for Smalltalk. </title> <booktitle> In Seventh Symposium on Principles of Programming Languages, </booktitle> <pages> pages 136-150. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1990. </year>
Reference-contexts: If the compiler ascertains that the conditions will hold during the execution, it generates the codes that exploit the information. 5.5 Related Work A number of type inference mechanisms for object-oriented programming languages have been proposed <ref> [115, 46, 100, 22] </ref>. In particular, the type inference in the THAL compiler is implemented using a constraint-based type inference algorithm [100]. The implementation is similar to that of [99] but is extended to infer types for groups and member actors.
Reference: [47] <author> A. Grimshaw, W. T. Strayer, and P. Narayan. </author> <title> Dynamic Object-Oriented Parallel Processing. </title> <journal> IEEE Parallel and Distributed Technology: Systems and Applications, </journal> <volume> 1(2) </volume> <pages> 33-47, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. <p> Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. Invocation of a parallel function creates a thread which executes asynchronously. Threads communicate through shared data and synchronize using monitors and condition variables. Mentat <ref> [47] </ref> and Charm++ [73] are similar in that both distinguish parallel objects from sequential ones; programmers are required to specify what classes are to be executed in parallel. Mentat objects map one-to-one onto processes in a virtual machine.
Reference: [48] <author> L. Gwennap. </author> <title> 620 Fills Out PowerPC Product Line. </title> <type> Microprocessor Report, 8(14), </type> <month> October </month> <year> 1994. </year>
Reference: [49] <author> L. Gwennap. </author> <title> UltraSparc Unleashes SPARC Performance. </title> <type> Microprocessor Report, 8(13), </type> <month> October </month> <year> 1994. </year>
Reference: [50] <author> L. Gwennap. P6 Underscores Intel's Lead. </author> <type> Microprocessor Report, 9(2), </type> <month> February </month> <year> 1995. </year>
Reference: [51] <author> L. Gwennap. </author> <title> Pentium Is First CPU to Reach 0.35 Micron. </title> <type> Microprocessor Report, 9(4), </type> <month> March </month> <year> 1995. </year>
Reference: [52] <author> L. Gwennap. </author> <title> Digital's 21164 Reaches 500 MHz. </title> <type> Microprocessor Report, 10(9), </type> <month> July </month> <year> 1996. </year>
Reference: [53] <author> C. Hewitt. </author> <title> Viewing Control Structures as Patterns of Passing Messages. </title> <journal> Journal of Artificial Intelligence, </journal> <volume> 8(3) </volume> <pages> 323-364, </pages> <year> 1977. </year>
Reference-contexts: distinction between active and passive objects is removed in actor languages because actors are active by definition. 7 Every actor is associated with a thread; however, the thread makes its presence manifest only when a message is scheduled. 2.3 Actor-Based Languages The Actor model was first introduced by Carl Hewitt <ref> [53] </ref>, refined by many others [55, 54, 30, 56] and defined in its current standard form by Agha [1]. Particularly, since its introduction many actor-based languages [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] have been proposed for programming concurrent computation.
Reference: [54] <author> C. Hewitt and R. Atkinson. </author> <title> Specification and Proof Techniques for Serializers. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 5(1), </volume> <month> January </month> <year> 1979. </year>
Reference-contexts: objects is removed in actor languages because actors are active by definition. 7 Every actor is associated with a thread; however, the thread makes its presence manifest only when a message is scheduled. 2.3 Actor-Based Languages The Actor model was first introduced by Carl Hewitt [53], refined by many others <ref> [55, 54, 30, 56] </ref> and defined in its current standard form by Agha [1]. Particularly, since its introduction many actor-based languages [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp.
Reference: [55] <author> C. Hewitt and H. Baker. </author> <title> Laws for Communicating Parallel Processes. </title> <booktitle> In IFIP Conference Proceedings, </booktitle> <year> 1977. </year>
Reference-contexts: objects is removed in actor languages because actors are active by definition. 7 Every actor is associated with a thread; however, the thread makes its presence manifest only when a message is scheduled. 2.3 Actor-Based Languages The Actor model was first introduced by Carl Hewitt [53], refined by many others <ref> [55, 54, 30, 56] </ref> and defined in its current standard form by Agha [1]. Particularly, since its introduction many actor-based languages [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp.
Reference: [56] <author> C. Hewitt and P. de Jong. </author> <title> Analyzing the Roles of Descriptions and Actions in Open Systems. </title> <booktitle> In Proceedings of the national Conference on Artificial Intelligence. AAAI, </booktitle> <month> August </month> <year> 1983. </year>
Reference-contexts: objects is removed in actor languages because actors are active by definition. 7 Every actor is associated with a thread; however, the thread makes its presence manifest only when a message is scheduled. 2.3 Actor-Based Languages The Actor model was first introduced by Carl Hewitt [53], refined by many others <ref> [55, 54, 30, 56] </ref> and defined in its current standard form by Agha [1]. Particularly, since its introduction many actor-based languages [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp.
Reference: [57] <author> M. G. Hinchey and S. A. Jarvis. </author> <title> Concurrent Systems: Formal Development in CSP. </title> <booktitle> International Series on Software Engineering. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1995. </year>
Reference-contexts: Thus, the sender may not know if the recipient will be in a consistent state in which it can logically respond to an incoming message. This problem is addressed in some process-oriented languages with input guards on synchronous communication <ref> [24, 92, 136, 57] </ref>: the recipient refuses to accept a message from a given sender (or a specific channel) until it is in a state in which it can process that message. Thus, the sender must busy-wait until the recipient is ready to accept the message.
Reference: [58] <author> C. A. R. Hoare. </author> <title> Communicating Sequential Processes. </title> <journal> Communications of the ACM, </journal> <volume> 21(8) </volume> <pages> 666-677, </pages> <month> August </month> <year> 1978. </year>
Reference-contexts: In THAL, synchronization necessary for correct execution is specified using local synchronization constraints. Synchronization constraints are a language construct to specify a subset of an actor's states under which the specified method of the actor may be invoked [127, 70, 40]. Unlike input guards in conventional process oriented languages <ref> [58] </ref>, they do not cause a sender to wait until such time when the recipient is in a state in which it can process the message. Thus, synchronization constraints ensure maximal overlap of computation and communication. Synchronization constraints are local if they are specified on a per actor basis.
Reference: [59] <author> J. G. Holm, A. Lain, and P. Banerjee. </author> <title> Compilation of Scientific Programs into Multithreaded and Message Driven Computation. </title> <booktitle> In Proceedings of the 1994 Scalable High Performance Computing Conference, </booktitle> <pages> pages 518-525, </pages> <address> Knoxville, TN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The discussion of join continuation in the context of the Actor model appears in [1]. Extracting join continuation through a source-to-source transformation was attempted in other actor-based languages as well [89, 62]. Also, a similar transformation technique for explicitly message-passing programs was presented in <ref> [59] </ref>.
Reference: [60] <author> M. Homewood and M. McLaren. </author> <title> Meiko CS-2 Interconnect Elan-Elite Design. </title> <booktitle> In Proceedings of Hot Interconnects, </booktitle> <month> August </month> <year> 1993. </year> <month> 83 </month>
Reference: [61] <author> W. Horwat. </author> <title> Concurrent Smalltalk on the Message Driven Processor. </title> <type> Master's thesis, </type> <institution> MIT, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: By contrast, Charm++ requires programmers take the responsibility of mapping of objects onto processing nodes. pC++ [87], C flfl [86], and pSather [95] are all C++-based COOP languages which are designed to support data parallelism. They differ in how to initiate data parallel execution. CST <ref> [61, 38] </ref> and DistributedConcurrentSmalltalk (DCS) [96] are two of many COOP languages which extended Smalltalk-80 [43]. CST supports concurrency using locks, asynchronous message passing, and distributed objects. Distributed objects are similar to aggregates in CA and are equipped with similar communication mechanisms.
Reference: [62] <author> C. Houck. </author> <title> Run-Time System Support for Distributed Actor Programs. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: The implementation iteratively traverses a global flow graph of a program to refine type information it gathers. The discussion of join continuation in the context of the Actor model appears in [1]. Extracting join continuation through a source-to-source transformation was attempted in other actor-based languages as well <ref> [89, 62] </ref>. Also, a similar transformation technique for explicitly message-passing programs was presented in [59].
Reference: [63] <author> C. Houck and G. Agha. HAL: </author> <title> A High-level Actor Language and Its Distributed Implementation. </title> <booktitle> In Proceedings of th 21st International Conference on Parallel Processing (ICPP '92), </booktitle> <volume> volume II, </volume> <pages> pages 158-165, </pages> <address> St. Charles, IL, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Although object migration is yet to be supported, a programmer may mimic it by remotely creating an object and explicitly forwarding its associated code. 10 Chapter 3 THAL: A Tailored High-level Actor Language THAL is a high-level language based on actors; it is a descendant of HAL <ref> [63, 5] </ref>. THAL allows a programmer to create actors, initialize their behaviors, and send them messages. As the computation unfolds, new messages are generated, new actors are created, and existing actors undergo state change.
Reference: [64] <author> N. Hutchinson, R. Raj, A. Black, H. Levy, and E. </author> <month> Jul. </month> <title> The Emerald Programming Language REPORT. </title> <type> Technical Report 87-10-07, </type> <institution> University of Washington, </institution> <month> October </month> <year> 1987. </year>
Reference-contexts: DCST allows multiple processes in a single object. Synchronization of the processes may be may be specified by a method relation which defines an exclusive relation between two methods or by a guard expression which defines when a method is enabled. Both Emerald <ref> [64] </ref> and Orca [116] support encapsulated abstract data types but without inheritance. Furthermore, they have clear distinction of a process and an object. For example, in Emerald, multiple threads of control may be active concurrently within a single object. Synchronization is provided by monitors. <p> CA also supports user-specified object placement to some extent but the runtime system largely takes responsibility to control over object placement. Charm++ [73] provides programmers with only partial control over object placement. For example, migration of parallel objects is not allowed. Emerald <ref> [64] </ref> allows object migration as well as code migration. In particular, Emerald objects have fine-grained mobility. Programmers may use a range of primitives to to control object mobility, such as object location, object movement, and object fix/unfix.
Reference: [65] <author> Intel Corporation. </author> <title> Paragon User's Guide, </title> <year> 1993. </year>
Reference: [66] <author> H. Ishihata, T. Horie, S. Inano, T. Shimizu, and S. Kato. </author> <title> An Architecture of Highly Parallel Computer AP1000. </title> <booktitle> In Proceedings of IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, </booktitle> <pages> pages 13-16, </pages> <month> May </month> <year> 1991. </year>
Reference: [67] <editor> J. Rees et. al. </editor> <title> The T Manual. </title> <type> Technical report, </type> <institution> Yale University, </institution> <year> 1985. </year>
Reference-contexts: If it fails, it climbs up the inheritance tree to respond to the message. Delegation implements the prototype approach to sharing knowledge in object oriented systems. It appears in actor languages [88, 135, 29] and several Lisp-based object oriented systems such as Director [72], T <ref> [67] </ref>, Orbit [113], and others. An object shares knowledge with a prototype by simply having the prototype as its acquaintance; the object may also keep its personal behavior idiosyncratic to itself.
Reference: [68] <author> R. H. Halstead Jr. </author> <title> Multilisp: A Language for Concurrent Symbolic Computation. </title> <journal> ACM TOPLAS, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <year> 1985. </year>
Reference-contexts: A technique used in a number of systems [117, 75] to implement CCRC-like abstractions is one using futures <ref> [68] </ref>. Futures are a promise for a value; they are a place holder for a value which is yet to be defined. In the future-based implementations, sending a request message creates a future which is immediately returned as the result of the request.
Reference: [69] <author> K. Mani Chandy and Carl Kesselman. </author> <title> CC++: A Declarative Concurrent Object-Oriented Programming Notation. </title> <editor> In G. Agha and P. Wegner and A. Yonezawa, editor, </editor> <booktitle> Research Direction in Concurrent Object-Oriented Programming, chapter 11, </booktitle> <pages> pages 281-313. </pages> <publisher> The MIT press, </publisher> <year> 1993. </year>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. <p> In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated [23, 69, 47, 73, 27, 87, 86, 95]. We describe a few examples below. Compositional C++ (CC++) <ref> [69] </ref> extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. Invocation of a parallel function creates a thread which executes asynchronously. Threads communicate through shared data and synchronize using monitors and condition variables.
Reference: [70] <author> D. Kafura, M. Mukherji, and G. Lavender. </author> <title> ACT++: A Class Library for Concurrent Programming in C++ Using Actors. </title> <journal> Journal of Object-Oriented Programming, </journal> <volume> 0(0) </volume> <pages> 47-62, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages. <p> Actalk implemented actors by augmenting ordinary Smalltalk objects with asynchronous message passing and message buffering. Actra was implemented by modifying the Smalltalk virtual machine. In contrast to the basic Actor model, communication between actors in Actra was synchronous. Another language following the extension approach is ACT++ <ref> [70] </ref>; it extended C++ with a class hierarchy which provides the concurrency abstraction of the Actor model. 2.4 Other COOP Languages The desire to leverage the existing compiler technology motivates implementing a COOP language by extending an existing sequential object-oriented language, such as C++ or Smalltalk, with a notion of process <p> In THAL, synchronization necessary for correct execution is specified using local synchronization constraints. Synchronization constraints are a language construct to specify a subset of an actor's states under which the specified method of the actor may be invoked <ref> [127, 70, 40] </ref>. Unlike input guards in conventional process oriented languages [58], they do not cause a sender to wait until such time when the recipient is in a state in which it can process the message. Thus, synchronization constraints ensure maximal overlap of computation and communication.
Reference: [71] <author> D. Kahaner, C. Moler, and S. Nash. </author> <title> Numerical Methods and Software. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: An automatic quadrature algorithm takes as inputs a function f , an interval [a; b], and an accuracy request * and produces a result Q and an error estimate E. The algorithm recursively divides all subintervals until it meets the accuracy request *. A sequential, globally adaptive quadrature technique <ref> [71] </ref> saves computation time by starting integral evaluation from coarser subintervals and repeatedly dividing the subinterval with the largest local error estimate until the accuracy request is met. 76 PEs Random D = 7 D = 6 D = 5 1 105.4 91.23 90.70 90.35 4 118.2 33.09 27.91 27.07 16
Reference: [72] <author> K. Kahn. </author> <title> Creation of Computer Animation from Story Descriptions. </title> <type> PhD thesis, </type> <institution> Massachusetts institute of Technology, </institution> <year> 1979. </year>
Reference-contexts: If it fails, it climbs up the inheritance tree to respond to the message. Delegation implements the prototype approach to sharing knowledge in object oriented systems. It appears in actor languages [88, 135, 29] and several Lisp-based object oriented systems such as Director <ref> [72] </ref>, T [67], Orbit [113], and others. An object shares knowledge with a prototype by simply having the prototype as its acquaintance; the object may also keep its personal behavior idiosyncratic to itself.
Reference: [73] <author> L. V. Kale and S. Krishnan. CHARM++: </author> <title> A Portable Concurrent Object Oriented System Based On C++. </title> <editor> In Andreas Paepcke, editor, </editor> <booktitle> Proceedings of OOPSLA 93'. </booktitle> <publisher> ACM Press, </publisher> <month> October </month> <year> 1993. </year> <journal> ACM SIGPLAN Notices 28(10). </journal>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. <p> Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. Invocation of a parallel function creates a thread which executes asynchronously. Threads communicate through shared data and synchronize using monitors and condition variables. Mentat [47] and Charm++ <ref> [73] </ref> are similar in that both distinguish parallel objects from sequential ones; programmers are required to specify what classes are to be executed in parallel. Mentat objects map one-to-one onto processes in a virtual machine. <p> The ABCL family provides a way to specify actor placement similar to ours, but does not support object migration. CA also supports user-specified object placement to some extent but the runtime system largely takes responsibility to control over object placement. Charm++ <ref> [73] </ref> provides programmers with only partial control over object placement. For example, migration of parallel objects is not allowed. Emerald [64] allows object migration as well as code migration. In particular, Emerald objects have fine-grained mobility. <p> However, THAL allows arrays to be part of an actor's state, hence migratable. It even allows sending arrays 47 in a message. A naive solution would be to make programmers supply a marshaling function for each actor and message <ref> [73] </ref>. Unfortunately, the solution may fail to work with dynamic load balancing that programmers are not aware of. Our solution is to let the compiler keep sufficient information available to the runtime system so that it can easily deduce relevant information for state and message packing.
Reference: [74] <author> V. </author> <title> Karamcheti. </title> <type> Private Communication, </type> <year> 1994. </year>
Reference-contexts: Both systems make cost of runtime operations explicit to a compiler, thereby enabling the compiler to perform a range of optimizations. The main difference is in the extent of location transparency they support. Aggregates in the Concert system are located at the same memory address on each node <ref> [74] </ref>. This location dependence limits aggregates' mobility, making it difficult to load-balance in dynamic, irregular computation. Concert objects other than aggregates are allocated in a global space and subject to global name translation.
Reference: [75] <author> V. Karamcheti and A. A. Chien. </author> <title> Concert Efficient Runtime Support for Concurrent Object-Oriented Programming Languages on Stock Hardware. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: A message sent to the aggregates is processed by one and only one constituent but which constituent receives the message is left unspecified (i.e., one-to-one-of-many type of communication). Unlike the Actor model, every message send in CA expects a reply by default <ref> [28, 75] </ref>. All of the above-mentioned actor languages have been designed and implemented from scratch. A different approach involves extending an existing sequential object-oriented language with the concurrency semantics of actors. In this approach, actors inherit their actions from a single Actor class which wraps sequential objects with actor semantics. <p> The compiler rearranges message arguments, puts array arguments after all simple ones, and store encoded packing information in packer (Section 4.7)/ 4.3.1 Scheduling with Deferred Message Stack Recognizing cost difference between remote and local message sending offers a substantial amount of performance gain, especially in fine-grained COOP languages <ref> [119, 75] </ref>. To exploit the cost difference in local message scheduling, the runtime system divides the message queue in a node into two sub-queues, local and remote, and distinguishes scheduling local messages from scheduling 33 remote messages. <p> Furthermore, both message frame allocation and argument marshaling are done in user code to eliminate redundant memory copy of message arguments from user space to kernel space. Methods execute to completion without blocking. Non-blocking execution precludes the use of immediate dispatch of a local message with function invocation <ref> [119, 75] </ref> because function invocation implicitly blocks the sender of the message. <p> The atomic method execution semantics, which allows no more than one active thread on an actor, interferes with the SFI and may cause a deadlock when two actors send messages in a mutually recursive manner. Other systems <ref> [119, 75] </ref> which employ the SFI avoid deadlock by providing a stack unwinding mechanism along with futures. schedule local messages. Suppose actors S 1 , R, and S 2 are on the same node. <p> When the message must be forwarded, the runtime system sees the packing information in packer and packs the message accordingly. Note that strings are treated as one-dimensional arrays of characters. 4.8 Related Work Among other systems the implementations of ABCL/onAP1000 [119, 120] and the Concert system <ref> [28, 75] </ref> have influenced the design of THAL most. ABCL/onAP1000 adopted an encapsulation approach to implement its runtime system. For example, the runtime system determines whether to use the stack-based or the queue-based scheduling mechanism for local messages. <p> However, a naive implementation of CCRC which context-switches a sender whenever it sends a request would make it less attractive on stock-hardware multicomputers because their context switch costs are high (e.g., 52 sec on CM-5). A technique used in a number of systems <ref> [117, 75] </ref> to implement CCRC-like abstractions is one using futures [68]. Futures are a promise for a value; they are a place holder for a value which is yet to be defined. <p> The shaded actor is blocked after sending its very first message to self and unable to progress because it cannot process the message. A future-based implementation is no better than the naive implementation [118]. Some systems replace a message send to self with a function call <ref> [28, 75] </ref>. It may be successful in avoiding deadlock but may not be used with the atomic method execution because the replacement may alter the meaning of the program incorrectly, as shown in Figure 5.10. Further, it it serializes the sender's computation eliminating the possibility of dynamic load balancing. <p> The implementation is similar to that of [99] but is extended to infer types for groups and member actors. A more detailed discussion on constraint-based type inference for object-oriented programming languages may be found in [101]. A 68 similar constraint-based type inference mechanism was implemented on the Concert system <ref> [28, 75] </ref> and is presented in [104]. The implementation iteratively traverses a global flow graph of a program to refine type information it gathers. The discussion of join continuation in the context of the Actor model appears in [1]. <p> A locality check is done using only locally available information and completes within 1 sec for locally created actors. The performance of the runtime primitives is comparable to that of other systems <ref> [119, 75] </ref>. The runtime system also supports two primitives to implement the call/return communication abstraction: continuation creation and reply. Continuation creation with two slots, one empty and one filled, takes 2.27 sec and deallocation takes 0.75 sec.
Reference: [76] <author> V. Karamcheti and A.A. Chien. </author> <title> A Comparison of Architectural Support for Messaging on the TMC CM-5 and the Cray T3D. </title> <booktitle> In Proceedings of International Symposium of Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: the dispatcher and the name server. 1 To our best knowledge, no current-generation implementation supports a full 64-bit address space. 31 The communication module and the program load module may be built on top of any well-defined low-level messaging layer, such as TCP/IP, Active Messages [130, 106], and Fast Messages <ref> [76] </ref>. They make actors an illusion of the completely connected network. Moreover, the hierarchical organization offers the runtime system some degree of network independence, and thus, portability.
Reference: [77] <author> R. Kessler and J. Schwarzmeier. </author> <title> CRAY T3D: A New Dimension for Cray Research. </title> <booktitle> In Proceedings of COMPCON, </booktitle> <pages> pages 176-182, </pages> <year> 1993. </year>
Reference: [78] <author> W. Kim and G. Agha. </author> <title> Compilation of a Highly Parallel Actor-Based Language. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Proceedings of the Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 1-15. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <note> LNCS 757. </note>
Reference-contexts: Out-of-order arrival of replies does not help because futures are touched sequentially conforming to the order of appearance of the requests in a method. In contrast to the future-based implementations, we employ a compiler-oriented approach <ref> [78, 5] </ref>. The compiler transforms a method containing CCRCs in such a way that a programmer would write a method with the same semantics if CCRC is not available. The compiler analyzes data dependence among requests in a method to identify those that may be executed concurrently.
Reference: [79] <author> W. Kim and G. Agha. </author> <title> Efficient Support of Location Transparency in Concurrent Object-Oriented Programming Languages. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <year> 1995. </year>
Reference-contexts: When a message is dequeued for processing, the synchronization constraints of the specified method are evaluated. A positive evaluation result means the method is disabled under the actor's current state and the message is put into the actor's pending queue <ref> [79] </ref>. Recall that synchronization constraints are a function of actor state and message arguments. When an actor changes its state, some messages in its pending queue may become enabled for processing.
Reference: [80] <author> W. Kim, R. Panwar, and G. Agha. </author> <title> Efficient Compilation of Call/Return Communication for Actor-Based Programming Languages. </title> <booktitle> In Proceedings of HiPC '96, </booktitle> <pages> pages 62-67, </pages> <year> 1996. </year>
Reference: [81] <author> E. J. Koldinger, J. S. Chase, and S. J. Eggers. </author> <title> Architectural Support for Single Address Space Operating Systems. </title> <booktitle> In Proceedings of ASPLOS V '92, </booktitle> <pages> pages 175-186, </pages> <year> 1992. </year>
Reference-contexts: It also simplifies placement specification of actors. Single Address Space Design The runtime support has been designed to concurrently execute multiple programs from different users. What makes it unique, however, is it makes them share the same address space <ref> [81] </ref>. Supporting a multi-user environment with a single instance of a runtime support precludes the library approach, where a compiled code is linked to a runtime library before execution. In the library approach, an executable is self-contained and does not share any address space with others.
Reference: [82] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <publisher> Benjamin/Cummings Publishing Company, Inc., </publisher> <year> 1994. </year> <month> 84 </month>
Reference-contexts: These constraints may be specified separated from their corresponding method definition [91]. Such separation facilitates code reuse [40]. Making synchronization constraints a disable condition and having them separated from corresponding method definitions are to avoid interference with inheritance [40] and a legacy from HAL. algorithm <ref> [82] </ref>. Systolic algorithms employ synchronized data movement in lock step. <p> As Figure 6.3 shows, the version with DLB performs worse on partitions of a small size due to the overhead for extra book-keeping. However, it eventually outperforms the version without DLB as the size increases. 6.4 Systolic Matrix Multiplication The systolic matrix multiplication algorithm, also known as Cannon's algorithm <ref> [82] </ref>, uses N 2 processors where N is a natural number. To compute C = A fi B, each matrix is divided into N 2 square blocks and matrix A is row-skewed and matrix B is column-skewed.
Reference: [83] <author> V. Kumar, A. Y. Grama, and V. N. Rao. </author> <title> Scalable Load Balancing Techniques for Parallel Com--puters. </title> <type> Technical Report 91-55, </type> <institution> CS Dept., University of Minnesota, </institution> <year> 1991. </year> <note> available via ftp ftp.cs.umn.edu:/users/kumar/lb_MIMD.ps.Z. </note>
Reference-contexts: However, the THAL compiler optimizes away actor creations since Fibonacci actors are purely functional. The computation tree of the Fibonacci program has a great deal of load imbalance. Table 6.2 and Figure 6.3 compare two execution results with and without dynamic load balancing (DLB). A receiver-initiated random polling scheme <ref> [83] </ref> is used for dynamic load balancing. As Figure 6.3 shows, the version with DLB performs worse on partitions of a small size due to the overhead for extra book-keeping.
Reference: [84] <author> T. T. Kwan, B. K. Totty, and D. A. Reed. </author> <title> Communication and Computation Performance of the CM-5. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 192-201, </pages> <year> 1993. </year>
Reference-contexts: Moreover, simulating 70 broadcast on the data network was more efficient when sending bulk data because the bandwidth of the data network is much higher than that of the control network <ref> [84] </ref>. Since Active Messages are not buffered [131], sending bulk data from one node to another requires a three-phase protocol. The source sends size information and the destination acknowledges with a buffer address. Then the source sends data without any concern about overflow.
Reference: [85] <author> G. Lapalme and P. Salle. Plasm-II: </author> <title> an Actor Approach to Concurrent Programming. </title> <editor> In G. Agha, P. Wegner, and A. Yonezawa, editors, </editor> <booktitle> The ACM SIGPLAN Workshop on Object-Based Concurrent Programming, </booktitle> <pages> pages 81-83, </pages> <address> San Diego, USA, </address> <month> September </month> <year> 1988. </year> <booktitle> The ACM SIGPLAN, </booktitle> <publisher> ACM Press. </publisher>
Reference-contexts: Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages. <p> It originally employed dynamic typing which was subsequently replaced with strong typing through the use of type declaration. Cantor version 2.2 also added vectors along with internal iteration. Another actor language targeted for parallel execution is Plasma-II <ref> [85] </ref>, a parallel extension of Plasma which was the first actor language defined by Carl Hewitt. Plasma-II was designed to be executed on a set of virtual machines distributed on heterogeneous platforms.
Reference: [86] <author> J. Larus. </author> <title> C**: A Large-Grain, Object-Oriented, Data Parallel Programming Language. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Proceedings of the Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 326-340. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <note> LNCS 757. </note>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. <p> Mentat objects map one-to-one onto processes in a virtual machine. By contrast, Charm++ requires programmers take the responsibility of mapping of objects onto processing nodes. pC++ [87], C flfl <ref> [86] </ref>, and pSather [95] are all C++-based COOP languages which are designed to support data parallelism. They differ in how to initiate data parallel execution. CST [61, 38] and DistributedConcurrentSmalltalk (DCS) [96] are two of many COOP languages which extended Smalltalk-80 [43].
Reference: [87] <author> J. K. Lee and D. Gannon. </author> <title> Object-Oriented Parallel Programming Experiments and Results. </title> <booktitle> In Proceedings Supercomputing 91, </booktitle> <pages> pages 273-282, </pages> <year> 1991. </year>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. <p> Mentat objects map one-to-one onto processes in a virtual machine. By contrast, Charm++ requires programmers take the responsibility of mapping of objects onto processing nodes. pC++ <ref> [87] </ref>, C flfl [86], and pSather [95] are all C++-based COOP languages which are designed to support data parallelism. They differ in how to initiate data parallel execution. CST [61, 38] and DistributedConcurrentSmalltalk (DCS) [96] are two of many COOP languages which extended Smalltalk-80 [43]. <p> Concurrent Aggregates (CA) [29] also supports a notion of groups but with a one-to-one-out-of-many type of communication where a message sent to a group (i.e., an aggregate) is processed by a unspecified member. pC++ <ref> [87, 20] </ref> has a notion of groups similar to that of CA but its use is limited to data parallel computation. The communication abstractions supported in THAL are found in other actor languages with different names.
Reference: [88] <author> H. Lieberman. </author> <title> Concurrent Object-Oriented Programming in ACT 1. </title> <editor> In A. Yonezawa and M. Tokoro, editors, </editor> <booktitle> Object-Oriented Concurrent Programming, chapter 16, </booktitle> <pages> pages 9-36. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: If it fails, it climbs up the inheritance tree to respond to the message. Delegation implements the prototype approach to sharing knowledge in object oriented systems. It appears in actor languages <ref> [88, 135, 29] </ref> and several Lisp-based object oriented systems such as Director [72], T [67], Orbit [113], and others. An object shares knowledge with a prototype by simply having the prototype as its acquaintance; the object may also keep its personal behavior idiosyncratic to itself. <p> Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages. <p> Particularly, since its introduction many actor-based languages [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] have been proposed for programming concurrent computation. Act1 <ref> [88] </ref> was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages. For example, it used continuations to support bidirectional control structure of sending a request and receiving a reply.
Reference: [89] <author> C. Manning. ACORE: </author> <title> The Design of a Core Actor Language and its Compiler. </title> <type> Master's thesis, </type> <institution> MIT, Artificial Intelligence Laboratory, </institution> <month> August </month> <year> 1987. </year>
Reference-contexts: Particularly, since its introduction many actor-based languages <ref> [121, 13, 88, 16, 11, 85, 135, 89, 70, 29] </ref> have been proposed for programming concurrent computation. Act1 [88] was an early actor language which was implemented in Lisp. It supported a number of abstractions which are still found in other contemporary actor-based languages. <p> Delegation was used to share knowledge among actors and implement error handling. The language also used futures for parallel computation and serializers for synchronization. Another actor language with Lisp-based implementation is Acore <ref> [89] </ref> which even borrowed the syntax of Lisp. Acore was the first language based on the Actor model defined in [1] so that a mutable actor implicitly serializes messages it receives and the expressions in a message handler may be evaluated concurrently. <p> We call this call/return communication. In the Actor model, call/return communication requires explicit manipulation of continuation actors and synchronization because communication in actors is point-to-point and non-blocking. Both of these characteristics provide an efficient execution model but are insufficient as programming abstractions. Like many earlier actor languages <ref> [89, 135] </ref>, THAL provides an abstract way of specifying call/return communication without requiring the programmer to necessarily manipulate continuations Call/return communication may be best expressed in the actor paradigm using the concurrent call/return communication (CCRC) abstraction; CCRC directly models the call/return communication by having continuation and synchronization implicit in its semantics. <p> Examples of the concurrent call/return communication abstraction are ask <ref> [89] </ref>, now [135], blocking send [29], and request [5]. THAL supports CCRC using two constructs, request and reply. They are represented with "." and reply, respectively. Execution of a request blocks the sender until a reply is sent back. <p> Such a modular specification methodology for actor placement has been developed in [102] on top of the THAL placement constructs. 3.6 Related work THAL owes much of its linguistic features to HAL which was, in turn, influenced by other actor languages, such as Acore <ref> [89] </ref>, ABCL/1 [135], and Rosette [126]. The language featured inheritance, limited forms of reflection, and synchronization constraints; the first two features are not supported in THAL for the sake of performance. HAL had been used as a test-bed for experimenting with new language constructs and dependability methods. <p> The implementation iteratively traverses a global flow graph of a program to refine type information it gathers. The discussion of join continuation in the context of the Actor model appears in [1]. Extracting join continuation through a source-to-source transformation was attempted in other actor-based languages as well <ref> [89, 62] </ref>. Also, a similar transformation technique for explicitly message-passing programs was presented in [59].
Reference: [90] <author> S. Matsuoka, K. Taura, and A. Yonezawa. </author> <title> Highly Efficiency and Encapsulated Re-ruse of Synchronization Code in Concurrent Object-Oriented Languages. </title> <booktitle> In ACM OOPSLA '93, </booktitle> <year> 1993. </year>
Reference-contexts: Synchronization constraints in THAL is also unique in that they are expressed as a disabling condition. Synchronization constraints in THAL are modeled after the work in [40]. Synchronization constraints in Rosette [127] are specified by using enabled sets. The ABCL family also has some provision for specifying synchronization constraints <ref> [90] </ref>. THAL is one of a few languages which make object locality visible to programmers. The placement primitives have been used as a basis for modular specification of partitioning and distribution strategy in [102].
Reference: [91] <author> S. Matsuoka and A. Yonezawa. </author> <title> Analysis of Inheritance Anomaly in Object-Oriented Concurrent Programming Languages. </title> <editor> In G. Agha, P. Wegner, and A. Yonezawa, editors, </editor> <booktitle> Research Directions in Object-Oriented Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Processing a message which matches msg-expr is delayed if bool-expr evaluates to true. Such synchronization constraints are called disabling constraints. These constraints may be specified separated from their corresponding method definition <ref> [91] </ref>. Such separation facilitates code reuse [40]. Making synchronization constraints a disable condition and having them separated from corresponding method definitions are to avoid interference with inheritance [40] and a legacy from HAL. algorithm [82]. Systolic algorithms employ synchronized data movement in lock step.
Reference: [92] <author> D. May, R. Shepherd, and C. Keane. </author> <title> Communicating Process Architecture: Transputer and Occam. </title> <editor> In P. Treleaven and M. Vanneschi, editors, </editor> <booktitle> Future Parallel Architecture, </booktitle> <pages> pages 35-81. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year> <note> LNCS 272. </note>
Reference-contexts: Thus, the sender may not know if the recipient will be in a consistent state in which it can logically respond to an incoming message. This problem is addressed in some process-oriented languages with input guards on synchronous communication <ref> [24, 92, 136, 57] </ref>: the recipient refuses to accept a message from a given sender (or a specific channel) until it is in a state in which it can process that message. Thus, the sender must busy-wait until the recipient is ready to accept the message.
Reference: [93] <author> R. Milner, M. Tofte, and R. Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Type inference is a compile-time analysis which provides untyped languages with the advantages of static typing. By having the THAL compiler infer types for expressions and verify their consistency, programmers may enjoy untyped languages' programmability and typed languages' reliability and efficiency at the same time <ref> [93, 109, 100] </ref>. The THAL compiler uses an extension of the constraint-based type inference developed by Palsberg and Schwartzbach [100]. In the algorithm, types are defined as a set of classes.
Reference: [94] <institution> MIPS Technologies, Inc. Product Overview: R10000 Microprocessor, </institution> <month> October </month> <year> 1994. </year>
Reference: [95] <author> S. Murer, J.A. Feldman, C.-C. Lim, and M.-M. Seidel. pSather: </author> <title> Layered Extensions to an Object-Oriented Language for Efficient parallel Computation. </title> <type> Technical Report TR-93-028, </type> <institution> ISCI, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: In particular, given the popularity and portability of C++,a number of COOP languages based on C++ have proliferated <ref> [23, 69, 47, 73, 27, 87, 86, 95] </ref>. We describe a few examples below. Compositional C++ (CC++) [69] extends C++ with a number of abstractions for process creation and synchronization. Synchronization is done via special shared variables. COOL [27] is targeted for shared-memory multiprocessors. <p> Mentat objects map one-to-one onto processes in a virtual machine. By contrast, Charm++ requires programmers take the responsibility of mapping of objects onto processing nodes. pC++ [87], C flfl [86], and pSather <ref> [95] </ref> are all C++-based COOP languages which are designed to support data parallelism. They differ in how to initiate data parallel execution. CST [61, 38] and DistributedConcurrentSmalltalk (DCS) [96] are two of many COOP languages which extended Smalltalk-80 [43]. CST supports concurrency using locks, asynchronous message passing, and distributed objects.
Reference: [96] <author> T. Nakajima, Y. Yokote, M. Tokoro, S. Ochiai, and T. Nagamatsu. </author> <month> DistributedConcurrentSmalltalk: </month>
Reference-contexts: They differ in how to initiate data parallel execution. CST [61, 38] and DistributedConcurrentSmalltalk (DCS) <ref> [96] </ref> are two of many COOP languages which extended Smalltalk-80 [43]. CST supports concurrency using locks, asynchronous message passing, and distributed objects. Distributed objects are similar to aggregates in CA and are equipped with similar communication mechanisms. DCS is an extension of ConcurrentSmalltalk [96] to a distributed interpersonal environment. <p> CST [61, 38] and DistributedConcurrentSmalltalk (DCS) <ref> [96] </ref> are two of many COOP languages which extended Smalltalk-80 [43]. CST supports concurrency using locks, asynchronous message passing, and distributed objects. Distributed objects are similar to aggregates in CA and are equipped with similar communication mechanisms. DCS is an extension of ConcurrentSmalltalk [96] to a distributed interpersonal environment. Concurrency is supported with asynchronous as well as synchronous method call as well as synchronous thread manipulation. DCST allows multiple processes in a single object.
References-found: 96

