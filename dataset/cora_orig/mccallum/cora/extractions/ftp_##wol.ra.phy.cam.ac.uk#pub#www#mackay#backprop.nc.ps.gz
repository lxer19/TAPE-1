URL: ftp://wol.ra.phy.cam.ac.uk/pub/www/mackay/backprop.nc.ps.gz
Refering-URL: http://131.111.48.24/mackay/README.html
Root-URL: 
Email: mackay@hope.caltech.edu  
Title: A Practical Bayesian Framework for Backprop Networks  
Author: David J.C. MacKay 
Keyword: Prerequisite  
Address: Pasadena CA 91125  
Affiliation: Computation and Neural Systems California Institute of Technology 139-74  
Abstract: A quantitative and practical Bayesian framework is described for learning of mappings in feedforward networks. The framework makes possible: (1) objective comparisons between solutions using alternative network architectures; (2) objective stopping rules for network pruning or growing procedures; (3) objective choice of magnitude and type of weight decay terms or additive regularisers (for penalising large weights, etc.); (4) a measure of the effective number of well-determined parameters in a model; (5) quantified estimates of the error bars on network parameters and on network output; (6) objective comparisons with alternative learning and interpolation models such as splines and radial basis functions. The Bayesian `evidence' automatically embodies `Occam's razor,' penalising over-flexible and over-complex models. The Bayesian approach helps detect poor underlying assumptions in learning models. For learning models well matched to a problem, a good correlation between generalisation ability This paper makes use of the Bayesian framework for regularisation and model comparison described in the companion paper `Bayesian interpolation' (MacKay, 1991a). This framework is due to Gull and Skilling (Gull, 1989a). and the Bayesian evidence is obtained.
Abstract-found: 1
Intro-found: 1
Reference: <author> Y.S. </author> <title> Abu-Mostafa (1990a). `The Vapnik-Chervonenkis dimension: information versus complexity in learning', </title> <booktitle> Neural Computation 1 3, </booktitle> <pages> 312-317. </pages>
Reference: <author> Y.S. </author> <title> Abu-Mostafa (1990b). `Learning from hints in neural networks', </title> <journal> J. </journal> <volume> Complexity 6, </volume> <pages> 192-198. </pages>
Reference: <author> C.M. </author> <title> Bishop (1991). `Exact calculation of the Hessian matrix for the multilayer perceptron', </title> <note> to appear in Neural Computation. </note>
Reference-contexts: I expect an exact analytic evaluation of the second derivatives <ref> (Bishop, 1991) </ref> would resolve this. To save programming effort I instead used second differences, which is computationally more demanding (~ kN backprops) than the analytic approach (~ N backprops).
Reference: <author> J.S. Denker and Y. </author> <title> Le Cun (1991). `Transforming neural-net output levels to probability distributions', </title> <booktitle> in Advances in neural information processing systems 3, </booktitle> <editor> ed. R.P. Lipp-mann et. al., </editor> <address> 853-859, </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> S.F. </author> <title> Gull (1989a). `Developments in Maximum entropy data analysis', </title> <editor> in J. Skilling, ed. </editor> <year> (1989a), </year> <pages> 53-71. </pages>
Reference: <author> R. Hanson, J. </author> <title> Stutz and P.Cheeseman (1991). `Bayesian classification theory', </title> <institution> NASA Ames TR FIA-90-12-7-01. </institution>
Reference-contexts: The same method of chopping up a complex model space is used in the unsupervised classification system, AutoClass <ref> (Hanson et. al., 1991) </ref>. Having adopted this slight shift in objective, it turns out that to set ff and fi and to compare alternative solutions to a learning problem, the integral we now need to evaluate is a local version of Z M .
Reference: <author> D. Haussler, M. Kearns and R. </author> <title> Schapire (1991). `Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension', </title> <type> preprint. </type>
Reference-contexts: V-C dimension is most often applied to classification problems; the evidence, on the other hand, can be evaluated equally easily for interpolation and classification problems. V-C dimension is a worst case measure, so it yields different results from Bayesian analysis <ref> (Haussler, 1991) </ref>. For example, V-C dimension is indifferent to the use of regularisers like (2), and to the value of ff, because the use of such regularisers does not rule out absolutely any particular network parameters.
Reference: <author> G.E. Hinton and T.J. </author> <title> Sejnowski (1986). `Learning and relearning in Boltzmann machines', in Parallel Distributed Processing, </title> <editor> Rumelhart et. al., </editor> <publisher> MIT Press. </publisher>
Reference: <author> C. Ji, R.R. Snapp and D. </author> <title> Psaltis (1990). `Generalizing smoothness constraints from discrete samples', </title> <booktitle> Neural Computation 2 2, </booktitle> <pages> 188-197. </pages>
Reference-contexts: The framework developed in this paper will apply not only to networks composed of `neurons,' but to any regression model for which we can compute the derivatives of the outputs with respect to the parameters, @y (x; w; A)=@w. objectively setting these parameters, though there are many rules of thumb <ref> (see Ji et. al., 1990, Weigend et. al., 1991 for examples) </ref>. One popular way of comparing networks trained with different parameter values is to assess their performance by measuring the error on an unseen test set or by similar cross-validation techniques.
Reference: <author> Y. Le Cun, J.S. Denker and S.S. </author> <month> Solla </month> <year> (1990). </year> <title> `Optimal Brain Damage', </title> <booktitle> in Advances in neural information processing systems 2, </booktitle> <editor> ed. David S. Touretzky, </editor> <address> 598-605, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The framework developed in this paper will apply not only to networks composed of `neurons,' but to any regression model for which we can compute the derivatives of the outputs with respect to the parameters, @y (x; w; A)=@w. objectively setting these parameters, though there are many rules of thumb <ref> (see Ji et. al., 1990, Weigend et. al., 1991 for examples) </ref>. One popular way of comparing networks trained with different parameter values is to assess their performance by measuring the error on an unseen test set or by similar cross-validation techniques.
Reference: <author> W.T. Lee and M.F. </author> <title> Tenorio (1991). `On Optimal Adaptive Classifier Design Criterion | How many hidden units are necessary for an optimal neural network classifier?', </title> <institution> Purdue University TR-EE-91-5. </institution>
Reference: <author> E. Levin, N. Tishby and S. </author> <month> Solla </month> <year> (1989). </year> <title> `A statistical approach to learning and generalization in layered neural networks', </title> <booktitle> in COLT '89: 2nd workshop on computational learning theory, </booktitle> <pages> 245-260. </pages>
Reference: <author> D.J.C. </author> <title> MacKay (1991a) `Bayesian interpolation', Neural Computation, this volume. </title>
Reference-contexts: In fact fi can be estimated from the training data alone. 2 Review of Bayesian regularisation and model comparison In the companion paper <ref> (MacKay, 1991a) </ref> it was demonstrated how the control parameters ff and fi are assigned by Bayes, and how alternative interpolation models can be compared. <p> However that paper assumed that M (w) only has one significant minimum which was well approximated as quadratic. (All the interpolation models discussed in <ref> (MacKay, 1991a) </ref> can be interpreted as two-layer networks with a fixed non-linear first layer and adaptive linear second layer.) In this section I briefly review the Bayesian framework, retaining that assumption. <p> Now it may be the case that the significant minima of M are locally quadratic, 2 The same notation, and the same abuses thereof, will be used as in <ref> (MacKay, 1991a) </ref>. 6 so we might be able to evaluate Z M by evaluating (9) at each significant minimum and adding up the Z M s; but the number of those minima is unknown, and this approach to evaluating Z M would seem dubious. <p> What obstacles remain to prevent us from evaluating the local Z fl M ? We need to evaluate or approximate the inverse Hessian of M , and we need to evaluate or approximate its determinant and/or trace <ref> (MacKay, 1991a) </ref>. Denker and Le Cun (1991) et. al. (1990) have already discussed how to approximate the Hessian of E D for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs. <p> The quadratic approximations break down when the number of parameters becomes too big compared with the number of data points. The next figures introduce the quantity fl, discussed in <ref> (MacKay, 1991a) </ref>, the number of well-measured parameters. In cases where the evaluation of the evidence proves difficult, it may be that fl will serve as a useful tool. <p> Relation to `generalisation error' What is the relationship between the evidence and the generalisation error (or its close relative, cross-validation)? A correlation between the two is certainly expected. But the evidence is not necessarily a good predictor of generalisation error <ref> (see discussion in MacKay, 1991a) </ref>. First, as illustrated in figure 8, the error on a test set is a noisy quantity, and a lot of data has to be devoted to the test set to get an acceptable signal to noise ratio. <p> The increased complexity of this prior model is penalised by an Occam factor for each new parameter ff c <ref> (see MacKay, 1991a) </ref>.
Reference: <author> D.J.C. </author> <title> MacKay (1991d) `The evidence framework applied to classification networks', in preparation. 19 J.E. Moody (1991). `Note on generalization, regularization and architecture selection in nonlinear learning systems', </title> <booktitle> in First IEEE-SP Workshop on neural networks for signal processing, </booktitle> <publisher> IEEE Computer society press. </publisher>
Reference-contexts: Application to classification problems This paper has thus far discussed the evaluation of the evidence for backprop networks trained on interpolation problems. Neural networks can also be trained to perform classification tasks. A future publication <ref> (MacKay, 1991d) </ref> will demonstrate that the Bayesian framework for model comparison can be applied to these problems too. Relation to V-C dimension Some papers advocate the use of V-C dimension (Abu-Mostafa, 1990a) as a criterion for penalising over-complex models (Abu-Mostafa, 1990b, Lee and Tenorio, 1991).
Reference: <author> S.J. </author> <title> Nowlan (1991). `Soft competitive adaptation: neural network learning algorithms based on fitting statistical mixtures', </title> <institution> Carnegie Mellon University Doctoral thesis CS-91-126. </institution>
Reference: <author> F.J. </author> <month> Pineda </month> <year> (1989). </year> <title> `Recurrent back-propagation and the dynamical approach to adaptive neural computation', </title> <booktitle> Neural Computation 1 161-172. </booktitle>
Reference-contexts: Alternatively, Radford Neal has suggested that the gradients @E val =@ff c could be more efficiently calculated using `recurrent backpropagation' <ref> (Pineda, 1989) </ref>, viewing w as the vector of activities of a recurrent network, and w MP as the fixed point whose error E val we wish to minimise. 16 the determinant of the Hessian.
Reference: <author> W.H. Press, B.P. Flannery, S.A. Teukolsky and W.T. </author> <title> Vetterling (1988). Numerical recipes in C, </title> <publisher> Cambridge. </publisher>
Reference-contexts: Demonstrations The demonstrations were performed as follows: Initial weight configuration: random weights drawn from a gaussian with W = 0:3. Optimisation algorithm for M (w): variable metric methods, using code from <ref> (Press et. al., 1988) </ref>, used several times in sequence with values of the fractional tolerance decreasing from 18 10 4 to 10 8 .
Reference: <author> D.E. Rumelhart, G.E. Hinton and R.J. </author> <title> Williams (1986). `Learning representations by back propagating errors', </title> <booktitle> Nature 323, </booktitle> <pages> 533-536. </pages>
Reference-contexts: 1 The gaps in backprop There are many knobs on the black box of `backprop' (learning by back-propagation of errors <ref> (Rumelhart et. al., 1986) </ref>). Generally these knobs are set by rules of thumb, trial and error, and the use of reserved test data to assess generalisation ability (or more sophisticated cross-validation).
Reference: <editor> D.E. Rumelhart (1987). Cited in Ji et. al. </editor> <year> (1990). </year>
Reference: <author> J. Skilling, </author> <title> editor (1989a). Maximum Entropy and Bayesian Methods, </title> <address> Cambridge 1988, </address> <publisher> Kluwer. </publisher>
Reference: <author> J. </author> <title> Skilling (1989b). `The eigenvalues of mega-dimensional matrices', </title> <editor> in J. Skilling, ed. </editor> <year> (1989a), </year> <pages> 455-466. </pages>
Reference-contexts: If this is the case, numerical methods are available to approximate the determinant or trace of a matrix in k 2 time <ref> (Skilling, 1989b) </ref>. Application to classification problems This paper has thus far discussed the evaluation of the evidence for backprop networks trained on interpolation problems. Neural networks can also be trained to perform classification tasks.
Reference: <author> N. Tishby, E. Levin and S.A. </author> <month> Solla </month> <year> (1989). </year> <title> `Consistent inference of probabilities in layered networks: predictions and generalization', </title> <booktitle> in Proc. IJCNN, </booktitle> <address> Washington. </address>
Reference: <author> A.M. </author> <title> Walker (1967). `On the asymptotic behaviour of posterior distributions', </title> <journal> J. R. Stat. Soc. </journal> <volume> B 31, </volume> <pages> 80-88. </pages>
Reference-contexts: The above solution was created by a three layer network with 19 hidden units. of free parameters, k. For large N=k the central limit theorem encourages us to use the gaussian approximation <ref> (Walker, 1967) </ref>. It is a matter for further research to establish how large N=k must be for this approximation to be reliable.
Reference: <author> A.S. Weigend, D.E. Rumelhart and B.A. </author> <title> Huberman (1991). `Generalization by weight-elimination with applications to forecasting', </title> <booktitle> in Advances in neural information processing systems 3., </booktitle> <editor> ed. R.P. Lippmann et. al., </editor> <address> 875-882, </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> I thank Mike Lewicki, Nick Weir, </author> <title> and Haim Sompolinsky for helpful conversations, and Andreas Herz for comments on the manuscript. This work was supported by a Caltech Fellowship and a Studentship from SERC, </title> <address> UK. </address> <month> 20 </month>
References-found: 25

