URL: http://www.cs.berkeley.edu/~oza/papers/cs287.ps
Refering-URL: http://www.cs.berkeley.edu/~oza/papers.html
Root-URL: 
Email: oza@cs.berkeley.edu  
Title: A Survey of Robot Architectures  
Author: Nikunj C. Oza 
Address: Berkeley, CA 94720-1776  
Affiliation: Computer Science Division University of California  
Abstract: The goal of a robot system in general is to solve problems of navigation and/or manipulation. To construct a robot system, one must answer many questions regarding the environment in which the robot is expected to operate and the robot architecture best suited for the problem. In this paper, we look at six different approaches to building robot systems. We examine the assumptions they make regarding the environment and themselves, determine whether they are justified, and suggest extensions to these robots. We compare these approaches and draw some conclusions about robot architectures in general. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Marko Balabanovic, Craig Becker, Sarah K. Morse, and Illah R. Nourbakhsh, </author> <booktitle> The Real-World Navigator CIRFFSS 1994 </booktitle>
Reference-contexts: Most chess computers get around the whole issue by requiring someone to enter the opponents moves directly through a user-interface and maintaining its own chessboard data structure. 4 If the sensors are assumed to be imperfect, how is the uncertainty dealt with? In one example <ref> [1] </ref>, a region of uncertainty is maintained such that the robot is guaranteed to be within that region at all times. The region of uncertainty is expanded as appropriate and contracted when landmarks are available which the robot can use to localize itself. <p> Also, it may be possible to merge goals with similar locations or times at which they need to be completed, in which case the tasks corresponding to these goals can be scheduled simultaneously, which may reduce scheduling time. 6. Real-World Navigator The Real-World Navigator <ref> [1] </ref> architecture consists of three levels. The Task level keeps track of the robots goal locations. The Navigator level directs the robot to achieve the goals given by the task level by using two maps. <p> This allows the slow planner to run without affecting the response of the reactive component of the architecture. Explicit reasoning about deadlines [7] and explicit maintenance of a region of uncertainty <ref> [1] </ref> can be more easily implemented in Gats framework since the addition of these high-level tasks does not slow down the control loop; however, it remains to be seen how much can be added to the planners tasks before it becomes so slow that it is unable to ever provide meaningful,
Reference: [2] <author> Rodney A. Brooks, </author> <title> A Robot that Walks; Emergent Behaviors from a Carefully Evolved Network MIT AI Lab Memo 1091, </title> <month> February </month> <year> 1989. </year>
Reference-contexts: Start Goal Next, we will examine the robot architecture described in <ref> [2] </ref>. 5 2. The Subsumption Architecture Brooks uses what he calls the subsumption architecture. It consists of several stacked layers, each of which is implemented as an augmented finite state machine (AFSM). An AFSM consists of registers, timers, and a conventional finite state machine (FSM). <p> An AFSM consists of registers, timers, and a conventional finite state machine (FSM). The finite state machine can perform computations based on values of the registers and store values into registers. A more detailed description of AFSMs is found in <ref> [2] </ref>. AFSMs corresponding to higher levels suppress inputs or inhibit outputs of lower level machines. That is, higher level machines can temporarily replace the existing inputs to a lower level machine with other inputs, and they can temporarily cut off the outputs of a lower level machine. <p> Additionally, higher level machines can access and manipulate the internal state of lower level machines. In Brookss robots, higher level machines correspond to higher level behaviors. From the lowest level to the highest level, the behaviors implemented in the six-legged robot described in <ref> [2] </ref> are: 1. Stand up: This consists of leg-down machines for each leg which keep the legs down. 2. Simple walk: For one leg at a time, the leg-down machine is inhibited, causing the leg to go up. <p> They do not know about the presence of higher levels. It is not clear how to use machine learning in the subsumption architecture to build up new layers. Constructing these layers appears to be more difficult than what is indicated in <ref> [2] </ref> because higher levels can suppress the inputs, inhibit outputs, and change the internal 6 state of lower levels, and the various machines operate asynchronously. It may be possible to implement Q-learning [11] in this framework. <p> When additional information comes in, it is necessary to remove anything in the world model that is no longer valid because of the new information. Rechecking every element of a large world model for validity would be intractable. An example of an alternative architecture is the behavior-based approach <ref> [2] </ref>. These typically use propositional logic representations 1 rather than first-order logic representations, making inference much easier. However, propositional logic lacks expressiveness. Specifically, propositional logic does not have quantifiers, variables, or term expressions.
Reference: [3] <author> Francesco Donini, Maurizio Lenzirini, Daniele Nardi, and Werner Nutt, </author> <booktitle> Tractable Concept Languages Proceedings of the Twelfth International Joint Conference on Artificial Intelligence Sydney, </booktitle> <address> Australia: </address> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address> <pages> 458-463 </pages>
Reference: [4] <author> Erann Gat, ALFA: </author> <booktitle> A Language for Programming Reactive Robotic Control Systems IEEE Conference on Robotics and Automation, </booktitle> <year> 1991 </year> <month> 15 </month>
Reference-contexts: We will examine this approach now. 4. Planning as a Subroutine Gats ATLANTIS system [5] consists of three major components. The lowest level component is the controller, a reactive control mechanism that performs simple reactive sensorimotor processes. It uses a language called ALFA <ref> [4] </ref> that allows the specification of the transfer functions required to control reactive robots and the implementation of these so that they can be connected to hardware. This language is similar in spirit to REX but provides very different sorts of abstractions, as described in [4]. <p> uses a language called ALFA <ref> [4] </ref> that allows the specification of the transfer functions required to control reactive robots and the implementation of these so that they can be connected to hardware. This language is similar in spirit to REX but provides very different sorts of abstractions, as described in [4]. The second major component is the sequencer. The sequencer initiates and terminates the primitive activities 11 performed by the controller and performs failure detection. The third major component, and the most interesting one, is the deliberator.
Reference: [5] <author> Erann Gat, </author> <title> Integrating Planning and Reacting in a Heterogeneous Asynchronous Architecture for Controlling Real-World Mobile Robots Proceedings AAAI-92, </title> <publisher> AAAI, </publisher> <year> 1992 </year>
Reference-contexts: Since planning and reasoning take a long time, they should only be done on parts of the environment that do not change significantly. Plans made on the basis of characteristics that change frequently are unlikely to be valid by the time the plans are completed. Gats ATLANTIS system <ref> [5] </ref> which allows planning to run asynchronously with the remainder of the architecture and uses plans to guide rather than control action appears to be a superior approach as this prevents the system from being delayed by a slow planner. We will examine this approach now. 4. <p> We will examine this approach now. 4. Planning as a Subroutine Gats ATLANTIS system <ref> [5] </ref> consists of three major components. The lowest level component is the controller, a reactive control mechanism that performs simple reactive sensorimotor processes. <p> On the other hand, it uses stored models of the environment like classical architectures. However, how the model is maintained is not indicated. Gats ATLANTIS system <ref> [5] </ref> removes planning and reasoning from the main control loop, which allows a traditional planner assuming a discrete action model to run asynchronously and in parallel with the sequencer and controller, which constitute the main control loop.
Reference: [6] <institution> Ian Horswill Visual Architecture and Cognitive Architecture To appear in JETAI Special Issue on Agent Architectures, </institution> <year> 1996 </year>
Reference-contexts: One problem with the classical AI approach is the sensing. Especially when vision is the main percept, the perceptual system may be unable to add data to the world model at the high rate at which data comes in. Horswill <ref> [6] </ref> points out that this bandwidth limitation is inherent in humans as well: our eyes can only focus on one object at a time. Many systems get around this problem by using sensors that are more specialized such as infrared and sonar sensors. <p> Another nice way to reduce this problem is to have the planner ask the sensors for information whenever the planner needs it. This way, the world model only keeps relevant information. Horswill <ref> [6] </ref> calls this a violation of the modularity of the classical architecture, but as this idea does not require one module to access the internal state of another, there is actually no such violation. Another problem with the classical approach is the maintenance of the world model. <p> Additionally, some of these systems do not use world models at all, in which case they work only in fully observable worlds. 3.2 Integrating Vision into a Behavior-Based Architecture Polly is a very simple behavior-based robot created by Horswill <ref> [6] </ref>. It moves around in the hallways of the MIT Artificial Intelligence Laboratory, finds people, asks 1 Actually, some behavior-based architectures like Brookss systems work with both truth values and analog measures. Indeed, Brookss systems registers are capable of keeping analog data such as the angles of the leg joints. <p> Behavior-based systems [2]<ref> [6] </ref> are sometimes designed to avoid using world models altogether, 14 which leads to robots that can only perform simple tasks in environments that are fully observable, or otherwise can only maintain very small histories of certain parameters decided upon ahead of time. Horswills Bertrand system [6] is able to perform some high level cognition, but since it does not maintain any world model, it is only able to reason about its current percepts.
Reference: [7] <author> Philippe Lalanda and Barbara Hayes-Roth, </author> <title> Deadline Management in Intelligent Agents Technical Report No. </title> <type> KSL 94-27, </type> <institution> Stanford University Knowledge Systems Laboratory, </institution> <year> 1994 </year>
Reference-contexts: Probabilistic reasoning could be used here just as in reasoning about sensor uncertainty. We will see a system where actions are assumed to take varying amounts of time, but average times are used for the purpose of scheduling <ref> [7] </ref>. Earlier, we discussed the question of whether the environment is discrete or continuous. This influences whether actions are discrete or continuous. <p> Gat also shows that planning and world modeling are useful, but plans should guide and not control action. 5. Deadline Management Lalanda and Hayes-Roth <ref> [7] </ref> discuss the problem of scheduling various tasks for a robot to perform. It is assumed that one or more methods are available that can perform each task. These methods may have different time and resource requirements, precision, certainty, and completeness. <p> They correspond instead to general behaviors that should be performed as conditions warrant. In contrast, a control schedule is a control plan in which each task also has a deadline, an earliest and latest start time, an estimated computation time, and preconditions of execution. The robot described in <ref> [7] </ref> has a meta-control decision criterion that uses the control plans and control schedule to schedule a task and choose a suitable method to perform that task. Deadline-first scheduling is used to schedule tasks that have deadlines. <p> A threshold that is too low increases the likelihood of not completing tasks on time because the robot does not allow enough slack time to account for unexpected delays. The most interesting features of the system described in <ref> [7] </ref> is that they distinguish importance from urgency and use that distinction to schedule only time-constrained goals. Non-time-constrained goals are thrown into holes in the schedule. Since scheduling is time-intensive, this distinction is very helpful. <p> This allows the slow planner to run without affecting the response of the reactive component of the architecture. Explicit reasoning about deadlines <ref> [7] </ref> and explicit maintenance of a region of uncertainty [1] can be more easily implemented in Gats framework since the addition of these high-level tasks does not slow down the control loop; however, it remains to be seen how much can be added to the planners tasks before it becomes so
Reference: [8] <author> H.J. Levesque and R.J. Brachman, </author> <title> A Fundamental Tradeoff in Knowledge Representation and Reasoning (revised version) R.J. </title> <editor> Brachman and H.J. Levesque (Eds.), </editor> <booktitle> Readings in Knowledge Representation, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address> <pages> 41-70. </pages>
Reference: [9] <author> Nils J. Nilsson, </author> <booktitle> Teleo-Reactive Programs for Agent Control Journal of Artificial Intelligence Research 1, </booktitle> <year> 1994, </year> <pages> 139-158. </pages>
Reference-contexts: Additionally, Brooks rejects the use of world models, therefore, his robots cannot represent the many facts and rules of inference necessary for high-level cognition. 2. Control Theory and Computer Science The Teleo-Reactive Program formalism <ref> [9] </ref> draws ideas from both control theory (continuous feedback and response) and computer science (hierarchical organization, recursion, and parameters that can be bound at runtime and passed to subroutines). Nilsson calls this formalism circuit semantics. The programs consist of condition-action rules as shown in Figure 2. <p> The use of automatic planning and machine learning to construct T-R programs needs to be investigated, although some preliminary work has already begun. In the area of machine learning, Nilsson has pointed out that T-R programs can be expressed as decision lists and as neural networks <ref> [9] </ref>, which are PAC learnable and have known learning algorithms. Currently, goals are represented simply as propositional statements (condition K1 is the ultimate goal of a T-R program). <p> However, its use of the Visual Routine Processor that focuses on only relevant parts of the image prevents Horswills systems from reaching sensor data bandwidth limits-one of several problems with the classical AI architecture that Horswill cites. Nilssons Teleo-Reactive Programs <ref> [9] </ref> are similar to behavior-based systems in that the connection between sensor data and actions is simple and conditions are continuously evaluated under some assumptions. On the other hand, it uses stored models of the environment like classical architectures. However, how the model is maintained is not indicated.
Reference: [10] <author> Nikunj C. Oza, </author> <title> Markov Decision Problems U.C. Berkeley Randomized Algorithms Class Project, </title> <year> 1996 </year>
Reference: [11] <author> Stuart J. Russell and Peter Norvig, </author> <title> Artificial Intelligence A Modern Approach, </title> <publisher> (Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1995). </year>
Reference-contexts: We then reveal questions that have to be answered when designing a robot. 2 2.1 Environments Before building a robot, it is important to describe the environment in which we expect the robot to operate. The following is a set of environmental attributes derived from <ref> [11] </ref> that will be sufficient to describe the environments assumed in the architectures that we will review. Static vs. Dynamic: In a static environment, the environment does not change while the robot is deliberating. <p> The region of uncertainty is expanded as appropriate and contracted when landmarks are available which the robot can use to localize itself. Alternatively, one could use probabilistic reasoning using Dynamic Belief Networks <ref> [11] </ref> to model the influence of the true parameter values and other factors on the sensors. Actions: Are the actions assumed to always complete perfectly? In many real robots, there are errors in the actuators that need to be accounted for. <p> Constructing these layers appears to be more difficult than what is indicated in [2] because higher levels can suppress the inputs, inhibit outputs, and change the internal 6 state of lower levels, and the various machines operate asynchronously. It may be possible to implement Q-learning <ref> [11] </ref> in this framework. For example, a Q-learning program could create an AFSM that finds actions to maximize a utility function, where the utility function is proportional to the stability of the robot. This way, the robot learns to use its legs to keep itself balanced while moving over obstacles.
References-found: 11

