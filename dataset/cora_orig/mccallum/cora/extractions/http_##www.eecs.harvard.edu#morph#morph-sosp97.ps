URL: http://www.eecs.harvard.edu/morph/morph-sosp97.ps
Refering-URL: http://www.eecs.harvard.edu/~zhwang/index.html
Root-URL: 
Title: System Support for Automatic Profiling and Optimization  
Author: Xiaolan Zhang, Zheng Wang, Nicholas Gloy, J. Bradley Chen, and Michael D. Smith 
Affiliation: Division of Engineering and Applied Sciences Harvard University  
Abstract: The Morph system provides a framework for automatic collection and management of profile information and application of profiledriven optimizations. In this paper, we focus on the operating system support that is required to collect and manage profile information on an end-user's workstation in an automatic, continuous, and transparent manner. Our implementation for a Digital Alpha machine running Digital UNIX 4.0 achieves runtime overheads of less than 0.3% during profile collection. Through the application of three code layout optimizations, we further show that Morph can use statistical profiles to improve application performance. With appropriate system support, automatic profiling and optimization is both possible and effective. 
Abstract-found: 1
Intro-found: 1
Reference: [ABD97] <author> J. Anderson, L. M. Berc, J. Dean, S. Ghemawat, M. R. Henzinger, S. Leung, R. L. Sites, M. T. Vandevoorde, C. A. Waldspurger, and W. E. Weihl, </author> <title> Continuous Profiling: </title> <booktitle> Where Have All the Cycles Gone? In Proceedings of the 16th ACM Symposium of Operating Systems Principles (in this volume), </booktitle> <month> October </month> <year> 1997. </year> <note> See also http://www.research.digital.com/SRC/dcpi/ </note>
Reference-contexts: Both implement profile-based optimizations, Etch for the Intel x86 architecture and Spike for Digital Alpha-based systems. The Digital Continuous Profiling Infrastructure (DCPI), developed at the Digital Systems Research Center, supports continuous monitoring of the entire system including the kernel <ref> [ABD97] </ref>. There are substantial similarities between DCPI profile collection and the continuous monitor used in Morph. Both DCPI and the Morph Monitor use statistical sampling to collect profile information of all system activity with very low overhead. The primary difference between the two monitors is how they have been applied. <p> This problem could be avoided by introducing randomness into the sampling interval, using an interrupt based on a countdown timer instead of (or in addition to) sampling during clock interrupts. This scheme is used by the continuous profiler in DCPI <ref> [ABD97] </ref>. Many popular processors provide appropriate hardware support, including the Digital Alpha and the Intel Pentium Pro.
Reference: [BCL94] <author> B. Bershad, J. B. Chen, D. Lee, and T. Romer, </author> <title> Avoiding Conflict Misses Dynamically in Large Direct-Mapped Caches. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, ACM, </booktitle> <pages> pages 158-170, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: All results reported in this section use the page coloring policy. The problems and pitfalls of page mapping algorithms are well documented in the research literature <ref> [KH92, CB93, BCL94] </ref>. Table 4 gives the overhead of the online component of profiling for our test workloads. To distinguish the impact of profiling from memory system effects, we compare execution times for the Morph kernel with profiling and the Morph kernel with profile collection disabled.
Reference: [CB93] <author> J. B. Chen and B. Bershad, </author> <title> The Impact of Operating System Structure on Memory System Performance. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Operating System Principles, ACM, </booktitle> <pages> pages 120-133, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: All results reported in this section use the page coloring policy. The problems and pitfalls of page mapping algorithms are well documented in the research literature <ref> [KH92, CB93, BCL94] </ref>. Table 4 gives the overhead of the online component of profiling for our test workloads. To distinguish the impact of profiling from memory system effects, we compare execution times for the Morph kernel with profiling and the Morph kernel with profile collection disabled.
Reference: [CH97] <author> A. Chernoff and R. Hookway, </author> <title> DIGITAL FX!32 - Running 32-Bit x86 Applications on Alpha NT. </title> <booktitle> To appear in Proceedings of the USENIX Windows NT Workshop, USENIX Association, </booktitle> <address> Berkeley CA, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: Although the Morph design does not preclude the use of new hardware support for profile collection, it does not require it either. Digitals FX!32 is a system that provides transparent execution of x86 Win32 applications on Windows NT Alpha systems <ref> [CH97, Rub96] </ref>. As a part of their emulation system, execution profiles of x86 code are collected and fed to a background process that translates the previously emulated portions of x86 binaries into native Alpha code. <p> This solution has major practical drawbacks, however, as it requires new software standards and standards compliance across the software industry. Another possibility is to develop new ways of acquiring the additional information needed to derive intermediate form program representations from current executables. Digitals FX!32 <ref> [CH97, Rub96] </ref> provides an example of progress in this approach. Our PostMorph tool represents another alternative. One of the greatest barriers to obtaining conclusive results for Morph is the lack of a compelling suite of interactive benchmarks.
Reference: [Chr96] <author> P. Christy, </author> <title> IA-64 and MercedWhat and Why. </title> <booktitle> In Microprocessor Report, </booktitle> <pages> pages 17-19, </pages> <month> 30 December </month> <year> 1996. </year>
Reference-contexts: In spite of the lack of a workable compiler infrastructure, the need for hostspecific optimizations is increasing in modern machines. Experts in the computer architecture and compiler communities anticipate that the importance of these optimizations will increase for the next generation of machines <ref> [Chr96, Gwe96] </ref>. 3. Implementation Our prototype implementation of Morph supports automatic profile generation and re-optimization for Digital Alpha-based workstations running Digital UNIX. We employed several custom system tools and made small modifications to Digital UNIX to support automatic profile generation, collection, and analysis.
Reference: [CL96] <author> R. Cohn and G. Lowney, </author> <title> Hot Cold Optimization of Large Windows NT Applications. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Microarchitecture, IEEE, </booktitle> <pages> pages 80-89, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: These tools were designed for UNIX systems and required either an intermediate form representation of the program or an executable that includes relocation information. More recent systems for Windows NT include Spike <ref> [CL96, Goo97] </ref> and Etch [RVL97]. Both implement profile-based optimizations, Etch for the Intel x86 architecture and Spike for Digital Alpha-based systems. The Digital Continuous Profiling Infrastructure (DCPI), developed at the Digital Systems Research Center, supports continuous monitoring of the entire system including the kernel [ABD97]. <p> The ideal test for our system would be a suite of large, interactive benchmarks in a format that permits re- optimization. Unfortunately, source or intermediate form representations for such benchmarks are not commonly available. Recent developments in late-code optimization <ref> [CL96, Rub96, RVL97] </ref> offer some promise in addressing these issues. 6. Conclusions This paper describes a system for continuous low-overhead profile collection designed to meet the unique requirements of automatic optimization.
Reference: [CMH96] <author> T. Conte, K. Menezes, and M. A. Hirsch, </author> <title> Accurate and Practical ProfileDriven Compilation Using the Profile Buffer. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Microarchitecture, IEEE, </booktitle> <pages> pages 201-211, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: In Morph we have focused on optimization, whereas the emphasis to date for DCPI has been on performance analysis. It would be relatively straightforward to use DCPI as a source of profiles for Morph. Conte et al. <ref> [CMH96] </ref> describe an approach in which new hardware support in the form of a profile buffer is used to collect statistics describing the behavior of conditional branches in the program. They use the resulting information to drive a superblock scheduling optimization.
Reference: [Col95] <author> Colusa Software, Omniware, </author> <title> A Universal Substrate for Mobile Code. </title> <note> White paper from Colusa Software, http://www.colusa.com/ </note>
Reference-contexts: Compiler optimizations are implemented as SUIF passes which apply transformations to this intermediate form. An important aspect of our design is that executable modules are machine and OS specific. Though we are aware of prior work on machine and operating system-neutral program distribution formats <ref> [OSF93, Col95] </ref>, we have chosen not to attempt similar functionality in Morph, focusing instead on the problem of using profiledriven optimizations to improve performance. The key to providing a viable framework for hostspecific optimization is to define a partitioning of the compilation process that supports efficient and effective retargeting.
Reference: [EA97] <author> K. Ebcioglu and E. Altman, </author> <title> DAISY: Dynamic Compilation for 100% Architectural Compatibility. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, ACM, </booktitle> <pages> pages 26-37, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: In this section, we evaluate the overhead of profile collection and profile processing. We do not discuss the overhead of the SUIF optimizations performed by the Morph Editor. SUIF is a research compiler, and is designed for flexibility rather than short compilation times. Ebcioglu and Altman <ref> [EA97] </ref> describe a dynamic compilation system designed specifically for compilation speed while still performing machinespecific optimizations such as global instruction scheduling. They report that their compiler requires 15 times fewer instructions per generated instruction than gcc.
Reference: [Fis97] <author> J. Fisher, </author> <title> Trace Scheduling: A Technique for Global Microcode Compaction. </title> <journal> In IEEE Transactions on Computers, </journal> <volume> Volume 30, Number 7, </volume> <pages> pages 478-490, </pages> <month> July </month> <year> 1981. </year>
Reference: [FF92] <author> J. Fisher and S. Freudenberger, </author> <title> Predicting Conditional Branches from Previous Runs of a Program. </title> <booktitle> In Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, ACM, </booktitle> <pages> pages 85-95, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: In conventional (non-automatic) profile-based optimization, complete profiles are collected for a number of scripted training input sets. This is in contrast to continuous profiling of all activity as with Morph. Fisher and Freudenberger <ref> [FF92] </ref> evaluate three techniques for combining multiple branch profiles: combining profiles directly, normalizing to give each test case the same weight in the composite profile, and polling 1 . <p> The Morph Manager uses direct combining, such that profiles contribute to the composite profile in proportion to their contribution to overall activity. We believe that direct combining is appropriate for a continuous monitor, even though normalization can give better results for scripted inputs <ref> [FF92] </ref>. When a module is optimized, the profile information for the module must also be transformed, to make it meaningful in the context of the new executable module.
Reference: [FK96] <author> M. Franz and T. Kistler, </author> <title> Slim Binaries. </title> <type> Technical Report No. 96-24, </type> <institution> Department of Information and Computer Science, University of California, Irvine, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: In practice, there are a number of alternatives for achieving this, including executable editing techniques [LS95, RVL97] and compact program representations <ref> [FK96] </ref>. Optimization must be transparent to the user. We assume that the people who use computers are nonspecialists with no background in computer science or compilation. Optimization should be transparent in that the user does not need to understand or actively participate in the optimization process.
Reference: [Goo97] <author> D. Goodwin, </author> <title> Interprocedural Dataflow Analysis in an Executable Optimizer. </title> <booktitle> In Proceedings of the 1997 ACM SIGPLAN Conference on Programming Language Design and Implementation, ACM, </booktitle> <pages> pages 122-133, </pages> <month> November </month> <year> 1997. </year>
Reference-contexts: These tools were designed for UNIX systems and required either an intermediate form representation of the program or an executable that includes relocation information. More recent systems for Windows NT include Spike <ref> [CL96, Goo97] </ref> and Etch [RVL97]. Both implement profile-based optimizations, Etch for the Intel x86 architecture and Spike for Digital Alpha-based systems. The Digital Continuous Profiling Infrastructure (DCPI), developed at the Digital Systems Research Center, supports continuous monitoring of the entire system including the kernel [ABD97].
Reference: [Gwe96] <author> L. Gwennap, </author> <title> Bringing Parallelism Out of the Closet. </title> <booktitle> In Microprocessor Report, </booktitle> <pages> pages 14-15, </pages> <month> 9 December </month> <year> 1996. </year>
Reference-contexts: In spite of the lack of a workable compiler infrastructure, the need for hostspecific optimizations is increasing in modern machines. Experts in the computer architecture and compiler communities anticipate that the importance of these optimizations will increase for the next generation of machines <ref> [Chr96, Gwe96] </ref>. 3. Implementation Our prototype implementation of Morph supports automatic profile generation and re-optimization for Digital Alpha-based workstations running Digital UNIX. We employed several custom system tools and made small modifications to Digital UNIX to support automatic profile generation, collection, and analysis.
Reference: [GWZ97] <author> N. Gloy, Z. Wang, X. Zhang, J. B. Chen, and M. D. Smith, </author> <title> Optimization with Statistical Profiles. </title> <type> Technical Report TR-02-97, </type> <institution> Center for Reliable Computing, Division of Engineering and Applied Sciences, Harvard University, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: We could attempt to adjust the time base in our statistical profiles to make them more similar to a frequency-based profile. However, our experience to date suggests that neither time nor frequency based profiles are clearly superior. <ref> [GWZ97] </ref> 3.4 The Morph Editor The Morph Editor applies optimizations using profiles from the Morph Monitor. The Editor is currently implemented as a composition of SUIF compiler passes which convert a program module in a lowSUIF intermediate form to optimized assembly language. <p> Our experience with Morph suggest that minimal training is needed to obtain most of the benefit of optimization. For a detailed discussion of our findings, see <ref> [GWZ97] </ref>. The execution time improvements given in Figure 3 are computed from the average of ten runs, with execution times measured using the Alpha cycle counter.
Reference: [KH92] <author> R. Kessler and M. Hill, </author> <title> Page Placement Algorithms for Large Real-Index Caches. </title> <journal> In ACM Transactions on Computer Systems, </journal> <volume> Volume 10, Number 4, pages:338-359, </volume> <month> November </month> <year> 1992. </year>
Reference-contexts: A problem that arises when attempting to measure overheads on the order of 0.1% for realistic workloads is that the overhead is smaller than the variation that can occur due to non-determinism in the system. A major source of such non-determinism is virtual-to-physical page mapping <ref> [KH92] </ref>. The standard Digital UNIX kernel uses a bin-hopping policy for allocation of physical memory pages. Although this policy has some desirable performance characteristics [KH92], it has the undesirable property of poor repeatability. <p> A major source of such non-determinism is virtual-to-physical page mapping <ref> [KH92] </ref>. The standard Digital UNIX kernel uses a bin-hopping policy for allocation of physical memory pages. Although this policy has some desirable performance characteristics [KH92], it has the undesirable property of poor repeatability. For our overhead measurement experiments, we replaced the bin-hopping policy with page coloring [TDF90], a deterministic policy, to improve the repeatability of our experiments. All results reported in this section use the page coloring policy. <p> All results reported in this section use the page coloring policy. The problems and pitfalls of page mapping algorithms are well documented in the research literature <ref> [KH92, CB93, BCL94] </ref>. Table 4 gives the overhead of the online component of profiling for our test workloads. To distinguish the impact of profiling from memory system effects, we compare execution times for the Morph kernel with profiling and the Morph kernel with profile collection disabled.
Reference: [LRW91] <author> M. Lam, E. Rothberg, and M. Wolf, </author> <title> The Cache Performance and Optimizations of Blocked Algorithms. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ACM, </booktitle> <pages> pages 63-74, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This information directs instruction scheduling. Instruction timing. Often, the relative cost of an instruction sequence changes from one machine implementation to the next. This information influences the instruction selection and scheduling processes. Cache parameters. This information can be used by locality optimizations such as data blocking <ref> [LRW91] </ref> and code layout [PH90]. These hardware parameters commonly vary between binary- compatible systems, even between those designed at the same time in similar VLSI technologies.
Reference: [LS95] <author> J. Larus and E. Schnarr, EEL: </author> <title> Machine Independent Executable. </title> <booktitle> In Proceedings of the ACM SIGPLAN 95 Conference on Programming Language Design and Implementation, ACM, </booktitle> <pages> pages 291-300, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: To enable optimization without source code, we assume that an intermediate-form representation of the program can be derived from the program distribution media, with all optimizations based on this intermediate form. In practice, there are a number of alternatives for achieving this, including executable editing techniques <ref> [LS95, RVL97] </ref> and compact program representations [FK96]. Optimization must be transparent to the user. We assume that the people who use computers are nonspecialists with no background in computer science or compilation. <p> Morph enables executable programs to evolve with changes in program usage patterns and computer hardware. This functionality is not provided by any current tool, although Morph builds on technology and techniques originally developed for program instrumentation and measurement. Several existing tools (Pixie [Smi91], ATOM [SE94], EEL <ref> [LS95] </ref>) rewrite executables for the purpose of program measurement. These instrumentation tools differ from Morph in two important ways. <p> Our monitor achieves this goal by using statistical sampling of program activity, rather than collecting a complete profile. In most current systems, profile information is typically obtained by executing an instrumented version of the application that generates profile information as a side-effect of program execution <ref> [Smi91, SE94, LS95] </ref>. A straightforward approach for automatic profile collection would be periodic use of a higher-overhead profiling system, such as an instrumentation-based profiler.
Reference: [OSF93] <author> Open Software Foundation Research Institute, </author> <booktitle> ANDF Collected Papers, Volume IV, Open Software Foundation, </booktitle> <month> December </month> <year> 1993. </year> <note> See also http://www.opengroup.org/RI/andf/ </note>
Reference-contexts: Compiler optimizations are implemented as SUIF passes which apply transformations to this intermediate form. An important aspect of our design is that executable modules are machine and OS specific. Though we are aware of prior work on machine and operating system-neutral program distribution formats <ref> [OSF93, Col95] </ref>, we have chosen not to attempt similar functionality in Morph, focusing instead on the problem of using profiledriven optimizations to improve performance. The key to providing a viable framework for hostspecific optimization is to define a partitioning of the compilation process that supports efficient and effective retargeting.
Reference: [PH90] <author> K. Pettis and R. Hansen, </author> <title> Profile Guided Code Positioning. </title> <booktitle> In Proceedings of the ACM SIGPLAN 90 Conference on Programming Language Design and Implementation, ACM, </booktitle> <pages> pages 16-27, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Instruction timing. Often, the relative cost of an instruction sequence changes from one machine implementation to the next. This information influences the instruction selection and scheduling processes. Cache parameters. This information can be used by locality optimizations such as data blocking [LRW91] and code layout <ref> [PH90] </ref>. These hardware parameters commonly vary between binary- compatible systems, even between those designed at the same time in similar VLSI technologies. In the absence of a suitable infrastructure for hostspecific optimization, hardware designers have created machines that attempt to execute programs efficiently without help from the compiler. <p> The Morph Editor implements the optimizations provided by Morph. The current version of our Editor supports three profile-based optimizations. Two of the optimizations, procedure layout and fluff removal, are designed to improve locality in the instruction reference stream <ref> [PH90] </ref>. The third is a basic block ordering optimization that improves both branch prediction and instruction reference locality [PH90, YJK97]. The Morph Monitor collects profile information for use by the Morph Editor. The Monitor collects profile samples with very low overhead, leaving subsequent processing to the Morph Manager. <p> The current version of our Editor supports three profile-based optimizations. Two of the optimizations, procedure layout and fluff removal, are designed to improve locality in the instruction reference stream [PH90]. The third is a basic block ordering optimization that improves both branch prediction and instruction reference locality <ref> [PH90, YJK97] </ref>. The Morph Monitor collects profile information for use by the Morph Editor. The Monitor collects profile samples with very low overhead, leaving subsequent processing to the Morph Manager. <p> The three code layout optimizations implemented in the Editor are branch alignment, fluff removal, and procedure layout. All are based on previous work by Pettis and Hansen <ref> [PH90] </ref>. The first optimization is branch alignment. This intra- procedural optimization reorders the program basic blocks to reduce control penalties, branch mispredictions and misfetches, and to improve instruction cache locality. We implement a greedy version of this technique, described by Young et al. [YJK97].
Reference: [Rub96] <author> N. Rubin, FX!32. </author> <booktitle> Work-in-progress talk at the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year> <note> See also http://www.digital.com/info/semiconductor/amt/fx32/ fx.html 12 </note>
Reference-contexts: Although the Morph design does not preclude the use of new hardware support for profile collection, it does not require it either. Digitals FX!32 is a system that provides transparent execution of x86 Win32 applications on Windows NT Alpha systems <ref> [CH97, Rub96] </ref>. As a part of their emulation system, execution profiles of x86 code are collected and fed to a background process that translates the previously emulated portions of x86 binaries into native Alpha code. <p> This solution has major practical drawbacks, however, as it requires new software standards and standards compliance across the software industry. Another possibility is to develop new ways of acquiring the additional information needed to derive intermediate form program representations from current executables. Digitals FX!32 <ref> [CH97, Rub96] </ref> provides an example of progress in this approach. Our PostMorph tool represents another alternative. One of the greatest barriers to obtaining conclusive results for Morph is the lack of a compelling suite of interactive benchmarks. <p> The ideal test for our system would be a suite of large, interactive benchmarks in a format that permits re- optimization. Unfortunately, source or intermediate form representations for such benchmarks are not commonly available. Recent developments in late-code optimization <ref> [CL96, Rub96, RVL97] </ref> offer some promise in addressing these issues. 6. Conclusions This paper describes a system for continuous low-overhead profile collection designed to meet the unique requirements of automatic optimization.
Reference: [RVL97] <author> T. Romer, G. Voelker, D. Lee, A. Wolman, W. Wong, B. Bershad, H. Levy, and J. B. Chen, </author> <title> Etch, an Instrumentation and Optimization tool for Win32 Programs. </title> <booktitle> To appear in Proceedings of the USENIX Windows NT Workshop, USENIX Association, </booktitle> <month> August </month> <year> 1997. </year> <note> See also http://www.cs.washington.edu/homes/bershad/Etch/ </note>
Reference-contexts: To enable optimization without source code, we assume that an intermediate-form representation of the program can be derived from the program distribution media, with all optimizations based on this intermediate form. In practice, there are a number of alternatives for achieving this, including executable editing techniques <ref> [LS95, RVL97] </ref> and compact program representations [FK96]. Optimization must be transparent to the user. We assume that the people who use computers are nonspecialists with no background in computer science or compilation. <p> These tools were designed for UNIX systems and required either an intermediate form representation of the program or an executable that includes relocation information. More recent systems for Windows NT include Spike [CL96, Goo97] and Etch <ref> [RVL97] </ref>. Both implement profile-based optimizations, Etch for the Intel x86 architecture and Spike for Digital Alpha-based systems. The Digital Continuous Profiling Infrastructure (DCPI), developed at the Digital Systems Research Center, supports continuous monitoring of the entire system including the kernel [ABD97]. <p> The ideal test for our system would be a suite of large, interactive benchmarks in a format that permits re- optimization. Unfortunately, source or intermediate form representations for such benchmarks are not commonly available. Recent developments in late-code optimization <ref> [CL96, Rub96, RVL97] </ref> offer some promise in addressing these issues. 6. Conclusions This paper describes a system for continuous low-overhead profile collection designed to meet the unique requirements of automatic optimization.
Reference: [SE94] <author> A. Srivastava and A. Eustace, </author> <title> ATOM: A System for Building Customized Program Analysis Tools. </title> <booktitle> In Proceedings of the ACM SIGPLAN 94 Conference on Programming Language Design and Implementation, ACM, </booktitle> <pages> pages 196-205, </pages> <month> June </month> <year> 1994. </year> <note> See also Research Report 94/2, </note> <institution> Western Research Laboratory, Digital Equipment Corporation. </institution>
Reference-contexts: Morph enables executable programs to evolve with changes in program usage patterns and computer hardware. This functionality is not provided by any current tool, although Morph builds on technology and techniques originally developed for program instrumentation and measurement. Several existing tools (Pixie [Smi91], ATOM <ref> [SE94] </ref>, EEL [LS95]) rewrite executables for the purpose of program measurement. These instrumentation tools differ from Morph in two important ways. <p> Our monitor achieves this goal by using statistical sampling of program activity, rather than collecting a complete profile. In most current systems, profile information is typically obtained by executing an instrumented version of the application that generates profile information as a side-effect of program execution <ref> [Smi91, SE94, LS95] </ref>. A straightforward approach for automatic profile collection would be periodic use of a higher-overhead profiling system, such as an instrumentation-based profiler.
Reference: [Smi91] <author> M. Smith, </author> <title> Tracing with Pixie. </title> <type> Technical Report CSL-TR-91-497, </type> <institution> Computer Systems Laboratory, Stanford University, Stanford, </institution> <address> CA, USA, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Morph enables executable programs to evolve with changes in program usage patterns and computer hardware. This functionality is not provided by any current tool, although Morph builds on technology and techniques originally developed for program instrumentation and measurement. Several existing tools (Pixie <ref> [Smi91] </ref>, ATOM [SE94], EEL [LS95]) rewrite executables for the purpose of program measurement. These instrumentation tools differ from Morph in two important ways. <p> Our monitor achieves this goal by using statistical sampling of program activity, rather than collecting a complete profile. In most current systems, profile information is typically obtained by executing an instrumented version of the application that generates profile information as a side-effect of program execution <ref> [Smi91, SE94, LS95] </ref>. A straightforward approach for automatic profile collection would be periodic use of a higher-overhead profiling system, such as an instrumentation-based profiler.
Reference: [Smi96] <author> M. Smith, </author> <title> Extending SUIF for Machinedependent Optimizations. </title> <booktitle> In Proceedings of the First SUIF Compiler Workshop, </booktitle> <address> Stanford, CA, </address> <pages> pages 14-25, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: We employed several custom system tools and made small modifications to Digital UNIX to support automatic profile generation, collection, and analysis. The compiler components of Morph are based on the SUIF research compiler infrastructure available from Stanford University [SUIF94]. We have extended this infrastructure to support profiledriven, machinespecific optimizations <ref> [Smi96] </ref>. We are planning support for Windows NT and the x86 ISA, as a step towards optimization of more complex interactive applications. Practical considerations led us to choose the UNIX/Alpha platform for our initial implementation, including access to source code for Digital UNIX.
Reference: [SUIF94] <author> Stanford SUIF Compiler Group, </author> <title> SUIF: A Parallelizing and Optimizing Research Compiler. </title> <type> Technical Report CSL-TR-94-620, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: We employed several custom system tools and made small modifications to Digital UNIX to support automatic profile generation, collection, and analysis. The compiler components of Morph are based on the SUIF research compiler infrastructure available from Stanford University <ref> [SUIF94] </ref>. We have extended this infrastructure to support profiledriven, machinespecific optimizations [Smi96]. We are planning support for Windows NT and the x86 ISA, as a step towards optimization of more complex interactive applications.
Reference: [SW92] <author> A. Srivastava and D. Wall, </author> <title> A Practical System for Intermodule Code Optimization at Link-Time. </title> <journal> In Journal of Programming Languages, </journal> <volume> Volume 1, Number 1, </volume> <pages> pages 1-18, </pages> <month> March </month> <year> 1993. </year> <note> See also Research Report 92/6, </note> <institution> Western Research Laboratory, Digital Equipment Corporation. </institution>
Reference-contexts: A further difference between Morph and earlier profiling tools is that Morph is designed specifically for automatic profiling and optimization. Morph applies profiledriven, machinespecific optimizations to intermediate representations of programs and libraries. Like Morph, three prior systems from Digital Equipment Corporation (Mahler [WP87], Epoxie [Wal92], OM <ref> [SW92] </ref>) also performed optimizations on programs after compilation. These tools were designed for UNIX systems and required either an intermediate form representation of the program or an executable that includes relocation information. More recent systems for Windows NT include Spike [CL96, Goo97] and Etch [RVL97].
Reference: [TDF90] <author> G. Taylor, P. Davies, and M. Farmwald, </author> <title> The TLB Slice A Low-Cost HighSpeed Address Translation Mechanism. </title> <booktitle> In Proceedings of the 17 th Annual International Symposium on Computer Architecture, ACM, </booktitle> <pages> pages 355-363, </pages> <year> 1990. </year>
Reference-contexts: The standard Digital UNIX kernel uses a bin-hopping policy for allocation of physical memory pages. Although this policy has some desirable performance characteristics [KH92], it has the undesirable property of poor repeatability. For our overhead measurement experiments, we replaced the bin-hopping policy with page coloring <ref> [TDF90] </ref>, a deterministic policy, to improve the repeatability of our experiments. All results reported in this section use the page coloring policy. The problems and pitfalls of page mapping algorithms are well documented in the research literature [KH92, CB93, BCL94].
Reference: [Wal92] <author> D. Wall, </author> <title> Systems for Late Code Modification. In Code Generation - Concepts, Tools, Techniques, </title> <publisher> Springer-Verlag, </publisher> <pages> pages 275-293, </pages> <year> 1992. </year>
Reference-contexts: A further difference between Morph and earlier profiling tools is that Morph is designed specifically for automatic profiling and optimization. Morph applies profiledriven, machinespecific optimizations to intermediate representations of programs and libraries. Like Morph, three prior systems from Digital Equipment Corporation (Mahler [WP87], Epoxie <ref> [Wal92] </ref>, OM [SW92]) also performed optimizations on programs after compilation. These tools were designed for UNIX systems and required either an intermediate form representation of the program or an executable that includes relocation information. More recent systems for Windows NT include Spike [CL96, Goo97] and Etch [RVL97].
Reference: [WP87] <author> D. Wall and M. Powell, </author> <title> The Mahler Experience: Using an Intermediate Language as the Machine Description. </title> <booktitle> In Second International Symposium on Architectural Support for Programming Languages and Operating Systems, ACM, </booktitle> <month> April </month> <year> 1987. </year> <note> See also Research Report 87/1, </note> <institution> Western Research Laboratory, Digital Equipment Corporation. </institution>
Reference-contexts: A further difference between Morph and earlier profiling tools is that Morph is designed specifically for automatic profiling and optimization. Morph applies profiledriven, machinespecific optimizations to intermediate representations of programs and libraries. Like Morph, three prior systems from Digital Equipment Corporation (Mahler <ref> [WP87] </ref>, Epoxie [Wal92], OM [SW92]) also performed optimizations on programs after compilation. These tools were designed for UNIX systems and required either an intermediate form representation of the program or an executable that includes relocation information. More recent systems for Windows NT include Spike [CL96, Goo97] and Etch [RVL97].
Reference: [YJK97] <author> C. Young, D. Johnson, D. Karger, and M. Smith, </author> <title> Near-optimal Intraprocedural Branch Alignment. </title> <booktitle> To appear in Proceedings of the ACM SIGPLAN 97 Conference on Programming Language Design and Implementation, ACM, </booktitle> <pages> pages 183-192, </pages> <month> June </month> <year> 1997. </year> <month> 13 </month>
Reference-contexts: The current version of our Editor supports three profile-based optimizations. Two of the optimizations, procedure layout and fluff removal, are designed to improve locality in the instruction reference stream [PH90]. The third is a basic block ordering optimization that improves both branch prediction and instruction reference locality <ref> [PH90, YJK97] </ref>. The Morph Monitor collects profile information for use by the Morph Editor. The Monitor collects profile samples with very low overhead, leaving subsequent processing to the Morph Manager. <p> The first optimization is branch alignment. This intra- procedural optimization reorders the program basic blocks to reduce control penalties, branch mispredictions and misfetches, and to improve instruction cache locality. We implement a greedy version of this technique, described by Young et al. <ref> [YJK97] </ref>. The algorithm considers the edge frequencies in order of decreasing weight and attempts to place the blocks at the ends of an edge adjacent to each other so that the control penalties are minimized. Fluff removal follows branch alignment.
References-found: 31

