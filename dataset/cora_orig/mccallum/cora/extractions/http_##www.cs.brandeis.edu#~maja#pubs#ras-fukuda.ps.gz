URL: http://www.cs.brandeis.edu/~maja/pubs/ras-fukuda.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~maja/publications.html
Root-URL: http://www.cs.brandeis.edu
Email: maja@cs.brandeis.edu  davec@cogs.susx.ac.uk  
Phone: fax: +1 617 736-2741,  2  fax: +44 1 273 671320,  
Title: Challenges in Evolving Controllers for Physical Robots  
Author: Maja Mataric and Dave Cliff 
Address: Waltham, MA 02254, USA,  Brighton BN1 9QH, UK,  
Affiliation: 1 Volen Center, Computer Science Department, Brandeis University,  School of Cognitive and Computing Sciences, University of Sussex,  
Abstract: This paper discusses the feasibility of applying evolutionary methods to automatically generating controllers for physical mobile robots. We overview the state of the art in the field, describe some of the main approaches, discuss the key challenges, unanswered problems, and some promising directions.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aizawa, A. N. & Wah, B. W. </author> <year> (1994), </year> <title> `Scheduling of Genetic Algorithms in a Noisy Environment', </title> <booktitle> Evolutionary Computation 2(2), </booktitle> <pages> 97-122. </pages>
Reference: <author> Beer, R. D. </author> <year> (1995), </year> <title> `On the Dynamics of Small Continuous-Time Recurrent Neural Networks', </title> <booktitle> Adaptive Behavior 3(4), </booktitle> <pages> 471-511. </pages>
Reference-contexts: Beer's analysis of the dynamics of small CTRNN circuits <ref> (Beer 1995) </ref> indicates that particular simple circuits, of one or two neurons, could constitute very useful building blocks for evolving larger CTRNNs with rich intrinsic dynamics. Nevertheless, Koza's ADF concept can still be employed, in the manner demonstrated by Gruau.
Reference: <author> Beer, R. D. & Gallagher, J. C. </author> <year> (1991), </year> <title> `Evolving Dynamical Neural Networks for Adaptive Behaviour', </title> <booktitle> Adaptive Behaviour 1(1), </booktitle> <pages> 91-122. </pages>
Reference: <author> Brooks, R. A. </author> <year> (1986), </year> <title> `A Robust Layered Control System for a Mobile Robot', </title> <journal> IEEE Journal of Robotics and Automation RA-2, </journal> <pages> 14-23. </pages>
Reference-contexts: Genetic programming has been applied to evolving navigation and wall following in a simulated sonar-based robot. The goal of the project was to demonstrate that genetic programming can be used to evolve a subsumption-style <ref> (Brooks 1986) </ref> robot controller represented with Lisp S-expressions, and compare it to an existing robotic system developed by Mataric (1992).
Reference: <author> Brooks, R. A. </author> <year> (1991), </year> <title> Intelligence Without Reason, </title> <booktitle> in `Proceedings, IJCAI-91'. </booktitle>
Reference-contexts: As the complexity of behaviors scales up, the need to o*oad much of the experimentation and evaluation to a simulation will increase. 3.2 Evolving in Simulation * Noise and Error Models: The difficulty of accurately simulating physical systems is well known in robotics <ref> (Brooks 1991) </ref>. Since it is impossible to simulate all details of a physical system, any abstraction made in a simulation may be exploited by the genetic algorithm and result in behavior that is maladaptive in the real world.
Reference: <author> Brooks, R. A. </author> <year> (1992), </year> <title> Artificial Life and Real Robots, </title> <booktitle> in `Proceedings, To--ward a Practice of Autonomous Systems, First European Conference on Artificial Life (ECAL)', </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <pages> pp. 3-10. </pages>
Reference-contexts: To this end, Harvey (1992a) developed a specialized crossover procedure for variable-length genotypes. In many autonomous agent applications, it is highly desirable to have some degree of symmetry, both in morphology and in the responses of the controller <ref> (Brooks 1992) </ref>. Using n-fold symmetry can, in principle, reduce the length of the genotype by a factor of n: for instance, with two-fold (e.g. bilateral) symmetry, the left-hand-side of the controller/morphology can be specified on the genome, while the right-hand-side can be generated by reflection in the appropriate axial plane.
Reference: <author> Cliff, D. & Miller, G. F. </author> <year> (1995), </year> <title> Tracking the Red Queen: Measurements of Adaptive Progress in Co-Evolutionary Simulations, </title> <editor> in F. Moran, A. Moreno, J. J. Merelo & P.Chacon, eds, </editor> <booktitle> `Advances in Artificial Life: Proceedings of the Third International Conference on Artificial Life', </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 200-218. </pages>
Reference-contexts: The resulting controller networks were analyzed using a number of techniques: qualitative studies of the functional architecture of the network (Cliff, Husbands & Harvey 1992) and the effects of noise (Cliff, Harvey & Husbands 1993a); and quantitative studies based on dynamical systems analysis <ref> (Husbands, Harvey & Cliff 1995) </ref>. Sims (1994) demonstrated a methodology for jointly evolving morphologies and controllers for embodied three-dimensional creatures. The creatures had realistic mass and inertial properties, and were situated in a physically-based dynamical simulation. <p> In co-evolutionary systems, cycles through genotype space are possible, and limited "genetic memory" can lead to an overall reduction in performance levels of the evolved controllers see <ref> (Cliff & Miller 1995) </ref> for further details. Nevertheless, it may be possible to automatically detect such situations and take appropriate actions (Cliff & Miller 1995), in which case co-evolution promises to be an approach with considerable potential. 3.6 Genetic Encodings Using evolutionary techniques to generate robot control systems requires that parameters <p> In co-evolutionary systems, cycles through genotype space are possible, and limited "genetic memory" can lead to an overall reduction in performance levels of the evolved controllers see <ref> (Cliff & Miller 1995) </ref> for further details. Nevertheless, it may be possible to automatically detect such situations and take appropriate actions (Cliff & Miller 1995), in which case co-evolution promises to be an approach with considerable potential. 3.6 Genetic Encodings Using evolutionary techniques to generate robot control systems requires that parameters determining the nature of the controller are encoded in a manner suitable for use in a genetic algorithm.
Reference: <author> Cliff, D., Harvey, I. & Husbands, P. </author> <year> (1993a), </year> <title> Evolved Recurrent Dynamical Networks Use Noise, </title> <editor> in S. Gielen & B. Kappen, eds, </editor> <booktitle> `Proceedings of the International Conference on Artificial Neural Networks (ICANN93)', </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 285-288. </pages>
Reference-contexts: The resulting controller networks were analyzed using a number of techniques: qualitative studies of the functional architecture of the network (Cliff, Husbands & Harvey 1992) and the effects of noise <ref> (Cliff, Harvey & Husbands 1993a) </ref>; and quantitative studies based on dynamical systems analysis (Husbands, Harvey & Cliff 1995). Sims (1994) demonstrated a methodology for jointly evolving morphologies and controllers for embodied three-dimensional creatures. The creatures had realistic mass and inertial properties, and were situated in a physically-based dynamical simulation.
Reference: <author> Cliff, D., Harvey, I. & Husbands, P. </author> <year> (1993b), </year> <title> `Explorations in Evolutionary Robotics', </title> <booktitle> Adaptive Behavior 2(1), </booktitle> <pages> 71-108. </pages>
Reference: <author> Cliff, D., Husbands, P. & Harvey, I. </author> <year> (1992), </year> <title> Analysis of Evolved Sensory Motor Controllers, </title> <type> Technical Report CSRP 264, </type> <institution> School of Cognitive and Computing Sciences, Sussex University. </institution> <note> Presented at the Second Euro-pean Conference on Artificial Life (ECAL93); unpublished proceedings. </note>
Reference-contexts: The robot was evolved to perform a simple visually guided behavior: to find its way to the center of a circular room. The resulting controller networks were analyzed using a number of techniques: qualitative studies of the functional architecture of the network <ref> (Cliff, Husbands & Harvey 1992) </ref> and the effects of noise (Cliff, Harvey & Husbands 1993a); and quantitative studies based on dynamical systems analysis (Husbands, Harvey & Cliff 1995). Sims (1994) demonstrated a methodology for jointly evolving morphologies and controllers for embodied three-dimensional creatures.
Reference: <author> Colombetti, M. & Dorigo, M. </author> <year> (1993), </year> <title> Learning to Control an Autonomous Robot by Distributed Genetic Algorithms, </title> <editor> in J.-A. Meyer, H. L. Roitblat & S. W. Wilson, eds, </editor> <booktitle> `Proceedings, Simulation of Adaptive Behavior SAB-92', </booktitle> <publisher> MIT Press, </publisher> <pages> pp. 305-311. </pages>
Reference-contexts: Consequently, much of the analysis is qualitative and based on human judgement. While human observers can apply reasonable phenomenological performance descriptions, relevant quantitative analysis is rare <ref> (Colombetti & Dorigo 1993) </ref>. Average performance is difficult to establish as trials vary significantly, and due to the overhead of physical experiments as well as their variability, typically insufficient data are available for statistically significant analysis.
Reference: <author> Colombetti, M. & Dorigo, M. </author> <year> (1994), </year> <title> `Training Agents to Perform Sequential Behavior', </title> <booktitle> Adaptive Behavior 2(3), </booktitle> <pages> 247-276. </pages>
Reference: <author> Floreano, D. </author> <year> (1993), </year> <title> Patterns of Interactions in Shared Environments, in `Toward A Practice of Autonomous Systems: </title> <booktitle> Proceedings of the First European Conference on Artificial Life', </booktitle> <pages> pp. 347-366. </pages>
Reference: <author> Floreano, D. & Mondada, F. </author> <year> (1994), </year> <title> Automatic Creation of an Autonomous Agent: Genetic Evolution of a Neural-Network Driven Robot, </title> <booktitle> in `Simulation of Adaptive Behavior SAB-94', </booktitle> <pages> pp. 421-430. </pages> <note> 30 Floreano, </note> <author> D. & Mondada, F. </author> <year> (1996), </year> <title> `Evolution of Homing Navigation in a Real Mobile Robot', </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics. </journal>
Reference-contexts: This section describes them in turn. 3.1 Evolving on Physical Robots * Real Time on Real Hardware: Evolution on physical systems takes prohibitively long. As demonstrated by the successful example of evolv 17 ing collision-free navigation on a Khepera <ref> (Floreano & Mondada 1994) </ref>, at an approximately 39 minutes per generation and a hundred generations, 65 hours were required to evolve the desired behavior.
Reference: <author> Funahashi, K. & Nakamura, Y. </author> <year> (1993), </year> <title> `Approximation of Dynamical Systems by continuous time recurrent neural networks', </title> <booktitle> neural networks 6, </booktitle> <pages> 801-806. </pages>
Reference-contexts: Furthermore, as Beer (1995) notes, a particular class of continuous-time recurrent neural networks (CTRNNs) has the added attraction of being universal dynamics approximators, i.e. the trajectory of any smooth dynamical system can be approximated by such networks <ref> (Funahashi & Nakamura 1993) </ref>. Beer's analysis of the dynamics of small CTRNN circuits (Beer 1995) indicates that particular simple circuits, of one or two neurons, could constitute very useful building blocks for evolving larger CTRNNs with rich intrinsic dynamics.
Reference: <author> Gallagher, J. C. & Beer, R. D. </author> <year> (1994), </year> <title> Application of evolved locomotion controllers to a hexapod robot, </title> <type> Technical report CES-94-7, </type> <institution> Case Western Reserve University Department of Computer Engineering and Science. </institution>
Reference: <author> Grefenstette, J. & Schultz, A. </author> <year> (1994), </year> <title> An Evolutionary Approach to Learning in Robots, </title> <booktitle> in `Proceedings, Machine Learning Workshop on Robot Learning', </booktitle> <address> New Brunswick, NJ. </address>
Reference-contexts: However, even through the efficiency of the real robot behavior was improved through the introduction of sensor noise in the simulation, a significant difference between the simulated and real navigation trajectories persisted (Nolfi et al. 1994). Work by Grefenstette and Schultz <ref> (Grefenstette & Schultz 1994) </ref>, also describes an application of genetic algorithms, within a classifier system SAMUEL, to the problem of learning collision-free navigation in simulation, and transferring those to a mobile robot.
Reference: <author> Gruau, F. </author> <year> (1994), </year> <title> `Automatic Definition of Modular Neural Networks', </title> <booktitle> Adaptive Behavior 3(2), </booktitle> <pages> 151-183. </pages>
Reference: <author> Harvey, I. </author> <year> (1990), </year> <title> The Artificial Evolution of Behaviour, </title> <editor> in J.-A. Meyer & S. W. Wilson, eds, </editor> <booktitle> `From Animals to Animats: Proceedings of the First International Conference on the Simulation of Adaptive Behavior', </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The widest possible range is given by allowing the length of the genotypes to be variable, as in Koza's genetic programming. Harvey <ref> (Har-vey 1990, Harvey 1992b, Harvey 1993, Harvey 1992a) </ref> has developed the species adaptation genetic algorithm (saga) explicitly for dealing with variable length genotypes.
Reference: <author> Harvey, I. </author> <year> (1992a), </year> <title> The SAGA Cross: the Mechanics of Crossover for Variable-length Genetic Algorithms, </title> <editor> in R. Manner & B. Manderick, eds, </editor> <title> `Parallel Problem Solving from Nature, 2', </title> <publisher> North-Holland, </publisher> <pages> pp. 269-278. </pages> <note> Also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP223. </note>
Reference: <author> Harvey, I. </author> <year> (1992b), </year> <title> Species Adaptation Genetic Algorithms: A Basis for a Continuing SAGA, </title> <editor> in F. Varela & P. Bourgine, eds, </editor> <title> `Towards a Practice of Autonomous Systems: </title> <booktitle> Proceedings of the First European Conference on Artificial Life (ECAL91)', </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <pages> pp. 346-354. </pages> <note> Also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP221. </note>
Reference: <author> Harvey, I. </author> <year> (1993), </year> <title> Evolutionary Robotics and SAGA: the case for Hill Crawling and Tournament Selection, </title> <editor> in C. Langton, ed., </editor> <booktitle> `Artificial Life 3 31 Proceedings', Santa Fe Institute Studies in the Sciences of Complexity, Proc. </booktitle> <volume> Vol. </volume> <pages> XVI, </pages> <note> Addison Wesley. Forthcoming; also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP222, </note> <year> 1992. </year>
Reference-contexts: During an evaluation, the instantaneous input to the sensory unit was an estimate of the instantaneous average image intensity of the pixels within the unit's receptive field. The gantry was used to demonstrate the principle of incremental evolution <ref> (Harvey 1993) </ref>. Rather than starting with a population of random genotypes when attempting to evolve controllers to achieve some challenging task, it is better to evolve from a population which has already been selected for a similar but less-challenging task.
Reference: <author> Harvey, I., Husbands, P. & Cliff, D. </author> <year> (1994), </year> <title> Seeing the Light: Artificial Evolution; Real Vision, </title> <editor> in D. Cliff, P. Husbands, J.-A. Meyer & S. W. Wilson, eds, </editor> <booktitle> `From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior (SAB94)', </booktitle> <publisher> MIT Press Bradford Books, </publisher> <pages> pp. 392-401. </pages>
Reference: <author> Hillis, W. D. </author> <year> (1990), </year> <title> `Co-evolving Parasites Improve Simulated Evolution as an Optimization Procedure', </title> <journal> Physica D 42, </journal> <pages> 228-234. </pages>
Reference-contexts: such solutions can be very elegant (e.g., see Nolfi et al. (1994) for a clever example used in evolving object size discrimination), they are not general and do not scale to more complex robot behaviors. 3.5 Co-evolution Co-evolution has been shown to be a powerful method for searching fitness landscapes <ref> (Hillis 1990, Lund 1995) </ref>.
Reference: <author> Husbands, P., Harvey, I. & Cliff, D. </author> <year> (1995), </year> <title> `Circle in the Round: State Space Attractors for Evolved Sighted Robots', </title> <booktitle> Robotics and Autonomous Systems 15, </booktitle> <pages> 83-106. </pages>
Reference-contexts: The resulting controller networks were analyzed using a number of techniques: qualitative studies of the functional architecture of the network (Cliff, Husbands & Harvey 1992) and the effects of noise (Cliff, Harvey & Husbands 1993a); and quantitative studies based on dynamical systems analysis <ref> (Husbands, Harvey & Cliff 1995) </ref>. Sims (1994) demonstrated a methodology for jointly evolving morphologies and controllers for embodied three-dimensional creatures. The creatures had realistic mass and inertial properties, and were situated in a physically-based dynamical simulation.
Reference: <author> Jakobi, N. </author> <year> (1994), </year> <title> Evolving sensorimotor control architectures in simulation for a real robot, </title> <type> Master's thesis, </type> <institution> University of Sussex School of Cognitive and Computing Sciences. </institution> <note> Unpublished. </note>
Reference: <author> Jakobi, N., Husbands, P. & Harvey, I. </author> <year> (1995), </year> <title> Noise and the Reality Gap: The Use of Simulation in Evolutionary Robotics, </title> <editor> in F. Moran, A. Moreno, J. J. Merelo & P.Chacon, eds, </editor> <booktitle> `Advances in Artificial Life: Proceedings of the Third International Conference on Artificial Life', </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 704-720. </pages>
Reference: <author> Koza, J. R. </author> <year> (1990), </year> <title> Evolution of Subsumption Using Genetic Programming, </title> <editor> in F. J. Varela & P. Bourgine, eds, </editor> <booktitle> `Proceedings, First European Conference on Artificial Life', </booktitle> <publisher> MIT Press, </publisher> <pages> pp. 110-119. </pages>
Reference-contexts: The genetic algorithm utilized many of Mataric's hand-crafted sensing and action primitives, including minimum overall sonar distance, minimum safe distance, edging distance, as well as control functions including move backwards by a fixed amount, turn right, turn left, and move forward <ref> (Koza 1990) </ref>. Other primitives, such as stopping, were eliminated in the simulation, and all twelve simulated sonar readings were used, unlike the hand-crafted solution which only relied on the front and lateral readings.
Reference: <author> Koza, J. R. </author> <year> (1992), </year> <title> Genetic Programming, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Finally, an even smaller number has evolved directly on physical robotic systems in real time. This section reviews selected research from each of the areas in turn. 2.1 Genetic Programming in Simulation Genetic programming (GP), introduced by John Koza <ref> (Koza 1992, Koza 1990) </ref>, is one of the more popular approaches to evolving controllers in simulation. Unlike genetic algorithms, which typically operate on bit strings, GP manipulates higher-level primitive constructs such as Lisp programs.
Reference: <author> Koza, J. R. </author> <year> (1994), </year> <title> Genetic Programming II: Automatic Discovery of Reusable Programs, </title> <publisher> MIT Press. </publisher>
Reference-contexts: Gruau (1994) has developed a modular encoding scheme for neural networks, inspired by Koza's work on gene-splicing for automatically defined functions (ADF's) <ref> (Koza 1994) </ref>. In Gruau's scheme, the genotype specifies a sequence of graph-rewrite operations which are applied to an initial graph consisting of a single neuron: many 24 of the rewrite operators generate one or more new neurons via a process of "cell-division".
Reference: <author> Koza, J. R. & Rice, J. P. </author> <year> (1992), </year> <title> Automatic Programming of Robots Using Genetic Programming, </title> <booktitle> in `Proceedings, AAAI-92', </booktitle> <publisher> MIT Press, </publisher> <pages> pp. 194-201. </pages>
Reference-contexts: Finally, an even smaller number has evolved directly on physical robotic systems in real time. This section reviews selected research from each of the areas in turn. 2.1 Genetic Programming in Simulation Genetic programming (GP), introduced by John Koza <ref> (Koza 1992, Koza 1990) </ref>, is one of the more popular approaches to evolving controllers in simulation. Unlike genetic algorithms, which typically operate on bit strings, GP manipulates higher-level primitive constructs such as Lisp programs.
Reference: <author> Lund, H. H. </author> <year> (1995), </year> <title> Specialization under Social Conditions in Shared Envi--ronments, </title> <booktitle> in `Proceedings, Advances in Artificial Life, Third European Conference on Artificial Life (ECAL)', </booktitle> <pages> pp. 477-489. </pages>
Reference-contexts: It has been particularly successful for evolving robust cooperative and competitive behaviors in societies <ref> (Lund 1995) </ref>, but has not yet been applied to evolving controllers for physical robots; the co-evolutionary simulations discussed above (Sims 1994, Reynolds 1994a) are not intended to result in the controllers for real robots.
Reference: <author> Mahadevan, S. & Connell, J. </author> <year> (1991), </year> <title> Automatic Programming of Behavior-based Robots using Reinforcement Learning, </title> <booktitle> in `Proceedings, AAAI-91', </booktitle> <address> Pittsburgh, PA, </address> <pages> pp. 8-14. </pages>
Reference: <author> Mataric, M. J. </author> <year> (1992), </year> <title> `Integration of Representation Into Goal-Driven Behavior-Based Robots', </title> <journal> IEEE Transactions on Robotics and Automation 8(3), </journal> <pages> 304-312. </pages>
Reference: <author> Mataric, M. J. </author> <year> (1994a), </year> <note> Learning to Behave Socially, </note> <editor> in D. Cliff, P. Husbands, J.-A. Meyer & S. Wilson, eds, </editor> <booktitle> `From Animals to Animats: International Conference on Simulation of Adaptive Behavior', </booktitle> <pages> pp. 453-462. </pages>
Reference: <author> Mataric, M. J. </author> <year> (1994b), </year> <title> Reward Functions for Accelerated Learning, </title> <editor> in W. </editor> <publisher> W. </publisher>
Reference-contexts: The use of shaping and basic primitive behaviors blurs the line between evolution and learning. For instance, work by Nolfi & Parisi (1995) employs basic behaviors (rather than motor velocities or even low-level actions) and a shaped fitness function, both of which have been successfully employed in robot learning <ref> (Mataric 1994b) </ref>. While these approaches utilize the programmer's expertise and thus bias the learning/evolution process in order to simplify and accelerate, they may be necessary in order to scale up the existing approaches to any realistic robotic behaviors and tasks.
Reference: <editor> Cohen & H. Hirsh, eds, </editor> <booktitle> `Proceedings of the Eleventh International Conference on Machine Learning (ML-94)', </booktitle> <publisher> Morgan Kauffman Publishers, Inc., </publisher> <address> New Brunswick, NJ, </address> <pages> pp. 181-189. </pages>
Reference: <author> Mataric, M. J. </author> <year> (1995), </year> <title> Evaluation of Learning Performance of Situated Embodied Agents, </title> <booktitle> in `Proceedings, Advances in Artificial Life, Third Eu-ropean Conference on Artificial Life (ECAL)', </booktitle> <pages> pp. 579-589. </pages>
Reference-contexts: Average performance is difficult to establish as trials vary significantly, and due to the overhead of physical experiments as well as their variability, typically insufficient data are available for statistically significant analysis. Since this problem is endemic in physical system evaluation <ref> (Mataric 1995) </ref> it must be addressed by the evolu tionary robotics community. 3.4 Fitness Function Design * Complexity of Design: The process of designing an evaluation function for behavior evolution on a robot is delicate and laborious (Mon 20 dada & Floreano 1996).
Reference: <author> Miglino, O., Lund, H. H. & Nolfi, S. </author> <year> (1995), </year> <title> Evolving Mobile Robots in Simulated and Real Environments, </title> <type> Technical Report Technical Report 95-04, </type> <institution> Institute of Psychology, C.N.R. - Rome. </institution>
Reference: <author> Mondada, F. & Floreano, D. </author> <year> (1996), </year> <title> `Evolution of Neural Control Structures: Some Experiments on Mobile Robots', </title> <booktitle> Robotics and Autonomous Systems. </booktitle>
Reference-contexts: The evolved behavior kept the robot wandering around its world until its internal battery level reached a low level, then taking a short path toward the light. The authors also describe the evolution of a simple grasping behavior <ref> (Mondada & Floreano 1996) </ref> by adding graspable balls to the environment, a simple gripper to the robot, and introducing gripping to the action set. The fitness function was based purely on the number of grasped objects.
Reference: <author> Nolfi, S. & Parisi, D. </author> <year> (1995), </year> <title> Evolving Non-trivial Behaviors on Real Robots: An Autonomous Robot that Picks Up Objects, </title> <booktitle> in `Proceedings, the Fourth Congress of the Italian Association for Artificial Intelligence', </booktitle> <publisher> Springer Verlag, </publisher> <address> Firenze. </address> <note> 33 Nolfi, </note> <author> S., Floreano, D., Miglino, O. & Mondada, F. </author> <year> (1994), </year> <title> Now to Evolve Autonomous Robots: </title> <booktitle> Different Approaches in Evolutionary Robotics, in `Proceedings, Artificial Life IV', </booktitle> <pages> pp. 190-197. </pages>
Reference-contexts: The authors have also evolved a grasping behavior on the Khepera, using the same simulator <ref> (Nolfi & Parisi 1995) </ref>. After some trial and error, they chose a 5-input 4-output network with no hidden units. The inputs included two frontal sensors, the average of the two left and two right side sensors, and the gripper sensor. <p> The work on evolving effective grasping behavior <ref> (Nolfi & Parisi 1995) </ref> has already demonstrated that, as more complex behaviors are evolved that involve the interaction of multiple goals and subgoals, the more complex the fitness functions becomes. To date, the designers have resorted to almost indirectly embedding all of the subgoals into the fitness function.
Reference: <author> Reynolds, C. </author> <year> (1993), </year> <title> An Evolved, Vision-Based Behavioral Model of Coordinated Group Motion, </title> <editor> in J.-A. Meyer, H. Roitblat & S. Wilson, eds, </editor> <booktitle> `Proceedings of the Second International Conference on Simulation of Adaptive Behaviour (SAB92)', </booktitle> <publisher> MIT Press Bradford Books, </publisher> <address> Cambridge, MA, </address> <pages> pp. 384-393. </pages>
Reference: <author> Reynolds, C. </author> <year> (1994a), </year> <title> Competition, Coevolution, and the Game of Tag, </title> <editor> in R. Brooks & P. Maes, eds, </editor> <booktitle> `Artificial Life IV', </booktitle> <publisher> MIT Press, </publisher> <pages> pp. 59-69. </pages>
Reference: <author> Reynolds, C. </author> <year> (1994b), </year> <title> Evolution of Corridor Following Behavior in a Noisy World, </title> <editor> in D. Cliff, P. Husbands, J.-A. Meyer & S. W. Wilson, eds, </editor> <booktitle> `From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior (SAB94)', </booktitle> <publisher> MIT Press Bradford Books, </publisher> <pages> pp. 402-410. </pages>
Reference: <author> Schultz, A. C. </author> <year> (1991), </year> <title> Using a Genetic Algorithm to Learn Strategies for Collision Avoidance and Local Navigation, </title> <booktitle> in `Proceedings, Seventh International Symposium on Unmanned Untethered, Submersible Technology', </booktitle> <address> Durham, </address> <publisher> NH, </publisher> <pages> pp. 213-225. </pages>
Reference: <author> Sims, K. </author> <year> (1994), </year> <title> Evolving 3D Morphology and Behavior by Competition, </title> <booktitle> in `Proceedings, Alife IV', </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <pages> pp. 28-39. </pages>
Reference-contexts: Any stochastic components in the algorithms compound the problem. Simulation designers have the luxury of eliminating non-determinism in order to create repeatable trials <ref> (Sims 1994) </ref>, but the results are not necessarily relevant in the physical, nondeterministic environment. The problems of variation and noise in evaluation are well known in the evolutionary computation community. This issue is particularly important in evolving architectures for autonomous agents. <p> It has been particularly successful for evolving robust cooperative and competitive behaviors in societies (Lund 1995), but has not yet been applied to evolving controllers for physical robots; the co-evolutionary simulations discussed above <ref> (Sims 1994, Reynolds 1994a) </ref> are not intended to result in the controllers for real robots. However, as 21 a method for accelerating evolution, co-evolution could be applied both in simulation and on a physical group of robots.
Reference: <author> Thompson, A. </author> <year> (1995), </year> <title> Evolving Electronic Robot Controllers that Exploit Hardware Resources, </title> <editor> in F. Moran, A. Moreno, J. J. Merelo & P.Chacon, eds, </editor> <booktitle> `Advances in Artificial Life: Proceedings of the Third International Conference on Artificial Life', </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 640-656. </pages>
Reference: <author> Yamauchi, B. M. & Beer, R. D. </author> <year> (1994), </year> <title> Integrating Reactive, Sequential, and Learning Behavior using Dynamical Neural Networks, </title> <editor> in D. Cliff, P. Husbands, J.-A. Meyer & S. W. Wilson, eds, </editor> <booktitle> `From Animals to An-imats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior (SAB94)', </booktitle> <publisher> MIT Press Bradford Books, </publisher> <pages> pp. 382-391. </pages>
References-found: 48

