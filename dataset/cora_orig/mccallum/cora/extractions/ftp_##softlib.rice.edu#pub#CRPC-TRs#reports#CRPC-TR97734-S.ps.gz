URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR97734-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: OPTIMIZATION USING SURROGATE OBJECTIVES ON A HELICOPTER TEST EXAMPLE  
Author: ANDREW J. BOOKER J. E. DENNIS, JR. PAUL D. FRANK DAVID B. SERAFINI AND VIRGINIA TORCZON 
Abstract: This paper presents results for a 31 variable helicopter rotor design example. Results are given for several numerical methods. This is a brief description of a portion of the Boe-ing/IBM/Rice University collaboration whose purpose is to develop effective numerical methods for managing the use of approximation concepts or response surface methodology in design optimization. 1. Introduction. The purpose of this paper is to present preliminary numerical 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jean-Francois M. Barthelemy and Raphael T. Haftka. </author> <title> Approximation concepts for optimum structural design a review. </title> <journal> Structural Optimization, </journal> <volume> 5 </volume> <pages> 129-144, </pages> <year> 1993. </year>
Reference-contexts: Current practice (See the contribution to this volume by B. Grossman and [5], <ref> [1] </ref>, [6] [14]) is to sample widely in design variable space, build a response surface model of the expensive high fidelity objective, and possibly of the constraints, and then to use the models as surrogates for the high fidelity objective function and constraints in doing optimization on the problem posed using
Reference: [2] <author> A. J. Booker, A. R. Conn, J. E. Dennis, Jr, Paul D. Frank, Michael Trosset, and Virginia Torczon. </author> <title> Global modeling for optimization: Boeing/IBM/Rice collaborative project 1995 final report. </title> <type> Technical Report ISSTECH-95-032, </type> <institution> Boeing Information Support Services, Research and Technology, </institution> <address> Box 3707, M/S 7L-68, Seattle, Washington 98124, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: The numbers reported for GA are the total number of values requested. It performs as advertised nice initial decrease and then leveling out. It makes little progress after 1500 evaluations and terminates at 3300 evaluations. * BLGS: This is an intuitively appealing method of Booker and Frank <ref> [2] </ref> in which several truth values are computed at each iteration. The number of expensive evaluations allocated to each iteration is fixed, in this case at 50.
Reference: [3] <author> A. J. Booker, J. E. Dennis, Jr., Paul D. Frank, David B. Serafini, Michael Trosset, and Virginia Torczon. </author> <title> A rigorous framework for optimization of expensive functions by surrogates. </title> <note> In preparation, </note> <year> 1997. </year>
Reference-contexts: This note forms a brief summary of a portion of the doctoral dissertation of David Serafini. More detail and more results can be found in [21] and <ref> [3] </ref>. The premise of our work is summed up in the following list: * Many optimal design problems are too computationally expensive for direct application of optimization codes. * Gradient methods may be inconvenient to apply and likely to converge to design refinements rather than breakthrough designs.
Reference: [4] <author> A. J. Booker, Paul D. Frank, A. R. Conn, J. E. Dennis, Jr., David B. Serafini, Virginia Torczon, and Michael Trosset. </author> <title> Multi-level design optimization: Boeing/IBM/Rice collaborative project 1996 final report. </title> <type> Technical Report ISSTECH-96-031, </type> <institution> Boeing Computer Services, Research and Technology, </institution> <address> Box 3707, M/S 7L-68, Seattle, Washington 98124, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: OAs are for box-constrained regions. To create a design meeting the mass constraint, we generated a large design in the box B defined by the variable bounds, and then we kept all the points in that design inside a slightly expanded constraint boundary. <ref> [4] </ref> The surrogates are from a class of flexible models that can be adjusted locally to some extent as new points are added. They are motivated by the supposition that the output being modeled is a realization of a Gaussian spatial process.
Reference: [5] <author> G. E. P. </author> <title> Box. The exploration and exploitation of response surfaces: Some general considerations and examples. </title> <journal> Biometrics, </journal> <volume> 10 </volume> <pages> 16-60, </pages> <month> March </month> <year> 1954. </year>
Reference-contexts: Current practice (See the contribution to this volume by B. Grossman and <ref> [5] </ref>, [1], [6] [14]) is to sample widely in design variable space, build a response surface model of the expensive high fidelity objective, and possibly of the constraints, and then to use the models as surrogates for the high fidelity objective function and constraints in doing optimization on the problem posed
Reference: [6] <author> S. L. Burgee, A. A. Giunta, V. Balabanov, B. Grossman, W. H. Mason, R. Narducci, R. T. Haftka, and L. T. Watson. </author> <title> A coarse grained parallel variable-complexity multidisciplinary optimization program. </title> <type> Technical Report 95-20, </type> <institution> Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, </institution> <address> VA 24061, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: Current practice (See the contribution to this volume by B. Grossman and [5], [1], <ref> [6] </ref> [14]) is to sample widely in design variable space, build a response surface model of the expensive high fidelity objective, and possibly of the constraints, and then to use the models as surrogates for the high fidelity objective function and constraints in doing optimization on the problem posed using the
Reference: [7] <author> A. R. Conn, K. Scheinberg, and Ph. L. Toint. </author> <title> On the convergence of derivative-free methods for unconstrained optimization. </title> <type> Technical Report 96/10, </type> <institution> Department of Mathematics, Faculte Universitaires, </institution> <address> B-5000 Namur, Belgium, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: Starting DFO in this way would completely eliminate the variability in the DFO results caused by taking a random first step. [8], <ref> [7] </ref>. 4 4. Sample Test Results. In this section, we will present a graphical summary of the test results so far for the 31 variable constant wake helicopter rotor design example.
Reference: [8] <author> A. R. Conn and Ph. L. Toint. </author> <title> An algorithm using quadratic interpolation for unconstrained derivative free optimization. </title> <editor> In Gianni Di Pillo and Franco Giannessi, editors, </editor> <title> Nonlinear Optimization and Applications. </title> <publisher> Plenum Publishing, </publisher> <year> 1995. </year>
Reference-contexts: Starting DFO in this way would completely eliminate the variability in the DFO results caused by taking a random first step. <ref> [8] </ref>, [7]. 4 4. Sample Test Results. In this section, we will present a graphical summary of the test results so far for the 31 variable constant wake helicopter rotor design example.
Reference: [9] <author> C. Currin, T. J. Mitchell, M. Morris, and D. Ylvisaker. </author> <title> A Bayesian approach to the design and analysis of computer experiments. </title> <type> Technical Report ORNL-6498, </type> <institution> Oak Ridge National Laboratory, </institution> <year> 1988. </year>
Reference-contexts: Called kriging models, they are recommended in the Design and Analysis of Computer Experiments (DACE) literature, surveyed in [20]. These models are made to interpolate the observations, and they depend on a set of correlation parameters [20] that we estimated via maximum likelihood estimation (MLE), as in <ref> [9] </ref>. In [13, 9], it is shown that MLE can be thought of as a form of cross-validation. This Gaussian process supposition is a convenient fiction ([23]) that provides useful error estimates, termed mean squared errors (mse), derived from the putative underlying Gaussian process. <p> Called kriging models, they are recommended in the Design and Analysis of Computer Experiments (DACE) literature, surveyed in [20]. These models are made to interpolate the observations, and they depend on a set of correlation parameters [20] that we estimated via maximum likelihood estimation (MLE), as in [9]. In <ref> [13, 9] </ref>, it is shown that MLE can be thought of as a form of cross-validation. This Gaussian process supposition is a convenient fiction ([23]) that provides useful error estimates, termed mean squared errors (mse), derived from the putative underlying Gaussian process.
Reference: [10] <author> J. E. Dennis, Jr. and Virginia Torczon. </author> <title> Direct search methods on parallel machines. </title> <journal> SIAM J. Optimization, </journal> <volume> 1(4) </volume> <pages> 448-474, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: This template of points is one that could be used to take one step of a parallel direct search (PDS) method on the surrogate <ref> [10] </ref>, [22]. When the surrogate is evaluated at these designs, we assume that the lower the value of the surrogate at a given design vector, the better the chance that the true objective would have an actual lower value there. <p> An amazing fact is that DFO requested function values at points for which only 3% failed to return a value. The numbers reported for DFO are the total number of values requested. * PDS: This is Torczon's implementation [22] of the parallel direct search method of <ref> [10] </ref>. The numbers reported for PDS are the total number of values requested. We used a smaller template than the default template on the distributed code.
Reference: [11] <author> J. E. Dennis, Jr. and Virginia Torczon. </author> <title> Managing approximation models in optimization. </title> <editor> In Natalia Alexandrov and M.Y. Hussaini, editors, </editor> <booktitle> Multidisciplinary Design Optimization: State-of-the-Art, </booktitle> <pages> pages 330-347. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1997. </year> <note> Also available as Rice U. CAAM Tech. Report 95-19. </note>
Reference-contexts: 1. Introduction. The purpose of this paper is to present preliminary numerical results for a new generalized version of the model management framework introduced by Dennis and Torczon in <ref> [11] </ref>. This note forms a brief summary of a portion of the doctoral dissertation of David Serafini. More detail and more results can be found in [21] and [3].
Reference: [12] <author> B. Efron and C. Stein. </author> <title> The jacknife estimate of variance. </title> <journal> The Annals of Statistics, </journal> <volume> 9(3) </volume> <pages> 586-596, </pages> <year> 1981. </year>
Reference-contexts: The surrogate ^ f provides a global model of f , and a promising use of the surrogate is in estimating the important variables in f. This is done by applying to ^ f the functional analysis of variance (ANOVA) introduced and described in <ref> [12, 19, 20] </ref>. The functional ANOVA provides estimates of contributions of individual variables to ^ f (main effects) and of combinations of variables to ^ f (interaction effects). We use these quantities obtained from ^ f as estimates of the corresponding quantities for f.
Reference: [13] <author> S. Geisser and W. F. Eddy. </author> <title> A predictive approach to model selection. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 74 </volume> <pages> 153-160, </pages> <year> 1979. </year>
Reference-contexts: Called kriging models, they are recommended in the Design and Analysis of Computer Experiments (DACE) literature, surveyed in [20]. These models are made to interpolate the observations, and they depend on a set of correlation parameters [20] that we estimated via maximum likelihood estimation (MLE), as in [9]. In <ref> [13, 9] </ref>, it is shown that MLE can be thought of as a form of cross-validation. This Gaussian process supposition is a convenient fiction ([23]) that provides useful error estimates, termed mean squared errors (mse), derived from the putative underlying Gaussian process.
Reference: [14] <author> A. A. Giunta, V. Balabanov, D. Haim, B. Grossman, W. H. Mason, L. T. Watson, and R. T. Haftka. </author> <title> Wing design for a high-speed civil transport using a design of experiments methodology. </title> <booktitle> In Proceedings of the Sixth AIAA/NASA/USAF Symposium on Multidisciplinary Analysis and Optimization, </booktitle> <address> Bellevue, WA, </address> <year> 1996. </year> <institution> American Institute of Aeronautics and Astronautics, </institution> <year> 1996. </year> <note> AIAA Paper 96-4001. </note>
Reference-contexts: Current practice (See the contribution to this volume by B. Grossman and [5], [1], [6] <ref> [14] </ref>) is to sample widely in design variable space, build a response surface model of the expensive high fidelity objective, and possibly of the constraints, and then to use the models as surrogates for the high fidelity objective function and constraints in doing optimization on the problem posed using the high
Reference: [15] <author> D. R. Jones, M. Schonlau, and W. J. Welch. </author> <title> A data analytic approach to bayesian global optimization. </title> <booktitle> In Proceedings of the ASA, </booktitle> <year> 1997. </year>
Reference-contexts: Note that the mse approaches 0 as x approaches an observation, and it is (relatively) large when x is far from any observations. There is some evidence that this may not be an unreasonable framework from which to predict future prediction errors <ref> [20, 15] </ref>, particularly if one can diagnose the fit [15] and determine the reasonableness of the Gaussian process assumption or determine a transformation of the response that makes it reasonable. <p> There is some evidence that this may not be an unreasonable framework from which to predict future prediction errors [20, 15], particularly if one can diagnose the fit <ref> [15] </ref> and determine the reasonableness of the Gaussian process assumption or determine a transformation of the response that makes it reasonable. In the BLGS algorithm mentioned below, mse is used to guide the selection of new points for improving the surrogate's accuracy.
Reference: [16] <author> David Levine. </author> <title> Users guide to the PGAPack parallel genetic algorithm library. </title> <type> Technical Report ANL-95/18, </type> <institution> Argonne National Laboratory, </institution> <month> January </month> <year> 1996. </year> <note> Available from URL ftp://info.mcs.anl.gov/pub/pgapack/pgapack.tar.Z. </note>
Reference-contexts: We used a smaller template than the default template on the distributed code. As advertised, it steadily descends to a quite good objective value, slowing down after about 1500 evaluations, but continuing to descend out to 5500 function evaluations. * GA: This is an algorithm from PGAPack <ref> [16] </ref>. We used the parameter settings suggested to us for this problem by its author David Levine of the Boeing Company. The numbers reported for GA are the total number of values requested. It performs as advertised nice initial decrease and then leveling out.
Reference: [17] <author> Robert Michael Lewis and Virginia Torczon. </author> <title> Pattern search algorithms for bound constrained minimization. </title> <type> Technical Report 96-20, </type> <institution> ICASE, NASA Langley Research Center, </institution> <address> Hampton, VA 23681-0001, </address> <month> March </month> <year> 1996. </year> <note> To appear in SIAM Journal on Optimization. </note>
Reference-contexts: The new truth values are added to the surrogate, and then the recalibrated surrogate is used to generate the next iterate. If no better design is found, then the convergence theory we use <ref> [17] </ref>, [18] requires a "poll" step on the current scale before we can decrease the scale of the search template. Without going into greater detail, the scale of the template sets the distances between points on the template, not the number of points in the template.
Reference: [18] <author> Robert Michael Lewis and Virginia Torczon. </author> <title> Rank ordering and positive bases in pattern search algorithms. </title> <type> Technical Report 96-71, </type> <institution> ICASE, NASA Langley Research Center, </institution> <address> Hampton, VA 23681-0001, </address> <month> December </month> <year> 1996. </year> <note> Submitted to SIAM Journal on Optimization. </note>
Reference-contexts: The new truth values are added to the surrogate, and then the recalibrated surrogate is used to generate the next iterate. If no better design is found, then the convergence theory we use [17], <ref> [18] </ref> requires a "poll" step on the current scale before we can decrease the scale of the search template. Without going into greater detail, the scale of the template sets the distances between points on the template, not the number of points in the template. <p> A poll step can be expensive. If it is unsuccessful, then it may require between n + 1 and 2n truth evaluations depending on the choice of positive basis <ref> [18] </ref>. In fact, our plan is that we will switch to the derivative-free optimization algorithm (DFO) presented in this volume by Andrew Conn after we encounter the first unsuccessful complete poll step.
Reference: [19] <author> A. B. Owen. </author> <title> Orthogonal arrays for computer experiments, integration and visualization. </title> <journal> Sta-tistica Sinica, </journal> <volume> 2 </volume> <pages> 439-452, </pages> <year> 1992. </year>
Reference-contexts: DACE Response Surface Models. The specific design vectors for which we compute f values to use in building the surrogate models are chosen from the same class of experimental designs used in quasi-Monte Carlo integration: orthogonal arrays (OAs) <ref> [19] </ref>. The designs we used were strength 2 designs, which means that if there are l distinct values for each variable then every subset of 2 variables is a grid in 2 the l values. This gives one confidence that these designs are "infiltrating" the design space well. <p> The surrogate ^ f provides a global model of f , and a promising use of the surrogate is in estimating the important variables in f. This is done by applying to ^ f the functional analysis of variance (ANOVA) introduced and described in <ref> [12, 19, 20] </ref>. The functional ANOVA provides estimates of contributions of individual variables to ^ f (main effects) and of combinations of variables to ^ f (interaction effects). We use these quantities obtained from ^ f as estimates of the corresponding quantities for f.
Reference: [20] <author> J. Sacks, W. J. Welch, T. J. Mitchell, and H. P. Wynn. </author> <title> Design and analysis of computer experiments. </title> <journal> Statistical Science, </journal> <volume> 4(4) </volume> <pages> 409-435, </pages> <year> 1989. </year>
Reference-contexts: They are motivated by the supposition that the output being modeled is a realization of a Gaussian spatial process. Called kriging models, they are recommended in the Design and Analysis of Computer Experiments (DACE) literature, surveyed in <ref> [20] </ref>. These models are made to interpolate the observations, and they depend on a set of correlation parameters [20] that we estimated via maximum likelihood estimation (MLE), as in [9]. In [13, 9], it is shown that MLE can be thought of as a form of cross-validation. <p> Called kriging models, they are recommended in the Design and Analysis of Computer Experiments (DACE) literature, surveyed in <ref> [20] </ref>. These models are made to interpolate the observations, and they depend on a set of correlation parameters [20] that we estimated via maximum likelihood estimation (MLE), as in [9]. In [13, 9], it is shown that MLE can be thought of as a form of cross-validation. <p> Note that the mse approaches 0 as x approaches an observation, and it is (relatively) large when x is far from any observations. There is some evidence that this may not be an unreasonable framework from which to predict future prediction errors <ref> [20, 15] </ref>, particularly if one can diagnose the fit [15] and determine the reasonableness of the Gaussian process assumption or determine a transformation of the response that makes it reasonable. <p> The surrogate ^ f provides a global model of f , and a promising use of the surrogate is in estimating the important variables in f. This is done by applying to ^ f the functional analysis of variance (ANOVA) introduced and described in <ref> [12, 19, 20] </ref>. The functional ANOVA provides estimates of contributions of individual variables to ^ f (main effects) and of combinations of variables to ^ f (interaction effects). We use these quantities obtained from ^ f as estimates of the corresponding quantities for f.
Reference: [21] <author> David B. Serafini. </author> <title> A Framework for Managing Models in Optimization for Computationally Expensive Functions. </title> <type> PhD thesis, </type> <institution> Rice University, Houston, TX, </institution> <year> 1997. </year>
Reference-contexts: This note forms a brief summary of a portion of the doctoral dissertation of David Serafini. More detail and more results can be found in <ref> [21] </ref> and [3]. The premise of our work is summed up in the following list: * Many optimal design problems are too computationally expensive for direct application of optimization codes. * Gradient methods may be inconvenient to apply and likely to converge to design refinements rather than breakthrough designs.
Reference: [22] <author> Virginia Torczon. </author> <title> PDS: Direct search methods for unconstrained optimization on either sequential or parallel machines. </title> <type> Technical Report 92-9, </type> <institution> Department of Mathematical Sciences, Rice University, </institution> <address> Houston, TX 77251-1892, </address> <year> 1992. </year> <note> Submitted to ACM Transactions on Mathematical Software. </note>
Reference-contexts: This template of points is one that could be used to take one step of a parallel direct search (PDS) method on the surrogate [10], <ref> [22] </ref>. When the surrogate is evaluated at these designs, we assume that the lower the value of the surrogate at a given design vector, the better the chance that the true objective would have an actual lower value there. <p> An amazing fact is that DFO requested function values at points for which only 3% failed to return a value. The numbers reported for DFO are the total number of values requested. * PDS: This is Torczon's implementation <ref> [22] </ref> of the parallel direct search method of [10]. The numbers reported for PDS are the total number of values requested. We used a smaller template than the default template on the distributed code.
Reference: [23] <author> Michael W. Trosset and Virginia Torczon. </author> <title> Numerical optimization using computer experiments. </title> <journal> Technometrics, </journal> <note> 1997. Submitted for publication. 7 </note>
References-found: 23

