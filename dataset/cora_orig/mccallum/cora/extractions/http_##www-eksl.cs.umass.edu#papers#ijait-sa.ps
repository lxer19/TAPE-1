URL: http://www-eksl.cs.umass.edu/papers/ijait-sa.ps
Refering-URL: http://eksl-www.cs.umass.edu/publications.html
Root-URL: 
Email: coheng@cs.umass.edu  
Title: A Toolbox for Analyzing Programs  
Author: Scott D. Anderson David M. Hart David L. Westbrook Paul R. Cohen fanderson, dhart, westy, 
Note: To appear in the International Journal on AI Tools  
Address: Amherst, MA 01003-4610  
Affiliation: Experimental Knowledge Systems Laboratory Computer Science Department, LGRC University of Massachusetts  
Abstract: The paper describes two separate but synergistic tools for running experiments on large Lisp programs. The first tool, called Clip (Common Lisp Instrumentation Package), allows the researcher to define and run experiments, including experimental conditions (parameter values of the planner or simulator) and data to be collected. The data are written out to data files that can be analyzed by statistics software. The second tool, called Clasp (Common Lisp Analytical Statistics Package), allows the researcher to analyze data from experiments by using graphics, statistical tests, and various kinds of data manipulation. Clasp has a graphical user interface (using CLIM, the Common Lisp Interface Manager) and also allows data to be directly processed by Lisp functions. Finally, the paper describes a number of other data-analysis modules have been added to work with Clip and Clasp.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Paul R. Cohen, Michael L. Greenberg, David M. Hart, and Adele E. Howe. </author> <title> Trial by fire: Understanding the design requirements for agents in complex environments. </title> <journal> AI Magazine, </journal> <volume> 10(3) </volume> <pages> 32-48, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: 1 Introduction The systems described in this article, Clip and Clasp were originally developed to aid our empirical, statistical work with an artificial intelligence (AI) program called Phoenix <ref> [1] </ref> that does online planning and execution in a very complex environment. The statistical work is necessary because the program is so complex that patterns of behavior (and misbehavior) only emerge from many trials in many conditions.
Reference: [2] <author> Scott D. Anderson, Adam Carlson, David L. Westbrook, David M. Hart, and Paul R. Cohen. Clasp/Clip: </author> <title> Common Lisp Analytical Statistics Package/Common Lisp Instrumentation Package. </title> <type> Technical Report 93-55, </type> <institution> University of Massachusetts at Amherst, Computer Science Department, </institution> <year> 1993. </year> <month> 15 </month>
Reference-contexts: This aspect of Clip is deferred to section 3.2. First, we present an overview of how Clip works and what you need to do to use it. (This article is no substitute for the Clip/Clasp manual <ref> [2] </ref>, where everything is rigorously explained.) To use Clip to run an experiment, Clip first needs to know how to run your simulator (or whatever your program is). <p> Clip also lets you run only part of the experiment, which facilitates breaking the experiment into parts to run on different machines. These are all explained at length in the Clip/Clasp documentation <ref> [2] </ref>. 4 Data Analysis The idea of Clasp began when we wanted to run a t-test on some experiment data without having to write out the data to a file in some tab-delimited format, move the code to another machine, run a statistics program, and load the data.
Reference: [3] <author> Tim Oates and Paul R. Cohen. </author> <title> Mixed-initiative schedule maintenance: A first step toward plan steering. </title> <editor> In Mark H. Burstein, editor, </editor> <title> ARPA/Rome Laboratory Knowledge-based Planning and Scheduling Initiative Workshop Proceedings. </title> <institution> Advanced Research Projects Agency and Rome Laboratory, </institution> <month> February </month> <year> 1994. </year> <note> Also available as Technical Report 94-31, </note> <institution> University of Massachusetts Computer Science Department. </institution>
Reference-contexts: The example uses the TransSim simulator and is based on a pilot experiment that Tim Oates used in designing his Plan Steering Agent <ref> [3, 4] </ref>. The purpose of the experiment is to assess the error rate of a demon that predicts the queue length at a port d days in advance, as a function of the variability of ship speed and the time delay, d. The following defines the TransSim simulator.
Reference: [4] <author> Tim Oates and Paul R. Cohen. </author> <title> Toward a plan steering agent: Experiments with schedule maintenance. </title> <booktitle> In Proceedings of the Second International Conference on Artificial Intelligence Planning Systems, </booktitle> <year> 1994. </year> <note> Also available as Technical Report 94-02, </note> <institution> University of Massachusetts Computer Science Department. </institution>
Reference-contexts: The example uses the TransSim simulator and is based on a pilot experiment that Tim Oates used in designing his Plan Steering Agent <ref> [3, 4] </ref>. The purpose of the experiment is to assess the error rate of a demon that predicts the queue length at a port d days in advance, as a function of the variability of ship speed and the time delay, d. The following defines the TransSim simulator.
Reference: [5] <author> Robert St. Amant and Paul R. Cohen. </author> <title> Preliminary system design for an EDA assistant. </title> <booktitle> In Preliminary Papers of the Fifth International Workshop on AI and Statistics, </booktitle> <pages> pages 502-512, </pages> <year> 1995. </year>
Reference-contexts: Exploratory Data Analysis After running an exploratory experiment and gathering data, the user is faced with the task of identifying significant relationships among the factors measured. This is called Exploratory Data Analysis (EDA). We are building a module that assists the user in this effort by employing EDA techniques <ref> [5, 6] </ref>. These techniques can partition data to distinguish different modes of behavior and generate functional descriptions of interactions between factors. Through detailed exploration of experimental data the user can gain a more complete picture of program behavior. <p> With this vision in mind we are currently developing the Assistant for Intelligent Data Exploration (Aide) to assist human analysts in exploratory data analysis (EDA) <ref> [5] </ref>. Aide adopts a planning approach to automating EDA. Data-directed mechanisms extract simple observations and suggestive indications from the data. Scripted combinations of EDA operations are then applied in a goal-directed fashion to generate simpler, deeper, or extended descriptions of the data.
Reference: [6] <author> John W. Tukey. </author> <title> Exploratory Data Analysis. </title> <publisher> Addison-Wesley, </publisher> <year> 1977. </year>
Reference-contexts: Exploratory Data Analysis After running an exploratory experiment and gathering data, the user is faced with the task of identifying significant relationships among the factors measured. This is called Exploratory Data Analysis (EDA). We are building a module that assists the user in this effort by employing EDA techniques <ref> [5, 6] </ref>. These techniques can partition data to distinguish different modes of behavior and generate functional descriptions of interactions between factors. Through detailed exploration of experimental data the user can gain a more complete picture of program behavior.
Reference: [7] <author> Bradley Efron and Gail Gong. </author> <title> A leisurely look at the bootstrap, the jackknife, and cross-validation. </title> <journal> The American Statistician, </journal> <volume> 37(1) </volume> <pages> 36-48, </pages> <month> February </month> <year> 1983. </year>
Reference: [8] <author> Bradley Efron and Robert Tibshirani. </author> <title> Statistical data analysis in the computer age. </title> <journal> Science, </journal> <volume> 253 </volume> <pages> 390-395, </pages> <month> July </month> <year> 1991. </year>
Reference: [9] <author> Adele E. Howe and Paul R. Cohen. </author> <title> Understanding planner behavior. </title> <journal> Artificial Intelligence. </journal> <note> To appear. </note>
Reference-contexts: Program actions often interact in unforeseen and deleterious ways. We employ a technique we call dependency detection, analyzing program execution traces with a statistical filter to find significant dependencies among interacting actions <ref> [9] </ref>. Once identified, these dependencies can be examined more carefully to find and fix the unforeseen interactions that often cause them.
Reference: [10] <author> Adele E. Howe. </author> <title> Finding dependencies in event streams using local search. </title> <booktitle> In Preliminary Papers of the Fifth International Workshop on AI and Statistics, </booktitle> <pages> pages 271-277, </pages> <year> 1995. </year>
Reference-contexts: This single-stream form of dependency detection has recently been enhanced by the incorporation of efficient heuristic techniques to guide the search for dependencies <ref> [10] </ref>. In addition, we have developed an algorithm for multi-stream dependency detection, which identifies significant dependencies in multiple concurrent streams (for example, the various sensor readings taken for an intensive care patient).
Reference: [11] <author> Tim Oates, Dawn E. Gregory, and Paul R. Cohen. </author> <title> Detecting complex dependencies in categorical data. </title> <booktitle> In Preliminary Papers of the Fifth International Workshop on AI and Statistics, </booktitle> <pages> pages 417-423, </pages> <year> 1995. </year>
Reference-contexts: Using this algorithm, we generated a set of predictive rules for port bottlenecks in TransSim that were better than the hand-crafted rules previously used <ref> [11] </ref>. Causal Induction Other techniques, in addition to dependency detection, can be employed to model program behavior. A predictive model should tell us how we can change the program to improve or correct its behavior. This requires that we understand the underlying causal relationships among the factors influencing its behavior.
Reference: [12] <author> Paul R. Cohen, Adam Carlson, L. A. Ballesteros, and Robert St. Amant. </author> <title> Automating path analysis for building causal models from data. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 57-64. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: A predictive model should tell us how we can change the program to improve or correct its behavior. This requires that we understand the underlying causal relationships among the factors influencing its behavior. We are developing a module that builds causal models from data <ref> [12] </ref>. The input to this module is a set of factors whose relationships are to be modeled. The output is a graph with factors at the nodes and with arcs that show both causal direction and strength of influence.
Reference: [13] <author> H. B. Asher. </author> <title> Causal Modeling. </title> <publisher> Sage Publications, </publisher> <year> 1983. </year>
Reference-contexts: The input to this module is a set of factors whose relationships are to be modeled. The output is a graph with factors at the nodes and with arcs that show both causal direction and strength of influence. Some of the causal induction techniques are based on path analysis <ref> [13, 14] </ref>. In addition, this module will provide several new algorithms that induce structural equation models from data [15].
Reference: [14] <author> C. C. Li. </author> <title> Path Analysis | A Primer. </title> <publisher> Boxwood Press, </publisher> <year> 1975. </year>
Reference-contexts: The input to this module is a set of factors whose relationships are to be modeled. The output is a graph with factors at the nodes and with arcs that show both causal direction and strength of influence. Some of the causal induction techniques are based on path analysis <ref> [13, 14] </ref>. In addition, this module will provide several new algorithms that induce structural equation models from data [15].
Reference: [15] <author> Paul R. Cohen, Dawn E. Gregory, L. A. Ballesteros, and Robert St. Amant. </author> <title> Two algorithms for inducing structural equation models from data. </title> <booktitle> In Preliminary Papers of the Fifth International Workshop on AI and Statistics, </booktitle> <pages> pages 129-139, </pages> <year> 1995. </year>
Reference-contexts: Some of the causal induction techniques are based on path analysis [13, 14]. In addition, this module will provide several new algorithms that induce structural equation models from data <ref> [15] </ref>. These algorithms, which are based on linear regression, compare quite favorably with two other well-known causal modeling algorithms that are based on conditional independence: the IC algorithm by Pearl and Verma [16] and the PC algorithm by Spirtes, et al. [17], often outperforming them.
Reference: [16] <author> J. Pearl and T. Verma. </author> <title> A statistical semantics for causation. </title> <journal> Statistics and Computing, </journal> <volume> 2 </volume> <pages> 91-95, </pages> <year> 1991. </year>
Reference-contexts: In addition, this module will provide several new algorithms that induce structural equation models from data [15]. These algorithms, which are based on linear regression, compare quite favorably with two other well-known causal modeling algorithms that are based on conditional independence: the IC algorithm by Pearl and Verma <ref> [16] </ref> and the PC algorithm by Spirtes, et al. [17], often outperforming them. This is most remarkable given the relative simplicity and computational efficiency of these algorithms when compared to IC and PC.
Reference: [17] <author> P. Spirtes, C. Glymour, and R. Scheines. </author> <title> Causation, Prediction and Search. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: These algorithms, which are based on linear regression, compare quite favorably with two other well-known causal modeling algorithms that are based on conditional independence: the IC algorithm by Pearl and Verma [16] and the PC algorithm by Spirtes, et al. <ref> [17] </ref>, often outperforming them. This is most remarkable given the relative simplicity and computational efficiency of these algorithms when compared to IC and PC.
Reference: [18] <author> L. A. Ballesteros. </author> <title> Regression-based causal induction with latent variable models. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, page 1426. American Association for Artificial Intelligence, </booktitle> <publisher> AAAI Press/The MIT Press, </publisher> <year> 1994. </year> <title> Student Abstract. </title>
Reference-contexts: This is most remarkable given the relative simplicity and computational efficiency of these algorithms when compared to IC and PC. The key is our reliance on regression techniques <ref> [18] </ref> and on a simple filtering heuristic we call !. (Roughly, ! is the percentage of the correlation that is indirect.) Case studies using these and other empirical techniques to analyze AI programs are included in a forthcoming textbook on empirical methods for AI research [19].
Reference: [19] <author> Paul R. Cohen. </author> <booktitle> Empirical Methods in Artificial Intelligence. </booktitle> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: our reliance on regression techniques [18] and on a simple filtering heuristic we call !. (Roughly, ! is the percentage of the correlation that is indirect.) Case studies using these and other empirical techniques to analyze AI programs are included in a forthcoming textbook on empirical methods for AI research <ref> [19] </ref>. It is possible that the major contribution of Clip/Clasp will not be as a standalone instrumentation and analysis package, but rather as a platform for the integration of more powerful techniques such as those described above.
Reference: [20] <author> Dawn E. Gregory and Paul R. Cohen. </author> <title> A function modeling approach to empirical science. </title> <booktitle> To be presented at the 10th International Conference on Mathematical and Computer Modelling. </booktitle>
Reference-contexts: Another intriguing problem that is a candidate for partial or full automation is experiment design. We are currently designing a Scientist's Empirical Assistant, Sea, that will provide an intelligent, goal-driven approach to creating scientific experiments <ref> [20] </ref>. Sea will use a large repository of knowledge to create one or more experiment plans. Clip will provide the basic building blocks by which experiments are run.
Reference: [21] <author> Bolt Beranek and Newman, Inc. and ISX Corporation. </author> <title> Common prototyping environment testbed release 1.0: User's guide. BBN Systems and Technologies, </title> <address> 10 Moulton Street, Cambridge, MA 02138, </address> <year> 1993. </year>
Reference-contexts: modeling to model the knowledge and information flow required to design empirical experiments such as those we use to analyze AI programs. 7 Related Work We know of no other Common Lisp instrumentation tool like Clip, with the exception of a package called Meters by Bolt, Beranek and Newman, Inc. <ref> [21] </ref>. Like Clip, Meters was developed for use in the Arpa/rl Planning Initiative (Arpi).
Reference: [22] <institution> Luke Tierney. XlispStat. School of Statistics Report #528, University of Minnesota, </institution> <year> 1988. </year>
Reference-contexts: Two well-developed Common Lisp statistical packages provide alternatives for the user requiring statistical or quantitative reasoning methods not (yet) implemented in Clasp: Xlisp-stat and Quail. Xlisp-stat <ref> [22, 23] </ref> was developed under Luke Tierney at the School of Statistics at the University of Minnesota. Xlisp-stat provides a rich set of statistical and dynamic graphing capabilities. Some features found in Xlisp-stat and not in Clasp include: nonlinear regression, maximization and minimum likelihood estimation, and approximate Bayesian computation.
Reference: [23] <author> Luke Tierney. LISP-STAT: </author> <title> An Object-Oriented Environment for Statistical Computing and Dynamic Graphics. </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year> <month> 16 </month>
Reference-contexts: Two well-developed Common Lisp statistical packages provide alternatives for the user requiring statistical or quantitative reasoning methods not (yet) implemented in Clasp: Xlisp-stat and Quail. Xlisp-stat <ref> [22, 23] </ref> was developed under Luke Tierney at the School of Statistics at the University of Minnesota. Xlisp-stat provides a rich set of statistical and dynamic graphing capabilities. Some features found in Xlisp-stat and not in Clasp include: nonlinear regression, maximization and minimum likelihood estimation, and approximate Bayesian computation.
References-found: 23

