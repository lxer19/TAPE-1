URL: http://www.cs.cmu.edu/afs/cs/project/prodigy-1/eugene/Public/Papers/design-changers.ps
Refering-URL: http://www.cs.cmu.edu/~eugene/Research/Past/academia.html
Root-URL: 
Title: Design of Representation-Changing Algorithms  
Author: Eugene Fink 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: February 1995  
Pubnum: CMU-CS-95-120  
Abstract: This research is supported by the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330. The views and conclusions contained in this document are those of the author and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of Wright Laboratory or the U. S. Government. 
Abstract-found: 1
Intro-found: 1
Reference: [ Allen et al., 1992 ] <author> John Allen, Pat Langley, and Stan Matwin. </author> <title> Knowledge and regularity in planning. </title> <booktitle> In Proceedings of the AAAI 1992 Spring Symposium on Computational Considerations in Supporting Incremental Modification and Reuse, </booktitle> <pages> pages 7-12, </pages> <year> 1992. </year>
Reference: [ Amarel, 1968 ] <author> Saul Amarel. </author> <title> On representations of problems of reasoning about actions. </title> <editor> In Donald Michie, editor, </editor> <booktitle> Machine Intelligence 3, </booktitle> <pages> pages 131-171. </pages> <publisher> American Elsevier Publishers, </publisher> <year> 1968. </year>
Reference: [ Bacchus and Yang, 1992 ] <author> Fahiem Bacchus and Qiang Yang. </author> <title> The expected value of hierarchical problem-solving. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <year> 1992. </year>
Reference: [ Bacchus and Yang, 1994 ] <author> Fahiem Bacchus and Qiang Yang. </author> <title> Downward refinement and the efficiency of hierarchical problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 71(1) </volume> <pages> 43-100, </pages> <year> 1994. </year>
Reference-contexts: Research on the automatic generation of new problem representations has been limited to several special cases of representation changes, including systems for decomposing a problem into subproblems [ Newell et al., 1960 ] , generating abstraction hierarchies <ref> [ Knoblock, 1994; Christensen, 1990; Bacchus and Yang, 1994 ] </ref> , replacing operators with macros [ Korf, 1985; Shell and Carbonell, 1989 ] , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and
Reference: [ Carbonell, 1983 ] <author> Jaime G. Carbonell. </author> <title> Learning by analogy: Formulating and generalizing plans from past experience. </title> <editor> In Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <publisher> Tioga Publishers, </publisher> <address> Palo Alto, CA, </address> <year> 1983. </year>
Reference-contexts: al., 1992; Carbonell, 1990 ] , which includes learning control rules [ Langley, 1983; Laird et al., 1986; Minton, 1988; Veloso and Borrajo, 1994 ] , generating abstraction hierarchies [ Knoblock, 1994 ] , replacing operators with macros [ Korf, 1985; Mooney, 1988 ] , and reusing past problem-solving cases <ref> [ Carbonell, 1983; Hall, 1987; Veloso, 1994 ] </ref> . These learning algorithms, however, are themselves representation-dependent: they easily learn useful information with some problem descriptions, but become helpless with others. <p> 1985; Shell and Carbonell, 1989 ] , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and Etzioni, 1992; Veloso and Borrajo, 1994 ] , and reusing past problem-solving episodes in analogical reasoning <ref> [ Carbonell, 1983; Veloso, 1994 ] </ref> . There has, however, been little research on the common principles underlying different types of representation-changers.
Reference: [ Carbonell, 1990 ] <author> Jaime G. Carbonell, </author> <title> editor. Machine Learning: Paradigms and Methods. </title> <publisher> MIT Press, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference: [ Christensen, 1990 ] <author> Jens Christensen. </author> <title> A hierarchical planner that generates its own abstraction hierarchies. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1004-1009, </pages> <year> 1990. </year>
Reference-contexts: Research on the automatic generation of new problem representations has been limited to several special cases of representation changes, including systems for decomposing a problem into subproblems [ Newell et al., 1960 ] , generating abstraction hierarchies <ref> [ Knoblock, 1994; Christensen, 1990; Bacchus and Yang, 1994 ] </ref> , replacing operators with macros [ Korf, 1985; Shell and Carbonell, 1989 ] , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and
Reference: [ Cohen, 1992 ] <author> William W. Cohen. </author> <title> Using distribution-free learning theory to analyze solution-path caching mechanisms. </title> <journal> Computational Intelligence, </journal> <volume> 8(2) </volume> <pages> 336-375, </pages> <year> 1992. </year>
Reference-contexts: theoretical frameworks for some special cases of representation changes, most notably generating abstraction hierarchies [ Korf, 1987; Knoblock, 1991b; Knoblock et al., 1991; Bacchus and Yang, 1992; Giunchiglia and Walsh, 1992 ] , replacing operators with macros [ Korf, 1985; Korf, 1987; Mooney, 1988 ] , and learning control rules <ref> [ Cohen, 1992 ] </ref> . A generalized model of representation changes was suggested by Korf, who formalized the concept of problem reformulation based on the notions of isomorphism and homomorphism of search spaces [ Korf, 1980 ] .
Reference: [ Etzioni, 1993 ] <author> Oren Etzioni. </author> <title> Acquiring search control knowledge via static analysis. </title> <journal> Artificial Intelligence, </journal> <volume> 62(2) </volume> <pages> 255-301, </pages> <year> 1993. </year>
Reference: [ Fikes et al., 1972 ] <author> Richard E. Fikes, P. Hart, and Nils J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3(4), </volume> <year> 1972. </year>
Reference-contexts: Replacing operators with macros: Replacing some operators in a domain description with macros constructed from these operators <ref> [ Fikes et al., 1972 ] </ref> . Removing operators: Deleting unnecessary operators from a domain description (see the Three-Rocket example in Section 2.1).
Reference: [ Fink and Yang, 1992 ] <author> Eugene Fink and Qiang Yang. </author> <title> Automatically abstracting effects of operators. </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <pages> pages 243-251, </pages> <year> 1992. </year>
Reference-contexts: For example, the alpine algorithm for learning abstraction hierarchies [ Knoblock, 1990 ] usually fails to generate a hierarchy when the domain contains unnecessary additional operators or the operator descriptions are too general <ref> [ Knoblock, 1991a; Fink and Yang, 1992 ] </ref> ; however, if the user selects a suitable domain description, alpine becomes very effective in reducing complexity of problem solving. <p> Instantiator is able to perform the representation change in the Tower-of-Hanoi domain, described in Section 2.2. Prim-Tweak and Margie are more complex algorithms, which improve problem representations by selecting primary effects of operators. We have implemented these algorithms in collaboration with Yang <ref> [ Fink and Yang, 1992; Fink and Yang, 1993 ] </ref> . <p> Call Prim-Tweak to select additional primary effects in order to ensure that the cost increase is at most C. operators: a specification of a representation-changer and a greedy algorithm that satisfies the specification. We have designed a greedy algorithm, called Margie, that satisfies this specification <ref> [ Fink and Yang, 1992; Fink and Yang, 1994b ] </ref> . We give an informal description of this algorithm at the bottom of Figure 12. The Margie algorithm considers different selections of primary effects and calls alpine to generate abstraction hierarchies based on these selections.
Reference: [ Fink and Yang, 1993 ] <author> Eugene Fink and Qiang Yang. </author> <title> Characterizing and automatically finding primary effects in planning. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1374-1379, </pages> <year> 1993. </year>
Reference-contexts: Instantiator is able to perform the representation change in the Tower-of-Hanoi domain, described in Section 2.2. Prim-Tweak and Margie are more complex algorithms, which improve problem representations by selecting primary effects of operators. We have implemented these algorithms in collaboration with Yang <ref> [ Fink and Yang, 1992; Fink and Yang, 1993 ] </ref> . <p> We use the same learning method as in Operator-Remover. An informal description of the Prim-Tweak learner is shown at the bottom of Figure 10. The learner takes an initial selection of primary effects, specified by the user or generated by a simple heuristical algorithm <ref> [ Fink and Yang, 1993 ] </ref> , and selects more primary effects to make sure that problem solving is complete and the cost increase is at most C.
Reference: [ Fink and Yang, 1994a ] <author> Eugene Fink and Qiang Yang. </author> <title> Automatically selecting and using primary effects in planning: Theory and experiments. </title> <type> Technical Report CMU-CS-94-206, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1994. </year> <month> 26 </month>
Reference-contexts: To complete this algorithm, we must provide procedures for generating an initial reduced set of operators and for selecting a new operator when the current reduced set of operators is not sufficient for problem solving. We discussed some methods for accomplishing these tasks in <ref> [ Fink and Yang, 1994a ] </ref> . The input to Operator-Remover must include the set of operators in a problem domain. We may also provide the information about possible initial and goal states of problems, which will make the algorithm more effective. <p> If the user-specified bound C on the value of a cost increase is less than 1.5, the algorithm will make the robot-in effect a primary effect of the break operator. In <ref> [ Fink and Yang, 1994a ] </ref> we presented a formal description of Prim-Tweak, described 19 Specification: Type of representation change: Selecting primary effects of operators. <p> We have demonstrated experimentally that Prim-Tweak considerably improves the efficiency of the abtweak planning system in many different domains <ref> [ Fink and Yang, 1994a ] </ref> . In Figure 11, we present the results of testing Prim-Tweak in two artificial domains.
Reference: [ Fink and Yang, 1994b ] <author> Eugene Fink and Qiang Yang. </author> <title> Search reduction in planning with primary effects. </title> <booktitle> In Proceedings of the Workshop on Theory Reformulation and Abstraction, </booktitle> <pages> pages 39-55, </pages> <year> 1994. </year>
Reference-contexts: Call Prim-Tweak to select additional primary effects in order to ensure that the cost increase is at most C. operators: a specification of a representation-changer and a greedy algorithm that satisfies the specification. We have designed a greedy algorithm, called Margie, that satisfies this specification <ref> [ Fink and Yang, 1992; Fink and Yang, 1994b ] </ref> . We give an informal description of this algorithm at the bottom of Figure 12. The Margie algorithm considers different selections of primary effects and calls alpine to generate abstraction hierarchies based on these selections.
Reference: [ Gentner and Stevens, 1983 ] <author> Dedre Gentner and Albert L. Stevens, </author> <title> editors. Mental Models, </title> <address> Hillside, NJ, 1983. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: People often simplify problems by changing their description, which is a crucial skill for mathematicians [ Polya, 1957 ] , physicists [ Qin and Simon, 1992; Larkin and Simon, 1987 ] , economists [ Tabachneck, 1992; Larkin and Simon, 1987 ] , and experts in many other areas <ref> [ Newell and Simon, 1972; Gentner and Stevens, 1983 ] </ref> . The purpose of our research is to automate the process of changing and improving problem representations.
Reference: [ Giunchiglia and Walsh, 1992 ] <author> Fausto Giunchiglia and Toby Walsh. </author> <title> A theory of abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 57 </volume> <pages> 323-389, </pages> <year> 1992. </year>
Reference: [ Hall, 1987 ] <author> Rogers P. Hall. </author> <title> Understanding analogical reasoning: Computational approaches. </title> <journal> Artificial Intelligence, </journal> <volume> 39 </volume> <pages> 39-120, </pages> <year> 1987. </year>
Reference-contexts: al., 1992; Carbonell, 1990 ] , which includes learning control rules [ Langley, 1983; Laird et al., 1986; Minton, 1988; Veloso and Borrajo, 1994 ] , generating abstraction hierarchies [ Knoblock, 1994 ] , replacing operators with macros [ Korf, 1985; Mooney, 1988 ] , and reusing past problem-solving cases <ref> [ Carbonell, 1983; Hall, 1987; Veloso, 1994 ] </ref> . These learning algorithms, however, are themselves representation-dependent: they easily learn useful information with some problem descriptions, but become helpless with others.
Reference: [ Hayes and Simon, 1974 ] <author> John R. Hayes and Herbert A. Simon. </author> <title> Understanding written problem instructions. </title> <editor> In L. W. Gregg, editor, </editor> <booktitle> Knowledge and Cognition, </booktitle> <pages> pages 167-200. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Potomac, MD, </address> <year> 1974. </year>
Reference-contexts: The input must satisfy certain semantic and syntactic rules, called the input language. If the description of a problem does not obey the rules of the input language, we must "translate" it into the input language before using the algorithm (Figure 4b) <ref> [ Hayes and Simon, 1974; Hayes and Simon, 1976 ] </ref> . When the description obeys the rules of the input language, we may still want to change it in order to simplify the problem.
Reference: [ Hayes and Simon, 1976 ] <author> John R. Hayes and Herbert A. Simon. </author> <title> The understanding process: Problem isomorphs. </title> <journal> Cognitive Psychology, </journal> <volume> 8 </volume> <pages> 165-190, </pages> <year> 1976. </year>
Reference-contexts: The input must satisfy certain semantic and syntactic rules, called the input language. If the description of a problem does not obey the rules of the input language, we must "translate" it into the input language before using the algorithm (Figure 4b) <ref> [ Hayes and Simon, 1974; Hayes and Simon, 1976 ] </ref> . When the description obeys the rules of the input language, we may still want to change it in order to simplify the problem.
Reference: [ Hayes and Simon, 1977 ] <author> John R. Hayes and Herbert A. Simon. </author> <title> Psychological difference among problem isomorphs. </title> <editor> In N. J. Castellan, D. B. Pisoni, and G. R. Potts, editors, </editor> <booktitle> Cognitive Theory. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillside, NJ, </address> <year> 1977. </year>
Reference: [ Hibler, 1994 ] <author> David Hibler. </author> <title> Implicit abstraction by thought experiments. </title> <booktitle> In Proceedings of the Workshop on Theory Reformulation and Abstraction, </booktitle> <pages> pages 9-26, </pages> <year> 1994. </year>
Reference-contexts: representation changes, including systems for decomposing a problem into subproblems [ Newell et al., 1960 ] , generating abstraction hierarchies [ Knoblock, 1994; Christensen, 1990; Bacchus and Yang, 1994 ] , replacing operators with macros [ Korf, 1985; Shell and Carbonell, 1989 ] , replacing problems with similar simpler problems <ref> [ Hibler, 1994 ] </ref> , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and Etzioni, 1992; Veloso and Borrajo, 1994 ] , and reusing past problem-solving episodes in analogical reasoning [ Carbonell, 1983; Veloso, 1994 ] .
Reference: [ Kaplan and Simon, 1990 ] <author> Craig A. Kaplan and Herbert A. Simon. </author> <title> In search of insight. </title> <journal> Cognitive Psychology, </journal> <volume> 22 </volume> <pages> 374-419, </pages> <year> 1990. </year>
Reference-contexts: Kaplan and Simon studied representation changes by human subjects when solving the Mutilated-Checkerboard problem <ref> [ Kaplan and Simon, 1990 ] </ref> and implemented a program that models the human reasoning on this problem [ Kaplan, 1989 ] .
Reference: [ Kaplan, 1989 ] <author> Craig A. Kaplan. </author> <title> switch: A simulation of representational change in the Mutilated Checkerboard problem. </title> <type> Technical Report C.I.P. 477, </type> <institution> Department of Psychology, Carnegie Mellon University, </institution> <year> 1989. </year>
Reference-contexts: Kaplan and Simon studied representation changes by human subjects when solving the Mutilated-Checkerboard problem [ Kaplan and Simon, 1990 ] and implemented a program that models the human reasoning on this problem <ref> [ Kaplan, 1989 ] </ref> . Newell was first to discuss the role of representation in AI problem solving: he showed that the complexity of reasoning in some games and puzzles strongly depends on the representation [ Newell, 1965; Newell, 1966 ] .
Reference: [ Knoblock et al., 1991 ] <author> Craig A. Knoblock, Josh Tenenberg, and Qiang Yang. </author> <title> Characterizing abstraction hierarchies for planning. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 692-697, </pages> <year> 1991. </year>
Reference-contexts: The importance of every predicate in a problem domain is represented by a natural number: the larger the number, the more important the predicate. Hierarchies generated by alpine are based on the following two constraints, which usually lead to a high efficiency of abstraction problem solving <ref> [ Knoblock et al., 1991 ] </ref> : For every operator Op in a problem domain, (1) if eff 1 and eff 2 are effects of Op, then Importance (eff 1 ) = Importance (eff 2 ); (2) if eff is an effect of Op and prec is a precondition of Op,
Reference: [ Knoblock, 1990 ] <author> Craig A. Knoblock. </author> <title> Learning abstraction hierarchies for problem solving. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 923-928, </pages> <year> 1990. </year>
Reference-contexts: These learning algorithms, however, are themselves representation-dependent: they easily learn useful information with some problem descriptions, but become helpless with others. For example, the alpine algorithm for learning abstraction hierarchies <ref> [ Knoblock, 1990 ] </ref> usually fails to generate a hierarchy when the domain contains unnecessary additional operators or the operator descriptions are too general [ Knoblock, 1991a; Fink and Yang, 1992 ] ; however, if the user selects a suitable domain description, alpine becomes very effective in reducing complexity of problem
Reference: [ Knoblock, 1991a ] <author> Craig A. Knoblock. </author> <title> Automatically Generating Abstractions for Problem Solving. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1991. </year> <note> Technical Report CMU-CS-91-120. </note>
Reference-contexts: For example, the alpine algorithm for learning abstraction hierarchies [ Knoblock, 1990 ] usually fails to generate a hierarchy when the domain contains unnecessary additional operators or the operator descriptions are too general <ref> [ Knoblock, 1991a; Fink and Yang, 1992 ] </ref> ; however, if the user selects a suitable domain description, alpine becomes very effective in reducing complexity of problem solving. <p> Most problem-solvers find the solution to the puzzle by an extensive search; the search time grows exponentially with the length of a solution plan. The search could be reduced by using an abstraction hierarchy of predicates <ref> [ Knoblock, 1991a ] </ref> , but the problem description in Figure 2 (b) does not allow us to generate a hierarchy of predicates, since this description contains only one predicate. <p> In complex domains, however, the full instantiation leads to a combinatorial explosion in the number of instantiated predicates and operators. Knoblock proposed a more sophisticated technique for replacing general predicates with specific ones, in which the user divides the values of variables into classes <ref> [ Knoblock, 1991a ] </ref> .
Reference: [ Knoblock, 1991b ] <author> Craig A. Knoblock. </author> <title> Search reduction in hierarchical problem solving. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 686-691, </pages> <year> 1991. </year>
Reference: [ Knoblock, 1994 ] <author> Craig A. Knoblock. </author> <title> Automatically generating abstractions for planning. </title> <journal> Artificial Intelligence, </journal> <volume> 68, </volume> <year> 1994. </year>
Reference-contexts: Every problem representation leaves some information implicit. Explicit representation of important information improves the performance. For example, we may improve the efficiency of a problem-solving system by encoding useful information about the domain in control rules [ Minton, 1988 ] or an abstraction hierarchy <ref> [ Knoblock, 1994 ] </ref> . <p> problem by designing learning algorithms that deduce important information from the domain description [ Newell et al., 1960; 1 Allen et al., 1992; Carbonell, 1990 ] , which includes learning control rules [ Langley, 1983; Laird et al., 1986; Minton, 1988; Veloso and Borrajo, 1994 ] , generating abstraction hierarchies <ref> [ Knoblock, 1994 ] </ref> , replacing operators with macros [ Korf, 1985; Mooney, 1988 ] , and reusing past problem-solving cases [ Carbonell, 1983; Hall, 1987; Veloso, 1994 ] . <p> Research on the automatic generation of new problem representations has been limited to several special cases of representation changes, including systems for decomposing a problem into subproblems [ Newell et al., 1960 ] , generating abstraction hierarchies <ref> [ Knoblock, 1994; Christensen, 1990; Bacchus and Yang, 1994 ] </ref> , replacing operators with macros [ Korf, 1985; Shell and Carbonell, 1989 ] , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and <p> three rockets and three moons, whereas the original description worked for any number of rockets and moons; thus, we have improved efficiency by limiting the set of problems that we can solve. 2.2 Tower of Hanoi We now show an example of a representation change that enables the alpine algorithm <ref> [ Knoblock, 1994 ] </ref> to generate an abstraction hierarchy, which reduces prodigy's search. We consider the Tower-of-Hanoi puzzle with three disks (Figure 2a). The user may describe the states of this puzzle with a single predicate, (on &lt;disk&gt; &lt;peg&gt;), and the operations with the operator shown in Figure 2 (b). <p> The alpine abstraction-generator is a very fast, polynomial-time algorithm that generates an abstraction hierarchy of predicates <ref> [ Knoblock, 1994 ] </ref> . The importance of every predicate in a problem domain is represented by a natural number: the larger the number, the more important the predicate. <p> prim") for problems with different optimal-solution sizes. (Note that the time scale is logarithmic|the use of primary effects improves efficiency by two orders of magnitude.) 4.3 Margie: Primary effects in learning abstraction hierarchies We next apply our approach to developing a representation-changer that improves the effectiveness of the alpine abstraction-generator <ref> [ Knoblock, 1994 ] </ref> by selecting primary effects of operators.
Reference: [ Korf, 1980 ] <author> Richard E. Korf. </author> <title> Toward a model of representation changes. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 41-78, </pages> <year> 1980. </year>
Reference-contexts: A generalized model of representation changes was suggested by Korf, who formalized the concept of problem reformulation based on the notions of isomorphism and homomorphism of search spaces <ref> [ Korf, 1980 ] </ref> . Korf's model, however, does not address "a method for evaluating the efficiency of a representation relative to a particular problem solver and heuristics to guide the search for an efficient representation for a problem" ( [ Korf, 1980 ] , page 75), whereas the use of <p> on the notions of isomorphism and homomorphism of search spaces <ref> [ Korf, 1980 ] </ref> . Korf's model, however, does not address "a method for evaluating the efficiency of a representation relative to a particular problem solver and heuristics to guide the search for an efficient representation for a problem" ( [ Korf, 1980 ] , page 75), whereas the use of such heuristics is essential for developing an efficient representation-changing system. To summarize, the results in representation changes in problem solving are still very limited.
Reference: [ Korf, 1985 ] <author> Richard E. Korf. Macro-operators: </author> <title> A week method for learning. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 35-77, </pages> <year> 1985. </year>
Reference-contexts: from the domain description [ Newell et al., 1960; 1 Allen et al., 1992; Carbonell, 1990 ] , which includes learning control rules [ Langley, 1983; Laird et al., 1986; Minton, 1988; Veloso and Borrajo, 1994 ] , generating abstraction hierarchies [ Knoblock, 1994 ] , replacing operators with macros <ref> [ Korf, 1985; Mooney, 1988 ] </ref> , and reusing past problem-solving cases [ Carbonell, 1983; Hall, 1987; Veloso, 1994 ] . These learning algorithms, however, are themselves representation-dependent: they easily learn useful information with some problem descriptions, but become helpless with others. <p> the automatic generation of new problem representations has been limited to several special cases of representation changes, including systems for decomposing a problem into subproblems [ Newell et al., 1960 ] , generating abstraction hierarchies [ Knoblock, 1994; Christensen, 1990; Bacchus and Yang, 1994 ] , replacing operators with macros <ref> [ Korf, 1985; Shell and Carbonell, 1989 ] </ref> , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and Etzioni, 1992; Veloso and Borrajo, 1994 ] , and reusing past problem-solving episodes in analogical <p> Researchers have developed theoretical frameworks for some special cases of representation changes, most notably generating abstraction hierarchies [ Korf, 1987; Knoblock, 1991b; Knoblock et al., 1991; Bacchus and Yang, 1992; Giunchiglia and Walsh, 1992 ] , replacing operators with macros <ref> [ Korf, 1985; Korf, 1987; Mooney, 1988 ] </ref> , and learning control rules [ Cohen, 1992 ] .
Reference: [ Korf, 1987 ] <author> Richard E. Korf. </author> <title> Planning as search: A quantitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 65-88, </pages> <year> 1987. </year>
Reference-contexts: Researchers have developed theoretical frameworks for some special cases of representation changes, most notably generating abstraction hierarchies [ Korf, 1987; Knoblock, 1991b; Knoblock et al., 1991; Bacchus and Yang, 1992; Giunchiglia and Walsh, 1992 ] , replacing operators with macros <ref> [ Korf, 1985; Korf, 1987; Mooney, 1988 ] </ref> , and learning control rules [ Cohen, 1992 ] .
Reference: [ Laird et al., 1986 ] <author> John E. Laird, Paul S. Rosenbloom, and Allen Newell. </author> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 11-46, </pages> <year> 1986. </year>
Reference: [ Laird et al., 1987 ] <author> John E. Laird, Allen Newell, and Paul S. Rosenbloom. </author> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: Newell was first to discuss the role of representation in AI problem solving: he showed that the complexity of reasoning in some games and puzzles strongly depends on the representation [ Newell, 1965; Newell, 1966 ] . Later, Newell with several other researchers implemented the Soar system <ref> [ Laird et al., 1987; Newell, 1992 ] </ref> , capable of using different descriptions of a problem domain to facilitate problem solving and learning. Soar, however, does not generate new representations; the human user must provide all domain descriptions.
Reference: [ Langley, 1983 ] <author> Pat Langley. </author> <title> Learning effective search heuristics. </title> <booktitle> In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 419-421, </pages> <year> 1983. </year>
Reference: [ Larkin and Simon, 1981 ] <author> Jill Larkin and Herbert A. Simon. </author> <title> Learning through growth of skill in mental modeling. </title> <booktitle> In Proceedings of the Third Annual Conference of the Cognitive Science Society, </booktitle> <year> 1981. </year>
Reference: [ Larkin and Simon, 1987 ] <author> Jill H. Larkin and Herbert A. Simon. </author> <title> Why a diagram is (sometimes) worth ten thousand words. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 65-99, </pages> <year> 1987. </year>
Reference-contexts: People often simplify problems by changing their description, which is a crucial skill for mathematicians [ Polya, 1957 ] , physicists <ref> [ Qin and Simon, 1992; Larkin and Simon, 1987 ] </ref> , economists [ Tabachneck, 1992; Larkin and Simon, 1987 ] , and experts in many other areas [ Newell and Simon, 1972; Gentner and Stevens, 1983 ] . <p> People often simplify problems by changing their description, which is a crucial skill for mathematicians [ Polya, 1957 ] , physicists [ Qin and Simon, 1992; Larkin and Simon, 1987 ] , economists <ref> [ Tabachneck, 1992; Larkin and Simon, 1987 ] </ref> , and experts in many other areas [ Newell and Simon, 1972; Gentner and Stevens, 1983 ] . The purpose of our research is to automate the process of changing and improving problem representations. <p> Simon, in collaboration with several other researchers, has analyzed the role of representation in mathematics <ref> [ Larkin and Simon, 1987 ] </ref> , physics [ Larkin and Simon, 1981; Larkin and Simon, 1987; Qin and Simon, 1992 ] , and economics [ Tabachneck, 1992 ] , and demonstrated that the use of good representations is essential for reasoning in these areas. <p> We now discuss some other research problems on automatic representation changes, which we plan to address. We follow Simon's view of representations as "data structures and programs operating on them" ( <ref> [ Larkin and Simon, 1987 ] </ref> , page 67). In an AI system, the programs are problem-solving algorithms; the data structures are the inputs of these algorithms, which may include operators, control rules, macros, libraries of past problem-solving episodes, etc.
Reference: [ Larkin et al., 1988 ] <author> Jill H. Larkin, Frederick Reif, Jaime G. Carbonell, and Angela Gugliotta. </author> <title> fermi: A flexible expert reasoner with multi-domain inferencing. </title> <journal> Cognitive Psychology, </journal> <volume> 12 </volume> <pages> 101-138, </pages> <year> 1988. </year>
Reference-contexts: Soar, however, does not generate new representations; the human user must provide all domain descriptions. A similar approach was used in the fermi expert system <ref> [ Larkin et al., 1988 ] </ref> , which automatically selects a representation for a given problem among several hand-coded representations.
Reference: [ Minton, 1988 ] <author> Steven Minton. </author> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mel-lon University, </institution> <year> 1988. </year> <note> Technical Report CMU-CS-88-133. </note>
Reference-contexts: Every problem representation leaves some information implicit. Explicit representation of important information improves the performance. For example, we may improve the efficiency of a problem-solving system by encoding useful information about the domain in control rules <ref> [ Minton, 1988 ] </ref> or an abstraction hierarchy [ Knoblock, 1994 ] .
Reference: [ Mooney, 1988 ] <author> Raymond J. Mooney. </author> <title> Generalizing the order of operators in macro-operators. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 270-283, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: from the domain description [ Newell et al., 1960; 1 Allen et al., 1992; Carbonell, 1990 ] , which includes learning control rules [ Langley, 1983; Laird et al., 1986; Minton, 1988; Veloso and Borrajo, 1994 ] , generating abstraction hierarchies [ Knoblock, 1994 ] , replacing operators with macros <ref> [ Korf, 1985; Mooney, 1988 ] </ref> , and reusing past problem-solving cases [ Carbonell, 1983; Hall, 1987; Veloso, 1994 ] . These learning algorithms, however, are themselves representation-dependent: they easily learn useful information with some problem descriptions, but become helpless with others. <p> Researchers have developed theoretical frameworks for some special cases of representation changes, most notably generating abstraction hierarchies [ Korf, 1987; Knoblock, 1991b; Knoblock et al., 1991; Bacchus and Yang, 1992; Giunchiglia and Walsh, 1992 ] , replacing operators with macros <ref> [ Korf, 1985; Korf, 1987; Mooney, 1988 ] </ref> , and learning control rules [ Cohen, 1992 ] .
Reference: [ Newell and Simon, 1972 ] <author> Allen Newell and Herbert A. Simon. </author> <title> Human Problem Solving. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: People often simplify problems by changing their description, which is a crucial skill for mathematicians [ Polya, 1957 ] , physicists [ Qin and Simon, 1992; Larkin and Simon, 1987 ] , economists [ Tabachneck, 1992; Larkin and Simon, 1987 ] , and experts in many other areas <ref> [ Newell and Simon, 1972; Gentner and Stevens, 1983 ] </ref> . The purpose of our research is to automate the process of changing and improving problem representations.
Reference: [ Newell et al., 1960 ] <author> Allen Newell, J. C. Shaw, and Herbert A. Simon. </author> <title> A variety of intelligent learning in a general problem solver. </title> <editor> In Marshall C. Yovits, editor, </editor> <booktitle> International Tracts in Computer Science and Technology and Their Applications, volume 2: Self-Organizing Systems, </booktitle> <pages> pages 153-189. </pages> <publisher> Pergamon Press, </publisher> <address> New York, NY, </address> <year> 1960. </year> <month> 28 </month>
Reference-contexts: Research on the automatic generation of new problem representations has been limited to several special cases of representation changes, including systems for decomposing a problem into subproblems <ref> [ Newell et al., 1960 ] </ref> , generating abstraction hierarchies [ Knoblock, 1994; Christensen, 1990; Bacchus and Yang, 1994 ] , replacing operators with macros [ Korf, 1985; Shell and Carbonell, 1989 ] , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by
Reference: [ Newell, 1965 ] <author> Allen Newell. </author> <title> Limitations of the current stock of ideas about problem solving. </title> <editor> In A. Kent and O. Tualbee, editors, </editor> <title> Electronic Information Handling. </title> <publisher> Spartan Books, </publisher> <address> Washington, DC, </address> <year> 1965. </year>
Reference-contexts: Newell was first to discuss the role of representation in AI problem solving: he showed that the complexity of reasoning in some games and puzzles strongly depends on the representation <ref> [ Newell, 1965; Newell, 1966 ] </ref> . Later, Newell with several other researchers implemented the Soar system [ Laird et al., 1987; Newell, 1992 ] , capable of using different descriptions of a problem domain to facilitate problem solving and learning.
Reference: [ Newell, 1966 ] <author> Allen Newell. </author> <title> On the representations of problems. </title> <institution> In Computer Science Research Reviews. Carnegie Institute of Technology, </institution> <address> Pittsburgh, PA, </address> <year> 1966. </year>
Reference-contexts: Newell was first to discuss the role of representation in AI problem solving: he showed that the complexity of reasoning in some games and puzzles strongly depends on the representation <ref> [ Newell, 1965; Newell, 1966 ] </ref> . Later, Newell with several other researchers implemented the Soar system [ Laird et al., 1987; Newell, 1992 ] , capable of using different descriptions of a problem domain to facilitate problem solving and learning.
Reference: [ Newell, 1992 ] <author> Allen Newell. </author> <title> Unified theories of cognition and the role of Soar. </title> <editor> In J. A. Michon and A. Akyurek, editors, </editor> <booktitle> Soar: A Cognitive Architecture in Perspective, </booktitle> <pages> pages 25-79. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Netherlands, </address> <year> 1992. </year>
Reference-contexts: Newell was first to discuss the role of representation in AI problem solving: he showed that the complexity of reasoning in some games and puzzles strongly depends on the representation [ Newell, 1965; Newell, 1966 ] . Later, Newell with several other researchers implemented the Soar system <ref> [ Laird et al., 1987; Newell, 1992 ] </ref> , capable of using different descriptions of a problem domain to facilitate problem solving and learning. Soar, however, does not generate new representations; the human user must provide all domain descriptions.
Reference: [ Perez and Etzioni, 1992 ] <author> M. Alicia Perez and Oren Etzioni. </author> <title> dynamic: A new role for training problems in EBL. </title> <editor> In D. Sleeman and P. Edwards, editors, </editor> <booktitle> Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [ Polya, 1957 ] <author> George Polya. </author> <title> How to Solve It. </title> <publisher> Doubleday, </publisher> <address> Garden City, NY, </address> <note> second edition, </note> <year> 1957. </year>
Reference-contexts: People often simplify problems by changing their description, which is a crucial skill for mathematicians <ref> [ Polya, 1957 ] </ref> , physicists [ Qin and Simon, 1992; Larkin and Simon, 1987 ] , economists [ Tabachneck, 1992; Larkin and Simon, 1987 ] , and experts in many other areas [ Newell and Simon, 1972; Gentner and Stevens, 1983 ] . <p> An important next step in AI research is to develop a system that automatically finds good representations. 1.2 Related work The importance of good representations has long been recognized by experts in many areas, most notably mathematicians <ref> [ Polya, 1957 ] </ref> . <p> We will concentrate on the efficiency-improving representation changes. We distinguish two main classes of representation changes: decomposing a problem into subproblems and reformulating a problem. 9 Decomposing a problem into subproblems. We can often decompose a hard problem into several simpler subproblems (Figure 5a) <ref> [ Polya, 1957 ] </ref> , as we did in the Interurban-Transportation example (Section 2.3). To perform such a decomposition, we need some approximate measure of the difficulty of problems in the domain. Subproblems may interact with each other, in which case certain subproblems must be solved before others.
Reference: [ Qin and Simon, 1992 ] <author> Yulin Qin and Herbert A. Simon. </author> <title> Imagery and mental models in problem solving. </title> <editor> In N. Hari Narayanan, editor, </editor> <booktitle> Proceedings of the AAAI 1992 Spring Symposium on Reasoning with Diagrammatic Representations, </booktitle> <address> Palo Alto, CA, </address> <year> 1992. </year> <institution> Stan-ford University. </institution>
Reference-contexts: People often simplify problems by changing their description, which is a crucial skill for mathematicians [ Polya, 1957 ] , physicists <ref> [ Qin and Simon, 1992; Larkin and Simon, 1987 ] </ref> , economists [ Tabachneck, 1992; Larkin and Simon, 1987 ] , and experts in many other areas [ Newell and Simon, 1972; Gentner and Stevens, 1983 ] .
Reference: [ Sacerdoti, 1974 ] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2) </volume> <pages> 115-135, </pages> <year> 1974. </year>
Reference-contexts: we use the number of operators in the reduced set as an objective function for estimating the problem-solving efficiency: the fewer operators, the more efficient problem solving. 13 Generating an abstraction hierarchy: Decomposing the set of predicates in a domain de-scription into several subsets, according to the "importance" of predicates <ref> [ Sacerdoti, 1974 ] </ref> . Replacing operators with macros: Replacing some operators in a domain description with macros constructed from these operators [ Fikes et al., 1972 ] . Removing operators: Deleting unnecessary operators from a domain description (see the Three-Rocket example in Section 2.1).
Reference: [ Shell and Carbonell, 1989 ] <author> Peter Shell and Jaime G. Carbonell. </author> <title> Towards a general framework for composing disjunctive and iterative macro-operators. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: the automatic generation of new problem representations has been limited to several special cases of representation changes, including systems for decomposing a problem into subproblems [ Newell et al., 1960 ] , generating abstraction hierarchies [ Knoblock, 1994; Christensen, 1990; Bacchus and Yang, 1994 ] , replacing operators with macros <ref> [ Korf, 1985; Shell and Carbonell, 1989 ] </ref> , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and Etzioni, 1992; Veloso and Borrajo, 1994 ] , and reusing past problem-solving episodes in analogical
Reference: [ Simon et al., 1985 ] <author> Herbert A. Simon, K. Kotovsky, and J. R. Hayes. </author> <title> Why are some problems hard? Evidence from the Tower of Hanoi. </title> <journal> Cognitive Psychology, </journal> <volume> 17 </volume> <pages> 248-294, </pages> <year> 1985. </year>
Reference: [ Simon, 1975 ] <author> Herbert A. Simon. </author> <title> The functional equivalence of problem solving skills. </title> <journal> Cognitive Psychology, </journal> <volume> 7 </volume> <pages> 268-288, </pages> <year> 1975. </year>
Reference: [ Stone and Veloso, 1994 ] <author> Peter Stone and Manuela M. Veloso. </author> <title> Learning to solve complex planning problems: Finding useful auxiliary problems. </title> <booktitle> In Proceedings of the AAAI 1994 Fall Symposium on Planning and Learning, </booktitle> <pages> pages 137-141, </pages> <year> 1994. </year>
Reference-contexts: Then, we describe a complex problem that can be considerably simplified by finding a good representation (Section 2.3). 2.1 Three-rocket transportation Consider a planning domain with a planet, three moons, three rockets, and several boxes (see Figure 1a) <ref> [ Stone and Veloso, 1994 ] </ref> . Initially, all boxes and all three rockets are on the planet. A rocket can carry any number of boxes to any moon. <p> This description, however, makes the problem hard for prodigy: the system tries to use the same rocket for transporting boxes to different moons. prodigy performs a long search to discover that each rocket can go to only one moon <ref> [ Stone and Veloso, 1994 ] </ref> . If we increase the number of moons and rockets, the problem-solving time grows exponentially. We can use control rules to reduce the search, but the Three-Rocket domain requires a complex set of rules, which are difficult to hand-code or learn automatically.
Reference: [ Stone et al., 1994 ] <author> Peter Stone, Manuela M. Veloso, and Jim Blythe. </author> <title> The need for different domain-independent heuristics. </title> <booktitle> In Proceedings of the Second International Conference on AI Planning Systems, </booktitle> <pages> pages 164-169, </pages> <year> 1994. </year>
Reference-contexts: Different problem-solving algorithms use different information about the domain and, therefore, perform efficiently with different representations <ref> [ Stone et al., 1994 ] </ref> . There is no "universal" representation that works well with all algorithms. The task of finding a good representation is usually left to the human user.
Reference: [ Tabachneck, 1992 ] <author> Hermina J. M. Tabachneck. </author> <title> Computational Differences in Mental Representations: Effects of Mode of Data Presentation on Reasoning and Understanding. </title> <type> PhD thesis, </type> <institution> Department of Psychology, Carnegie Mellon University, </institution> <year> 1992. </year> <month> 29 </month>
Reference-contexts: People often simplify problems by changing their description, which is a crucial skill for mathematicians [ Polya, 1957 ] , physicists [ Qin and Simon, 1992; Larkin and Simon, 1987 ] , economists <ref> [ Tabachneck, 1992; Larkin and Simon, 1987 ] </ref> , and experts in many other areas [ Newell and Simon, 1972; Gentner and Stevens, 1983 ] . The purpose of our research is to automate the process of changing and improving problem representations. <p> Simon, in collaboration with several other researchers, has analyzed the role of representation in mathematics [ Larkin and Simon, 1987 ] , physics [ Larkin and Simon, 1981; Larkin and Simon, 1987; Qin and Simon, 1992 ] , and economics <ref> [ Tabachneck, 1992 ] </ref> , and demonstrated that the use of good representations is essential for reasoning in these areas.
Reference: [ Tamble et al., 1990 ] <author> Milind Tamble, Allen Newell, and Paul S. Rosenbloom. </author> <title> The problem of expensive chunks and its solution by restricting expressiveness. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 299-348, </pages> <year> 1990. </year>
Reference: [ Veloso and Borrajo, 1994 ] <author> Manuela M. Veloso and Daniel Borrajo. </author> <title> Learning strategy knowledge incrementally. </title> <booktitle> In Proceedings of the Sixth International Conference on Tools with Artificial Intelligence, </booktitle> <pages> pages 484-490, </pages> <address> New Orleans, LA, </address> <year> 1994. </year>
Reference-contexts: Algorithms for learning control rules are often ineffective for a too general or too specific description of predicates and operators <ref> [ Veloso and Borrajo, 1994 ] </ref> , but again we may improve their performance by using a suitable representation. To ensure the effectiveness of a learning algorithm in finding useful features of the problem domain, the human user needs to find a good representation for this algorithm.
Reference: [ Veloso, 1994 ] <author> Manuela M. Veloso. </author> <title> Planning and Learning by Analogical Reasoning. </title> <publisher> Springer Verlag, </publisher> <year> 1994. </year> <month> 30 </month>
Reference-contexts: al., 1992; Carbonell, 1990 ] , which includes learning control rules [ Langley, 1983; Laird et al., 1986; Minton, 1988; Veloso and Borrajo, 1994 ] , generating abstraction hierarchies [ Knoblock, 1994 ] , replacing operators with macros [ Korf, 1985; Mooney, 1988 ] , and reusing past problem-solving cases <ref> [ Carbonell, 1983; Hall, 1987; Veloso, 1994 ] </ref> . These learning algorithms, however, are themselves representation-dependent: they easily learn useful information with some problem descriptions, but become helpless with others. <p> 1985; Shell and Carbonell, 1989 ] , replacing problems with similar simpler problems [ Hibler, 1994 ] , 2 changing the search space by learning control rules [ Minton, 1988; Etzioni, 1993; Perez and Etzioni, 1992; Veloso and Borrajo, 1994 ] , and reusing past problem-solving episodes in analogical reasoning <ref> [ Carbonell, 1983; Veloso, 1994 ] </ref> . There has, however, been little research on the common principles underlying different types of representation-changers.
References-found: 57

