URL: http://www.cs.sunysb.edu/~prashant/docs/fgffq.ps
Refering-URL: http://www.cs.sunysb.edu/~prashant/
Root-URL: http://www.cs.sunysb.edu
Email: (chiueh, prashant)@cs.sunysb.edu  
Title: FGFFQ: A Scalable Real-Time Packet Scheduling Technique for Terabit Routers  
Author: Tzi-cker Chiueh Prashant Pradhan 
Address: NY 11794-4400  
Affiliation: Computer Science Department State University of New York at Stony Brook Stony Brook,  
Abstract: Weighted Fair Queuing (WFQ) is a packet scheduling technique that has been proposed and is currently used in modern network routers to provide end-to-end delay and bandwidth guarantees. Unfortunately the scalability of existing WFQ implementation techniques in large-scale backbone routers is relatively poor. Various approximation techniques have been proposed to improve WFQ's scheduling efficiency at the expense of looser performance bounds. This paper describes a packet scheduling technique called Fixed-Granularity Fluid Fair Queuing (FGFFQ), which is shown analytically and empirically to be more scalable than WFQ. The key idea in FGFFQ is to transparently add a simple and efficient multiplexing/demultiplexing mechanism above existing link-layer protocols so that network-layer packets do not have to be travel on network links in contiguous pieces. FGFFQ not only can completely eliminate WFQ's packet priority calculation and sorting overhead, but also can approximate the fluid fair queuing model by choosing appropriate scheduling granularities. In addition, the scheduling model of FGFFQ supports both work-conserving and non-work-conserving disciplines and can accommodate low-latency and low-bandwidth real-time connections such as Internet telephony applications without wasting network bandwidth resources. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Keshav, S., </author> <title> Congestion Control in Computer Networks, </title> <type> UCB/CSD 91/649, </type> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: Section 5 concludes this paper with a summary of major research results and an outline of on-going work. 2 Related Work Packetized weighted fair queueing is based upon the fluid processor sharing model [3]. WFQ has been discussed in <ref> [1] </ref> and an implementation and simulation study is reported in [2]. [2] discusses the performance cost of various data structures for the priority sorting required in WFQ and mainly considers insertion costs with varying number of connections and buffers. <p> That is, FGFFQ is expected to compare at least as favorably with WFQ in data transmission overhead as in the Suez prototype case. With custom data movement hardware, the real-time packet overhead is going to dominate the data copying overhead. The study in <ref> [1] </ref> showed that it takes close to 1000 instructions to insert a packet into a priority heap with per connection queueing, assuming that 1000 connections are sharing an output link.
Reference: [2] <author> Keshav, S., </author> <title> On the Efficient Implementation of Fair Queueing, </title> <journal> Journal of Internetworking: Research and Experience, V2, </journal> <volume> N3, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: Section 5 concludes this paper with a summary of major research results and an outline of on-going work. 2 Related Work Packetized weighted fair queueing is based upon the fluid processor sharing model [3]. WFQ has been discussed in [1] and an implementation and simulation study is reported in <ref> [2] </ref>. [2] discusses the performance cost of various data structures for the priority sorting required in WFQ and mainly considers insertion costs with varying number of connections and buffers. <p> WFQ has been discussed in [1] and an implementation and simulation study is reported in <ref> [2] </ref>. [2] discusses the performance cost of various data structures for the priority sorting required in WFQ and mainly considers insertion costs with varying number of connections and buffers.
Reference: [3] <author> Parekh, A., </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks, </title> <type> Ph.D. Dissertation, </type> <institution> Massachussetts Institute of Technology, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: Section 5 concludes this paper with a summary of major research results and an outline of on-going work. 2 Related Work Packetized weighted fair queueing is based upon the fluid processor sharing model <ref> [3] </ref>. WFQ has been discussed in [1] and an implementation and simulation study is reported in [2]. [2] discusses the performance cost of various data structures for the priority sorting required in WFQ and mainly considers insertion costs with varying number of connections and buffers. <p> Virtual Clock [4] assigns virtual service times independent of the system load by attempting to emulate a static TDM system. Hence, the priority calculation in VC is simple. However, as shown in <ref> [3] </ref> VC can punish packets for over-using the link during underload even if they are not affecting the guarantees of other active connections later.
Reference: [4] <author> Zhang, L., </author> <title> Virtual Clock : A new Traffic Control Algorithm for packet switching networks, </title> <booktitle> In Proceedings of ACM SIGCOMM 96, </booktitle> <address> p.19-29, Philadelphia, </address> <month> September </month> <year> 1990. </year> <month> 15 </month>
Reference-contexts: However, besides insertion costs into the appropriate data structure, another source of overhead in WFQ is the virtual time calculation upon packet arrivals which may involve an iterated deletion of connections that are no longer backlogged in the corresponding fluid model when that packet arrives. Virtual Clock <ref> [4] </ref> assigns virtual service times independent of the system load by attempting to emulate a static TDM system. Hence, the priority calculation in VC is simple.
Reference: [5] <author> Golestani, S., </author> <title> A Self-Clocked Fair Queueing Scheme for Broadband Applications, </title> <booktitle> In Proceed--ings of IEEE INFOCOMM 94, </booktitle> <address> p.636-646, Toronto, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Hence, the priority calculation in VC is simple. However, as shown in [3] VC can punish packets for over-using the link during underload even if they are not affecting the guarantees of other active connections later. Work in <ref> [5] </ref> attempts to do away with the virtual time computation overhead by using the finish time of the packet currently in service to approximate the system virtual time, at the cost of worsening the delay bounds. [11] uses a similar idea and uses the start tag of the packet currently in
Reference: [6] <author> Zhang, H. and Bennett, A.C.R. </author> <title> WF2Q : Worst-Case Fair Weighted Fair Queueing, </title> <booktitle> In Proceedings of IEEE INFOCOMM 96, </booktitle> <address> p.120-128, San Fransisco, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: The priority of transmission is determined based on an eligibility time and a delay bound. Eligibility times are controlled through the bandwdith reservation and any jitter bounds, if specified. The work, however, does not address the performance issues associated with implementing WFQ. 2 A different line of work in <ref> [6] </ref> attempts to improve packetized WFQ so that connections do not get over-served relative to the fluid model by selecting, at any time, the packet to transmit from just the subset of packets that would have started service in the fluid model by that time. 3 FGFFQ Scheduling Based on a
Reference: [7] <author> Golestani, S., </author> <title> Congestion-Free Transmission of Real Time Traffic in Packet Networks, </title> <booktitle> In Proceedings of IEEE INFOCOMM 96, </booktitle> <address> p.527-542, San Fransisco, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: The algorithm provides throughput fairness but gives large delay bounds. The issue of non-work conserving service disciplines to reduce burstiness of traffic inside the network has been addressed in scheduling mechanisms like jitter-EDD [8], HRR [9], Stop-and-Go <ref> [7] </ref> and RCSP [10]. Among these, decoupling of delay and bandwidth bounds can be achieved in jitter-EDD and RCSP. [12] also addresses the problem of delay-bandwidth decoupling by incorporating a delay parameter in the priority calculation equations of WFQ.
Reference: [8] <author> Verma, D., Zhang, H. and Ferrari, D., </author> <title> Guaranteeing delay-jitter bounds in packet switching networks, </title> <booktitle> In Proceedings of Tricomm 91, </booktitle> <address> p.35-46, Chapel Hill, </address> <month> april </month> <year> 1991. </year>
Reference-contexts: The algorithm provides throughput fairness but gives large delay bounds. The issue of non-work conserving service disciplines to reduce burstiness of traffic inside the network has been addressed in scheduling mechanisms like jitter-EDD <ref> [8] </ref>, HRR [9], Stop-and-Go [7] and RCSP [10]. Among these, decoupling of delay and bandwidth bounds can be achieved in jitter-EDD and RCSP. [12] also addresses the problem of delay-bandwidth decoupling by incorporating a delay parameter in the priority calculation equations of WFQ.
Reference: [9] <author> Kalmaneck, C., Kanakia, H. and Keshav, S., </author> <title> Rate COntrolled Servers for very high-speed networks, </title> <booktitle> In Proceedings of IEEE Global Telecommunications Conference, </booktitle> <address> p.300.3.1-300.3.9, San Diego, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: The algorithm provides throughput fairness but gives large delay bounds. The issue of non-work conserving service disciplines to reduce burstiness of traffic inside the network has been addressed in scheduling mechanisms like jitter-EDD [8], HRR <ref> [9] </ref>, Stop-and-Go [7] and RCSP [10]. Among these, decoupling of delay and bandwidth bounds can be achieved in jitter-EDD and RCSP. [12] also addresses the problem of delay-bandwidth decoupling by incorporating a delay parameter in the priority calculation equations of WFQ.
Reference: [10] <author> Zhang, H. and Ferrari, D., </author> <title> Rate Controlled Static Priority Queueing, </title> <booktitle> In Proceedings of IEEE INFOCOMM 93, </booktitle> <address> p.227-236, San Fransisco, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: The algorithm provides throughput fairness but gives large delay bounds. The issue of non-work conserving service disciplines to reduce burstiness of traffic inside the network has been addressed in scheduling mechanisms like jitter-EDD [8], HRR [9], Stop-and-Go [7] and RCSP <ref> [10] </ref>. Among these, decoupling of delay and bandwidth bounds can be achieved in jitter-EDD and RCSP. [12] also addresses the problem of delay-bandwidth decoupling by incorporating a delay parameter in the priority calculation equations of WFQ.
Reference: [11] <author> Goyal, P., Vin, H.M. and Cheng, H., </author> <title> Start-Time Fair Queueing : A Scheduling Algorithm for Integrated Services Packet Switching Networks, </title> <booktitle> In Proceedings of ACM SIGCOMM 96, </booktitle> <address> Stanford, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Work in [5] attempts to do away with the virtual time computation overhead by using the finish time of the packet currently in service to approximate the system virtual time, at the cost of worsening the delay bounds. <ref> [11] </ref> uses a similar idea and uses the start tag of the packet currently in service to approximate current virtual time.
Reference: [12] <author> Norival, R.F. and Pasquale, J., </author> <title> Leave-In-Time : A New Service Discipline for Real Time Communications in a Packet Switching Network, </title> <booktitle> In Proceedings of ACM SIGCOMM 95, </booktitle> <address> Cam-bridge, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: The issue of non-work conserving service disciplines to reduce burstiness of traffic inside the network has been addressed in scheduling mechanisms like jitter-EDD [8], HRR [9], Stop-and-Go [7] and RCSP [10]. Among these, decoupling of delay and bandwidth bounds can be achieved in jitter-EDD and RCSP. <ref> [12] </ref> also addresses the problem of delay-bandwidth decoupling by incorporating a delay parameter in the priority calculation equations of WFQ. The priority of transmission is determined based on an eligibility time and a delay bound. Eligibility times are controlled through the bandwdith reservation and any jitter bounds, if specified. <p> The above scheduling and MUDEM algorithms still work in this case, except that the receiver's connection-ID/output-queue map should allow multiple link-layer connections to be mapped to the same per-network-connection output queue. The work in <ref> [12] </ref> assigns connections to delay classes, where each delay class is characterized by a rate, which is the maximum amount of bandwidth that can be allocated to connections in that class, and a base delay, which is a measure of the delay that lower priority classes may suffer because of the <p> The admission control algorithm in <ref> [12] </ref> chooses a delay class to assign to a connection, taking into account the base delay of the higher priority classes and the rate allocation of that delay class.
Reference: [13] <author> Shreedhar, M. and Varghese, G., </author> <title> Efficient Fair Queueing using Deficit Round Robin, </title> <booktitle> In Proceedings of ACM SIGCOMM 95, </booktitle> <address> p.231-242, Cambridge, </address> <month> September </month> <year> 1995. </year> <month> 16 </month>
Reference-contexts: The finish tag of the packet is the start tag added to the weighted packet length. This does away with the large delay bounds of SCFQ. However, the implementation overhead is still logarithmic in the number of connections. Deficit Round Robin <ref> [13] </ref> serves connections in round robin order, attempting to service an amount proportional to its reservation on the average, while still respecting packet boundaries, by keeping track of the unused part of the reservation in a round and carrying it over to the next round.
References-found: 13

