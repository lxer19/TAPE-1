URL: http://www.math.macalester.edu/~fox/old/cs88/er-92-03.ps
Refering-URL: http://www.math.macalester.edu/~fox/old/cs88/cbr.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Abstract  
Abstract: Given an arbitrary learning situation, it is difficult to determine the most appropriate learning strategy. The goal of this research is to provide a general representation and processing framework for introspective reasoning for strategy selection. The learning framework for an introspective system is to perform some reasoning task. As it does, the system also records a trace of the reasoning itself, along with the results of such reasoning. If a reasoning failure occurs, the system retrieves and applies an introspective explanation of the failure in order to understand the error and repair the knowledge base. A knowledge structure called a Meta-Explanation Pattern is used to both explain how conclusions are derived and why such conclusions fail. If reasoning is represented in an explicit, declarative manner, the system can examine its own reasoning, analyze its reasoning failures, identify what it needs to learn, and select appropriate learning strategies in order to learn the required knowledge without overreli ance on the programmer.
Abstract-found: 1
Intro-found: 1
Reference: <author> Cox, M., & Ram, A. </author> <title> Using Introspective Reasoning to Select Learning Strategies. </title> <editor> in Michalski, R. & Tecuci, G. (eds), </editor> <booktitle> Proc. of 1st Intl. Workshop on Multi-Strategy Learning, </booktitle> <pages> 217-230, </pages> <year> 1991. </year>
Reference-contexts: If on the other hand, the reasoner retrieves a structure that later proves inappropriate, it must specialize the indices to this structure so that the retrieval will not recur in similar situations <ref> (Cox & Ram, 1991) </ref>. Novel Situation - A failure can arise when the reasoner does not have an appropriate knowledge structures to deal with a situation. <p> In order to perform this kind of reasoning, a new kind of knowledge structure was proposed, called a Meta-Explanation Pat D. Sleeman and P. Edwards (eds.), Machine Learning: Proceedings of the Ninth Inernational Conference, Aberdeen, Scotland (July, 1992), pp. 123-128. 124 Cox and Ram tern (Meta-XP) <ref> (Cox & Ram, 1991) </ref>. Meta-XPs are similar to explanation patterns (Schank, 1986), and are causal justifications of the reasoning performed by a system that explain how and why the system reasons. These structures form the bases for blame assignment and learning.
Reference: <author> Carbonell, J. G. </author> <title> Derivational Analogy: A theory of reconstructive problem solving and expertise acquisition, </title> <editor> in R. Michalski, J. Carbonell, & T. Mitchell (eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> 2, </volume> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA., </address> <year> 1986. </year>
Reference: <author> DeJong, G., & Mooney, R. </author> <title> Explanation-Based Learning: An Alternative View, </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176, </pages> <year> 1986. </year>
Reference: <author> Doyle, J. A. </author> <title> A Truth Maintenance System, </title> <journal> Artificial Intelli 128 Cox and Ram gence, </journal> (12):231-272, 1979. 
Reference-contexts: To represent these conditions, Meta-AQUA uses non-monotonic logic values of in (in the current set of beliefs) and out (out of the current set of beliefs) <ref> (Doyle, 1979) </ref>. Extended values include hypothesized-in (weakly assumed in) and hypothesized (unknown). Thus absolute retrieval failure is represented by A [truth = in] = E [truth = out].
Reference: <author> Flann, N., & Dietterich, T. </author> <title> A Study of Explanation-Based Methods for Inductive Learning. </title> <journal> Machine Learning. </journal> <volume> 4 </volume> <pages> 187-266, </pages> <year> 1989. </year>
Reference: <author> Genest, J., Matwin, S., & Plante, B. </author> <title> Explanation-Based Learning with Incomplete Theories: A three-step approach, </title> <booktitle> in Proc. of 7th Intl. Conf. on Machine Learning, </booktitle> <address> Austin, TX, </address> <month> (June), </month> <pages> 286-294, </pages> <year> 1990. </year>
Reference: <author> Hammond, K. </author> <title> Case-Based Planning: Viewing Planning as a Memory Task, </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1989. </year>
Reference: <author> Hunter, L. E. </author> <title> Planning to Learn. </title> <booktitle> in Proc. of 12th Annual Conf. of the Cognitive Science Society, </booktitle> <address> Cambridge, MA, </address> <month> (July), </month> <pages> 261-276, </pages> <year> 1990. </year>
Reference: <author> Michalski, R. S. </author> <title> Inferential Learning Theory as a Basis for Mul-tistrategy Task-Adaptive Learning. </title> <editor> In Michalski, R. S. & Tecuci, G. (eds.), </editor> <booktitle> Proc. of the 1st Intl. Workshop on Multi-Strategy Learning, </booktitle> <pages> 3-18, </pages> <year> 1991. </year>

Reference: <author> Ram, A. </author> <title> A Theory of Questions and Question Asking, </title> <journal> The Journal of the Learning Sciences, </journal> <volume> 1(3,4), </volume> <year> 1991. </year>
Reference-contexts: If on the other hand, the reasoner retrieves a structure that later proves inappropriate, it must specialize the indices to this structure so that the retrieval will not recur in similar situations <ref> (Cox & Ram, 1991) </ref>. Novel Situation - A failure can arise when the reasoner does not have an appropriate knowledge structures to deal with a situation. <p> Incorrect BK- Even if the reasoner has applicable knowledge structures, they may be incorrect or incomplete. Learning in such cases is usually incremental, involving strategies such as elaborative question asking <ref> (Ram, 1991, 1992) </ref> applied to the reasoning chain, and abstraction or generalization techniques applied to the BK. Meta-AQUA is a computer program that performs multi-strategy learning through self-analysis of its reasoning processes during a story understanding task. <p> In order to perform this kind of reasoning, a new kind of knowledge structure was proposed, called a Meta-Explanation Pat D. Sleeman and P. Edwards (eds.), Machine Learning: Proceedings of the Ninth Inernational Conference, Aberdeen, Scotland (July, 1992), pp. 123-128. 124 Cox and Ram tern (Meta-XP) <ref> (Cox & Ram, 1991) </ref>. Meta-XPs are similar to explanation patterns (Schank, 1986), and are causal justifications of the reasoning performed by a system that explain how and why the system reasons. These structures form the bases for blame assignment and learning.
Reference: <author> Ram, A. </author> <title> Indexing, Elaboration and Refinement: Incremental Learning of Explanatory Cases. </title> <note> To appear in Machine Learning. Also available as Tech. Report git-cc-92/04, </note> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <year> 1992. </year>
Reference-contexts: Novel Situation - A failure can arise when the reasoner does not have an appropriate knowledge structures to deal with a situation. In such cases, the reasoner could use a variety of learning strategies, including explanation-based generalization (EBG) (DeJong & Mooney, 1986; Mitch-ell, et al., 1986) or explanation-based refinement <ref> (Ram, 1992) </ref>, coupled with index learning (Hammond, 1989; Ram, 1992) for the new knowledge structures. Incorrect BK- Even if the reasoner has applicable knowledge structures, they may be incorrect or incomplete.
Reference: <author> Ram, A. and Hunter, L. </author> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning. </title> <note> To appear in Applied Intelligence. 2(1). </note>
Reference: <author> Schank, R. C. </author> <title> Explanation Patterns, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: Sleeman and P. Edwards (eds.), Machine Learning: Proceedings of the Ninth Inernational Conference, Aberdeen, Scotland (July, 1992), pp. 123-128. 124 Cox and Ram tern (Meta-XP) (Cox & Ram, 1991). Meta-XPs are similar to explanation patterns <ref> (Schank, 1986) </ref>, and are causal justifications of the reasoning performed by a system that explain how and why the system reasons. These structures form the bases for blame assignment and learning. There are two broad classes of Meta-XPs: Trace Meta-XPs and Introspective Meta-XPs.
Reference: <author> Shavlik, J. W., & Towell, G. G. </author> <title> An Approach to Combining Explanation-Based and Neural Learning Algorithms. </title> <journal> Connection Science. </journal> <volume> 1(3), </volume> <year> 1989. </year>
References-found: 14

