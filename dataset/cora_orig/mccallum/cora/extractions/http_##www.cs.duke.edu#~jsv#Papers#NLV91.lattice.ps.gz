URL: http://www.cs.duke.edu/~jsv/Papers/NLV91.lattice.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node3.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: I/O Overhead and Parallel VLSI Architectures for Lattice Computations  
Author: Mark H. Nodine, Daniel P. Lopresti, and Jeffrey S. Vitter 
Date: 1910  April 12, 1990  
Address: Box  Providence, RI 02912  
Affiliation: Dept. of Computer Science  Brown University  
Abstract: In this paper we introduce input/output (I/O) overhead as a complexity measure for VLSI implementations of two-dimensional lattice computations of the type arising in the simulation of physical systems. We show by pebbling arguments that = (n 1 ) when there are n 2 processing elements available. If the results are required to be observed at every generation, and no on-chip storage is allowed, we show the lower bound is the constant 2. We then examine four VLSI architectures and show that one of them, the multi-generation sweep architecture, also has I/O overhead proportional to n 1 . We compare the constants of proportionality between the lower bound and the architecture. Finally, we prove a closed-form for the discrete minimization equation giving the optimal number of generations to compute for the multi-generation sweep architecture. 
Abstract-found: 1
Intro-found: 1
Reference: [Coo] <author> S. A. Cook, </author> <title> "An Observation on Time-Storage Tradeoffs," </title> <booktitle> Proc. 5th Annual ACM Symposium on Theory of Computation (May 1973), </booktitle> <pages> 29-33. </pages>
Reference-contexts: Appendix A proves a closed form 2 for the optimal number of generations to compute in the multigeneration sweep architecture before viewing the results. Our conclusions are given in Section 4. 2 Lower Bounds on I/O Overhead Graph pebbling is a powerful technique for proving computational lower bounds <ref> [Coo, HoK, KSS, SaV] </ref>. For nine-cell lattice computations, a general result in Kugelmass et al. can be specialized to 8 ff assuming that each of n 2 processors (e.g. an n fi n array) has ff bits of local storage.
Reference: [Dew] <author> A. K. Dewdney, </author> <title> "Computer Recreations," </title> <booktitle> Scientific American 252 (May 1985), </booktitle> <pages> 18-30. 13 </pages>
Reference-contexts: Despite the apparent simplicity in having purely local rules govern the time evolution of the system, Life exhibits complex behavior and in fact possesses the same computational power as a Turing machine <ref> [Dew] </ref>. It also admits of a universal constructor to allow self-replicating structures [Pou]. Lattice computations have important applications in physical simulations. Examples of simulations that use such automata are two-dimensional lattice gas computations [KSS], diffusion-limited aggregation [MaT], two-dimensional diffusion, fluid dynamics, spin glasses, and ballistics [ToM].
Reference: [GKP] <author> R. L. Graham, D. E. Knuth, and O. Patashnik, </author> <title> in Concrete Mathe--matics, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989, </year> <note> Chapter 4. </note>
Reference: [HoK] <author> J.W. Hong and H.T. Kung, </author> <title> "I/O Complexity: The Red-Blue Pebble Game," </title> <booktitle> Proc. 13th Annual ACM Symposium on Theory of Computation (May 1981), </booktitle> <pages> 326-333. </pages>
Reference-contexts: Appendix A proves a closed form 2 for the optimal number of generations to compute in the multigeneration sweep architecture before viewing the results. Our conclusions are given in Section 4. 2 Lower Bounds on I/O Overhead Graph pebbling is a powerful technique for proving computational lower bounds <ref> [Coo, HoK, KSS, SaV] </ref>. For nine-cell lattice computations, a general result in Kugelmass et al. can be specialized to 8 ff assuming that each of n 2 processors (e.g. an n fi n array) has ff bits of local storage.
Reference: [KSS] <author> S.D. Kugelmass, R. Squier, and K. Steiglitz, </author> <title> "Performance of VLSI Engines for Lattice Computations," </title> <booktitle> Complex Systems 1 (October 1987), </booktitle> <pages> 939-965. </pages>
Reference-contexts: It also admits of a universal constructor to allow self-replicating structures [Pou]. Lattice computations have important applications in physical simulations. Examples of simulations that use such automata are two-dimensional lattice gas computations <ref> [KSS] </ref>, diffusion-limited aggregation [MaT], two-dimensional diffusion, fluid dynamics, spin glasses, and ballistics [ToM]. A VLSI circuit to solve the Poisson equation has been implemented using lattice computation techniques [Man]. <p> Highly local data movement coupled with a tremendous potential for parallelism would seem to make these problems an ideal match for VLSI. Kugelmass et al. showed, however, that VLSI-based machines performing such computations are severely constrained by input/output (I/O) requirements <ref> [KSS] </ref>. Using a simpler new argument, we improve by a constant factor the theoretical lower bound on I/O that can be derived from their work. We then present and analyze four VLSI architectures within this framework. <p> Appendix A proves a closed form 2 for the optimal number of generations to compute in the multigeneration sweep architecture before viewing the results. Our conclusions are given in Section 4. 2 Lower Bounds on I/O Overhead Graph pebbling is a powerful technique for proving computational lower bounds <ref> [Coo, HoK, KSS, SaV] </ref>. For nine-cell lattice computations, a general result in Kugelmass et al. can be specialized to 8 ff assuming that each of n 2 processors (e.g. an n fi n array) has ff bits of local storage.
Reference: [Man] <author> S. Manohar, </author> <title> "Superconducting with VLSI," </title> <institution> Brown Univ., </institution> <type> Ph.D. Thesis, </type> <year> 1988. </year>
Reference-contexts: Lattice computations have important applications in physical simulations. Examples of simulations that use such automata are two-dimensional lattice gas computations [KSS], diffusion-limited aggregation [MaT], two-dimensional diffusion, fluid dynamics, spin glasses, and ballistics [ToM]. A VLSI circuit to solve the Poisson equation has been implemented using lattice computation techniques <ref> [Man] </ref>. Highly local data movement coupled with a tremendous potential for parallelism would seem to make these problems an ideal match for VLSI. Kugelmass et al. showed, however, that VLSI-based machines performing such computations are severely constrained by input/output (I/O) requirements [KSS].
Reference: [MaT] <author> N. Margolus and T. Toffoli, </author> <title> "Cellular Automata Machines," </title> <booktitle> Complex Systems 1 (October 1987), </booktitle> <pages> 967-993. </pages>
Reference-contexts: It also admits of a universal constructor to allow self-replicating structures [Pou]. Lattice computations have important applications in physical simulations. Examples of simulations that use such automata are two-dimensional lattice gas computations [KSS], diffusion-limited aggregation <ref> [MaT] </ref>, two-dimensional diffusion, fluid dynamics, spin glasses, and ballistics [ToM]. A VLSI circuit to solve the Poisson equation has been implemented using lattice computation techniques [Man]. Highly local data movement coupled with a tremendous potential for parallelism would seem to make these problems an ideal match for VLSI. <p> The algorithm is changed slightly so that the array computes only (n k)=2 + 1 generations in step 4. Toffoli and Margolus mention this technique under the name "scooping", but do not analyze it from the standpoint of I/O efficiency <ref> [MaT, ToM] </ref>.
Reference: [Pou] <author> W. Poundstone, </author> <title> The Recursive Universe, Contemporary Books, </title> <address> Chicago, IL, </address> <year> 1985. </year>
Reference-contexts: Despite the apparent simplicity in having purely local rules govern the time evolution of the system, Life exhibits complex behavior and in fact possesses the same computational power as a Turing machine [Dew]. It also admits of a universal constructor to allow self-replicating structures <ref> [Pou] </ref>. Lattice computations have important applications in physical simulations. Examples of simulations that use such automata are two-dimensional lattice gas computations [KSS], diffusion-limited aggregation [MaT], two-dimensional diffusion, fluid dynamics, spin glasses, and ballistics [ToM]. A VLSI circuit to solve the Poisson equation has been implemented using lattice computation techniques [Man].
Reference: [SaV] <author> J.E. Savage and J.S. Vitter, </author> <title> "Parallelism in Space-Time Trade-Offs," </title> <booktitle> Advances in Computing Research 4 (1987), </booktitle> <pages> 117-146. </pages>
Reference-contexts: Appendix A proves a closed form 2 for the optimal number of generations to compute in the multigeneration sweep architecture before viewing the results. Our conclusions are given in Section 4. 2 Lower Bounds on I/O Overhead Graph pebbling is a powerful technique for proving computational lower bounds <ref> [Coo, HoK, KSS, SaV] </ref>. For nine-cell lattice computations, a general result in Kugelmass et al. can be specialized to 8 ff assuming that each of n 2 processors (e.g. an n fi n array) has ff bits of local storage.
Reference: [ToM] <author> T. Toffoli and N. Margolus, </author> <title> Cellular Automata Machines: A New Environment for Modeling, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: It also admits of a universal constructor to allow self-replicating structures [Pou]. Lattice computations have important applications in physical simulations. Examples of simulations that use such automata are two-dimensional lattice gas computations [KSS], diffusion-limited aggregation [MaT], two-dimensional diffusion, fluid dynamics, spin glasses, and ballistics <ref> [ToM] </ref>. A VLSI circuit to solve the Poisson equation has been implemented using lattice computation techniques [Man]. Highly local data movement coupled with a tremendous potential for parallelism would seem to make these problems an ideal match for VLSI. <p> In practice, of course, this scheme is not useful because it ignores problems larger than n fi n. 3.2 Array Sweep Architecture In this architecture, described by Toffoli <ref> [ToM] </ref>, the complete lattice computation is stored in an mfim grid of memory cells. The processor array repetitively loads n fi n subproblems, updates states by a single generation, and writes results back to their original off-chip locations. <p> The algorithm is changed slightly so that the array computes only (n k)=2 + 1 generations in step 4. Toffoli and Margolus mention this technique under the name "scooping", but do not analyze it from the standpoint of I/O efficiency <ref> [MaT, ToM] </ref>.
References-found: 10

