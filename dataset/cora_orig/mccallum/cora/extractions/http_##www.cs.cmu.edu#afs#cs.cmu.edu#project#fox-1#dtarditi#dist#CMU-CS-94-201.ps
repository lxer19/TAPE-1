URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/fox-1/dtarditi/dist/CMU-CS-94-201.ps
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/dtarditi/web/dtarditi-home.html
Root-URL: 
Title: Measuring the Cost of Storage Management  
Author: David Tarditi Amer Diwan 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: May 3, 1995  
Abstract: Submitted for publication. This paper is also published as Fox Memorandum CMU-CS-FOX-94-08. Abstract We study the cost of storage management for garbage-collected programs compiled with the Standard ML of New Jersey compiler. We show that the cost of storage management is not the same as the time spent garbage collecting. For many of the programs, the time spent garbage collecting is less than the time spent doing other storage-management tasks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> APPEL, A. W. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software Practice and Experience 19, </journal> <month> 2 (Feb. </month> <year> 1989), </year> <pages> 171-184. </pages>
Reference-contexts: In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection <ref> [22, 1, 2] </ref>. In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. <p> In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. The SML/NJ system uses a simple variant of generational copying garbage collection <ref> [1] </ref>. Memory is divided into an old generation and an allocation area. New objects are created in the allocation area. When the allocation area becomes full, the live data in the allocation area is copied to the old generation in a minor collection. <p> However, they give data for only Knuth-Bendix and YACC in their paper. 3.5 Garbage collection sizing parameters We used the default strategy for sizing the allocation area and the old generation <ref> [1] </ref>. The heap is sized as r times the size of the old generation after the old generation is collected, where r is the desired ratio of heap size to live data. We used the default system value (r=5).
Reference: [2] <author> APPEL, A. W. </author> <title> A Runtime System. </title> <booktitle> Lisp and Symbolic Computation 3, </booktitle> <address> 4 (Nov. </address> <year> 1990), </year> <pages> 343-380. </pages>
Reference-contexts: In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection <ref> [22, 1, 2] </ref>. In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused.
Reference: [3] <author> APPEL, A. W. </author> <title> Compiling with Continuations. </title> <publisher> Cam-bridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction We study the cost of storage management for garbage-collected programs compiled with the Standard ML of New Jersey compiler <ref> [3] </ref>. There are two motivations for conducting this study. First, we want to better understand the cost of storage management. Since costs due to storage management occur throughout the entire execution of a program, it is not adequate to measure only the time spent garbage collecting. <p> The SML/NJ compiler <ref> [3] </ref> is a state-of-the-art compiler for SML. We used version 0.91. The compiler concentrates on making allocation cheap and function calls fast. 2.3 Storage management in the SML/NJ sys tem Storage management in the SML/NJ system has many components. One component is garbage collection. <p> Live objects are copied using a Cheney scan [7], which copies objects in a breadth-first order. The criteria for when to collect the whole heap is described in Section 3.5. Generational garbage collection is efficient because most allocated objects die young (about 99% <ref> [3, p. 206] </ref>) and few objects are copied from the allocation area. Before an object can be allocated, the mutator must check whether there is sufficient space on the heap to allocate the object. If not, a garbage collection is needed. <p> Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel <ref> [3] </ref> 6 . Table 5 gives for each program its source code size in lines, its maximum heap size in kilobytes, its compiled code size in kilobytes, 7 and its running time in seconds on a DECsta-tion 5000/200. The source code size excludes comments and blank lines. <p> The compiled-code 4 Partial-word writes are treated differently, but since there are so few in our programs, we can ignore them in our discussion without loss of accuracy. 5 Available from the authors. 6 The description of these programs has been taken from <ref> [3] </ref>. 7 This includes 207 kilobytes of code for the standard libraries. 4 size excludes the size of the garbage collector and other run-time support code. The excluded code is about 60 kilobytes in size. The running time is the minimum of five runs.
Reference: [4] <author> APPEL, A. W., MATTSON, J. S., AND TARDITI, D. </author> <title> A lexical analyzer generator for Standard ML. Distributed with Standard ML of New Jersey, </title> <year> 1989. </year>
Reference-contexts: The input is the sample session from Section 7.5 of [8]. Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi <ref> [4] </ref>, processing the lexical description of Standard ML. Life The game of Life, written by Chris Reade [25], running 50 generations of a glider gun. It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image.
Reference: [5] <author> BALL, T., AND LARUS, J. R. </author> <title> Optimally profiling and tracing programs. </title> <booktitle> In Proceedings of the 19th Annual ACM Symposium on Principles of Programming Languages (Jan. 1992), ACM. </booktitle>
Reference-contexts: In addition, for position-dependent code, the table gives absolute addresses; whereas in position-independent code the table gives relative offsets and the address of the target must also be computed. 3.2 Trace generation We extended QPT (Quick Program Profiler and Tracer) <ref> [5, 21, 20] </ref> to produce memory traces for SML/NJ programs. QPT rewrites an executable program to produce compressed trace information; QPT also produces a corresponding regeneration program that expands the compressed trace into a full address trace.
Reference: [6] <author> CHASE, D. R. </author> <title> Safety considerations for storage allocation optimizations. </title> <booktitle> Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation 23, </booktitle> <month> 7 (July </month> <year> 1988), </year> <pages> 1-10. </pages>
Reference-contexts: The first three entries are the cost of garbage collection. The remaining rows are the storage management costs in the mutator. The one instruction-level cost of storage management that we do not measure is the effect of storage management on program optimization <ref> [6] </ref>. Diwan et al. [13] have presented techniques that allow extensive optimization even using copying collection with unambiguous roots. However, we do not measure this cost. Storage management also affects the memory-system cost incurred during mutation. We were unable to measure this effect directly.
Reference: [7] <author> CHENEY, C. </author> <title> A nonrecursive list compacting algorithm. </title> <journal> Communications of the ACM 13, </journal> <volume> 11 (Nov. </volume> <year> 1970), </year> <pages> 677-678. </pages>
Reference-contexts: In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection [22, 1, 2]. In copying garbage collection <ref> [17, 7] </ref>, an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. The SML/NJ system uses a simple variant of generational copying garbage collection [1]. <p> When the size of the old generation becomes sufficiently large, the entire heap is collected in a major collection. Live objects are copied using a Cheney scan <ref> [7] </ref>, which copies objects in a breadth-first order. The criteria for when to collect the whole heap is described in Section 3.5. Generational garbage collection is efficient because most allocated objects die young (about 99% [3, p. 206]) and few objects are copied from the allocation area.
Reference: [8] <author> CLEAVELAND, R., PARROW, J., AND STEFFEN, B. </author> <title> The Concurrency Workbench: A semantics-based tool for the verification of concurrent systems. </title> <journal> Transactions on Programming Languages and Systems 15, </journal> <month> 1 (Jan. </month> <year> 1993), </year> <pages> 36-72. </pages>
Reference-contexts: These costs were insignificant and are omitted from the graph. All the costs of garbage collection include memory-system costs. For mutation we measured 5 Program Description CW The Concurrency Workbench <ref> [8] </ref> is a tool for analyzing networks of finite state processes expressed in Milner's Calculus of Communicating Systems. The input is the sample session from Section 7.5 of [8]. Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. <p> All the costs of garbage collection include memory-system costs. For mutation we measured 5 Program Description CW The Concurrency Workbench <ref> [8] </ref> is a tool for analyzing networks of finite state processes expressed in Milner's Calculus of Communicating Systems. The input is the sample session from Section 7.5 of [8]. Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [4], processing the lexical description of Standard ML.
Reference: [9] <author> CROWLEY, W. P., HENDRICKSON, C. P., AND RUDY, T. E. </author> <title> The SIMPLE code. </title> <type> Tech. Rep. </type> <institution> UCID 17715, Lawrence Livermore Laboratory, Livermore, </institution> <address> CA, </address> <month> Feb. </month> <year> 1978. </year>
Reference-contexts: It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image. Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark <ref> [9] </ref>, translated into ID [16], and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin. YACC An LALR (1) parser generator, implemented by David R. Tarditi [30], processing the grammar of Standard ML.
Reference: [10] <author> CYPRESS SEMICONDUCTOR, ROSS TECHNOLOGY SUBSIDIARY. </author> <title> SPARC RISC User's Guide, second ed., </title> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: For the DECStation 5000/200 memory-system organization, which is favorable to heap allocation, increasing the allocation area size is unlikely to change the memory-system cost. Halving the cache size for the DECStation 5000/200 organization affects performance little [14, 15]. Some other memory-system organizations, such as the SPARC-StationII <ref> [10] </ref>, are more sensitive to cache size. Increasing the allocation area size can increase the memory-system cost greatly.
Reference: [11] <author> DETLEFS, D., DOSSER, A., AND ZORN, B. </author> <title> Memory allocation costs in large C and C++ programs. </title> <type> Tech. Rep. CU-CS-665-93, </type> <institution> University of Colorado, </institution> <year> 1993. </year>
Reference-contexts: He finds that tag insertion and removal costs about 4.5% with the best software scheme. There have been several studies of the cost of storage management in languages with explicitly-managed heap storage and stack allocation of procedure activation records. Detlefs <ref> [11] </ref> measures time spent in allocation and deallocation routines, but does not measure the cost of managing the stack.
Reference: [12] <author> DIGITAL EQUIPMENT CORPORATION. </author> <title> DS5000/200 KN02 System Module Functional Specification. </title>
Reference-contexts: Second, we want to identify bottlenecks in the storage-management strategy of the SML/NJ compiler and suggest potential improvements. We measure the cost of storage management for eight programs on a DECstation 5000/200 <ref> [12] </ref>. The measurements include most of the instruction-level and memory-system costs of storage management. We measure instructions spent garbage collecting, allocating, checking if garbage collection is necessary, tagging, implementing a write barrier, and making code relocatable so that it can be placed in the heap and garbage-collected. <p> We made the measurements using trace-driven simulation. This allowed us to count the instructions spent performing various tasks, such as tagging integers and implementing the write barrier. The memory simulator modeled the entire memory system of the DECStation 5000/200 <ref> [12] </ref>, which is favorable to programs which heap allocate intensively. A less favorable memory-system organization would increase the cost of storage management by increasing the cost of allocation [14, 15]. The remainder of the paper is organized as follows.
Reference: [13] <author> DIWAN, A., MOSS, J. E. B., AND HUDSON, R. L. </author> <title> Compiler support for garbage collection in a statically typed language. </title> <booktitle> In Proceedings of the SIG-PLAN '92 Conference on Programming Language Design and Implementation (San Francisco, </booktitle> <address> Califor-nia, </address> <month> June </month> <year> 1992), </year> <title> SIGPLAN, </title> <publisher> ACM Press, </publisher> <pages> pp. 273-282. </pages>
Reference-contexts: The first three entries are the cost of garbage collection. The remaining rows are the storage management costs in the mutator. The one instruction-level cost of storage management that we do not measure is the effect of storage management on program optimization [6]. Diwan et al. <ref> [13] </ref> have presented techniques that allow extensive optimization even using copying collection with unambiguous roots. However, we do not measure this cost. Storage management also affects the memory-system cost incurred during mutation. We were unable to measure this effect directly.
Reference: [14] <author> DIWAN, A., TARDITI, D., AND MOSS, E. </author> <title> Memory subsystem performance of programs with intensive heap allocation. </title> <type> Tech. Rep. </type> <institution> CMU-CS-93-227, School of Computer Science, Carnegie Mellon University, </institution> <month> Dec. </month> <year> 1993. </year> <note> Submitted for publication. </note>
Reference-contexts: The memory simulator modeled the entire memory system of the DECStation 5000/200 [12], which is favorable to programs which heap allocate intensively. A less favorable memory-system organization would increase the cost of storage management by increasing the cost of allocation <ref> [14, 15] </ref>. The remainder of the paper is organized as follows. Section 2 introduces terminology and describes the storage-management strategy used by the SML/NJ compiler. Section 3 describes the measurement techniques and benchmark programs. Section 4 presents measurements for eight SML/NJ programs. Section 5 reviews related work. <p> We extended QPT in two ways. First, we modified QPT and the SML/NJ system to produce traces for SML/NJ programs. Second, we added an event tracing facility to QPT. The changes to QPT and the SML/NJ system are described elsewhere <ref> [14, 15] </ref>. One important change we made to the SML/NJ system was to place code outside the heap so that it was not moved by garbage collection. In the original system, code was placed in the heap and it was moved by garbage collection. <p> The extensions to Tycho, described in <ref> [14, 15] </ref>, allow us to measure costs due to the entire memory system, not just the cache. Table 2 summarizes the memory system of the DEC-station 5000/200. The DECstation 5000/200 has a split instruction and data cache. <p> The DECstation also has a write buffer to avoid stalling the CPU on a write; the CPU needs to stall on a write only when the write-buffer fills up. This memory system is favorable to allocation-intensive programs <ref> [14, 15] </ref>. 3.4 Benchmark Programs The material in this section originally appeared elsewhere [15] and is repeated here to keep this paper self-contained. Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel [3] 6 . <p> For the DECStation 5000/200 memory-system organization, which is favorable to heap allocation, increasing the allocation area size is unlikely to change the memory-system cost. Halving the cache size for the DECStation 5000/200 organization affects performance little <ref> [14, 15] </ref>. Some other memory-system organizations, such as the SPARC-StationII [10], are more sensitive to cache size. Increasing the allocation area size can increase the memory-system cost greatly. <p> If there were a penalty for write misses 10 , the programs would run 24% to 72% slower than they do now <ref> [14, 15] </ref>. In other words, with a penalty for cache write misses, most of the cost of storage management would be for initializing newly-allocated objects.
Reference: [15] <author> DIWAN, A., TARDITI, D., AND MOSS, E. </author> <title> Memory subsystem performance of programs with copying garbage collection. </title> <booktitle> In Proceedings of the 21st Annual ACM Symposium on Principles of Programming languages (Portland, </booktitle> <address> Oregon, </address> <month> Jan. </month> <year> 1994), </year> <booktitle> ACM, </booktitle> <pages> pp. 1-14. </pages>
Reference-contexts: The memory simulator modeled the entire memory system of the DECStation 5000/200 [12], which is favorable to programs which heap allocate intensively. A less favorable memory-system organization would increase the cost of storage management by increasing the cost of allocation <ref> [14, 15] </ref>. The remainder of the paper is organized as follows. Section 2 introduces terminology and describes the storage-management strategy used by the SML/NJ compiler. Section 3 describes the measurement techniques and benchmark programs. Section 4 presents measurements for eight SML/NJ programs. Section 5 reviews related work. <p> All objects are tagged, so that garbage collection can find all live objects and copy them. All objects except integers have a header word which gives the kind and 1 An extendedbasic block is a block of code with only forward jumps. 2 This figure originally appeared elsewhere <ref> [15] </ref>. % check for heap overflow cmp alloc+12,top branch-if-gt call-gc % write the object store tag,(alloc) store ra,4 (alloc) store rd,8 (alloc) % save pointer to object move alloc+4,result % add 12 to alloc pointer add alloc,12 the size of the object. <p> We extended QPT in two ways. First, we modified QPT and the SML/NJ system to produce traces for SML/NJ programs. Second, we added an event tracing facility to QPT. The changes to QPT and the SML/NJ system are described elsewhere <ref> [14, 15] </ref>. One important change we made to the SML/NJ system was to place code outside the heap so that it was not moved by garbage collection. In the original system, code was placed in the heap and it was moved by garbage collection. <p> The extensions to Tycho, described in <ref> [14, 15] </ref>, allow us to measure costs due to the entire memory system, not just the cache. Table 2 summarizes the memory system of the DEC-station 5000/200. The DECstation 5000/200 has a split instruction and data cache. <p> The DECstation also has a write buffer to avoid stalling the CPU on a write; the CPU needs to stall on a write only when the write-buffer fills up. This memory system is favorable to allocation-intensive programs <ref> [14, 15] </ref>. 3.4 Benchmark Programs The material in this section originally appeared elsewhere [15] and is repeated here to keep this paper self-contained. Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel [3] 6 . <p> This memory system is favorable to allocation-intensive programs [14, 15]. 3.4 Benchmark Programs The material in this section originally appeared elsewhere <ref> [15] </ref> and is repeated here to keep this paper self-contained. Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel [3] 6 . <p> For the DECStation 5000/200 memory-system organization, which is favorable to heap allocation, increasing the allocation area size is unlikely to change the memory-system cost. Halving the cache size for the DECStation 5000/200 organization affects performance little <ref> [14, 15] </ref>. Some other memory-system organizations, such as the SPARC-StationII [10], are more sensitive to cache size. Increasing the allocation area size can increase the memory-system cost greatly. <p> If there were a penalty for write misses 10 , the programs would run 24% to 72% slower than they do now <ref> [14, 15] </ref>. In other words, with a penalty for cache write misses, most of the cost of storage management would be for initializing newly-allocated objects. <p> If data does not fit in the cache, increasing the size of the data leads to proportionately more cache misses. The effect of cache size on SML/NJ programs is explored thoroughly elsewhere <ref> [15] </ref>. There were no dramatic boundary conditions for SML/NJ programs on the DECStation 5000/200. Just as header words increase the size of data, storage-management instructions increase the size of a program. This may cause additional instruction-cache misses. <p> Zorn [34] compares the cost of two simulated garbage-collection algorithms. In contrast, we measure an actual implementation. He measures the memory-system cost using the cache-miss ratio, which is an inaccurate indicator of performance because it does not separate the cost of read and write misses <ref> [15] </ref>. Wilson et al.[33] and Peng and Sohi [24] also measure the memory-system cost of garbage collection using the cache-miss ratio. They do not measure the instruction-level cost of garbage collection or costs incurred during mutation.
Reference: [16] <author> EKANADHAM, K., AND ARVIND. </author> <title> SIMPLE: An exercise in future scientific programming. Technical Report Computation Structures Group Memo 273, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> July </month> <year> 1987. </year> <note> Simultaneously published as IBM/T. J. </note> <institution> Watson Research Center Research Report 12686, </institution> <address> Yorktown Heights, NY. </address> <month> 12 </month>
Reference-contexts: It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image. Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark [9], translated into ID <ref> [16] </ref>, and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin. YACC An LALR (1) parser generator, implemented by David R. Tarditi [30], processing the grammar of Standard ML.
Reference: [17] <author> FENICHEL, R. R., AND YOCHELSON, J. C. </author> <title> A LISP garbage-collector for virtual-memory computer systems. </title> <journal> Communications of the ACM 12, </journal> <volume> 11 (Nov. </volume> <year> 1969), </year> <pages> 611-612. </pages>
Reference-contexts: In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection [22, 1, 2]. In copying garbage collection <ref> [17, 7] </ref>, an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. The SML/NJ system uses a simple variant of generational copying garbage collection [1].
Reference: [18] <author> GRUNWALD, D., ZORN, B., AND HENDERSON, R. </author> <title> Improving the cache locality of memory allocation. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation (Albuquerque, </booktitle> <address> New Mexico, </address> <month> June </month> <year> 1993), </year> <booktitle> ACM, </booktitle> <pages> pp. 177-186. </pages>
Reference-contexts: There have been several studies of the cost of storage management in languages with explicitly-managed heap storage and stack allocation of procedure activation records. Detlefs [11] measures time spent in allocation and deallocation routines, but does not measure the cost of managing the stack. Grunwald et al. <ref> [18] </ref> finds that the implementation of explicit heap management can affect the performance of allocation-intensive C programs significantly. 6 Conclusion We have studied the cost of storage management for programs compiled with the SML/NJ compiler. Modern programming languages, such as SML, LISP, and object-oriented languages, use dynamic heap allocation extensively.
Reference: [19] <author> HILL, M., AND SMITH, A. </author> <title> Evaluating associativity in CPU caches. </title> <journal> IEEE Transactions on Computers 38, </journal> <month> 12 (Dec. </month> <year> 1989), </year> <pages> 1612-1630. </pages>
Reference-contexts: The tracing mechanism is non-intrusive: the traces produced by QPT correspond to addresses in the original programs rather than those in the instrumented programs. 3.3 Memory system simulation We simulated the DECstation 5000/200 memory system using an extended version of Tycho <ref> [19] </ref>, a cache simulator. The extensions to Tycho, described in [14, 15], allow us to measure costs due to the entire memory system, not just the cache. Table 2 summarizes the memory system of the DEC-station 5000/200. The DECstation 5000/200 has a split instruction and data cache.
Reference: [20] <author> LARUS, J. R. </author> <title> Abstract Execution: A technique for efficiently tracing programs. </title> <journal> Software Practice and Experience 20, </journal> <month> 12 (Dec. </month> <year> 1990), </year> <pages> 1241-1258. </pages>
Reference-contexts: In addition, for position-dependent code, the table gives absolute addresses; whereas in position-independent code the table gives relative offsets and the address of the target must also be computed. 3.2 Trace generation We extended QPT (Quick Program Profiler and Tracer) <ref> [5, 21, 20] </ref> to produce memory traces for SML/NJ programs. QPT rewrites an executable program to produce compressed trace information; QPT also produces a corresponding regeneration program that expands the compressed trace into a full address trace.
Reference: [21] <author> LARUS, J. R., AND BALL, T. </author> <title> Rewriting executable files to measure program behavior. </title> <type> Tech. Rep. Wis 1083, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: In addition, for position-dependent code, the table gives absolute addresses; whereas in position-independent code the table gives relative offsets and the address of the target must also be computed. 3.2 Trace generation We extended QPT (Quick Program Profiler and Tracer) <ref> [5, 21, 20] </ref> to produce memory traces for SML/NJ programs. QPT rewrites an executable program to produce compressed trace information; QPT also produces a corresponding regeneration program that expands the compressed trace into a full address trace.
Reference: [22] <author> LIEBERMAN, H., AND HEWITT, C. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM 26, </journal> <volume> 6 (1983), </volume> <pages> 419-429. </pages>
Reference-contexts: In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection <ref> [22, 1, 2] </ref>. In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused.
Reference: [23] <author> MILNER, R., TOFTE, M., AND HARPER, R. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The number of instructions executed to perform a task is the instruction-level cost of that task. The time spent by the processor waiting for memory while performing a task is the memory-system cost of that task. 2.2 Standard ML and the SML/NJ system Standard ML (SML) <ref> [23] </ref> is a call-by-value, lexically scoped language with higher-order functions, garbage collection, polymorphic static typing, provable safety properties, a sophisticated module system, and a dynamically-scoped exception mechanism. The SML/NJ compiler [3] is a state-of-the-art compiler for SML. We used version 0.91.
Reference: [24] <author> PENG, C.-J., AND SOHI, G. S. </author> <title> Cache memory design considerations to support languages with dynamic heap allocation. </title> <type> Tech. Rep. 860, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: In contrast, we measure an actual implementation. He measures the memory-system cost using the cache-miss ratio, which is an inaccurate indicator of performance because it does not separate the cost of read and write misses [15]. Wilson et al.[33] and Peng and Sohi <ref> [24] </ref> also measure the memory-system cost of garbage collection using the cache-miss ratio. They do not measure the instruction-level cost of garbage collection or costs incurred during mutation.
Reference: [25] <author> READE, C. </author> <title> Elements of Functional Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [4], processing the lexical description of Standard ML. Life The game of Life, written by Chris Reade <ref> [25] </ref>, running 50 generations of a glider gun. It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image.
Reference: [26] <author> REINHOLD, M. B. </author> <title> Cache Performance of Garbage-Collected Programming Languages. </title> <type> PhD thesis, </type> <institution> Laboratory for Computer Science, MIT, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: Wilson et al.[33] and Peng and Sohi [24] also measure the memory-system cost of garbage collection using the cache-miss ratio. They do not measure the instruction-level cost of garbage collection or costs incurred during mutation. Reinhold <ref> [26] </ref> measures the cost of garbage collection for a Scheme system, including the change in memory-system performance of entire programs, but does not measure costs incurred during mutation. Steenkiste [28] studies ways to reduce the cost of tagging in Lisp. He also studies instructions used for stack allocation.
Reference: [27] <author> REPPY, J. H. </author> <title> Asynchronous Signals in Standard ML. </title> <type> Tech. Rep. 90-1144, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: Checks are placed on many extended basic blocks that do not allocate, since these checks are also used to implement asynchronous signals <ref> [27] </ref>. Allocation is done in-line, except for the allocation of arrays and strings. Since the entire allocation area is always reclaimed, objects can be allocated sequentially from the allocation area in only two instructions. <p> This is despite the fact that the check and allocating an object both take two instructions on the MIPS, and that a check is sometimes for multiple allocations. We speculate that this is because the SML/NJ compiler overloads checks to implement asynchronous signals <ref> [27] </ref>.
Reference: [28] <author> STEENKISTE, P. </author> <title> LISP on a Reduced-Instruction-Set Processor: Characterization and Optimization. </title> <type> PhD thesis, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <address> Stanford,CA 94305, </address> <month> Mar. </month> <year> 1987. </year>
Reference-contexts: They do not measure the instruction-level cost of garbage collection or costs incurred during mutation. Reinhold [26] measures the cost of garbage collection for a Scheme system, including the change in memory-system performance of entire programs, but does not measure costs incurred during mutation. Steenkiste <ref> [28] </ref> studies ways to reduce the cost of tagging in Lisp. He also studies instructions used for stack allocation. He is primarily concerned with hardware support to improve tag checking required for dynamic typing. He finds that tag insertion and removal costs about 4.5% with the best software scheme.
Reference: [29] <author> STEFANOVI C, D., AND MOSS, E. </author> <title> Characterisation of object behavior in Standard ML of New Jersey. </title> <booktitle> In Proceedings of the 1994 ACM Conference on Lisp and Functional Programming (1994). </booktitle>
Reference-contexts: The percent of total allocation in the other column for PIA and Simple is large because those programs are floating-point intensive. Stefanovic and Moss <ref> [29] </ref> find that the allocation of callee-save continuation closures on the heap has a profound impact on the young-object dynamics of ML programs. In the programs they measured 9 , most objects are short-lived. They attribute the high mortality rate to the allocation of callee-save continuation closures on the heap.
Reference: [30] <author> TARDITI, D., AND APPEL, A. W. ML-YACC, </author> <title> version 2.0. Distributed with Standard ML of New Jersey, </title> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark [9], translated into ID [16], and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin. YACC An LALR (1) parser generator, implemented by David R. Tarditi <ref> [30] </ref>, processing the grammar of Standard ML.
Reference: [31] <author> UNGAR, D. </author> <title> The design and evaluation of a high performance Smalltalk system. </title> <publisher> ACM Distinguished Dissertation. MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1987. </year>
Reference-contexts: Figure 12 gives an estimate of the cost due to these extra instruction-cache misses for each of the programs. 5 Related work This study is more comprehensive in its measurements than previous works studying the cost of storage management in garbage-collected systems. Ungar <ref> [31] </ref> measures the time spent garbage collecting and the cost of integer Program Est. cost (% execution time) CW 1.8 Knuth-Bendix 0.1 Lexgen 0.9 Life 0.0 PIA 0.4 Simple 0.4 VLIW 3.8 YACC 1.1 Table 12: Estimate of instruction cache costs due to storage management instructions tagging in a Smalltalk system,
Reference: [32] <author> WAUGH, K. G., MCANDREW, P., AND MICHAEL-SON, G. </author> <title> Parallel implementations from function prototypes: a case study. </title> <type> Tech. Rep. </type> <institution> Computer Science 90/4, Heriot-Watt University, Edinburgh, </institution> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [4], processing the lexical description of Standard ML. Life The game of Life, written by Chris Reade [25], running 50 generations of a glider gun. It is implemented using lists. PIA A perspective inversion algorithm <ref> [32] </ref>, deciding the location of an object in a perspective video image. Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark [9], translated into ID [16], and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin.
Reference: [33] <author> WILSON, P. R., LAM, M. S., AND MOHER, T. G. </author> <title> Caching considerations for generational garbage collection: a case for large and set-associative caches. </title> <type> Tech. Rep. </type> <institution> EECS-90-5, University of Illinios at Chicago, </institution> <month> Dec. </month> <year> 1990. </year>
Reference: [34] <author> ZORN, B. G. </author> <title> Comparative Performance evaluation of garbage collection algorithms. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <address> CA 94720, </address> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: Zorn <ref> [34] </ref> compares the cost of two simulated garbage-collection algorithms. In contrast, we measure an actual implementation. He measures the memory-system cost using the cache-miss ratio, which is an inaccurate indicator of performance because it does not separate the cost of read and write misses [15].
References-found: 34

