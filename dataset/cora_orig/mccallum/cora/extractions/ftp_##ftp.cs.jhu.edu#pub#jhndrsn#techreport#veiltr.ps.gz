URL: ftp://ftp.cs.jhu.edu/pub/jhndrsn/techreport/veiltr.ps.gz
Refering-URL: http://www.cs.jhu.edu/~jhndrsn/research.html
Root-URL: http://www.cs.jhu.edu
Title: Finding Genes in DNA with a Hidden Markov Model  
Author: John Henderson Steven Salzberg Kenneth H. Fasman 
Date: Jan. 31, 1996, revised Aug. 28, 1996  
Abstract: This study describes a new Hidden Markov Model (HMM) system for segmenting uncharacterized genomic DNA sequences into exons, introns, and intergenic regions. Separate HMM modules were designed and trained for specific regions of DNA: exons, introns, intergenic regions, and splice sites. The models were then tied together to form a biologically feasible topology. The integrated HMM was trained further on a set of eukaryotic DNA sequences, and tested by using it to segment a separate set of sequences. The resulting HMM system, which is called VEIL (Viterbi Exon-Intron Locator), obtains an overall accuracy on test data of 92% of total bases correctly labelled, with a correlation coefficient of 0.68. Using the more stringent test of exact exon prediction, VEIL correctly located both ends of 46% of the exons. Moreover, more than 50% of the exons it predicts are exactly correct. These results compare favorably to the best previous results for gene structure prediction, and demonstrate the benefits of using HMMs for this problem.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Bahl, F. Jelinek, and R. Mercer. </author> <title> A maximum likelihood approach to continuous speech recognition. </title> <journal> IEEE Trans. on Acoustics, Speech, and Signal Processing, </journal> <pages> pages 308-319, </pages> <year> 1983. </year>
Reference-contexts: More details of the comparisons are given in Section 3. 2 2 HMMs for gene finding Hidden Markov Models have been remarkably successful in the field of speech recognition <ref> [1, 17] </ref>, where they are used in most state-of-the-art systems. Biological sequences, like speech, can be modelled as the output of a process that progresses through a series of discrete states, some of which are "hidden" to the observer.
Reference: [2] <author> P. Baldi, S. Brunak, Y. Chauvin, J. Engelbrecht, and A. Krogh. </author> <title> Hidden Markov models of human genes. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <volume> volume 6, </volume> <pages> pages 761-768. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: The directory pub/veil contains the executables and the database used in this study. 2 to use them for analysis of DNA and protein sequences. HMMs have been used for finding periodicities in DNA <ref> [2] </ref>, for exploring structural similarities of families of genes [6], for producing multiple sequence alignments [14, 3], for finding palindromic repeats [13], and for protein secondary structure prediction [7, 4, 8].
Reference: [3] <author> P. Baldi, Y. Chauvin, T. Hunkapiller, and M. McClure. </author> <title> Hidden Markov models of biological primary sequence information. </title> <journal> In Proc. Natl. Acad. Sci. USA, </journal> <volume> volume 91, </volume> <pages> pages 1059-1063, </pages> <month> February </month> <year> 1994. </year> <month> 20 </month>
Reference-contexts: The directory pub/veil contains the executables and the database used in this study. 2 to use them for analysis of DNA and protein sequences. HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes [6], for producing multiple sequence alignments <ref> [14, 3] </ref>, for finding palindromic repeats [13], and for protein secondary structure prediction [7, 4, 8]. Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise.
Reference: [4] <author> M. Brown, R. Hughey, A. Krogh, I. Mian, K. Sjolander, and D. Haussler. </author> <title> Using Dirichlet mixture priors to derive hidden Markov models for protein families. </title> <editor> In L. Hunter, D. Searls, and J. Shavlik, editors, </editor> <booktitle> Proc. First Internatl. Conf. on Intelligent Systems for Molecular Biology (ISMB-93), </booktitle> <pages> pages 47-55, </pages> <address> Menlo Park, CA, 1993. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes [6], for producing multiple sequence alignments [14, 3], for finding palindromic repeats [13], and for protein secondary structure prediction <ref> [7, 4, 8] </ref>. Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise. The VEIL system described herein demonstrates how to use HMMs to find complex gene structures in eukaryotic DNA sequences.
Reference: [5] <author> M. Burset and R. Guigo. </author> <title> Evaluation of gene structure prediction programs. </title> <journal> Ge-nomics, </journal> <volume> 34(3) </volume> <pages> 353-367, </pages> <year> 1996. </year>
Reference-contexts: Details of the models and the algorithms are explained below. VEIL has been tested on a database of 570 vertebrate sequences that was collected by Burset and Guigo <ref> [5] </ref> specifically to test gene-finding systems. Our cross-validated results show that VEIL obtains a summary accuracy of 92% of bases correctly labelled, with a sensitivity of 74% and specificity of 72% for exonic regions, and a correlation coefficient of 0.68. <p> Assumption number 3 is the only difference between a truly general gene-finder and VEIL; we assume that exactly one gene exists in the data, which of course is not necessarily true. Other benchmark experiments to date have also relied on this assumption <ref> [5] </ref>. Extending VEIL to relax this assumption is discussed below. <p> In order to compare VEIL to other gene finding systems, we used the database collected in the recent comprehensive study by Burset and Guigo <ref> [5] </ref>, comparing a number of the major gene-finding systems using a single database. This data consists of sequences from GenBank release 85.0 since January 1993, so it included relatively recent entries. <p> P (All) is the probability that we will mark any base correctly. A comparison of the results in Table 1 to the results in Table 1 of Burset and Guigo's comprehensive study of seven major gene-finding systems <ref> [5] </ref> shows that VEIL is competitive with any of those existing systems. <p> A number of systems have already reported major improvements by tying together a purely computational approach with a database search method. Burset and Guigo <ref> [5] </ref>, for example, found that systems that did this achieved a substantial increase in the accuracy of exact exon prediction, from a typical level of 40% on average to more than 60%.
Reference: [6] <author> G. Churchill. </author> <title> Hidden Markov chains and the analysis of genome structure. </title> <journal> Computers and Chemistry, </journal> <volume> 16(2) </volume> <pages> 107-115, </pages> <year> 1992. </year>
Reference-contexts: The directory pub/veil contains the executables and the database used in this study. 2 to use them for analysis of DNA and protein sequences. HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes <ref> [6] </ref>, for producing multiple sequence alignments [14, 3], for finding palindromic repeats [13], and for protein secondary structure prediction [7, 4, 8]. Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise.
Reference: [7] <author> A. Delcher, S. Kasif, H. Goldberg, and W. Hsu. </author> <title> Probabilistic prediction of protein secondary structure using causal networks. </title> <booktitle> In Proc. of the Eleventh National Conf. on Artificial Intelligence (AAAI-93), </booktitle> <pages> pages 316-321. </pages> <publisher> AAAI Press, </publisher> <month> July </month> <year> 1993. </year>
Reference-contexts: HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes [6], for producing multiple sequence alignments [14, 3], for finding palindromic repeats [13], and for protein secondary structure prediction <ref> [7, 4, 8] </ref>. Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise. The VEIL system described herein demonstrates how to use HMMs to find complex gene structures in eukaryotic DNA sequences.
Reference: [8] <author> A. L. Delcher, S. Kasif, H. R. Goldberg, and B. Hsu. </author> <title> Probabilistic prediction of protein secondary structure using causal networks. </title> <booktitle> In Proc. of the Eleventh National Conf. on Artificial Intelligence, </booktitle> <pages> pages 316-321, </pages> <year> 1993. </year>
Reference-contexts: HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes [6], for producing multiple sequence alignments [14, 3], for finding palindromic repeats [13], and for protein secondary structure prediction <ref> [7, 4, 8] </ref>. Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise. The VEIL system described herein demonstrates how to use HMMs to find complex gene structures in eukaryotic DNA sequences.
Reference: [9] <author> J. Fickett and C.-S. Tung. </author> <title> Assessment of protein coding measures. </title> <journal> Nucleic Acids Research, </journal> 20(24) 6441-6450, 1992. 
Reference-contexts: usage (certain codons and 3 E-M for HMMs is also commonly referred to as the Forward-backward or Baum-Welch algorithm. 4 dicodons appear more frequently in coding than in non-coding DNA) and periodicity (because of preferential codon usage, some bases show a tendency to appear every third position within coding regions) <ref> [9] </ref>. Another goal in the design of this model was to rule out in-frame stop codons. The model was initially trained on whole exons only, before being tied together with the other models as explained below. We designed a similar HMM to capture introns. <p> There are still three main stages which are traversed in order and cyclically. This is because, based on previous research <ref> [9] </ref>, there are differences in the frequency of codon usage between exons and introns, and VEIL is trying to capture those differences. All paths through the intron model start at the Donor Site model and exit through the Acceptor Site model.
Reference: [10] <author> X. Guan and E. Uberbacher. </author> <title> Alignments of DNA and protein sequences containing frameshift errors. </title> <journal> CABIOS, </journal> <volume> 12(1) </volume> <pages> 31-40, </pages> <year> 1996. </year>
Reference-contexts: Likewise with the start of transcription and translation some entries use the start codon to define the start of the first exon, even though this may not be technically correct. 7 The authors of GRAIL have proposed an iterative algorithm for removing apparent frame shifts <ref> [28, 10] </ref>. 2.6 Finding more than one parse By default, the Viterbi algorithm gives us the single best alignment of a sequence to our model, and this is what the current version of VEIL outputs.
Reference: [11] <author> R. Guigo, S. Knudsen, N. Drake, and T. Smith. </author> <title> Prediction of gene structure. </title> <journal> J. Mol. Biol., </journal> <volume> 226 </volume> <pages> 141-157, </pages> <year> 1992. </year>
Reference-contexts: Email: salzberg@cs.jhu.edu. z Genome Database, c/o Whitehead/MIT Center for Genome Research, One Kendall Square, Bldg. 300, Cambridge, MA 02139. Email: ken@gdb.org. 1 under development, and improvements continue to appear. Some of the leading systems are GRAIL [25], GeneID <ref> [11] </ref>, GeneParser [22], SORFIND [12], and FGENEH [24]. These systems use a variety of sophisticated computational techniques, including neural network algorithms, dynamic programming, rule-based methods, decision trees, and probabilistic reasoning.
Reference: [12] <author> G. Hutchinson and M. Hayden. </author> <title> The prediction of exons through an analysis of spliceable open reading frames. </title> <journal> Nucleic Acids Research, </journal> <volume> 20 </volume> <pages> 3453-3462, </pages> <year> 1992. </year>
Reference-contexts: Email: salzberg@cs.jhu.edu. z Genome Database, c/o Whitehead/MIT Center for Genome Research, One Kendall Square, Bldg. 300, Cambridge, MA 02139. Email: ken@gdb.org. 1 under development, and improvements continue to appear. Some of the leading systems are GRAIL [25], GeneID [11], GeneParser [22], SORFIND <ref> [12] </ref>, and FGENEH [24]. These systems use a variety of sophisticated computational techniques, including neural network algorithms, dynamic programming, rule-based methods, decision trees, and probabilistic reasoning.
Reference: [13] <author> K. Karplus. </author> <title> Using Markov models and Hidden Markov Models to find repetitive extragenic palindromic sequences in Escherichia coli. </title> <type> Technical Report UCSC-CRL-94-24, </type> <institution> University of California, </institution> <address> Santa Cruz, CA, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes [6], for producing multiple sequence alignments [14, 3], for finding palindromic repeats <ref> [13] </ref>, and for protein secondary structure prediction [7, 4, 8]. Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise. The VEIL system described herein demonstrates how to use HMMs to find complex gene structures in eukaryotic DNA sequences.
Reference: [14] <author> A. Krogh, M. Brown, I. Mian, K. Sjolander, and D. Haussler. </author> <title> Hidden Markov Models in computational biology: Applications to protein modeling. </title> <journal> J. of Molecular Biology, </journal> <volume> 235 </volume> <pages> 1501-1531, </pages> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: The directory pub/veil contains the executables and the database used in this study. 2 to use them for analysis of DNA and protein sequences. HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes [6], for producing multiple sequence alignments <ref> [14, 3] </ref>, for finding palindromic repeats [13], and for protein secondary structure prediction [7, 4, 8]. Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise.
Reference: [15] <author> A. Krogh, I. Mian, and D. Haussler. </author> <title> A hidden markov model that finds genes in E. Coli DNA. </title> <journal> Nucleic Acids Research, </journal> <volume> 22 </volume> <pages> 4768-4778, </pages> <year> 1994. </year> <month> 21 </month>
Reference-contexts: HMMs have been used for finding periodicities in DNA [2], for exploring structural similarities of families of genes [6], for producing multiple sequence alignments [14, 3], for finding palindromic repeats [13], and for protein secondary structure prediction [7, 4, 8]. Krogh et al. <ref> [15] </ref> have used HMMs to find genes in E. coli, where the problem of introns does not arise. The VEIL system described herein demonstrates how to use HMMs to find complex gene structures in eukaryotic DNA sequences.
Reference: [16] <author> D. Kulp, D. Haussler, M. G. Reese, and F. H. Eeckman. </author> <title> A generalized hidden Markov model for the recognition of human genes in DNA. </title> <booktitle> In ISMB-96: Proc. Fourth Internatl. Conf. Intelligent Systems for Molecular Biology, </booktitle> <pages> pages 134-141, </pages> <address> Menlo Park, CA, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Krogh et al. [15] have used HMMs to find genes in E. coli, where the problem of introns does not arise. The VEIL system described herein demonstrates how to use HMMs to find complex gene structures in eukaryotic DNA sequences. Kulp et al. <ref> [16] </ref> are also developing an HMM system for this task, using a generalized HMM architecture that is very different from VEIL's.
Reference: [17] <author> K.-F. Lee. </author> <title> Automatic Speech Recognition: The Development of the SPHINX System. </title> <publisher> Kluwer Academic, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: More details of the comparisons are given in Section 3. 2 2 HMMs for gene finding Hidden Markov Models have been remarkably successful in the field of speech recognition <ref> [1, 17] </ref>, where they are used in most state-of-the-art systems. Biological sequences, like speech, can be modelled as the output of a process that progresses through a series of discrete states, some of which are "hidden" to the observer. <p> Larger HMMs have many more free parameters and therefore require much more data for accurate training. These small models have nonetheless produced impressive results. 2.1 HMM basics Although HMMs cannot be covered in detail here, a brief introduction will be useful. For more a detailed description, see Lee <ref> [17] </ref> or Rabiner [19]. An HMM models a process in which some of the details are unknown, or hidden. Typically this process is stochastic in nature. <p> These algorithms are called the forward, Viterbi, and Expectation Maximization (E-M) algorithms. For our experiments, we only needed the Viterbi and E-M (sometimes called the Forward-Backward) algorithms, so we will only describe those algorithms here. This description is merely a summary; for details the reader should see Lee <ref> [17] </ref>. The E-M algorithm is used to solve what is known as the learning problem in HMMs; 11 i.e., to determine reasonable values for all the probabilities in an HMM. <p> In order to search efficiently for the best path, the Viterbi algorithm builds a data structure called a trellis, which requires O (ne) storage space. (For details of how the trellis is constructed, see <ref> [17] </ref>.) The trellis consists of a sequence of stages, one for each successive base in the input. Each stage contains one node for each state in the model.
Reference: [18] <author> S. Mount, X. Peng, and E. Meier. </author> <title> Some nasty little facts to bear in mind when predicting splice sites. In Gene-Finding and Gene Structure Prediction Workshop, </title> <address> Philadelphia, PA, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: The Donor model has 9 stages, and the Acceptor model has 15 stages. The lengths of these models were based on the lengths of the consensus sequences for donor and acceptor sites as given in Mount et al. <ref> [18] </ref> and Senapathy et al. [21].
Reference: [19] <author> L. Rabiner. </author> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <booktitle> Proc. of the IEEE, </booktitle> <pages> pages 257-286, </pages> <year> 1989. </year>
Reference-contexts: We have developed a training regimen that allows us to tie together these smaller HMMs into a single gene-finding system. 1 VEIL uses the well-known EM algorithm <ref> [19] </ref> to train all its models, and once the training is complete, it uses the Viterbi algorithm [26] to parse a new sequence into its component exons and introns. Details of the models and the algorithms are explained below. <p> These small models have nonetheless produced impressive results. 2.1 HMM basics Although HMMs cannot be covered in detail here, a brief introduction will be useful. For more a detailed description, see Lee [17] or Rabiner <ref> [19] </ref>. An HMM models a process in which some of the details are unknown, or hidden. Typically this process is stochastic in nature. Most commonly, HMMs are used to model sequential data or processes, which could be a sequence of nucleotides, sounds (for speech processing), or any other discrete sequence.
Reference: [20] <author> S. Salzberg, X. Chen, J. Henderson, and K. Fasman. </author> <title> Finding genes in DNA using decision trees and dynamic programming. </title> <booktitle> In ISMB-96: Proc. Fourth Internatl. Conf. Intelligent Systems for Molec. Bio., </booktitle> <pages> pages 201-210, </pages> <address> Menlo Park, CA, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: After the splice sites were fully trained, from the edge and state probabilities in those models, one could read off conditional probability matrices similar to the ones used in MORGAN <ref> [20] </ref>. These edges contain, after training, the conditional probability of observing base x in position i given that base y appears in position i 1. Unlike neural networks, the weights on the edges in HMMs have a clear, precise interpretation. <p> This assumption is important to other dynamic programming systems such as GRAIL [27] and MORGAN <ref> [20] </ref>, because it significantly reduces the number of alternative parses.
Reference: [21] <author> P. Senapathy, M. Shapiro, and N. Harris. </author> <title> Splice junctions, branch points, and exons: sequence statistics, identification, and applications to genome project. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 183 </volume> <pages> 252-278, </pages> <year> 1990. </year>
Reference-contexts: The Donor model has 9 stages, and the Acceptor model has 15 stages. The lengths of these models were based on the lengths of the consensus sequences for donor and acceptor sites as given in Mount et al. [18] and Senapathy et al. <ref> [21] </ref>. While the exon model will mark every state traversed in it with an e, and the intron model marks every state traversed in it with an i, the splice site models have some states indicating they are part of an exon and others that are part of an intron.
Reference: [22] <author> E. E. Snyder and G. D. Stormo. </author> <title> Identification of coding regions in genomic DNA sequences: An application of dynamic programming and neural networks. </title> <journal> Nucleic Acids Research, </journal> <volume> 21(3) </volume> <pages> 607-613, </pages> <year> 1993. </year>
Reference-contexts: Email: salzberg@cs.jhu.edu. z Genome Database, c/o Whitehead/MIT Center for Genome Research, One Kendall Square, Bldg. 300, Cambridge, MA 02139. Email: ken@gdb.org. 1 under development, and improvements continue to appear. Some of the leading systems are GRAIL [25], GeneID [11], GeneParser <ref> [22] </ref>, SORFIND [12], and FGENEH [24]. These systems use a variety of sophisticated computational techniques, including neural network algorithms, dynamic programming, rule-based methods, decision trees, and probabilistic reasoning.
Reference: [23] <author> E. E. Snyder and G. D. Stormo. </author> <title> Identification of coding regions in genomic DNA. </title> <journal> Journal of Molecular Biology, </journal> <volume> 248 </volume> <pages> 1-18, </pages> <year> 1995. </year>
Reference-contexts: It is unclear whether using the k best parses would provide much benefit, however, because the top ranking parses all look highly similar to one another, a phenomenon that has been observed in other systems as well <ref> [23] </ref>. 3 Methods and Results 3.1 The database of DNA sequences The final accuracy of the VEIL system, and the accuracy of the probabilities it learns, depend to a large extent on the quality and quantity of data used to train them.
Reference: [24] <author> V. Solovyev, A. Salamov, and C. Lawrence. </author> <title> Predicting internal exons by oligonu-cleotide composition and discriminant analysis of spliceable open reading frames. </title> <journal> Nucleic Acids Res., </journal> <volume> 22 </volume> <pages> 5156-5163, </pages> <year> 1994. </year>
Reference-contexts: Email: salzberg@cs.jhu.edu. z Genome Database, c/o Whitehead/MIT Center for Genome Research, One Kendall Square, Bldg. 300, Cambridge, MA 02139. Email: ken@gdb.org. 1 under development, and improvements continue to appear. Some of the leading systems are GRAIL [25], GeneID [11], GeneParser [22], SORFIND [12], and FGENEH <ref> [24] </ref>. These systems use a variety of sophisticated computational techniques, including neural network algorithms, dynamic programming, rule-based methods, decision trees, and probabilistic reasoning.
Reference: [25] <author> E. Uberbacher and R. </author> <title> Mural. Locating protein-coding regions in human DNA sequences by a multiple sensor-neural network approach. </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 88 </month> <pages> 11261-11265, </pages> <year> 1991. </year>
Reference-contexts: Email: salzberg@cs.jhu.edu. z Genome Database, c/o Whitehead/MIT Center for Genome Research, One Kendall Square, Bldg. 300, Cambridge, MA 02139. Email: ken@gdb.org. 1 under development, and improvements continue to appear. Some of the leading systems are GRAIL <ref> [25] </ref>, GeneID [11], GeneParser [22], SORFIND [12], and FGENEH [24]. These systems use a variety of sophisticated computational techniques, including neural network algorithms, dynamic programming, rule-based methods, decision trees, and probabilistic reasoning.
Reference: [26] <author> A. </author> <title> Viterbi. Error bounds for convolutional codes and an asymptotically optimal decoding algorithm. </title> <journal> IEEE Trans. Informat. Theory, </journal> <volume> IT-13:260-269, </volume> <month> April </month> <year> 1967. </year>
Reference-contexts: We have developed a training regimen that allows us to tie together these smaller HMMs into a single gene-finding system. 1 VEIL uses the well-known EM algorithm [19] to train all its models, and once the training is complete, it uses the Viterbi algorithm <ref> [26] </ref> to parse a new sequence into its component exons and introns. Details of the models and the algorithms are explained below. VEIL has been tested on a database of 570 vertebrate sequences that was collected by Burset and Guigo [5] specifically to test gene-finding systems. <p> For this purpose, we use the Viterbi algorithm <ref> [26] </ref>, a dynamic programming algorithm that efficiently aligns any sequence to an HMM.
Reference: [27] <author> Y. Xu, R. Mural, and E. Uberbacher. </author> <title> Constructing gene models from accurately predicted exons: an application of dynamic programming. </title> <journal> CABIOS, </journal> <volume> 10(6) </volume> <pages> 613-623, </pages> <year> 1994. </year>
Reference-contexts: This assumption is important to other dynamic programming systems such as GRAIL <ref> [27] </ref> and MORGAN [20], because it significantly reduces the number of alternative parses.
Reference: [28] <author> Y. Xu, R. Mural, and E. Uberbacher. </author> <title> Correcting sequencing errors in DNA coding regions using a dynamic programming approach. </title> <journal> CABIOS, </journal> <volume> 11(2) </volume> <pages> 117-124, </pages> <year> 1995. </year> <month> 23 </month>
Reference-contexts: Likewise with the start of transcription and translation some entries use the start codon to define the start of the first exon, even though this may not be technically correct. 7 The authors of GRAIL have proposed an iterative algorithm for removing apparent frame shifts <ref> [28, 10] </ref>. 2.6 Finding more than one parse By default, the Viterbi algorithm gives us the single best alignment of a sequence to our model, and this is what the current version of VEIL outputs.
References-found: 28

