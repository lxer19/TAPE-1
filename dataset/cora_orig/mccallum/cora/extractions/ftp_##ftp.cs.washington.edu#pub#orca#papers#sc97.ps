URL: ftp://ftp.cs.washington.edu/pub/orca/papers/sc97.ps
Refering-URL: http://www.cs.washington.edu/research/zpl/papers/abstracts/sc97.html
Root-URL: 
Phone: 704  
Title: Portable Performance of Data Parallel Languages  
Author: Ton Ngo Lawrence Snyder, Bradford Chamberlain 
Affiliation: Dept. of Computer Science Engineering IBM T. J. Watson Research Center University of Washington  
Address: P.O. Box  Yorktown Heights, NY 10598 Seattle, WA 98195  
Note: Appears in "Proceedings of the SC '97: High Performance Networking and Computing," 1997.  
Abstract: A portable program executes on different platforms and yields consistent performance. With the focus on portability, this paper presents an in-depth study of the performance of three NAS benchmarks (EP, MG, FT) compiled with three commercial HPF compilers (APR, PGI, IBM) on the IBM SP2. Each benchmark is evaluated in two versions: using DO loops and using F90 constructs and/or HPF's Forall statement. Base-line comparison is provided by versions of the benchmarks written in Fortran/MPI and ZPL, a data parallel language developed at the University of Washington. While some F90/Forall programs achieve scalable performance with some compilers, the results indicate a considerable portability problem in HPF programs. Two sources for the problem are identified. First, Fortran's semantics require extensive analysis and optimization to arrive at a parallel program; therefore relying on the compiler's capability alone leads to unpredictable performance. Second, the wide differences in the parallelization strategies used by each compiler often require an HPF program to be customized for the particular compiler. While improving compiler optimizations may help to reduce some performance variations, the results suggest that the foremost criteria for portability is a concise performance model that the compiler must adhere to and that the users can rely on. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ramesh Agarwal, Bowen Alpern, Larry Carter, Fred Gustavson, David Klepacki Rick Lawrence, and Mohammad Zubair. </author> <title> High performance parallel implementation of the NAS kernel benchmarks on the IBM SP2. </title> <journal> IBM Systems Journal, </journal> <volume> 34(2) </volume> <pages> 263-272, </pages> <year> 1995. </year>
Reference-contexts: A u (1) evaluate residual z = M k r (2) compute correction u = u + z (3) apply correction where A is the trilinear finite element discretization of the Laplace operator r 2 , M k is the V-cycle multigrid operator as defined in the NPB1 benchmark specification <ref> [1, 4] </ref>. The algorithm implemented in the NPB2.1 version consists of three phases: the first phase computes the residual, the second phase is a set of steps that applies the M k operator to compute the correction while the last phase applies the correction.
Reference: [2] <author> Ramesh Agarwal, Fred Gustavson, and Mohammad Zubair. </author> <title> An efficient parallel algorithm for the 3-D FFT NAS parallel benchmark. </title> <booktitle> In Proceedings of SHPCC 1994, </booktitle> <pages> pages 129-133. </pages> <institution> IBM Thomas J. Watson Research Center, </institution> <year> 1994. </year>
Reference-contexts: The problem statement requires 6 solutions, therefore the benchmark consists of 1 forward FFT and 6 pairs of dot products and inverse FFTs. The NPB2.1 implementation follows a standard parallelization scheme <ref> [5, 2] </ref>. The 3-D FFT computation consists of traversing and applying the 1-D FFT along each of the three dimensions. The 3-D array is partitioned along the third dimension to allow each processor to independently carry out the 1-D FFT along the first and second dimension.
Reference: [3] <institution> Applied Parallel Research. </institution> <note> XHPF User's Guide, version 2.0 edition, </note> <month> January </month> <year> 1995. </year>
Reference-contexts: In related work, APR published the performance of its HPF compiler for a suite of HPF programs, along with detailed descriptions of their program restructuring process using the APR FORGE tool to improve the codes <ref> [3, 11] </ref>. The programs are well tuned to the APR compiler and in many cases rely on the use of APR-specific directives rather than standard HPF directives. <p> All compilers (ZPL and HPF) recognize this pattern well and employ optimizations such as message vectorization and storage preallocation for the nonlocal data <ref> [3, 8, 9, 12] </ref>. Therefore, although the benchmark is rather complex, the initial indication is that both HPF and ZPL should be able to produce efficient parallel programs.
Reference: [4] <author> D. Bailey, E. Barszcz, J. Barton, D. Browning, R. Carter, L. Dagum, R. Fatoohi, S. Finebertg, P. Frederickson, T. Lasinski, R. Schreiber, H. Simon, V. Venkatakrishnan, and S. Weeratunga. </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report RNR-94-007, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <month> March </month> <year> 1991. </year> <month> 16 </month>
Reference-contexts: This will result in an overall complexity of O (n 2 ). Fortunately, the property of the mod operation allows x k to be computed in O (log k) steps by using a binary exponentiation algorithm <ref> [4] </ref>. The goal then is to balance between method (1) and (2) to achieve parallelism while maintaining the O (n) cost. Because EP is not available in the NPB2.1 suite, we use the implementation provided by APR as the DO loop version. <p> A u (1) evaluate residual z = M k r (2) compute correction u = u + z (3) apply correction where A is the trilinear finite element discretization of the Laplace operator r 2 , M k is the V-cycle multigrid operator as defined in the NPB1 benchmark specification <ref> [1, 4] </ref>. The algorithm implemented in the NPB2.1 version consists of three phases: the first phase computes the residual, the second phase is a set of steps that applies the M k operator to compute the correction while the last phase applies the correction.
Reference: [5] <author> David Bailey, Tim Harris, William Saphir, Rob van der Wijngaart, Alex Woo, and Maurice Yarrow. </author> <title> The NAS parallel benchmark 2.0. </title> <type> Technical Report NAS-95-020, </type> <institution> NASA Ames Research Center, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: The problem statement requires 6 solutions, therefore the benchmark consists of 1 forward FFT and 6 pairs of dot products and inverse FFTs. The NPB2.1 implementation follows a standard parallelization scheme <ref> [5, 2] </ref>. The 3-D FFT computation consists of traversing and applying the 1-D FFT along each of the three dimensions. The 3-D array is partitioned along the third dimension to allow each processor to independently carry out the 1-D FFT along the first and second dimension.
Reference: [6] <author> S. Benkner, Barbara Chapman, and H. Zima. </author> <title> Vienna Fortran 90. </title> <booktitle> In Proceedings of Scalable High Performance Computing Conference 1992, </booktitle> <pages> pages 51-59. </pages> <institution> Department for Statistics and Computer Science, Vienna University, Austria, </institution> <year> 1992. </year>
Reference-contexts: One of HPF's distinctions is that it is the first parallel language with a recognized standard | indeed, HPF can be regarded as the integration of several similar data parallel languages including Fortran D, Vienna Fortran and CM Fortran <ref> [6, 14, 22] </ref>. The attractions of HPF are manifold. First, its use of Fortran as a base language promises quick user acceptance since the language is well established in the target community.
Reference: [7] <author> Zeki Bozkus, Alok Choudhary, Geoffrey Fox, Tomasz Haupt, Sanjay Ranka, and Min-You Wu. </author> <title> Compiling Fortran 90D/HPF for distributed memory mimd computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21 </volume> <pages> 15-26, </pages> <year> 1994. </year>
Reference: [8] <author> Zeki Bozkus, Larry Meadows, Steven Nakamoto, Vincent Schuster, and Mark Young. </author> <title> Com piling High Performance Fortran. </title> <booktitle> In Proceedings ofthe Seventh SIAM Conference on Parallel Processing for Scientific Computing. The Portland Group, </booktitle> <publisher> Inc., </publisher> <year> 1995. </year>
Reference-contexts: Therefore, we believe that the suite of APR benchmarks is not well suited for evaluating HPF compilers in general. Similarly, papers by vendors describing their individual HPF compilers typically show some performance numbers; however it remains difficult to make comparisons across compilers <ref> [8, 12, 13] </ref>. Lin et al. used the APR benchmark suite to compare the performance of ZPL versions of the programs against the corresponding HPF performance published by APR and found that ZPL generally outperforms HPF [17]. <p> All compilers (ZPL and HPF) recognize this pattern well and employ optimizations such as message vectorization and storage preallocation for the nonlocal data <ref> [3, 8, 9, 12] </ref>. Therefore, although the benchmark is rather complex, the initial indication is that both HPF and ZPL should be able to produce efficient parallel programs.
Reference: [9] <author> Bradford Chamberlain, Sung-Eun Choi, E Lewis, Calvin Lin, Lawrence Snyder, and Derrick Weathersby. Factor-Join: </author> <title> A unique approach to compiling array languages for parallel machines. </title> <booktitle> In 9th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 481-500. </pages> <institution> University of Washington, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: All compilers (ZPL and HPF) recognize this pattern well and employ optimizations such as message vectorization and storage preallocation for the nonlocal data <ref> [3, 8, 9, 12] </ref>. Therefore, although the benchmark is rather complex, the initial indication is that both HPF and ZPL should be able to produce efficient parallel programs.
Reference: [10] <author> High Performance Fortran Forum. </author> <title> HPF language specification version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Rice University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Of these languages, High Performance Fortran <ref> [10] </ref> constitutes the most widespread effort, involving a large consortium of companies and universities.
Reference: [11] <author> Richarcd Friedman, John Levesque, and Gene Wagenbreth. </author> <title> Fortran parallelization hand book. </title> <type> Technical report, </type> <institution> Applied Parallel Research, </institution> <address> Sacramento, CA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: In related work, APR published the performance of its HPF compiler for a suite of HPF programs, along with detailed descriptions of their program restructuring process using the APR FORGE tool to improve the codes <ref> [3, 11] </ref>. The programs are well tuned to the APR compiler and in many cases rely on the use of APR-specific directives rather than standard HPF directives.
Reference: [12] <author> Manish Gupta, Sam Midkiff, Edith Schonberg, Ven Seshadri, David Shields, KoYang Wang, Waimee Ching, and Ton Ngo. </author> <title> An HPF compiler for the IBM SP2. </title> <booktitle> In Supercomputing 1995, </booktitle> <address> San Diego, </address> <month> December </month> <year> 1995. </year> <institution> IBM T. J. Watson Research Center, IEEE. </institution>
Reference-contexts: Therefore, we believe that the suite of APR benchmarks is not well suited for evaluating HPF compilers in general. Similarly, papers by vendors describing their individual HPF compilers typically show some performance numbers; however it remains difficult to make comparisons across compilers <ref> [8, 12, 13] </ref>. Lin et al. used the APR benchmark suite to compare the performance of ZPL versions of the programs against the corresponding HPF performance published by APR and found that ZPL generally outperforms HPF [17]. <p> All compilers (ZPL and HPF) recognize this pattern well and employ optimizations such as message vectorization and storage preallocation for the nonlocal data <ref> [3, 8, 9, 12] </ref>. Therefore, although the benchmark is rather complex, the initial indication is that both HPF and ZPL should be able to produce efficient parallel programs.
Reference: [13] <author> Jonathan Harris, John Bircsak, Regina Bolduc, Jill Diewald, Israel Gale, Neil Johnson, Shin Lee, Alexander Nelson, and Carl Offner. </author> <title> Compiling High Performance Fortran for distributed-memory systems. </title> <journal> Digital Technical Journal, </journal> <volume> 7(3) </volume> <pages> 5-38, </pages> <year> 1995. </year>
Reference-contexts: Therefore, we believe that the suite of APR benchmarks is not well suited for evaluating HPF compilers in general. Similarly, papers by vendors describing their individual HPF compilers typically show some performance numbers; however it remains difficult to make comparisons across compilers <ref> [8, 12, 13] </ref>. Lin et al. used the APR benchmark suite to compare the performance of ZPL versions of the programs against the corresponding HPF performance published by APR and found that ZPL generally outperforms HPF [17].
Reference: [14] <author> Seema Hiranandani, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Evaluating compiler optimiza tions for Fortran D. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21 </volume> <pages> 27-45, </pages> <year> 1994. </year>
Reference-contexts: One of HPF's distinctions is that it is the first parallel language with a recognized standard | indeed, HPF can be regarded as the integration of several similar data parallel languages including Fortran D, Vienna Fortran and CM Fortran <ref> [6, 14, 22] </ref>. The attractions of HPF are manifold. First, its use of Fortran as a base language promises quick user acceptance since the language is well established in the target community.
Reference: [15] <author> Calvin Lin. </author> <title> ZPL language reference manual. </title> <type> Technical report, </type> <institution> University of Washington, </institution> <year> 1994. </year>
Reference: [16] <author> Calvin Lin and Lawrence Snyder. ZPL: </author> <title> An array sublanguage. </title> <booktitle> In Languages and Compilers for Parallel Computing. </booktitle> <year> 1993. </year>
Reference-contexts: To evaluate the effect of data dependences on compiler analysis, we consider two versions of each benchmark: one programmed using DO loops, and the second using F90 constructs and/or HPF's Forall statement. For the comparison, we also consider the performance of each benchmark written in MPI and ZPL <ref> [16] </ref>, a data parallel language developed at the University of Washington. Since message passing programs yield scalable performance but are not convenient, the MPI results represent a level of performance that the HPF programs should use as a point of reference.
Reference: [17] <author> Calvin Lin, Lawrence Snyder, Ruth Anderson, Brad Chamberlain, Sung-Eun Choi, George Forman, E Lewis, and Derrick Weathersby. </author> <title> ZPL vs. HPF: A comparison of performance and programming style. </title> <type> Technical Report UW-CSE-95-11-05, </type> <institution> University of Washington, </institution> <address> Seattle, Wa 98195, </address> <month> November </month> <year> 1995. </year> <month> 17 </month>
Reference-contexts: Lin et al. used the APR benchmark suite to compare the performance of ZPL versions of the programs against the corresponding HPF performance published by APR and found that ZPL generally outperforms HPF <ref> [17] </ref>. However, without access to the APR compiler at the time, detailed analysis was not possible, limiting the comparison to the aggregate timings. This paper makes the following contributions: 1.
Reference: [18] <author> Ton Ngo. </author> <title> The Role of Performance Models in Parallel Programming and Languages. </title> <type> PhD thesis, </type> <institution> University of Washington, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: To this end, the language specification must serve as a consistent contract between the compiler and the programmer. We call this contract the performance model of the language <ref> [18] </ref>. A robust performance model has a dual effect: the program performance is (1) predictable to the user and (2) portable across different platforms. With the focus on the portability issue, we study in-depth the performance of three NAS benchmarks compiled with three commercial HPF compilers on the IBM SP2.
Reference: [19] <author> Ton Ngo and Lawrence Snyder. </author> <title> On the influence of programming models on shared memory computer performance. </title> <booktitle> In Proceedings of the 1992 Scalable High Performance Computing Conference, </booktitle> <pages> pages 284-291. </pages> <institution> Dept of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, Wa, </address> <month> May </month> <year> 1992. </year>
Reference: [20] <author> William Saphir, Alex Woo, and Maurice Yarrow. </author> <title> NAS parallel benchmark 2.1 results: </title> <type> 8/96. Technical Report NAS-96-010, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <month> December </month> <year> 1995. </year>
Reference: [21] <author> Lawrence Snyder. </author> <title> A ZPL programming guide. </title> <type> Technical report, </type> <institution> University of Washington, </institution> <year> 1994. </year>
Reference: [22] <institution> Thinking Machines Corporation. </institution> <note> CM Fortran Programming Guide, version 2.2 edition, </note> <month> October </month> <year> 1994. </year> <month> 18 </month>
Reference-contexts: One of HPF's distinctions is that it is the first parallel language with a recognized standard | indeed, HPF can be regarded as the integration of several similar data parallel languages including Fortran D, Vienna Fortran and CM Fortran <ref> [6, 14, 22] </ref>. The attractions of HPF are manifold. First, its use of Fortran as a base language promises quick user acceptance since the language is well established in the target community.
References-found: 22

