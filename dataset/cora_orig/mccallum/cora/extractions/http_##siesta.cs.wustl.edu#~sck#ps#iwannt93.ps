URL: http://siesta.cs.wustl.edu/~sck/ps/iwannt93.ps
Refering-URL: http://siesta.cs.wustl.edu/~sck/
Root-URL: 
Email: sck@cs.wustl.edu barry@cs.wustl.edu ame@cs.wustl.edu wwl@cs.wustl.edu  
Title: Real-Time Identification of Language from Raw Speech Waveforms  
Author: Stan C. Kwasny, Barry L. Kalman, A. Maynard Engebretson, and Weilan Wu 
Address: St. Louis, Missouri 63130 USA  
Affiliation: Department of Computer Science Washington University  
Abstract: Real-time language identification is a problem well-suited to neural network solution. By limiting the amount of speech processing at the frontend this can be achieved to a surprising degree. In our experiments we have developed a recurrent neural network which has been trained and tested using examples from English and French. The recurrent network produces a series of activation patterns (one outcome for each cycle) which can be seen as votes for or against each language. These votes are summed over an interval of speech and the segment is classified.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Abe and K. </author> <title> Shikano "Statistical analysis of bilingual speaker's speech for cross-language voice conversion," </title> <journal> Journal of the Acoustic Society of America, </journal> <volume> vol. 90, </volume> <pages> pp. 76-82, </pages> <year> 1991. </year>
Reference-contexts: In the past, there have been studies that demonstrate the existence of statistically significant differences among spoken languages at the acoustic level [5] [2] and also at the level of phonetic features [3] [8]. Abe et al <ref> [1] </ref> have considered some of the differences in automatically converting a speaker's voice from one language into another.
Reference: [2] <author> K. </author> <title> Atkinson "Language identification from nonsegmental cues," </title> <journal> Journal of the Acoustic Society of America, </journal> <volume> vol. 44, </volume> <editor> p. 378(A), </editor> <year> 1968. </year>
Reference-contexts: In the past, there have been studies that demonstrate the existence of statistically significant differences among spoken languages at the acoustic level [5] <ref> [2] </ref> and also at the level of phonetic features [3] [8]. Abe et al [1] have considered some of the differences in automatically converting a speaker's voice from one language into another.
Reference: [3] <author> P.B. </author> <title> Denes "On the statistics of spoken English," </title> <journal> Journal of the Acoustic Society of America, </journal> <volume> vol. 35, </volume> <pages> pp. 892-904, </pages> <year> 1963. </year> <month> 166 </month>
Reference-contexts: In the past, there have been studies that demonstrate the existence of statistically significant differences among spoken languages at the acoustic level [5] [2] and also at the level of phonetic features <ref> [3] </ref> [8]. Abe et al [1] have considered some of the differences in automatically converting a speaker's voice from one language into another.
Reference: [4] <author> J.L. </author> <title> Elman "Finding Structure in Time," </title> <journal> Cognitive Science, </journal> <volume> vol. 14, </volume> <pages> pp. 179-212, </pages> <year> 1990. </year>
Reference-contexts: The output from each was low-pass filtered and decimated by a factor of 200 to provide real-valued activation patterns for the network. These were presented to the recurrent network in the proper time sequence. 3 Network Design and Training Our network architecture is based on a simple recurrent network <ref> [4] </ref>, in which the activation pattern of the hidden units is copied back as additional input unit activations. In our version, the input units and copyback units are also connected directly to the output allowing those connections to learn the linear portion of the required mapping.
Reference: [5] <author> T.D. Hanley, J.C. Snidecor, </author> <title> and R.L. Ringel "Some acoustic difference among languages," </title> <journal> Phonetica, </journal> <volume> vol. 14, </volume> <pages> pp. 97-107, </pages> <year> 1966. </year>
Reference-contexts: In the past, there have been studies that demonstrate the existence of statistically significant differences among spoken languages at the acoustic level <ref> [5] </ref> [2] and also at the level of phonetic features [3] [8]. Abe et al [1] have considered some of the differences in automatically converting a speaker's voice from one language into another.
Reference: [6] <author> B.L. Kalman, S.C. Kwasny, and A. </author> <title> Abella "Decomposing Input Patterns to Facilitate Training," </title> <booktitle> in Proceedings of the World Congress on Neural Networks, vol. III, </booktitle> <address> Hillsdale, New Jersey: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1993, </year> <pages> pp. 503-506. </pages>
Reference-contexts: This results in 84 counted votes from each segment. For training to succeed, we needed to apply singular value decomposition (svd) to the input patterns essentially re-orienting the data to maximize orthogonality among the input unit activations <ref> [6] </ref>. We have found this particular technique valuable in a variety of problems. With this, training succeeded.
Reference: [7] <author> S.C. Kwasny, B.L. Kalman, W. Wu, </author> <title> and A.M. Engebretson "Identifying Language from Speech: An Example of High-Level, Statistically-Based Feature Extraction," </title> <booktitle> in Proceedings of the 14th Annual Conference of the Cognitive Science Society, </booktitle> <address> Hillsdale, New Jersey: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1992. </year>
Reference-contexts: Real-time language identification is a problem well-suited to neural network solution. By limiting the amount of speech processing at the frontend, 162 this can be achieved to a surprising degree. In our preliminary studies, re-ported earlier, using a feedforward network <ref> [7] </ref> and using a recurrent neural network [11], we have shown that classification can be conducted in real time for two speakers, male and female. We have assumed that it is only necessary for the model to see relatively raw speech waveforms, represented as sampled frequency bands over time.
Reference: [8] <author> H. Kucera and G.K. </author> <title> Monroe "A comparative quantitative phonology of Russian, Czech, and German," </title> <address> New York: </address> <publisher> American Elsevier, </publisher> <year> 1968. </year>
Reference-contexts: In the past, there have been studies that demonstrate the existence of statistically significant differences among spoken languages at the acoustic level [5] [2] and also at the level of phonetic features [3] <ref> [8] </ref>. Abe et al [1] have considered some of the differences in automatically converting a speaker's voice from one language into another.
Reference: [9] <author> Y.K. Muthusamy and R.A. </author> <title> Cole "Automatic Segmentation and Identification of Ten Languages Using Telephone Speech," </title> <booktitle> in Proceedings of the 1992 International Conference on Spoken Language Processing, </booktitle> <volume> vol. 2, </volume> <year> 1992, </year> <pages> pp. 1007-1010. </pages>
Reference-contexts: Leading much of this research has been the Oregon Graduate Institute (OGI) who have collected a database of phone speech in ten languages described in [10] and have built a system that distinguishes among those languages <ref> [9] </ref>. In the past, there have been studies that demonstrate the existence of statistically significant differences among spoken languages at the acoustic level [5] [2] and also at the level of phonetic features [3] [8].
Reference: [10] <author> Y.K. Muthusamy, R.A. Cole, </author> <title> and B.T. Oshika "The OGI Multi-Language Telephone Speech Corpus," </title> <booktitle> in Proceedings of the 1992 International Conference on Spoken Language Processing, </booktitle> <volume> vol. 2, </volume> <year> 1992, </year> <pages> pp. 895-898. </pages>
Reference-contexts: Leading much of this research has been the Oregon Graduate Institute (OGI) who have collected a database of phone speech in ten languages described in <ref> [10] </ref> and have built a system that distinguishes among those languages [9]. In the past, there have been studies that demonstrate the existence of statistically significant differences among spoken languages at the acoustic level [5] [2] and also at the level of phonetic features [3] [8].
Reference: [11] <author> W. Wu, </author> <title> S.C. Kwasny, B.L. Kalman, and A.M. Engebretson "Identifying Language from Raw Speech: An Application of Recurrent Neural Networks," </title> <booktitle> in Proceedings of the 5th Midwest Artificial Intelligence and Cognitive Science Society Conference, </booktitle> <year> 1993, </year> <pages> pp. 53-57. 167 </pages>
Reference-contexts: Real-time language identification is a problem well-suited to neural network solution. By limiting the amount of speech processing at the frontend, 162 this can be achieved to a surprising degree. In our preliminary studies, re-ported earlier, using a feedforward network [7] and using a recurrent neural network <ref> [11] </ref>, we have shown that classification can be conducted in real time for two speakers, male and female. We have assumed that it is only necessary for the model to see relatively raw speech waveforms, represented as sampled frequency bands over time.
References-found: 11

