URL: file://ftp.cs.princeton.edu/pub/people/arora/ldtest.ps
Refering-URL: http://www.cs.princeton.edu/~arora/publist.html
Root-URL: http://www.cs.princeton.edu
Email: Fellowship.arora@cs.princeton.edu. madhu@watson.ibm.com  
Title: Improved low-degree testing and its applications  input, with high probability.  
Author: Sanjeev Arora Madhu Sudan 
Date: 1  
Note: t 0:5, then the tester/corrector deter mines ffi and generates O(  ffi randomized programs such that one of them is correct on every  Supported by an NSF CAREER award and an Alfred P. Sloan  
Affiliation: Princeton University  IBM Watson Research Center  
Abstract: NP = PCP(log n; 1) and related results crucially depend upon the close connection between the probability with which a function passes a low degree test and the distance of this function to the nearest degree d polynomial. In this paper we study a test proposed by Rubinfeld and Sudan [RS93]. The strongest previously known connection for this test states that a function passes the test with probability ffi for some ffi &gt; 7=8 iff the function has agreement ffi with a polynomial of degree d. We present a new, and surprisingly strong, analysis which shows that the preceding statement is true for ffi t 0:5. The analysis uses a version of Hilbert irreducibility, a tool of algebraic geometry. As a consequence we obtain an alternate construction for the following proof system: A constant prover 1-round proof system for NP languages in which the verifier uses O(log n) random bits, receives answers of size O(log n) bits, and has an error prob ability of at most 2 log 1* n . Such a proof system, which implies the NP-hardness of approximating Set Cover to within (log n) factors, has already been obtained by Raz and Safra [RazS96]. Our result was completed after we heard of their claim. A second consequence of our analysis is a self tester/corrector for any buggy program that (supposedly) computes a polynomial over a finite field. If the program is correct only on ffi fraction of inputs where ffi = 1= jFj * ffi ) values for every input, such that one of them is the correct output. In fact, our techniques yield something stronger: Given the buggy program, we can construct O( 1 
Abstract-found: 1
Intro-found: 1
Reference: [ALRS92] <author> S. Ar, R. Lipton, R. Rubinfeld and M. Sudan. </author> <title> Reconstructing algebraic functions from noisy data. </title> <booktitle> Proceedings of the 33rd Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: As for correction, note that its meaning is not clear when ffi &lt; 1=2, since as many as O (1=ffi) polynomials could have agreement ffi with the program. Two notions of correction are possible, as noted in <ref> [ALRS92] </ref>. The weaker one is that for each input, the corrector outputs O (1=ffi) values, one of which is correct. Such a corrector is known [Su96]. The stronger notion is that 2 the corrector create O ( 1 ffi ) programs (polynomials) such that w.h.p. one of them is correct. <p> ij y 2 a i : : : = 0 i=0 j=0 n a i Since (1 + d x )(1 + d y ), the number of variables, exceeds n, the number of constraints, a nontrivial solution exists. 2 Then Sudan uses the following lemma from Ar et al. <ref> [ALRS92] </ref>.
Reference: [A93] <author> S. Arora Unpublished, </author> <year> 1993. </year>
Reference-contexts: We remark that a similar statement had earlier been proved for really large fields jFj &gt; 2 O (m+d+1=ffi) <ref> [A93, T93] </ref>, but that field size is too large for most applications. We also prove a related result, Theorem 3, which is more useful for constructing efficient PCP-style verifiers.
Reference: [A94] <author> S. Arora. </author> <title> Probabilistic Checking of Proofs and Hardness of Approximation Problems. </title> <type> PhD thesis, </type> <institution> U.C. Berkeley, </institution> <year> 1994. </year> <note> Available from http://www.cs.princeton.edu/~ arora </note> . 
Reference-contexts: Paper organization. We state and explain our main theorem (Theorem 1) and its corollaries (Theorems 3 and 4) in Section 2. We prove the theorem in Section 3. This proof resembles proofs of earlier results <ref> [RS93, ALMSS92, A94, FS95] </ref>, in that it has two parts. <p> Then in Section 3.3 we "bootstrap" to allow larger m. This part uses probabilistic arguments and relies upon the cases m = 2; 3 (including Theorems 3 and 4 for the cases m = 2; 3). It is inspired by the "symmetry-based" approach of Arora <ref> [A94] </ref>. Finally, the appendix contains the construction of constant prover 1-round proof systems and proofs of many lemmas. 2 The Low-degree Test Let F be a finite field and m; d be integers. <p> We rely on symmetry-based arguments similar to those in <ref> [A94] </ref>. These use the notion of a k-dimensional subspaces of F m Definition 3 Let m; k 2 Z + and k &lt; m.
Reference: [ABSS93] <author> S. Arora, L. Babai, J. Stern and Z. Sweedyk. </author> <title> The hardness of approximating problems defined by linear constraints. </title> <booktitle> Proceedings of the 34th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1993. </year>
Reference-contexts: For most of these problems it implies NP-hardness, but for some |most notably the problem of approximating set cover within a factor O (log n) and an entire set of problems in <ref> [ABSS93] </ref> | it is only known to imply quasi-NP-hardness (a quasi-NP-hard problem has a polynomial-time algorithm only if NP Time (n polylog (n) )). Plugging our improved analysis of the low degree test into known constructions leads to very efficient constant-prover 1-round proof systems for NP. <p> So long as we use the verifier composition idea of [AS92], 3 provers appears to be the best possible. Reducing the number of provers to 2 would imply the NP-hardness of approximation problems dealt with in <ref> [ABSS93] </ref>. Thanks Sanjeev Arora thanks Laci Babai and Kati Friedl for introducing him to "symmetry-based" arguments for the low degree test in summer 1993. We thank Dick Lipton for saving us from fruitless labor on an incorrect conjecture on irreducibility (he provided a counterexample).
Reference: [ALMSS92] <author> S. Arora, C. Lund, R. Motwani, M. Sudan and M. Szegedy. </author> <title> Proof verification and the hardness of approximation problems. </title> <booktitle> Proceedings of the 33rd Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: 1 Introduction The use of algebraic techniques has recently led to new (probabilistic) characterizations of traditional complexity classes. These characterizations involve an interaction between an untrustworthy prover (or many provers) and a polynomial-time verifier. In MIP= NEXP-TIME [BFL91], and NP = PCP (log n; 1) <ref> [AS92, ALMSS92] </ref> the verifier has to probabilistically verify the satisfiability of a boolean formula by reading very few bits in a "proof string" presented by a prover. In IP=PSPACE [LFKN92, Sh92] the verifier has to probabilistically verify tautologyhood of a quantified boolean formulae by interacting with a prover. <p> Recall that NP=PCP (log n; 1) implies the hardness of computing approximate solutions to many optimization problems such as clique [FGLSS91, AS92], chromatic number and set cover [LY93], and max-3sat <ref> [ALMSS92] </ref>. <p> Paper organization. We state and explain our main theorem (Theorem 1) and its corollaries (Theorems 3 and 4) in Section 2. We prove the theorem in Section 3. This proof resembles proofs of earlier results <ref> [RS93, ALMSS92, A94, FS95] </ref>, in that it has two parts. <p> In particular, there exists at least one line for which the two events in the preceding paragraph happen. Let l 0 be such a line. The existing analysis of the low degree test <ref> [ALMSS92] </ref> implies that for each ffi &lt; 1, every function with d-success-rate at least 1 ffi=24 has agreement at least 1 ffi=12 with some degree d polynomial. Let g be this polynomial for f .
Reference: [AS92] <author> S. Arora and S. Safra. </author> <title> Probabilistic checking of proofs: a new characterization of NP. </title> <booktitle> Proceedings of the 33rd Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: 1 Introduction The use of algebraic techniques has recently led to new (probabilistic) characterizations of traditional complexity classes. These characterizations involve an interaction between an untrustworthy prover (or many provers) and a polynomial-time verifier. In MIP= NEXP-TIME [BFL91], and NP = PCP (log n; 1) <ref> [AS92, ALMSS92] </ref> the verifier has to probabilistically verify the satisfiability of a boolean formula by reading very few bits in a "proof string" presented by a prover. In IP=PSPACE [LFKN92, Sh92] the verifier has to probabilistically verify tautologyhood of a quantified boolean formulae by interacting with a prover. <p> Recall that NP=PCP (log n; 1) implies the hardness of computing approximate solutions to many optimization problems such as clique <ref> [FGLSS91, AS92] </ref>, chromatic number and set cover [LY93], and max-3sat [ALMSS92]. <p> Existing analyses of all low degree tests cannot say anything meaningful about f if ffi &lt; 1=2; in fact the analyses of <ref> [FGLSS91, GLRSW91, RS93, AS92] </ref> require ffi &gt; 1 O (1=d). A crucial ingredient of NP=PCP (log n; 1) was an analysis (actually just a combination of the analyses of [AS92, RS93]) of the above test that worked for any ffi &gt; 1 *, where * &gt; 0 is fixed. <p> A crucial ingredient of NP=PCP (log n; 1) was an analysis (actually just a combination of the analyses of <ref> [AS92, RS93] </ref>) of the above test that worked for any ffi &gt; 1 *, where * &gt; 0 is fixed. <p> So long as we use the verifier composition idea of <ref> [AS92] </ref>, 3 provers appears to be the best possible. Reducing the number of provers to 2 would imply the NP-hardness of approximation problems dealt with in [ABSS93]. Thanks Sanjeev Arora thanks Laci Babai and Kati Friedl for introducing him to "symmetry-based" arguments for the low degree test in summer 1993.
Reference: [BFL91] <author> L. Babai, L. Fortnow, and C. Lund. </author> <title> Non-deterministic exponential time has two-prover interactive protocols. </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 3-40, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction The use of algebraic techniques has recently led to new (probabilistic) characterizations of traditional complexity classes. These characterizations involve an interaction between an untrustworthy prover (or many provers) and a polynomial-time verifier. In MIP= NEXP-TIME <ref> [BFL91] </ref>, and NP = PCP (log n; 1) [AS92, ALMSS92] the verifier has to probabilistically verify the satisfiability of a boolean formula by reading very few bits in a "proof string" presented by a prover. <p> If this is the case, accept. This test is similar in flavor to all other known low degree tests, such as the original test in <ref> [BFL91] </ref> and later ones in [BFLS91, FGLSS91, GLRSW91]. (Many of those tests check the degree of the polynomial in each variable, whereas the test we described checks the total degree.) Let ffi denote the probability with which f passes the low-degree test.
Reference: [BFLS91] <author> L. Babai, L. Fortnow, L. Levin, and M. Szegedy. </author> <title> Checking computations in polylogarithmic time. </title> <booktitle> Proceedings of the 23rd Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: If this is the case, accept. This test is similar in flavor to all other known low degree tests, such as the original test in [BFL91] and later ones in <ref> [BFLS91, FGLSS91, GLRSW91] </ref>. (Many of those tests check the degree of the polynomial in each variable, whereas the test we described checks the total degree.) Let ffi denote the probability with which f passes the low-degree test.
Reference: [BGS95] <author> M. Bellare, O. Goldreich and M. Sudan. </author> <title> Free bits, PCPs and non-approximability | towards tight results. </title> <booktitle> Proceedings of the 36th Symposium on Foundations of Computer Science, IEEE, 1995. TR95-024 of ECCC, the Electronic Colloquium on Computational Complexity, </booktitle> <address> http://www.eccc.uni-trier.de/eccc/. </address>
Reference-contexts: By the Chebyshev inequality, Pr [jX C j ffffi] V [X C ] where V [X C ] denotes the variance of X C . We show next (using an argument from <ref> [BGS95] </ref>) that V [X C ] 2= jFj, thus proving the lemma.
Reference: [BGLR93] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Russell. </author> <title> Efficient probabilistically checkable proofs. </title> <booktitle> Proceedings of the 25th Annual Symposium on Theory of Computing, ACM, 1993. (See also Errata sheet in Proceedings of the 26th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1994). </year>
Reference-contexts: Such systems imply the NP-hardness of approximating Set Cover to within a factor of O (ln n) (see the reduction of [LY93], adapted for more than 2 provers in <ref> [BGLR93] </ref>). Raz and Safra [RazS96] had before us constructed such systems; so our construction can be viewed as an alternative proof of their result. <p> We note that the recent techniques of [RazS96] do no seem to provide a tester/corrector. Past work. The first construction of a nontrivial constant prover 1-round proof system for NP appeared in [LS91]; others appeared in <ref> [FL92, BGLR93, T94, FK94, R95] </ref>. These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see [R95]).
Reference: [BLR90] <author> M. Blum, M. Luby, and R. Rubinfeld. </author> <title> Self-testing/correcting with applications to numerical problems. </title> <booktitle> In Proc. 22nd ACM Symp. on Theory of Computing, </booktitle> <pages> pages 73-83, </pages> <year> 1990. </year>
Reference-contexts: Suppose we are given a potentially buggy program that purportedly computes a (unknown) m-variate polynomial over a finite field F. Program testing/correcting <ref> [BLR90] </ref> concerns the following problems: (i) testing: determine ffi, the fraction of points at which this program is correct and (ii) correction: for each input, correct the output of the program in case it is incorrect.
Reference: [F96] <author> U. Feige. </author> <title> A threshold of ln n for Set Cover. </title> <booktitle> Proceedings of the 28th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1996. </year> <editor> [FGLSS91] . U. Feige, S. Goldwasser, L. L ovasz, S. Safra and M. </editor> <title> Szegedy. Interactive proofs and the hardness of approximating cliques. </title> <journal> Journal of the ACM, </journal> <volume> 43(2) </volume> <pages> 268-292, </pages> <year> 1996. </year>
Reference: [FK94] <author> U. Feige and J. Kilian. </author> <title> Two prover protocols Low error at affordable rates. </title> <booktitle> Proceedings of the 26th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference-contexts: We note that the recent techniques of [RazS96] do no seem to provide a tester/corrector. Past work. The first construction of a nontrivial constant prover 1-round proof system for NP appeared in [LS91]; others appeared in <ref> [FL92, BGLR93, T94, FK94, R95] </ref>. These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see [R95]).
Reference: [FK95] <author> U. Feige and J. Kilian. </author> <title> Impossibility results for recycling random bits in two-prover proof systems. </title> <booktitle> Proceedings of the 27th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1995. </year>
Reference-contexts: These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see [R95]). It was also known <ref> [FK95] </ref> that some obvious ideas (such as "recycling randomness") cannot let us get around this. Earlier this year Raz and Safra [RazS96] found a construction of a proof system achieving subconstant error.
Reference: [FL92] <author> U. Feige and L. L ovasz. </author> <title> Two-prover one-round proof systems: Their power and their problems. </title> <booktitle> Proceedings of the 24th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1992. </year> <month> 26 </month>
Reference-contexts: We note that the recent techniques of [RazS96] do no seem to provide a tester/corrector. Past work. The first construction of a nontrivial constant prover 1-round proof system for NP appeared in [LS91]; others appeared in <ref> [FL92, BGLR93, T94, FK94, R95] </ref>. These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see [R95]).
Reference: [FS95] <author> K. Friedl and M. Sudan. </author> <title> Some improvements to low-degree tests. </title> <booktitle> Proceedings of the Third Israel Symposium on Theory and Computing Systems, IEEE, </booktitle> <year> 1995. </year>
Reference-contexts: This analysis showed that if a function f passes the test with probability ffi &gt; 1 *, then there exists a degree d polynomial that has agreement ffi with f . (The value of * for which this is true was later improved to 1=8 <ref> [FS95] </ref>.) In this paper we present an analysis (see Theorem 4) that continues to say something meaningful about f even when ffi is fairly close to 0. <p> Paper organization. We state and explain our main theorem (Theorem 1) and its corollaries (Theorems 3 and 4) in Section 2. We prove the theorem in Section 3. This proof resembles proofs of earlier results <ref> [RS93, ALMSS92, A94, FS95] </ref>, in that it has two parts. <p> The converse can also be shown to be true: if on every line in F m , the values of f are described by a univariate degree-d polynomial and F is sufficiently large (q (d + 1)( p p1 ), where p is the characteristic of the field <ref> [FS95] </ref>), then f must be a degree-d polynomial. The low degree test is presented with f : F m ! F, and an integer d. It is also presented a table that is meant to be a "proof" that f is a degree d polynomial.
Reference: [GLRSW91] <author> P. Gemmell, R. Lipton, R. Rubinfeld, M. Sudan and A. Wigderson. </author> <title> Self-testing/correcting for polynomials and for approximate functions. </title> <booktitle> Proceedings of the 23rd Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1991. </year>
Reference-contexts: If this is the case, accept. This test is similar in flavor to all other known low degree tests, such as the original test in [BFL91] and later ones in <ref> [BFLS91, FGLSS91, GLRSW91] </ref>. (Many of those tests check the degree of the polynomial in each variable, whereas the test we described checks the total degree.) Let ffi denote the probability with which f passes the low-degree test. <p> Existing analyses of all low degree tests cannot say anything meaningful about f if ffi &lt; 1=2; in fact the analyses of <ref> [FGLSS91, GLRSW91, RS93, AS92] </ref> require ffi &gt; 1 O (1=d). A crucial ingredient of NP=PCP (log n; 1) was an analysis (actually just a combination of the analyses of [AS92, RS93]) of the above test that worked for any ffi &gt; 1 *, where * &gt; 0 is fixed.
Reference: [GRS] <author> O. Goldreich, R. Rubinfeld and M. Sudan. </author> <title> Learning polynomials with queries: The highly noisy case. </title> <booktitle> Proceedings of the 36th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1995. </year>
Reference: [K85] <author> E. Kaltofen. </author> <title> Polynomial-time reductions from multivariate to bi- and univariate integral polynomial factorization. </title> <journal> SIAM Journal on Computing, </journal> <volume> 14(2) </volume> <pages> 469-489, </pages> <year> 1985. </year>
Reference-contexts: First in Section 3.1 we prove the theorem when m is constant (specifically, m = 2; 3); this uses algebraic arguments inspired by Sudan's [Su96] work on reconstructing polynomials from very noisy data and Kaltofen's work on "Effective Hilbert Irreducibility" <ref> [K85, K95] </ref>. Then in Section 3.3 we "bootstrap" to allow larger m. This part uses probabilistic arguments and relies upon the cases m = 2; 3 (including Theorems 3 and 4 for the cases m = 2; 3). It is inspired by the "symmetry-based" approach of Arora [A94]. <p> Now we state and prove this fact. It is a simpler version of Kaltofen's "Effective Hilbert Irreducibility" <ref> [K85] </ref>. in that it focusses only factors that are monic and linear in one of the variables. The proof essentially follows from Kaltofen [K95], and is included here for completeness.
Reference: [K85] <author> E. Kaltofen. </author> <title> Effective Hilbert irreducibility. </title> <journal> Information and Control, </journal> <volume> 66 </volume> <pages> 123-137, </pages> <year> 1985. </year>
Reference-contexts: First in Section 3.1 we prove the theorem when m is constant (specifically, m = 2; 3); this uses algebraic arguments inspired by Sudan's [Su96] work on reconstructing polynomials from very noisy data and Kaltofen's work on "Effective Hilbert Irreducibility" <ref> [K85, K95] </ref>. Then in Section 3.3 we "bootstrap" to allow larger m. This part uses probabilistic arguments and relies upon the cases m = 2; 3 (including Theorems 3 and 4 for the cases m = 2; 3). It is inspired by the "symmetry-based" approach of Arora [A94]. <p> Now we state and prove this fact. It is a simpler version of Kaltofen's "Effective Hilbert Irreducibility" <ref> [K85] </ref>. in that it focusses only factors that are monic and linear in one of the variables. The proof essentially follows from Kaltofen [K95], and is included here for completeness.
Reference: [K95] <author> E. Kaltofen. </author> <title> Effective Noether irreducibility forms and applications. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 50(2) </volume> <pages> 274-295, </pages> <year> 1995. </year>
Reference-contexts: First in Section 3.1 we prove the theorem when m is constant (specifically, m = 2; 3); this uses algebraic arguments inspired by Sudan's [Su96] work on reconstructing polynomials from very noisy data and Kaltofen's work on "Effective Hilbert Irreducibility" <ref> [K85, K95] </ref>. Then in Section 3.3 we "bootstrap" to allow larger m. This part uses probabilistic arguments and relies upon the cases m = 2; 3 (including Theorems 3 and 4 for the cases m = 2; 3). It is inspired by the "symmetry-based" approach of Arora [A94]. <p> Now we state and prove this fact. It is a simpler version of Kaltofen's "Effective Hilbert Irreducibility" [K85]. in that it focusses only factors that are monic and linear in one of the variables. The proof essentially follows from Kaltofen <ref> [K95] </ref>, and is included here for completeness.
Reference: [LS91] <author> D. Lapidot and A. Shamir. </author> <title> Fully Parallelized Multi-prover protocols for NEXP-time. </title> <booktitle> Proceedings of the 32nd Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1991. </year>
Reference-contexts: We note that the recent techniques of [RazS96] do no seem to provide a tester/corrector. Past work. The first construction of a nontrivial constant prover 1-round proof system for NP appeared in <ref> [LS91] </ref>; others appeared in [FL92, BGLR93, T94, FK94, R95]. These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see [R95]).
Reference: [LFKN92] <author> C. Lund, L. Fortnow, H. Karloff, and N. Nisan. </author> <title> Algebraic methods for interactive proof systems. </title> <journal> Journal of the ACM, </journal> <volume> 39(4) </volume> <pages> 859-868, </pages> <year> 1992. </year>
Reference-contexts: In MIP= NEXP-TIME [BFL91], and NP = PCP (log n; 1) [AS92, ALMSS92] the verifier has to probabilistically verify the satisfiability of a boolean formula by reading very few bits in a "proof string" presented by a prover. In IP=PSPACE <ref> [LFKN92, Sh92] </ref> the verifier has to probabilistically verify tautologyhood of a quantified boolean formulae by interacting with a prover. <p> All these results fundamentally rely on the same idea: the verifier first arithmetizes (or algebraizes) the boolean formula, which involves viewing a boolean assignment not as a sequence of bits but as values of a polynomial <ref> [LFKN92] </ref>. From then on, verifying satisfi-ability or tautologyhood involves verifying | using some efficient algebraic procedures | specific properties of a polynomial that has been provided by the prover.
Reference: [LY93] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <booktitle> Proceedings of the 25th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1993. </year>
Reference-contexts: Recall that NP=PCP (log n; 1) implies the hardness of computing approximate solutions to many optimization problems such as clique [FGLSS91, AS92], chromatic number and set cover <ref> [LY93] </ref>, and max-3sat [ALMSS92]. <p> Plugging our improved analysis of the low degree test into known constructions leads to very efficient constant-prover 1-round proof systems for NP. Such systems imply the NP-hardness of approximating Set Cover to within a factor of O (ln n) (see the reduction of <ref> [LY93] </ref>, adapted for more than 2 provers in [BGLR93]). Raz and Safra [RazS96] had before us constructed such systems; so our construction can be viewed as an alternative proof of their result.
Reference: [PS94] <author> A. Polishchuk and D. Spielman. </author> <title> Nearly Linear Sized Holographic Proofs. </title> <booktitle> Proceedings of the 26th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1994. </year>
Reference: [R95] <author> R. Raz. </author> <title> A parallel repetition theorem. </title> <booktitle> Proceedings of the 27th Annual Symposium on Theory of Computing, ACM, </booktitle> <year> 1995. </year>
Reference-contexts: We note that the recent techniques of [RazS96] do no seem to provide a tester/corrector. Past work. The first construction of a nontrivial constant prover 1-round proof system for NP appeared in [LS91]; others appeared in <ref> [FL92, BGLR93, T94, FK94, R95] </ref>. These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see [R95]). <p> These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see <ref> [R95] </ref>). It was also known [FK95] that some obvious ideas (such as "recycling randomness") cannot let us get around this. Earlier this year Raz and Safra [RazS96] found a construction of a proof system achieving subconstant error.
Reference: [RazS96] <author> R. Raz and S. Safra. </author> <type> Personal communication. </type> <month> March </month> <year> 1996. </year> <type> Manuscript. </type> <month> September </month> <year> 1996. </year>
Reference-contexts: Such systems imply the NP-hardness of approximating Set Cover to within a factor of O (ln n) (see the reduction of [LY93], adapted for more than 2 provers in [BGLR93]). Raz and Safra <ref> [RazS96] </ref> had before us constructed such systems; so our construction can be viewed as an alternative proof of their result. <p> Finding such a corrector was an open problem. Our analysis leads to such a corrector. We omit details from this abstract, but they are obvious from reading our proofs (specifically, by noting their "algorithmic" nature). We note that the recent techniques of <ref> [RazS96] </ref> do no seem to provide a tester/corrector. Past work. The first construction of a nontrivial constant prover 1-round proof system for NP appeared in [LS91]; others appeared in [FL92, BGLR93, T94, FK94, R95]. <p> It was also known [FK95] that some obvious ideas (such as "recycling randomness") cannot let us get around this. Earlier this year Raz and Safra <ref> [RazS96] </ref> found a construction of a proof system achieving subconstant error. Our result, though obtained independently, was completed a couple of months after we had heard of the existence of their result (the missing part at the time was our proof of the bivariate case of Theorem 1).
Reference: [RS93] <author> R. Rubinfeld and M. Sudan. </author> <title> Robust characterizations of polynomials with applications to program testing. </title> <journal> SIAM Journal on Computing 25:2, </journal> <pages> pp. 252-271, </pages> <year> 1996. </year>
Reference-contexts: Both d and are inputs to the test.) The low degree test is allowed to be probabilistic and it has to read as few values of f as possible. We are interested in a test described in <ref> [RS93] </ref> that works roughly as follows: Pick a 1 random "line" in F m and verify that the restriction of f to this line agrees significantly with some univariate degree d polynomial. If this is the case, accept. <p> Existing analyses of all low degree tests cannot say anything meaningful about f if ffi &lt; 1=2; in fact the analyses of <ref> [FGLSS91, GLRSW91, RS93, AS92] </ref> require ffi &gt; 1 O (1=d). A crucial ingredient of NP=PCP (log n; 1) was an analysis (actually just a combination of the analyses of [AS92, RS93]) of the above test that worked for any ffi &gt; 1 *, where * &gt; 0 is fixed. <p> A crucial ingredient of NP=PCP (log n; 1) was an analysis (actually just a combination of the analyses of <ref> [AS92, RS93] </ref>) of the above test that worked for any ffi &gt; 1 *, where * &gt; 0 is fixed. <p> Paper organization. We state and explain our main theorem (Theorem 1) and its corollaries (Theorems 3 and 4) in Section 2. We prove the theorem in Section 3. This proof resembles proofs of earlier results <ref> [RS93, ALMSS92, A94, FS95] </ref>, in that it has two parts.
Reference: [Sch80] <author> J. T. Schwartz. </author> <title> Probabilistic algorithms for verification of polynomial identities. </title> <journal> Journal of the ACM, </journal> <volume> 27 </volume> <pages> 701-717, </pages> <year> 1980. </year>
Reference: [Sh92] <author> A. Shamir. </author> <title> IP = PSPACE. </title> <journal> Journal of the ACM, </journal> <volume> 39(4) </volume> <pages> 869-877, </pages> <year> 1992. </year>
Reference-contexts: In MIP= NEXP-TIME [BFL91], and NP = PCP (log n; 1) [AS92, ALMSS92] the verifier has to probabilistically verify the satisfiability of a boolean formula by reading very few bits in a "proof string" presented by a prover. In IP=PSPACE <ref> [LFKN92, Sh92] </ref> the verifier has to probabilistically verify tautologyhood of a quantified boolean formulae by interacting with a prover.
Reference: [Su96] <author> M. Sudan. </author> <title> Maximum likelihood decoding of Reed Solomon codes. </title> <booktitle> Proceedings of the 37th Symposium on Foundations of Computer Science, IEEE, </booktitle> <year> 1996. </year>
Reference-contexts: Two notions of correction are possible, as noted in [ALRS92]. The weaker one is that for each input, the corrector outputs O (1=ffi) values, one of which is correct. Such a corrector is known <ref> [Su96] </ref>. The stronger notion is that 2 the corrector create O ( 1 ffi ) programs (polynomials) such that w.h.p. one of them is correct. Finding such a corrector was an open problem. Our analysis leads to such a corrector. <p> We prove the theorem in Section 3. This proof resembles proofs of earlier results [RS93, ALMSS92, A94, FS95], in that it has two parts. First in Section 3.1 we prove the theorem when m is constant (specifically, m = 2; 3); this uses algebraic arguments inspired by Sudan's <ref> [Su96] </ref> work on reconstructing polynomials from very noisy data and Kaltofen's work on "Effective Hilbert Irreducibility" [K85, K95]. Then in Section 3.3 we "bootstrap" to allow larger m. <p> Step 2 depends on a fairly difficult technical fact, Theorem 23, which will be proved separately in Section 4.1. Step 1 is motivated by Sudan's <ref> [Su96] </ref> technique for reconstructing univariate polynomials from very noisy data. Sudan makes the following observation.
Reference: [T93] <author> G. Tardos. </author> <type> Personal Communication, </type> <year> 1993. </year>
Reference-contexts: We remark that a similar statement had earlier been proved for really large fields jFj &gt; 2 O (m+d+1=ffi) <ref> [A93, T93] </ref>, but that field size is too large for most applications. We also prove a related result, Theorem 3, which is more useful for constructing efficient PCP-style verifiers.
Reference: [T94] <author> G. Tardos. </author> <title> Multi-prover encoding schemes and three-prover proof systems. </title> <booktitle> Proceedings of the 9th Annual Conference on Structure in Complexity Theory, IEEE, </booktitle> <year> 1994. </year>
Reference-contexts: We note that the recent techniques of [RazS96] do no seem to provide a tester/corrector. Past work. The first construction of a nontrivial constant prover 1-round proof system for NP appeared in [LS91]; others appeared in <ref> [FL92, BGLR93, T94, FK94, R95] </ref>. These systems could not reduce the error probability to below a constant while using O (log n) random bits (the best construction needs O (k log n) random bits to make the error probability 2 k ; see [R95]).
Reference: [T96] <author> G. Tardos. </author> <type> Personal Communication, </type> <year> 1996. </year> <month> 27 </month>
Reference-contexts: The number of provers in our construction grows as O (1=*). If we are willing to increase the error probability to 2 log 1=3 n then the number of provers is 5. (The number of provers can be reduced to 3 using a technique of Tardos <ref> [T96] </ref>). Whether or not the number of provers can be reduced to to 2 remains an open problem. Now we briefly describe low degree tests; see Section 2 for more details.
References-found: 34

