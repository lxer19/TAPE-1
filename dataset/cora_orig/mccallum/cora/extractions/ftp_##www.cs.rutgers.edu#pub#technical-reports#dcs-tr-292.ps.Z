URL: ftp://www.cs.rutgers.edu/pub/technical-reports/dcs-tr-292.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: LOWER AND UPPER BOUNDS FOR INCREMENTAL ALGORITHMS  Written under the direction of  
Author: BY ARTHUR MICHAEL BERMAN Marvin C. Paull 
Degree: A dissertation submitted to the Graduate School|New Brunswick  in partial fulfillment of the requirements for the degree of Doctor of Philosophy  and approved by  
Date: October, 1992  
Note: Graduate Program in Computer Science  
Address: New Jersey  Brunswick, New Jersey  
Affiliation: Rutgers, The State University of  New  
Abstract-found: 0
Intro-found: 1
Reference: [ABJ89] <author> R. Agrawal, A. Borgida, and H.V. Jagadish. </author> <title> Efficient management of transitive relationships in large data and knowledge bases. </title> <booktitle> In Proceedings of the ACM-SIGMOD International Conference on Management of Data. Association for Computing Machinery, </booktitle> <year> 1989. </year>
Reference: [ACR + 87] <author> B. Alpern, A. Carle, B. Rosen, P. Sweeney, and F. K. Zadek. </author> <title> Incremental evaluation of attributed graphs. </title> <type> Technical Report RC 13205, </type> <institution> IBM Thomas J. Watson Research Center, </institution> <address> Yorktown Heights, New York, </address> <month> October </month> <year> 1987. </year>
Reference: [AHR + 90] <author> B. Alpern, R. Hoover, B. K. Rosen, P. F. Sweeney, and F. K. Zadeck. </author> <title> Incremental evaluation of computational circuits. </title> <booktitle> In Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 32-42. </pages> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1990. </year>
Reference-contexts: by the update; this approach is referred to here as ffi-analysis, and algorithms that are efficient in terms of ffi-analysis are referred to as ffi-incremental algorithms. 1 This is a generalization of an idea that first appeared in a paper by Reps [Rep82] and was extended by Alpern et al. <ref> [AHR + 90] </ref>. Reps presented an incremental algorithm for updating an attribute graph with performance linear in the number of vertices in the graph whose attributes are altered by the update. 2 Using this approach along with ideas in [AHR + 90], Ramalingam and Reps developed several ffi-incremental algorithms on graphs. <p> paper by Reps [Rep82] and was extended by Alpern et al. <ref> [AHR + 90] </ref>. Reps presented an incremental algorithm for updating an attribute graph with performance linear in the number of vertices in the graph whose attributes are altered by the update. 2 Using this approach along with ideas in [AHR + 90], Ramalingam and Reps developed several ffi-incremental algorithms on graphs. They also applied a technique from [AHR + 90] to prove incremental lower bounds in a restricted model of computation. <p> algorithm for updating an attribute graph with performance linear in the number of vertices in the graph whose attributes are altered by the update. 2 Using this approach along with ideas in <ref> [AHR + 90] </ref>, Ramalingam and Reps developed several ffi-incremental algorithms on graphs. They also applied a technique from [AHR + 90] to prove incremental lower bounds in a restricted model of computation. This chapter will discuss ffi-analysis, particularly as a tool for proving lower bounds, and present new lower bounds results. In Chapter 6 we will develop a new ffi-incremental algorithm. <p> This chapter will discuss ffi-analysis, particularly as a tool for proving lower bounds, and present new lower bounds results. In Chapter 6 we will develop a new ffi-incremental algorithm. We discuss the value of this type of analysis versus the alternatives in Chapter 7. 1 In <ref> [AHR + 90] </ref>, the term incremental algorithm is used as we use ffi-incremental algorithm. <p> First, if the graph under consideration is of bounded degree, 3 In his seminal work on ffi-analysis [Rep82], Reps used "INFLUENCED" to represent the neighbors of modified [affected. We follow the more recent usage in Alpern et al. <ref> [AHR + 90] </ref> and Ramalingam and Reps [RR91]. 4 As pointed out in [RR91], for bounded degree graphs there is a difference of only a constant factor between the size of ffi and the size of its neighborhood, for incremental algorithms that depend on a polynomial function of kffik. 5 Ramalingam <p> Even trickier issues about the definition of kffik will arise in Chapter 6. 5.3 Lower Bounds Arguments 5.3.1 Local Persistence The lower bound argument in <ref> [AHR + 90] </ref> applies to a model of computation termed local persistence. In this model, all data is associated with the vertices of the graph. <p> As each vertex is visited, the local information for that vertex can be updated. All operations are deterministic. 5.3.2 The Incremental Circuit Value Problem Alpern et al. proved a lower bound for the incremental circuit value problem, within the model of local persistence <ref> [AHR + 90] </ref>. The incremental circuit value problem requires the maintenance of the values computed by gates in a circuit as changes are made to the circuit. <p> We refer to them here as non-ffi-incremental. Two methods are used in [RR91] to classify problems as non-ffi-incremental. The first is a direct proof similar in form to that used in <ref> [AHR + 90] </ref> | a pair of changes is presented in which the first affects only a constant number of vertices, requiring 43 the second to process the entire graph even though kffik is still bounded. <p> a DAG; i.e., xy does not induce a cycle. 6 In this procedure, and for the procedures to follow, we assume that we have a queue package available, with the following characteristics: * emptyQueue (q): initializes q to be an empty queue. 6 By using the priority ordering algorithm in <ref> [AHR + 90] </ref>, cycle-inducing edges can be detected in time O (kffi 2 k log kffik), but of course in this case the algorithm would not be ffi-incremental, by a similar argument to that in x6.4.1. 63 * enqueue (q; x): adds element x to the end of queue q. * <p> There are at least three approaches that might be taken to deal with the problem: 1. Maintain dynamically a priority order on the vertices in time O (kffi 2 k log kffik) <ref> [AHR + 90] </ref>, and test the vertices in reverse priority order. This guarantees that when a vertex v is checked, the reach sets for all its successors are up-to-date. <p> One should point out that while these are limitations of the general approach, in practice many of the algorithms proposed have functions that are not only bounded, but also of quite reasonable complexity <ref> [Rep82, RR91, AHR + 90] </ref>. Furthermore, large graphs from domains such as data flow analysis are likely to have low average density, even when there is no a priori bound on the degree of the graph.
Reference: [AHU74] <author> A.Aho, J. Hopcroft, and J. Ullman. </author> <title> The Design and Analysis of Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: Some of the arguments appear in this paper; the others can be derived easily. Problems with O (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, <ref> [AHU74] </ref> Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x <p> Some of the arguments appear in this paper; the others can be derived easily. Problems with O (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, <ref> [AHU74] </ref> Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest <p> Some of the arguments appear in this paper; the others can be derived easily. Problems with O (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, <ref> [AHU74] </ref> Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph <p> Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph <ref> [AHU74] </ref> 4.6.2 An Incremental Algorithm for Minimal Spanning Trees Frederickson has presented an algorithm for incremental update of edges in a Minimal Spanning Tree (MST), and an extension that can be used to update the Connected Components in a graph [Fre85]. <p> For example, consider Heapsort <ref> [AHU74] </ref>: before the algorithm can sort, it must put the input items into a heap. Not until long after the entire data set has been input can we expect any output. Alternatively, an online algorithm executes by reading its input an item at a time and computing as it goes. <p> The on-line execution of requires that the instructions in be executed from left to right, executing the ith instruction in without looking at any following instructions. The off-line execution of permits all of to be scanned before any answers need to be produced. <ref> [AHU74, p109] </ref> Note that this definition is given in terms of a sequence of "instructions." While there is no fundamental difference between instructions and any other kind of input data, the description of the input as a sequence of instructions is typical for an online problem. <p> See, for example, [Sar86, Wes89]. 7.2.2 Model of Computation A lower bound is most applicable when it is proved for a robust model of computation. The most appealing model for sequential lower bound proofs is the Random Access Machine (RAM) <ref> [AHU74] </ref>, which closely models a typical computer. Not all incremental lower bounds are derived in the RAM model. The well-known super-linear lower bound for the Union-Find algorithm is proved for a Pointer Machine [Tar75]; in this model all memory accesses follow via pointers, with no address arithmetic allowed. <p> The pointer machine, while strictly weaker than the random-access machine model of computation <ref> [AHU74] </ref>, is a realistic model for list-processing algorithms [Tar83]. The fundamental difference between the pointer machine and the random access machine is that, in the pointer machine, address arithmetic is not allowed. The pointer machine model was used to derive the lower bound for the Union-Find algorithm [Tar75].
Reference: [AI91] <author> G. Ausiello and G. F. </author> <title> Italiano. On-line algorithms for polynomially solvable satisfiability problems. </title> <journal> Journal of Logic Programming, </journal> <volume> 10(1) </volume> <pages> 69-90, </pages> <year> 1991. </year>
Reference: [AIMSN90] <author> G. Ausiello, G. F. Italiano, A. Marchetti-Spaccamela, and U. Nanni. </author> <title> Incremental algorithms for minimal length paths. </title> <booktitle> In Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 12-21. </pages> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1990. </year>
Reference: [AMSN89] <author> G. Ausiello, A. Marchetti-Spaccamela, and U. Nanni. </author> <title> Dynamic maintenances of paths and path expressions in graphs. </title> <booktitle> In Proceedings of the International Symposium on Symbolic and Albegraic Computation, </booktitle> <pages> pages 1-12, </pages> <address> Berlin, </address> <year> 1989. </year> <note> Springer-Verlag. Lecture Notes in Computer Science 358. </note>
Reference: [ASU86] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: With some additional restrictions on the form of the system, the reaching definitions and connected components problems can be modeled as well. For an overview of data flow analysis problems, see <ref> [ASU86] </ref>; for a discussion of the system equations model applied to data flow analysis, see [Hec77] and [RP86]. A system of equations of form (4.5.1), can be modeled as a digraph constructed from the variable interdependencies. <p> Problems with O (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, [AHU74] Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions <ref> [ASU86] </ref> Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph [AHU74] 4.6.2 An Incremental Algorithm for Minimal Spanning Trees Frederickson has presented an algorithm for <p> with O (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, [AHU74] Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions <ref> [ASU86] </ref> Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph [AHU74] 4.6.2 An Incremental Algorithm for Minimal Spanning Trees Frederickson has presented an algorithm for incremental update of edges in <p> Can the algorithm given in x6.6 be generalized to apply to a larger class of graphs, e.g., reducible flow graphs <ref> [ASU86] </ref>? 3. Can a ffi-incremental algorithm for TC-DAG be found that does better than kffik 2 , or conversely, can it be shown that this is a lower bound? 4.
Reference: [BPR86] <author> A. M. Berman, M. C. Paull, and B. G. Ryder. </author> <title> Proving relative lower bounds for incremental algorithms. </title> <type> Technical Report DCS-TR-154, </type> <institution> Department of Computer Science, Rutgers University, </institution> <year> 1986. </year>
Reference-contexts: Such a set of equations can be used to solve the connected components problem, which was shown in Section 4.4.2 to be in Class 2. It can be shown that any problem that can be modeled in this way is in Class 2; the details can be found in <ref> [BPR86] </ref>. 4.6 Implications 4.6.1 A Collection of IRLB's 1=`. Some of the arguments appear in this paper; the others can be derived easily.
Reference: [BPR90] <author> A. M. Berman, M. C. Paull, and B. G. Ryder. </author> <title> Proving relative lower bounds for incremental algorithms. </title> <journal> Acta Informatica, </journal> <volume> 27 </volume> <pages> 665-683, </pages> <year> 1990. </year>
Reference-contexts: Incremental Relative Lower Bounds: The method of Incremental Relative Lower Bounds (IRLB's) is presented and applied to many incremental problems; the material in this chapter appeared previously in <ref> [BPR90] </ref>. 5. ffi-Analysis of Incremental Algorithms: The ffi-analysis approach to analyzing in cremental algorithms is presented; new results in this model are derived. 6. <p> While we cannot hope that this dissertation will clean up this semantic mess, this chapter carefully defines the exact meaning of "incremental algorithm" within this dissertation. These definitions are based on those in [PaCB84] and <ref> [BPR90] </ref>. Definition 2.1.1 Let ff:P ! Q be a function with domain P being the set of problem instances or inputs , and range Q the set of answers or outputs . <p> We will provide an intuitive description of the method and then lay it out more formally, first 1 The results in this chapter were published in <ref> [BPR90] </ref>. 16 discussing the general approach and then showing specific examples. We will show that for certain functions, the lower bound for any incremental algorithm is proportional to the lower bound for computing that function. Thus, we call a bound produced by this method an incremental relative lower bound .
Reference: [BR90] <author> M. Burke and B. G. Ryder. </author> <title> A critical analysis of incremental iterative data flow analysis algorithms. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(7), </volume> <month> July </month> <year> 1990. </year> <month> 110 </month>
Reference-contexts: For some domains, it may be possible to compare the utility of incremental algorithms considering their performance for the types of inputs that are most likely to occur <ref> [BR90] </ref>. There have also been a few attempts to demonstrate the utility of incremental algorithms by comparing their performance on random data, versus starting over from scratch; see [Car88, RLP90].
Reference: [BT89] <author> G. Di Battista and R. Tamassia. </author> <title> Incremental planarity testing. </title> <booktitle> In Proceedings of the Thirtieth Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 436-441. </pages> <institution> Institute of Electrical and Electronics Engineers Computer Society, </institution> <year> 1989. </year>
Reference: [BT90] <author> G. Di Battista and R. Tamassia. </author> <title> On-line graph algorithms with spqr-trees. </title> <booktitle> In Proceedings of the Seventeenth International Colloquium on Automata, Languages and Programming. European Association for Theoretical Computer Science, </booktitle> <year> 1990. </year> <note> Extended abstract. </note>
Reference: [Bur90] <author> M. Burke. </author> <title> An interval-based approach to exhaustive and incremental inter-procedural data-flow analysis. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 341-395, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: We refer to the latter changes as "structural changes." Ryder's original incremental data flow analysis algorithms handled only non-structural changes in code; however, they were extended to handle structural changes later <ref> [Bur90, CR88] </ref>. Our results show that their worst case behavior can be no better than the best known data flow analysis algorithm. This justifies Ryder's claim that worst case analysis is not an appropriate measure of the utility of these incremental algorithms.
Reference: [Car88] <author> M. Carroll. </author> <title> Data flow analysis via attribute and dominator updates. </title> <type> PhD thesis, </type> <institution> Rutgers University, </institution> <month> May </month> <year> 1988. </year>
Reference-contexts: There have also been a few attempts to demonstrate the utility of incremental algorithms by comparing their performance on random data, versus starting over from scratch; see <ref> [Car88, RLP90] </ref>. While it has often been suggested that a better empirical test would be based on data collected from actual problem domains, we are not aware of any work of this kind.
Reference: [CBT + 92] <author> R. F. Cohen, G. Di Battista, R. Tamassia, I. G. Tollis, and P. Bertolazzi. </author> <title> A framework for dynamic graph drawing. </title> <booktitle> In Proceedings of the Eighth Annual Symposium on Computational Geometry. Association for Computing Machinery, </booktitle> <year> 1992. </year> <note> Extended abstract. </note>
Reference: [CC82] <author> G. A. Cheston and D. G. Corneil. </author> <title> Graph property update algorithms and their application to distance matrices. </title> <journal> Infor, </journal> <volume> 20(3) </volume> <pages> 178-201, </pages> <month> August </month> <year> 1982. </year>
Reference-contexts: The operation searchpath (x,y) returns an arbitrary path from x to y in G if such a path exists, otherwise null. Italiano's 1 This problem was addressed implicitly by Cheston and Corneil in <ref> [CC82] </ref>; their methods do not yield any improvement over the start-over algorithm in the worst case. 52 method supports a simple reachability query pathexists (a,b) in O (1) time. A single addition (or searchpath) can require O (nm) time in the worst case. Deletions are not addressed.
Reference: [CH78] <author> F. Chin and D. Houck. </author> <title> Algorithms for updating minimum spanning trees. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 16 </volume> <pages> 333-344, </pages> <year> 1978. </year>
Reference: [Che76] <author> G. A. Cheston. </author> <title> Incremental Algorithms In Graph Theory. </title> <type> PhD thesis, </type> <institution> Univ. of Toronto, 1976. Department of Computer Science Tech. </institution> <type> Report 91. </type>
Reference-contexts: This is hardly surprising; what is surprising is that despite the fact that this result is widely assumed (see, e.g., <ref> [Che76] </ref>), the conditions under which this result does and does not hold true have not been carefully considered. 1 Typically, a good incremental algorithm maintains some auxiliary information about the operation of the algorithm from one incremental change to the next. <p> A statement similar to Corollary 3.4.2 was made in <ref> [Che76] </ref>, although it was not proved. In the arguments above, the characterization of the lower bound depends strictly upon the function at hand and not upon its implementation. However, the history does not depend just upon the function, but also upon the particular algorithm used to compute that function.
Reference: [Che84] <author> G. A. Cheston. </author> <title> On-line connectivity algorithms. </title> <journal> Networks, </journal> <volume> 14 </volume> <pages> 83-94, </pages> <year> 1984. </year>
Reference: [CLR91] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: For further information on graphs, see an algorithms or data structures reference, e.g., <ref> [Tar83, CLR91] </ref>. Definition 2.2.1 Let G = (V; E) be a graph, where V is a set representing the vertices, and E is the set of edges. Each edge is a set of size two fu; vg 2 E, where u; v 2 V and u 6= v. <p> If there is a path from u to v, we write u ; v. 2.3 Asymptotic Growth Notation We use the standard definitions as given in the algorithms textbook of Cormen, Leis-erson, and Rivest <ref> [CLR91] </ref>. For all the following definitions, c, c 1 , c 2 , and n 0 represent positive constants, and g (n) any given function. <p> For the general problem, the Transitive Closure can be computed in the time it takes to perform matrix multiplication, which is O (n 2:376 ) <ref> [CLR91, CW87] </ref>. There is no known lower bound for this problem other than the obvious (n 2 ) | the size of the original set of relations is jSj fi jSj = n 2 . <p> As another example, consider the minimum spanning tree problem. Clearly this problem has a nave linear lower bound (m + n); the upper bound is O (m + n log n) <ref> [CLR91] </ref>. 96 For a dense graph, m = O (n 2 ), hence O (m + n log n) = O (n 2 + n log n) = O (n 2 ), i.e., linear. Since minimum spanning tree is a Class 2 problem, it cannot be updated faster than 1=n. <p> For example, consider path-finding, or closed semiring problems, which are conjectured to require !(n 2 ) time, although the only known bound is (n 2 ) <ref> [CLR91] </ref>. The all-pairs shortest paths problem is a special case of a closed-semiring problem. By IRLB analysis we know that incremental algorithms for this problem can be no faster, in the worst case, than starting over (see x4.4.1). <p> Can good (Class 2 or Class 3) IRLB proofs be found that apply to the "easy" update (typically, additions)? 5. A hypergraph is like an undirected graph, except that edges connect arbitrary subsets of the vertices rather than pairs of vertices <ref> [CLR91, pp. 89-90] </ref>. Would problems on hypergraphs yield IRLB's falling between Class 2 and Class 3? There is also an issue here as to the "atomic" nature of a change when a single edge is a set of size O (n). Problems related to ffi-analysis 1.
Reference: [CR88] <author> M. D. Carroll and B. G. Ryder. </author> <title> Incremental data flow analysis via dominator and attribute updates. </title> <booktitle> In Conference Record of the Fifteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 274-284, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: We refer to the latter changes as "structural changes." Ryder's original incremental data flow analysis algorithms handled only non-structural changes in code; however, they were extended to handle structural changes later <ref> [Bur90, CR88] </ref>. Our results show that their worst case behavior can be no better than the best known data flow analysis algorithm. This justifies Ryder's claim that worst case analysis is not an appropriate measure of the utility of these incremental algorithms. <p> In Frederickson's algorithm [Fre85] and in the similar methods of Italiano [Ita91], large clusters of vertices in the graph are condensed into clusters, and links are maintained between the clusters. In Carroll and Ryder's algorithms for updating attribute and dominator graphs <ref> [CR88] </ref>, a tree is laid over the target graph, and pointers can be followed along the tree edges, which are not in general the same as edges in the graph.
Reference: [Cul91] <author> P. Cull. </author> <title> Review of "Proving relative lower bounds for incremental algorithms" by A. </title> <editor> M. Berman et al. </editor> <publisher> Computing Reviews, </publisher> <pages> page 375, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Furthermore, since the proof is based on deletions, it also applies to partially-dynamic algorithms that process deletions. However, an IRLB based on a sequence of deletions says nothing about sequences of additions only. This was pointed out in <ref> [Cul91] </ref>. It is not clear that this should be considered a limitation of the method; rather, it may reflect the fact that for many incremental problems, one side of the incremental problem is more difficult than the other, as discussed in x7.2.1.
Reference: [CW87] <author> D. Coppersmith and S. Winograd. </author> <title> Matrix multiplication via arithmetic progressions. </title> <booktitle> In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 1-6. </pages> <institution> Association for Computing Machinery, </institution> <year> 1987. </year>
Reference-contexts: For the general problem, the Transitive Closure can be computed in the time it takes to perform matrix multiplication, which is O (n 2:376 ) <ref> [CLR91, CW87] </ref>. There is no known lower bound for this problem other than the obvious (n 2 ) | the size of the original set of relations is jSj fi jSj = n 2 .
Reference: [Dij59] <author> E. W. Dijkstra. </author> <title> A note on two problems in connexion with graphs. </title> <journal> Nu-merische Mathematik, </journal> <volume> 1 </volume> <pages> 269-271, </pages> <year> 1959. </year> <month> 111 </month>
Reference-contexts: Note that a more careful, direct analysis of the complexity of the algorithm, which is not provided by Ramalingam and Reps, might yield a better bound. However, since the algorithm is based directly on Dijkstra's algorithm <ref> [Dij59] </ref> for shortest paths, it is certainly not going to be any better than O (n 3 ).
Reference: [EG85] <author> S. Even and H. Gazit. </author> <title> Updating distances in dynamic graphs. Methods Oper. </title> <journal> Research, </journal> <volume> 49 </volume> <pages> 371-387, </pages> <year> 1985. </year>
Reference-contexts: Our technique encompasses a result of Even and Gazit, who showed for the particular problem of computing all shortest paths in a directed graph that an incremental algorithm can do no better, in the worst case, than recomputing the solution with the new inputs <ref> [EG85] </ref>. We demonstrate our technique by bounding a number of incremental algorithms drawn from various domains. Our results have interesting implications with respect to the optimality of an incremental algorithm previously developed by Ryder in [Ryd83, RP88]. <p> this section we present some graph problems and argue their IRLB classification. 4.4.1 A Recapitulation of All-pairs Shortest Paths Even and Gazit show that no incremental algorithm for the All-pairs Shortest Paths (ASP) problem in a directed graph can be any faster, in the worst case, than recomputing from scratch <ref> [EG85] </ref>. In our terms, this places the function ASP in Class 3 . Here we recapitulate Even and Gazit's argument to show how it fits within our framework.
Reference: [EIT + 92] <author> D. Eppstein, G. F. Italiano, R. Tamassia, R. E. Tarjan, J. Westbrook, and M. Yung. </author> <title> Maintenance of a minimum spanning forest in a dynamic planar graph. </title> <journal> Journal of Algorithms, </journal> <volume> 13 </volume> <pages> 33-54, </pages> <year> 1992. </year>
Reference: [ES81] <author> S. Even and Y. Shiloach. </author> <title> An on-line edge deletion problem. </title> <journal> Journal of the ACM, </journal> <volume> 28(1) </volume> <pages> 1-4, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: For example, the method of Even and Shiloach for updating connected 5 List maintenance problems are a notable exception; see, e.g., [ST85]. 94 components requires O (n) per deletion (amortized) <ref> [ES81] </ref>. By working in only one direction, a partially-dynamic algorithm can "throw away" structure as it goes, whereas a fully-dynamic algorithm typically needs to maintain complicated history information.
Reference: [Fre85] <author> G. N. Frederickson. </author> <title> Data structures for on-line updating of minimum spanning trees, with applications. </title> <journal> SIAM Journal of Computing, </journal> <volume> 14(4) </volume> <pages> 781-798, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph [AHU74] 4.6.2 An Incremental Algorithm for Minimal Spanning Trees Frederickson has presented an algorithm for incremental update of edges in a Minimal Spanning Tree (MST), and an extension that can be used to update the Connected Components in a graph <ref> [Fre85] </ref>. His algorithm runs in time O ( p m), where m is the 35 number of edges in the graph. The algorithm requires O (m) preprocessing, plus the time to find the initial minimum spanning tree, which is known to be O (m log fi (m; n)) 6 [GGST86]. <p> Examples of this approach include Frederickson's algorithm for updating minimum spanning trees <ref> [Fre85] </ref>, which has guaranteed improved worst-case performance over the start-over algorithm, and Ryder's algorithms for incremental data flow analysis [RP88], which in the worst case is no better than starting over. <p> Frederickson's algorithm for updating minimum spanning trees <ref> [Fre85] </ref>, on the other hand, is an example of a fully-dynamic algorithm. Edge additions and deletions, as well as weight increases and decreases are all addressed. <p> An incremental update algorithm that had a worst-case performance of O (n) could be quite good; in fact, an O (n) lower bound on this problem can be derived from the IRLB argument for connectivity (see x4.4.2). Furthermore, O (n) is the performance of Frederickson's algorithm on dense graphs <ref> [Fre85] </ref>. 101 As the inherent complexity of the problem increases, a ffi-analysis lower bound becomes progressively less interesting. For example, consider path-finding, or closed semiring problems, which are conjectured to require !(n 2 ) time, although the only known bound is (n 2 ) [CLR91]. <p> In Frederickson's algorithm <ref> [Fre85] </ref> and in the similar methods of Italiano [Ita91], large clusters of vertices in the graph are condensed into clusters, and links are maintained between the clusters. <p> The Class 2 IRLB does allow for incremental algorithms that are faster than starting over, and in fact such an algorithm exists (Frederickson's algorithm <ref> [Fre85] </ref>). There is no contradiction here | even though very small updates might require looking at the entire graph (the ffi-analysis result) the incremental algorithm can still always beat starting over . Furthermore, Frederickson's algorithm uses a complicated data structure that is not allowed in the local persistence model.
Reference: [FS84] <author> G. N. Frederickson and M. A. Srinivas. </author> <title> On-line updating of degree-constrained minimum spanning trees. </title> <booktitle> In Proceedings of the Twenty-Second Allerton Conference on Communication, Control, and Computing, </booktitle> <month> October </month> <year> 1984. </year>
Reference: [Fuj81] <author> S. Fujishige. </author> <title> A note on the problem of updating shortest paths. </title> <journal> Networks, </journal> <volume> 11 </volume> <pages> 317-319, </pages> <year> 1981. </year>
Reference: [Gaz83] <author> H. Gazit. </author> <title> Algorithms in dynamic graphs. </title> <type> Master's thesis, </type> <institution> Technion, Haifa, Israel, </institution> <month> May </month> <year> 1983. </year> <note> In Hebrew. </note>
Reference: [GGST86] <author> H. Gabow, Z. Galil, T. Spencer, and R. E. Tarjan. </author> <title> Efficient algorithms for finding minimum spanning trees in undirected and directed graphs. </title> <journal> Combinatorica, </journal> <volume> 6(2) </volume> <pages> 109-122, </pages> <year> 1986. </year>
Reference-contexts: His algorithm runs in time O ( p m), where m is the 35 number of edges in the graph. The algorithm requires O (m) preprocessing, plus the time to find the initial minimum spanning tree, which is known to be O (m log fi (m; n)) 6 <ref> [GGST86] </ref>. In Section 4.4.2, we described a method for demonstrating that MST is in IRLB Class 2.
Reference: [Gho83] <author> V. Ghodssi. </author> <title> Incremental analysis of programs. </title> <type> PhD thesis, </type> <institution> University of Central Florida, </institution> <year> 1983. </year>
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman & Company, </publisher> <year> 1979. </year>
Reference-contexts: theorem must hold. 13 3.4 NP-complete Incremental Algorithms Now we apply Theorem 3.2.3 to an NP-complete problem, 3-SAT, and bound the speed of incremental algorithms for this problem. 3-SAT is the problem of determining whether a set of clauses, each clause containing exactly three literals, has a satisfying truth assignment <ref> [GJ79] </ref>. We will show that no NP-complete problem can have a polynomial time incremental algorithm (with restricted history) unless P = NP .
Reference: [GSV78] <author> S. Goto and A. Sangiovanni-Vincentelli. </author> <title> A new shortest path updating algorithm. </title> <journal> Networks, </journal> <volume> 8 </volume> <pages> 341-372, </pages> <year> 1978. </year>
Reference: [Har83] <author> D. Harel. </author> <title> On line maintenance of the connected components of dynamic graphs. </title> <journal> Unpublished manuscipt, </journal> <year> 1983. </year>
Reference: [Hec77] <author> M. S. Hecht. </author> <title> Flow Analysis of Computer Programs. </title> <publisher> Elsevier North-Holland, </publisher> <year> 1977. </year>
Reference-contexts: With some additional restrictions on the form of the system, the reaching definitions and connected components problems can be modeled as well. For an overview of data flow analysis problems, see [ASU86]; for a discussion of the system equations model applied to data flow analysis, see <ref> [Hec77] </ref> and [RP86]. A system of equations of form (4.5.1), can be modeled as a digraph constructed from the variable interdependencies. <p> An example of a constrained system of equations can be derived from the reaching definitions problem of data flow analysis <ref> [Hec77, RP86] </ref>. A flow graph is a digraph representation of the execution flow in a single-entry procedure. Each node represents a straight-line code sequence; edges represent possible transfer of control at execution time. <p> (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, [AHU74] Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination <ref> [Hec77, RP86] </ref> Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph [AHU74] 4.6.2 An Incremental Algorithm for Minimal Spanning Trees Frederickson has presented an algorithm for incremental update of edges in a Minimal <p> An identical argument to this can be made for connected components. 4.6.3 Implications for Incremental Data Flow Analysis The classical data flow analysis problems, such as reaching definitions, available expressions, and very busy expressions, can all be formulated as systems of equations <ref> [Hec77, RP86] </ref>. By the arguments in Section 4.5, they can be shown to be in Class 3 .
Reference: [HS76] <author> E. Horowitz and S. Sahni. </author> <title> Fundamentals of Data Structures. </title> <publisher> Computer Science Press, </publisher> <year> 1976. </year>
Reference-contexts: After ` steps, the list will be sorted, in total time o (` log `). But this is clearly a contradiction since comparison sorting cannot be that fast (see, e.g., <ref> [HS76, pp. 350-352] </ref>). So the best incremental comparison sorting algorithm (with restricted history) cannot be faster than log `. 3.3 Bounding Amortized Complexity In amortized complexity, the time per operation is averaged over a worst-case sequence of operations [Tar84].
Reference: [IK83] <author> T. Ibaraki and N. Katoh. </author> <title> On-line computation of transitive closure of graphs. </title> <journal> Information Processing Letters, </journal> <volume> 16 </volume> <pages> 95-97, </pages> <year> 1983. </year>
Reference-contexts: so the DAG algorithm requires O (n 3 ); as a practical matter it is much faster than the standard multiplicative algorithm for 51 many graphs. 6.2 Incremental Upper Bounds There has been quite a bit of work in developing incremental algorithms for this problem, beginning with Ibaraki and Katoh <ref> [IK83] </ref>. 1 Ibaraki and Katoh give algorithms for updating the transitive closure for a graph with edge additions and edge deletions. After each change in the graph, the transitive closure information can be accessed in constant time.
Reference: [Ita86] <author> G. F. </author> <title> Italiano. Amortized efficiency of a path retrieval data structure. </title> <journal> Theoretical Computer Science, </journal> <volume> 48 </volume> <pages> 273-281, </pages> <year> 1986. </year> <month> 112 </month>
Reference-contexts: In <ref> [Ita86] </ref> Italiano introduced an algorithm that can process a sequence of n edge additions and searchpath operations in O (n) amortized time per operation.
Reference: [Ita88] <author> G. F. </author> <title> Italiano. Finding paths and deleting edges in directed acyclic graphs. </title> <journal> Information Processing Letters, </journal> <volume> 28 </volume> <pages> 5-11, </pages> <year> 1988. </year>
Reference-contexts: A single addition (or searchpath) can require O (nm) time in the worst case. Deletions are not addressed. Italiano has also developed algorithms for updates on DAG's <ref> [Ita88] </ref>. These algorithms support a sequence of edge deletions in O (n) amortized time per deletion. A sequence of any number of deletions m requires a total of O (nm) in the worst case. This improves on Ibaraki and Katoh's result when m n.
Reference: [Ita91] <author> G. F. </author> <title> Italiano. Dynamic Data Structures for Graphs. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1991. </year> <note> Technical Report CUCS-019-91. </note>
Reference-contexts: There is a substantial amount of interest in fully-dynamic incremental algorithms. Frederickson's algorithm for handling updates to Minimum Spanning Trees and Connected Components stands out as the best-known result in this field, but others have made progress as well. For example, Italiano's dissertation <ref> [Ita91] </ref> presents fully-dynamic algorithms for updating 2-Edge Connectivity. Italiano also notes: . . . for many graph theoretical problems there is no known efficient partially dynamic algorithm for handling edge deletions only . . . . <p> Since . . . dynamic problems with edge insertions only can be solved much more efficiently than the corresponding fully dynamic problems, it seems quite natural 97 to ask whether more efficient techniques for handling edge deletions only can be designed. <ref> [Ita91, p. 95] </ref> The interest shown in developing fully-dynamic incremental algorithms justifies lower bound methods, such as the IRLB, which are based on sequences of deletions, or additions, whichever is the more difficult case. <p> In Frederickson's algorithm [Fre85] and in the similar methods of Italiano <ref> [Ita91] </ref>, large clusters of vertices in the graph are condensed into clusters, and links are maintained between the clusters.
Reference: [Knu73] <author> D. E. Knuth. </author> <title> Fundamental Algorithms, </title> <booktitle> volume III of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1973. </year>
Reference-contexts: update will be !(n); in such cases, showing the problem to be non-incremental in the ffi-analysis problem does not yield a better lower bound. 8 7.4.3 Weakness of the Local Persistence Model of Computation At first glance, the local persistence model (x5.3.1) looks fairly close to the pointer machine model <ref> [Knu73] </ref>. The pointer machine, while strictly weaker than the random-access machine model of computation [AHU74], is a realistic model for list-processing algorithms [Tar83]. The fundamental difference between the pointer machine and the random access machine is that, in the pointer machine, address arithmetic is not allowed.
Reference: [KRvM88] <author> J. Keables, K. Roberson, and A. von Mayrhauser. </author> <title> Data flow analysis and its application to software maintenance. </title> <booktitle> In Proceedings of the IEEE Conference on Software Maintenance, </booktitle> <pages> pages 335-347. </pages> <institution> Institute of Electrical and Electronics Engineers Computer Society, </institution> <month> October </month> <year> 1988. </year>
Reference: [LD91] <author> H. R. Lewis and L. Denenberg. </author> <title> Data Structures and Their Algorithms. </title> <publisher> Harper Collins, </publisher> <year> 1991. </year>
Reference-contexts: If instead the graph is presented as a linked list or in some other form, then an adjacency matrix can be constructed in linear time as the graph is read in, using an implementation that supports constant time initialization; see, e.g., <ref> [LD91, pp. 136-138] </ref>. 5 We understand that Ramalingam and Reps may have independently developed algorithms for the closely related problem of updating reachability on reducible flow graphs [Rep92]. 58 59 in parentheses represent the topological sort mapping. <p> Furthermore, we need to be able to list the members of a set in time proportional to the number of members, an operation not supported by a bit vector. A data structure with these characteristics can be found in, e.g., <ref> [LD91, pp. 258-259] </ref>. The amount of storage required to implement sets in this way will be larger by a constant factor that is approximately 2d, where d is the number of bits per word for a particular machine.
Reference: [LPv88] <author> J. A. La Poutre and J. van Leeuwen. </author> <title> Maintenance of transitive closures and transitive reductions of graphs. </title> <editor> In H. Gottler and H. J. Schneider, editors, </editor> <booktitle> Graph-Theoretic Concepts in Computer Science 1987, volume 314 of Lecture Notes in Computer Science, </booktitle> <pages> pages 106-120, </pages> <address> Berlin-Heidelberg-New York, 1988. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This improves on Ibaraki and Katoh's result when m n. Again, it is possible that in the worst case a single deletion could require O (nm) time. Similar results were reported independently in <ref> [LPv88] </ref>, who also extend their deletion method to general digraphs, at a higher time complexity. More recently, Yellin has improved on these when the degree of the graph is bounded [Yel91].
Reference: [Mar89] <author> T. J. Marlowe. </author> <title> Data Flow Analysis and Incremental Iteration. </title> <type> PhD thesis, </type> <institution> Rutgers University, </institution> <month> October </month> <year> 1989. </year> <month> DCS-TR-225. </month>
Reference: [Meh84] <author> K. Mehlhorn. </author> <title> Data Structures and Algorithms 2: Graph Algorithms and NP-Completeness. </title> <booktitle> EATCS Monographs on Theoretical Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: Transitive closure on a DAG can be computed in O (njE red j). E red is the set of edges in the reduced graph for G, that is, the smallest graph with the same transitive closure as G <ref> [Meh84] </ref>. <p> It is well-known that t exists if and only if G is acyclic; the mapping can be found in linear time (O (n + m)) <ref> [Meh84] </ref>. In conjunction with the computation of the topological sort, we will maintain an inverted list of the vertices so that we can traverse them in topologically sorted order. Let x = t 1 (i) be the vertex such that t (x) = i.
Reference: [Ov81] <author> M. H. Overmars and J. van Leeuwen. </author> <title> Maintenance of configurations in the plane. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 23(2) </volume> <pages> 166-204, </pages> <month> October </month> <year> 1981. </year>
Reference: [PaCB84] <author> M. C. Paull, C. Ching an Cheng, and A. M. Berman. </author> <title> Exploring the structure of incremental algorithms. </title> <type> Technical Report DCS-TR-139, </type> <institution> Department of Computer Science, Rutgers University, </institution> <month> May </month> <year> 1984. </year> <note> Preliminary version. </note>
Reference-contexts: 1. Introduction: this introduction. 2. Definitions: some fundamental definitions for incremental algorithms. 3 3. A General Lower Bounds Result: Relatively weak but general bounds that apply to nearly all incremental algorithms are derived; some of the material in this chapter appeared previously in <ref> [PaCB84] </ref>. 4. <p> While we cannot hope that this dissertation will clean up this semantic mess, this chapter carefully defines the exact meaning of "incremental algorithm" within this dissertation. These definitions are based on those in <ref> [PaCB84] </ref> and [BPR90]. Definition 2.1.1 Let ff:P ! Q be a function with domain P being the set of problem instances or inputs , and range Q the set of answers or outputs . <p> However, this may not be the case if the 1 Some of the material in this chapter appeared in <ref> [PaCB84] </ref>. 9 entire state is "dumped" at each step; instead, a record of changes in state should be written as output, from which the sequence of states can be constructed later. <p> If these conditions cannot be met, it is still possible to apply a weaker theorem. That theorem, described in <ref> [PaCB84] </ref>, yields an IRLB of 1=`, which, of course, is not useful for functions with linear lower bounds. Condition ii in Theorem 4.2.4 is needed only when the changed problem increases in length. <p> With this modification, certain bounds are still easily provable for functions not known to be polynomial | for example, for those that are NP -complete. This theorem appeared with a different proof in <ref> [PaCB84] </ref>. Theorem 4.2.5 Consider an incremental algorithm A for function ff and a procedure of the form shown in Figure 4.1 constructed using A. If: i. <p> Note that this corollary is a restatement, and re-proving, of Theorem 3.2.3 in terms of the IRLB. Corollary 4.3.1 If a function ff has a fast initialization value, then it has an IRLB of 1=`: <ref> [PaCB84] </ref> Proof We prove this by applying Theorem 4.2.5. To do this, we must first describe a procedure of the form shown in Figure 4.1, and then prove that this procedure meets the preconditions for the theorem.
Reference: [Pau88] <author> M.C. Paull. </author> <title> Introduction to Algorithm Design Principles. </title> <address> Wiley-Inter-science, </address> <year> 1988. </year>
Reference-contexts: To transform this graph back to the original graph, the n added edges are removed; hence *(`) = n, and minimal spanning tree is in Class 2 . 4.5 Solving Systems of Equations This section considers problems formulated as a system of equations whose the solution yields the problem solution <ref> [Pau88] </ref>. We demonstrate some common problems that can 28 be given this representation. 2 Our systems of equations are either unconstrained or constrained , depending on the relation between the constants and coefficients. We first consider unconstrained systems. <p> An example of a function whose solution can be modeled as above is the minimum-maximum edge weight path, or bottleneck flow problem, as described in <ref> [Pau88] </ref>. Consider a weighted digraph with a distinguished node v. <p> Problems with O (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, [AHU74] Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, <ref> [Pau88] </ref> Reaching Definitions x 4.5.2, [RP86] Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph [AHU74] 4.6.2 An Incremental Algorithm for Minimal
Reference: [Pol86] <author> L. L. Pollock. </author> <title> An approach to incremental compilation of optimized code. </title> <type> PhD thesis, </type> <institution> University of Pittsburgh, </institution> <month> April </month> <year> 1986. </year>
Reference: [PR85] <author> S. Pawagi and I. V. Ramakrishnan. </author> <title> Parallel updates of graph properties in logarithmic time. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 186-193. </pages> <institution> Institute of Electrical and Electronics Engineers Computer Society, </institution> <year> 1985. </year>
Reference: [PS89] <author> L. L. Pollock and M. L. Soffa. </author> <title> An incremental version of iterative data flow analysis. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(12) </volume> <pages> 1537-1549, </pages> <month> December </month> <year> 1989. </year> <month> 113 </month>
Reference: [PT88] <author> F. P. Preparata and R. Tamassia. </author> <title> Fully dynamic techniques for point location and transitive closure in planar structures. </title> <booktitle> In Proceedings of the Twenty-Ninth Annual IEEE Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 558-567. </pages> <institution> Institute of Electrical and Electronics Engineers - Computer Society, </institution> <year> 1988. </year>
Reference: [RC86] <author> B. G. Ryder and M. D. Carroll. </author> <title> An incremental algorithm for software analysis. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 171-179. </pages> <institution> Association for Computing Machinery, </institution> <year> 1986. </year>
Reference: [Rei87] <author> J. H. Reif. </author> <title> A topological approach to dynamic graph connectivity. </title> <journal> Information Processing Letters, </journal> <volume> 25 </volume> <pages> 65-70, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: This method is used to show that the Single-Source Reachability problem is non-ffi-incremental for locally persistent algorithms. The second method is a problem reduction approach similar to that in <ref> [Rei87] </ref>. This method is used to extend the reachability result to Single-Source (or Single-Sink) Closed-Semiring Path problems and Meet-Semilattice Data-Flow Analysis problems. 5.4 New ffi-Analysis Lower Bounds for Undirected Graphs In this section we apply the techniques discussed above to several problems of undirected graphs. <p> Thus we see the methods as complementary. 104 7.6 Another Approach Complete Dynamic Problems Reif has proposed another approach to analyzing incremental algorithms <ref> [Rei87] </ref>. By using Turing Machine reductions, he is able to categorize a group of problems as equally difficult to solve incrementally. While this does not yield a lower bound result, it does give some insight into the difficulty of developing incremental algorithms for a class of problems.
Reference: [Rep82] <author> T. Reps. </author> <title> Optimal-time incremental semantic analysis for syntax-directed editors. </title> <booktitle> In Conference Record of the Ninth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 169-176. </pages> <institution> Association for Computing Machinery, </institution> <year> 1982. </year>
Reference-contexts: function of the size of the changes required by the update; this approach is referred to here as ffi-analysis, and algorithms that are efficient in terms of ffi-analysis are referred to as ffi-incremental algorithms. 1 This is a generalization of an idea that first appeared in a paper by Reps <ref> [Rep82] </ref> and was extended by Alpern et al. [AHR + 90]. <p> There are a couple of mitigating factors that make this more of a theoretical concern than a practical problem. First, if the graph under consideration is of bounded degree, 3 In his seminal work on ffi-analysis <ref> [Rep82] </ref>, Reps used "INFLUENCED" to represent the neighbors of modified [affected. <p> One should point out that while these are limitations of the general approach, in practice many of the algorithms proposed have functions that are not only bounded, but also of quite reasonable complexity <ref> [Rep82, RR91, AHR + 90] </ref>. Furthermore, large graphs from domains such as data flow analysis are likely to have low average density, even when there is no a priori bound on the degree of the graph.
Reference: [Rep88] <author> T. Reps. </author> <title> Incremental evaluation for attribute grammars with unrestricted movement between tree modifications. </title> <journal> Acta Informatica, </journal> <volume> 25 </volume> <pages> 155-178, </pages> <year> 1988. </year>
Reference: [Rep92] <author> T. Reps, </author> <month> March </month> <year> 1992. </year> <type> Personal Communication. </type>
Reference-contexts: matrix can be constructed in linear time as the graph is read in, using an implementation that supports constant time initialization; see, e.g., [LD91, pp. 136-138]. 5 We understand that Ramalingam and Reps may have independently developed algorithms for the closely related problem of updating reachability on reducible flow graphs <ref> [Rep92] </ref>. 58 59 in parentheses represent the topological sort mapping. Dashed lines represent edges added in steps 2 and removed in step 7. 60 14-20].
Reference: [RLP90] <author> B. G. Ryder, W. Landi, and H. Pande. </author> <title> Profiling an incremental data flow analysis algorithm. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(2) </volume> <pages> 129-140, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: There have also been a few attempts to demonstrate the utility of incremental algorithms by comparing their performance on random data, versus starting over from scratch; see <ref> [Car88, RLP90] </ref>. While it has often been suggested that a better empirical test would be based on data collected from actual problem domains, we are not aware of any work of this kind.
Reference: [Rod68] <author> V. V. Rodionov. </author> <title> The parametric problem of shortest distances. </title> <journal> U.S.S.R. Computational Mathematics and Mathematical Physics, </journal> <volume> 8(5) </volume> <pages> 336-343, </pages> <year> 1968. </year>
Reference: [RP86] <author> B. G. Ryder and M. C. Paull. </author> <title> Elimination algorithms for data flow analysis. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(3) </volume> <pages> 277-316, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: With some additional restrictions on the form of the system, the reaching definitions and connected components problems can be modeled as well. For an overview of data flow analysis problems, see [ASU86]; for a discussion of the system equations model applied to data flow analysis, see [Hec77] and <ref> [RP86] </ref>. A system of equations of form (4.5.1), can be modeled as a digraph constructed from the variable interdependencies. <p> An example of a constrained system of equations can be derived from the reaching definitions problem of data flow analysis <ref> [Hec77, RP86] </ref>. A flow graph is a digraph representation of the execution flow in a single-entry procedure. Each node represents a straight-line code sequence; edges represent possible transfer of control at execution time. <p> Problems with O (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, [AHU74] Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, <ref> [RP86] </ref> Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination [Hec77, RP86] Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph [AHU74] 4.6.2 An Incremental Algorithm for Minimal Spanning Trees Frederickson has presented <p> (1) IRLB's (Class 3) Reference Shortest path in a digraph (various forms) x 4.4.1, [AHU74] Transitive Closure of a binary relation x 6.3 Planarity Testing [AHU74] Strong Connectivity [AHU74] Minimum-Maximum edge weight path x 4.5.1, [Pau88] Reaching Definitions x 4.5.2, [RP86] Available Expressions [ASU86] Live Uses of Variables [ASU86] Domination <ref> [Hec77, RP86] </ref> Problems with 1=`; 1= p ` IRLB's (Class 2) Reference Connected Components x 4.4.2 Biconnected Components x 4.4.2 Minimum Spanning Tree x 4.4.2 Shortest path, undirected graph [AHU74] 4.6.2 An Incremental Algorithm for Minimal Spanning Trees Frederickson has presented an algorithm for incremental update of edges in a Minimal <p> An identical argument to this can be made for connected components. 4.6.3 Implications for Incremental Data Flow Analysis The classical data flow analysis problems, such as reaching definitions, available expressions, and very busy expressions, can all be formulated as systems of equations <ref> [Hec77, RP86] </ref>. By the arguments in Section 4.5, they can be shown to be in Class 3 .
Reference: [RP88] <author> B. G. Ryder and M. C. Paull. </author> <title> Incremental data flow analysis algorithms. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(1) </volume> <pages> 1-50, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: We demonstrate our technique by bounding a number of incremental algorithms drawn from various domains. Our results have interesting implications with respect to the optimality of an incremental algorithm previously developed by Ryder in <ref> [Ryd83, RP88] </ref>. <p> This justifies Ryder's claim that worst case analysis is not an appropriate measure of the utility of these incremental algorithms. It also justifies the alternative performance analyses on a reasonable, structured programming language <ref> [RP88] </ref>. An interesting question under investigation is the possibility that incremental algorithms which handle only certain classes of code changes, or which are applicable to a restricted set of a ik , c i , may have better worst case performance than suggested by our IRLB results. <p> By restricting Allen/Cocke interval analysis, on which Ryder's incremental data flow algorithms are based, to programs whose loop nesting level is bounded by a constant, we can improve the worst case bound from O (n 2 ) to O (n) <ref> [RP88] </ref>. Similar results may be achievable with incremental data flow algorithms. 37 Chapter 5 ffi-Analysis of Incremental Algorithms 5.1 Overview In [RR91], Ramalingam and Reps argue that classifying incremental algorithms by their worst-case asymptotic performance may be unnecessarily pessimistic in many cases. <p> Examples of this approach include Frederickson's algorithm for updating minimum spanning trees [Fre85], which has guaranteed improved worst-case performance over the start-over algorithm, and Ryder's algorithms for incremental data flow analysis <ref> [RP88] </ref>, which in the worst case is no better than starting over. Update algorithms that beat the start-over algorithm for a single change, in the worst case, have been relatively few; the IRLB method gives some insight into why this has been the case for many problems.
Reference: [RR91] <author> G. Ramalingam and T. Reps. </author> <title> On the computational complexity of incremental algorithms. </title> <type> Technical Report #1033, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <year> 1991. </year>
Reference-contexts: Similar results may be achievable with incremental data flow algorithms. 37 Chapter 5 ffi-Analysis of Incremental Algorithms 5.1 Overview In <ref> [RR91] </ref>, Ramalingam and Reps argue that classifying incremental algorithms by their worst-case asymptotic performance may be unnecessarily pessimistic in many cases. <p> to mean so many things already that we do not believe that it is sufficiently descriptive of the context, hence ffi-incremental. 2 More precisely, linear in the size of the neighborhood of the change, as discussed in Section 5.2. 38 5.2 The ffi-Analysis Model The ffi-analysis model as developed in <ref> [RR91] </ref> applies specifically to graph problems. In particular, they consider directed graphs in which there is a value associated with each vertex. <p> Alpern et al. claim that "... incremental analysis ... studies running time as a function of the size of a change in the underlying data structures ...." In <ref> [RR91] </ref>, Ramalingam and Reps state that ... instead of analyzing the behavior of algorithms in terms of the size of the size of the entire current input ... we concentrate on analyzing algorithms in terms of the size of an "adaptive" parameter ... that captures the changes in the input and <p> First, if the graph under consideration is of bounded degree, 3 In his seminal work on ffi-analysis [Rep82], Reps used "INFLUENCED" to represent the neighbors of modified [affected. We follow the more recent usage in Alpern et al. [AHR + 90] and Ramalingam and Reps <ref> [RR91] </ref>. 4 As pointed out in [RR91], for bounded degree graphs there is a difference of only a constant factor between the size of ffi and the size of its neighborhood, for incremental algorithms that depend on a polynomial function of kffik. 5 Ramalingam and Reps denote such a problem non-incremental. <p> We follow the more recent usage in Alpern et al. [AHR + 90] and Ramalingam and Reps <ref> [RR91] </ref>. 4 As pointed out in [RR91], for bounded degree graphs there is a difference of only a constant factor between the size of ffi and the size of its neighborhood, for incremental algorithms that depend on a polynomial function of kffik. 5 Ramalingam and Reps denote such a problem non-incremental. 40 then the size of the <p> For several other problems in graphs with cycles, it is shown in <ref> [RR91] </ref> that no bounded locally persistent algorithm can be found; that is, a change affecting only a constant number of vertices may require the examination of every vertex in the graph. <p> These problems are dubbed "non-incremental" by Ramalingam and Reps, although as they point out this claim is only proven in the local persistence model. We refer to them here as non-ffi-incremental. Two methods are used in <ref> [RR91] </ref> to classify problems as non-ffi-incremental. <p> This extension can be applied to Theorems 5.4.5 and 5.5.2 below, and Proposition 4.2 in Ramalingam and Reps <ref> [RR91, p. 27] </ref>. 5.4.2 Biconnectivity Definition 5.4.4 Two vertices x and y in a graph G = (V; E) are biconnected if they are connected by at least two disjoint paths. <p> There is also the dual problem of determining, for each vertex x and a distinguished vertex k, whether there is a path from x to k; k is called the sink and the problem the Single-Sink Reachability problem. 61 In <ref> [RR91] </ref> it is shown that SS-REACH is non-ffi-incremental in the local persistence model (see x5.3.1). This is demonstrated with the graph reproduced in Figure 6.6. <p> Determining the affected set for transitive closure is more of a problem, since we are not updating a single label for each vertex, but rather a set of labels. A similar problem arose when Ramalingam and Reps analyzed All-Shortest Paths <ref> [RR91, p.15] </ref>, and we use a similar, but not identical, approach. In order for our definition of affected to be reasonable, it must meet the spirit of ffi-analysis, in which local changes require a small amount of work regardless of the input size of the start-over problem. <p> One should point out that while these are limitations of the general approach, in practice many of the algorithms proposed have functions that are not only bounded, but also of quite reasonable complexity <ref> [Rep82, RR91, AHR + 90] </ref>. Furthermore, large graphs from domains such as data flow analysis are likely to have low average density, even when there is no a priori bound on the degree of the graph. <p> Thus, we know that it is impossible to find an incremental algorithm that does better than O (n 2 ). Via ffi-analysis it can be shown that closed-semiring problems are non incremental in the local persistence model <ref> [RR91] </ref>; however, this is weaker than the more general IRLB bound, and hence is not particularly useful. <p> On the other hand, Ramalingam and Reps give a ffi-incremental algorithm for updating shortest paths, specifically for the All Pairs Shortest Paths &gt; 0 (APSP&gt;0) problem <ref> [RR91] </ref>. However, there is no contradiction here because the worst case complexity of their algorithm can be as bad as starting over. The algorithm for APSP&gt;0 has complexity O (kffik 2 + kffik 1 log kffik 1 ). <p> Problems related to ffi-analysis 1. Is there a better way to look at the extended size of ffi? The current method does not generalize well to problems where the label at a node is a vector or set (see x6.6.3 and <ref> [RR91] </ref>). 2. Can ffi-analysis be applied to domains other than graph theoretical problems? 108 3. Can a meta-proof technique, similar to the IRLB approach, be developed that would simplify the process of finding proofs of non-ffi-incrementality? Most of the proofs have very similar structure. 4.
Reference: [RTD83] <author> T. Reps, T. Teitelbaum, and A. Demers. </author> <title> Incremental context-dependent analysis for language-based editors. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(3) </volume> <pages> 449-477, </pages> <year> 1983. </year>
Reference: [Ryd83] <author> B. G. Ryder. </author> <title> Incremental data flow analysis. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 167-176. </pages> <institution> Association for Computing Machinery, </institution> <month> January </month> <year> 1983. </year> <month> 114 </month>
Reference-contexts: We demonstrate our technique by bounding a number of incremental algorithms drawn from various domains. Our results have interesting implications with respect to the optimality of an incremental algorithm previously developed by Ryder in <ref> [Ryd83, RP88] </ref>.
Reference: [Sac86] <author> M. G. Sackrowitz. </author> <title> Incremental updating of depth-first search trees. </title> <type> Technical Report DCS-TR-173, </type> <institution> Department of Computer Science, Rutgers University, </institution> <address> New Brunswick, NJ 08903, </address> <month> January </month> <year> 1986. </year>
Reference: [Sar86] <author> N. Sarnak. </author> <title> Persistent data structures. </title> <type> PhD thesis, </type> <address> New York University, </address> <year> 1986. </year>
Reference-contexts: Finally, we note that there has been quite a bit of work on persistent algorithms, which can be thought of as partially-dynamic algorithms that can back up to previous states. See, for example, <ref> [Sar86, Wes89] </ref>. 7.2.2 Model of Computation A lower bound is most applicable when it is proved for a robust model of computation. The most appealing model for sequential lower bound proofs is the Random Access Machine (RAM) [AHU74], which closely models a typical computer.
Reference: [SP73] <author> P. M. Spira and A. Pan. </author> <title> On finding and updating shortest paths and spanning trees. </title> <booktitle> In Symposium on Switching and Automata Theory, </booktitle> <pages> pages 82-84. </pages> <institution> Institute of Electrical and Electronics Engineers Computer Society, </institution> <year> 1973. </year>
Reference: [ST85] <author> D. M. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Communications of the ACM, </journal> <year> 1985. </year>
Reference-contexts: We note that it may be possible to find partially-dynamic incremental algorithm for the "hard" direction that is more efficient, or simpler, than a fully-dynamic incremental algorithm. For example, the method of Even and Shiloach for updating connected 5 List maintenance problems are a notable exception; see, e.g., <ref> [ST85] </ref>. 94 components requires O (n) per deletion (amortized) [ES81]. By working in only one direction, a partially-dynamic algorithm can "throw away" structure as it goes, whereas a fully-dynamic algorithm typically needs to maintain complicated history information.
Reference: [Tam88] <author> R. Tamassia. </author> <title> A dynamic data structure for planar graph embedding. </title> <booktitle> In Proceedings of the Fifteenth International Colloquium on Automata, Languages and Programming, </booktitle> <pages> pages 576-590, </pages> <address> Berlin, </address> <year> 1988. </year> <note> European Association for Theoretical Computer Science, Springer-Verlag. Lecture Notes in Computer Science 317. </note>
Reference: [Tar75] <author> R. E. Tarjan. </author> <title> Efficiency of a good but not linear set union algorithm. </title> <journal> Journal of the ACM, </journal> <volume> 22 </volume> <pages> 215-225, </pages> <year> 1975. </year>
Reference-contexts: As a final comment, we have observed that amortization arguments often depend on a sequence of changes of the same kind, e.g., adding elements, in which a data structure "moves in one direction." An example is the disjoint set union problem <ref> [Tar75] </ref>, in which the "entropy" of the data structure can be shown to decrease as set lookups are performed. <p> Incremental algorithms can be categorized as fully- or partially-dynamic, depending on whether they handle a single type of change, e.g., insertions, or both insertions and deletions. 4 For example, Tarjan's "Union-Find" algorithm <ref> [Tar75] </ref> can be viewed as a partially-dynamic incremental algorithm for the Connected Components problem; the algorithm handles edge additions, but apparently cannot be generalized to handle deletions. Frederickson's algorithm for updating minimum spanning trees [Fre85], on the other hand, is an example of a fully-dynamic algorithm. <p> The most appealing model for sequential lower bound proofs is the Random Access Machine (RAM) [AHU74], which closely models a typical computer. Not all incremental lower bounds are derived in the RAM model. The well-known super-linear lower bound for the Union-Find algorithm is proved for a Pointer Machine <ref> [Tar75] </ref>; in this model all memory accesses follow via pointers, with no address arithmetic allowed. <p> The fundamental difference between the pointer machine and the random access machine is that, in the pointer machine, address arithmetic is not allowed. The pointer machine model was used to derive the lower bound for the Union-Find algorithm <ref> [Tar75] </ref>. However, local persistence is substantially weaker than a pointer machine, because of the restriction that the pointers followed during a computation must follow the structure of the input problem. In other words, no data structures can be used to assist in the update.
Reference: [Tar83] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms. </title> <booktitle> CBMS-NSF Regional Conference Series in Applied Mathematics. </booktitle> <publisher> SIAM, </publisher> <year> 1983. </year>
Reference-contexts: For further information on graphs, see an algorithms or data structures reference, e.g., <ref> [Tar83, CLR91] </ref>. Definition 2.2.1 Let G = (V; E) be a graph, where V is a set representing the vertices, and E is the set of edges. Each edge is a set of size two fu; vg 2 E, where u; v 2 V and u 6= v. <p> The pointer machine, while strictly weaker than the random-access machine model of computation [AHU74], is a realistic model for list-processing algorithms <ref> [Tar83] </ref>. The fundamental difference between the pointer machine and the random access machine is that, in the pointer machine, address arithmetic is not allowed. The pointer machine model was used to derive the lower bound for the Union-Find algorithm [Tar75].
Reference: [Tar84] <author> R. E. Tarjan. </author> <title> Amortized computational complexity. </title> <journal> SIAM J. Alg. Disc. Meth., </journal> <volume> 6(2) </volume> <pages> 306-318, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: So the best incremental comparison sorting algorithm (with restricted history) cannot be faster than log `. 3.3 Bounding Amortized Complexity In amortized complexity, the time per operation is averaged over a worst-case sequence of operations <ref> [Tar84] </ref>. The advantage of amortized analysis is that in some cases, the average time per operation in the worst-case sequence is less than the worst-case time. Theorem 3.2.3 can be viewed as applying to the amortized case as well as the worst-case. <p> This is the motivation behind ffi-analysis. It is often suggested that amortized analysis <ref> [Tar84] </ref> may be a useful way to com pare incremental algorithms. However, we would argue that in the update model such methods often are neither particularly appropriate nor useful. <p> In such a situation, an amortized analysis, in which we average the running time per operation over a (worst-case) sequence of operations, can yield an answer that is both realistic and robust. <ref> [Tar84] </ref> There is no hard and fast line between algorithms we call "update" and those we call "online." It is more a matter of the questions that we choose to ask. Online algorithms typically refer to a sequence of operations, rather than a solution that needs to be updated.
Reference: [TP90] <author> R. Tamassia and F. P. Preparata. </author> <title> Dynamic maintenance of planar digraphs. </title> <journal> Algorithmica, </journal> <volume> 5 </volume> <pages> 509-527, </pages> <year> 1990. </year>
Reference: [Wes89] <author> J. Westbrook. </author> <title> Algorithms and data structures for dynamic graph problems. </title> <type> PhD thesis, </type> <institution> Princeton University, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: Finally, we note that there has been quite a bit of work on persistent algorithms, which can be thought of as partially-dynamic algorithms that can back up to previous states. See, for example, <ref> [Sar86, Wes89] </ref>. 7.2.2 Model of Computation A lower bound is most applicable when it is proved for a robust model of computation. The most appealing model for sequential lower bound proofs is the Random Access Machine (RAM) [AHU74], which closely models a typical computer.
Reference: [WT92] <author> J. Westbrook and R. E. Tarjan. </author> <title> Maintaining bridge-connected and bicon-nected components on-line. </title> <journal> Algorithmica, </journal> <volume> 7 </volume> <pages> 433-464, </pages> <year> 1992. </year>
Reference: [Yel91] <author> D. M. Yellin. </author> <title> Speeding up dynamic transitive closure for bounded degree graphs. </title> <note> To be published in Acta Informatica, </note> <year> 1991. </year>
Reference-contexts: Similar results were reported independently in [LPv88], who also extend their deletion method to general digraphs, at a higher time complexity. More recently, Yellin has improved on these when the degree of the graph is bounded <ref> [Yel91] </ref>. His approach handles a sequence of m insertions in time O (dm fl ), where d is the degree bound and m fl is the size of the transitive closure. <p> Consider changes of size O (1). In this case, the cost for an AddEdgeTC-DAG, ffi, will really depend upon the size of the neighborhood of the change. In some situations in which an incremental algorithm for a DAG is applied, the graph may have bounded degree <ref> [Yel91] </ref>. In this case, the size of the neighborhood is also bounded by a constant, and the cost of AddEdgeTC-DAG is also O (1). <p> true when considering worst-case performance; for amortized arguments, it may make sense to treat a sequence of changes as a single unit. 4 In some cases, the algorithm may handle both types of change, but the analysis may apply only to a sequence of one type of change; see, e.g., <ref> [Yel91] </ref>. 93 more challenging, goal is finding a fully-dynamic algorithm. Typically, although not always, online algorithms are partially-dynamic. 5 Likewise, a lower-bound argument can apply to partially or fully dynamic versions of the underlying problem.
Reference: [YS88] <author> D. M. Yellin and R. Strom. INC: </author> <title> A language for incremental computation. </title> <booktitle> In Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 115-124. </pages> <institution> Association for Computing Machinery, </institution> <year> 1988. </year>
Reference-contexts: We argue that this is not a significant deterrent to the value of the bound in most cases. First, many of the problems for which there has been interest in incremental methods, such as Connected Components and Transitive Closure (see, e.g., <ref> [YS88] </ref>), have linear time start-over algorithms; in this case, the lower bound is also known (linear) and hence an 7 The reader may recognize that the signature corresponds to the upper-diagonal portion of an adjacency matrix. 99 IRLB can be used to find an absolute lower bound on the incremental algorithm.
Reference: [Zad84] <author> F. Zadeck. </author> <title> Incremental data flow analysis in a structured program editor. </title> <booktitle> In Proceedings of the SIGPLAN 1984 Conference on Programming Language Design and Implementation. Association for Computing Machinery, </booktitle> <month> July </month> <year> 1984. </year> <month> 115 </month>
References-found: 82

