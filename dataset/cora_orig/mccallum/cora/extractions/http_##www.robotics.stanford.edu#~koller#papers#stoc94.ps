URL: http://www.robotics.stanford.edu/~koller/papers/stoc94.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/stoc94.html
Root-URL: http://www.robotics.stanford.edu
Email: daphne@cs.berkeley.edu  megiddo@almaden.ibm.com  i51bbvs@rz.unibw-muenchen.de  
Title: Fast Algorithms for Finding Randomized Strategies in Game Trees  
Author: Daphne Koller Nimrod Megiddo Bernhard von Stengel 
Note: Research supported in part by ONR Contracts N00014-91-C-0026 and N00014-94-C-0007, by the Air Force Office of Scientific Research (AFSC) under Contract F49620-91-C-0080, and by the Volkswagen Foundation. Some of the work was performed while the first author was at Stanford University. The United States Government is authorized to reproduce and distribute reprints for governmental purposes. In: Proceedings of the 26th ACM Symposium on the Theory of Computing, 1994, 750-759  
Address: Berke-ley, CA 94720;  650 Harry Road, San Jose, CA 95120  650 Harry Road, San Jose, CA 95120;  Mu-nich, 85577 Neubiberg, Germany.  
Affiliation: Computer Science Division, University of California,  and IBM Almaden Research Center,  IBM Almaden Research Center,  and School of Mathematical Sciences, Tel Aviv University, Tel Aviv, Israel. Informatik 5, University of the Federal Armed Forces at  
Abstract: Interactions among agents can be conveniently described by game trees. In order to analyze a game, it is important to derive optimal (or equilibrium) strategies for the different players. The standard approach to finding such strategies in games with imperfect information is, in general, computationally intractable. The approach is to generate the normal form of the game (the matrix containing the payoff for each strategy combination), and then solve a linear program (LP) or a linear complementarity problem (LCP). The size of the normal form, however, is typically exponential in the size of the game tree, thus making this method impractical in all but the simplest cases. This paper describes a new representation of strategies which results in a practical linear formulation of the problem of two-player games with perfect recall (i.e., games where players never forget anything, which is a standard assumption). Standard LP or LCP solvers can then be applied to find optimal randomized strategies. The resulting algorithms are, in general, exponentially better than the standard ones, both in terms of time and in terms of space. fl In Proceedings of the 26th Annual ACM Symposium on Theory of Computing, 1994
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> R. J. Aumann and eds. S. Hart. </editor> <booktitle> Handbook of Game Theory, </booktitle> <volume> Vol. 1. </volume> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Game theory models and analyzes situations involving conflict and cooperation among independent decision makers. It has played a substantial role in economics <ref> [1] </ref>, and has been applied to biology [19], safeguards systems [2] and in the military [18], among other areas. In computer science, the idea of modeling interactive situations as games is becoming more common.
Reference: [2] <author> R. Avenhaus. </author> <title> Safeguards Systems Analysis. </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: 1 Introduction Game theory models and analyzes situations involving conflict and cooperation among independent decision makers. It has played a substantial role in economics [1], and has been applied to biology [19], safeguards systems <ref> [2] </ref> and in the military [18], among other areas. In computer science, the idea of modeling interactive situations as games is becoming more common. The classic paper of Chandra, Kozen and Stockmeyer [5] characterized the class PSPACE in terms of two-player games.
Reference: [3] <author> S. Ben-David, A. Borodin, R. Karp, G. Tardos, and A. Wigderson. </author> <title> On the power of randomization in online algorithms. </title> <booktitle> In Proceedings of the 22nd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 379-386, </pages> <year> 1990. </year>
Reference-contexts: For example, Yao's technique of proving lower bounds for randomized algorithms [39] follows directly from the classical minimax theorem [36] from game theory. A number of recent results in online computation are based on game-theoretic techniques (most obviously <ref> [3] </ref>). Game theory has been used in artificial intelligence to model interactions among intelligent agents, for example [32]. In the context of distributed systems, such issues as collective coin flipping [4] and privacy and security [14] have been analyzed using games.
Reference: [4] <author> M. Ben-Or and N. Linial. </author> <title> Collective coinf flipping, robust voting games and minima of Banzhaf values. </title> <booktitle> In Proceedings of the 26th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 408-416, </pages> <year> 1985. </year>
Reference-contexts: A number of recent results in online computation are based on game-theoretic techniques (most obviously [3]). Game theory has been used in artificial intelligence to model interactions among intelligent agents, for example [32]. In the context of distributed systems, such issues as collective coin flipping <ref> [4] </ref> and privacy and security [14] have been analyzed using games. Other interactions relevant to computer science, such as network routing or load-sharing in distributed systems, also seem to fit naturally in a game-theoretic framework.
Reference: [5] <author> A. K. Chandra, D. C. Kozen, and L. J. Stock-meyer. </author> <title> Alternation. </title> <journal> Journal of the ACM, </journal> <volume> 28 </volume> <pages> 114-133, </pages> <year> 1981. </year>
Reference-contexts: In computer science, the idea of modeling interactive situations as games is becoming more common. The classic paper of Chandra, Kozen and Stockmeyer <ref> [5] </ref> characterized the class PSPACE in terms of two-player games. The later work on interactive proof systems [34, 7] is also best understood in those terms. Reif [31] extends the paradigm of interactive proofs to a more general class of games.
Reference: [6] <author> S. J. Chung. </author> <title> NP-completeness of the linear complementarity problem. </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 60 </volume> <pages> 393-399, </pages> <year> 1989. </year>
Reference-contexts: This is a special case of our Theorem 1.2 (see Section 5). While Lemke's algorithm typically avoids complete enumeration, its worst-case running time is still exponential. Deciding if a general LCP has a solution is N P-complete <ref> [6] </ref>, but the present LCP always has one. As we mentioned in the introduction, it is not known whether an equilibrium of a bimatrix game can be found in polynomial time; the problem is also not known to be N P-hard.
Reference: [7] <author> A. Condon, J. Feigenbaum, C. Lund, and P. Shor. </author> <title> Probabilistically checkable debate systems and approximation algorithms for PSPACE-hard functions (extended abstract). </title> <booktitle> In Proceedings of the 25nd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 305-314, </pages> <year> 1993. </year>
Reference-contexts: In computer science, the idea of modeling interactive situations as games is becoming more common. The classic paper of Chandra, Kozen and Stockmeyer [5] characterized the class PSPACE in terms of two-player games. The later work on interactive proof systems <ref> [34, 7] </ref> is also best understood in those terms. Reif [31] extends the paradigm of interactive proofs to a more general class of games. Worst-case analysis of algorithms can also be viewed naturally as a game between the solver and an adversary.
Reference: [8] <author> R. W. Cottle, J.-S. Pang, and R. E. Stone. </author> <title> The Linear Complementarity Problem. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: The system (10) and (11) is a linear complementarity problem (LCP) <ref> [8] </ref>. All solutions to this system can be found with a simple complete enumeration scheme whose running time is exponential in the size of the matrix. <p> Lemke's algorithm [25] is a pivoting scheme similar to the simplex algorithm for linear programming, but with a different "complementarity" rule for the entering and leaving variables, and no objective function; for expositions see <ref> [29, 8] </ref>. <p> It may happen that Lemke's algorithm does not terminate with a solution to the LCP (13). (The analogous phenomenon occurs with the simplex algorithm in case of an unbounded objective function.) One condition that prevents this possibility is asserted in the following Theorem 4.4.13 of <ref> [8] </ref>. Theorem 5.2 If (i) z T M z 0 for all z 0, (ii) z 0, M z 0 and z T M z = 0 imply b T z 0, and (iii) the problem is nondegenerate, then Lemke's algorithm computes a solution of the LCP (13). <p> Thereby, the solution is not changed by performing the pivoting operations as if " is "just vanishing", which is implemented by certain lexicographic comparisons only involving b and M (and no "); see <ref> [8, p. 340] </ref>. A similar technique for prevention of cycling given a degenerate problem is known for the simplex algorithm.
Reference: [9] <author> N. Dalkey. </author> <title> Equivalence of information patterns and essentially indeterminate games. </title> <editor> In H. W. Kuhn and A. W. Tucker, editors, </editor> <booktitle> Contributions to the Theory of Games II, </booktitle> <pages> pages 217-243. </pages> <publisher> Princeton University Press, </publisher> <year> 1953. </year>
Reference-contexts: By definition, the normal form lists all pure strategies of both players. This number is exponential, since each combination of choices defines a pure strategy. It is sometimes possible to reduce the size of the normal form by eliminating redundant rows or columns in the matrix <ref> [9] </ref>. These are caused by certain information sets that are unreachable due to an earlier choice of the player. Unfortunately, this reduced normal form may still have exponential size. This is also observed in practice [28, 38]. <p> This justifies our intuition that the set f k ( k (a))g a of realization weights of the leaves a captures all the relevant information about k . We call such strategies 1 and ~ 1 equivalent . (This corresponds to a standard notion of equivalence of strategies <ref> [9] </ref>.) A set of realization weights therefore describes an equivalence class of mixed strategies. Using techniques of [22], we can prove that this equivalence class contains a member that can be represented compactly.
Reference: [10] <author> G. B. Dantzig. </author> <title> Linear Programming and Extensions. </title> <publisher> Princeton University Press, </publisher> <year> 1963. </year> <month> 758 </month>
Reference-contexts: This is known as the weak duality theorem, stating that feasible primal and dual objective function values comprise mutual bounds. By the strong duality theorem <ref> [10] </ref>, they are equal at optimality; that is, y; q is an optimal pair iff q T f = q T F y = x T By: (4) Analogously, a best response x to the strategy y of player 2 is a solution to the following problem: maximize x subject to <p> An equilibrium of the zero-sum game, that is, a pair of optimal solutions to (8) and (9), is simultaneously computed by the simplex algorithm <ref> [10] </ref>. The problem can of course be solved in polynomial time (in the size of the matrix) by any polynomial linear programming algorithm.
Reference: [11] <author> S. Even and R. E. Tarjan. </author> <title> A combinatorial problem which is complete in polynomial space. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 23 </volume> <pages> 710-719, </pages> <year> 1976. </year>
Reference-contexts: Thus it is not surprising that games are typically hard to solve when represented using their rules. For example, it is PSPACE-hard to find optimal strategies for generalized Go [27] and a variety of other games <ref> [33, 11] </ref>, and EXPTIME-complete to find optimal strategies for generalized Chess [12] or generalized Checkers [13]. A game in extensive form is represented as a tree (a formal definition is given in Section 2).
Reference: [12] <author> A. S. Fraenkel and D. Lichtenstein. </author> <title> Computing a perfect strategy for n fi n Chess requires time exponential in n. </title> <journal> Journal of Combinatorial Theory, Series A, </journal> <volume> 31 </volume> <pages> 199-214, </pages> <year> 1981. </year>
Reference-contexts: Thus it is not surprising that games are typically hard to solve when represented using their rules. For example, it is PSPACE-hard to find optimal strategies for generalized Go [27] and a variety of other games [33, 11], and EXPTIME-complete to find optimal strategies for generalized Chess <ref> [12] </ref> or generalized Checkers [13]. A game in extensive form is represented as a tree (a formal definition is given in Section 2). The nodes of the tree are game states (e.g., chess board positions together with the history of the game), the branchings result from the players' actions.
Reference: [13] <author> A. S. Fraenkel and D. Lichtenstein. </author> <title> n by n Checkers in EXPTIME complete. </title> <journal> SIAM Journal on Computing, </journal> <volume> 13(2) </volume> <pages> 252-267, </pages> <year> 1984. </year>
Reference-contexts: For example, it is PSPACE-hard to find optimal strategies for generalized Go [27] and a variety of other games [33, 11], and EXPTIME-complete to find optimal strategies for generalized Chess [12] or generalized Checkers <ref> [13] </ref>. A game in extensive form is represented as a tree (a formal definition is given in Section 2). The nodes of the tree are game states (e.g., chess board positions together with the history of the game), the branchings result from the players' actions.
Reference: [14] <author> M. Franklin, Z. Galil, and M. Yung. </author> <title> Eavesdropping games: A graph-theoretic approach to privacy in distributed systems. </title> <booktitle> In Proceedings of the 34th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 670-679, </pages> <year> 1993. </year>
Reference-contexts: Game theory has been used in artificial intelligence to model interactions among intelligent agents, for example [32]. In the context of distributed systems, such issues as collective coin flipping [4] and privacy and security <ref> [14] </ref> have been analyzed using games. Other interactions relevant to computer science, such as network routing or load-sharing in distributed systems, also seem to fit naturally in a game-theoretic framework.
Reference: [15] <author> I. Gilboa, E. Kalai, and E. Zemel. </author> <title> The complexity of eliminating dominated strategies. </title> <journal> Mathematics of Operations Research, </journal> <volume> 18(3) </volume> <pages> 553-565, </pages> <year> 1993. </year>
Reference-contexts: The problem of finding an equilibrium is known neither to belong to P nor to be N P-hard. The complexity of various associated problems has been studied in <ref> [16, 20, 15] </ref>. Applied to extensive-form games, these normal-form algorithms are typically impractical for any but toy problems. <p> Unfortunately, this reduced normal form may still have exponential size. This is also observed in practice [28, 38]. A further reduction of bimatrix games, based on elimination of payoff-dominated rows or columns has been studied in <ref> [20, 15] </ref>. 4 Realization Weights Mixed strategies assign a probability to each of the exponentially many pure strategies. It turns out that some of this information is redundant.
Reference: [16] <author> I. Gilboa and E. Zemel. </author> <title> Nash and correlated equilibria: Some complexity considerations. </title> <journal> Games and Economic Behavior, </journal> <volume> 1 </volume> <pages> 80-93, </pages> <year> 1989. </year>
Reference-contexts: The problem of finding an equilibrium is known neither to belong to P nor to be N P-hard. The complexity of various associated problems has been studied in <ref> [16, 20, 15] </ref>. Applied to extensive-form games, these normal-form algorithms are typically impractical for any but toy problems. <p> As we mentioned in the introduction, it is not known whether an equilibrium of a bimatrix game can be found in polynomial time; the problem is also not known to be N P-hard. The related N P-hardness results of Gilboa and Zemel <ref> [16] </ref> concern questions that essentially require consideration of all equilibria. The complexity of finding a single equilibrium of such a game is an important open question that remains unresolved. Unfortunately, for a game in extensive form, even if it is zero-sum, the algorithms described in this section are typically impractical.
Reference: [17] <author> M. Grotschel, L. Lovasz, and A. Schrijver. </author> <title> Geometric Algorithms and Combinatorial Optimization. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: While Wilson conjectured that his algorithm is efficient, he was not able to prove this fact (see Section 4). Koller and Megiddo [21] presented the first polynomial time algorithm for solving zero-sum games with perfect recall. Their algorithm, however, is based on the ellipsoid algorithm for linear programming <ref> [17] </ref>, and is therefore not very practical. They also showed that, in games with imperfect recall , the problem of solving such games is N P-hard. In this paper, we present a method that avoids the exponential blowup of the normal-form transformation.
Reference: [18] <author> O. Hajek. </author> <title> Pursuit Games. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: 1 Introduction Game theory models and analyzes situations involving conflict and cooperation among independent decision makers. It has played a substantial role in economics [1], and has been applied to biology [19], safeguards systems [2] and in the military <ref> [18] </ref>, among other areas. In computer science, the idea of modeling interactive situations as games is becoming more common. The classic paper of Chandra, Kozen and Stockmeyer [5] characterized the class PSPACE in terms of two-player games.
Reference: [19] <author> J. Hofbauer and K. Sigmund. </author> <title> The Theory of Evolution and Dynamical Systems. </title> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: 1 Introduction Game theory models and analyzes situations involving conflict and cooperation among independent decision makers. It has played a substantial role in economics [1], and has been applied to biology <ref> [19] </ref>, safeguards systems [2] and in the military [18], among other areas. In computer science, the idea of modeling interactive situations as games is becoming more common. The classic paper of Chandra, Kozen and Stockmeyer [5] characterized the class PSPACE in terms of two-player games.
Reference: [20] <author> D. E. Knuth, C. H. Papadimitriou, and J. N. Tsit-siklis. </author> <title> A note on strategy elimination in bimatrix games. </title> <journal> Operations Research Letters, </journal> <volume> 7 </volume> <pages> 103-107, </pages> <year> 1988. </year>
Reference-contexts: The problem of finding an equilibrium is known neither to belong to P nor to be N P-hard. The complexity of various associated problems has been studied in <ref> [16, 20, 15] </ref>. Applied to extensive-form games, these normal-form algorithms are typically impractical for any but toy problems. <p> Unfortunately, this reduced normal form may still have exponential size. This is also observed in practice [28, 38]. A further reduction of bimatrix games, based on elimination of payoff-dominated rows or columns has been studied in <ref> [20, 15] </ref>. 4 Realization Weights Mixed strategies assign a probability to each of the exponentially many pure strategies. It turns out that some of this information is redundant.
Reference: [21] <author> D. Koller and N. Megiddo. </author> <title> The complexity of two-person zero-sum games in extensive form. </title> <journal> Games and Economic Behavior, </journal> <volume> 4 </volume> <pages> 528-552, </pages> <year> 1992. </year>
Reference-contexts: Wilson [38] presented an algorithm that directly solves two-person games with perfect recall, where the players do not forget facts they once knew. While Wilson conjectured that his algorithm is efficient, he was not able to prove this fact (see Section 4). Koller and Megiddo <ref> [21] </ref> presented the first polynomial time algorithm for solving zero-sum games with perfect recall. Their algorithm, however, is based on the ellipsoid algorithm for linear programming [17], and is therefore not very practical. <p> The basic idea is that the outcome of the game depends only on the distribution of probability weights that a randomized strategy induces on the leaves of the tree. We represent a strategy compactly in terms of 751 these realization weights, as introduced in <ref> [21] </ref>. These are defined directly in terms of the game tree, so their total size is linear rather than exponential in its size. As we show, this compact representation has a number of advantages. <p> It can also be used to provide a proof that Wilson's algorithm [38] is efficient. Also under the assumption of perfect recall, we can obtain further results. Then, the realization weights can be defined by a small system of linear constraints <ref> [21, 37] </ref>. In fact, the matrix representing this system is sparse and of linear size in the size of the game tree if stored sparsely. In [37], von Stengel noted that the same holds for the payoff matrices if the players are treated symmetrically. <p> In general, this problem is N P-hard [22]. However, if the players have perfect recall, we can characterize realization weights by a small set of linear constraints <ref> [21] </ref>. As in Section 3, these constraints can be used to find equilibria as solutions to an LP or LCP, but of small size.
Reference: [22] <author> D. Koller and N. Megiddo. </author> <title> Finding small sample spaces satisfying given constraints. </title> <note> SIAM Journal on Discrete Mathematics, 1993. To appear. </note>
Reference-contexts: We call such strategies 1 and ~ 1 equivalent . (This corresponds to a standard notion of equivalence of strategies [9].) A set of realization weights therefore describes an equivalence class of mixed strategies. Using techniques of <ref> [22] </ref>, we can prove that this equivalence class contains a member that can be represented compactly. More precisely, define the support of k to be the set of pure strategies to which it assigns positive probability. <p> The major problem in this context is in deciding whether a particular vector x = (x ) represents some mixed strategy 1 . In general, this problem is N P-hard <ref> [22] </ref>. However, if the players have perfect recall, we can characterize realization weights by a small set of linear constraints [21]. As in Section 3, these constraints can be used to find equilibria as solutions to an LP or LCP, but of small size.
Reference: [23] <author> H. W. Kuhn. </author> <title> Extensive games and the problem of information. </title> <editor> In H. W. Kuhn and A. W. Tucker, editors, </editor> <booktitle> Contributions to the Theory of Games II, </booktitle> <pages> pages 193-216. </pages> <publisher> Princeton University Press, </publisher> <year> 1953. </year>
Reference-contexts: Our algorithms are therefore exponentially better than the standard ones both in terms of time and in terms of space. 2 Extensive-Form Games This section recalls the standard definition of a game in extensive form <ref> [23] </ref>. The basic structure of the game is a finite directed tree whose nodes denote game states. A play of the game starts at the root, proceeds according to the players' actions, and ends at a leaf. <p> These use local randomization, by describing a probability distribution over the choices at each information set. In games with perfect recall, for every mixed strategy there is an equivalent behavior strategy <ref> [23] </ref>, so that we could use behavior strategies as a compact representation of a mixed strategy. However, behavior strategies are not suitable for the purposes of computing equilibria, since the payoff cannot be described as a linear function in the variables defining a behavior strategy. 756 of linear constraints.
Reference: [24] <author> Z. F. Lansdowne, G. B. Dantzig, R. P. Harvey, and R. D. McKnight. </author> <title> Development of an algorithm to solve multi-stage games. </title> <type> Technical report, </type> <institution> Control Analysis Corporation, </institution> <address> Palo Alto, CA, </address> <year> 1973. </year>
Reference-contexts: Even for game trees with a few dozen nodes, the resulting normal form is huge, so that it is infeasible to solve the resulting LP or LCP. This computational difficulty has often forced analysts to find solution techniques tailored to specific games <ref> [24] </ref> or even to abandon the game-theoretical approach altogether [28]. There has been some work on the problem of solving extensive form games directly. Thereby, backward induction is used to generate strategies for LP or LCP solvers dynamically from the game tree.
Reference: [25] <author> C. E. Lemke. </author> <title> Bimatrix equilibrium points and mathematical programming. </title> <journal> Management Science, </journal> <volume> 11 </volume> <pages> 681-689, </pages> <year> 1965. </year>
Reference-contexts: A Nash equilibrium of a general two-player game in normal form can be found by solving a linear complementarity problem (LCP). The associated LCP can be solved by Lemke's <ref> [25] </ref> or the related Lemke-Howson algorithm [26], whose running time is in the worst case exponential in the size of the normal form, but which seems to work better in practice. The problem of finding an equilibrium is known neither to belong to P nor to be N P-hard. <p> The system (10) and (11) is a linear complementarity problem (LCP) [8]. All solutions to this system can be found with a simple complete enumeration scheme whose running time is exponential in the size of the matrix. Lemke's algorithm <ref> [25] </ref> finds one solution to this system, i.e., one equilibrium, without the complete enumeration; it is known that certain equilibria are "elusive" to this method. <p> A closely related algorithm by Lemke and Howson [26] uses a slightly different LCP involving only A and B ; for a nice exposition see [35]. Termination of Lemke's algorithm for the LCP (10) is not proved in <ref> [25] </ref>. This is a special case of our Theorem 1.2 (see Section 5). While Lemke's algorithm typically avoids complete enumeration, its worst-case running time is still exponential. Deciding if a general LCP has a solution is N P-complete [6], but the present LCP always has one. <p> If the game has general payoffs, its equilibria are the solutions to the LCP (10). This shows Theorem 1.2, except for the claim that this LCP can be solved by Lemke's algorithm, which we will show in the remainder of this paper. Lemke's algorithm <ref> [25] </ref> is a pivoting scheme similar to the simplex algorithm for linear programming, but with a different "complementarity" rule for the entering and leaving variables, and no objective function; for expositions see [29, 8].
Reference: [26] <author> C. E. Lemke and Jr. J. T. Howson. </author> <title> Equilibrium points in bimatrix games. </title> <journal> Journal of the Society for Industrial and Applied Mathematics, </journal> <volume> 12 </volume> <pages> 413-423, </pages> <year> 1964. </year>
Reference-contexts: A Nash equilibrium of a general two-player game in normal form can be found by solving a linear complementarity problem (LCP). The associated LCP can be solved by Lemke's [25] or the related Lemke-Howson algorithm <ref> [26] </ref>, whose running time is in the worst case exponential in the size of the normal form, but which seems to work better in practice. The problem of finding an equilibrium is known neither to belong to P nor to be N P-hard. <p> Lemke's algorithm [25] finds one solution to this system, i.e., one equilibrium, without the complete enumeration; it is known that certain equilibria are "elusive" to this method. A closely related algorithm by Lemke and Howson <ref> [26] </ref> uses a slightly different LCP involving only A and B ; for a nice exposition see [35]. Termination of Lemke's algorithm for the LCP (10) is not proved in [25]. This is a special case of our Theorem 1.2 (see Section 5).
Reference: [27] <author> D. Lichtenstein and M. Sipser. </author> <title> Go is polynomial-space hard. </title> <journal> Journal of the ACM, </journal> <volume> 27 </volume> <pages> 393-401, </pages> <year> 1980. </year>
Reference-contexts: The increase in size when a tree is generated from rules may not even be bounded. Thus it is not surprising that games are typically hard to solve when represented using their rules. For example, it is PSPACE-hard to find optimal strategies for generalized Go <ref> [27] </ref> and a variety of other games [33, 11], and EXPTIME-complete to find optimal strategies for generalized Chess [12] or generalized Checkers [13]. A game in extensive form is represented as a tree (a formal definition is given in Section 2).
Reference: [28] <author> W. F. Lucas. </author> <title> An overview of the mathematical theory of games. </title> <booktitle> Management Science, 15, Appendix P:3-19, </booktitle> <year> 1972. </year>
Reference-contexts: This computational difficulty has often forced analysts to find solution techniques tailored to specific games [24] or even to abandon the game-theoretical approach altogether <ref> [28] </ref>. There has been some work on the problem of solving extensive form games directly. Thereby, backward induction is used to generate strategies for LP or LCP solvers dynamically from the game tree. <p> These are caused by certain information sets that are unreachable due to an earlier choice of the player. Unfortunately, this reduced normal form may still have exponential size. This is also observed in practice <ref> [28, 38] </ref>. A further reduction of bimatrix games, based on elimination of payoff-dominated rows or columns has been studied in [20, 15]. 4 Realization Weights Mixed strategies assign a probability to each of the exponentially many pure strategies. It turns out that some of this information is redundant.
Reference: [29] <author> K. G. Murty. </author> <title> Linear Complementarity, Linear and Nonlinear Programming. </title> <publisher> Heldermann Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: Lemke's algorithm [25] is a pivoting scheme similar to the simplex algorithm for linear programming, but with a different "complementarity" rule for the entering and leaving variables, and no objective function; for expositions see <ref> [29, 8] </ref>.
Reference: [30] <author> J. F. Nash. </author> <title> Non-cooperative games. </title> <journal> Annals of Mathematics, </journal> <volume> 54 </volume> <pages> 286-295, </pages> <year> 1951. </year>
Reference-contexts: The Nash equilibrium is the central solution concept of noncooperative game theory. It reflects the modern paradigm that all players act individually, and coop-erative acts (such as signing a contract) are explicitly modeled and must be rational for each player. As shown by Nash <ref> [30] </ref>, every game has an equilibrium, possibly requiring the use of randomized strategies. The algorithmic problem is to find one. In this paper, we investigate the problem of solving two-person games represented as game trees. <p> Nash <ref> [30] </ref> proved that every game has such an equilibrium. For zero-sum games, the equilibrium is a particularly strong solution concept. There, it is equivalent to a pair of max-min strategies, where each player optimizes his or her worst-case expected payoff.
Reference: [31] <author> J. H. Reif. </author> <title> The complexity of two-player games of incomplete information. </title> <journal> Journal of Computer and Systems Sciences, </journal> <volume> 29 </volume> <pages> 274-301, </pages> <year> 1984. </year>
Reference-contexts: The classic paper of Chandra, Kozen and Stockmeyer [5] characterized the class PSPACE in terms of two-player games. The later work on interactive proof systems [34, 7] is also best understood in those terms. Reif <ref> [31] </ref> extends the paradigm of interactive proofs to a more general class of games. Worst-case analysis of algorithms can also be viewed naturally as a game between the solver and an adversary.
Reference: [32] <author> J. S. Rosenschein. </author> <title> Consenting agents: Negotiation mechanisms for multi-agent systems. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 792-799, </pages> <year> 1993. </year>
Reference-contexts: A number of recent results in online computation are based on game-theoretic techniques (most obviously [3]). Game theory has been used in artificial intelligence to model interactions among intelligent agents, for example <ref> [32] </ref>. In the context of distributed systems, such issues as collective coin flipping [4] and privacy and security [14] have been analyzed using games. Other interactions relevant to computer science, such as network routing or load-sharing in distributed systems, also seem to fit naturally in a game-theoretic framework.
Reference: [33] <author> T. J. Schaefer. </author> <title> On the complexity of some two-person perfect-information games. </title> <journal> Journal of Computer and Systems Sciences, </journal> <volume> 16 </volume> <pages> 185-225, </pages> <year> 1978. </year>
Reference-contexts: Thus it is not surprising that games are typically hard to solve when represented using their rules. For example, it is PSPACE-hard to find optimal strategies for generalized Go [27] and a variety of other games <ref> [33, 11] </ref>, and EXPTIME-complete to find optimal strategies for generalized Chess [12] or generalized Checkers [13]. A game in extensive form is represented as a tree (a formal definition is given in Section 2).
Reference: [34] <author> A. Shamir. </author> <title> IP = PSPACE. </title> <journal> Journal of the ACM, </journal> <volume> 39 </volume> <pages> 869-877, </pages> <year> 1992. </year>
Reference-contexts: In computer science, the idea of modeling interactive situations as games is becoming more common. The classic paper of Chandra, Kozen and Stockmeyer [5] characterized the class PSPACE in terms of two-player games. The later work on interactive proof systems <ref> [34, 7] </ref> is also best understood in those terms. Reif [31] extends the paradigm of interactive proofs to a more general class of games. Worst-case analysis of algorithms can also be viewed naturally as a game between the solver and an adversary.
Reference: [35] <author> L. S. Shapley. </author> <title> A note on the Lemke-Howson algorithm. </title> <journal> Mathematical Programming Study, </journal> <volume> 1 </volume> <pages> 175-189, </pages> <year> 1974. </year>
Reference-contexts: A closely related algorithm by Lemke and Howson [26] uses a slightly different LCP involving only A and B ; for a nice exposition see <ref> [35] </ref>. Termination of Lemke's algorithm for the LCP (10) is not proved in [25]. This is a special case of our Theorem 1.2 (see Section 5). While Lemke's algorithm typically avoids complete enumeration, its worst-case running time is still exponential.
Reference: [36] <author> J. von Neumann and O. Morgenstern. </author> <title> The Theory of Games and Economic Behavior. </title> <publisher> Princeton University Press, </publisher> <address> 2nd edition, </address> <year> 1947. </year>
Reference-contexts: Worst-case analysis of algorithms can also be viewed naturally as a game between the solver and an adversary. For example, Yao's technique of proving lower bounds for randomized algorithms [39] follows directly from the classical minimax theorem <ref> [36] </ref> from game theory. A number of recent results in online computation are based on game-theoretic techniques (most obviously [3]). Game theory has been used in artificial intelligence to model interactions among intelligent agents, for example [32].
Reference: [37] <author> B. von Stengel. </author> <title> Lp representation and efficient computation of behavior strategies. </title> <type> Technical Report S-9301, </type> <institution> University of the Federal Armed Forces at Munich, </institution> <year> 1993. </year>
Reference-contexts: It can also be used to provide a proof that Wilson's algorithm [38] is efficient. Also under the assumption of perfect recall, we can obtain further results. Then, the realization weights can be defined by a small system of linear constraints <ref> [21, 37] </ref>. In fact, the matrix representing this system is sparse and of linear size in the size of the game tree if stored sparsely. In [37], von Stengel noted that the same holds for the payoff matrices if the players are treated symmetrically. <p> Then, the realization weights can be defined by a small system of linear constraints [21, 37]. In fact, the matrix representing this system is sparse and of linear size in the size of the game tree if stored sparsely. In <ref> [37] </ref>, von Stengel noted that the same holds for the payoff matrices if the players are treated symmetrically. Using realization weights and LP duality, equilibrium strategies can then be found by solving a corresponding LP or LCP. <p> As in Section 3, these constraints can be used to find equilibria as solutions to an LP or LCP, but of small size. Essentially, this corresponds to a strategic description of the game (called sequence form in <ref> [37] </ref>) where sequences replace pure strategies. 1 For the remainder of this section, assume that both players have perfect recall.
Reference: [38] <author> R. Wilson. </author> <title> Computing equilibria of two-person games from the extensive form. </title> <journal> Management Science, </journal> <volume> 18 </volume> <pages> 448-460, </pages> <year> 1972. </year>
Reference-contexts: There has been some work on the problem of solving extensive form games directly. Thereby, backward induction is used to generate strategies for LP or LCP solvers dynamically from the game tree. Wilson <ref> [38] </ref> presented an algorithm that directly solves two-person games with perfect recall, where the players do not forget facts they once knew. While Wilson conjectured that his algorithm is efficient, he was not able to prove this fact (see Section 4). <p> As we show, this compact representation has a number of advantages. It can be used to construct a simple exponential-time algorithm for solving arbitrary two-person games (even with imperfect recall). It can also be used to provide a proof that Wilson's algorithm <ref> [38] </ref> is efficient. Also under the assumption of perfect recall, we can obtain further results. Then, the realization weights can be defined by a small system of linear constraints [21, 37]. <p> These are caused by certain information sets that are unreachable due to an earlier choice of the player. Unfortunately, this reduced normal form may still have exponential size. This is also observed in practice <ref> [28, 38] </ref>. A further reduction of bimatrix games, based on elimination of payoff-dominated rows or columns has been studied in [20, 15]. 4 Realization Weights Mixed strategies assign a probability to each of the exponentially many pure strategies. It turns out that some of this information is redundant. <p> Intuitively, if the player makes different choices on the paths to a and b, and does not forget, then he or she must be able to distinguish between a and b, so these nodes belong to different information sets. As we mentioned in the introduction, Wilson <ref> [38] </ref> presented an algorithm for solving general two-player games with perfect recall. We can also use this idea to provide a formal analysis for this algorithm. Wil-son's algorithm does not use the entire normal form.
Reference: [39] <author> A. C. Yao. </author> <title> Probabilistic computation: Towards a unified measure of complexity. </title> <booktitle> In Proceedings of the 18th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 222-227, </pages> <year> 1977. </year> <month> 759 </month>
Reference-contexts: Reif [31] extends the paradigm of interactive proofs to a more general class of games. Worst-case analysis of algorithms can also be viewed naturally as a game between the solver and an adversary. For example, Yao's technique of proving lower bounds for randomized algorithms <ref> [39] </ref> follows directly from the classical minimax theorem [36] from game theory. A number of recent results in online computation are based on game-theoretic techniques (most obviously [3]). Game theory has been used in artificial intelligence to model interactions among intelligent agents, for example [32].
Reference: [40] <author> E. Zermelo. </author> <title> Uber eine Anwendung der Mengen--lehre auf die Theorie des Schachspiels. </title> <editor> In E. W. Hobson and A. E. H. Love, editors, </editor> <booktitle> Proceedings of the Fifth International Congress of Mathematicians II, </booktitle> <pages> pages 501-504. </pages> <publisher> Cambridge University Press, </publisher> <year> 1913. </year> <month> 760 </month>
Reference-contexts: For games with perfect information, this idea is precisely the well-known max-min algorithm, due to Zermelo <ref> [40] </ref>. (A game has perfect information if at each point in the game all players know the entire history of the game up to that point.
References-found: 40

