URL: http://www.icsi.berkeley.edu/~nikki/papers/ICSLP98.ps
Refering-URL: http://www.icsi.berkeley.edu/~nikki/papers/
Root-URL: http://www.icsi.berkeley.edu
Email: fnikki, morgang@icsi.berkeley.edu  
Title: COMBINING CONNECTIONIST MULTI-BAND AND FULL-BAND PROBABILITY STREAMS FOR SPEECH RECOGNITION OF NATURAL NUMBERS  
Author: Nikki Mirghafori and Nelson Morgan 
Address: Berkeley  
Affiliation: International Computer Science Institute University of California at  
Abstract: In this work we show that multi-band ASR could be used to improve the speech recognition accuracy of natural numbers for clean speech when the multi-band (MB) information stream is used in addition to the full-band (FB) one. We also observe that a similar combination method significantly reduces the error rate on reverberant speech. Finally, we analyze the error patterns of the full-band and multi-band paradigms to understand why the combination of the two streams is effective. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. B. Allen. </author> <title> How do humans process and recognize speech? IEEE Trans. </title> <booktitle> on Speech and Audio Proc., </booktitle> <address> 2(4):567577, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: 1. INTRODUCTION There has been much interest generated in the speech recognition community on multi-band automatic speech recognition (ASR) [2, 11, 12, 8] since Jont Allen's cogent retelling of Har-vey Fletcher's work on the articulation index <ref> [4, 1] </ref>.
Reference: 2. <author> H. Bourlard and S. Dupont. </author> <title> Subband-based speech recognition. </title> <booktitle> In ICASSP, </booktitle> <volume> volume 2, </volume> <pages> pages 125128, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: 1. INTRODUCTION There has been much interest generated in the speech recognition community on multi-band automatic speech recognition (ASR) <ref> [2, 11, 12, 8] </ref> since Jont Allen's cogent retelling of Har-vey Fletcher's work on the articulation index [4, 1]. <p> It has been shown that multi-band ASR performance is similar to that of the full-band paradigm on continuous speech, and significantly better in many noise conditions (especially for narrow band noise), when the multi-band streams are combined on a frame level <ref> [11, 2] </ref>. It is less clear if the multi-band paradigm can be used to significantly improve recognition accuracy for clean speech. Furthermore, if we can indeed confirm such improvements, we would like to understand the reason for this effect.
Reference: 3. <author> H. Bourlard and N. Morgan. </author> <title> Connectionist Speech Recognition A Hybrid Approach. </title> <publisher> Kluwer Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: The database is phonetically hand-transcribed. For the purposes of this study, we use approximately two hours of the database for training and cross validation, and forty minutes as a test set. Our baseline full-band system is an HMM/MLP based <ref> [3] </ref> system. We train the MLP phonetic probability estimator on a nine-frame window of 8th-order RASTA-PLP cepstra [5], energy, and delta-RASTA-PLP cepstral features over a 25 ms window, stepped every 10 ms.
Reference: 4. <author> H. Fletcher. </author> <title> Speech and Hearing in Communication. </title> <publisher> Krieger, </publisher> <address> New York, </address> <year> 1953. </year>
Reference-contexts: 1. INTRODUCTION There has been much interest generated in the speech recognition community on multi-band automatic speech recognition (ASR) [2, 11, 12, 8] since Jont Allen's cogent retelling of Har-vey Fletcher's work on the articulation index <ref> [4, 1] </ref>.
Reference: 5. <author> H. Hermansky and N. Morgan. </author> <title> RASTA processing of speech. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> 2(4):578589, </volume> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Our baseline full-band system is an HMM/MLP based [3] system. We train the MLP phonetic probability estimator on a nine-frame window of 8th-order RASTA-PLP cepstra <ref> [5] </ref>, energy, and delta-RASTA-PLP cepstral features over a 25 ms window, stepped every 10 ms.
Reference: 6. <author> R. A. Jacobs. </author> <title> Methods for combining experts' probability assessments. </title> <booktitle> Neural Computation, </booktitle> <address> 7(5):867888, </address> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: One explanation, inspired by the expert-merging community, is that the error rate decreases when two different experts with different characteristics (preferably orthogonal) are combined <ref> [6] </ref>. We want to understand how our full-band and multi-band recog-nizers are different, and how this difference affects performance [13].
Reference: 7. <author> B. E. D. Kingsbury. </author> <title> Perceptually-inspired signal processing strategies for robust speech recognition in reverberant environments. </title> <type> PhD thesis, </type> <institution> University of Califor-nia, Berkeley, California, </institution> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: The 3 For this size test set, an absolute difference of more than 1.1% is considered statistically significant (using z-scores on binomial distributions). 4 Although this ratio might suggest a seriously degraded signal, recent listening tests showed essentially no reduction in intelligibility with respect to tests using the clean signal <ref> [7] </ref>. WER for each subband, the multi-band, and the merged systems are reported in Table 2. The WER for the full-band system is 32.2%, which is significantly better than each of the multi-band systems (38.2% 42.7%).
Reference: 8. <author> N. Mirghafori and N. Morgan. </author> <title> Transmissions and transitions: A study of two common assumptions in multi-band ASR. </title> <booktitle> In ICASSP, </booktitle> <volume> volume 2, </volume> <pages> pages 713716, </pages> <address> Seat-tle, WA, </address> <month> May </month> <year> 1998. </year>
Reference-contexts: 1. INTRODUCTION There has been much interest generated in the speech recognition community on multi-band automatic speech recognition (ASR) <ref> [2, 11, 12, 8] </ref> since Jont Allen's cogent retelling of Har-vey Fletcher's work on the articulation index [4, 1].
Reference: 9. <author> J. D. O'Connor, L. J. Gerstman, A. M. Liberman, P. C. Delattre, and F. Cooper. </author> <title> Acoustic cues for the perception of initial /w,y,r,l/ in english. Word, </title> <address> 13:2443, </address> <year> 1957. </year>
Reference-contexts: The FB system, on the other hand, is significantly more accurate in classifying /ao/, /n/, /iy/, /ah/, /f/, and /s/. Research on the acoustic cues for the perception of liquids and glides has shown that the duration of the formant transitions provides the essential cue for these speech sounds <ref> [9] </ref>. For discrimination of vowels, however, simultaneous identification of the location of the first two formants is necessary.
Reference: 10. <author> T. Robinson, L. Almeida, J. Boite, H. Bourlard, F. Fall-side, M. Hochberg, D. Kershaw, P. Kohn, Y. Konig, N. Morgan, J. Neto, S. Renals, M. Saerens, and C. Woot-ers. </author> <title> A neural network based, speaker independent, large vocabulary, continuous speech recognition system: The WERNICKE project. </title> <booktitle> In EUROSPEECH, pages 1941 1944, </booktitle> <address> Berlin, Germany, </address> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: The system is trained on hand-transcribed phone labels (without embedded realignment). We use a multiple pronunciation lexicon (derived from the hand transcriptions), a bigram language model, and a synchronous-time decoder called Y0 (described in <ref> [10] </ref>), which uses a single density per phone with repeated states for a simple durational model. The word error rate (WER) of this base 1 Note that some of the 56 phones do not occur in the NUMBERS database and have zero priors.
Reference: 11. <author> S. Tibrewala and H. Hermansky. </author> <title> Sub-band based recognition of noisy speech. </title> <booktitle> In ICASSP, </booktitle> <volume> volume 2, </volume> <pages> pages 12551258, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: 1. INTRODUCTION There has been much interest generated in the speech recognition community on multi-band automatic speech recognition (ASR) <ref> [2, 11, 12, 8] </ref> since Jont Allen's cogent retelling of Har-vey Fletcher's work on the articulation index [4, 1]. <p> It has been shown that multi-band ASR performance is similar to that of the full-band paradigm on continuous speech, and significantly better in many noise conditions (especially for narrow band noise), when the multi-band streams are combined on a frame level <ref> [11, 2] </ref>. It is less clear if the multi-band paradigm can be used to significantly improve recognition accuracy for clean speech. Furthermore, if we can indeed confirm such improvements, we would like to understand the reason for this effect.
Reference: 12. <author> M. J. Tomlinson, M. J. Russell, R. K. Moore, A. P. Buckland, and M. A. Fawley. </author> <title> Modelling asynchrony in speech using elementary single-signal decomposition. </title> <booktitle> In ICASSP, </booktitle> <volume> volume 2, </volume> <pages> pages 12471250, </pages> <month> Apr. </month> <year> 1997. </year>
Reference-contexts: 1. INTRODUCTION There has been much interest generated in the speech recognition community on multi-band automatic speech recognition (ASR) <ref> [2, 11, 12, 8] </ref> since Jont Allen's cogent retelling of Har-vey Fletcher's work on the articulation index [4, 1].
Reference: 13. <author> S.-L. Wu, B. E. D. Kingsbury, N. Morgan, and S. Green-berg. </author> <title> Incorporating information from syllable-length time scales into automatic speech recognition. </title> <booktitle> In ICASSP, </booktitle> <pages> pages 721724, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1998. </year>
Reference-contexts: One explanation, inspired by the expert-merging community, is that the error rate decreases when two different experts with different characteristics (preferably orthogonal) are combined [6]. We want to understand how our full-band and multi-band recog-nizers are different, and how this difference affects performance <ref> [13] </ref>. If possible, we would also like to associate these differences with phonetic content: are there particular phones or features that one system is better at discriminating than the other? t s eh sil ... s 258 8495 110 1159 ... sil 436 2733 68 40237 ...
References-found: 13

