URL: ftp://cse.ogi.edu/pub/tech-reports/1994/94-012.ps.gz
Refering-URL: ftp://cse.ogi.edu/pub/tech-reports/README.html
Root-URL: http://www.cse.ogi.edu
Email: walpole-@cse.ogi.edu  
Title: Adaptive Execution of Data Parallel Computations on Networks of Heterogeneous Workstations  
Author: Robert Prouty, Steve Otto, Jonathan Walpole -prouty, otto, 
Date: March 21, 1994  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Pubnum: Technical report number: CSE-94-012  
Abstract: Parallel environments consisting of a network of heterogeneous workstations introduce an inherently dynamic environment that differs from multicomputers. Workstations are usually considered shared resources while multicomputers provide dedicated processing power. The number of workstations available for use is continually changing; the parallel machine presented by the network is in effect continually reconfiguring itself. Application programs must effectively adapt to the changing number of processing nodes while maintaining computational efficiency. This paper examines methods for adapting to this dynamic environment within the framework of explicit message passing under the data parallel programming model. We present four requirements which we feel a method must satisfy. Several potential methods are examined within the framework and evaluated according to how well they address the defined requirements. An application-level technique called Application Data Movement (ADM) is described. Although this technique puts much of the responsibility of adaptation on the application programmer, it has the advantage of running on heterogeneous workstations. Related work, such as Dataparallel C and Piranha, is also examined and compared to ADM. The application of the ADM methodology to a real application, a neural-network classifier based on conjugate-gradient optimization, is outlined and discussed. Preliminary results are presented and analyzed. The computation has been shown to achieve in excess of 70 MFLOPS under quiet conditions on a network of nine heterogeneous machines, two HP 9000/720s, two DEC Alphas, and five Sun SPARCstation 10s, while maintaining an efficiency of nearly 80%. 
Abstract-found: 1
Intro-found: 1
Reference: [BC89] <author> Etienne Barnard and Ronald Cole, </author> <title> A Neural-net training program based on conjugate-gradient optimization, </title> <type> Technical Report CSE-89-014, </type> <institution> Oregon Graduate Institute, </institution> <year> 1989 </year>
Reference-contexts: The f irst is that ADM allows truly heterogeneous migration and work distribution. The second is that the precision of work redistribution is limited only by the application. 4.3 An Example Computation The ADM method has been applied to Opt, a neural-network classifier based on conjugate-gradient optimization <ref> [BC89] </ref>. Opt is generally employed as a speech classifier, and as such utilizes enormous (500KB to 400MB) training sets as input. A training set consists of a series of f loating point vectors. These vectors, called exemplars, represent digitized speech sounds.
Reference: [BLL] <author> Allan Bricker, Michael Litzkow, and Miron Liuney. </author> <type> Condor Technical summary. </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, WI. </institution>
Reference: [Bro92] <author> Eugene D. Brooks III. </author> <title> Massively Parallel Computing. </title> <booktitle> The 1992 MPCI Yearly Report: Harnessing the Killer Micros, Massively Parallel Computing Initiative, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: 1 Introduction High performance workstations connected by local area networks are becoming common in academic and industrial research environments. The aggregate computational power represented by these workstation networks often rivals and in some cases exceeds the power of traditional supercomputers <ref> [Bro92] </ref>. Workstation performance is rapidly increasing, and network capacity (speed and bandwidth) is also expected to increase as new technologies become widespread. Because these workstations sit idle much of the time, they are an attractive source of effectively free computational power.
Reference: [CG+] <author> N. Carriero, D. Gelernter, D. Kaminsky, J. Westbrook. </author> <title> Adaptive Parallelism with Piranha. </title>
Reference: [CG89] <author> N. Carriero and D. Gelernter, </author> <title> Linda in Context. </title> <journal> Communications of the ACM, </journal> <volume> 32(4), </volume> <month> April </month> <year> 1989. </year>
Reference: [DS92] <author> A. Deshpande and M. Schultz. </author> <title> Efficient Parallel Programming with Linda. </title> <booktitle> Supercomputing 92, </booktitle> <year> 1992. </year>
Reference: [GB+93] <author> A. Giest, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, V. Sunderam. </author> <title> PVM 3.0 Users Guides and Reference Manual. </title> <month> February </month> <year> 1993. </year>
Reference-contexts: The most serious disadvantage is they complicate the process of writing the application. 5.2 Application Level Approaches The worker-coordinator programming model is a popular application level method for solving the traditional load balancing problem. The worker-coordinator model (WC) is conceptually simple, and is mentioned in <ref> [GB+93] </ref> as the pool of tasks paradigm and covered in several variations in [GKR91] under source initiated load balancing algorithms. WC is often programmed in a master slave style, but not all master slave programs are WC.
Reference: [GK92] <author> D. Gelernter and D. Kaminsky, </author> <title> Supercomputing out of Recycled Garbage: Preliminary Experience with Piranha, </title> <booktitle> Sixth ACM International Conference on Supercomputing, </booktitle> <address> Washington, D.C., </address> <month> July 19-23 </month> <year> 1992. </year>
Reference: [GKR91] <author> A. Y. Grama, V. Kumar, and V. N. Rao. </author> <title> Experimental Evaluation of Load Balancing Techniques for the Hypercube. </title> <booktitle> Parallel Computing 91, </booktitle> <pages> pages 497513, </pages> <publisher> Elsevier Science Publishers B. V., </publisher> <year> 1992. </year> <month> 21 </month>
Reference-contexts: The worker-coordinator model (WC) is conceptually simple, and is mentioned in [GB+93] as the pool of tasks paradigm and covered in several variations in <ref> [GKR91] </ref> under source initiated load balancing algorithms. WC is often programmed in a master slave style, but not all master slave programs are WC. The WC model implies very specif ic behavior from the master and the slaves. The central premise is that processors request work when they become idle.
Reference: [GS92] <author> G. A. Geist and V. S. Sunderam. </author> <title> Network-Based Concurrent Computing on the PVM System. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 4(4):293311, </volume> <month> June </month> <year> 1992. </year>
Reference: [Kon93] <author> R. Konuru, J. Walpole, S. Otto. </author> <title> A User-Level Process Package for Concurrent Computing. </title> <type> Technical report in progress. </type> <institution> Oregon Graduate Institute, </institution> <year> 1993. </year>
Reference: [LL] <author> Mike Litzkow and Miron Livny. </author> <title> Experience with the Condor distributed batch system. </title> <institution> Computer Sciences Department, University of Wisconsin, Madison, WI. </institution>
Reference: [LLM88] <author> M. Litzkow, M. Livny, and M. </author> <title> Mutka. CondorA Hunter of Idle Workstations. </title> <booktitle> In Proceedings of the 8th International Conference on Distributed Computer Systems, </booktitle> <pages> pages 104-111, </pages> <address> San Jose, CA, </address> <month> June </month> <year> 1988. </year>
Reference: [NQ93] <author> Nenad Nedeljkovic and Michael J. Quinn, </author> <title> Data-Parallel Programming on a Network of Heterogeneous WorkstationsConcurrency: </title> <journal> Practice and Experience, </journal> <volume> 5(4) </volume> <pages> 257-268, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Therefore, the number of workstations available for use is continually changing. Worknets thus introduce an inherently dynamic environment that differs from multicomputers. A parallel application running on a worknet must adapt to the dynamic nature of the environment. This adaptation is the focus of this paper. Dataparallel C <ref> [NQ93] </ref> and Piranha [GK92][CG+] are two systems designed to adaptively utilize worknets. Dataparallel C was developed by Michael Quinn at Oregon State University as a SIMD programming language to run dataparallel programs on worknets and perform automatic load balancing.
Reference: [Rev92] <author> Louis S. Revor. </author> <title> DQS Users guide. </title> <institution> Computing and Telecommunications Division, Argonne National Laboratory, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: What is needed is a higher entity which can control all ADM applications on a worknet; what is needed is a global scheduler. The DSRG is currently working on defining an interface between message passing systems such as PVM and the Distributed Queuing System <ref> [Rev92] </ref> (DQS). The need for a global scheduler can be clarified by an example. One of the basic assumptions underlying ADM is that all other work on the worknet is local work on the nodes.
References-found: 15

