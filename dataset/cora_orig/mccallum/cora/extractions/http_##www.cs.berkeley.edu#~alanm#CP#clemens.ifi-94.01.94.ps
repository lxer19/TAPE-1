URL: http://www.cs.berkeley.edu/~alanm/CP/clemens.ifi-94.01.94.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Email: e-mail: cap@ifi.unizh.ch,  
Phone: Tel. +41-1-257 43 26  
Title: Massive Parallelism with Workstation Clusters Challenge or Nonsense?  
Author: Clemens H. CAP 
Date: December 14, 1993  
Address: Winterthurerstrasse 190 CH-8057 Zurich, Switzerland  
Affiliation: Department of Computer Science University of Zurich  
Pubnum: Technical Report IFI-TR 94.01  
Abstract: Workstation cluster computing recently has become an important and successful technique. The communication bottleneck limits this approach to small and medium sized configurations of up to 30 workstations for most applications. This paper demonstrates that for certain algorithms massively parallel cluster computing using thousands of workstations in the Internet is feasible. It describes structures for the coordination of a large number of geographically dispersed processes. The paper introduces Lola, a library supporting massively parallel computing in wide area networks, and provides an application example.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Ahuja, N. Carriero, D. Gelernter, Linda and Friends. </author> <booktitle> IEEE Computer 19(8), </booktitle> <year> 1986, </year> <pages> 26-34. </pages>
Reference: [2] <author> M. Asawa and S. Misra, Robinhood: </author> <title> Resource Sharing by Time Stealing Between DOS PCs on a LAN, </title> <type> Technical report 91/2, </type> <institution> James Cook University North Queensland, </institution> <month> october </month> <year> 1991. </year>
Reference: [3] <author> J. Baud et al., </author> <title> SHIFT: The Scalable Heterogeneous Integrated Facility for HEP Computing. </title> <editor> In Y. Watase (ed.), </editor> <title> Computing in High Energy Physics 91 , Universal Academy Press, </title> <address> Tokyo. </address>
Reference: [4] <author> R. D. Bjornson, </author> <title> Linda on Distributed Memory Multiprocessors. </title> <type> PhD Thesis and technical report YALEU/DCS/RR-931, </type> <institution> University of Yale, </institution> <month> november </month> <year> 1992. </year>
Reference-contexts: Furthermore the high number of collisions in a heavily loaded Ethernet has an adverse effect on speedup. Similar observations can be made for many applications due to their small grain size and locality <ref> [4] </ref>, [9]. There can be at most 255 workstations in a local area network, and on the average there are only some 20 machines in a LAN. Therefore massive parallelism with workstation clusters will have to use several LANs connected by metropolitan and wide area network technology.
Reference: [5] <author> R. Bjornson, N. Carriero, D. Gelernter, T. Mattson, D. Kaminsky and A. Sherman. </author> <title> Experience with Linda. </title> <type> Technical report 866, </type> <institution> department of computer science, Yale University, </institution> <month> august </month> <year> 1991. </year>
Reference: [6] <author> R. Butler, E. Lusk, </author> <title> User's Guide to the p4 Parallel Programming System. </title> <type> Technical report, </type> <institution> Argonne National Laboratory, </institution> <month> august </month> <year> 1992. </year>
Reference-contexts: The worker processes within a LAN may use additional means of communication to exchange data among them. Since there are several cluster software systems like Parform [10], PVM [15], P4 <ref> [6] </ref> and many others [9] which support this kind of communication we will not further elaborate upon this.
Reference: [7] <author> J. Corbin, </author> <title> The Art of Distributed Applications. Sun Technical Reference Library, </title> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference: [8] <author> C. H. </author> <title> Cap, Massively Parallel Computing in Wide Area Networks. </title> <type> Technical report, </type> <institution> department of computer science, University of Zurich, </institution> <year> 1993. </year>
Reference-contexts: disadvantageous in production runs. 5 Implementation and Practical Experiences To test our approach, above routines were implemented in C for 23 different workstation/operating system combinations and installed on over 800 workstations from up to 31 local area networks of the Internet, situated in all five continents of the globe [12], <ref> [8] </ref>. The system is nicknamed Lola, which is an abbreviation for loosely coupled large area and was used to develop a prototype for the comparison of genetic sequences. Portability for the various systems was astonishingly easy to achieve by a small number of preprocessor directives. <p> Only the new, given gene and the obtained scores and gene identifiers had to be communicated, so there was no communication bottleneck. The table below shows the speedup obtained in different experiments [12], <ref> [8] </ref>. Number of Parallel Runtime on one Runtime on one Speedup vs. Speedup vs.
Reference: [9] <editor> C. H. Cap, Architekturelle Entscheidungen zur Unterstutzung parallelen Rechnens in Workstation Clustern und deren Realisierung in existenten Produkten. </editor> <booktitle> Proceedings 2. ITG/GI Workshop Workstations, </booktitle> <address> Hagen 1993, </address> <publisher> VDE Verlag. </publisher>
Reference-contexts: Furthermore the high number of collisions in a heavily loaded Ethernet has an adverse effect on speedup. Similar observations can be made for many applications due to their small grain size and locality [4], <ref> [9] </ref>. There can be at most 255 workstations in a local area network, and on the average there are only some 20 machines in a LAN. Therefore massive parallelism with workstation clusters will have to use several LANs connected by metropolitan and wide area network technology. <p> Consequence: Massive parallelism using workstations in a wide area network is possible, but only for special applications and algorithms. 2.2 Do We Need Special Control Mechanisms in a WAN? There presently exist many software packages which assist the programmer in developing parallel programs for workstation clusters <ref> [9] </ref>, [32]. In principle these systems could also control parallelism within wide area networks, because they are independent of the communication medium as long as a suitable interfaces, like the Berkeley socket abstraction, are available. <p> The worker processes within a LAN may use additional means of communication to exchange data among them. Since there are several cluster software systems like Parform [10], PVM [15], P4 [6] and many others <ref> [9] </ref> which support this kind of communication we will not further elaborate upon this. Communication on the inter-LAN layer can go upstream (up the tree towards the root) or downstream (down the tree towards the leafs) and is under the control of the wide area cluster software.
Reference: [10] <author> C. H. Cap and V. Strumpen, </author> <title> Efficient Parallel Computing in Distributed Workstation Environments. </title> <booktitle> Parallel Computing, </booktitle> <month> 19(11), </month> <year> 1993. </year> <month> 15 </month>
Reference-contexts: On the other hand, <ref> [10] </ref> shows, that communication represents a severe bottleneck of a hypercomputer. One might also expect a limit on the number of workstations, since usually a larger number of processors also means an increased communication load. <p> Massive Parallelism in a WAN Possible at All? Computations simulating two-dimensional heat conduction using a cluster of 40 Sparc workstations produced an average communication bandwidth of 5.288 MBit/sec or 52.88 % of the physical bandwidth of an Ethernet, under the assumption that communication takes place during the entire run [11], <ref> [10] </ref>. The peak communication load therefore was still higher. An Ethernet utilization of more than 20 % is already considered a high load. <p> The worker processes within a LAN may use additional means of communication to exchange data among them. Since there are several cluster software systems like Parform <ref> [10] </ref>, PVM [15], P4 [6] and many others [9] which support this kind of communication we will not further elaborate upon this.
Reference: [11] <author> C. H. Cap and V. Strumpen, </author> <title> The Parform A High Performance Parallel Platform for Efficient Computation in a Distributed Workstation Environment. </title> <type> Technical report IFI-TR 92.07 Technical report, </type> <institution> department of computer science, University of Zurich, </institution> <year> 1992. </year>
Reference-contexts: Is Massive Parallelism in a WAN Possible at All? Computations simulating two-dimensional heat conduction using a cluster of 40 Sparc workstations produced an average communication bandwidth of 5.288 MBit/sec or 52.88 % of the physical bandwidth of an Ethernet, under the assumption that communication takes place during the entire run <ref> [11] </ref>, [10]. The peak communication load therefore was still higher. An Ethernet utilization of more than 20 % is already considered a high load.
Reference: [12] <author> C. H. Cap and V. Strumpen, </author> <title> Massively Parallel Computing in the Internet Entry to the SuPar-Cup'93. </title> <institution> Department of computer science, University of Zurich, </institution> <year> 1993. </year> <note> This entry won the first prize of the SuParCup93. </note>
Reference-contexts: is disadvantageous in production runs. 5 Implementation and Practical Experiences To test our approach, above routines were implemented in C for 23 different workstation/operating system combinations and installed on over 800 workstations from up to 31 local area networks of the Internet, situated in all five continents of the globe <ref> [12] </ref>, [8]. The system is nicknamed Lola, which is an abbreviation for loosely coupled large area and was used to develop a prototype for the comparison of genetic sequences. Portability for the various systems was astonishingly easy to achieve by a small number of preprocessor directives. <p> Only the new, given gene and the obtained scores and gene identifiers had to be communicated, so there was no communication bottleneck. The table below shows the speedup obtained in different experiments <ref> [12] </ref>, [8]. Number of Parallel Runtime on one Runtime on one Speedup vs. Speedup vs.
Reference: [13] <author> J. J. Dongarra, R. Hempel, A. J. G. Hey and D. W. Walker, </author> <title> A Proposal for a User-Level, Message-Passing Interface in a Distributed Memory Environment. </title> <type> Technical report CS-93-186, </type> <institution> University of Tennessee, Knoxville, </institution> <month> january </month> <year> 1993. </year>
Reference: [14] <author> G. Geist, M. Heath, B. Peyton and P. Worley. </author> <title> PICL a Portable Instrumented Communication Library. </title> <type> Technical report ORNL-TM-11130, </type> <institution> Oak Ridge National Laboratory, </institution> <month> Juli </month> <year> 1990. </year> <month> netlib@ornl.gov. </month>
Reference: [15] <author> G. Geist and V. Sunderam. </author> <title> The PVM system: Supercomputer Level Concurrent Computation on a Heterogeneous Network of Workstations. </title> <booktitle> Proceedings of the Sixth Distributed Memory Computing Conference, </booktitle> <publisher> IEEE Press, 1991,258-261. </publisher>
Reference-contexts: The worker processes within a LAN may use additional means of communication to exchange data among them. Since there are several cluster software systems like Parform [10], PVM <ref> [15] </ref>, P4 [6] and many others [9] which support this kind of communication we will not further elaborate upon this.
Reference: [16] <author> M. Griebel, W. Huber, T. Stortkuhl and C. Zenger, </author> <title> On the Parallel Solution of 3D PDEs on a Network of Workstations and on Vector Computers. </title>
Reference-contexts: 1 Introduction Recent research activities have shown, that workstation cluster computing or hypercom-puting provides a fair amount of computing power at a reasonable price. <ref> [16] </ref> reports a performance of more than 1 Gflops in a cluster of 110 workstations and [23] demonstrates, that for certain applications cluster solutions provide a price performance ratio which is two orders of magnitude better than for classical supercomputers. [32] estimates that fl Research partially supported by Firma Siemens AG <p> In their experiments a smaller number of supercomputers was coupled for optimizing the structure of large molecules with a modified Hartree-Fock method [21]. Massively parallel approaches were studied with 110 workstations at the Technical University of Munich <ref> [16] </ref>. The employed algorithm was optimized to reduce the necessary communication and a special physical layout of the LAN was used. The 1992 winners of the Gordon Bell prize [23] made experiments with up to 192 workstations using PVM.
Reference: [17] <author> R. Hempel, </author> <title> The ANL/GMD Macros (PARMACS) in FORTRAN for Portable Parallel Programming Using the Message Passing Programming Model, User's Guide and Reference Manual. </title> <institution> Gesellschaft fur Mathematik und Datenverarbeitung mbH (GMD), </institution> <month> november </month> <year> 1991. </year>
Reference: [18] <author> HPCwire, </author> <title> Comparing the Efficiency of molecular biology sequence-analysis computations. </title> <journal> Electronic Newsletter HPCwire, </journal> <volume> topic 815, </volume> <month> March 1, </month> <year> 1993. </year> <title> Further source: </title> <booktitle> SDSC's Computational Science Advances. </booktitle>
Reference-contexts: For example the BLASTPM code from molecular biology required 1820 sec. computing time on a Sun 4 workstation and 1522 sec. on a CRAY Y-MP <ref> [18] </ref>. Similar experiences are reported by [23]. Many problems from mathematical physics are concerned with a local physical law, which is given by a differential equation.
Reference: [19] <author> R. J. Lipton, T. G. Marr and J. D. Welsh, </author> <title> Computational Approaches to Discovering Semantics in Molecular Biology. </title> <booktitle> Proc. IEEE 77(7) 1989, </booktitle> <pages> pp. 1056-1060. </pages>
Reference-contexts: Given a new gene sequence the task is to determine all those genes of a database which are most similar to the given one. This application is very important in modern gene technology and its background is described further in <ref> [19] </ref>. The employed algorithm was developed by Smith and Waterman and uses dynamic programming techniques. It is further explained in [29] and [33]. For parallelization we partitioned the database consisting of 106.684 genes into subsets which were distributed to the individual LANs.
Reference: [20] <author> M. Litzkow, M. Livny and M. </author> <title> Mutka, Condor Hunter of Idle Workstations. </title> <type> Technical report 730, </type> <institution> University of Wisconsin, </institution> <month> december </month> <year> 1987. </year>
Reference: [21] <author> H. P. Luthi, J. Almlof, </author> <title> Network Supercomputing: A distributed-concurrent direct SCF scheme. </title> <journal> Theoretica Chimica Acta 84, </journal> <year> 1993, </year> <pages> pp. 443-455. </pages>
Reference-contexts: Therefore massive parallelism with workstation clusters will have to use several LANs connected by metropolitan and wide area network technology. With the present communication technology the following sustained bandwidths were observed in Internet connections <ref> [21] </ref>: 2 National (Switzerland) 100 kBytes/sec Transnational (Europe) 1 - 50 kBytes/sec Transatlantic 30 kBytes/sec Transpacific 3 kBytes/sec Therefore only special applications and algorithms with low communication demands are reasonable for massively parallel cluster solutions. <p> For example, parallel runs should be restricted to certain times of the day (or rather, of the night or of the weekend) and scheduled to machines, whose performance is not required locally. 6 Similar Work and Further Research WAN parallelism has been studied in [27], <ref> [21] </ref>, [30]. In their experiments a smaller number of supercomputers was coupled for optimizing the structure of large molecules with a modified Hartree-Fock method [21]. Massively parallel approaches were studied with 110 workstations at the Technical University of Munich [16]. <p> of the weekend) and scheduled to machines, whose performance is not required locally. 6 Similar Work and Further Research WAN parallelism has been studied in [27], <ref> [21] </ref>, [30]. In their experiments a smaller number of supercomputers was coupled for optimizing the structure of large molecules with a modified Hartree-Fock method [21]. Massively parallel approaches were studied with 110 workstations at the Technical University of Munich [16]. The employed algorithm was optimized to reduce the necessary communication and a special physical layout of the LAN was used.
Reference: [22] <author> C. D. Marsan, </author> <title> NSF pursues computing without walls. </title> <journal> Federal Computer Week 6(35), </journal> <volume> 53, </volume> <month> november 30, </month> <year> 1992. </year>
Reference: [23] <author> H. Nakanishi, V. Rego and V. Sunderam, </author> <title> Superconcurrent Simulation of Polymer Chains on Heterogeneous Networks. </title> <booktitle> Proceedings Supercomputer 92, </booktitle> <address> Minneapolis, </address> <publisher> IEEE Press, </publisher> <year> 1992, </year> <pages> 561-569. </pages>
Reference-contexts: 1 Introduction Recent research activities have shown, that workstation cluster computing or hypercom-puting provides a fair amount of computing power at a reasonable price. [16] reports a performance of more than 1 Gflops in a cluster of 110 workstations and <ref> [23] </ref> demonstrates, that for certain applications cluster solutions provide a price performance ratio which is two orders of magnitude better than for classical supercomputers. [32] estimates that fl Research partially supported by Firma Siemens AG Munchen and Schweizer Bundesamt fur Kon-junktur und Wirtschaftsforderung, grant numbers 2255.1 and 2554.1. 1 90% of <p> For example the BLASTPM code from molecular biology required 1820 sec. computing time on a Sun 4 workstation and 1522 sec. on a CRAY Y-MP [18]. Similar experiences are reported by <ref> [23] </ref>. Many problems from mathematical physics are concerned with a local physical law, which is given by a differential equation. Their dominating operations are floating point operations and the locality of the physical law is reflected in the algorithm by a high demand for interprocess communication. <p> Massively parallel approaches were studied with 110 workstations at the Technical University of Munich [16]. The employed algorithm was optimized to reduce the necessary communication and a special physical layout of the LAN was used. The 1992 winners of the Gordon Bell prize <ref> [23] </ref> made experiments with up to 192 workstations using PVM. In 1993 the first prize of the Mannheim SuParCup was awarded to the author of this paper and to his collaborator Volker Strumpen for the genetic application described above, using a previous version of Lola.
Reference: [24] <author> Parasoft Corporation, </author> <title> Express Version 1.0: A Communication Environment for Parallel Computers. </title> <year> 1988. </year>
Reference: [25] <author> L. R. Revor, </author> <title> DQS users guide. </title> <institution> Computing and Telecommunications Division, Argonne National Laboratory, </institution> <month> september </month> <year> 1992. </year>
Reference: [26] <author> R. Roth, T. Setz, </author> <title> LiPS: A System for Distributed Processing on Workstations. </title> <type> Technical report, </type> <institution> FB-14 Informatik, Universitat des Saarlandes, </institution> <month> february </month> <year> 1993. </year>
Reference: [27] <author> W. Scott, P. Arbenz, S. Vogel and H. P. Luthi, </author> <title> Network Supercomputing. </title> <booktitle> EPFL Supercomputing Review, </booktitle> <month> november </month> <year> 1991. </year>
Reference-contexts: For example, parallel runs should be restricted to certain times of the day (or rather, of the night or of the weekend) and scheduled to machines, whose performance is not required locally. 6 Similar Work and Further Research WAN parallelism has been studied in <ref> [27] </ref>, [21], [30]. In their experiments a smaller number of supercomputers was coupled for optimizing the structure of large molecules with a modified Hartree-Fock method [21]. Massively parallel approaches were studied with 110 workstations at the Technical University of Munich [16].
Reference: [28] <author> G. Shoinas, </author> <title> Issues on the Implementation of Programming Systems for Distributed Applications. </title> <type> Technical report, </type> <institution> University of Crete, </institution> <year> 1991. </year> <month> 16 </month>
Reference: [29] <author> T. F. Smith, M. S. Waterman, </author> <title> Identification of Common Molecular Subsequences. </title> <journal> Journal of Molec--ular Biology 147, </journal> <year> 1981, </year> <pages> pp. 195-197 </pages>
Reference-contexts: This application is very important in modern gene technology and its background is described further in [19]. The employed algorithm was developed by Smith and Waterman and uses dynamic programming techniques. It is further explained in <ref> [29] </ref> and [33]. For parallelization we partitioned the database consisting of 106.684 genes into subsets which were distributed to the individual LANs. The new, given gene was entered at the master process and broadcast to the slaves and worker processes.
Reference: [30] <author> C. Sprenger, Netzwerk-Computing. </author> <type> Diploma thesis, </type> <institution> Institut fur wissenschaftliches Rechnen, ETH Zurich, </institution> <month> march </month> <year> 1992. </year>
Reference-contexts: For example, parallel runs should be restricted to certain times of the day (or rather, of the night or of the weekend) and scheduled to machines, whose performance is not required locally. 6 Similar Work and Further Research WAN parallelism has been studied in [27], [21], <ref> [30] </ref>. In their experiments a smaller number of supercomputers was coupled for optimizing the structure of large molecules with a modified Hartree-Fock method [21]. Massively parallel approaches were studied with 110 workstations at the Technical University of Munich [16].
Reference: [31] <author> V. Strumpen, </author> <title> Parallel Molecular Sequence Analysis on Workstations in the Internet. </title> <type> Technical report, </type> <institution> department of computer science, University of Zurich, </institution> <year> 1993. </year>
Reference: [32] <author> L. H. Turcotte, </author> <title> A Survey of Software Environments for Exploiting Networked Computing Resources. </title> <institution> Technical report of the engineering research center for computational field simulation, </institution> <month> june </month> <year> 1993. </year>
Reference-contexts: a fair amount of computing power at a reasonable price. [16] reports a performance of more than 1 Gflops in a cluster of 110 workstations and [23] demonstrates, that for certain applications cluster solutions provide a price performance ratio which is two orders of magnitude better than for classical supercomputers. <ref> [32] </ref> estimates that fl Research partially supported by Firma Siemens AG Munchen and Schweizer Bundesamt fur Kon-junktur und Wirtschaftsforderung, grant numbers 2255.1 and 2554.1. 1 90% of Lawrence Livermore National Laboratory's workload could be solved with work-station clusters in reasonable time. <p> Consequence: Massive parallelism using workstations in a wide area network is possible, but only for special applications and algorithms. 2.2 Do We Need Special Control Mechanisms in a WAN? There presently exist many software packages which assist the programmer in developing parallel programs for workstation clusters [9], <ref> [32] </ref>. In principle these systems could also control parallelism within wide area networks, because they are independent of the communication medium as long as a suitable interfaces, like the Berkeley socket abstraction, are available.
Reference: [33] <author> R. A. Wagner and M. J. Fischer, </author> <title> The String to String Correction Problem. </title> <booktitle> JACM 21(2) 1974, </booktitle> <pages> pp. 168-173. </pages>
Reference-contexts: This application is very important in modern gene technology and its background is described further in [19]. The employed algorithm was developed by Smith and Waterman and uses dynamic programming techniques. It is further explained in [29] and <ref> [33] </ref>. For parallelization we partitioned the database consisting of 106.684 genes into subsets which were distributed to the individual LANs. The new, given gene was entered at the master process and broadcast to the slaves and worker processes.
References-found: 33

