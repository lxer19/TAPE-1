URL: http://www.cse.ogi.edu/DISC/projects/immunix/bugtol.ps.gz
Refering-URL: http://www.cse.ogi.edu/DISC/projects/immunix/publications.html
Root-URL: http://www.cse.ogi.edu
Email: (crispin@cse.ogi.edu)  
Title: 1 Death, Taxes, and Imperfect Software: Surviving the Inevitable  
Author: Crispin Cowan and Calton Pu and Heather Hinton 
Web: http://www.cse.ogi.edu/DISC/projects/immunix  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  Electrical and Computer Engineering, Ryerson Polytechnic University  
Abstract: A security system is only as strong as its weakest link. This observation lead to security architectures that use a small trusted computing base (TCB) to minimize the number of links in the system. A small TCB both reduces the chance of a bug occurring by reducing the volume of software that may contain a bug, and also makes formal verification of the correctness of the TCB feasible. Unfortunately, for a variety of reasons, the commercial marketplace of popular operating systems has chosen to ignore this line of reasoning. The trusted computing base (system components embodied with significant amounts of trust) is not small, is not formally verified, and consequently is neither correct nor secure. We conclude that it is inevitable that commodity systems software will have flawed security. Techniques have developed to allow systems to cope with potential security flaws, which we call security bug tolerance . Security bug tolerance enhances the survivability of a flawed system by post hoc dealing with the systems security flaws. This paper presents a categorization scheme for security bug tolerance techniques, and populates it with techniques of our own and from the literature. The categorization allows the reader to analyze various techniques to discover their similarities and differences, en abling the reader to compare relatively diverse tools on their merits.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> AUSCERT. </author> <title> overflow_wrapper.c Wrap Programs to Prevent Command Line Argument Buffer Overrun Vulnerabilities. </title> <month> ftp://ftp.auscert.org.au/pub/ auscert/tools/overflow_wrapper , May </month> <year> 1997. </year>
Reference-contexts: Many privileged programs are sloppily written, and thus vulnerable to creative input, such as large strings that induce buffer overflows or other errors. Wrappers have been developed that restrict the syntax of input to privileged programs to finite-length strings and safe character sets <ref> [1, 25] </ref>. Javas security depends on a three-pronged security model: the Java compilers type safety, the Java bytecode verifier, and the JVM sandbox.
Reference: [2] <editor> B. Blakley and D.M. Kienzle. </editor> <title> Some Weaknesses of the TCB Model. </title> <booktitle> In Proceedings of the IEEE Symposium on Security and Privacy , Oakland, </booktitle> <address> CA, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: This has generated enough controversy to be the subject of a formal debate at the 1997 IEEE Symposium on Security and Privacy <ref> [ 2, 14,19] </ref>. If formal verification is not feasible, developers that care somewhat about security strive to minimize security bugs with a variety of debugging and bug minimization techniques, such as strict coding practices, red teaming, and fault-injection.
Reference: [3] <author> Klaus Brunnstein. </author> <title> Mr. </title> <type> Bill Gates: </type> <institution> MS Software Essentially Bug-free. comp.risks 17.43, </institution> <month> October </month> <year> 1995. </year> <note> http://catless.ncl.ac.uk/Risks/17.43.html#subj5 </note> . 
Reference: [4] <author> Fred Cohen. </author> <title> The Deception Toolkit. </title> <address> comp.risks 19.62, </address> <month> March </month> <year> 1998. </year> <note> http:// all.net/dtk.html </note> . 
Reference-contexts: Otherwise, the defender must depend on the mystery property to slow down the attackers search of the permutation space. There are few extant examples of interface permutations. One example is the Deception Tool Kit <ref> [4] </ref>, which provides tools to spoof the existence of servers. Like the killdeer bird faking an injury to draw predators away from the nest, these faux servers are intended to draw the attackers attention away from the machine that is running an actual server. <p> We postulate that restricting virtual machine im plementations is more effective and easier than implementation permutations. Thus one must be cautious when presented with a permutation security bug tolerance technique. What is the permutation protecting, and how effective is it? For instance, the deception toolkit <ref> [4] </ref> is most effective at disguising a genuine service provider by surrounding it with faux service providers; how difficult is it for the attacker to identify the genuine service provider by other means? Permuting the size of stack frame activation records [8]successfully defeats existing stack smashing attacks because they depend on
Reference: [5] <author> Crispin Cowan, Calton Pu, Dave Maier, Heather Hinton, Peat Bakke, Steve Beattie, Aaron Grier, Perry Wagle, and Qian Zhang. StackGuard: </author> <title> Automatic Adaptive Detection and Prevention of Buffer-Overflow Attacks. </title> <booktitle> In 7th USENIX Security Conference , San Antonio, </booktitle> <address> TX, </address> <month> January </month> <year> 1998. </year>
Reference-contexts: If the stack is not executable, this attack fails. These patches require added code to handle rare instances where the stack does need to be executable, and the kernel switches it back and forth as necessary. StackGuard : Stackguard <ref> [5] </ref> is our compiler extension to protect programs against stack smashing attacks, similar to those considered for nonexecutable stacks above. StackGuard adds code to programs to do integrity checking on their activation records. <p> Forrest provides an example of permutations in a virtual machine implementation [8] in the form of a modified C compiler that randomly permutes the size of stack frame activation records. Like StackGuard <ref> [5] </ref>, this is designed to stop stack smashing attacks against the virtual machine implementation for C programs, which has the unfortunate property that some of the virtual machines data structures such as the return address are accessible to the programs being executed. <p> attacker to identify the genuine service provider by other means? Permuting the size of stack frame activation records [8]successfully defeats existing stack smashing attacks because they depend on a static stack layout, but how difficult is it to construct stack smashing attacks that can adapt to a dynamic stack layout <ref> [5, 17] </ref>? Implementation permutations that are both transparent to the application programmer and effective in defeating or slowing attacks require a lot of information. <p> For instance, while Forrests compiler makes certain stack smashing attacks more difficult to deploy, a similar implementation restriction in StackGuard makes an identical attack impossible. As an added benefit, restrictions have permutation-like side effects. For instance, the StackGuard implementation <ref> [5] </ref> failed to detect some attacks, but these attacks were none the less stopped because of the permuted data layout induced by StackGuard. 5.3 What it All Means All of the techniques presented are adaptations to enhance the security of a component of a system.
Reference: [6] <author> Solar Designer. </author> <title> NonExecutable User Stack. </title> <address> http://www.false.com/security/ linux-stack/ </address> . 
Reference-contexts: Violations of these rules produce runtime error re ports to facilitate debugging, but these reports could become security alerts. Nonexecutable Stack : Casper Dik and Solar Designer produced patches for Solaris [7] and Linux <ref> [6] </ref>, respectively, that make the stack segment of the users virtual address space non-executable. This protects programs from stack smashing attacks, which inject code onto the programs stack, and alter the return address to jump to that code. If the stack is not executable, this attack fails.
Reference: [7] <author> Casper Dik. </author> <title> NonExecutable Stack for Solaris. </title> <note> Posting to comp.security.unix , http://x10.dejanews.com/ getdoc.xp?AN=207344316&CONTEXT=890082637.1567359211&% hitnum=69&AH=1 , January 2 1997. </note>
Reference-contexts: Violations of these rules produce runtime error re ports to facilitate debugging, but these reports could become security alerts. Nonexecutable Stack : Casper Dik and Solar Designer produced patches for Solaris <ref> [7] </ref> and Linux [6], respectively, that make the stack segment of the users virtual address space non-executable. This protects programs from stack smashing attacks, which inject code onto the programs stack, and alter the return address to jump to that code. If the stack is not executable, this attack fails.
Reference: [8] <author> Stephanie Forrest, Anil Somayaji, and David. H. Ackley. </author> <note> Building Diverse Computer Systems . In HotOS-VI , May 1997. </note>
Reference-contexts: An IDS forms an important part of a dynamic interface restriction by providing a sophisticated notion of when the interface should be restricted. Intrusion detection systems come in a variety of forms <ref> [8, 22, 12, 13] </ref> but all share the basic property that they examine interface usage, and indicate suspicious usage, providing dynamically restrictable interfaces with an indication of when to be more restrictive. 3.2 Implementation Restrictions Like interface restrictions, implementation restrictions contain the potential damage that can be inflicted by attackers exploiting <p> The implementation permutation has not been applied post hoc to some implementation, but rather has been designed in to the virtual machine implementation. Forrest provides an example of permutations in a virtual machine implementation <ref> [8] </ref> in the form of a modified C compiler that randomly permutes the size of stack frame activation records.
Reference: [9] <author> Reed Hastings and Bob Joyce. Purify: </author> <title> Fast Detection of Memory Leaks and Access Errors. </title> <booktitle> In Proceedings of the Winter USENIX Conference , 1992. </booktitle> <address> http:// www.rational.com/support/ techpapers/fast_detection/ </address> . 
Reference-contexts: Table 3 summarizes some added-code implementation restrictions, describing what additional correctness checks are provided by the added code in each case. Purify : Purify is a debugging tool for C programs, focusing on memory problems <ref> [9] </ref>. It provides its own linker, which inserts integrity checking code around every memory reference to ensure that memory is being used in a consistent fashion.
Reference: [10] <author> Joakim Jardenberg. </author> <note> Crack a Mac Contest. http://hacke.infinit.se/ , February 1997. </note>
Reference-contexts: The canonical example is the bastion host in a firewall. It is essential that this host not be compromised, and so they are configured with the absolute minimum of services, minimizing potentially exploitable vul nerabilities. The Crack a Mac challenge <ref> [10] </ref> provides another example of this technique, where a Macintosh web server is set up as a public challenge to crackers. The platform is highly secure, because the MacOS has no native TCP server programs, so the installed web server is the only net work vulnerability.
Reference: [11] <author> Richard Jones and Paul Kelly. </author> <title> Bounds Checking for C. </title> <address> http://www 16 ala.doc.ic.ac.uk/&lt;HardSpace phjk/BoundsChecking.html, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Most do so as part of the programming language semantics, which we view as an interface restric tion as described in Section 3.1.1. However, array bounds checking has also been added to languages that do not support array bounds, such as C <ref> [11] </ref>. 3.2.2 Removed Code: Minimizing Risk The likelihood of a bug is proportionate to the size and complexity of the software in question, so the smaller a program is, the more likely it is to be correct.
Reference: [12] <author> Gene H. Kim and E.H. Spafford. </author> <title> Writing, Supporting, and Evaluating Tripwire: A Publicly Available Security Tool. </title> <booktitle> In Proceedings of the USENIX UNIX Applications Development Symposium , pages 88107, </booktitle> <address> Toronto, Canada, </address> <year> 1994. </year>
Reference-contexts: An IDS forms an important part of a dynamic interface restriction by providing a sophisticated notion of when the interface should be restricted. Intrusion detection systems come in a variety of forms <ref> [8, 22, 12, 13] </ref> but all share the basic property that they examine interface usage, and indicate suspicious usage, providing dynamically restrictable interfaces with an indication of when to be more restrictive. 3.2 Implementation Restrictions Like interface restrictions, implementation restrictions contain the potential damage that can be inflicted by attackers exploiting
Reference: [13] <author> Calvin Ko, George Fink, and Karl Levitt. </author> <title> Automated Detection of Vulnerabilities in Privileged Programs by Execution Monitoring. </title> <booktitle> In Proceedings of the 10th Annual Computer Security Applications Conference , pages 134144, </booktitle> <address> Orlando, FL, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: An IDS forms an important part of a dynamic interface restriction by providing a sophisticated notion of when the interface should be restricted. Intrusion detection systems come in a variety of forms <ref> [8, 22, 12, 13] </ref> but all share the basic property that they examine interface usage, and indicate suspicious usage, providing dynamically restrictable interfaces with an indication of when to be more restrictive. 3.2 Implementation Restrictions Like interface restrictions, implementation restrictions contain the potential damage that can be inflicted by attackers exploiting
Reference: [14] <author> John McLean. </author> <title> Is the Trusted Computing Base concept fundamentally Flawed? In Proceedings of the IEEE Symposium on Security and Privacy , Oakland, </title> <address> CA, </address> <month> May </month> <year> 1997. </year>
Reference: [15] <author> Martin Minow. </author> <title> Crack a Mac Server Cracked. </title> <address> comp.risks 19.31, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: The platform is highly secure, because the MacOS has no native TCP server programs, so the installed web server is the only net work vulnerability. The challenge eventually fell to an attacker <ref> [15] </ref>, but the failure was a 3 rd party plug-in extension to the web server; had the plug-in code also been removed, the server would have been even more secure. Like the interface restrictions described in Section 3.1, implementation restrictions can be applied dynamically.
Reference: [16] <author> Nathan Myers. </author> <title> FOCUS Magazine Interview with Bill Gates: Microsoft Code Has No Bugs. </title> <address> http://www.cantrip.org/nobugs.html </address> . 
Reference: [17] <author> Aleph One. </author> <title> Smashing The Stack For Fun And Profit. </title> <address> Phrack , 7(49), </address> <month> November </month> <year> 1996. </year>
Reference-contexts: attacker to identify the genuine service provider by other means? Permuting the size of stack frame activation records [8]successfully defeats existing stack smashing attacks because they depend on a static stack layout, but how difficult is it to construct stack smashing attacks that can adapt to a dynamic stack layout <ref> [5, 17] </ref>? Implementation permutations that are both transparent to the application programmer and effective in defeating or slowing attacks require a lot of information.
Reference: [18] <author> D.L. Parnas, S.P. Kwan, and J. van Schouwen. </author> <title> Evaluation Standards for Safety Critical Software. </title> <booktitle> In Proceedings of the International Working Group on Nuclear Power Plant Control and Instrumentation, IAEA NPPCS Specialists Meeting on Microprocessors in Systems Important to the Safety of Nuclear Power Plants , London, </booktitle> <address> UK, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Bug minimization and elimination techniques are only applied when safety is of paramount importance, and cost is a minor consider ation, such as nuclear reactor control <ref> [18] </ref>. Thus debugging techniques will not be used enough to make systems actually secure, and it is likely that the widespread use of systems that have security bugs will be a persistent state for some time to come.
Reference: [19] <author> William R. Schockley. </author> <title> Is the Reference Monitor Concept Fatally Flawed? The Case for the Negative. </title> <booktitle> In Proceedings of the IEEE Symposium on Security and Privacy , Oakland, </booktitle> <address> CA, </address> <month> May </month> <year> 1997. </year>
Reference: [20] <author> Christoph L. Schuba, Ivan V. Krsul, Markus G. Kuhn, Eugene H. Spafford, Aurobindo Sundaram, and Diego Zamboni. </author> <title> Analysis of a Denial of Service Attack on TCP. </title> <booktitle> In Proceedings of the IEEE Symposium on Security and Privacy , Oakland, </booktitle> <address> CA, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: This form of access control is convenient for users, but highly insecure. A system supporting dynamic interface restriction could disable the honoring of .rhost specifications when the local intrusion detection system suspects intruders are present in the domain. Schuba et al <ref> [20] </ref> present a more reasonable example of dynamic interface restriction. This work defends against the TCP SYN flood denial-of-service attack by dynamically adjusting the timeout window for TCP connection requests.
Reference: [21] <author> Howie Shrobe. </author> <note> ARPATech 96 Information Survivability Briefing. http:// www.darpa.mil/ito/ARPATech96_Briefs/survivability/ survive_brief.html , May 1996. </note>
Reference-contexts: If data corruption goes undetected, then checkpointing the data will succeed only in checkpointing corrupted data. This paper presents a categorization of security bug tolerance techniques. These techniques all en hance the survivability <ref> [21] </ref> of the system with respect to various kinds of threats that the system itself is not capable of handling. We propose that survivability is, in part, the study of how to effectively retrofit security to a system that was not designed with security as a goal.
Reference: [22] <author> Internet Security Systems. </author> <title> Real-time Attack Recognition and Response: A Solution for Tightening Network Security. </title> <type> Report, </type> <institution> Internet Security Systems, </institution> <year> 1997. </year>
Reference-contexts: An IDS forms an important part of a dynamic interface restriction by providing a sophisticated notion of when the interface should be restricted. Intrusion detection systems come in a variety of forms <ref> [8, 22, 12, 13] </ref> but all share the basic property that they examine interface usage, and indicate suspicious usage, providing dynamically restrictable interfaces with an indication of when to be more restrictive. 3.2 Implementation Restrictions Like interface restrictions, implementation restrictions contain the potential damage that can be inflicted by attackers exploiting
Reference: [23] <author> Unknown. </author> <title> Interview with Bill Gates. FOCUS , (43):206212, </title> <month> October 23 </month> <year> 1995. </year>
Reference-contexts: New features seem to matter more than correctness. Consider the calls to Microsofts support line <ref> [3,16, 23 ] </ref>: Most calls request help on how to do some particular task 5% of calls request some new feature Less than 1% of calls are to report bugs 3 Advertisements, where software vendors promote their products, compare features, and occasionally speed, but rarely correctness.
Reference: [24] <author> Wietse Venema. </author> <title> TCP WRAPPER: Network Monitoring, Access Control, and Booby Traps. </title> <booktitle> In Proceedings of the Third Usenix UNIX Security Symposium , pages 8592, </booktitle> <address> Baltimore, MD, </address> <month> September </month> <year> 1992. </year> <note> ftp://ftp.win.tue.nl/pub/security/ tcp_wrapper.ps.Z </note> . 
Reference-contexts: A wrapper is a program wrapped around a program suspected of having bugs. The wrapper takes input intended for the subject program and does various integrity checks on it. If the input passes muster, it is passed on to the subject program, oth erwise it is rejected. TCP Wrappers <ref> [24] </ref> is an example, which acts like a small firewall on the host, restricting access to particular ports and services. Wrappers have also been applied to vulnerabilities in application programs.
Reference: [25] <author> Joe Zbiciak. </author> <title> wrapper.c Generic Wrapper to Prevent Exploitation of suid/sgid Programs. Bugtraq mailing list, </title> <note> http://geek-girl.com/bugtraq/ , May 19 1997. http://cegt201.bradley.edu/ im14u2c/wrapper/ </note> . 
Reference-contexts: Many privileged programs are sloppily written, and thus vulnerable to creative input, such as large strings that induce buffer overflows or other errors. Wrappers have been developed that restrict the syntax of input to privileged programs to finite-length strings and safe character sets <ref> [1, 25] </ref>. Javas security depends on a three-pronged security model: the Java compilers type safety, the Java bytecode verifier, and the JVM sandbox.
References-found: 25

