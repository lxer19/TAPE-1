URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mmoll/www/moll.convergence-zone.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mmoll/www/publications.html
Root-URL: 
Email: mmoll+@cs.cmu.edu  risto@cs.utexas.edu  
Title: Convergence-Zone Episodic Memory: Analysis and Simulations  
Author: Mark Moll Risto Miikkulainen 
Address: Pittsburgh, PA 15213 USA  Austin, TX 78712 USA  
Affiliation: School of Computer Science Carnegie Mellon University  Department of Computer Sciences The University of Texas at Austin  
Abstract: Human episodic memory provides a seemingly unlimited storage for everyday experiences, and a retrieval system that allows us to access the experiences with partial activation of their components. The system is believed to consist of a fast, temporary storage in the hippocampus, and a slow, long-term storage within the neocortex. This paper presents a neural network model of the hippocampal episodic memory inspired by Damasio's idea of Convergence Zones. The model consists of a layer of perceptual feature maps and a binding layer. A perceptual feature pattern is coarse coded in the binding layer, and stored on the weights between layers. A partial activation of the stored features activates the binding pattern, which in turn reactivates the entire stored pattern. For many configurations of the model, a theoretical lower bound for the memory capacity can be derived, and it can be an order of magnitude or higher than the number of all units in the model, and several orders of magnitude higher than the number of binding-layer units. Computational simulations further indicate that the average capacity is an order of magnitude larger than the theoretical lower bound, and making the connectivity between layers sparser causes an even further increase in capacity. Simulations also show that if more descriptive binding patterns are used, the errors tend to be more plausible (patterns are confused with other similar patterns), with a slight cost in capacity. The convergence-zone episodic memory therefore accounts for the immediate storage and associative retrieval capability and large capacity of the hippocampal memory, and shows why the memory encoding areas can be much smaller than the perceptual maps, consist of rather coarse computational units, and be only sparsely connected to the perceptual maps. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ackley, D. H., Hinton, G. E., and Sejnowski, T. J. </author> <year> (1985). </year> <title> A learning algorithm for Boltzmann machines. </title> <journal> Cognitive Science, </journal> <volume> 9 </volume> <pages> 147-169. </pages>
Reference: <author> Alon, N., and Spencer, J. H. </author> <year> (1992). </year> <title> The Probabilistic Method. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Alvarez, P., and Squire, L. R. </author> <year> (1994). </year> <title> Memory consolidation and the medial temporal lobe: A simple network model. </title> <booktitle> Proceedings of the National Academy of Sciences of the USA, </booktitle> <volume> 91 </volume> <pages> 7041-7045. </pages>
Reference: <author> Amaral, D. G., Ishizuka, N., and Claiborne, B. </author> <year> (1990). </year> <title> Neurons, numbers and the hippocampal network. </title> <editor> In Storm-Mathisen, J., Zimmer, J., and Ottersen, O. P., editors, </editor> <title> Understanding the Brain through the Hippocampus, </title> <booktitle> vol. 83 of Progress in Brain Research, </booktitle> <pages> 1-11. </pages> <address> New York: </address> <publisher> Elsevier. </publisher>
Reference-contexts: storing and retrieving, for example, 10 6 memories would require in the order of 10 8 nodes and 10 16 connections, which is unrealistic, given that the hippocampal formation in higher animals such as the rat is estimated to have about 10 6 primary excitatory neurons with 10 10 connections <ref> (Amaral et al. 1990) </ref>, and the entire human brain is estimated to have about 10 11 neurons and 10 15 synapses (Jessell 1991). These earlier models had a uniform, abstract structure and were not specifically motivated by any particular part of the human memory system. <p> to all units in the hippocampus, there are a total of 10 8 afferent connections to the hippocampus, and the number of such connections per vertical column in the feature maps and per excitatory neuron in the hippocampus is 10 2 , both of which are small but possible numbers <ref> (Amaral et al. 1990) </ref>.
Reference: <author> Amari, S.-I. </author> <year> (1977). </year> <title> Neural theory of association and concept formation. </title> <journal> Biological Cybernetics, </journal> <volume> 26 </volume> <pages> 175-185. </pages>
Reference: <author> Amari, S.-I. </author> <year> (1988). </year> <title> Associative memory and its statistical neurodynamical analysis. </title> <editor> In Haken, H., editor, </editor> <booktitle> Neural and Synergetic Computers, </booktitle> <pages> 85-99. </pages> <address> Berlin: </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: Above, a theoretical lower bound for the capacity of simple recall within a given error tolerance was derived, and the average capacity was estimated experimentally. Two other types of capacity can also be defined for an associative memory model <ref> (Amari 1988) </ref>. The absolute capacity refers to the maximum number of patterns that the network can represent as equilibrium states, and the relative capacity is the maximum number of patterns that can be retrieved by progressive recall.
Reference: <author> Amit, D. J. </author> <year> (1989). </year> <title> Modeling Brain Function: The World of Attractor Neural Networks. </title> <address> Cambridge, UK: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Amit, D. J., Gutfreund, H., and Sompolinsky, H. </author> <year> (1985a). </year> <title> Spin-glass models of neural networks. </title> <journal> Physical Review A, </journal> <volume> 32 </volume> <pages> 1007-1018. </pages>
Reference: <author> Amit, D. J., Gutfreund, H., and Sompolinsky, H. </author> <year> (1985b). </year> <title> Storing infinite numbers of patterns in a spin-glass model of neural networks. </title> <journal> Physical Review Letters, </journal> <volume> 55 </volume> <pages> 1530-1533. </pages>
Reference: <author> Anderson, J. A. </author> <year> (1972). </year> <title> A simple neural network generating an interactive memory. </title> <journal> Mathematical Biosciences, </journal> <volume> 14 </volume> <pages> 197-220. </pages>
Reference: <author> Anderson, J. A., Silverstein, J. W., Ritz, S. A., and Jones, R. S. </author> <year> (1977). </year> <title> Distinctive features, categorical perception and probability learning: Some applications of a neural model. </title> <journal> Psychological Review, </journal> <volume> 84 </volume> <pages> 413-451. </pages>
Reference: <author> Bain, L. J., and Engelhardt, M. </author> <year> (1987). </year> <title> Introduction to Probability and Mathematical Statistics. </title> <address> Boston, MA: </address> <publisher> PWS Publishers. </publisher>
Reference: <author> Boss, B., Peterson, G., and Cowan, W. </author> <year> (1985). </year> <title> On the numbers of neurons in the dentate gurys of the rat. </title> <journal> Brain Research, </journal> <volume> 338 </volume> <pages> 144-150. </pages>
Reference: <author> Boss, B., Turlejski, K., Stanfield, B., and Cowan, W. </author> <year> (1987). </year> <title> On the numbers of neurons in fields CA1 and CA3 of the hippocampus of Sprague-Dawley and Wistar rats. </title> <journal> Brain Research, </journal> <volume> 406 </volume> <pages> 280-287. </pages>
Reference: <author> Cooper, L. N. </author> <year> (1973). </year> <title> A possible organization of animal memory and learning. </title> <editor> In Lundquist, B., and Lundquist, S., editors, </editor> <booktitle> Proceedings of the Nobel Symposium on Collective Properties of Physical Systems, </booktitle> <pages> 252-264. </pages> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Damasio, A. R. </author> <year> (1989a). </year> <title> The brain binds entities and events by multiregional activation from convergence zones. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 123-132. </pages>
Reference: <author> Damasio, A. R. </author> <year> (1989b). </year> <title> Time-locked multiregional retroactivation: A systems-level proposal for the neural substrates of recall and recognition. </title> <journal> Cognition, </journal> <volume> 33 </volume> <pages> 25-62. </pages>
Reference: <author> Fahlman, S. E. </author> <year> (1991). </year> <title> The recurrent cascade-correlation architecture. </title> <editor> In Lippmann, R. P., Moody, J. E., and Touretzky, D. S., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <pages> 190-205. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fahlman, S. E., and Lebiere, C. </author> <year> (1990). </year> <title> The cascade-correlation learning architecture. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> 524-532. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Faris, W. G., and Maier, R. S. </author> <year> (1988). </year> <title> Probabilistic analysis of a learning matrix. </title> <booktitle> Advances in Applied Probability, </booktitle> <volume> 20 </volume> <pages> 695-705. </pages>
Reference: <author> French, R. M. </author> <year> (1991). </year> <title> Using semi-distributed representations to overcome catastrophic forgetting in connectionist networks. </title> <booktitle> In Proceedings of the 13th Annual Conference of the Cognitive Science Society, </booktitle> <pages> 173-178. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. 24 Gardner-Medwin, </publisher> <editor> A. R. </editor> <year> (1976). </year> <title> The recall of events through the learning of associations between their parts. </title> <journal> Proceedings of the Royal Society of London B, </journal> <volume> 194 </volume> <pages> 375-402. </pages>
Reference-contexts: Several techniques have been proposed to alleviate forgetting, including using weights with different learning rates (Hinton and Plaut 1987), gradually including new examples and phasing out earlier ones (Hetherington and Seidenberg 1989), forcing semidistributed hidden-layer representations <ref> (French 1991) </ref>, concentrating changes on novel parts of the inputs (Kortge 1990), using units with localized receptive fields (Kruschke 1992), and adding new units and weights to encode new information (Fahlman 1991; Fahlman and Lebiere 1990).
Reference: <author> Gibson, W. G., and Robinson, J. </author> <year> (1992). </year> <title> Statistical analysis of the dynamics of a sparse associative memory. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 645-661. </pages>
Reference-contexts: Also, such a retrieval would probably be more robust against invalid retrieval cues (i.e. cues that are not part of the pattern to be retrieved). The dynamics of the progressive recall process are difficult to analyze <ref> (see Gibson and Robinson 1992 for a possible approach) </ref> and expensive to simulate, and simple recall was thus used in this first implementation of the convergence-zone model. <p> Little and Shaw's (1975) network of stochastic neurons, and Gardner-Medwin's (1976) and Marr's (1971) models of the hippocampus fall in this category. Progressive recall gives them a potentially higher capacity, which with high connectivity exceeds that of the Hopfield network <ref> (Gibson and Robinson 1992) </ref>.
Reference: <author> Gluck, M. A., and Myers, C. E. </author> <year> (1993). </year> <title> Hippocampal mediation of stimulus representation: A computational theory. </title> <journal> Hippocampus, </journal> <volume> 3 </volume> <pages> 491-516. </pages>
Reference: <author> Grossberg, S. </author> <year> (1983). </year> <title> Studies of Mind and Brain: Neural Principles of Learning, Perception, Development, Cognition and Motor Control. </title> <publisher> Dordrecht, Holland; Boston: Reidel. </publisher>
Reference: <author> Grossberg, S. </author> <year> (1987). </year> <title> Competitive learning: From interactive activation to adaptive resonance. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 23-63. </pages>
Reference: <author> Halgren, E. </author> <year> (1984). </year> <title> Human hippocampal and amygdala recording and stimulation: Evidence for a neural model of recent memory. </title> <editor> In Squire, L., and Butters, N., editors, </editor> <booktitle> The Neuropsychology of Memory, </booktitle> <pages> 165-182. </pages> <address> New York: Guilford. </address>
Reference: <author> Hasselmo, M. E., Rolls, E. T., and Baylis, G. C. </author> <year> (1989). </year> <title> The role of expression and identity in the face-selective responses of neurons in the temporal visual cortex of the monkey. </title> <journal> Behavioural Brain Research, </journal> <volume> 32 </volume> <pages> 203-218. </pages>
Reference: <author> Hebb, D. O. </author> <year> (1949). </year> <title> The Organization of Behavior: A Neuropsychological Theory. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Heit, G., Smith, M. E., and Halgren, E. </author> <year> (1989). </year> <title> Neural encoding of individual words and faces by the human hippocampus and amygdala. </title> <journal> Nature, </journal> <volume> 333 </volume> <pages> 773-775. </pages>
Reference: <author> Hertz, J., Krogh, A., and Palmer, R. G. </author> <year> (1991). </year> <title> Introduction to the Theory of Neural Computation. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Hetherington, P. A., and Seidenberg, M. S. </author> <year> (1989). </year> <booktitle> Is there "catastrophic interference" in connectionist networks? In Proceedings of the 11th Annual Conference of the Cognitive Science Society, </booktitle> <pages> 26-33. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference-contexts: Several techniques have been proposed to alleviate forgetting, including using weights with different learning rates (Hinton and Plaut 1987), gradually including new examples and phasing out earlier ones <ref> (Hetherington and Seidenberg 1989) </ref>, forcing semidistributed hidden-layer representations (French 1991), concentrating changes on novel parts of the inputs (Kortge 1990), using units with localized receptive fields (Kruschke 1992), and adding new units and weights to encode new information (Fahlman 1991; Fahlman and Lebiere 1990).
Reference: <author> Hinton, G. E., and Anderson, J. A., </author> <title> editors (1981). Parallel Models of Associative Memory. </title> <address> Hills-dale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Hinton, G. E., and Plaut, D. C. </author> <year> (1987). </year> <title> Using fast weights to deblur old memories. </title> <booktitle> In Proceedings of the Ninth Annual Conference of the Cognitive Science Society, </booktitle> <pages> 177-186. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference-contexts: If the patterns are to be learned incrementally, without repeating the earlier patterns, the later patterns in the sequence erase the earlier associations from memory. Several techniques have been proposed to alleviate forgetting, including using weights with different learning rates <ref> (Hinton and Plaut 1987) </ref>, gradually including new examples and phasing out earlier ones (Hetherington and Seidenberg 1989), forcing semidistributed hidden-layer representations (French 1991), concentrating changes on novel parts of the inputs (Kortge 1990), using units with localized receptive fields (Kruschke 1992), and adding new units and weights to encode new information
Reference: <author> Hopfield, J. J. </author> <year> (1982). </year> <title> Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> Proceedings of the National Academy of Sciences, USA, </booktitle> <volume> 79 </volume> <pages> 2554-2558. </pages>
Reference-contexts: Although it is an abstract model of the hippocampal system, it is consistent with the more low-level models of the hippocampal circuitry, and complements them well. 10.1 The Hopfield model The Hopfield network <ref> (Hopfield 1982) </ref> was originally developed to model the computational properties of neurobiological systems from the perspective of statistical mechanics (Amit et al. 1985a, 1985b; Kirkpatrick and Sherrington 1988; Peretto and Niez 1986). The Hopfield network is characterized by full connectivity, except from a unit to itself. <p> The capacity for the Hopfield network has been shown theoretically to be N=4 ln N (Amit 1989; Hertz et al. 1991; Keeler 1988; McEliece et al. 1986), and experimentally about 0:15N <ref> (Hopfield 1982) </ref>. For the convergence-zone model such a simple closed-form formula is difficult to derive, because the model has many more parameters and correlations that complicate the analysis. However, as was shown above, a lower bound can be derived for a given set of parameters.
Reference: <author> Hopfield, J. J. </author> <year> (1984). </year> <title> Neurons with graded response have collective computational properties like those of two-state neurons. </title> <booktitle> Proceedings of the National Academy of Sciences, USA, </booktitle> <volume> 81 </volume> <pages> 3088-3092. </pages>
Reference: <author> Jessell, E. R. K. </author> <year> (1991). </year> <title> Nerve cells and behavior. </title> <editor> In Kandel, E. R., Schwartz, J. H., and Jessell, T. M., editors, </editor> <booktitle> Principles of Neural Science, </booktitle> <pages> 18-32. </pages> <publisher> Elsevier. </publisher>
Reference-contexts: which is unrealistic, given that the hippocampal formation in higher animals such as the rat is estimated to have about 10 6 primary excitatory neurons with 10 10 connections (Amaral et al. 1990), and the entire human brain is estimated to have about 10 11 neurons and 10 15 synapses <ref> (Jessell 1991) </ref>. These earlier models had a uniform, abstract structure and were not specifically motivated by any particular part of the human memory system.
Reference: <author> Kairiss, E. W., and Miranker, W. L. </author> <year> (1996). </year> <title> Cortical memory dynamics. </title> <type> Technical Report 9604, </type> <institution> Neuroengineering and Neuroscience Center, Yale University, </institution> <address> New Haven, CT. 25 Kanerva, P. </address> <year> (1988). </year> <title> Sparse Distributed Memory. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Keeler, J. D. </author> <year> (1988). </year> <title> Comparison between Kanerva's SDM and Hopfield-type neural networks. </title> <journal> Cognitive Science, </journal> <volume> 12 </volume> <pages> 299-329. </pages>
Reference: <author> Kirkpatrick, S., and Sherrington, D. </author> <year> (1988). </year> <title> Infinite range models of spin-glasses. </title> <journal> Physical Review B, </journal> <volume> 17 </volume> <pages> 4384-4403. </pages>
Reference: <author> Knapp, A. G., and Anderson, J. A. </author> <year> (1984). </year> <title> Theory of categorization based on distributed memory storage. </title> <journal> Journal of Experimental Psychology: Learning, Memory and Cognition, </journal> <volume> 10 </volume> <pages> 616-637. </pages>
Reference: <author> Knudsen, E. I., du Lac, S., and Esterly, S. D. </author> <year> (1987). </year> <title> Computational maps in the brain. </title> <editor> In Cowan, W. M., Shooter, E. M., Stevens, C. F., and Thompson, R. F., editors, </editor> <booktitle> Annual Review of Neuroscience, </booktitle> <pages> 41-65. </pages> <address> Palo Alto: </address> <publisher> Annual Reviews. </publisher>
Reference-contexts: Since the input to the memory consists of sensory experience, in the model it should have a representation similar to the perceptual representations in the brain. The low-level sensory representations are organized into maps, that is, similar sensory inputs are represented by nearby locations on the cortical surface <ref> (Knudsen et al. 1987) </ref>. It is possible that also higher-level representations have a map-like structure.
Reference: <author> Kohonen, T. </author> <year> (1971). </year> <title> A class of randomly organized associative memories. </title> <journal> Acta Polytechnica Scandinavica, </journal> <volume> EL 25. </volume>
Reference: <author> Kohonen, T. </author> <year> (1972). </year> <title> Correlation matrix memories. </title> <journal> IEEE Transactions on Computers, C-21:353-359. </journal>
Reference: <author> Kohonen, T. </author> <year> (1977). </year> <title> Associative Memory: A System-Theoretical Approach. </title> <address> Berlin; Heidelberg; New York: </address> <publisher> Springer. </publisher>
Reference: <author> Kohonen, T. </author> <year> (1989). </year> <title> Self-Organization and Associative Memory. </title> <address> Berlin; Heidelberg; New York: </address> <publisher> Springer. </publisher> <address> Third edition. </address>
Reference: <author> Kohonen, T., and Makisara, K. </author> <year> (1986). </year> <title> Representation of sensory information in self-organizing feature maps. </title> <editor> In Denker, J. S., editor, </editor> <booktitle> Neural Networks for Computing, </booktitle> <pages> 271-276. </pages> <address> New York: </address> <publisher> American Institute of Physics. </publisher>
Reference: <author> Kortge, C. A. </author> <year> (1990). </year> <title> Episodic memory in connectionist networks. </title> <booktitle> In Proceedings of the 12th Annual Conference of the Cognitive Science Society, </booktitle> <pages> 764-771. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference-contexts: Several techniques have been proposed to alleviate forgetting, including using weights with different learning rates (Hinton and Plaut 1987), gradually including new examples and phasing out earlier ones (Hetherington and Seidenberg 1989), forcing semidistributed hidden-layer representations (French 1991), concentrating changes on novel parts of the inputs <ref> (Kortge 1990) </ref>, using units with localized receptive fields (Kruschke 1992), and adding new units and weights to encode new information (Fahlman 1991; Fahlman and Lebiere 1990).
Reference: <author> Kruschke, J. K. </author> <year> (1992). </year> <title> ALCOVE: An exemplar-based connectionist model of category learning. </title> <journal> Psychological Review, </journal> <volume> 99 </volume> <pages> 22-44. </pages>
Reference-contexts: proposed to alleviate forgetting, including using weights with different learning rates (Hinton and Plaut 1987), gradually including new examples and phasing out earlier ones (Hetherington and Seidenberg 1989), forcing semidistributed hidden-layer representations (French 1991), concentrating changes on novel parts of the inputs (Kortge 1990), using units with localized receptive fields <ref> (Kruschke 1992) </ref>, and adding new units and weights to encode new information (Fahlman 1991; Fahlman and Lebiere 1990). In these models, one-shot storage is still not possible, although the number of required iterations is reduced, and old information can be relearned very fast.
Reference: <author> Little, W. A., and Shaw, G. L. </author> <year> (1975). </year> <title> A statistical theory of short and long term memory. </title> <journal> Behavioral Biology, </journal> <volume> 14 </volume> <pages> 115-133. </pages>
Reference: <author> Marr, D. </author> <year> (1971). </year> <title> Simple memory: A theory for archicortex. </title> <journal> Philosophical Transactions of the Royal Society of London B, </journal> <volume> 262 </volume> <pages> 23-81. </pages>
Reference: <author> McClelland, J. L., McNaughton, B. L., and O'Reilly, R. C. </author> <year> (1995). </year> <title> Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory. </title> <journal> Psychological Review, </journal> <volume> 102 </volume> <pages> 419-457. </pages>
Reference: <author> McClelland, J. L., and Rumelhart, D. E. </author> <year> (1986a). </year> <title> Amnesia and distributed memory. </title> <editor> In Rumel-hart, D. E., and McClelland, J. L., editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 2: Psychological and Biological Models, </booktitle> <pages> 503-527. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. 26 McClelland, </publisher> <editor> J. L., and Rumelhart, D. E. </editor> <year> (1986b). </year> <title> A distributed model of human learning and memory. </title> <editor> In McClelland, J. L., and Rumelhart, D. E., editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 2: Psychological and Biological Models, </booktitle> <pages> 170-215. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> McCloskey, M., and Cohen, N. J. </author> <year> (1989). </year> <title> Catastrophic interference in connectionist networks: The sequential learning problem. </title> <journal> The Psychology of Learning and Motivation, </journal> <volume> 24 </volume> <pages> 104-169. </pages>
Reference: <author> McEliece, R. J., Posner, E. C., Rodemich, E. R., and Venkatesh, S. S. </author> <year> (1986). </year> <title> The capacity of the hopfield associative memory. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 33 </volume> <pages> 461-482. </pages>
Reference: <author> McNaughton, B. L., and Morris, R. G. M. </author> <year> (1987). </year> <title> Hippocampal synaptic enhancement and information storage within a distributed memory system. </title> <journal> Trends in Neuroscience, </journal> <volume> 10 </volume> <pages> 408-415. </pages>
Reference: <author> Merzenich, M. M., Nelson, R. J., Stryker, M. P., Cynader, M. S., Schoppmann, A., and Zook, J. M. </author> <year> (1984). </year> <title> Somatosensory cortical map changes following digit amputation in adult monkeys. </title> <journal> Journal of Comparative Neurology, </journal> <volume> 224 </volume> <pages> 591-605. </pages>
Reference: <author> Miikkulainen, R. </author> <year> (1992). </year> <title> Trace feature map: A model of episodic associative memory. </title> <journal> Biological Cybernetics, </journal> <volume> 67 </volume> <pages> 273-282. </pages>
Reference: <author> Miikkulainen, R. </author> <year> (1993). </year> <title> Subsymbolic Natural Language Processing: An Integrated Model of Scripts, Lexicon, and Memory. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Miller, K. D., and MacKay, D. J. C. </author> <year> (1992). </year> <title> The role of constrains in Hebbian learning. CNS Memo 19, Computation and Neural Systems Program, </title> <institution> California Institute of Technology, Pasadena, </institution> <address> CA. </address>
Reference: <author> Milner, P. </author> <year> (1989). </year> <title> A cell assembly theory of hippocampal amnesia. </title> <journal> Neuropshychologia, </journal> <volume> 27 </volume> <pages> 23-30. </pages>
Reference: <author> Murre, J. M. J. </author> <year> (1995). </year> <title> A model of amnesia. </title> <type> Manuscript. </type>
Reference: <author> O'Reilly, R. C., and McClelland, J. L. </author> <year> (1994). </year> <title> Hippocampal conjunctive encoding, storage, and recall: Avoiding a trade-off. </title> <journal> Hippocampus, </journal> <volume> 4 </volume> <pages> 661-682. </pages>
Reference: <author> Palm, G. </author> <year> (1980). </year> <title> On associative memory. </title> <journal> Biological Cybernetics, </journal> <volume> 36 </volume> <pages> 19-31. </pages>
Reference: <author> Palm, G. </author> <year> (1981). </year> <title> On the storage capacity of an associative memory with randomly distributed storage elements. </title> <journal> Biological Cybernetics, </journal> <volume> 39 </volume> <pages> 125-127. </pages>
Reference: <author> Peretto, P., and Niez, J. </author> <year> (1986). </year> <title> Collective properties of neural networks. </title> <editor> In Bienenstock, E., Fo-gelman Soulie, F., and Weisbuch, G., editors, </editor> <booktitle> Disordered Systems and Biological Organization, </booktitle> <pages> 171-185. </pages> <address> Berlin; Heidelberg; New York: </address> <publisher> Springer. </publisher>
Reference: <author> Ratcliff, R. </author> <year> (1990). </year> <title> Connectionist models of recognition memory: Constraints imposed by learning and forgetting functions. </title> <journal> Psychological Review, </journal> <volume> 97 </volume> <pages> 285-308. </pages>
Reference: <author> Read, W., Nenov, V. I., and Halgren, E. </author> <year> (1994). </year> <title> Role of inhibition in memory retrieval by hip-pocampal area CA3. </title> <journal> Neuroscience and Biobehavioral Reviews, </journal> <volume> 18 </volume> <pages> 55-68. </pages>
Reference: <author> Ritter, H. J. </author> <year> (1991). </year> <title> Asymptotic level density for a class of vector quantization processes. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 2 </volume> <pages> 173-175. </pages> <note> 27 Rolls, </note> <author> E. T. </author> <year> (1984). </year> <title> Neurons in the cortex of the temporal lobe and in the amygdala of the monkey with responses selective for faces. </title> <journal> Human Neurobiology, </journal> 3:209-222. 
Reference: <author> Schmajuk, N. A., and DiCarlo, J. J. </author> <year> (1992). </year> <title> Stimulus configuration, classical conditioning, and hippocampal function. </title> <journal> Psychological Review, </journal> <volume> 99 </volume> <pages> 268-305. </pages>
Reference: <author> Sejnowski, T. J., and Churchland, P. S. </author> <year> (1989). </year> <title> Brain and cognition. </title> <editor> In Posner, M. I., editor, </editor> <booktitle> Foundations of Cognitive Science, chapter 8, </booktitle> <pages> 315-356. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: It is reasonable to assume feature maps with 10 6 of such columns <ref> (Sejnowski and Churchland 1989) </ref>. Each input activates a local area on the map, including perhaps 10 2 columns above threshold. Therefore, the feature maps could be approximated with 10 4 computational units.
Reference: <author> Squire, L. R. </author> <year> (1987). </year> <title> Memory and Brain. </title> <publisher> Oxford, </publisher> <address> UK; New York: </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: Episodic memory is characterized by extreme efficiency and high capacity. New memories are formed every few seconds, and many of those persist for years, even decades <ref> (Squire 1987) </ref>. Another fl An earlier version of this paper appeared in Neural Networks, 10:1017-1036, 1997. y Acknowledgements: We thank Greg Plaxton for pointing us to martingale analysis on this problem, and two anonymous reviewers for references on hippocampal modeling, and for suggesting experiments with sparse connectivity.
Reference: <author> Squire, L. R. </author> <year> (1992). </year> <title> Memory and the hippocampus: A synthesis from findings with rats, monkeys, and humans. </title> <journal> Psychological Review, </journal> <volume> 99 </volume> <pages> 195-231. </pages>
Reference: <author> Squire, L. R., Shimamura, A. P., and Amaral, D. G. </author> <year> (1989). </year> <title> Memory and the hippocampus. In Byrne, </title> <editor> J. H., and Berry, W. O., editors, </editor> <booktitle> Neural Models of Plasticity, </booktitle> <pages> 208-239. </pages> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Steinbuch, K. </author> <year> (1961). </year> <title> Die lernmatrix. </title> <journal> Kybernetic, </journal> <volume> 1 </volume> <pages> 36-45. </pages>
Reference-contexts: There is no distinction between key and data fields either; every feature map can function as a key in the convergence-zone model. Other related statistical models include the learning matrix <ref> (Steinbuch 1961) </ref> and the associative net (Willshaw et al. 1969), which are precursors of the correlation matrix model. These had a uniform matrix structure connecting inputs to outputs in a single step.
Reference: <author> Sutherland, R. W., and Rudy, J. W. </author> <year> (1989). </year> <title> Configural association theory: The role of the hip-pocampal formation in learning, memory and amnesia. </title> <journal> Psychobiology, </journal> <volume> 17 </volume> <pages> 129-144. </pages>
Reference: <author> Teyler, T. J., and Discenna, P. </author> <year> (1986). </year> <title> The hippocampal memory indexing theory. </title> <journal> Behavioral Neuroscience, </journal> <volume> 100 </volume> <pages> 147-154. </pages>
Reference: <author> Treves, A., and Rolls, E. T. </author> <year> (1991). </year> <title> What determines the capacity of autoassociative memories in the brain? Network, </title> <booktitle> 2 </booktitle> <pages> 371-398. </pages>
Reference: <author> Treves, A., and Rolls, E. T. </author> <year> (1994). </year> <title> Computational analysis of the role of the hippocampus in memory. </title> <journal> Hippocampus, </journal> <volume> 4 </volume> <pages> 374-391. </pages>
Reference: <author> Tulving, E. </author> <year> (1972). </year> <title> Episodic and semantic memory. </title> <editor> In Tulving, E., and Donaldson, W., editors, </editor> <booktitle> Organization of Memory, </booktitle> <pages> 381-403. </pages> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference-contexts: 1 Introduction Human memory system can be divided into semantic memory of facts, rules, and general knowledge, and episodic memory that records the individual's day-to-day experiences <ref> (Tulving 1972, 1983) </ref>. Episodic memory is characterized by extreme efficiency and high capacity. New memories are formed every few seconds, and many of those persist for years, even decades (Squire 1987).
Reference: <author> Tulving, E. </author> <year> (1983). </year> <title> Elements of Episodic Memory. </title> <publisher> Oxford, </publisher> <address> UK; New York: </address> <publisher> Oxford University Press. </publisher>
Reference: <author> Wickelgren, W. A. </author> <year> (1979). </year> <title> Chunking and consolidation: A theoretical synthesis of semantic networks, configuring, S-R versus cognitive learning, normal forgetting, the amnesic syndrome, </title> <journal> and the hippocampal arousal system. Psychological Review, </journal> <volume> 86 </volume> <pages> 44-60. </pages>
Reference: <author> Willshaw, D. J., Buneman, O. P., and Longuet-Higgins, H. C. </author> <year> (1969). </year> <title> Non-holographic associative memory. </title> <journal> Nature, </journal> <volume> 222 </volume> <pages> 960-962. </pages>
Reference-contexts: There is no distinction between key and data fields either; every feature map can function as a key in the convergence-zone model. Other related statistical models include the learning matrix (Steinbuch 1961) and the associative net <ref> (Willshaw et al. 1969) </ref>, which are precursors of the correlation matrix model. These had a uniform matrix structure connecting inputs to outputs in a single step.
Reference: <author> Wilson, M. A., and McNaughton, B. L. </author> <year> (1993). </year> <title> Dynamics of the hippocampal ensemble code for space. </title> <journal> Science, </journal> <volume> 261 </volume> <pages> 1055-1058. 28 </pages>
References-found: 83

