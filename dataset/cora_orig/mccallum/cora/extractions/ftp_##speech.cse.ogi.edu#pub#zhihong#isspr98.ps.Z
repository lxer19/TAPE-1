URL: ftp://speech.cse.ogi.edu/pub/zhihong/isspr98.ps.Z
Refering-URL: http://cslu.cse.ogi.edu/people/hu/index.html
Root-URL: http://www.cse.ogi.edu
Email: fax:(503)690-1306 (zhihong@cse.ogi.edu)  
Title: Speaker Normalization using Correlations Among Classes (ISSPR'98) for Spoken Language Understanding hypothesis are tested in
Author: Zhihong Huy, Etienne Barnardy and Pieter Vermeuleny 
Note: These  
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000, USA,  
Affiliation: Center  Oregon Graduate Institute of Science and Technology  
Abstract: In this research, we study the relationship amongst speakers and different sounds in speech, investigate the relevant features to represent this relationship, and explore the applications in speaker normalization/adaptation. We propose a new method which incorporate correlations amongst classes. Using principal component analysis we construct a speaker space based on a speaker covari-ance matrix obtained from the training data. The speaker covariance matrix is constructed in such a manner as to explicitly describe the correlations between classes. By explicitly modeling these correlations it is possible to adapt the model or normalize the speaker's features. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Eide and H. Gish, </author> <title> "A parametric approach to vocal tract length normalization," </title> <booktitle> Proceedings of ICASSP, </booktitle> <pages> pp. 346-348, </pages> <year> 1996. </year>
Reference-contexts: The features used in speech recognition systems are based on the model of the ear rather than an explicit vocal tract model. These features are typically cepstral transformations of the warped (MEL scale or Bark scale) frequency spectrum and do not explicitly model the vocal tract. Eide and Gish <ref> [1] </ref> use a parametric normalization method which counteracts the effect of var ied vocal tract length. In this work and similar work done by others [2, 3] the vocal tract length variation is crudely compensated for by finding an appropriate linear scaling of the warped frequency axis.
Reference: [2] <author> T. Kamm, A. Andreou, and J. Cohen, </author> <title> "Vocal tract normalization in speech recognition: Compensating for systematic speaker variability," </title> <year> 1995. </year>
Reference-contexts: Eide and Gish [1] use a parametric normalization method which counteracts the effect of var ied vocal tract length. In this work and similar work done by others <ref> [2, 3] </ref> the vocal tract length variation is crudely compensated for by finding an appropriate linear scaling of the warped frequency axis. Methods such as maximum likelihood linear regression (MLLR) [4, 5] adapt the acoustic models rather than the acoustic features.
Reference: [3] <author> D. Burnett, </author> <title> Rapid Speaker Adaptation for Neural Network Speech Recognizers. </title> <type> PhD thesis, </type> <institution> Oregon Graduate Institute, </institution> <month> Decem-ber </month> <year> 1996. </year>
Reference-contexts: Eide and Gish [1] use a parametric normalization method which counteracts the effect of var ied vocal tract length. In this work and similar work done by others <ref> [2, 3] </ref> the vocal tract length variation is crudely compensated for by finding an appropriate linear scaling of the warped frequency axis. Methods such as maximum likelihood linear regression (MLLR) [4, 5] adapt the acoustic models rather than the acoustic features.
Reference: [4] <author> V. Leggetter, </author> <title> Statistical Trajectory Models for Phonetic Recognition. </title> <type> PhD thesis, </type> <institution> Cam-bridge University, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: In this work and similar work done by others [2, 3] the vocal tract length variation is crudely compensated for by finding an appropriate linear scaling of the warped frequency axis. Methods such as maximum likelihood linear regression (MLLR) <ref> [4, 5] </ref> adapt the acoustic models rather than the acoustic features. The models are adapted using a set of linear transformations, which were estimated in a maximum likelihood fashion using the adaptation data.
Reference: [5] <author> M. Gales and P. Woodland, </author> <title> "Variance compensation within the MLLR framework," </title> <type> Tech. Rep. </type> <institution> CUED/F-INFENG/TR242, Cambridge University, </institution> <month> February </month> <year> 1996. </year>
Reference-contexts: In this work and similar work done by others [2, 3] the vocal tract length variation is crudely compensated for by finding an appropriate linear scaling of the warped frequency axis. Methods such as maximum likelihood linear regression (MLLR) <ref> [4, 5] </ref> adapt the acoustic models rather than the acoustic features. The models are adapted using a set of linear transformations, which were estimated in a maximum likelihood fashion using the adaptation data.
Reference: [6] <author> S. Cox, </author> <title> "Predictive speaker adaptation in speech recognition," </title> <booktitle> Computer Speech and Language, </booktitle> <volume> vol. 9, </volume> <pages> pp. 1-17, </pages> <year> 1995. </year>
Reference-contexts: If we can compute a model transformation to adapt one class, e.g /ah/, there should be a reasonable amount of information to form the transformation for another vowel such as /eh/. Cox <ref> [6] </ref> presented an approach that use training data to build linear models between sounds. With this method it is possible to adapt unseen classes using this linear relationship obtained from the training data. This method, however assumes the relation between classes are identical for all speakers.
Reference: [7] <author> J. Hillenbrand, L. Getty, M. Clark, and K. Wheeler, </author> <title> "Acoustic characteristics of american english vowels," </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> vol. 97, no. 5, </volume> <pages> pp. 3099-3111, </pages> <year> 1995. </year>
Reference-contexts: The Hillenbrand data set is an extension of the Peterson & Barney data which were collected at the University of Michigan <ref> [7] </ref>. In this data set, F 1 -F 4 contours are measured for 12 vowels in the /h-V-d/ context for 45 men, 48 women, and 46 children. This data set has extra dynamic information compared to the Peterson and Barney data.
Reference: [8] <author> L. Welling and H. Ney, </author> <title> "A model for efficient formant estimation," </title> <booktitle> in icassp, </booktitle> <pages> pp. 797-800, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: In our study, the features we use are mostly formants. The three formant frequency values for for each vowel in the TIMIT data set are estimated using a formant estimation method proposed by Welling and Ney <ref> [8] </ref>, followed by a heuristic formant tracking algorithm. 3.2 Physical meaning of the speaker space In this section, we investigate the relationship between the model we proposed and that of the speech production. The studies are conducted on Hillenbrand data.
References-found: 8

