URL: http://www.cs.colorado.edu/~grunwald/LowPowerWorkshop/FinalPapers/PS/kogge-notredame.ps
Refering-URL: http://www.cs.colorado.edu/~grunwald/LowPowerWorkshop/agenda.html
Root-URL: http://www.cs.colorado.edu
Title: Split Register File Architectures for Inherently Lower Power Microprocessors  
Author: V. Zyuban and P. Kogge 
Address: IN 46556, USA  
Affiliation: Computer Science Eng. Department, University of Notre Dame,  
Abstract: Register files represent a substantial portion of the energy budget in modern processors, and are growing rapidly with the trend towards wider instruction issue. The actual access energy costs depend greatly on the register file circuitry and technology used. However, according to a recent study, it appears that neither technology scaling nor circuitry techniques will prevent centralized register files from becoming the dominant power component of next-generation superscalar processors. This paper studies alternative methods for inter-instruction communication as to their energy efficiency and begins to lay out approaches at the architectural level that would allow inherently more energy-efficient computations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. E. Breach, T. N. Vijaykumar, and G. S. Sohi, </author> <title> The Anatomy of the Register File in a Multiscalar Processor, </title> <booktitle> Proc. 27th Annual Int'l Symp. on Microarchitecture, </booktitle> <pages> pp. 181-190, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Since the assignment of an operation to a functional unit is done at compile time, VLIW compiler must carefully choose 2 a cluster for every operation and a register file bank where the result will be written. 4.2 Multiscalar Architecture The Multiscalar architecture <ref> [1, 6, 7] </ref> executes code segments identified at compile time in parallel on multiple processing elements organized as a circular chain.
Reference: [2] <author> B. Cmelik, </author> <title> The SHADE Simulator, </title> <type> Sun-Labs Technical Report, </type> <year> 1993. </year>
Reference-contexts: To evaluate the efficiency of the opcode-based steering we set up an experiment, based on the SPARC instruction set simulator Shade <ref> [2] </ref>. The methodology of the experiment was as follows: Each entry in the simulated physical register array has a tag that shows in which register file the data is being stored. All read accesses to register files are recorded in a matrix.
Reference: [3] <author> R. Colwell, et al., </author> <title> A VLIW Architecture for a Trace Scheduling Compiler, </title> <journal> IEEE Transactions on Computers, pp. </journal> <volume> 967979, NO. 8, </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: However, thus far researchers have been primarily concerned with access times, not energy costs. 4.1 Limited Connectivity VLIWs The ideal VLIW architecture would be a machine with many functional units connected to a single central register file <ref> [3] </ref>. This organization would enable any operation to be carried out on any available function unit, simplifying code generation. <p> To avoid the degradation in performance caused by multi-porting a single register file researchers have suggested partitioning the register file into banks, so that each functional unit is connected to a specific bank <ref> [3, 15] </ref>. Some kind of crossover provides a limited access to the registers from other banks. Every operation specifies its destination bank at compile time. This arrangement alleviates the problem with the number of ports, but brings about the problem of inter-bank data traffic.
Reference: [4] <author> K. Farkas, N. Jouppi, P. Chow, </author> <title> Register File Design Considerations in Dynamically Scheduled Processors. </title> <type> Technical Report 95/10, </type> <institution> Digital Equipment Corporation Western Research Lab, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: To estimate the number of registers we used the results in <ref> [4] </ref>, where it was found that for a four-issue and eight-issue machines the performance saturates around 80 and 128 registers, respectively. Based on this data, and assuming that 40 registers is sufficient for a single issue machine, we extrapolate the dependence linearly to two-issue and 16-issue machines. <p> Suppose we have a superscalar processor capable of issuing IW instruction in parallel. Using the above assumptions, a conventional centralized register file would have N read;centr = 2IW , read ports and N write;centr = IW write ports, and N reg;centr N 0 + 12 fi IW physical registers <ref> [4] </ref>. Ideally, we would like to partition the centralized register file into m local register files (m &lt; IW ) in such a way that every local register file has N ports;local = 1 m N ports;centr ports, and N reg;local = 1 m N reg;centr entries.
Reference: [5] <author> M. Franklin and G. S. Sohi, </author> <title> Register Traffic Analysis for Streamlining Inter-Operation Communication in Fine-Grain Parallel Processors, </title> <booktitle> Proc. 25th Annual Int'l Symp. on Microarchitecture, </booktitle> <pages> pp. 236-245, </pages> <year> 1992. </year>
Reference-contexts: Typically, around half the registers written by a small trace line (16 or 24 instructions) are not live beyond the trace line. The proportion of such local registers increases for larger trace lines <ref> [5] </ref>. In the Trace Window architecture, locally live destination registers are renamed to a physical register file local to the trace line; live-on-exit destination registers are renamed to a global register file. <p> We expect to see a more significant saturation of scheduling improvement for the analysis window sizes around 32 instructions, because most of the register instances are consumed within 32 instructions <ref> [5] </ref>. The results show that different optimization target result in quite different traffic-delay tradeoffs. By increasing the weight of the traffic cost we place more emphasis on minimization of the traffic cost, however, this also results in performance decrease (higher CPI).
Reference: [6] <author> M. Franklin and G. S. Sohi, </author> <title> The Expandable Split Window Architecture for Exploiting Fine-Grain Parallelism, </title> <booktitle> Proc. 19th Annual Int'l Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1992. </year>
Reference-contexts: Since the assignment of an operation to a functional unit is done at compile time, VLIW compiler must carefully choose 2 a cluster for every operation and a register file bank where the result will be written. 4.2 Multiscalar Architecture The Multiscalar architecture <ref> [1, 6, 7] </ref> executes code segments identified at compile time in parallel on multiple processing elements organized as a circular chain.
Reference: [7] <author> M. Franklin, </author> <title> The Multiscalar Architecture, </title> <type> Ph.D. Thesis, </type> <institution> University of Wisconsin-Madison, </institution> <type> Tech. Report 1196, </type> <month> November </month> <year> 1993. </year>
Reference-contexts: Since the assignment of an operation to a functional unit is done at compile time, VLIW compiler must carefully choose 2 a cluster for every operation and a register file bank where the result will be written. 4.2 Multiscalar Architecture The Multiscalar architecture <ref> [1, 6, 7] </ref> executes code segments identified at compile time in parallel on multiple processing elements organized as a circular chain.
Reference: [8] <author> R. Gonzalez and M. Horowitz, </author> <title> Energy Dissipation in General Purpose Microprocessors, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 31, No. 9, </volume> <month> September </month> <year> 1996. </year>
Reference-contexts: This leads to the growth of the on-chip hardware, and dissipated power. Energy-delay product, delay operation fi energy operation , or its inverse SP EC 2 W , seem to be a reasonable metric for power efficiency of a design <ref> [8] </ref>. Smaller energy-delay values imply a lower energy solution at the same level of performance a more energy-efficient design. Reference [10] described and analyzed those portions of a microarchitecture where complexity, and consequently power grow with increasing instruction issue width.
Reference: [9] <author> H. Kojima, </author> <title> et al.,Power Analysis of a Programmable DSP for Architecture/Program Optimization,IEEE Symposium on Low Power Electronics, </title> <address> San Jose, </address> <pages> pp. 2627, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: const + N change fi E change , where E const is a constant energy independent of the data activity at the inputs, N change is the average number of bit transitions at the inputs in one clock cycle, and E change is a coefficient specific for every processing unit <ref> [9, 12] </ref>. By steering instructions that access the same registers to the same processing unit cluster we increase the probability that operand values of these instructions are correlated, and thereby reduce the average number of bit transitions at the inputs of functional units. <p> Runs with higher weight of the traffic cost resulted in more significant reductions in data switching activity. The observed reduction in the switching activity could result in up to 10% reduction in the dissipated power of the corresponding functional units <ref> [9, 12] </ref>. The reduction in the switching activities at the inputs and outputs of local register files was even more significant, up to 17%. This could be used to further reduce the access energy to local register files [17].
Reference: [10] <author> S. Palacharla, N. Jouppi, J. Smith, </author> <title> Complexity-Effective Superscalar Processor. </title> <booktitle> In: Proceedings of the 24th Annual International Symposium on Computer Architecture. </booktitle> <pages> pp. </pages> <address> 206218, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Energy-delay product, delay operation fi energy operation , or its inverse SP EC 2 W , seem to be a reasonable metric for power efficiency of a design [8]. Smaller energy-delay values imply a lower energy solution at the same level of performance a more energy-efficient design. Reference <ref> [10] </ref> described and analyzed those portions of a microarchitecture where complexity, and consequently power grow with increasing instruction issue width. Among them are: register rename logic, wakeup and selection logic, data bypass logic, register files, caches and instruction fetch logic. <p> The suggested split register file architecture is similar to the dependence-based architecture that was proposed in <ref> [10] </ref> to simplify wakeup and select logic (which was found to be the most critical in terms of the delay complexity), and thus allow faster clocking. In the dependence-based architecture the instruction issue window is replaced with a number of FIFO buffers, each queue holding a chain of dependent instructions. <p> Instructions from multiple queues are issue in parallel. The key difference between our approach and the dependence-based architecture is that the register file in the dependence-based architecture is not partitioned into register files local to clusters. Also, the dependence-based architecture has not been studied for energy efficiency in <ref> [10] </ref>. Before going any further the efficiency of the idea must be evaluated.
Reference: [11] <institution> U.S. </institution> <note> Patent No. 5,657,291, issued Aug. 12, 1997 to A. </note> <author> Podlesny, G. Kristovsky, A. Malshin, </author> <title> Multiport Register File Memory Cell Configuration for Read Operation. </title>
Reference-contexts: We did a study for various circuit organizations of the RF, and tried to find the lower bound on the access energy. The study showed that even when the Port Priority Selection (PPS) technique <ref> [11] </ref> is applied, combined with double-ended reads and low-swing writes (which was found to be the most energy efficient), still the access energy grows significantly as the number of ports and the number of registers increases, Fig. 1.
Reference: [12] <author> T. Sato, </author> <title> et al.,Evaluation of Architecture-level Power Estimation for CMOS RISC Processors,IEEE Symposium on Low Power Electronics, </title> <address> San Jose, </address> <pages> pp. 4445, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: const + N change fi E change , where E const is a constant energy independent of the data activity at the inputs, N change is the average number of bit transitions at the inputs in one clock cycle, and E change is a coefficient specific for every processing unit <ref> [9, 12] </ref>. By steering instructions that access the same registers to the same processing unit cluster we increase the probability that operand values of these instructions are correlated, and thereby reduce the average number of bit transitions at the inputs of functional units. <p> Runs with higher weight of the traffic cost resulted in more significant reductions in data switching activity. The observed reduction in the switching activity could result in up to 10% reduction in the dissipated power of the corresponding functional units <ref> [9, 12] </ref>. The reduction in the switching activities at the inputs and outputs of local register files was even more significant, up to 17%. This could be used to further reduce the access energy to local register files [17].
Reference: [13] <author> M. Tremblay, B. Joy and K. Shin, </author> <title> A Three Dimensional Register File For Superscalar Processors. </title> <booktitle> In: Proceedings of the 28th Annual Hawaii International Conference on System Sciences. </booktitle> <pages> pp. </pages> <address> 191201, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: The silicon area of a multiported memory, built using conventional approaches, grows quadratically in the number of ports <ref> [13] </ref>. Therefore, taking into account growth both in storage needs and the number of ports, we should expect that the power portion of such multi-ported on-chip memories will grow rapidly in the future.
Reference: [14] <author> M. Tremblay, D. Greenley and K. Normoyle, </author> <title> The Design of the Microarchitecture of UltraSPARC TM -I, </title> <booktitle> Proceedings of the IEEE. </booktitle> <pages> pp. 165311663, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: For an Amdahl's law-like ff of 0:5 <ref> [14] </ref> the fl is between 3 and 4:6! bar) and a conventional RF architecture (2nd bar) versus issue width, 0:5 feature size, V dd = 3:3V .
Reference: [15] <author> J. Turley and H. Hakkarainen, </author> <title> TI's New 'C6x DSP Screams at 1,600 MIPS, Microprocessor Report, </title> <journal> pp. </journal> <volume> 14 17, </volume> <month> February 17, </month> <year> 1997. </year>
Reference-contexts: To avoid the degradation in performance caused by multi-porting a single register file researchers have suggested partitioning the register file into banks, so that each functional unit is connected to a specific bank <ref> [3, 15] </ref>. Some kind of crossover provides a limited access to the registers from other banks. Every operation specifies its destination bank at compile time. This arrangement alleviates the problem with the number of ports, but brings about the problem of inter-bank data traffic.
Reference: [16] <author> S. Vajapeyam and T. Miltra, </author> <title> Improving Superscalar Instruction Dispatch and Issue by Exploiting Dynamic Code Sequences, </title> <booktitle> Proc. 24th Annual Int'l Symposium on Computer Architecture, </booktitle> <month> June, </month> <year> 1997. </year>
Reference-contexts: Finding appropriate static program chunks and load balancing across the processing elements, as well as identification of the last possible register instances, are some of the issues that arise in this approach. 4.3 Trace Window Architecture The partitioning of the physical register file in the Trace Window architecture <ref> [16] </ref> is based on the fact that not all physical registers are live beyond the trace line that produces them. Typically, around half the registers written by a small trace line (16 or 24 instructions) are not live beyond the trace line.
Reference: [17] <author> V. Zyuban, P. Kogge, </author> <title> The Energy Complexity of Register Files, </title> <booktitle> IEEE Symposium on Low Power Electronics and Design, </booktitle> <address> Monterey, </address> <month> August </month> <year> 1998. </year> <month> 6 </month>
Reference-contexts: Therefore, taking into account growth both in storage needs and the number of ports, we should expect that the power portion of such multi-ported on-chip memories will grow rapidly in the future. In our recent work <ref> [17] </ref> we studied the dependence of the access energy to a multiported register file upon the number of read and write ports, and the number of registers in the register file. <p> The reduction in the switching activities at the inputs and outputs of local register files was even more significant, up to 17%. This could be used to further reduce the access energy to local register files <ref> [17] </ref>. In the experiments described above we analyzed properties of code, avoiding implementation details as much as possible. As a next step we plan to come up with certain implementation that would allow us to take advantage of the discovered properties.
References-found: 17

