URL: http://www.eecis.udel.edu:80/~jchu/icmas95.ps
Refering-URL: http://www.eecis.udel.edu:80/~jchu/
Root-URL: http://www.cis.udel.edu
Email: E-mail: fjchu,carberryg@cis.udel.edu  
Title: Communication for Conflict Resolution in Multi-Agent Collaborative Planning  
Author: Jennifer Chu-Carroll and Sandra Carberry 
Address: 19716, USA  
Affiliation: Department of Computer and Information Sciences University of Delaware Newark, DE  
Date: 49-56, 1995  
Note: Proceedings of the First Int'l Conference on Multiagent Systems, pp.  
Abstract: Conflict management, communication, and negotiation are important components of collaborative multi-agent activity. Thus, a collaborative agent must be able to handle situations in which conflicts arise and must be capable of negotiating with other agents to reach an agreement. This paper presents a model which 1) captures multi-agent collaboration in a Propose-Evaluate-Modify cycle of actions, 2) initiates negotiation with the executing agent to resolve detected conflicts regarding proposed actions and proposed beliefs, 3) selects the focus of the modification process when multiple conflicts arise, and 4) handles the negotiation of proposed domain actions, proposed problem-solving actions, and proposed beliefs in a unified manner. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. </author> <year> 1991. </year> <title> Discourse structure in the TRAINS project. </title> <booktitle> In Darpa Speech and Natural Language Workshop. </booktitle>
Reference-contexts: Therefore, we separate the dialogue model into an existing model and a set of proposed additions, following Allen who differentiated among private, proposed, and shared modules of beliefs <ref> (Allen 1991) </ref>. For example, suppose that earlier dialogue suggests that EA has the goal of getting a Bachelor of Arts degree (Get-Bach-Arts (EA)).
Reference: <author> Bratman, M. </author> <year> 1990. </year> <title> What is intention? In Cohen; Morgan; and Pollack., eds., Intentions in Communication. </title> <publisher> MIT Press. </publisher> <pages> chapter 2, 15-31. </pages>
Reference-contexts: The agents involved in such collaboration bring to the plan construction task different knowledge about the domain and the desirable characteristics of the domain plan. In particular, EA has knowledge about his particular circumstances and preferences that are potential influencers <ref> (Bratman 1990) </ref> of the domain plan being developed.
Reference: <author> Cawsey, A.; Galliers, J.; Logan, B.; Reece, S.; and Sparck Jones, K. </author> <year> 1993. </year> <title> Revising beliefs and intentions: A unified framework for agent interaction. </title> <booktitle> In The Ninth Biennial Conference of the Society for the Study of Artificial Intelligence and Simulation of Be-haviour, </booktitle> <pages> 130-139. </pages>
Reference-contexts: are not trying to enforce their views on one another or to maximize their own benefits, but rather are trying to share their individual knowledge and beliefs in order to determine what really is best (Chu-Carroll & Carberry 1995b). 6 The strength of an agent's beliefs is modeled with endorsements <ref> (Cawsey et al. 1993) </ref>, which are explicit records of factors that affect one's certainty in a hypothesis (Cohen 1985). Our endorsements include the semantics of the utterance used to convey a belief, the level of expertise of the agent conveying the belief, stereotypical knowledge, etc.
Reference: <author> Chu-Carroll, J., and Carberry, S. </author> <year> 1994. </year> <title> A plan-based model for response generation in collaborative task-oriented dialogues. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 799-805. </pages>
Reference: <author> Chu-Carroll, J., and Carberry, S. </author> <year> 1995a. </year> <title> Generating information-sharing subdialogues in expert-user consultation. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence. </booktitle>
Reference: <author> Chu-Carroll, J., and Carberry, S. </author> <year> 1995b. </year> <title> Response generation in collaborative negotiation. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 136-143. </pages>
Reference: <author> Cohen, P. R. </author> <year> 1985. </year> <title> Heuristic Reasoning about Uncertainty: An Artificial Intelligence Approach. </title> <publisher> Pitman Publishing Company. </publisher>
Reference-contexts: rather are trying to share their individual knowledge and beliefs in order to determine what really is best (Chu-Carroll & Carberry 1995b). 6 The strength of an agent's beliefs is modeled with endorsements (Cawsey et al. 1993), which are explicit records of factors that affect one's certainty in a hypothesis <ref> (Cohen 1985) </ref>. Our endorsements include the semantics of the utterance used to convey a belief, the level of expertise of the agent conveying the belief, stereotypical knowledge, etc.
Reference: <author> Conry, S. E.; Meyer, R. A.; and Lesser, V. R. </author> <year> 1988. </year> <title> Multistage negotiation in distributed planning. </title>
Reference-contexts: Related Work Researchers have developed conflict resolution strategies for various types of conflicts, including resolving conflicting goals between non-fully cooperative agents (Sycara 1989), resolving conflicts in resource allocation among cooperative agents <ref> (Conry, Meyer, & Lesser 1988) </ref>, resolving conflicts between coordinating sub-problems in distributed problem-solving (Klein 1991; Lander & Lesser 1992), maintaining consistency among beliefs of computational agents (Huhns & Bridgeland 1991), etc. In addition, Rosenschein and Zlotkin (1994) proposed a general theory characterizing the relationship between domains and appropriate negotiation mechanisms.
Reference: <editor> In Bond, A. H., and Gasser, L., eds., </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc. </publisher> <pages> 367-383. </pages>
Reference: <author> Elzer, S.; Chu-Carroll, J.; and Carberry, S. </author> <year> 1994. </year> <title> Recognizing and utilizing user preferences in collaborative consultation dialogues. </title> <booktitle> In Proceedings of the Fourth International Conference on User Modeling, </booktitle> <pages> 19-24. </pages>
Reference-contexts: A plan is considered suboptimal if there exists a better way to perform the desired action. We evaluate the optimality of a plan with respect to EA's preferences <ref> (Elzer, Chu-Carroll, & Carberry 1994) </ref>. The evaluation of actions is a top-down process which terminates as soon as a conflict regarding an action or parent-child relationship is detected, since conflicts about child actions are irrelevant if the parent action is rejected.
Reference: <author> Galliers, J. R. </author> <year> 1992. </year> <title> Autonomous belief revision and communication. In Gardenfors., ed., Belief Revision. </title> <publisher> Cambridge University Press. </publisher>
Reference: <author> Grosz, B., and Kraus, S. </author> <year> 1993. </year> <title> Collaborative plans for group activities. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence. </booktitle>
Reference: <author> Grosz, B. J., and Sidner, C. L. </author> <year> 1990. </year> <title> Plans for discourse. </title> <editor> In Cohen; Morgan; and Pollack., eds., </editor> <title> Intentions in Communication. </title> <publisher> MIT Press. </publisher> <pages> chapter 20, 417-444. </pages>
Reference: <author> Huhns, M. N., and Bridgeland, D. M. </author> <year> 1991. </year> <title> Multia-gent truth maintenance. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 21(6) </journal> <pages> 1437-1445. </pages>
Reference-contexts: strategies for various types of conflicts, including resolving conflicting goals between non-fully cooperative agents (Sycara 1989), resolving conflicts in resource allocation among cooperative agents (Conry, Meyer, & Lesser 1988), resolving conflicts between coordinating sub-problems in distributed problem-solving (Klein 1991; Lander & Lesser 1992), maintaining consistency among beliefs of computational agents <ref> (Huhns & Bridgeland 1991) </ref>, etc. In addition, Rosenschein and Zlotkin (1994) proposed a general theory characterizing the relationship between domains and appropriate negotiation mechanisms. These research efforts have focused on different aspects of conflict resolution from ours.
Reference: <author> Joshi, A. K. </author> <year> 1982. </year> <title> Mutual beliefs in question-answer systems. </title> <editor> In Smith, N., ed., </editor> <title> Mutual Knowledge. </title> <publisher> Academic Press. </publisher> <pages> chapter 4, 181-197. </pages>
Reference-contexts: Introduction Conflict management, communication, and negotiation are important components of multi-agent activity. Conflict resolution involves communication among agents communication for the purpose of squaring away <ref> (Joshi 1982) </ref> discrepancies among agents' beliefs. Successful communication requires strategic planning to say the right thing at the right time.
Reference: <author> Klein, M. </author> <year> 1991. </year> <title> Supporting conflict resolution in cooperative design systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics 21(6) </journal> <pages> 1379-1389. </pages>
Reference: <author> Lambert, L., and Carberry, S. </author> <year> 1991. </year> <title> A tripartite plan-based model of dialogue. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 47-54. </pages>
Reference-contexts: For example, the agents might negotiate the strategies they will use to construct the domain plan. Agents also collaborate on their beliefs, forming a set of mutual beliefs that are rele vant to the task at hand. Thus we use an enhanced version of the dialogue model presented in <ref> (Lambert & Carberry 1991) </ref> to capture the current intentions of the dialogue participants.
Reference: <author> Lander, S. E., and Lesser, V. R. </author> <year> 1992. </year> <title> Negotiated search: Cooperative search among heterogeneous expert agents. </title> <booktitle> In AAAI-92 Workshop: Cooperation Among Heterogeneous Intelligent Systems, </booktitle> <pages> 74-83. </pages>
Reference: <author> Logan, B.; Reece, S.; Cawsey, A.; Galliers, J.; and Sparck Jones, K. </author> <year> 1994. </year> <title> Belief revision and dialogue management in information retrieval. </title> <type> Technical Report 339, </type> <institution> University of Cambridge, Computer Laboratory. </institution>
Reference-contexts: 1992) discussed earlier to predict EA's view on bel 7 It is possible to provide support/attack for an evidential relationship. 8 For a full account of the algorithm, see (Chu-Carroll & Carberry 1995b). based on the system's knowledge of EA's existing beliefs and the evidence to be presented to him <ref> (Logan et al. 1994) </ref>. An Example of Conflict Negotiation In the example given in utterances (1) and (2), whose dialogue model was shown in Figure 1, the evaluator rejected the proposed domain action Obtain-Exemption (EA, French) because it believes that the action is infeasible. <p> They argued that in the information retrieval dialogues they analyzed, "in no cases does negotiation extend beyond the initial belief conflict and its immediate resolution." <ref> (Logan et al. 1994, page 141) </ref>; thus they do not provide a mechanism for collaborative negotiation.
Reference: <author> Pollack, M. E. </author> <year> 1986. </year> <title> A model of plan inference that distinguishes between the beliefs of actors and observers. </title> <booktitle> In Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 207-214. </pages>
Reference-contexts: A plan is considered invalid if either an action in the plan cannot be performed (an action is infeasible) or a child action does not contribute to its parent action as intended (the plan is ill-formed <ref> (Pollack 1986) </ref>). A plan is considered suboptimal if there exists a better way to perform the desired action. We evaluate the optimality of a plan with respect to EA's preferences (Elzer, Chu-Carroll, & Carberry 1994). <p> Smith teaching AI provides support for the belief that he is not going on sabbatical. The process for evaluating proposed beliefs starts at the leaf node of the proposed belief tree, Teaches (Smith,AI,next semester). The system searches for 4 A recipe <ref> (Pollack 1986) </ref> is a template for performing actions.
Reference: <author> Rosenschein, J. S., and Zlotkin, G. </author> <year> 1994. </year> <title> Rules of Encounter Designing Conventions for Automated Negotiation among Computers. </title> <publisher> MIT Press. </publisher>
Reference: <author> Sidner, C. L. </author> <year> 1994. </year> <title> An artificial discourse language for collaborative negotiation. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 814-819. </pages>
Reference-contexts: IRI-9122026. situations involving embedded negotiation during conflict resolution. Communication and Collaboration Sidner formulated an artificial language for modeling collaborative discourse using proposal/acceptance and proposal/rejection sequences <ref> (Sidner 1994) </ref>. While Sid-ner's work is descriptive, our research is prescriptive in that we have identified appropriate response generation strategies for agents involved in collaborative interactions.
Reference: <author> Sycara, K. </author> <year> 1989. </year> <title> Argumentation: Planning other agents' plans. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <pages> 517-523. </pages>
Reference-contexts: This results in collaborative negotiation. Such negotiation differs from other kinds of negotiation, such as labor negotiation <ref> (Sycara 1989) </ref>, in that the participants are not trying to enforce their views on one another or to maximize their own benefits, but rather are trying to share their individual knowledge and beliefs in order to determine what really is best (Chu-Carroll & Carberry 1995b). 6 The strength of an agent's <p> Related Work Researchers have developed conflict resolution strategies for various types of conflicts, including resolving conflicting goals between non-fully cooperative agents <ref> (Sycara 1989) </ref>, resolving conflicts in resource allocation among cooperative agents (Conry, Meyer, & Lesser 1988), resolving conflicts between coordinating sub-problems in distributed problem-solving (Klein 1991; Lander & Lesser 1992), maintaining consistency among beliefs of computational agents (Huhns & Bridgeland 1991), etc.
Reference: <author> Walker, M. A. </author> <year> 1992. </year> <title> Redundancy in collaborative dialogue. </title> <booktitle> In Proceedings of the 15th International Conference on Computational Linguistics, </booktitle> <pages> 345-351. </pages>
Reference-contexts: Resolving Conflicts A Negotiated Process Once CA detects a relevant conflict, she must notify EA of the conflict and attempt to resolve it to do otherwise is to fail in her responsibilities as a collaborative participant <ref> (Walker 1992) </ref>. This results in collaborative negotiation.
Reference: <author> Young, R. M.; Moore, J. D.; and Pollack, M. E. </author> <year> 1994. </year> <title> Towards a principled representation of discourse plan s. </title> <booktitle> In Proceedings of the Sixteenth Annual Meeting of the Cognitive Science Society, </booktitle> <pages> 946-951. </pages>
Reference-contexts: Conflict resolution and negotiation are necessary only if the top-level proposed beliefs are not accepted since if the agents agree on a particular belief relevant to the domain plan being constructed, it is irrelevant whether they both agree on all the evidence for that belief <ref> (Young, Moore, & Pollack 1994) </ref>. Examples of Conflict Detection To illustrate the evaluation process, we return to the example depicted in the dialogue model in Figure 1. The system evaluates the proposal beginning with the proposed domain actions.
References-found: 25

