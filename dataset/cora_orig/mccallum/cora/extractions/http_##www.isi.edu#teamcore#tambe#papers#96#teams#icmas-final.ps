URL: http://www.isi.edu/teamcore/tambe/papers/96/teams/icmas-final.ps
Refering-URL: http://www.isi.edu/teamcore/tambe/agent.html
Root-URL: http://www.isi.edu
Email: tambe@isi.edu  
Title: Teamwork in Real-world, Dynamic Environments  
Author: Milind Tambe 
Web: http://www.isi.edu/soar/tambe  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Computer Science Department University of Southern California  
Abstract: Flexible teamwork in real-world multi-agent domains is more than a union of agents' simultaneous execution of individual plans, even if such execution is pre-coordinated. Indeed, uncertainties in complex, dynamic domains often obstruct preplanned coordination, with a resultant breakdown in teamwork. The central hypothesis in this paper is that for effective teamwork, agents should be provided explicit team plans and an underlying model of teamwork that explicitly outlines their commitments and responsibilities as participants in team activities. Such a model enables team members to flexibly reason about coordination activities. The underlying model we have provided is based on the joint intentions framework; although we present some key modifications to reflect the practical constraints in (some) real-world domains. This framework has been implemented in the context of a real-world synthetic environment for helicopter-combat simulation; some empirical results are presented. 1 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bates, J.; Loyall, A. B.; and Reilly, W. S. </author> <year> 1992. </year> <title> Integrating reactivity, goals and emotions in a broad agent. </title> <type> Technical Report CMU-CS-92-142, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: 1 Introduction Many AI researchers are today striving to build agents for complex, dynamic multi-agent domains, such as, virtual theatre (Hayes-Roth, Brownston, & Gen 1995), realistic virtual training environments (e.g., for emergency drill (Pi-mentel & Teixeira 1994) or combat (Tambe et al. 1995; Rao et al. 1993)), virtual interactive fiction <ref> (Bates, Loyall, & Reilly 1992) </ref>, RoboCup robotic and virtual soccer (Kitano et al. 1995) and robotic collaboration by observation (Ku-niyoshi et al. 1994). Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains.
Reference: <author> Calder, R. B.; Smith, J. E.; Courtemanche, A. J.; </author> <month> Mar, </month> <note> J. </note>
Reference: <author> M. F.; and Ceranowicz, A. Z. </author> <year> 1993. </year> <title> Modsaf behavior simulation and control. </title> <booktitle> In Proceedings of the Conference on Computer Generated Forces and Behavioral Representation. </booktitle>
Reference: <author> Cohen, P. R., and Levesque, H. J. </author> <year> 1991. </year> <note> Teamwork. Nous 35. </note>
Reference-contexts: Such team activities are not merely a union of simultaneous, coordinated individual activities (Grosz & Sidner 1990; Cohen & Levesque 1991). For instance, ordinary automobile traffic is not considered teamwork, despite the simultaneous activity, coordinated by traffic signs <ref> (Cohen & Levesque 1991) </ref>. Indeed, our commonsense notion of teamwork involves more than simple coordination, e.g., the American Heritage Dictionary defines it as cooperative effort by the members of a team to achieve a common goal. <p> To execute such team plans, team members must be provided an explicit model of teamwork their commitments and responsibilities as team members so they can flexibly reason about coordination and communication. In our work, this model is the formal joint intentions framework <ref> (Cohen & Levesque 1991) </ref>, which we have modified in key ways to accommodate the constraints that appear typical in (some) real-world dynamic domains. Before describing reactive team plans in detail, we first concretely motivate their need by describing our initial experiences in designing agent teams for a real-world domain. <p> Further contributions of this paper include: (i) Detailed illustration of an implementation of the modified joint intentions framework <ref> (Cohen & Levesque 1991) </ref> in a real-world multi-agent domain; (ii) key modifications to the joint intentions framework to reflect important constraints in the domain; (iii) introduction and implementation of team operators (reactive team plans); (iv) techniques for recovery from failure of team activities.
Reference: <author> Davis, R. </author> <year> 1982. </year> <title> Expert systems: where are we? and where do we go from here? AI Magazine 3(2). </title>
Reference-contexts: To achieve such flexibility we apply one key lesson from the arena of knowledge-based systems an agent must be provided explicit deep or causal models of its domains of operation <ref> (Davis 1982) </ref>. The key here is to recognize that when an agent participates in a team activity, teamwork is itself one of the domains, and hence the agent must be provided an explicit model of teamwork.
Reference: <author> Firby, J. </author> <year> 1987. </year> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI). </booktitle>
Reference-contexts: Discussions with Phil Cohen and Ira Smith were helpful clarifying the issues in Section 3. terminate via terminating conditions. Agents built in architectures such as PRS (Ingrand et al. 1992), BB1 (Hayes-Roth, Brownston, & Gen 1995), RAP <ref> (Firby 1987) </ref> and Soar (Newell 1990) for dynamic domains may be (at least abstractly) characterized in this fashion. Instead of individuals, this paper focuses on agent teams in dynamic domains.
Reference: <author> Grosz, B. J., and Sidner, C. L. </author> <year> 1990. </year> <title> Plans for discourse. In Intentions in Communication. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <pages> 417-445. </pages>
Reference: <author> Hayes-Roth, B.; Brownston, L.; and Gen, R. V. </author> <year> 1995. </year> <title> Multiagent collaobration in directed improvisation. </title> <booktitle> In Proceedings of the International Conference on Multi-Agent Systems (ICMAS-95). </booktitle>
Reference: <author> Huber, M., and Durfee, E. </author> <year> 1995. </year> <title> On acting together: Without communication. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Reasoning about Mental states. </booktitle>
Reference-contexts: Jennings's implementation of the joint intentions framework in an industrial multi-agent setting is one notable exception (Jennings 1995). Huber and Durfee describe a similar implementation, although in a smaller scale testbed <ref> (Huber & Durfee 1995) </ref>. There are several key differences in our work. First, in both these efforts, agents' collaborative activity appears to involve a two level hierarchy of a joint goal and a joint plan, with individuals engaged in specific roles in the plan. <p> However, agents have to explicitly check if lower-level team operators are unachievable, and recover from failures. Recovery is important, else the entire team effort will go to waste. Finally, in (Jennings 1995) issues of communication risk are not considered (although they are considered in <ref> (Huber & Durfee 1995) </ref>). Our recent work on team tracking (Tambe 1996) which involves inferring other team's joint goals and intentions based on observations of their actions is the predecessor to the work reported here.
Reference: <author> Ingrand, F. F.; Georgeff, M. P.; ; and Rao, A. S. </author> <year> 1992. </year> <title> An architecture for real-time reasoning and system control. </title> <journal> IEEE EXPERT 7(6). </journal>
Reference-contexts: I thank Ramesh Patil, Marcus Huber, Takahira Yamaguchi and Wei-Min Shen for helpful comments on an earlier draft of this paper. Discussions with Phil Cohen and Ira Smith were helpful clarifying the issues in Section 3. terminate via terminating conditions. Agents built in architectures such as PRS <ref> (Ingrand et al. 1992) </ref>, BB1 (Hayes-Roth, Brownston, & Gen 1995), RAP (Firby 1987) and Soar (Newell 1990) for dynamic domains may be (at least abstractly) characterized in this fashion. Instead of individuals, this paper focuses on agent teams in dynamic domains.
Reference: <author> Jennings, N. </author> <year> 1994. </year> <title> Commitments and conventions: the foundation of coordination in multi-agent systems. </title> <journal> The Knowledge Engineering Review 8. </journal>
Reference: <author> Jennings, N. </author> <year> 1995. </year> <title> Controlling cooperative problem solving in industrial multi-agent systems using joint intentions. </title> <booktitle> Artificial Intelligence 75. </booktitle>
Reference-contexts: The recent formal theories of collaborative action have begun to provide the required models for flexible rea-soning about team activities (Cohen & Levesque 1991; Grosz & Sidner 1990; Kinny et al. 1992; Jennings 1995); although few multi-agent implementations have built on them <ref> (Jennings 1995) </ref> (a notable exception is (Jennings 1995), described in Section 6). In contrast, this paper describes an implemented, real-world multi-agent system that builds upon one such model. <p> The recent formal theories of collaborative action have begun to provide the required models for flexible rea-soning about team activities (Cohen & Levesque 1991; Grosz & Sidner 1990; Kinny et al. 1992; Jennings 1995); although few multi-agent implementations have built on them <ref> (Jennings 1995) </ref> (a notable exception is (Jennings 1995), described in Section 6). In contrast, this paper describes an implemented, real-world multi-agent system that builds upon one such model. <p> Jennings's implementation of the joint intentions framework in an industrial multi-agent setting is one notable exception <ref> (Jennings 1995) </ref>. Huber and Durfee describe a similar implementation, although in a smaller scale testbed (Huber & Durfee 1995). There are several key differences in our work. <p> More specifically, even if a single agent is incapacitated, the team operator hierarchy does not completely fall apart. However, agents have to explicitly check if lower-level team operators are unachievable, and recover from failures. Recovery is important, else the entire team effort will go to waste. Finally, in <ref> (Jennings 1995) </ref> issues of communication risk are not considered (although they are considered in (Huber & Durfee 1995)). Our recent work on team tracking (Tambe 1996) which involves inferring other team's joint goals and intentions based on observations of their actions is the predecessor to the work reported here.
Reference: <author> Kinny, D.; Ljungberg, M.; Rao, A.; Sonenberg, E.; Tid-hard, G.; and Werner, E. </author> <year> 1992. </year> <title> Planned team activity. </title> <editor> In Castelfranchi, C., and Werner, E., eds., </editor> <booktitle> Artificial Social Systems, Lecture notes in AI 830. </booktitle> <publisher> Springer Verlag, </publisher> <address> New York. </address>
Reference: <author> Kitano, H.; Asada, M.; Kuniyoshi, Y.; Noda, I.; and Os-awa, E. </author> <year> 1995. </year> <title> Robocup: The robot world cup initiative. </title> <booktitle> In Proceedings of IJCAI-95 Workshop on Entertainment and AI/Alife. </booktitle>
Reference-contexts: agents for complex, dynamic multi-agent domains, such as, virtual theatre (Hayes-Roth, Brownston, & Gen 1995), realistic virtual training environments (e.g., for emergency drill (Pi-mentel & Teixeira 1994) or combat (Tambe et al. 1995; Rao et al. 1993)), virtual interactive fiction (Bates, Loyall, & Reilly 1992), RoboCup robotic and virtual soccer <ref> (Kitano et al. 1995) </ref> and robotic collaboration by observation (Ku-niyoshi et al. 1994). Most of this research has so far focused on enabling individual agents to cope with the complexities of these dynamic domains. One promising approach that has emerged is the use of hierarchical reactive plans. <p> These lessons appears applicable to other dynamic multi-agent domains, including other applications of the simulation technology described here such as training for (natural) disaster relief, medical emergencies etc. Indeed, to test these lessons, we have begun implementing this framework for players in the RoboCup virtual soccer tournament <ref> (Kitano et al. 1995) </ref>.
Reference: <author> Kuniyoshi, Y.; Rougeaux, S.; Ishii, M.; Kita, N.; Sakane, S.; and Kakikura, M. </author> <year> 1994. </year> <title> Cooperation by observation: the framework and the basic task pattern. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation. </booktitle>
Reference: <author> Levesque, H. J.; Cohen, P. R.; and Nunes, J. </author> <year> 1990. </year> <title> On acting together. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <address> Menlo Park, Calif.: </address> <publisher> AAAI press. </publisher>
Reference: <author> Newell, A. </author> <year> 1990. </year> <title> Unified Theories of Cognition. </title> <address> Cam-bridge, Mass.: </address> <publisher> Harvard Univ. Press. </publisher>
Reference-contexts: Discussions with Phil Cohen and Ira Smith were helpful clarifying the issues in Section 3. terminate via terminating conditions. Agents built in architectures such as PRS (Ingrand et al. 1992), BB1 (Hayes-Roth, Brownston, & Gen 1995), RAP (Firby 1987) and Soar <ref> (Newell 1990) </ref> for dynamic domains may be (at least abstractly) characterized in this fashion. Instead of individuals, this paper focuses on agent teams in dynamic domains.
Reference: <author> Pimentel, K., and Teixeira, K. </author> <year> 1994. </year> <title> Virtual reality: Through the new looking glass. Blue Ridge Summit, </title> <address> PA: Windcrest/McGraw-Hill. </address>
Reference: <author> Rajput, S., and Karr, C. R. </author> <year> 1995. </year> <title> Cooperative behavior in modsaf. </title> <type> Technical Report IST-CR-95-35, </type> <institution> Institute for simulation and training, University of Central Florida. </institution>
Reference: <author> Rao, A. S.; Lucas, A.; Morley, D.; Selvestrel, M.; and Murray, G. </author> <year> 1993. </year> <title> Agent-oriented architecture for air-combat simulation. </title> <type> Technical Report Technical Note 42, </type> <institution> The Australian Artificial Intelligence Institute. </institution>
Reference: <author> Rosenbloom, P. S.; Laird, J. E.; Newell, A.; ; and McCarl, R. </author> <year> 1991. </year> <title> A preliminary analysis of the soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence 47(1-3):289-325. </journal>
Reference: <author> Tambe, M., and Rosenbloom, P. S. </author> <year> 1995. </year> <title> RESC: An approach for real-time, dynamic agent tracking. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). </booktitle>
Reference-contexts: These pilot agents have participated in large scale combat exercises, some involving expert human pilots <ref> (Tambe et al. 1995) </ref>. <p> This paper will focus on pilot agents for a company of (up to eight) attack helicopters, which execute missions in a synthetic 3D terrain with hills, valleys and ridges (e.g., southern Califor-nia) <ref> (Tambe, Schwamb, & Rosenbloom 1995) </ref>. 2 As shown in Figure 1, in a typical attack mission, the company may fly 25-50 kilometers at varying altitudes, to halt at a holding point. <p> When the mission completes, the helicopters regroup and return to base. The ridge line is ideal for masking. In our first implementation of the helicopter company, each pilot agent was provided an operator (reactive plan) hierarchy to execute its mission <ref> (Tambe, Schwamb, & Rosen-bloom 1995) </ref>. Figure 2 illustrates a portion of this operator hierarchy (at any one time, only one path in this hierarchy from the root to a leaf node is active).
Reference: <author> Tambe, M.; Johnson, W. L.; Jones, R.; Koss, F.; Laird, J. E.; Rosenbloom, P. S.; and Schwamb, K. </author> <year> 1995. </year> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine 16(1). </journal>
Reference-contexts: These pilot agents have participated in large scale combat exercises, some involving expert human pilots <ref> (Tambe et al. 1995) </ref>. <p> This paper will focus on pilot agents for a company of (up to eight) attack helicopters, which execute missions in a synthetic 3D terrain with hills, valleys and ridges (e.g., southern Califor-nia) <ref> (Tambe, Schwamb, & Rosenbloom 1995) </ref>. 2 As shown in Figure 1, in a typical attack mission, the company may fly 25-50 kilometers at varying altitudes, to halt at a holding point. <p> When the mission completes, the helicopters regroup and return to base. The ridge line is ideal for masking. In our first implementation of the helicopter company, each pilot agent was provided an operator (reactive plan) hierarchy to execute its mission <ref> (Tambe, Schwamb, & Rosen-bloom 1995) </ref>. Figure 2 illustrates a portion of this operator hierarchy (at any one time, only one path in this hierarchy from the root to a leaf node is active).
Reference: <author> Tambe, M.; Schwamb, K.; and Rosenbloom, P. S. </author> <year> 1995. </year> <title> Building intelligent pilots for simulated rotary wing aircraft. </title> <booktitle> In Proceedings of the Fifth Conference on Computer Generated Forces and Behavioral Representation. </booktitle>
Reference-contexts: These pilot agents have participated in large scale combat exercises, some involving expert human pilots <ref> (Tambe et al. 1995) </ref>. <p> This paper will focus on pilot agents for a company of (up to eight) attack helicopters, which execute missions in a synthetic 3D terrain with hills, valleys and ridges (e.g., southern Califor-nia) <ref> (Tambe, Schwamb, & Rosenbloom 1995) </ref>. 2 As shown in Figure 1, in a typical attack mission, the company may fly 25-50 kilometers at varying altitudes, to halt at a holding point. <p> When the mission completes, the helicopters regroup and return to base. The ridge line is ideal for masking. In our first implementation of the helicopter company, each pilot agent was provided an operator (reactive plan) hierarchy to execute its mission <ref> (Tambe, Schwamb, & Rosen-bloom 1995) </ref>. Figure 2 illustrates a portion of this operator hierarchy (at any one time, only one path in this hierarchy from the root to a leaf node is active).
Reference: <author> Tambe, M. </author> <year> 1996. </year> <title> Tracking dynamic team activity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI). </booktitle>
Reference-contexts: Recovery is important, else the entire team effort will go to waste. Finally, in (Jennings 1995) issues of communication risk are not considered (although they are considered in (Huber & Durfee 1995)). Our recent work on team tracking <ref> (Tambe 1996) </ref> which involves inferring other team's joint goals and intentions based on observations of their actions is the predecessor to the work reported here. However, given its focus on tracking other teams, issues such as communication, recovery from unachievable team operators were all explicitly excluded from consideration.
Reference: <author> Tidhar, G.; Selvestrel, M.; and Heinze, C. </author> <year> 1995. </year> <title> Modeling teams and team tactics in whole air mission modelling. </title> <type> Technical Report Technical Note 60, </type> <institution> The Australian Artificial Intelligence Institute. </institution>
References-found: 26

