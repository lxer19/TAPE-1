URL: ftp://cag.lcs.mit.edu/pub/dm/papers/mann:filecache.ps.gz
Refering-URL: http://www.pdos.lcs.mit.edu/~dm/
Root-URL: 
Title: 103 A Coherent Distributed File Cache With Directory Write-behind  
Author: Timothy Mann, Andrew Birrell, Andy Hisgen, Charles Jerian, and Garret Swart 
Address: 130 Lytton Avenue Palo Alto, California 94301  
Affiliation: Systems Research Center  
Date: June 10, 1993  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Mary Baker, Satoshi Asami, Etienne Deprit, John Ousterhout, and Margo Seltzer. </author> <title> Non-volatile memory for fast, reliable file systems. </title> <booktitle> In Proc. 5th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 10-22. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: Perhaps the ultimate solution to this problem is to eliminate write-behind, instead using non-volatile RAM on each file server to shield clients from the latency of synchronous disk writes <ref> [1] </ref>. Echo took a two-pronged approach to dealing with lost write-behind. First, make it easy for an application writer to ensure that, when a crash halts the application and causes some of its write-behind to be lost, the data structures it stores in the file system remain consistent.
Reference: [2] <author> Mary Baker and Mark Sullivan. </author> <title> The recovery box: Using fast recovery to provide high availability in the UNIX environment. </title> <booktitle> In Proc. Summer 1992 USENIX Conference, </booktitle> <pages> pages 31-43. </pages> <publisher> USENIX Association, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: But failure recovery is much slower, because many clerks must be contacted and a substantial number of tokens must be recovered from eachtwo minutes is a typical time for this process in Sprite <ref> [2] </ref> and if some of the clerks are down, the server may have to wait for an additional 28 timeout period to discover this. <p> tokens, which is considerably faster (and which 12 Perhaps the Sprite research group has reached a similar conclusion; Sprite has recently been modified to replicate tokens in a segment of the server's own memory that is usually preserved across reboots, recovering tokens from clients only when this memory is lost <ref> [2] </ref>. 13 Thus a user who logs into a machine obviously must trust its clerk, since the clerk is able to request any operation it pleases on behalf of the user.
Reference: [3] <author> Mary G. Baker, John H. Hartman, Michael D. Kupfer, Ken W. Shirriff, and John K. Ousterhout. </author> <title> Measurements of a distributed file system. </title> <booktitle> In Proc. 13th Symp. on Operating Systems Principles, </booktitle> <pages> pages 198-212. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: Perhaps such a heuristic could also detect sequentially shared files. Further research seems to be needed in this area; however, when Baker et al. <ref> [3] </ref> compared the performance of the Sprite and Echo schemes for handling write-shared files, they found that the choice made little difference on the workload traces they were able to gather. Sprite does not replicate its token directory.
Reference: [4] <author> Andrew D. Birrell, Andy Hisgen, Charles Jerian, Timothy Mann, and Garret Swart. </author> <title> The Echo distributed file system. </title> <type> Research report, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo <ref> [4] </ref> and discuss various other aspects in detail [9, 10, 11, 12, 18, 25]. In the next section we discuss the motivation for Echo's cache design; then in Section 3 we present the cache's coherence and ordering semantics and the facilities for reporting lost write-behind.
Reference: [5] <author> Michael Burrows. </author> <title> Efficient Data Sharing. </title> <type> PhD thesis, </type> <institution> University of Cam-bridge, </institution> <month> September </month> <year> 1988. </year>
Reference-contexts: In environments where files are often accessed in this wayVMS, for exampleone could change Echo's token mechanism to work on byte ranges instead of whole files, using the technique Burrows describes in his thesis <ref> [5] </ref>. We did have a few problems with widely shared, mutable directories, but we were able to work around them. <p> Like Sprite, AFS does not use leases and thus does not provide strict single-copy equivalence. Burrows has implemented a file caching service, called MFS <ref> [5] </ref>, that is similar to Echo's in many respects. MFS caches both files and directories, with write-behind for both, and with coherence implemented using a token scheme similar to Echo's. Like Sprite and AFS, MFS does not use leases and thus fails to provide strict single-copy equivalence. <p> action taken in a QuickSilver program is part of a single atomic transaction that commits when the program exitsbut this behavior is not appropriate for many programs, for example, long-running text editors. 16 For a more extensive bibliography on file systems that do caching on client machines, see Burrows's thesis <ref> [5] </ref>. 16 Of course, for some applications, using Echo's semantics requires modifying applications by adding forder calls.
Reference: [6] <author> Sheng-Yang Chiu and Roy Levin. </author> <title> The Vesta repository: A file system extension for software development. </title> <type> Research Report 106, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <year> 1993. </year>
Reference-contexts: A number of the techniques for using Echo's ordering constraints that we have just described have been used in real applications. In particular, the Vesta software configuration management system <ref> [6, 17] </ref> developed by colleagues at our research center uses variants of both the file and directory replacement techniques. (Vesta uses the techniques to atomically create new files and directories full of files, not to replace existing ones.) Vesta could also have used the write-ahead logging technique, but unfortunately the Vesta
Reference: [7] <author> Lucille Glassman, Dennis Grinberg, Cynthia Hibbard, Loretta Guarino Reid, and Mary-Claire van Leunen. Hector: </author> <title> Connecting words with definitions. </title> <institution> Research Report 92A, Systems Research Center, Digital Equipment Corporation, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: Perhaps this example sounds contrived, but we are aware of real-world instances of the same phenomenon. Our colleagues in the Hector lexicography project <ref> [7] </ref> tried to use NFS to maintain a shared file of dictionary definitions being read and updated by multiple lexicographers.
Reference: [8] <author> Cary G. Gray and David R. Cheriton. Leases: </author> <title> An efficient fault-tolerant mechanism for distributed file cache consistency. </title> <booktitle> In Proc. 12th Symp. on Operating Systems Principles, </booktitle> <pages> pages 202-210. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1989. </year>
Reference-contexts: If a server loses touch with a clerk, the server does not revoke the clerk's tokens until an agreed-upon timeout (or lease <ref> [8] </ref>) has expired. Therefore, two applications that read from different caches at the same time can never see inconsistent data, even if one is running on a machine that has been partitioned away from the rest of the network. <p> server may have revoked them, even if the network connecting the clerk and server is broken. (For this application, the clerk and server clocks do not actually have to be synchronized; it is sufficient for them to run at the same 11 The term lease was first used by Gray <ref> [8] </ref>; we compare his system with ours in Section 7. 27 rate within some known error boundwhich is fortunate since there is no way to synchronize clocks on two machines that cannot communicate!) Echo uses sessions to reduce the amount of network traffic needed to keep leases up to date. <p> As mentioned above, we believe that byte-range tokens would be a useful addition to the Echo token scheme under workloads where shared, mutable random-access files are common. Gray coined the term lease in a paper about his file caching server <ref> [8] </ref>. We developed the lease concept simultaneously and independently of Gray, but chose to adopt his terminology when we learned of his work. Gray's system does not use write-behind at all, so it needs only one kind of token.
Reference: [9] <author> Andy Hisgen, Andrew Birrell, Charles Jerian, Timothy Mann, and Garret Swart. </author> <title> Some consequences of excess load on the Echo replicated file system. </title> <booktitle> In Proc. 2nd Workshop on the Management of Replicated Data, </booktitle> <pages> pages 92-95. </pages> <publisher> IEEE, </publisher> <month> November </month> <year> 1992. </year> <month> 43 </month>
Reference-contexts: This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo [4] and discuss various other aspects in detail <ref> [9, 10, 11, 12, 18, 25] </ref>. In the next section we discuss the motivation for Echo's cache design; then in Section 3 we present the cache's coherence and ordering semantics and the facilities for reporting lost write-behind.
Reference: [10] <author> Andy Hisgen, Andrew Birrell, Charles Jerian, Timothy Mann, and Garret Swart. </author> <title> New-value logging in the Echo replicated file system. </title> <type> Research report, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo [4] and discuss various other aspects in detail <ref> [9, 10, 11, 12, 18, 25] </ref>. In the next section we discuss the motivation for Echo's cache design; then in Section 3 we present the cache's coherence and ordering semantics and the facilities for reporting lost write-behind. <p> In addition, group commit to the log could have come into play on the server <ref> [10] </ref>, reducing the total number of disk writes. As is evident from these measurements, both the Echo clerk and server required considerably more CPU time to do comparable operations than their Unix counterparts. The server in particular was heavily CPU bound.
Reference: [11] <author> Andy Hisgen, Andrew Birrell, Chuck Jerian, Timothy Mann, Michael Schroeder, and Garret Swart. </author> <title> Granularity and semantic level of replication in the Echo distributed file system. </title> <booktitle> In Proc. Workshop on the Management of Replicated Data, </booktitle> <pages> pages 2-4. </pages> <publisher> IEEE, </publisher> <month> November </month> <year> 1990. </year>
Reference-contexts: This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo [4] and discuss various other aspects in detail <ref> [9, 10, 11, 12, 18, 25] </ref>. In the next section we discuss the motivation for Echo's cache design; then in Section 3 we present the cache's coherence and ordering semantics and the facilities for reporting lost write-behind.
Reference: [12] <author> Andy Hisgen, Andrew Birrell, Timothy Mann, Michael Schroeder, and Garret Swart. </author> <title> Availability and consistency tradeoffs in the Echo distributed file system. </title> <booktitle> In Proc. 2nd Workshop on Workstation Operating Systems, </booktitle> <pages> pages 49-54. </pages> <publisher> IEEE, </publisher> <month> September </month> <year> 1989. </year>
Reference-contexts: This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo [4] and discuss various other aspects in detail <ref> [9, 10, 11, 12, 18, 25] </ref>. In the next section we discuss the motivation for Echo's cache design; then in Section 3 we present the cache's coherence and ordering semantics and the facilities for reporting lost write-behind.
Reference: [13] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanaraynan, Robert N. Sidebotham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The benchmarks include compiling 100 one-line C programs, running the make phase of the Andrew benchmark <ref> [13] </ref>, creating a new version of a software package in the Vesta system, and some simple loops creating and deleting files and directories. The benchmarks all run considerably faster with Echo's directory write-behind enabled than with it disabled. <p> Sprite does not use leases. If a server loses touch with a clerk, it invalidates the clerk's tokens immediately. Therefore, for the reasons discussed in Section 6.2 above, Sprite does not provide strict single-copy equivalence. 36 The Andrew File System <ref> [13, 14] </ref> caches both files and directories on client machines. On directory updates, AFS does write-through, not write-behind. AFS caches files in their entirety, not block by block, and it delays writing changes to a file back to the server at least until the file is closed.
Reference: [14] <author> Michael L. Kazar. </author> <title> Synchronization and caching issues in the Andrew file system. </title> <booktitle> In Proc. Winter 1988 USENIX Conference, </booktitle> <pages> pages 27-36. </pages> <publisher> USENIX Association, </publisher> <month> February </month> <year> 1988. </year>
Reference-contexts: Sprite does not use leases. If a server loses touch with a clerk, it invalidates the clerk's tokens immediately. Therefore, for the reasons discussed in Section 6.2 above, Sprite does not provide strict single-copy equivalence. 36 The Andrew File System <ref> [13, 14] </ref> caches both files and directories on client machines. On directory updates, AFS does write-through, not write-behind. AFS caches files in their entirety, not block by block, and it delays writing changes to a file back to the server at least until the file is closed.
Reference: [15] <author> James J. Kistler and M. Satyanaraynan. </author> <title> Disconnected operation in the Coda file system. </title> <booktitle> In Proc. 13th Symp. on Operating Systems Principles, </booktitle> <pages> pages 213-225. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: This goal led us to implement a file cache with strict coherence and a replication scheme with strict consistency between copies. We chose not to explore the alternative approach used in the LOCUS [20, 27] and Coda <ref> [15] </ref> file systems, in which replicas or cached copies of files are allowed to diverge during periods when the network is not fully connected. <p> On networks that are often unavailable, however, file systems that allow controlled forms of incoherence, such as LOCUS [20, 27] and Coda <ref> [15] </ref>, may be more practical. If the system's token directory is lost, all client machines lose their write-behind, disrupting the work of many users. Therefore the token directory must be either replicated, recoverable from clients after a server crash, or both.
Reference: [16] <author> Butler Lampson, Martn Abadi, Michael Burrows, and Edward Wobber. </author> <title> Authentication in distributed systems: Theory and practice. </title> <booktitle> In Proc. 13th Symp. on Operating Systems Principles, </booktitle> <pages> pages 165-182. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: Echo has adopted a security model in which servers do not trust client machines; instead, client machines use a cryptographic protocol to authenticate themselves as acting on behalf of the users who have logged in to them <ref> [16] </ref>. This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo [4] and discuss various other aspects in detail [9, 10, 11, 12, 18, 25]. <p> A clerk is able to authenticate itself as a particular user if (and only if) that user has logged into the clerk machine. 13 The authentication and login protocols Echo uses were developed as part of a separate security architecture project and are described in detail in another paper <ref> [16] </ref>. We use two kinds of caching to make access control decisions fast. First, there is caching within the authentication protocol implementation, so that most remote procedure calls are authenticated with no extra packets or cryptographic overhead. Authentication caching is beyond the scope of this paper.
Reference: [17] <author> Roy Levin and Paul McJones. </author> <title> The Vesta approach to precise configuration of large software systems. </title> <type> Research Report 105, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <year> 1993. </year>
Reference-contexts: A number of the techniques for using Echo's ordering constraints that we have just described have been used in real applications. In particular, the Vesta software configuration management system <ref> [6, 17] </ref> developed by colleagues at our research center uses variants of both the file and directory replacement techniques. (Vesta uses the techniques to atomically create new files and directories full of files, not to replace existing ones.) Vesta could also have used the write-ahead logging technique, but unfortunately the Vesta
Reference: [18] <author> Timothy Mann, Andy Hisgen, and Garret Swart. </author> <title> An algorithm for data replication. </title> <type> Research Report 46, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo [4] and discuss various other aspects in detail <ref> [9, 10, 11, 12, 18, 25] </ref>. In the next section we discuss the motivation for Echo's cache design; then in Section 3 we present the cache's coherence and ordering semantics and the facilities for reporting lost write-behind.
Reference: [19] <author> Michael N. Nelson, Brent B. Welch, and John K. Ousterhout. </author> <title> Caching in the Sprite network file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 134-154, </pages> <month> February </month> <year> 1988. </year> <month> 44 </month>
Reference-contexts: Another alternative would be for a server that crashes to recover tokens from clerks when it reboots, as is done in the Sprite file system <ref> [19] </ref>. This scheme could also be used when a backup server takes over from the primary. With this scheme, normal operation is slightly faster, because the primary does not have to call the backup on each token acquisition. <p> In particular, other systems often use different terms for what we call volumes, clerks, and tokens. Like Echo, the Sprite file system uses tokens to maintain coherence in a distributed file cache <ref> [19] </ref>. Sprite's caching differs in several respects from Echo's, however. Sprite clerks cache only files, not directories. When a Sprite application process asks to open a file, the local clerk sends the request on to the server machine that stores the file, and the pathname lookup is done there.
Reference: [20] <author> G. Popek, B. Walker, J. Chow, D. Edwards, C. Kline, G. Rudisin, and G. Thiel. </author> <title> LOCUS: A network transparent, high reliability distributed system. </title> <booktitle> In Proc. 8th Symp. on Operating Systems Principles, </booktitle> <pages> pages 169-177. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1981. </year>
Reference-contexts: This goal led us to implement a file cache with strict coherence and a replication scheme with strict consistency between copies. We chose not to explore the alternative approach used in the LOCUS <ref> [20, 27] </ref> and Coda [15] file systems, in which replicas or cached copies of files are allowed to diverge during periods when the network is not fully connected. <p> The Echo system uses the AN1 network [23], which achieves very high availability through redundancy, though Ethernet and most other non-redundant local area networks have high enough availability for the purpose. On networks that are often unavailable, however, file systems that allow controlled forms of incoherence, such as LOCUS <ref> [20, 27] </ref> and Coda [15], may be more practical. If the system's token directory is lost, all client machines lose their write-behind, disrupting the work of many users. Therefore the token directory must be either replicated, recoverable from clients after a server crash, or both.
Reference: [21] <author> Russel Sandberg, David Goldberg, Steve Kleiman, Dan Walsh, and Bob Lyon. </author> <title> Design and implementation of the Sun network filesystem. </title> <booktitle> In Proc. Summer 1985 USENIX Conference, </booktitle> <pages> pages 119-130. </pages> <publisher> USENIX Association, </publisher> <month> June </month> <year> 1985. </year>
Reference-contexts: Our desire to present a single-system image also led us to emulate a single-machine Unix 2 file system more carefully than some other distributed file systems have done. For example, unlike NFS <ref> [21, 24] </ref>, Echo keeps a file that has been unlinked from the name space in existence as long as any application program has it open.
Reference: [22] <author> Frank Schmuck and Jim Wyllie. </author> <title> Experience with transactions in QuickSilver. </title> <booktitle> In Proc. 13th Symp. on Operating Systems Principles, </booktitle> <pages> pages 239-253. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1991. </year>
Reference-contexts: QuickSilver <ref> [22] </ref> provides a transactional interface to its file system. Operations on multiple files and directories can be grouped into a transaction that is committed or aborted as a unit.
Reference: [23] <author> Michael D. Schroeder, Andrew D. Birrell, Michael Burrows, Hal Murray, Roger M. Needham, Thomas L. Rodeheffer, Edwin H. Satterthwaite, and Charles P. Thacker. Autonet: </author> <title> A high-speed, self-configuring local area network using point-to-point links. </title> <type> Research Report 59, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: The Echo servers were running on 6-processor Fireflies and used DEC RA-90 disks. Client and server machines were connected by the 100 Mbit/sec AN1 network <ref> [23] </ref>. The one Unix benchmark was run on a 1-processor VAX, again using the 3 MIPS MicroVAX chip, but with DEC RA-82 disks. Table 1 shows the results of a simple compilation benchmark. <p> The Echo system uses the AN1 network <ref> [23] </ref>, which achieves very high availability through redundancy, though Ethernet and most other non-redundant local area networks have high enough availability for the purpose.
Reference: [24] <author> Sun Microsystems, Inc. NFS: </author> <title> Network file system protocol specification. </title> <type> RFC 1094, </type> <institution> Network Information Center, SRI International, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: Our desire to present a single-system image also led us to emulate a single-machine Unix 2 file system more carefully than some other distributed file systems have done. For example, unlike NFS <ref> [21, 24] </ref>, Echo keeps a file that has been unlinked from the name space in existence as long as any application program has it open.
Reference: [25] <author> Garret Swart, Andrew Birrell, Andy Hisgen, Charles Jerian, and Timothy Mann. </author> <title> Availability in the Echo file system. </title> <type> Research report, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: This paper concentrates on Echo's client cache. Separate papers give a complete overview of Echo [4] and discuss various other aspects in detail <ref> [9, 10, 11, 12, 18, 25] </ref>. In the next section we discuss the motivation for Echo's cache design; then in Section 3 we present the cache's coherence and ordering semantics and the facilities for reporting lost write-behind.
Reference: [26] <author> Charles P. Thacker, Lawrence C. Stewart, and Edwin H. Satterthwaite Jr. Firefly: </author> <title> A multiprocessor workstation. </title> <type> Research Report 23, </type> <institution> Systems Research Center, Digital Equipment Corporation, </institution> <month> December </month> <year> 1987. </year>
Reference-contexts: Hence, except where specifically stated, the running times measured in these benchmarks do not include the time to flush writes to disk with sync or fsync. In all the benchmarks discussed below, the Echo clerk and the benchmark programs themselves were running on a 4-processor Firefly <ref> [26] </ref>, with each processor a 3 MIPS MicroVAX chip. The Echo servers were running on 6-processor Fireflies and used DEC RA-90 disks. Client and server machines were connected by the 100 Mbit/sec AN1 network [23].
Reference: [27] <author> B. Walker, G. Popek, R. English, C. Kline, and G. Thiel. </author> <title> The LOCUS distributed operating system. </title> <booktitle> In Proc. 9th Symp. on Operating Systems Principles, </booktitle> <pages> pages 49-70. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1983. </year>
Reference-contexts: This goal led us to implement a file cache with strict coherence and a replication scheme with strict consistency between copies. We chose not to explore the alternative approach used in the LOCUS <ref> [20, 27] </ref> and Coda [15] file systems, in which replicas or cached copies of files are allowed to diverge during periods when the network is not fully connected. <p> The Echo system uses the AN1 network [23], which achieves very high availability through redundancy, though Ethernet and most other non-redundant local area networks have high enough availability for the purpose. On networks that are often unavailable, however, file systems that allow controlled forms of incoherence, such as LOCUS <ref> [20, 27] </ref> and Coda [15], may be more practical. If the system's token directory is lost, all client machines lose their write-behind, disrupting the work of many users. Therefore the token directory must be either replicated, recoverable from clients after a server crash, or both.
Reference: [28] <author> Brent Welch and John Ousterhout. </author> <title> Prefix tables: A simple mechanism for locating files in a distributed filesystem. </title> <booktitle> In Proc. 6th Intl. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 184-189. </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1986. </year> <month> 45 </month>
Reference-contexts: Sprite clerks do prefix caching so that most requests can be sent directly to the correct server, without the need to broadcast or consult a name server first <ref> [28] </ref>. A prefix cache is not a full-fledged directory cache; it simply maps prefixes of absolute pathnames to the servers that store the files whose names begin with those prefixes.
References-found: 28

