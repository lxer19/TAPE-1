URL: http://www.cs.jhu.edu/~weiss/winnow.ps
Refering-URL: http://www.cs.jhu.edu/~weiss/ir.html
Root-URL: 
Email: weiss@cs.jhu.edu  kasif@eecs.uiuc.edu  
Title: Winnow vs. SMART: A Comparison in the Newsgroup Classification Domain  
Author: Scott A. Weiss Simon Kasif 
Date: April 24, 1997  
Address: Chicago  
Affiliation: Department of Computer Science The Johns Hopkins University  Department of Computer Science University of Illinois at  
Abstract: We detail our continuing investigation into the problem of classifying USENET postings by newsgroup. Our best results utilize a simple method we called full-text concatenation in the SMART information retrieval system. In this paper, we describe our variant on Littlestone and Warmuth's Winnow algorithm to perform the classification task. We discuss the important differences between our method and standard Winnow, and the way in which this domain differs from standard tasks. We provide experimental results showing the effects of different parameters on accuracy, and compare Winnow's performance to the SMART algorithm.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Golding and D. Roth. </author> <title> Applying winnow to context-sensitive spelling correction. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Machine Learning, </booktitle> <pages> pages 182-190, </pages> <address> San Francisco, CA, </address> <month> July </month> <year> 1996. </year> <month> 9 </month>
Reference-contexts: Notice that this is similar to the problem posed in the perceptron algorithm [4]. Winnow has been used successfully in domains such as spelling correction <ref> [1] </ref>. The basic Winnow algorithm is straightforward. We are given a set of examples classified as A or :A, each with the same n attributes.
Reference: [2] <author> K. Lang. Newsweeder: </author> <title> Learning to filter netnews. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 331-339, </pages> <address> Tahoe City, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: There have been a number of projects that attempt to provide some order to the USENET. Most involve the routing task of delivering interesting or relevant 1 articles to the user. Examples include the SIFT project at Stanford [7] and the Newsweeder project <ref> [2] </ref> from CMU. Some search engines on the World Wide Web, such as Infoseek and Alta Vista, also allow users to do keyword searches on the recent newsgroup postings. In our previous work [6], we investigated the classification problem. A user submits an article for posting.
Reference: [3] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: a new linear threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: The term selection created very short metadocuments. We hypothesized that we required a better method of feature selection that could heighten the importance of certain terms, but not completely eliminate low-frequency terms. 2 Winnow We decided to apply the Winnow algorithm designed by Littlestone <ref> [3] </ref> to this domain. Winnow is a machine learning algorithm for determining the optimal 2 parameters for a linear thresholding function. Consider a space where each example has attributes x 1 ; x 2 ; : : : ; x n , and one of two labels A or :A.
Reference: [4] <author> M. Minsky and S. Papert. </author> <title> Perceptrons. </title> <publisher> MIT Press, </publisher> <year> 1969. </year>
Reference-contexts: We wish to learn the weights w 1 ; : : : ; w n that maximize the number of correct classifications on past and future examples. Notice that this is similar to the problem posed in the perceptron algorithm <ref> [4] </ref>. Winnow has been used successfully in domains such as spelling correction [1]. The basic Winnow algorithm is straightforward. We are given a set of examples classified as A or :A, each with the same n attributes.
Reference: [5] <author> G. Salton. </author> <title> The SMART Retrieval System Experiments in Automatic Document Processing. </title> <publisher> Prentice Hall, </publisher> <year> 1971. </year>
Reference-contexts: We called our technique the metadocument approach. Each newsgroup is represented by a single document created by analyzing a collection of training documents. These metadocuments are then cast into a vector space as in the SMART information retrieval system <ref> [5] </ref>. The features of a metadocument vector represent the words that occur in it.
Reference: [6] <author> S. Weiss, S. Kasif, and E. Brill. </author> <title> Text categorization in usenet newsgroups: A progress report. </title> <booktitle> In Working Notes of the 1996 AAAI Spring Symposium on Machine Learning in Information Access, </booktitle> <address> Stanford, CA, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: Examples include the SIFT project at Stanford [7] and the Newsweeder project [2] from CMU. Some search engines on the World Wide Web, such as Infoseek and Alta Vista, also allow users to do keyword searches on the recent newsgroup postings. In our previous work <ref> [6] </ref>, we investigated the classification problem. A user submits an article for posting. We would like to automatically determine the appropriate newsgroup (s) to which it should be directed. We called our technique the metadocument approach. <p> These "typical" documents were then concatenated to form a metadocument. In optimal term selection, we built a metadocument from those terms whose presence strongly indicated a particular group. See our paper <ref> [6] </ref> for more details. The size of the resultant metadocument appeared to be directly correlated with accuracy. The full-text concatenation method (which used all the training terms to form a metadocument) had the best accuracy. <p> In our previous paper <ref> [6] </ref>, our second-best accuracies achieved accuracies of 76% with typical document selection and 73% with term selection (using 100 documents per group for training, 8 Training/Test Sizes Full-text Winnow 100-200 0.89 0.85 200-100 0.87 0.87 Table 4: SMART vs.
Reference: [7] <author> T. Yan and H. Garcia-Molina. </author> <title> Sift a tool for wide-area information dissemination. </title> <booktitle> Proceedings of the 1995 USENIX Technical Conference, </booktitle> <pages> pages 177-186, </pages> <year> 1995. </year>
Reference-contexts: These and other "worthless" postings make finding useful information difficult. There have been a number of projects that attempt to provide some order to the USENET. Most involve the routing task of delivering interesting or relevant 1 articles to the user. Examples include the SIFT project at Stanford <ref> [7] </ref> and the Newsweeder project [2] from CMU. Some search engines on the World Wide Web, such as Infoseek and Alta Vista, also allow users to do keyword searches on the recent newsgroup postings. In our previous work [6], we investigated the classification problem.
References-found: 7

