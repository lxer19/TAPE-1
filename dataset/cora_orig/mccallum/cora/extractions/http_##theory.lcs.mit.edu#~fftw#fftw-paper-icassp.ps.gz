URL: http://theory.lcs.mit.edu/~fftw/fftw-paper-icassp.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~fftw/
Root-URL: 
Email: athena@theory.lcs.mit.edu  stevenj@alum.mit.edu  
Title: FFTW: AN ADAPTIVE SOFTWARE ARCHITECTURE FOR THE FFT  
Author: Matteo Frigo Steven G. Johnson 
Address: 545 Technology Square NE43-203 Cambridge, MA 02139  77 Massachusetts Avenue, 12-104 Cambridge, MA 02139  
Affiliation: MIT Laboratory for Computer Science  Massachusetts Institute of Technology  
Abstract: FFT literature has been mostly concerned with minimizing the number of floating-point operations performed by an algorithm. Unfortunately, on present-day microprocessors this measure is far less important than it used to be, and interactions with the processor pipeline and the memory hierarchy have a larger impact on performance. Consequently, one must know the details of a computer architecture in order to design a fast algorithm. In this paper, we propose an adaptive FFT program that tunes the computation automatically for any particular hardware. We compared our program, called FFTW, with over 40 implementations of the FFT on 7 machines. Our tests show that FFTW's self-optimizing approach usually yields significantly better performance than all other publicly available software. FFTW also compares favorably with machine-specific, vendor-optimized libraries. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Oppenheim and R. W. Schafer, </author> <title> Discrete-time Signal Processing. </title> <address> Englewood Cliffs, NJ 07632: </address> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: 1. INTRODUCTION The discrete Fourier transform (DFT) is an important tool in many branches of science and engineering <ref> [1] </ref> and has been studied extensively [2]. For many practical applications, it is important to have an implementation of the DFT that is as fast as possible. In the past, speed was the direct consequence of clever algorithms [2] that minimized the number of arithmetic operations. <p> The executor works by explicit recursion, in contrast with the traditional loop-based implementations <ref> [1, page 608] </ref>. We chose an explicitly recursive implementation because of theoretical evidence that divide-and-conquer algorithms improve locality [8]. For example, as soon as a subproblem fits into the cache, no further cache misses are needed in order to solve that subproblem. We planner for N = 32768. <p> This AST contains some useless code, such as multiplications by 0 and 1, but the code is polished by the following optimization phase. The current version of the AST generator contains knowledge of many DFT algorithms, including Cooley-Tukey (in the form presented in <ref> [1, page 611] </ref>), a prime factor algorithm (as described in [1, page 619]), a split-radix algorithm [2], and Rader's algorithm for transforms of prime length [9]. Our first implementation of the Cooley-Tukey AST generator consisted of 60 lines of Caml code. <p> The current version of the AST generator contains knowledge of many DFT algorithms, including Cooley-Tukey (in the form presented in [1, page 611]), a prime factor algorithm (as described in <ref> [1, page 619] </ref>), a split-radix algorithm [2], and Rader's algorithm for transforms of prime length [9]. Our first implementation of the Cooley-Tukey AST generator consisted of 60 lines of Caml code.
Reference: [2] <author> P. Duhamel and M. Vetterli, </author> <title> Fast Fourier transforms: a tutorial review and a state of the art, </title> <booktitle> Signal Processing, </booktitle> <volume> vol. 19, </volume> <pages> pp. 259299, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: 1. INTRODUCTION The discrete Fourier transform (DFT) is an important tool in many branches of science and engineering [1] and has been studied extensively <ref> [2] </ref>. For many practical applications, it is important to have an implementation of the DFT that is as fast as possible. In the past, speed was the direct consequence of clever algorithms [2] that minimized the number of arithmetic operations. <p> (DFT) is an important tool in many branches of science and engineering [1] and has been studied extensively <ref> [2] </ref>. For many practical applications, it is important to have an implementation of the DFT that is as fast as possible. In the past, speed was the direct consequence of clever algorithms [2] that minimized the number of arithmetic operations. On present-day general-purpose microprocessors, however, the performance of a program is mostly determined by complicated interactions of the code with the processor pipeline, and by the structure of the memory. <p> The current version of the AST generator contains knowledge of many DFT algorithms, including Cooley-Tukey (in the form presented in [1, page 611]), a prime factor algorithm (as described in [1, page 619]), a split-radix algorithm <ref> [2] </ref>, and Rader's algorithm for transforms of prime length [9]. Our first implementation of the Cooley-Tukey AST generator consisted of 60 lines of Caml code.
Reference: [3] <author> J. W. Cooley and J. W. Tukey, </author> <title> An algorithm for the machine computation of the complex Fourier series, </title> <journal> Mathematics of Computation, </journal> <volume> vol. 19, </volume> <pages> pp. 297301, </pages> <month> Apr. </month> <year> 1965. </year>
Reference-contexts: In this paper, we address this problem by means of a novel adaptive approach, where the program itself adapts the computation to the details of the hardware. We developed FFTW, an adaptive, high performance implementation of the Cooley-Tukey fast Fourier transform (FFT) algorithm <ref> [3] </ref>, written in C. We have compared many C and Fortran implementations of the DFT on several machines, and our experiments show that FFTW typically yields significantly better performance than all other publicly available DFT software. <p> We also discuss how FFTW builds a plan (a sequence of instructions that specifies the operation of the executor). Finally, we present evidence that FFTW's adaptive architecture is a good idea. The executor implements the Cooley-Tukey FFT algorithm <ref> [3] </ref>, which centers around factoring the size N of the transform into N = N 1 N 2 .
Reference: [4] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms. </title> <address> Cambridge, Massachusetts: </address> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The combination of codelets applied by the executor is specified by a special data structure called a plan. The plan is determined at runtime, before the computation begins, by a planner which uses a dynamic programming algorithm <ref> [4, chapter 16] </ref> to find a fast composition of codelets. The planner tries to minimize the actual execution time, and not the number of floating point operations, since, as we show in Section 2, there there is little correlation between these two performance measures. <p> Ideally, FFTW's planner should try all possible plans. This approach, however, is not practical due to the combinatorial explosion of the number of plans. Instead, the planner uses a dynamic-programming algorithm <ref> [4, chapter 16] </ref> to prune the search space. In order to use dynamic-programming, we assumed optimal substructure [4]: if an optimal plan for a size N is known, this plan is still optimal when size N is used as a subproblem of a larger transform. <p> Ideally, FFTW's planner should try all possible plans. This approach, however, is not practical due to the combinatorial explosion of the number of plans. Instead, the planner uses a dynamic-programming algorithm [4, chapter 16] to prune the search space. In order to use dynamic-programming, we assumed optimal substructure <ref> [4] </ref>: if an optimal plan for a size N is known, this plan is still optimal when size N is used as a subproblem of a larger transform. This assumption is in principle false because of the different states of the cache in the two cases.
Reference: [5] <author> X. Leroy, </author> <title> The Caml Light system release 0.71. </title> <institution> Institut National de Recherche en Informatique at Automatique (IN-RIA), </institution> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: For this reason, we found it convenient to generate the codelets automatically by means of a special-purpose compiler. FFTW's codelet generator, written in the Caml Light dialect of the functional language ML <ref> [5] </ref>, is a sophisticated program that first produces a representation of the codelet in the form of abstract C syntax tree, and then optimizes the codelet by applying well known transformations such as constant folding and algebraic identities. <p> The codelet generator accepts as input an integer N and produces a normal or a twiddle codelet that computes the Fourier transform of size N (either the forward or backward transform). The generator is written in the Caml Light dialect of ML <ref> [5] </ref>. Caml is an applicative, polymorphic, and strongly typed functional language with first-class functions, algebraic data types, and pattern matching. The generator operates on a subset of the abstract syntax tree (AST) of the C language. First, the generator produces an AST for a nave program that computes the transform.
Reference: [6] <author> M. Frigo and S. G. Johnson. </author> <note> http://theory.lcs. mit.edu/fftw. </note>
Reference-contexts: FFTW provides a function that creates a plan for a transform of a specified size, and once the plan has been created it can be used as many times as needed. The FFTW library (currently at version 1.2) is publicly available at our WWW page <ref> [6] </ref>. FFTW is not a toy system, but a production-quality library that already enjoys many hundreds of users. FFTW performs one- and multidimensional transforms, and it is not restricted to input sizes that are powers of 2. A parallel version of the executor, written in Cilk [7], also exists. <p> PERFORMANCE RESULTS We have compared FFTW with over 40 other complex FFT implementations on 7 platforms, but due to space constraints we can only present a small, characteristic selection of that data here. (For more results, see <ref> [6] </ref>.) In Figure 4, the performance is shown for the 8 fastest codes on an UltraSPARC, along with that of 4 other interesting or well-known programs.
Reference: [7] <author> R. D. Blumofe, C. F. Joerg, B. C. Kuszmaul, C. E. Leis-erson, K. H. Randall, and Y. Zhou, Cilk: </author> <title> An efficient multithreaded runtime system, </title> <booktitle> in Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), </booktitle> <address> (Santa Barbara, California), </address> <pages> pp. </pages> <address> 207216, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: FFTW is not a toy system, but a production-quality library that already enjoys many hundreds of users. FFTW performs one- and multidimensional transforms, and it is not restricted to input sizes that are powers of 2. A parallel version of the executor, written in Cilk <ref> [7] </ref>, also exists. The rest of the paper is organized as follows. In Section 2 we outline the runtime structure of FFTW, consisting of the executor and the planner. In Section 3 we briefly describe the compile-time structure of FFTWthat is, the codelet generator.
Reference: [8] <author> R. D. Blumofe, M. Frigo, C. F. Joerg, C. E. Leiserson, and K. H. Randall, </author> <title> An analysis of dag-consistent distributed shared-memory algorithms, </title> <booktitle> in Proceedings of the Eighth Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), (Padua, Italy), </booktitle> <pages> pp. 297308, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: The executor works by explicit recursion, in contrast with the traditional loop-based implementations [1, page 608]. We chose an explicitly recursive implementation because of theoretical evidence that divide-and-conquer algorithms improve locality <ref> [8] </ref>. For example, as soon as a subproblem fits into the cache, no further cache misses are needed in order to solve that subproblem. We planner for N = 32768. The units of speed (MFLOPS) and the machine are described in Section 4.
Reference: [9] <author> C. M. Rader, </author> <title> Discrete Fourier transforms when the number of data samples is prime, </title> <journal> Proc. of the IEEE, </journal> <volume> vol. 56, </volume> <pages> pp. 11071108, </pages> <month> June </month> <year> 1968. </year>
Reference-contexts: The current version of the AST generator contains knowledge of many DFT algorithms, including Cooley-Tukey (in the form presented in [1, page 611]), a prime factor algorithm (as described in [1, page 619]), a split-radix algorithm [2], and Rader's algorithm for transforms of prime length <ref> [9] </ref>. Our first implementation of the Cooley-Tukey AST generator consisted of 60 lines of Caml code.
Reference: [10] <author> C. V. Loan, </author> <title> Computational Frameworks for the Fast Fourier Transform. </title> <address> Philadelphia: </address> <publisher> SIAM, </publisher> <year> 1992. </year>
Reference-contexts: Speed is measured in MFLOPS, defined for a transform of size N as (5N log 2 N )t, where t is the time in s (see <ref> [10, page 45] </ref>). The codes are listed in the legend under the author's name (or by program name if it is more well-known), and are sorted by average relative performance. They include the Sun Performance Library version 1.2 (SUNPERF); public-domain code by T. Ooura (Fortran, 1996), J.
Reference: [11] <author> P. N. Swarztrauber, </author> <title> Vectorizing the FFTs, </title> <booktitle> Parallel Computations, </booktitle> <pages> pp. 5183, </pages> <year> 1982. </year> <editor> G. </editor> <publisher> Rodrigue ed. </publisher>
Reference-contexts: They include the Sun Performance Library version 1.2 (SUNPERF); public-domain code by T. Ooura (Fortran, 1996), J. Green (C, 1996), and R. H. Krukar (C, 1990); the Fortran FFT-PACK library <ref> [11] </ref>; a Fortran split-radix FFT by Sorensen [12]; a Fortran FFT by Singleton [13]; Temperton's Fortran GPFA code [14]; Bailey's 4-step FFT implementation [15]; Sitton's QFT code [16]; and the four1 routine from [17] (NRF). We get similar numbers on other machines.
Reference: [12] <author> H. V. Sorensen, M. T. Heideman, and C. S. Burrus, </author> <title> On computing the split-radix FFT, </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> vol. 34, </volume> <pages> pp. 152156, </pages> <month> Feb. </month> <year> 1986. </year>
Reference-contexts: They include the Sun Performance Library version 1.2 (SUNPERF); public-domain code by T. Ooura (Fortran, 1996), J. Green (C, 1996), and R. H. Krukar (C, 1990); the Fortran FFT-PACK library [11]; a Fortran split-radix FFT by Sorensen <ref> [12] </ref>; a Fortran FFT by Singleton [13]; Temperton's Fortran GPFA code [14]; Bailey's 4-step FFT implementation [15]; Sitton's QFT code [16]; and the four1 routine from [17] (NRF). We get similar numbers on other machines.
Reference: [13] <author> R. C. </author> <title> Singleton, An algorithm for computing the mixed radix fast Fourier transform, </title> <journal> IEEE Transactions on Audio and Electroacoustics, </journal> <volume> vol. AU-17, </volume> <pages> pp. 93103, </pages> <month> June </month> <year> 1969. </year>
Reference-contexts: They include the Sun Performance Library version 1.2 (SUNPERF); public-domain code by T. Ooura (Fortran, 1996), J. Green (C, 1996), and R. H. Krukar (C, 1990); the Fortran FFT-PACK library [11]; a Fortran split-radix FFT by Sorensen [12]; a Fortran FFT by Singleton <ref> [13] </ref>; Temperton's Fortran GPFA code [14]; Bailey's 4-step FFT implementation [15]; Sitton's QFT code [16]; and the four1 routine from [17] (NRF). We get similar numbers on other machines.
Reference: [14] <author> C. Temperton, </author> <title> A generalized prime factor FFT algorithm for any n = 2 p 3 q 5 r , SIAM Journal on Scientific and Statistical Computing, </title> <journal> vol. </journal> <volume> 13, </volume> <pages> pp. 676686, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: They include the Sun Performance Library version 1.2 (SUNPERF); public-domain code by T. Ooura (Fortran, 1996), J. Green (C, 1996), and R. H. Krukar (C, 1990); the Fortran FFT-PACK library [11]; a Fortran split-radix FFT by Sorensen [12]; a Fortran FFT by Singleton [13]; Temperton's Fortran GPFA code <ref> [14] </ref>; Bailey's 4-step FFT implementation [15]; Sitton's QFT code [16]; and the four1 routine from [17] (NRF). We get similar numbers on other machines.
Reference: [15] <author> D. H. Bailey, </author> <title> A high-performance FFT algorithm for vector supercomputers, </title> <journal> Intl. Journal on Supercomputing Applications, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 8287, </pages> <year> 1988. </year>
Reference-contexts: Ooura (Fortran, 1996), J. Green (C, 1996), and R. H. Krukar (C, 1990); the Fortran FFT-PACK library [11]; a Fortran split-radix FFT by Sorensen [12]; a Fortran FFT by Singleton [13]; Temperton's Fortran GPFA code [14]; Bailey's 4-step FFT implementation <ref> [15] </ref>; Sitton's QFT code [16]; and the four1 routine from [17] (NRF). We get similar numbers on other machines.
Reference: [16] <author> H. Guo, G. A. Sitton, and C. S. Burrus, </author> <title> The quick discrete fourier transform, </title> <booktitle> in Proc. IEEE Int. Conf. Acoust., Speech, and Signal Proc., </booktitle> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Ooura (Fortran, 1996), J. Green (C, 1996), and R. H. Krukar (C, 1990); the Fortran FFT-PACK library [11]; a Fortran split-radix FFT by Sorensen [12]; a Fortran FFT by Singleton [13]; Temperton's Fortran GPFA code [14]; Bailey's 4-step FFT implementation [15]; Sitton's QFT code <ref> [16] </ref>; and the four1 routine from [17] (NRF). We get similar numbers on other machines. For example, on an IBM RS/6000, FFTW ranges from 55% faster than IBM's ESSL library for N = 64, to 12% slower for N = 16384, to again 7% faster for N = 131072. 5.
Reference: [17] <author> W. H. Press, S. A. Teukolsky, and W. T. Vetterling, </author> <title> Numerical Recipes in Fortran: </title> <booktitle> The Art of Scientific Computing. </booktitle> <address> New York, NY: </address> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Green (C, 1996), and R. H. Krukar (C, 1990); the Fortran FFT-PACK library [11]; a Fortran split-radix FFT by Sorensen [12]; a Fortran FFT by Singleton [13]; Temperton's Fortran GPFA code [14]; Bailey's 4-step FFT implementation [15]; Sitton's QFT code [16]; and the four1 routine from <ref> [17] </ref> (NRF). We get similar numbers on other machines. For example, on an IBM RS/6000, FFTW ranges from 55% faster than IBM's ESSL library for N = 64, to 12% slower for N = 16384, to again 7% faster for N = 131072. 5.
Reference: [18] <author> S. K. S. Gupta, C. Huang, P. Sadayappan, and R. W. John-son, </author> <title> A framework for generating distributed-memory parallel programs for block recursive algorithms, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 34, </volume> <pages> pp. 137153, </pages> <month> 1 May </month> <year> 1996. </year>
Reference-contexts: CONCLUSION We believe computer architectures have become so complex that manually optimizing software is difficult to the point of impracticality. Our FFTW system is a method of dealing with such complexity. Similar ideas have been incorporated by other researchers <ref> [18] </ref> into an interesting system called EXTENT which uses a tensor product framework to synthesize Fortran FFTs for multiprocessors. Like FFTW, EXTENT generates code optimized for speed, but unlike FFTW, the generated program only works for one transform size.
Reference: [19] <author> S. Kamin, </author> <title> Standard ML as a meta-programming language. </title> <type> Unpublished technical report, </type> <note> available from s-kamin@uiuc.edu, </note> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: Like FFTW, EXTENT generates code optimized for speed, but unlike FFTW, the generated program only works for one transform size. The idea of using ML as a metalanguage for generating C applications first appeared, to the best of our knowledge, in <ref> [19] </ref>. Other automatic systems for the generation of FFT programs include [20], which describes the generation of FFT programs for prime sizes. [21] presents a generator of Pascal programs implementing a prime factor FFT algorithm. Johnson and Burrus [22] applied dynamic programming to the design of optimal DFT modules.
Reference: [20] <author> I. Selesnick and C. S. Burrus, </author> <title> Automatic generation of prime length FFT programs, </title> <journal> IEEE Transactions on Signal Processing, </journal> <pages> pp. 1424, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: The idea of using ML as a metalanguage for generating C applications first appeared, to the best of our knowledge, in [19]. Other automatic systems for the generation of FFT programs include <ref> [20] </ref>, which describes the generation of FFT programs for prime sizes. [21] presents a generator of Pascal programs implementing a prime factor FFT algorithm. Johnson and Burrus [22] applied dynamic programming to the design of optimal DFT modules.
Reference: [21] <author> F. Perez and T. Takaoka, </author> <title> A prime factor FFT algorithm implementation using a program generation technique, </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> vol. 35, </volume> <pages> pp. 12211223, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: The idea of using ML as a metalanguage for generating C applications first appeared, to the best of our knowledge, in [19]. Other automatic systems for the generation of FFT programs include [20], which describes the generation of FFT programs for prime sizes. <ref> [21] </ref> presents a generator of Pascal programs implementing a prime factor FFT algorithm. Johnson and Burrus [22] applied dynamic programming to the design of optimal DFT modules. These systems all try to minimize the arithmetic complexity of the transform rather than its execution time.
Reference: [22] <author> H. W. Johnson and C. S. Burrus, </author> <title> The design of optimal DFT algorithms using dynamic programming, </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> vol. 31, </volume> <pages> pp. 378387, </pages> <month> Apr. </month> <year> 1983. </year>
Reference-contexts: Other automatic systems for the generation of FFT programs include [20], which describes the generation of FFT programs for prime sizes. [21] presents a generator of Pascal programs implementing a prime factor FFT algorithm. Johnson and Burrus <ref> [22] </ref> applied dynamic programming to the design of optimal DFT modules. These systems all try to minimize the arithmetic complexity of the transform rather than its execution time. Adaptive techniques such as the ones we have used appear very attractive, but much work remains to be done.
References-found: 22

