URL: http://www.cs.gatech.edu/grads/f/Harold.Forbes/complex.ps.Z
Refering-URL: http://www.cs.gatech.edu/grads/f/Harold.Forbes/mppubs.html
Root-URL: 
Title: Object Technologies and Real-Time Scheduling  
Author: Harold Forbes Karsten Schwan 
Date: October 2, 1995  
Address: Atlanta, GA 30332  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: Any object-based real-time system gives rise to real-time scheduling issues not easily solved by use of standard scheduling methods, including: (1) the invocation of an object's method may imply the need for online schedulability analysis for the thread(s) able to execute method code, (2) parallelism internal to objects may result in the need to schedule multiple threads and target processors simultaneously, and (3) methods that invoke other methods as part of their execution give rise to hierarchically composed groups of to-be-scheduled real-time threads. The Rapid scheduler presented in this paper addresses such dynamic object-based real-time systems for target machines comprised of both multi- and uniprocessor machines. To address the variety of needs of object-based real-time systems, Rapid is 1) configurable to the target multiprocessor architecture, 2) dynamically re-configurable to changes in application requirements, 3) efficient in terms of processor utilization, and 4) effective in producing high quality schedules. Rapid's current implementation addresses hard deadline application, with future work concerning alternative formulations of timing constraints. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <type> Technical report, </type> <institution> Department of Computer Science and Engineering, University of Washington, TR 90-04-02, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: Performance ad vantages derived from the resulting asynchrony among steps (1)-(3) are evaluated in Section 3. In future work, alternative implementations of internal interactions among different scheduler components will be evaluated to address the general topic of suitable operating system interfaces for real-time operating systems' resource managers <ref> [1] </ref>. The remainder of this paper is structured as follows. In Section 2, the internal structure of Rapid is described in detail, in order to explain the performance measurements in Section 3. Conclusions and future research appear in Section 4. 2 The Rapid Scheduler functional decomposition of the object system.
Reference: [2] <author> Tomas E Bihari, Thomas M Walliser, and Mark R Patterson. </author> <title> Controlling the adaptive suspension vehicle. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 59-64, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Invocation of a high-level object may require that scheduling analysis be accomplished for multiple lower level objects on multiple processors in order to guarantee that resources are available to complete the invocation on time. For example, on a walking robot such as ASV <ref> [2] </ref>, the atomic invocation of Robot$move would cause a sequence of invocations to Robot$step. Robot$step would in turn cause a sequence of invocations to leg$move and a parallel invocation of leg$push for each leg of the robot (see figure 1).
Reference: [3] <author> Ben Blake. </author> <title> A Fast, Effective Scheduling Framework for Parallel Computing Systems. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, Ohio State University, </institution> <year> 1990. </year> <month> C-128-B. </month>
Reference-contexts: In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [11]. Multiprocessor implementations of internally concurrent schedulers were first described in <ref> [3] </ref>, then generalized and evaluated rigorously and experimentally in [10, 14]. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines.
Reference: [4] <author> H. Burkhardt III, S. Frank, B. Knobe, and J. Rothnie. </author> <title> Overview of the ksr1 computer system. </title> <type> Technical Report KSR-TR-9202001, </type> <institution> Kendall Square Research, </institution> <address> Boston, </address> <month> February </month> <year> 1992. </year>
Reference: [5] <author> Dilip D. Kandlur, Daniel L. Kiskis, and Kang G. Shin. HARTOS: </author> <title> A distributed real-time operating system. </title> <booktitle> In Operating Systems Review of ACM SIGOPS, </booktitle> <pages> pages 72-89. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1989. </year>
Reference: [6] <author> C. D. Locke, H. Tokuda, and E. D. Jensen. </author> <title> A time-driven scheduling model for real-time operating systems. </title> <type> Technical report, </type> <institution> Carnegie-Mellon University, </institution> <year> 1985. </year>
Reference-contexts: The synchronous interface generates an offer to ensure that prospective tasks are examined in latency order and to allow opportunistic scheduling concurrency. While there is no optimal algorithm for dynamic multiprocessor scheduling [7], least latency first is an effective scheduling policy <ref> [6, 14] </ref>. Creating an offer can also decrease scheduling latency for a task that must be analyzed on multiple slot lists either because analysis fails on one or more slot lists, or because the task is scheduled with a best-fit policy.
Reference: [7] <author> A. K. Mok and M. L. Dertouzos. </author> <title> Multiprocessor scheduling in a hard real-time environment. </title> <booktitle> In Proc. of the Seventh Texas Conference on Computing Systems, </booktitle> <month> November </month> <year> 1978. </year>
Reference-contexts: Both the asynchronous and synchronous interfaces to Rapid generate offers. The synchronous interface generates an offer to ensure that prospective tasks are examined in latency order and to allow opportunistic scheduling concurrency. While there is no optimal algorithm for dynamic multiprocessor scheduling <ref> [7] </ref>, least latency first is an effective scheduling policy [6, 14]. Creating an offer can also decrease scheduling latency for a task that must be analyzed on multiple slot lists either because analysis fails on one or more slot lists, or because the task is scheduled with a best-fit policy.
Reference: [8] <author> Douglas Niehaus, Krithi Ramamritham, John A. Stankovic, Gary Wallace, and Charles Weems. </author> <title> The spring scheduling co-processor: Design, use and performance. </title> <booktitle> In Proceedings of the Real-Time Systems Symposium, </booktitle> <pages> pages 106-111. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: On-line real-time scheduling. On-line real-time schedulers have been constructed in many past and several recent research efforts. The Spring operating system designers have implemented and evaluated multiprocessor schedulers running on single, dedicated nodes of small-scale parallel embedded systems [12], with recent work addressing hardware support for on-line scheduling <ref> [8] </ref>, and past work addressing distributed real-time systems [9]. Shin et al.[5] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling. <p> The fundamental problem with extending Rapid to non-shared memory computers involves generating and resolving multiple copies of a single offer. It may be necessary to provide a third scheduling component that specifically handles non-local offers. This is the approach used by Spring <ref> [8] </ref>. It is inevitable that scheduling latency will increase for non-local offers. The application interface needs further research. Most objects will not be satisfied with a failed scheduling analysis. They will possibly adjust some system or task parameters and try to schedule the task again.
Reference: [9] <author> K. Ramamritham, J. Stankovic, and Wl Zhao. </author> <title> Distributed scheduling of tasks with deadlines and resource requirements. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 1,110-1,123, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: The Spring operating system designers have implemented and evaluated multiprocessor schedulers running on single, dedicated nodes of small-scale parallel embedded systems [12], with recent work addressing hardware support for on-line scheduling [8], and past work addressing distributed real-time systems <ref> [9] </ref>. Shin et al.[5] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling. In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [11].
Reference: [10] <author> Karsten Schwan and Hongyi Zhou. </author> <title> Dynamic scheduling of hard real-time tasks and real-time threads. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(8) </volume> <pages> 736-748, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [11]. Multiprocessor implementations of internally concurrent schedulers were first described in [3], then generalized and evaluated rigorously and experimentally in <ref> [10, 14] </ref>. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines. Also, higher level mechanisms for managing soft real-time parallel applications are being studied at the University of Rochester [13].
Reference: [11] <author> Brinkley Sprunt, Lui Sha, and John Lehoczky. </author> <title> Aperiodic task scheduling for hard-real-time systems. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 1 </volume> <pages> 27-60, </pages> <year> 1989. </year> <month> 16 </month>
Reference-contexts: Shin et al.[5] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling. In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms <ref> [11] </ref>. Multiprocessor implementations of internally concurrent schedulers were first described in [3], then generalized and evaluated rigorously and experimentally in [10, 14]. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines.
Reference: [12] <author> J. A. Stankovic and K. Ramamritham. </author> <title> The spring kernel: A new paradigm for real-time systems. </title> <journal> IEEE Software, </journal> <volume> 8(3) </volume> <pages> 62-72, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: On-line real-time scheduling. On-line real-time schedulers have been constructed in many past and several recent research efforts. The Spring operating system designers have implemented and evaluated multiprocessor schedulers running on single, dedicated nodes of small-scale parallel embedded systems <ref> [12] </ref>, with recent work addressing hardware support for on-line scheduling [8], and past work addressing distributed real-time systems [9]. Shin et al.[5] and the HartOS operating system group has experimented with tradeoffs in communication vs. performance and quality in distributed real-time scheduling.
Reference: [13] <author> R. W. Wisniewski and C. M. Brown. Ephor, </author> <title> a run-time environment for parallel intelligent applications. </title> <booktitle> In Proceedings of the Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <pages> pages 51-60, </pages> <address> April 1993. Newport Beach, CA. </address>
Reference-contexts: The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines. Also, higher level mechanisms for managing soft real-time parallel applications are being studied at the University of Rochester <ref> [13] </ref>. Scheduler performance and concurrency. The Rapid scheduler builds on our previous research in real-time, multiprocessor threads [14], but focuses on two topics not explored to date: (1) the use of concurrency during scheduling and (2) the efficient implementation of concurrent multiprocessor schedulers on large scale parallel machines.
Reference: [14] <author> Hongyi Zhou, Karsten Schwan, and Ian F Akyildiz. </author> <title> Performance effects of information sharing in a distributed multiprocessor real-time scheduler. </title> <booktitle> In Real-Time Systems Symposium. IEEE, IEEE, </booktitle> <year> 1992. </year> <note> Also available as GIT-CC-91/40 from Ga. Tech. 17 </note>
Reference-contexts: The synchronous interface is 2 for scheduling tasks with very low latency requirements while the asynchronous interface supports efficient, high-throughput scheduling of sets of tasks. And, because Rapid is concurrent, both synchronous scheduling and asynchronous scheduling can occur simultaneously. Finally, Rapid's use of Zhou's slot-list dynamic scheduling algorithm <ref> [14] </ref> ensures that scheduling a task on a processor is as efficient and effective as currently possible. On-line real-time scheduling. On-line real-time schedulers have been constructed in many past and several recent research efforts. <p> In addition, research at Carnegie Mellon University has been extending priority-based scheduling methods to address dynamic system behaviors, typically by development of novel scheduling algorithms [11]. Multiprocessor implementations of internally concurrent schedulers were first described in [3], then generalized and evaluated rigorously and experimentally in <ref> [10, 14] </ref>. The latter work also developed new algorithms for schedulability analysis and addressed the scalability of schedulers in terms of their locality characteristics on large-scale parallel machines. Also, higher level mechanisms for managing soft real-time parallel applications are being studied at the University of Rochester [13]. <p> Also, higher level mechanisms for managing soft real-time parallel applications are being studied at the University of Rochester [13]. Scheduler performance and concurrency. The Rapid scheduler builds on our previous research in real-time, multiprocessor threads <ref> [14] </ref>, but focuses on two topics not explored to date: (1) the use of concurrency during scheduling and (2) the efficient implementation of concurrent multiprocessor schedulers on large scale parallel machines. <p> This research currently uses a 64-node shared memory KSR-2 multiprocessor; its primary contributions are: * Scheduler concurrency in contrast to <ref> [14] </ref>, schedulability analysis and scheduling are performed by multiple, concurrently executed threads, thereby enabling us to vary both the latency of scheduling for individual requests and scheduling throughput, by variation of internal scheduler concurrency. Presentation of performance gains due to parallelism appear in Section 3. <p> In addition to a scheduler, a scheduling group contains a slot list (SL), a task list (TL), and a Dispatcher for each processor in the group. A slot list is the data structure of Zhou's <ref> [14] </ref> scheduling algorithm that records the times in the future that the processor is busy. <p> The synchronous interface generates an offer to ensure that prospective tasks are examined in latency order and to allow opportunistic scheduling concurrency. While there is no optimal algorithm for dynamic multiprocessor scheduling [7], least latency first is an effective scheduling policy <ref> [6, 14] </ref>. Creating an offer can also decrease scheduling latency for a task that must be analyzed on multiple slot lists either because analysis fails on one or more slot lists, or because the task is scheduled with a best-fit policy. <p> In the synchronous interface, the fork makes a procedure call to the scheduler. In both cases, if preliminary analysis fails, the fork procedure returns failure to the calling task. 2 This type of analysis has been previously described in <ref> [14] </ref>. 6 The scheduler, whether executing synchronously or asynchronously, accomplishes the slot list analysis phase by the following pseudo code: While ( Now + analysis_time () + selection_time () &lt; scheduler_deadline ) - offer = find_eligible_offer (offer_list) for_each processor in scheduling_group - if ( now + analysis_time () &lt; scheduler_deadline ) <p> Preliminary analysis contributes to Rapid's efficiency by using an O (1) heuristic to filter out obviously unshedulable tasks <ref> [14] </ref> before running the O (n log n) slot list algorithm. However, preliminary analysis can decrease Rapid's effectiveness through false rejections. The maximum number of schedulers that can simultaneously attempt to analyze a single offer can be set for each offer generated. <p> A mechanism similar to Zhou's interval list and an enhancement of preliminary scheduling analysis may be sufficient to implement hierarchical processor utilization control. Acknowledgments. Hongyi Zhou has provided some assistance in comparing the quality of Rapid scheduling to her previous results published in <ref> [14] </ref>. 15
References-found: 14

