URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR354.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: An Implementation of an Applicative File System  
Author: Brian C. Heck and David S. Wise 
Keyword: CR categories and Subject Descriptors: D.4.2 [Storage Management]: Storage hierarchies; D.1.1 [Applicative (Functional) Programming]; E.2 [Data Storage Representations]: Linked representations; H.0 [Information Systems]. General Term: Design. Additional Key Words and Phrases: Reference counting heap, mark/sweep garbage collection, hardware, Scheme, functional programming.  
Address: Bloomington, IN 47405-4101 USA  
Affiliation: Computer Science Department Indiana University  
Pubnum: Technical Report 354  
Email: Email: heckb@cs.indiana.edu  
Phone: Fax: +1 (812) 855-4829  
Abstract: A purely functional file system has been built on top of pure Scheme. It provides persistent structures and massive storage expected of file systems, without explicit side-effects like read and write. The file system becomes an additional, lazy argument to programs that would read from it, and an additional result from functions that would alter it. Functional programming on lazy structures replaces in-place side-effects with a significant storage management problem, handled by conjoining the heap to the file system. A hardware implementation of reference counting is extended out to manage sectors, as well as the primary heap. Backing it is a garbage collector of heap and of disk (i.e. UNIX's fsck), needed only at reboot. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> John Backus. </author> <title> Can programming be liberated from the von Neumann style? A functional style and its algebra of programs. </title> <journal> Comm. ACM, </journal> <month> 21,8 (August </month> <year> 1978), </year> <pages> 613-641. </pages>
Reference-contexts: Sometimes the problem is set aside, and the language enjoys an absence of restriction on transactions that are "outside" the program, as in ML, Lisp 1.5, or Scheme. Such languages do not extend very well to parallel processing. Other languages attempt to isolate the problem: Backus's ASM in FP <ref> [1] </ref>, William's and Wimmer's histories in FL [16], and Lucassen's and Gifford's effect streams in FX [10] are all serious efforts to encapsulate the "impure" file activity in order to isolate it from the "pure" functional portion of the language. Haskell [5] follows this tack.
Reference: 2. <author> David J. McNally and Antony J. T. Davie. </author> <title> Two models for integrating persistence and lazy functional languages. </title> <journal> SIGPLAN Notices, </journal> <month> 26,5 (May </month> <year> 1991), </year> <pages> 43-52. </pages>
Reference-contexts: Haskell [5] follows this tack. Alternatively, the time or scope for creation of persistent structures has been restricted <ref> [2] </ref>. In contrast, this research neither partitions nor encapsulates data.
Reference: 3. <author> Daniel P. Friedman and David S. Wise. </author> <title> Garbage collecting a heap which includes a scatter table. </title> <note> Information Processing Letters 5,6 (Dec 1976), 161-164. </note>
Reference-contexts: One consideration for migration of graphs to disk is that multiply referenced nodes provide opportunities for data sharing and introduce a possibility of circularity. We assert that circularity in manifest graphs can be detected and sector reference counts corrected to allow reference counting to collect the disk structures <ref> [3] </ref>. As for suspensions, we would install them into the file system verbatim, that is, unexpanded. The suspensions would remain persistent on disk, but heap resident versions could be thawed and allowed to continue their work.
Reference: 4. <author> Daniel P. Friedman and David S. Wise. </author> <title> Aspects of applicative programming for file systems. </title> <booktitle> In Proc. of ACM Conf. on Language Design for Reliable Software, SIGPLAN Notices 12,3 (Mar 1977), </booktitle> <pages> 41-55. </pages>
Reference-contexts: Similarly, it has long been understood that Landin's streams [9], or lazy evaluation, allows a simple system to be expressed as an applicative program <ref> [4, 6] </ref> whose input is the stream stdin and whose output is the stream stdout. However, two things essential to a full operating system are still missing from such models: some kind of indeterminism, e.g. to interleave multiple, asynchronous inputs; and a persistent file system to cushion users against failures. <p> This is not to say that the entire file will be heap resident at any given time; if the file is sufficiently large that may not be possible). 7 Examples The first example is a file editor taken from Friedman's and Wise's <ref> [4] </ref> paper. The example editor consumes a list of commands (stored in the file "commands"), applies the commands to the contents of another file "rhyme", and returns a list. We then install the list as a new version of the file "rhyme" in a new file system.
Reference: 5. <editor> Paul Hudak, Simon Peyton Jones, and Philip Wadler (eds.). </editor> <title> Report on the Programming Language Haskell. </title> <journal> SIGPLAN Notices 27,5 (May 1992), R1-R164. </journal>
Reference-contexts: However, as often as they are taught and used, their scope of application has been restricted to formalism, to toy algorithms, and to simple systems. True, "purity" has been constrained at higher levels, to yield success stories like Lisp's (with side effects), ML's [11] (without laziness), and maybe Haskell's <ref> [5] </ref> (under UNIX I/O). With such constraints, however, they are unlikely to fulfill their acknowledged promise for parallel processing. ?? To appear in Proc. Intl. <p> Haskell <ref> [5] </ref> follows this tack. Alternatively, the time or scope for creation of persistent structures has been restricted [2]. In contrast, this research neither partitions nor encapsulates data.
Reference: 6. <author> Peter Henderson, Geraint A. Jones, and Simon B. Jones. </author> <title> The LispKit Manual. </title> <type> Tech. Monograph PRG-32 (2 vols.), </type> <institution> Programming Research Grp., Oxford Univ. </institution> <year> (1983). </year>
Reference-contexts: Similarly, it has long been understood that Landin's streams [9], or lazy evaluation, allows a simple system to be expressed as an applicative program <ref> [4, 6] </ref> whose input is the stream stdin and whose output is the stream stdout. However, two things essential to a full operating system are still missing from such models: some kind of indeterminism, e.g. to interleave multiple, asynchronous inputs; and a persistent file system to cushion users against failures.
Reference: 7. <author> Donald E. Knuth. </author> <booktitle> The Art of Computer Programming 1 (2nd edition), </booktitle> <address> Reading, MA, </address> <publisher> Addison Wesley (1973). </publisher>
Reference-contexts: In ffi 1 (the root of the old file system), both links still point to the old data structure, 1 . 6.1 File Creation A request for migration of a data structure ff to disk initiates a preorder-sequential compression <ref> [7] </ref> of ff into a set of sectors P + . At some time (undefined but "soon") after a request to make a data structure a file, the data structure will become persistent. Currently, AFS has eager behavior inherited from Scheme, but implicit laziness could be inserted.
Reference: 8. <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The ObjectStore database system, </title> <journal> Comm. ACM 34,10 (Oct 1991), </journal> <pages> 50-63. </pages>
Reference-contexts: Alternatively, the time or scope for creation of persistent structures has been restricted [2]. In contrast, this research neither partitions nor encapsulates data. This treatment, in fact, would be transparent to the user if she were not required to participate, contributing some important declarations about her data. (ObjectStore <ref> [8] </ref>, a general database system, similarly depends on only a few type assertions.) This is experimental work; one test of success is just to build a hierarchical memory in a purely functional environment without any "barriers." Another is to make it work well. We have succeeded in the first test.
Reference: 9. <author> P. J. Landin. </author> <title> A correspondence between ALGOL 60 and Church's lambda notation: Part I. </title> <journal> Comm. ACM 8,2 (Feb 1965), </journal> <pages> 89-101. </pages>
Reference-contexts: Although one can argue that important, non-"toy" algorithms (like divide-and-conquer tree searching or Strassen's matrix multiplication) were first invented and are best taught using functional style; nevertheless, even these are used in production from C or Fortran source code. Similarly, it has long been understood that Landin's streams <ref> [9] </ref>, or lazy evaluation, allows a simple system to be expressed as an applicative program [4, 6] whose input is the stream stdin and whose output is the stream stdout.
Reference: 10. <author> John M. Lucassen and David K. Gifford. </author> <title> Polymorphic effect systems. </title> <booktitle> Conf. Rec. 15th ACM Symp. on Principles of Programming Languages (Jan 1988), </booktitle> <pages> 47-57. </pages>
Reference-contexts: Such languages do not extend very well to parallel processing. Other languages attempt to isolate the problem: Backus's ASM in FP [1], William's and Wimmer's histories in FL [16], and Lucassen's and Gifford's effect streams in FX <ref> [10] </ref> are all serious efforts to encapsulate the "impure" file activity in order to isolate it from the "pure" functional portion of the language. Haskell [5] follows this tack. Alternatively, the time or scope for creation of persistent structures has been restricted [2].
Reference: 11. <author> R. Milner, M. Tofte, and R. Harper. </author> <title> The Definition of Standard ML. </title> <address> Cambridge, MA, </address> <publisher> MIT Press (1990). </publisher>
Reference-contexts: However, as often as they are taught and used, their scope of application has been restricted to formalism, to toy algorithms, and to simple systems. True, "purity" has been constrained at higher levels, to yield success stories like Lisp's (with side effects), ML's <ref> [11] </ref> (without laziness), and maybe Haskell's [5] (under UNIX I/O). With such constraints, however, they are unlikely to fulfill their acknowledged promise for parallel processing. ?? To appear in Proc. Intl.
Reference: 12. <author> D. M. Ritchie and K. Thompson. </author> <title> The UNIX time-sharing system. </title> <journal> Bell System Tech. J. 57,6 (Jul-Aug 1978), </journal> <pages> 1905-1930. </pages>
Reference-contexts: With 1024-byte sectors this yields a quarter-gigabyte file system. However, the effect of internal fragmentation reduces this. Moreover, the present tests were run on a prototype file-system of 4000 sectors, so to demonstrate a space-constrained configuration. AFS's directory structure is modeled after UNIX <ref> [12, 14] </ref>. All files have an associated data node (dnode) similar to a UNIX inode except that there are no indirect pointers. Dnodes contain a single pointer to the unique first sector of the file.
Reference: 13. <institution> Lightship Software. MacScheme c flVersion 1.9 development. Beaverton, </institution> <address> OR (1989). </address>
Reference-contexts: Early benchmarks show it running MachScheme (hobbled to use a recursive stack) faster than equivalent code using a RAM heap [18]. MachScheme is MacScheme <ref> [13] </ref> ported to the Mach operating system on the NeXT computer, and subsequently revised to use RCM for its heap of binary nodes.
Reference: 14. <author> K. Thompson. </author> <title> UNIX Implementation. </title> <journal> Bell System Tech. J. 57,6 (Jul-Aug 1978), </journal> <pages> 1931-1946. </pages>
Reference-contexts: With 1024-byte sectors this yields a quarter-gigabyte file system. However, the effect of internal fragmentation reduces this. Moreover, the present tests were run on a prototype file-system of 4000 sectors, so to demonstrate a space-constrained configuration. AFS's directory structure is modeled after UNIX <ref> [12, 14] </ref>. All files have an associated data node (dnode) similar to a UNIX inode except that there are no indirect pointers. Dnodes contain a single pointer to the unique first sector of the file.
Reference: 15. <author> J. Weizenbaum. </author> <title> Symmetric list processor. </title> <journal> Comm. </journal> <note> ACM 6,9 (Dec 1963), 524-544. </note>
Reference-contexts: Each of these three operations requires only finite time; a node can return to available space still containing live, yet-counted pointers <ref> [15] </ref>. Thus, one memory location can, on one hand, handle a store and, on the other, act on a couple increments or decrements during one memory cycle. RCM is controlled by reading or writing to special memory registers.
Reference: 16. <author> John H. Williams and Edward Wimmers. </author> <title> Sacrificing simplicity for convenience: where do you draw the line? Conf. </title> <booktitle> Rec. 15th ACM Symp. on Principles of Programming Languages (Jan 1988), </booktitle> <pages> 169-179. 16 </pages>
Reference-contexts: Such languages do not extend very well to parallel processing. Other languages attempt to isolate the problem: Backus's ASM in FP [1], William's and Wimmer's histories in FL <ref> [16] </ref>, and Lucassen's and Gifford's effect streams in FX [10] are all serious efforts to encapsulate the "impure" file activity in order to isolate it from the "pure" functional portion of the language. Haskell [5] follows this tack.
Reference: 17. <author> David S. Wise. </author> <title> Design for a multiprocessing heap with on-board reference counting. </title> <editor> In P. Jouannaud (ed.), </editor> <booktitle> Functional Programming Languages and Computer Architecture, Lecture Notes in Computer Science 201, </booktitle> <address> Berlin, </address> <publisher> Springer (Sept 1985), </publisher> <pages> 289-304. </pages>
Reference-contexts: A foundation to the system is the hardware implementation of Reference Counting Memory (RCM) <ref> [17, 18] </ref>. RCM is reported elsewhere, and the interesting story here is how AFS was laid over it. However, a brief overview of the hardware is necessary first. 3.1 Reference Counting in Hardware RCM has been implemented as a device on a NeXT computer.
Reference: 18. <author> David S. Wise, Caleb Hess, Willie Hunt, and Eric Ost. </author> <title> Uniprocessor performance of a reference-counting hardware heap. </title> <type> Tech. </type> <institution> Rept., Computer Science Department, </institution> <note> Indiana Univ. </note> <editor> (in preparation). </editor> <title> This article was processed using the L a T E X macro package with LLNCS style 17 </title>
Reference-contexts: A foundation to the system is the hardware implementation of Reference Counting Memory (RCM) <ref> [17, 18] </ref>. RCM is reported elsewhere, and the interesting story here is how AFS was laid over it. However, a brief overview of the hardware is necessary first. 3.1 Reference Counting in Hardware RCM has been implemented as a device on a NeXT computer. <p> Early benchmarks show it running MachScheme (hobbled to use a recursive stack) faster than equivalent code using a RAM heap <ref> [18] </ref>. MachScheme is MacScheme [13] ported to the Mach operating system on the NeXT computer, and subsequently revised to use RCM for its heap of binary nodes.
References-found: 18

