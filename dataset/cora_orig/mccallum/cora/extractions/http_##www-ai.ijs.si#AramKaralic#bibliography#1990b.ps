URL: http://www-ai.ijs.si/AramKaralic/bibliography/1990b.ps
Refering-URL: http://www-ai.ijs.si/AramKaralic/bibliography/1990b.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Experiments With Assistant in  
Author: Rheumatology Aram Karalic, Vladimir Pirnat 
Date: (december 1990)  
Pubnum: IJS delovno porocilo DP-5909  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Mladenic, D.: "Magnus Asistent: sistem za avtomatsko ucenje", diplomsko delo, Univerza v Ljubljani, </author> <note> Fakulteta za elektrotehniko in racunalnistvo, Ljubljana, </note> <year> 1990. </year>
Reference: [2] <author> Karalic, A., Pirnat, V.: </author> <title> "Significance Level Based Classification With Multiple Trees", </title> <address> IJS delovno porocilo DP-6040, Ljubljana, </address> <month> Januar </month> <year> 1991. </year>
Reference: [3] <author> Shortliffe, E.: </author> <title> "Computer-based Medical Consultations: MYCIN", </title> <publisher> Elsevier, </publisher> <year> 1976. </year>
Reference-contexts: Most of the well known expert systems, such as MYCIN <ref> [3] </ref> and PROSPECTOR [4] were constructed this way. This method of knowledge-acquisition at the present state of the expert systems technology makes the knowledge-base construction the most expensive and time consuming stage in the development of expert systems. The problem is known as the "Feigenbaum bottleneck".
Reference: [4] <author> Duda, R., Gaschnig, J., Hart, P.: </author> <title> "Model design in the Prospector consultant system for mineral exploration", Expert systems in the Microelectronic Age, </title> <publisher> Edinburgh University Press, </publisher> <year> 1979. </year>
Reference-contexts: Most of the well known expert systems, such as MYCIN [3] and PROSPECTOR <ref> [4] </ref> were constructed this way. This method of knowledge-acquisition at the present state of the expert systems technology makes the knowledge-base construction the most expensive and time consuming stage in the development of expert systems. The problem is known as the "Feigenbaum bottleneck".
Reference: [5] <author> Quinlan, J.R.: </author> <title> "Induction of decision trees", Machine learning 1, </title> <publisher> Kluwer academic press Publishers, </publisher> <address> Boston, </address> <year> 1986. </year>
Reference-contexts: diseased joints ~ H H H H H H H H H H H Hj sex @ @ @R pain in joints ~ @ @ @ male rheumatologist female other doctor artrotic pain RTG A AU artritic pain Menell ~ ff A The method is based on Quinlan's ID3 approach <ref> [5] </ref> whereby several improvements have been added to the original Quinlan's algorithm. These improvements are described elsewhere [8] and deal mostly with new methods to combat noise in the data (incorrect data) and incompleteness of the data (missing values for some attributes).
Reference: [6] <author> Kononenko, I., Bratko,I.: </author> <title> "Evaluation of performance of inductive learning systems", </title> <booktitle> proceedings of XXXI Yugoslav conference for ETAN, </booktitle> <address> Bled, </address> <year> 1987. </year>
Reference-contexts: classification accuracy: percentage of the unseen patients, which were cor rectly classified (diagnosed) by the induced decision tree. * Entropy: average amount of information (bits) needed to correctly classify one pa tient. 9 * Information content: amount of the information, contributed by the tree for classi- fication of one example <ref> [6] </ref>. * Relative information content (RIC): RIC = information content entropy The experiments with ASSISTANT were run on MicroVAX II. Parameter settings for the system were as listed in Figure 6.
Reference: [7] <author> Kononenko, I.: "Razvoj sistema za induktivno ucenje Asistent", magistrsko delo, Univerza Edvarda Kardelja v Ljubljani, Fakulteta za elektrotehniko, Ljubljana, </author> <year> 1985. </year>
Reference-contexts: For example: from observing how the doctor diagnosed 10000 patients, such a system could learn how to diagnose previously unseen patients. This kind of learning is called learning from examples. For automatic learning from examples a system called ASSISTANT <ref> [7] </ref> was developed at the E. Kardelj University, Faculty of Electrical and Computer Engineering, and Jo`ef Stefan Institute in Ljubljana. Knowledge synthesis in ASSISTANT is based on learning from examples.
Reference: [8] <author> Cestnik, B., Kononenko, I., Bratko, I.: </author> <title> "ASSISTANT 86: A Knowldege elicitation tool for sophisticated users", v: Bratko, </title> <editor> I., Lavrac, N. (ured.): </editor> <booktitle> Progress in Machine Learning, </booktitle> <publisher> Sigma Press, </publisher> <address> Wilmslow, </address> <year> 1987. </year>
Reference-contexts: These improvements are described elsewhere <ref> [8] </ref> and deal mostly with new methods to combat noise in the data (incorrect data) and incompleteness of the data (missing values for some attributes). ASSISTANT's learning algorithm first selects the most informative attribute and splits a learning set into subsets.
Reference: [9] <author> Mladenic, D.: "Magnus Asistent: sistem za avtomatsko ucenje", diplomsko delo, Univerza v Ljubljani, </author> <note> Fakulteta za elektrotehniko in racunalnistvo, Ljubljana, 1990. 13 </note>
References-found: 9

