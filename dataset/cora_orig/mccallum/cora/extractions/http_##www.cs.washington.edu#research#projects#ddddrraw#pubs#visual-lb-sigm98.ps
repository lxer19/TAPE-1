URL: http://www.cs.washington.edu/research/projects/ddddrraw/pubs/visual-lb-sigm98.ps
Refering-URL: http://www.cs.washington.edu/research/projects/ddddrraw/pubs/visual-lb.abstract.html
Root-URL: 
Title: Scheduling Policies to Support Distributed 3D Multimedia Applications  
Author: Thu D. Nguyen and John Zahorjan 
Date: June 1998  
Note: To Appear In Proceedings of the SIGMETRICS '98/ PERFORMANCE '98 Joint International Conference on Measurement and Modeling of Computer Systems,  
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington,  
Abstract: We consider the problem of scheduling the rendering component of 3D multimedia applications on a cluster of workstations connected via a local area network. Our goal is to meet a periodic real-time constraint. In abstract terms, the problem we address is how best to schedule tasks with unpredictable service times on distinct processing nodes so as to meet a real-time deadline, given that all communication among nodes entails some (possibly large) overhead. We consider two distinct classes of schemes, static, in which task reallocations are scheduled to occur at specific times, and dynamic, in which reallocations are triggered by some processor going idle. For both classes we further examine both global reassignments, in which all nodes are rescheduled at a rescheduling moment, and local reassignments, in which only a subset of the nodes engage in rescheduling at any one time. We show that global dynamic policies work best over a range of parameterizations appropriate to such systems. We introduce a new policy, Dynamic with Shadowing, that places a small number of tasks in the schedules of multiple workstations to reduce the amount of communication required to complete the schedule. This policy is shown to dominate the other alternatives considered over most of the parameter space. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bestavros. </author> <title> Load Profiling in Distributed Real-Time Systems. </title> <journal> Information Sciences, </journal> <volume> 101(12):127, </volume> <month> Sept. </month> <year> 1997. </year>
Reference-contexts: Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., [12, 25, 4, 6]), especially those that dealt with real-time tasks (e.g., <ref> [9, 1] </ref>). However, the former had as a goal minimizing response time, rather than meeting real-time deadlines, while the latter addressed workloads in which each task had its own deadline, rather than our situation in which there is a single deadline for the ensemble of tasks.
Reference: [2] <author> C.-I. H. Chen and V. Cherkassky. </author> <title> Task Reallocation for Fault Tolerance in Multiprocessor Systems. </title> <booktitle> In Proceedings of the IEEE 1990 National Aerospace and Electronics Conference, </booktitle> <pages> pages 495500, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., [10, 19]) as well as scheduling of fault-tolerance real-time systems (e.g., <ref> [8, 2] </ref>), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [3] <author> T. W. Crockett. </author> <title> An Introduction to Parallel Rendering. </title> <booktitle> Parallel Computing, </booktitle> <address> 23(7):819843, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Thus, scene descriptions that stress the main memory capacities of current workstations are almost certainly too complicated to be rendered in real-time, even on multiple processors. 1.1 Related Work Although our work is motivated by the parallel rendering problem, unlike much of the previous work on parallel rendering <ref> [3] </ref>, we are as concerned with minimizing the inter-frame variance as we are with maximizing the mean frame rate.
Reference: [4] <author> D. Eager, E. Lazowska, and J. Zahorjan. </author> <title> Adaptive Load Sharing in Homogeneous Distributed Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12(5):662675, </volume> <month> May </month> <year> 1986. </year>
Reference-contexts: Lastly, we evaluate the policies based on the probability that a deadline is met, rather than on the average time to complete all the work. Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., <ref> [12, 25, 4, 6] </ref>), especially those that dealt with real-time tasks (e.g., [9, 1]).
Reference: [5] <author> D. A. Ellsworth. </author> <title> A New Algorithm for Interactive Graphics on Multicomputers. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 14(4):3340, </volume> <month> July </month> <year> 1994. </year>
Reference-contexts: We assume that a higher level component of the sched-uler, not addressed here, uses information about object rendering times obtained over a sequence of frames to occasionally regroup scene objects into roughly equal sized tasks. (Example of such schemes have been de scribed in <ref> [5, 15] </ref>.) * The cost of communicating for the purposes of scheduling is relatively large, on the order of a few percent of the deadline time.
Reference: [6] <author> M. Harchol-Balter and A. B. Downey. </author> <title> Exploiting Process Lifetime Distributions for Dynamic Load Balancing. </title> <booktitle> In Proceedings of the ACM SIGMETRICS Conference, </booktitle> <pages> pages 1324, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Lastly, we evaluate the policies based on the probability that a deadline is met, rather than on the average time to complete all the work. Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., <ref> [12, 25, 4, 6] </ref>), especially those that dealt with real-time tasks (e.g., [9, 1]).
Reference: [7] <author> D. D. Kouvatsos. </author> <title> Entropy Maximisation and Queueing Network Models. </title> <journal> Annals of Operations Research, </journal> <volume> 48(14):63126, </volume> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: More specifically, we assume that task execution times are exponentially distributed. A major advantage of the exponential over other potential distributions is that it allows us to find an optimal schedule for the static policy we propose. Additionally, it is the maximum entropy distribution <ref> [7] </ref>, and so is motivated by the absence of information available at this time on actual task time distributions (which is highly data dependent in any case). We denote the mean task service time by 1=.
Reference: [8] <author> C. M. Krishna and K. G. Shin. </author> <title> On Scheduling Tasks with a Quick Recovery from Failure. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-35(5):448455, </volume> <month> May </month> <year> 1986. </year>
Reference-contexts: Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., [10, 19]) as well as scheduling of fault-tolerance real-time systems (e.g., <ref> [8, 2] </ref>), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [9] <author> J. F. Kurose and R. Chipalkatti. </author> <title> Load Sharing in Soft Real-Time Distributed Computer Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-36(8):9931000, </volume> <month> Aug. </month> <year> 1987. </year>
Reference-contexts: Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., [12, 25, 4, 6]), especially those that dealt with real-time tasks (e.g., <ref> [9, 1] </ref>). However, the former had as a goal minimizing response time, rather than meeting real-time deadlines, while the latter addressed workloads in which each task had its own deadline, rather than our situation in which there is a single deadline for the ensemble of tasks.
Reference: [10] <author> C. Liu and J. Layland. </author> <title> Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment. </title> <journal> Journal of the ACM, </journal> <volume> 20(1):4661, </volume> <month> Jan. </month> <year> 1973. </year>
Reference-contexts: While Shekhar et al. consider some similar policies, they are not concerned with meeting a real-time deadline. Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., <ref> [10, 19] </ref>) as well as scheduling of fault-tolerance real-time systems (e.g., [8, 2]), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [11] <author> J. Liu and V. A. Saletore. </author> <title> Self-Scheduling on Distributed-Memory Machines. </title> <booktitle> In Supercomputing '93, </booktitle> <pages> pages 814823, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [18, 21, 11, 16] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when work remains against the overhead of finding that work. <p> Broadcasting a single message to all processors and then waiting until a message is received from each (using UDP/IP) con 2 This policy is very similar to a number of loop scheduling policies that have been proposed for NUMA systems <ref> [11, 13, 16, 24] </ref>, and shares with nearly all loop scheduling strategies the essential property that chunk sizes decrease as the size of the work pool decreases. sumes about 0.3 ms of CPU on both the sender and the re-ceivers, with a lag of about 0.7 ms 3 .
Reference: [12] <author> M. Livny and M. Melman. </author> <title> Load Balancing in Homogeneous Broadcast Distributed Systems. </title> <booktitle> In Proceedings of the ACM Computer Network Performance Symposium, </booktitle> <pages> pages 4755, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Lastly, we evaluate the policies based on the probability that a deadline is met, rather than on the average time to complete all the work. Finally, our work is also related in spirit to earlier results on load balancing in distributed systems (e.g., <ref> [12, 25, 4, 6] </ref>), especially those that dealt with real-time tasks (e.g., [9, 1]).
Reference: [13] <author> E. P. Markatos and T. J. LeBlanc. </author> <title> Using Processor Affinity in Loop Scheduling on Shared-Memory Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(4):379400, </volume> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Broadcasting a single message to all processors and then waiting until a message is received from each (using UDP/IP) con 2 This policy is very similar to a number of loop scheduling policies that have been proposed for NUMA systems <ref> [11, 13, 16, 24] </ref>, and shares with nearly all loop scheduling strategies the essential property that chunk sizes decrease as the size of the work pool decreases. sumes about 0.3 ms of CPU on both the sender and the re-ceivers, with a lag of about 0.7 ms 3 .
Reference: [14] <author> T. D. Nguyen and J. Zahorjan. </author> <title> Scheduling Policies to Support Distributed Multi-Media Applications. </title> <type> Technical Report 97-11-03, </type> <institution> University of Washington, Department of Computer Science and Engineering, </institution> <note> (http://www.cs.washington.edu/homes/zahorjan/ddddrraw /papers/intraframe lb abstract.html), </note> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: In our prototype system, a VRML viewer [23], fl This work supported in part by the National Science Foundation (Grants CCR-9704503 and CCR-9200832), Microsoft Corporation, and Intel Corporation. An extended version of this paper is available as reference <ref> [14] </ref>. which allows interactive manipulation of 3D scenes downloaded over the World Wide Web, is the canonical application. In this context, improving performance means extending the complexity of the scenes that can be rendered at a sufficiently fast as well as consistent frame rate. <p> Because of space limitations, we present only some representative results here, and limit our discussion to the cases where full replication of the scene description is possible (the global policies). A longer version of this paper <ref> [14] </ref> (available online) presents the full set of results, and shows that global variants of the policies dominate the local ones.
Reference: [15] <author> D. Nicol and J. Saltz. </author> <title> Dynamic Remapping of Parallel Computations with Varying Resource Demands. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 37(9):10731087, </volume> <month> Septem-ber </month> <year> 1988. </year>
Reference-contexts: We assume that a higher level component of the sched-uler, not addressed here, uses information about object rendering times obtained over a sequence of frames to occasionally regroup scene objects into roughly equal sized tasks. (Example of such schemes have been de scribed in <ref> [5, 15] </ref>.) * The cost of communicating for the purposes of scheduling is relatively large, on the order of a few percent of the deadline time.
Reference: [16] <author> S. Orlando and R. Perego. </author> <title> Exploiting Partial Replication in Unbalanced Parallel Loop Scheduling on Multi-computers. </title> <journal> Microprocessing and Microprogramming, </journal> <volume> 41(89):645658, </volume> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [18, 21, 11, 16] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when work remains against the overhead of finding that work. <p> Broadcasting a single message to all processors and then waiting until a message is received from each (using UDP/IP) con 2 This policy is very similar to a number of loop scheduling policies that have been proposed for NUMA systems <ref> [11, 13, 16, 24] </ref>, and shares with nearly all loop scheduling strategies the essential property that chunk sizes decrease as the size of the work pool decreases. sumes about 0.3 ms of CPU on both the sender and the re-ceivers, with a lag of about 0.7 ms 3 .
Reference: [17] <author> S. Pakin, V. Karamcheti, and A. Chien. </author> <title> Fast Mes--sages: Efficient, Portable Communication for Workstation Clusters and MPPs. </title> <journal> IEEE Concurrency, </journal> <volume> 5(2):60 72, </volume> <month> Apr. </month> <year> 1997. </year>
Reference-contexts: The static policy (SMR) is dominated by one or more dynamic policies in nearly all of our experiments. The exceptions are when there are many processors and many tasks 3 Unfortunately, current production operating systems impose overheads that are considerably larger than those achievable experimentally (e.g., <ref> [17, 22] </ref>). (which corresponds to low workload variance), and the communication overhead is large. As our evaluation of the static policy is optimistic with respect to any real implementation, we conclude that dynamic policies are most appropriate for the prototype system we are building and others like it.
Reference: [18] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided Self-Scheduling: A Practical Scheduling Scheme for Parallel Supercomputers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(12):14251439, </volume> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [18, 21, 11, 16] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when work remains against the overhead of finding that work.
Reference: [19] <author> K. Ramamritham, J. A. Stankovic, and P.-F. Shiah. </author> <title> Efficient Scheduling Algorithms for Real-Time Multiprocessor Systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(2), </volume> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: While Shekhar et al. consider some similar policies, they are not concerned with meeting a real-time deadline. Our work also differs in a number of respects from the established literature on real-time scheduling. For one thing, in contrast to the classical work on schedulability (e.g., <ref> [10, 19] </ref>) as well as scheduling of fault-tolerance real-time systems (e.g., [8, 2]), there is a single deadline by which all of our tasks must be completed, rather than a deadline per task.
Reference: [20] <author> S. Shekhar, S. Ravada, V. Kumar, D. Chubb, and G. Turner. </author> <title> Declustering and Load-Balancing Methods for Parallelizing Geographic Information Systems. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <note> To Appear. </note>
Reference-contexts: Thus, in this paper, we address the problem of scheduling to maximize the probability of meeting a real-time deadline as opposed to structuring the parallel rendering system to maximize the mean frame rate. Our work is perhaps closest in spirit to that of Shekhar et al. <ref> [20] </ref>. While Shekhar et al. consider some similar policies, they are not concerned with meeting a real-time deadline. Our work also differs in a number of respects from the established literature on real-time scheduling.
Reference: [21] <author> T. H. Tzen and L. M. Ni. </author> <title> Trapezoid Self-Scheduling: </title>
Reference-contexts: Our work is related to efforts in loop scheduling for parallel processors (e.g., <ref> [18, 21, 11, 16] </ref>) in that the basic problem a loop scheduling discipline must solve is how to balance the performance loss due to processors going idle when work remains against the overhead of finding that work.
References-found: 21

