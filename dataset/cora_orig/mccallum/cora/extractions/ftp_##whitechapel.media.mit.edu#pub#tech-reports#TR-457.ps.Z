URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-457.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: (jdavis j bobick@media.mit.edu)  
Title: A Silhouette-based Interactive Dual-screen Environment  
Author: James W. Davis Aaron F. Bobick 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: MIT Media Laboratory,  
Note: SIDEshow:  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 457 Vision and Modeling group Abstract In this paper, we present a new multi-screen interactive environment. The system extracts a silhouette of the participant for driving the interaction using a method that overcomes the inherent problems associated with traditional chroma-keying, background subtraction, and rear-light projection methods. We present an approach for generating a robust silhouette of the participant using specialized infrared lighting while not making the underlying technology apparent to those interacting within the system. The design also enables video projection screens to be placed in front of and behind the user without interfering with the silhouette extraction process. The framework itself is a portable system which can act as a re-usable infrastructure for many interactive projects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Darrell, T., P. Maes, B. Blumberg, and A. Pent-land. </author> <title> A novel environment for situated vision and behavior. In IEEE Wkshp. for Visual Behaviors (CVPR-94), </title> <year> 1994. </year>
Reference-contexts: 1 Introduction When designing interactive environments, it's imperative for the system to be engaging as well as be reliably "aware" of the person (or people) interacting within the space. Many installations are designed with a single large video display, which is the main focus of attention for the user <ref> [9, 7, 8, 1, 2] </ref>. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. <p> As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. Other approaches use similar variants of chroma-keying (i.e. blue-screening) <ref> [1] </ref>, background subtraction [10, 3], or rear-light projection [5] to enable a video camera to extract a silhouette the person, where the person need not wear special clothing.
Reference: [2] <author> Davis, J. and A. Bobick. </author> <title> Virtual pat: a virtual personal aerobics trainer. MIT Media Lab Perceptual Computing Group Technical Report No. 436, </title> <publisher> MIT, </publisher> <year> 1997. </year>
Reference-contexts: 1 Introduction When designing interactive environments, it's imperative for the system to be engaging as well as be reliably "aware" of the person (or people) interacting within the space. Many installations are designed with a single large video display, which is the main focus of attention for the user <ref> [9, 7, 8, 1, 2] </ref>. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. <p> We have recently begun to develop our own interactive project in this space. To incorporate our additional research efforts of recognizing human movement, we developed a prototype system for a virtual Personal Aerobics Trainer (virtual PAT) <ref> [2] </ref>. Unlike workout video tapes or TV exercise shows, this system allows the user to create and personalize an aerobics session to meet the user's needs and desires.
Reference: [3] <author> Hogg, D. </author> <title> Model-based vision: a paradigm to see a walking person. </title> <journal> Image and Vision Computing, </journal> <volume> 1(1), </volume> <year> 1983. </year>
Reference-contexts: As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. Other approaches use similar variants of chroma-keying (i.e. blue-screening) [1], background subtraction <ref> [10, 3] </ref>, or rear-light projection [5] to enable a video camera to extract a silhouette the person, where the person need not wear special clothing.
Reference: [4] <author> Ishii, H., and B. Ullmer. </author> <title> Tangible bits: towards seamless interfaces between people, bits and atoms. </title> <booktitle> In CHI'97, </booktitle> <pages> pages 234 - 241, </pages> <year> 1997. </year>
Reference-contexts: Many installations are designed with a single large video display, which is the main focus of attention for the user [9, 7, 8, 1, 2]. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects <ref> [9, 7, 8, 4] </ref>. Other approaches use similar variants of chroma-keying (i.e. blue-screening) [1], background subtraction [10, 3], or rear-light projection [5] to enable a video camera to extract a silhouette the person, where the person need not wear special clothing.
Reference: [5] <author> Krueger, M. </author> <title> Artificial reality II. </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. Other approaches use similar variants of chroma-keying (i.e. blue-screening) [1], background subtraction [10, 3], or rear-light projection <ref> [5] </ref> to enable a video camera to extract a silhouette the person, where the person need not wear special clothing. <p> The framework we have presented is general enough for the system to used in a variety of applications. In Krueger's well known work <ref> [5] </ref>, he mainly relied on a silhouette of the participant to drive the interaction. A phosphorescent light-wall behind the user was employed to extract a clean silhouette.
Reference: [6] <author> Murray, J. </author> <title> Hamlet on the Holodeck: the Future of Narrative in Cyberspace. </title> <publisher> The Free Press, Simon & Schuster, </publisher> <year> 1997. </year>
Reference-contexts: If the space is to be used as an interactive environment, the color methods as well as the rear-light approach have an obvious technological crutch on display for all to see. Immersion is a strong requirement when building interactive environments <ref> [6] </ref>, and part of this illusion may be broken if such walls are incorporated. One slight variant of the chroma-keying method is known as background subtraction. Here a snapshot of the environment with no people inside is stored as a reference image.
Reference: [7] <author> Paradiso, J. </author> <title> Electronic music interfaces. </title> <journal> IEEE Spectrum, </journal> <volume> 34(12) </volume> <pages> 18-30, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: 1 Introduction When designing interactive environments, it's imperative for the system to be engaging as well as be reliably "aware" of the person (or people) interacting within the space. Many installations are designed with a single large video display, which is the main focus of attention for the user <ref> [9, 7, 8, 1, 2] </ref>. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. <p> Many installations are designed with a single large video display, which is the main focus of attention for the user [9, 7, 8, 1, 2]. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects <ref> [9, 7, 8, 4] </ref>. Other approaches use similar variants of chroma-keying (i.e. blue-screening) [1], background subtraction [10, 3], or rear-light projection [5] to enable a video camera to extract a silhouette the person, where the person need not wear special clothing.
Reference: [8] <author> Rekimoto, J. and N. </author> <title> Matsushita. Perceptual surfaces: towards a human and object sensitive interactive display. </title> <booktitle> In Workshop on Perceptual User Interfaces (PUI-97), </booktitle> <pages> pages 30 - 32, </pages> <month> October </month> <year> 1997. </year>
Reference-contexts: 1 Introduction When designing interactive environments, it's imperative for the system to be engaging as well as be reliably "aware" of the person (or people) interacting within the space. Many installations are designed with a single large video display, which is the main focus of attention for the user <ref> [9, 7, 8, 1, 2] </ref>. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. <p> Many installations are designed with a single large video display, which is the main focus of attention for the user [9, 7, 8, 1, 2]. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects <ref> [9, 7, 8, 4] </ref>. Other approaches use similar variants of chroma-keying (i.e. blue-screening) [1], background subtraction [10, 3], or rear-light projection [5] to enable a video camera to extract a silhouette the person, where the person need not wear special clothing.
Reference: [9] <author> Strickon, J. and J. Paradiso. </author> <title> Tracking hands above large interactive surfaces with a low-cost scanning laser rangefinder. </title> <note> In Submitted to CHI'98, </note> <year> 1998. </year>
Reference-contexts: 1 Introduction When designing interactive environments, it's imperative for the system to be engaging as well as be reliably "aware" of the person (or people) interacting within the space. Many installations are designed with a single large video display, which is the main focus of attention for the user <ref> [9, 7, 8, 1, 2] </ref>. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. <p> Many installations are designed with a single large video display, which is the main focus of attention for the user [9, 7, 8, 1, 2]. As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects <ref> [9, 7, 8, 4] </ref>. Other approaches use similar variants of chroma-keying (i.e. blue-screening) [1], background subtraction [10, 3], or rear-light projection [5] to enable a video camera to extract a silhouette the person, where the person need not wear special clothing.
Reference: [10] <author> Wren, C., Azarbayejani, A., Darrell, T., and A. Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <booktitle> In SPIE Conference on Integration Issues in Large Commercial Media Delivery Systems, </booktitle> <year> 1995. </year>
Reference-contexts: As for sensing the person in the space, some installations use specialized light, lasers, or electric field sensing to detects hands or objects [9, 7, 8, 4]. Other approaches use similar variants of chroma-keying (i.e. blue-screening) [1], background subtraction <ref> [10, 3] </ref>, or rear-light projection [5] to enable a video camera to extract a silhouette the person, where the person need not wear special clothing.
References-found: 10

