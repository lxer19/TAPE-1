URL: ftp://ftp.fas.sfu.ca/pub/cs/han/kdd/pakdd98.ps
Refering-URL: http://fas.sfu.ca/cs/research/groups/DB/sections/publication/kdd/kdd.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: fhan, nstefano, koperskig@cs.sfu.ca  
Title: Selective Materialization: An Efficient Method for Spatial Data Cube Construction  
Author: Jiawei Han, Nebojsa Stefanovic, and Krzysztof Koperski 
Keyword: Data warehouse, data mining, on-line analytical processing (OLAP), spatial databases, spatial data analysis, spatial OLAP.  
Address: Burnaby, BC, Canada V5A 1S6  
Affiliation: School of Computing Science Simon Fraser University  
Abstract: On-line analytical processing (OLAP) has gained its popularity in database industry. With a huge amount of data stored in spatial databases and the introduction of spatial components to many relational or object-relational databases, it is important to study the methods for spatial data warehousing and on-line analytical processing of spatial data. In this paper, we study methods for spatial OLAP, by integration of nonspatial on-line analytical processing (OLAP) methods with spatial database implementation techniques. A spatial data warehouse model, which consists of both spatial and nonspatial dimensions and measures, is proposed. Methods for computation of spatial data cubes and analytical processing on such spatial data cubes are studied, with several strategies proposed, including approximation and partial materialization of the spatial objects resulted from spatial OLAP operations. Some techniques for selective materialization of the spatial computation results are worked out, and the performance study has demonstrated the effectiveness of these techniques. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Agarwal, R. Agrawal, P. M. Deshpande, A. Gupta, J. F. Naughton, R. Rama-krishnan, and S. Sarawagi. </author> <title> On the computation of multidimensional aggregates. </title> <booktitle> In Proc. 1996 Int. Conf. Very Large Data Bases, </booktitle> <pages> pages 506-521, </pages> <address> Bombay, India, </address> <month> Sept. </month> <year> 1996. </year>
Reference-contexts: A variant of a star schema model is called a snowflake (schema) model [2, 10], where some dimension tables are normalized, further splitting into more tables, forming the shape similar to a piece of snowflake. With such a star/snowflake schema model, multi-dimensional databases or data cubes <ref> [1, 8] </ref> can be constructed to facilitate typical OLAP operations such as drill-down, roll-up, dicing, slicing, pivoting, etc. To model spatial data warehouses, the star/snowflake schema model is still considered to be a good choice because it provides a concise and organized warehouse structure and facilitates OLAP operations. <p> Roll-up, which generalizes one or a few dimensions (including the removal of some dimensions when desired) and performs appropriate aggregations in the corresponding measure (s). For nonspatial measures, aggregation is implemented in the same way as in nonspatial data cubes <ref> [1, 5, 13] </ref>. However, for spatial measures, aggregation takes a collection of a spatial pointers in a map or map-overlay and performs certain spatial aggregation operation, such as region merge, or map overlay. <p> Instead of computing such aggregations on-the-fly, it is often necessary to precompute some high-level views (cuboids <ref> [1] </ref>) and save them in the database as materialized views (computed cuboids) to facilitate fast OLAP operations. There are different products in (nonspatial) data warehouse industry: some materialize every cuboid, some none, and some only part of the cube (i.e., some of the cuboids). <p> There are different products in (nonspatial) data warehouse industry: some materialize every cuboid, some none, and some only part of the cube (i.e., some of the cuboids). There are interesting studies on efficient computation of data cubes <ref> [1, 13] </ref>. A previous study [8] shows that materializing every view requires a huge amount of disk space, whereas not materializing any view requires a great deal of on-the-fly, and often redundant, computation. <p> In our analysis, we have adopted the philosophy and algorithm of selective materialization of data cubes as proposed in [8]. Is it possible to use our analysis to the approaches which attempt to materialize every cuboid in a data cube <ref> [1] </ref>? Yes, it is reasonable, because even if it is sometimes plausible to materialize every cuboid for nonspatial measures, it is rarely possible to materialize every cell of the cuboids for spatial measures since each cell contains groups of large spatial objects.
Reference: 2. <author> S. Chaudhuri and U. Dayal. </author> <title> An overview of data warehousing and OLAP technology. </title> <journal> ACM SIGMOD Record, </journal> <volume> 26 </volume> <pages> 65-74, </pages> <year> 1997. </year>
Reference-contexts: It is an imminent task to develop efficient methods for the analysis and understanding of such huge amount of spatial data and utilize them effectively. Following the trend of the development of data warehousing and data mining techniques <ref> [2, 4, 9] </ref>, we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining [3, 7, 11]. <p> Following the trend of the development of data warehousing and data mining techniques [2, 4, 9], we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining [3, 7, 11]. Similar to nonspatial data warehouses <ref> [2, 9] </ref>, we consider that a spatial data warehouse is a subject-oriented, integrated, time-variant, and non-volatile collection of both spatial and nonspatial data in support of management's decision-making process. <p> New models and techniques should be developed for on-line analysis of voluminous spatial data. In this paper, we propose the construction of spatial data warehouse using a spatial data cube model (also called a spatial multidimensional database model). A star/snowflake model <ref> [2] </ref> is used to build a spatial data cube which consists of some spatial dimensions and/or measures together with nonspatial ones. Methods for efficient implementation of spatial data cubes are examined with some interesting techniques proposed, especially on precomputation and selective materialization of spatial OLAP results. <p> data mining [3, 7, 11]. 2 A model of spatial data warehouses Unlike relational or entity-relationship models which are used for designing databases for ad-hoc querying and on-line transaction processing, data warehouse is designed for on-line analytical processing and business decision making, and it usually adopts a star schema model <ref> [2, 10] </ref>, where the data warehouse contains a large central table (fact table) and a set of smaller attendant tables (dimensional tables) displayed in a radial pattern around the central table. The fact table stores the keys of multiple dimensions and the numerical measures of the business. <p> The fact table stores the keys of multiple dimensions and the numerical measures of the business. The dimensional tables are where the textual description of the dimensions of the business are stored. A variant of a star schema model is called a snowflake (schema) model <ref> [2, 10] </ref>, where some dimension tables are normalized, further splitting into more tables, forming the shape similar to a piece of snowflake. <p> Computing such spatial merges of a large number of regions flexibly and dynamically poses a major challenge to the implementation of spatial OLAP operations. Only if appropriate precomputation is performed, can the response time be satisfactory to users. Similar to the structure of a nonspatial data cube <ref> [2, 13] </ref>, a spatial data cube consists of a lattice of cuboids, with the lowest one (base cuboid) references all the dimensions at the primitive abstraction level (i.e., group-by all the dimensions), and the highest one (apex point) summarizes all the dimensions at the top-most Fig. 3.
Reference: 3. <author> M. Ester, H.-P. Kriegel, and J. Sander. </author> <title> Spatial data mining: A database approach. </title> <booktitle> In Proc. Int. Symp. Large Spatial Databases (SSD'97), </booktitle> <pages> pages 47-66, </pages> <address> Berlin, Ger-many, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Following the trend of the development of data warehousing and data mining techniques [2, 4, 9], we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining <ref> [3, 7, 11] </ref>. Similar to nonspatial data warehouses [2, 9], we consider that a spatial data warehouse is a subject-oriented, integrated, time-variant, and non-volatile collection of both spatial and nonspatial data in support of management's decision-making process. <p> The precomputation of spatial OLAP results, such as merge of a number of spatially connected regions, is important not only for fast response in result display but also for further spatial analysis and spatial data mining <ref> [3, 7, 11] </ref>. 2 A model of spatial data warehouses Unlike relational or entity-relationship models which are used for designing databases for ad-hoc querying and on-line transaction processing, data warehouse is designed for on-line analytical processing and business decision making, and it usually adopts a star schema model [2, 10], where <p> Moreover, a dimension can be specified by experts/users based on the relationships among attributes or among particular data values, or be generated automatically based on spatial data analysis techniques <ref> [3, 7, 11] </ref>. We distinguish two cases for modeling measures in a spatial data cube. 1. Numerical measure is a measure containing only numerical data.
Reference: 4. <author> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy. </author> <title> Advances in Knowledge Discovery and Data Mining. </title> <publisher> AAAI/MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: It is an imminent task to develop efficient methods for the analysis and understanding of such huge amount of spatial data and utilize them effectively. Following the trend of the development of data warehousing and data mining techniques <ref> [2, 4, 9] </ref>, we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining [3, 7, 11].
Reference: 5. <author> J. Gray, S. Chaudhuri, A. Bosworth, A. Layman, D. Reichart, M. Venkatrao, F. Pellow, and H. Pirahesh. </author> <title> Data cube: A relational aggregation operator generalizing group-by, </title> <journal> cross-tab and sub-totals. Data Mining and Knowledge Discovery, </journal> <volume> 1 </volume> <pages> 29-54, </pages> <year> 1997. </year>
Reference-contexts: Numerical measure is a measure containing only numerical data. For example, one measure in a spatial data warehouse could be monthly revenue of a region, and a roll-up may get the total revenue by year, by county, etc. Numerical measures can be further classified into distributive, algebraic, and holistic <ref> [5] </ref>. The scope of our discussion related to numerical measures is confined to distributive and algebraic measures. 2. Spatial measure is a measure which contains one or a collection of pointers to spatial objects. <p> Roll-up, which generalizes one or a few dimensions (including the removal of some dimensions when desired) and performs appropriate aggregations in the corresponding measure (s). For nonspatial measures, aggregation is implemented in the same way as in nonspatial data cubes <ref> [1, 5, 13] </ref>. However, for spatial measures, aggregation takes a collection of a spatial pointers in a map or map-overlay and performs certain spatial aggregation operation, such as region merge, or map overlay.
Reference: 6. <author> R. H. Guting. </author> <title> An introduction to spatial database systems. </title> <journal> The VLDB Journal, </journal> <volume> 3 </volume> <pages> 357-400, </pages> <year> 1994. </year>
Reference-contexts: The second challenge is the realization of fast and flexible on-line analytical processing in a spatial data warehouse, and this is the goal of our study. In spatial database research, spatial indexing and accessing methods have been studied extensively for efficient storage and access of spatial data <ref> [6] </ref>. <p> Slicing and dicing, which of each selects a portion of the cube based on the constant (s) in one or a few dimensions. This can be realized by transforming the selection criteria into a query against the spatial data warehouse and be processed by query processing methods <ref> [6] </ref>. 2. Pivoting, which presents the measures in different cross-tabular layouts. This can be implemented in a similar way as in nonspatial data cubes. 3. Roll-up, which generalizes one or a few dimensions (including the removal of some dimensions when desired) and performs appropriate aggregations in the corresponding measure (s). <p> The principles discussed here, however, are also applicable to other kinds of spatial operations, such as spatial map overlay, spatial join <ref> [6] </ref>, and intersection between lines and regions. 3.1 Choices for computation of spatial measures There are at least three possible choices regarding the computation of spatial measures in spatial data cube construction: 1.
Reference: 7. <author> J. Han, K. Koperski, and N. Stefanovic. GeoMiner: </author> <title> A system prototype for spatial data mining. </title> <booktitle> In Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data, </booktitle> <pages> pages 553-556, </pages> <address> Tucson, Arizona, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: Following the trend of the development of data warehousing and data mining techniques [2, 4, 9], we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining <ref> [3, 7, 11] </ref>. Similar to nonspatial data warehouses [2, 9], we consider that a spatial data warehouse is a subject-oriented, integrated, time-variant, and non-volatile collection of both spatial and nonspatial data in support of management's decision-making process. <p> The precomputation of spatial OLAP results, such as merge of a number of spatially connected regions, is important not only for fast response in result display but also for further spatial analysis and spatial data mining <ref> [3, 7, 11] </ref>. 2 A model of spatial data warehouses Unlike relational or entity-relationship models which are used for designing databases for ad-hoc querying and on-line transaction processing, data warehouse is designed for on-line analytical processing and business decision making, and it usually adopts a star schema model [2, 10], where <p> Moreover, a dimension can be specified by experts/users based on the relationships among attributes or among particular data values, or be generated automatically based on spatial data analysis techniques <ref> [3, 7, 11] </ref>. We distinguish two cases for modeling measures in a spatial data cube. 1. Numerical measure is a measure containing only numerical data. <p> If the OLAP results are used only for viewing, display-only mode could be useful. However, they can be used for further spatial analysis and spatial data mining, such as spatial association, classification, etc. <ref> [7, 11] </ref> and it is important to merge a number of spatially connected regions for such analysis. 2. Precompute and store some rough approximation/estimation of the spatial mea sures in a spatial data cube.
Reference: 8. <author> V. Harinarayan, A. Rajaraman, and J. D. Ullman. </author> <title> Implementing data cubes efficiently. </title> <booktitle> In Proc. 1996 ACM-SIGMOD Int. Conf. Management of Data, </booktitle> <pages> pages 205-216, </pages> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: A variant of a star schema model is called a snowflake (schema) model [2, 10], where some dimension tables are normalized, further splitting into more tables, forming the shape similar to a piece of snowflake. With such a star/snowflake schema model, multi-dimensional databases or data cubes <ref> [1, 8] </ref> can be constructed to facilitate typical OLAP operations such as drill-down, roll-up, dicing, slicing, pivoting, etc. To model spatial data warehouses, the star/snowflake schema model is still considered to be a good choice because it provides a concise and organized warehouse structure and facilitates OLAP operations. <p> There are different products in (nonspatial) data warehouse industry: some materialize every cuboid, some none, and some only part of the cube (i.e., some of the cuboids). There are interesting studies on efficient computation of data cubes [1, 13]. A previous study <ref> [8] </ref> shows that materializing every view requires a huge amount of disk space, whereas not materializing any view requires a great deal of on-the-fly, and often redundant, computation. <p> factors may need to be considered when judging whether a cuboid should be selected for materialization: (1) the potential access frequency of the generated cuboid, (2) the size of the generated cuboid, and (3) how the materialization of one cuboid may benefit the computation of other cuboids in the lattice <ref> [8] </ref>. A greedy cuboid-selection algorithm has been presented in [8] based on the analysis of the latter two factors. <p> a cuboid should be selected for materialization: (1) the potential access frequency of the generated cuboid, (2) the size of the generated cuboid, and (3) how the materialization of one cuboid may benefit the computation of other cuboids in the lattice <ref> [8] </ref>. A greedy cuboid-selection algorithm has been presented in [8] based on the analysis of the latter two factors. <p> In our subsequent analysis, we assume that a set of cuboids have been selected for materialization using an extended cuboid-selection algorithm similar to the one in <ref> [8] </ref> and examine how to determine which sets of mergeable spatial objects should be precomputed. Two algorithms, pointer intersection and object connection, are worked out for selection of precomputed objects. The general idea of the algorithms is as follows. <p> Input: A cube lattice which consists of a set of selected cuboids obtained by running an extended cuboid-selection algorithm similar to <ref> [8] </ref>. An access frequency table which registers the access frequency of each cuboid in the lattice. A group of spatial pointers in each cell of a cuboid in the lattice. A region map which illustrates the neighborhood of the regions. <p> The algorithm is to find those spatial object groups in the data cube which are frequently accessed and mergeable, and then perform spatial merge for them in precomputation. The algorithm works on the candidate cuboids that are selected based on an extension to a well-known cuboid selection algorithm <ref> [8] </ref>. Lines (1) to (4) ensure that every pair of cuboids is examined for each candidate cube cell which derives the maximal intersections of spatial object pointers and stores them into candidate table. Note that a self-intersection for cuboids is performed as well. <p> Since it is challenging to compute spatial measures in such a data cube, our study has been focused on the method for selective materialization of spatial measures. In comparison with previous studies of selective materialization of data cubes, such as <ref> [8] </ref>, a major difference of our approach is the granularity of selective materialization. <p> In our analysis, we have adopted the philosophy and algorithm of selective materialization of data cubes as proposed in <ref> [8] </ref>.
Reference: 9. <author> W. H. Inmon. </author> <title> Building the Data Warehouse. </title> <publisher> John Wiley, </publisher> <year> 1996. </year>
Reference-contexts: It is an imminent task to develop efficient methods for the analysis and understanding of such huge amount of spatial data and utilize them effectively. Following the trend of the development of data warehousing and data mining techniques <ref> [2, 4, 9] </ref>, we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining [3, 7, 11]. <p> Following the trend of the development of data warehousing and data mining techniques [2, 4, 9], we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining [3, 7, 11]. Similar to nonspatial data warehouses <ref> [2, 9] </ref>, we consider that a spatial data warehouse is a subject-oriented, integrated, time-variant, and non-volatile collection of both spatial and nonspatial data in support of management's decision-making process.
Reference: 10. <author> R. Kimball. </author> <title> The Data Warehouse Toolkit. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: data mining [3, 7, 11]. 2 A model of spatial data warehouses Unlike relational or entity-relationship models which are used for designing databases for ad-hoc querying and on-line transaction processing, data warehouse is designed for on-line analytical processing and business decision making, and it usually adopts a star schema model <ref> [2, 10] </ref>, where the data warehouse contains a large central table (fact table) and a set of smaller attendant tables (dimensional tables) displayed in a radial pattern around the central table. The fact table stores the keys of multiple dimensions and the numerical measures of the business. <p> The fact table stores the keys of multiple dimensions and the numerical measures of the business. The dimensional tables are where the textual description of the dimensions of the business are stored. A variant of a star schema model is called a snowflake (schema) model <ref> [2, 10] </ref>, where some dimension tables are normalized, further splitting into more tables, forming the shape similar to a piece of snowflake.
Reference: 11. <author> K. Koperski, J. Han, and J. Adhikary. </author> <title> Mining knowledge in geographic data. </title> <note> In Comm. ACM (to appear), </note> <year> 1998. </year>
Reference-contexts: Following the trend of the development of data warehousing and data mining techniques [2, 4, 9], we propose to construct spatial data warehouses to facilitate on-line spatial data analysis and spatial data mining <ref> [3, 7, 11] </ref>. Similar to nonspatial data warehouses [2, 9], we consider that a spatial data warehouse is a subject-oriented, integrated, time-variant, and non-volatile collection of both spatial and nonspatial data in support of management's decision-making process. <p> The precomputation of spatial OLAP results, such as merge of a number of spatially connected regions, is important not only for fast response in result display but also for further spatial analysis and spatial data mining <ref> [3, 7, 11] </ref>. 2 A model of spatial data warehouses Unlike relational or entity-relationship models which are used for designing databases for ad-hoc querying and on-line transaction processing, data warehouse is designed for on-line analytical processing and business decision making, and it usually adopts a star schema model [2, 10], where <p> Moreover, a dimension can be specified by experts/users based on the relationships among attributes or among particular data values, or be generated automatically based on spatial data analysis techniques <ref> [3, 7, 11] </ref>. We distinguish two cases for modeling measures in a spatial data cube. 1. Numerical measure is a measure containing only numerical data. <p> If the OLAP results are used only for viewing, display-only mode could be useful. However, they can be used for further spatial analysis and spatial data mining, such as spatial association, classification, etc. <ref> [7, 11] </ref> and it is important to merge a number of spatially connected regions for such analysis. 2. Precompute and store some rough approximation/estimation of the spatial mea sures in a spatial data cube.
Reference: 12. <author> N. Stefanovic. </author> <title> Design and implementation of on-line analytical processing (OLAP) of spatial data. M.Sc. </title> <type> Thesis, </type> <institution> Simon Fraser University, Canada, </institution> <month> Septem-ber </month> <year> 1997. </year>
Reference-contexts: For more detailed explanation of the algorithm steps and several optimiza tion techniques used we refer to <ref> [12] </ref>. Rationale of the algorithm. The algorithm is to find those spatial object groups in the data cube which are frequently accessed and mergeable, and then perform spatial merge for them in precomputation. <p> Object connection algorithm will detect group C in its get max connected intersection procedure and since its frequency may be higher than that for groups A and B and it may be merged. We provide a more formal explanation in a form of a theorem <ref> [12] </ref>. 4 Performance Analysis In the previous section, we presented two algorithms for selective materialization of spatial measures: pointer intersection algorithm, and object connection algorithm. In order to evaluate and compare their performances, we implemented the algorithms and conducted a simulation study. We first analyze effectiveness of the algorithms. <p> On the contrary, pointer intersection algorithm shows slightly better performance when the frequency threshold increases due to fewer groups tested for spatial connectivity. We also compared the two algorithms with respect to scalability to the number of cuboids in the spatial data cube and the experiments showed similar results <ref> [12] </ref>. We anticipate that future spatial data warehouses will be built on the following two premises: large number of objects and relatively small number of frequent queries. According to the conducted experiments, we believe that pointer intersection algorithm fits better than object connection algorithm into such data warehouse environment.
Reference: 13. <author> Y. Zhao, P. M. Deshpande, and J. F. Naughton. </author> <title> An array-based algorithm for simultaneous multidimensional aggregates. </title> <booktitle> In Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data, </booktitle> <pages> pages 159-170, </pages> <address> Tucson, Arizona, </address> <month> May </month> <year> 1997. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Roll-up, which generalizes one or a few dimensions (including the removal of some dimensions when desired) and performs appropriate aggregations in the corresponding measure (s). For nonspatial measures, aggregation is implemented in the same way as in nonspatial data cubes <ref> [1, 5, 13] </ref>. However, for spatial measures, aggregation takes a collection of a spatial pointers in a map or map-overlay and performs certain spatial aggregation operation, such as region merge, or map overlay. <p> Computing such spatial merges of a large number of regions flexibly and dynamically poses a major challenge to the implementation of spatial OLAP operations. Only if appropriate precomputation is performed, can the response time be satisfactory to users. Similar to the structure of a nonspatial data cube <ref> [2, 13] </ref>, a spatial data cube consists of a lattice of cuboids, with the lowest one (base cuboid) references all the dimensions at the primitive abstraction level (i.e., group-by all the dimensions), and the highest one (apex point) summarizes all the dimensions at the top-most Fig. 3. <p> There are different products in (nonspatial) data warehouse industry: some materialize every cuboid, some none, and some only part of the cube (i.e., some of the cuboids). There are interesting studies on efficient computation of data cubes <ref> [1, 13] </ref>. A previous study [8] shows that materializing every view requires a huge amount of disk space, whereas not materializing any view requires a great deal of on-the-fly, and often redundant, computation.
References-found: 13

