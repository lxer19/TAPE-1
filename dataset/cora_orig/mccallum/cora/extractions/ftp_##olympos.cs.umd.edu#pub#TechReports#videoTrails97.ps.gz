URL: ftp://olympos.cs.umd.edu/pub/TechReports/videoTrails97.ps.gz
Refering-URL: http://www.cs.umd.edu/~christos/cpub.html
Root-URL: 
Title: VideoTrails Representing and Visualizing Structure in Video Sequences  
Author: Vikrant Kobla, David Doermann Christos Faloutsos 
Address: College Park, MD 20742 3275.  College Park, MD 20742.  
Affiliation: Laboratory for Language and Media Processing University of Maryland,  Department of Computer Science University of Maryland,  
Abstract: In this paper, we describe a novel technique which reduces a sequence of MPEG encoded video frames to a trail of points in a low dimensional space. In this space, we can cluster frames, analyze transitions between clusters and compute properties of the resulting trail. By classifying portions of the trail as either stationary or transitional, we are able to detect gradual edits between shots. Furthermore, tracking the interaction of clusters over time, we lay the groundwork for the complete analysis and representation of the video's physical and semantic structure. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Ariki and Y. Saito. </author> <title> Extraction of TV news articles based on scene cut detection using DCT clustering. </title> <booktitle> In Proc. of the IEEE International Conference on Image Processing, </booktitle> <volume> volume 3, </volume> <pages> pages 847-850, </pages> <year> 1996. </year>
Reference-contexts: Work has also been done in the field of video data modeling in which defining objects and events in video is given importance [7]. The notion of using DCT information to cluster similar frames was employed in the paper by Ariki and Saito <ref> [1] </ref> for the specific application of extracting news articles.
Reference: [2] <author> F. Arman, A. Hsu, and M.Y. Chiu. </author> <title> Image processing on compressed data for large video databases. </title> <booktitle> In Proc. of the ACM Multimedia Conference, </booktitle> <pages> pages 267-272, </pages> <year> 1993. </year>
Reference-contexts: Detecting some physical changes such as cuts and camera motion is fairly easy and algorithms have appeared in many recent papers <ref> [2, 8, 16, 19] </ref>. Detecting gradual transitions and special effect edits, on the other hand, is a tougher problem in the compressed domain.
Reference: [3] <institution> Center for the Computation and Visualization of Geometric Structures | University of Minnesota. qhull. Software, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Then the convex hull volume ratio is given by, CHR (T ) = Vol (T ) We used the qhull <ref> [3] </ref> program to calculate the volume of the convex hull of a given set of points for our analysis. 4.1.4 MBR Shape The final criterion that we use is the shape of the MBR of the trail.
Reference: [4] <author> M. Cherfaoui and C. Bertin. </author> <title> Two-stage strategy for indexing and presenting video. </title> <booktitle> In Proc. of the SPIE Conference on Storage and Retrieval for Image and Video Databases II, </booktitle> <volume> volume 2185, </volume> <pages> pages 174-184, </pages> <year> 1994. </year>
Reference-contexts: Early work by Cherfaoui and Bertin <ref> [4] </ref> provides a two-stage strategy for segmenting a clip into shots, and then manually grouping these shots into sequences of shots and further into themes to enable hierarchical browsing.
Reference: [5] <author> C. Faloutsos and K. Lin. </author> <title> FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets. </title> <booktitle> In Proc. of the ACM SIGMOD Conference, </booktitle> <pages> pages 163-174, </pages> <year> 1995. </year>
Reference-contexts: We utilize the DC coefficients of the luminance and chrominance components of an MPEG frame as features and the Euclidean distance between the feature vectors to test for similarity between frames. Using a technique called FastMap <ref> [5] </ref>, we perform dimensionality reduction to generate a low-dimensional vector for each frame. <p> By successively applying the two projections, the requisite number of coordinates can be obtained in O (kn) time where k is the target dimension and n is the number of points. The reader can refer to a paper on FastMap <ref> [5] </ref> for more information, including the pseudo-code of the algorithm. Finally, before we proceed further, we must clarify an important notion regarding FastMap.
Reference: [6] <author> C. Faloutsos, M. Ranganathan, and Y. Manolopou-los. </author> <title> Fast subsequence matching in time-series databases. </title> <booktitle> In Proc. of the ACM SIGMOD Conference, </booktitle> <pages> pages 419-429, </pages> <year> 1994. </year>
Reference-contexts: The marginal cost is then, MC (T ) MC (T [ fp i g) = m + 1 k=0 MBR (T [ fp i g) k + 0:5 This cost function was previously used in the paper by Faloutsos et al. <ref> [6] </ref>. We compare MC (T [ fp i g) with the previous marginal cost, and if the former is greater, then we identify a trail cut between the points p i1 and p i .
Reference: [7] <author> P. Kelly, A. Gupta, and R. Jain. </author> <title> Visual computing meets data modeling: Defining objects in multi-camera video databases. </title> <booktitle> In Proc. of the SPIE Conference on Storage and Retrieval for Still Image and Video Databases IV, </booktitle> <volume> volume 2670, </volume> <pages> pages 120-131, </pages> <year> 1996. </year>
Reference-contexts: More recently, a paper by Zhong et al. [20] describes a generalized top-down hierarchical clustering process to build hierarchical representations of videos. Work has also been done in the field of video data modeling in which defining objects and events in video is given importance <ref> [7] </ref>. The notion of using DCT information to cluster similar frames was employed in the paper by Ariki and Saito [1] for the specific application of extracting news articles.
Reference: [8] <author> V. Kobla, D. Doermann, and K. Lin. </author> <title> Archiving, indexing, and retrieval of video in the compressed domain. </title> <booktitle> In Proc. of the SPIE Conference on Multimedia Storage and Archiving Systems, </booktitle> <volume> volume 2916, </volume> <pages> pages 78-89, </pages> <year> 1996. </year>
Reference-contexts: Detecting some physical changes such as cuts and camera motion is fairly easy and algorithms have appeared in many recent papers <ref> [2, 8, 16, 19] </ref>. Detecting gradual transitions and special effect edits, on the other hand, is a tougher problem in the compressed domain. <p> In general, the larger the dimension of the FastMap output space is, the better the distribution and clustering of the output points. This can be inferred from the significant increase in retrieval percentage when FastMap points are used to index video clips <ref> [8, 10] </ref>. Most of the discussions that follow in this paper are applicable to points with a dimension greater than three, albeit with a substantial increase in computation. Again, we must note that the coordinates of the output points do not carry any special meaning. <p> detection transition. 5.1 Global Motion Detection Our approach involves using the motion vectors encoded in the MPEG format to determine the type of global or camera motion that may be present, including zoom-in, zoom-out, pan left, pan right, tilt up, tilt down, and a combination of zoom, pan and tilt <ref> [8, 11] </ref>. Since our goal is to filter out any kind of global motion leading to a transitional trail, the analysis does not distinguish between camera motion and consistent motion of objects in the scene that give the appearance of camera motion.
Reference: [9] <author> V. Kobla, D. Doermann, K. Lin, and C. Faloutsos. </author> <title> Feature normalization for video indexing and retrieval. </title> <type> CfAR Technical Report CAR-TR-847 (CS-TR-3732), </type> <institution> University of Maryland, </institution> <year> 1996. </year>
Reference-contexts: Our approach is based on our previous work on compressed domain analysis of video to extract low-dimensional spatial features from frames of an MPEG encoded video clip <ref> [9, 10] </ref>. Using the DC coefficients 1 of I frames, we can estimate the DC coefficients of MBs of P and B frames with minimal computation [15]. This results in a uniform representation of the spatial data of all types of frames of an MPEG clip. <p> Using a technique called FastMap [5], we perform dimensionality reduction to generate a low-dimensional vector for each frame. Since the feature extraction has been described in previous work <ref> [9, 10] </ref>, we continue with a description of the dimensionality reduction. 2.1 Dimensionality Reduction The primary advantage of FastMap is that it runs in time linear in the number of objects in the database. <p> This ambiguity can be resolved by extracting the global motion directly from the temporal features present in the MPEG compression stream, and tagging these transitions as motion transitions <ref> [9, 10] </ref>. Thus, the transitions not tagged as motion transitions are detected as gradual transition edits.
Reference: [10] <author> V. Kobla, D. Doermann, K. Lin, and C. Faloutsos. </author> <title> Compressed domain video indexing techniques using dct and motion vector information in MPEG video. </title> <booktitle> In Proc. of the SPIE Conference on Storage and Retrieval for Still Image and Video Databases V, </booktitle> <volume> volume 3022, </volume> <pages> pages 200-211, </pages> <year> 1997. </year>
Reference-contexts: Our approach is based on our previous work on compressed domain analysis of video to extract low-dimensional spatial features from frames of an MPEG encoded video clip <ref> [9, 10] </ref>. Using the DC coefficients 1 of I frames, we can estimate the DC coefficients of MBs of P and B frames with minimal computation [15]. This results in a uniform representation of the spatial data of all types of frames of an MPEG clip. <p> Using a technique called FastMap [5], we perform dimensionality reduction to generate a low-dimensional vector for each frame. Since the feature extraction has been described in previous work <ref> [9, 10] </ref>, we continue with a description of the dimensionality reduction. 2.1 Dimensionality Reduction The primary advantage of FastMap is that it runs in time linear in the number of objects in the database. <p> In general, the larger the dimension of the FastMap output space is, the better the distribution and clustering of the output points. This can be inferred from the significant increase in retrieval percentage when FastMap points are used to index video clips <ref> [8, 10] </ref>. Most of the discussions that follow in this paper are applicable to points with a dimension greater than three, albeit with a substantial increase in computation. Again, we must note that the coordinates of the output points do not carry any special meaning. <p> This ambiguity can be resolved by extracting the global motion directly from the temporal features present in the MPEG compression stream, and tagging these transitions as motion transitions <ref> [9, 10] </ref>. Thus, the transitions not tagged as motion transitions are detected as gradual transition edits.
Reference: [11] <author> V. Kobla, D. Doermann, and A. Rosenfeld. </author> <title> Compressed domain video segmentation. </title> <type> CfAR Technical Report CAR-TR-839 (CS-TR-3688), </type> <institution> University of Maryland, </institution> <year> 1996. </year>
Reference-contexts: detection transition. 5.1 Global Motion Detection Our approach involves using the motion vectors encoded in the MPEG format to determine the type of global or camera motion that may be present, including zoom-in, zoom-out, pan left, pan right, tilt up, tilt down, and a combination of zoom, pan and tilt <ref> [8, 11] </ref>. Since our goal is to filter out any kind of global motion leading to a transitional trail, the analysis does not distinguish between camera motion and consistent motion of objects in the scene that give the appearance of camera motion.
Reference: [12] <author> D. Le Gall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> Communications of the ACM, </journal> <volume> 34 </volume> <pages> 46-58, </pages> <year> 1991. </year>
Reference-contexts: In this paper, we will present techniques to detect various physical events directly in the compressed domain in MPEG encoded video <ref> [12] </ref>. By operating on features inherent in the representation, such as the type of each Macroblock (MB), the Discrete Cosine Transform (DCT) coefficients of each MB, and the motion vector components for the forward, backward, and bidirectionally predicted MBs, we reduce the need for decompression.
Reference: [13] <author> J. Meng, Y. Juan, and S.F. Chang. </author> <title> Scene change detection in a MPEG compressed video sequence. </title> <booktitle> In Proc. of the SPIE Conference on Digital Video Compression: Algorithms and Technologies, </booktitle> <volume> volume 2419, </volume> <pages> pages 14-25, </pages> <year> 1995. </year>
Reference-contexts: If that is the case, by using the sum of the absolute difference of the corresponding DC coefficients as the comparison metric, any ramp input should yield a symmetric plateau output with sloping sides. Another technique suggested by Meng et al. <ref> [13] </ref> involves using the intensity variance to detect dissolves. They measured frame variance by using the DC coefficients of the I and P frames, and ob served that during a dissolve the variance curve shows a parabolic shape.
Reference: [14] <author> B. Shahraray. </author> <title> Scene change detection and content-based sampling of video. </title> <booktitle> In Proc. of the SPIE Conference on Digital Video Compression: Algorithms and Technologies, </booktitle> <volume> volume 2419, </volume> <pages> pages 2-13, </pages> <year> 1995. </year>
Reference-contexts: They measured frame variance by using the DC coefficients of the I and P frames, and ob served that during a dissolve the variance curve shows a parabolic shape. There have also been research done in this area that require pixel data (uncompressed data) to work <ref> [14, 18, 19] </ref>. Most of these earlier work on gradual transition detection perform well on linear transitions, but not on more general transitions. We look for shot consistency, to detect transition. The advantage of our technique is that transitions are detected irrespective of whether they are linear or not.
Reference: [15] <author> B.L. Yeo and B. Liu. </author> <title> On the extraction of DC sequence from MPEG compressed video. </title> <booktitle> In Proc. of the IEEE International Conference on Image Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 260-263, </pages> <year> 1995. </year>
Reference-contexts: Using the DC coefficients 1 of I frames, we can estimate the DC coefficients of MBs of P and B frames with minimal computation <ref> [15] </ref>. This results in a uniform representation of the spatial data of all types of frames of an MPEG clip.
Reference: [16] <author> B.L. Yeo and B. Liu. </author> <title> Unified approach to temporal segmentation of motion JPEG and MPEG video. </title> <booktitle> In Proc. of the International Conference on Multimedia Computing and Systems, </booktitle> <pages> pages 2-13, </pages> <year> 1995. </year>
Reference-contexts: Detecting some physical changes such as cuts and camera motion is fairly easy and algorithms have appeared in many recent papers <ref> [2, 8, 16, 19] </ref>. Detecting gradual transitions and special effect edits, on the other hand, is a tougher problem in the compressed domain. <p> Many other special effect edits exist that may not be simple linear transformations like the ones described above. Two techniques that are applicable in the DCT compressed domain have been suggested by researchers. The paper by Yeo and Liu <ref> [16] </ref> suggests a method in which every frame is compared to the k th frame following it. The separation parameter k should be larger than the number of frames in the edit.
Reference: [17] <author> M. Yeung and B.L. Yeo. </author> <title> Video content characterization and compaction for digital library applications. </title> <booktitle> In Proc. of the SPIE Conference on Storage and Retrieval for Still Image and Video Databases V, </booktitle> <volume> volume 3022, </volume> <pages> pages 45-58, </pages> <year> 1997. </year>
Reference-contexts: The notion of using DCT information to cluster similar frames was employed in the paper by Ariki and Saito [1] for the specific application of extracting news articles. Work by Yeung and Yeo <ref> [17] </ref> also deals with the characterization of video content and its representation in a compact form using temporal events such as dialogues, actions, and story units. 2 VideoTrails Our approach to analyzing a video clip involves first generating a trail of points in a low-dimensional space where each point is derived <p> On the other hand, action sequences typically contain many transitional trails corresponding to shots with high activity. There would be little inter-shot similarity amongst the action shots. Earlier work on this prob lem can be found in <ref> [17] </ref>. Key frame selection: Judicious selection of key frames is important in many applications, especially in extracting features for indexing video. An ideal key frame for a shot should be representative of all the frames of a shot. <p> We can use the points chosen for key frames to represent the entire cluster, and if we create directed edges between these key frame points, we can develop a directed graph representation of the entire video clip which can be used for performing analysis for extracting story units <ref> [17] </ref>. Video classification: Certain types of video clips have a standard structure which can be used to classify other videos having the same structure. For example, a typical half-hour local news report has one or two standard shots of news anchors interspersed with shots of on-location news clippings.
Reference: [18] <author> R. Zabih, J. Miller, and K. Mai. </author> <title> Feature-based algorithm for detecting and classifying scene breaks. </title> <booktitle> In Proc. of the ACM Multimedia Conference, </booktitle> <pages> pages 189-200, </pages> <year> 1995. </year>
Reference-contexts: They measured frame variance by using the DC coefficients of the I and P frames, and ob served that during a dissolve the variance curve shows a parabolic shape. There have also been research done in this area that require pixel data (uncompressed data) to work <ref> [14, 18, 19] </ref>. Most of these earlier work on gradual transition detection perform well on linear transitions, but not on more general transitions. We look for shot consistency, to detect transition. The advantage of our technique is that transitions are detected irrespective of whether they are linear or not.
Reference: [19] <author> H.J. Zhang, A. Kankanhalli, </author> <title> and S.W. Smoliar. Automatic partitioning of full-motion video. </title> <journal> Multimedia Systems, </journal> <volume> 1 </volume> <pages> 10-28, </pages> <year> 1993. </year>
Reference-contexts: Detecting some physical changes such as cuts and camera motion is fairly easy and algorithms have appeared in many recent papers <ref> [2, 8, 16, 19] </ref>. Detecting gradual transitions and special effect edits, on the other hand, is a tougher problem in the compressed domain. <p> They measured frame variance by using the DC coefficients of the I and P frames, and ob served that during a dissolve the variance curve shows a parabolic shape. There have also been research done in this area that require pixel data (uncompressed data) to work <ref> [14, 18, 19] </ref>. Most of these earlier work on gradual transition detection perform well on linear transitions, but not on more general transitions. We look for shot consistency, to detect transition. The advantage of our technique is that transitions are detected irrespective of whether they are linear or not.
Reference: [20] <author> D. Zhong, H. Zhang, and S.F. Chang. </author> <title> Cluster--ing methods for video browsing and annotation. </title> <booktitle> In Proc. of the SPIE Conference on Storage and Retrieval for Still Image and Video Databases IV, </booktitle> <volume> volume 2670, </volume> <pages> pages 239-246, </pages> <year> 1996. </year>
Reference-contexts: Early work by Cherfaoui and Bertin [4] provides a two-stage strategy for segmenting a clip into shots, and then manually grouping these shots into sequences of shots and further into themes to enable hierarchical browsing. More recently, a paper by Zhong et al. <ref> [20] </ref> describes a generalized top-down hierarchical clustering process to build hierarchical representations of videos. Work has also been done in the field of video data modeling in which defining objects and events in video is given importance [7].
References-found: 20

