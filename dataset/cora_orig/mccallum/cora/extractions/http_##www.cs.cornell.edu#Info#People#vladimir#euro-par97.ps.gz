URL: http://www.cs.cornell.edu/Info/People/vladimir/euro-par97.ps.gz
Refering-URL: http://www.cs.cornell.edu/Info/People/vladimir/papers.html
Root-URL: http://www.cs.brown.edu/
Email: fvladimir,pingali,stodghilg@cs.cornell.edu  
Title: A Relational Approach to the Compilation of Sparse Matrix Programs  
Author: Vladimir Kotlyar, Keshav Pingali, and Paul Stodghill 
Address: Ithaca, NY 14853, USA  
Affiliation: Computer Science Department, Cornell University  
Abstract: We present a relational algebra based framework for compiling efficient sparse matrix code from dense DO-ANY loops and a specification of the representation of the sparse matrix. We present experimental data that demonstrates that the code generated by our compiler achieves performance competitive with that of hand-written codes for important computational kernels.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Corinne Ancourt and Franois Irigoin. </author> <title> Scanning polyhedra with do loops. </title> <booktitle> In Principle and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: For these iterations, we need efficient access to the corresponding entries in the matrices and vectors. Since the constraints are not linear and the sets being computed are not convex, we cannot use methods based on polyhedral algebra, such as Fourier-Motzkin elimination <ref> [1] </ref>, to efficiently enumerate these sets. Our approach is based on relational algebra, and models A, X and Y as relations (tables) that hold tuples of array indices and values. Conceptually, the relation corresponding to a sparse matrix contains both zero and non-zero values.
Reference: 2. <institution> Argonne National Laboratory. </institution> <month> PETSc, </month> <title> the Portable, Extensible Toolkit for Scientific Computation. </title> <address> http://www.mcs.anl.gov/petsc/petsc.html. </address>
Reference-contexts: 1, we would still have to provide at 6 2 = 36 versions of sparse matrix-matrix product (assuming that the result is stored in a single format)! The lack of extensibility in such a "sparse BLAS" approach has been addressed by object-oriented solver libraries, like the PETSC library from Ar-gonne <ref> [2] </ref>. These libraries provide templates for a certain class of solvers (for example, Krylov space iterative solvers) and allow a user to add new formats by providing hooks for the implementations of some algebraic operations (such as matrix-vector product).
Reference: 3. <author> Aart J.C. Bik and Harry A.G. Wijshoff. </author> <title> Advanced compiler optimizations for sparse computations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 31 </volume> <pages> 14-24, </pages> <year> 1995. </year>
Reference-contexts: One possibility is to give the compiler a dense matrix program, declare that some matrices are actually sparse, and make the compiler responsible for choosing appropriate storage formats and for generating sparse matrix programs. This idea has been explored by Bik and Wijshoff <ref> [3, 4] </ref>, but their approach is limited to simple sparse matrix formats that are not representative of those used in high-performance codes. Intuitively, they trade the ability to handle a variety of formats for the ability to compile arbitrary loop nests. We have taken a different approach. <p> It is relatively easy to come up with insertion schemes for simple formats like CRS and CCS which insert entries at a very fine level for example, for inserting into a row or column as it is being enumerated (this is the approach taken by Bik and Wijshoff <ref> [3, 4] </ref>). More complicated formats, like BlockSolve, are more difficult to handle: the BlockSolve library [7] analyzes and reorders the whole matrix in order to discover inodes. At this point, we have taken the following position: each data structure should provide a method to pack it from a hash table. <p> If some of the arrays are sparse, then some of the iterations of the loop nest will execute "simpler" versions of the original statement S. In most cases, the simpler version is just a NOP. Bik and Wijshoff <ref> [3, 4] </ref> describe an attribute grammar for computing guards, called sparsity predicates, that determine when non-trivial computations must be performed in the loop body. If P is the sparsity predicate, the resulting program is the following.
Reference: 4. <author> Aart J.C. Bik and Harry A.G. Wijshoff. </author> <title> Automatic data structure selection and transformation for sparse matrix computations. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 7(2):109 - 126, </volume> <year> 1996. </year>
Reference-contexts: One possibility is to give the compiler a dense matrix program, declare that some matrices are actually sparse, and make the compiler responsible for choosing appropriate storage formats and for generating sparse matrix programs. This idea has been explored by Bik and Wijshoff <ref> [3, 4] </ref>, but their approach is limited to simple sparse matrix formats that are not representative of those used in high-performance codes. Intuitively, they trade the ability to handle a variety of formats for the ability to compile arbitrary loop nests. We have taken a different approach. <p> It is relatively easy to come up with insertion schemes for simple formats like CRS and CCS which insert entries at a very fine level for example, for inserting into a row or column as it is being enumerated (this is the approach taken by Bik and Wijshoff <ref> [3, 4] </ref>). More complicated formats, like BlockSolve, are more difficult to handle: the BlockSolve library [7] analyzes and reorders the whole matrix in order to discover inodes. At this point, we have taken the following position: each data structure should provide a method to pack it from a hash table. <p> If some of the arrays are sparse, then some of the iterations of the loop nest will execute "simpler" versions of the original statement S. In most cases, the simpler version is just a NOP. Bik and Wijshoff <ref> [3, 4] </ref> describe an attribute grammar for computing guards, called sparsity predicates, that determine when non-trivial computations must be performed in the loop body. If P is the sparsity predicate, the resulting program is the following.
Reference: 5. <author> Henri Cohen. </author> <title> A Course in Computational Algebraic Number Theory. Graduate Texts in Mathematics. </title> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Apply column operations to reduce the data access matrix to column echelon form. This is equivalent to multiplying the matrix H on the right by a unimodular matrix U, which can be found using standard algorithms <ref> [5] </ref>. DO i = 1; n Y (i) = Y (i) + A (i j; j) fl X (j) B B B @ j t j x C C C A 0 B B B 1 0 1 1 1 0 1 C C C j Fig. 6.
Reference: 6. <author> Alan George and Joseph W-H Liu. </author> <title> Computer Solution of Large Sparse Positive Definite Systems. </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1981. </year>
Reference-contexts: Second, for most algorithms, it takes a lot of code reorganization to produce an efficient sparse program that is tuned to a particular format. We illustrate these points by describing two formats | a classical format called Compressed Column Storage (CCS) <ref> [6] </ref> and a modern one used in the BlockSolve library [7]. CCS format is illustrated in Fig. 2. The matrix is compressed along the columns and is stored using three arrays: COLP, VALS and ROWIND.
Reference: 7. <author> Mark T. Jones and Paul E. Plassmann. </author> <title> BlockSolve95 users manual: Scalable library software for the parallel solution of sparse linear systems. </title> <type> Technical Report ANL-95/48, </type> <institution> Argonne National Laboratory, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: We illustrate these points by describing two formats | a classical format called Compressed Column Storage (CCS) [6] and a modern one used in the BlockSolve library <ref> [7] </ref>. CCS format is illustrated in Fig. 2. The matrix is compressed along the columns and is stored using three arrays: COLP, VALS and ROWIND. <p> More complicated formats, like BlockSolve, are more difficult to handle: the BlockSolve library <ref> [7] </ref> analyzes and reorders the whole matrix in order to discover inodes. At this point, we have taken the following position: each data structure should provide a method to pack it from a hash table.
Reference: 8. <author> Vladimir Kotlyar, Keshav Pingali, and Paul Stodghill. </author> <title> Compiling parallel sparse code for user-defined data structures. </title> <booktitle> In Proceedings of Eights SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <month> March </month> <year> 1997. </year> <note> Available as Cornell Computer Science Technical Report from http://cs-tr.cs.cornell.edu. </note>
Reference-contexts: These decisions depend on the storage formats used for the sparse arrays. In summary, there are four problems that we must address. The first problem is to describe the structure of storage formats to the compiler. We outline this in Section 2 (details are in <ref> [8] </ref>). The second problem is to formulate relational queries (Section 3.1), and discover joins. In our example, this step was easy because all array subscripts are loop variables. When array subscripts are general affine functions of loop variables, discovering joins requires computing the echelon form of certain matrices (Section 3.2). <p> array value field, and F indicates an array index field. 2.2 Access Methods For each level of the index hierarchy (such as I and (J; V ) is the case of CRS storage), access methods for searching and enumerating the indices must be provided to the compiler, as described in <ref> [8] </ref>. This set of access methods does not specify how non-zero elements (fill) are inserted.
Reference: 9. <author> Wei Li and Keshav Pingali. </author> <title> Access Normalization: Loop restructuring for NUMA compilers. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(4) </volume> <pages> 353-375, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: H = B B I . . . 1 C A 0 B @ a 0 a n C C f = B B 0 . . . 1 C A Following <ref> [9] </ref>, the matrix H is called a data access matrix.
Reference: 10. <author> Sergio Pissantezky. </author> <title> Sparse Matrix Technology. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1984. </year>
Reference-contexts: Table 1 illustrates specification of the hierarchy of indices for a variety of formats. In this notation the operator is used to indicate the nesting of the fields within the structure. For example, I J V in the Compressed Row Storage (CRS) format <ref> [10] </ref> indicates that we have to access a particular row before we can enumerate the column indices and values; and that within a row, we can search on the column index to find a particular value.
Reference: 11. <author> Raghu Ramakrishnan. </author> <title> Database Management Systems. College Custom Series. </title> <publisher> McGraw-Hill, Inc, </publisher> <address> beta edition, </address> <year> 1996. </year>
Reference-contexts: Figures 10 and 11 are examples of join orderings produced by this step. Once we have found the nesting order of the joins, we have to select an algorithm for performing each of the joins. The basic algorithms for performing joins can be found in database literature <ref> [11, 13] </ref>. Our compiler selects an appropriate algorithm based on the properties of access methods of the joined relations. It is at this point that the sparsity predicate is "folded" into join implementations in order to produce enumerations over a correct combination of zeros and non-zeros.
Reference: 12. <author> Gilbert Strang. </author> <title> Introduction to applied mathematics. </title> <publisher> Wellesley-Cambridge Press, </publisher> <year> 1986. </year>
Reference-contexts: An important property that we need to convey is that inodes partition the matrix into disjoint pieces. We denote it by the 6" symbol subscript in T inode . This will differentiate the i-node storage format from the format often used in Finite Element analysis <ref> [12] </ref>. In this format the matrix is represented as a sum of element matrices. The element matrices are stored just like the inodes, and the overall type for this format is T FE in Tab. 1, where E is the field of element numbers.
Reference: 13. <author> Jeffrey D. Ullman. </author> <title> Principles of Database and Knowledge-Base Systems, v. I and II. </title> <publisher> Computer Science Press, </publisher> <year> 1988. </year>
Reference-contexts: Figures 10 and 11 are examples of join orderings produced by this step. Once we have found the nesting order of the joins, we have to select an algorithm for performing each of the joins. The basic algorithms for performing joins can be found in database literature <ref> [11, 13] </ref>. Our compiler selects an appropriate algorithm based on the properties of access methods of the joined relations. It is at this point that the sparsity predicate is "folded" into join implementations in order to produce enumerations over a correct combination of zeros and non-zeros.
References-found: 13

