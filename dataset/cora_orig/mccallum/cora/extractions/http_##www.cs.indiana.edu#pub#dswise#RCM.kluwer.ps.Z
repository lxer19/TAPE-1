URL: http://www.cs.indiana.edu/pub/dswise/RCM.kluwer.ps.Z
Refering-URL: http://www.cs.indiana.edu/pub/dswise/
Root-URL: http://www.cs.indiana.edu
Title: Research Demonstration of a Hardware Reference-Counting Heap LISP and Symbolic Computation  
Author: David S. Wise Brian Heck Caleb Hess Willie Hunt and Eric Ost zx 
Keyword: CR categories and Subject Descriptors: E.2 [Data Storage Representations]: Linked representations; D.4.2 [Storage Management]: Allocation/Deallocation strategies; B.3.2 [Memory Structures]: Design Stylesprimary memory, shared memory; C.1.2 [Processor Architectures]: Multiple Data Stream Architectures (Multiprocessors)Parallel processors; D.1.1 [Programming Techniques]: Applicative (Functional) Programming Techniques; B.5.1 [Register-transfer-level Implementation]: Design Memory design. General Term: Performance. Additional Key Words and Phrases: Uniprocessor, garbage collection.  
Address: Bloomington, Indiana 47405-4101 USA  
Affiliation: Indiana University  
Pubnum: 10,  
Email: dswise@cs.indiana.edu  
Date: 2 (July 1997), 159181  April 1997  
Abstract: A hardware self-managing heap memory (RCM) for languages like LISP, SMALLTALK, and JAVA has been designed, built, tested and benchmarked. On every pointer write from the processor, reference-counting transactions are performed in real time within this memory, and garbage cells are reused without processor cycles. A processor allocates new nodes simply by reading from a distinguished location in its address space. The memory hardware also incorporates support for off-line, multiprocessing, mark-sweep garbage collection. Performance statistics are presented from a partial implementation of SCHEME over five different memory models and two garbage collection strategies, from main memory (no access to RCM) to a fully operational RCM installed on an external bus. The performance of the RCM memory is more than competitive with main memory. fl Research reported herein was sponsored, in part, by the National Science Foundation under Grant Numbers DCR 85-21497 and DCR 90 027092. y c fl1997 by Kluwer Academic Press. This document is made available electronically with permission of the copyright owner on a noncommercial basis exclusively for personal use. Copyright and all other rights are maintained by Kluwer or by the authors, notwithstanding that they have offered their work electronically. This work may not be reposted without the explicit permission of Kluwer. z Computer Science Department x Center for Innovative Computer Applications 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. W. Appel. </author> <title> Garbage collection can be faster than stack allocation. </title> <journal> Inf. Proc. Lett. </journal> <volume> 25, </volume> <month> 4 (June </month> <year> 1987), </year> <month> 275279. </month>
Reference-contexts: Conventional garbage collection, however, assembles global knowledge (Nothing points here); thus, any multiprocessor realization requires much synchronization, which is not a constraint on uniprocessors where garbage collection is thought to be perfected <ref> [1, 11] </ref> The asynchronous, atomic transactions of reference counting [8] make it the heap manager of choice for a multiprocessor or multitasking system, It is commonly used to recover available sectors from a shared disk, where a traversing collector is only rarely used (e.g.UNIX's fsck.) In contrast, garbage collection has become
Reference: [2] <author> A. W. Appel, J. R. Ellis, and K. Li. </author> <title> Real-time concurrent collection on stock multiprocessors. </title> <booktitle> Proc. SIGPLAN '88 Conf. Programming Language Design and Implementation, ACM SIGPLAN Notices 23, </booktitle> <month> 7 (July </month> <year> 1988), </year> <month> 1120. </month>
Reference-contexts: Indeed, others have implemented such hardware for uniprocessing or proposed it for multiprocessing <ref> [3, 18, 2, 28, 31, 33] </ref>. Although reference counting has been used successfully for managing secondary storage, garbage collection is still thought to be far more suitable for primary storage, where hardware support will be the most effective. <p> including some features that have been implemented but, as yet, not exercised. 2 Reference Counting in Hardware 2.1 Why Reference Counting? There are three reasons why reference counting [8] was studied as a primary strategy for memory management, in spite of prevailing practice using either off-line or on-line garbage collection <ref> [7, 2, 3, 29, 22, 30] </ref>. First, the same properties of reference counting that make it the usual strategy for managing disk sectors also become particularly important in multiprocessing. The three transactions (v.i.) that here implement reference counting are all finite and non-global.
Reference: [3] <author> H. G. Baker, Jr. </author> <title> List processing in real time on a serial computer. </title> <journal> Comm. ACM 21, </journal> <month> 4 (April </month> <year> 1978), </year> <month> 280294. </month>
Reference-contexts: Indeed, others have implemented such hardware for uniprocessing or proposed it for multiprocessing <ref> [3, 18, 2, 28, 31, 33] </ref>. Although reference counting has been used successfully for managing secondary storage, garbage collection is still thought to be far more suitable for primary storage, where hardware support will be the most effective. <p> including some features that have been implemented but, as yet, not exercised. 2 Reference Counting in Hardware 2.1 Why Reference Counting? There are three reasons why reference counting [8] was studied as a primary strategy for memory management, in spite of prevailing practice using either off-line or on-line garbage collection <ref> [7, 2, 3, 29, 22, 30] </ref>. First, the same properties of reference counting that make it the usual strategy for managing disk sectors also become particularly important in multiprocessing. The three transactions (v.i.) that here implement reference counting are all finite and non-global. <p> While arbitrary circular structures are well known to break reference counting, they are often overused; even classic examples are better implemented without any cycles [26, x2.2.4]. Moreover, that wisdom ignores strategies for circularities that sustain reference counting in useful situations [9, 5, 17, 39]. Baker <ref> [3, 4] </ref>, for instance, implies that it consumes both address space and processor time, neither of which is used here. 2.2 A heap node The prototype provides nodes that are either atomic or binary, as the skeletal C++ declaration below illustrates.
Reference: [4] <author> H. G. Baker, Jr. </author> <title> Preface to H. </title> <editor> G. Baker, Jr. (ed.) </editor> <booktitle> Memory Management. Lecture Notes in Computer Science 986, </booktitle> <address> Berlin, </address> <publisher> Springer (1995), vviii. </publisher>
Reference-contexts: While arbitrary circular structures are well known to break reference counting, they are often overused; even classic examples are better implemented without any cycles [26, x2.2.4]. Moreover, that wisdom ignores strategies for circularities that sustain reference counting in useful situations [9, 5, 17, 39]. Baker <ref> [3, 4] </ref>, for instance, implies that it consumes both address space and processor time, neither of which is used here. 2.2 A heap node The prototype provides nodes that are either atomic or binary, as the skeletal C++ declaration below illustrates. <p> The latter are used to implement matrix decomposition in Section 5.2, below. These generalizations are needed by SMALLTALK and C++-style languages, whose efficient implementations likely require a four-pointer node; cf. Section 6. typedef word char <ref> [4] </ref>; //A 32-bit word at address 4k. typedef unsigned int bool; const bool false=0, true=1; enum Type -atomic, binaryNode-; typedef struct Node union - struct -struct Node *left, *right;- twoLinks; double atom; data; bool mark, liveLeft, liveRight; Type type; unsigned int RefCt; - RCMnode; const leftRight = 4; //Bit 2 distinguishes
Reference: [5] <author> D. G. Bobrow. </author> <title> Managing reentrant structures using reference counts. </title> <journal> ACM Trans. Prog. Lang. Sys./ </journal> <volume> 2, </volume> <month> 3 (July </month> <year> 1980), </year> <month> 269273. </month>
Reference-contexts: While arbitrary circular structures are well known to break reference counting, they are often overused; even classic examples are better implemented without any cycles [26, x2.2.4]. Moreover, that wisdom ignores strategies for circularities that sustain reference counting in useful situations <ref> [9, 5, 17, 39] </ref>. Baker [3, 4], for instance, implies that it consumes both address space and processor time, neither of which is used here. 2.2 A heap node The prototype provides nodes that are either atomic or binary, as the skeletal C++ declaration below illustrates.
Reference: [6] <author> D. W. Clark and C. C. Green. </author> <title> A note on shared structure in LISP. </title> <journal> Inform. Proc. Ltrs. </journal> <volume> 7, </volume> <month> 6 (October </month> <year> 1978), </year> <month> 312314. </month>
Reference-contexts: At the destination address, both increments const sticky = 16777215; // 2**24 -1 but can be far smaller---e.g. 255. void incrementCount (RCMnode *ptr)- if (ptr-&gt;RefCt &lt; Sticky) ptr-&gt;RefCt++ ; - and decrements occur as atomic transactions; the sticky count provides that the counter can be smaller than the worst-case requirement <ref> [6] </ref>. void decrement (RCMnode *ptr)- if ( (ptr-&gt;RefCt &gt;= Sticky) || (bool)(-- ptr-&gt;RefCt) ) -;- else FREE (ptr); - The instruction FREE (ptr) above indicates return of ptr to the available-space structure on board RCM (at mem ory.) The increment and decrement operations are serialized at their target address, but either
Reference: [7] <author> J. Cohen. </author> <title> Garbage collection of linked data structures. </title> <journal> Comput. Surveys 13, </journal> <month> 3 (September </month> <year> 1981), </year> <month> 341367. </month>
Reference-contexts: Storage management is the broad problem of recovering unused space from the heap without explicit instructions from the programmer. It includes both reference counting, garbage collection, and hybrids of the two, like that reported here. Although the second term is often used to include all of storage management <ref> [7, 25] </ref>, we choose the original taxonomy [26, p. 412] because we find it more descriptive: reference counting is a better analog of curbside recycling than of trash collection. 2 Because of the central role played by heap management, it has now become a problem worthy of hardware support. <p> including some features that have been implemented but, as yet, not exercised. 2 Reference Counting in Hardware 2.1 Why Reference Counting? There are three reasons why reference counting [8] was studied as a primary strategy for memory management, in spite of prevailing practice using either off-line or on-line garbage collection <ref> [7, 2, 3, 29, 22, 30] </ref>. First, the same properties of reference counting that make it the usual strategy for managing disk sectors also become particularly important in multiprocessing. The three transactions (v.i.) that here implement reference counting are all finite and non-global.
Reference: [8] <author> G. E. Collins. </author> <title> A method for overlapping and erasure of lists. </title> <journal> Comm. ACM 3, </journal> <month> 12 (December </month> <year> 1960), </year> <month> 655657. </month>
Reference-contexts: Conventional garbage collection, however, assembles global knowledge (Nothing points here); thus, any multiprocessor realization requires much synchronization, which is not a constraint on uniprocessors where garbage collection is thought to be perfected [1, 11] The asynchronous, atomic transactions of reference counting <ref> [8] </ref> make it the heap manager of choice for a multiprocessor or multitasking system, It is commonly used to recover available sectors from a shared disk, where a traversing collector is only rarely used (e.g.UNIX's fsck.) In contrast, garbage collection has become the heap-management algorithm of choice on uniprocessors, where its <p> The sixth section presents the results of our testing; the final section reviews the future, including some features that have been implemented but, as yet, not exercised. 2 Reference Counting in Hardware 2.1 Why Reference Counting? There are three reasons why reference counting <ref> [8] </ref> was studied as a primary strategy for memory management, in spite of prevailing practice using either off-line or on-line garbage collection [7, 2, 3, 29, 22, 30].
Reference: [9] <author> L. P. Deutsch and D. G. Bobrow. </author> <title> An efficient, incremental, real-time garbage collector. </title> <journal> Comm. ACM 19, </journal> <month> 9 (September </month> <year> 1976), </year> <month> 522526. </month>
Reference-contexts: While arbitrary circular structures are well known to break reference counting, they are often overused; even classic examples are better implemented without any cycles [26, x2.2.4]. Moreover, that wisdom ignores strategies for circularities that sustain reference counting in useful situations <ref> [9, 5, 17, 39] </ref>. Baker [3, 4], for instance, implies that it consumes both address space and processor time, neither of which is used here. 2.2 A heap node The prototype provides nodes that are either atomic or binary, as the skeletal C++ declaration below illustrates. <p> Like recopying collection, it runs in just the time necessary for traversing and counting active pointers. Each mark is an increment to a recomputed reference count, correcting counts inflated by cycles or, with more compact counts, unsticking shrunken sticky counts <ref> [9] </ref>. Thus, garbage collection improves the performance of reference counting, just as reference counting symbiotically postpones the need for collection.
Reference: [10] <author> L. P. Deutsch and A. M. Schiffman. </author> <title> Efficient implementation of the SMALLTALK-80 system. </title> <booktitle> Conf. Rec. 11th ACM Symp. on Principles of Programming Languages (1984), </booktitle> <pages> 297302. </pages>
Reference-contexts: It provides multiprocessor marking in place and in a single processor cycle; it requires no interprocessor synchronization and only a few cycles for each node traversed. This support in hardware for hybrid garbage collection is also new. State-of-the-art storage managers used in Smalltalk systems <ref> [23, 10] </ref>, as well as many secondary-storage managers, are also hybrids of garbage collection and reference counting, but this device is the first to provide hardware support for both. 3 In-place Garbage Collection This prototype provides several new features not included in the idea/concept paper [36], including hardware support for Deutsch-Schorr-Waite
Reference: [11] <author> A. Diwan, D. Tarditi, & E. Moss. </author> <title> Memory-system performance of programs with intensive heap allocation. </title> <journal> ACM Trans. Comput. Sys. </journal> <volume> 13, </volume> <month> 3 (August </month> <year> 1995), </year> <month> 244273. </month>
Reference-contexts: Conventional garbage collection, however, assembles global knowledge (Nothing points here); thus, any multiprocessor realization requires much synchronization, which is not a constraint on uniprocessors where garbage collection is thought to be perfected <ref> [1, 11] </ref> The asynchronous, atomic transactions of reference counting [8] make it the heap manager of choice for a multiprocessor or multitasking system, It is commonly used to recover available sectors from a shared disk, where a traversing collector is only rarely used (e.g.UNIX's fsck.) In contrast, garbage collection has become <p> However, exactly this class of large, parallel programs is where current garbage-collection technology fades <ref> [11] </ref>. With storage management essential to modern programming languages, like Smalltalk, ML, Lisp, Haskell, and Java, we must either abandon languages that depend on automatic storage management and cast our parallel programs in the likes of C, or find strategies for managing dynamic storage on parallel processors.
Reference: [12] <author> I. S. Duff, R. G. Grimes, and J. G. Lewis. </author> <title> Sparse matrix test problems. </title> <journal> ACM Trans. Math. </journal> <volume> Software 15, </volume> <month> 1 (March </month> <year> 1989), </year> <month> 114. </month>
Reference-contexts: Full and undulant-block pivoting are used. That is, any 2 p fi 2 p subtree (submatrix) might be eliminated in a single elimination step; pivoting attempts to eliminate a large block with a small determinant. One matrix has been selected from the Harwell-Boeing data set <ref> [12] </ref> of sparse matrices. We chose CAN62 because it is small, integer, and non-singular. Its decomposition consumes many nodes without generating bignums that would skew measurements of heap use. It is a 62 fi 62 (patterned) symmetric matrix with 140 nonzero elementsall ones, with determinant 117.
Reference: [13] <author> R. K. Dybvig. </author> <title> Three Implementation Models for SCHEME, </title> <type> Ph.D. dissertation, </type> <institution> Univ. of North Carolina at Chapel Hill (April 1987). </institution>
Reference-contexts: That presumption can place an unusual demand on heap-management, especially where programs do not need it and might do better to exploit a hardware stack, just as C always does. Some compilers of applicative languages manage to eliminate heap-resident continuations for algorithms that could also be expressed in C <ref> [13] </ref>. Such a compilation would be necessary for a fair comparison to C, and is suggested by our experience with this design. 18 The present implementation is a board-level prototype installed as an I/O device on a bus, but the underlying design supports VLSI implementation [36] like ordinary dynamic RAM. <p> Acknowledgements: Thank You to MACH's designers, for providing preservation of transparent-translation tables, to NeXT for most generously providing us NBICs and prototype boards. to Bob Wehrmiester for early help on hardware, to Peter Beckman for preparing the matrix data, and to Esen Tuna for loaning us a compiler <ref> [13] </ref>. Thanks also to anonymous referees for helpful comments.
Reference: [14] <author> S. I. Feldman. </author> <title> Technological Maturity Scale. </title> <type> Personal communication (1991). </type>
Reference-contexts: Financial Breakeven. The concept is known to be the technique of choice in a significant domain, and that it is profitable to use it in general software practice [and] in concert with other techniques <ref> [14] </ref>. In that context this paper reports a research demonstration of hardware support for reference-counting and garbage collection as part of computer memory. Related work [21] supports scientific breakeven, as well. The concept was published twelve years ago [36].
Reference: [15] <author> S. I. Feldman. </author> <title> Technological maturity and the history of UNIX. Keynote address, </title> <booktitle> USENIX Summer 1992 Technical Conference, </booktitle> <address> San Antonio, TX (June 10, </address> <year> 1992). </year>
Reference-contexts: 1 Introduction 1.1 Technological Maturity Scale In 1992 Stuart Feldman presented a series of hurdles by which to measure progress in computing <ref> [15] </ref>. Paralleling the accepted milestones before thermonuclear-fusion power, he specified five milestones for new computer technologies by comparisons with alternative tools: 1. Idea/Concept. An idea has been conceived and, perhaps, published. It sounds good and original but, at most, [only] back-of-the-envelope calculations and trivial (usually paper) examples support it. 2.
Reference: [16] <author> J. Frens & D. S. Wise. </author> <title> Matrix inversion Using quadtrees implemented in GOFER. </title> <type> Technical Rept. 433, </type> <institution> Computer Science Dept., Indiana Univ. </institution> <month> (May </month> <year> 1995). </year>
Reference-contexts: seconds extrapolates (if RCM were local memory) to 501 seconds on Stock RAM, which would halve the performance, including collections, that we observed there. 6.2 Exact-arithmetic Quadtree-Matrix Inversion The second test program is exact-arithmetic matrix inversion, chosen because the problem is familiar and non-trivial, and because the purely applicative algorithm <ref> [37, 16] </ref>though unfamiliar and not compiled wellmust perform in place if it is ever to compete with popular alternatives. The results appear as Table 2 and Figure 6.
Reference: [17] <author> D. P. Friedman and D. S. Wise. </author> <title> Reference counting can manage the circular environments of mutual recursion. </title> <journal> Inform. Proc. Ltrs. </journal> <volume> 8, </volume> <month> 1 (January </month> <year> 1979), </year> <month> 4144. </month>
Reference-contexts: While arbitrary circular structures are well known to break reference counting, they are often overused; even classic examples are better implemented without any cycles [26, x2.2.4]. Moreover, that wisdom ignores strategies for circularities that sustain reference counting in useful situations <ref> [9, 5, 17, 39] </ref>. Baker [3, 4], for instance, implies that it consumes both address space and processor time, neither of which is used here. 2.2 A heap node The prototype provides nodes that are either atomic or binary, as the skeletal C++ declaration below illustrates.
Reference: [18] <author> D. Gries. </author> <title> An exercise in proving programs correct. </title> <journal> Comm. ACM 20, </journal> <month> 12 (December </month> <year> 1977), 921930. </year>
Reference-contexts: Indeed, others have implemented such hardware for uniprocessing or proposed it for multiprocessing <ref> [3, 18, 2, 28, 31, 33] </ref>. Although reference counting has been used successfully for managing secondary storage, garbage collection is still thought to be far more suitable for primary storage, where hardware support will be the most effective. <p> In a multiprocessing implementation all transactions (increments and decrements, as well as marking) would be dispatched asynchronously to be performed locally at memory. A balanced multiprocessor computes fast; therefore, a multiprocessing heap-mutator <ref> [18] </ref> generates garbage at a tremendous rate, and a balanced collector requires parallelism to keep apace.
Reference: [19] <author> A. Gottlieb, R. Girshman, C. P. Kruskal, K. P. McAuliffe, L. Rudolph, and M. Snir. </author> <title> The NYU ultracomputer Designing an MIMD shared memory parallel computer. </title> <journal> IEEE Trans. Computers C-32, </journal> <month> 2 (February </month> <year> 1983), </year> <pages> 175-189. </pages>
Reference-contexts: A unique, non-caching path between any source-destination pair, as on a bus or a banyan net <ref> [19] </ref> meets this constraint. Consistency of RCM memory is assured because memory overwrites occur as atomic operations locally at each RCM.
Reference: [20] <author> R. H. Halstead, Jr. </author> <title> MULTILISP: a language for concurrent symbolic computation. </title> <journal> ACM Trans. Prog. Lang. Sys./ </journal> <volume> 7, </volume> <month> 4 (October </month> <year> 1985), </year> <month> 501538. </month>
Reference-contexts: Innovative steps must be taken without a timetable for financial breakeven. 1.2 Reference-Counting Memory We report the design, construction, and testing of a specialized memory that provides system-level heap management in real time, providing atomic transactions that allow multiported access and multiprocessing collection <ref> [20] </ref> without repeated synchronization. The memory system is installed on a NeXT cube, and experiments compare it here to conventional collection on that machine: both stop/copy and mark/sweep.
Reference: [21] <author> B. Heck and D. S. Wise. </author> <title> Implementation of an applicative file system. </title> <editor> In Y. Bekkers and J. Cohen (eds.), </editor> <booktitle> Memory Management. Lecture Notes in Computer Science 637, </booktitle> <address> Berlin, </address> <publisher> Springer (1992), </publisher> <pages> 248263. </pages>
Reference-contexts: In that context this paper reports a research demonstration of hardware support for reference-counting and garbage collection as part of computer memory. Related work <ref> [21] </ref> supports scientific breakeven, as well. The concept was published twelve years ago [36]. The path from idea/concept to scientific breakeven is usually a story and, indeed, parts of this paper read like a narrative. <p> The memory system is installed on a NeXT cube, and experiments compare it here to conventional collection on that machine: both stop/copy and mark/sweep. It has been used to support a purely Applicative File System <ref> [21] </ref> and it has served as a test for rapid-prototyping of new insights into compile-time management [39]. Storage management is the broad problem of recovering unused space from the heap without explicit instructions from the programmer. <p> While substantially successful on all three goals, the three did erect additional constraints around the design. Later on, the RCM became essential to the Applicative File System <ref> [21] </ref>, toward which the development of the ultimate SCHEME software was directed. The rapid prototyping effort dictated that we use available hardware and software as much as possible. <p> They also offer the first research demonstration of such support for mark/sweep collection. Although these are yet uniprocessor results, together, they contribute to a research demonstration of hardware support for multiprocessing storage management. Furthermore, we can now recognize the Applicative File System <ref> [21] </ref> as a demonstration of scientific breakeven of reference counting in hardware. RCM allowed management of both disk and main memory under a homogeneous storage-management strategy: on-line reference counting as the primary algorithm, backed up by an expensive, offline garbage-collector.
Reference: [22] <author> P. Hudak and R. M. Keller. </author> <title> Garbage collection and task deletion in distributed applicative processing systems. </title> <booktitle> Conf. Rec. 1982 ACM Symp. on Lisp and Functional Programming (1982), </booktitle> <pages> 168178. </pages>
Reference-contexts: including some features that have been implemented but, as yet, not exercised. 2 Reference Counting in Hardware 2.1 Why Reference Counting? There are three reasons why reference counting [8] was studied as a primary strategy for memory management, in spite of prevailing practice using either off-line or on-line garbage collection <ref> [7, 2, 3, 29, 22, 30] </ref>. First, the same properties of reference counting that make it the usual strategy for managing disk sectors also become particularly important in multiprocessing. The three transactions (v.i.) that here implement reference counting are all finite and non-global.
Reference: [23] <author> D. H. H. Ingalls. </author> <title> The SMALLTALK-76 programming system: </title> <booktitle> design and implementation. Conf. Rec. 5th ACM Symp. on Principles of Programming Languages (1978), </booktitle> <volume> 915. </volume> <pages> 20 </pages>
Reference-contexts: It provides multiprocessor marking in place and in a single processor cycle; it requires no interprocessor synchronization and only a few cycles for each node traversed. This support in hardware for hybrid garbage collection is also new. State-of-the-art storage managers used in Smalltalk systems <ref> [23, 10] </ref>, as well as many secondary-storage managers, are also hybrids of garbage collection and reference counting, but this device is the first to provide hardware support for both. 3 In-place Garbage Collection This prototype provides several new features not included in the idea/concept paper [36], including hardware support for Deutsch-Schorr-Waite
Reference: [24] <author> S. D. Johnson. B. Bose & S. D. Johnson. DDD-FM9001: </author> <title> Derivation of a verified microprocessor; an exercise in integrating verification with formal derivation. </title> <editor> In G. Milne & L. Pierre (eds.), </editor> <booktitle> Proc. IFIP Conf. on Correct Hardware Design and Verification Methods. Lecture Notes in Computer Science 683, </booktitle> <address> Berlin, </address> <publisher> Springer (1993), 191202. </publisher>
Reference-contexts: The project had three original motivations: exercise of rapid hardware prototyping from another project, refinement of our digital design tools <ref> [24] </ref>, and support for applicative programming research. While substantially successful on all three goals, the three did erect additional constraints around the design. Later on, the RCM became essential to the Applicative File System [21], toward which the development of the ultimate SCHEME software was directed.
Reference: [25] <author> R. Jones & R. Lins. </author> <title> Garbage Collection, Algorithms for Automatic Dynamic Memory Management, </title> <address> New York, </address> <publisher> John Wiley & Sons (1996). </publisher>
Reference-contexts: Storage management is the broad problem of recovering unused space from the heap without explicit instructions from the programmer. It includes both reference counting, garbage collection, and hybrids of the two, like that reported here. Although the second term is often used to include all of storage management <ref> [7, 25] </ref>, we choose the original taxonomy [26, p. 412] because we find it more descriptive: reference counting is a better analog of curbside recycling than of trash collection. 2 Because of the central role played by heap management, it has now become a problem worthy of hardware support.
Reference: [26] <author> D. E. Knuth. </author> <title> The Art of Computer Programming I, Fundamental Algorithms (2nd ed.), </title> <address> Reading, MA, </address> <publisher> Addison-Wesley (1973). </publisher>
Reference-contexts: It includes both reference counting, garbage collection, and hybrids of the two, like that reported here. Although the second term is often used to include all of storage management [7, 25], we choose the original taxonomy <ref> [26, p. 412] </ref> because we find it more descriptive: reference counting is a better analog of curbside recycling than of trash collection. 2 Because of the central role played by heap management, it has now become a problem worthy of hardware support. <p> Conventional wisdom, that it breaks on cycles, stems from overstatements in both textbooks and research references. While arbitrary circular structures are well known to break reference counting, they are often overused; even classic examples are better implemented without any cycles <ref> [26, x2.2.4] </ref>. Moreover, that wisdom ignores strategies for circularities that sustain reference counting in useful situations [9, 5, 17, 39]. <p> It models the cons nodes of SCHEME and LISP, but also suffices for aggregates of arbitrary size via naturally corresponding binary trees <ref> [26, x2.3.2] </ref> or, better, complete trees [26, x2.3.4.5]. The latter are used to implement matrix decomposition in Section 5.2, below. These generalizations are needed by SMALLTALK and C++-style languages, whose efficient implementations likely require a four-pointer node; cf. <p> It models the cons nodes of SCHEME and LISP, but also suffices for aggregates of arbitrary size via naturally corresponding binary trees [26, x2.3.2] or, better, complete trees <ref> [26, x2.3.4.5] </ref>. The latter are used to implement matrix decomposition in Section 5.2, below. These generalizations are needed by SMALLTALK and C++-style languages, whose efficient implementations likely require a four-pointer node; cf. <p> For example, writing an address to either of two distinguished addresses dispatches an increment or, respectively, a decrement to the count of the addressed node. A special garbage-collection mode, during which the interpretation of reads and writes to RCM is completely redefined, supports a Deutsch-Schorr-Waite mark-phase <ref> [26, 34] </ref>. It provides multiprocessor marking in place and in a single processor cycle; it requires no interprocessor synchronization and only a few cycles for each node traversed. This support in hardware for hybrid garbage collection is also new.
Reference: [27] <author> D. E. Knuth. </author> <title> The Art of Computer Programming III, Sorting and Searching, </title> <address> Reading, MA, </address> <publisher> Addison-Wesley, </publisher> <year> (1973). </year>
Reference-contexts: Appendix A presents our code for a SCHEME function that inserts a keyinformation pair into an initially empty, AVL or balanced tree <ref> [27, x6.2.3] </ref>. It is purely functional, returning the resulting tree from each insertion without requiring side effects to its arguments. The first test is to apply it in a tail-recursion to insert 75,000 different random numbers into an initially empty tree.
Reference: [28] <author> B. Lang, C. Queinnec, J. Piquer. </author> <title> Garbage collecting the world. </title> <booktitle> Conf. Rec. 19th ACM Symp. on Principles of Programming Languages (1992), </booktitle> <pages> 3950. </pages>
Reference-contexts: Indeed, others have implemented such hardware for uniprocessing or proposed it for multiprocessing <ref> [3, 18, 2, 28, 31, 33] </ref>. Although reference counting has been used successfully for managing secondary storage, garbage collection is still thought to be far more suitable for primary storage, where hardware support will be the most effective.
Reference: [29] <author> H. Lieberman and C. Hewitt. </author> <title> A real-time garbage collector based on the lifetime of objects. </title> <journal> Comm. ACM 26, </journal> <month> 6 (June </month> <year> 1983), 419429. </year>
Reference-contexts: including some features that have been implemented but, as yet, not exercised. 2 Reference Counting in Hardware 2.1 Why Reference Counting? There are three reasons why reference counting [8] was studied as a primary strategy for memory management, in spite of prevailing practice using either off-line or on-line garbage collection <ref> [7, 2, 3, 29, 22, 30] </ref>. First, the same properties of reference counting that make it the usual strategy for managing disk sectors also become particularly important in multiprocessing. The three transactions (v.i.) that here implement reference counting are all finite and non-global.
Reference: [30] <author> D. Moon. </author> <title> Garbage collection in a large LISP system. </title> <booktitle> Conf. Rec. 1984 ACM Symp. on Lisp and Functional Programming, </booktitle> <pages> 235246. </pages>
Reference-contexts: including some features that have been implemented but, as yet, not exercised. 2 Reference Counting in Hardware 2.1 Why Reference Counting? There are three reasons why reference counting [8] was studied as a primary strategy for memory management, in spite of prevailing practice using either off-line or on-line garbage collection <ref> [7, 2, 3, 29, 22, 30] </ref>. First, the same properties of reference counting that make it the usual strategy for managing disk sectors also become particularly important in multiprocessing. The three transactions (v.i.) that here implement reference counting are all finite and non-global. <p> Some might not accept it as scientific breakeven, however, because in-house experience may be too narrow. In a broader sense, all these results contribute to scientific breakeven (over software) of hardware support for storage management, where extramural research demonstrations already exist <ref> [30, 31, 33] </ref>. 7.3 Future Work Advocates and implementors of functional programming and heap memory should take care to separate their assumptions from C++'s, from ours, and from an ideal. Many presume a low-level continuation-passing style, which makes it easy to return functions as results to outer environments.
Reference: [31] <author> K. Nilsen. </author> <title> Progress in hardware-assisted real-time garbage collection. </title> <editor> In H. G. Baker (ed.), </editor> <booktitle> Memory Management. Lecture Notes in Computer Science 986, </booktitle> <address> Berlin, </address> <publisher> Springer (1995), </publisher> <pages> 355379. </pages>
Reference-contexts: Indeed, others have implemented such hardware for uniprocessing or proposed it for multiprocessing <ref> [3, 18, 2, 28, 31, 33] </ref>. Although reference counting has been used successfully for managing secondary storage, garbage collection is still thought to be far more suitable for primary storage, where hardware support will be the most effective. <p> Some might not accept it as scientific breakeven, however, because in-house experience may be too narrow. In a broader sense, all these results contribute to scientific breakeven (over software) of hardware support for storage management, where extramural research demonstrations already exist <ref> [30, 31, 33] </ref>. 7.3 Future Work Advocates and implementors of functional programming and heap memory should take care to separate their assumptions from C++'s, from ours, and from an ideal. Many presume a low-level continuation-passing style, which makes it easy to return functions as results to outer environments.
Reference: [32] <editor> J. Rees and W. Clinger (Eds.) </editor> <title> Revised 3 report on the algorithmic language SCHEME. </title> <journal> ACM SIGPLAN Notices 21, </journal> <month> 12 (December </month> <year> 1986), </year> <month> 3779. </month>
Reference: [33] <author> W. Schmidt & K. Nilsen. </author> <title> Performance of a hardware-assisted real-time garbage collector. </title> <booktitle> ASPLOS-VI Proc.: 6th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, ACM SIGPLAN Notices 29, </booktitle> <month> 11 (November </month> <year> 1994), </year> <month> 7685. </month>
Reference-contexts: Indeed, others have implemented such hardware for uniprocessing or proposed it for multiprocessing <ref> [3, 18, 2, 28, 31, 33] </ref>. Although reference counting has been used successfully for managing secondary storage, garbage collection is still thought to be far more suitable for primary storage, where hardware support will be the most effective. <p> Some might not accept it as scientific breakeven, however, because in-house experience may be too narrow. In a broader sense, all these results contribute to scientific breakeven (over software) of hardware support for storage management, where extramural research demonstrations already exist <ref> [30, 31, 33] </ref>. 7.3 Future Work Advocates and implementors of functional programming and heap memory should take care to separate their assumptions from C++'s, from ours, and from an ideal. Many presume a low-level continuation-passing style, which makes it easy to return functions as results to outer environments.
Reference: [34] <author> H. Schorr and W. M. Waite. </author> <title> An efficient machine-independent procedure for garbage collection in various list structures. </title> <journal> Comm. ACM 10, </journal> <month> 8 (August </month> <year> 1967), </year> <month> 501506. </month>
Reference-contexts: Every pointer written causes an increment to the new referent, and every pointer erased causes a decrement, as well; thus, the common pointer overwrite causes both. Although the principal strategy is on-line reference counting, implemented purely in memory [36], RCM also includes support for mark/sweep garbage collection <ref> [34] </ref> that is both fast and parallel, but off-line. In a multiprocessing implementation all transactions (increments and decrements, as well as marking) would be dispatched asynchronously to be performed locally at memory. <p> For example, writing an address to either of two distinguished addresses dispatches an increment or, respectively, a decrement to the count of the addressed node. A special garbage-collection mode, during which the interpretation of reads and writes to RCM is completely redefined, supports a Deutsch-Schorr-Waite mark-phase <ref> [26, 34] </ref>. It provides multiprocessor marking in place and in a single processor cycle; it requires no interprocessor synchronization and only a few cycles for each node traversed. This support in hardware for hybrid garbage collection is also new. <p> as well as many secondary-storage managers, are also hybrids of garbage collection and reference counting, but this device is the first to provide hardware support for both. 3 In-place Garbage Collection This prototype provides several new features not included in the idea/concept paper [36], including hardware support for Deutsch-Schorr-Waite collection <ref> [34] </ref>. It has two features that render this algorithm competitive with recopying collection, even on this uniprocessor and, more importantly, that also provide for asynchronous, multiprocessing collection. <p> On one or two later visits, another live pointer can be read/written with later read, and ultimately the stack is read out and the last live pointer written back, restoring the node to its original configuration <ref> [34] </ref>. The effect of these special reads and write is to allow traversal of a node with two live pointers in six memory cycles, with one live pointer in four memory cycles, and with both pointers dead (e.g. atomic) in just one cycle.
Reference: [35] <author> J. Weizenbaum. </author> <title> Symmetric list processor. </title> <journal> Comm. ACM 6, </journal> <month> 9 (December </month> <year> 1963), </year> <month> 524544. </month>
Reference-contexts: Each 1 It is necessary to dispatch increment before decrement to handle correctly a reflexive assignment, ptr=ptr when ptr is a unique reference. 5 of these three operations requires only finite time. A node typically returns to available space still containing live, yet-counted pointers <ref> [35] </ref>. 2.4 The physical implementation and reference-count memory. The data memory handles conventional reads and writes from the processor (s), delivered via address and data busses and and strobed just as on ordinary RAM.
Reference: [36] <author> D. S. Wise. </author> <title> Design for a multiprocessing heap with on-board reference counting. </title> <editor> In J.P. Jouannaud (ed.), </editor> <booktitle> Functional Programming Languages and Computer Architecture, Lecture Notes in Computer Science 201, </booktitle> <address> Berlin, </address> <publisher> Springer (1985), </publisher> <pages> 289304. </pages>
Reference-contexts: In that context this paper reports a research demonstration of hardware support for reference-counting and garbage collection as part of computer memory. Related work [21] supports scientific breakeven, as well. The concept was published twelve years ago <ref> [36] </ref>. The path from idea/concept to scientific breakeven is usually a story and, indeed, parts of this paper read like a narrative. However, the writing of stories like thiseven unsuccessful onesis essential to advancing the complex symbiosis between hardware and software. <p> Every pointer written causes an increment to the new referent, and every pointer erased causes a decrement, as well; thus, the common pointer overwrite causes both. Although the principal strategy is on-line reference counting, implemented purely in memory <ref> [36] </ref>, RCM also includes support for mark/sweep garbage collection [34] that is both fast and parallel, but off-line. In a multiprocessing implementation all transactions (increments and decrements, as well as marking) would be dispatched asynchronously to be performed locally at memory. <p> managers used in Smalltalk systems [23, 10], as well as many secondary-storage managers, are also hybrids of garbage collection and reference counting, but this device is the first to provide hardware support for both. 3 In-place Garbage Collection This prototype provides several new features not included in the idea/concept paper <ref> [36] </ref>, including hardware support for Deutsch-Schorr-Waite collection [34]. It has two features that render this algorithm competitive with recopying collection, even on this uniprocessor and, more importantly, that also provide for asynchronous, multiprocessing collection. <p> Such a compilation would be necessary for a fair comparison to C, and is suggested by our experience with this design. 18 The present implementation is a board-level prototype installed as an I/O device on a bus, but the underlying design supports VLSI implementation <ref> [36] </ref> like ordinary dynamic RAM. The prototype is now installed in a uniprocessor, but the design is targeted for several banks of RCM within a multiprocessor. Moreover, the software now available is only a prototype compiler, so there is much opportunity for improvement there too.
Reference: [37] <author> D. S. Wise. </author> <title> Undulant block elimination and integer-preserving matrix inversion. </title> <institution> Sci. Comput. </institution> <note> Programming (to appear). Technical Rept. 418, </note> <institution> Computer Science Dept., Indiana Univ. </institution> <note> (revised August 1995). </note>
Reference-contexts: seconds extrapolates (if RCM were local memory) to 501 seconds on Stock RAM, which would halve the performance, including collections, that we observed there. 6.2 Exact-arithmetic Quadtree-Matrix Inversion The second test program is exact-arithmetic matrix inversion, chosen because the problem is familiar and non-trivial, and because the purely applicative algorithm <ref> [37, 16] </ref>though unfamiliar and not compiled wellmust perform in place if it is ever to compete with popular alternatives. The results appear as Table 2 and Figure 6. <p> Its properties as additive identity and multiplicative annihilator unifies the algorithms for sparse and dense matrices. The algorithm used to exercise RCM is an exact-arithmetic LU decomposition and inversion algorithm <ref> [37] </ref>, followed by a back-multiply (AA 0 ) to the matrix (dI). Full and undulant-block pivoting are used. That is, any 2 p fi 2 p subtree (submatrix) might be eliminated in a single elimination step; pivoting attempts to eliminate a large block with a small determinant.
Reference: [38] <author> D. S. Wise and J. Franco. </author> <title> Costs of quadtree representation of non-dense matrices. </title> <journal> J. Parallel Distrib. Comput. </journal> <volume> 9, </volume> <month> 3 (July </month> <year> 1990), </year> <pages> 282-296. 21 </pages>
Reference-contexts: The results appear as Table 2 and Figure 6. The problem is to compute from an integer matrix, A, both d = det A and (when d 6= 0) another matrix A 0 = dA 1 . The quadtree representation of matrices <ref> [38] </ref> offers a uniform representation of both sparse and full matrices as directed, acyclic graphs (dags). Briefly, a matrix is either homogeneously zero (NIL), or a non-zero 1 fi 1 scalar (that integer), or it is a quadruple of four equally-ordered submatrices.
Reference: [39] <author> D. S. Wise & J. Walgenbach. </author> <title> Static and dynamic partitioning of pointers as links and threads. </title> <booktitle> Proc. 1996 Intl. Conf. on Functional Programming, ACM SIGPLAN Notices 31 , 6 (June 1996), </booktitle> <pages> 4249. </pages>
Reference-contexts: It has been used to support a purely Applicative File System [21] and it has served as a test for rapid-prototyping of new insights into compile-time management <ref> [39] </ref>. Storage management is the broad problem of recovering unused space from the heap without explicit instructions from the programmer. It includes both reference counting, garbage collection, and hybrids of the two, like that reported here. <p> While arbitrary circular structures are well known to break reference counting, they are often overused; even classic examples are better implemented without any cycles [26, x2.2.4]. Moreover, that wisdom ignores strategies for circularities that sustain reference counting in useful situations <ref> [9, 5, 17, 39] </ref>. Baker [3, 4], for instance, implies that it consumes both address space and processor time, neither of which is used here. 2.2 A heap node The prototype provides nodes that are either atomic or binary, as the skeletal C++ declaration below illustrates. <p> Processing of the doubled dispatches from RCM-pointer writes, moreover, is also absorbed by interleaved transactions that do not involve reference-counts: e.g. RCM reads, RCM writes or overwrites of dead data, and RAM or idle-memory cycles. Data in RCM is tagged as either live or dead <ref> [39] </ref> at memory. Atomic information and immediate references, like 6 NULL, are dead; pointers are tagged live. When a dead (atomic) datum is written to RCM, no increment is dispatched, and when a dead datum is overwritten there, no decrement is issued. <p> One is on-line multiprocessor reference-counting; a related one is off-line multiprocessor garbage-collection. Another is an unimplemented facility to store a dead pointer (or thread) in a single cycle; originally intended to recover circular structures, it has since demonstrated itself useful for reducing counts in other contexts, as well <ref> [39] </ref>, and must be included in any revision. We foresee many RCMs built to a standard SIMM interface and installed on a stock multiprocessor.
References-found: 39

