URL: ftp://ftp.cwi.nl/pub/pdg/pdbn.ps.Z
Refering-URL: http://www.cwi.nl/~pdg/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Phone: 26,  
Title: On Predictive Distributions and Bayesian Networks  
Author: Petri Kontkanen, Petri Myllymaki, Tomi Silander, Henry Tirri Peter Grunwald 
Address: P.O.Box  FIN-00014 University of Helsinki, Finland  P.O. Box 94079, NL-1090 GB Amsterdam, The Netherlands  
Affiliation: Complex Systems Computation Group (CoSCo)  Department of Computer Science  CWI, Department of Algorithms and Architectures  
Abstract: In this paper we are interested in discrete prediction problems for a decision-theoretic setting, where the task is to compute the predictive distribution for a finite set of possible alternatives. This question is first addressed in a general framework, where we consider a set of probability distributions defined by some parametric model class. The standard Bayesian approach is to compute the posterior probability for the model parameters, given a prior distribution and sample data, and fix the parameters to the instantiation with the maximum a posteriori probability. A more accurate predictive distribution can be obtained by computing the evidence, i.e., the integral over all the individual parameter instantiations. As an alternative to these two approaches, we demonstrate how to use Rissanen's new definition of stochastic complexity for determining predictive distributions. We then describe how these predictive inference methods can be realized in the case of Bayesian networks. In particular, we demonstrate the use of Jeffrey's prior as the prior distribution for computing the evidence predictive distribution. It can be shown that the evidence predictive distribution with Jeffrey's prior approaches the new stochastic complexity predictive distribution in the limit with increasing amount of sample data. For computational reasons, in the experimental part of the paper the three predictive distributions are compared by using the tree-structured simple Naive Bayes model. The experimentation with several public domain classification datasets suggest that the evidence approach produces the most accurate predictions in the log-score sense, especially with small training sets.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.O. Berger. </author> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: All possible outcomes, corresponding to the set of possible actions given, are assumed to result to some gain or utility, the value of which depends on the correct (but unknown) action in the decision problem in question. From 1 the decision-theoretic point of view (see e.g. <ref> [1] </ref>), the optimal procedure in this case is to to choose the action with the maximal expected utility. To be able to maximize the expected utility, one needs to determine the predictive distribution for all the possible actions, by using the problem domain probability distribution. <p> The reader may verify this by trying the following very simple example: suppose X = fX 1 ; X 2 g, X 1 and X 2 are independent and take on values in f0; 1g, U = fX 1 g, V = fX 2 g,M = <ref> [0; 1] </ref>, where P (x 1 ; x 2 jfi) is defined by P (X 1 = 1jfi) = P (X 2 = 1jfi) = fi. Further suppose D = ((1; 1)) and ~u 2 = 1.
Reference: [2] <author> B.S. Clarke and A.R. Barron. </author> <title> Information-theoretic asymptotics of Bayes methods. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 36(3) </volume> <pages> 453-471, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Clarke and Barron <ref> [2] </ref> proved that for i.i.d. data from model classes with finite integral R jI (fi)j 1=2 dfi, we have the following asymptotic expansion for all fi 2 M: E fi [ log P evj (D)] = E fi [log P (Djfi)] + r log 2 Z q jI (fi)jdfi + o
Reference: [3] <author> G. Cooper and E. Herskovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 309-347, </pages> <year> 1992. </year>
Reference-contexts: As showed in <ref> [3, 7] </ref>, with Bayesian networks this integral can be solved analytically, yielding P ev ( ~ d t j D) = i=1 q i =1 x i =1 q i x i ) where i f i q i x i l=1 f i q i l From (14) we see
Reference: [4] <author> G.F. Cooper. </author> <title> The computational complexity of probabilistic inference using Bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):393-405, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Secondly, using Jeffrey's prior as formulated here, requires computing the marginal likelihood for the parents of each node in the Bayesian network. As this problem is known to be NP-hard for multi-connected Bayesian network structures <ref> [4] </ref>, determining Jeffrey's priors in practice may 2 be computationally difficult. <p> Unfortunately, for multi-connected Bayesian net works, this problem is known to be NP-hard <ref> [4] </ref>.
Reference: [5] <author> M.H. </author> <title> DeGroot. Optimal statistical decisions. </title> <publisher> McGraw-Hill, </publisher> <year> 1970. </year>
Reference-contexts: Furthermore, all the conditional distributions of the variables given their parents are assumed to be multinomial, i.e., X ijq i ~ Multi (1; i q i 1 ; : : : ; i q i n i ). Since the family of Dirichlet densities is conjugate (see e.g. <ref> [5] </ref>) to the family of multinomials, i.e. the functional form of parameter distribution remains invariant in the prior-to-posterior transformation, we assume that the prior distributions of the parameters are from this family 2 .
Reference: [6] <author> D. Geiger and D. Heckerman. </author> <title> A characterization of the Dirichlet distribution through global and local independence. </title> <type> Technical Report MSR-TR-94-16, </type> <institution> Microsoft Research, </institution> <month> November (revised February </month> <year> 1995) 1994. </year>
Reference-contexts: = (~u; ~v), t = N + 1: P map ( ~ d t j D) = P ( ~ d t j ^ fi (D)) = i=1 q i =1 x i =1 q i x i ) 2 An additional justification for using Dirichlet priors is given in <ref> [6] </ref>, where it is shown that under certain assumptions, Dirichlet is the only prior that can be used without violating the assumptions made. 8 where ^ i f i q i x i 1 l=1 f i q i l n i and f i q i x i are the
Reference: [7] <author> D. Heckerman, D. Geiger, </author> <title> and D.M. Chickering. Learning Bayesian networks: The combination of knowledge and statistical data. </title> <journal> Machine Learning, </journal> <volume> 20(3) </volume> <pages> 197-243, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: As showed in <ref> [3, 7] </ref>, with Bayesian networks this integral can be solved analytically, yielding P ev ( ~ d t j D) = i=1 q i =1 x i =1 q i x i ) where i f i q i x i l=1 f i q i l From (14) we see
Reference: [8] <author> P. Kontkanen, P. Myllymaki, T. Silander, H. Tirri, and P. Grunwald. </author> <title> Comparing predictive inference methods for discrete domains. </title> <booktitle> In Proceedings of the Sixth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 311-318, </pages> <address> Ft. Lauderdale, Flor-ida, </address> <month> January </month> <year> 1997. </year>
Reference-contexts: This can be seen as an extension of the work reported in <ref> [8] </ref>, where the problem was studied in the more limited Naive Bayes classifier context. Furthermore, in addition to the standard case with uniform prior distribution, we discuss here also the use of Jeffrey's prior for computing the evidence predictive distribution.
Reference: [9] <editor> D. Michie, D.J. Spiegelhalter, and C.C. Taylor, editors. </editor> <title> Machine Learning, Neural and Statistical Classification. </title> <publisher> Ellis Horwood, </publisher> <address> London, </address> <year> 1994. </year>
Reference-contexts: we studied how the prediction quality of our various approaches depends on the size of the training set D. 4.2 Crossvalidation results In our crossvalidation experiments, we initially used with each of the datasets the same number of folds as in the major experimental comparison performed by the Statlog project <ref> [9] </ref> (the number of folds used in each case can be found in Table 1).
Reference: [10] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: This suggests using P evj instead of P sc as a predictive distribution, at least in those cases where the regularity conditions for (11) and (13) hold. 7 3 Predictive Distributions for Bayesian Networks 3.1 Bayesian Networks A Bayesian (belief) network <ref> [10, 14] </ref> is a graphical high-level representation of a probability distribution over a set of discrete variables. More precisely, a Bayesian network is an acyclic directed graph, where the nodes correspond to the domain variables X 1 ; : : : ; X m .
Reference: [11] <author> J. Rissanen. </author> <title> Stochastic complexity. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 49(3) </volume> <pages> 223-239 and 252-265, </pages> <year> 1987. </year>
Reference-contexts: Rissanen <ref> [11] </ref> has introduced the concept in the mid-eighties.
Reference: [12] <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific Publishing Company, </publisher> <address> New Jersey, </address> <year> 1989. </year>
Reference-contexts: In the evidence approach, the predictive distribution is obtained by integrating over all the possible parameter instantiations, in other words, over all the distributions representable by the chosen model form. As pointed out in <ref> [12] </ref>, in information theoretic terms, minus the logarithm of the evidence integral can be regarded as a formalization of stochastic complexity (SC), i.e., the shortest possible codelength for coding the training set, the given and estimated parts of the query vector, with respect to the chosen model form. <p> In this case, the predictive distribution (1) 4 becomes P ev ( ~ d j D) = P ( ~ d j D; fi)P (fi)dfi: (6) 2.4 The stochastic complexity predictive distribution P sc Stochastic Complexity is a central notion in the theory of Minimum Description Length Inference <ref> [12, 13] </ref>. Rissanen [11] has introduced the concept in the mid-eighties. <p> Here by `shortest code' one means the code that gives as short as possible a code length to all possible data sets D. It is a well-known fact from information theory (see for example <ref> [12] </ref>) that for any complete code C, there is a corresponding probability distribution P C such that for all data sets D, log P C (D) is the length of the encoding of D when the encoding is done using C. <p> This motivates the use of P sc for prediction. The definition above gives no explicit formula for the stochastic complexity; indeed, in Ris-sanen's words [13], "it leaves open the burning question of how to compute it". There are several reasons <ref> [12] </ref> of why log P ev (D) is a good candidate for the stochastic complexity. Therefore, Rissanen originally proposed it as its mathematical definition: S (D) = log P ev (D). <p> The deeper reason for this unsettling behavior is that P sc does not satisfy Kolmogorov's compatibility condition (see for example <ref> [12] </ref>) which says that for any random process P , P ~ d P ( ~ d; D) = P (D).
Reference: [13] <author> J. Rissanen. </author> <title> Fisher information and stochastic complexity. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 42(1) </volume> <pages> 40-47, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: Recently Rissanen <ref> [13] </ref> has introduced an alternative coding scheme, which in some cases produces much shorter codes than the evidence approach, while retaining the code length approximately the same for the other cases. In the third approach considered here, we define the predictive distribution by using Rissanen's new definition of stochastic complexity. <p> The case with Jeffrey's prior distribution is particularly interesting as it can be shown that with this prior the evidence predictive distribution approaches the stochastic complexity predictive distribution when the sample size increases <ref> [13] </ref>. Although the general forms for computing the three predictive distributions for Bayesian networks are described in Section 3, there remains some computational problems if the methods are to be used in practice. <p> In this case, the predictive distribution (1) 4 becomes P ev ( ~ d j D) = P ( ~ d j D; fi)P (fi)dfi: (6) 2.4 The stochastic complexity predictive distribution P sc Stochastic Complexity is a central notion in the theory of Minimum Description Length Inference <ref> [12, 13] </ref>. Rissanen [11] has introduced the concept in the mid-eighties. <p> This motivates the use of P sc for prediction. The definition above gives no explicit formula for the stochastic complexity; indeed, in Ris-sanen's words <ref> [13] </ref>, "it leaves open the burning question of how to compute it". There are several reasons [12] of why log P ev (D) is a good candidate for the stochastic complexity. Therefore, Rissanen originally proposed it as its mathematical definition: S (D) = log P ev (D). Recently, however, Rissanen [13] <p> <ref> [13] </ref>, "it leaves open the burning question of how to compute it". There are several reasons [12] of why log P ev (D) is a good candidate for the stochastic complexity. Therefore, Rissanen originally proposed it as its mathematical definition: S (D) = log P ev (D). Recently, however, Rissanen [13] has shown that there exists a code that is itself not dependent on any prior distributions of parameters and which in general yields even shorter codelengths than the code with lengths log P ev (D). <p> On the other hand, as is implicitly suggested by Rissanen in <ref> [13] </ref>, the theoretical results imply that if we want to find a good predictive distribution, we should look for the random process (i.e. a stable distribution) that best approximates P sc . This is what we will do in the following. In [13] an important theorem was proved which says that, <p> hand, as is implicitly suggested by Rissanen in <ref> [13] </ref>, the theoretical results imply that if we want to find a good predictive distribution, we should look for the random process (i.e. a stable distribution) that best approximates P sc . This is what we will do in the following. In [13] an important theorem was proved which says that, under some weak regularity conditions on the model class M, we have for all fi 2 M, E fi [ log P sc (D)] = E fi [log P (Djfi)] + r log 2 Z q jI (fi)jdfi + o (1) (11) <p> We will see in Section 3.5 that condition 1) is satisfied for a certain set of Bayesian network models used in our experiments reported in Section 4. The reader may check in <ref> [13] </ref> that the other conditions for (11) to hold are also satisfied in this case. The Fisher information is used for defining a particular prior distribution called Jeffrey's prior , denoted by (fi). <p> Moreover, calculations of the o (1) terms show that, at least for the class of multinomial distributions, they go to zero very rapidly as N increases <ref> [13] </ref>. On the other hand, it is very easy to show that P ev is stable for any prior P , and thus P evj is stable too.
Reference: [14] <author> R.D. Shachter. </author> <title> Probabilistic inference and influence diagrams. </title> <journal> Operations Research, </journal> <volume> 36(4) </volume> <pages> 589-604, </pages> <month> July-August </month> <year> 1988. </year>
Reference-contexts: This suggests using P evj instead of P sc as a predictive distribution, at least in those cases where the regularity conditions for (11) and (13) hold. 7 3 Predictive Distributions for Bayesian Networks 3.1 Bayesian Networks A Bayesian (belief) network <ref> [10, 14] </ref> is a graphical high-level representation of a probability distribution over a set of discrete variables. More precisely, a Bayesian network is an acyclic directed graph, where the nodes correspond to the domain variables X 1 ; : : : ; X m .
Reference: [15] <author> H. Tirri, P. Kontkanen, and P. Myllymaki. </author> <title> Probabilistic instance-based learning. </title> <editor> In L. Saitta, editor, </editor> <booktitle> Machine Learning: Proceedings of the Thirteenth International Conference, </booktitle> <pages> pages 507-515. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1996. </year> <month> 19 </month>
Reference-contexts: In addition to comparison purposes between the different predictive distributions, the results in Figures 1 and 2 are interesting as they show surprisingly good performance of the Naive Bayes model when compared to the results reported in the machine learning literature (for references, see e.g., <ref> [15] </ref>). This fact becomes especially clear if we look at the maximal results reported here, which in many cases is justifiable as many of the results reported in the literature seem to be obtained by this way, although this fact may not be explicitly stated.
References-found: 15

