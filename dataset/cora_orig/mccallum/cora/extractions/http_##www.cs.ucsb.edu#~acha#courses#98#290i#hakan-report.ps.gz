URL: http://www.cs.ucsb.edu/~acha/courses/98/290i/hakan-report.ps.gz
Refering-URL: http://www.cs.ucsb.edu/~acha/courses/98/290i.html
Root-URL: http://www.cs.ucsb.edu
Title: Performance Evaluation of Declustering Techniques for Similarity Searching  
Author: Hakan Ferhatosmanoglu 
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. C. Du and J. S. Sobolewski. </author> <title> Disk allocation for cartesian product files on multiple-disk systems. </title>
Reference-contexts: The core problem of designing a parallel nearest neighbor algorithm is to find an adequate distribution of the data onto the disks. Several declustering techniques have been proposed for improving the performance of range queries, and partial match queries, and similarity queries. Disk Modulo (DM) <ref> [1] </ref>, Fieldwise Exclusive (FX) [2], and Hilbert (HCAM) [3] have been originally proposed to support range and partial match queries. For instance, the performance of HCAM is best for square range queries in two dimensions. However, these schemes can also be used for nearest neighbor queries.
Reference: [2] <author> M. H. Kim and S. Pramanik. </author> <title> Optimal file distribution for partial match retrieval. </title>
Reference-contexts: The core problem of designing a parallel nearest neighbor algorithm is to find an adequate distribution of the data onto the disks. Several declustering techniques have been proposed for improving the performance of range queries, and partial match queries, and similarity queries. Disk Modulo (DM) [1], Fieldwise Exclusive (FX) <ref> [2] </ref>, and Hilbert (HCAM) [3] have been originally proposed to support range and partial match queries. For instance, the performance of HCAM is best for square range queries in two dimensions. However, these schemes can also be used for nearest neighbor queries.
Reference: [3] <author> C. Faloutsos and P. Bhagwat. </author> <title> Declustering using fractals. </title>
Reference-contexts: Several declustering techniques have been proposed for improving the performance of range queries, and partial match queries, and similarity queries. Disk Modulo (DM) [1], Fieldwise Exclusive (FX) [2], and Hilbert (HCAM) <ref> [3] </ref> have been originally proposed to support range and partial match queries. For instance, the performance of HCAM is best for square range queries in two dimensions. However, these schemes can also be used for nearest neighbor queries. Near Optimal Declustering (NoD) [4] was developed for nearest neighbor queries.
Reference: [4] <author> S. Berchtold, C. Bohm, B. Braunmuller, D. A. Keim, and H-P. Kriegel. </author> <title> Fast parallel similarity search in multimedia databases. </title>
Reference-contexts: For instance, the performance of HCAM is best for square range queries in two dimensions. However, these schemes can also be used for nearest neighbor queries. Near Optimal Declustering (NoD) <ref> [4] </ref> was developed for nearest neighbor queries. Finally, Cyclic Allocation [5] was developed for both range and nearest neighbor queries. <p> Given high dimensional array of tiles, the HCAM method first converts the array into a linear sequence, and then allocates the tiles to devices in a round-robin fashion following the linear sequence. NoD was proposed in <ref> [4] </ref> to optimize nearest-neighbour queries in high dimensional datasets. This scheme requires that each dimension be divided into exactly two parts, thus the value of each coordinate is either 0 or 1. <p> Metrics with Indexing The metrics and criterions that were used in some related previous works do not accurately reflect the real performance of the systems. A new metric with a real index structure is needed. 3.1 Previous Work and Extensions In <ref> [4] </ref>, near optimal declustering is defined in the following way: A declustering algorithm DA is near-optimal, if and only if for any two buckets b and c and for any dimension d of the data space: if b and c differ in one (direct neighbor) or two dimensions (indirect neighbor), they <p> in the following way: A declustering algorithm DA is near-optimal, if and only if for any two buckets b and c and for any dimension d of the data space: if b and c differ in one (direct neighbor) or two dimensions (indirect neighbor), they are distributed to different disks. <ref> [4] </ref> By this definition, the number of direct and indirect neighbors of a bucket that are allocated to the same disk as the bucket itself can be a measure of how far the allocation is from being a near-optimal allocation. The number 0 indicates near-optimal declustering according to this definition. <p> In order to have some idea about the practical relevance of these schemes, in this part of the experiments, I use real and highly clustered data. Two of these real dataset are same with the dataset that is used in <ref> [4] </ref>. Therefore, I have three main goals to use real data. Firstly, to see the performance of these schemes in the case of nonuniformity, secondly, to see the practical relevance of the schemes, thirdly, to compare the schemes with NoD by using the same datasets. <p> For 8-dimensions, NoD does not use more than 16 disks, even if there are more than 16 disks available. To decluster an 8-dimensioanl data space, NoD algorithm requires 16 disks to achieve near-optimality according to their definition. In <ref> [4] </ref>, all the graphs are considered up to 16 disks after which the algorithm has no improvement. The relation between the dimensionality and the number of disks can be seen in Figure 12. <p> Weakness and strength of all of these schemes are analyzed in terms of a cost metric. Some limitations and specifications of the techniques have been studied. This project shows that the metrics and criterions that were used in some related previous works <ref> [4] </ref> and [7] do not accurately reflect the real performance of the systems. Therefore, in my experiment design I use an index structure SS-tree, which is originally for high dimensional similarity search, to see the number of bucket retrieval in an actual similarity searching.
Reference: [5] <author> S. Prabhakar, K. Abdel-Ghaffar, D. Agrawal, and A. El Abbadi. </author> <title> Cyclic declustering of two-dimensional data. </title>
Reference-contexts: For instance, the performance of HCAM is best for square range queries in two dimensions. However, these schemes can also be used for nearest neighbor queries. Near Optimal Declustering (NoD) [4] was developed for nearest neighbor queries. Finally, Cyclic Allocation <ref> [5] </ref> was developed for both range and nearest neighbor queries. <p> Each bucket can therefore be identified by a binary number, where each bit identifies the bucket in each dimension. The Cyclic Allocation Scheme, which was proposed in <ref> [5] </ref>, defined for all dimensions, and allocate the bucket (x 1 , x 2 , x 3 ,.,x d-1 ) be allocated to disk D. <p> However, this definition of near-optimal declustering does not reflect the degree of parallelism achieved.. As mentioned above, data which has to be read in executing a query are distributed as equally as possible among the disks. The metric proposed in <ref> [5] </ref> is an extension of this near-optimal definition. They define a new criterion for comparing the quality of declustering for direct and indirect neighbors.
Reference: [6] <author> B. Moon, A. Acharya, and J. Saltz. </author> <title> Study of Scalable Declustering Algorithms for Parallel Grid Files. </title>
Reference-contexts: Comparison of the performance of the these schemes with uniformly and nonuniformly distributed datasets is also done in the project. Extensions of these schemes for grid files, by using a tie-breaking or conflict resolution mechanism of some sort, are also possible <ref> [6] </ref>. Since, the indexing used in this project is a tree structured method, which has been proposed specifically for similarity search, tiling rather than Grid Files, is used for partitioning the data space. Since the techniques are designed in a static way, performance may deteriorate in case of dynamic datasets. <p> These results show that, since these schemes use tiling for Cartesian Product Files, they cannot be used in non-uniformly distributed data. Extension of these schemes to Grid Files is given in <ref> [6] </ref>. Moreover, in [6], it has been shown that, even with extensions, the scalability of these schemes for multidimensional range queries is also limited. Figure 9 is another example of this situation. <p> These results show that, since these schemes use tiling for Cartesian Product Files, they cannot be used in non-uniformly distributed data. Extension of these schemes to Grid Files is given in <ref> [6] </ref>. Moreover, in [6], it has been shown that, even with extensions, the scalability of these schemes for multidimensional range queries is also limited. Figure 9 is another example of this situation. However, in this data set the difference between the performance of each scheme can be seen in an easier way. <p> And it has been shown that, these schemes work better if the dataset is uniformly distributed. Extensions of these schemes for grid files, by using a tie-breaking or conflict resolution mechanism of some sort, are also possible <ref> [6] </ref>. This extension is possible to the current system. Another extension to the system can be done by analyzing how declustering techniques can be handled in order to deal with dynamic datasets in efficient ways. Tiling mechanism and the indexing of the current system is suitable for future dynamic versions.
Reference: [7] <author> S. Prabhakar, D. Agrawal, and A. El Abbadi. </author> <title> Efficient Disk Allocation for Fast Similarity Searching. </title>
Reference-contexts: Weakness and strength of all of these schemes are analyzed in terms of a cost metric. Some limitations and specifications of the techniques have been studied. This project shows that the metrics and criterions that were used in some related previous works [4] and <ref> [7] </ref> do not accurately reflect the real performance of the systems. Therefore, in my experiment design I use an index structure SS-tree, which is originally for high dimensional similarity search, to see the number of bucket retrieval in an actual similarity searching.
References-found: 7

