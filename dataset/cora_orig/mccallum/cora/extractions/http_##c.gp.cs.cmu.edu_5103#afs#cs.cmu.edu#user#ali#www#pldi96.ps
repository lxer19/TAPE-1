URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/ali/www/pldi96.ps
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs/project/cmcl/www/cmcc/papers.html
Root-URL: http://www.cs.cmu.edu
Title: Source-Level Debugging of Scalar Optimized Code  
Author: Ali-Reza Adl-Tabatabai and Thomas Gross ; 
Address: Pittsburgh, PA 15213 CH 8092 Zurich  
Affiliation: 1 School of Computer Science 2 Institut f ur Computer Systeme Carnegie Mellon University ETH Z urich  
Note: To appear in the Proceedings of PLDI'96, ACM SIGPLAN'96 Conf. on Programming Language Design and Implementation, May 1996, Philadelphia, PA  
Abstract: Although compiler optimizations play a crucial role in the performance of modern computer systems, debugger technology has lagged behind in its support of optimizations. Yet debugging the unoptimized translation is often impossible or futile, so handling of code optimizations in the debugger is necessary. But compiler optimizations make it difficult to provide source-level debugger functionality: Global optimizations can cause the runtime value of a variable to be inconsistent with the source-level value expected at a breakpoint; such variables are called endangered variables. A debugger must detect and warn the user of endangered variables otherwise the user may draw incorrect conclusions about the program. This paper presents a new algorithm for detecting variables that are endangered due to global scalar optimizations. Our approach provides more precise classifications of variables and is still simpler than past approaches. We have implemented and evaluated our techniques in the context of the cmcc optimizing C compiler. We describe the compiler extensions necessary to perform the required bookkeeping of compiler optimizations. We present measurements of the effect of optimizations on a debugger's ability to present the expected values of variables to the user. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Adl-Tabatabai. </author> <title> Source-Level Debugging of Globally Optimized Code. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1996. </year>
Reference-contexts: However, there are situations when a debugger cannot tell whether the actual value of V corresponds to the expected value of V , in which case the user is warned that V is suspect [2]. Suspect variables are caused by ambiguities due to either multiple paths reaching a breakpoint <ref> [1] </ref>, or pointer assignment that are executed out of order [2]. <p> The above approach presents a baseline that can be improved, for example, by using runtime values to reconstruct a variable's expected value (recovery <ref> [19, 1] </ref>). Runtime values can also be used to differentiate between suspect and current values (e.g., by determining which path was taken to reach a specific breakpoint; an example is provided in Section 2.2). <p> DOC can detect variables that are endangered due to instruction scheduling, but cannot deal with data-value problems caused by global optimizations. The shortcomings and constraints of these debuggers are discussed in detail in <ref> [3, 2, 1] </ref>. Our own earlier work [3, 2] concentrates on the effects of global register allocation and local code scheduling. We do not discuss these aspects any further in this paper, as underlined by Figure 1. <p> In Figure 2, E 2 = RedCopy (E 3 ). noncurrent, since the actual value of x is different from the speculative code hoisting transformations <ref> [1] </ref>. expected value of x due to E 3 prematurely assigning to x the source-level value assigned by E 2 . <p> Typically, a variable is endangered over a small region of the program, and only a few variables are endangered. Therefore, an efficient implementation of our analyses can be based on slotwise analysis [16]. (For more implementation details, see <ref> [1] </ref>.) Note that the data-flow analysis does not need to determine which instance of an expression hoist reaches, but rather that some expression hoist reaches; that is, the compiler need not determine that E 2 = RedCopy (E 3 ), but rather that E 3 is a hoisted instance of E, <p> The dead reach of a variable V is generated by a dead assignment to V and killed by any other kind of assignment to V <ref> [1] </ref>. 2.5 Recovery If dead code elimination eliminates an assignment to a variable V , it may be possible to recover the expected value of V from the values of compiler temporaries. Consider the example in Figure 4 (a). <p> IR marker nodes are lowered to special marker instructions, that convey essentially the same information as the IR marker nodes. Instructions are also annotated with information indicating which instructions correspond to source-level assignments. Additional information is passed along for detecting endangered variables caused by instruction scheduling, as described in <ref> [2, 1] </ref>. 4 Experimental results To better understand the effect of global optimizations on source-level debugging, we instrumented our algorithms to count the number of variables that are endangered at each breakpoint. <p> The cmcc optimizer hoisted mainly address computations. The few source-level assignments that were hoisted code location problems, since they affect setting and reporting of break-points. Code location problems are discussed in [26] and <ref> [1] </ref>. 5 We use a variant of the nonresidency algorithm described in [3]. This algorithm was modified to handle live range splitting [1]. <p> The few source-level assignments that were hoisted code location problems, since they affect setting and reporting of break-points. Code location problems are discussed in [26] and <ref> [1] </ref>. 5 We use a variant of the nonresidency algorithm described in [3]. This algorithm was modified to handle live range splitting [1].
Reference: [2] <author> A. Adl-Tabatabai and T. Gross. </author> <title> Detection and recovery of endangered variables caused by instruction scheduling. </title> <booktitle> In Proc. ACM SIGPLAN'93 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 13-25. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: However, if optimizations have moved or eliminated assignment expressions, the actual value of a variable V may not correspond to the expected value of V , in which case V is endangered <ref> [19, 13, 2] </ref> and additional information must be provided to the user. There are two mutually exclusive classes of endangered variables: noncurrent variables and suspect variables. <p> Sometimes the debugger can tell that the actual value of V definitely does not correspond to the expected value of V , in which case the actual value of V is displayed to the user with a warning that V is noncurrent <ref> [19, 13, 2] </ref>. However, there are situations when a debugger cannot tell whether the actual value of V corresponds to the expected value of V , in which case the user is warned that V is suspect [2]. <p> However, there are situations when a debugger cannot tell whether the actual value of V corresponds to the expected value of V , in which case the user is warned that V is suspect <ref> [2] </ref>. Suspect variables are caused by ambiguities due to either multiple paths reaching a breakpoint [1], or pointer assignment that are executed out of order [2]. <p> whether the actual value of V corresponds to the expected value of V , in which case the user is warned that V is suspect <ref> [2] </ref>. Suspect variables are caused by ambiguities due to either multiple paths reaching a breakpoint [1], or pointer assignment that are executed out of order [2]. <p> The techniques described in this paper allow the debugger to detect whether a variable is noncurrent, suspect or current, and convey to the user in source terms how optimizations have affected the value of a variable. 1.2 Debugger model Our model of debugging assumes that the debugger is non-invasive <ref> [3, 2] </ref>; the code generated by the compiler and debugged by the user is the default code generated with optimizations enabled. <p> DOC can detect variables that are endangered due to instruction scheduling, but cannot deal with data-value problems caused by global optimizations. The shortcomings and constraints of these debuggers are discussed in detail in <ref> [3, 2, 1] </ref>. Our own earlier work [3, 2] concentrates on the effects of global register allocation and local code scheduling. We do not discuss these aspects any further in this paper, as underlined by Figure 1. <p> DOC can detect variables that are endangered due to instruction scheduling, but cannot deal with data-value problems caused by global optimizations. The shortcomings and constraints of these debuggers are discussed in detail in [3, 2, 1]. Our own earlier work <ref> [3, 2] </ref> concentrates on the effects of global register allocation and local code scheduling. We do not discuss these aspects any further in this paper, as underlined by Figure 1. <p> These transformations do not cause data-value problems 4 . 4 Code duplication, basic block deletion and basic block insertion create Only after the final object code is produced are all opti-mizations exposed, and thus the analyses for detecting endangered variables are performed on an instruction-level representation of the program <ref> [3, 2] </ref>. Like most compilers, cmcc has a two-level intermediate representation consisting of a machine-independent IR used for global optimizations (e.g., partial redundancy elimination), and an instruction-level representation used for machine-dependent optimizations (e.g., register allocation and instruction scheduling). <p> IR marker nodes are lowered to special marker instructions, that convey essentially the same information as the IR marker nodes. Instructions are also annotated with information indicating which instructions correspond to source-level assignments. Additional information is passed along for detecting endangered variables caused by instruction scheduling, as described in <ref> [2, 1] </ref>. 4 Experimental results To better understand the effect of global optimizations on source-level debugging, we instrumented our algorithms to count the number of variables that are endangered at each breakpoint. <p> This makes the problem tractable and enables us to provide additional information to the user by conveying the actual value of a variable in source terms. Third, our approach is integrated with other implemented solutions to problems caused by local instruction scheduling and global register allocation, described in <ref> [2] </ref> and [3]. Thus, we are able to address a wide range of common global and local scalar optimizations included in most research and production optimizing compilers of the last decade. Acknowledgments We thank Ken Lueh for his many contributions to the cmcc compiler.
Reference: [3] <author> A. Adl-Tabatabai and T. Gross. </author> <title> Evicted variables and the interaction of global register allocation and symbolic debugging. </title> <booktitle> In Conf. Record of the 20th Annual ACM Symp. on Principles of Prog. Lang., </booktitle> <pages> pages 371-383. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: When global register allocation is performed, the register assigned to a variable V may be shared with other variables as well as temporaries. Thus at a breakpoint there may be no value of V available; V is nonresident <ref> [3] </ref> if the value in the register assigned to V may be the value of some variable other than V . <p> The debugger reports that the value of a nonresident variable V is unavailable since the value in the register assigned to V does not correspond to a meaningful source-level value of V <ref> [3] </ref>. If at a breakpoint a variable V is resident, then the value in the runtime location of V corresponds to some source-level value of V . <p> The techniques described in this paper allow the debugger to detect whether a variable is noncurrent, suspect or current, and convey to the user in source terms how optimizations have affected the value of a variable. 1.2 Debugger model Our model of debugging assumes that the debugger is non-invasive <ref> [3, 2] </ref>; the code generated by the compiler and debugged by the user is the default code generated with optimizations enabled. <p> DOC [14] and CXdb [8] are examples of two real debuggers for optimized code. These debuggers detect whether a variable is nonresident (using a conservative approach based on a variable's live range <ref> [3] </ref>). CXdb only detects whether a variable is resident; it is up to the user to determine the correspondence between a variable's actual value and source code values. DOC can detect variables that are endangered due to instruction scheduling, but cannot deal with data-value problems caused by global optimizations. <p> DOC can detect variables that are endangered due to instruction scheduling, but cannot deal with data-value problems caused by global optimizations. The shortcomings and constraints of these debuggers are discussed in detail in <ref> [3, 2, 1] </ref>. Our own earlier work [3, 2] concentrates on the effects of global register allocation and local code scheduling. We do not discuss these aspects any further in this paper, as underlined by Figure 1. <p> DOC can detect variables that are endangered due to instruction scheduling, but cannot deal with data-value problems caused by global optimizations. The shortcomings and constraints of these debuggers are discussed in detail in [3, 2, 1]. Our own earlier work <ref> [3, 2] </ref> concentrates on the effects of global register allocation and local code scheduling. We do not discuss these aspects any further in this paper, as underlined by Figure 1. <p> E may be a constant, a fetch from a temporary, or some more general computation such as addition. In the case that E is a fetch from a temporary T , we generate the residence <ref> [3] </ref> of V in the storage location assigned to T . If E is a constant, we generate a special constant residence for V , indicating that the value of V is a constant. <p> These transformations do not cause data-value problems 4 . 4 Code duplication, basic block deletion and basic block insertion create Only after the final object code is produced are all opti-mizations exposed, and thus the analyses for detecting endangered variables are performed on an instruction-level representation of the program <ref> [3, 2] </ref>. Like most compilers, cmcc has a two-level intermediate representation consisting of a machine-independent IR used for global optimizations (e.g., partial redundancy elimination), and an instruction-level representation used for machine-dependent optimizations (e.g., register allocation and instruction scheduling). <p> The cmcc optimizer hoisted mainly address computations. The few source-level assignments that were hoisted code location problems, since they affect setting and reporting of break-points. Code location problems are discussed in [26] and [1]. 5 We use a variant of the nonresidency algorithm described in <ref> [3] </ref>. This algorithm was modified to handle live range splitting [1]. <p> Third, our approach is integrated with other implemented solutions to problems caused by local instruction scheduling and global register allocation, described in [2] and <ref> [3] </ref>. Thus, we are able to address a wide range of common global and local scalar optimizations included in most research and production optimizing compilers of the last decade. Acknowledgments We thank Ken Lueh for his many contributions to the cmcc compiler.
Reference: [4] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Therefore, data-value problems can be handled by restricting attention to transformations that affect assignments to source-level variables. Many scalar optimizations, such as strength reduction, constant folding and constant propagation <ref> [4] </ref> do not directly affect assignments to source variables 1 . Other optimizations, like loop induction variable strength reduction and elimination, allow the debugger to infer source values from compiler temporaries that replace eliminated variables. <p> Path problems are easily solved by an appropriate data-flow framework. The data-flow analysis used to detect endangered variables due to code hoisting is similar to the reaching definitions analysis <ref> [4] </ref>.
Reference: [5] <author> D. Bernstein and M. Rodeh. </author> <title> Global instruction scheduling for superscalar machines. </title> <booktitle> In Proc. ACM SIGPLAN '91 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 241-255. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: Examples of code hoisting optimizations include partial redundancy elimination [23, 12, 15, 21] and global instruction scheduling algorithms that perform non-speculative hoisting of instructions <ref> [5] </ref> 2 .
Reference: [6] <author> P. Briggs and K. Cooper. </author> <title> Effective partial redundancy elimination. </title> <booktitle> In Proc. ACM SIGPLAN'94 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 159-170. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Examples of code sinking optimiza 2 The algorithms described in this paper have been extended to deal with tions include partial dead code elimination [22], unspecula--tion [17], global instruction scheduling algorithms that sink code past conditional branches [10], superblock dead code elimination [11] and forward propagation <ref> [6] </ref>. 2.1 Core optimizations Code motion and elimination are related, since some code motion algorithms operate by computing the set of program points where insertions of expressions render other expressions either dead or available [22, 23]. <p> S 1 : x=y+z tmp=y+z S 3 : ..x.. S 3 : ..y+z.. S 3 : ..tmp.. After copy propagation and dead code elimination (c) After common subexpression elimination. In cmcc, assignment propagation is performed to improve partial redundancy elimination <ref> [12, 6] </ref> and the situation described above occurs quite often. The final effect of this series of transformations is that the source-level variable x is replaced with tmp.
Reference: [7] <author> P. Briggs, K. D. Cooper, K. Kennedy, and L. Torczon. </author> <title> Coloring heuristics for register allocation. </title> <booktitle> In Proc. ACM SIGPLAN'89 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 275-284. </pages> <publisher> ACM, </publisher> <month> July </month> <year> 1989. </year>
Reference-contexts: Our implementations of partial redundancy elimination, strength reduction and partial dead code elimination are based on the algorithms described in [21], [20] and [22]. The global register allocator is a Chaitin-style register allocator [9] with the improvements described in <ref> [7] </ref>. So far, we have retargeted cmcc to the MIPS, SPARC, DLX, and iWarp architectures. We used the MIPS code generator to gather the results that we report in this paper. In this paper, we base our empirical evaluation on the set of eight C programs from SPEC92.
Reference: [8] <author> G. Brooks, G. Hansen, and S. Simmons. </author> <title> A new approach to debugging optimized code. </title> <booktitle> In Proc. ACM SIGPLAN'92 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 1-11. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: DOC [14] and CXdb <ref> [8] </ref> are examples of two real debuggers for optimized code. These debuggers detect whether a variable is nonresident (using a conservative approach based on a variable's live range [3]).
Reference: [9] <author> G. J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <booktitle> In Proc. ACM SIGPLAN 1982 Symp. on Compiler Construction, </booktitle> <pages> pages 98-105, </pages> <month> June </month> <year> 1982. </year> <journal> In SIGPLAN Notices, v. </journal> <volume> 17, </volume> <editor> n. </editor> <volume> 6. </volume>
Reference-contexts: These optimizations are based mostly on the standard bit-vector algorithms described in [12]. Our implementations of partial redundancy elimination, strength reduction and partial dead code elimination are based on the algorithms described in [21], [20] and [22]. The global register allocator is a Chaitin-style register allocator <ref> [9] </ref> with the improvements described in [7]. So far, we have retargeted cmcc to the MIPS, SPARC, DLX, and iWarp architectures. We used the MIPS code generator to gather the results that we report in this paper.
Reference: [10] <author> P. P. Chang, S. A. Mahlke, W. Y. Chen, N. J. Warter, and W. W. Hwu. </author> <title> Impact: An architectural framework for multiple-instruction-issue processors. </title> <booktitle> In Proc. 18th Intl. Symp. on Computer Architecture, </booktitle> <pages> pages 266-275. </pages> <address> ACM/IEEE, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Examples of code sinking optimiza 2 The algorithms described in this paper have been extended to deal with tions include partial dead code elimination [22], unspecula--tion [17], global instruction scheduling algorithms that sink code past conditional branches <ref> [10] </ref>, superblock dead code elimination [11] and forward propagation [6]. 2.1 Core optimizations Code motion and elimination are related, since some code motion algorithms operate by computing the set of program points where insertions of expressions render other expressions either dead or available [22, 23].
Reference: [11] <author> P. P. Chang, S. A. Mahlke, and W. W. Hwu. </author> <title> Using profile information to assist classic code optimizations. </title> <journal> Software Practice and Experience, </journal> <volume> 21(12) </volume> <pages> 1301-1321, </pages> <month> Dec </month> <year> 1991. </year>
Reference-contexts: Examples of code sinking optimiza 2 The algorithms described in this paper have been extended to deal with tions include partial dead code elimination [22], unspecula--tion [17], global instruction scheduling algorithms that sink code past conditional branches [10], superblock dead code elimination <ref> [11] </ref> and forward propagation [6]. 2.1 Core optimizations Code motion and elimination are related, since some code motion algorithms operate by computing the set of program points where insertions of expressions render other expressions either dead or available [22, 23].
Reference: [12] <author> F. Chow. </author> <title> A Portable, Machine-independent Global Optimizer Design and Measurements. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1984. </year>
Reference-contexts: Table 1 lists the optimizations performed by cmcc. These optimizations are based mostly on the standard bit-vector algorithms described in <ref> [12] </ref>. Our implementations of partial redundancy elimination, strength reduction and partial dead code elimination are based on the algorithms described in [21], [20] and [22]. The global register allocator is a Chaitin-style register allocator [9] with the improvements described in [7]. <p> In fact, it is these invariants that have allowed us to produce a solution to the problem that is significantly simpler than the approaches described in [25] and [13]. Examples of code hoisting optimizations include partial redundancy elimination <ref> [23, 12, 15, 21] </ref> and global instruction scheduling algorithms that perform non-speculative hoisting of instructions [5] 2 . <p> S 1 : x=y+z tmp=y+z S 3 : ..x.. S 3 : ..y+z.. S 3 : ..tmp.. After copy propagation and dead code elimination (c) After common subexpression elimination. In cmcc, assignment propagation is performed to improve partial redundancy elimination <ref> [12, 6] </ref> and the situation described above occurs quite often. The final effect of this series of transformations is that the source-level variable x is replaced with tmp. <p> In all cases, the dead reach of V is killed by E. A similar approach is used to recover the value of a source-level induction variable that is replaced by a strength-reduced expression. Linear function test replacement <ref> [12] </ref> replaces a loop test involving a source-level variable with a compiler synthesized temporary.
Reference: [13] <author> M. Copperman. </author> <title> Debugging optimized code without being misled. </title> <journal> ACM Trans. on Prog. Lang. Syst., </journal> <volume> 16(3) </volume> <pages> 387-427, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: However, if optimizations have moved or eliminated assignment expressions, the actual value of a variable V may not correspond to the expected value of V , in which case V is endangered <ref> [19, 13, 2] </ref> and additional information must be provided to the user. There are two mutually exclusive classes of endangered variables: noncurrent variables and suspect variables. <p> Sometimes the debugger can tell that the actual value of V definitely does not correspond to the expected value of V , in which case the actual value of V is displayed to the user with a warning that V is noncurrent <ref> [19, 13, 2] </ref>. However, there are situations when a debugger cannot tell whether the actual value of V corresponds to the expected value of V , in which case the user is warned that V is suspect [2]. <p> Register optimizations are included in our compiler (otherwise, we would not claim to have an optimizing compiler) and therefore included in our evaluation. Other researchers that have investigated the problem of detecting endangered variables caused by global optimizations are Copperman <ref> [13] </ref> and Wismueller [24]. Both of these works provide formal frameworks but do not specify how their solutions can be extended to the problems faced by a real compiler. Copperman's approach [13] is based on data-flow analysis of intermediate representations of the program. <p> Other researchers that have investigated the problem of detecting endangered variables caused by global optimizations are Copperman <ref> [13] </ref> and Wismueller [24]. Both of these works provide formal frameworks but do not specify how their solutions can be extended to the problems faced by a real compiler. Copperman's approach [13] is based on data-flow analysis of intermediate representations of the program. This representation captures the effects of transformations (global optimizations), but does not cover all aspects of the translation (e.g., register allocation) and does not deal with faults and user interrupts. <p> Without an implementation, it is difficult to evaluate the practicality of Copperman's approach. Wis-mueller [24, 25] concentrates only on detecting whether the expected value of a variable can be displayed to the user; his algorithms do not distinguish between nonresident, suspect, and noncurrent variables. Both <ref> [13] </ref> and [24] assume that the compiler can mangle the source code arbitrarily, resulting in an arbitrarily difficult problem and in a solution that is difficult to both understand and implement. <p> Or, if an expression is eliminated due to redundancy, the value must be available somewhere, and the debugger can provide this value to the user. <ref> [13] </ref> and [24] fail to take these constraints into account. Another major difference between the earlier work by Cop-perman and Wismueller is that they attempt to capture a summary effect of all optimizations. Then they attempt to relate the optimized code back to the source code. <p> By taking advantage of these code motion invariants, our algorithms are greatly simplified. In fact, it is these invariants that have allowed us to produce a solution to the problem that is significantly simpler than the approaches described in [25] and <ref> [13] </ref>. Examples of code hoisting optimizations include partial redundancy elimination [23, 12, 15, 21] and global instruction scheduling algorithms that perform non-speculative hoisting of instructions [5] 2 . <p> Moreover, the analyses are very similar to other analyses that are done by the compiler and can thus take advantage of an infrastructure that is already present. This is in contrast to other approaches that require specialized data-flow analyses and program representations <ref> [13, 24] </ref>. To gather the information required for our data-flow analysis, the program intermediate representation is annotated during optimizations to mark hoisted and sunk assignments, and additional markers are inserted to indicate points from which source-level assignments are eliminated. <p> Hence, a combination of residence detection and our simple data-flow algorithm for detecting endangered variables caused by dead code elimination is good enough for most practical situations. Moreover, since assignments are almost never hoisted, the code location issue of syntactic versus semantic breakpoints <ref> [26, 13, 24] </ref> is not important; the simple syntactic breakpoint model is good enough for a useful debugger. There are three noteworthy aspects of our approach that allow us to proceed in solving a problem that researchers have struggled with in the past.
Reference: [14] <author> D. S. Coutant, S. Meloy, and M. Ruscetta. </author> <title> Doc: A practical approach to source-level debugging of globally optimized code. </title> <booktitle> In Proc. ACM SIGPLAN'88 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 125-134. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1988. </year>
Reference-contexts: DOC <ref> [14] </ref> and CXdb [8] are examples of two real debuggers for optimized code. These debuggers detect whether a variable is nonresident (using a conservative approach based on a variable's live range [3]).
Reference: [15] <author> D. M. Dhamdhere. </author> <title> Practical adaptation of the global optimization algorithm of morel and renvoise. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 291-294, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: In fact, it is these invariants that have allowed us to produce a solution to the problem that is significantly simpler than the approaches described in [25] and [13]. Examples of code hoisting optimizations include partial redundancy elimination <ref> [23, 12, 15, 21] </ref> and global instruction scheduling algorithms that perform non-speculative hoisting of instructions [5] 2 .
Reference: [16] <author> D.M. Dhamdhere, B.K. Rosen, and F.K. Zadeck. </author> <title> How to analyze large programs efficiently and informatively. </title> <booktitle> In Proc. ACM SIGPLAN'92 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 212-223. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1992. </year>
Reference-contexts: Typically, a variable is endangered over a small region of the program, and only a few variables are endangered. Therefore, an efficient implementation of our analyses can be based on slotwise analysis <ref> [16] </ref>. (For more implementation details, see [1].) Note that the data-flow analysis does not need to determine which instance of an expression hoist reaches, but rather that some expression hoist reaches; that is, the compiler need not determine that E 2 = RedCopy (E 3 ), but rather that E 3
Reference: [17] <author> D. Ebcioglu, R. Groves, K. Kim, G. Silberman, and I. Ziv. </author> <title> Vliw compilation techniques in a superscalar environment. </title> <booktitle> In Proc. ACM SIGPLAN'94 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 36-48. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Examples of code sinking optimiza 2 The algorithms described in this paper have been extended to deal with tions include partial dead code elimination [22], unspecula--tion <ref> [17] </ref>, global instruction scheduling algorithms that sink code past conditional branches [10], superblock dead code elimination [11] and forward propagation [6]. 2.1 Core optimizations Code motion and elimination are related, since some code motion algorithms operate by computing the set of program points where insertions of expressions render other expressions either
Reference: [18] <author> C. Fraser and D. Hanson. </author> <title> A Retargetable C Compiler: Design and Implementation. </title> <address> Benjamin/Cummings, </address> <year> 1995. </year>
Reference-contexts: This issue is discussed in more detail in Section 3. 1.4 Experimental framework The algorithms described in this paper are implemented in the cmcc compiler, CMU's optimizing C compiler. cmcc uses the lcc ANSI C front end <ref> [18] </ref>. Table 1 lists the optimizations performed by cmcc. These optimizations are based mostly on the standard bit-vector algorithms described in [12]. Our implementations of partial redundancy elimination, strength reduction and partial dead code elimination are based on the algorithms described in [21], [20] and [22].
Reference: [19] <author> J. L. Hennessy. </author> <title> Symbolic debugging of optimized code. </title> <journal> ACM Trans. on Prog. Lang. Syst., </journal> <volume> 4(3) </volume> <pages> 323-344, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: However, if optimizations have moved or eliminated assignment expressions, the actual value of a variable V may not correspond to the expected value of V , in which case V is endangered <ref> [19, 13, 2] </ref> and additional information must be provided to the user. There are two mutually exclusive classes of endangered variables: noncurrent variables and suspect variables. <p> Sometimes the debugger can tell that the actual value of V definitely does not correspond to the expected value of V , in which case the actual value of V is displayed to the user with a warning that V is noncurrent <ref> [19, 13, 2] </ref>. However, there are situations when a debugger cannot tell whether the actual value of V corresponds to the expected value of V , in which case the user is warned that V is suspect [2]. <p> The above approach presents a baseline that can be improved, for example, by using runtime values to reconstruct a variable's expected value (recovery <ref> [19, 1] </ref>). Runtime values can also be used to differentiate between suspect and current values (e.g., by determining which path was taken to reach a specific breakpoint; an example is provided in Section 2.2). <p> However, all of these refinements are improvements to this overall model, which therefore plays a central role in the organization of a debugger. 1.3 Prior work There exists a small body of literature on debugging optimized code, starting with Hennessy's paper <ref> [19] </ref>, which defined some of the basic terms (e.g., endangered, noncurrent). DOC [14] and CXdb [8] are examples of two real debuggers for optimized code. These debuggers detect whether a variable is nonresident (using a conservative approach based on a variable's live range [3]).
Reference: [20] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Lazy strength reduction. </title> <journal> Journal of Prog. Languages, </journal> <volume> 1(1) </volume> <pages> 71-91, </pages> <year> 1993. </year>
Reference-contexts: Table 1 lists the optimizations performed by cmcc. These optimizations are based mostly on the standard bit-vector algorithms described in [12]. Our implementations of partial redundancy elimination, strength reduction and partial dead code elimination are based on the algorithms described in [21], <ref> [20] </ref> and [22]. The global register allocator is a Chaitin-style register allocator [9] with the improvements described in [7]. So far, we have retargeted cmcc to the MIPS, SPARC, DLX, and iWarp architectures. We used the MIPS code generator to gather the results that we report in this paper.
Reference: [21] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Optimal code motion: </title> <journal> Theory and practice. ACM Trans. on Prog. Lang. Syst., </journal> <volume> 16(4) </volume> <pages> 1117-1155, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Table 1 lists the optimizations performed by cmcc. These optimizations are based mostly on the standard bit-vector algorithms described in [12]. Our implementations of partial redundancy elimination, strength reduction and partial dead code elimination are based on the algorithms described in <ref> [21] </ref>, [20] and [22]. The global register allocator is a Chaitin-style register allocator [9] with the improvements described in [7]. So far, we have retargeted cmcc to the MIPS, SPARC, DLX, and iWarp architectures. We used the MIPS code generator to gather the results that we report in this paper. <p> In fact, it is these invariants that have allowed us to produce a solution to the problem that is significantly simpler than the approaches described in [25] and [13]. Examples of code hoisting optimizations include partial redundancy elimination <ref> [23, 12, 15, 21] </ref> and global instruction scheduling algorithms that perform non-speculative hoisting of instructions [5] 2 .
Reference: [22] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Partial dead code elimination. </title> <booktitle> In Proc. ACM SIGPLAN'94 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 147-158. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Table 1 lists the optimizations performed by cmcc. These optimizations are based mostly on the standard bit-vector algorithms described in [12]. Our implementations of partial redundancy elimination, strength reduction and partial dead code elimination are based on the algorithms described in [21], [20] and <ref> [22] </ref>. The global register allocator is a Chaitin-style register allocator [9] with the improvements described in [7]. So far, we have retargeted cmcc to the MIPS, SPARC, DLX, and iWarp architectures. We used the MIPS code generator to gather the results that we report in this paper. <p> Examples of code sinking optimiza 2 The algorithms described in this paper have been extended to deal with tions include partial dead code elimination <ref> [22] </ref>, unspecula--tion [17], global instruction scheduling algorithms that sink code past conditional branches [10], superblock dead code elimination [11] and forward propagation [6]. 2.1 Core optimizations Code motion and elimination are related, since some code motion algorithms operate by computing the set of program points where insertions of expressions render other <p> algorithms that sink code past conditional branches [10], superblock dead code elimination [11] and forward propagation [6]. 2.1 Core optimizations Code motion and elimination are related, since some code motion algorithms operate by computing the set of program points where insertions of expressions render other expressions either dead or available <ref> [22, 23] </ref>. If the debugger can detect endangered variables caused by code hoisting and dead code elimination, then we have the foundation to debug optimized code, since these two transformations capture the effects of the elimination and movement transformations discussed above (including code sinking).
Reference: [23] <author> E. Morel and C. </author> <title> Renvoise. Global optimization by suppression of partial redundancies. </title> <journal> Communications of the ACM, </journal> <volume> 22(2) </volume> <pages> 96-103, </pages> <month> Feb </month> <year> 1979. </year>
Reference-contexts: In fact, it is these invariants that have allowed us to produce a solution to the problem that is significantly simpler than the approaches described in [25] and [13]. Examples of code hoisting optimizations include partial redundancy elimination <ref> [23, 12, 15, 21] </ref> and global instruction scheduling algorithms that perform non-speculative hoisting of instructions [5] 2 . <p> algorithms that sink code past conditional branches [10], superblock dead code elimination [11] and forward propagation [6]. 2.1 Core optimizations Code motion and elimination are related, since some code motion algorithms operate by computing the set of program points where insertions of expressions render other expressions either dead or available <ref> [22, 23] </ref>. If the debugger can detect endangered variables caused by code hoisting and dead code elimination, then we have the foundation to debug optimized code, since these two transformations capture the effects of the elimination and movement transformations discussed above (including code sinking).
Reference: [24] <author> R. Wismueller. </author> <title> Debugging of globally optimized programs using data flow analysis. </title> <booktitle> In Proc. ACM SIGPLAN'94 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 278-289. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Compiler extensions are only necessary to generate the information required to analyze the effect of optimizing transformations on the data-value problems. Moreover, our algorithms work on a single representation of a program; this is in contrast to other approaches (e.g., <ref> [24] </ref>) that keep around a copy of the original source program representation. Our paper concludes with an empirical evaluation; we report on measurements for the eight C programs of the SPEC92 suite. 1.1 The data-value problem We summarize here the terminology; for examples and motivation we defer to the references. <p> Register optimizations are included in our compiler (otherwise, we would not claim to have an optimizing compiler) and therefore included in our evaluation. Other researchers that have investigated the problem of detecting endangered variables caused by global optimizations are Copperman [13] and Wismueller <ref> [24] </ref>. Both of these works provide formal frameworks but do not specify how their solutions can be extended to the problems faced by a real compiler. Copperman's approach [13] is based on data-flow analysis of intermediate representations of the program. <p> This representation captures the effects of transformations (global optimizations), but does not cover all aspects of the translation (e.g., register allocation) and does not deal with faults and user interrupts. Without an implementation, it is difficult to evaluate the practicality of Copperman's approach. Wis-mueller <ref> [24, 25] </ref> concentrates only on detecting whether the expected value of a variable can be displayed to the user; his algorithms do not distinguish between nonresident, suspect, and noncurrent variables. <p> Without an implementation, it is difficult to evaluate the practicality of Copperman's approach. Wis-mueller [24, 25] concentrates only on detecting whether the expected value of a variable can be displayed to the user; his algorithms do not distinguish between nonresident, suspect, and noncurrent variables. Both [13] and <ref> [24] </ref> assume that the compiler can mangle the source code arbitrarily, resulting in an arbitrarily difficult problem and in a solution that is difficult to both understand and implement. <p> Or, if an expression is eliminated due to redundancy, the value must be available somewhere, and the debugger can provide this value to the user. [13] and <ref> [24] </ref> fail to take these constraints into account. Another major difference between the earlier work by Cop-perman and Wismueller is that they attempt to capture a summary effect of all optimizations. Then they attempt to relate the optimized code back to the source code. <p> Bookkeeping also inserts special IR marker nodes to mark points of interest to the debugger. These annotations and markers are ignored by optimizations and optimizations are not constrained in any way. This is in contrast to the approach described in <ref> [24] </ref> where a representation of the original source program is kept as a copy, and links are maintained between the intermediate representation used for optimizations and the original representation (e.g., an abstract syntax tree). <p> Moreover, the analyses are very similar to other analyses that are done by the compiler and can thus take advantage of an infrastructure that is already present. This is in contrast to other approaches that require specialized data-flow analyses and program representations <ref> [13, 24] </ref>. To gather the information required for our data-flow analysis, the program intermediate representation is annotated during optimizations to mark hoisted and sunk assignments, and additional markers are inserted to indicate points from which source-level assignments are eliminated. <p> Hence, a combination of residence detection and our simple data-flow algorithm for detecting endangered variables caused by dead code elimination is good enough for most practical situations. Moreover, since assignments are almost never hoisted, the code location issue of syntactic versus semantic breakpoints <ref> [26, 13, 24] </ref> is not important; the simple syntactic breakpoint model is good enough for a useful debugger. There are three noteworthy aspects of our approach that allow us to proceed in solving a problem that researchers have struggled with in the past.
Reference: [25] <author> R. Wismueller. </author> <title> Quellsprachorientiertes Debugging von op-timierten Programmen. </title> <type> PhD thesis, </type> <institution> Technische Universitaet Muenchen, Munich, Germany, </institution> <month> Dec. </month> <year> 1994. </year> <note> (in German). Published (1995) by Shaker Verlag, Aachen (Germany), ISBN 3-8265-0841-6. </note>
Reference-contexts: This representation captures the effects of transformations (global optimizations), but does not cover all aspects of the translation (e.g., register allocation) and does not deal with faults and user interrupts. Without an implementation, it is difficult to evaluate the practicality of Copperman's approach. Wis-mueller <ref> [24, 25] </ref> concentrates only on detecting whether the expected value of a variable can be displayed to the user; his algorithms do not distinguish between nonresident, suspect, and noncurrent variables. <p> By taking advantage of these code motion invariants, our algorithms are greatly simplified. In fact, it is these invariants that have allowed us to produce a solution to the problem that is significantly simpler than the approaches described in <ref> [25] </ref> and [13]. Examples of code hoisting optimizations include partial redundancy elimination [23, 12, 15, 21] and global instruction scheduling algorithms that perform non-speculative hoisting of instructions [5] 2 .
Reference: [26] <author> P. Zellweger. </author> <title> Interactive Source-Level Debugging of Optimized Programs. </title> <type> PhD thesis, </type> <institution> University of California, Berke-ley, </institution> <month> May </month> <year> 1984. </year> <note> Published as Xerox PARC Technical Report CSL-84-5. </note>
Reference-contexts: A source-level debugger must solve two types of problems: First, the debugger must map a source statement to an instruction in the object code to set a breakpoint and map an instruction to the source code to report a fault or user interrupt (code location problems <ref> [26] </ref>). Second, the debugger must retrieve and display the values of source variables in a manner consistent with what the user expects with respect to the source statement where execution has halted (data-value problems [26]). <p> an instruction to the source code to report a fault or user interrupt (code location problems <ref> [26] </ref>). Second, the debugger must retrieve and display the values of source variables in a manner consistent with what the user expects with respect to the source statement where execution has halted (data-value problems [26]). When a program has been compiled with optimizations, mappings between breakpoints in the source and object code become complicated, and values of variables can be inaccessible in the runtime state or inconsistent with what the user expects. <p> The cmcc optimizer hoisted mainly address computations. The few source-level assignments that were hoisted code location problems, since they affect setting and reporting of break-points. Code location problems are discussed in <ref> [26] </ref> and [1]. 5 We use a variant of the nonresidency algorithm described in [3]. This algorithm was modified to handle live range splitting [1]. <p> Hence, a combination of residence detection and our simple data-flow algorithm for detecting endangered variables caused by dead code elimination is good enough for most practical situations. Moreover, since assignments are almost never hoisted, the code location issue of syntactic versus semantic breakpoints <ref> [26, 13, 24] </ref> is not important; the simple syntactic breakpoint model is good enough for a useful debugger. There are three noteworthy aspects of our approach that allow us to proceed in solving a problem that researchers have struggled with in the past.
References-found: 26

