URL: http://www.eecs.umich.edu/PPP/ICS95.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Email: alexe,davidson@eecs.umich.edu abraham@hpl.hp.com  
Title: Optimum Modulo Schedules for Minimum Register Requirements  
Author: Alexandre E. Eichenberger and Edward S. Davidson Santosh G. Abraham 
Keyword: Register-sensitive modulo scheduling, software pipelining, loop scheduling, instruction level parallelism, VLIW, superscalar.  
Address: 1501 Page Mill Road Ann Arbor, MI 48109-2122 Palo Alto, CA 94304  
Affiliation: Advanced Computer Architecture Laboratory Hewlett Packard Laboratories EECS Department, University of Michigan  
Abstract: Modulo scheduling is an efficient technique for exploiting instruction level parallelism in a variety of loops, resulting in high performance code but increased register requirements. We present a combined approach that schedules the loop operations for the highest steady state throughput and minimum register requirements. Our method determines optimal register requirements for machines with finite resources and for general dependence graphs. We compare the performance of this and other modulo schedulers for a benchmark of 629 loops from the Perfect Club, SPEC-89, and the Livermore Fortran Kernels. Measurements demonstrate the potential of register-sensitive modulo schedulers, which will be useful in evaluating the performance of register-sensitive modulo scheduling heuristics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. R. Rau and J. A. Fisher. </author> <title> Instruction-level parallel processing: History, overview, and perspective. </title> <journal> In The Journal of Supercomputing, </journal> <volume> volume 7, </volume> <pages> pages 9-50, </pages> <address> Boston, July 1993. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: [2] <author> P. Y. Hsu. </author> <title> Highly Concurrent Scalar Processing. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference: [3] <author> B. R. Rau. </author> <title> Iterative Modulo Scheduling: An algorithm for software pipelining loops. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 63-74, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Loop iterations with multiple basic blocks are IF-converted; however, predicates are ignored when evaluating the register requirements of a schedule. Our scheduling method satisfies arbitrary resource and dependence constraints and minimizes MaxLive <ref> [3] </ref>, the minimum number of registers required to generate spill-free code. MaxLive corresponds to the maximum number of live values at any single cycle of the loop schedule. To improve the execution time of register-sensitive modulo schedulers, we propose a technique that removes redundant edges of the dependence graph. <p> The following algorithm finds a schedule with the highest steady state throughput over all modulo schedules, and the minimum register requirements among such schedules: 1. Compute the Minimum Initiation Interval (M II) <ref> [3] </ref> and set the tentative II to M II. 2. Build the integer linear programming system as indi cated in Figure 4 and search for a solution. 3. If the system built in Step 2 fails to find a feasible solution, increase II by one and return to Step 2. <p> The resulting schedule has the lowest achievable register requirements for the given machine, loop, and MRT. Iterative Modulo Scheduler <ref> [3] </ref>: This scheduler has been designed to deal efficiently with realistic machine models while producing schedules with near optimal steady state throughput. <p> Experimental findings show that this algorithm requires the scheduling of only 59% more operations than does acyclic list scheduling while resulting in schedules that are optimal in II for 96% of loops in their benchmark <ref> [3] </ref>. In its current form, it does not attempt to minimize the register requirements of its schedules; however, preliminary investigations show that the register requirements of its schedules may be reduced significantly by simple heuristics. <p> This choice was motivated by the availability of quality code for this machine. Also, the resource requirements of the Cydra 5 machine are complex [10], thus stressing the importance of good and robust scheduling algorithms. In particular, the machine configuration is the one used in <ref> [3] </ref>. <p> Our empirical findings show that the complex resource requirements of the Cydra 5 machine does not significantly impact the register requirements of a modulo schedule with minimal MaxLive in the benchmark considered. Also, our findings show that the Iterative Modulo Scheduler <ref> [3] </ref> which does not attempt to minimize registers nevertheless achieves the minimum MaxLive in 60% of the loops and uses an average of 14.03 additional registers over the remaining loops.
Reference: [4] <author> M. Lam. </author> <title> Software pipelining: An effective scheduling technique for VLIW machines. </title> <booktitle> Proceedings of the ACM SIG-PLAN'88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 318-328, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The scope of modulo scheduling has been widened to a large variety of loops. Loops with conditional statements are handled using hierarchical reduction <ref> [4] </ref> or IF-conversion [5]. Modulo scheduling has also been extended to a large variety of loops with early exits, such as while loops [6][7]. Furthermore, the code expansion due to modulo scheduling can be eliminated by using special hardware, such as rotating register files and predicated execution [8].
Reference: [5] <author> N. J. Warter, G. E. Haab, and J. W. Bockhaus. </author> <title> Enhanced Modulo Scheduling for loops with conditional branches. </title> <booktitle> Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1992. </year>
Reference-contexts: The scope of modulo scheduling has been widened to a large variety of loops. Loops with conditional statements are handled using hierarchical reduction [4] or IF-conversion <ref> [5] </ref>. Modulo scheduling has also been extended to a large variety of loops with early exits, such as while loops [6][7]. Furthermore, the code expansion due to modulo scheduling can be eliminated by using special hardware, such as rotating register files and predicated execution [8].
Reference: [6] <author> M. S. Schlansker, V. Kathail, and S. Anik. </author> <title> Height reduction of control recurrences for ILP processors. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 40-51, </pages> <month> November </month> <year> 1994. </year>
Reference: [7] <author> P. P. Tirumalai, M. Lee, and M. S. Schlansker. </author> <title> Paralleliza-tion of loops with exits on pipelined architectures. </title> <booktitle> Proceedings of Supercomputing '90, </booktitle> <pages> pages 200-212, </pages> <month> November </month> <year> 1990. </year>
Reference: [8] <author> B. R. Rau, M. Lee, P. P. Tirumalai, and M. S. Schlansker. </author> <title> Register allocation for software pipelined loops. </title> <booktitle> Proceedings of the ACM SIGPLAN'92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 283-299, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Modulo scheduling has also been extended to a large variety of loops with early exits, such as while loops [6][7]. Furthermore, the code expansion due to modulo scheduling can be eliminated by using special hardware, such as rotating register files and predicated execution <ref> [8] </ref>. Since modulo scheduling exploits high levels of parallelism, it results in higher register requirements because more values are needed to support more concurrent operations. This effect is inherent to parallelism and will be exacerbated by wider machines and higher latency pipelines [9]. <p> Our scheduling method handles general dependence graphs, including loop-carried dependence and common sub-expressions. This work complements the register allocation algorithm presented by Rau, Lee, Tirumalai, and Schlansker <ref> [8] </ref>, which achieves register allocations that are within one register of the MaxLive bound for the vast majority of modulo-scheduled loops on machines with rotating register files and predicated execution to support modulo scheduling.
Reference: [9] <author> W. Mangione-Smith, S. G. Abraham, and E. S. Davidson. </author> <title> Register requirements of pipelined processors. </title> <booktitle> Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 260-271, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Since modulo scheduling exploits high levels of parallelism, it results in higher register requirements because more values are needed to support more concurrent operations. This effect is inherent to parallelism and will be exacerbated by wider machines and higher latency pipelines <ref> [9] </ref>. As a result, developing scheduling techniques that exploit instruction level parallelism while containing the register requirements is crucial to the performance of future machines. Our research aims at understanding the fundamental relationship between instruction level parallelism and register requirements for a set of benchmarks under realistic assumptions. <p> Because of its increased search space, the new method of this paper results in lower register requirements in 11% percent of the loops in our benchmark. This work also generalizes the linear-time algorithm for determining minimum register requirements by Mangione-Smith et al <ref> [9] </ref>, which requires that each virtual register be used no more than once. Our scheduling method handles general dependence graphs, including loop-carried dependence and common sub-expressions.
Reference: [10] <author> G. R. Beck, D. W. L. Yen, and T. L. Anderson. </author> <title> The Cydra 5 mini-supercomputer: Architecture and implementation. </title> <journal> The Journal of Supercomputing, </journal> <volume> 7 </volume> <pages> 143-180, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: loops with arbitrary depen dence graphs on machines with arbitrary resource constraints. 31 We compare the performance of this and other modulo sched-ulers for a benchmark of 629 loops from the Perfect Club, SPEC-89, and the Livermore Fortran Kernels for the Cy-dra 5 machine, a machine with complex resource usage <ref> [10] </ref>. Though the general algorithm presented in this paper may be too expensive to be integrated in a compiler, the improvements obtained in register requirements motivate the development of better heuristics for combined scheduling and register allocation for modulo-scheduled loops. <p> The machine model used in these experiments corresponds to the Cydra 5 machine. This choice was motivated by the availability of quality code for this machine. Also, the resource requirements of the Cydra 5 machine are complex <ref> [10] </ref>, thus stressing the importance of good and robust scheduling algorithms. In particular, the machine configuration is the one used in [3].
Reference: [11] <author> R. Govindarajan, E. R. Altman, and G. R. Gao. </author> <title> Minimizing register requirements under resource-constrained rate-optimal software pipelining. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 85-94, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: This method is thus useful in assessing the performance of modulo-scheduling heuristics. This work builds upon the modulo scheduling algorithm proposed by Govindarajan, Altman, and Gao <ref> [11] </ref> in which the entire modulo scheduling space is searched to find a schedule with minimum buffer requirements. This algorithm produces schedules for machines with finite heterogeneous functional units. <p> Finally, Max-Live is the sum of fractional and integral MaxLives. The schedule presented in Figure 1b is a schedule that results in the minimum buffer requirements for this kernel and target machine, as presented by Govindarajan et al <ref> [11] </ref>. In their study, registers are approximated by conceptual FIFO buffers which are reserved for a time interval that is a multiple of II. It thus corresponds to searching for a schedule that minimizes integral MaxLive. <p> The definition of the schedule search space used in this section is similar to the one presented by Govindarajan et al <ref> [11] </ref>. All variables of the model presented in this section are summarized in Table 2. <p> Table 2: Variables for the modulo scheduling model. store the result of operation i, as proposed by Govindarajan et al <ref> [11] </ref>. Algorithm 1 is directly applicable to this integer programming model as well. <p> The resulting schedule has the lowest register requirements of any modulo schedule for the given machine, loop, and initiation interval. MinBuf Scheduler: This scheduler minimizes Integral Max-Live over all valid modulo schedules using an integer programming model similar to the one proposed by Govindara-jan <ref> [11] </ref>. The resulting schedule has the lowest buffer requirements of any modulo schedule for the given machine, loop, and initiation interval. Buffers, as opposed to regis ters, must be reserved for a time interval that is a multiple of II. <p> Also, our findings show that the Iterative Modulo Scheduler [3] which does not attempt to minimize registers nevertheless achieves the minimum MaxLive in 60% of the loops and uses an average of 14.03 additional registers over the remaining loops. The MinBuf Scheduler <ref> [11] </ref> finds a schedule with minimum MaxLive in 75% of the loops and uses an average of 1.52 additional registers over the remaining loops.
Reference: [12] <author> A. E. Eichenberger, E. S. Davidson, and S. G. Abraham. </author> <title> Minimum register requirements for a modulo schedule. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 75-84, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Because of its accurate modeling of the register requirements, our method results in lower register requirements in 25% percent of the loops in our benchmark. This work generalizes our previous work on optimizing an existing modulo schedule for a given loop to reduce its register requirements <ref> [12] </ref>. Although our previous work also modeled the register requirements of a loop accurately, a schedule with minimum register requirements was not sought over the entire search space of valid modulo schedules. <p> We selected these values to obtain concise examples; however, our method works independently of the numbers of functional units, resource constraints, and latencies. Example 1 This example <ref> [12] </ref> illustrates how to compute the register requirements of a modulo-scheduled loop. <p> Buffers, as opposed to regis ters, must be reserved for a time interval that is a multiple of II. We present here the register requirements associated with these schedules in our comparisons. 38 MinReg Stage Scheduler <ref> [12] </ref>: This scheduler minimizes MaxLive over all valid modulo schedules that share a given MRT. <p> The MinBuf Scheduler [11] finds a schedule with minimum MaxLive in 75% of the loops and uses an average of 1.52 additional registers over the remaining loops. The MinReg Stage Scheduler <ref> [12] </ref> finds a schedule with minimum MaxLive in 89% of the loops and uses an average of 1.45 additional registers over the remaining loops. This paper demonstrates that selecting a good schedule results in lower register requirements.
Reference: [13] <author> Q. Ning and G. R. Gao. </author> <title> A novel framework of register allocation for software pipelining. </title> <booktitle> Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 29-42, </pages> <year> 1993. </year>
Reference-contexts: For machines with out hardware support, their algorithm typically achieves register allocations that are within four registers of the MaxLive bound, after loop unrolling and consequent code expansion. Finally, in contrast to the work by Ning and Gao <ref> [13] </ref> and Ramanujam [14], we allow finite machine resource constraints. Moreover, we do not approximate the register pressure by minimizing the average number of live values over all cycles, but rather we explicitly minimize the maximum number of live values at any single cycle of the loop.
Reference: [14] <author> J. Ramanujam. </author> <title> Optimal software pipelining of nested loops. </title> <booktitle> Proceedings of the International Parallel Processing Symposium, </booktitle> <pages> pages 335-342, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: For machines with out hardware support, their algorithm typically achieves register allocations that are within four registers of the MaxLive bound, after loop unrolling and consequent code expansion. Finally, in contrast to the work by Ning and Gao [13] and Ramanujam <ref> [14] </ref>, we allow finite machine resource constraints. Moreover, we do not approximate the register pressure by minimizing the average number of live values over all cycles, but rather we explicitly minimize the maximum number of live values at any single cycle of the loop.
Reference: [15] <author> R. A. Huff. </author> <title> Lifetime-sensitive modulo scheduling. </title> <booktitle> Proceedings of the ACM SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 258-267, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: As a result, the register edge (load, add) cannot be removed from G 0 . To determine the conditions under which edges can be safely removed, we introduce the M inDist relation as proposed by Huff <ref> [15] </ref>. M inDist (x; y) represents the minimum number of cycles, possibly negative, that must occur be tween the time operation X is scheduled until the time operation Y is scheduled, if there is a path in the dependence graph from X to Y . <p> M inDist is guaranteed to converge to a solution because II is chosen such that all cycles in the dependence graph have nonpositive costs <ref> [15] </ref>. Theorem 1 (Edge Removal Test) Consider the opera tions A, B, and C in V with edges (a; b) and (a; c) in E sched and E reg of G. <p> The latency and dependence distance of the outgoing edges from start and of the incoming edges to stop are 0. Using the methodology presented by Huff <ref> [15] </ref>, the M inDist relation can be used to determine a lower bound and an upper bound on the schedule time of each operation. We know that an operation i cannot be scheduled earlier than M inDist (start; i) cycles after the start pseudo operation. <p> For the purpose of comparison, we also present the register requirements of an efficient modulo scheduling algorithm that presently does not attempt to minimize the register requirements. Unfortunately, we are unable to provide a comparison with Huff's scheduling algorithm <ref> [15] </ref> since his machine model differs slightly from ours and his latest scheduler, presented in [15], was not available to us. MinReg Scheduler: This scheduler minimizes MaxLive over all valid modulo schedules using the integer programming model developed in Section 3 and summarized in Fig ure 4. <p> Unfortunately, we are unable to provide a comparison with Huff's scheduling algorithm <ref> [15] </ref> since his machine model differs slightly from ours and his latest scheduler, presented in [15], was not available to us. MinReg Scheduler: This scheduler minimizes MaxLive over all valid modulo schedules using the integer programming model developed in Section 3 and summarized in Fig ure 4. <p> In this graph, the X-axis represents MaxLive and the Y-axis represents the fraction of loops scheduled. This graph presents three curves. The first curve, labeled "Schedule independent lower bound," corresponds to <ref> [15] </ref> and is representative of the register requirements of a machine without any resource conflicts. The second curve presents the register requirements of the schedules generated by the MinReg Scheduler.
Reference: [16] <author> M. Berry et al. </author> <title> The Perfect Club Benchmarks: Effective performance evaluation of supercomputers. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: In its current form, it does not attempt to minimize the register requirements of its schedules; however, preliminary investigations show that the register requirements of its schedules may be reduced significantly by simple heuristics. In this section, we use a benchmark of loops obtained from the Perfect Club <ref> [16] </ref>, SPEC-89 [17], and the Livermore Fortran Kernels [18]. Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler [19].
Reference: [17] <author> J. Uniejewski. </author> <title> SPEC Benchmark Suite: Designed for today's advanced system. </title> <journal> SPEC Newsletter, </journal> <month> Fall </month> <year> 1989. </year>
Reference-contexts: In this section, we use a benchmark of loops obtained from the Perfect Club [16], SPEC-89 <ref> [17] </ref>, and the Livermore Fortran Kernels [18]. Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler [19].
Reference: [18] <author> F. H. McMahon. </author> <title> The Livermore Fortran Kernels: A computer test of the numerical performance range. </title> <type> Technical Report UCRL-53745, </type> <institution> Lawrence Livermore National Laboratory, Livermore, California, </institution> <year> 1986. </year>
Reference-contexts: In this section, we use a benchmark of loops obtained from the Perfect Club [16], SPEC-89 [17], and the Livermore Fortran Kernels <ref> [18] </ref>. Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler [19].
Reference: [19] <author> J. C. Dehnert and R. A. Towle. </author> <title> Compiling for the Cydra 5. </title> <journal> The Journal of Supercomputing, </journal> <volume> 7 </volume> <pages> 181-227, </pages> <month> May </month> <year> 1993. </year> <month> 40 </month>
Reference-contexts: Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler <ref> [19] </ref>. The input to the four scheduling algorithms consists of the Fortran77 compiler intermediate representation after load-store elimination, recurrence back-substitution, and IF-conversion.
References-found: 19

