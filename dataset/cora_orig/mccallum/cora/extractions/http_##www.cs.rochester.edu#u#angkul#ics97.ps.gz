URL: http://www.cs.rochester.edu/u/angkul/ics97.ps.gz
Refering-URL: http://www.cs.rochester.edu/stats/oldmonths/1998.04/docs-name.html
Root-URL: 
Title: Distributed Shared Memory Systems with Improved Barrier Synchronization and Data Transfer  
Author: Nian-Feng Tzeng and Angkul Kongmunvattana 
Address: Lafayette, LA 70504  
Affiliation: Center for Advanced Computer Studies University of Southwestern Louisiana  
Abstract: This paper introduces an efficient barrier synchronization algorithm based on the binomial spanning tree (BST) and proposes a data transfer reduction technique for distributed shared memory systems under release consistency. The introduced BST-based barrier algorithm parallelizes and distributes the workload amongs participating processors, alleviating network contention and yielding less retransmission. As a result, performance improves, and the degree of improvement increases quickly as the number of participants grows. Our barrier algorithm and data transfer reduction technique are incorporated in TreadMarks for evaluation using various benchmarks on a network of workstations and the IBM SP machine. Experimental results are gathered and demonstrated. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Agerwala, J. L. Martin, J. H. Mirza, D. C. Sadler, D. M. Dias, and M. Snir. </author> <title> SP2 system architecture. </title> <journal> IBM Systems Journal, </journal> <volume> 34(2) </volume> <pages> 152-184, </pages> <year> 1995. </year>
Reference-contexts: As expected, the degree of reduction corresponds to the amount of data transfer reduction. 5 Performance Evaluation on IBM SP In order to evaluate the behavior of our proposed barrier approach in a larger system, we used the IBM SP machine <ref> [1] </ref> at Argonne National Laboratory as a hardware platform for study. The same set of four benchmarks is executed on this SP machine with TreadMarks employed. When the proposed barrier approach is incorporated, all the codes, except the barrier implementation, are kept unchanged, as before.
Reference: [2] <author> C. Amza, A. L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel. TreadMarks: </author> <title> Shared Memory Computing on Networks of Workstations. </title> <journal> Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Update information for every participant is generally distinct and is computed according to the update records gathered from all the arriving processors. As a result, the barrier under release consistency involves a "scatter" operation to forward different update information to different participants. 2.3 TreadMarks TreadMarks <ref> [2] </ref> is a software DSM implementation under the LRC model, and our investigation is based on the TreadMarks framework.
Reference: [3] <author> J. B. Carter, J. K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and Performance of Munin. </title> <booktitle> In Proc. of the 13th ACM Symp. on Operating Systems Principles (SOSP'91), </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Multiple updates on shared data are allowed locally by different processors, but all the updates have to be completed at any release following those updates. An eager software implementation of release consistency can be found in Munin <ref> [3] </ref>, where a processor delays propagating its updates of shared data until the execution of a release. Later on, a lazy release consistency (LRC) was considered [9], in an attempt to further postpone the propagation of updates until the acquire (to the shared data made by another processor).
Reference: [4] <author> S. Y. Cheung and V. S. Sunderam. </author> <title> Performance of Barrier Synchronization Methods in a Multiaccess Network. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 6(8) </volume> <pages> 890-895, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Barrier synchronization is a common and powerful primitive for synchronizing a large number of cooperating processors in a parallel system. It ensures all participating processors to reach a certain execution point before they may proceed beyond that point. Many papers on barrier synchronization have appeared in the literature <ref> [4, 6, 7, 10, 12] </ref>, but none of them considered the particular need of the DSM system. Specifically, for software DSM systems under the release consistency model, barrier synchronization not only makes sure the arrival of all participants but also enforces memory consistency when they leave the barrier. <p> Early studies on barrier synchronization have focused on the use of specific synchronization hardware [7, 10], on the software implementation of synchronization algorithms [6, 12], or on the evaluation of barrier synchro nization performance <ref> [4] </ref>. Those studies all deal with barrier synchronization in which action (3) is satisfied simply through a broadcast operation (or mechanism) to all participating processors. Under RC model, barrier synchronization provides coherent views of shared pages after the barrier.
Reference: [5] <author> K. Gharachorloo, D. E. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. L. Hennessy. </author> <title> Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors. </title> <booktitle> In Proc. of the 17th Annual Int'l Symp. on Computer Architecture (ISCA'90), </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Apparently, the software implementation is most attractive since it involves no added hardware, which tends to be machine-dependent and expensive. The data transfer due to coherent enforcement under a software implementation, however, has to be minimized. To this end, the release consistency (RC) model <ref> [5] </ref> is a preferred choice for a software DSM implementation due to its low coherence traffic. RC does not guarantee that shared memory is consistent all of the time, but rather making sure consistence only after synchronization operations. <p> A less restrictive model tends to yield higher efficiency, because it normally imposes a shorter memory access latency and incurs lower communication overhead caused by memory coherence enforcement. 2.1 Release consistency Release consistency (RC) <ref> [5] </ref> is one of the least restrictive memory consistency models, and it ensures a synchronized program to see a sequentially consistent execution through the use of two synchronization operations: acquire for a processor to get access to a shared variable, and release for a processor to relinquish an acquired variable, permitting
Reference: [6] <author> D. Hensgen, R. Finkel, and U. Manber. </author> <title> Two Algorithms for Barrier Synchronization. </title> <journal> Int'l Journal on Parallel Programming, </journal> <volume> 17(1) </volume> <pages> 1-17, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Barrier synchronization is a common and powerful primitive for synchronizing a large number of cooperating processors in a parallel system. It ensures all participating processors to reach a certain execution point before they may proceed beyond that point. Many papers on barrier synchronization have appeared in the literature <ref> [4, 6, 7, 10, 12] </ref>, but none of them considered the particular need of the DSM system. Specifically, for software DSM systems under the release consistency model, barrier synchronization not only makes sure the arrival of all participants but also enforces memory consistency when they leave the barrier. <p> Early studies on barrier synchronization have focused on the use of specific synchronization hardware [7, 10], on the software implementation of synchronization algorithms <ref> [6, 12] </ref>, or on the evaluation of barrier synchro nization performance [4]. Those studies all deal with barrier synchronization in which action (3) is satisfied simply through a broadcast operation (or mechanism) to all participating processors. Under RC model, barrier synchronization provides coherent views of shared pages after the barrier.
Reference: [7] <author> D. Johnson, D. Lilja, and J. Riedl. </author> <title> A Circulating Active Barrier Synchronization Mechanism. </title> <booktitle> In Proc. of the 1995 Int'l Conf. on Parallel Processing (ICPP'95), </booktitle> <volume> volume I, </volume> <pages> pages 202-209, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Barrier synchronization is a common and powerful primitive for synchronizing a large number of cooperating processors in a parallel system. It ensures all participating processors to reach a certain execution point before they may proceed beyond that point. Many papers on barrier synchronization have appeared in the literature <ref> [4, 6, 7, 10, 12] </ref>, but none of them considered the particular need of the DSM system. Specifically, for software DSM systems under the release consistency model, barrier synchronization not only makes sure the arrival of all participants but also enforces memory consistency when they leave the barrier. <p> Early studies on barrier synchronization have focused on the use of specific synchronization hardware <ref> [7, 10] </ref>, on the software implementation of synchronization algorithms [6, 12], or on the evaluation of barrier synchro nization performance [4]. Those studies all deal with barrier synchronization in which action (3) is satisfied simply through a broadcast operation (or mechanism) to all participating processors.
Reference: [8] <author> S. L. Johnsson and C.-T. Ho. </author> <title> Optimum Broadcasting and Personalized Communication in Hypercubes. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-38(9):1249-1268, </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: in Section 5. 3.1 Approach In contrast to designating a single processor for collecting update records, for calculating the update result for each participant and for scattering calculated update results to all participants in sequence, we propose an efficient barrier approach on the basis of a binomial spanning tree (BST) <ref> [8] </ref>. This BST-based barrier approach is found to be superior to other tree-based (such as the binary tree and other unbalanced trees) barrier schemes. A BST with four levels is illustrated in Figure 1, where the root is at level 0, its children are at level 1, and so on. <p> This can be observed in Figure 1, where the addresses of all nodes in ST 1 have their rightmost bits in common. A formal definition of the BST is provided in <ref> [8] </ref>. In fact, a BST possesses above properties for any arbitrary N . The BST of size 10 is depicted in Figure 2 with solid lines, and it is easy to validate the properties for this BST.
Reference: [9] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy Release Consistency for Software Distributed Shared Memory. </title> <booktitle> In Proc. of the 19th Annual Int'l Symp. on Computer Architecture (ISCA'92), </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: An eager software implementation of release consistency can be found in Munin [3], where a processor delays propagating its updates of shared data until the execution of a release. Later on, a lazy release consistency (LRC) was considered <ref> [9] </ref>, in an attempt to further postpone the propagation of updates until the acquire (to the shared data made by another processor). It has been demonstrated that LRC generally outperforms eager release consistency, with respect to the number of messages and the amount of data exchanged [9]. <p> consistency (LRC) was considered <ref> [9] </ref>, in an attempt to further postpone the propagation of updates until the acquire (to the shared data made by another processor). It has been demonstrated that LRC generally outperforms eager release consistency, with respect to the number of messages and the amount of data exchanged [9]. In this paper, we are interested in DSM systems under the release consistency model. 2.2 Barrier Synchronization The barrier is a synchronization primitive for parallel computing.
Reference: [10] <author> M. T. O'Keefe and H. G. Dietz. </author> <title> Hardware Barrier Synchronization: Static Barrier MIMD (SBM). </title> <booktitle> In Proc. of the 1990 Int'l Conf. on Parallel Processing (ICPP'90), </booktitle> <volume> volume I, </volume> <pages> pages 35-42, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Barrier synchronization is a common and powerful primitive for synchronizing a large number of cooperating processors in a parallel system. It ensures all participating processors to reach a certain execution point before they may proceed beyond that point. Many papers on barrier synchronization have appeared in the literature <ref> [4, 6, 7, 10, 12] </ref>, but none of them considered the particular need of the DSM system. Specifically, for software DSM systems under the release consistency model, barrier synchronization not only makes sure the arrival of all participants but also enforces memory consistency when they leave the barrier. <p> Early studies on barrier synchronization have focused on the use of specific synchronization hardware <ref> [7, 10] </ref>, on the software implementation of synchronization algorithms [6, 12], or on the evaluation of barrier synchro nization performance [4]. Those studies all deal with barrier synchronization in which action (3) is satisfied simply through a broadcast operation (or mechanism) to all participating processors.
Reference: [11] <author> J. Protic, M. Tomasevic, and V. Milutinovic. </author> <title> Distributed Shared Memory: Concepts and Systems. </title> <journal> IEEE Parallel & Distributed Technology, </journal> <volume> 4 </volume> <pages> 63-79, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: DSM combines the ease of shared memory programming paradigm with the scalability and constructability of distributed memory systems, such as the network of workstations (NOW) and distributed memory multiprocessors. Due to its potential advantages, DSM has been an active research area, with many prototype systems implemented and demonstrated <ref> [11, 13] </ref>. The address space of a DSM system is distributed across memories at interconnected processors. To reduce traffic over the network, a replication of certain data stored at a remote processor is usually created in the local cache of a processor.
Reference: [12] <author> M. Scott and J. Mellor-Crummey. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Barrier synchronization is a common and powerful primitive for synchronizing a large number of cooperating processors in a parallel system. It ensures all participating processors to reach a certain execution point before they may proceed beyond that point. Many papers on barrier synchronization have appeared in the literature <ref> [4, 6, 7, 10, 12] </ref>, but none of them considered the particular need of the DSM system. Specifically, for software DSM systems under the release consistency model, barrier synchronization not only makes sure the arrival of all participants but also enforces memory consistency when they leave the barrier. <p> Early studies on barrier synchronization have focused on the use of specific synchronization hardware [7, 10], on the software implementation of synchronization algorithms <ref> [6, 12] </ref>, or on the evaluation of barrier synchro nization performance [4]. Those studies all deal with barrier synchronization in which action (3) is satisfied simply through a broadcast operation (or mechanism) to all participating processors. Under RC model, barrier synchronization provides coherent views of shared pages after the barrier.
Reference: [13] <author> N.-F. Tzeng and P.-C. Yew. </author> <title> Special Issue on Distributed Shared Memory Systems. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 29(2), </volume> <month> September </month> <year> 1995. </year>
Reference-contexts: DSM combines the ease of shared memory programming paradigm with the scalability and constructability of distributed memory systems, such as the network of workstations (NOW) and distributed memory multiprocessors. Due to its potential advantages, DSM has been an active research area, with many prototype systems implemented and demonstrated <ref> [11, 13] </ref>. The address space of a DSM system is distributed across memories at interconnected processors. To reduce traffic over the network, a replication of certain data stored at a remote processor is usually created in the local cache of a processor. <p> Multiple copies of data, while improving read performance, pose the need of coherence enforcement, which can be achieved through hardware, software, or a combination of the two <ref> [13] </ref>. Apparently, the software implementation is most attractive since it involves no added hardware, which tends to be machine-dependent and expensive. The data transfer due to coherent enforcement under a software implementation, however, has to be minimized.
Reference: [14] <author> P.-C. Yew, N.-F. Tzeng, and D. H. Lawrie. </author> <title> Distributing hot-spot addressing in large-scale multiprocessors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-36(4):388-395, </volume> <month> April </month> <year> 1987. </year> <month> 155 </month>
Reference-contexts: Every node sends a message (which also contains the memory update record) to its immediate parent to post its arrival at the barrier. This is similar in concept to the software combining technique described earlier in <ref> [14] </ref>. As a result, any node in a system with N participants will receive at most n such messages, where n is the smallest integer satisfying N 2 n . Specifically, the root of any ST j receives exactly n j such messages.
References-found: 14

