URL: http://www.eecs.umich.edu/techreports/systems/control_group/cgr47.ps.Z
Refering-URL: http://www.eecs.umich.edu/home/techreports/sys90.html
Root-URL: http://www.cs.umich.edu
Title: Time-Average and Asymptotically Optimal Flow Control Policies in Networks with Multiple Transmitters  
Author: Redha M. Bournas, Frederick J. Beutler and Demosthenis Teneketzis 
Date: September 10, 1991  
Address: Ann Arbor, Michigan 48109  
Affiliation: Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> P. Billingsley, </author> <title> Convergence of Probability Measures, </title> <publisher> John Wiley, </publisher> <address> NY, </address> <year> 1968. </year>
Reference-contexts: Using the strong law of large numbers and the theory of convergence of probability measures as in Billingsley <ref> [1] </ref>, we have been able to show that the cost component (1) asymptotically goes to zero as T ! 1. In addition, the corresponding asymptotically optimal policies are state independent and proportional to the arrival processes rates. <p> The key to this interchange is the uniform integrability of the sequence as indicated in <ref> [1] </ref>, Theorem 5.4. In this regard, we shall often make use of the following facts: Lemma 3.4: (Uniform Integrability) (a) Let Z, fZ n g be a sequence of non-negative integrable random variables, and suppose that Z n converges in distribution (or with probability 1, or in probability) to Z.
Reference: [2] <author> R. M. Bournas, F. J. Beutler and D. Teneketzis, </author> <title> Properties of Optimal Hop-By-Hop Allocation Policies in Networks with Multiple Transmitters and Linear Equal Holding Costs, </title> <type> Technical Report No. </type> <institution> CGR-32, EECS Dept., The University of Michigan, </institution> <note> January 1991; submitted for publication to IEEE Transactions on Automatic Control. 26 </note>
Reference-contexts: For a detailed overview on the architectural layers and flow control mechanisms, the reader is referred to [7, 8, 17]. The hop-by-hop scheme studied in this paper is the same as the one in <ref> [2, 3, 4, 5] </ref>, its purpose being to maintain a smooth flow of traffic between M transmitting stations attempting to send messages through a single communication channel to an adjacent receiving station. The time axis is divided into equal segments called slots. <p> Cansever and Milito also conjectured results for M &gt; 2 transmitters. Later, they extended their work to more complex networks with multiple states in a layered, tree-like network [5]. Our model in <ref> [2] </ref> is similar to that of [3, 4]. As in these references, the cost per phase in [2] is the expectation of the sum of the number of untransmitted packets at the respective stations. <p> Cansever and Milito also conjectured results for M &gt; 2 transmitters. Later, they extended their work to more complex networks with multiple states in a layered, tree-like network [5]. Our model in <ref> [2] </ref> is similar to that of [3, 4]. As in these references, the cost per phase in [2] is the expectation of the sum of the number of untransmitted packets at the respective stations. Our objective then was to dynamically allocate a fixed number T of slots among the M 2 transmitters to minimize the total discounted cost. Our results in [2] include a partial characterization of a <p> references, the cost per phase in <ref> [2] </ref> is the expectation of the sum of the number of untransmitted packets at the respective stations. Our objective then was to dynamically allocate a fixed number T of slots among the M 2 transmitters to minimize the total discounted cost. Our results in [2] include a partial characterization of a set of 1 optimal allocation policies. These structural properties enable us to prove that, for the set of all discount factors fi &lt; 1, a finite number of dynamic optimal allocations suffice to complete describe an optimal allocation policy. <p> The time-average optimal policy can be obtained as a limit of infinite horizon optimal discounted policies as the discounting factor fi ! 1. 3. The properties of the time-average optimal policy are the same as those derived in <ref> [2] </ref> for optimal discounted policies. 4. Upper and lower performance bounds are obtained for the cost attained by the optimal policy. For each phase length T , the existence of time-average optimal policies and the derivation of their structural properties are based on: (1) the work of Bournas et al. [2] <p> <ref> [2] </ref> for optimal discounted policies. 4. Upper and lower performance bounds are obtained for the cost attained by the optimal policy. For each phase length T , the existence of time-average optimal policies and the derivation of their structural properties are based on: (1) the work of Bournas et al. [2] on the infinite horizon optimal discounted cost and structural properties of the optimal discounted stationary policies, and (2) the work of Sennott [18]. <p> Under these conditions, we then construct a pure strategy possessed of finite long-term average cost. In Section 4, we demonstrate the existence of optimal time-average stationary policies, and show that these policies have the same properties as those derived in <ref> [2] </ref> for optimal discounted stationary strategies. In Section 5, we exhibit the existence of a stationary nonrandomized policy under which the long-term average number of packets awaiting transmission at the beginning of each phase converges to zero as T ! 1. <p> The motivation of policies of this class is provided by the properties of optimal discounted policies, as given in Theorem 3.8 of <ref> [2] </ref>. Such a policy, applied to fX n g, induces an fS n g that will meet our needs. In fact, fS n g is simply the total cost at epoch n, so that the time-average of fS n g becomes 12 the time-average of the total cost. <p> We shall prove the existence of time-average optimal policies and investigate their qualitative properties based on the following results: (1) the properties of the total expected discounted infinite horizon cost of <ref> [2] </ref>, (2) the properties of the Markov chain induced by the pure policy of the previous section, and (3) the work of Sennott [18] on average cost optimal stationary policies. <p> We first summarize the properties of the minimal achievable total expected discounted cost and the properties of the optimal discounted policies as given in <ref> [2] </ref>. <p> In <ref> [2] </ref>, the authors study the properties of the discounted value function 16 V fi (x) and of the optimal policies that attain the infimum (4.5). It is shown in [2], Lemma 2.2, Lemma 3.1, equations (3.8) and (3.16), respectively, that V fi (x) has the following properties: (P1) For every state <p> In <ref> [2] </ref>, the authors study the properties of the discounted value function 16 V fi (x) and of the optimal policies that attain the infimum (4.5). It is shown in [2], Lemma 2.2, Lemma 3.1, equations (3.8) and (3.16), respectively, that V fi (x) has the following properties: (P1) For every state x and discount factor fi, V fi (x) is finite. (P2) V fi (x) is non-decreasing in x; that is, for each i, V fi (x + e i <p> (1) ; . . . ; Y (M) ), Y (j) denotes the random sequence fY (j) n g 1 n=0 , and L (x; w) is the expected cost per phase, i.e, L (x; w) = P M The properties of the fi-discounted optimal policies are as follows (see <ref> [2] </ref>, The orem 3.8 and Lemma 3.6). <p> Furthermore, f satisfies properties (P4) and (P5) of the optimal discounted policies, as well as the properties found in Sections 4 and 5 of <ref> [2] </ref> for M = 2. 5. An Asymptotically Optimal Stationary Policy In this Section, we study the asymptotic behaviour of the queueing system as a function of the phase length T . <p> We also proved that these time-average optimal strategies have the same properties as those derived in <ref> [2] </ref> for optimal discounted strategies. This result is of practical importance since: (1) the time-average cost criterion is a more natural setting for flow control problems, and (2) these qualitative properties are very useful in the search for optimal time-average policies.
Reference: [3] <author> D.H. Cansever and R.A. Milito, </author> <title> "Optimal Hop-by-Hop Flow Control policies with Multiple Transmitters," </title> <booktitle> Proceedings of the 26 th Conference on Decision and Control, </booktitle> <address> Los Angeles, CA, </address> <month> December </month> <year> 1987, </year> <pages> pp. 1858-1862. </pages>
Reference-contexts: For a detailed overview on the architectural layers and flow control mechanisms, the reader is referred to [7, 8, 17]. The hop-by-hop scheme studied in this paper is the same as the one in <ref> [2, 3, 4, 5] </ref>, its purpose being to maintain a smooth flow of traffic between M transmitting stations attempting to send messages through a single communication channel to an adjacent receiving station. The time axis is divided into equal segments called slots. <p> Optimal flow control allocations were first analyzed by Rosberg and Gopal [16], who considered a single transmitter, and a cost function reflecting the number of queued packets together with the number of unutilized (i.e., wasted) transmission slots. Subsequently, Cansever and Milito <ref> [3] </ref> investigated the problem for two transmitters (M = 2) with identical arrival statistics, with later generalizations to heterogeneous arrivals [4]. Cansever and Milito also conjectured results for M &gt; 2 transmitters. Later, they extended their work to more complex networks with multiple states in a layered, tree-like network [5]. <p> Cansever and Milito also conjectured results for M &gt; 2 transmitters. Later, they extended their work to more complex networks with multiple states in a layered, tree-like network [5]. Our model in [2] is similar to that of <ref> [3, 4] </ref>. As in these references, the cost per phase in [2] is the expectation of the sum of the number of untransmitted packets at the respective stations. <p> Finally, if the message generating processes at the M 2 transmitters are iid, we find an explicit form of the optimal allocation policy (compare <ref> [3] </ref>) that does not depend on the discount factor fi. Here, we turn our attention to time-average policies. We believe that a time-average cost criterion is a more natural setting for flow control problems, since it represents the long-term performance measure of the flow control algorithm.
Reference: [4] <author> D.H. Cansever and R.A. Milito, </author> <title> "Optimal Hop-by-Hop Flow Control policies with Multiple Transmitters," </title> <booktitle> Proceedings of the 27 th Conference on Decision and Control, </booktitle> <address> Austin, TX, </address> <month> December </month> <year> 1988, </year> <pages> pp. 1291-1296. </pages>
Reference-contexts: For a detailed overview on the architectural layers and flow control mechanisms, the reader is referred to [7, 8, 17]. The hop-by-hop scheme studied in this paper is the same as the one in <ref> [2, 3, 4, 5] </ref>, its purpose being to maintain a smooth flow of traffic between M transmitting stations attempting to send messages through a single communication channel to an adjacent receiving station. The time axis is divided into equal segments called slots. <p> Subsequently, Cansever and Milito [3] investigated the problem for two transmitters (M = 2) with identical arrival statistics, with later generalizations to heterogeneous arrivals <ref> [4] </ref>. Cansever and Milito also conjectured results for M &gt; 2 transmitters. Later, they extended their work to more complex networks with multiple states in a layered, tree-like network [5]. Our model in [2] is similar to that of [3, 4]. <p> Cansever and Milito also conjectured results for M &gt; 2 transmitters. Later, they extended their work to more complex networks with multiple states in a layered, tree-like network [5]. Our model in [2] is similar to that of <ref> [3, 4] </ref>. As in these references, the cost per phase in [2] is the expectation of the sum of the number of untransmitted packets at the respective stations.
Reference: [5] <author> D.H. Cansever and R.A. Milito, </author> <title> "Optimal Multistage Hop-by-Hop Flow Control Policies," </title> <booktitle> Proceedings of the 28 th Conference on Decision and Control, </booktitle> <address> Tampa, FL, </address> <month> December </month> <year> 1989, </year> <pages> pp. 2530-2535. </pages>
Reference-contexts: For a detailed overview on the architectural layers and flow control mechanisms, the reader is referred to [7, 8, 17]. The hop-by-hop scheme studied in this paper is the same as the one in <ref> [2, 3, 4, 5] </ref>, its purpose being to maintain a smooth flow of traffic between M transmitting stations attempting to send messages through a single communication channel to an adjacent receiving station. The time axis is divided into equal segments called slots. <p> Cansever and Milito also conjectured results for M &gt; 2 transmitters. Later, they extended their work to more complex networks with multiple states in a layered, tree-like network <ref> [5] </ref>. Our model in [2] is similar to that of [3, 4]. As in these references, the cost per phase in [2] is the expectation of the sum of the number of untransmitted packets at the respective stations. <p> This implies by Lemma 3.2 that P [U 0 = 0] &lt; 1, so that lim sup n!1 V n = +1 w.p.1, by <ref> [5] </ref> or [6]. (3.3) is now immediate upon invoking (3.5) and (3.8). Remark. We note that if = 1 and the arrival processes at all transmitters are de terministic, a control policy with finite long-term average cost exists.
Reference: [6] <author> W. Feller, </author> <title> An Introduction to Probability Theory and Its Applications, </title> <booktitle> Vol. 2, 2nd edition, </booktitle> <publisher> John Wiley, </publisher> <address> NY, </address> <year> 1971. </year>
Reference-contexts: In the next Section, we will then take advantage of the established theoretical results of the G=G=1 queue [14, 10, 11] and the theory of random walks <ref> [6, 9] </ref>, to study the stability behaviour of the queueing network. 3. Existence of Finite Average Cost Policies In this Section, we derive necessary and sufficient conditions on the statistics of the arrival processes at the transmitters that will guarantee the existence of finite long-term average cost flow control policies. <p> If &gt; 1, then the drift of V n , E (U 0 ) = (1)T , is positive so that lim n!1 V n = 1 almost surely, see Feller <ref> [6] </ref> or Gut [9]. Thus (3.2) follows immediately from (3.5) and (3.8). Assume next that = 1, and the arrival processes at the transmitters are not all deterministic, i.e, for some i and all n 2 Z + , P [Y (i) 0 = n] &lt; 1. <p> This implies by Lemma 3.2 that P [U 0 = 0] &lt; 1, so that lim sup n!1 V n = +1 w.p.1, by [5] or <ref> [6] </ref>. (3.3) is now immediate upon invoking (3.5) and (3.8). Remark. We note that if = 1 and the arrival processes at all transmitters are de terministic, a control policy with finite long-term average cost exists.
Reference: [7] <author> M. Gerla and L. Kleinrock, </author> <title> "Flow Control: A Comparative Survey," </title> <journal> IEEE Transactions on Communications, </journal> <volume> Vol. COMM-28, </volume> <pages> pp. 533-574, </pages> <year> 1980. </year>
Reference-contexts: 1. Introduction We consider a flow control problem that arises in the performance modelling of the `hop-by-hop' layer of computer communication networks. For a detailed overview on the architectural layers and flow control mechanisms, the reader is referred to <ref> [7, 8, 17] </ref>. The hop-by-hop scheme studied in this paper is the same as the one in [2, 3, 4, 5], its purpose being to maintain a smooth flow of traffic between M transmitting stations attempting to send messages through a single communication channel to an adjacent receiving station.
Reference: [8] <author> M. Gerla and L. Kleinrock, </author> <title> "Flow Control Protocols," Computer Network Architectures and Protocols, </title> <editor> P. E. Green, Jr., Ed. </editor> <address> New York: </address> <publisher> Plenum, </publisher> <year> 1982, </year> <pages> pp. 361-412. </pages>
Reference-contexts: 1. Introduction We consider a flow control problem that arises in the performance modelling of the `hop-by-hop' layer of computer communication networks. For a detailed overview on the architectural layers and flow control mechanisms, the reader is referred to <ref> [7, 8, 17] </ref>. The hop-by-hop scheme studied in this paper is the same as the one in [2, 3, 4, 5], its purpose being to maintain a smooth flow of traffic between M transmitting stations attempting to send messages through a single communication channel to an adjacent receiving station.
Reference: [9] <author> A. Gut, </author> <title> Stopped Random Walks, Limit Theorems and Applications, </title> <publisher> Springer-Verlag, </publisher> <address> NY, </address> <year> 1988. </year>
Reference-contexts: In the next Section, we will then take advantage of the established theoretical results of the G=G=1 queue [14, 10, 11] and the theory of random walks <ref> [6, 9] </ref>, to study the stability behaviour of the queueing network. 3. Existence of Finite Average Cost Policies In this Section, we derive necessary and sufficient conditions on the statistics of the arrival processes at the transmitters that will guarantee the existence of finite long-term average cost flow control policies. <p> If &gt; 1, then the drift of V n , E (U 0 ) = (1)T , is positive so that lim n!1 V n = 1 almost surely, see Feller [6] or Gut <ref> [9] </ref>. Thus (3.2) follows immediately from (3.5) and (3.8). Assume next that = 1, and the arrival processes at the transmitters are not all deterministic, i.e, for some i and all n 2 Z + , P [Y (i) 0 = n] &lt; 1. <p> Remark. Suppose that we generalize assumption (5.2) to E [(~ 1 ) m+1 ] &lt; 1; for some integer m 1, 1 j M: (5:32) Applying Theorem 5 of <ref> [9] </ref> to W (1; 0), we get that E [W m (1; 0)] &lt; 1.
Reference: [10] <author> J. Kiefer and J. Wolfowitz, </author> <title> "On the Theory of Queues with Many Servers," </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> Vol. 78, </volume> <pages> pp. 1-18, </pages> <month> January </month> <year> 1955. </year>
Reference-contexts: In the next Section, we will then take advantage of the established theoretical results of the G=G=1 queue <ref> [14, 10, 11] </ref> and the theory of random walks [6, 9], to study the stability behaviour of the queueing network. 3. <p> i.e, for any control policy and any initial state X 1 = x, n!1 n k=1 n!1 Proof: When &lt; 1, the waiting time process fW n g, as defined by (2.16), tends in distribution to a finite random variable, say W , see Lindley [14] or Kiefer and Wolfowitz <ref> [10] </ref>. Since E [(~ (i) 1 ) 2 ] = 1 implies that E [U 2 0 ] = 1, then by Theorem 3 of Kiefer and Wolfowitz [11], E (W ) = 1. <p> Under the condition &lt; 1, it was established in <ref> [10] </ref> and [11] (see also [14]) that there is the limit in distribution W n (x) ! W (3:26) where W does not depend on x.
Reference: [11] <author> J. Kiefer and J. Wolfowitz, </author> <title> "On the Characteristics of the General Queueing Process with Applications to Random Walk," </title> <journal> Ann. Math. Stat. </journal> <volume> No. 27, </volume> <pages> pp. 147-161, </pages> <year> 1956. </year>
Reference-contexts: In the next Section, we will then take advantage of the established theoretical results of the G=G=1 queue <ref> [14, 10, 11] </ref> and the theory of random walks [6, 9], to study the stability behaviour of the queueing network. 3. <p> Since E [(~ (i) 1 ) 2 ] = 1 implies that E [U 2 0 ] = 1, then by Theorem 3 of Kiefer and Wolfowitz <ref> [11] </ref>, E (W ) = 1. In addition, by [11], Theorem 1, we have P [ lim 1 n X W k = E (W )] = 1: (3:11) This result together with (3.5) and (3.8) imply (3.10). <p> Since E [(~ (i) 1 ) 2 ] = 1 implies that E [U 2 0 ] = 1, then by Theorem 3 of Kiefer and Wolfowitz <ref> [11] </ref>, E (W ) = 1. In addition, by [11], Theorem 1, we have P [ lim 1 n X W k = E (W )] = 1: (3:11) This result together with (3.5) and (3.8) imply (3.10). <p> Under the condition &lt; 1, it was established in [10] and <ref> [11] </ref> (see also [14]) that there is the limit in distribution W n (x) ! W (3:26) where W does not depend on x. In addition, it is shown in [11] that lim E [W n (0)] = E [W ] &lt; 1 ; (3:27) with the convergence and the finiteness <p> Under the condition &lt; 1, it was established in [10] and <ref> [11] </ref> (see also [14]) that there is the limit in distribution W n (x) ! W (3:26) where W does not depend on x. In addition, it is shown in [11] that lim E [W n (0)] = E [W ] &lt; 1 ; (3:27) with the convergence and the finiteness of E [W ] following from the existence of a finite second moment for Y n . <p> This result together with (5.27) yield (5.23). Furthermore, by <ref> [11] </ref>, Theorem 5, the negative drift of the random walk underlying fW n g and (5.2) ensure that W (1; 0) is integrable. From Lemma 3.4 (c) and Lemma 5.4 we then deduce that fW (T; x); T T 0 g is uniformly integrable.
Reference: [12] <author> J. F. C. Kingman, </author> <title> "Inequalities in the Theory of Queues," </title> <journal> J. Roy. Statist. Soc. Ser. </journal> <volume> B 32, </volume> <pages> pp. 102-110, </pages> <year> 1970. </year>
Reference-contexts: In general, there is no such explicit formula. However, from the bounds of <ref> [12] </ref> on the waiting time process of the G=G=1 queue, we obtain E [( j=1 Y 0 T ) + ] 2 E (W ) j=1 ( (j) ) 2 ; (3:34) where ( (j) ) 2 = V ar (~ (j) ).
Reference: [13] <author> P. Kumar and P. Varaiya, </author> <title> Stochastic Systems: Estimation, Identification and Adaptive Control, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1986. </year>
Reference-contexts: Since the receiver also knows w (j) can deduce X (j) k by the relation (2.1). It follows further from the evolution equation (2.3) that fX k g is a Markov decision process, whose optimal control requires only the most recently available state (cf. <ref> [13] </ref>, Sec. 6.7).
Reference: [14] <author> D. V. Lindley, </author> <title> "The Theory of Queues with a Single Server," </title> <booktitle> Proceedings of the Cambridge Philosophical Society, </booktitle> <volume> Vol. 48, </volume> <pages> pp. 277-289, </pages> <year> 1952. </year>
Reference-contexts: next define the random process W n = S n if n = 1 (2:16) The random process fW n g behaves exactly like the waiting time for a D=G=1 queue with interarrival times equal to the phase length T , and iid service times fY n g, see Lindley <ref> [14] </ref>. Combining (2.15) and (2.16) produces the relation S n W n ; (2:17) which is to say that under any control policy, the total cost at epoch n is at least as high as the waiting time of the nth customer of a D=G=1 system. <p> In the next Section, we will then take advantage of the established theoretical results of the G=G=1 queue <ref> [14, 10, 11] </ref> and the theory of random walks [6, 9], to study the stability behaviour of the queueing network. 3. <p> The inequality (3.5) is the key to the following proof. If &gt; 1, W n does not possess a limiting distribution, see <ref> [14] </ref>. In addition, lim n!1 W n = 1 almost surely. This result is not explicitly stated in [14], but it can be seen as follows. <p> The inequality (3.5) is the key to the following proof. If &gt; 1, W n does not possess a limiting distribution, see <ref> [14] </ref>. In addition, lim n!1 W n = 1 almost surely. This result is not explicitly stated in [14], but it can be seen as follows. Define the sequence of iid random variables U k = Y k T; (3:6) and the random walk V n = 0 if n = 0 k=0 U k if n 1. <p> unstable under any control policy, i.e, for any control policy and any initial state X 1 = x, n!1 n k=1 n!1 Proof: When &lt; 1, the waiting time process fW n g, as defined by (2.16), tends in distribution to a finite random variable, say W , see Lindley <ref> [14] </ref> or Kiefer and Wolfowitz [10]. Since E [(~ (i) 1 ) 2 ] = 1 implies that E [U 2 0 ] = 1, then by Theorem 3 of Kiefer and Wolfowitz [11], E (W ) = 1. <p> Under the condition &lt; 1, it was established in [10] and [11] (see also <ref> [14] </ref>) that there is the limit in distribution W n (x) ! W (3:26) where W does not depend on x. <p> This technique of substituting a random walk is a well known approach to G=G=1 queues, as in Lindley <ref> [14] </ref>. Our first result is that W n (T; x) converges uniformly to zero w.p.1 as T ! 1, and this entails convergence to zero in probability of X n (T; x) for each n 2 as T ! 1.
Reference: [15] <author> S. A. Lippman, </author> <title> "On Dynamic Programming with Unbounded Rewards," </title> <journal> Management Science, </journal> <volume> Vol. 21, No. 11, </volume> <pages> pp. 1225-1233, </pages> <year> 1975. </year> <month> 27 </month>
Reference: [16] <author> Z. </author> <title> Rosberg and I.S. Gopal, "Optimal Hop-By-Hop Flow Control in Computer Networks," </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> Vol. AC-31, </volume> <pages> pp. 813-822, </pages> <year> 1986. </year>
Reference-contexts: The window allocations by the receiver thus constitute a discrete-time Markov decision process with partial information. Optimal flow control allocations were first analyzed by Rosberg and Gopal <ref> [16] </ref>, who considered a single transmitter, and a cost function reflecting the number of queued packets together with the number of unutilized (i.e., wasted) transmission slots.
Reference: [17] <author> M. Schwartz, </author> <title> Computer Communication Networks, Design and Analysis. </title> <address> En-glewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1977. </year>
Reference-contexts: 1. Introduction We consider a flow control problem that arises in the performance modelling of the `hop-by-hop' layer of computer communication networks. For a detailed overview on the architectural layers and flow control mechanisms, the reader is referred to <ref> [7, 8, 17] </ref>. The hop-by-hop scheme studied in this paper is the same as the one in [2, 3, 4, 5], its purpose being to maintain a smooth flow of traffic between M transmitting stations attempting to send messages through a single communication channel to an adjacent receiving station.
Reference: [18] <author> L. I. Sennott, </author> <title> "Average Cost Optimal Stationary Policies in Infinite State Markov Decision Processes with Unbounded Costs," </title> <journal> Operations Research, </journal> <volume> Vol. 37, No. 4,pp. </volume> <pages> 626-633, </pages> <year> 1989. </year>
Reference-contexts: phase length T , the existence of time-average optimal policies and the derivation of their structural properties are based on: (1) the work of Bournas et al. [2] on the infinite horizon optimal discounted cost and structural properties of the optimal discounted stationary policies, and (2) the work of Sennott <ref> [18] </ref>. Finally, we prove that in the absence of costs accrued by messages within the phase, there exists a policy such that the time-average cost tends toward zero as 2 the phase length T ! 1. <p> existence of time-average optimal policies and investigate their qualitative properties based on the following results: (1) the properties of the total expected discounted infinite horizon cost of [2], (2) the properties of the Markov chain induced by the pure policy of the previous section, and (3) the work of Sennott <ref> [18] </ref> on average cost optimal stationary policies. We first summarize the properties of the minimal achievable total expected discounted cost and the properties of the optimal discounted policies as given in [2]. <p> By similar reasoning, property (P5) assures that the slots are allocated so that all the queued messages that are known to the receiver are transmitted and hence the number of wasted slots is minimized. We now verify that Assumptions 1-3 of <ref> [18] </ref> which ensure the existence of an average cost optimal stationary policy are satisfied. Assumption 1 is exactly property (P1). From property (P2), V fi (x) V fi (0) 0, so that Assumption 2 is met. <p> By the Lemma on p. 628 of <ref> [18] </ref> we already know that a convergent subsequence of ff fi n g exists, and from the Theorem on the same page, it follows from Assumptions one to three in [18] that the limit of f is a time-average optimal allocation. <p> By the Lemma on p. 628 of <ref> [18] </ref> we already know that a convergent subsequence of ff fi n g exists, and from the Theorem on the same page, it follows from Assumptions one to three in [18] that the limit of f is a time-average optimal allocation. <p> For this x, (P4) indicates that an optimal allocation is w (x) = T e i , where e i is the unit vector along component i; moreover, the same allocation is optimal for any fi &lt; 1. With the application of the quoted results from <ref> [18] </ref>, together with the finiteness of the set of optimal allocation strategies, we obtain 18 Theorem 4.1: Every sequence of discount factors fi converging to unity has a subsequence ffi n g such that the corresponding optimal stationary allocation policies ff fi n g satisfy f = f fi n for
References-found: 18

