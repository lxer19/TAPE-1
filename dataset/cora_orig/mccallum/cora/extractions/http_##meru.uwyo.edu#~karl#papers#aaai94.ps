URL: http://meru.uwyo.edu/~karl/papers/aaai94.ps
Refering-URL: http://meru.uwyo.edu/~karl/pubs.html
Root-URL: 
Email: fkarl,patbg@eolus.uwyo.edu  
Title: Compositional Instance-Based Learning  
Author: Karl Branting and Patrick Broos 
Address: 82071-3682  
Affiliation: Department of Computer Science, University of Wyoming Laramie, Wyoming  
Abstract: This paper proposes a new algorithm for acquisition of preference predicates by a learning apprentice, termed Compositional Instance-Based Learning (CIBL), that permits multiple instances of a preference predicate to be composed, directly exploiting the transitivity of preference predicates. In an empirical evaluation, CIBL was consistently more accurate than a 1-NN instance-based learning strategy unable to compose instances. The relative performance of CIBL and decision tree induction was found to depend upon (1) the complexity of the preference predicate being acquired and (2) the dimensionality of the feature space. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. </author> <year> 1989. </year> <title> Incremental, instance-based learning of independent and graded concepts. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> 387-391. </pages>
Reference-contexts: The sensitivity to irrelevant features exhibited by CIBL has been observed in other studies of instance-based learning <ref> (Aha 1989) </ref>. The second experiment tested the hypothesis that the relative performance of CIBL and ID3 depends on the dimensionality of the feature space as well as on the complexity of the quality function underlying the preference predicate.
Reference: <author> Aha, D. </author> <year> 1992. </year> <title> Generalizing from case studies: A case study. </title> <booktitle> In Proceedings of the Ninth International Workshop on Machine Learning, </booktitle> <pages> 1-10. </pages>
Reference-contexts: Decision tree induction algorithms such as ID3 are suitable for nonlinearly separable data. However, the performance of decision tree induction algorithms has been shown to be sometimes weaker than that of instance-based algorithms when the training set is sparse or the concept being acquired is highly "polymorphic" <ref> (Aha 1992) </ref>. Our hypothesis concerning the complexity of astronomers' preference predicates suggested that these factors would often characterize acquisition of observation scheduling preference predicates. We therefore turned to an instance-based approach to this problem.
Reference: <author> Aho, A.; Hopcroft, J.; and Ullman, J. </author> <year> 1974. </year> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley Publishing Co. </publisher>
Reference-contexts: XY found by CIBL. In practice, CIBL constructs all possible uncertain arcs, forming a dense graph with two special nodes, X and Y (for clarity, Figure 2 shows only those uncertain arcs on the best path from Y to X). The standard Dijk-stra algorithm <ref> (Aho, Hopcroft, & Ullman 1974) </ref> is then used to find the lowest cost path connecting Y and X, where edges from the tail to the head of a training arc are assigned zero cost and edges representing uncertain arcs are assigned a cost equal to their Euclidean length.
Reference: <author> Broos, P. </author> <year> 1993. </year> <title> An expert system for telescope scheduling. </title> <type> Master's thesis, </type> <institution> University of Wyoming. </institution>
Reference: <author> Callan, J.; Fawcett, T.; and Rissland, E. </author> <year> 1991. </year> <title> Adaptive case-based reasoning. </title> <booktitle> In Proceedings of the Third DARPA Case-Based Reasoning Workshop, </booktitle> <pages> 179-190. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, the complexity of astronomers' explanations for preferring one schedule over another led us to hypothesize that the underlying evaluation function Q for astronomical observation schedules, as with preference predicates in many other domains <ref> (Callan, Fawcett, & Rissland 1991) </ref>, is typically not linear, and that the instances of P Q are therefore not linearly separable. If correct, this hypothesis would imply that learning algorithms that presuppose linear separability, such as the state preference method, are inappropriate for this domain.
Reference: <author> Dent, L.; Boticario, J.; McDermott, J.; Mitchell, T.; and Zabowski, D. </author> <year> 1992. </year> <title> A personal learning apprentice. </title> <booktitle> In Proceedings of Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 96-103. </pages> <address> San Jose, CA: </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: Systems that engage in this form of learning are termed learning apprentice systems (Mitchell, Mahadevan, & Steinberg 1985). Learning apprentice systems have been developed for VLSI design (Mahadevan et al. 1993), acquisition of "interface agents" (Maes & Kozierok 1993), and calendar management <ref> (Dent et al. 1992) </ref>. An important form of knowledge that can be acquired by observing users' decisions is knowledge of users' preferences. In configuration tasks such as design or scheduling, for example, there may be numerous configurations that satisfy all applicable hard constraints. <p> Moreover, it appeared that individual astronomers often differ significantly in their preferences. These factors cast doubt on the feasibility of devising an a priori evaluation function appropriate for multiple users. A more promising approach was to develop a learning apprentice system capable of forming "personalized knowledge-based systems" <ref> (Dent et al. 1992) </ref> by acquiring the scheduling preferences of individual astronomers. The next section describes previous approaches to the problem of acquiring preference criteria and proposes a novel algorithm for this task called Compositional Instance-Based Learning (CIBL).
Reference: <author> Maes, P., and Kozierok, R. </author> <year> 1993. </year> <title> Learning interface agents. </title> <booktitle> In Proceedings of Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> 459-466. </pages> <address> Washington, D.C.: </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: Systems that engage in this form of learning are termed learning apprentice systems (Mitchell, Mahadevan, & Steinberg 1985). Learning apprentice systems have been developed for VLSI design (Mahadevan et al. 1993), acquisition of "interface agents" <ref> (Maes & Kozierok 1993) </ref>, and calendar management (Dent et al. 1992). An important form of knowledge that can be acquired by observing users' decisions is knowledge of users' preferences. In configuration tasks such as design or scheduling, for example, there may be numerous configurations that satisfy all applicable hard constraints.
Reference: <author> Mahadevan, S.; Mitchell, T.; Mostow, J.; Steinberg, L.; and Tadepalli, P. </author> <year> 1993. </year> <title> An apprentice-based approach to knowledge acquisition. </title> <booktitle> Artificial Intelligence 64(1). </booktitle>
Reference-contexts: Systems that engage in this form of learning are termed learning apprentice systems (Mitchell, Mahadevan, & Steinberg 1985). Learning apprentice systems have been developed for VLSI design <ref> (Mahadevan et al. 1993) </ref>, acquisition of "interface agents" (Maes & Kozierok 1993), and calendar management (Dent et al. 1992). An important form of knowledge that can be acquired by observing users' decisions is knowledge of users' preferences.
Reference: <author> Mitchell, T.; Mahadevan, S.; and Steinberg, L. </author> <year> 1985. </year> <title> Leap: A learning apprentice for vlsi design. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: One approach to reducing these costs is to design systems that can acquire knowledge by observing human problem-solving steps during normal use of the system. Systems that engage in this form of learning are termed learning apprentice systems <ref> (Mitchell, Mahadevan, & Steinberg 1985) </ref>. Learning apprentice systems have been developed for VLSI design (Mahadevan et al. 1993), acquisition of "interface agents" (Maes & Kozierok 1993), and calendar management (Dent et al. 1992).
Reference: <author> Quinlan, J. R. </author> <year> 1986. </year> <title> Induction of decision trees. </title> <booktitle> Machine Learning 1 </booktitle> <pages> 81-106. </pages>
Reference-contexts: One approach has been to use decision tree induction algorithms, such as ID3 <ref> (Quinlan 1986) </ref>, to induce a general representation for P Q . <p> "Y is preferred to X": &lt; +; Y; X; kXY k ; kX Y k &gt; (Y X) Since the (3N+1) elements of each ID3 feature vector are real numbers, we used an implementation of ID3 supplied by Ray Mooney that handles real-valued fea tures in the manner proposed by <ref> (Quinlan 1986) </ref>. Artificial Domain Experiments We first compared the accuracy of CIBL to that of 1ARC and ID3 on the task of learning preference functions, P Q , for a variety of artificial evaluation functions, Q, shown in Figure 3.
Reference: <author> Stanfill, C., and Waltz, D. </author> <year> 1986. </year> <title> Toward memory-based reasoning. </title> <journal> Communications of the ACM 29(12). </journal>
Reference: <author> Utgoff, P., and Clouse. </author> <year> 1991. </year> <title> Two kinds of training information for evaluation function learning. </title> <booktitle> In Proceedings of Ninth National Conference on Artificial Intelligence, </booktitle> <pages> 596-600. </pages> <address> Anaheim: </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: An alternative approach, termed the state preference method, uses parameter adjustment to learn a set of feature weights W such that for every training instance, P Q (x; y), W (F (x) F (y)) &gt; 0, where F (n) is a vector of numeric attributes representing state n <ref> (Utgoff & Clouse 1991) </ref>.
Reference: <author> Utgoff, P., and Saxena, S. </author> <year> 1987. </year> <title> Learning a preference predicate. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> 115-121. </pages>
Reference-contexts: Airmass can be minimized by observing a star at the time midway between its rising time and setting time. model of the relative desirability of schedules as a function of their relevant attributes. Knowledge of users' preferences can be expressed as a preference predicate <ref> (Utgoff & Saxena 1987) </ref> P Q (x; y) [Q (x) &gt; Q (y)], where Q (s) is an evaluation function that expresses the "quality" of state s.
References-found: 13

