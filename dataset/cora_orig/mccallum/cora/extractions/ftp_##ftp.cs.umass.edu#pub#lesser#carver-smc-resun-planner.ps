URL: ftp://ftp.cs.umass.edu/pub/lesser/carver-smc-resun-planner.ps
Refering-URL: http://dis.cs.umass.edu/research/dresun.html
Root-URL: 
Title: on Planning, Scheduling and Control, vol.  A Planner for the Control of Problem-Solving Systems  
Author: Norman Carver and Victor Lesser 
Address: Amherst, Massachusetts 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Note: To appear in IEEE Transactions on Systems, Man, and Cybernetics, special issue  This work was supported by the Office of Naval Research under University Research Initiative grant number N00014-86-K-0764 and by DARPA under ONR contract N00014-89-J-1877.  
Pubnum: 23, no.  
Email: (carver@cs.umass.edu, lesser@cs.umass.edu)  
Date: 6, November 1993:  
Abstract: As part of research on sophisticated control for sensor interpretation, we have developed a planning-based control scheme for blackboard systems. A planner's goal/plan/subgoal structure provides explicit context information that can be used to index and apply large amounts of context-specific control knowledge. The key obstacle to using planning for the control of problem solvers is the need to deal with uncertain and dynamically changing situations without incurring unacceptable overhead. We have addressed these problems in several ways: our planner is script-based, planning and execution are interleaved, plans can invoke information gathering actions, plan refinement is controlled by plan-specific focusing heuristics, and the system's focus-of-attention can be dynamically shifted by the refocusing mechanism. Refocusing makes it possible to postpone focusing decisions and maintain the opportunistic control capabilities of conventional blackboard systems. Planning with refocusing results in a view of the control process as both a search for problem solutions and a search for the best methods to determine these solutions. The planner has been implemented in the RESUN interpretation system and has been used with a simulated aircraft monitoring application and a system for understanding household sounds. Our experience confirms that the combination of control plans with context-specific focusing heuristics provides a modular framework for developing and maintaining complex control strategies. In experiments, we have been able to achieve significant performance improvements as a result of the ability to encode sophisticated control strategies despite the overhead of the planning mechanism. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Agre and D. Chapman, "Pengi: </author> <booktitle> An Implementation of a Theory of Action" in Proceedings of AAAI-87, </booktitle> <pages> pp. 268-272, </pages> <year> 1987. </year>
Reference-contexts: One response to the combinatorics of classical planning and its problems in dealing with uncertain and dynamic situations has been to go to the other extreme and argue that planning is not needed at all. In the reactive control or situated action approach <ref> [1, 34] </ref>, actions result from rules or procedures whose invocation is based solely on properties of the immediate situation.
Reference: [2] <author> B. Buchanan and R. Smith, </author> <title> "Fundamentals of Expert Systems," </title> <booktitle> in The Handbook of Artificial Intelligence, </booktitle> <volume> Volume 4, </volume> <editor> Avron Barr, Paul Cohen, and Edward Feigenbaum, editors. </editor> <address> Reading, MA: </address> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Experience with knowledge-based systems suggests that the use of explicit control mechanisms supports the development, understanding, and maintenance of systems with sophisticated control strategies <ref> [2, 13] </ref>. We believe that a planning-based control mechanism can support the use of sophisticated control strategies and this will be a major focus of the paper. However, relatively few AI problem solvers have used planning mechanisms.
Reference: [3] <author> N. Carver and V. Lesser, </author> <title> Control for Interpretation: Planning to Resolve Uncertainty, </title> <type> Technical Report 90-53, </type> <institution> Computer and Information Science Department, University of Mas-sachusetts, </institution> <year> 1990. </year>
Reference-contexts: Interpretation problems have typically been approached using blackboard systems. The blackboard model of problem solving is appropriate for sensor interpretation because blackboards support the incremental and opportunistic styles of problem solving that are required for such problems <ref> [3, 5, 8, 28] </ref>. However, despite the power of the blackboard model, most blackboard-based interpretation systems have used a very limited range of strategies for resolving hypothesis uncertainty. Specifically, they have used variations of incremental hypothesize and test that indirectly resolve uncertainty through the aggregation of evidence for the hypotheses. <p> can be used to change the focus-of-attention of the system while it is waiting for a data gathering action to complete so that the system is not idled. 4 Status and Experimental Results We originally implemented the RESUN control architecture described in this paper using a simulated aircraft monitoring application <ref> [3, 4] </ref>. The implementation is in Common Lisp on a Texas 23 Instruments Explorer using GBB [17] for the domain blackboard.
Reference: [4] <author> N. Carver, </author> <title> Sophisticated Control for Interpretation: Planning to Resolve Uncertainty, </title> <type> Ph.D. Thesis, </type> <institution> Computer and Information Science Department, University of Massachusetts, </institution> <year> 1990. </year>
Reference-contexts: Interpretation can be difficult because there may be combinatorial numbers of alternative possible explanations of the data, the correctness of each interpretation hypothesis will be uncertain, creating each hypothesis may be computationally expensive, and the volume of data is often too great for complete examination <ref> [4] </ref>. Interpretation problems have typically been approached using blackboard systems. The blackboard model of problem solving is appropriate for sensor interpretation because blackboards support the incremental and opportunistic styles of problem solving that are required for such problems [3, 5, 8, 28]. <p> By planning, we will mean "deciding on a course of action before acting" [11] (at least on a partial course of action) and developing an explicit goal/plan/subgoal structure as part of the control process. 1 gies like differential diagnosis 2 can directly resolve the sources of uncertainty about interpretation hypotheses <ref> [4, 5] </ref>. In part, the strategy limitations of blackboard-based interpretation systems are a result of inadequate representations of evidence and uncertainty [4, 5, 28]. For instance, the ability to use more sophisticated strategies for resolving uncertainty requires that a system be able to identify when these strategies are applicable. <p> In part, the strategy limitations of blackboard-based interpretation systems are a result of inadequate representations of evidence and uncertainty <ref> [4, 5, 28] </ref>. For instance, the ability to use more sophisticated strategies for resolving uncertainty requires that a system be able to identify when these strategies are applicable. <p> The RESUN system provides this information by associating symbolic source of uncertainty (SOU) statements with its hypotheses. These SOUs are derived from RESUN's model of the uncertainty in (abductive) interpretation inferences <ref> [4, 5] </ref>. RESUN's SOUs make it possible to use a wide range of strategies for resolving uncertainty. However, we found that existing blackboard control mechanisms did not support the type of goal-directed (context-specific) reasoning that is necessary to deal effectively with such a range of interpretation strategies. <p> However, this alternative may also be likely to fail if its relatively high rating results 3 from the same factors as an already failed choice. Note also that dependency-directed backtracking mechanisms do not solve this aspect of the decision revision problem <ref> [4] </ref>. To deal with these issues, a number of researchers have advocated that the process of making control decisions be viewed as a problem solving task in itself and that this process be made more explicit|e.g., [9, 12, 13, 21, 27]. <p> In order to take full advantage of meta-level knowledge such as meta-rules, there must be additional structure to the knowledge that identifies the context in which the knowledge applies in order to index (and partition) the knowledge <ref> [4, 13] </ref>. Davis recognizes this as a solution to the overhead problem and suggests that meta-rules be associated with the (domain action) retrieval properties|e.g., goals. <p> The aircraft monitoring application and the model of uncertainty used in RESUN are described in more detail in <ref> [4, 5] </ref>. 3.2 Plan Expansion and Refinement The RESUN approach to planning can be described as script-based, incremental planning augmented with context-specific focusing and refocusing mechanisms. <p> The most significant innovation in the RESUN planner is its refocusing mechanism. In effect, the refocusing mechanism provides the RESUN system with an intelligent, nonchronological backtracking scheme <ref> [4] </ref>. While the planner needs to have backtracking capability, we have not used an implicit backtracking mechanism in this planner. For example, chronological backtracking is not used because it would be inappropriate in a reactive planner. Also, backtracking should not be driven by failures alone. <p> Other grammar operators not appearing in the figure schema include: :SHUFFLE, :LIST-SHUFFLE, :CONDITIONAL, and :XOR (see <ref> [4] </ref>). For each subgoal listed in the Grammar clause of a plan definition, a corresponding subgoal definition form must be provided. Subgoal definitions identify the Goal Form, Input Variables, and Output Variables for each subgoal. <p> can be used to change the focus-of-attention of the system while it is waiting for a data gathering action to complete so that the system is not idled. 4 Status and Experimental Results We originally implemented the RESUN control architecture described in this paper using a simulated aircraft monitoring application <ref> [3, 4] </ref>. The implementation is in Common Lisp on a Texas 23 Instruments Explorer using GBB [17] for the domain blackboard. <p> Third, the refocusing mechanism does make it possible to obtain opportunstic control capabilities from a planner. Fourth, the framework is useable in practice on realistic problems. A description of the aircraft monitoring experiments is contained in <ref> [4] </ref>. One purpose of the experiments was to evaluate whether or not the RESUN framework could be used to implement sophisticated interpretation strategies and to analyze the importance of the different features of the system.
Reference: [5] <author> N. Carver and V. Lesser, </author> <title> "A New Framework for Sensor Interpretation: Planning to Resolve Sources of Uncertainty," </title> <booktitle> Proceedings of AAAI-91, </booktitle> <pages> pp. 724-731, </pages> <year> 1991. </year>
Reference-contexts: Interpretation problems have typically been approached using blackboard systems. The blackboard model of problem solving is appropriate for sensor interpretation because blackboards support the incremental and opportunistic styles of problem solving that are required for such problems <ref> [3, 5, 8, 28] </ref>. However, despite the power of the blackboard model, most blackboard-based interpretation systems have used a very limited range of strategies for resolving hypothesis uncertainty. Specifically, they have used variations of incremental hypothesize and test that indirectly resolve uncertainty through the aggregation of evidence for the hypotheses. <p> By planning, we will mean "deciding on a course of action before acting" [11] (at least on a partial course of action) and developing an explicit goal/plan/subgoal structure as part of the control process. 1 gies like differential diagnosis 2 can directly resolve the sources of uncertainty about interpretation hypotheses <ref> [4, 5] </ref>. In part, the strategy limitations of blackboard-based interpretation systems are a result of inadequate representations of evidence and uncertainty [4, 5, 28]. For instance, the ability to use more sophisticated strategies for resolving uncertainty requires that a system be able to identify when these strategies are applicable. <p> In part, the strategy limitations of blackboard-based interpretation systems are a result of inadequate representations of evidence and uncertainty <ref> [4, 5, 28] </ref>. For instance, the ability to use more sophisticated strategies for resolving uncertainty requires that a system be able to identify when these strategies are applicable. <p> The RESUN system provides this information by associating symbolic source of uncertainty (SOU) statements with its hypotheses. These SOUs are derived from RESUN's model of the uncertainty in (abductive) interpretation inferences <ref> [4, 5] </ref>. RESUN's SOUs make it possible to use a wide range of strategies for resolving uncertainty. However, we found that existing blackboard control mechanisms did not support the type of goal-directed (context-specific) reasoning that is necessary to deal effectively with such a range of interpretation strategies. <p> Differential diagnosis means that hypothesis uncertainty is resolved by attempting to discount the possible alternative explanations for a hypothesis' supporting evidence. The possibility of alternative explanations for data is the key source of interpretation uncertainty since interpretation is based on abductive inference <ref> [5] </ref>. 2 problems in several ways. The primary innovation of the framework is its refocusing mechanism. Refocusing makes it possible for the planner to maintain the opportunistic control capabilities of more conventional blackboard problem-solving systems. <p> The aircraft monitoring application and the model of uncertainty used in RESUN are described in more detail in <ref> [4, 5] </ref>. 3.2 Plan Expansion and Refinement The RESUN approach to planning can be described as script-based, incremental planning augmented with context-specific focusing and refocusing mechanisms.
Reference: [6] <author> N. Carver, Z. Cvetanovic, and V. Lesser, </author> <title> "Sophisticated Cooperation in FA/C Distributed Problem Solving Systems," </title> <booktitle> Proceedings of AAAI-91, </booktitle> <pages> pp. 191-198, </pages> <year> 1991. </year>
Reference-contexts: Currently we simply use focusing heuristics that key off of the goals and resources to determine how to proceed|rather than adjusting the goals. We have also developed a distributed version of the RESUN system <ref> [6] </ref>. The goal/plan/subgoal structure (along with RESUN's symbolic model of uncertainty) provides the system with a rich language for communicating with other agents about the state of its problem solving. Another area of interest that we are current pursuing is the development of a parallel architecture implementation of RESUN.
Reference: [7] <author> N. Carver and V. Lesser, </author> <title> "The Evolution of Blackboard Control," to appear in Expert Systems with Applications, </title> <journal> special issue on The Blackboard Paradigm and Its Applications, </journal> <volume> vol 7, no. </volume> <pages> 1, </pages> <note> 1993 (also available as Technical Report 92-71, </note> <institution> Computer Science Department, University of Massachusetts, </institution> <year> 1992). </year>
Reference-contexts: Opportunistic control allows a system to deal with 4 uncertain and dynamic situations because the system can re-direct its efforts as necessary|instead of being limited to a predetermined (and possibly inappropriate) strategy. However, there has been a steady evolution of blackboard control toward more goal-directed mechanisms <ref> [7] </ref>. The reason for this is clear: without (explicit) goal-directed control it is difficult for a system to identify actions critical to meeting its overall goals (especially when a sequence of actions is necessary to accomplish some goal [12]). <p> This is equivalent to having a totally data/event-directed control mechanism and it seems clear from research on blackboard systems that this approach is insufficient for much problem solving <ref> [7, 12, 22, 25] </ref>. An intermediate approach that has received much recent attention is often referred to as reactive planning [16, 18].
Reference: [8] <author> W. Clancey, </author> <title> "Heuristic Classification," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 27, </volume> <pages> pp. 289-350, </pages> <year> 1985. </year>
Reference-contexts: Interpretation problems have typically been approached using blackboard systems. The blackboard model of problem solving is appropriate for sensor interpretation because blackboards support the incremental and opportunistic styles of problem solving that are required for such problems <ref> [3, 5, 8, 28] </ref>. However, despite the power of the blackboard model, most blackboard-based interpretation systems have used a very limited range of strategies for resolving hypothesis uncertainty. Specifically, they have used variations of incremental hypothesize and test that indirectly resolve uncertainty through the aggregation of evidence for the hypotheses.
Reference: [9] <author> W. Clancey and C. Bock, </author> <title> Representing Control Knowledge as Abstract Tasks and Metarules, </title> <type> Technical Report KSL 85-16, </type> <institution> Knowledge Systems Laboratory, Computer Science Department, Stanford University, </institution> <year> 1986. </year>
Reference-contexts: To deal with these issues, a number of researchers have advocated that the process of making control decisions be viewed as a problem solving task in itself and that this process be made more explicit|e.g., <ref> [9, 12, 13, 21, 27] </ref>. This involves providing a body of explicit meta-level (heuristic) knowledge about the domain and actions that is used to guide the refinement process. With such knowledge, a system can "reason explicitly" about control because the meta-level knowledge explicitly identifies the factors that influence control decisions. <p> Clancey's work on NEOMYCIN was an attempt to provide more structure to Davis' meta-rules format through a planning-based mechanism. Control knowledge in NEOMYCIN was defined in terms of tasks <ref> [9, 10] </ref> which were made up of a sequence of conditional actions represented as meta-rules. A prime motivation for NEOMYCIN was the recognition that similar "strategies" (what we have called "methods") were being repeatedly encoded in meta-rules that were relevant to different situations.
Reference: [10] <author> W. Clancey, </author> <title> "From GUIDON to NEOMYCIN and HERACLES in Twenty Short Lessons," </title> <journal> AI Magazine, </journal> <volume> vol. 7, no. 3, </volume> <pages> pp. 40-60, </pages> <year> 1986. </year>
Reference-contexts: Clancey's work on NEOMYCIN was an attempt to provide more structure to Davis' meta-rules format through a planning-based mechanism. Control knowledge in NEOMYCIN was defined in terms of tasks <ref> [9, 10] </ref> which were made up of a sequence of conditional actions represented as meta-rules. A prime motivation for NEOMYCIN was the recognition that similar "strategies" (what we have called "methods") were being repeatedly encoded in meta-rules that were relevant to different situations.
Reference: [11] <editor> P. Cohen and E. Feigenbaum, editors, </editor> <booktitle> The Handbook of Artificial Intelligence, Volume 3. </booktitle> <address> Lost Altos, CA: </address> <publisher> Kaufmann, </publisher> <year> 1982. </year>
Reference-contexts: By constrast, strate 1 We use the term "planning-based" here to distinguish our sense of the term "planning" from the more restricted sense in which it is used in "classical planning" research|see [36]. By planning, we will mean "deciding on a course of action before acting" <ref> [11] </ref> (at least on a partial course of action) and developing an explicit goal/plan/subgoal structure as part of the control process. 1 gies like differential diagnosis 2 can directly resolve the sources of uncertainty about interpretation hypotheses [4, 5].
Reference: [12] <author> D. Corkill, V. Lesser, and E. Hudlicka, </author> <title> "Unifying Data-Directed and Goal-Directed Control: An Example and Experiments," </title> <booktitle> Proceedings of AAAI-82, </booktitle> <pages> pp. 143-147, </pages> <year> 1982. </year>
Reference-contexts: To deal with these issues, a number of researchers have advocated that the process of making control decisions be viewed as a problem solving task in itself and that this process be made more explicit|e.g., <ref> [9, 12, 13, 21, 27] </ref>. This involves providing a body of explicit meta-level (heuristic) knowledge about the domain and actions that is used to guide the refinement process. With such knowledge, a system can "reason explicitly" about control because the meta-level knowledge explicitly identifies the factors that influence control decisions. <p> The reason for this is clear: without (explicit) goal-directed control it is difficult for a system to identify actions critical to meeting its overall goals (especially when a sequence of actions is necessary to accomplish some goal <ref> [12] </ref>). Thus, a key issue is how to make control more goal-directed without sacrificing opportunism. 2.2 Planning for Control In this section we will look at how planning-based approaches to control can address the issues raised in the previous section. <p> One problem with this is that it can be difficult to judge the importance of the actions without an understanding of the role they play in fulfilling some goal|e.g., because the "quality" of intermediate-level hypotheses may be poor from a purely data-directed perspective <ref> [12] </ref>. Another problem with this approach is that it can incur substantial overhead since the decision about whether to continue with the sequence is effectively being reconsidered on each control cycle. <p> This is equivalent to having a totally data/event-directed control mechanism and it seems clear from research on blackboard systems that this approach is insufficient for much problem solving <ref> [7, 12, 22, 25] </ref>. An intermediate approach that has received much recent attention is often referred to as reactive planning [16, 18]. <p> The desirability of planning for control of problem-solving systems was recognized early on in blackboard system research. For example, Hearsay-II included special mechanisms that always scheduled certain knowledge sources together [28]. The goal-directed blackboard architecture of Corkill and Lesser <ref> [12] </ref> included subgoaling and precondition-action backchaining mechanisms (that are an implicit part of any planning frameworks), but did not construct plans.
Reference: [13] <author> R. Davis, </author> <title> "Meta-Rules: Reasoning about Control," </title> <journal> Artificial Intelligence, </journal> <volume> volume 15, </volume> <pages> pp. 179-222, </pages> <year> 1980. </year>
Reference-contexts: Experience with knowledge-based systems suggests that the use of explicit control mechanisms supports the development, understanding, and maintenance of systems with sophisticated control strategies <ref> [2, 13] </ref>. We believe that a planning-based control mechanism can support the use of sophisticated control strategies and this will be a major focus of the paper. However, relatively few AI problem solvers have used planning mechanisms. <p> The paper concludes with a summary of the contributions of the framework and directions for future research. 2 Control of AI Problem Solvers 2.1 Basic Issues AI systems have typically made control decisions in a two-stage process. Davis <ref> [13] </ref> terms these the retrieval and the refinement stages. The retrieval stage determines the actions that the system might take next given the current state of problem-solving. The refinement stage selects the action (s) that actually will be taken next (out of those identified by the retrieval stage). <p> To deal with these issues, a number of researchers have advocated that the process of making control decisions be viewed as a problem solving task in itself and that this process be made more explicit|e.g., <ref> [9, 12, 13, 21, 27] </ref>. This involves providing a body of explicit meta-level (heuristic) knowledge about the domain and actions that is used to guide the refinement process. With such knowledge, a system can "reason explicitly" about control because the meta-level knowledge explicitly identifies the factors that influence control decisions. <p> With such knowledge, a system can "reason explicitly" about control because the meta-level knowledge explicitly identifies the factors that influence control decisions. For production (rule-based) systems, Davis <ref> [13] </ref> proposed that explicit meta-level knowledge might take the form of a set of meta-rules. Meta-rule conditions would refer to key features of the problem solving situation. Meta-rule "actions" would then state preferences for (domain) rules whose characteristics are appropriate for the current situation. <p> In order to take full advantage of meta-level knowledge such as meta-rules, there must be additional structure to the knowledge that identifies the context in which the knowledge applies in order to index (and partition) the knowledge <ref> [4, 13] </ref>. Davis recognizes this as a solution to the overhead problem and suggests that meta-rules be associated with the (domain action) retrieval properties|e.g., goals.
Reference: [14] <author> J. Doyle, </author> <title> A Model for Deliberation, Action, and Introspection, </title> <type> Ph.D. Thesis, Technical Report AI-TR-581, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1980. </year>
Reference-contexts: Traditionally, AI systems used monolithic evaluation functions to make refinement-stage decisions. A single ("global") evaluation function computed a numeric rating for each of the retrieval-stage alternatives, which reflected that alternative's "likelihood" to succeed. One of the key problems with this approach is what Doyle <ref> [14] </ref> termed the "inaccessibility of control information." All the reasoning being done by the evaluation function is implicit in the function's computations and the resulting numeric rating.
Reference: [15] <author> E. Durfee and V. Lesser, </author> <title> "Incremental Planning to Control a Blackboard-Based Problem Solver," </title> <booktitle> Proceedings of AAAI-86, </booktitle> <pages> pp. 58-64, </pages> <year> 1986. </year>
Reference-contexts: The goal-directed blackboard architecture of Corkill and Lesser [12] included subgoaling and precondition-action backchaining mechanisms (that are an implicit part of any planning frameworks), but did not construct plans. The incremental planning approach of Durfee and Lesser <ref> [15] </ref> for a blackboard-based vehicle monitoring system builds abstract models of the data and uses these models to develop plans that guide the selection of knowledge sources. Planning in their approach effectively occurs at two different levels of ab 27 straction.
Reference: [16] <author> R. J. Firby, </author> <title> "An Investigation into Reactive Planning in Complex Domains," </title> <booktitle> Proceedings of AAAI-87, </booktitle> <pages> pp. 202-206, </pages> <year> 1987. </year>
Reference-contexts: In other words, the problem with classical planners is that they are neither opportunistic nor reactive [36]. Recently there has been a significant amount of research on reactive planning <ref> [16, 18] </ref> and on the interleaving of planning and execution [26]. As we will see, these types of approaches can make planning appropriate for the control of problem-solving systems. <p> This is the purpose of the Failure and Satisfaction conditions. A similar approach has been used in other reactive planners|e.g. Firby's RAP system <ref> [16] </ref>. It is important to realize, however, that this approach requires the kind of intelligent backtracking capabilities that are provided by our refocusing mechanism. 3.6 Actions Incremental planning makes it possible to deal with the uncertainty about the outcome of actions that is an inherent part of most problem-solving systems. <p> This is equivalent to having a totally data/event-directed control mechanism and it seems clear from research on blackboard systems that this approach is insufficient for much problem solving [7, 12, 22, 25]. An intermediate approach that has received much recent attention is often referred to as reactive planning <ref> [16, 18] </ref>. Proponents of this approach recognize the limitations of planning based on complete world models and perfectly predictable actions, but they argue that planning is still necessary for intelligent control. One approach to reactive planning is Firby's RAP system [16, 20]. <p> Proponents of this approach recognize the limitations of planning based on complete world models and perfectly predictable actions, but they argue that planning is still necessary for intelligent control. One approach to reactive planning is Firby's RAP system <ref> [16, 20] </ref>. RAPs (Reactive Action Packages) are similar to our control plans and the RAP expansion process is similar to RESUN's basic planning process.
Reference: [17] <author> K. Gallagher, D. Corkill, and P. Johnson, </author> <title> GBB Reference Manual, </title> <type> Technical Report 88-66, </type> <institution> Computer and Information Science Department, University of Massachusetts, </institution> <year> 1988. </year>
Reference-contexts: The implementation is in Common Lisp on a Texas 23 Instruments Explorer using GBB <ref> [17] </ref> for the domain blackboard.
Reference: [18] <author> M. Georgeff and A. Lansky, </author> <title> "Reactive Reasoning and Planning," </title> <booktitle> Proceedings of AAAI-87, </booktitle> <pages> pp. 677-682, </pages> <year> 1987. </year>
Reference-contexts: In other words, the problem with classical planners is that they are neither opportunistic nor reactive [36]. Recently there has been a significant amount of research on reactive planning <ref> [16, 18] </ref> and on the interleaving of planning and execution [26]. As we will see, these types of approaches can make planning appropriate for the control of problem-solving systems. <p> This is equivalent to having a totally data/event-directed control mechanism and it seems clear from research on blackboard systems that this approach is insufficient for much problem solving [7, 12, 22, 25]. An intermediate approach that has received much recent attention is often referred to as reactive planning <ref> [16, 18] </ref>. Proponents of this approach recognize the limitations of planning based on complete world models and perfectly predictable actions, but they argue that planning is still necessary for intelligent control. One approach to reactive planning is Firby's RAP system [16, 20]. <p> Another approach to reactive planning is the Procedural Reasoning System (PRS) of Georgeff and others <ref> [18, 19] </ref>. PRS is also a script-based, incremental planner and like RESUN it is both opportunistic and reactive. The main difference is in the way that plans and control knowledge are invoked.
Reference: [19] <author> M. Georgeff and F. Ingrand, </author> <title> "Decision-Making in an Embedded Reasoning System," </title> <booktitle> Proceedings of IJCAI-89, </booktitle> <pages> pp. 972-978, </pages> <year> 1989. </year>
Reference-contexts: Another approach to reactive planning is the Procedural Reasoning System (PRS) of Georgeff and others <ref> [18, 19] </ref>. PRS is also a script-based, incremental planner and like RESUN it is both opportunistic and reactive. The main difference is in the way that plans and control knowledge are invoked.
Reference: [20] <author> S. Hanks and R. J. Firby, </author> <title> "Issues and Architectures for Planning and Execution," Proceedings of DARPA Workshop on Innovative Approaches to Planning, Scheduling, </title> <journal> and Control, </journal> <pages> pp. </pages> <year> 59-70,1990. </year>
Reference-contexts: Proponents of this approach recognize the limitations of planning based on complete world models and perfectly predictable actions, but they argue that planning is still necessary for intelligent control. One approach to reactive planning is Firby's RAP system <ref> [16, 20] </ref>. RAPs (Reactive Action Packages) are similar to our control plans and the RAP expansion process is similar to RESUN's basic planning process.
Reference: [21] <author> B. Hayes-Roth and F. Hayes-Roth, </author> <title> "A Cognitive Model of Planning," </title> <journal> Cognitive Science, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 275-310, </pages> <year> 1979. </year>
Reference-contexts: To deal with these issues, a number of researchers have advocated that the process of making control decisions be viewed as a problem solving task in itself and that this process be made more explicit|e.g., <ref> [9, 12, 13, 21, 27] </ref>. This involves providing a body of explicit meta-level (heuristic) knowledge about the domain and actions that is used to guide the refinement process. With such knowledge, a system can "reason explicitly" about control because the meta-level knowledge explicitly identifies the factors that influence control decisions.
Reference: [22] <author> B. Hayes-Roth, </author> <title> "A Blackboard Architecture for Control," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 26, </volume> <pages> pp. 251-321, </pages> <year> 1985. </year>
Reference-contexts: Opportunism simply results from the use of particular types of conditions that cause the system to redirect its method search. It may also be of interest to note that the notion of opportunism that we have differs somewhat from that in the BB1 paradigm <ref> [22] </ref> (discussed in Section 5). In that system, opportunistic actions are allowed to post new "subgoals" for the system. <p> This is equivalent to having a totally data/event-directed control mechanism and it seems clear from research on blackboard systems that this approach is insufficient for much problem solving <ref> [7, 12, 22, 25] </ref>. An intermediate approach that has received much recent attention is often referred to as reactive planning [16, 18]. <p> A second level of planning is then used to choose knowledge source sequences to meet these intermediate-level goals. Because both the data abstraction model and the planning mechanism here are closely tied to vehicle tracking, though, their application is limited. The BB1 system <ref> [22, 23, 24, 35] </ref> is the first blackboard framework to use a true planning-based approach to control and it remains one of the most sophisticated blackboard control frameworks. The control planning mechanism of BB1 extends the blackboard model with a separate control blackboard and control knowledge sources.
Reference: [23] <author> B. Hayes-Roth and M. Hewett "BB1: </author> <title> An Implementation of the Blackboard Control Architecture," in Blackboard Systems, </title> <editor> Robert Engelmore and Tony Morgan, editors. </editor> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: A second level of planning is then used to choose knowledge source sequences to meet these intermediate-level goals. Because both the data abstraction model and the planning mechanism here are closely tied to vehicle tracking, though, their application is limited. The BB1 system <ref> [22, 23, 24, 35] </ref> is the first blackboard framework to use a true planning-based approach to control and it remains one of the most sophisticated blackboard control frameworks. The control planning mechanism of BB1 extends the blackboard model with a separate control blackboard and control knowledge sources.
Reference: [24] <author> B. Hayes-Roth, R. Washington, R. Hewett, and M. Hewett, </author> <title> "Intelligent Monitoring and Control," </title> <booktitle> Proceedings of IJCAI-89, </booktitle> <pages> pp. 243-249, </pages> <year> 1989. </year>
Reference-contexts: These are important capabilities for interpretation problems, which may involve passive sensors that continuously generate large amounts of data and active sensors whose operation may be controlled by the interpretation system. Recent work on the BB1 framework <ref> [24] </ref> does provide a mechanism that blackboard systems might use to deal with large amounts of data being generated by sensors. Here, the control component provides filters to autonomous processors that limit the data that is passed on to the main reasoning component. <p> A second level of planning is then used to choose knowledge source sequences to meet these intermediate-level goals. Because both the data abstraction model and the planning mechanism here are closely tied to vehicle tracking, though, their application is limited. The BB1 system <ref> [22, 23, 24, 35] </ref> is the first blackboard framework to use a true planning-based approach to control and it remains one of the most sophisticated blackboard control frameworks. The control planning mechanism of BB1 extends the blackboard model with a separate control blackboard and control knowledge sources.
Reference: [25] <author> F. Hayes-Roth and V. Lesser, </author> <title> "Focus of Attention in the Hearsay-II Speech Understanding System," </title> <booktitle> Proceedings of IJCAI-77, </booktitle> <pages> pp. 27-35, </pages> <year> 1977. </year>
Reference-contexts: This is equivalent to having a totally data/event-directed control mechanism and it seems clear from research on blackboard systems that this approach is insufficient for much problem solving <ref> [7, 12, 22, 25] </ref>. An intermediate approach that has received much recent attention is often referred to as reactive planning [16, 18].
Reference: [26] <editor> J. Hendler, A. Tate, and M. </editor> <title> Drummond, "AI Planning: Systems and Techniques," </title> <journal> AI Magazine, </journal> <volume> vol. 11, no. 2, </volume> <pages> pp. 61-77, </pages> <year> 1990. </year>
Reference-contexts: In other words, the problem with classical planners is that they are neither opportunistic nor reactive [36]. Recently there has been a significant amount of research on reactive planning [16, 18] and on the interleaving of planning and execution <ref> [26] </ref>. As we will see, these types of approaches can make planning appropriate for the control of problem-solving systems. One of the key motivations for using a planning-based control framework is that the goal/plan/subgoal hierarchy that is instantiated by a planner provides detailed and explicit context information for control decisions. <p> Forming complete plans prior to executing them is not possible for control in applications like interpretation where the outcome of actions is uncertain and where external agents can affect the world <ref> [26] </ref>. Our control planner is a reactive planner, in part, because it interleaves planning with execution and bases further expansion of its plans on the outcome of earlier actions.
Reference: [27] <author> E. Hudlicka and V. Lesser, </author> <title> "Meta-Level Control Through Fault Detection and Diagnosis," </title> <booktitle> Proceedings of AAAI-84, </booktitle> <pages> pp. 153-161, </pages> <year> 1984. </year>
Reference-contexts: To deal with these issues, a number of researchers have advocated that the process of making control decisions be viewed as a problem solving task in itself and that this process be made more explicit|e.g., <ref> [9, 12, 13, 21, 27] </ref>. This involves providing a body of explicit meta-level (heuristic) knowledge about the domain and actions that is used to guide the refinement process. With such knowledge, a system can "reason explicitly" about control because the meta-level knowledge explicitly identifies the factors that influence control decisions.
Reference: [28] <author> V. Lesser and L. Erman, </author> <title> "A Retrospective View the Hearsay-II Architecture," </title> <booktitle> Proceedings of IJCAI-77, </booktitle> <pages> pp. 790-800, </pages> <year> 1977. </year>
Reference-contexts: Interpretation problems have typically been approached using blackboard systems. The blackboard model of problem solving is appropriate for sensor interpretation because blackboards support the incremental and opportunistic styles of problem solving that are required for such problems <ref> [3, 5, 8, 28] </ref>. However, despite the power of the blackboard model, most blackboard-based interpretation systems have used a very limited range of strategies for resolving hypothesis uncertainty. Specifically, they have used variations of incremental hypothesize and test that indirectly resolve uncertainty through the aggregation of evidence for the hypotheses. <p> In part, the strategy limitations of blackboard-based interpretation systems are a result of inadequate representations of evidence and uncertainty <ref> [4, 5, 28] </ref>. For instance, the ability to use more sophisticated strategies for resolving uncertainty requires that a system be able to identify when these strategies are applicable. <p> As a result, the framework does not support method search nor intelligent backtracking as the RESUN framework does. The desirability of planning for control of problem-solving systems was recognized early on in blackboard system research. For example, Hearsay-II included special mechanisms that always scheduled certain knowledge sources together <ref> [28] </ref>. The goal-directed blackboard architecture of Corkill and Lesser [12] included subgoaling and precondition-action backchaining mechanisms (that are an implicit part of any planning frameworks), but did not construct plans.
Reference: [29] <author> V. Lesser and D. Corkill, </author> <title> "The Distributed Vehicle Monitoring Testbed: A Tool for Investigating Distributed Problem Solving Networks," </title> <journal> AI Magazine, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 15-33, </pages> <note> 1983 (also in Blackboard Systems, </note> <editor> Robert Engelmore and Tony Morgan, editors. </editor> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1988). </year>
Reference-contexts: We attempted to make these benchmark control strategies correspond to the kinds of strategies that are used in more conventional blackboard systems|e.g., the (earlier versions of the) Distributed Vehicle Monitoring Testbed (DVMT) <ref> [29] </ref>, a system that used a similar vehicle monitoring task.
Reference: [30] <author> V. Lesser, H. Nawab, et al., </author> <title> Integrated Signal Processing and Signal Understanding, </title> <type> Technical Report 91-34, </type> <institution> Computer and Information Science Department, University of Massachusetts, </institution> <year> 1991. </year>
Reference-contexts: The current interpretation methods are defined in terms of more than 30 control plans with about 100 subgoals and approximately 40 primitives. More recently, the RESUN framework has been used in the development of the IPUS (Integrated Processing and Understanding of Signals) signal understanding testbed <ref> [30] </ref>. IPUS is currently being applied to the understanding of household sounds such as would be required by a robot. While this is also an interpretation application, it is different enough from aircraft monitoring that certain features of the RESUN mechanism have been more fully exercised.
Reference: [31] <author> D. McDermott, </author> <title> "Planning and Acting," </title> <journal> Cognitive Science, </journal> <volume> vol. 2, no. 2, </volume> <pages> pp. 71-109, </pages> <year> 1978. </year>
Reference-contexts: Thus, the two steps Identify-Available-Sensors and Choose-Sensor really accomplish the goal of having a sensor that can be activated, so our plans would be written as: (:SEQUENCE Have-Available-Sensor, Have-Activated-Sensor). See <ref> [31] </ref> for a different view of this same issue. As we stated earlier, we believe that a planning approach to control provides an excellent framework for defining and applying complex heuristic control knowledge. <p> On the other hand, because metalevel KAs can be interrupted, PRS is able to place an upper bound on its response time|an important feature for applications like robot control. Relatively few "problem-solving systems" have made use of planning-based control. One early example is McDermott's NASL system <ref> [31] </ref>. NASL was a script-based, incremental planner, but it was neither opportunistic nor reactive. Planning was controlled by choice rules that were indexed/retrieved like plan schemas. The main focus of NASL was to explore a view of planning that is different from the conventional search view.
Reference: [32] <author> H. Nawab and V. Lesser, </author> <title> "Integrated Processing and Understanding of Signals," in Symbolic and Knowledge-Based Signal Processing, </title> <editor> Alan Oppenheim and Hamid Nawab, editors. </editor> <address> New York: </address> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: One of the key differences is that in IPUS the basic data from sampling the environment can be processed multiple times using a number of algorithms and parameter settings. Reprocessing of data must be tightly controlled; driven by particular uncertainties in the developing high-level models <ref> [32] </ref>. As we said in the introduction, the question of how well a problem solver supports the use of sophisticated control strategies is largely an issue of heuristic adequacy. Because of this, it is difficult to make definitive statements about the RESUN control planner from any limited set of experiments.
Reference: [33] <author> E. Rich and K. Knight, </author> <booktitle> Artificial Intelligence. </booktitle> <address> New York: </address> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: This is due to the lack of (tractable) optimal decision procedures for AI problems and/or uncertainty in the information that is necessary to make optimal decisions (e.g., models of the state of the world, applicability of operators). As a result, AI problem solving often involves heuristic search <ref> [33] </ref>. When we refer to "AI problem-solving systems" in this paper, we are specifically referring to systems that solve problems via heuristic search. The performance of AI problem solvers that use heuristic search is dependent on the knowledge they can apply to control search. <p> The final two subsections of this section look in more detail at the kinds of actions that are used in the system and the way control plan schemas are defined. 3.1 Goals and Interpretation Uncertainty Since planning involves problem reduction <ref> [33] </ref>, a planning-based approach to control requires that the subgoals the system must accomplish if it is to satisfy its overall goal be made explicit (and those subgoals must be decomposable). RESUN supports the creation of explicit subgoals through its model of the uncertainty in (abductive) interpretation inferences.
Reference: [34] <editor> W. Swartout, editor, </editor> <title> "Report: DARPA Santa Cruz Workshop on Planning," </title> <journal> AI Magazine, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 115-131, </pages> <year> 1988. </year>
Reference-contexts: One response to the combinatorics of classical planning and its problems in dealing with uncertain and dynamic situations has been to go to the other extreme and argue that planning is not needed at all. In the reactive control or situated action approach <ref> [1, 34] </ref>, actions result from rules or procedures whose invocation is based solely on properties of the immediate situation.
Reference: [35] <author> R. Washington and B. Hayes-Roth, </author> <title> "Input Data Management in Real-Time AI Systems," </title> <booktitle> Proceedings of IJCAI-89, </booktitle> <pages> pp. 250-255, </pages> <year> 1989. </year>
Reference-contexts: A second level of planning is then used to choose knowledge source sequences to meet these intermediate-level goals. Because both the data abstraction model and the planning mechanism here are closely tied to vehicle tracking, though, their application is limited. The BB1 system <ref> [22, 23, 24, 35] </ref> is the first blackboard framework to use a true planning-based approach to control and it remains one of the most sophisticated blackboard control frameworks. The control planning mechanism of BB1 extends the blackboard model with a separate control blackboard and control knowledge sources.
Reference: [36] <author> D. Wilkins, </author> <title> Practial Planning: Extending the Classical AI Planning Paradigm. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman, </publisher> <year> 1988. </year> <month> 32 </month>
Reference-contexts: Thus, when we speak about whether or not a problem solver "supports" the use of sophisticated control strategies, we are talking about the notion of heuristic adequacy (being "efficient enough to be useful in practice" <ref> [36] </ref>) rather than any absolute ability/inability to implement particular search strategies. In this paper we will examine the use of planning-based 1 approaches for the control of AI problem-solving systems and we will present a new planning-based control framework that was developed for the RESUN interpretation system. <p> By constrast, strate 1 We use the term "planning-based" here to distinguish our sense of the term "planning" from the more restricted sense in which it is used in "classical planning" research|see <ref> [36] </ref>. <p> First of all, it is important to understand that "classical planning" research <ref> [36] </ref> is not generally appropriate for the control of problem-solving systems because it involves strategic planning: determining a complete sequence of actions that solve a problem prior to taking any actions. <p> Strategic planners are not useful for applications in which blackboard systems would typically be used because the situations are too uncertain and/or dynamic to permit problem solving actions to be completely pre-planned. In other words, the problem with classical planners is that they are neither opportunistic nor reactive <ref> [36] </ref>. Recently there has been a significant amount of research on reactive planning [16, 18] and on the interleaving of planning and execution [26]. As we will see, these types of approaches can make planning appropriate for the control of problem-solving systems. <p> Opportunstic control means being able to take advantage of new information or situations to change strategies and improve problem solving performance. Reactive control means being able to "react in an acceptable amount of time to any changes that occur in the world" <ref> [36] </ref>. To be opportunstic in a domain with real-time constraints requires that a system be reactive. However, 6 section we will discuss the need for explicit goals in planning-based systems and the way that RESUN identifies its goals. The next subsection will illustrate the basic planning mechanism. <p> Making a planner script-based makes the planning process more tractable because the use of plan schemas limits the "reasoning about actions" that is a major source of combinatorial complexity in classical planners <ref> [36] </ref>. However, it is important to note that planning is still a combinatorial problem due to uncertainty about the best plans to use to satisfy subgoals and the best plan-versions (method instances) to be pursued. In other words, script-based planning still involves search. <p> Failure to specify satisfaction conditions does not change the semantics of a plan, it merely means that goals may be achieved multiple times by the control process. In classical planners, detecting and handling subgoal interactions is a major source of complexity <ref> [36] </ref>. Because of the uncertainty in most problem solving domains, we limit the consideration of subgoal interactions during the plan expansion and refinement process. <p> The use of explicit information gathering actions enhances the reactivity of the planner in two different ways. First, tractability of the planner is enhanced because the system does not maintain a complete world model (this is a major source of complexity in classical planners due to the frame problem <ref> [36] </ref>). The RESUN planner maintains only partial state information through the variable bindings in the individual plans; each plan models just what it needs to know about the world and keeps it sufficiently up-to-date with information gathering actions.
References-found: 36

