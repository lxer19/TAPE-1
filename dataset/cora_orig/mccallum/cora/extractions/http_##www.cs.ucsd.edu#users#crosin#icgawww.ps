URL: http://www.cs.ucsd.edu/users/crosin/icgawww.ps
Refering-URL: http://www.cs.ucsd.edu/users/crosin/
Root-URL: http://www.cs.ucsd.edu
Email: fcrosin,rikg@cs.ucsd.edu  
Title: Methods for Competitive Co-evolution: Finding Opponents Worth Beating  
Author: Christopher D. Rosin Richard K. Belew 
Degree: (Submitted to ICGA 95)  
Address: La Jolla, CA 92093-0114  
Affiliation: Cognitive Computer Science Research Group Department of Computer Science and Engineering University of California, San Diego  
Abstract: Co-evolution refers to the simultaneous evolution of two or more genetically distinct populations with coupled fitness landscapes. In this paper we consider "competitive co-evolution," in which the fitness of an individual in a "host" population is based on direct competition with individual(s) from a "parasite" population. Competitive coevolution is applied to three game-learning problems: Tic-Tac-Toe (TTT), Nim and a small version of Go. Two new techniques in competitive co-evolution are explored. "Competitive fitness sharing" changes the way fitness is measured, and "shared sampling" alters the way parasites are chosen for testing hosts. Experiments using TTT and Nim show a substantial improvement in performance when these methods are used. Preliminary results using co-evolution for the discovery of cellular automata rules for playing Go are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Angeline, P.J., and J.B. Pollack. </author> <title> Competitive Environments Evolve Better Solutions for Complex Tasks. </title> <booktitle> In Proceedings of the Fifth International Conference on Genetic Algorithms Morgan Kaufmann, </booktitle> <year> 1993. </year>
Reference-contexts: It also arises in the evolution of AI game-playing strategies where the range of potential strategies makes it difficult to establish the sort of fixed, "exogenous" fitness function typically used in genetic algorithms (GAs) <ref> [1] </ref>. More generally, a number of situations arise in complex software engineering applications where the construction of appropriate test suites to demonstrate the reliability of software is considered almost as important as the development of the software itself. <p> fitness is being measured and when it is being used to measure fitness, respectively. 2.1 Competitive Fitness Sharing The usual way to assign fitness based on success in a set of competitions is to add up the score in all competitions (where score is often a binary value indicating success/failure) <ref> [1, 8, 2] </ref>. This will be called "simple fitness" here. A different method, similar to fitness sharing, is also tested here, and improves performance on the test problems. In fitness sharing [7] a sharing function is defined, to measure similarity between individuals. <p> First, our genomic representation assumes no knowledge about or searching of the games' underlying tree structure. Furthermore, the GA must also solve the problem of finding good parasites to test candidate strategies in order to solve the games. In <ref> [1] </ref>, evolving TTT strategies in a competitive environment was found to be a difficult problem (under a different representation, and without symmetries eliminated, though). 3.2 Genetic Algorithm In all TTT and Nim experiments presented here, two populations compete.
Reference: [2] <author> Axelrod, R. </author> <title> Evolution of Strategies in the Iterated Prisoner's Dilemma. In Genetic Algorithms and Simulated Annealing Morgan Kaufmann, </title> <year> 1989. </year>
Reference-contexts: Such interactions have been hypothesized to occur in nature and modelled by game-theoretic constructions such as Maynard Smith's "evolutionary stable strategies," [10] and the Prisoners' Dilemma <ref> [2] </ref>. It also arises in the evolution of AI game-playing strategies where the range of potential strategies makes it difficult to establish the sort of fixed, "exogenous" fitness function typically used in genetic algorithms (GAs) [1]. <p> By viewing the software solutions as one population and the test 1 suites as another, competitive co-evolution allows the simultaneous search for both [8]. Note that there is a distinction between domains where the competition is symmetric (games such as Prisoners' Dilemma, for example <ref> [2] </ref>), and domains where it is asymmetric (for example, with a solution / test case distinction). Games (such as the ones used in this paper) may also be asymmetric; this can be due, for example, to the advantage enjoyed by the first player to move. <p> fitness is being measured and when it is being used to measure fitness, respectively. 2.1 Competitive Fitness Sharing The usual way to assign fitness based on success in a set of competitions is to add up the score in all competitions (where score is often a binary value indicating success/failure) <ref> [1, 8, 2] </ref>. This will be called "simple fitness" here. A different method, similar to fitness sharing, is also tested here, and improves performance on the test problems. In fitness sharing [7] a sharing function is defined, to measure similarity between individuals.
Reference: [3] <author> Bedau, M.A., and N.H. Packard. </author> <title> Measurement of Evolutionary Activity, </title> <booktitle> Teleology, 11 and Life. In Artificial Life II Addison-Wesley, </booktitle> <year> 1991. </year>
Reference-contexts: Extinction events are typically fairly rare, but there are fewer extinction events when sharing and shared sampling are used. 4.2 Typical Runs both populations during one run, in which shar 2 This brings the measure in closer correspondence with gene usage <ref> [3] </ref>. ing and shared sampling of 10% of the parasite population were used. TTT is the easier of the two problems: with parameters tuned well, perfect solutions could be found after about 1.5 million game-pairs (3 million games).
Reference: [4] <author> Berlekamp, E.R., J.H. Conway and R.K. Guy. </author> <title> Winning Ways for Your Mathematical Plays Academic Press, </title> <year> 1982. </year>
Reference-contexts: Players alternate removing an arbitrary number of stones from a single pile. The player to take the last stone wins. The configuration used here starts with 4 piles, containing 3, 4, 5, and 4 stones. This configuration allows the first player to force a win with optimal play <ref> [4] </ref>. The representation used for both games has each gene corresponding to a single position in the game. In TTT, symmetric positions are removed, and the genes are ordered on the genome in the following, rather arbitrary way.
Reference: [5] <author> Dawkins, R. The Blind Watchmaker Norton, </author> <year> 1986. </year>
Reference-contexts: Repeated failure by either host or parasite populations represents an evolutionary challenge that can lead to an evolutionary "arms race" <ref> [5] </ref>. New genotypes arise to defeat old ones. From the perspective of GA engineers, we desire that this process go on indefinitely. Each new parasite type should serve as a drive towards further innovation, creating ever-greater levels of complexity and performance.
Reference: [6] <author> Durham, T. </author> <title> "A program with a touch of Zen". </title> <booktitle> In Computing Horizons Addison-Wesley, </booktitle> <year> 1985. </year>
Reference-contexts: For these reasons, cellular automata (CA) seem to provide a natural representation of strategies for the game. Hand-designed cellular automata rules have been used in a program written by Al-lan Scarff, apparently with some success <ref> [6] </ref>. Here, each intersection on the Go board corresponds to one cell in the CA. Each cell contains 8 bits of state, all of which may be modified by the action of evolved rules.
Reference: [7] <author> Goldberg, D.E. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley, </title> <year> 1989. </year>
Reference-contexts: This will be called "simple fitness" here. A different method, similar to fitness sharing, is also tested here, and improves performance on the test problems. In fitness sharing <ref> [7] </ref> a sharing function is defined, to measure similarity between individuals. An individual's fitness is then divided by the sum of its similarities with each other individual in the population. This rewards unusual individuals.
Reference: [8] <author> Hillis, W.D. </author> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <booktitle> In Artificial Life II Addison-Wesley, </booktitle> <year> 1991. </year>
Reference-contexts: By viewing the software solutions as one population and the test 1 suites as another, competitive co-evolution allows the simultaneous search for both <ref> [8] </ref>. Note that there is a distinction between domains where the competition is symmetric (games such as Prisoners' Dilemma, for example [2]), and domains where it is asymmetric (for example, with a solution / test case distinction). <p> fitness is being measured and when it is being used to measure fitness, respectively. 2.1 Competitive Fitness Sharing The usual way to assign fitness based on success in a set of competitions is to add up the score in all competitions (where score is often a binary value indicating success/failure) <ref> [1, 8, 2] </ref>. This will be called "simple fitness" here. A different method, similar to fitness sharing, is also tested here, and improves performance on the test problems. In fitness sharing [7] a sharing function is defined, to measure similarity between individuals.
Reference: [9] <editor> Levy, D. (editor). </editor> <publisher> Computer Games Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: A description of the game, and some of the early work in getting computers to play it, can be found in <ref> [9] </ref>. The game involves placing stones at intersections on a grid. Go is fairly visual, and playing seems to involve much intuitive pattern matching. In addition, some properties of the game are nearly invariant of position on the grid.
Reference: [10] <author> Maynard Smith, J. </author> <title> Evolution and the Theory of Games Cambridge University Press, </title> <year> 1992. </year>
Reference-contexts: Such interactions have been hypothesized to occur in nature and modelled by game-theoretic constructions such as Maynard Smith's "evolutionary stable strategies," <ref> [10] </ref> and the Prisoners' Dilemma [2]. It also arises in the evolution of AI game-playing strategies where the range of potential strategies makes it difficult to establish the sort of fixed, "exogenous" fitness function typically used in genetic algorithms (GAs) [1].
Reference: [11] <author> Schraudolph, N.N., P. Dayan, and T.J. Se-jnowski. </author> <title> Temporal Difference Learning of Position Evaluation in the Game of Go. </title> <note> In Neural Information Processing Systems 6 Morgan Kaufmann, 1994. 12 </note>
Reference-contexts: Fitness sharing, and a shared sample of 15 opponents, were used. To evaluate the success of evolved strategies, they were tested against Wally, a weak public-domain Go-playing program that has been used by other authors to test learned Go strategies <ref> [11] </ref>. After about 250 generations, some of the best strategies were able to consistently defeat Wally. These strategies were still not very good, though.
References-found: 11

