URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1998/tr-98-010.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1998.html
Root-URL: http://www.icsi.berkeley.edu
Title: Geospatial Information Extraction: Querying or Quarrying?  
Author: Agnes Voisard Marcus Jurgens 
Address: Berlin, Takustr. 9, D-14195 Berlin, Germany.  Berlin, Garystr. 21, D-14195 Berlin, Germany.  
Affiliation: Institute of Computer Science, Freie Universitat  Institute of Statistics and Econometrics, Freie Universitat  
Note: Author's permanent address:  Author's permanent address:  
Pubnum: TR-98-010  
Email: E-mail: voisard@inf.fu-berlin.de  E-mail: juergens@inf.fu-berlin.de  
Date: April 1998  
Abstract: We focus here on the access to multiple, distributed, heterogeneous and autonomous information sources storing geospatial data and we study alternatives to integrate them. Common solutions to data integration in the database area nowadays are the data warehouse approach and the wrapper/mediator approach. None of them is really satisfactory to handle a large range of geospatial applications. In this paper we present a novel hybrid approach to data integration based on the two popular paradigms. We believe that such architectures will be of major importance in the geospatial applications of the near future. 
Abstract-found: 1
Intro-found: 1
Reference: [GCB + 97] <author> H. Gray, S. Chaudhuri, A. Bosworth, A. Layman, D. Reichart, and M. Venkatrao. </author> <title> Data cube: A relational aggregation operator generalizing group-by, </title> <journal> cross-tab, and sub-totals. Data Mining and Knowledge Discovery, </journal> <volume> 1(1) </volume> <pages> 29-53, </pages> <year> 1997. </year>
Reference-contexts: It should be mentioned that in this example, there exist group by operations over calculated values that are not supported by standard SQL. The extension of SQL with a cube operator to overcome this problem is discussed in <ref> [GCB + 97] </ref>. One way to avoid using a group by over calculated values is to consider a star schema. In a star schema the dimensions are not directly stored in the fact tables but in dimension tables.
Reference: [GMHI + 95] <author> H. Garcia-Molina, J. Hammer, K. Ireland, Y. Papakonstantinou, J. Ullman, and J. Widom. </author> <title> Integrating and accessing heterogeneous information sources in TSIM-MIS. </title> <booktitle> In Proceedings of the AAAI Symposium on Information Gathering, </booktitle> <pages> pages 61-64, </pages> <year> 1995. </year>
Reference-contexts: Data conversion works both ways. Queries from Section 2. Common approaches to data integration 4 the mediator are transformed to queries understood by the sources and data from the sources is converted to a format processable by the mediator <ref> [GMHI + 95] </ref> (Step 3). In such systems, the results are collected from the information sources and the mediator performs translation, filtering and merging of data before returning the answer to the client. A mediator is a software module that refines in some way information from one or more sources.
Reference: [Gut88] <author> R. H. Guting. </author> <title> Geo-relational algebra: A model and query language for geometric database systems. </title> <editor> In J. W. Schmidt, S. Ceri, and M. Missikoff, editors, </editor> <booktitle> Advances in Database Technology. Proceedings of the International Conference on Extending Database Technology (EDBT'88), Lecture Notes in Computer Science No. </booktitle> <volume> 951, </volume> <pages> pages 506-527, </pages> <address> Berlin/New York, 1988. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: R-prec-a keeps the actual precipitation and R-prec-p contains the predicted weather map. We assume that these maps are stored in relations whose schema is given below. Regarding attribute types, we assume the existence of basic types and of geospatial types, such as point, line and region <ref> [Gut88, SV89] </ref>. Timestamp is a combination of types time and date. * R-alt (Location: point, Altitude: real) * R-water (Rivername: string, Area: region) Section 3.
Reference: [Han97] <author> J. Han. </author> <title> Spatial data mining and spatial data warehousing. </title> <booktitle> Tutorial Notes of the International Symposium on Spatial Databases (SSD'97), </booktitle> <address> Berlin, Germany, </address> <year> 1997. </year>
Reference-contexts: An important issue concerns the geospatial data warehouse organization itself, both at a logical and at a physical level. For instance, issues such as the adaptability of such systems to various applications and time-space trade-offs still need to be addressed. <ref> [Han97] </ref> shows a first step towards that direction with selective materialization, based on the fact that computing on the fly is expensive, saving all combinations has a huge space overhead and that rough approximations lead to accuracy problems.
Reference: [Inm96] <author> W. H. Inmon. </author> <title> Building the Data Warehouse. </title> <publisher> Wiley Computer Publishing, </publisher> <address> New York, 2nd edition, </address> <year> 1996. </year>
Reference-contexts: geospatial applications in order to illustrate their use, before studying the main differences between the two solutions. 2.1 Eager approach (data warehouse) In the eager or in-advance approach, data is integrated in advance in a data warehouse, which is defined as a subject-oriented, integrated, non-volatile and time-variant collection of data <ref> [Inm96] </ref>. It allows the multidimensional storage of data. A common integrator component extracts data sets from different sources and integrates them before sending them to the warehouse. Figure 1 illustrates this approach. <p> Such analysis would be difficult with the pure mediator approach. Geospatial applications dealing with analysis over time gain from using a data warehouse. In such systems the life-expectancy of data is 5-10 years (compared to 60-90 days in operational systems <ref> [Inm96] </ref>). In some applications such as the ones handled by decision support systems (DSS), expected response time is usually relaxed and the order is minutes or hours. Hence the analogy with "quarrying data".
Reference: [LS97] <author> H. J. Lenz and A. Shoshani. </author> <title> Summarizability in OLAP and statistical data bases. </title> <booktitle> In Proceedings of 9th International Conference on Statistical and Scientific Database Management. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1997. </year>
Reference-contexts: Sets of locations (points) could be summarized to regions and, for example, the average precipitation per region could be calculated. It could also be aggregated over both time and space at each possible aggregation level. However, the type of data that can be summarized has to be carefully chosen. <ref> [LS97] </ref> defines a framework and a set of conditions for summarizability of data in statistical databases and OLAP. 3.3 Configuring parameters: A qualitative approach Within this mixed solution, the criteria for using either mechanism are based on infrastructure, i.e., on the characteristics of the networks and the collection of data sources,
Reference: [MQM97] <author> Inderpal Singh Mumick, Dallan Quass, and Barinderpal Singh Mumick. </author> <title> Maintenance of data cubes and summary tables in a warehouse. </title> <booktitle> SIGMOD Record (ACM Special Interest Group on Management of Data), </booktitle> <volume> 26(2) </volume> <pages> 100-110, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Results of aggregation are calculated in advance during times when the system is not used for analysis (e.g. during nights or weekends). They are stored in summary tables <ref> [MQM97] </ref>. The more data is aggregated, the faster can queries be processed, but the higher are update and storage costs. [WGL + 96] presents algorithms for selection of summary tables and indices. Aggregation is appropriate when clients require specific predictable portions of information.
Reference: [SR95] <author> M. Scholl and P. Rigaux. </author> <title> Multi-scale partitions: Applications to spatial and statistical databases. </title> <editor> In M. J. Egenhofer and J. Herring, editors, </editor> <booktitle> Proceedings of the 4th International Symposium on Spatial Databases (SSD'95), Lecture Notes in Computer Science No. </booktitle> <volume> 951, </volume> <pages> pages 170-183, </pages> <address> Berlin/New York, 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Conceptual models to describe hierarchies in many dimensions (e.g., time and space) are also missing. These models encompass aggregation rules in addition to geospatial objects. Work from the statistical database community could be adapted to take the notion of space into account, as initiated by <ref> [SR95] </ref>. Another issue concerns the granularity and the partitioning of data. What level of detail has to be shown? How to break the data into separate physical units that are handled independently? Data can be partitioned by date, organizational units, geography, and clustered according to users' needs.
Reference: [SV89] <author> M. Scholl and A. Voisard. </author> <title> Thematic map modeling. </title> <editor> In A. Buchman, O. Gunther, T.R. Smith, and Y.F. Yang, editors, </editor> <title> Design and Implementation of Large Spatial Databases, </title> <booktitle> First Symposium SSD'89, Lecture Notes in Computer Science No. </booktitle> <volume> 409, </volume> <pages> pages 167-192, </pages> <address> Berlin/New York, 1989. </address> <publisher> Springer-Verlag. </publisher> <address> References 15 </address>
Reference-contexts: R-prec-a keeps the actual precipitation and R-prec-p contains the predicted weather map. We assume that these maps are stored in relations whose schema is given below. Regarding attribute types, we assume the existence of basic types and of geospatial types, such as point, line and region <ref> [Gut88, SV89] </ref>. Timestamp is a combination of types time and date. * R-alt (Location: point, Altitude: real) * R-water (Rivername: string, Area: region) Section 3.
Reference: [WGL + 96] <author> J. Wiener, H. Gupta, W. Labio, Y. Zhuge, H. Garcia-Molina, and J. Widom. </author> <title> System prototype for warehouse view maintenance. </title> <booktitle> In Proceedings of the ACM Workshop on Materialized Views: Techniques and Applications, </booktitle> <pages> pages 26-33, </pages> <year> 1996. </year>
Reference-contexts: Results of aggregation are calculated in advance during times when the system is not used for analysis (e.g. during nights or weekends). They are stored in summary tables [MQM97]. The more data is aggregated, the faster can queries be processed, but the higher are update and storage costs. <ref> [WGL + 96] </ref> presents algorithms for selection of summary tables and indices. Aggregation is appropriate when clients require specific predictable portions of information.
Reference: [Wid97] <author> J. Widom. </author> <title> Research problems in data warehousing. </title> <booktitle> In Proceedings of the 4th International Conference on Information and Knowledge Management (CIKM'95), </booktitle> <year> 1997. </year>
Reference-contexts: In the sequel we refer to these actions as 3-step data handling. In the database area, common approaches to data integration are as follows <ref> [Wid97] </ref>: In the eager approach, data is collected in a data warehouse, which allows direct querying and analysis. The query-driven or lazy approach, on the other hand, hinges on the concepts of a mediator together with wrappers built on top of the participating repositories.
References-found: 11

