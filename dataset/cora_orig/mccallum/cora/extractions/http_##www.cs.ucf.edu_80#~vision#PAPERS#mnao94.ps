URL: http://www.cs.ucf.edu:80/~vision/PAPERS/mnao94.ps
Refering-URL: http://www.cs.ucf.edu:80/~vision/tech_papers.html
Root-URL: 
Email: email: ftian, shahg@cs.ucf.edu  
Title: A General Approach for Determining 3D Motion and Structure of Multiple Objects from Image Trajectories  
Author: Tina Yu Tian and Mubarak Shah 
Address: Orlando, FL 32816  
Affiliation: Austin, Texas.  Computer Vision Lab, Computer Science Department University of Central Florida,  
Date: November 11-12, 1994,  
Note: To appear in IEEE WORKSHOP ON MOTION OF NON-RIGID AND ARTICULATED OBJECTS,  
Abstract: We present a general approach to determine 3D motion and structure of multiple objects undergoing arbitrary motions. We segment the scene based on 3D motion parameters. First, the general motion model is fitted to each single trajectory. For this nonlinear fitting, initial estimtes are obtained by a linear multiple motion SFM algorithm using the first two frames. Next, trajectories are clustered into groups corresponding to different moving objects. In our approach, discontinuous trajectories, resulting from occlusion, are also allowed. Finally, the multiple trajectory fitting is applied to each trajectory group to improve the estimates further. Our simulation results show that the proposed method is robust. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Adiv. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. </title> <journal> PAMI, </journal> <volume> 7 </volume> <pages> 384-401, </pages> <year> 1985. </year>
Reference-contexts: However, segmentation using displacement field itself cannot distinguish between real motion boundaries and depth disconti-nuities. Another approach for segmentation is based on the set of coherent motion parameters, independent of depth values. This approach (e.g. <ref> [1, 5, 7] </ref>) exploits 2D parametric motion approximations, ignoring the higher-order information of the displacement vector, and thus yields incorrect motion segmentation. Moreover, using a 2D motion model to segment a 3D scene can lead to ambiguities. Methods in [4] and [9] belong to multi-frame approaches for multiple motions.
Reference: [2] <author> A. Azarbayejani, T. Starner, B. Horowitz, and A. Pentland. </author> <title> Visually controlled graphics. </title> <journal> PAMI, </journal> <volume> 15 </volume> <pages> 602-605, </pages> <year> 1993. </year>
Reference-contexts: Most of the existing multi-frame SFM algorithms (e.g. <ref> [3, 6, 2] </ref>) deal with a single moving object (ego-motion). For multiple motions, a straightforward method is to segment the displacement field or 2D trajectories first, and then apply an ego-motion SFM algorithm to each moving object.
Reference: [3] <author> T. Broida and R. Chellappa. </author> <title> Estimating the kinematics and structure of a rigid object from a se (a) (b) against different noise levels. (a) Translation error. (b) Relative rotation error. (c) Relative depth error. quence of monocular images. </title> <journal> PAMI, </journal> <volume> 13 </volume> <pages> 497-513, </pages> <year> 1991. </year>
Reference-contexts: Most of the existing multi-frame SFM algorithms (e.g. <ref> [3, 6, 2] </ref>) deal with a single moving object (ego-motion). For multiple motions, a straightforward method is to segment the displacement field or 2D trajectories first, and then apply an ego-motion SFM algorithm to each moving object. <p> To facilitate the minimization, we define our objective function as the error between the expected 3D positions of imaged and measured features, rather than as 2D projection error as in <ref> [3] </ref>. Let h t (a) be the 3D coordinates of a point at time t, given parameter a.
Reference: [4] <author> C. Debrunner, and N. Ahuja. </author> <title> Motion and Structure Factorization and Segmentation of Long Multiple Motion Image Sequences. </title> <booktitle> In ECCV'92, </booktitle> <pages> pp. 217-221, </pages> <year> 1992. </year>
Reference-contexts: This approach (e.g. [1, 5, 7]) exploits 2D parametric motion approximations, ignoring the higher-order information of the displacement vector, and thus yields incorrect motion segmentation. Moreover, using a 2D motion model to segment a 3D scene can lead to ambiguities. Methods in <ref> [4] </ref> and [9] belong to multi-frame approaches for multiple motions. In [4], an orthographic factorization-based method was used to compute motion and structure for a single object, and split and merge processes were repeatly performed to partition trajectories into groups corresponding to different objects. <p> Moreover, using a 2D motion model to segment a 3D scene can lead to ambiguities. Methods in <ref> [4] </ref> and [9] belong to multi-frame approaches for multiple motions. In [4], an orthographic factorization-based method was used to compute motion and structure for a single object, and split and merge processes were repeatly performed to partition trajectories into groups corresponding to different objects. In [9], 3D line segments obtained from stereo were used as tokens, which greatly simplies the problem.
Reference: [5] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using temporal integration. </title> <booktitle> In ECCV'92, </booktitle> <pages> pp. 282-287, </pages> <year> 1992. </year>
Reference-contexts: However, segmentation using displacement field itself cannot distinguish between real motion boundaries and depth disconti-nuities. Another approach for segmentation is based on the set of coherent motion parameters, independent of depth values. This approach (e.g. <ref> [1, 5, 7] </ref>) exploits 2D parametric motion approximations, ignoring the higher-order information of the displacement vector, and thus yields incorrect motion segmentation. Moreover, using a 2D motion model to segment a 3D scene can lead to ambiguities. Methods in [4] and [9] belong to multi-frame approaches for multiple motions.
Reference: [6] <author> H. Sawhney, J. Oliensis, and A. Hanson. </author> <title> Image description and 3-d reconstruction from image trajectories of rotational motion. </title> <journal> PAMI, </journal> <volume> 15 </volume> <pages> 885-898, </pages> <year> 1993. </year>
Reference-contexts: Most of the existing multi-frame SFM algorithms (e.g. <ref> [3, 6, 2] </ref>) deal with a single moving object (ego-motion). For multiple motions, a straightforward method is to segment the displacement field or 2D trajectories first, and then apply an ego-motion SFM algorithm to each moving object.
Reference: [7] <author> J. Wang and E. Adelson. </author> <title> Layer representation for motion analysis. </title> <booktitle> In CVPR'93, </booktitle> <pages> pp. 361-366, </pages> <year> 1993. </year>
Reference-contexts: However, segmentation using displacement field itself cannot distinguish between real motion boundaries and depth disconti-nuities. Another approach for segmentation is based on the set of coherent motion parameters, independent of depth values. This approach (e.g. <ref> [1, 5, 7] </ref>) exploits 2D parametric motion approximations, ignoring the higher-order information of the displacement vector, and thus yields incorrect motion segmentation. Moreover, using a 2D motion model to segment a 3D scene can lead to ambiguities. Methods in [4] and [9] belong to multi-frame approaches for multiple motions.
Reference: [8] <author> J. Weng, T. Huang, and N. Ahuja. </author> <title> Motion and structure from two perspective views: Algorithms, error analysis, and error estimation. </title> <journal> PAMI, </journal> <volume> 11 </volume> <pages> 451-476, </pages> <year> 1989. </year>
Reference-contexts: Our method consists of five modules. The first module generates trajectories from image correspondence of feature points by tracking over multiple frames. The second module computes the initial guess for the single trajectory fitting module by using two-frame multiple motion SFM algorithm (extended from <ref> [8] </ref>), in order to avoid being trapped into a local minimum and to speed up the convergence. The third module fits a general motion model to each trajectory, the fourth module groups trajectories into sets corresponding to each moving object and merges the "broken" trajectories, caused by occlusion. <p> There are a number of algorithms which can provide a closed-form solution for motion and structure estimation. We have chosen Weng et al.'s linear algorithm <ref> [8] </ref> based on epipolar constraint, because of its simplicity, and have extended their method to deal with multiple motions. We subdivide the image into overlapping patches. The algorithm is as follows: Algorithm: InitGuess 1. <p> We subdivide the image into overlapping patches. The algorithm is as follows: Algorithm: InitGuess 1. For each overlapping patch, (a) Count the number of feature points, n, in side the patch. (b) If n 8, apply Weng et al.'s algorithm <ref> [8] </ref> to the set of feature points in the patch, and compute motion parameters. (c) If the smallest eigenvalue of A &gt; A, (representing the residual error of the optimization function A &gt; A, where A is given in the following form is large (this implies that the patch contains multiple
Reference: [9] <author> Z. Zhang and O. Faugeras. </author> <title> Three-Dimensional Motion Computation and Object Segmentation in a Long Sequence of Stereo Frames. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7:3, </volume> <pages> 211-241, </pages> <year> 1992. </year>
Reference-contexts: This approach (e.g. [1, 5, 7]) exploits 2D parametric motion approximations, ignoring the higher-order information of the displacement vector, and thus yields incorrect motion segmentation. Moreover, using a 2D motion model to segment a 3D scene can lead to ambiguities. Methods in [4] and <ref> [9] </ref> belong to multi-frame approaches for multiple motions. In [4], an orthographic factorization-based method was used to compute motion and structure for a single object, and split and merge processes were repeatly performed to partition trajectories into groups corresponding to different objects. In [9], 3D line segments obtained from stereo were <p> Methods in [4] and <ref> [9] </ref> belong to multi-frame approaches for multiple motions. In [4], an orthographic factorization-based method was used to compute motion and structure for a single object, and split and merge processes were repeatly performed to partition trajectories into groups corresponding to different objects. In [9], 3D line segments obtained from stereo were used as tokens, which greatly simplies the problem. A kinematic model was fitted for each token by extended Kalman filter, and tokens were grouped into objects based on Mahalanobis distance of kinematic parameters.
References-found: 9

