URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P446.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Title: Stability of Augmented System Factorizations in Interior-Point Methods  
Author: Stephen Wright 
Affiliation: MATHEMATICS AND COMPUTER SCIENCE DIVISION, ARGONNE NATIONAL LABORATORY  
Note: PREPRINT MCS-P446-0694,  
Date: July 7, 1995  
Abstract: Some implementations of interior-point algorithms obtain their search directions by solving symmetric indefinite systems of linear equations. The conditioning of the coefficient matrices in these so-called augmented systems deteriorates on later iterations, as some of the diagonal elements grow without bound. Despite this apparent difficulty, the steps produced by standard factorization procedures are often accurate enough to allow the interior-point method to converge to high accuracy. When the underlying linear program is nondegenerate, we show that convergence to arbitrarily high accuracy occurs, at a rate that closely approximates the theory. We also explain and demonstrate what happens when the linear program is degenerate, where convergence to acceptable accuracy (but not arbitrarily high accuracy) is usually obtained. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bunch and L. Kaufman, </author> <title> Some stable methods for calculating inertia and solving symmetric linear systems, </title> <journal> Mathematics of Computation, </journal> <volume> 31 (1977), </volume> <pages> pp. 163-179. </pages>
Reference-contexts: Specifically, the search direction (; x; s) satisfies the linear equations 2 4 A 0 0 3 5 6 x s 7 2 4 b Ax 3 5 ; (5) where oe 2 <ref> [0; 1] </ref> is known as the centering parameter and the important quantity is defined by The step length ff along the search direction is determined by various factors; minimally, the updated x and s components are required to stay strictly positive: (x; s) + ff (x; s) &gt; 0: (6) At <p> In the following theorem, we specify a set of conditions for which this happy situation holds. In later sections, we identify situations under which these conditions hold. In the remainder of the paper, we use ff fl to denote the largest number in <ref> [0; 1] </ref> such that (x + ffx; s + ffs) 0 for all ff 2 [0; ff fl ]; (17a) (x + ffx) T (s + ffs) is decreasing for ff 2 [0; ff fl ]: (17b) Theorem 4.1 Suppose that Assumption 1 holds. <p> Then for all sufficiently small, we have 1 ff fl = O (); (19) and Proof. From (11a) and (18a), we have s N + ffs N &gt; 0; x B + ffx B &gt; 0; for all ff 2 <ref> [0; 1] </ref>, so these components do not restrict the value of ff fl . <p> Since u is much smaller than 1, we use (18b) as well to deduce that s N + ff d s N s N + ffs N + ff ( d s N s N ) &gt; 0; for all ff 2 <ref> [0; 1] </ref>. Similarly, we can show that x B + ff d x B &gt; 0 for all ff 2 [0; 1]. For the decrease condition (17b) we show that the duality gap actually decreases over the entire interval [0; 1] for both exact and approximate search directions, so that this <p> to deduce that s N + ff d s N s N + ffs N + ff ( d s N s N ) &gt; 0; for all ff 2 <ref> [0; 1] </ref>. Similarly, we can show that x B + ff d x B &gt; 0 for all ff 2 [0; 1]. For the decrease condition (17b) we show that the duality gap actually decreases over the entire interval [0; 1] for both exact and approximate search directions, so that this condition does not play a role in determining ff fl or ^ff fl . <p> s N s N ) &gt; 0; for all ff 2 <ref> [0; 1] </ref>. Similarly, we can show that x B + ff d x B &gt; 0 for all ff 2 [0; 1]. For the decrease condition (17b) we show that the duality gap actually decreases over the entire interval [0; 1] for both exact and approximate search directions, so that this condition does not play a role in determining ff fl or ^ff fl . <p> For the exact direction, we have from (5), (18a), and oe 2 [0; 1=2] that d (x + ffx) T (s + ffs) = x T s + s T x + 2ffx T s (1 oe)n + 2kxkksk n=2 + O ( 2 ); for all ff 2 <ref> [0; 1] </ref>. Hence, for sufficiently small, the duality gap is decreasing over [0; 1]. For the approximate direction ( d x; d s), this bound can be modified slightly to account for the inexactness. <p> 2 [0; 1=2] that d (x + ffx) T (s + ffs) = x T s + s T x + 2ffx T s (1 oe)n + 2kxkksk n=2 + O ( 2 ); for all ff 2 <ref> [0; 1] </ref>. Hence, for sufficiently small, the duality gap is decreasing over [0; 1]. For the approximate direction ( d x; d s), this bound can be modified slightly to account for the inexactness. <p> We omit the details, which are straightforward but messy, and state the conclusion as d (x + ff d x) T (s + ff d s) n=2 + O (u + 2 ): Again, we find that the duality gap is decreasing over the whole interval ff 2 <ref> [0; 1] </ref>. Hence, the only condition that can bound ff fl and ^ff fl away from 1 is (17a), and then only for the N -components of x and the B-components of s. <p> It is sufficient to describe just the first stage of the procedure. Later stages apply the same technique recursively to the remaining submatrix. The pivot selection procedure for Bunch-Kaufman <ref> [1] </ref> is as follows. <p> The algorithm continues by applying this procedure to T . Note that the O i are generally changed by each stage of the factorization. The submatrix CE 1 contains the subdiagonals in the first one or two columns of the L factor. Bunch and Kaufman <ref> [1] </ref> show that for the particular choice ffi = (1 + p 17)=8, we have max j T ij j (2:57) max jT ij j; (44) so there is a modest bound on element growth during each stage of the factorization. 14 When applied to canonical matrices, the Bunch-Kaufman procedure selects <p> The matrix A is 24 dense and random, with elements defined by A 1j = o 10 6o3 ; j = 1; : : : ; n; where every instance of o is selected from a uniform distribution on the interval <ref> [0; 1] </ref>. (We choose all the elements in the first row of A to be positive to ensure that the feasible region is bounded.) We control the size of the index sets B and N (to control the amount of degeneracy) and set N = f1; 2; : : : ;
Reference: [2] <author> I. S. Duff, </author> <title> The solution of augmented systems, </title> <type> Technical Report RAL-93-084, </type> <institution> Ruther-ford Appleton Laboratory, </institution> <note> Oxon, </note> <author> U. K., </author> <month> November </month> <year> 1993. </year> <month> 35 </month>
Reference-contexts: Vavasis [18] gives an illuminating discussion of the augmented system in other contexts besides optimization. He presents a solution method that is provably stable in a certain sense, but which is not guaranteed to produce "useful" steps in the sense of this paper. Duff <ref> [2] </ref> also discusses augmented systems in a general context and describes a sparse factorization procedure. 2 Interior-Point Methods We consider the linear program in standard form: min c T x; Ax = b; x 0; (1) where x 2 IR n and b 2 IR m .
Reference: [3] <author> A. Forsgren, P. Gill, and J. Shinnerl, </author> <title> Stability of symmetric ill-conditioned systems arising in interior methods for constrained optimization, </title> <type> Report TRITA-MAT-1994-24, </type> <institution> Royal Institute of Technology, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Wright [21] analyzed Gaussian elimination in the context of interior-point algorithms for linear complementarity problems. Simultaneously with the original version of this paper, and independently, Forsgren, Gill, and Shinnerl <ref> [3] </ref> performed an analysis of the augmented system in barrier algorithms. Their analysis tends to be more detailed than ours, and a few of the results overlap.
Reference: [4] <author> R. Fourer and S. Mehrotra, </author> <title> Solving symmetric indefinite systems in an interior-point method for linear programming, </title> <journal> Mathematical Programming, </journal> <volume> 62 (1993), </volume> <pages> pp. 15-39. </pages>
Reference-contexts: This work was supported by the Mathematical, Information, and Computational Sciences Division subprogram of the Office of Computational and Technology Research, U.S. Department of Energy, under Contract W-31-109-Eng-38. 1 least one practical interior-point code for linear programming (see Fourer and Mehrotra <ref> [4] </ref>). We assume that no attempt is made to improve the conditioning of the underlying linear systems by guessing whether each component of the solution is at a bound. <p> Mehrotra's [13] predictor-corrector search direction differs from the one analyzed in this paper, but under our assumptions below, the difference vanishes as the solution is approached. Newer codes, such as those described by Mehrotra [13], Fourer and Mehrotra <ref> [4] </ref>, Lustig, Marsten, and Shanno [11], Vanderbei [17], and Xu, Hung, and Ye [22] all implement Mehrotra's predictor-corrector strategy. These newer codes 2 continue to use step lengths based on ff fl ; hence, we pay particular attention to the effect of roundoff error on this quantity. <p> Theorem 7.2 Suppose T is a canonical matrix in which B is square. Then, for all sufficiently small , the Bunch-Parlett factorization followed by the solution process outlined in Section 6 satisfies Condition 1. 8 The Sparse Bunch-Parlett Factorization Several authors (notably Fourer and Mehrotra <ref> [4] </ref>) have proposed a sparse variant of the Bunch-Parlett factorization that compromises between maintaining sparsity and limiting element growth in the remaining matrix. We outline the pivot selection procedure as described by [4], with a slight modification noted below. <p> outlined in Section 6 satisfies Condition 1. 8 The Sparse Bunch-Parlett Factorization Several authors (notably Fourer and Mehrotra <ref> [4] </ref>) have proposed a sparse variant of the Bunch-Parlett factorization that compromises between maintaining sparsity and limiting element growth in the remaining matrix. We outline the pivot selection procedure as described by [4], with a slight modification noted below. For each index i = 1; 2; : : : ; n we define the degree n i to be the number of off-diagonal nonzeros in row i. <p> Theorem 8.1 The results of Theorems 6.1 and 6.2 hold when the sparse Bunch-Parlett factorization is used in place of the Bunch-Kaufman procedure. To obtain this result, we modified the acceptance condition (56) for 1 fi 1 pivots. In the description of <ref> [4] </ref>, the right-hand side is 1=ffi rather than 2=ffi. With the original choice, the sparse Bunch-Parlett algorithm applied to a degenerate canonical matrix could allow another type of pivot: a 2 fi 2 pivot in which one diagonal is from fl and the other has size O ( + u). <p> This option works well for most purposes, since stalling usually occurs only after is reduced to O (u), by which time the problem has usually converged to acceptable accuracy. Fourer and Mehrotra <ref> [4] </ref> report that the convergence criteria are usually satisfied before the ill effects of roundoff are seen. Our testing in Section 10 allows a similar conclusion. A second option is to switch to a termination procedure when the interior-point algorithm stalls.
Reference: [5] <author> A. J. Goldman and A. W. Tucker, </author> <title> Theory of linear programming, in Linear Equalities and Related Systems, </title> <editor> H. W. Kuhn and A. W. Tucker, eds., </editor> <publisher> Primceton University Press, Princeton, </publisher> <editor> N. J., </editor> <year> 1956, </year> <pages> pp. 53-97. </pages>
Reference-contexts: well known that B and N form a partition of f1; 2; : : : ; ng and that there is at least one solution ( fl ; x fl ; s fl ) that is strictly complementary, that is, x fl + s fl &gt; 0 (Goldman and Tucker <ref> [5] </ref>). The cardinality of B is denoted by jBj.
Reference: [6] <author> C. Gonzaga, </author> <title> Path-following methods in linear programming, </title> <journal> SIAM Review, </journal> <volume> 34 (1991), </volume> <pages> pp. 167-224. </pages>
Reference-contexts: The best-known potential-reduction algorithm in this class was devised by Kojima, Mizuno, and Yoshise [8]; the review paper of Todd [16] contains a wealth of historical information on potential-reduction methods. Early developments in path-following methods are surveyed by Gonzaga <ref> [6] </ref>, while Mizuno, Todd, and Ye [14] describe an important variant of these methods that does not require the iterates to stay within a cramped neighborhood of the central path.
Reference: [7] <author> O. G uler and Y. Ye, </author> <title> Convergence behavior of interior-point algorithms, </title> <booktitle> Mathematical Programming, </booktitle> <year> (1993), </year> <pages> pp. 215-228. </pages>
Reference-contexts: Guler and Ye <ref> [7] </ref> study algorithms in which all iterates are strictly feasible; that is Ax = b; A T + s = c; (x; s) &gt; 0: (13) In fact they require that x and s be slightly separated from the boundary of the positive orthant, in the sense that x i s
Reference: [8] <author> M. Kojima, S. Mizuno, and A. Yoshise, </author> <title> An O( p nL) iteration potential reduction algorithm for linear complementarity problems, </title> <journal> Mathematical Programming, </journal> <volume> 50 (1991), </volume> <pages> pp. 331-342. </pages>
Reference-contexts: The effects of roundoff error are tracked by using fairly standard techniques from backward error analysis. The most successful interior-point methods for practical linear programming problems are primal-dual methods. The best-known potential-reduction algorithm in this class was devised by Kojima, Mizuno, and Yoshise <ref> [8] </ref>; the review paper of Todd [16] contains a wealth of historical information on potential-reduction methods.
Reference: [9] <author> I. J. Lustig, R. E. Marsten, and D. F. Shanno, </author> <title> Computational experience with a primal-dual interior point method for linear programming, Linear Algebra and Its Applications, </title> <booktitle> 152 (1991), </booktitle> <pages> pp. </pages> <month> 191-222. </month> <title> [10] , Computational experience with a globally convergent primal-dual predictor-corrector algorithm for linear programming, </title> <type> Technical Report SOR 92-10, </type> <institution> Program in Statistics and Operations Research, Princeton University, Princeton, N. J., </institution> <year> 1992. </year> <title> [11] , Interior-point methods for linear programming: Computational state of the art, </title> <journal> ORSA Journal on Computing, </journal> <volume> 6 (1994), </volume> <pages> pp. 1-14. </pages>
Reference-contexts: Some of these developments took place in the context of linear complementarity, a class of problems that includes linear programming as a special case. On the computational side, the OB1 code described by Lustig, Marsten, and Shanno <ref> [9] </ref> generated search directions of the type described in this paper. They compute the maximum step ff fl that could be taken along this direction without violating the positivity bounds, then set the actual step length to .995 ff fl . <p> Moreover, (12) is trivially satisfied for all feasible algorithms. The infeasible-interior-point algorithm described by Wright [19] satisfies Assumption 1. So does the algorithm in [20], provided that the sequence or iterates (x; s) is bounded. Implemented algorithms such as those of Vanderbei [17], Lustig, Marsten, and Shanno <ref> [9, 10] </ref>, and Xu, Hung, and Ye [22] usually step a fixed multiple of the distance to the boundary rather than enforce a potential reduction condition or a condition like (14). Nevertheless, the iteration sequence usually satisfies the properties of Assumption 1 for most practical problems.
Reference: [12] <author> N. Megiddo, </author> <title> On finding primal- and dual-optimal bases, </title> <journal> ORSA Journal on Computing, </journal> <volume> 3 (1991), </volume> <pages> pp. 63-65. </pages>
Reference-contexts: Our testing in Section 10 allows a similar conclusion. A second option is to switch to a termination procedure when the interior-point algorithm stalls. A finite termination procedure (see, for example, Ye [23]) or crossover to the simplex method (Meggido <ref> [12] </ref>) could be activated. A third option is simply to fix r at zero in the computations once it has reached the O (u) level, because at this stage our current point is feasible to within the limits of floating-point arithmetic.
Reference: [13] <author> S. Mehrotra, </author> <title> On the implementation of a primal-dual interior point method, </title> <journal> SIAM Journal on Optimization, </journal> <volume> 2 (1992), </volume> <pages> pp. 575-601. </pages>
Reference-contexts: They compute the maximum step ff fl that could be taken along this direction without violating the positivity bounds, then set the actual step length to .995 ff fl . Mehrotra's <ref> [13] </ref> predictor-corrector search direction differs from the one analyzed in this paper, but under our assumptions below, the difference vanishes as the solution is approached. Newer codes, such as those described by Mehrotra [13], Fourer and Mehrotra [4], Lustig, Marsten, and Shanno [11], Vanderbei [17], and Xu, Hung, and Ye [22] <p> Mehrotra's <ref> [13] </ref> predictor-corrector search direction differs from the one analyzed in this paper, but under our assumptions below, the difference vanishes as the solution is approached. Newer codes, such as those described by Mehrotra [13], Fourer and Mehrotra [4], Lustig, Marsten, and Shanno [11], Vanderbei [17], and Xu, Hung, and Ye [22] all implement Mehrotra's predictor-corrector strategy.
Reference: [14] <author> S. Mizuno, M. Todd, and Y. Ye, </author> <title> On adaptive step primal-dual interior-point algorithms for linear programming, </title> <journal> Mathematics of Operations Research, </journal> <volume> 18 (1993), </volume> <pages> pp. 964-981. </pages>
Reference-contexts: The best-known potential-reduction algorithm in this class was devised by Kojima, Mizuno, and Yoshise [8]; the review paper of Todd [16] contains a wealth of historical information on potential-reduction methods. Early developments in path-following methods are surveyed by Gonzaga [6], while Mizuno, Todd, and Ye <ref> [14] </ref> describe an important variant of these methods that does not require the iterates to stay within a cramped neighborhood of the central path. Zhang [24] extended the path-following approach further, allowing the iterates to be infeasible while retaining global convergence and polynomial complexity; see also Wright [20].
Reference: [15] <author> D. B. </author> <title> Poncele on, Barrier methods for large-scale quadratic programming, </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1990. </year>
Reference-contexts: These newer codes 2 continue to use step lengths based on ff fl ; hence, we pay particular attention to the effect of roundoff error on this quantity. Previous analysis of the ill-conditioned linear systems that arise in interior-point and barrier methods has been carried out by Ponceleon <ref> [15] </ref> and Wright [21]. Ponceleon [15] showed that these systems are not too sensitive to structured perturbations from a certain class provided that the underlying optimization problem is well conditioned. Wright [21] analyzed Gaussian elimination in the context of interior-point algorithms for linear complementarity problems. <p> Previous analysis of the ill-conditioned linear systems that arise in interior-point and barrier methods has been carried out by Ponceleon <ref> [15] </ref> and Wright [21]. Ponceleon [15] showed that these systems are not too sensitive to structured perturbations from a certain class provided that the underlying optimization problem is well conditioned. Wright [21] analyzed Gaussian elimination in the context of interior-point algorithms for linear complementarity problems.
Reference: [16] <author> M. Todd, </author> <title> Potential reduction methods in mathematical programming, </title> <type> Technical Report 1112, </type> <institution> Cornell University, </institution> <address> Ithaca, N.Y., 14853-3801, </address> <year> 1995. </year> <month> 36 </month>
Reference-contexts: The effects of roundoff error are tracked by using fairly standard techniques from backward error analysis. The most successful interior-point methods for practical linear programming problems are primal-dual methods. The best-known potential-reduction algorithm in this class was devised by Kojima, Mizuno, and Yoshise [8]; the review paper of Todd <ref> [16] </ref> contains a wealth of historical information on potential-reduction methods. Early developments in path-following methods are surveyed by Gonzaga [6], while Mizuno, Todd, and Ye [14] describe an important variant of these methods that does not require the iterates to stay within a cramped neighborhood of the central path.
Reference: [17] <author> R. J. Vanderbei, </author> <title> LOQO User's Manual, </title> <type> Technical Report SOR 92-5, </type> <institution> Program in Statistics and Operations Research, Princeton University, Princeton, N.J., </institution> <year> 1992. </year>
Reference-contexts: Mehrotra's [13] predictor-corrector search direction differs from the one analyzed in this paper, but under our assumptions below, the difference vanishes as the solution is approached. Newer codes, such as those described by Mehrotra [13], Fourer and Mehrotra [4], Lustig, Marsten, and Shanno [11], Vanderbei <ref> [17] </ref>, and Xu, Hung, and Ye [22] all implement Mehrotra's predictor-corrector strategy. These newer codes 2 continue to use step lengths based on ff fl ; hence, we pay particular attention to the effect of roundoff error on this quantity. <p> Moreover, (12) is trivially satisfied for all feasible algorithms. The infeasible-interior-point algorithm described by Wright [19] satisfies Assumption 1. So does the algorithm in [20], provided that the sequence or iterates (x; s) is bounded. Implemented algorithms such as those of Vanderbei <ref> [17] </ref>, Lustig, Marsten, and Shanno [9, 10], and Xu, Hung, and Ye [22] usually step a fixed multiple of the distance to the boundary rather than enforce a potential reduction condition or a condition like (14).
Reference: [18] <author> S. Vavasis, </author> <title> Stable numerical algorithms for equilibrium systems, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 15 (1994), </volume> <pages> pp. 1108-1131. </pages>
Reference-contexts: Their analysis tends to be more detailed than ours, and a few of the results overlap. However, they assume that the factorization algorithms select the large diagonal elements as pivots before any others, a pattern that does not generally occur in practice. Vavasis <ref> [18] </ref> gives an illuminating discussion of the augmented system in other contexts besides optimization. He presents a solution method that is provably stable in a certain sense, but which is not guaranteed to produce "useful" steps in the sense of this paper.
Reference: [19] <author> S. J. Wright, </author> <title> A path-following infeasible-interior-point algorithm for linear complementarity problems, Optimization Methods and Software, </title> <booktitle> 2 (1993), </booktitle> <pages> pp. </pages> <month> 79-106. </month> <title> [20] , A path-following interior-point algorithm for linear and quadratic optimization problems, </title> <type> Preprint MCS-P401-1293, </type> <institution> Mathematics and Computer Science Division, Ar-gonne National Laboratory, Argonne, Ill., </institution> <month> December </month> <year> 1993. </year> <note> (to appear in Annals of Operations Research). [21] , Stability of linear equations solvers in interior-point methods, Preprint MCS-P400-1293, </note> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <month> December </month> <year> 1993. </year> <note> (to appear in SIAM Journal on Matrix Analysis and Applications). </note>
Reference-contexts: It is easy to infer from their results that (11) holds for all subsequences that approach these limit points. Moreover, (12) is trivially satisfied for all feasible algorithms. The infeasible-interior-point algorithm described by Wright <ref> [19] </ref> satisfies Assumption 1. So does the algorithm in [20], provided that the sequence or iterates (x; s) is bounded.
Reference: [22] <author> X. Xu, P. Hung, and Y. Ye, </author> <title> A simplified homogeneous and self-dual linear programming algorithm and its implementation. </title> <type> Manuscript, </type> <month> September </month> <year> 1993. </year>
Reference-contexts: Newer codes, such as those described by Mehrotra [13], Fourer and Mehrotra [4], Lustig, Marsten, and Shanno [11], Vanderbei [17], and Xu, Hung, and Ye <ref> [22] </ref> all implement Mehrotra's predictor-corrector strategy. These newer codes 2 continue to use step lengths based on ff fl ; hence, we pay particular attention to the effect of roundoff error on this quantity. <p> The infeasible-interior-point algorithm described by Wright [19] satisfies Assumption 1. So does the algorithm in [20], provided that the sequence or iterates (x; s) is bounded. Implemented algorithms such as those of Vanderbei [17], Lustig, Marsten, and Shanno [9, 10], and Xu, Hung, and Ye <ref> [22] </ref> usually step a fixed multiple of the distance to the boundary rather than enforce a potential reduction condition or a condition like (14). Nevertheless, the iteration sequence usually satisfies the properties of Assumption 1 for most practical problems.
Reference: [23] <author> Y. Ye, </author> <title> On the finite convergence of interior-point algorithms for linear programming, </title> <type> Tech. Rep. 91-5, </type> <institution> Department of Management Sciences, University of Iowa, Iowa City, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: Our testing in Section 10 allows a similar conclusion. A second option is to switch to a termination procedure when the interior-point algorithm stalls. A finite termination procedure (see, for example, Ye <ref> [23] </ref>) or crossover to the simplex method (Meggido [12]) could be activated. A third option is simply to fix r at zero in the computations once it has reached the O (u) level, because at this stage our current point is feasible to within the limits of floating-point arithmetic.
Reference: [24] <author> Y. Zhang, </author> <title> On the convergence of a class of infeasible-interior-point methods for the horizontal linear complementarity problem, </title> <journal> SIAM Journal on Optimization, </journal> <volume> 4 (1994), </volume> <pages> pp. 208-227. </pages>
Reference-contexts: Early developments in path-following methods are surveyed by Gonzaga [6], while Mizuno, Todd, and Ye [14] describe an important variant of these methods that does not require the iterates to stay within a cramped neighborhood of the central path. Zhang <ref> [24] </ref> extended the path-following approach further, allowing the iterates to be infeasible while retaining global convergence and polynomial complexity; see also Wright [20]. Some of these developments took place in the context of linear complementarity, a class of problems that includes linear programming as a special case.
References-found: 20

