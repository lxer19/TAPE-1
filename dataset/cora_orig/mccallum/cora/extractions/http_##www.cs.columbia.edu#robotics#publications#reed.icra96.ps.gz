URL: http://www.cs.columbia.edu/robotics/publications/reed.icra96.ps.gz
Refering-URL: http://www.cs.columbia.edu/robotics/publications/publications.html
Root-URL: http://www.cs.columbia.edu
Title: Automated Model Acquisition using Volumes of Occlusion  
Author: Michael Reed and Peter K. Allen 
Address: New York, NY 10027  
Affiliation: Center for Research in Intelligent Systems Department of Computer Science Columbia University,  
Abstract: Two primary requirements of any system that relies on active vision to perform modeling from observation are that it be able to use previously acquired data to drive the sensing process and that it can iteratively incorporate newly sensed data. This paper discusses an approach to automating CAD model acquisition by allowing the system to keep track of what parts of the sensed object have yet to be imaged. This is achieved by explicitly representing the volume of occlusion as well as its surfaces of the object obtained from any one sensing operation. Models built from distinct views of the object, and which include their volume of occlusion, are merged using set operations. The resulting composite model consists of the visible surfaces from each model along with the intersection of the volumes of occlusion and contains the necessary information for planning the next viewpoint. 
Abstract-found: 1
Intro-found: 1
Reference: [Bajcsy and Solina1987] <editor> Ruzena Bajcsy and Franc Solina. </editor> <title> Three dimensional object representation revisited. </title> <booktitle> In Proceedings International Conference on Computer Vision, </booktitle> <address> London, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: Although for simple data such as spheres or cubes it is possible to go directly from the point data to a complete volumetric model <ref> [Bajcsy and Solina1987] </ref>, this method limits the complexity of the model unless combined with other modeling methods such as Constructive Solid Geometry.
Reference: [Besl and Jain1986] <author> P. J. Besl and R. C. Jain. </author> <title> Invariant surface characteristics for 3D object. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 33 </volume> <pages> 33-80, </pages> <year> 1986. </year>
Reference-contexts: To produce accurate estimates, the data must be smoothed by applying a filter or using an estimation technique. However, any filter that distorts the data, as many do in the vicinity of edges, will have detrimental effects on the later recovery of surfaces near those edges <ref> [Besl and Jain1986] </ref>. In our work we have minimized the processing of the data before the geometric relationships between the data are analyzed, using one pass of a median filter to remove the spike noise and reduce other anomalies without excessively degrading the data.
Reference: [Besl1988] <author> P. Besl. </author> <title> Surfaces in Range Image Understanding. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Scanning is by no means a perfect process. Laser rangefinders have noise that is affected by the surface material, color, and geometry. Further, the noise is not normally distributed, and is therefore difficult to remove <ref> [Besl1988] </ref>. Figure 2 shows how the error per data point typically ranges for just one of these contributing factors: the angle of inclination of the surface with respect to the imaging laser. To produce accurate estimates, the data must be smoothed by applying a filter or using an estimation technique.
Reference: [Chen and Medioni1991] <author> Y. Chen and G. Medioni. </author> <title> Object modeling by registration of multiple range images. </title> <booktitle> In Proceedings 1991 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 2724-2729, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Many of the efforts have focused on creating specific surface or volume modeling primitives. Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics [Solina1987], bicubic patches [Potmesil1982], and integrated point sets <ref> [Chen and Medioni1991] </ref>. A number of recent efforts have attempted to generate Boundary Representations (B-reps) from multiple views, including [Parvin and Medioni1992, Hoover et al.1994, Stenstrom and Connolly1992] and our work is in this vein.
Reference: [Chen1988] <author> C. H. Chen. 3D-Poly: </author> <title> A Robot Vision System for Recognizing Objects in Occluded Environments. </title> <type> PhD thesis, </type> <institution> School of Electrical Engineering, Purdue University, </institution> <month> December </month> <year> 1988. </year>
Reference-contexts: Because the data is from polyhedral objects , we have implemented an adaptive planar fit based on that used by <ref> [Chen1988] </ref> to determine local surface normals. This method uses a combination of region growing and surface normal analysis to facilitate rapid segmentation, while still allowing one to adjust the parameters of the segmentation.
Reference: [Connolly1985] <author> C. Connolly. </author> <title> The determination of next best views. </title> <booktitle> In Proceedings 1985 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 432-435, </pages> <year> 1985. </year>
Reference-contexts: Much prior work in sensor planning addresses the problem of determining sensing strategies for the purpose of scene reconstruction [Maver and Bajcsy1990] [Xie et al.1986] <ref> [Connolly1985] </ref> [Shmuel and Werman1990] [Whaite and Ferrie1990]. In these systems a model of the scene is incrementally built by successively sensing the unknown world from effective sensor configurations using the information acquired about the world to this point.
Reference: [Diamond and Kreplin1994] <author> Amit Diamond and Terry Kreplin. </author> <title> 3D laser digitizing for reverse engineering, moldmaking, quality assurance, and rapid prototyping purposes. In Rapid Prototyping and Manufacturing '94, </title> <type> Dearborn, </type> <institution> Michigan, </institution> <month> April </month> <year> 1994. </year> <title> Society of Manufacturing Engineers and the Rapid Prototyping Association. </title> <booktitle> (in Additional Papers Addendum). </booktitle>
Reference-contexts: Applications in which 3-D solid or surface data must be acquired from physical models or prototypes include <ref> [Diamond and Kreplin1994] </ref> model makers in the automotive industry ,Consumer goods manufacturers, Inspection and quality assurance of parts, and reverse engineering.
Reference: [Fuchs et al.1980] <author> H. Fuchs, Z. Kedem, and B. Naylor. </author> <title> On visible surface generation by a priori tree structures. </title> <journal> Computer Graphics, </journal> <volume> 14(3) </volume> <pages> 124-133, </pages> <month> June </month> <year> 1980. </year>
Reference-contexts: The desiderata for a representation are that it be effective at modeling the segmented data of each view and be able to quickly merge the different views into a single, accurate representation of the data. Such a representation is the BSP tree <ref> [Fuchs et al.1980, Naylor1981] </ref> A BSP tree is a method by which n dimensional space is partitioned by n 1 dimensional hyperplanes. Once a space has been partitioned by a hyperplane, it is represented by two n dimensional half-spaces, one on each side of the partitioning hyperplane.
Reference: [Hoover et al.1994] <author> Adam Hoover, Dmitry Goldgof, and Kevin Bowyer. </author> <title> Building a b-rep from a segmented range image. </title> <booktitle> In Proceedings of the 1994 Second CAD-Based Vision Workshop, </booktitle> <pages> pages 74-81, </pages> <address> Champion, PA, </address> <month> Febru-ary </month> <year> 1994. </year>
Reference-contexts: Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics [Solina1987], bicubic patches [Potmesil1982], and integrated point sets [Chen and Medioni1991]. A number of recent efforts have attempted to generate Boundary Representations (B-reps) from multiple views, including <ref> [Parvin and Medioni1992, Hoover et al.1994, Stenstrom and Connolly1992] </ref> and our work is in this vein. The B-rep is used by most CAD systems and can efficiently encode the geometry and topology of a wide range of objects.
Reference: [Jain and Flynn1993] <author> Anil K. Jain and Patrick J. Flynn, </author> <title> editors. Three-Dimensional Object Recognition Systems. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1993. </year>
Reference-contexts: In addition, the direct methods have a high computational cost when integrating information from multiple views: and entire recalculation of the object's surface is often required after each merge operation. For more complex objects it is necessary to segment the image into a collection of smaller surface patches <ref> [Jain and Flynn1993] </ref>.Most methods rely on some previous knowledge of the ob ject being imaged to improve the performance of the estimation. Because the data is from polyhedral objects , we have implemented an adaptive planar fit based on that used by [Chen1988] to determine local surface normals.
Reference: [Maver and Bajcsy1990] <author> J. Maver and R. </author> <title> Bajcsy. How to decide from the first view where to look next. </title> <booktitle> In Proceedings 1990 DARPA Image Understanding Workshop, </booktitle> <pages> pages 482-496, </pages> <year> 1990. </year> <editor> [Naylor et al.1990] B. Naylor, J. Amantides, and W. </editor> <title> Thibault. Merging BSP trees yields polyhedral set operations. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 115-124, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Much prior work in sensor planning addresses the problem of determining sensing strategies for the purpose of scene reconstruction <ref> [Maver and Bajcsy1990] </ref> [Xie et al.1986] [Connolly1985] [Shmuel and Werman1990] [Whaite and Ferrie1990]. In these systems a model of the scene is incrementally built by successively sensing the unknown world from effective sensor configurations using the information acquired about the world to this point. <p> For polygons of the first type, we may plan the next viewpoint by choosing a viewing direction that is perpendicular to the surface of the polygon, causing the next compositing operation to bound that polygon. Following <ref> [Maver and Bajcsy1990] </ref>, a histogram of the surface normals weighted by polygon area should be built so that the direction that bounds the most volume of occlusion will be chosen.
Reference: [Naylor1981] <author> Bruce F. Naylor. </author> <title> A Priori Based Techniques for Determining Visibility Priority for 3-D Scenes. </title> <type> PhD thesis, </type> <institution> University of Texas at Dallas, </institution> <month> May </month> <year> 1981. </year>
Reference-contexts: The desiderata for a representation are that it be effective at modeling the segmented data of each view and be able to quickly merge the different views into a single, accurate representation of the data. Such a representation is the BSP tree <ref> [Fuchs et al.1980, Naylor1981] </ref> A BSP tree is a method by which n dimensional space is partitioned by n 1 dimensional hyperplanes. Once a space has been partitioned by a hyperplane, it is represented by two n dimensional half-spaces, one on each side of the partitioning hyperplane.
Reference: [Nevatia and Binford1977] <author> R. Nevatia and T. Binford. </author> <title> Description and recognition of curved objects. </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 77-98, </pages> <year> 1977. </year>
Reference-contexts: Many of the efforts have focused on creating specific surface or volume modeling primitives. Some representative examples include generalized cylinders <ref> [Nevatia and Binford1977] </ref>, superquadrics [Solina1987], bicubic patches [Potmesil1982], and integrated point sets [Chen and Medioni1991]. A number of recent efforts have attempted to generate Boundary Representations (B-reps) from multiple views, including [Parvin and Medioni1992, Hoover et al.1994, Stenstrom and Connolly1992] and our work is in this vein.
Reference: [Parvin and Medioni1992] <author> B. Parvin and G. Medioni. </author> <title> B-rep from unregistered multiple range images. </title> <booktitle> In IEEE International Conference on Robotics & Automation, </booktitle> <pages> pages 1602-1607, </pages> <address> Nice, </address> <year> 1992. </year>
Reference-contexts: Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics [Solina1987], bicubic patches [Potmesil1982], and integrated point sets [Chen and Medioni1991]. A number of recent efforts have attempted to generate Boundary Representations (B-reps) from multiple views, including <ref> [Parvin and Medioni1992, Hoover et al.1994, Stenstrom and Connolly1992] </ref> and our work is in this vein. The B-rep is used by most CAD systems and can efficiently encode the geometry and topology of a wide range of objects.
Reference: [Potmesil1982] <author> Michael Potmesil. </author> <title> Generating three dimensional surface models of solid objects from multiple projections. </title> <type> Technical Report 33, </type> <institution> Image Processing Laboratory, RPI, </institution> <month> October </month> <year> 1982. </year>
Reference-contexts: Many of the efforts have focused on creating specific surface or volume modeling primitives. Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics [Solina1987], bicubic patches <ref> [Potmesil1982] </ref>, and integrated point sets [Chen and Medioni1991]. A number of recent efforts have attempted to generate Boundary Representations (B-reps) from multiple views, including [Parvin and Medioni1992, Hoover et al.1994, Stenstrom and Connolly1992] and our work is in this vein.
Reference: [Shmuel and Werman1990] <author> A. Shmuel and M. Werman. </author> <title> Active vision: 3d from and image sequence. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <pages> pages 48-54, </pages> <month> June 16-21 </month> <year> 1990. </year>
Reference-contexts: Much prior work in sensor planning addresses the problem of determining sensing strategies for the purpose of scene reconstruction [Maver and Bajcsy1990] [Xie et al.1986] [Connolly1985] <ref> [Shmuel and Werman1990] </ref> [Whaite and Ferrie1990]. In these systems a model of the scene is incrementally built by successively sensing the unknown world from effective sensor configurations using the information acquired about the world to this point.
Reference: [Shum et al.1994] <author> H. Shum, K. Ikeuchi, and R. Reddy. </author> <title> Virtual reality modeling from a sequence of range images. </title> <booktitle> In Proceedings 1994 ARPA Image Understanding Workshop, </booktitle> <pages> pages 1189-1198, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: reached the point where the resulting model is precise enough to be used in manufacturing processes [Tarbox and Gottshlich1995] fl This work was supported in part by DARPA contract DACA-76-92-C-0007, NSF grants CDA-90-24735 and IRI-93-11877, and an ONR MURI Grant [Sobh et al.1995], or for display in virtual reality environments <ref> [Shum et al.1994] </ref>. Many of the efforts have focused on creating specific surface or volume modeling primitives. Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics [Solina1987], bicubic patches [Potmesil1982], and integrated point sets [Chen and Medioni1991].
Reference: [Sobh et al.1995] <author> T. M. Sobh, J. Owen, C. Jaynes, M. Dekhil, and T.C. Henderson. </author> <title> Industrial inspection and reverse engineering. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 61(3) </volume> <pages> 468-474, </pages> <month> may </month> <year> 1995. </year>
Reference-contexts: Recent work has reached the point where the resulting model is precise enough to be used in manufacturing processes [Tarbox and Gottshlich1995] fl This work was supported in part by DARPA contract DACA-76-92-C-0007, NSF grants CDA-90-24735 and IRI-93-11877, and an ONR MURI Grant <ref> [Sobh et al.1995] </ref>, or for display in virtual reality environments [Shum et al.1994]. Many of the efforts have focused on creating specific surface or volume modeling primitives. Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics [Solina1987], bicubic patches [Potmesil1982], and integrated point sets [Chen and Medioni1991].
Reference: [Solina1987] <author> Franc Solina. </author> <title> Shape recovery and segmentation with deformable part models. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Pennsylvania, </institution> <month> December </month> <year> 1987. </year>
Reference-contexts: Many of the efforts have focused on creating specific surface or volume modeling primitives. Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics <ref> [Solina1987] </ref>, bicubic patches [Potmesil1982], and integrated point sets [Chen and Medioni1991]. A number of recent efforts have attempted to generate Boundary Representations (B-reps) from multiple views, including [Parvin and Medioni1992, Hoover et al.1994, Stenstrom and Connolly1992] and our work is in this vein.
Reference: [Stenstrom and Connolly1992] <author> J. R. Stenstrom and C. I. Connolly. </author> <title> Constructing object models from multiple images. </title> <journal> Int. Journal of Computer Vision, </journal> <volume> 9(3) </volume> <pages> 185-212, </pages> <year> 1992. </year>
Reference-contexts: Some representative examples include generalized cylinders [Nevatia and Binford1977], superquadrics [Solina1987], bicubic patches [Potmesil1982], and integrated point sets [Chen and Medioni1991]. A number of recent efforts have attempted to generate Boundary Representations (B-reps) from multiple views, including <ref> [Parvin and Medioni1992, Hoover et al.1994, Stenstrom and Connolly1992] </ref> and our work is in this vein. The B-rep is used by most CAD systems and can efficiently encode the geometry and topology of a wide range of objects.
Reference: [Suk and Bhandarkar1992] <author> Minsoo Suk and Suchendra M. Bhandarkar. </author> <title> Three-Dimensional Object Recognition from Range Images. Computer Science Workbench. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: After segmentation there are pixels that have not been classified as belonging to any surface. In order to classify these pixels, we apply a post-segmentation filtering process <ref> [Suk and Bhandarkar1992] </ref>. An unclassified pixel that is surrounded by classified pixels may be handled by applying a mask to the image which classifies the pixel according to the majority region in the mask.
Reference: [Tarabanis et al.1991] <author> K. Tarabanis, Roger Tsai, and Peter K. Allen. </author> <title> Automated sensor planning for robotic vision tasks. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <address> Sacramento, </address> <month> April 9-11 </month> <year> 1991. </year>
Reference-contexts: However, since convexities will exist on most objects, the polygon may be blocked by self-occlusion by another part of the object. In these cases it would be useful to use the results from sensor planning research <ref> [Tarabanis et al.1991, Tarabanis et al.1994, Tarabanis et al.1995] </ref> to compute a strategy for scanning.
Reference: [Tarabanis et al.1994] <author> K. Tarabanis, Roger Tsai, and Peter K. Allen. </author> <title> Analytical characterization of the feature detectability constraints of resolution, focus and field-of-view for vision sensor planning. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 59(3) </volume> <pages> 340-358, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: However, since convexities will exist on most objects, the polygon may be blocked by self-occlusion by another part of the object. In these cases it would be useful to use the results from sensor planning research <ref> [Tarabanis et al.1991, Tarabanis et al.1994, Tarabanis et al.1995] </ref> to compute a strategy for scanning.
Reference: [Tarabanis et al.1995] <author> K. Tarabanis, R. Y. Tsai, and A. </author> <title> Kaul. </title> <journal> Computing occlusion-free viewpoints. IEEE Transactions Pattern Analysis and Machine Intelligence, </journal> <note> to appear 1995. </note>
Reference-contexts: However, since convexities will exist on most objects, the polygon may be blocked by self-occlusion by another part of the object. In these cases it would be useful to use the results from sensor planning research <ref> [Tarabanis et al.1991, Tarabanis et al.1994, Tarabanis et al.1995] </ref> to compute a strategy for scanning.
Reference: [Tarbox and Gottshlich1995] <author> G.H. Tarbox and S.N. Gottshlich. Ivis: </author> <title> An integrated volumetric inspection system. </title> <booktitle> Computer Vision and Image Understanding, </booktitle> <volume> 61(3) </volume> <pages> 430-444, </pages> <month> may </month> <year> 1995. </year>
Reference-contexts: Recent work has reached the point where the resulting model is precise enough to be used in manufacturing processes <ref> [Tarbox and Gottshlich1995] </ref> fl This work was supported in part by DARPA contract DACA-76-92-C-0007, NSF grants CDA-90-24735 and IRI-93-11877, and an ONR MURI Grant [Sobh et al.1995], or for display in virtual reality environments [Shum et al.1994].
Reference: [Thibault and Naylor1987] <author> W. Thibault and B. Naylor. </author> <title> Set operations on polyhedra using binary space partitioning trees. </title> <journal> Computer Graphics, </journal> <volume> 21(4), </volume> <month> July </month> <year> 1987. </year>
Reference-contexts: We may represent space contained or outside a polyhedra by associating a label at each of the leaves denoting the space represented there as either "in" or "out" <ref> [Thibault and Naylor1987] </ref>. The BSP tree has unique advantages as an intermediate representation for the different views. Its tree structure allows very efficient algorithms to be developed, it is compact, and it is numerically robust.
Reference: [Whaite and Ferrie1990] <author> P. Whaite and F. Ferrie. </author> <title> From uncertainty to visual exploration. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 690-697, </pages> <year> 1990. </year>
Reference-contexts: Much prior work in sensor planning addresses the problem of determining sensing strategies for the purpose of scene reconstruction [Maver and Bajcsy1990] [Xie et al.1986] [Connolly1985] [Shmuel and Werman1990] <ref> [Whaite and Ferrie1990] </ref>. In these systems a model of the scene is incrementally built by successively sensing the unknown world from effective sensor configurations using the information acquired about the world to this point.
Reference: [Wohlers1994] <author> Terry Wohlers. </author> <title> State of the industry. In Rapid Prototyping and Manufacturing '94, </title> <type> Dearborn, </type> <institution> Michigan, </institution> <month> April </month> <year> 1994. </year> <title> Society of Manufacturing Engineers and the Rapid Prototyping Association. </title>
Reference-contexts: There are still parts which are best designed using the tools of model makers, in materials such as clay or wood. It has been said that everyone would be using CAD systems if they were "as comfortable and easy to use as foam, clay, and pine." <ref> [Wohlers1994] </ref>. As long as this state of affairs continues, there will be parts for which there are no CAD data.
Reference: [Xie et al.1986] <author> S. Xie, T.W. Calvert, and B.K. Bhat-tacharaya. </author> <title> Planning views for the incremental construction of body models. </title> <booktitle> In Proceedings of the 8th International Conference on Pattern Recognition, </booktitle> <pages> pages 154-157, </pages> <year> 1986. </year>
Reference-contexts: Much prior work in sensor planning addresses the problem of determining sensing strategies for the purpose of scene reconstruction [Maver and Bajcsy1990] <ref> [Xie et al.1986] </ref> [Connolly1985] [Shmuel and Werman1990] [Whaite and Ferrie1990]. In these systems a model of the scene is incrementally built by successively sensing the unknown world from effective sensor configurations using the information acquired about the world to this point.
References-found: 29

