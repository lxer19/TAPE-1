URL: http://vismod.www.media.mit.edu/vismod/demos/kidsroom/kidsroom.ps.Z
Refering-URL: http://vismod.www.media.mit.edu/vismod/demos/kidsroom/info.html
Root-URL: http://www.media.mit.edu
Email: (kidsroom@media.mit.edu)  
Title: KidsRoom: A Perceptually-Based Interactive and Immersive Story Environment  
Author: Aaron F. Bobick, Stephen S. Intille, James W. Davis Freedom Baird, Claudio S. Pinhanez Lee W. Campbell, Yuri A. Ivanov, Arjan Schutte, Andrew Wilson 
Address: 20 Ames Street Cambridge, MA 02139  
Affiliation: The MIT Media Laboratory  
Note: The  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 398 November, 1996 Revised June 1998 Abstract The KidsRoom is a perceptually-based, interactive, narrative playspace for children. Images, music, narration, light, and sound effects are used to transform a normal child's bedroom into a fantasy land where children are guided through a reactive adventure story. The fully-automated system was designed with the following goals: (1) to keep the focus of user action and interaction in the physical, not virtual space; (2) to permit multiple, collaborating people to simultaneously engage in an interactive experience combining both real and virtual objects; (3) to use computer-vision algorithms to identify activity in the space without requiring the participants to wear any special clothing or devices; (4) to use narrative to constrain the perceptual recognition, and to use perceptual recognition to allow participants to drive the narrative; (5) to create a truly immersive and interactive room environment. We believe the KidsRoom is the first multi-person, fully-automated, interactive, narrative environment ever constructed using non-encumbering sensors. This paper describes the KidsRoom, the technology that makes it work, and the issues that were raised during the system's development. 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.T. Azuma. </author> <title> A survey of augmented reality. Presence: Teleoperators and Virtual Environments, </title> <type> 6(4), </type> <month> August </month> <year> 1997. </year>
Reference-contexts: Their goal, as is ours, was to augment spaces that we are comfortable with, but the technology available at that time required the use of body gear for sensing gesture and speech. Even today, most work in augmented environments requires cumbersome sensing and head-mounted display gear <ref> [1] </ref>. Research on physical, remotely sensed, interactive spaces began with Krueger's Videoplace system [20]. Krueger designed installations that explored many different modes of interaction, most of which entailed large body gesture. In one example, the user interacted with his or her own silhouette on video screens.
Reference: [2] <author> J.M. Barrie. Peter Pan. EP Dutton, </author> <year> 1988. </year>
Reference-contexts: Inspired by famous children's stories in which children are transported from their bedrooms to magical places (e.g. <ref> [2, 34, 27] </ref>), the story begins in a child's bedroom and progresses through three other worlds. We will describe the last world in detail, to give the reader a feel for the story, it's characters, and the interactive responsiveness of the entire system.
Reference: [3] <author> Joseph Bates, A. Bryan Loyall, and W. Scott Reilly. </author> <title> An architecture for action, emotion, and social behavior. </title> <booktitle> In Proc. of the Fourth European Workshop on Modeling Autonomous Agents in a Multi-Agent World, </booktitle> <editor> S. Martino al Cimino, </editor> <address> Italy, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: We note that an alternative mechanism to timers is to use the AI concept of planning to model the change in the states of the world <ref> [3] </ref>. Recently, Pinhanez, Mase, and Bobick [24] have proposed the use of interval scripts, where all the sensing and actuating activities are associated with temporal intervals, whose activation is determined by the result of a constraint satisfaction algorithm based on the input from the sensors and the past interaction.
Reference: [4] <author> B.B. Bederson and A. Druin. </author> <title> Computer augmented environments: New places to learn, work, and play. </title> <booktitle> In Advances in Human Computer Interaction, </booktitle> <volume> volume 5, chapter 2. </volume> <publisher> Ablex, </publisher> <year> 1995. </year>
Reference-contexts: where there is a natural story-line to drive the situation. 3 Interaction in augmented environments Bederson and Druin classify work on computer interactive interface systems into those that focus on building interfaces where information is superimposed on the physical world and those that embed information into the physical world itself <ref> [4] </ref>. The majority of research in the human computer interface and computer graphics fields has focused on systems of the first form, where a user must wear gear such as glove sensors, specially-colored clothing, or microphones. <p> Artists Christa Sommerer, Laurent Mignonneau, and Naoko Tosa have integrated computer vision, computer graphics, and emotion and speech recognition techniques [30, 32]. Bederson and Druin believe, as do we, that the best immersive physical environments will have multi-modal inputs and outputs <ref> [4] </ref>. Increasing computational speed is now making it possible to explore domains like immer-sive office environments [35, 18], living spaces, and theater performances [25].
Reference: [5] <author> Aaron F. Bobick. </author> <title> Movement, activity, and action: the role of knowledge in the perception of motion. </title> <journal> Phil. Trans. Royal Society London B, </journal> <volume> 352 </volume> <pages> 1257-1265, </pages> <year> 1997. </year>
Reference-contexts: However, even if a room is densely wired with sensing devices, the difficult problem of understanding what is happening in the space still needs to be addressed, and that is a fundamental component of our research on understanding action in the vision domain <ref> [5] </ref>. like to play with each other in real spaces enhanced by imaginary constructs (e.g. couches as caves) and can be easily motivated by supplementary imagery, sound and lighting. 3 The final design of the KidsRoom was intended to achieve each of these goals. <p> Throughout this paper, we will lump all types of action recognition together. However, within the computer vision community, researchers are developing a taxonomy of action based on the computational representations and methods required to understand each action type (e.g. a taxonomy of movement, activity, and action <ref> [5] </ref>). Many actions of interest require that contextual knowledge be used for recognition in addition to sensed motion and position information. In simple contexts, direct measurement of body position can sometimes be used to recognize activity.
Reference: [6] <author> R.A. </author> <title> Bolt. The Human Interface. </title> <publisher> Wadsworth, Inc., </publisher> <address> Belmont, California, </address> <year> 1984. </year>
Reference-contexts: Such systems have been alternately termed augmented environments, immersive environments, intelligent rooms [31], smart rooms [23], and interactive spaces. One early example of augmenting a physical space was the Media Room project of Bolt and Negroponte <ref> [6] </ref>. Their system allowed a user sitting in a chair, ostensibly in his or her future living room, to interact with a screen by pointing and talking.
Reference: [7] <author> Broderbund Software. Myst. </author> <title> An interactive CDROM, </title> <year> 1994. </year>
Reference-contexts: action and a reasonable response, the child will not understand that he or she has caused the action to happen. 10.2 Exploratory vs. scripted narrative spaces In our initial design of the KidsRoom, we planned to create a primarily exploratory space, modeled somewhat on popular non-linear computer games like Myst <ref> [7] </ref>. We designed and built prototypes for the first and second worlds using this model. In the first world, there was no talking furniture.
Reference: [8] <author> M.H. Coen. </author> <title> Building brains for rooms: designing distributed software agents. </title> <booktitle> In Proc. of the Conf. on Innovative Applications of Artificial Intelligence, </booktitle> <pages> pages 971-977. </pages> <publisher> AAAI Press, </publisher> <year> 1997. </year>
Reference-contexts: The room is controlled by a distributed agent-based architecture <ref> [8] </ref>. The goal of the project is to remove the computer from the human-computer interface. An alternative approach to the design of interactive spaces is to mediate computer interaction through the manipulation of real, physical objects. Druin, for instance, constructed a stuffed-animal doll called Noobie [13]. <p> Communication is achieved using the RPC protocol. The server architecture has proven effective for allowing different individuals to work on different components of the system using the computer system most appropriate for the particular task. As noted by Coen <ref> [8] </ref>, it is critical for any large distributed room control mechanism that individual components can be stopped and started without requiring a reboot of the entire system. III.
Reference: [9] <author> C. Cruz-Neira, </author> <title> D.J. Sandin, and T.A. DeFanti. Surround-screen projection-based virtual reality: </title> <booktitle> The design and implementation of the CAVE. In Proc. of SIGGRAPH Computer Graphics Conference, </booktitle> <pages> pages 135-142. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> August </month> <year> 1993. </year> <title> 18 experience the room a second and third time. </title>
Reference-contexts: We were forced, therefore, to choose camera and rug positions so that people in the room would never appear in front of a screen in the image views - a serious limitation for a space like the KidsRoom or (even worse) the Cave <ref> [9] </ref>. Recent work motivated by this problem may alleviate this constraint [19, 12]. * Even in a space as large as 24 feet by 18 feet with a high ceiling, placing cameras so that the resulting views were non-occluded proved tricky.
Reference: [10] <author> G. Davenport and G. Friedlander. </author> <title> Interactive transformational environments: Wheel of life. </title> <editor> In E. Barrett and M. Redmond, editors, </editor> <title> Contextual media: multimedia and interpretation, </title> <booktitle> chapter 1, </booktitle> <pages> pages 1-25. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA USA, </address> <year> 1995. </year>
Reference-contexts: The experience should be compelling in the sense that the users should be more concerned with their own actions and behaviors than with how the interactive system works. Children. We want the environment to be tailored to children. Davenport and Friedlander <ref> [10] </ref> and Druin and Perlin [14] both observed that adults visiting their interactive installations sometimes had difficulty immersing themselves in the narrative. Children already 2 Some of the direct sensing tasks could be implemented using other devices such as micro-switches to detect presence of a person on a bed. <p> Interestingly, Druin and Perlin comment that some adults were confused with the whole idea of an immersive experience. One participant commented, I didn't think I should touch anything. You know, Mom always said, Do not touch! Narrative in interactive physical spaces was further explored by Davenport and Friedlander <ref> [10] </ref>. They wanted people to feel as though they were walking through a computer monitor into a magic landscape. They constructed a four-world, human-controlled installation where the narrative was actualized by the transformative actions of the visitor moving through it. The room used light, sound, video, and computer displays. <p> Users did not share any common goals. Other authors have observed that exploratory, puzzle-solving spaces can sometimes make it difficult for adults to immerse themselves in an interactive world <ref> [14, 10] </ref>. When a story is added to the physical environment, a theatrical-like experience is created. Once the theatrical nature of the system is apparent, it is easier for people to imagine their roles and, if they are not too self-conscious, act them out.
Reference: [11] <author> J.W. Davis and A.F. Bobick. </author> <title> The representation and recognition of action using temporal templates. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 928-934. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1997. </year>
Reference-contexts: Moment-based shape features [16] are computed from the the blob images like those shown in Figure 12d and are statistically compared to a database of training examples of people making a Y. 7.3.3 Movement recognition The last technique used to recognize monster moves uses recognition of motion templates <ref> [11] </ref>. In this method, successive video frames of the background subtracted images of the people are temporally integrated to yield a temporal template of the action. Templates for the flap and spin moves are shown in Figure 13.
Reference: [12] <author> J.W. Davis and A.F. Bobick. SIDESHOW: </author> <title> a silhouette based interactive dual-screen environment. </title> <type> Perceptual Computing Technical Report 457, </type> <institution> MIT Media Laboratory, </institution> <address> 20 Ames St. Cambridge, MA 02139, </address> <month> March </month> <year> 1998. </year>
Reference-contexts: Recent work motivated by this problem may alleviate this constraint <ref> [19, 12] </ref>. * Even in a space as large as 24 feet by 18 feet with a high ceiling, placing cameras so that the resulting views were non-occluded proved tricky.
Reference: [13] <author> A. Druin. Noobie: </author> <title> the animal design playstation. </title> <booktitle> In Proc. of Human Factors in Computing Systems (CHI), </booktitle> <volume> volume 20, </volume> <pages> pages 45-53, </pages> <year> 1988. </year>
Reference-contexts: The goal of the project is to remove the computer from the human-computer interface. An alternative approach to the design of interactive spaces is to mediate computer interaction through the manipulation of real, physical objects. Druin, for instance, constructed a stuffed-animal doll called Noobie <ref> [13] </ref>. Children interacted with Noobie by squeezing the doll's limbs and watching a display embedded in its belly.
Reference: [14] <author> A. Druin and K. Perlin. </author> <title> Immersive environments: a physical approach to the computer interface. </title> <booktitle> In Proc. of Human Factors in Computing Systems (CHI), </booktitle> <pages> pages 325-326, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The experience should be compelling in the sense that the users should be more concerned with their own actions and behaviors than with how the interactive system works. Children. We want the environment to be tailored to children. Davenport and Friedlander [10] and Druin and Perlin <ref> [14] </ref> both observed that adults visiting their interactive installations sometimes had difficulty immersing themselves in the narrative. Children already 2 Some of the direct sensing tasks could be implemented using other devices such as micro-switches to detect presence of a person on a bed. <p> Druin and Perlin set out to construct immersive physical environments for adults that responded to movement and touch in real physical spaces <ref> [14] </ref>. They supplemented a real environment with a simple narrative and in 1993 debuted an interactive installation with three stories: one humorous story about baby sitting, another more serious narrative about heaven and hell, and a final murder-mystery scenario. <p> Users did not share any common goals. Other authors have observed that exploratory, puzzle-solving spaces can sometimes make it difficult for adults to immerse themselves in an interactive world <ref> [14, 10] </ref>. When a story is added to the physical environment, a theatrical-like experience is created. Once the theatrical nature of the system is apparent, it is easier for people to imagine their roles and, if they are not too self-conscious, act them out.
Reference: [15] <author> J. Glos and M. Umaschi. </author> <title> Once upon an object...: </title> <booktitle> computationally-augmented toys for storytelling. In Proc. of the Int'l Conf. on Computational Intelligence and Multimedia Applications (ICCIMA), </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: Instead of bringing children to the virtual space on the screen and forcing interaction with special devices, the interface was brought into the world of the children and embedded into devices with which they were already comfortable (also see <ref> [33, 15] </ref>). Druin and Perlin set out to construct immersive physical environments for adults that responded to movement and touch in real physical spaces [14].
Reference: [16] <author> M. Hu. </author> <title> Visual pattern recognition by moment invariants. </title> <journal> IRE Transactions on Information Theory, </journal> <volume> IT-8(2), </volume> <year> 1962. </year>
Reference-contexts: Here we use a pattern recognition approach to classify the background subtracted images of the person. Moment-based shape features <ref> [16] </ref> are computed from the the blob images like those shown in Figure 12d and are statistically compared to a database of training examples of people making a Y. 7.3.3 Movement recognition The last technique used to recognize monster moves uses recognition of motion templates [11].
Reference: [17] <author> S.S. Intille, J.W. Davis, </author> <title> and A.F. Bobick. Real-time closed-world tracking. </title> <booktitle> In Proc. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 697-703. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1997. </year>
Reference-contexts: It is important for the algorithm to keep track of how many people are in the room, which is achieved by having everyone in the room enter and exit through a door region. 9 The context-sensitive, non-rigid object tracking method is fully described and tested elsewhere <ref> [17] </ref>. output of the tracking system. Each person is represented by a single point, the centroid of his or her blob. The box in the lower left corner represents the door region of the room, where people can enter and exit at any time. <p> ellipse model for standing and crouching positions. 10 10 For all moves, the control system ignores the move reported by the vision system if the tracking has indicated the person is not on the rug. right image shows the output of the tracking system, which is described and evaluated elsewhere <ref> [17] </ref>. All three people and the bed are being tracked as they move about. The box in the lower left denotes the room's door region, where all objects must enter and exit. <p> capability to a space like the Kids-Room with loud music, loud sound effects, and loud children remains a significant challenge. 10.5.2 Object tracking difficulties The KidsRoom tracking algorithm does an excellent job of keeping track of where people are but occasionally makes errors when keeping track of who people are <ref> [17] </ref>. In other words, the tracker sometimes swaps two people, thinking 16 that one is the other, but in normal operation does not lose a person altogether. The KidsRoom, therefore, was designed with the expectation that perfect tracking of identity might be problematic.
Reference: [18] <author> H. Ishii and B. Ullmer. </author> <title> Tangible bits: towards seamless interfaces between people, bits, and atoms. </title> <booktitle> In Proc. of Human Factors in Computing Systems (CHI), </booktitle> <pages> pages 234-241, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: Bederson and Druin believe, as do we, that the best immersive physical environments will have multi-modal inputs and outputs [4]. Increasing computational speed is now making it possible to explore domains like immer-sive office environments <ref> [35, 18] </ref>, living spaces, and theater performances [25].
Reference: [19] <author> Y. Ivanov, A.F. Bobick, and J. Lui. </author> <title> Fast lighting independent background subtraction. </title> <booktitle> In IEEE Workshop on Visual Surveillance - VS'98, </booktitle> <pages> pages 49-55, </pages> <month> January </month> <year> 1998. </year> <note> Also appears as MIT Media Lab Perceptual Computing Group TR#437. </note>
Reference-contexts: Even this modest use of lighting effects enhances the ambiance of the KidsRoom. The lighting is fully computer controlled using a MIDI light board. Some of our recent efforts in using automated vision systems in theater [25] use a multi-camera segmentation method that is invariant to lighting changes <ref> [19] </ref>. 8.4 Animation Control To capture the imaginative flavor of a story-book and to prevent the video effects from dominating the attention of the children, the KidsRoom uses layered, still-frame, cartoon-like animation sequences. <p> Recent work motivated by this problem may alleviate this constraint <ref> [19, 12] </ref>. * Even in a space as large as 24 feet by 18 feet with a high ceiling, placing cameras so that the resulting views were non-occluded proved tricky.
Reference: [20] <author> M.W. Krueger. </author> <title> Environmental technology: Making the real world virtual. </title> <journal> In Communications of the ACM, </journal> <volume> volume 36, </volume> <pages> pages 36-37, </pages> <year> 1993. </year>
Reference-contexts: Even today, most work in augmented environments requires cumbersome sensing and head-mounted display gear [1]. Research on physical, remotely sensed, interactive spaces began with Krueger's Videoplace system <ref> [20] </ref>. Krueger designed installations that explored many different modes of interaction, most of which entailed large body gesture. In one example, the user interacted with his or her own silhouette on video screens.
Reference: [21] <author> Margot Lovejoy. </author> <title> Postmodern Currents: Art and Artists in the Age of Electronic Media. </title> <address> Ann Arbour, London, England, </address> <year> 1989. </year>
Reference-contexts: A variety of artistic experiments have been undertaken involving computerized spaces. A review of this work is beyond the scope of this paper, but references and a critical analysis of some of the experiments are available <ref> [21, 26] </ref>. A notable installation is Masaki Fujihata's Beyond Pages, featuring a virtual book whose illustrations of objects such as a lamp and door react to the user's gestures.
Reference: [22] <author> P. Maes, A. Pentland, B. Blumberg, T. Darrell, J. Brown, and J. Yoon. </author> <title> ALIVE: Artificial life interactive video environment. </title> <journal> Intercommunication, </journal> <volume> 7 </volume> <pages> 48-49, </pages> <year> 1994. </year>
Reference-contexts: The ALIVE project improved on Krueger's system by replacing special blue-screening hardware with computer vision algorithms that can track the position and gestures of a single person moving in front of an arbitrarily complex, static background <ref> [22] </ref>. A single user can interact with virtual creatures by watching his or her own image superimposed with behavior-based creatures on a large video wall. The user must orient towards the video wall to observe the interesting action.
Reference: [23] <author> A. Pentland. </author> <title> Smart rooms. </title> <journal> Scientific American, </journal> <volume> 274(4), </volume> <month> April </month> <year> 1996. </year>
Reference-contexts: The KidsRoom is an example of systems of the second form, where the computer interface becomes unobtrusively embedded in the physical world itself. Such systems have been alternately termed augmented environments, immersive environments, intelligent rooms [31], smart rooms <ref> [23] </ref>, and interactive spaces. One early example of augmenting a physical space was the Media Room project of Bolt and Negroponte [6]. Their system allowed a user sitting in a chair, ostensibly in his or her future living room, to interact with a screen by pointing and talking.
Reference: [24] <author> Claudio S. Pinhanez, Kenji Mase, and Aaron F. Bo-bick. </author> <title> Interval scripts: a design paradigm for story-based interactive systems. </title> <booktitle> In Proc. of Human Factors in Computing Systems (CHI), </booktitle> <pages> pages 287-294, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: We note that an alternative mechanism to timers is to use the AI concept of planning to model the change in the states of the world [3]. Recently, Pinhanez, Mase, and Bobick <ref> [24] </ref> have proposed the use of interval scripts, where all the sensing and actuating activities are associated with temporal intervals, whose activation is determined by the result of a constraint satisfaction algorithm based on the input from the sensors and the past interaction.
Reference: [25] <author> C.S. Pinhanez and A.F. Bobick. It/I: </author> <title> Theatre with an automatic and reactive computer graphics character. </title> <booktitle> In Proc. of SIGGRAPH'98 Sketches, </booktitle> <month> July </month> <year> 1998. </year>
Reference-contexts: Bederson and Druin believe, as do we, that the best immersive physical environments will have multi-modal inputs and outputs [4]. Increasing computational speed is now making it possible to explore domains like immer-sive office environments [35, 18], living spaces, and theater performances <ref> [25] </ref>. The two major obstacles to building fully-automated reactive spaces are (1) finding practical, computationally-feasible sensing modalities that can understand a variety of different types of human action and interaction and (2) developing a computationally-feasible control mechanism and inter-communication architecture for coordinating perceptual input, narrative control, and perceptual output systems. <p> Even this modest use of lighting effects enhances the ambiance of the KidsRoom. The lighting is fully computer controlled using a MIDI light board. Some of our recent efforts in using automated vision systems in theater <ref> [25] </ref> use a multi-camera segmentation method that is invariant to lighting changes [19]. 8.4 Animation Control To capture the imaginative flavor of a story-book and to prevent the video effects from dominating the attention of the children, the KidsRoom uses layered, still-frame, cartoon-like animation sequences.
Reference: [26] <author> Frank Popper. </author> <title> Art of the Electronic Age. </title> <publisher> Thames and Hudson, </publisher> <address> London, England, </address> <year> 1993. </year>
Reference-contexts: A variety of artistic experiments have been undertaken involving computerized spaces. A review of this work is beyond the scope of this paper, but references and a critical analysis of some of the experiments are available <ref> [21, 26] </ref>. A notable installation is Masaki Fujihata's Beyond Pages, featuring a virtual book whose illustrations of objects such as a lamp and door react to the user's gestures.
Reference: [27] <author> M. Sendak. </author> <title> Where the Wild Things Are. </title> <publisher> Harpercollins Juvenile Books, </publisher> <year> 1988. </year>
Reference-contexts: Inspired by famous children's stories in which children are transported from their bedrooms to magical places (e.g. <ref> [2, 34, 27] </ref>), the story begins in a child's bedroom and progresses through three other worlds. We will describe the last world in detail, to give the reader a feel for the story, it's characters, and the interactive responsiveness of the entire system.
Reference: [28] <author> T.B. Sheridan. </author> <title> Musings on telepresence and virtual presence. Presence: </title> <booktitle> Teleoperators and Virtual Environments, </booktitle> <volume> 1(1) </volume> <pages> 120-125, </pages> <year> 1992. </year>
Reference-contexts: The story ties the physical space, the participant's actions, and the different output media together into a coherent, rich, and therefore immersive experience. Some existing work has studied the criteria that lead to the feeling of immersion or presence in virtual environments <ref> [28] </ref>. Here we just note that our system meets eight of the ten criteria commonly identified as important for creating a feeling of presence in a virtual space [29].
Reference: [29] <author> M. Slater and M. Usoh. </author> <title> Presence in immersive virtual environments. </title> <booktitle> In IEEE Virtual Reality Annual International Symposium, </booktitle> <pages> pages 90-96, </pages> <year> 1993. </year>
Reference-contexts: Some existing work has studied the criteria that lead to the feeling of immersion or presence in virtual environments [28]. Here we just note that our system meets eight of the ten criteria commonly identified as important for creating a feeling of presence in a virtual space <ref> [29] </ref>. One of the two criteria the KidsRoom does not meet, a similarity in visual appearance of the subjects and their representation in the virtual environment, does not apply to a system where people are interacting in the real world.
Reference: [30] <author> Christa Sommerer and Laurent Mignonneau. </author> <title> Art as a living system. </title> <journal> Leonardo, </journal> <volume> 30(5), </volume> <month> October </month> <year> 1997. </year>
Reference-contexts: A notable installation is Masaki Fujihata's Beyond Pages, featuring a virtual book whose illustrations of objects such as a lamp and door react to the user's gestures. Artists Christa Sommerer, Laurent Mignonneau, and Naoko Tosa have integrated computer vision, computer graphics, and emotion and speech recognition techniques <ref> [30, 32] </ref>. Bederson and Druin believe, as do we, that the best immersive physical environments will have multi-modal inputs and outputs [4]. Increasing computational speed is now making it possible to explore domains like immer-sive office environments [35, 18], living spaces, and theater performances [25].
Reference: [31] <author> Mark C. Torrance. </author> <title> Advances in human-computer interaction: the intelligent room. </title> <booktitle> In Working notes of the CHI 95 research symposium, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: The KidsRoom is an example of systems of the second form, where the computer interface becomes unobtrusively embedded in the physical world itself. Such systems have been alternately termed augmented environments, immersive environments, intelligent rooms <ref> [31] </ref>, smart rooms [23], and interactive spaces. One early example of augmenting a physical space was the Media Room project of Bolt and Negroponte [6]. <p> The user must orient towards the video wall to observe the interesting action. The Intelligent Room system consists of several cameras and two large screens in a small room <ref> [31] </ref>. A single person is tracked using computer vision, and simple pointing gestures are recovered.
Reference: [32] <author> Naoko Tosa, Hideki Hashimoto, Kaoru Sezaki, Ya-suharu Kunii, Toyotoshi Yamada, Kotaro Sabe, Ryosuke Nishino, Hiroshi Harashima, and Fumio Harashima. </author> <title> Network-based neuro-baby with robotic hand. </title> <booktitle> In Proc. of IJCAI'95 Workshop on Entertainment and AI/Alife, </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: A notable installation is Masaki Fujihata's Beyond Pages, featuring a virtual book whose illustrations of objects such as a lamp and door react to the user's gestures. Artists Christa Sommerer, Laurent Mignonneau, and Naoko Tosa have integrated computer vision, computer graphics, and emotion and speech recognition techniques <ref> [30, 32] </ref>. Bederson and Druin believe, as do we, that the best immersive physical environments will have multi-modal inputs and outputs [4]. Increasing computational speed is now making it possible to explore domains like immer-sive office environments [35, 18], living spaces, and theater performances [25].
Reference: [33] <author> M. Umaschi. </author> <title> Soft toys with computer hearts: building personal storytelling environments. </title> <booktitle> In CHI Extended Abstracts, </booktitle> <pages> pages 20-21. </pages> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: Instead of bringing children to the virtual space on the screen and forcing interaction with special devices, the interface was brought into the world of the children and embedded into devices with which they were already comfortable (also see <ref> [33, 15] </ref>). Druin and Perlin set out to construct immersive physical environments for adults that responded to movement and touch in real physical spaces [14].
Reference: [34] <author> Walt Disney Productions. Bedknobs and broomsticks. Movie, </author> <year> 1971. </year>
Reference-contexts: Inspired by famous children's stories in which children are transported from their bedrooms to magical places (e.g. <ref> [2, 34, 27] </ref>), the story begins in a child's bedroom and progresses through three other worlds. We will describe the last world in detail, to give the reader a feel for the story, it's characters, and the interactive responsiveness of the entire system.
Reference: [35] <author> M. Weiser. </author> <title> Some computer science issues in ubiquitous computing. </title> <journal> In Communications of the ACM, </journal> <volume> volume 36, </volume> <pages> pages 74-84, </pages> <year> 1993. </year>
Reference-contexts: Bederson and Druin believe, as do we, that the best immersive physical environments will have multi-modal inputs and outputs [4]. Increasing computational speed is now making it possible to explore domains like immer-sive office environments <ref> [35, 18] </ref>, living spaces, and theater performances [25].
Reference: [36] <author> Christopher Wren, Ali Azarbayejani, Trevor Darrell, and Alex Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 19(7) </volume> <pages> 780-785, </pages> <month> July </month> <year> 1997. </year> <month> 20 </month>
Reference-contexts: For instance, in the ALIVE system, the position of a person's hands and head are estimated using computer vision, and the relative position of these objects is used to determine if a person is making a gesture <ref> [36] </ref>. The KidsRoom moves beyond just measurement of position towards recognition of action using measurement and context.
References-found: 36

