URL: ftp://ftpipr.ira.uka.de/pub/projects/BRA7274_B-Learn_II/papers/mlj96cb.ps.gz
Refering-URL: http://wwwipr.ira.uka.de/projects/blearn/blearnpub.html
Root-URL: 
Email: baroglio@di.unito.it  attilio@di.unito.it  kaiser@ira.uka.de  nuttin@mech.kuleuven.ac.be  piola@di.unito.it  
Title: Learning Controllers for Industrial Robots  
Author: C. BAROGLIO A. GIORDANA M. KAISER M. NUTTIN R. PIOLA 
Keyword: Robotics, Neural Networks, Fuzzy Controllers, Multistrategy Learning  
Address: Torino, C.so Svizzera 185, 10149 Torino, Italy  Torino, C.so Svizzera 185, 10149 Torino, Italy  Torino, C.so Svizzera 185, 10149 Torino, Italy  
Affiliation: Dipartimento di Informatica, Universita di  Dipartimento di Informatica, Universita di  University of Karlsruhe, Institute for Real-Time Computer Systems Robotics  Katholieke Universiteit Leuven, Department of Mechanical Engineering, Division PMA  Dipartimento di Informatica, Universita di  
Note: 1-31 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: One of the most significant cost factors in robotics applications is the design and development of real-time robot control software. Control theory helps when linear controllers have to be developed, but it doesn't sufficiently support the generation of non-linear controllers, although in many cases (such as in compliance control), nonlinear control is essential for achieving high performance. This paper discusses how Machine Learning has been applied to the design of (non-)linear controllers. Several alternative function approximators, including Multilayer Perceptrons (MLP), Radial Basis Function Networks (RBFNs), and Fuzzy Controllers are analyzed and compared, leading to the definition of two major families: Open Field Function Function Approximators and Locally Receptive Field Function Approximators. It is shown that RBFNs and Fuzzy Controllers bear strong similarities, and that both have a symbolic interpretation. This characteristics allows for applying both symbolic and statistic learning algorithms to synthesize the network layout from a set of examples and, possibly, some background knowledge. Three integrated learning algorithms, two of which are original, are described and evaluated on experimental test cases. The first test case is provided by a robot KUKA IR-361 engaged into the "peg-into-hole" task, whereas the second is represented by a classical prediction task on the Mackey-Glass time series. From the experimental comparison, it appears that both Fuzzy Controllers and RBFNs synthesised from examples are excellent approximators, and that, in practice, they can be even more accurate than MLPs. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alpaydin, E. </author> <year> (1991). </year> <title> GAL: Networks that grow when they learn and shrink when they forget. </title> <type> Technical Report TR-91-032, </type> <institution> International Computer Science Institute, Berkeley, USA. </institution>
Reference-contexts: Gradient descent can be quite slow but it can easily be adapted in order to be done incrementally on-line. On the contrary, the pseudo-inverse matrix transformation is fast but not incremental. Approaches to construct also the network layout in an incremental manner are, for instance, GAL <ref> (Alpaydin, 1991) </ref> and Fritzke's Growing Cell Structures (Fritzke, 1993). The most common approach to design a Fuzzy Controller is to setup the network layout manually, relying on the domain knowledge of a human expert (Nuttin et al., 1994).
Reference: <author> Asada, H. </author> <year> (1990). </year> <title> Teaching and learning of compliance using neural nets: Representation and generation of nonlinear compliance. </title> <booktitle> In Proceedings of the 1990 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1237 - 1244. </pages>
Reference-contexts: Unfortunately, a reaction proportional to the error is not always the best solution to restore the nominal state as quickly as possible. For the peg-into-hole task, it has even been proven that the optimal controller must be non linear <ref> (Asada, 1990) </ref>. 4 BAROGLIO, GIORDANA, KAISER, NUTTIN AND PIOLA However, while control theory offers a good basis for developing linear controllers, it does not support the design of non-linear controllers sufficiently. <p> This application is particularly interesting because the optimal control is known to be non-linear <ref> (Asada, 1990) </ref>. In our case, both the peg and the hole had a circular section. The diameter of the chamfered peg was 30 [mm], the clearance between the peg and the hole was 0:15 [mm]: The hole was located on a plane surface.
Reference: <author> Barto, A., Sutton, R., and Watkins, C. </author> <year> (1990). </year> <title> Sequential decision problems and neural networks. </title> <booktitle> In Advances in neural information processing system, </booktitle> <volume> volume 2. </volume> <publisher> Morgan Kauffman, </publisher> <address> San mateo, Ca. </address>
Reference: <author> Barto, A. G., Sutton, R. S., and Anderson, C. W. </author> <year> (1983). </year> <title> Neuronlike elements that can solve difficult learning control problems. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <pages> pages 835-846. </pages>
Reference: <author> Berenji, H. </author> <year> (1990). </year> <title> Machine learning in fuzzy control. </title> <booktitle> In International Conference on Fuzzy Logic & Neural Networks, </booktitle> <pages> pages 231-234, </pages> <address> Iizuka, Fukuoka, Japan. </address>
Reference-contexts: The most common approach to design a Fuzzy Controller is to setup the network layout manually, relying on the domain knowledge of a human expert (Nuttin et al., 1994). Variants of the error gradient descent have been proposed in order to refine the fuzzy sets in a second step <ref> (Berenji, 1990) </ref>. In the framework of the present work, three alternative procedures have been defined in order to automate the layout construction of a LRFN.
Reference: <author> Berenji, H. </author> <year> (1992). </year> <title> Fuzzy logic controllers. </title> <editor> In Yager, R. and Zadeh, L., editors, </editor> <title> An Introduction to Fuzzy Logic Applications in Intelligent Systems. </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: In the literature, regression has been tackled by means of different techniques such as neural networks (Rumelhart and McClelland, 1986; Rumelhart et al., 1985), prediction trees, statistics (Cramer, 1974; Quinlan, 1993), regression trees (Breiman et al., 1984), and fuzzy logics <ref> (Berenji, 1992) </ref>; moreover, it has been seen either as a supervised or as a reinforcement learning task (Barto et al., 1983; Gullapalli, 1990). <p> The major result of this research is the characterization of a class of approximators (including Radial Basis Function Networks (Poggio and Girosi, 1990) and Fuzzy Controllers <ref> (Berenji, 1992) </ref>), that we will call Locally Receptive Field Networks (LRFN), which exhibits properties that are more interesting than those of the well-known multilayer perceptron. <p> Therefore, empirical tools such as Fuzzy Controllers <ref> (Berenji, 1992) </ref>, that allow non-linear control functions to be realized while avoiding the burden of developing a mathematical model, are attracting a lot of attention. <p> As a matter of fact, Fuzzy Controllers do not correspond to a single architecture but to a wide family that contains the topology of Figure 2b as a special case. Nevertheless, in our research, we focused on a specific topology, derived from the one proposed by Berenji <ref> (Berenji, 1992) </ref>. Figure 6 shows the corresponding network representation. Different to RBFNs, the fuzzy controller is organized as a three-layered network plus an input layer. The first hidden layer neurons are feature detectors with a unidimensional Gaussian activation field, which receives only one input signal. <p> Most of the techniques proposed are, for instance, related to the TD () method, in which differences of prediction in subsequent timesteps are exploited (see (Sutton and Barto, 1987)). One system that integrates neural and reinforcement learning is Berenji's GARIC <ref> (Berenji and Khedkar, 1992) </ref>. This system uses a fuzzy controller, implemented as a neural network, which is very similar to those described in Section 3. However, it is extremely easy to think to GARIC's variants in which the other kinds of LRFN approximators are used instead of fuzzy controllers.
Reference: <author> Berenji, H. and Khedkar, P. </author> <year> (1992). </year> <title> Learning and tuning fuzzy controllers through reinforcements. </title> <journal> IEEE Transactions on neural networks, </journal> <volume> 3(5) </volume> <pages> 724-740. </pages>
Reference-contexts: In the literature, regression has been tackled by means of different techniques such as neural networks (Rumelhart and McClelland, 1986; Rumelhart et al., 1985), prediction trees, statistics (Cramer, 1974; Quinlan, 1993), regression trees (Breiman et al., 1984), and fuzzy logics <ref> (Berenji, 1992) </ref>; moreover, it has been seen either as a supervised or as a reinforcement learning task (Barto et al., 1983; Gullapalli, 1990). <p> The major result of this research is the characterization of a class of approximators (including Radial Basis Function Networks (Poggio and Girosi, 1990) and Fuzzy Controllers <ref> (Berenji, 1992) </ref>), that we will call Locally Receptive Field Networks (LRFN), which exhibits properties that are more interesting than those of the well-known multilayer perceptron. <p> Therefore, empirical tools such as Fuzzy Controllers <ref> (Berenji, 1992) </ref>, that allow non-linear control functions to be realized while avoiding the burden of developing a mathematical model, are attracting a lot of attention. <p> As a matter of fact, Fuzzy Controllers do not correspond to a single architecture but to a wide family that contains the topology of Figure 2b as a special case. Nevertheless, in our research, we focused on a specific topology, derived from the one proposed by Berenji <ref> (Berenji, 1992) </ref>. Figure 6 shows the corresponding network representation. Different to RBFNs, the fuzzy controller is organized as a three-layered network plus an input layer. The first hidden layer neurons are feature detectors with a unidimensional Gaussian activation field, which receives only one input signal. <p> Most of the techniques proposed are, for instance, related to the TD () method, in which differences of prediction in subsequent timesteps are exploited (see (Sutton and Barto, 1987)). One system that integrates neural and reinforcement learning is Berenji's GARIC <ref> (Berenji and Khedkar, 1992) </ref>. This system uses a fuzzy controller, implemented as a neural network, which is very similar to those described in Section 3. However, it is extremely easy to think to GARIC's variants in which the other kinds of LRFN approximators are used instead of fuzzy controllers.
Reference: <author> Bergadano, F. and Giordana, A. </author> <year> (1988). </year> <title> A knowledge intensive approach to concept induction. </title> <booktitle> In Proceedings of the 5th International Conference on Machine Learning, </booktitle> <pages> pages 305-317, </pages> <address> Ann Arbor, MI. </address> <publisher> Morgan Kauffman. </publisher>
Reference-contexts: Given a set of classes O, it starts the search from a formula , which can be the predicate T rue or a more complex formula (suggested by an expert or deduced from a domain theory) <ref> (Bergadano and Giordana, 1988) </ref>. One major feature, distinguishing SMART+ from other first order language learning systems, is its ability to deal with continuous attributes.
Reference: <author> Bergadano, F., Giordana, A., and Saitta, L. </author> <year> (1988). </year> <title> Learning concepts in noisy environment. </title> <journal> IEEE Transaction on Pattern Analysis and Machine Intelligence, </journal> <pages> pages 555-578. </pages>
Reference-contexts: Given a set of classes O, it starts the search from a formula , which can be the predicate T rue or a more complex formula (suggested by an expert or deduced from a domain theory) <ref> (Bergadano and Giordana, 1988) </ref>. One major feature, distinguishing SMART+ from other first order language learning systems, is its ability to deal with continuous attributes.
Reference: <author> Berthold, M. </author> <year> (1994). </year> <title> A time delay radial basis function network for phoneme recognition. </title> <booktitle> In IEEE International Conference on Neural Networks, </booktitle> <address> Orlando, Florida. </address>
Reference-contexts: Time-Delays in Radial Basis Function Networks For handling time-variant inputs, time delays can also be introduced in RBFNs. Such an extension has been proposed by Berthold <ref> (Berthold, 1994) </ref>. membership values and their history over the last d time steps, such that 10 BAROGLIO, GIORDANA, KAISER, NUTTIN AND PIOLA y (t) = f (~x (t)) = s ( i=1 j=0 In addition, it is also possible to delay the actual input vector ~x (t), i.e., to give each <p> that 10 BAROGLIO, GIORDANA, KAISER, NUTTIN AND PIOLA y (t) = f (~x (t)) = s ( i=1 j=0 In addition, it is also possible to delay the actual input vector ~x (t), i.e., to give each neuron access to ~x (t); ~x (t1); : : : ; ~x (td) <ref> (Berthold, 1994) </ref>. However, this increases the dimension of the input space from dim (~x) to (d+1)fidim (~x) and, consequently, results in a much higher number of connections that are to be considered. Also, a higher number of examples is necessary to sufficiently cover the input space.
Reference: <author> Bonissone, P. and Chiang, K. </author> <year> (1993). </year> <title> Fuzzy logic controllers: from development to deployment. </title> <booktitle> In IEEE International Conference on Neural Networks, volume 2, </booktitle> <address> San Francisco, CA. </address>
Reference-contexts: This property has already been exploited for manually encoding fuzzy controller's layouts using qualitative domain knowledge <ref> (Bonissone and Chiang, 1993) </ref>. We will show how symbolic learning algorithms can be used to automatically build excellent layouts for LRFNs.
Reference: <author> Botta, M. and Giordana, A. </author> <year> (1993). </year> <title> SMART+: A multi-strategy learning tool. </title> <booktitle> In IJCAI-93, Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, volume 2, </booktitle> <address> Chambery, France. </address>
Reference: <author> Breiman, L., Friedman, J., Ohlsen, R., and Stone, C. </author> <year> (1984). </year> <title> Classification And Regression Trees. </title> <publisher> Wadsworth & Brooks, </publisher> <address> Pacific Grove, CA. </address>
Reference-contexts: In the literature, regression has been tackled by means of different techniques such as neural networks (Rumelhart and McClelland, 1986; Rumelhart et al., 1985), prediction trees, statistics (Cramer, 1974; Quinlan, 1993), regression trees <ref> (Breiman et al., 1984) </ref>, and fuzzy logics (Berenji, 1992); moreover, it has been seen either as a supervised or as a reinforcement learning task (Barto et al., 1983; Gullapalli, 1990). <p> One of the procedures is based on a variant of the k-means according to the algorithm described in (Moody and Darken, 1989; Wilpon and Rabiner, 1985). A second procedure is based on CART <ref> (Breiman et al., 1984) </ref>, an algorithm for generating Regression Trees. Finally, the third technique is based on symbolic learning methods in the line of (Sammut et al., 1992), and allows learning both from data and from background knowledge. <p> A setting of fi &gt; 0:5 or even fi &gt; 1 results in an initial cluster set that already provides ambiguous classifications. This is usually not desired. 4.2. Learning LRFNs' Layouts with CART Regression Trees were introduced by <ref> (Breiman et al., 1984) </ref> for function approximation. A regression tree partitions the domain of a function f (~x) into rectangular regions (Fig. 7) where the value of f (~x) is similar, such that it can be approximated by a constant. <p> Therefore, f (~x) is approximated by a histogram as accurately as the subdivision of the input domain permits. The algorithm for generating a regression tree (CART) is simple and a detailed description can be found in <ref> (Breiman et al., 1984) </ref>. Given a learning set f (~x 1 ; y 1 ); : : : ; (~x n ; y n )g; CART works as follows: 1.
Reference: <author> Cramer, H. </author> <year> (1974). </year> <title> Mathematical Methods of Statistics. </title> <publisher> Princeton University Press. </publisher>
Reference: <author> Crowder, R. </author> <year> (1990). </year> <title> Predicting the mackey-glass time series with cascade-correlation learning. </title>
Reference: <editor> In D. Touretzky, G. H. and T.Sejnovsky, editors, </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School, </booktitle> <pages> pages 117-123. </pages> <institution> Carnegie Mellon University. </institution>
Reference-contexts: A thorough description of the system is beyond the aim of this paper, thus we will only describe the subset of it that has been used here. As well as FOIL <ref> (Quinlan, 1990) </ref> and FOCL (Pazzani and Kibler, 1992), SMART+ uses a general to specific learning strategy.

Reference: <author> ERA (1995). </author> <title> Neural Networks: </title> <institution> Producing Dependable Systems, Solihull, West Midlands, UK. ERA Technology. </institution>
Reference-contexts: This fact points out another critical point which must be faced before using neural controllers in industrial applications, i.e., the development of validation techniques that are accepted by the mechanical engineers <ref> (ERA, 1995) </ref>. LEARNING CONTROLLERS FOR INDUSTRIAL ROBOTS 25 a) b) 5.2.
Reference: <author> Fahlmann, S. E. and Lebiere, C. </author> <year> (1989). </year> <booktitle> The cascade-correlation learning architecture. In Advances in Neural Information Processing Systems 2 (NIPS-2), </booktitle> <address> Denver, Colorado. </address>
Reference-contexts: OFFNs' layout is usually defined in an empirical way by using rules of thumb to select both the number of neurons and the connnecting topology; algorithms such as KBANN (Towell et al., 1990) or Cascade-Correlation <ref> (Fahlmann and Lebiere, 1989) </ref> are designed for specific applications or architectures and do not help in the general case. On the contrary, several algorithms are available for automating LRFNs layout construction.
Reference: <author> Fritzke, B. </author> <year> (1993). </year> <title> Growing cell structure: A self-organizing network for unsupervised and supervised learning. </title> <type> Technical Report TR-93-026, </type> <institution> International Computer Science Institute. </institution>
Reference-contexts: On the contrary, the pseudo-inverse matrix transformation is fast but not incremental. Approaches to construct also the network layout in an incremental manner are, for instance, GAL (Alpaydin, 1991) and Fritzke's Growing Cell Structures <ref> (Fritzke, 1993) </ref>. The most common approach to design a Fuzzy Controller is to setup the network layout manually, relying on the domain knowledge of a human expert (Nuttin et al., 1994).
Reference: <author> Gullapalli, V. </author> <year> (1990). </year> <title> A stochastic reinforcement learning algorithm for learning real valued functions. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 671-692. </pages>
Reference: <author> Hornik, K., Stinchcombe, M., and White, H. </author> <year> (1989). </year> <title> Multilayer feed-forward networks are universal approximators. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 359-366. </pages>
Reference-contexts: The choice of an activation function belonging to one or the other family entails properties fundamentally different. As it has been proven in <ref> (Hornik et al., 1989) </ref>, a universal function approximator can be constructed using only three layers of nodes (input, hidden and output), if the activation function in the hidden layer is non-linear.
Reference: <author> Jang, J. </author> <year> (1993). </year> <title> ANFIS: Adaptive-Network-Based Fuzzy Inference System. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, SMC-23(3):665-687. </journal>
Reference: <author> Jones, R., Lee, Y., Barnes, C., Flake, G., Lee, K., and Lewis, P. </author> <year> (1990). </year> <title> Function approximation and time series prediction with neural networks. </title> <booktitle> In Proceedings of IEEE International Joint Conference on Neural Networks, </booktitle> <pages> pages I-649-665. </pages>
Reference: <author> Kaiser, M., Camarinha-Matos, L., Giordana, A., Klingspor, V., del R. Millan, J., Nuttin, M., and Suarez, R. </author> <year> (1994). </year> <title> Robot learning three case studies in robotics and machine learning. </title> <booktitle> In Proceedings of the IVAR '94, </booktitle> <address> Leuven, Belgium. </address>
Reference-contexts: The expected benefits are a decrease in the cost for developing the control software itself and an increase in robots' reliability and flexibility. B-LEARN II is a wide-spectrum project, structured into several subprojects related to different applicative fields <ref> (Kaiser et al., 1994) </ref>. <p> The only way to get rid of this problem is to widen the learning framework by means of an integrated approach <ref> (Kaiser and Kreuziger, 1994) </ref>, using also other learning paradigms (such as reinforcement learning) that are capable of continuously improving the controller's performance.
Reference: <author> Kaiser, M., Friedrich, H., and Dillmann, R. </author> <year> (1995a). </year> <title> Obtaining good performance from a bad teacher. </title> <booktitle> In International Conference on Machine Learning, Workshop on Programming by Demonstration, </booktitle> <address> Tahoe City, California. </address>
Reference-contexts: It is extremely hard to explicitly formalize this knowledge as a theory; nevertheless, it is easy to apply it to generate examples of control, and even from bad examples, control knowledge can be obtained <ref> (Kaiser et al., 1995a) </ref>. Considering this second knowledge source, we immediately recognize the typical supervised learning framework, that can be applied for regression as well as for classification problems. We would like, however, to stress the importance of exploiting qualitative theories too.
Reference: <author> Kaiser, M., Klingspor, V., del R. Millan, J., Accame, M., Wallner, F., and Dillmann, R. </author> <year> (1995b). </year> <title> Using machine learning techniques in real-world mobile robots. </title> <journal> IEEE Expert. </journal>
Reference-contexts: However, the cost of programming such robots is high, and learning capabilities, i.e., the ability of the robot to gain profit from its experiences, become indispensible for fully exploiting the robot's potential autonomy <ref> (Kaiser et al., 1995b) </ref>. In this paper, we describe the results of an investigation done in the framework of the Esprit project No. 7274, B-LEARN II. The fundamental goal of the project is the enhancement of current industrial robots by incorporating learning capabilities on all levels of robot control.
Reference: <author> Kaiser, M. and Kreuziger, J. </author> <year> (1994). </year> <title> Integration of symbolic and connectionist processing to ease robot programming and control. </title> <booktitle> In ECAI'94 Workshop on Combining Symbolic and Connectionist Processing, </booktitle> <pages> pages 20 - 29. </pages>
Reference-contexts: The expected benefits are a decrease in the cost for developing the control software itself and an increase in robots' reliability and flexibility. B-LEARN II is a wide-spectrum project, structured into several subprojects related to different applicative fields <ref> (Kaiser et al., 1994) </ref>. <p> The only way to get rid of this problem is to widen the learning framework by means of an integrated approach <ref> (Kaiser and Kreuziger, 1994) </ref>, using also other learning paradigms (such as reinforcement learning) that are capable of continuously improving the controller's performance.
Reference: <author> Kaiser, M., Retey, A., and Dillmann, R. </author> <year> (1995c). </year> <title> Robot skill acquisition via human demonstration. </title> <booktitle> In Proceedings of the International Conference on Advanced Robotics (ICAR '95). </booktitle>
Reference: <author> Lapedes, A. </author> <title> and R.Farber (1987). Nonlinear signal processing using neural networks: Prediction and system modeling. </title> <type> Technical Report LA-UR-87-2662, </type> <institution> Los Alamos National Laboratory. </institution>
Reference: <author> Mason, M. </author> <year> (1981). </year> <title> Compliance and force control for computer controlled manipulators. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 11. </volume>
Reference-contexts: To this aim, data originating from force and torque sensors are employed. In general, compliant motion refers to tasks that require the robot to establish or maintain contact with its environment such that the capability of continuously adapting the robot's action to its perception is needed <ref> (Mason, 1981) </ref>. As an example, we can think of executing the insertion of a peg into a hole.
Reference: <author> Miller, W. T., Sutton, R. S., and Werbos, P. J. </author> <year> (1990). </year> <title> Neural networks for control. </title> <publisher> The MIT Press. </publisher>
Reference-contexts: Furthermore, LRFNs LEARNING CONTROLLERS FOR INDUSTRIAL ROBOTS 3 allow for incremental learning, which is an important issue especially when realizing adaptive controllers <ref> (Miller et al., 1990) </ref>. An important novelty is the multistrategy method we propose for learning LRFNs from examples of correct behavior and background knowledge.
Reference: <author> Moody, J. </author> <year> (1989). </year> <title> Fast learning in multi-resolution hierarchies. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Regarding the learning procedure based on modified k-means, we refer to the work by <ref> (Moody and Darken, 1989) </ref>. He reports a NDEI of 0.055 obtained with a training set of 10,000 examples and 1,000 hidden neurons.
Reference: <author> Moody, J. and Darken, C. </author> <year> (1988). </year> <title> Learning with localized receptive fields. </title> <editor> In Sejnowski, T., Touretzky, D., and Hinton, G., editors, </editor> <booktitle> Connectionist Models Summer School, </booktitle> <institution> Carnegie Mellon University. </institution>
Reference-contexts: Afterwards, the networks can be trained on-line e.g. by error minimization using a gradient descent technique, which has the advantage that it is also applicable on-line. LEARNING CONTROLLERS FOR INDUSTRIAL ROBOTS 13 4.1. Learning LRFNs' Layout by means of Statistical Clustering The original proposal by Moody and Darken <ref> (Moody and Darken, 1988) </ref> for learning RBFNs' layouts was to use a modified k-means clustering algorithm to find a set of k clusters. However, k-means is an unsupervised algorithm, i.e., it does not take the output information into account. <p> An obvious way to train the cluster centers during training is to apply a Kohonen-style nearest neighbour algorithm, also referred to as adaptive incremental k-means algorithm <ref> (Moody and Darken, 1988) </ref>. Given an example (~x; y), the center of the cluster closest to ~x is moved into the direction of ~x according to ~x closest = ~x closest + (~x ~x closest ) where denotes a learning rate.
Reference: <author> Moody, J. and Darken, C. </author> <year> (1989). </year> <title> Fast learning in networks of locally tuned units. </title> <booktitle> Neural Computations, </booktitle> <volume> 1(2) </volume> <pages> 281-294. </pages>
Reference-contexts: Regarding the learning procedure based on modified k-means, we refer to the work by <ref> (Moody and Darken, 1989) </ref>. He reports a NDEI of 0.055 obtained with a training set of 10,000 examples and 1,000 hidden neurons.
Reference: <author> Musavi, M., Ahmed, W., Chan, K., Faris, K., and Hummels, D. </author> <year> (1992). </year> <title> On the training of radial basis function classifiers. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 595-603. </pages>
Reference-contexts: If the examples given for training the RBF are in the form of (~x; ~y) with ~y being the desired output vector for input ~x, the network construction should use this information. The procedure applied for the experiments described in Section 5 is based on work presented in <ref> (Musavi et al., 1992) </ref>. <p> Differently than the observations documented in <ref> (Musavi et al., 1992) </ref>, for function approximation problems as they are considered here, selecting ff &lt; 1 has proven to provide very satisfactory results, both in terms of network size and final approximation accuracy (see Section 5). The fi parameter determines the initial size of the clusters.
Reference: <author> Nuttin, M., Van Brussel, H., Baroglio, C., and Piola, R. </author> <year> (1994). </year> <title> Fuzzy controller synthesis in robotic assembly: Procedure and experiments. </title> <booktitle> In FUZZ-IEEE-94: Third IEEE International Conference on Fuzzy Systems, World Congress on Computational Intelligence. </booktitle>
Reference-contexts: Approaches to construct also the network layout in an incremental manner are, for instance, GAL (Alpaydin, 1991) and Fritzke's Growing Cell Structures (Fritzke, 1993). The most common approach to design a Fuzzy Controller is to setup the network layout manually, relying on the domain knowledge of a human expert <ref> (Nuttin et al., 1994) </ref>. Variants of the error gradient descent have been proposed in order to refine the fuzzy sets in a second step (Berenji, 1990). In the framework of the present work, three alternative procedures have been defined in order to automate the layout construction of a LRFN.
Reference: <author> Nuttin, M., Van Brussel, H., Peirs, J., Soembagijo, A. S., and Sonck, S. </author> <year> (1995). </year> <title> Learning the peg-into-hole assembly operation with a connectionist reinforcement technique. </title> <booktitle> In Second LEARNING CONTROLLERS FOR INDUSTRIAL ROBOTS 31 International CIRP Workshop on Learning in Intelligent Manufacturing Systems, </booktitle> <pages> pages 335-357, </pages> <address> Budapest, Hungary. </address>
Reference: <author> Park, J. and Sandberg, W. </author> <year> (1993). </year> <title> Universal approximation using radial-basis functions. </title> <booktitle> Neural Computation, </booktitle> <pages> 5. </pages>
Reference-contexts: It has been proven that these networks are capable of universal approximation on &lt; or on compact subsets of &lt; <ref> (Park and Sandberg, 1993) </ref>, given suitable centers i . 3.3. Time-Delays in Radial Basis Function Networks For handling time-variant inputs, time delays can also be introduced in RBFNs.
Reference: <author> Pazzani, M. and Kibler, D. </author> <year> (1992). </year> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 57-94. </pages>
Reference-contexts: A thorough description of the system is beyond the aim of this paper, thus we will only describe the subset of it that has been used here. As well as FOIL (Quinlan, 1990) and FOCL <ref> (Pazzani and Kibler, 1992) </ref>, SMART+ uses a general to specific learning strategy.
Reference: <author> Peng, J. and Williams, R. </author> <year> (1992). </year> <title> Efficient learning and planning within the Dyna framework. </title> <booktitle> In Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <address> Honolulu, HI. </address>
Reference: <author> Poggio, T. and Girosi, F. </author> <year> (1990). </year> <title> Networks for approximation and learning. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78(9) </volume> <pages> 1481-1497. </pages>
Reference-contexts: The major result of this research is the characterization of a class of approximators (including Radial Basis Function Networks <ref> (Poggio and Girosi, 1990) </ref> and Fuzzy Controllers (Berenji, 1992)), that we will call Locally Receptive Field Networks (LRFN), which exhibits properties that are more interesting than those of the well-known multilayer perceptron. <p> A good example of the first family is the well-known sigmoid function (x) = 1 1+e x , widely used in MLPs and in all their descendants. Examples of the second family are the multidimensional Gaussian functions used in Radial Basis Function Networks (RBFNs) <ref> (Poggio and Girosi, 1990) </ref> or in Statistical Neural Networks (SNN) (Specht, 1988; Specht, 1990). The choice of an activation function belonging to one or the other family entails properties fundamentally different. <p> LEARNING CONTROLLERS FOR INDUSTRIAL ROBOTS 9 3.2. Radial Basis Function Networks RBFNs (Fig. 2b) are a family of LRF-Networks architecture that has already been investigated by several authors and recently received a strong mathematical foundation thanks to Poggio and Girosi <ref> (Poggio and Girosi, 1990) </ref>. Principally, a RBFN consists of an input layer holding the current input values, a hidden layer representing a number of closed regions (often called kernels) in the input space, and an output layer integrating the signals calculated by the hidden layer units.
Reference: <author> Quinlan, J. </author> <year> (1993). </year> <title> Combining instance-based and model-based learning. </title> <booktitle> In Proceedings of the 10 th machine learning conference, </booktitle> <pages> pages 236-243, </pages> <address> Amherst, MA. </address>
Reference: <author> Quinlan, R. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266. </pages>
Reference-contexts: A thorough description of the system is beyond the aim of this paper, thus we will only describe the subset of it that has been used here. As well as FOIL <ref> (Quinlan, 1990) </ref> and FOCL (Pazzani and Kibler, 1992), SMART+ uses a general to specific learning strategy.
Reference: <author> Rumelhart, D., Hinton, G., and Williams, R. </author> <year> (1985). </year> <title> Learning internal representations by error propagation. </title> <type> Technical Report 8506, </type> <institution> Institute for Cognitive Science, La Jolla: University of California, </institution> <address> San Diego. </address>
Reference-contexts: Let moreover f (~x) depend upon a set P of tunable parameters. The error gradient descent is performed by iteratively updating each parameter P i 2 P with the following rule <ref> (Rumelhart et al., 1985) </ref>: P i = @P i @E @y = (Y y) @P i If the update of the parameter P takes place immediately, the learning will be characterized as on-line. <p> For the TDNN experiments, the structure of the network and the number of delays at each layer was designed manually in a trial-and-error manner. Afterwards, the networks were trained by backpropagation <ref> (Rumelhart et al., 1985) </ref>. The topologies used had a complexity ranging from 10 to 20 neurons. The best number of delay units found during the experimentation was 3 in the input layer and 0 in the other layers.
Reference: <author> Rumelhart, D. E. and McClelland, J. L. </author> <year> (1986). </year> <title> Parallel Distributed Processing : Explorations in the Microstructure of Coginition, Parts I & II. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference: <author> Sammut, C., Hurst, S., Kedzier, D., and Michie, D. </author> <year> (1992). </year> <title> Learning to fly. </title> <editor> In Sleeman, D. and Edwards, P., editors, </editor> <booktitle> Machine Learning Proceedings of the Ninth International Workshop (ML92), </booktitle> <pages> pages 385-393. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Approximating Control Functions The task of learning to approximate continuous functions has been investigated in many fields, using alternative approaches such as statistics (Breiman et al., 1984; Specht, 1988; Specht, 1990), connectionism (Rumelhart and McClelland, 1986; Barto et al., 1990), fuzzy logics (Zadeh, 1992; Berenji, 1992), and symbolic machine learning <ref> (Sammut et al., 1992) </ref>. In applicative domains such as robotics and automated controls, two approx-imators attracted a great attention: Multi-Layer Perceptrons (MLPs) and Fuzzy Controllers (FCs). <p> A second procedure is based on CART (Breiman et al., 1984), an algorithm for generating Regression Trees. Finally, the third technique is based on symbolic learning methods in the line of <ref> (Sammut et al., 1992) </ref>, and allows learning both from data and from background knowledge. In the present form, the procedure based on k-means is immediately applicable to the RBFN and TDRBFN architectures whereas the other two have been implemented in order to work on the architecture of the fuzzy controller. <p> In this way, the regression problem becomes a classification problem, being O the set of classes and f fl (~x) the learning set, which can be solved using an algorithm such as C4.5. An example of this method is also described in <ref> (Sammut et al., 1992) </ref>. 16 BAROGLIO, GIORDANA, KAISER, NUTTIN AND PIOLA The classification knowledge in a decision tree can be processed similarly to the one encoded in regression trees, in order to obtain an LRF network.
Reference: <author> Sanger, T. </author> <year> (1991). </year> <title> A tree-structured adaptive network for function approximate in high-dimensional spaces. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 2(2) </volume> <pages> 285-293. </pages>
Reference: <author> Specht, D. </author> <year> (1988). </year> <title> Probabilistic neural networks for classification mapping, or associative memory. </title> <booktitle> In IEEE International Conference on Neural Networks, </booktitle> <volume> volume 1, </volume> <pages> pages 525-532. </pages>
Reference: <author> Specht, D. </author> <year> (1990). </year> <title> Probabilistic neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 3 </volume> <pages> 109-118. </pages>
Reference: <author> Sutton, R. and Barto, A. </author> <year> (1987). </year> <title> A temporal-difference method of classical conditioning. </title> <booktitle> In proceedings of the Ninth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 355-378, </pages> <address> Seattle, WA. </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: Most of the techniques proposed are, for instance, related to the TD () method, in which differences of prediction in subsequent timesteps are exploited (see <ref> (Sutton and Barto, 1987) </ref>). One system that integrates neural and reinforcement learning is Berenji's GARIC (Berenji and Khedkar, 1992). This system uses a fuzzy controller, implemented as a neural network, which is very similar to those described in Section 3.
Reference: <author> Towell, G. and Shavlik, J. </author> <year> (1993). </year> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13(1) </volume> <pages> 71-101. </pages>
Reference-contexts: Such mappings, which are naturally supported by the RBFNs are left out from the learning algorithm used by KBANN. KBANN has been improved by adding algorithms for turning a multilayer perceptron back into a propositional theory (see <ref> (Towell and Shavlik, 1993) </ref> for a description of the method), a process we will call "inverse mapping of the network".
Reference: <author> Towell, G., Shavlik, J., and Noordwier, M. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of the 8 th National Conference on Artificial Intelligence AAAI'90, </booktitle> <pages> pages 861-866. </pages>
Reference-contexts: A trained MLP has therefore the tendency to overgeneralize. Depending on the application (e.g., if it is safety-critical or not), under (over)generalization can be either an advantage or a disadvantage. by a conjunctive logical assertion. Finally, an important property of LRFNs (as opposed to MLPs, which, with few exceptions <ref> (Towell et al., 1990) </ref>, are black-boxes w.r.t. their interpretation) is the possibility to directly obtain a symbolic interpretation of the hidden neurons. <p> OFFNs' layout is usually defined in an empirical way by using rules of thumb to select both the number of neurons and the connnecting topology; algorithms such as KBANN <ref> (Towell et al., 1990) </ref> or Cascade-Correlation (Fahlmann and Lebiere, 1989) are designed for specific applications or architectures and do not help in the general case. On the contrary, several algorithms are available for automating LRFNs layout construction. <p> In the literature, at least two other methods have been already proposed in order to integrate the symbolic and connectionist paradigms. The first is KBANN by Shavlik and Towell <ref> (Towell et al., 1990) </ref>, who proposed to use a propositional theory in order to initialize a multilayer perceptron. The considered task was classification in a domain of Boolean features.
Reference: <author> Waibel, A., Hanazawa, T., Hinton, G., Shikano, K., and Lang, K. </author> <year> (1989). </year> <title> Phoneme recognition using time-delay neural networks. </title> <journal> IEEE Transactions on acoustics, speech and signal processing, </journal> <pages> pages 328-339. </pages>
Reference-contexts: It is worth noticing that the choice of these four types originates from an earlier, much wider, explorative investigation. 3.1. Time-Delay Neural Networks The Time-Delay Neural Networks (TDNNs) have been introduced by A. Waibel <ref> (Waibel et al., 1989) </ref> to handle time variant signals, and are basically an extension of the multilayer perceptron. When coping with time variant signals, it is important to consider the short term history in order to predict the future values.
Reference: <author> Wettschereck, D. and Dietterich, T. </author> <year> (1991). </year> <title> Improving the performance of radial basis function networks by learning center locations. </title> <booktitle> In Advances in Neural Information Processing Systems 4 (NIPS-4). </booktitle>
Reference: <author> Weymaere, N. and Martens, J. </author> <year> (1991). </year> <title> A fast and robust learning algorithm for feedforward neural networks. Neural Networks, </title> <type> 4. </type>
Reference: <author> Williams, R. J. </author> <year> (1992). </year> <title> Simple statistical gradient-following algorithms for connectionist reinforcement learning. </title> <booktitle> Machine Learning, </booktitle> <pages> pages 229 -256. </pages>
Reference: <author> Wilpon, J. and Rabiner, L. </author> <year> (1985). </year> <title> A modified k-means clustering algorithm for use in isolated work recognition. </title> <journal> IEEE transactions on acoustics, speech and signal processing, ASSP-33:587-594. </journal>
Reference: <author> Yih, J. and Shieh, J. </author> <year> (1992). </year> <title> On the development of a fuzzy model-based controller for robotic manipulators. </title> <booktitle> In Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems, </booktitle> <address> Raleigh, NC. </address>
Reference: <author> Zadeh, L. </author> <year> (1992). </year> <title> Knowledge representation in fuzzy logic. </title> <editor> In Yager, R. and Zadeh, L., editors, </editor> <title> An Introduction to Fuzzy Logic Applications in Intelligent Systems. </title> <publisher> Kluwer Academic Publishers. </publisher>
References-found: 59

