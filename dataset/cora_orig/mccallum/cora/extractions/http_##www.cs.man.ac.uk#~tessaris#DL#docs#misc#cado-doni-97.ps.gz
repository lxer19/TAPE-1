URL: http://www.cs.man.ac.uk/~tessaris/DL/docs/misc/cado-doni-97.ps.gz
Refering-URL: http://www.cs.man.ac.uk/~tessaris/DL/papers.html
Root-URL: http://www.cs.man.ac.uk
Email: e-mail: fcadoli|doninig@dis.uniroma1.it  
Title: A Survey on Knowledge Compilation  
Author: Marco Cadoli and Francesco M. Donini 
Keyword: Knowledge Representation, Efficiency of Reasoning  
Address: Via Salaria 113, I-00198 Roma, Italy  
Affiliation: Dipartimento di Informatica e Sistemistica Universit OE a di Roma La Sapienza  
Abstract: Knowledge compilation is an AI technique for addressing computationally demanding reasoning problems. In this paper we survey recent results in knowledge compilation of propositional knowledge bases. We first define and limit the scope of such a technique, then we survey exact and approximate knowledge compilation methods. We include a discussion of compilation for non-monotonic knowledge bases. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. L. Astrachan and M. E. Stickel. </author> <title> Caching and lemmaizing in model elimination theorem provers. </title> <booktitle> In Proceedings of the Eleventh International Conference on Automated Deduction (CADE-92), </booktitle> <pages> pages 224238, </pages> <year> 1992. </year>
Reference-contexts: The preprocessing should take a finite amount of time. Note that this definition excludes techniques such as lemmaizing in theorem proving <ref> [1] </ref> as knowledge compilation techniques, unless the same lemmata are reused in many different proofs, and the theorem prover stops in a finite amount of time.
Reference: [2] <author> R. Ben-Eliyahu and R. Dechter. </author> <title> Propositional semantics for disjunctive logic programs. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 12:5387, </volume> <year> 1994. </year>
Reference-contexts: An application of their method in the context of disjunctive logic programs can be found in <ref> [2] </ref>. 5.3. Belief revision Belief revision has to do with evolution of the state of a knowledge base: How does our set of beliefs change when new information arrives? Several researchers attempted to define formalizations of belief revision, subject to the following question.
Reference: [3] <author> R. Ben-Eliyahu and R. Dechter. </author> <title> Default reasoning using classical logic. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 84(12):113150, </volume> <year> 1996. </year>
Reference-contexts: Such a problem is p 2 -complete [29]. As for the possibility of compiling hD; W i into a propositional formula of size polynomial in jDj + jW j, limitations similar to those of circumscription are proved in [8, 27]. Ben-Eliyahu and Dechter <ref> [3] </ref> show how to compile a default theory into a propositional formula, such that default extensions are one-to-one with models of the propositional formula.
Reference: [4] <author> A. Borgida, R. J. Brachman, D. W. Etherington, and H. A. Kautz. </author> <title> Vivid knowledge and tractable reasoning: Preliminary report. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 1146 1152, </pages> <year> 1989. </year>
Reference-contexts: Also theory approximation can be combined with knowledge compilation, e.g., compiling a propositional knowledge base KB into a Horn formula whose models are a subset or a superset of the models of KB. Another issue related to knowledge compilation, which was discussed in the AI literature (cf., e.g., <ref> [36, 4] </ref>), is vivification of knowledge. Vivification is the process of making reasoning tractable by using both preprocessing and default conclusions, at the expense of losing completeness, and, sometimes, soundness. AI Communications 0 () 0 ISSN 0921-7126 / $8.00 , IOS Press 2 Marco Cadoli and Francesco M.
Reference: [5] <author> Y. Boufkhad, E. Gregoire, P. Marquis, B. Mazure, and L. Sajs. </author> <title> Tractable cover compilations. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence (IJCAI-97), </booktitle> <pages> pages 122127, </pages> <year> 1997. </year>
Reference-contexts: Observe that the number of log n-CNF is super-polynomial in n, hence this method is strictly more general than the compilation proposed by Moses and Tennenholtz (log n-CNF queries do not admit an efficient basis). A related approach has been recently proposed in <ref> [5] </ref>. 6.3. Fixed-parameter tractability Another body of research bearing similarities with the idea of knowledge compilation is fixed parameter 12 Marco Cadoli and Francesco M. Donini / A Survey on Knowledge Compilation tractability [20, 21].
Reference: [6] <author> M. Cadoli. </author> <title> Semantical and computational aspects of Horn approximations. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 3944, </pages> <year> 1993. </year>
Reference-contexts: The general inference procedure could still use the approximations to prune its search space. This basic idea has been extended to other polynomial-time target languages in [52, 17], some of which non-propositional. Other researchers have investigated computational properties of Horn compilations <ref> [6, 28] </ref>. 5. Compilation of non-monotonic knowledge bases As we already said, Definition 1 sets two basic requirements, by means of the two polynomials it refers to.
Reference: [7] <author> M. Cadoli, F. M. Donini, P. Liberatore, and M. Schaerf. </author> <title> The size of a revised knowledge base. </title> <booktitle> In Proceedings of the Fourteenth ACM SIGACT SIGMOD SIGART Symposium on Principles of Database Systems (PODS-95), </booktitle> <pages> pages 151162, </pages> <year> 1995. </year> <note> Extended version available as Technical Report DIS 34-96, </note> <institution> Dipartimento di Informatica e Sistemistica, UniversitOEa di Roma La Sapienza, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: She shows that when the size of the revising formula is bounded by a constant, the size of the result is polynomial. Cadoli et al. <ref> [7] </ref> analyze many formalizations for belief revision, pointing out which ones admit a polynomial-size compilation and which ones are unlikely to have any.
Reference: [8] <author> M. Cadoli, F. M. Donini, and M. Schaerf. </author> <note> Is intractability of non-monotonic reasoning a real drawback? Artificial Intelligence Journal, 88(12):215251, </note> <year> 1996. </year>
Reference-contexts: Donini / A Survey on Knowledge Compilation f v (is &lt;f,v&gt; in P)? Fig. 1. Compilation of a problem 2.1. Theoretical limits to knowledge compilation Recalling the distinction of fixed and varying parts of a problem, a possible definition for compilable problems is the following. Definition 1 (cf. <ref> [8] </ref>) A problem [P , F , V ] is compilable if there exist two polynomials p 1 , p 2 and an algorithm ASK such that for each instance f of F there is a data structure D f such that: 1. jD f j p 1 (jf j); 2. <p> As for the [T j= fl, T , fl] problem, we still do not know whether it is compilable or not, although there are some conditional results that give interesting information. It has recently been shown <ref> [8, 34] </ref> that if 1 We thank Pierre Marquis for this remark. Marco Cadoli and Francesco M. <p> Nevertheless, to give a formal proof that a problem is not compilable is quite difficult. As an example, proving that [T j= fl, T , fl] is not compilable implies P 6= NP (a necessary and sufficient condition for compi-lability is shown in <ref> [8] </ref>). In fact, this is a typical situation when dealing with non-compilability of problems, that we can parallel with the traditional notion of polynomial-time intractability: proving intractability is usually done proving NP-hardness, which means that a problem does not have polynomial-time algorithms provided P 6= NP. <p> Such a problem is p 2 -complete [29]. As for the possibility of compiling hD; W i into a propositional formula of size polynomial in jDj + jW j, limitations similar to those of circumscription are proved in <ref> [8, 27] </ref>. Ben-Eliyahu and Dechter [3] show how to compile a default theory into a propositional formula, such that default extensions are one-to-one with models of the propositional formula. <p> They observe that queries in k-CNF admit an efficient basis, namely all clauses with k literals. Along the same lines, Cadoli et al. <ref> [8] </ref> observed that for k-CNF queries compilation of circumscrip-tive knowledge bases into polynomial-size structures is possible. They also point out restricted forms of default theories and queries for which compilation to a polynomial-size structure is possible.
Reference: [9] <author> M. Cadoli, F. M. Donini, M. Schaerf, and R. Silvestri. </author> <title> On compact representations of propositional circumscription. </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 182:183202, </address> <year> 1997. </year>
Reference-contexts: The problem of checking whether CIRC (T ) j= fl, fl being a clause, is p complete [23]. As for the possibility to translate CI RC (T ) into an equivalent formula T 0 of size polynomial in jT j, in <ref> [9] </ref> it is shown that this would imply the collapse of the polynomial hierarchy. Several definitions of equivalence are taken into account, and each of them has different implications. <p> More formally, CIRC (T ) = EGCW A (T ) = T [ ffljfl is a negative clause and fl is true in all minimal models of T g Of course, from a knowledge compilation point of view only the minimal clauses should be added. In <ref> [9] </ref> worst cases are given, for which such a compilation outputs an exponential number of minimal clauses. Nerode et al. [44] compile a database interpreted under circumscription by finding its minimal models using a mixed integer linear programming.
Reference: [10] <author> M. Cadoli, F.M. Donini, P. Liberatore, and M. Schaerf. </author> <title> Preprocessing of intractable problems. </title> <type> Technical Report DIS 24-97, </type> <institution> Dipartimento di Informatica e Sistemistica, UniversitOEa di Roma La Sapienza, </institution> <month> November </month> <year> 1997. </year>
Reference-contexts: An extensive and formal analysis of the similarities and differences of the two approaches is performed in <ref> [10] </ref>. 7. Conclusions In this paper we surveyed knowledge compilation, a technique for making reasoning computationally easier by exploiting the output of a preprocessing phase. The first proposals of such a technique concerned prime implicants/implicates.
Reference: [11] <author> M. Cadoli and M. Schaerf. </author> <title> A survey of complexity results for non-monotonic logics. </title> <journal> Journal of Logic Programming, </journal> <volume> 17:127160, </volume> <year> 1993. </year>
Reference-contexts: The relation to compilation is evident, since entailment problems in most propositional non-monotonic logics are either p p complete <ref> [11] </ref>, while reasoning problems in classical propositional logic are typically either NP- or coNP-complete.
Reference: [12] <author> T. Castell and M. Cayrol. </author> <title> Computation of prime implicates and prime implicants by the Davis and Putnam procedure. </title> <booktitle> In Workshop on Advances in Propositional Deduction, held at ECAI-96, </booktitle> <pages> pages 6164, </pages> <year> 1996. </year> <editor> Marco Cadoli and Francesco M. </editor> <title> Donini / A Survey on Knowledge Compilation 13 </title>
Reference-contexts: However, this method may require too many resolutions to be performed. Research on algorithms for computing prime implicates started a long time ago: some algorithms can be found in <ref> [55, 54, 48, 33, 38, 14, 12] </ref>. Most of them rely on the assumption that the knowledge base is in CNF. Ngair [45] proposes a more general algorithm for computing prime implicates that requires the knowledge base to be a conjunction of DNF formulae.
Reference: [13] <author> A. K. Chandra and G. Markowsky. </author> <title> On the number of prime implicants. </title> <journal> Discrete Mathematics, </journal> <volume> 24:711, </volume> <year> 1978. </year>
Reference-contexts: Ngair [45] proposes a more general algorithm for computing prime implicates that requires the knowledge base to be a conjunction of DNF formulae. From a theoretical study, the numbers of prime im-plicants and prime implicates of a knowledge base with n variables were shown <ref> [13] </ref> to be exponential in n in the worst case. Schrag and Crawford [50] made an experimental study of the number of implicates and prime implicates for CNF knowledge bases of increasing size, at different values of the ratio (number of clauses)/(number of variables).
Reference: [14] <author> J. de Kleer. </author> <title> An improved incremental algorithm for generating prime implicates. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> pages 780 785, </pages> <year> 1992. </year>
Reference-contexts: However, this method may require too many resolutions to be performed. Research on algorithms for computing prime implicates started a long time ago: some algorithms can be found in <ref> [55, 54, 48, 33, 38, 14, 12] </ref>. Most of them rely on the assumption that the knowledge base is in CNF. Ngair [45] proposes a more general algorithm for computing prime implicates that requires the knowledge base to be a conjunction of DNF formulae.
Reference: [15] <author> R. Dechter and I. Rish. </author> <title> Directional resolution: The Davis-Putnam procedure, revisited. </title> <booktitle> In Proceedings of the Fourth International Conference on the Principles of Knowledge Representation and Reasoning (KR-94), </booktitle> <pages> pages 134145, </pages> <year> 1994. </year>
Reference-contexts: Such a set of literals can be seen as an impli-cant of the formula. Since the DP procedure searches through all possible assignments, it eventually produces all implicants, from which prime implicants can be selected. Schrag tests his method for critically-constrained 3CNF knowledge bases. Dechter and Rish <ref> [15] </ref> propose to add implicates to a CNF knowledge base by performing resolutions based on a given ordering of variables. After the addition, one can generate models of the knowledge base in time linear in the compiled knowledge base.
Reference: [16] <author> A. del Val. </author> <title> Tractable databases: How to make propositional unit resolution complete through compilation. </title> <booktitle> In Proceedings of the Fourth International Conference on the Principles of Knowledge Representation and Reasoning (KR-94), </booktitle> <pages> pages 551561, </pages> <year> 1994. </year>
Reference-contexts: After the addition, one can generate models of the knowledge base in time linear in the compiled knowledge base. Hence, their compilation method is more focused on facilitating model generation than query answering. 3.2. Unit-resolution-complete compilations Since the number of prime implicates is exponential in many cases, del Val <ref> [16] </ref> proposes an enhanced method using prime implicates. Let us consider some preliminary aspects that show intuitively the advantages of such a method. <p> Therefore, the clause C 3 is not redundant with respect to unit resolution, and must be kept in the compilation of the knowledge base. del Val <ref> [16] </ref> gives cases in which unit-resolution-complete compilation can discard an exponential number of prime implicates, and gives some favorable experimental comparisons with prime implicates methods for some benchmark problems from theorem proving. <p> More precisely, methods computing impli-cants like Schrag's [49] yield lower bounds: if a query Q is not implied by one of the already computed im-plicants of KB, then KB 6j= Q. On the other hand, all other methods based on implicates, as del Val's <ref> [16] </ref> and Marquis' [39], yield upper bounds if stopped before they completed compilation: if one of the already computed implicates implies the query Q, then KB j= Q. 4.2.
Reference: [17] <author> A. del Val. </author> <title> An analysis of approximate knowledge compilation. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <pages> pages 830 836, </pages> <year> 1995. </year>
Reference-contexts: The general inference procedure could still use the approximations to prune its search space. This basic idea has been extended to other polynomial-time target languages in <ref> [52, 17] </ref>, some of which non-propositional. Other researchers have investigated computational properties of Horn compilations [6, 28]. 5. Compilation of non-monotonic knowledge bases As we already said, Definition 1 sets two basic requirements, by means of the two polynomials it refers to.
Reference: [18] <author> A. del Val. </author> <title> Approximate knowledge compilation: The first order case. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), </booktitle> <pages> pages 498503, </pages> <year> 1996. </year>
Reference-contexts: Related work In this section we briefly mention other forms of knowledge compilation, namely compilation of knowledge bases which already support polynomial-time inference algorithms (Section 6.1), and compilation that does not yield knowledge bases (Section 6.2). As for compilation of first-order knowledge bases, a preliminary investigation is shown in <ref> [18] </ref>. Finally, we briefly compare knowledge compilation with the related idea of fixed parameter tractability (Section 6.3). 6.1. Optimizing polynomial-time query answering Compilation can make sense also for knowledge bases for which the problem of query answering is already doable in polynomial-time.
Reference: [19] <author> P. Doherty, W. Lukaszewicz, and A. Szalas. </author> <title> Computing circumscription revisited: A reduction algorithm. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <pages> pages 15021508, </pages> <year> 1995. </year>
Reference-contexts: Many researchers tried to find classes of first-order formulae whose circumscription is equivalent to a first-order formula, and proposed methods for finding such equivalent formulae. Some of such methods (cf. e.g., <ref> [19] </ref>) work for the propositional case, and can therefore be used as methods for knowledge compilation. 5.2. Default logic A propositional default theory [47] is a pair hD; W i, where D is a collection of special inference rules called defaults, and W is a set of propositional formulae.
Reference: [20] <author> R. G. Downey and M. F. Fellows. </author> <title> Fixed-parameter tractability and completeness: Basic results. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(4):873921, </volume> <year> 1995. </year>
Reference-contexts: A related approach has been recently proposed in [5]. 6.3. Fixed-parameter tractability Another body of research bearing similarities with the idea of knowledge compilation is fixed parameter 12 Marco Cadoli and Francesco M. Donini / A Survey on Knowledge Compilation tractability <ref> [20, 21] </ref>. There are problems such that the input can be naturally split into two parts, e.g., whether a graph G has a clique of size k or not. In this case k is a parameter that can be fixed.
Reference: [21] <author> R. G. Downey and M. F. Fellows. </author> <title> Parameterized complexity, </title> <month> February </month> <year> 1995. </year> <type> Manuscript, </type> <pages> 411 pages. </pages> <note> To appear by Springer in 1997. </note>
Reference-contexts: A related approach has been recently proposed in [5]. 6.3. Fixed-parameter tractability Another body of research bearing similarities with the idea of knowledge compilation is fixed parameter 12 Marco Cadoli and Francesco M. Donini / A Survey on Knowledge Compilation tractability <ref> [20, 21] </ref>. There are problems such that the input can be naturally split into two parts, e.g., whether a graph G has a clique of size k or not. In this case k is a parameter that can be fixed.
Reference: [22] <author> T. Eiter and G. Gottlob. </author> <title> On the complexity of propositional knowledge base revision, updates and conterfactuals. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 57:227270, </volume> <year> 1992. </year>
Reference-contexts: If T and P are inconsistent, can we still infer something reasonable from all the knowledge we have? In other words, what are the logical consequences of the theory T when it is revised by the formula P ? Many formalizations for belief revision have been proposed in the literature <ref> [22] </ref>. Starting from a propositional knowledge base, a reasonable requirement is that after a revision the knowledge base is still expressed as a propositional formula. However, for most of the be Marco Cadoli and Francesco M.
Reference: [23] <author> T. Eiter and G. Gottlob. </author> <title> Propositional circumscription and extended closed world reasoning are p 2 -complete. </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 114:231245, </address> <year> 1993. </year>
Reference-contexts: This simple definition can be enriched in several ways. The problem of checking whether CIRC (T ) j= fl, fl being a clause, is p complete <ref> [23] </ref>. As for the possibility to translate CI RC (T ) into an equivalent formula T 0 of size polynomial in jT j, in [9] it is shown that this would imply the collapse of the polynomial hierarchy.
Reference: [24] <author> M. </author> <title> Fitting. First-Order Logic and Automated Theorem Proving. </title> <publisher> Springer, </publisher> <address> second edition, </address> <year> 1996. </year>
Reference-contexts: Finally a brief conclusion is drawn in Section 7. 2. Knowledge compilation: Terminology In the paper we assume the reader is familiar with the basic concepts of Propositional Logic and Automated Theorem Proving. For an introduction to the subject, see for example <ref> [24] </ref>. Throughout the paper we interchangeably consider a knowledge base both as a set of formulae and as one formula made of the conjunction of all formulae in such a set.
Reference: [25] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability, </title>
Reference-contexts: We denote the size of a knowledge base (or a formula) KB, i.e., the number of distinct occurrences of propositional variables, as jKBj. In the paper we also assume that the reader has some basic notions of computational complexity concepts; we refer to <ref> [25, 46] </ref> for a thorough introduction in the field of complexity. In particular, we refer to complexity classes P, NP, coNP, p p p 3 , PH.
References-found: 25

