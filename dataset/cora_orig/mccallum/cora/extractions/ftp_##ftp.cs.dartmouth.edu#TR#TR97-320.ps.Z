URL: ftp://ftp.cs.dartmouth.edu/TR/TR97-320.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR97-320/
Root-URL: http://www.cs.dartmouth.edu
Email: ney@cs.dartmouth.edu  
Title: On-Line File Caching  
Author: Neal E. Young 
Address: Hanover, NH 03755-3510  
Affiliation: Department of Computer Science Dartmouth College  
Pubnum: Technical Report PCS-TR97-320  
Abstract: Consider the following file caching problem: in response to a sequence of requests for files, where each file has a specified size and retrieval cost, maintain a cache of files of total size at most some specified k so as to minimize the total retrieval cost. Specifically, when a requested file is not in the cache, bring it into the cache, pay the retrieval cost, and choose files to remove from the cache so that the total size of files in the cache is at most k. This problem generalizes previous paging and caching problems by allowing objects of arbitrary size and cost, both important attributes when caching files for world-wide-web browsers, servers, and proxies. We give a simple deterministic on-line algorithm that generalizes many well-known paging and weighted-caching strategies, including least-recently-used, first-in-first-out, flush-when-full, and the balance algorithm. On any request sequence, the total cost incurred by the algorithm is at most k=(k h + 1) times the minimum possible using a cache of size h k. For any algorithm satisfying the latter bound, we show it is also the case that for most choices of k, the retrieval cost is either insignificant or the competitive ratio is constant. This helps explain why competitive ratios of many on-line paging algorithms have been typically observed to be constant in practice. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Proceedings of the Twenty-Ninth Annual ACM Symposium on Theory of Computing, El Paso, Texas, </institution> <month> 4-6 May </month> <year> 1997. </year>
Reference: [2] <author> Allan Borodin, Sandy Irani, Prabhakar Raghavan, and Baruch Schieber. </author> <title> Competitive paging with locality of reference. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 50(2) </volume> <pages> 244-258, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: This is in contrast to the theoretically optimal competitive ratio of k. A number of refinements of competitive analysis have been proposed to try to understand the relevant factors. Borodin, Irani, Raghavan, and Schieber <ref> [2] </ref>, in order to model locality of reference, proposed the access-graph model which restricts the request sequences to paths in a given graph (related papers include [3, 8, 5]).
Reference: [3] <author> Amos Fiat and Anna R. Karlin. </author> <title> Randomized and multipointer paging with locality of reference. </title> <booktitle> In Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 626-634, </pages> <address> Las Vegas, Nevada, 29 May-1 June 1995. </address>
Reference-contexts: A number of refinements of competitive analysis have been proposed to try to understand the relevant factors. Borodin, Irani, Raghavan, and Schieber [2], in order to model locality of reference, proposed the access-graph model which restricts the request sequences to paths in a given graph (related papers include <ref> [3, 8, 5] </ref>). Karlin, Phillips, and Raghavan [10] proposed a variant in which the graph is a Markov chain (i.e. the edges of the graph are assigned probabilities, and the request sequence corresponds to a random walk) (see also [12]).
Reference: [4] <author> Amos Fiat, Richard M. Karp, Michael Luby, Lyle A. McGeoch, Daniel D. Sleator, and Neal E. Young. </author> <title> Competitive paging algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 12(4) </volume> <pages> 685-699, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Sleator and Tarjan also showed that this performance guarantee is the best possible for any deterministic on-line algorithm. A simple randomized paging algorithm called the marking algorithm was shown to be 2 ln k-competitive by Fiat et al. <ref> [4] </ref>. An optimal ln k-competitive randomized paging algorithm was given by McGeoch and Sleator [14]. In [18], deterministic paging strategies were shown to be loosely O (ln k)-competitive.
Reference: [5] <author> Amos Fiat and Ziv Rosen. </author> <title> Experimental studies of access graph based heuristics: </title> <booktitle> Beating the LRU standard? In Proceedings of the Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 63-72, </pages> <address> New Orleans, Louisiana, </address> <month> 5-7 January </month> <year> 1997. </year>
Reference-contexts: A number of refinements of competitive analysis have been proposed to try to understand the relevant factors. Borodin, Irani, Raghavan, and Schieber [2], in order to model locality of reference, proposed the access-graph model which restricts the request sequences to paths in a given graph (related papers include <ref> [3, 8, 5] </ref>). Karlin, Phillips, and Raghavan [10] proposed a variant in which the graph is a Markov chain (i.e. the edges of the graph are assigned probabilities, and the request sequence corresponds to a random walk) (see also [12]).
Reference: [6] <editor> IEEE. </editor> <booktitle> 35th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Santa Fe, New Mexico, </address> <month> 20-22 November </month> <year> 1994. </year>
Reference: [7] <author> Sandy Irani. </author> <title> Page replacement with multi-size pages and applications to Web caching. </title> <booktitle> In ACM [1], </booktitle> <pages> pages 701-710. </pages>
Reference-contexts: For these two cases, Irani <ref> [7] </ref> gave O (log 2 k)-competitive randomized on-line algorithms. Comment: the importance of sizes and costs. File caching is important for world-wide-web applications. For instance, in browsers and proxy servers remote files are cached locally to avoid remote retrieval. <p> Comment: the importance of sizes and costs. File caching is important for world-wide-web applications. For instance, in browsers and proxy servers remote files are cached locally to avoid remote retrieval. In web servers, disk files are cached in fast memory to speed response time. As Irani points out (see <ref> [7] </ref> and references therein), file size is an important consideration; caching policies adapted from memory management applications that don't take size into account do not work well in practice. Allowing arbitrary costs is likely to be important as well.
Reference: [8] <author> Sandy Irani, Anna R. Karlin, and Steven Phillips. </author> <title> Strongly competitive algorithms for paging with locality of reference. </title> <journal> SIAM Journal on Computing, </journal> <volume> 25(3) </volume> <pages> 477-497, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: A number of refinements of competitive analysis have been proposed to try to understand the relevant factors. Borodin, Irani, Raghavan, and Schieber [2], in order to model locality of reference, proposed the access-graph model which restricts the request sequences to paths in a given graph (related papers include <ref> [3, 8, 5] </ref>). Karlin, Phillips, and Raghavan [10] proposed a variant in which the graph is a Markov chain (i.e. the edges of the graph are assigned probabilities, and the request sequence corresponds to a random walk) (see also [12]).
Reference: [9] <author> David Karger, Eric Lehman, Tom Leighton, Matthew Levine, Daniel Lewin, and Rina Pani-grahy. </author> <title> Consistent hashing and random trees: Distributed caching protocols for relieving hot spots on the World Wide Web. </title> <booktitle> In ACM [1], </booktitle> <pages> pages 654-663. </pages>
Reference-contexts: Finally, the focus here is on simple local caching strategies, rather than distributed strategies in which servers cooperate to cache pages across a network (see e.g. <ref> [9] </ref>). 2 Manasse, McGeoch, and Sleator [13] show that no deterministic on-line algorithm for the well-known k-server problem on any metric space of more than k points is better than k kh+1 -competitive.
Reference: [10] <author> Anna R. Karlin, Steven J. Phillips, and Prabhakar Raghavan. </author> <title> Markov paging (extended abstract). </title> <booktitle> In 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 208-217, </pages> <address> Pittsburgh, Pennsylvania, </address> <month> 24-27 October </month> <year> 1992. </year> <note> IEEE. </note>
Reference-contexts: Borodin, Irani, Raghavan, and Schieber [2], in order to model locality of reference, proposed the access-graph model which restricts the request sequences to paths in a given graph (related papers include [3, 8, 5]). Karlin, Phillips, and Raghavan <ref> [10] </ref> proposed a variant in which the graph is a Markov chain (i.e. the edges of the graph are assigned probabilities, and the request sequence corresponds to a random walk) (see also [12]).
Reference: [11] <author> Elias Koutsoupias and Christos H. Papadimitriou. </author> <title> Beyond competitive analysis. </title> <booktitle> In 35th Annual Symposium on Foundations of Computer Science [6], </booktitle> <pages> pages 394-400. </pages>
Reference-contexts: Karlin, Phillips, and Raghavan [10] proposed a variant in which the graph is a Markov chain (i.e. the edges of the graph are assigned probabilities, and the request sequence corresponds to a random walk) (see also [12]). Koutsoupias and Papadimitriou <ref> [11] </ref> proposed the comparative ratio (for comparing classes of on-line algorithms) and the diffuse adversary model (in which the adversary chooses a probability distribution, rather than a sequence, from some restricted class of distributions).
Reference: [12] <author> Carsten Lund, Steven Phillips, and Nick Reingold. </author> <title> IP over connection-oriented networks and distributional paging. </title> <booktitle> In 35th Annual Symposium on Foundations of Computer Science [6], </booktitle> <pages> pages 424-434. </pages>
Reference-contexts: Karlin, Phillips, and Raghavan [10] proposed a variant in which the graph is a Markov chain (i.e. the edges of the graph are assigned probabilities, and the request sequence corresponds to a random walk) (see also <ref> [12] </ref>). Koutsoupias and Papadimitriou [11] proposed the comparative ratio (for comparing classes of on-line algorithms) and the diffuse adversary model (in which the adversary chooses a probability distribution, rather than a sequence, from some restricted class of distributions).
Reference: [13] <author> M. S. Manasse, L. A. McGeoch, and D. D. Sleator. </author> <title> Competitive algorithms for server problems. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 208-230, </pages> <year> 1990. </year>
Reference-contexts: Similarly, the marking algorithm was shown to be loosely (2 ln ln k + O (1))-competitive. Uniform sizes, arbitrary costs. The special case of file caching when all file sizes are the same is called weighted caching. For weighted caching, Manasse, McGeoch and Sleator <ref> [13] </ref> showed that an algorithm called the balance algorithm is k-competitive. Subsequently in [18] a generalization of that algorithm called the "greedy-dual" algorithm was shown to be k kh+1 -competitive. The greedy dual algorithm generalizes many well-known paging and weighted-caching strategies, including least-recently-used, first-in-first-out, flush-when-full, and the balance algorithm. <p> Finally, the focus here is on simple local caching strategies, rather than distributed strategies in which servers cooperate to cache pages across a network (see e.g. [9]). 2 Manasse, McGeoch, and Sleator <ref> [13] </ref> show that no deterministic on-line algorithm for the well-known k-server problem on any metric space of more than k points is better than k kh+1 -competitive.
Reference: [14] <author> Lyle A. McGeoch and Daniel Dominic Sleator. </author> <title> A strongly competitive randomized paging algorithm. </title> <journal> Algorithmica, </journal> <volume> 6 </volume> <pages> 816-825, </pages> <year> 1991. </year>
Reference-contexts: A simple randomized paging algorithm called the marking algorithm was shown to be 2 ln k-competitive by Fiat et al. [4]. An optimal ln k-competitive randomized paging algorithm was given by McGeoch and Sleator <ref> [14] </ref>. In [18], deterministic paging strategies were shown to be loosely O (ln k)-competitive.
Reference: [15] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Comm. ACM, </journal> <volume> 28(2) </volume> <pages> 202-208, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Specifically, when a requested file is not in the cache, bring it into the cache, paying the retrieval cost of the file, and choose files to remove from the cache so that the total size of files remaining in the cache is at most k. Following Sleator and Tarjan <ref> [15] </ref>, we say a file caching algorithm is c (h; k)-competitive if on any sequence the total retrieval cost incurred by the algorithm using a cache of size k is at most c (h; k) times the minimum possible cost using a cache of size h. <p> Uniform sizes, uniform costs. With the restriction that all file sizes and costs are the same, the problem is called paging. Paging has been extensively studied. In a seminal paper, Sleator and Tarjan <ref> [15] </ref> showed that least-recently-used and a number of other deterministic on-line paging strategies were k kh+1 -competitive. Sleator and Tarjan also showed that this performance guarantee is the best possible for any deterministic on-line algorithm.
Reference: [16] <author> Neal Young. </author> <title> Competitive paging and dual-guided algorithms for weighted caching and matching. </title> <type> (Thesis) Tech. Rep. </type> <institution> CS-TR-348-91, Computer Science Department, Princeton University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: kh -competitive algorithm is (*; ffi)-loosely c-competitive for any 0 &lt; *; ffi &lt; 1 and : 1 + ln ln * : We also leave the proof of this result to the main paper. (This proof is similar to the proof of Theorem 2.) Since it is shown in <ref> [16, 17] </ref> that the marking algorithm (a randomized on-line algorithm) is (1 + 2 ln k kh )-competitive for paging, it follows that Corollary 2 The marking algorithm is (*; ffi)-loosely c-competitive for paging for c = O 1 + ln ffi 1 The constant in the O-notation is about 2e.
Reference: [17] <author> Neal Young. </author> <title> On-line caching as cache size varies. </title> <booktitle> In Proc. of the Second Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 241-250, </pages> <year> 1991. </year>
Reference-contexts: kh -competitive algorithm is (*; ffi)-loosely c-competitive for any 0 &lt; *; ffi &lt; 1 and : 1 + ln ln * : We also leave the proof of this result to the main paper. (This proof is similar to the proof of Theorem 2.) Since it is shown in <ref> [16, 17] </ref> that the marking algorithm (a randomized on-line algorithm) is (1 + 2 ln k kh )-competitive for paging, it follows that Corollary 2 The marking algorithm is (*; ffi)-loosely c-competitive for paging for c = O 1 + ln ffi 1 The constant in the O-notation is about 2e.
Reference: [18] <author> Neal E. Young. </author> <title> The k-server dual and loose competitiveness for paging. </title> <journal> Algorithmica, </journal> <volume> 11(6) </volume> <pages> 525-541, </pages> <month> June </month> <year> 1994. </year> <month> 8 </month>
Reference-contexts: A simple randomized paging algorithm called the marking algorithm was shown to be 2 ln k-competitive by Fiat et al. [4]. An optimal ln k-competitive randomized paging algorithm was given by McGeoch and Sleator [14]. In <ref> [18] </ref>, deterministic paging strategies were shown to be loosely O (ln k)-competitive. <p> Uniform sizes, arbitrary costs. The special case of file caching when all file sizes are the same is called weighted caching. For weighted caching, Manasse, McGeoch and Sleator [13] showed that an algorithm called the balance algorithm is k-competitive. Subsequently in <ref> [18] </ref> a generalization of that algorithm called the "greedy-dual" algorithm was shown to be k kh+1 -competitive. The greedy dual algorithm generalizes many well-known paging and weighted-caching strategies, including least-recently-used, first-in-first-out, flush-when-full, and the balance algorithm. Arbitrary sizes, cost = 1 or cost = size. <p> Landlord is a generalization of the greedy-dual algorithm <ref> [18] </ref> for weighted caching. <p> Our analysis is based on a simple potential function ( = (h 1) f2ll credit [f ] + k P f2opt cost (f ) credit [f ]) and is substantially simpler than the analysis of the algorithm in <ref> [18] </ref> for the special case of weighted caching. This paper: (*; ffi)-loosely c-competitiveness. <p> This paper: (*; ffi)-loosely c-competitiveness. In practice it has been observed that on "typical" request sequences, paging algorithms such as least-recently-used, using a cache of size k, incur a cost within a small constant factor (independent of k) times the minimum possible using a cache of size k <ref> [18] </ref>. This is in contrast to the theoretically optimal competitive ratio of k. A number of refinements of competitive analysis have been proposed to try to understand the relevant factors. <p> In this paper we introduce a refinement of the aforementioned loosely competitive ratio <ref> [18] </ref> (another previously proposed alternative model). The model is motivated by two observations: In practice, if the retrieval cost is low enough in an absolute sense, the competitive ratio is of no concern. <p> In particular, if an algorithm can be shown to be competitive in this sense, then that is further evidence that it will do well in practice. Our proof is similar in spirit to the proof in <ref> [18] </ref> for the special case of paging, but the proof here is much simpler, more general, and gives a stronger result.
References-found: 18

