URL: http://www.eecs.umich.edu/PPP/ICS94b.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Email: Email: karent@eecs.umich.edu  
Title: Data and Program Restructuring of Irregular Applications for Cache-Coherent Multiprocessors  
Author: Karen A. Tomko and Santosh G. Abraham 
Address: Ann Arbor, MI 48109-2122  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan  
Abstract: Applications with irregular data structures such as sparse matrices or finite element meshes account for a large fraction of engineering and scientific applications. Domain decomposition techniques are commonly used to partition these applications to reduce interprocessor communication on message passing parallel systems. Our work investigates the use of domain decomposition techniques on cache-coherent parallel systems. Many good domain decomposition algorithms are now available. We show that further application improvements are attainable using data and program restructuring in conjunction with domain decomposition. We give techniques for data layout to reduce communication, blocking with subdo-mains to improve uniprocessor cache behavior, and insertion of prefetches to hide the latency of interprocessor communication. This paper details our restructuring techniques and provides experimental results on the KSR1 multiprocessor for a sparse matrix application. The experimental results include counts of cache misses provided by the KSR PMON performance monitoring tool. Our data show that cache coherency traffic can be reduced by 30%-60% using our data layout scheme and that more than 53% of the remaining coherency cache misses can be eliminated using prefetch instructions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anant Agarwal, David Kranz, and Venkat Natara-jan. </author> <title> Automatic partitioning of parallel loops for cache-coherent multiprocessors. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 2-11, </pages> <year> 1993. </year>
Reference-contexts: Automatic partitioning techniques for regular parallel loops on cache-coherent processors which minimize coherency traffic have been developed by Hudak and Abraham [12] and by Agarwal, Kranz and Natarajan <ref> [1] </ref>. These techniques find optimal partitions for programs with linear array subscript expressions. However, the mathematical approaches used do not extend to indirect array references common in irregular code. We use domain decomposition algorithms to partition irregular codes containing indirect access and then apply optimizations to minimize coherency traffic.
Reference: [2] <author> Stephen Barnard and Horst Simon. </author> <title> A fast multi-level implementation of recursive spectral bisections for partitioning unstructured problems. </title> <type> Technical Report RNR-92-33, </type> <institution> NASA Ames Research Center, NAS Systems Division, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: We use domain decomposition algorithms to partition data structures of irregular applications. Many domain decomposition algorithms have been proposed. Some examples are: binary decomposition [3], recursive coordinate bisection (RCB), recursive graph bisection (RGB), recursive spectral bisection (RSB) decomposition <ref> [2] </ref>, [17], greedy algorithms [8] and simulated annealing. These algorithms partition a graph representing the data structure or communication structure of the program with the goal of evenly distributing computational load amongst processors and minimizing the amount of data shared between two or more domains. <p> There are 136; 491 and 306; 635 non-zero elements in the A matrix for the two data sets respectively. The data sets were partitioned into domains using a program provided by Barnard and Simon which implements their Recursive Spectral Bisection (RSB) algorithm <ref> [2] </ref>. The A matrix was partitioned directly (as opposed to partitioning the finite element mesh) since the structure of the A matrix determines the communication pattern within the iterative solver. We used data copying to group together the non-contiguous array sections accessed within each domain (subdomain).
Reference: [3] <author> Marsha J. Berger and Shahid H. Bokhari. </author> <title> A partitioning strategy for nonuniform problems on multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5):570-580, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: In addition, we use information provided by the domain decomposition algorithm to identify the data that will cause coherency misses and thus should be prefetched. We use domain decomposition algorithms to partition data structures of irregular applications. Many domain decomposition algorithms have been proposed. Some examples are: binary decomposition <ref> [3] </ref>, recursive coordinate bisection (RCB), recursive graph bisection (RGB), recursive spectral bisection (RSB) decomposition [2], [17], greedy algorithms [8] and simulated annealing.
Reference: [4] <author> Eric Boyd, John-David Wellman, Santosh G. Abraham, and Edward Davidson. </author> <title> Evaluating the communication performance of MPPs using synthetic sparse matrix multiplication workloads. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 240-250, </pages> <year> 1993. </year>
Reference-contexts: The Kendall Square Research KSR1 was used to evaluate our methods. We give a brief description of the architecture here, much of which has been taken from <ref> [19, 4] </ref>. The KSR1 is characterized by a hierarchical ring interconnection network and cache-only memory architecture. Each cell, consisting of a 20 megahertz processor, a 512 kilobyte subcache, and a 32 megabyte local cache, is connected to a unidirectional pipelined slotted ring.
Reference: [5] <author> Peter Brezany, Michael Gerndt, Viera Sipkova, and Hans Zima. </author> <title> SUPERB support for irregular scientific computations. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 314-321, </pages> <year> 1992. </year>
Reference-contexts: We use a domain decomposition tool to partition the graph and determine the communication dependencies between the domains. Brezany, Gerndt, Sipkova and Zima have incorporated generation of calls to the PARTI library into their SUPERB compiler <ref> [5] </ref>. Hanxleden, Kennedy, Koelbel, Das and Saltz have incorporated PARTI into the FORTRAN D compiler and use some heuristics to optimize communication performance [11].
Reference: [6] <author> David Callahan, Ken Kennedy, and Allan Porterfield. </author> <title> Software prefetching. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 40-52, </pages> <year> 1991. </year>
Reference-contexts: Our results comply with the results in [18], blocking in sparse codes is beneficial only when unavoidable capacity misses 1 are not dominant. Gornish, Granston and Veidenbaum [10] and Callahan, Kennedy and Porterfield <ref> [6] </ref> both propose compiler algorithms for inserting prefetch instructions in regular dense applications. Neither algorithm takes indirect array accesses into account. Windheiser et al. [19] evaluate using prefetch and poststore commands in a sparse matrix application. Similarly, we insert prefetches into a sparse matrix application.
Reference: [7] <author> A. Chatterjee, J.M. Jin, and J.L. Volakis. </author> <title> Application of edge-based finite elements and ABCs to 3-D scattering. </title> <journal> IEEE Transactions on Antennas and Propagation, </journal> <volume> 41 </volume> <pages> 221-226, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: We determine the block size required for each parallel region and use the minimum (most constrained) block size for the entire control loop. 7 Experimental Results In order to evaluate the techniques described above we hand restructured the FEM-ATS radiation modeling application developed at the University of Michigan <ref> [7] </ref> and ran several experiments on a 64 processor Kendall Square Research KSR1. The main routine in FEM-ATS is a sparse solver which uses the biconjugate gradient method to iteratively calculate approximate solutions to a linear system. The vector operations of the main loop are outlined in Figure 11.
Reference: [8] <author> Charbel Farhat and Michel Lesoinne. </author> <title> Automatic partitioning of unstructured meshes for the parallel solution of problems in computational mechanics. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 36 </volume> <pages> 745-764, </pages> <year> 1993. </year>
Reference-contexts: We use domain decomposition algorithms to partition data structures of irregular applications. Many domain decomposition algorithms have been proposed. Some examples are: binary decomposition [3], recursive coordinate bisection (RCB), recursive graph bisection (RGB), recursive spectral bisection (RSB) decomposition [2], [17], greedy algorithms <ref> [8] </ref> and simulated annealing. These algorithms partition a graph representing the data structure or communication structure of the program with the goal of evenly distributing computational load amongst processors and minimizing the amount of data shared between two or more domains.
Reference: [9] <author> Dennis Gannon, William Jalby, and Kyle Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: We use domain decomposition algorithms to partition irregular codes containing indirect access and then apply optimizations to minimize coherency traffic. Blocking and data prefetching are common techniques for improving memory hierarchy performance on uniproces-sors as well as multiprocessors. Gannon, Jalby and Gallivan <ref> [9] </ref> and Wolf and Lam [20] describe methods for improving uniprocessor cache performance using blocking for regular applications. Temam and Jalby [18] model the cache behavior of sparse codes and propose a diagonal blocking technique.
Reference: [10] <author> Edward H. Gornish, Elana D. Granston, and Alexander V. Veidenbaum. </author> <title> Compiler-directed data prefetching in multiprocessors with memory hierarchies. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 354-368, </pages> <year> 1990. </year>
Reference-contexts: We propose a blocking technique using domain decomposition to partition the data assigned to each processor into blocks. Our results comply with the results in [18], blocking in sparse codes is beneficial only when unavoidable capacity misses 1 are not dominant. Gornish, Granston and Veidenbaum <ref> [10] </ref> and Callahan, Kennedy and Porterfield [6] both propose compiler algorithms for inserting prefetch instructions in regular dense applications. Neither algorithm takes indirect array accesses into account. Windheiser et al. [19] evaluate using prefetch and poststore commands in a sparse matrix application.
Reference: [11] <author> Reinhard v. Hanxleden and Ken Kennedy. </author> <title> Relaxing SIMD control flow constraints using loop transformations. </title> <institution> Technical Report Rice COMP TR92-181, Rice University, Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: Brezany, Gerndt, Sipkova and Zima have incorporated generation of calls to the PARTI library into their SUPERB compiler [5]. Hanxleden, Kennedy, Koelbel, Das and Saltz have incorporated PARTI into the FORTRAN D compiler and use some heuristics to optimize communication performance <ref> [11] </ref>. The program analysis in the two compilers mentioned above is similar to the analysis that is required to automate our irregular partitioning scheme, we intend to use what we can from this work in the future.
Reference: [12] <author> David E. Hudak and Santosh G. Abraham. </author> <title> Compiling Parallel Loops for High Performance Computers: Partitioning, Data Assignment, and Remapping. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: The communication optimizations in the SUPERB and FORTRAN D compilers are designed for message passing machines and are not directly useful for our machine model. Automatic partitioning techniques for regular parallel loops on cache-coherent processors which minimize coherency traffic have been developed by Hudak and Abraham <ref> [12] </ref> and by Agarwal, Kranz and Natarajan [1]. These techniques find optimal partitions for programs with linear array subscript expressions. However, the mathematical approaches used do not extend to indirect array references common in irregular code.
Reference: [13] <institution> Kendall Square Research Corporation, </institution> <address> 170 Tracer Lane, Waltham, MA, </address> <month> 02154-1379. </month> <title> KSR1 Principles of Operation, </title> <year> 1991. </year>
Reference-contexts: This transformation was done for all of our experiments in order to minimize conflict cache misses in the data subcache of the KSR1. The measurements reported in our experiments were gathered using the KSR PMON library <ref> [13] </ref>. PMON provides performance data on a per processor basis for all threads in a process. PMON allows access to a hardware event monitor which counts cache miss events, prefetch events and clock cycles for timing.
Reference: [14] <author> L.-C. Lu and M. Chen. </author> <title> Parallelizing loops with indirect array references or pointers. </title> <booktitle> In Proceedings of the 4th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 201-217, </pages> <year> 1991. </year>
Reference-contexts: Since our machine model has a single address space, local and global mapping is not necessary. Ponnusamy, et al. [16] and Lu and Chen <ref> [14] </ref> give methods for building an iteration dependence graph at runtime which is partitioned for parallel execution. We also generate a graph at runtime but it represents the communication dependencies in the data structure not dependencies between loop iterations.
Reference: [15] <author> Ravi Mirchandaney, Joel H. Saltz, Roger M. Smith, David M. Nicol, and Kay Crowley. </author> <title> Principles of run-time support for parallel processors. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 140-152, </pages> <year> 1988. </year>
Reference-contexts: However, on a shared-address system, the size of messages is fixed to the cache line size and the scheduling of messages (the timing of inter-cache transfers) is determined by the data layout and access pattern. Saltz et al. <ref> [15] </ref> have developed a run time library, PARTI, which has been used to facilitate much research on compiling for irregular applications.
Reference: [16] <author> Ravi Ponnusamy, Joel Saltz, Raja Das, Charles Koel-bel, and Alok Choudhary. </author> <title> A runtime data mapping scheme for irregular problems. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 216-219, </pages> <year> 1992. </year>
Reference-contexts: Since our machine model has a single address space, local and global mapping is not necessary. Ponnusamy, et al. <ref> [16] </ref> and Lu and Chen [14] give methods for building an iteration dependence graph at runtime which is partitioned for parallel execution. We also generate a graph at runtime but it represents the communication dependencies in the data structure not dependencies between loop iterations.
Reference: [17] <author> Horst Simon. </author> <title> Partitioning of unstructured problems for parallel processing. </title> <journal> Computing Systems in Engineering, </journal> 2(2/3):135-148, 1991. 
Reference-contexts: We use domain decomposition algorithms to partition data structures of irregular applications. Many domain decomposition algorithms have been proposed. Some examples are: binary decomposition [3], recursive coordinate bisection (RCB), recursive graph bisection (RGB), recursive spectral bisection (RSB) decomposition [2], <ref> [17] </ref>, greedy algorithms [8] and simulated annealing. These algorithms partition a graph representing the data structure or communication structure of the program with the goal of evenly distributing computational load amongst processors and minimizing the amount of data shared between two or more domains.
Reference: [18] <author> Olivier Temam and William Jalby. </author> <title> Characterizing the behavior of sparse algorithms on caches. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pages 578-587, </pages> <year> 1992. </year>
Reference-contexts: Blocking and data prefetching are common techniques for improving memory hierarchy performance on uniproces-sors as well as multiprocessors. Gannon, Jalby and Gallivan [9] and Wolf and Lam [20] describe methods for improving uniprocessor cache performance using blocking for regular applications. Temam and Jalby <ref> [18] </ref> model the cache behavior of sparse codes and propose a diagonal blocking technique. We propose a blocking technique using domain decomposition to partition the data assigned to each processor into blocks. Our results comply with the results in [18], blocking in sparse codes is beneficial only when unavoidable capacity misses <p> Temam and Jalby <ref> [18] </ref> model the cache behavior of sparse codes and propose a diagonal blocking technique. We propose a blocking technique using domain decomposition to partition the data assigned to each processor into blocks. Our results comply with the results in [18], blocking in sparse codes is beneficial only when unavoidable capacity misses 1 are not dominant. Gornish, Granston and Veidenbaum [10] and Callahan, Kennedy and Porterfield [6] both propose compiler algorithms for inserting prefetch instructions in regular dense applications. Neither algorithm takes indirect array accesses into account.
Reference: [19] <author> Daniel Windheiser, Eric Boyd, Eric Hao, Santosh G. Abraham, and Edward Davidson. </author> <title> KSR1 multiprocessor: Analysis of latency hiding techniques in a sparse solver. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, </booktitle> <pages> pages 454-461, </pages> <year> 1993. </year>
Reference-contexts: Gornish, Granston and Veidenbaum [10] and Callahan, Kennedy and Porterfield [6] both propose compiler algorithms for inserting prefetch instructions in regular dense applications. Neither algorithm takes indirect array accesses into account. Windheiser et al. <ref> [19] </ref> evaluate using prefetch and poststore commands in a sparse matrix application. Similarly, we insert prefetches into a sparse matrix application. In addition, we use information provided by the domain decomposition algorithm to identify the data that will cause coherency misses and thus should be prefetched. <p> The Kendall Square Research KSR1 was used to evaluate our methods. We give a brief description of the architecture here, much of which has been taken from <ref> [19, 4] </ref>. The KSR1 is characterized by a hierarchical ring interconnection network and cache-only memory architecture. Each cell, consisting of a 20 megahertz processor, a 512 kilobyte subcache, and a 32 megabyte local cache, is connected to a unidirectional pipelined slotted ring. <p> The majority of interpro-cessor communication occurs between processors during the matrix vector multiply and the vector update of p. Since A is static, the communication pattern is the same for all iterations of the solver. A detailed description of the paral-lelization of FEM-ATS is given in <ref> [19] </ref>. <p> Reproduced from <ref> [19] </ref> We used two data sets in our experiments. The sizes of the data set are n = 8; 841 (9k data set), and n = 20; 033 (20k data set) where the sparse matrix A is nxn.
Reference: [20] <author> Michael E. Wolf and Monica S. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the ACM SIG-PLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 30-44, </pages> <year> 1991. </year>
Reference-contexts: We use domain decomposition algorithms to partition irregular codes containing indirect access and then apply optimizations to minimize coherency traffic. Blocking and data prefetching are common techniques for improving memory hierarchy performance on uniproces-sors as well as multiprocessors. Gannon, Jalby and Gallivan [9] and Wolf and Lam <ref> [20] </ref> describe methods for improving uniprocessor cache performance using blocking for regular applications. Temam and Jalby [18] model the cache behavior of sparse codes and propose a diagonal blocking technique. We propose a blocking technique using domain decomposition to partition the data assigned to each processor into blocks.
References-found: 20

