URL: http://polaris.cs.uiuc.edu/reports/1134.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: A Collection of Codes for Sparse Matrix Computations  
Author: U. Meier G. Skinner J. Gunnels 
Note: CSRD, University of Illinois, 305 Talbot, 104 S. Wright, Urbana, IL 61801. This work was supported in part by the U.S. Department of Energy under Grant No. DOE DE-FG02-85ER25001 and the National Science Foundation under Grant No. NSF CCR-8717942.  
Date: July 1991  
Abstract: This report summarizes software for sparse matrix computations available at CSRD and gives some information about its usage. The packages described include SPLIB, a collection of basic matrix operations, iterative solvers and precondition-ers; RPPACK, a Row Projection methods PACKage; and DNSPCG, a Double precision NonSymmetric Preconditioned Conjugate Gradient package. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. C. Anderson and Y. Saad. </author> <title> "Solving Sparse Triangular Systems on Parallel Computers." </title> <journal> International Journal of High Speed Computing, </journal> <volume> 1 </volume> <pages> 73-95, </pages> <year> 1989. </year> <note> Also appeared as CSRD Report No. 794, </note> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <year> 1988. </year>
Reference-contexts: LEVELS Computes the level scheduling data structure for lower triangular matrices, see <ref> [1] </ref>. RETMX Returns the maximum absolute value in each row of an input matrix. RNRMS Computes the norms of the rows of a matrix. The usual three norms k:k 1 ; k:k 2 ; and k:k 1 are supported. <p> The advantage of this scheme for matrix multiplications has been illustrated in [14] and in <ref> [1] </ref> in the context of triangular system solutions. REFERENCES 41
Reference: [2] <author> R. </author> <title> Bramley "Row Projection Methods for Linear Systems," </title> <type> CSRD Report No. 881, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: In SPLIB, we provide the user with a variety of independent modules, that can be easily extracted used within other codes. SPLIB contains the basic routines from SPARSKIT, along with iterative linear solvers, preconditioners and reordering routines. RPPACK <ref> [2] </ref> [3] is a software package for solving nonsymmetric linear systems by row projection methods, another class of iterative solvers which are often more robust but slower in convergence than the conjugate gradient-like methods used in the above packages. <p> RNSP gives the size of real working storage for preconditioning. See the program documentation for further details. A listing of SPDRV appears in Appendix A. 3 RPPACK 18 3 RPPACK 3.1 Description RPPACK is a software package which was created by Randy Bramley as a research tool <ref> [2] </ref> [3]. It solves a general sparse system of equations by means of a CG accelerated block row projection algorithm. Two basic methods are available, one based on the Kaczmarz or successive projection method and the other based on the Cimmino or sum of projections method.
Reference: [3] <author> R. Bramley "RP-Pack: </author> <title> A Tool for Examining Row Projection Methods," </title> <type> CSRD Report No. 1008, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: In SPLIB, we provide the user with a variety of independent modules, that can be easily extracted used within other codes. SPLIB contains the basic routines from SPARSKIT, along with iterative linear solvers, preconditioners and reordering routines. RPPACK [2] <ref> [3] </ref> is a software package for solving nonsymmetric linear systems by row projection methods, another class of iterative solvers which are often more robust but slower in convergence than the conjugate gradient-like methods used in the above packages. <p> RNSP gives the size of real working storage for preconditioning. See the program documentation for further details. A listing of SPDRV appears in Appendix A. 3 RPPACK 18 3 RPPACK 3.1 Description RPPACK is a software package which was created by Randy Bramley as a research tool [2] <ref> [3] </ref>. It solves a general sparse system of equations by means of a CG accelerated block row projection algorithm. Two basic methods are available, one based on the Kaczmarz or successive projection method and the other based on the Cimmino or sum of projections method.
Reference: [4] <author> I. S. Duff. </author> <title> "A Survey of Sparse Matrix Research." </title> <booktitle> In Proceedings of the IEEE, </booktitle> <volume> Vol. 65, </volume> <pages> pp. 500-535, </pages> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: If the matrix is symmetric we need only to store its lower triangular part. This is a collection of rows whose length varies. A simple method used to store a Symmetric Skyline matrix is to place all the rows in order from 1 to N , <ref> [4] </ref> in a real array A and then keep an integer array which holds the pointers to the beginning of each row. The column positions of the nonzero elements stored in A can be easily derived and are therefore not kept.
Reference: [5] <author> I. S. Duff, A. M. Erisman, and J. K. Reid. </author> <title> Direct Methods for Sparse Matrices. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1986. </year>
Reference-contexts: Many of the other existing schemes are specialized to some extent. The reader is referred to the book by Duff et al. <ref> [5] </ref> for more details. B.1 Storage Formats In the following sections we denote by A the matrix under consideration and by N its row dimension and NN Z the number of its nonzero elements. <p> The savings in memory and in the use of indirect addressing with this scheme over Compressed Sparse Row can be substantial for large values of NBLK. B.1.7 The Symmetric Skyline format (SSK) A Skyline matrix is often referred to as a variable band matrix or a profile matrix <ref> [5] </ref>. The main attraction of skyline matrices is that when pivoting is not necessary then the skyline structure of the matrix is preserved during Gaussian elimination. If the matrix is symmetric we need only to store its lower triangular part. This is a collection of rows whose length varies.
Reference: [6] <author> I. S. Duff, R. G. Grimes, and J. G. Lewis. </author> <title> "Sparse Matrix Test Problems." </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> Vol. 15, </volume> <pages> pp. 1-14, </pages> <year> 1989. </year>
Reference-contexts: These routines are essentially geared towards the utilization of the Harwell/Boeing collection of matrices. The routines readmt and prtmt allow to read and create files containing matrices stored in the H/B format. For details concerning this format the reader is referred to <ref> [6] </ref>. While the purpose of readmt is clear, it is not obvious that one single subroutine can write a matrix in H/B format and still satisfy the needs of all users.
Reference: [7] <author> H. Elman. </author> <title> "Iterative Methods for Large, Sparse, Nonsymmetric Systems of Linear Equations," </title> <type> Technical Report No. 229, </type> <institution> Yale University, </institution> <year> 1982. </year>
Reference-contexts: The advantage of this scheme is that the storage is predictable. SSOR uses the SSOR-iteration matrix as a preconditioner for the system, and is probably the poorest of all preconditioners given here, but easy to implement. Further details of these preconditioners may be found in <ref> [7] </ref>. ILUS performs an ILU (s)-factorization for s levels of fill-in ILUSYM performs a symbolic ILU (s)-factorization for s levels of fill-in, used in ILUS and MILUS ILUT performs an ILUT-factorization (unpublished) which uses a dual thresholding strategy for dropping elements. Arbitrary accuracy is allowed in ILUT. <p> UTLTSL performs a forward solve followed by a backward solve for any of the above transposed factorization matrices (L T y = b, U T x = y). 2 SPLIB 15 2.5 Iterative solvers The iterative solvers given here are conjugate gradient-like. CGNE and CGNR <ref> [7] </ref> are just the classical CG applied to the two types of normal equations with the symmetric positive definite matrices A T A and AA T . Unfortunately, these two methods exhibit slow convergence because the condition number of A T A and AA T increase significantly compared to A.
Reference: [8] <author> R. Fletcher. </author> <title> "Conjugate Gradient Methods for Indefinite Systems." In Numerical Analysis Dundee 1975, </title> <editor> G. Watson, ed. </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: Unfortunately, these two methods exhibit slow convergence because the condition number of A T A and AA T increase significantly compared to A. BICG <ref> [8] </ref>, CGS [18] and CGSTAB [19] are methods which preserve the 3-term recurrence of the residual polynomials, one of CG's strong characteristics, but not the minimization property. GMRES (k) [16] preserves the minimization property in each iteration step, but does not preserve the 3-term recurrence.
Reference: [9] <author> D. Kincaid, J. Respess, D. Young, and R. Grimes. </author> <title> "Algorithm 586 ITPACK 2C: A FORTRAN Package for Solving Large Sparse Linear Systems by Adaptive Accelerated Iterative Methods." </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> Vol. 8, </volume> <pages> pp. 302-322, </pages> <year> 1982. </year>
Reference-contexts: This underscores the importance of providing tools for sparse matric computations. Several efforts have been made to develop software packages that deal with sparse matrices, among which we find SPARSKIT [15], PCGPAK [17], ITPACK <ref> [9] </ref> [10], NSPCG [11], ELLPACK [13], just to mention some of them. Among these packages, ITPACK and ELLPACK deal specificly with symmetric sparse matrices. Our focus is the more difficult and less explored case of nonsymmetric sparse matrices. SPARSKIT, developed by Y. <p> Several sparse matrix data structures are available to represent matrices whose structures range from highly structured to completely unstructured. This package which was developed as part of the ITPACK project of the Center for Numerical Analysis at the University of Texas at Austin <ref> [9] </ref> [10] is here made available in a double precision version on ax1, the Alliant FX2800 of CSRD. Below we will give some excerpts of the NSPCG User's Guide [11]. The complete User's Guide in latex format can be found on ax1 in /groups/mathlib/hbform/dnspcg/usernsp.tex.
Reference: [10] <author> D. R. Kincaid and D. M. Young. </author> <title> "The ITPACK Project: Past, Present, and Future." </title> <type> Technical Report No. </type> <institution> CNA-180, The University of Texas at Austin, Center for Numerical Analysis, </institution> <month> March </month> <year> 1983. </year>
Reference-contexts: This underscores the importance of providing tools for sparse matric computations. Several efforts have been made to develop software packages that deal with sparse matrices, among which we find SPARSKIT [15], PCGPAK [17], ITPACK [9] <ref> [10] </ref>, NSPCG [11], ELLPACK [13], just to mention some of them. Among these packages, ITPACK and ELLPACK deal specificly with symmetric sparse matrices. Our focus is the more difficult and less explored case of nonsymmetric sparse matrices. SPARSKIT, developed by Y. <p> Several sparse matrix data structures are available to represent matrices whose structures range from highly structured to completely unstructured. This package which was developed as part of the ITPACK project of the Center for Numerical Analysis at the University of Texas at Austin [9] <ref> [10] </ref> is here made available in a double precision version on ax1, the Alliant FX2800 of CSRD. Below we will give some excerpts of the NSPCG User's Guide [11]. The complete User's Guide in latex format can be found on ax1 in /groups/mathlib/hbform/dnspcg/usernsp.tex.
Reference: [11] <author> T. C. Oppe, W. D. Joubert and D. R. Kincaid. </author> <title> "NSPCG User's guide. A Package for Solving Large Linear Systems by Various Iterative Methods." </title> <type> Technical Report No. </type> <institution> CNA-216, The University of Texas at Austin, Center for Numerical Analysis, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: This underscores the importance of providing tools for sparse matric computations. Several efforts have been made to develop software packages that deal with sparse matrices, among which we find SPARSKIT [15], PCGPAK [17], ITPACK [9] [10], NSPCG <ref> [11] </ref>, ELLPACK [13], just to mention some of them. Among these packages, ITPACK and ELLPACK deal specificly with symmetric sparse matrices. Our focus is the more difficult and less explored case of nonsymmetric sparse matrices. SPARSKIT, developed by Y. <p> Below we will give some excerpts of the NSPCG User's Guide <ref> [11] </ref>. The complete User's Guide in latex format can be found on ax1 in /groups/mathlib/hbform/dnspcg/usernsp.tex. <p> In addition, the code may also compute the most important 5 diagonals if wanted, or it can get those indicated by the user through the array IOF F . B APPENDIX: DATA STRUCTURES FOR SPARSE MATRICES 39 B.1.5 The Ellpack-Itpack format (ELL) The Ellpack-Itpack format <ref> [12, 20, 11] </ref> is a generalization of the diagonal storage scheme which is intended for general sparse matrices with a limited maximum number of nonze-ros per row. Two rectangular arrays of the same size are required, one real and one integer.
Reference: [12] <author> T. C. Oppe and D. R. Kincaid. </author> <title> "The Performance of ITPACK on Vector Computers for Solving Large Sparse Linear Systems Arising in Sample Oil Reservoir Simulation Problems." </title> <journal> Communications in Applied Numerical Methods, </journal> <volume> Vol. 2, </volume> <pages> pp. 1-7, </pages> <year> 1986. </year> <note> REFERENCES 42 </note>
Reference-contexts: In addition, the code may also compute the most important 5 diagonals if wanted, or it can get those indicated by the user through the array IOF F . B APPENDIX: DATA STRUCTURES FOR SPARSE MATRICES 39 B.1.5 The Ellpack-Itpack format (ELL) The Ellpack-Itpack format <ref> [12, 20, 11] </ref> is a generalization of the diagonal storage scheme which is intended for general sparse matrices with a limited maximum number of nonze-ros per row. Two rectangular arrays of the same size are required, one real and one integer.
Reference: [13] <author> J. R. Rice and R. F. Boisvert (eds.) </author> <title> Solving Elliptic Problems Using ELLPACK. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: This underscores the importance of providing tools for sparse matric computations. Several efforts have been made to develop software packages that deal with sparse matrices, among which we find SPARSKIT [15], PCGPAK [17], ITPACK [9] [10], NSPCG [11], ELLPACK <ref> [13] </ref>, just to mention some of them. Among these packages, ITPACK and ELLPACK deal specificly with symmetric sparse matrices. Our focus is the more difficult and less explored case of nonsymmetric sparse matrices. SPARSKIT, developed by Y. <p> The user may represent the matrix in one of several sparse matrix formats: primary storage (the same format used in the ELLPACK package <ref> [13] </ref> from Purdue University), symmetric diagonal storage, nonsymmetric diagonal storage, symmetric coordinate storage, or nonsymmetric coordinate storage. * The package can be used in a matrix-free mode, in which the user supplies cus tomized routines for performing matrix operations.
Reference: [14] <author> Y. Saad. </author> <title> "Krylov Subspace Methods on Supercomputers." </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> Vol. 10, </volume> <pages> pp. 1200-1232, </pages> <year> 1989. </year>
Reference-contexts: B.1.4 The diagonal format (DIA) The matrices that arise in many applications often consist of a few diagonals. This structure has probably been the first one to be exploited for the purpose of improving performance of matrix by vector products on supercomputers, see references in <ref> [14] </ref>. To store these matrices we may store the diagonals in a rectangular array DIAG (1 : N; 1 : N DIAG) where NDIAG is the number of diagonals. We also need to know the offsets of each of the diagonals with respect to the main diagonal. <p> An additional pointer is needed to indicate where the diagonal elements, which separate the lower from the upper part, are located in this array. B.1.9 The Jagged Diagonal Format (JAD) This storage mode is very useful for the efficient implementation of iterative methods on parallel and vector processors <ref> [14] </ref>. Starting from the CSR format, the idea is to first reorder the rows of the matrix decreasingly according to their number of nonzeros entries. Then, a new data structure is built by constructing what we call "jagged diagonals" (j-diagonals). <p> The advantage of this scheme for matrix multiplications has been illustrated in <ref> [14] </ref> and in [1] in the context of triangular system solutions. REFERENCES 41
Reference: [15] <author> Y. Saad. "SPARSKIT: </author> <title> a Basic Tool Kit for Sparse Matrix Computation," </title> <type> CSRD Report No. 1029, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Principally, all matrices arising where partial differential equations occur have a sparse structure of varying complexity. This underscores the importance of providing tools for sparse matric computations. Several efforts have been made to develop software packages that deal with sparse matrices, among which we find SPARSKIT <ref> [15] </ref>, PCGPAK [17], ITPACK [9] [10], NSPCG [11], ELLPACK [13], just to mention some of them. Among these packages, ITPACK and ELLPACK deal specificly with symmetric sparse matrices. Our focus is the more difficult and less explored case of nonsymmetric sparse matrices. SPARSKIT, developed by Y. Saad [15], is a basic <p> we find SPARSKIT <ref> [15] </ref>, PCGPAK [17], ITPACK [9] [10], NSPCG [11], ELLPACK [13], just to mention some of them. Among these packages, ITPACK and ELLPACK deal specificly with symmetric sparse matrices. Our focus is the more difficult and less explored case of nonsymmetric sparse matrices. SPARSKIT, developed by Y. Saad [15], is a basic tool kit which provides many useful basic routines for sparse matrix manipulation, but has few higher level solvers for linear systems. <p> The authors of SPARSKIT have divided the many tools into subsections to provide a better overview. This section contains excerpts from the report, SPARSKIT: a Basic Tool Kit for Sparse Matrix Computation <ref> [15] </ref>. 2 SPLIB 6 2.3.1 Basic linear algebra routines The usual algebraic operations involving two matrices, such as C = A + B, C = A + fiB, C = AB, etc.., are fairly common in sparse matrix computations. These basic matrix operations are described in the first subsection.
Reference: [16] <author> Y. Saad and M. Schultz. </author> <title> "GMRES: a Generalized Minimal Residual Algorithm for Solving Nonsymmetric Linear Systems." </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> Vol. 7, </volume> <pages> pp. 856-869, </pages> <year> 1986. </year>
Reference-contexts: BICG [8], CGS [18] and CGSTAB [19] are methods which preserve the 3-term recurrence of the residual polynomials, one of CG's strong characteristics, but not the minimization property. GMRES (k) <ref> [16] </ref> preserves the minimization property in each iteration step, but does not preserve the 3-term recurrence. These solvers are not guaranteed to converge, but when they do they often converge quickly. Each solver can be used with the above preconditioners.
Reference: [17] <institution> Scientific Computing Associates, Inc. PCGPAK User's Guide. </institution> <address> New Haven, CT, </address> <year> 1987. </year>
Reference-contexts: Principally, all matrices arising where partial differential equations occur have a sparse structure of varying complexity. This underscores the importance of providing tools for sparse matric computations. Several efforts have been made to develop software packages that deal with sparse matrices, among which we find SPARSKIT [15], PCGPAK <ref> [17] </ref>, ITPACK [9] [10], NSPCG [11], ELLPACK [13], just to mention some of them. Among these packages, ITPACK and ELLPACK deal specificly with symmetric sparse matrices. Our focus is the more difficult and less explored case of nonsymmetric sparse matrices. SPARSKIT, developed by Y.
Reference: [18] <author> P. Sonneveld. </author> <title> "CGS: a Fast Lanczos-type Solver for Nonsymmetric Linear Systems." </title> <journal> SIAM Journal on Scientific and Statistical Computing Vol. </journal> <volume> 10, </volume> <pages> pp. 36-52, </pages> <year> 1989. </year>
Reference-contexts: Unfortunately, these two methods exhibit slow convergence because the condition number of A T A and AA T increase significantly compared to A. BICG [8], CGS <ref> [18] </ref> and CGSTAB [19] are methods which preserve the 3-term recurrence of the residual polynomials, one of CG's strong characteristics, but not the minimization property. GMRES (k) [16] preserves the minimization property in each iteration step, but does not preserve the 3-term recurrence.
Reference: [19] <author> H. Van der Vorst and P. Sonneveld. "CGSTAB: </author> <title> a More Smoothly Converging Variant of CGS." </title> <type> Technical Report, </type> <institution> Delft University of Technology, </institution> <year> 1990. </year>
Reference-contexts: Unfortunately, these two methods exhibit slow convergence because the condition number of A T A and AA T increase significantly compared to A. BICG [8], CGS [18] and CGSTAB <ref> [19] </ref> are methods which preserve the 3-term recurrence of the residual polynomials, one of CG's strong characteristics, but not the minimization property. GMRES (k) [16] preserves the minimization property in each iteration step, but does not preserve the 3-term recurrence.
Reference: [20] <author> D. M. Young, T.C. Oppe, D. R. Kincaid, and L. J. Hayes. </author> <title> "On the use of vector computers for solving large sparse linear systems." </title> <type> Technical Report No. </type> <institution> CNA-199, The University of Texas at Austin, Center for Numerical Analysis, </institution> <month> April </month> <year> 1985. </year>
Reference-contexts: In addition, the code may also compute the most important 5 diagonals if wanted, or it can get those indicated by the user through the array IOF F . B APPENDIX: DATA STRUCTURES FOR SPARSE MATRICES 39 B.1.5 The Ellpack-Itpack format (ELL) The Ellpack-Itpack format <ref> [12, 20, 11] </ref> is a generalization of the diagonal storage scheme which is intended for general sparse matrices with a limited maximum number of nonze-ros per row. Two rectangular arrays of the same size are required, one real and one integer.
References-found: 20

