URL: http://ai.eecs.umich.edu/people/jmvidal/papers/jetai.ps
Refering-URL: http://ai.eecs.umich.edu/people/jmvidal/jmvidal.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fjmvidal, durfeeg@umich.edu  
Phone: 313-763-9074, 313-936-1563  
Title: Learning Nested Agent Models in an Information Economy  Running Head: Learning Nested Agent Models.  
Author: Jose M. Vidal and Edmund H. Durfee 
Date: May 26, 1997  
Address: 1101 Beal Avenue Ann Arbor, MI 48109-2110  
Affiliation: Artificial Intelligence Laboratory University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: <author> Akerlof, G. A. </author> <year> (1970). </year> <title> The market for `lemons': Quality uncertainty and the market mechanism. </title> <journal> The Quaterly Journal of Economics, </journal> <pages> pages 488-500. </pages>
Reference: <author> Atkins, D. E., Birmingham, W. P., Durfee, E. H., Glover, E. J., Mullen, T., Rundensteiner, E. A., Soloway, E., Vidal, J. M., Wallace, R., and Wellman, 27 M. P. </author> <year> (1996). </year> <title> Toward inquiry-based education through interacting software agents. </title> <journal> IEEE Computer. </journal> <note> http://www.computer.org/pubs/computer/dli/ r50069/r50069.htm. </note>
Reference-contexts: By situating agents in an economic society, as we do in the University of Michigan Digital Library (UMDL), we can make each agent responsible for making its own decisions about when to buy/sell and who to do business with <ref> (Atkins et al., 1996) </ref>. A market-based infrastructure, built around computational auction agents, serves to discourage agents from engaging in strategic reasoning to manipulate the system by keeping the competitive pressures high. <p> We are also encouraged by the fact that increasing the agents' capabilities changes the system in ways that we can recognize from our everyday economic experience. 24 Some of the agent structures shown in this paper are already being imple-mented into the UMDL <ref> (Atkins et al., 1996) </ref>. We have a basic economic infrastructure that allows agents to engage in commerce, and the agents use customizable heuristics for determining their strategic behavior. We are working on incorporating the more advanced modeling capabilities into our agents in order to enable more interesting strategic behaviors.
Reference: <author> Axelrod, R. M. </author> <year> (1984). </year> <title> The Evolution of Cooperation. </title> <publisher> Basic Books. </publisher>
Reference: <author> Durfee, E. H., Gmytrasiewicz, P. J., and Rosenschein, J. S. </author> <year> (1994). </year> <title> The utility of embedded communications and the emergence of protocols. </title> <booktitle> In Proceedings of the 13th International Distributed Artificial Intelligence Workshop. </booktitle>
Reference: <author> Epstein, J. M. and Axtell, R. L. </author> <year> (1996). </year> <title> Growing Artifical Societies: Social Science from the Bottom Up. </title> <publisher> Brookings Institution. </publisher>
Reference: <author> Glance, N. S. </author> <year> (1993). </year> <title> Dynamics with Expectations. </title> <type> PhD thesis, </type> <institution> Stanford University. </institution>
Reference-contexts: The studies of (Shoham and Ten-nenholtz, 1992), and <ref> (Glance, 1993) </ref> focus on very simple but numerous agents and emphasize their emergent behavior. (Hu and Wellman, 1996) show that learning agents in an economic domain sometimes converge to globally sub-optimal equilibria.
Reference: <author> Gmytrasiewicz, P. J. </author> <year> (1996). </year> <title> On reasoning about other agents. </title> <editor> In Wooldridge, M., Muller, J. P., and Tambe, M., editors, </editor> <booktitle> Intelligent Agents Volume II, Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 143-155. </pages> <publisher> Springer-Verlag. </publisher>
Reference: <author> Hu, J. and Wellman, M. P. </author> <year> (1996). </year> <title> Self-fulfilling bias in multiagent learning. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems, </booktitle> <pages> pages 118-125. </pages>
Reference-contexts: The studies of (Shoham and Ten-nenholtz, 1992), and (Glance, 1993) focus on very simple but numerous agents and emphasize their emergent behavior. <ref> (Hu and Wellman, 1996) </ref> show that learning agents in an economic domain sometimes converge to globally sub-optimal equilibria. <p> In all tests, we found the behavior for any particular run does not necessarily reflect the average behavior of the system. The prices have a tendency to sometimes reach temporary stable points. These conjectural equilibria, as described in <ref> (Hu and Wellman, 1996) </ref>, are instances when all of the agents' models are correctly predicting the others' behavior and, therefore, the agents do not need to change their models or their actions. These conjectural equilibria points are seldom global optima for the agents.
Reference: <author> Hubler, A. and Pines, D. </author> <year> (1994). </year> <title> Complexity: Methaphors, Models and Reality, chapter Prediction and Adaptation in an Evolving Chaotic Environment, </title> <address> pages 343-379. </address> <publisher> Addison Wesley. </publisher>
Reference: <author> Kauffman, S. A. </author> <year> (1994). </year> <title> Complexity: Models, Metaphors and Reality, chapter Whispers from Carnot: </title> <booktitle> The Origins of Order and Principles of Adaptation in Complex Nonequilibrium Systems, </booktitle> <pages> pages 83-136. </pages> <note> Addison Wesley. 28 Mullen, </note> <author> T. and Wellman, M. P. </author> <year> (1996). </year> <title> Some issues in the design of market--oriented agents. </title> <editor> In Wooldridge, M., Muller, J. P., and Tambe, M., editors, </editor> <booktitle> Intelligent Agents Volume II, Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 283-298. </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The rewards, we are finding, start to diminish as the other agents become "smarter". We can intuit that the agents in these systems will eventually settle on some level of nesting that balances their costs of keeping nested models with their gains from taking better actions <ref> (Kauffman, 1994) </ref>.
Reference: <author> Nadella, R. and Sen, S. </author> <year> (1997). </year> <title> Correlating internal parameters and external performance. </title> <editor> In Wei, G., editor, </editor> <booktitle> Distributed Artificial Intelligence Meets Machine Learning, </booktitle> <pages> pages 137-150. </pages> <publisher> Springer. </publisher>
Reference-contexts: We address this issue and try to determine when and which models an agent should keep. Within the MAS community, some work (Sen, 1996) has focused on how artificial AI-based learning agents would fare in communities of similar agents. For example, <ref> (Nadella and Sen, 1997) </ref> and (Terabe et al., 1997) show how agents can 2 learn the capabilities of others via repeated interactions, but these agents do not learn to predict what actions other might take.
Reference: <author> Rosenschein, J. S. and Zlotkin, G. </author> <year> (1994). </year> <title> Rules of Encounter. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: Agents might try to manipulate the interactions to their individual benefits, at the cost of the global efficiency. To avoid this, the protocols and mechanisms that the agents engage in might be constructed to make manipulation irrational <ref> (Rosenschein and Zlotkin, 1994) </ref>, but unfortunately this strategy is only applicable in restricted domains.
Reference: <author> Russell, S. </author> <year> (1995). </year> <title> Rationality and intelligence. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 950-957. </pages>
Reference: <author> Sen, S., </author> <title> editor (1996). </title> <booktitle> Working Notes for the AAAI Symposium on Adaptation, Co-evolution and Learning in Multiagent Systems. </booktitle>
Reference-contexts: They do not explicitly consider the fact that the agents inhabit communities of learning agents. That is, their agents do not try to model other agents. We address this issue and try to determine when and which models an agent should keep. Within the MAS community, some work <ref> (Sen, 1996) </ref> has focused on how artificial AI-based learning agents would fare in communities of similar agents. <p> Most of the work in MAS also fails to recognize the possible gains from using explicit agent models to predict agent actions. <ref> (Tambe and Rosenbloom, 1996) </ref> is an exception and gives another approach for using nested agent models. However, they do not go so far as to try to quantify the advantages of their nested models or show how these could be learned via observations.
Reference: <author> Shoham, Y. and Tennenholtz, M. </author> <year> (1992). </year> <title> Emergent conventions in multi-agent systems. </title> <booktitle> In Proceedings of Knowledge Representation. </booktitle>
Reference-contexts: Our results point to metrics that can be used to make quantitative predictions as to the benefits obtained from learning and using deeper models. 1.1 Related work Different research communities have run across the problems that arise from having agents learning in societies of learning agents. The studies of <ref> (Shoham and Ten-nenholtz, 1992) </ref>, and (Glance, 1993) focus on very simple but numerous agents and emphasize their emergent behavior. (Hu and Wellman, 1996) show that learning agents in an economic domain sometimes converge to globally sub-optimal equilibria.
Reference: <author> Sutton, R. S. </author> <year> (1988). </year> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44. </pages>
Reference-contexts: In general, these agents get some input, take an action, then receive some reward. This framework is the same framework used in reinforcement learning, which is why we decided to use a form of reinforcement learning <ref> (Sutton, 1988) </ref> (Watkins and Dayan, 1992), for implementing learning in our agents. Both buyers and sellers will use the equations in the next few sections for determining what actions to take.
Reference: <author> Tambe, M. and Rosenbloom, P. S. </author> <year> (1996). </year> <title> Architectures for agents that track other agents in multi-agent worlds. </title> <editor> In Wooldridge, M., Muller, J. P., and Tambe, M., editors, </editor> <booktitle> Intelligent Agents Volume II, Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 156-170. </pages> <note> Springer-Verlag. 29 Terabe, </note> <author> M., Wasio, T., Katai, O., and Sawaragi, T. </author> <year> (1997). </year> <title> A study of orga-nizational learning in multi-agent systems. </title> <editor> In Wei, G., editor, </editor> <booktitle> Distributed Artificial Intelligence Meets Machine Learning, </booktitle> <pages> pages 168-179. </pages> <publisher> Springer. </publisher>
Reference-contexts: Most of the work in MAS also fails to recognize the possible gains from using explicit agent models to predict agent actions. <ref> (Tambe and Rosenbloom, 1996) </ref> is an exception and gives another approach for using nested agent models. However, they do not go so far as to try to quantify the advantages of their nested models or show how these could be learned via observations.
Reference: <author> Vidal, J. M. and Durfee, E. H. </author> <year> (1996a). </year> <title> The impact of nested agent models in an information economy. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems, </booktitle> <pages> pages 377-384. </pages> <address> http://ai.eecs.umich.edu/ people/jmvidal/papers/amumdl/. </address>
Reference: <author> Vidal, J. M. and Durfee, E. H. </author> <year> (1996b). </year> <title> Using recursive agent models effectively. </title> <editor> In Wooldridge, M., Muller, J. P., and Tambe, M., editors, </editor> <booktitle> Intelligent Agents Volume II, Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 171-196. </pages> <publisher> Springer-Verlag. </publisher> <address> http://ai.eecs.umich.edu/people/jmvidal/papers/lr-rmm2/. </address>

References-found: 19

