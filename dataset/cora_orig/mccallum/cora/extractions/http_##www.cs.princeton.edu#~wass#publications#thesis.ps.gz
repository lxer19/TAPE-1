URL: http://www.cs.princeton.edu/~wass/publications/thesis.ps.gz
Refering-URL: http://www.cs.princeton.edu/~wass/publications.html
Root-URL: http://www.cs.princeton.edu
Title: COMPLEXITY MEASURES FOR ASSEMBLY SEQUENCES  
Author: Michael Goldwasser 
Degree: a dissertation submitted to the department of computer science and the committee on graduate studies of stanford university in partial fulfillment of the requirements for the degree of doctor of philosophy By  
Date: June 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> P. Agarwal, M. de Berg, D. Halperin, and M. Sharir. </author> <title> Efficient generation of k-directional assembly sequences. </title> <booktitle> In Proc. 7th ACM Symp. on Discrete Algorithms, </booktitle> <pages> pages 122-131, </pages> <year> 1996. </year>
Reference-contexts: Therefore, we consider the additional problem of choosing the best such sequence for a product, when restricted to linear assembly sequences. Note that, even when restricted to linear sequences, there still may be exponentially many valid sequences for a given product. R2 Constant Size Family of Motions. <ref> [1] </ref> Originally, our only assumption was that the number of blocking graphs is polynomially bounded in the number of parts. Now we consider instances where the number of graphs in bounded by some constant, k.
Reference: [2] <author> S. Arora. </author> <title> Polynomial-time approximation schemes for Euclidean TSP and other geometric problems. </title> <booktitle> In Proc. 37th Symp. on Found. Comput. Sci., </booktitle> <pages> pages 1-11, </pages> <year> 1996. </year>
Reference-contexts: BACKGROUND 14 to a geometric setting. For example, there exists some c &gt; 0 for which achieving a (1 + c)- approximation for the Metric tsp problem is NP-hard [65], however in the Euclidean plane, TSP can be approximated to within (1 + *) for all * &gt; 0 <ref> [2] </ref>. Similarly, achieving an n * - approximation for Minimum Independent Set is NP-hard [34], however for planar graphs, Minimum Independent Set can be approximated to within (1 + *) [6]. Similar results hold for most optimization problem when restricted to planar graphs [49].
Reference: [3] <author> S. Arora, L. Babai, J. Stern, and Z. Sweedyk. </author> <title> The hardness of approximate optima in lattices, codes and linear equations. </title> <booktitle> In Proc. 34th Symp. on Found. Comput. Sci., </booktitle> <pages> pages 724-733, </pages> <year> 1993. </year>
Reference-contexts: For problems in Class III, it is quasi-NP-hard to achieve a 2 log 1fl n factor 2 approximation for any fl &gt; 0. Label Cover is the canonical problem in this class <ref> [3] </ref>, although the class contains several other natural problems such as Longest Path [45] and Nearest Lattice Vector [3]. Finally, Class IV consists of the hardest problems, namely those for which it is NP-hard to achieve an n * approximation factor for some * &gt; 0. <p> Label Cover is the canonical problem in this class <ref> [3] </ref>, although the class contains several other natural problems such as Longest Path [45] and Nearest Lattice Vector [3]. Finally, Class IV consists of the hardest problems, namely those for which it is NP-hard to achieve an n * approximation factor for some * &gt; 0. This class includes problems such as Clique [34] and Coloring [58]. <p> Our lower bounds provide some of the strongest such inapproximability results for a natural, combinatorial, geometric problem. Similar lower bounds have been shown for the Nearest Lattice Vector problem <ref> [3] </ref>, however this problem is not combinatorial, and although it shares the same lower bound as our problem, we cannot directly relate the hardness of the two problems.
Reference: [4] <author> S. Arora and C. Lund. </author> <title> Hardness of approximations. </title> <editor> In D. Hochbaum, editor, </editor> <title> Approximation Algorithms for NP-Hard Problems. </title> <publisher> PWS Publishing Company, </publisher> <address> Boston, MA, </address> <year> 1996. </year>
Reference-contexts: Research in the theory of approximability has consider exactly this issue for other NP-hard optimization problems <ref> [4, 23, 41, 62] </ref>. Since we cannot expect to find the optimal solution in polynomial time, the goal is to develop a polynomial time approximation algorithm that returns a solution whose cost can be bounded by some function of the true optimal cost. <p> Many researchers have worked towards classifying the approximability of different NP-hard problems <ref> [4, 5, 15, 64] </ref>. We will consider four broad classes defined in [4], which group problems based on the strength of the inapproximability results that have been proven. <p> Many researchers have worked towards classifying the approximability of different NP-hard problems [4, 5, 15, 64]. We will consider four broad classes defined in <ref> [4] </ref>, which group problems based on the strength of the inapproximability results that have been proven. Class I includes all problems for which approximating the optimal solution to within a factor of (1 + *) is NP-hard for some * &gt; 0. <p> The typical such problem in this class is Set Cover, for which the threshold of approximability has been placed at 1 that is, this would imply NP DTIME (n poly (log n) ). "A proof of quasi-NP-hardness is good evidence that the problem has no polynomial-time algorithm." <ref> [4] </ref> CHAPTER 2. <p> Proof: Approximating the Label Cover min problem within a factor of 2 log 1fl n is quasi-NP-hard for any fl &gt; 0 <ref> [4] </ref>. Combining this lower bound with Theorem 13 proves our result. <p> It is already conjectured that Label Cover is truly n * -hard to approximate for some * &gt; 0 <ref> [4] </ref>, a result that would carry over through all of our reductions. However it may be possible to strengthen the lower bounds for and/or scheduling without necessarily settling the Label Cover conjecture. Secondly, we offer no non-trivial (i.e. o (n)) approximation algorithms for any of these problems.
Reference: [5] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof verification and intractability of approximation problems. </title> <booktitle> In Proc. 33rd Symp. on Found. Comput. Sci., </booktitle> <pages> pages 13-22, </pages> <year> 1992. </year>
Reference-contexts: Many researchers have worked towards classifying the approximability of different NP-hard problems <ref> [4, 5, 15, 64] </ref>. We will consider four broad classes defined in [4], which group problems based on the strength of the inapproximability results that have been proven.
Reference: [6] <author> B. Baker. </author> <title> Approximation algorithms for NP-complete problems on planar graphs. </title> <journal> J. ACM, </journal> <volume> 41(1) </volume> <pages> 153-180, </pages> <year> 1994. </year>
Reference-contexts: Similarly, achieving an n * - approximation for Minimum Independent Set is NP-hard [34], however for planar graphs, Minimum Independent Set can be approximated to within (1 + *) <ref> [6] </ref>. Similar results hold for most optimization problem when restricted to planar graphs [49].
Reference: [7] <author> D. Baldwin. </author> <title> Algorithmic methods and software tools for the generation of mechanical assembly sequences. M.Sc. </title> <type> thesis, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process.
Reference: [8] <author> R. Bhatia, S. Khuller, and J. Naor. </author> <title> The loading time scheduling problem. </title> <booktitle> In Proc. 36th Symp. on Found. Comput. Sci., </booktitle> <pages> pages 72-81, </pages> <year> 1995. </year> <note> 97 BIBLIOGRAPHY 98 </note>
Reference-contexts: us a solution with cost at most: (jF j 1)(OPT 2) + 1 + jF j = (jF j 1)(OPT) 2 (jF j 1) + 1 + jF j The techniques we have used in this proof are very similar to those used for approximating the Shortest Common Supersequence problem <ref> [8] </ref>. For more discussion of the relation between re-orientations and supersequences, see the proofs of Theorems 31 and 33. <p> These results come from a natural reduction from the Loading Time Scheduling Problem <ref> [8] </ref>. Theorem 29 It is quasi-NP-hard to achieve a 2 log 1fl n -approximation for any fl &gt; 0, for the problem of minimizing the number of steps while removing a key part when restricted to linear operations. <p> Proof: We begin by proving this result for the goal of removing a key part from the assembly. We will give a reduction from the Loading Time Scheduling Problem, defined as follows <ref> [8] </ref>. There is a set of n jobs, and machines, and each job, j, can only be performed by some subset of the machines, M (j). An algorithm pays for loading a machine, but once that machine is loaded, it may perform any available operations at no additional cost. <p> An example of such a graph is given in Figure 6.4. 4 actually, we reversal all edges of G, as <ref> [8] </ref> defines an edge from x to y as signifying that y cannot be run until after x. CHAPTER 6. <p> For this reason, we claim that any solution to the ltsp instance can be translated to a solution with equal cost for removing the key part, and vice versa, and thus we have an approximation preserving reduction. At this point, we rely on results shown in <ref> [8] </ref> combined with a result of [59], to prove our claims, where the number of machines for ltsp corresponds to jF j. CHAPTER 6.
Reference: [9] <author> P. Bonizzoni, M. Duella, and G. Mauri. </author> <title> Approximation complexity of longest common subsequence and shortest common supersequence over fixed alphabet. </title> <type> Technical Report 117/94, </type> <institution> Universita degli Studi di Milano, </institution> <year> 1994. </year>
Reference-contexts: The problem of finding the shortest common supersequence is known to be NP-hard [23], and more recently it was shown to be Max-SNP-hard, even over a binary alphabet <ref> [9] </ref>. Therefore, by doubling the alphabet as above, we get that our problem of removing a part is Max-SNP-hard, when jF j 4.
Reference: [10] <author> G. Boothroyd. </author> <title> Assembly Automation and Product Design. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: Based on a great deal of work with industrial applications, Boothroyd et al. suggest several empirical measures that effect the cost of assembly for a product <ref> [10, 11] </ref>. More formal complexity measures have been defined by both Wilson and Latombe [76], as well as Wolter [78]. A collection of cost measures for assembly planning gathered by Jones and Wilson is included in [42].
Reference: [11] <author> G. Boothroyd, P. Dewhurst, and W. Knight. </author> <title> Product Design for Manufacture and Assembly. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: Based on a great deal of work with industrial applications, Boothroyd et al. suggest several empirical measures that effect the cost of assembly for a product <ref> [10, 11] </ref>. More formal complexity measures have been defined by both Wilson and Latombe [76], as well as Wolter [78]. A collection of cost measures for assembly planning gathered by Jones and Wilson is included in [42].
Reference: [12] <author> S. Caselli and F. Zanichelli. </author> <title> On assembly sequence planning using petri nets. </title> <booktitle> In Proc IEEE Int. Symp. on Assembly and Task Planning, </booktitle> <pages> pages 239-244, </pages> <year> 1995. </year>
Reference-contexts: CHAPTER 2. BACKGROUND 8 Others have looked at general heuristics that attempt to minimize the cost of assembly sequences. Millner et al. consider using simulated annealing in selecting least-cost assembly sequences [60], and Caselli and Zanichelli consider the use of petri nets for finding assembly sequences <ref> [12] </ref>. Both of these techniques suffer either in requiring possibly exponential time in finding the optimal sequence or else in quickly finding a sequence without any provable guarantee as to its quality.
Reference: [13] <author> S. Chakrabarty and J. Wolter. </author> <title> A hierarchical approach to assembly planning. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 258-263, </pages> <year> 1994. </year>
Reference-contexts: A hierarchical approach is used by Chakrabarty and Wolter to identify common subassemblies in products, such as the many passenger chairs in an airplane <ref> [13] </ref>. Moradi et al. consider the automatic identification of groups of parts that either can be or must be assembled together, again reducing the effective number of sequences to consider [61].
Reference: [14] <author> B. Chazelle, H. Edelsbrunner, L. Guibas, R. Pollack, R. Seidel, M. Sharir, and J. Snoeyink. </author> <title> Counting and cutting cycles of lines and rods in space. Computational Geometry: </title> <journal> Theory and Applications, </journal> <volume> 1(6) </volume> <pages> 305-323, </pages> <year> 1992. </year>
Reference-contexts: More recent work has looked at the efficiency of computing and verifying depth orders <ref> [14, 18] </ref>, and a very complete discussion of depth orders is given by de Berg [17]. Related to our work in a general sense, there is a good deal of research regarding the approximation of problems in geometric settings.
Reference: [15] <author> P. Crescenzi and V. Kahn. </author> <title> A compendium of NP optimization problems. </title> <type> Technical Report SI/RR-95/02, </type> <institution> Dipartimento di Scienceze dell'Informazione. Universita di Roma "La Sapienza", </institution> <year> 1995. </year>
Reference-contexts: Many researchers have worked towards classifying the approximability of different NP-hard problems <ref> [4, 5, 15, 64] </ref>. We will consider four broad classes defined in [4], which group problems based on the strength of the inapproximability results that have been proven.
Reference: [16] <author> R. Dawson. </author> <title> On removing a ball without disturbing the others. </title> <journal> Mathematics Magazine, </journal> <volume> 57(1) </volume> <pages> 27-30, </pages> <year> 1984. </year>
Reference-contexts: d-dimensions, there must exist at least min (n; d + 1) balls that can each be individually translated to infinity without disturbing any other balls, while at the same time he provides a construction of convex parts in three dimensions for which no individual part can be translated to infinity <ref> [16] </ref>. Almost a decade later, Snoeyink and Stolfi were able to settle an open question by providing a collection of convex polyhedra in three dimensions for which no subset of parts could be separated from the remaining set, using either translations or combined translations and rotations.
Reference: [17] <author> M. de Berg. </author> <title> Ray Shooting, Depth Orders and Hidden Surface Removal. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1993. </year>
Reference-contexts: More recent work has looked at the efficiency of computing and verifying depth orders [14, 18], and a very complete discussion of depth orders is given by de Berg <ref> [17] </ref>. Related to our work in a general sense, there is a good deal of research regarding the approximation of problems in geometric settings.
Reference: [18] <author> M. de Berg, M. Overmars, and O. Schwarzkopf. </author> <title> Computing and verifying depth orders. </title> <journal> SIAM J. Comput., </journal> <volume> 23(2) </volume> <pages> 432-446, </pages> <year> 1994. </year>
Reference-contexts: More recent work has looked at the efficiency of computing and verifying depth orders <ref> [14, 18] </ref>, and a very complete discussion of depth orders is given by de Berg [17]. Related to our work in a general sense, there is a good deal of research regarding the approximation of problems in geometric settings.
Reference: [19] <author> F. Dehne and J.-R. Sack. </author> <title> Translation separability of polygons. </title> <journal> Visual Computer, </journal> <volume> 3(4) </volume> <pages> 227-235, </pages> <year> 1987. </year>
Reference-contexts: Constructing a sequence for the individual removal of polygons from a collection in two dimensions was studied by Dehne and Sack in 1987 <ref> [19] </ref>. In this work, they introduce what the term the movability wheel, which can be though of as a very preliminary version of the ndbg.
Reference: [20] <author> D. Dutta and T. Woo. </author> <title> Algorithm for multiple disassembly and parallel assemblies. </title> <journal> J. Engineering for Industry, </journal> <volume> 117(1) </volume> <pages> 102-109, </pages> <year> 1995. </year> <note> BIBLIOGRAPHY 99 </note>
Reference-contexts: For a restricted class of inputs that have a so-called "total ordering" property, a greedy algorithm is given that claims to produce the minimal length sequence to remove any give part <ref> [20, 79] </ref>, however the required input property does not have a clear definition. For the general setting, our results in Section 7.5 will prove not only the difficulty of finding an optimal sequence by this cost measure, but even a near-optimal solution. <p> 14 13 9 9 13.6 21 9 11 12 13 11 10 14.3 23 7 10 10 10 10 7 12.8 25 6 9 10 13 9 6 11.1 27 5 10 6 7 6 5 8.2 TIME 116900 12200 26700 12500 25700 13255.5 Appendix B Questioning the Claims of <ref> [20, 79] </ref> In a sequence of two journal articles, Woo and Dutta present an algorithm for the removal of a part (or multiple parts) from a product made of polyhedral parts in either two or three dimensions [20, 79]. <p> TIME 116900 12200 26700 12500 25700 13255.5 Appendix B Questioning the Claims of <ref> [20, 79] </ref> In a sequence of two journal articles, Woo and Dutta present an algorithm for the removal of a part (or multiple parts) from a product made of polyhedral parts in either two or three dimensions [20, 79]. They allow for parts to be removed, one at a time, using translations to infinity. <p> For these totally ordered products, this claim ammounts to solving the (G2/C4/R1) variant for which we proved a 2 log 1fl n lower bound, even in the Disks setting. This potential contradiction leads us to reconsider the claims of optimality made in <ref> [20, 79] </ref>, and the assemblies to which the algorithm applies. Unfortunately, we feel that their presentation suffers from being inconsistent and vague, and thus their claims are in question. <p> We will begin by addressing their definitions and claims which we feel are not sufficiently clear. Following this, we will give an example of a product very similar to an example they give, for which their optimality claim does not hold. 91 APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 92 Figure B.1: Freedom for Infinitesimal Translational B.1 Cost Measure The first issue for us is to understand what cost measure they claim to be optimizing. <p> Based on their explicit description of the check for removability, we seem to have no choice but to assume that they are considering only the local freedom for infinitesimal translations. APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 93 This decision is also consistent with the fact that in their algorithm for disassembly, when trying to find the effects of the removal of one part on the removability of other parts, they only recheck the removal of those parts which are adjacent to the first part removed. <p> Originally, they define this property in Definition 1.3 of [79] as follows: "An assembly is partially ordered if the disassembly of a component requires an immediate prior disassembly of k components. If k &lt; 2, the assembly is totally ordered." The concept is defined in a similar manner in <ref> [20] </ref>, although the word immediate is no longer present when they define total ordering in Section 2.1 as: "A sequential assembly S is partially ordered if the removal of a component in the assembly requires the prior disassembly of k (&gt; 1) components. <p> If this is indeed the intended concept of total ordering, then their claims of optimality are quite trivial. If every part requires either one or two steps for removal, it is quite simple to identify those APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 94 Figure B.2: An example given by Woo and Dutta parts which can be removed in one step from the full assembly. For all other parts, it must be that the removal of some single other part must create the freedom for removing this part. <p> For all other parts, it must be that the removal of some single other part must create the freedom for removing this part. In fact, at one point, it seems that maybe this is the interpretation which they intend, as they describe, in Section 3.3 of <ref> [20] </ref>, a scenario in which ": : : the removal of each component is possible after the removal of at most one other component and the assembly is totally ordered. <p> Also, this interpretation would be somewhat surprising, given that the examples they give of their algorithm in action (Figure 3.3 of [79] and Figure 4 of <ref> [20] </ref>) both result in trees with heights greater than two. If we take the second interpretation, namely that a parts removal may rely on the prior removal of some specific other part, this seems a more natural view for the concepts of defining a partial order or total order. <p> Unfortunately, if this is the interpretation, it is not clear at a glance how to tell whether a given product has this required property or not. Also, in this respect, their use of the phrase is quite puzzling, as they give an example in <ref> [20] </ref>, of an assembly which we show in Figure B.2. <p> One could remove APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 95 Figure B.3: Our counterexample for optimal disassembly parts in the following order, b; c; d; e, and thus remove both d and e without removing a. <p> One could remove APPENDIX B. QUESTIONING THE CLAIMS OF [20, 79] 95 Figure B.3: Our counterexample for optimal disassembly parts in the following order, b; c; d; e, and thus remove both d and e without removing a. B.4 Counterexample In <ref> [20] </ref>, they consider the product which we showed in Figure B.2, and they walk through the execution of their algorithm on this example, and show the resulting sequences which are optimal. <p> Clearly, for either of these cost measures, the optimal sequence is first to remove b, followed by c, and then d, requiring APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 96 Figure B.4: The resulting DT for our counterexample cost 2 by either metric.
Reference: [21] <author> T. De Fazio and D. Whitney. </author> <title> Simplified generation of all mechanical assembly sequences. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 3(6) </volume> <pages> 640-658, </pages> <year> 1987. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process. <p> As our work is intricately related to this approach, in the following section, we will review in greater detail the concept of non-directional blocking graphs and the subsequent results. Other techniques allow for the enumeration of all possible assembly sequences in time proportional to the number of such sequences <ref> [21] </ref>, however for most products, there will be exponentially many such sequences. The assembly-by-disassembly approach for assembly sequencing has become quite popular. When considering non-rigid parts, stability, fixturing, and insertion forces, assembly and disassembly sequences are no longer symmetric [55]. However, even under our assumptions, 6 CHAPTER 2.
Reference: [22] <author> U. Feige. </author> <title> A threshold of ln n for approximating set cover. </title> <booktitle> In Proc. 28th ACM Symp. Theory Comput., </booktitle> <pages> pages 314-318, </pages> <year> 1996. </year>
Reference-contexts: BACKGROUND 11 Class Factor of Approximation that is hard Representative Problems I 1 + * Max-3Sat II O (log n) Set Cover III 2 log 1fl n Label Cover IV n * Clique Table 2.1: The four classes and their representative problems [Arora/Lund] ln n (1 + o (1)) <ref> [22] </ref>. For problems in Class III, it is quasi-NP-hard to achieve a 2 log 1fl n factor 2 approximation for any fl &gt; 0. <p> Similar results hold for most optimization problem when restricted to planar graphs [49]. There exists a (1 + o (1)) ln n lower bound for approximating the Set Cover problem <ref> [22] </ref>, however the Rectangle Cover problem, covering a set of axis-aligned rectangles with minimum number of points, has no such inapproximability results [62]. Our lower bounds provide some of the strongest such inapproximability results for a natural, combinatorial, geometric problem.
Reference: [23] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: Research in the theory of approximability has consider exactly this issue for other NP-hard optimization problems <ref> [4, 23, 41, 62] </ref>. Since we cannot expect to find the optimal solution in polynomial time, the goal is to develop a polynomial time approximation algorithm that returns a solution whose cost can be bounded by some function of the true optimal cost. <p> What distinguishes this setting from more traditional scheduling is the form of the precedence constraints. Commonly, a task may have what we term an and-precedence constraint, in that it has an associated set of tasks, all of which must be scheduled before that task <ref> [23] </ref>. Unfortunately, this is not the case in our assembly sequencing problem. <p> Minimizing the number of ones in satisfying a 3CNF formula is known to be n 0:5* -hard to approximate [44], and related minimization problems are studied in [50]. 5.3 Previous Work Although the topic of scheduling with precedence constraints has a long and rich history <ref> [23, 29, 53] </ref>, there has been relatively little research focusing on models such as and/or 2 We choose, in this situation, to direct an edge from t i to t j , to be consistent with the notion of edges in a directed blocking graph. <p> Lemma 36 The Convex Polygon Cover problem is NP-hard. Proof: We will base this result on a reduction from the problem of Planar Vertex Cover, which is known to be NP-complete <ref> [23] </ref>. Given an instance of Planar Vertex Cover, we can simply let each edge of the graph be represented by a degenerate polygon, and we consider this input to the Convex Polygon Cover problem. <p> The goals G3 & G5, are generalization of the others, and thus the hardness results also apply. 7.4 Finding a Common Supersequence Proof of Theorem 33: When constrained to using linear moves, we give a construction which reduces the problem of finding a common supersequence <ref> [23] </ref>, to the problem of fully disassembling an assembly consisting of polygons in two-dimensions. A string T is a super-sequence of a string S, if S can be obtained by erasing zero or more symbols of T . <p> The problem of finding the shortest common supersequence is known to be NP-hard <ref> [23] </ref>, and more recently it was shown to be Max-SNP-hard, even over a binary alphabet [9]. Therefore, by doubling the alphabet as above, we get that our problem of removing a part is Max-SNP-hard, when jF j 4.
Reference: [24] <author> D. Gillies. </author> <title> Algorithms to Schedule Tasks with AND/OR Precedence Constraints. </title> <type> Ph.D. thesis, </type> <institution> University of Illinois, Urbana, IL, </institution> <year> 1993. </year>
Reference-contexts: Often the meaning of the directed edge is reversed in scheduling literature. CHAPTER 5. AND/OR SCHEDULING 39 precedence constraints. However, a series of papers by Gillies et al, study several variants of scheduling with and/or precedence constraints <ref> [24, 25] </ref>. Our model for this problem was chosen to be similar to [24, 25], however with one key difference. As mentioned in Section 5.2, the precedence constraints for an instance can be represented as a directed graph. <p> CHAPTER 5. AND/OR SCHEDULING 39 precedence constraints. However, a series of papers by Gillies et al, study several variants of scheduling with and/or precedence constraints <ref> [24, 25] </ref>. Our model for this problem was chosen to be similar to [24, 25], however with one key difference. As mentioned in Section 5.2, the precedence constraints for an instance can be represented as a directed graph. In this previous work, only the case of partial order precedence constraints is considered. <p> For this reason, we make no apriori assumptions about the structure of the precedence constraints. The work of <ref> [24, 25] </ref> studies a larger variety of settings, including multiple processors, deadlines, and individual processing times. They prove the NP-hardness of finding feasible schedules in many settings that are polynomially solvable with more traditional and-precedence constraints, however they do not consider the approximability of the corresponding optimization problems.
Reference: [25] <author> D. Gillies and J. Liu. </author> <title> Scheduling tasks with AND/OR precedence constraints. </title> <journal> SIAM J. Comput., </journal> <volume> 24(4) </volume> <pages> 797-810, </pages> <year> 1995. </year>
Reference-contexts: Often the meaning of the directed edge is reversed in scheduling literature. CHAPTER 5. AND/OR SCHEDULING 39 precedence constraints. However, a series of papers by Gillies et al, study several variants of scheduling with and/or precedence constraints <ref> [24, 25] </ref>. Our model for this problem was chosen to be similar to [24, 25], however with one key difference. As mentioned in Section 5.2, the precedence constraints for an instance can be represented as a directed graph. <p> CHAPTER 5. AND/OR SCHEDULING 39 precedence constraints. However, a series of papers by Gillies et al, study several variants of scheduling with and/or precedence constraints <ref> [24, 25] </ref>. Our model for this problem was chosen to be similar to [24, 25], however with one key difference. As mentioned in Section 5.2, the precedence constraints for an instance can be represented as a directed graph. In this previous work, only the case of partial order precedence constraints is considered. <p> For this reason, we make no apriori assumptions about the structure of the precedence constraints. The work of <ref> [24, 25] </ref> studies a larger variety of settings, including multiple processors, deadlines, and individual processing times. They prove the NP-hardness of finding feasible schedules in many settings that are polynomially solvable with more traditional and-precedence constraints, however they do not consider the approximability of the corresponding optimization problems.
Reference: [26] <author> M. Goldwasser, J.-C. Latombe, and R. Motwani. </author> <title> Complexity measures for assembly sequences. </title> <booktitle> In Proc IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1581-1587, </pages> <year> 1996. </year>
Reference-contexts: We prove that achieving a 2 log 1fl n -approximation to minimizing the total number of disks which must be removed to access the given disks is hard for any fl &gt; 0. Much of this work has appeared previously in <ref> [26, 27, 67] </ref>. 1.1 Presentation Overview This paper proceeds as follows. In the following section, we define the assembly sequencing problem and introduce several terms and definitions used throughout the paper.
Reference: [27] <author> M. Goldwasser and R. Motwani. </author> <title> Intractability of assembly sequencing: Unit disks in the plane. In Proc. of the Workshop on Algorithms and Data Structures, </title> <note> page To appear, </note> <year> 1997. </year>
Reference-contexts: We prove that achieving a 2 log 1fl n -approximation to minimizing the total number of disks which must be removed to access the given disks is hard for any fl &gt; 0. Much of this work has appeared previously in <ref> [26, 27, 67] </ref>. 1.1 Presentation Overview This paper proceeds as follows. In the following section, we define the assembly sequencing problem and introduce several terms and definitions used throughout the paper.
Reference: [28] <author> S. Gottschlich, C. Ramos, and D. Lyons. </author> <title> Assembly and task planning: A taxonomy. </title> <journal> IEEE Robotics and Automation Magazine, </journal> <volume> 1(3) </volume> <pages> 4-12, </pages> <year> 1994. </year>
Reference-contexts: Efficient algorithms have been developed, for many classes of motions, which guarantee to find a valid assembly sequence when one exists. The IEEE Technical Committee on Assembly and Task Planning summarized the current state of assembly sequencing by explaining <ref> [28] </ref>, "after years of work in this field, a basic planning methodology has emerged that is capable of producing a feasible plan : : : The challenges still facing the field are to develop efficient and robust analysis tools and to develop planners capable of finding optimal or near-optimal sequences rather <p> In fact, in 1994, the IEEE Technical Committee on Assembly and Task Planning summarized the current state of assembly sequencing by explaining <ref> [28] </ref>, "after years of work in this field, a basic planning methodology has emerged that is capable of producing a feasible plan : : : The challenges still facing the field are to develop efficient and robust analysis tools and to develop planners capable of finding optimal or near-optimal sequences rather
Reference: [29] <author> R. Graham. </author> <title> Bounds on multiprocessing timing anomalies. </title> <journal> SIAM J. Appl. Math., </journal> <volume> 17 </volume> <pages> 416-426, </pages> <year> 1969. </year>
Reference-contexts: Minimizing the number of ones in satisfying a 3CNF formula is known to be n 0:5* -hard to approximate [44], and related minimization problems are studied in [50]. 5.3 Previous Work Although the topic of scheduling with precedence constraints has a long and rich history <ref> [23, 29, 53] </ref>, there has been relatively little research focusing on models such as and/or 2 We choose, in this situation, to direct an edge from t i to t j , to be consistent with the notion of edges in a directed blocking graph.
Reference: [30] <author> L. Guibas, D. Halperin, H. Hirukawa, and J.-C. Latombe R. Wilson. </author> <title> A simple and efficient procedure for polyhedral assembly partitioning under infinitesimal motions. </title> <booktitle> In Proc IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 2553-2560, </pages> <year> 1995. </year>
Reference-contexts: For many classes of motions parameterized by a constant number of degrees of freedom, polynomial algorithms were then developed to find a binary, monotone assembly sequence when one exists <ref> [30, 33, 74, 76] </ref>. A good deal of this success was achieved within the framework of non-directional blocking graphs [32, 74, 76]. <p> In a series of work since then, geometric algorithms have been developed and improved for building the ndbg when the motion class allowed includes, infinitesimal translations [76], extended translations (i.e., to infinity) [76], multiple step translations in the plane [33], and infinitesimal generalized motions (i.e., rigid body motions) <ref> [30, 76] </ref>. As a general rule, it seems that a family of motions with a constant number of degrees of freedom leads to a polynomial number of distinct equivalence classes. A more recent survey presents a unified framework for understanding the collection of work surrounding the non-directional blocking graphs [32]. <p> This algorithm runs in polynomially time, is quite simple, and has been implemented in assembly sequencing systems for many of the above motion classes <ref> [30, 46, 67, 74] </ref>. As we will see, searching for a "good" sequence in this way is not quite so simple. CHAPTER 2. BACKGROUND 10 2.2 Approximation Theory For most variants, finding the optimal cost assembly sequence will turn out to be NP-hard.
Reference: [31] <author> L. Guibas and F. Yao. </author> <title> On translating a set of rectangles. </title> <editor> In F. Preparata, editor, </editor> <booktitle> Computational Geometry, Advances in Computing Research, </booktitle> <pages> pages 61-77. </pages> <publisher> JAI Press Inc., </publisher> <year> 1983. </year>
Reference-contexts: result of Guibas and Yao from 1983 states that for any given direction, there will always exist some part that can be translated to infinity in that direction without disturbing the others, and thus the single direction of translation can be used to repeatedly remove parts one at a time <ref> [31] </ref>. <p> For a collection of convex parts in two dimensions, Guibas and Yao show that for any given direction, there will always exist some part which can be translated to infinity in the direction without disturbing the other parts <ref> [31] </ref>. This fact has an immediate impact for assembly sequencing. For any given direction, this implies that the blocking graph will not contain any directed cycles. This is an example of identifying additional structure on blocking graphs from a geometric setting.
Reference: [32] <author> D. Halperin, J.-C. Latombe, and R. Wilson. </author> <title> A general framework for assembly planning: The path space approach. </title> <type> Manuscript, </type> <year> 1997. </year> <note> BIBLIOGRAPHY 100 </note>
Reference-contexts: For many classes of motions parameterized by a constant number of degrees of freedom, polynomial algorithms were then developed to find a binary, monotone assembly sequence when one exists [30, 33, 74, 76]. A good deal of this success was achieved within the framework of non-directional blocking graphs <ref> [32, 74, 76] </ref>. As our work is intricately related to this approach, in the following section, we will review in greater detail the concept of non-directional blocking graphs and the subsequent results. <p> As a general rule, it seems that a family of motions with a constant number of degrees of freedom leads to a polynomial number of distinct equivalence classes. A more recent survey presents a unified framework for understanding the collection of work surrounding the non-directional blocking graphs <ref> [32] </ref>. For each of these families of motions, the ndbg framework immediately provides a polynomial time algorithm for constructing a feasible assembly sequence, if one exists. <p> Other restrictions can also be added to our graph-theoretic model quite naturally. One interesting constraint that has been considered quite often in assembly sequencing is to require that all subassemblies which are used during the construction of a product are connected subassemblies <ref> [32, 47, 74] </ref>. Generally, unconnected subassemblies require additional expensive fixturing, and are more troublesome in terms of stability and maneuverability. The additional connectedness restriction can easily be modeled as a part of vas. <p> special case, when all graphs in the family F are subsets of the connection graph, finding a feasible assembly sequence can be done in polynomial time, however it remains an open question for the general case, whether a feasible sequence can be find in polynomial time with this connectedness requirement <ref> [32] </ref>. Other additional restrictions, common to assembly planning, are surveyed in [42, 43], where they show that several of the constraints can be naturally integrated into the ndbg approach. Appendix A Tables of Experimental Results These tables contain the results of the experiments described in Section 4.5.
Reference: [33] <author> D. Halperin and R. Wilson. </author> <title> Assembly partitioning along simple paths: the case of multiple translations. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1585-1592, </pages> <year> 1995. </year>
Reference-contexts: For many classes of motions parameterized by a constant number of degrees of freedom, polynomial algorithms were then developed to find a binary, monotone assembly sequence when one exists <ref> [30, 33, 74, 76] </ref>. A good deal of this success was achieved within the framework of non-directional blocking graphs [32, 74, 76]. <p> In a series of work since then, geometric algorithms have been developed and improved for building the ndbg when the motion class allowed includes, infinitesimal translations [76], extended translations (i.e., to infinity) [76], multiple step translations in the plane <ref> [33] </ref>, and infinitesimal generalized motions (i.e., rigid body motions) [30, 76]. As a general rule, it seems that a family of motions with a constant number of degrees of freedom leads to a polynomial number of distinct equivalence classes.
Reference: [34] <author> J. Hastad. </author> <title> Clique is hard to approximate within n 1* . In Proc. </title> <booktitle> 37th Symp. on Found. Comput. Sci., </booktitle> <pages> pages 627-636, </pages> <year> 1996. </year>
Reference-contexts: Finally, Class IV consists of the hardest problems, namely those for which it is NP-hard to achieve an n * approximation factor for some * &gt; 0. This class includes problems such as Clique <ref> [34] </ref> and Coloring [58]. Because we will use these problems in several reductions, we give both definitions and notation for the Set Cover and Label Cover problems. <p> Similarly, achieving an n * - approximation for Minimum Independent Set is NP-hard <ref> [34] </ref>, however for planar graphs, Minimum Independent Set can be approximated to within (1 + *) [6]. Similar results hold for most optimization problem when restricted to planar graphs [49].
Reference: [35] <author> R. Hoffman. </author> <title> A common sense approach to assembly sequence planning. </title> <booktitle> In Computer-Aided Mechanical Assembly Planning, </booktitle> <pages> pages 289-314. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Bo-ston, </address> <year> 1991. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process.
Reference: [36] <author> L. Homem de Mello and A. Sanderson. </author> <title> AND/OR graph representation of assembly plans. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 6(2) </volume> <pages> 188-199, </pages> <year> 1990. </year>
Reference-contexts: We use this result in Chapter 6, along with many 1 N.B.: this is not to be confused with the and/or tree used by Homem de Mello and Sanderson for representing all feasible assembly sequences <ref> [36, 38] </ref> CHAPTER 1. INTRODUCTION 4 reductions between different variants of the vas problem, to prove the inapproximability of most variants of the virtual assembly sequencing problems. Finally, we re-introduce the geometry in Chapter 7, proving the inapproximability for several cost measures, even in the original geometric settings. <p> For instance we can start by computing all valid operations that can be performed on the original assembly, and then again consider all valid operations on each of those results. A data structure for representing all the feasible subassemblies has been suggested in <ref> [36] </ref>, where the and/or graph is introduced 2 . The advantage of this approach is that, rather than examining all of the potential 2 n subsets of the parts, time can be saved by only considering those subassemblies which arise naturally.
Reference: [37] <author> L. Homem de Mello and A. Sanderson. </author> <title> Computer-Aided Mechanical Assembly Planning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process.
Reference: [38] <author> L. Homem de Mello and A. Sanderson. </author> <title> A correct and complete algorithms for the generation of mechanical assembly sequences. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 7(2) </volume> <pages> 228-240, </pages> <year> 1991. </year>
Reference-contexts: We use this result in Chapter 6, along with many 1 N.B.: this is not to be confused with the and/or tree used by Homem de Mello and Sanderson for representing all feasible assembly sequences <ref> [36, 38] </ref> CHAPTER 1. INTRODUCTION 4 reductions between different variants of the vas problem, to prove the inapproximability of most variants of the virtual assembly sequencing problems. Finally, we re-introduce the geometry in Chapter 7, proving the inapproximability for several cost measures, even in the original geometric settings. <p> Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process. <p> Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process. Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility <ref> [38, 77] </ref>. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings [39, 47, 48, 63, 75, 78].
Reference: [39] <author> J. Hopcroft, J. Schwartz, and M. Sharir. </author> <title> On the complexity of motion planning for multiple independent objects: P-space hardness of the "Warehouseman's Problem". </title> <journal> Int. J. Robotics Research, </journal> <volume> 3(4) </volume> <pages> 76-88, </pages> <year> 1984. </year>
Reference-contexts: Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility [38, 77]. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings <ref> [39, 47, 48, 63, 75, 78] </ref>. This led some researchers to consider restricted, but still interesting, versions of the problem, for instance requiring monotone sequences, where each operation generates a final subassembly, two-handed sequences, where every operation merges exactly two subassemblies.
Reference: [40] <author> T. Jiang and M. Li. </author> <title> On the approximation of shortest common supersequences and longest common subsequences. </title> <booktitle> In Automata, Languages and Programming (Proc. 21st ICALP), volume 820 of Lecture Notes in Computer Science, </booktitle> <pages> pages 191-202. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Therefore, by doubling the alphabet as above, we get that our problem of removing a part is Max-SNP-hard, when jF j 4. Also, it was shown in <ref> [40] </ref> that there exists a constant ffi &gt; 0, such that it is quasi-NP-hard to approximate the shortest common supersequence to within a factor of log ffi n.
Reference: [41] <author> D. Johnson. </author> <title> Approximation algorithms for combinatorial problems. </title> <journal> J. Comput. Systems Sci., </journal> <volume> 9 </volume> <pages> 256-278, </pages> <year> 1974. </year>
Reference-contexts: Research in the theory of approximability has consider exactly this issue for other NP-hard optimization problems <ref> [4, 23, 41, 62] </ref>. Since we cannot expect to find the optimal solution in polynomial time, the goal is to develop a polynomial time approximation algorithm that returns a solution whose cost can be bounded by some function of the true optimal cost.
Reference: [42] <author> R. Jones and R. Wilson. </author> <title> A survey of constraints in automated assembly planning. </title> <booktitle> In Proc IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 1525-1532, </pages> <year> 1996. </year>
Reference-contexts: More formal complexity measures have been defined by both Wilson and Latombe [76], as well as Wolter [78]. A collection of cost measures for assembly planning gathered by Jones and Wilson is included in <ref> [42] </ref>. Once a cost measure has been chosen, the question becomes how to find a low cost assembly sequence. As we mentioned, it is possible to generate all possible sequences, and thus evaluate the cost of each, choosing the best. <p> Other additional restrictions, common to assembly planning, are surveyed in <ref> [42, 43] </ref>, where they show that several of the constraints can be naturally integrated into the ndbg approach. Appendix A Tables of Experimental Results These tables contain the results of the experiments described in Section 4.5.
Reference: [43] <author> R. Jones, R. Wilson, and T. Calton. </author> <title> Constraint-based interactive assembly planning. </title> <journal> In Proc IEEE Int. Conf. on Robotics and Automation, </journal> <note> page To appear, 1997. BIBLIOGRAPHY 101 </note>
Reference-contexts: Other additional restrictions, common to assembly planning, are surveyed in <ref> [42, 43] </ref>, where they show that several of the constraints can be naturally integrated into the ndbg approach. Appendix A Tables of Experimental Results These tables contain the results of the experiments described in Section 4.5.
Reference: [44] <author> V. Kann. </author> <title> Polynomially bounded minimization problems which are hard to approximate. </title> <booktitle> In Automata, Languages and Programming (Proc. 20th ICALP), volume 700 of Lecture Notes in Computer Science, </booktitle> <pages> pages 52-63. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: We are unaware of any previous results for this exact approximation problem. Minimizing the number of ones in satisfying a 3CNF formula is known to be n 0:5* -hard to approximate <ref> [44] </ref>, and related minimization problems are studied in [50]. 5.3 Previous Work Although the topic of scheduling with precedence constraints has a long and rich history [23, 29, 53], there has been relatively little research focusing on models such as and/or 2 We choose, in this situation, to direct an edge
Reference: [45] <author> D. Karger, R. Motwani, and G. Ramkumar. </author> <title> On approximating the longest path in a graph. </title> <booktitle> In Proc. of the Workshop on Algorithms and Data Structures, volume 709 of Lecture Notes in Computer Science, </booktitle> <pages> pages 421-432, </pages> <year> 1993. </year>
Reference-contexts: For problems in Class III, it is quasi-NP-hard to achieve a 2 log 1fl n factor 2 approximation for any fl &gt; 0. Label Cover is the canonical problem in this class [3], although the class contains several other natural problems such as Longest Path <ref> [45] </ref> and Nearest Lattice Vector [3]. Finally, Class IV consists of the hardest problems, namely those for which it is NP-hard to achieve an n * approximation factor for some * &gt; 0. This class includes problems such as Clique [34] and Coloring [58].
Reference: [46] <author> S. Kaufman, R. Wilson, R. Jones, T. Calton, and A. Ames. </author> <title> The Archimedes 2 mechanical assembly planning system. </title> <booktitle> In Proc IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 3361-3368, </pages> <year> 1996. </year>
Reference-contexts: We directly question these previous claims in Appendix B. Finally, several software systems offer the user the option of optimizing the sequence over a choice of complexity measures <ref> [46, 67, 78] </ref>, however these systems must rely on current techniques and thus either require possibly exponential search techniques to find the true optimal, or else polynomial heuristics with no performance guarantees on the cost of the resulting sequence. 2.1.1 A Review of Non-Directional Blocking Graphs A key concept in understanding <p> This algorithm runs in polynomially time, is quite simple, and has been implemented in assembly sequencing systems for many of the above motion classes <ref> [30, 46, 67, 74] </ref>. As we will see, searching for a "good" sequence in this way is not quite so simple. CHAPTER 2. BACKGROUND 10 2.2 Approximation Theory For most variants, finding the optimal cost assembly sequence will turn out to be NP-hard. <p> VIRTUAL ASSEMBLY SEQUENCING (VAS) 20 of freedom as possible. Note that this differs from restriction R2, in that we are not told which directions to use in restricting our search. C2 Fewest Re-orientations. <ref> [46, 55, 78] </ref> The cost of an assembly sequence is equal to the number of operations that use a direction that is different from the previous operation (we will also charge the very first operation). <p> As was mentioned in Section 2.1, there has been a great deal of success for finding feasible assembly sequences in many settings. There are two different software systems for assembly sequencing based on the ndbg framework, which are quite robust <ref> [46, 67] </ref>. Both of these packages are complete in finding feasible assembly sequences when they exist. Additionally, both of these systems offer their users the opportunity to optimize sequences over several of the cost measures that we consider. <p> For this reason, we performed experiments using input drawn from various sources. This section described these experiments, including the results and our conclusions. 4.5.1 The Model Assemblies For our experiments, we consider several model assemblies that have been used as a test bed by previous research on assembly sequencing <ref> [46, 67, 74] </ref>. These models consist of three dimensional polygonal parts, and we consider their disassembly using infinitesimal translations to separate parts. The ndbg's for products have been constructed using either the STAAT [67] or ARCHIMEDES [46] assembly sequencers. Redundant blocking graphs CHAPTER 4. <p> These models consist of three dimensional polygonal parts, and we consider their disassembly using infinitesimal translations to separate parts. The ndbg's for products have been constructed using either the STAAT [67] or ARCHIMEDES <ref> [46] </ref> assembly sequencers. Redundant blocking graphs CHAPTER 4. ALGORITHMS, HEURISTICS AND EXPERIMENTS 32 were then removed, and the remaining family of blocking graphs is used as input for our experiment. Description: An electric bell, modeled with varying levels of detail [74]. Courtesy of Randy Wilson.
Reference: [47] <author> L. Kavraki and M. Kolountzakis. </author> <title> Partitioning a planar assembly into two connected parts is NP-complete. </title> <journal> Information Processing Letters, </journal> <volume> 55(3) </volume> <pages> 159-165, </pages> <year> 1995. </year>
Reference-contexts: Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility [38, 77]. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings <ref> [39, 47, 48, 63, 75, 78] </ref>. This led some researchers to consider restricted, but still interesting, versions of the problem, for instance requiring monotone sequences, where each operation generates a final subassembly, two-handed sequences, where every operation merges exactly two subassemblies. <p> Other restrictions can also be added to our graph-theoretic model quite naturally. One interesting constraint that has been considered quite often in assembly sequencing is to require that all subassemblies which are used during the construction of a product are connected subassemblies <ref> [32, 47, 74] </ref>. Generally, unconnected subassemblies require additional expensive fixturing, and are more troublesome in terms of stability and maneuverability. The additional connectedness restriction can easily be modeled as a part of vas.
Reference: [48] <author> L. Kavraki, J.-C. Latombe, and R. Wilson. </author> <title> Complexity of partitioning an assembly. </title> <booktitle> In Proc. 5th Canad. Conf. Comput. Geom., </booktitle> <pages> pages 12-17, </pages> <address> Waterloo, Canada, </address> <year> 1993. </year>
Reference-contexts: Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility [38, 77]. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings <ref> [39, 47, 48, 63, 75, 78] </ref>. This led some researchers to consider restricted, but still interesting, versions of the problem, for instance requiring monotone sequences, where each operation generates a final subassembly, two-handed sequences, where every operation merges exactly two subassemblies.
Reference: [49] <author> S. Khanna and R. Motwani. </author> <title> Towards a syntactic characterization of PTAS. </title> <booktitle> In Proc. 28th ACM Symp. Theory Comput., </booktitle> <pages> pages 329-337, </pages> <year> 1996. </year>
Reference-contexts: Similarly, achieving an n * - approximation for Minimum Independent Set is NP-hard [34], however for planar graphs, Minimum Independent Set can be approximated to within (1 + *) [6]. Similar results hold for most optimization problem when restricted to planar graphs <ref> [49] </ref>. There exists a (1 + o (1)) ln n lower bound for approximating the Set Cover problem [22], however the Rectangle Cover problem, covering a set of axis-aligned rectangles with minimum number of points, has no such inapproximability results [62].
Reference: [50] <author> S. Khanna, M. Sudan, and L. Trevisan. </author> <title> Constraint satisfaction: The approximability of minimization problems. </title> <booktitle> In Proc. 12th IEEE Comput. Complexity Conference, </booktitle> <year> 1997. </year>
Reference-contexts: We are unaware of any previous results for this exact approximation problem. Minimizing the number of ones in satisfying a 3CNF formula is known to be n 0:5* -hard to approximate [44], and related minimization problems are studied in <ref> [50] </ref>. 5.3 Previous Work Although the topic of scheduling with precedence constraints has a long and rich history [23, 29, 53], there has been relatively little research focusing on models such as and/or 2 We choose, in this situation, to direct an edge from t i to t j , to <p> The first is a study of constraint satisfaction problems, in which they consider the the problem of minimizing the number of ones required to satisfy a collection of constraints on boolean variables <ref> [50] </ref>. Their main result is that there are a finite number of distinct levels of approximability for minimizing the number of ones needed in satisfying such constraint systems.
Reference: [51] <author> M. Klawe, W Paul, N. Pippenger, and M. Yannakakis. </author> <title> On monotone formulae with restricted depth. </title> <booktitle> In Proc. 16th ACM Symp. Theory Comp., </booktitle> <pages> pages 539-550, </pages> <year> 1984. </year>
Reference-contexts: Secondly, there is a great deal of previous work related to the size and depth of boolean circuits, including those for monotone boolean formulae <ref> [51, 66, 80] </ref>.
Reference: [52] <author> S. Krishnan and A. Sanderson. </author> <title> Path planning algorithms for assembly sequence planning. </title> <booktitle> In Proc. Int. Symp. on Intelligent Robotics, </booktitle> <pages> pages 428-439, </pages> <year> 1991. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process.
Reference: [53] <author> E. Lawler, J. Lenstra, H. Rinnooy Kan, and D. Shmoys. </author> <title> Sequencing and scheduling: algorithms and complexity. </title> <booktitle> In Handbooks in Operations Research and Management Science, </booktitle> <volume> Vol. 4, </volume> <pages> pages 445-522. </pages> <publisher> North-Holland, </publisher> <year> 1993. </year>
Reference-contexts: Minimizing the number of ones in satisfying a 3CNF formula is known to be n 0:5* -hard to approximate [44], and related minimization problems are studied in [50]. 5.3 Previous Work Although the topic of scheduling with precedence constraints has a long and rich history <ref> [23, 29, 53] </ref>, there has been relatively little research focusing on models such as and/or 2 We choose, in this situation, to direct an edge from t i to t j , to be consistent with the notion of edges in a directed blocking graph.
Reference: [54] <author> K. Lee and R. Gadh. </author> <title> Computer aided design for disassembly: a destructive approach. </title> <booktitle> In Proc. IEEE Int. Sym. on Electronics and the Environment, </booktitle> <pages> pages 173-178, </pages> <year> 1996. </year>
Reference-contexts: However, even under our assumptions, 6 CHAPTER 2. BACKGROUND 7 when there is a symmetry, there are several important problems, such as removing a given part for service, which arise as partial disassembly problems. For this reason, some researchers have focused on models for disassembly <ref> [54, 57, 68, 69, 72] </ref>. With the ability to find feasible sequences efficiently, researchers have noted the importance of evaluating the inherent complexity of a product in terms of the optimal cost for assembly.
Reference: [55] <author> S. Lee. </author> <title> Backward assembly planning with assembly cost analysis. </title> <booktitle> In Proc IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 2382-2391, </pages> <year> 1992. </year> <note> BIBLIOGRAPHY 102 </note>
Reference-contexts: In general, these tasks are not necessarily symmetric, for instance when considering flexible parts which may be deformed during assembly (e.g., snap-fit parts), or when considering stability, insertion forces or fixturing <ref> [55] </ref>. However, under our assumptions, these two tasks are indeed symmetrical. The advantage of the assembly-by-disassembly approach is that the final assembled product is usually much more constrained than the initial configuration of parts, and so infeasible plans can be more quickly eliminated in this way. <p> The assembly-by-disassembly approach for assembly sequencing has become quite popular. When considering non-rigid parts, stability, fixturing, and insertion forces, assembly and disassembly sequences are no longer symmetric <ref> [55] </ref>. However, even under our assumptions, 6 CHAPTER 2. BACKGROUND 7 when there is a symmetry, there are several important problems, such as removing a given part for service, which arise as partial disassembly problems. <p> capable of producing a feasible plan : : : The challenges still facing the field are to develop efficient and robust analysis tools and to develop planners capable of finding optimal or near-optimal sequences rather than just feasible sequences." This focus on evaluating the cost of assembly sequences has grown <ref> [55, 72, 76, 78, 79] </ref>. The first issue for finding low cost sequences, of course, is that there are many possible ways to define the cost of a sequence, depending on how the sequence will be used in a manufacturing system. <p> VIRTUAL ASSEMBLY SEQUENCING (VAS) 20 of freedom as possible. Note that this differs from restriction R2, in that we are not told which directions to use in restricting our search. C2 Fewest Re-orientations. <ref> [46, 55, 78] </ref> The cost of an assembly sequence is equal to the number of operations that use a direction that is different from the previous operation (we will also charge the very first operation).
Reference: [56] <author> S. Lee and Y. Shin. </author> <title> Assembly planning based on geometric reasoning. </title> <journal> Computers and Graphics, </journal> <volume> 14(2) </volume> <pages> 237-250, </pages> <year> 1990. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process.
Reference: [57] <author> A. Lowe and S. Niku. </author> <title> Methodology for design for disassembly. </title> <journal> In ASME Publication #DE, </journal> <volume> volume 81, </volume> <pages> pages 47-53, </pages> <year> 1995. </year>
Reference-contexts: However, even under our assumptions, 6 CHAPTER 2. BACKGROUND 7 when there is a symmetry, there are several important problems, such as removing a given part for service, which arise as partial disassembly problems. For this reason, some researchers have focused on models for disassembly <ref> [54, 57, 68, 69, 72] </ref>. With the ability to find feasible sequences efficiently, researchers have noted the importance of evaluating the inherent complexity of a product in terms of the optimal cost for assembly.
Reference: [58] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <journal> J. ACM, </journal> <volume> 41(5) </volume> <pages> 960-981, </pages> <year> 1994. </year>
Reference-contexts: Finally, Class IV consists of the hardest problems, namely those for which it is NP-hard to achieve an n * approximation factor for some * &gt; 0. This class includes problems such as Clique [34] and Coloring <ref> [58] </ref>. Because we will use these problems in several reductions, we give both definitions and notation for the Set Cover and Label Cover problems.
Reference: [59] <author> M. Middendorf. Supersequences, </author> <title> runs, and CD grammar systems. </title> <editor> In J. Dassow and A. Kelemenova, editors, </editor> <booktitle> Developments in Theoretical Computer Science, volume 6 of Topics in Computer Science, </booktitle> <pages> pages 101-114. </pages> <year> 1994. </year>
Reference-contexts: At this point, we rely on results shown in [8] combined with a result of <ref> [59] </ref>, to prove our claims, where the number of machines for ltsp corresponds to jF j. CHAPTER 6. <p> Finally, even if strings have consecutive occurrences of the same symbol, it was shown that for an alphabet of size jj = 3, that finding a common supersequence with the minimum number of runs is NP-complete <ref> [59] </ref>. A run is defined as a group of consecutive occurrences of the same symbol, and hence the number of runs is exactly equal to the number of re-orientation in our problem. For this reason, minimizing the number of re-orientations is NP-complete when jF j = 3.
Reference: [60] <author> J. Millner, S. Graves, and D. Whitney. </author> <title> Using simulated annealing to select least-cost assembly sequences. </title> <booktitle> In Proc IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 2058-2063, </pages> <year> 1994. </year>
Reference-contexts: CHAPTER 2. BACKGROUND 8 Others have looked at general heuristics that attempt to minimize the cost of assembly sequences. Millner et al. consider using simulated annealing in selecting least-cost assembly sequences <ref> [60] </ref>, and Caselli and Zanichelli consider the use of petri nets for finding assembly sequences [12]. Both of these techniques suffer either in requiring possibly exponential time in finding the optimal sequence or else in quickly finding a sequence without any provable guarantee as to its quality.
Reference: [61] <author> H. Moradi, K. Goldberg, S. Lee, and R. Wilson. </author> <title> Geometry-based part grouping for assembly planning. </title> <type> Manuscript, </type> <year> 1997. </year>
Reference-contexts: Moradi et al. consider the automatic identification of groups of parts that either can be or must be assembled together, again reducing the effective number of sequences to consider <ref> [61] </ref>. Although both of these techniques are quite practical for reducing the effective size of the problems, they simply delay the exponential computation required to overcome increasingly large data sets, and thus the need for better automated reasoning for finding low cost sequences. CHAPTER 2.
Reference: [62] <author> R. Motwani. </author> <title> Approximation algorithms. </title> <type> Stanford Technical Report STAN-CS-92-1435, </type> <year> 1992. </year>
Reference-contexts: Research in the theory of approximability has consider exactly this issue for other NP-hard optimization problems <ref> [4, 23, 41, 62] </ref>. Since we cannot expect to find the optimal solution in polynomial time, the goal is to develop a polynomial time approximation algorithm that returns a solution whose cost can be bounded by some function of the true optimal cost. <p> The goal of Label Cover min is to give a labeling that covers all edges, while minimizing the total number of labels assigned to nodes of U . Finally, we need to define our notion of approximation-preserving reductions <ref> [62, 64] </ref>. Classical reductions, for instance those equating all NP-complete problems, show that finding the optimal solution for one problem can be used to find the optimal solution for another problem. <p> There exists a (1 + o (1)) ln n lower bound for approximating the Set Cover problem [22], however the Rectangle Cover problem, covering a set of axis-aligned rectangles with minimum number of points, has no such inapproximability results <ref> [62] </ref>. Our lower bounds provide some of the strongest such inapproximability results for a natural, combinatorial, geometric problem. <p> Output: A set of points P, such that every polygon of R contains at least one point of P. Cost: The number of points, jPj. A similar, even more restricted problem, Rectangle Cover is defined in <ref> [62] </ref>, where all polygons are axis-aligned rectangles. It is not known whether Rectangle Cover is NP-hard. CHAPTER 7.
Reference: [63] <author> B. Natarajan. </author> <title> On planning assemblies. </title> <booktitle> In Proc. 4th ACM Symp. on Computational Geometry, </booktitle> <pages> pages 299-308, </pages> <year> 1988. </year>
Reference-contexts: Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility [38, 77]. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings <ref> [39, 47, 48, 63, 75, 78] </ref>. This led some researchers to consider restricted, but still interesting, versions of the problem, for instance requiring monotone sequences, where each operation generates a final subassembly, two-handed sequences, where every operation merges exactly two subassemblies.
Reference: [64] <author> C. Papadimitriou and M. Yannakakis. </author> <title> Optimization, approximation, and complexity classes. </title> <journal> J. Comput. Systems Sci., </journal> <volume> 43(3) </volume> <pages> 425-440, </pages> <year> 1991. </year>
Reference-contexts: Many researchers have worked towards classifying the approximability of different NP-hard problems <ref> [4, 5, 15, 64] </ref>. We will consider four broad classes defined in [4], which group problems based on the strength of the inapproximability results that have been proven. <p> Class I includes all problems for which approximating the optimal solution to within a factor of (1 + *) is NP-hard for some * &gt; 0. The canonical problem for this class is Max-3Sat, and the class includes all Max-SNP-complete problems <ref> [64] </ref>, for example Vertex Cover, Metric tsp, Max Cut, and others. Class II groups those problems for which it is quasi-NP-hard 1 to achieve an approximation ratio of c log n for some c &gt; 0. <p> The goal of Label Cover min is to give a labeling that covers all edges, while minimizing the total number of labels assigned to nodes of U . Finally, we need to define our notion of approximation-preserving reductions <ref> [62, 64] </ref>. Classical reductions, for instance those equating all NP-complete problems, show that finding the optimal solution for one problem can be used to find the optimal solution for another problem.
Reference: [65] <author> C. Papadimitriou and M. Yannakakis. </author> <title> The traveling salesman problem with distances one and two. </title> <journal> Mathematics of Operations Research, </journal> <volume> 18(1) </volume> <pages> 1-11, </pages> <year> 1993. </year>
Reference-contexts: More often than not, an optimization problem becomes significantly easier when its input is restricted CHAPTER 2. BACKGROUND 14 to a geometric setting. For example, there exists some c &gt; 0 for which achieving a (1 + c)- approximation for the Metric tsp problem is NP-hard <ref> [65] </ref>, however in the Euclidean plane, TSP can be approximated to within (1 + *) for all * &gt; 0 [2].
Reference: [66] <author> R. Raz and A. Wigderson. </author> <title> Monotone circuits for matching require linear depth. </title> <journal> J. ACM, </journal> <volume> 39(3) </volume> <pages> 736-744, </pages> <year> 1992. </year>
Reference-contexts: Secondly, there is a great deal of previous work related to the size and depth of boolean circuits, including those for monotone boolean formulae <ref> [51, 66, 80] </ref>.
Reference: [67] <author> B. Romney, C. Godard, M. Goldwasser, and G. Ramkumar. </author> <title> An efficient system for geometric assembly sequence generation and evaluation. </title> <booktitle> In Proc. ASME Int. Computers in Engineering Conference, </booktitle> <pages> pages 699-712, </pages> <year> 1995. </year> <note> BIBLIOGRAPHY 103 </note>
Reference-contexts: We prove that achieving a 2 log 1fl n -approximation to minimizing the total number of disks which must be removed to access the given disks is hard for any fl &gt; 0. Much of this work has appeared previously in <ref> [26, 27, 67] </ref>. 1.1 Presentation Overview This paper proceeds as follows. In the following section, we define the assembly sequencing problem and introduce several terms and definitions used throughout the paper. <p> We directly question these previous claims in Appendix B. Finally, several software systems offer the user the option of optimizing the sequence over a choice of complexity measures <ref> [46, 67, 78] </ref>, however these systems must rely on current techniques and thus either require possibly exponential search techniques to find the true optimal, or else polynomial heuristics with no performance guarantees on the cost of the resulting sequence. 2.1.1 A Review of Non-Directional Blocking Graphs A key concept in understanding <p> This algorithm runs in polynomially time, is quite simple, and has been implemented in assembly sequencing systems for many of the above motion classes <ref> [30, 46, 67, 74] </ref>. As we will see, searching for a "good" sequence in this way is not quite so simple. CHAPTER 2. BACKGROUND 10 2.2 Approximation Theory For most variants, finding the optimal cost assembly sequence will turn out to be NP-hard. <p> We consider a few such restricted versions of the assembly sequencing problem. R1 Linear Sequence. <ref> [67, 76] </ref> A linear assembly sequence is one in which each operation brings together a single part with an existing subassembly. Such sequences are reminiscent of a classical assembly line, in which each station is responsible for adding one part. <p> Our view is that success with these basic measures is a necessary first step before examining specialized combinations of complexity measures. C1 Fewest Number of Directions. <ref> [67, 76, 78] </ref> The cost of an assembly sequence is equal to the number of directions of F that are used. Once a direction has been used, future uses of the same direction are free of charge. <p> As was mentioned in Section 2.1, there has been a great deal of success for finding feasible assembly sequences in many settings. There are two different software systems for assembly sequencing based on the ndbg framework, which are quite robust <ref> [46, 67] </ref>. Both of these packages are complete in finding feasible assembly sequences when they exist. Additionally, both of these systems offer their users the opportunity to optimize sequences over several of the cost measures that we consider. <p> For this reason, we performed experiments using input drawn from various sources. This section described these experiments, including the results and our conclusions. 4.5.1 The Model Assemblies For our experiments, we consider several model assemblies that have been used as a test bed by previous research on assembly sequencing <ref> [46, 67, 74] </ref>. These models consist of three dimensional polygonal parts, and we consider their disassembly using infinitesimal translations to separate parts. The ndbg's for products have been constructed using either the STAAT [67] or ARCHIMEDES [46] assembly sequencers. Redundant blocking graphs CHAPTER 4. <p> These models consist of three dimensional polygonal parts, and we consider their disassembly using infinitesimal translations to separate parts. The ndbg's for products have been constructed using either the STAAT <ref> [67] </ref> or ARCHIMEDES [46] assembly sequencers. Redundant blocking graphs CHAPTER 4. ALGORITHMS, HEURISTICS AND EXPERIMENTS 32 were then removed, and the remaining family of blocking graphs is used as input for our experiment. Description: An electric bell, modeled with varying levels of detail [74]. Courtesy of Randy Wilson. <p> Each peg will naturally have some specific region of directions, by which it can be translated away from the base. An example of a single such peg is shown in Figure 7.1, modified from <ref> [67] </ref>. Now we consider the minimum number of directions which must be used to remove all the pegs from the base.
Reference: [68] <author> N. Shyamsundar and R. Gadh. </author> <title> Selective disassembly of virtual prototypes. </title> <booktitle> In Proc. IEEE Int. Conf. on Systems, Man, and Cybernetics, </booktitle> <volume> volume 4, </volume> <pages> pages 3159-3164, </pages> <year> 1996. </year>
Reference-contexts: However, even under our assumptions, 6 CHAPTER 2. BACKGROUND 7 when there is a symmetry, there are several important problems, such as removing a given part for service, which arise as partial disassembly problems. For this reason, some researchers have focused on models for disassembly <ref> [54, 57, 68, 69, 72] </ref>. With the ability to find feasible sequences efficiently, researchers have noted the importance of evaluating the inherent complexity of a product in terms of the optimal cost for assembly.
Reference: [69] <author> N. Shyamsundar and R. Gadh. </author> <title> Geometric abstractions to support disassembly evaluation. </title> <booktitle> In Proc. 23rd Design Automation Conference, page To appear, </booktitle> <year> 1997. </year>
Reference-contexts: However, even under our assumptions, 6 CHAPTER 2. BACKGROUND 7 when there is a symmetry, there are several important problems, such as removing a given part for service, which arise as partial disassembly problems. For this reason, some researchers have focused on models for disassembly <ref> [54, 57, 68, 69, 72] </ref>. With the ability to find feasible sequences efficiently, researchers have noted the importance of evaluating the inherent complexity of a product in terms of the optimal cost for assembly.
Reference: [70] <author> J. Snoeyink and J. Stolfi. </author> <title> Objects that cannot be taken apart with two hands. </title> <booktitle> In Proc. ACM Symp. on Computational Geometry, </booktitle> <pages> pages 247-256, </pages> <year> 1993. </year>
Reference-contexts: Courtesy of Randy Wilson. Description: A model aircraft engine, modeled with varying levels of detail [74]. Courtesy of Randy Wilson. Description: Snoeyink and Stolfi describe a model of a 30 part assembly of convex parts in three dimensions, for which there is no legal separation <ref> [70] </ref>. We have deleted one of the pieces to provide an interesting model that may be disassembled. Courtesy of Jack Snoeyink.
Reference: [71] <author> J. Stolfi. </author> <title> Oriented Projective Geometry: A Framework for Geometric Computations. </title> <publisher> Academic Press, </publisher> <year> 1991. </year>
Reference-contexts: Proof: Given a set of polygons in the plane, we will consider the corresponding homogeneous coordinates to project them onto the upper hemisphere <ref> [71] </ref>. Given a single such projection, we can design a peg which can be removed from the base using exactly those directions represented by the polygon.
Reference: [72] <author> A. Subramani. </author> <title> Development of a Design for Service Methodology. </title> <type> Ph.D. thesis, </type> <institution> Dept. Industrial and Manufacting Eng., </institution> <address> U. Rhode Island, Kingston, RI, </address> <year> 1992. </year>
Reference-contexts: However, even under our assumptions, 6 CHAPTER 2. BACKGROUND 7 when there is a symmetry, there are several important problems, such as removing a given part for service, which arise as partial disassembly problems. For this reason, some researchers have focused on models for disassembly <ref> [54, 57, 68, 69, 72] </ref>. With the ability to find feasible sequences efficiently, researchers have noted the importance of evaluating the inherent complexity of a product in terms of the optimal cost for assembly. <p> capable of producing a feasible plan : : : The challenges still facing the field are to develop efficient and robust analysis tools and to develop planners capable of finding optimal or near-optimal sequences rather than just feasible sequences." This focus on evaluating the cost of assembly sequences has grown <ref> [55, 72, 76, 78, 79] </ref>. The first issue for finding low cost sequences, of course, is that there are many possible ways to define the cost of a sequence, depending on how the sequence will be used in a manufacturing system.
Reference: [73] <author> G. Toussaint. </author> <title> Movable separability of sets. </title> <editor> In G. Toussaint, editor, </editor> <booktitle> Computational Geometry, </booktitle> <pages> pages 335-375. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1985. </year>
Reference-contexts: Similar issues on the separability of polygons were studied by Toussaint in 1985 for more general classes of shapes in two dimensions, such as monotone or star-shaped polygons <ref> [73] </ref>. Constructing a sequence for the individual removal of polygons from a collection in two dimensions was studied by Dehne and Sack in 1987 [19]. In this work, they introduce what the term the movability wheel, which can be though of as a very preliminary version of the ndbg. <p> Similar results on the separability of objects may provide us with additional properties, however they do not provide any immediate algorithmic results. For example, Toussaint shows that for any two star-shaped polygons in two dimensions, there must exist some direction of translations which separates the two <ref> [73] </ref>. In terms of our graphs, this tells us that there must be at least one blocking graph where the corresponding edge between two parts is missing. Whether this property is helpful for assembly sequencing is not clear.
Reference: [74] <author> R. Wilson. </author> <title> On Geometric Assembly Planning. </title> <type> Ph.D. thesis, </type> <institution> Dept. Comput. Sci., Stan-ford Univ., Stanford, </institution> <address> CA, </address> <year> 1992. </year> <note> Stanford Technical Report STAN-CS-92-1416. </note>
Reference-contexts: We begin by studying a graph-theoretic generalization of assembly sequencing which we term virtual assembly sequencing (vas). Much of the success in finding feasible sequences has been a result of the introduction of the non-directional blocking graph <ref> [74, 76] </ref>. For a given direction of motion, the geometric model of the product can be analyzed to construct a graph that represents the blocking relationships among the parts. <p> Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process. <p> For many classes of motions parameterized by a constant number of degrees of freedom, polynomial algorithms were then developed to find a binary, monotone assembly sequence when one exists <ref> [30, 33, 74, 76] </ref>. A good deal of this success was achieved within the framework of non-directional blocking graphs [32, 74, 76]. <p> For many classes of motions parameterized by a constant number of degrees of freedom, polynomial algorithms were then developed to find a binary, monotone assembly sequence when one exists [30, 33, 74, 76]. A good deal of this success was achieved within the framework of non-directional blocking graphs <ref> [32, 74, 76] </ref>. As our work is intricately related to this approach, in the following section, we will review in greater detail the concept of non-directional blocking graphs and the subsequent results. <p> The key insight is that many distinct motions may be represented by the identical dbg, since slight changes in a direction may not effect the blocking relationships between any of the parts. This fact led to the development of the non-directional blocking graph (ndbg) <ref> [74, 76] </ref>. CHAPTER 2. BACKGROUND 9 During the construction of an ndbg, the space of motions are divided into equivalence classes based on the blocking graphs, and the resulting ndbg consists of a single dbg for each equivalence class. <p> Thus the ndbg completely captures the necessary geometric information for identifying all valid operations for those motions. The only issue remaining is the number of equivalence classes and how to compute them. In the original work <ref> [74] </ref>, they show that the number of such equivalence classes is poly-nomially bounded in the complexity of the input, for three-dimensional polyhedra, when the operations involved are either infinitesimal translations, infinitesimal translations with rotations, or translations to infinity. <p> This algorithm runs in polynomially time, is quite simple, and has been implemented in assembly sequencing systems for many of the above motion classes <ref> [30, 46, 67, 74] </ref>. As we will see, searching for a "good" sequence in this way is not quite so simple. CHAPTER 2. BACKGROUND 10 2.2 Approximation Theory For most variants, finding the optimal cost assembly sequence will turn out to be NP-hard. <p> For this reason, we performed experiments using input drawn from various sources. This section described these experiments, including the results and our conclusions. 4.5.1 The Model Assemblies For our experiments, we consider several model assemblies that have been used as a test bed by previous research on assembly sequencing <ref> [46, 67, 74] </ref>. These models consist of three dimensional polygonal parts, and we consider their disassembly using infinitesimal translations to separate parts. The ndbg's for products have been constructed using either the STAAT [67] or ARCHIMEDES [46] assembly sequencers. Redundant blocking graphs CHAPTER 4. <p> Redundant blocking graphs CHAPTER 4. ALGORITHMS, HEURISTICS AND EXPERIMENTS 32 were then removed, and the remaining family of blocking graphs is used as input for our experiment. Description: An electric bell, modeled with varying levels of detail <ref> [74] </ref>. Courtesy of Randy Wilson. Description: A model aircraft engine, modeled with varying levels of detail [74]. Courtesy of Randy Wilson. Description: Snoeyink and Stolfi describe a model of a 30 part assembly of convex parts in three dimensions, for which there is no legal separation [70]. <p> ALGORITHMS, HEURISTICS AND EXPERIMENTS 32 were then removed, and the remaining family of blocking graphs is used as input for our experiment. Description: An electric bell, modeled with varying levels of detail <ref> [74] </ref>. Courtesy of Randy Wilson. Description: A model aircraft engine, modeled with varying levels of detail [74]. Courtesy of Randy Wilson. Description: Snoeyink and Stolfi describe a model of a 30 part assembly of convex parts in three dimensions, for which there is no legal separation [70]. We have deleted one of the pieces to provide an interesting model that may be disassembled. <p> Other restrictions can also be added to our graph-theoretic model quite naturally. One interesting constraint that has been considered quite often in assembly sequencing is to require that all subassemblies which are used during the construction of a product are connected subassemblies <ref> [32, 47, 74] </ref>. Generally, unconnected subassemblies require additional expensive fixturing, and are more troublesome in terms of stability and maneuverability. The additional connectedness restriction can easily be modeled as a part of vas.
Reference: [75] <author> R. Wilson, L. Kavraki, J.-C. Latombe, and T. Lozano-Perez. </author> <title> Two-handed assembly sequencing. </title> <journal> Int. J. of Robotics Research, </journal> <volume> 14(4) </volume> <pages> 335-350, </pages> <year> 1995. </year>
Reference-contexts: Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility [38, 77]. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings <ref> [39, 47, 48, 63, 75, 78] </ref>. This led some researchers to consider restricted, but still interesting, versions of the problem, for instance requiring monotone sequences, where each operation generates a final subassembly, two-handed sequences, where every operation merges exactly two subassemblies.
Reference: [76] <author> R. Wilson and J.-C. Latombe. </author> <title> Geometric reasoning about mechanical assembly. </title> <journal> Artificial Intelligence, </journal> <volume> 71(2) </volume> <pages> 371-396, </pages> <year> 1994. </year>
Reference-contexts: We begin by studying a graph-theoretic generalization of assembly sequencing which we term virtual assembly sequencing (vas). Much of the success in finding feasible sequences has been a result of the introduction of the non-directional blocking graph <ref> [74, 76] </ref>. For a given direction of motion, the geometric model of the product can be analyzed to construct a graph that represents the blocking relationships among the parts. <p> Once this is done, each of the resulting subassemblies can be disassembled in a similar manner. The structure of this decomposition can be represented naturally as a binary assembly tree. Figure 1.1 gives an example of such an assembly tree, taken from <ref> [76] </ref>, for a simple two-dimensional product. The root of the tree represents the fully assembled product, and the children of an internal node represent two subassemblies that can be combined together to produce the larger subassembly represented by the parent. <p> For many classes of motions parameterized by a constant number of degrees of freedom, polynomial algorithms were then developed to find a binary, monotone assembly sequence when one exists <ref> [30, 33, 74, 76] </ref>. A good deal of this success was achieved within the framework of non-directional blocking graphs [32, 74, 76]. <p> For many classes of motions parameterized by a constant number of degrees of freedom, polynomial algorithms were then developed to find a binary, monotone assembly sequence when one exists [30, 33, 74, 76]. A good deal of this success was achieved within the framework of non-directional blocking graphs <ref> [32, 74, 76] </ref>. As our work is intricately related to this approach, in the following section, we will review in greater detail the concept of non-directional blocking graphs and the subsequent results. <p> capable of producing a feasible plan : : : The challenges still facing the field are to develop efficient and robust analysis tools and to develop planners capable of finding optimal or near-optimal sequences rather than just feasible sequences." This focus on evaluating the cost of assembly sequences has grown <ref> [55, 72, 76, 78, 79] </ref>. The first issue for finding low cost sequences, of course, is that there are many possible ways to define the cost of a sequence, depending on how the sequence will be used in a manufacturing system. <p> Based on a great deal of work with industrial applications, Boothroyd et al. suggest several empirical measures that effect the cost of assembly for a product [10, 11]. More formal complexity measures have been defined by both Wilson and Latombe <ref> [76] </ref>, as well as Wolter [78]. A collection of cost measures for assembly planning gathered by Jones and Wilson is included in [42]. Once a cost measure has been chosen, the question becomes how to find a low cost assembly sequence. <p> Figure 2.1 gives an example of a two-dimensional product as well as two dbgs for infinitesimal translation <ref> [76] </ref>. The blocking graph for a given motion provides a compact representation of all collision-free operations for that motion, as each directed cut between some subset S and subset T in a dbg corresponds to a collision-free partition. <p> The key insight is that many distinct motions may be represented by the identical dbg, since slight changes in a direction may not effect the blocking relationships between any of the parts. This fact led to the development of the non-directional blocking graph (ndbg) <ref> [74, 76] </ref>. CHAPTER 2. BACKGROUND 9 During the construction of an ndbg, the space of motions are divided into equivalence classes based on the blocking graphs, and the resulting ndbg consists of a single dbg for each equivalence class. <p> In a series of work since then, geometric algorithms have been developed and improved for building the ndbg when the motion class allowed includes, infinitesimal translations <ref> [76] </ref>, extended translations (i.e., to infinity) [76], multiple step translations in the plane [33], and infinitesimal generalized motions (i.e., rigid body motions) [30, 76]. <p> In a series of work since then, geometric algorithms have been developed and improved for building the ndbg when the motion class allowed includes, infinitesimal translations <ref> [76] </ref>, extended translations (i.e., to infinity) [76], multiple step translations in the plane [33], and infinitesimal generalized motions (i.e., rigid body motions) [30, 76]. As a general rule, it seems that a family of motions with a constant number of degrees of freedom leads to a polynomial number of distinct equivalence classes. <p> In a series of work since then, geometric algorithms have been developed and improved for building the ndbg when the motion class allowed includes, infinitesimal translations [76], extended translations (i.e., to infinity) [76], multiple step translations in the plane [33], and infinitesimal generalized motions (i.e., rigid body motions) <ref> [30, 76] </ref>. As a general rule, it seems that a family of motions with a constant number of degrees of freedom leads to a polynomial number of distinct equivalence classes. A more recent survey presents a unified framework for understanding the collection of work surrounding the non-directional blocking graphs [32]. <p> We consider a few such restricted versions of the assembly sequencing problem. R1 Linear Sequence. <ref> [67, 76] </ref> A linear assembly sequence is one in which each operation brings together a single part with an existing subassembly. Such sequences are reminiscent of a classical assembly line, in which each station is responsible for adding one part. <p> Our view is that success with these basic measures is a necessary first step before examining specialized combinations of complexity measures. C1 Fewest Number of Directions. <ref> [67, 76, 78] </ref> The cost of an assembly sequence is equal to the number of directions of F that are used. Once a direction has been used, future uses of the same direction are free of charge. <p> This is typically slow and might require additional expensive fixtures. In both of these cases, using an orientation that was encountered earlier in the process is of no advantage unless the product is still in that orientation. C3 Fewest Number of Non-Linear Steps. <ref> [76] </ref> An operation is linear if one of the two subassemblies is a single part. The cost of an assembly sequence is equal to the number of non-linear operations. <p> Notice that for goal G1, full disassembly, every possible binary assembly sequence will require exactly (n 1) steps. Therefore, this cost measure is only meaningful for the partial disassembly problems. C5 Minimum Depth of an Assembly Sequence. <ref> [76] </ref> The cost of an assembly sequence is equal to the depth of the corresponding tree. The motivation here is that in many assembly environments, parallelism in production is helpful, and the minimum depth tree has the quickest throughput, in a sense. <p> When minimizing the depth for full disassembly, the worst possible cost is still n 1, however we know that the best possible depth for any full tree must be at least dlog 2 ne. Observation 7 A stack assembly is defined in <ref> [76] </ref> as a product that can be completely (dis)assembled using translations along a single direction. They observe that a product admits a stack assembly sequence, if and only if one of the blocking graphs is acyclic, and that this can be checked in polynomial time.
Reference: [77] <author> R. Wilson and J. Rit. </author> <title> Maintaining geometric dependencies in and assembly planner. </title> <booktitle> In Proc. IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 890-895, </pages> <year> 1990. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process. <p> Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process. Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility <ref> [38, 77] </ref>. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings [39, 47, 48, 63, 75, 78].
Reference: [78] <author> J. Wolter. </author> <title> On the Automatic Generation of Plans for Mechanical Assembly. </title> <type> Ph.D. thesis, </type> <institution> University of Michigan, </institution> <year> 1988. </year>
Reference-contexts: Note however, that the assembly tree only represents the structure of the decomposition, but not the desired sequence in which the operations are performed. Chapter 2 Background 2.1 Assembly Sequencing The use of automation in assembly sequencing has increased rapidly over the years <ref> [7, 21, 35, 37, 38, 52, 56, 74, 77, 78] </ref>. Progressing from days when assembly sequencing was purely a craft of the human designers, computers have become a powerful tool in the sequencing process. <p> Early systems resulted in potentially exponential time generate-and-test sequencers, operating by generating candidate operations and testing their feasibility [38, 77]. The problem of finding a valid assembly sequence was later shown to be intractable in many general settings <ref> [39, 47, 48, 63, 75, 78] </ref>. This led some researchers to consider restricted, but still interesting, versions of the problem, for instance requiring monotone sequences, where each operation generates a final subassembly, two-handed sequences, where every operation merges exactly two subassemblies. <p> capable of producing a feasible plan : : : The challenges still facing the field are to develop efficient and robust analysis tools and to develop planners capable of finding optimal or near-optimal sequences rather than just feasible sequences." This focus on evaluating the cost of assembly sequences has grown <ref> [55, 72, 76, 78, 79] </ref>. The first issue for finding low cost sequences, of course, is that there are many possible ways to define the cost of a sequence, depending on how the sequence will be used in a manufacturing system. <p> Based on a great deal of work with industrial applications, Boothroyd et al. suggest several empirical measures that effect the cost of assembly for a product [10, 11]. More formal complexity measures have been defined by both Wilson and Latombe [76], as well as Wolter <ref> [78] </ref>. A collection of cost measures for assembly planning gathered by Jones and Wilson is included in [42]. Once a cost measure has been chosen, the question becomes how to find a low cost assembly sequence. <p> We directly question these previous claims in Appendix B. Finally, several software systems offer the user the option of optimizing the sequence over a choice of complexity measures <ref> [46, 67, 78] </ref>, however these systems must rely on current techniques and thus either require possibly exponential search techniques to find the true optimal, or else polynomial heuristics with no performance guarantees on the cost of the resulting sequence. 2.1.1 A Review of Non-Directional Blocking Graphs A key concept in understanding <p> Our view is that success with these basic measures is a necessary first step before examining specialized combinations of complexity measures. C1 Fewest Number of Directions. <ref> [67, 76, 78] </ref> The cost of an assembly sequence is equal to the number of directions of F that are used. Once a direction has been used, future uses of the same direction are free of charge. <p> VIRTUAL ASSEMBLY SEQUENCING (VAS) 20 of freedom as possible. Note that this differs from restriction R2, in that we are not told which directions to use in restricting our search. C2 Fewest Re-orientations. <ref> [46, 55, 78] </ref> The cost of an assembly sequence is equal to the number of operations that use a direction that is different from the previous operation (we will also charge the very first operation). <p> An example of a single such peg is shown in Figure 7.1, modified from [67]. Now we consider the minimum number of directions which must be used to remove all the pegs from the base. As pointed out in <ref> [78] </ref>, this instance looks very much like a Set Cover problem, in that we must choose a minimum number of directions, where each direction allows for the removal of some set of pegs.
Reference: [79] <author> T. Woo and D. Dutta. </author> <title> Automatic disassembly and total ordering in three dimensions. </title> <journal> J. Engineering for Industry, </journal> <volume> 113(2) </volume> <pages> 207-213, </pages> <year> 1991. </year>
Reference-contexts: capable of producing a feasible plan : : : The challenges still facing the field are to develop efficient and robust analysis tools and to develop planners capable of finding optimal or near-optimal sequences rather than just feasible sequences." This focus on evaluating the cost of assembly sequences has grown <ref> [55, 72, 76, 78, 79] </ref>. The first issue for finding low cost sequences, of course, is that there are many possible ways to define the cost of a sequence, depending on how the sequence will be used in a manufacturing system. <p> For a restricted class of inputs that have a so-called "total ordering" property, a greedy algorithm is given that claims to produce the minimal length sequence to remove any give part <ref> [20, 79] </ref>, however the required input property does not have a clear definition. For the general setting, our results in Section 7.5 will prove not only the difficulty of finding an optimal sequence by this cost measure, but even a near-optimal solution. <p> The motivations for this measure are similar to those for the R1 restriction, however rather than absolutely requiring that all steps are linear, we simply attempt to minimize the use of non-linear operations. C4 Fewest Number of Steps. <ref> [79] </ref> The cost of an assembly sequence is equal to the total number of operations used. Notice that for goal G1, full disassembly, every possible binary assembly sequence will require exactly (n 1) steps. Therefore, this cost measure is only meaningful for the partial disassembly problems. <p> 14 13 9 9 13.6 21 9 11 12 13 11 10 14.3 23 7 10 10 10 10 7 12.8 25 6 9 10 13 9 6 11.1 27 5 10 6 7 6 5 8.2 TIME 116900 12200 26700 12500 25700 13255.5 Appendix B Questioning the Claims of <ref> [20, 79] </ref> In a sequence of two journal articles, Woo and Dutta present an algorithm for the removal of a part (or multiple parts) from a product made of polyhedral parts in either two or three dimensions [20, 79]. <p> TIME 116900 12200 26700 12500 25700 13255.5 Appendix B Questioning the Claims of <ref> [20, 79] </ref> In a sequence of two journal articles, Woo and Dutta present an algorithm for the removal of a part (or multiple parts) from a product made of polyhedral parts in either two or three dimensions [20, 79]. They allow for parts to be removed, one at a time, using translations to infinity. <p> For these totally ordered products, this claim ammounts to solving the (G2/C4/R1) variant for which we proved a 2 log 1fl n lower bound, even in the Disks setting. This potential contradiction leads us to reconsider the claims of optimality made in <ref> [20, 79] </ref>, and the assemblies to which the algorithm applies. Unfortunately, we feel that their presentation suffers from being inconsistent and vague, and thus their claims are in question. <p> We will begin by addressing their definitions and claims which we feel are not sufficiently clear. Following this, we will give an example of a product very similar to an example they give, for which their optimality claim does not hold. 91 APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 92 Figure B.1: Freedom for Infinitesimal Translational B.1 Cost Measure The first issue for us is to understand what cost measure they claim to be optimizing. <p> In their first paper in 1991, they claim in Section 3.1 that "the DT thus constructed yields a minimum number of removals (motions) in order to access a certain component" <ref> [79] </ref>. In the 1995 paper, they claim to remove a part while minimizing the number of adjacent parts which are removed. In fact, in this second paper, they claim to be able to solve this task, even when asked to remove an arbitrary set of parts. <p> They are very clear in that they consider strictly translational, one-step motions. In terms of whether they wish to consider infinitesimal translations versus translations to infinity, they explicitly express on the first page of <ref> [79] </ref> that there are several criteria for "clearing" a part from a subassembly, and that they choose to adopt the criterion which requires that "the component can be translated to infinity." However, the subroutine which they present for checking for the removability of a given part clearly checks only for infinitesimal <p> The algorithm Disassemblable which they present for computing the freedom of a part from a subassembly is based entirely from examining the contact faces which the part in question shares with adjacent parts <ref> [79] </ref>. As an example, if their algorithm were run on the two part assembly which they provide in figure 1.3 (a) of [79], (our Figure B.1), it would determine that part a 1 can be successfully removed along the positive X-axis, when clearly this is not possible if the part must <p> present for computing the freedom of a part from a subassembly is based entirely from examining the contact faces which the part in question shares with adjacent parts <ref> [79] </ref>. As an example, if their algorithm were run on the two part assembly which they provide in figure 1.3 (a) of [79], (our Figure B.1), it would determine that part a 1 can be successfully removed along the positive X-axis, when clearly this is not possible if the part must be cleared to infinity. <p> Based on their explicit description of the check for removability, we seem to have no choice but to assume that they are considering only the local freedom for infinitesimal translations. APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 93 This decision is also consistent with the fact that in their algorithm for disassembly, when trying to find the effects of the removal of one part on the removability of other parts, they only recheck the removal of those parts which are adjacent to the first part removed. <p> Their claims are simply that their algorithms are guaranteed to find the optimal sequence for products which exhibit this special property, and so in order to refute such claims, we must understand this property. Originally, they define this property in Definition 1.3 of <ref> [79] </ref> as follows: "An assembly is partially ordered if the disassembly of a component requires an immediate prior disassembly of k components. <p> If this is indeed the intended concept of total ordering, then their claims of optimality are quite trivial. If every part requires either one or two steps for removal, it is quite simple to identify those APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 94 Figure B.2: An example given by Woo and Dutta parts which can be removed in one step from the full assembly. For all other parts, it must be that the removal of some single other part must create the freedom for removing this part. <p> Also, this interpretation would be somewhat surprising, given that the examples they give of their algorithm in action (Figure 3.3 of <ref> [79] </ref> and Figure 4 of [20]) both result in trees with heights greater than two. <p> One could remove APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 95 Figure B.3: Our counterexample for optimal disassembly parts in the following order, b; c; d; e, and thus remove both d and e without removing a. <p> Clearly, for either of these cost measures, the optimal sequence is first to remove b, followed by c, and then d, requiring APPENDIX B. QUESTIONING THE CLAIMS OF <ref> [20, 79] </ref> 96 Figure B.4: The resulting DT for our counterexample cost 2 by either metric.
Reference: [80] <author> A. Yao. </author> <title> A lower bound for the monotone depth of connectivity. </title> <booktitle> In Proc. 35th Symp. on Found. Comput. Sci., </booktitle> <pages> pages 302-308, </pages> <year> 1994. </year>
Reference-contexts: Secondly, there is a great deal of previous work related to the size and depth of boolean circuits, including those for monotone boolean formulae <ref> [51, 66, 80] </ref>.
References-found: 80

