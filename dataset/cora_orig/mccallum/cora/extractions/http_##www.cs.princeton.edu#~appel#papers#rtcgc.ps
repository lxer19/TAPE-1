URL: http://www.cs.princeton.edu/~appel/papers/rtcgc.ps
Refering-URL: http://www.cs.princeton.edu/~appel/papers/
Root-URL: http://www.cs.princeton.edu
Title: Real-time Concurrent Collection on Stock Multiprocessors  
Author: Andrew W. Appel John R. Ellis Kai Li 
Abstract: We have designed and implemented a copying garbage-collection algorithm that is efficient, real-time, concurrent, runs on commerial uniprocessors and shared-memory multiprocessors, and requires no change to compilers. The algorithm uses standard virtual-memory hardware to detect references to "from space" objects and to synchronize the collector and mutator threads. We have implemented and measured a prototype running on SRC's 5-processor Firefly. It will be straightforward to merge our techniques with generational collection. An incremental, non-concurrent version could be implemented easily on many versions of Unix. 
Abstract-found: 1
Intro-found: 1
Reference: [Appel 87] <author> Andrew W. Appel. </author> <title> Garbage collection can be faster than stack allocation. </title> <journal> Information Processing Letters, </journal> <volume> 25(4) </volume> <pages> 275-279, </pages> <year> 1987. </year>
Reference-contexts: No one has yet built a practical concurrent mark-and-sweep collector, and it may be difficult to make them efficient [Hickey 84]. Asymptotically, copying-based collectors have the potential to be much more efficient than reference-counting or mark-and-sweep collectors <ref> [Baker 78, Appel 87] </ref>. Copying collectors (including our algorithm) do work proportional only to the amount of reachable objects; thus, as the total available memory is increased relative to the number of reachable objects, the time to reclaim an object approaches zero in the limit. <p> When to-space fills up, the mutator stops and initiates a new collection. Stop-and-copy collectors can be very efficient, especially when the total available memory is much larger than the amount of live objects <ref> [Baker 78, Appel 87] </ref>. <p> Multiple Mutator Threads How many mutator threads can one collector support while remaining real-time and concurrent? In general, this depends on the total amount of memory, since copying collectors are arbitrarily efficient as the ratio of memory size to reachable objects increases <ref> [Baker 78, Appel 87] </ref>. How many threads could our initial implementation support with its 6-megabyte heap? Even though ML limited us to one mutator thread, we can make a rough estimate.
Reference: [Baker 78] <author> H. G. Baker. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <year> 1978. </year>
Reference-contexts: No one has yet built a practical concurrent mark-and-sweep collector, and it may be difficult to make them efficient [Hickey 84]. Asymptotically, copying-based collectors have the potential to be much more efficient than reference-counting or mark-and-sweep collectors <ref> [Baker 78, Appel 87] </ref>. Copying collectors (including our algorithm) do work proportional only to the amount of reachable objects; thus, as the total available memory is increased relative to the number of reachable objects, the time to reclaim an object approaches zero in the limit. <p> Unfortunately, we still don't have enough experience with scaled-up implementations to make final comparisons. Baker's algorithm <ref> [Baker 78] </ref> was the first real-time, copying-based collector. But it isn't concurrent, it requires special hardware, and its first implementation on Lisp machines wasn't efficient (users turned it off). <p> When to-space fills up, the mutator stops and initiates a new collection. Stop-and-copy collectors can be very efficient, especially when the total available memory is much larger than the amount of live objects <ref> [Baker 78, Appel 87] </ref>. <p> But they are unsuitable for real-time or interactive applications because of the long delay while the mutator is suspended. 4 Baker's Algorithm In Baker's real-time algorithm <ref> [Baker 78] </ref>, when to-space fills up, the collector stops the mutator, flips, but then copies only the root objects (for example, those referenced from the registers). It then resumes the mutator immediately. Reachable objects are copied incrementally from from-space while the mutator executes. <p> Then it allocates the object and returns. (The FlipThreshold must be set large enough so that there is room for the collector to finish scanning, copying any remaining reachable objects into to-space <ref> [Baker 78] </ref>.) 8 In our experiments, we quickly discovered that the collector and the mutator (via the allocator) were contending for the global lock. This contention would get worse with many mutator threads. <p> Multiple Mutator Threads How many mutator threads can one collector support while remaining real-time and concurrent? In general, this depends on the total amount of memory, since copying collectors are arbitrarily efficient as the ratio of memory size to reachable objects increases <ref> [Baker 78, Appel 87] </ref>. How many threads could our initial implementation support with its 6-megabyte heap? Even though ML limited us to one mutator thread, we can make a rough estimate.
Reference: [Brooks 84] <author> Rodney A. Brooks. </author> <title> Trading data space for reduced time and code space in real-time garbage collection on stock hardware. </title> <booktitle> In SIGPLAN Notices (Proceedings of ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments), </booktitle> <pages> pages 256-262, </pages> <year> 1984. </year>
Reference-contexts: Unfortunately, we still don't have enough experience with scaled-up implementations to make final comparisons. Baker's algorithm [Baker 78] was the first real-time, copying-based collector. But it isn't concurrent, it requires special hardware, and its first implementation on Lisp machines wasn't efficient (users turned it off). Brooks <ref> [Brooks 84] </ref> showed how to implement Baker's algorithm on stock hardware at the cost of an extra word per object and extra instructions to initialize and reference objects. <p> Every fetch and allocation is slowed down by a small, bounded amount of time. Thus Baker's algorithm is more suitable for real-time applications. In the absence of hardware support, Baker's algorithm is not very efficient, since a few extra instructions must be performed on every fetch. Brooks's variant <ref> [Brooks 84] </ref> is intended to be efficient on stock hardware; but it requires an extra word per object, it does an extra memory reference on each fetch, and it requires a few additional instructions to implement the basic operations of comparing pointers, replacing the contents of a cell, and initializing a <p> Clark [Clark 77] found that even in a pointer language like Lisp, references to an address were often followed by references to nearby addresses. This leads to the heuristic: After a page trap, scan the pages adjacent to the trapping page. Brooks <ref> [Brooks 84] </ref> and others have suggested that it is better to scan stacks from the bottom up, the bottom-most objects are more likely to survive the current collection (pointers to objects on the top of the stack will soon get popped), and work won't be wasted.
Reference: [Cardelli 84] <author> Luca Cardelli. </author> <title> Compiling a functional language. </title> <booktitle> In 1984 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 208-217, </pages> <year> 1984. </year>
Reference-contexts: And even on uniprocessors, more and more operating systems are starting to offer multi-threaded capabilities as support is added for distributed computing based on remote procedure call. A First Implementation and Experiment We have implemented the collector in an early version of ML, a statically type-checked polymorphic language <ref> [Cardelli 84] </ref>. While this version of ML is not particularly efficient, it is both simple and tractable.
Reference: [Clark 77] <author> Douglas W. Clark and C. Cordell Green. </author> <title> An empirical study of list structure in Lisp. </title> <journal> Communications of the ACM, </journal> <volume> 20(2) </volume> <pages> 78-87, </pages> <year> 1977. </year>
Reference-contexts: These references are largely to be found in the newest pages added to the to-space 14 as a result of scanning the trapping page. A good heuristic might be: After a page trap, scan the newest pages of to-space first. Clark <ref> [Clark 77] </ref> found that even in a pointer language like Lisp, references to an address were often followed by references to nearby addresses. This leads to the heuristic: After a page trap, scan the pages adjacent to the trapping page.
Reference: [Gabriel 85] <author> Richard Gabriel. </author> <title> Performance and Evaluation of Lisp Systems. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: All three versions used a page size of 1K bytes and a heap with 3 megabytes per space. The sequential version scanned from 1 to 4K bytes for every 1K bytes allocated. The concurrent version used an Allocate chunk size of 65K. We picked the Boyer benchmark from Gabriel <ref> [Gabriel 85] </ref> as our first experiment. It is a small rule rewriter designed to test the performance of Lisp systems executing theorem provers. It allocates a large amount of non-trivial, fine-grained data structures and then accesses those structures repeatedly.
Reference: [Halstead 84] <author> Robert H. Halstead, Jr. </author> <title> Implementation of Multilisp: Lisp on a Multiprocessor. </title> <booktitle> In 1984 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 9-17, </pages> <year> 1984. </year>
Reference-contexts: Later generational collectors of various sorts [Moon 84, Ungar 86, Shaw 87] were much more efficient and provided much better average latency by reducing the load on virtual memory. But none of them are concurrent. Only Moon's is real-time, but it requires special hardware. The Concert Multilisp collector <ref> [Halstead 84] </ref> generalized Baker's algorithm to a shared-memory multiprocessor. The algorithm is concurrent, in the sense that multiple threads can be executing at the same time, but as with Baker's algorithm, the execution of each thread is interleaved incrementally with calls to the collector. <p> Thus a single collector might very well support at least 10 continuously executing threads. Multiple Collector Threads and Shared Virtual Memory What if there are a very large number of threads and processors? Using multiple heaps like those of the Multilisp collector <ref> [Halstead 84] </ref>, our general techniques should allow for multiple scanning and trap threads. (The "multiple heaps" can be viewed as partitions of a single heap.) Each heap would have its own trap and scanning threads. A lock bit per from-space page ensures that an object is copied at most once.
Reference: [Hickey 84] <author> Tim Hickey and Jacques Cohen. </author> <title> Performance analysis of on-the-fly garbage collection. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1143-1154, </pages> <year> 1984. </year>
Reference-contexts: But compared to copying collectors, it isn't particularly efficient, and it cannot reclaim circular structures. No one has yet built a practical concurrent mark-and-sweep collector, and it may be difficult to make them efficient <ref> [Hickey 84] </ref>. Asymptotically, copying-based collectors have the potential to be much more efficient than reference-counting or mark-and-sweep collectors [Baker 78, Appel 87].
Reference: [Li 86] <author> Kai Li. </author> <title> Shared Virtual Memory on Loosely Coupled Multiprocessors. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1986. </year> <month> 23 </month>
Reference-contexts: A lock bit per from-space page ensures that an object is copied at most once. Only at a flip must all the threads synchronize. Kai Li <ref> [Li 86] </ref> introduced the notion of shared virtual memory, providing a single, shared virtual-memory address space for many processors having distinct physical memories. Pages are exchanged between processors using a high-bandwidth bus or local network, with only one processor at a time allowed write access to a page.
Reference: [Lieberman 83] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 23(6) </volume> <pages> 419-429, </pages> <year> 1983. </year>
Reference-contexts: Generational Collection Generational collection can drastically reduce the work of a copying collector by scanning and copying far fewer objects <ref> [Lieberman 83, Moon 84, Ungar 86] </ref>. Many fewer pages are touched by the collector, resulting in better virtual-memory performance [Shaw 87]. Generational collection is based on two observations: new objects have a higher death rate than old objects, and few old objects reference new objects.
Reference: [Moon 84] <author> David A. Moon. </author> <title> Garbage collection in a large LISP system. </title> <booktitle> In ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 235-246, </pages> <year> 1984. </year>
Reference-contexts: Brooks [Brooks 84] showed how to implement Baker's algorithm on stock hardware at the cost of an extra word per object and extra instructions to initialize and reference objects. Later generational collectors of various sorts <ref> [Moon 84, Ungar 86, Shaw 87] </ref> were much more efficient and provided much better average latency by reducing the load on virtual memory. But none of them are concurrent. Only Moon's is real-time, but it requires special hardware. <p> Generational Collection Generational collection can drastically reduce the work of a copying collector by scanning and copying far fewer objects <ref> [Lieberman 83, Moon 84, Ungar 86] </ref>. Many fewer pages are touched by the collector, resulting in better virtual-memory performance [Shaw 87]. Generational collection is based on two observations: new objects have a higher death rate than old objects, and few old objects reference new objects.
Reference: [North 87] <author> S. C. North and J. H. Reppy. </author> <title> Concurrent garbage collection on stock hardware. </title> <editor> In Gilles Kahn, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture (LNCS 274), </booktitle> <pages> pages 113-133. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: The algorithm is concurrent, in the sense that multiple threads can be executing at the same time, but as with Baker's algorithm, the execution of each thread is interleaved incrementally with calls to the collector. The collector requires special hardware support for acceptable efficiency. The Pegasus collector <ref> [North 87] </ref> starts with Brooks's basic technique to make a concurrent collector that runs on stock uniprocessors. But it relies on basic assumptions that would prevent it from running on a multiprocessor. Like Brooks's algorithm, objects require an extra word and an extra indirection on every reference.
Reference: [Rovner 85a] <author> Paul Rovner. </author> <title> On Adding Garbage Collection and Runtime Types to a Strongly-Typed, Statically-Checked, Concurrent Language. </title> <note> Xerox PARC Report CSL-84-7, </note> <year> 1985. </year>
Reference-contexts: Further, our algorithm will work with any compiler already geared for a copying collector. Previous Work In recent years, researchers have built collectors that are far less obtrusive to programs than the original "stop-the-world" collectors. Reference-counting collectors first demonstrated that collection could be unobtrusive even to systems programs <ref> [Rovner 85a] </ref>. The current Modula-2+ collector [Rovner 85b] is real-time, concurrent, and runs on the Firefly, a shared-memory multiprocessor built from 5 MicroVAX II CPUs (1 MIP each) [Thacker 87]. But compared to copying collectors, it isn't particularly efficient, and it cannot reclaim circular structures.
Reference: [Rovner 85b] <author> Paul Rovner, Roy Levin, and John Wick. </author> <title> On Extending Modula-2 For Building Large, Integrated Systems. </title> <type> Research Report 3, </type> <institution> DEC Systems Research Center, </institution> <year> 1985. </year>
Reference-contexts: Previous Work In recent years, researchers have built collectors that are far less obtrusive to programs than the original "stop-the-world" collectors. Reference-counting collectors first demonstrated that collection could be unobtrusive even to systems programs [Rovner 85a]. The current Modula-2+ collector <ref> [Rovner 85b] </ref> is real-time, concurrent, and runs on the Firefly, a shared-memory multiprocessor built from 5 MicroVAX II CPUs (1 MIP each) [Thacker 87]. But compared to copying collectors, it isn't particularly efficient, and it cannot reclaim circular structures. <p> A Comparison with Reference Counting Out of curiosity, we implemented the same Boyer benchmark in a small, compiled Lisp that uses the Modula-2+ allocator and concurrent reference-counting collector <ref> [Rovner 85b] </ref>. The Lisp version allocated 1.8 megabytes compared to the 12.2 megabytes allocated by the ML version; unlike the ML implementation, the Lisp doesn't allocate things like argument records in the heap.
Reference: [Shaw 87] <author> Robert A. Shaw. </author> <title> Improving Garbage Collector Performance in Virtual Memory. </title> <type> Technical Report CSL-TR-87-323, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <year> 1987. </year>
Reference-contexts: Brooks [Brooks 84] showed how to implement Baker's algorithm on stock hardware at the cost of an extra word per object and extra instructions to initialize and reference objects. Later generational collectors of various sorts <ref> [Moon 84, Ungar 86, Shaw 87] </ref> were much more efficient and provided much better average latency by reducing the load on virtual memory. But none of them are concurrent. Only Moon's is real-time, but it requires special hardware. <p> Generational Collection Generational collection can drastically reduce the work of a copying collector by scanning and copying far fewer objects [Lieberman 83, Moon 84, Ungar 86]. Many fewer pages are touched by the collector, resulting in better virtual-memory performance <ref> [Shaw 87] </ref>. Generational collection is based on two observations: new objects have a higher death rate than old objects, and few old objects reference new objects. <p> During most collections, only the new area and the remembered pointers must be scanned, copying only the new-area objects that are still live. As objects survive collections, they are "aged" and copied outside of the new area; the entire heap is collected very infrequently. Ungar [Ungar 86] and Shaw <ref> [Shaw 87] </ref> show how to implement generational collectors on stock hardware while reducing the demand on virtual memory.
Reference: [Thacker 87] <author> Charles P. Thacker and Lawrence C. Stewart. Firefly: </author> <title> A Multiprocessor Workstation. </title> <booktitle> In Proceedings of the Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 164-172. </pages> <publisher> ACM, </publisher> <year> 1987. </year>
Reference-contexts: Shared-memory multiprocessors are becoming widespread, so it's important to find efficient concurrent collection algorithms. With today's technology, the marginal cost of adding extra processors and caches to a machine is small. Most new large mainframes are multiprocessors, and the System Research Center's Firefly <ref> [Thacker 87] </ref> has shown that it is economical to build multiprocessor workstations. Fine-grained synchronization between the collector and the mutator is a problem for concurrent collectors. <p> Reference-counting collectors first demonstrated that collection could be unobtrusive even to systems programs [Rovner 85a]. The current Modula-2+ collector [Rovner 85b] is real-time, concurrent, and runs on the Firefly, a shared-memory multiprocessor built from 5 MicroVAX II CPUs (1 MIP each) <ref> [Thacker 87] </ref>. But compared to copying collectors, it isn't particularly efficient, and it cannot reclaim circular structures. No one has yet built a practical concurrent mark-and-sweep collector, and it may be difficult to make them efficient [Hickey 84]. <p> A First Implementation and Experiment We have implemented the collector in an early version of ML, a statically type-checked polymorphic language [Cardelli 84]. While this version of ML is not particularly efficient, it is both simple and tractable. The implementation runs on the Firefly using SRC's Taos operating system <ref> [Thacker 87] </ref>, which extends DEC Ul 16 Stop-and-Copy Sequential Concurrent Total elapsed time 252 sec 281 (1.11) 207 ( .82) Mutator time 180 180 180 Mutator overhead 29% 36% 13% Total CPU time 247 257 (1.04) 266 (1.08) Collector time 67 77 (1.15) 86 (1.28) Table 1: Execution times trix (Berkeley
Reference: [Ungar 86] <author> David Ungar. </author> <title> The Design and Evaluation of a High Performance Smalltalk System. </title> <publisher> MIT Press, </publisher> <year> 1987. </year> <month> 24 </month>
Reference-contexts: Brooks [Brooks 84] showed how to implement Baker's algorithm on stock hardware at the cost of an extra word per object and extra instructions to initialize and reference objects. Later generational collectors of various sorts <ref> [Moon 84, Ungar 86, Shaw 87] </ref> were much more efficient and provided much better average latency by reducing the load on virtual memory. But none of them are concurrent. Only Moon's is real-time, but it requires special hardware. <p> Generational Collection Generational collection can drastically reduce the work of a copying collector by scanning and copying far fewer objects <ref> [Lieberman 83, Moon 84, Ungar 86] </ref>. Many fewer pages are touched by the collector, resulting in better virtual-memory performance [Shaw 87]. Generational collection is based on two observations: new objects have a higher death rate than old objects, and few old objects reference new objects. <p> During most collections, only the new area and the remembered pointers must be scanned, copying only the new-area objects that are still live. As objects survive collections, they are "aged" and copied outside of the new area; the entire heap is collected very infrequently. Ungar <ref> [Ungar 86] </ref> and Shaw [Shaw 87] show how to implement generational collectors on stock hardware while reducing the demand on virtual memory.
References-found: 17

