URL: http://www.cs.columbia.edu/~klavans/articles/psfiles/icslip94.ps
Refering-URL: http://www.cs.columbia.edu/~klavans/articles.html
Root-URL: http://www.cs.columbia.edu
Email: klavans@cs.columbia.edu  klavans@research.att.com evelyne@research.att.com  
Title: Inducing Concatenative Units from Machine Readable Dictionaries and Corpora for Speech Synthesis  
Author: Evelyne Tzoukermann* and Judith L. Klavansy* and 
Address: New York, New York 10027  600 Mountain Avenue, Murray Hill, N.J. 07974  
Affiliation: yColumbia University, Department of Computer Science  *A.T.&T. Bell Laboratories  
Abstract: The purpose of this research is to determine the best method for deciding on an optimal set of concatenative units for concatenative speech synthesis. Of the two main approaches to speech synthesis: segmental synthesis and rule-based synthesis, the former relies heavily on the successful choice of concatenative units. Segmental synthesis consists of concatenating segmental units (diphones, tri-phones, etc); rule-based synthesis consists of the computation of control parameters based on pre-established rules. Deciding on the set of diphones is quite straightforward in the sense that it suffices to take the phoneme inventory of a language, and simply combine each phoneme with every other one. For example, taking the approximately 35 French phonemes, 1225 phonemic pairs (35x35) constitute the complete and exhaustive starting diphone inventory. On the other hand, deciding on the set of triphones, quadriphones and larger units raises difficult questions about the nature of phonemes in a given language such as: (1) stability vs instability in a coarticulatory environment, (2) size of overall inventory, and (3) frequency of that unit in the language, in combination with factors (1) and (2). We report on experiments with four different databases, with comparisons between the resources regarding their n-gram frequency output. The first two databases consist of pronunciation field information from two dictionaries, the Encyclopedic Robert French dictionary [16] with 85,000 headwords, and the smaller Collins Gem [13] containing 15,000 words. For comparison, we use two text corpora, the Hansard (about 2.5 million words) and the smaller Tubach and Boe [31] corpus (80,000 words); both corpora were processed by a set of grapheme-to-phoneme rules [18]. A frequency extraction program was applied to all four resources to extract trigram phonemic frequencies; this serves as a basis for comparison between dictionary derived data and corpus derived frequencies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Benjamin Ao, Chilin Shih, and Richard Sproat. </author> <title> A corpus-based mandarin text-to-speech synthesizer. </title> <address> Yokohama, Japan, </address> <year> 1994. </year> <booktitle> Proceedings of the 2nd International Conference on Spoken Language Processing. </booktitle>
Reference-contexts: Typically, TTS systems are rule-based, the most common set of steps being: morphological analysis of word forms by rule, word level pronunciation by grapheme-to-phoneme rules, interword level phenomena by rule, and intonational contouring, also by rule. Corpus data has just started being used for developing TTS systems <ref> [1] </ref> and we report on one of these usages. Although the majority of speech recognition systems rely on probabilistic methods over large text corpora, such techniques have been slow to find their ways into TTS systems.
Reference: [2] <author> Beryl T. Atkins, Judith Kegl, and Beth Levin. </author> <title> Anatomy of a verb entry: from linguistics theory to lexicographic practice. </title> <journal> International Journal of Lexicography, </journal> <volume> 1 </volume> <pages> 84-126, </pages> <year> 1988. </year>
Reference-contexts: The Use of Machine-Readable Dictionaries MRDs, no matter how small and no matter how internally inconsistent, have proven to be an invaluable resource for a wide variety of applications <ref> [2] </ref>. Machine readable dictionaries first became available on a limited basis in the 60's. Merriam Webster's Seventh (W7) [25] was manually input and was informally passed around on magnetic tape and in long print-outs from site to site. Other dictionaries (e.g.
Reference: [3] <institution> Veronique Auberge. La synthese de la parole: `des regles aux lexique'. </institution> <type> PhD thesis, </type> <institution> Universite de Grenoble, Grenoble, France, </institution> <year> 1991. </year>
Reference-contexts: Although the statistical analysis of MRDs has focussed primarily on definitions and translations, [19] has used the pronunciation field as data. Strategies for finding a methodology for building polyphonic units differ greatly. Some researchers, such as <ref> [3] </ref> based their set on perceptually validated tests; the perceptually salient categories were determined and the final set was selected using response frequencies grouped by categories. Others, such as [4], first group the different phonemes by classes, separating them according to their acoustic stability or unstability.
Reference: [4] <author> Frederic Bimbot. </author> <title> Synthese de la Parole: Des Segments aux regles, avec utilisation de la decomposition temporelle. </title> <type> PhD thesis, </type> <institution> Telecom Paris 88 E019, Paris, France, </institution> <year> 1988. </year>
Reference-contexts: Strategies for finding a methodology for building polyphonic units differ greatly. Some researchers, such as [3] based their set on perceptually validated tests; the perceptually salient categories were determined and the final set was selected using response frequencies grouped by categories. Others, such as <ref> [4] </ref>, first group the different phonemes by classes, separating them according to their acoustic stability or unstability. Each phoneme is combined with another and then the unstable ones are surrounded by stable phonemes. <p> Our next steps include determining methods for evaluating choices between competing selected sets. In addition we intend to consider linguistic phenomena such as transitions between unstable phonemes (such as liquids and glides). We believe that approaches, such as <ref> [4] </ref> that use linguistic knowledge and select the output using statistics on corpora, can help optimization. However, we also believe that building an optimal set of units is an iterative process that is a function of the synthesized voice itself as well as the synthesis technique (e.g.
Reference: [5] <author> Bran Boguraev and Ted Briscoe. </author> <title> Introduction, </title> <booktitle> chapter Chapter I, </booktitle> <pages> pages 1-40. </pages> <publisher> Longman, </publisher> <address> Burnt Hill, Harlow, </address> <publisher> Essex, </publisher> <year> 1989. </year>
Reference-contexts: Carter <ref> [5] </ref> discusses the use of LDOCE pronunciation field information for speech recognition. The next section of the paper focuses on the structure of electronic dictionaries for TTS in particular.
Reference: [6] <author> P. Brown, S. Della Pietra, V. Della Pietra, M. Goldsmith, J. Hajic, R. Mercer, and S. Mohanty. </author> <title> But dictionaries are data too. </title> <booktitle> In Proceedings of DARPA, </booktitle> <address> Princeton, New Jersey, </address> <year> 1993. </year> <booktitle> Workshop on Speech and Natural Language. </booktitle>
Reference-contexts: Related Research Dictionary definitions have been used as the input to statistical methods for word sense disambiguation by [32], among others. Definitions have also been used as input to probabilistic systems <ref> [6] </ref>, and as a source of relational data [23] for building lexical knowledge bases. The question of the relationship between dictionary data and the larger language is raised by [22] in building bilingual lexicons, again focussing on definition and translation fields.
Reference: [7] <author> David Carter. </author> <title> LDOCE and Speech Recognition, </title> <booktitle> chapter Chapter 6, </booktitle> <pages> pages 135-152. </pages> <publisher> Longman, </publisher> <address> Burnt Hill, Harlow, </address> <publisher> Essex, </publisher> <year> 1989. </year>
Reference-contexts: The entry for "denticulate" has a morphologically related run-on form "denticulated" in the early part of the entry, and the pronunciation of that run-on is related to the main entry, but the user must figure out how to chop and append the given syllables. <ref> [7] </ref> reports on the need to resyllabify entries already syllabified in LDOCE, since syllable boundaries for written forms usually reflect hyphenation conventions, rather than phonologically motivated syllabification conventions necessary for pronunciation.
Reference: [8] <author> Kenneth Church. </author> <title> Stress assignment in letter to sound rules for speech synthesis. </title> <booktitle> In ACL Proceedings, 23rd Annual Meeting, </booktitle> <pages> pages 246-253, </pages> <address> Morristown, NJ, </address> <year> 1985. </year> <institution> Association for Computational Linguistics. </institution>
Reference-contexts: If the spelling was none of the above, it was pronounced by the spelling-to-phoneme routines [10], [21]. Pre-processing took care of acronyms and abbreviations, and some post-processing was done (e.g., to flap t's and d's where appropriate and where not indicated in W7). <ref> [8] </ref> reports on the successful use of W7 for a stress assignment guessing algorithm, as part of the TTS system at AT&T Bell Laboratories. Carter [5] discusses the use of LDOCE pronunciation field information for speech recognition.
Reference: [9] <editor> Collins Cobuild English Language Dictionary. </editor> <publisher> Collins Publishers, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: J. Wat-son research Center in the late 60's [15] later added syntactic and morphological information from W7. The later system, described 1 Mention must be made of the CoBuild Dictionary <ref> [9] </ref> which promises to be the most useful so far, but due to its expense, has turned out to be of limited use at this time, except by large very well-funded industrial laboratories (e.g.
Reference: [10] <author> Paul Cohen. </author> <title> Spelling to sound conversion for text to speech. </title> <year> 1982. </year>
Reference-contexts: If a form could not be found, first a check was made to see if it was a punctuation mark, number, etc.; these were handled by special routines. If the spelling was none of the above, it was pronounced by the spelling-to-phoneme routines <ref> [10] </ref>, [21].
Reference: [11] <author> Cecil Coker. </author> <title> A dictionary-intensive letter-to-sound program. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> Supplement 1, 78:S7, </volume> <year> 1985. </year>
Reference-contexts: In the end, a collection of over 7700 polyphones is collected and statistics are run through a corpus to select the top 3000 units. In [19], a dictionary of over 110,000 entries containing 51,219 common words and 59,625 proper nouns is used for selecting candidate units [27], <ref> [11] </ref>, [28]. The phonemic string is split according to ten language-dependent segmentation principles. For example, the word "abacus" [qab--ks] is first transformed into cuttable units as follows: [#qa,qab,b,k,k,s,s#]. Once each dictionary word is split, the duplicates are removed and the remaining units form the set of concatenative units.
Reference: [12] <editor> Collins Spanish Dictionary: Spanish-English. </editor> <publisher> Collins Publishers, </publisher> <address> Glasgow, </address> <year> 1989. </year>
Reference-contexts: However, if pronunciation varies during inflection of nouns and adjectives, the pronunciation field reflects that variation which makes the information difficult to extract automatically. For example, in (3) and (4), one needs to know the 2 Notice, however, that the full Collins Spanish-English dictionary <ref> [12] </ref>, as opposed to the other bilinguals, does not contain any pronunciation information.
Reference: [13] <author> P-H Cousin. </author> <title> Collins Gem French Dictionary: </title> <publisher> French-English. English-French. Harper Collins Publishers, </publisher> <address> London, </address> <year> 1991. </year>
Reference-contexts: Although this is rather surprising taking into account that the smaller versions such as the paperback and gem ([14], <ref> [13] </ref>, [24]) do have a phonetic field, it could be attributed to the fact that pronunciation rules in Spanish are relatively predictable. nature of the rule to apply in order to get the feminine form of the adjective. (3) blanc, blanche /bl~a, bl~aS/ adj. et n. (4) vif, vive /vif, viv/
Reference: [14] <author> P-H. Cousin, L. Sinclair, J-F. Allain, and C. E. Love. </author> <title> The Collins Paperback French Dictionary: </title> <publisher> French-English. English-French. Collins Publishers, </publisher> <address> London, </address> <year> 1989. </year>
Reference: [15] <author> N.R. Dixon and H. D. Maxey. </author> <title> Terminal analog synthesis of continuous speech using the diphone method of segment assembly. </title> <journal> In IEEE Transactions on Audio and Electroacoustics AU16, </journal> <pages> pages 40-50, </pages> <year> 1968. </year>
Reference-contexts: To date, TTS research has primarily used Webster's Seventh (for English), Collins' bilinguals, and other non-English monolin-guals, since these are available in electronic format. 1 The diphone based text to speech system first developed at the IBM T. J. Wat-son research Center in the late 60's <ref> [15] </ref> later added syntactic and morphological information from W7.
Reference: [16] <editor> Alain Duval et al. Robert Encyclopedic Dictionary (CDROM). Hachette, </editor> <address> Paris, </address> <year> 1992. </year>
Reference-contexts: Nevertheless, parsing dictionaries in general can be a very complex operation [26] and even the extraction of one field, such as the pronunciation, can pose problems. Similar to W7, in the Robert French dictionary <ref> [16] </ref>, which contains about 89,000 entries, several pronunciations can be given for a headword and the choice of one must be made.
Reference: [17] <author> Tzoukermann Evelyne. </author> <title> Issues in text-to-speech for french. </title> <booktitle> In Proceedings of Coling94, Kyoto, Japan, 1994. International Conference on Computational Linguistics. </booktitle>
Reference-contexts: Our purpose is two-fold: one practical and one theoretical. On the practical side, a speech synthesis system for French is being built at AT&T Bell Laboratories <ref> [17] </ref>, and the output of this research will help to determine and optimize set of most frequent concatenative units for putting into the working system. On the theoretical side, our goal is to explore the question of what constitutes adequate data for inducing this optimal set of concatenative units. <p> In (3), the feminine /bl~aS/ (blanche,"white") is obtained by adding the phoneme /S/ to the masculine /bl~a/. In (4), the form /viv/ (vive,"sharp, quick") is formed by stripping the affix /f/ and adding the morpheme /v/. For the French TTS system <ref> [17] </ref>, the set of diphones was established by taking most of the phonemes for French (35) and coupling them with another (35 2 = 1225 pairs). Then, the diphones were extracted from the pronunciation field of the headword of the Robert dictionary.
Reference: [18] <editor> Marty F. Trois systemes informatiques de transcription phonetique et graphemique. Le Fran cais Moderne, LX, </editor> <volume> 2 </volume> <pages> 179-197, </pages> <year> 1992. </year>
Reference: [19] <author> Coleman John. </author> <title> Computation of candidate synthesis units. </title> <booktitle> In 11222-930719-07TM, </booktitle> <address> Murray Hill, N.J., USA, </address> <year> 1993. </year> <type> Technical Memorandum, </type> <institution> AT& Bell Laboratories. </institution>
Reference-contexts: The question of the relationship between dictionary data and the larger language is raised by [22] in building bilingual lexicons, again focussing on definition and translation fields. Although the statistical analysis of MRDs has focussed primarily on definitions and translations, <ref> [19] </ref> has used the pronunciation field as data. Strategies for finding a methodology for building polyphonic units differ greatly. Some researchers, such as [3] based their set on perceptually validated tests; the perceptually salient categories were determined and the final set was selected using response frequencies grouped by categories. <p> Each phoneme is combined with another and then the unstable ones are surrounded by stable phonemes. In the end, a collection of over 7700 polyphones is collected and statistics are run through a corpus to select the top 3000 units. In <ref> [19] </ref>, a dictionary of over 110,000 entries containing 51,219 common words and 59,625 proper nouns is used for selecting candidate units [27], [11], [28]. The phonemic string is split according to ten language-dependent segmentation principles. For example, the word "abacus" [qab--ks] is first transformed into cuttable units as follows: [#qa,qab,b,k,k,s,s#].
Reference: [20] <author> Coleman John and Pilar Prieto. </author> <title> Accurate pronunciation rules for american spanish text-to-speech. </title> <booktitle> In 11222-930719-06TM, </booktitle> <address> Murray Hill, N.J., USA, </address> <year> 1993. </year> <type> Technical Memorandum, </type> <institution> AT& Bell Laboratories. </institution>
Reference-contexts: Other techniques allow the selection of a minimal set of word pairs for inter-word junctures; every candidate unit inside and across words is included. The same strategy was replicated on the Collins Spanish-English dictionary by <ref> [20] </ref>. In this fashion, the dictionary is used as a sample of the language in the sense that it assumes that most of the phonemic combinations in the language are present.
Reference: [21] <author> Judith Klavans and Sara Basson. </author> <title> Documentation of letter to sound components of the walrus text to speech system. </title> <address> Yorktown Heights, New York, </address> <year> 1984. </year> <type> Unpublished manuscript, </type> <institution> IBM, T. J. Watson Research Center. </institution>
Reference-contexts: If a form could not be found, first a check was made to see if it was a punctuation mark, number, etc.; these were handled by special routines. If the spelling was none of the above, it was pronounced by the spelling-to-phoneme routines [10], <ref> [21] </ref>.
Reference: [22] <author> Judith Klavans and Evelyne Tzoukermann. </author> <title> The bicord system: Combining lexical information from bilingual corpora and machine readable dictionaries. </title> <publisher> Helsinki, </publisher> <address> Finland, </address> <year> 1990. </year> <booktitle> Proceedings of the 13th International Conference on Computational Linguistics. </booktitle>
Reference-contexts: Definitions have also been used as input to probabilistic systems [6], and as a source of relational data [23] for building lexical knowledge bases. The question of the relationship between dictionary data and the larger language is raised by <ref> [22] </ref> in building bilingual lexicons, again focussing on definition and translation fields. Although the statistical analysis of MRDs has focussed primarily on definitions and translations, [19] has used the pronunciation field as data. Strategies for finding a methodology for building polyphonic units differ greatly.
Reference: [23] <author> Judith L. Klavans, Martin S. Chodorow, and Nina Wacholder. </author> <title> From dictionary to knowledge base via taxonomy. Centre for the New Oxford English Dictionary and Text Research: Electronic Text Research, </title> <institution> University of Waterloo, Canada, </institution> <year> 1990. </year> <booktitle> Proceedings of the Sixth Conference of the University of Waterloo. </booktitle>
Reference-contexts: Related Research Dictionary definitions have been used as the input to statistical methods for word sense disambiguation by [32], among others. Definitions have also been used as input to probabilistic systems [6], and as a source of relational data <ref> [23] </ref> for building lexical knowledge bases. The question of the relationship between dictionary data and the larger language is raised by [22] in building bilingual lexicons, again focussing on definition and translation fields.
Reference: [24] <author> Gonzales M. </author> <title> Collins Gem Spanish Dictionary: </title> <publisher> French-English. English-French. Harper Collins Publishers, </publisher> <address> London, </address> <year> 1990. </year>
Reference-contexts: Although this is rather surprising taking into account that the smaller versions such as the paperback and gem ([14], [13], <ref> [24] </ref>) do have a phonetic field, it could be attributed to the fact that pronunciation rules in Spanish are relatively predictable. nature of the rule to apply in order to get the feminine form of the adjective. (3) blanc, blanche /bl~a, bl~aS/ adj. et n. (4) vif, vive /vif, viv/ adj.
Reference: [25] <author> Merriam. </author> <title> Webster's Seventh New Collegiate Dictionary. </title> <editor> G.& C. Merriam, Springfield, </editor> <address> Mass., </address> <year> 1963. </year>
Reference-contexts: The Use of Machine-Readable Dictionaries MRDs, no matter how small and no matter how internally inconsistent, have proven to be an invaluable resource for a wide variety of applications [2]. Machine readable dictionaries first became available on a limited basis in the 60's. Merriam Webster's Seventh (W7) <ref> [25] </ref> was manually input and was informally passed around on magnetic tape and in long print-outs from site to site. Other dictionaries (e.g. LDOCE, Collins Bilinguals, Robert monolingual, and so on) continue to become available for use.
Reference: [26] <author> M. Neff and B. Boguraev. </author> <title> Dictionaries, dictionary grammars and dictionary entry parsing. </title> <booktitle> In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Vancouver, Canada, </address> <year> 1989. </year> <institution> Association for Computational Linguistics. </institution>
Reference-contexts: The pronunciation field: Extracting the pronunciation field from the MRD is one of the most obvious uses of the dictionary. Nevertheless, parsing dictionaries in general can be a very complex operation <ref> [26] </ref> and even the extraction of one field, such as the pronunciation, can pose problems. Similar to W7, in the Robert French dictionary [16], which contains about 89,000 entries, several pronunciations can be given for a headword and the choice of one must be made.
Reference: [27] <author> Olive J. P. </author> <title> A new algorithm for a concatenative speech synthesis system using an augmented acoustic inventory of speech sounds. </title> <editor> In Gerard Bailly and Christian Benoit, editors, </editor> <booktitle> Proceedings of the ESCA Workshop on Speech Synthesis, </booktitle> <year> 1990. </year>
Reference-contexts: In the end, a collection of over 7700 polyphones is collected and statistics are run through a corpus to select the top 3000 units. In [19], a dictionary of over 110,000 entries containing 51,219 common words and 59,625 proper nouns is used for selecting candidate units <ref> [27] </ref>, [11], [28]. The phonemic string is split according to ten language-dependent segmentation principles. For example, the word "abacus" [qab--ks] is first transformed into cuttable units as follows: [#qa,qab,b,k,k,s,s#]. Once each dictionary word is split, the duplicates are removed and the remaining units form the set of concatenative units.
Reference: [28] <author> Olive J. P. and M. Y. Liberman. </author> <title> A set of concatenative units for speech synthesis. </title> <editor> In J. J. Wolf and D. H. Klatt, editors, </editor> <booktitle> Speech Communication Papers Presented at the 97th Meeting of the Acoustical Society of America, </booktitle> <pages> pages 515-518, </pages> <address> New York: </address> <institution> American Institute of Physics, </institution> <year> 1979. </year>
Reference-contexts: In the end, a collection of over 7700 polyphones is collected and statistics are run through a corpus to select the top 3000 units. In [19], a dictionary of over 110,000 entries containing 51,219 common words and 59,625 proper nouns is used for selecting candidate units [27], [11], <ref> [28] </ref>. The phonemic string is split according to ten language-dependent segmentation principles. For example, the word "abacus" [qab--ks] is first transformed into cuttable units as follows: [#qa,qab,b,k,k,s,s#]. Once each dictionary word is split, the duplicates are removed and the remaining units form the set of concatenative units.
Reference: [29] <author> Richard W. Sproat. Newtts: </author> <title> A user's manual. </title> <booktitle> In 11222-921102-09TM, </booktitle> <address> Murray Hill, N.J., USA, </address> <year> 1992. </year> <type> Technical Memorandum, </type> <institution> AT& Bell Laboratories. </institution>
Reference-contexts: Furthermore, there is no morphological productivity to create the effects of flocking or to create new units <ref> [29] </ref>. Thus, it was our hypothesis that a dictionary could provide essential concatenative unit data without recourse to larger corpora. Our results showed that for interword phenomena, the hypothesis was correct, whereas for intraword effects, such as liaison and assimilation, the dictionary field information falls short.
Reference: [30] <author> John Thomas, Judith Klavans, Jonas Nartey, Cliff Pickover, David Reich, and Mary Beth Rosson. "walrus: </author> <title> High-quality text-to-speech research system. </title> <booktitle> pages 19-28. Proceedings of the IEEE on Speech Synthesis and Recognition, </booktitle> <year> 1984. </year>
Reference-contexts: Microsoft, AT&T Bell Laboratories). in <ref> [30] </ref> was sentence-based; each sentence was run through a syn-tactic parser for part of speech assignment. Pronunciations were retrieved from a list of spellings and pronunciations derived and cleaned from W7.
Reference: [31] <author> J-P Tubach and Boe L J. </author> <title> Un corpus de transcription phonetique (300,000 phones) constitution et exploitation statistique. </title> <institution> Ecole Nationale Superieure des Telecommunications, </institution> <year> 1990. </year> <note> Telecom Paris 90 D 002. </note>
Reference: [32] <author> Yorick Wilks, Dan Fass, Cheg-Ming Guo, James McDonald, Tony Plate, and Brian Slator. </author> <title> A tractable machine dictionary as a resource for computational semantics, </title> <booktitle> chapter Chapter 9, </booktitle> <pages> pages 193-228. </pages> <publisher> Longman, </publisher> <address> Burnt Hill, Harlow, </address> <publisher> Essex, </publisher> <year> 1989. </year>
Reference-contexts: The remaining 4% consist primarily of prefixes and suffixes which are listed in the dictionary without pronunciations and which would not be useful in isolation in any case. Related Research Dictionary definitions have been used as the input to statistical methods for word sense disambiguation by <ref> [32] </ref>, among others. Definitions have also been used as input to probabilistic systems [6], and as a source of relational data [23] for building lexical knowledge bases.
References-found: 32

