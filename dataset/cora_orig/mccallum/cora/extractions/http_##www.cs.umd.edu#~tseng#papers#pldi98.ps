URL: http://www.cs.umd.edu/~tseng/papers/pldi98.ps
Refering-URL: http://www.cs.umd.edu/projects/cosmic/papers.html
Root-URL: 
Email: frivera,tsengg@cs.umd.edu  
Title: Data Transformations for Eliminating Conflict Misses  
Author: Gabriel Rivera, Chau-Wen Tseng 
Address: College Park, MD 20742  
Affiliation: Department of Computer Science University of Maryland  
Abstract: Many cache misses in scientific programs are due to conflicts caused by limited set associativity. We examine two compile-time data-layout transformations for eliminating conflict misses, concentrating on misses occuring on every loop iteration. Inter-variable padding adjusts variable base addresses, while intra-variable padding modifies array dimension sizes. Two levels of precision are evaluated. PadLite only uses array and column dimension sizes, relying on assumptions about common array reference patterns. Pad analyzes programs, detecting conflict misses by linearizing array references and calculating conflict distances between uniformly-generated references. The Euclidean algorithm for computing the gcd of two numbers is used to predict conflicts between different array columns for linear algebra codes. Experiments on a range of programs indicate PadLite can eliminate conflicts for benchmarks, but Pad is more effective over a range of cache and problem sizes. Padding reduces cache miss rates by 16% on average for a 16K direct-mapped cache. Execution times are reduced by 6% on average, with some SPEC95 programs improving up to 15%. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson, S. Amarasinghe, and M. Lam. </author> <title> Data and computation transformation for multiprocessors. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Jeremiassen and Eggers automatically eliminate false sharing in explicitly parallel programs by changing the placement of variables [12]. Amarasinghe et al. demonstrate the utility of data layout transformations for eliminating conflict misses in parallel applications <ref> [1] </ref>. They find it to be significant in eliminating adverse cache effects, though specialized optimizations are necessary to reduce computation overhead for modified array subscripts. Cierniak and Li examine combining array transpose and loop transformations to improve locality for parallel programs [6].
Reference: [2] <author> B. Bershad, D. Lee, T. Romer, and B. Chen. </author> <title> Avoiding conflict misses dynamically in large direct-mapped caches. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses [18]. Researchers have examined methods to eliminate conflict misses using hardware [11, 13] or 10 operating systems support <ref> [2, 4] </ref>. These techniques are general and apply to a wide range of programs. However, for many scientific Fortran codes we can achieve similar or better performance using inexpensive data layout transformations.
Reference: [3] <author> W. Bolosky, R. Fitzgerald, and M. Scott. </author> <title> Simple but effective techniques for NUMA memory management. </title> <booktitle> In Proceedings of the Twelfth Symposium on Operating Systems Principles, </booktitle> <address> Litchfield Park, AZ, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: We believe compiler transformations can be very effective in eliminating conflict misses for scientific programs with regular access patterns. We evaluate two compiler transformations to eliminate conflict misses: inter- and intra-variable padding <ref> [3, 21] </ref>. Unlike standard compiler transfor This research was supported in part by NSF grant #CCR9711514 and NSF CAREER Award #ASC9625531 in New Technologies.
Reference: [4] <author> E. Bugnion, J. Anderson, T. Mowry, M. Rosenblum, and M. Lam. </author> <title> Compiler-directed page coloring for multiprocessors. </title> <booktitle> In Proceedings of the Eighth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VIII), </booktitle> <address> Boston, MA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses [18]. Researchers have examined methods to eliminate conflict misses using hardware [11, 13] or 10 operating systems support <ref> [2, 4] </ref>. These techniques are general and apply to a wide range of programs. However, for many scientific Fortran codes we can achieve similar or better performance using inexpensive data layout transformations.
Reference: [5] <author> D. Calahan. </author> <title> Performance evaluation of static and dynamic memory systems on the Cray-2. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: These techniques are general and apply to a wide range of programs. However, for many scientific Fortran codes we can achieve similar or better performance using inexpensive data layout transformations. Many researchers have investigated the related problem of avoiding memory bank conflicts in vector systems <ref> [5] </ref>, but do not discuss compiler techniques. A number of researchers have examined data layout transformations, usually in the context of parallel programs. Jeremiassen and Eggers automatically eliminate false sharing in explicitly parallel programs by changing the placement of variables [12].
Reference: [6] <author> M. Cierniak and W. Li. </author> <title> Unifying data and control transformations for distributed shared-memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: They find it to be significant in eliminating adverse cache effects, though specialized optimizations are necessary to reduce computation overhead for modified array subscripts. Cierniak and Li examine combining array transpose and loop transformations to improve locality for parallel programs <ref> [6] </ref>. More recently, O'Boyle & Knijnenburg [19] and Kandemir et al. [14] investigate array transpose as a technique for improving data locality in uniprocessors.
Reference: [7] <author> S. Coleman and K. S. M c Kinley. </author> <title> Tile size selection using cache organization and data layout. </title> <booktitle> In Proceedings of the SIGPLAN '95 Conference on Programming Language Design and Implementation, </booktitle> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Thus, we need only compare r 0 to L s , returning c 0 as the smallest conflicting value once r 0 is smaller. Coleman and McKinley use a related algorithm for finding non-conflicting tile sizes <ref> [7] </ref>. The value j fl is selected to meet three criteria. First, j fl must be small enough to avoid excessive or infinite testing of successively larger column sizes. This is needed since transformations using LinPad2 iteratively test larger and larger column sizes until the heuristic decides not to reject. <p> Loop permutation and tiling are the primary optimization techniques [9, 17, 23], though loop fission (distribution) and loop fusion have also been found to be helpful [15, 17]. Coleman and McKin-ley show how to select tile sizes which avoid conflict misses using the Euclidean algorithm <ref> [7] </ref>. McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses [18]. Researchers have examined methods to eliminate conflict misses using hardware [11, 13] or 10 operating systems support [2, 4].
Reference: [8] <author> J. Ferrante, V. Sarkar, and W. Thrash. </author> <title> On estimating and enhancing cache effectiveness. </title> <editor> In U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, Fourth International Workshop, </booktitle> <address> Santa Clara, CA, </address> <month> August </month> <year> 1991. </year> <note> Springer-Verlag. </note>
Reference-contexts: McFarling shows compiler transformations of code sequences can help eliminate conflict misses in the instruction cache [16]. Many researchers have also examined the problem of deriving estimates of cache misses in order to help guide data locality optimizations <ref> [8, 9, 23] </ref>. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. establish that conflict misses can significantly degrade performance and present an analytical method for detecting and counting the number of cache misses due to conflicts [20].
Reference: [9] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: In our experiments on a 16K cache, InterPadLite has always found a satisfactory layout. 2.1.2 InterPad To eliminate severe conflict misses, InterPad considers pairs of array references with constant conflict distances on each loop iteration. Such pairs are commonly uniformly generated references <ref> [9] </ref> extended for conforming arrays, arrays that have equal dimension sizes in all but their highest dimension and possess equal-sized elements. <p> Wolf and Lam provide a concise definition and summary of important types of data locality [23]. Gannon et al. introduce the notion of uniformly generated references as a means of discovering group reuse between references to the same array <ref> [9] </ref>. Most compiler researchers have concentrated on computation-reordering transformations. Loop permutation and tiling are the primary optimization techniques [9, 17, 23], though loop fission (distribution) and loop fusion have also been found to be helpful [15, 17]. <p> Gannon et al. introduce the notion of uniformly generated references as a means of discovering group reuse between references to the same array [9]. Most compiler researchers have concentrated on computation-reordering transformations. Loop permutation and tiling are the primary optimization techniques <ref> [9, 17, 23] </ref>, though loop fission (distribution) and loop fusion have also been found to be helpful [15, 17]. Coleman and McKin-ley show how to select tile sizes which avoid conflict misses using the Euclidean algorithm [7]. <p> McFarling shows compiler transformations of code sequences can help eliminate conflict misses in the instruction cache [16]. Many researchers have also examined the problem of deriving estimates of cache misses in order to help guide data locality optimizations <ref> [8, 9, 23] </ref>. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. establish that conflict misses can significantly degrade performance and present an analytical method for detecting and counting the number of cache misses due to conflicts [20].
Reference: [10] <author> S. Ghosh, M. Martonosi, and S. Malik. </author> <title> Cache miss equations: An analytical representation of cache misses. </title> <booktitle> In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Ghosh et al. calculate conflict misses more accurately by counting the number of 11 integer solutions to cache miss equations, linear Diophantine equations that exactly specify the cache line to which each reference is mapped for every loop <ref> [10] </ref>. They demonstrate how to use cache miss equations to select array paddings to eliminate conflict misses and block sizes for tiling. Because of the complexity and expense of their more precise algorithms, both Temam et al. and Ghosh et al. have only evaluated their algorithms on a few kernels.
Reference: [11] <author> A. Gonzalez, M. Valero, N. Topham, and J. Parcerisa. </author> <title> Eliminating cache conflict misses through XOR-based placement functions. </title> <booktitle> In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses [18]. Researchers have examined methods to eliminate conflict misses using hardware <ref> [11, 13] </ref> or 10 operating systems support [2, 4]. These techniques are general and apply to a wide range of programs. However, for many scientific Fortran codes we can achieve similar or better performance using inexpensive data layout transformations.
Reference: [12] <author> T. Jeremiassen and S. Eggers. </author> <title> Reducing false sharing on shared memory multiprocessors through compile time data transformations. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Santa Barbara, CA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: A number of researchers have examined data layout transformations, usually in the context of parallel programs. Jeremiassen and Eggers automatically eliminate false sharing in explicitly parallel programs by changing the placement of variables <ref> [12] </ref>. Amarasinghe et al. demonstrate the utility of data layout transformations for eliminating conflict misses in parallel applications [1]. They find it to be significant in eliminating adverse cache effects, though specialized optimizations are necessary to reduce computation overhead for modified array subscripts.
Reference: [13] <author> N. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses [18]. Researchers have examined methods to eliminate conflict misses using hardware <ref> [11, 13] </ref> or 10 operating systems support [2, 4]. These techniques are general and apply to a wide range of programs. However, for many scientific Fortran codes we can achieve similar or better performance using inexpensive data layout transformations.
Reference: [14] <author> M. Kandemir, J. Ramanujam, and A. Choudhary. </author> <title> A compiler algorithm for optimizing locality in loop nests. </title> <booktitle> In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: Cierniak and Li examine combining array transpose and loop transformations to improve locality for parallel programs [6]. More recently, O'Boyle & Knijnenburg [19] and Kandemir et al. <ref> [14] </ref> investigate array transpose as a technique for improving data locality in uniprocessors. Manjikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion [15].
Reference: [15] <author> N. Manjikian and T. Abdelrahman. </author> <title> Fusion of loops for parallelism and locality. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 8(2) </volume> <pages> 193-209, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: Most compiler researchers have concentrated on computation-reordering transformations. Loop permutation and tiling are the primary optimization techniques [9, 17, 23], though loop fission (distribution) and loop fusion have also been found to be helpful <ref> [15, 17] </ref>. Coleman and McKin-ley show how to select tile sizes which avoid conflict misses using the Euclidean algorithm [7]. McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses [18]. <p> Manjikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion <ref> [15] </ref>. McFarling shows compiler transformations of code sequences can help eliminate conflict misses in the instruction cache [16]. Many researchers have also examined the problem of deriving estimates of cache misses in order to help guide data locality optimizations [8, 9, 23].
Reference: [16] <author> S. McFarling. </author> <title> Program optimization for instruction caches. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-III), </booktitle> <pages> pages 257-270, </pages> <address> Boston, MA, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: Manjikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion [15]. McFarling shows compiler transformations of code sequences can help eliminate conflict misses in the instruction cache <ref> [16] </ref>. Many researchers have also examined the problem of deriving estimates of cache misses in order to help guide data locality optimizations [8, 9, 23]. These models typically can predict only capacity misses because they assume a fully-associative cache.
Reference: [17] <author> K. S. M c Kinley, S. Carr, and C.-W. Tseng. </author> <title> Improving data locality with loop transformations. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 18(4) </volume> <pages> 424-453, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: Gannon et al. introduce the notion of uniformly generated references as a means of discovering group reuse between references to the same array [9]. Most compiler researchers have concentrated on computation-reordering transformations. Loop permutation and tiling are the primary optimization techniques <ref> [9, 17, 23] </ref>, though loop fission (distribution) and loop fusion have also been found to be helpful [15, 17]. Coleman and McKin-ley show how to select tile sizes which avoid conflict misses using the Euclidean algorithm [7]. <p> Most compiler researchers have concentrated on computation-reordering transformations. Loop permutation and tiling are the primary optimization techniques [9, 17, 23], though loop fission (distribution) and loop fusion have also been found to be helpful <ref> [15, 17] </ref>. Coleman and McKin-ley show how to select tile sizes which avoid conflict misses using the Euclidean algorithm [7]. McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses [18].
Reference: [18] <author> K. S. M c Kinley and O. Temam. </author> <title> A quantitative analysis of loop nest locality. </title> <booktitle> In Proceedings of the Eighth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VIII), </booktitle> <address> Boston, MA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Conflict misses have been found to be a significant source of poor performance in scientific programs, particularly within loop nests <ref> [18] </ref>. We believe compiler transformations can be very effective in eliminating conflict misses for scientific programs with regular access patterns. We evaluate two compiler transformations to eliminate conflict misses: inter- and intra-variable padding [3, 21]. <p> Coleman and McKin-ley show how to select tile sizes which avoid conflict misses using the Euclidean algorithm [7]. McKinley and Temam perform a study of loop-nest oriented cache behavior for scientific programs and conclude that conflict misses cause half of all cache misses and most intra-nest misses <ref> [18] </ref>. Researchers have examined methods to eliminate conflict misses using hardware [11, 13] or 10 operating systems support [2, 4]. These techniques are general and apply to a wide range of programs. However, for many scientific Fortran codes we can achieve similar or better performance using inexpensive data layout transformations.
Reference: [19] <author> M. O'Boyle and P. Knijnenburg. </author> <title> Non-singular data transformations: Definition, validity, </title> <booktitle> and applications. In Proceedings of the 1997 ACM International Conference on Supercomputing, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: They find it to be significant in eliminating adverse cache effects, though specialized optimizations are necessary to reduce computation overhead for modified array subscripts. Cierniak and Li examine combining array transpose and loop transformations to improve locality for parallel programs [6]. More recently, O'Boyle & Knijnenburg <ref> [19] </ref> and Kandemir et al. [14] investigate array transpose as a technique for improving data locality in uniprocessors. Manjikian and Abdelrahman perform cache partitioning, spacing out variables as far as possible in a cache, in order to reduce conflict misses in parallel programs after loop fusion [15].
Reference: [20] <author> O. Temam, C. Fricker, and W. Jalby. </author> <title> Cache interference phenomena. </title> <booktitle> In Proceedings of the 1994 ACM SIGMET-RICS Conference on Measurement & Modeling Computer Systems, </booktitle> <address> Santa Clara, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. establish that conflict misses can significantly degrade performance and present an analytical method for detecting and counting the number of cache misses due to conflicts <ref> [20] </ref>. Ghosh et al. calculate conflict misses more accurately by counting the number of 11 integer solutions to cache miss equations, linear Diophantine equations that exactly specify the cache line to which each reference is mapped for every loop [10].
Reference: [21] <author> J. Torrellas, M. Lam, and J. Hennessy. </author> <title> Shared data placement optimizations to reduce multiprocessor cache miss rates. </title> <booktitle> In Proceedings of the 1990 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: We believe compiler transformations can be very effective in eliminating conflict misses for scientific programs with regular access patterns. We evaluate two compiler transformations to eliminate conflict misses: inter- and intra-variable padding <ref> [3, 21] </ref>. Unlike standard compiler transfor This research was supported in part by NSF grant #CCR9711514 and NSF CAREER Award #ASC9625531 in New Technologies.
Reference: [22] <author> R. Wilson et al. </author> <title> SUIF: An infrastructure for research on parallelizing and optimizing compilers. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 29(12) </volume> <pages> 31-37, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: PadLite therefore fails to eliminate the existing severe conflict misses. Analysis enables Pad to find a layout eliminating these conflicts. 4 Experimental Evaluation 4.1 Evaluation Framework To experimentally evaluate inter- and intra-variable padding, we implemented both transformations in the Stanford SUIF compiler <ref> [22] </ref>. Additional transformations are performed to give the compiler control over variable base addresses. First, local array and structure variables are promoted into the global scope (globalization). Formal parameters to functions do not need to be promoted, since they represent variables declared elsewhere.
Reference: [23] <author> M. E. Wolf and M. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year> <month> 12 </month>
Reference-contexts: However, more powerful analysis is needed to prove the safety of padding for large programs. 5 Related Work Data locality has been recognized as a significant performance issue for both scalar and parallel architectures. Wolf and Lam provide a concise definition and summary of important types of data locality <ref> [23] </ref>. Gannon et al. introduce the notion of uniformly generated references as a means of discovering group reuse between references to the same array [9]. Most compiler researchers have concentrated on computation-reordering transformations. <p> Gannon et al. introduce the notion of uniformly generated references as a means of discovering group reuse between references to the same array [9]. Most compiler researchers have concentrated on computation-reordering transformations. Loop permutation and tiling are the primary optimization techniques <ref> [9, 17, 23] </ref>, though loop fission (distribution) and loop fusion have also been found to be helpful [15, 17]. Coleman and McKin-ley show how to select tile sizes which avoid conflict misses using the Euclidean algorithm [7]. <p> McFarling shows compiler transformations of code sequences can help eliminate conflict misses in the instruction cache [16]. Many researchers have also examined the problem of deriving estimates of cache misses in order to help guide data locality optimizations <ref> [8, 9, 23] </ref>. These models typically can predict only capacity misses because they assume a fully-associative cache. Temam et al. establish that conflict misses can significantly degrade performance and present an analytical method for detecting and counting the number of cache misses due to conflicts [20].
References-found: 23

