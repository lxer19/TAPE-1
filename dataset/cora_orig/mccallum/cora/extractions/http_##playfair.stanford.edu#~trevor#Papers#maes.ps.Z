URL: http://playfair.stanford.edu/~trevor/Papers/maes.ps.Z
Refering-URL: http://playfair.stanford.edu/~trevor/Papers/
Root-URL: 
Title: Dynamic Mixtures of Splines: a Model for Saliency Grouping in the Time Frequency Plane  
Author: Stephane H. Maes Trevor Hastie 
Keyword: curve fitting, EM algorithm, Kullback-Leibler distance, saliency extraction, mixtures of Gaussians.  
Address: Room 23-148B, P.O. Box 218, Yorktown Heights, NY 10598, USA.  Hall, Stanford University, CA94305.  
Affiliation: Department,  Statistics Department, Sequoia  
Note: IBM, T. J. Watson Research Center, Human Language Technologies, Acoustic Processing  
Email: e-mail: smaes@watson.ibm.com.  email: trevor@stat.stanford.edu  
Phone: Phone: +1-(914)-945-2908; Fax: +1-(914)-945-4490;  
Date: March 11, 1997  
Abstract: We describe a new approach for focusing images obtained by time-frequency analysis of speech signals. Our summary consists of a set of curves which include the formants. Due to the oscillatory nature of the two dimensional data, all the classical approaches to this problem have shortcomings. Our method is semi-automatic, requiring as input only the maximum number of curves. The summary curves are designed to correspond with human perception: they are not allowed to cross, they can die with time, new curves can be born, or the same curve can die and then be reborn. Our approach is based on two modeling assumptions a) we view each normalized image as a probability density function, and b) we approximate these densities, conditional on time, as mixtures of Gaus-sians. The curves then represent the means of the Gaussians as a function of time. Within this framework, we fit the model by maximum cross-entropy, and enforce the constraints by adapting the standard fitting algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Assaleh. </author> <title> Robust features for speaker identification. </title> <type> PhD thesis, </type> <institution> CAIP Center - Rutgers University, The State Univeristy of New Jersey, </institution> <address> New 19 Brunswick, NJ, </address> <year> 1993. </year>
Reference-contexts: The modulation model of speech assumes that speech utterances can be written as a linear combination of primary components. Each of these primary component can be expressed as an amplitude and frequency modulated sine function <ref> [7, 13, 1] </ref>. In this framework, we must extract or track the center frequency and bandwidth of the primary components of the signal as a function of time. These would be curves in time passing through the ribbons in Fig. 1. <p> In doing this, the following precautions are taken: * if any two curves c k (t) cross during this extrapolation, we interchange their coefficients from the point of crossing onwards. Such crossings of primary components are not consistent with the speech model <ref> [1, 9] </ref>. * We repeat the histogram procedure in each band, to check for the birth of new ribbons not accounted for by the current model.
Reference: [2] <author> V. Caselles. </author> <title> A geometric model for active contours in image processing. </title> <type> Technical report, </type> <institution> Ceremade, centre de recherce des mathematiques de la decision, 1987. Cahier de mathematiques de la decision, </institution> <month> 9210. </month>
Reference-contexts: The definition of features and edges as introduced by D. Marr [14] do not apply as almost every pixel is a singularity. Alternative definitions do not lead to any better results. * Local non-linear variational methods for edge detection, and often closure, by minimization of pseudo-energy functionals <ref> [2] </ref> or by maximization of the energy content [17, 23], end up isolating the different pixels and therefore providing a useless granular image. * Object oriented techniques exist for segmentation. These include mor phological approaches as well as bottom-up and top-down approaches [22].
Reference: [3] <author> I. Daubechies and S. Maes. </author> <title> Wavelets in medicine and biology. </title> <editor> In A. Al-roubi and M. Unser, editors, </editor> <title> A nonlinear squeezing of the continuous wavelet analysis based on auditory nerve models. </title> <publisher> CRC Press, </publisher> <month> April </month> <year> 1996. </year>
Reference-contexts: 1 Introduction For automatic speech and speaker recognition, a new representation was recently introduced, known as the Synchrosqueezed Plane Representation <ref> [11, 3] </ref>. This is a nonlinear transformation of the wavelet transform. Wavelet transforms (WT) of speech provide a time-scale representations of the speech signal [16]. <p> The synchrosqueezed representation is a nonlinear transformation of this plane that mimics some aspects of the human auditory system. The syn-chrosqueezed plane emphasizes coherent structures of the signal (i.e. primary components). The representation is robust to acoustic distortions <ref> [9, 3] </ref>, a feature attributable to the average property of the auditory nerve representation and to its phase-derivation. Examples of synchrosqueezed images are given in Figs 1-3|the frequencies tend to band in ribbons that change smoothly as a function of time.
Reference: [4] <author> Dempster, A.P., Laird, N.M., and Rubin, </author> <title> D.B. Maximum likelihood from incomplete data via the EM algorithm (with discussion). </title> <journal> J. R. Statist. Soc. B, </journal> <volume> 39 </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: While smoothness could be imposed in a number of ways, cubic splines are simple to implement, and have naturally-described smoothness properties in terms of integrated second-squared derivatives. As is often the case with mixture models, we rely on a version of the iterative EM-algorithm <ref> [4] </ref> to fit our mixture model by maximum likelihood estimation. While EM algorithms are notoriously slow, a combination of good starting values and the spatial smoothness ensure rapid convergence. <p> This leaves the conditional part, which we maximize over the parameters -. We use the Estimation-Maximization algorithm <ref> [4] </ref>, which simplifies the optimization process, and allows us to easily incorporate the extra bells and whistles required to enforce the constraints we have outlined.
Reference: [5] <author> J. L. Flanagan. </author> <title> Speech analysis synthesis and perception. </title> <publisher> Springer-Verlag, </publisher> <year> 1972. </year>
Reference-contexts: These ribbons can easily be characterized by visual inspection of the images. Some of the ribbons have indeed the classical behavior of formants and the planes can be read by specialists just like spectrograms <ref> [5] </ref>. In accordance with the modulation model, and after studying many examples, the following constraints seem natural: Ribbons are not allowed to cross each other. Ribbons can die. Ribbons are allowed to merge, in which case one of them dies. New ribbons can be born.
Reference: [6] <author> W. T. Freeman. </author> <title> Steerable filters and local analysis of image structure. </title> <type> PhD thesis, </type> <institution> M.I.T, </institution> <address> Cambridge, MA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: This method uses dynamic programming to imple-ment saliency extraction by iterated pairing <ref> [20, 19, 21, 6] </ref>. Structures are built up locally by iteratively pairing together substructures. For the synchrosqueezed plane images, this method turned out to be very unreliable.
Reference: [7] <author> J.F. Kaiser. </author> <title> Some useful properties of the Teager's energy operators. </title> <booktitle> In Proc. IEEE ICASSP, </booktitle> <pages> pages II.149-II.152, </pages> <year> 1993. </year>
Reference-contexts: The modulation model of speech assumes that speech utterances can be written as a linear combination of primary components. Each of these primary component can be expressed as an amplitude and frequency modulated sine function <ref> [7, 13, 1] </ref>. In this framework, we must extract or track the center frequency and bandwidth of the primary components of the signal as a function of time. These would be curves in time passing through the ribbons in Fig. 1.
Reference: [8] <author> S. P. Lloyd. </author> <title> Least squares quantization in PCM. </title> <journal> IEEE Trans. Inf. Theory, </journal> <volume> 28(2 (part2)):pp. </volume> <pages> 129-136, </pages> <year> 1982. </year>
Reference-contexts: These are then used to seed the Lloyd's K-mean algorithm <ref> [8, 15] </ref>, which is similar in spirit to the EM algorithm, but much simpler. K-means alternates between the two simple steps: Partition: Assign each pixel to the closest (in !) center c k .
Reference: [9] <author> S. Maes. </author> <title> The wavelet tranform in signal processing, with application to the extraction of the speech modulation model features. </title> <type> PhD thesis, </type> <institution> Uni-versite Catholique de Louvain, Louvain-la-Neuve, Belgium, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: The synchrosqueezed representation is a nonlinear transformation of this plane that mimics some aspects of the human auditory system. The syn-chrosqueezed plane emphasizes coherent structures of the signal (i.e. primary components). The representation is robust to acoustic distortions <ref> [9, 3] </ref>, a feature attributable to the average property of the auditory nerve representation and to its phase-derivation. Examples of synchrosqueezed images are given in Figs 1-3|the frequencies tend to band in ribbons that change smoothly as a function of time. <p> Details of the limitations of the classical image processing methods of extraction of saliencies can be found in <ref> [9] </ref>, and are outlined here. The conclusion is that they all fail in many situations and therefore require supervision. * The synchrosqueezed plane representation does not have the characteristics of a typical image. Oscillations and noise are encountered everywhere, often partially obscuring the relevant objects that constitute the ribbons. <p> In doing this, the following precautions are taken: * if any two curves c k (t) cross during this extrapolation, we interchange their coefficients from the point of crossing onwards. Such crossings of primary components are not consistent with the speech model <ref> [1, 9] </ref>. * We repeat the histogram procedure in each band, to check for the birth of new ribbons not accounted for by the current model. <p> This 16 Colored noise is present with SNR = 15 dB. allows a continuous transition between a formant-based modulation model which represents speech only by its formants and a sine-wave representation which introduces a large amount of sinusoidals for the same purpose <ref> [9] </ref>. the synchrosqueezed plane is corrupted by additive noise, which as observed in Fig. 4 does not modify the behavior of the ribbons. In practice, with the strategy used to determine the first guesses, only two passes through the whole V (t;!) are usually required.
Reference: [10] <author> S. Maes. </author> <title> Fast quasi-continuous wavelet algorithms for analysis and synthesis of 1-D signals. </title> <note> to be published in SIAM J. Applied Math. </note> <month> (Nov. </month> <year> 1997), </year> <month> April </month> <year> 1995. </year>
Reference-contexts: This representation is obtained by filtering the speech signal with a filter-bank of overlapping quasi-constant filters (i.e. filters obtained by successive dilations of a single filter) <ref> [10, 12] </ref>. This results in a quasi-continuous wavelet transform (QCWT), which is a intermediate between the classical discrete-time WT and the continuous WT [10, 12] Although this approach has strong physiological motivations, the primary components, such as formants, are not well separated in the time-frequency plane and very difficult to extract. <p> This representation is obtained by filtering the speech signal with a filter-bank of overlapping quasi-constant filters (i.e. filters obtained by successive dilations of a single filter) <ref> [10, 12] </ref>. This results in a quasi-continuous wavelet transform (QCWT), which is a intermediate between the classical discrete-time WT and the continuous WT [10, 12] Although this approach has strong physiological motivations, the primary components, such as formants, are not well separated in the time-frequency plane and very difficult to extract. The synchrosqueezed representation is a nonlinear transformation of this plane that mimics some aspects of the human auditory system.
Reference: [11] <author> S. Maes. </author> <title> Robust speech and speaker recognition using instantaneous frequencies and amplitudes obtained with wavelet-derived syn-chrosqueezing measures. In Program on Spline Functions and the Theory of Wavelets, </title> <address> Montreal, Canada, </address> <month> March </month> <year> 1996. </year> <institution> Centre de Recherches Mathematiques, Universite de Montreal. </institution> <type> invited paper. 20 </type>
Reference-contexts: 1 Introduction For automatic speech and speaker recognition, a new representation was recently introduced, known as the Synchrosqueezed Plane Representation <ref> [11, 3] </ref>. This is a nonlinear transformation of the wavelet transform. Wavelet transforms (WT) of speech provide a time-scale representations of the speech signal [16].
Reference: [12] <author> S. Maes. </author> <title> Signal analysis and synthesis with 1-D quasi-continuous wavelet transform. </title> <booktitle> In Proc. 12th. International Conference on analysis and optimization of systems, </booktitle> <address> Paris, </address> <month> June </month> <year> 1996. </year> <month> IRSIA. </month>
Reference-contexts: This representation is obtained by filtering the speech signal with a filter-bank of overlapping quasi-constant filters (i.e. filters obtained by successive dilations of a single filter) <ref> [10, 12] </ref>. This results in a quasi-continuous wavelet transform (QCWT), which is a intermediate between the classical discrete-time WT and the continuous WT [10, 12] Although this approach has strong physiological motivations, the primary components, such as formants, are not well separated in the time-frequency plane and very difficult to extract. <p> This representation is obtained by filtering the speech signal with a filter-bank of overlapping quasi-constant filters (i.e. filters obtained by successive dilations of a single filter) <ref> [10, 12] </ref>. This results in a quasi-continuous wavelet transform (QCWT), which is a intermediate between the classical discrete-time WT and the continuous WT [10, 12] Although this approach has strong physiological motivations, the primary components, such as formants, are not well separated in the time-frequency plane and very difficult to extract. The synchrosqueezed representation is a nonlinear transformation of this plane that mimics some aspects of the human auditory system.
Reference: [13] <author> P. Maragos, J. F. Kaiser, and T.F. Quatieri. </author> <title> Energy separation in signal modulation with application to speech analysis. </title> <journal> IEEE Trans. Signal Proc., </journal> <volume> 41(10):pp. </volume> <pages> 3024-3051, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: The modulation model of speech assumes that speech utterances can be written as a linear combination of primary components. Each of these primary component can be expressed as an amplitude and frequency modulated sine function <ref> [7, 13, 1] </ref>. In this framework, we must extract or track the center frequency and bandwidth of the primary components of the signal as a function of time. These would be curves in time passing through the ribbons in Fig. 1.
Reference: [14] <author> D. Marr and E. Hildreth. </author> <title> Theory of edge detection. </title> <journal> Proc. of Royal Soc. of London, </journal> <pages> pages pp. 187-217, </pages> <year> 1980. </year>
Reference-contexts: Oscillations and noise are encountered everywhere, often partially obscuring the relevant objects that constitute the ribbons. As a result, standard feature extraction and edge detection techniques for images are inefficient and inaccurate. The definition of features and edges as introduced by D. Marr <ref> [14] </ref> do not apply as almost every pixel is a singularity.
Reference: [15] <author> J. Max. </author> <title> Quantizing for minimum distorsion. </title> <journal> IRE Trans. Inform. Theory, </journal> <volume> 6 - 1(3):pp. </volume> <pages> 7-12, </pages> <year> 1960. </year>
Reference-contexts: These are then used to seed the Lloyd's K-mean algorithm <ref> [8, 15] </ref>, which is similar in spirit to the EM algorithm, but much simpler. K-means alternates between the two simple steps: Partition: Assign each pixel to the closest (in !) center c k .
Reference: [16] <author> O. Rioul and M. Vetterli. </author> <title> Wavelet and signal processing. </title> <journal> IEEE Sign. Proc. Magazine, </journal> <pages> pages 14-38, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: 1 Introduction For automatic speech and speaker recognition, a new representation was recently introduced, known as the Synchrosqueezed Plane Representation [11, 3]. This is a nonlinear transformation of the wavelet transform. Wavelet transforms (WT) of speech provide a time-scale representations of the speech signal <ref> [16] </ref>. Typically low frequency events will appear at a high scale with poor temporal localization, while high frequency events will appear at a low scale but will be well localized in time.
Reference: [17] <author> C. Ronse. </author> <title> On idempotence and related requirements in edge detection. </title> <type> preprint, </type> <year> 1993. </year>
Reference-contexts: Marr [14] do not apply as almost every pixel is a singularity. Alternative definitions do not lead to any better results. * Local non-linear variational methods for edge detection, and often closure, by minimization of pseudo-energy functionals [2] or by maximization of the energy content <ref> [17, 23] </ref>, end up isolating the different pixels and therefore providing a useless granular image. * Object oriented techniques exist for segmentation. These include mor phological approaches as well as bottom-up and top-down approaches [22]. In our experiments these did not work on the synchrosqueezing measure.
Reference: [18] <author> L. I. Rudin, S. Osher, and E. Fatemi. </author> <title> Nonlinear total variation based noise removal algorithm. </title> <institution> In Modelisations mathematiques pour le traite-ment d'image, Problemes non lineaires appliques, Rocquencourt, France, 1992. Ecoles CEA - EDF -INRIA, </institution> <month> March 16-18. </month>
Reference-contexts: This in turn blurs the behavior of the ribbons, loosing most of the gain obtained by the introduction of the synchrosqueezed measure. * Restoration by noise cancellation techniques were applied to the syn-chrosqueezed plane, using the most efficient techniques available <ref> [18] </ref>. these also failed to produce any useful summaries. 7 * Iterated pairing. This method uses dynamic programming to imple-ment saliency extraction by iterated pairing [20, 19, 21, 6]. Structures are built up locally by iteratively pairing together substructures.
Reference: [19] <author> A. Sashua. </author> <title> Structural saliency: The detection of globally salient structures using a locally connected network. </title> <note> Revised version, </note> <institution> Dept. Appl. Math. and Comp. Science, The Weizmann Inst. of Science, Rehovot, Israel, </institution> <year> 1990. </year>
Reference-contexts: This method uses dynamic programming to imple-ment saliency extraction by iterated pairing <ref> [20, 19, 21, 6] </ref>. Structures are built up locally by iteratively pairing together substructures. For the synchrosqueezed plane images, this method turned out to be very unreliable.
Reference: [20] <author> A. Sashua and S. Ullman. </author> <title> Structural saliency: The detection of globally salient structuresusing a locally connected network. </title> <booktitle> In Proc. 2nd Int. Conf. Computer Vision, </booktitle> <pages> pages 321-327, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: This method uses dynamic programming to imple-ment saliency extraction by iterated pairing <ref> [20, 19, 21, 6] </ref>. Structures are built up locally by iteratively pairing together substructures. For the synchrosqueezed plane images, this method turned out to be very unreliable.
Reference: [21] <author> A. Sashua and S. Ullman. </author> <title> Grouping contours by iterated pairing network. </title> <editor> In R.P. Lippmann, J.E. Moody, and D.S. Touretzky, editors, </editor> <booktitle> Neural Information Processing Systems, </booktitle> <volume> volume 3. </volume> <publisher> Morgan Kauffman Publ., </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: This method uses dynamic programming to imple-ment saliency extraction by iterated pairing <ref> [20, 19, 21, 6] </ref>. Structures are built up locally by iteratively pairing together substructures. For the synchrosqueezed plane images, this method turned out to be very unreliable.
Reference: [22] <author> J. Serra and L. Vincent. </author> <title> An overview of morphological filtering. Circuits Systems and Signal Process., </title> <booktitle> 11(1):pp. </booktitle> <pages> 47-108, </pages> <year> 1992. </year> <month> 21 </month>
Reference-contexts: These include mor phological approaches as well as bottom-up and top-down approaches <ref> [22] </ref>. In our experiments these did not work on the synchrosqueezing measure.
Reference: [23] <author> S. Venkatesh and R. Owens. </author> <title> Implementation detail of a feature detec-tion algorithm. </title> <type> Technical Report 89/12, </type> <institution> Univ. Western Australia, Dpt. Comp. </institution> <address> Sc., </address> <year> 1989. </year> <month> 22 </month>
Reference-contexts: Marr [14] do not apply as almost every pixel is a singularity. Alternative definitions do not lead to any better results. * Local non-linear variational methods for edge detection, and often closure, by minimization of pseudo-energy functionals [2] or by maximization of the energy content <ref> [17, 23] </ref>, end up isolating the different pixels and therefore providing a useless granular image. * Object oriented techniques exist for segmentation. These include mor phological approaches as well as bottom-up and top-down approaches [22]. In our experiments these did not work on the synchrosqueezing measure.
References-found: 23

