URL: ftp://dis.cs.umass.edu/pub/offline-icmas96.ps
Refering-URL: http://dis.cs.umass.edu/research/taems-learn.html
Root-URL: 
Email: nagendra@cs.umass.edu  
Title: Off-line Learning of Coordination in Functionally Structured Agents for Distributed Data Processing  
Author: M V Nagendra Prasad, and Victor R Lesser 
Address: Amherst, MA 01002.  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: When we design multi-agent systems for realistic, worth-oriented environments, coordination problems they present involve intricate and sophisticated interplay between the domain and the various system components. Achieving effective coordination in such systems is a difficult problem for a number of reasons like local views of problem-solving task and uncertainty about the outcomes of interacting non-local tasks. In this paper, we present a learning algorithm that endows agents with the capability to choose an appropriate coordination algorithm based on the present problem solving situation in the domain of distributed data processing.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. W. Aha, D. Kibler, and M. K. Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 37-66, </pages> <year> 1991. </year>
Reference-contexts: In this paper, we present a learning algorithm that uses an abstract characterization of the coordination problem instance to choose a coordination algorithm from among the three classes of algorithms discussed in the previous section. Our learning algorithm falls into the category of Instance-Based Learning algorithms <ref> [1] </ref>. It involves subjecting the multi-agent system to a series of runs to obtain a set of situation vectors and the corresponding system performances (normalized based on estimates of the best possible system performances) for each of the three coordination algorithms discussed previously.
Reference: [2] <author> Noam Chomsky. </author> <title> Syntactic Structures. </title> <publisher> Mouton and Co., </publisher> <year> 1966. </year>
Reference-contexts: They offer a structured way of describing topological relationships between entities in a domain. Graph grammars are fundamentally similar to string grammars <ref> [2, 12] </ref> with the difference lying in the productions. A graph production is a triple p = (g l ,g r ,E) where g l is the subgraph to be replaced (left hand side) and g r is the subgraph to be inserted in its place in the host graph.
Reference: [3] <author> Keith S. Decker. </author> <title> Environment Centered Analysis and Design of Coordination Mechanisms. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <year> 1995. </year>
Reference-contexts: We present some of our early and very encouraging experimental results and conclude. 2 TMS: Task Analysis, Environment Modeling, and Simulation The TMS framework (Task Analysis, Environment Modeling, and Simulation) <ref> [4, 3] </ref> represents coordination problems in a formal, domain-independent way. In the simplest terms, a TMS model of a task environment specifies what actions are available to agents and how those actions relate to one another and to the performance of the system as a whole. <p> We have used it to represent coordination problems in distributed sensor networks, hospital patient scheduling, airport resource management, distributed information retrieval, pilot's associate, local area network diagnosis, etc. <ref> [3] </ref>. TMS models problem-solving activities of intelligent agents operating in complex environments where: * Responses to some tasks are required by specific deadlines. * The problem-solving environment involves a worth-oriented domain [13]. <p> Interested readers will find many more details and examples in <ref> [3] </ref>. The following description is top-down, starting with the environment and ending with what the agent perceives. Thus we do not define a coordination problem until the final subsection. <p> If there is more than one non-local effect, then the effects are applied one after the other in an order specified in the model. We have defined at least sixteen example non-local effects <ref> [3] </ref>. We can define a performance measure P (E) for the system (or for an agent) that is a function of the episode. <p> A similar problem studied in DAI is the multi-agent self-interested coordination problem, where we choose an agent's control function so as to attempt to maximize only it's own performance (with the realization that other agents are doing likewise). 2.2 Grammar-based Task Structure Generation Decker and Lesser <ref> [3, 6] </ref> illustrate the importance of extensive empirical studies in determining the role of different coordination algorithms in different task environments. <p> grammar based generator allow us to easily represent and explore these tasks or others that may arise in this domain. 3 Instantiating Environment-specific Coordination Mechanisms In order to bring to bear different collections of coordination mechanisms for different multi-agent problem-solving environments, we use the Generalized Partial Global Planning (GPGP) approach <ref> [6, 3] </ref>. The coordination module in GPGP consists of several coordination mechanisms, each of which notices certain features in the task structures locally known, and responds by taking certain communication or information gathering actions, or by proposing new commitments.
Reference: [4] <author> Keith S. Decker and Victor R. Lesser. </author> <title> Quantitative modeling of complex computational task environments. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 217-224, </pages> <address> Washington, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: We present some of our early and very encouraging experimental results and conclude. 2 TMS: Task Analysis, Environment Modeling, and Simulation The TMS framework (Task Analysis, Environment Modeling, and Simulation) <ref> [4, 3] </ref> represents coordination problems in a formal, domain-independent way. In the simplest terms, a TMS model of a task environment specifies what actions are available to agents and how those actions relate to one another and to the performance of the system as a whole.
Reference: [5] <author> Keith S. Decker and Victor R. Lesser. </author> <title> Quantitative modeling of complex environments. </title> <journal> International Journal of Intelligent Systems in Accounting, Finance, and Management, </journal> <volume> 2(4) </volume> <pages> 215-234, </pages> <month> December </month> <year> 1993. </year> <title> Special issue on Mathematical and Computational Models of Organizations: Models and Characteristics of Agent Behavior. </title>
Reference-contexts: The first is that an agent's control decisions, based only on its local view of problem-solving task structures, may lead to inappropriate decisions about which activity it should do next, what results it should transmit to other agents and what results it should ask other agents to produce <ref> [8, 5] </ref>. If an agent has a view of the task structures of other agents it can make more informed choices.
Reference: [6] <author> Keith S. Decker and Victor R. Lesser. </author> <title> Designing a family of coordination algorithms. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems, </booktitle> <address> San Francisco, </address> <month> June </month> <year> 1995. </year> <note> AAAI Press. Longer version available as UMass CS-TR 94-14. </note>
Reference-contexts: A similar problem studied in DAI is the multi-agent self-interested coordination problem, where we choose an agent's control function so as to attempt to maximize only it's own performance (with the realization that other agents are doing likewise). 2.2 Grammar-based Task Structure Generation Decker and Lesser <ref> [3, 6] </ref> illustrate the importance of extensive empirical studies in determining the role of different coordination algorithms in different task environments. <p> grammar based generator allow us to easily represent and explore these tasks or others that may arise in this domain. 3 Instantiating Environment-specific Coordination Mechanisms In order to bring to bear different collections of coordination mechanisms for different multi-agent problem-solving environments, we use the Generalized Partial Global Planning (GPGP) approach <ref> [6, 3] </ref>. The coordination module in GPGP consists of several coordination mechanisms, each of which notices certain features in the task structures locally known, and responds by taking certain communication or information gathering actions, or by proposing new commitments.
Reference: [7] <author> E. Durfee and V. Lesser. </author> <title> Predictability vs. responsiveness: Coordinating problem solvers in dynamic domains. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 66-71, </pages> <address> St. Paul, Minnesota, </address> <month> August </month> <year> 1988. </year> <month> 11 </month>
Reference-contexts: IRI-9523419 and EEC-9209623. The content of this paper does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred. 1 non-coherent activity to occur may be the optimal coordination strategy <ref> [7] </ref>. In this case, local problem solving is done more efficiently where there is no additional overhead for coordination. Nagendra Prasad et. al.[11] developed a tool for representing interesting, complex coordination problems and instantiating environment-specific coordination mechanisms for facilitating empirical studies of effectiveness of different coordination mechanisms in different environments.
Reference: [8] <author> Edmund H. Durfee and Victor R. Lesser. </author> <title> Using partial global plans to coordinate distributed problem solvers. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: The first is that an agent's control decisions, based only on its local view of problem-solving task structures, may lead to inappropriate decisions about which activity it should do next, what results it should transmit to other agents and what results it should ask other agents to produce <ref> [8, 5] </ref>. If an agent has a view of the task structures of other agents it can make more informed choices.
Reference: [9] <author> Alan Garvey and Victor Lesser. </author> <title> Design-to-time scheduling with uncertainty. </title> <type> CS Technical Report 95-03, </type> <institution> University of Massachusetts, </institution> <year> 1995. </year>
Reference-contexts: We create a virtual task structure from the locally available task structure of an agent by letting each of the facilitates inter-relationships potentially effecting a local task to actually take effect 3 . We use a design-to-time real-time scheduler <ref> [9] </ref> to schedule this virtual task structure to see the effect of coordinating on facilitates inter-relationships for a particular agent. The next two components represent an approximation of the effect of detecting hard coordination inter-relationships on the quality and duration of the local task structures at an agent.
Reference: [10] <author> S. Mullins and J. R. Rinderle. </author> <title> Grammatical Approaches to Engineering Design, part i. </title> <booktitle> Research in Engineering Design, </booktitle> <volume> 2 </volume> <pages> 121-135, </pages> <year> 1991. </year>
Reference-contexts: We then show how a data-flow model of data processing can be captured by task structures and their grammatical specifications. 2.2.1 Graph Grammars Graph grammars are a powerful tool used in a number of domains <ref> [10, 12] </ref> to capture and characterize the underlying structural regularities. They offer a structured way of describing topological relationships between entities in a domain. Graph grammars are fundamentally similar to string grammars [2, 12] with the difference lying in the productions. <p> A graph production is a 4-tuple p i = hg i r ; E i ; P r (p i )i where P j l ) are isomorphic) Let G 0 be a graph derived from S using P. Rewriting this graph involves what is called a LEARRE method <ref> [10] </ref>: Locate a subgraph g 0 that is isomorphic to the left-hand side, g i l of production p i 2 P , establish the Embedding Area in G 0 , Remove g 0 along with all the edges incident on it, Replace g 0 with g i r and Embed
Reference: [11] <author> M. V. Nagendra Prasad, Keith S. Decker, Alan Garvey, and Victor R. Lesser. </author> <title> Exploring Organizational Designs with TAEMS: A Case Study of Distributed Data Processing. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems, </booktitle> <address> Kyoto, Japan, </address> <month> December </month> <year> 1996. </year> <note> AAAI Press. </note>
Reference-contexts: In this paper, we present a learning algorithm that endows agents with the capability to choose a coordination mechanism based on the present problem solving situation to maximize its performance. We use the same domain of distributed data processing as in <ref> [11] </ref>. The rest of the paper is organized as follows. We briefly review the TMS task structure representation for complex multi-agent coordination problems and a description of a graph-grammar-based stochastic task structure description language. We show that this tool can be used to model a distributed data processing problem. <p> We show that this tool can be used to model a distributed data processing problem. This description closely follows our work on modeling organizational designs in the distributed data processing domain, presented in more detail in <ref> [11] </ref> 1 . We then describe our learning algorithm that learns to choose among three coordination modes of different levels of sophistication: no commitments, tacit a priori commitments and dynamically generated commitments. <p> As the crisis tasks probability increases rough and data-flow algorithms outperform modular. <ref> [11] </ref> discusses the reasons for this performance dynamics. We will summarize them here and refer readers interested in details to [11]. The commitment mechanisms implemented as of now in GPGP are one-way. <p> As the crisis tasks probability increases rough and data-flow algorithms outperform modular. <ref> [11] </ref> discusses the reasons for this performance dynamics. We will summarize them here and refer readers interested in details to [11]. The commitment mechanisms implemented as of now in GPGP are one-way. There are commitments from the predecessor end of the interrelations to the agents at the successor end but not the other way.
Reference: [12] <author> M. </author> <title> Nagl. A Tutorial and Bibliographic Survey on Graph Grammars. </title> <editor> In V. Claus, H. Ehrig, and G. Rozenberg, editors, </editor> <title> Graph Grammars and their Application to Computer Science and Biology, </title> <publisher> LNCS 73, </publisher> <pages> pages 70-126. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1979. </year>
Reference-contexts: We then show how a data-flow model of data processing can be captured by task structures and their grammatical specifications. 2.2.1 Graph Grammars Graph grammars are a powerful tool used in a number of domains <ref> [10, 12] </ref> to capture and characterize the underlying structural regularities. They offer a structured way of describing topological relationships between entities in a domain. Graph grammars are fundamentally similar to string grammars [2, 12] with the difference lying in the productions. <p> They offer a structured way of describing topological relationships between entities in a domain. Graph grammars are fundamentally similar to string grammars <ref> [2, 12] </ref> with the difference lying in the productions. A graph production is a triple p = (g l ,g r ,E) where g l is the subgraph to be replaced (left hand side) and g r is the subgraph to be inserted in its place in the host graph.
Reference: [13] <author> J. S. Rosenschein and G. Zlotkin. </author> <title> Designing conventions for automated negotition. </title> <journal> AI Magazine, </journal> <pages> pages 29-46, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: TMS models problem-solving activities of intelligent agents operating in complex environments where: * Responses to some tasks are required by specific deadlines. * The problem-solving environment involves a worth-oriented domain <ref> [13] </ref>. In a worth-oriented domain, goals are encoded as functions that rate the acceptability of states, and the agents strive for the best solution possible (but not necessarily an optimal solution).
Reference: [14] <author> A. Sanfeliu and K. S. Fu. </author> <title> Tree-graph Grammars for Pattern Recognition. </title> <editor> In H. Ehrig, M. Nagl, and G. Rozenberg, editors, </editor> <title> Graph Grammars and their Application to Computer Science, </title> <publisher> LNCS 153, </publisher> <pages> pages 349-368. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1983. </year>
Reference-contexts: and the edge-label alphabet () are finite, non-empty, mutually disjoint sets, A n , A t , and A are the respective sets of attributes, S 2 n is the start label (can be a node or a graph) and P is a finite nonempty set of graph production rules <ref> [14] </ref>. A graph production is a 4-tuple p i = hg i r ; E i ; P r (p i )i where P j l ) are isomorphic) Let G 0 be a graph derived from S using P.
Reference: [15] <author> Y. Shoham and M. Tennenholtz. </author> <title> On the synthesis of useful social laws for artificial agent societies (preliminary report). </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 276-281, </pages> <address> San Jose, </address> <month> July </month> <year> 1992. </year> <month> 12 </month>
Reference-contexts: The agents have the relevant non-local view of the coordination problem, detect coordination relationships, but use rough commitments for routine tasks and communicate the committed results. It might be possible to view rough commitments as precompiled social laws <ref> [15] </ref>. 4 Learning Coordination Many researchers have shown that no single coordination mechanism is good for all situations. However, there is little in the literature that deals with how to choose a coordination strategy based on the situation.
References-found: 15

