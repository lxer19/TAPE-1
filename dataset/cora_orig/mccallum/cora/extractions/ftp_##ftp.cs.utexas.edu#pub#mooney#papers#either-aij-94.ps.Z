URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/either-aij-94.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: ourstond@rcwcl1.dnet.bp.com  mooney@cs.utexas.edu  
Title: Theory Refinement Combining Analytical and Empirical Methods  
Author: Dirk Ourston Raymond J. Mooney 
Address: 4440 Warrensville Center Rd. Cleveland OH, 44128  Austin, TX 78712  
Affiliation: British Petroleum Research  Computer Sciences Department University of Texas  
Abstract: This article describes a comprehensive approach to automatic theory revision. Given an imperfect theory, the approach combines explanation attempts for incorrectly classified examples in order to identify the failing portions of the theory. For each theory fault, correlated subsets of the examples are used to inductively generate a correction. Because the corrections are focused, they tend to preserve the structure of the original theory. Because the system starts with an approximate domain theory, in general fewer training examples are required to attain a given level of performance (classification accuracy) compared to a purely empirical system. The approach applies to classification systems employing a propositional Horn-clause theory. The system has been tested in a variety of application domains, and results are presented for problems in the domains of molecular biology and plant disease diagnosis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Bareiss, B. W. Porter, and K. Murray. </author> <title> Supporting start-to-finish development of knowledge bases. </title> <journal> Machine Learning, </journal> 4(3/4):259-284, 1989. 
Reference-contexts: Therefore, a knowledge-base formed by theory refinement is much more suitable for supplying meaningful explanations for its conclusions, an important aspect of the usability of an expert system. The theory refinement system we have developed, Either (Explanation-based and 1 Bareiss, Porter, and Murray <ref> [ 1 ] </ref> divide the knowledge base refinement phase into two stages: the first establishes the correctness of the knowledge base, and second improves efficiency.
Reference: [2] <author> F. Bergadano and A. Giordana. </author> <title> A knowledge intensive approach to concept induction. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 305-317, </pages> <address> Ann Arbor, MI, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Many systems do not revise the theory itself but instead revise the operational definition of a concept <ref> [ 2; 18; 35 ] </ref> . Still other systems rely on active experimentation rather than a provided training set to detect and correct errors [ 39 ] . <p> Focl (First-Order Combined Learner) is a hybrid system that uses Foil [ 38 ] as its inductive component. It is capable of handling both incomplete and incorrect first-order Horn-clause theories. Focl is based on the process of operationalization using a technique similar to that employed in Ml-smart <ref> [ 2 ] </ref> . The system continually attempts to re-express higher-level concepts in the theory in terms of lower-level concepts until the goal concept is expressed in terms of observables.
Reference: [3] <editor> L. A. Birnbaum and G. C. Collins, editors. </editor> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning: Section on Learning From Theory and Data, </booktitle> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Consequently, a number of recent research projects have focused on integrating these two basic approaches to machine learning <ref> [ 42; 3 ] </ref> .
Reference: [4] <author> T. Cain. </author> <title> The ductor: A theory revision system for propositional domains. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 485-489, </pages> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Finally, previous systems do not have Either's modularity and therefore cannot easily take advantage of advances in the individual areas of deduction, abduction, and induction. 8 RELATED RESEARCH 31 Rtls [ 14 ] , Kbann [ 46 ] , Focl [ 35 ] , and Ductor <ref> [ 4 ] </ref> are theory revision systems that come the closest to handling as many types of imperfections as Either. Each of these systems is discussed in more detail below. In the case of Rtls, a propositional Horn-clause theory is flattened into disjunctive-normal-form (DNF) prior to correction.
Reference: [5] <author> E. Charniak and D. McDermott. </author> <title> Introduction to AI. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1985. </year> <note> REFERENCES 35 </note>
Reference-contexts: In each case, Either attempts to find a minimum cover in order to minimize change to the initial theory. 3 THE BASIC THEORY REVISION ALGORITHM 10 3.1.1 The Minimum Antecedent Cover Abduction <ref> [ 5; 20 ] </ref> is used find antecedents whose removal would help fix failing positives. The normal logical definition of abduction is: Given: A domain theory, T , and an observed fact O.
Reference: [6] <author> William W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pages 743-748, </pages> <address> Boston, MA, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Some previous systems are only capable of generalizing an overly specific theory [ 49; 7; 48; 44 ] while others are only capable of specializing an overly general theory <ref> [ 12; 26; 6 ] </ref> . Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] .
Reference: [7] <author> A. P. Danyluk. </author> <title> Finding new rules for incomplete theories: Explicit biases for induction with contextual information. </title> <booktitle> In Proceedings of the Sixth International Conference on Machine Learning, </booktitle> <pages> pages 34-36, </pages> <address> Ithaca, NY, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: This is the first situation illustrated in Figure 6 where there is a gap at the "top" of the theory. For example, imagine the category rule for concluding cup was missing from the cup theory. Other research in the refinement of incomplete theories with missing rules <ref> [ 7 ] </ref> as 6 Or if higher-level corrections are syntactically simpler, see Section 5. 5 REVISING HIGHER-LEVEL RULES 20 sumes that the domain theory has correct rules for inferring categories from intermediate concepts but is instead missing rules connecting observables to intermediate concepts. <p> Some previous systems are only capable of generalizing an overly specific theory <ref> [ 49; 7; 48; 44 ] </ref> while others are only capable of specializing an overly general theory [ 12; 26; 6 ] . Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] .
Reference: [8] <author> G. F. DeJong and R. J. Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176, </pages> <year> 1986. </year>
Reference-contexts: Research in machine learning attempts to solve the knowledge acquisition problem by developing systems that automatically acquire the requisite knowledge from experience. However, empirical learning systems [ 36; 22; 41 ] do not take significant advantage of existing domain knowledge and explanation-based learning systems <ref> [ 8; 25 ] </ref> require a complete and correct domain theory. Consequently, a number of recent research projects have focused on integrating these two basic approaches to machine learning [ 42; 3 ] .
Reference: [9] <author> W. F. Dowling and J. H. Gallier. </author> <title> Linear-time algorithms for testing the satisfiability of propositional horn formulae. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 267-284, </pages> <year> 1984. </year>
Reference-contexts: It should also be noted that while propositional Horn-clause theorem proving can be performed in linear time <ref> [ 9 ] </ref> , the algorithm implemented in Either does not use the more efficient methods, making the deductive component another prime target for future improvement. 7 Experimental Results Either was tested on two domain theories to determine its ability to revise real expert rulebases using real data.
Reference: [10] <author> G. Drastal, G. Czako, and S. Raatz. </author> <title> Induction in an abstraction space: A form of constructive induction. </title> <booktitle> In Proceedings of the Eleventh International Joint conference on Artificial intelligence, </booktitle> <pages> pages 708-712, </pages> <address> Detroit, MI, </address> <month> Aug </month> <year> 1989. </year>
Reference-contexts: Figure 6 illustrates how a theory can have gaps at various levels. Previous research has focused on handling gaps at a particular level in a theory. For example, some research in constructive induction <ref> [ 10; 23 ] </ref> assumes that the existing domain theory defines a set of intermediate concepts (derived features) in terms of observables. The rules connecting these intermediate concepts to the categories are assumed to be missing and must be learned using induction.
Reference: [11] <author> D. H. Fisher and K. B. McKusick. </author> <title> An empirical comparison of id3 and backpropagation. </title> <booktitle> In Proceedings of the Eleventh International Joint conference on Artificial intelligence, </booktitle> <pages> pages 788-793, </pages> <address> Detroit, MI, </address> <month> Aug </month> <year> 1989. </year>
Reference-contexts: The likely explanation for the performance advantage is that the DNA task involves learning a concept of the form N out of these M features must be present. Experiments comparing backpropagation and Id3 report that backpropagation is better at learning N out of M functions <ref> [ 11 ] </ref> . Some aspects of the promoter concept fit the N out of M format where, for example, there are several potential sites where hydrogen bonds can form between the DNA and the protein; if enough of these bonds form, promoter activity can occur.
Reference: [12] <author> N. S. Flann and T. G. Dietterich. </author> <title> A study of explanation-based methods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4(2) </volume> <pages> 187-226, </pages> <year> 1989. </year>
Reference-contexts: Some previous systems are only capable of generalizing an overly specific theory [ 49; 7; 48; 44 ] while others are only capable of specializing an overly general theory <ref> [ 12; 26; 6 ] </ref> . Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] .
Reference: [13] <author> M. Garey and D. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <publisher> Freeman, </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: Since the general minimum set covering problem is NP-Hard <ref> [ 13 ] </ref> , Either uses a version of the greedy covering algorithm to find the antecedent cover. The greedy algorithm does not guarantee to find the minimum cover, but will come within a logarithmic factor of it and runs in polynomial time [ 19 ] .
Reference: [14] <author> A. Ginsberg. </author> <title> Theory reduction, theory revision, </title> <booktitle> and retranslation. In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pages 777-782, </pages> <address> Detroit, MI, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Finally, previous systems do not have Either's modularity and therefore cannot easily take advantage of advances in the individual areas of deduction, abduction, and induction. 8 RELATED RESEARCH 31 Rtls <ref> [ 14 ] </ref> , Kbann [ 46 ] , Focl [ 35 ] , and Ductor [ 4 ] are theory revision systems that come the closest to handling as many types of imperfections as Either. Each of these systems is discussed in more detail below.
Reference: [15] <author> A. Ginsberg, S. M. Weiss, and P. Politakis. </author> <title> Automatic knowledge based refinement for classification systems. </title> <journal> Artificial Intelligence, </journal> <volume> 35 </volume> <pages> 197-226, </pages> <year> 1988. </year>
Reference-contexts: Normal knowledge acquisition can be divided into two phases: an initial phase in which a knowledge engineer extracts a rough set of rules from an expert, and knowledge base refinement, in which the initial knowledge base is refined to produce a high-performance system <ref> [ 15 ] </ref> 1 . The initial knowledge base is acquired as whole rules, or sets of rules, that are used to represent various concepts in the domain. <p> Some previous work has addressed the problem of refining the probabilities or certainty factors attached to rules <ref> [ 21; 15 ] </ref> ; however, such numerical adjustments have not been integrated with more symbolic revisions such as learning new rules. We are currently developing a system that first "tweaks" certainty factors until no more improvement is possible and then resorts to learning new rules.
Reference: [16] <author> A. R. Golding and P. S. Rosenbloom. </author> <title> Improving rule-based systems through case-based reasoning. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pages 22-27, </pages> <address> Anaheim, CA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: For example, it has been shown that neural networks are particularly suitable for learning concepts involving N out of M functions [ 46 ] . In addition, case-based reasoning has been shown to be an effective adjunct to a rule-based system for exception processing <ref> [ 16 ] </ref> . Finally, when insufficient training data is available, some form of active knowledge acquisition, like experimentation, is required [ 39 ] . In each of these cases, using the basic Either algorithm to focus the knowledge acquisition should improve both comprehensibility and accuracy.
Reference: [17] <author> D. Haussler. </author> <title> Quantifying inductive bias: </title> <journal> Artificial intelligence learning algorithms and Valiant's learning framework. Artificial Intelligence, </journal> <volume> 26 </volume> <pages> 177-221, </pages> <year> 1988. </year>
Reference-contexts: Like retraction, antecedent generalization is successful if it does not introduce any new failing negatives. Consequently, antecedent generalization is a one-sided generalization <ref> [ 17 ] </ref> : only the positive examples are considered for the generalization, the negative examples are used simply to determine if the generalization was successful. 3.2.3 Inductive Rule Addition If both antecedent retraction and generalization result in over-generalization, the inductive component is used to learn entirely new rules for the <p> In summary, we can apply the following result (Theorem 4.4) from <ref> [ 17 ] </ref> : Let H be a hypothesis space and L be a learning algorithm that uses H consistently (see definition below). <p> Formally, a learning algorithm uses a hypothesis space consistently if (from <ref> [ 17 ] </ref> , Definition 4.3), for any sequence of examples, Q: 1. If the version space of Q is not empty, then the algorithm produces a hypothesis in the version space, 2.
Reference: [18] <author> H. Hirsh. </author> <title> Incremental Version-Space Merging: A General Framework for Concept Learning. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <address> Palo Alto, CA, </address> <month> June </month> <year> 1989. </year> <note> REFERENCES 36 </note>
Reference-contexts: Many systems do not revise the theory itself but instead revise the operational definition of a concept <ref> [ 2; 18; 35 ] </ref> . Still other systems rely on active experimentation rather than a provided training set to detect and correct errors [ 39 ] .
Reference: [19] <author> D. S. Johnson. </author> <title> Approximation algorithms for combinatorial problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9 </volume> <pages> 256-278, </pages> <year> 1974. </year>
Reference-contexts: The greedy algorithm does not guarantee to find the minimum cover, but will come within a logarithmic factor of it and runs in polynomial time <ref> [ 19 ] </ref> . The algorithm iteratively updates a partial cover, as follows. At each iteration, the algorithm chooses a partial proof and adds its antecedent retractions to the evolving cover.
Reference: [20] <author> H. J. Levesque. </author> <title> A knowledge-level account of abduction. </title> <booktitle> In Proceedings of the Eleventh International Joint conference on Artificial intelligence, </booktitle> <pages> pages 1061-1067, </pages> <address> Detroit, MI, </address> <month> Aug </month> <year> 1989. </year>
Reference-contexts: In each case, Either attempts to find a minimum cover in order to minimize change to the initial theory. 3 THE BASIC THEORY REVISION ALGORITHM 10 3.1.1 The Minimum Antecedent Cover Abduction <ref> [ 5; 20 ] </ref> is used find antecedents whose removal would help fix failing positives. The normal logical definition of abduction is: Given: A domain theory, T , and an observed fact O.
Reference: [21] <author> X. Ling and M. Valtorta. </author> <title> Revision of reduced theories. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 519-523, </pages> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Some previous work has addressed the problem of refining the probabilities or certainty factors attached to rules <ref> [ 21; 15 ] </ref> ; however, such numerical adjustments have not been integrated with more symbolic revisions such as learning new rules. We are currently developing a system that first "tweaks" certainty factors until no more improvement is possible and then resorts to learning new rules.
Reference: [22] <author> R.S. Michalksi, I. Mozetic, J. Hong, and N. Lavrac. </author> <title> The multi-purpose incremental learning system aq15 and its testing application to three medical domains. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pages 1041-1045, </pages> <address> Philadel-phia, PA, </address> <month> Aug </month> <year> 1986. </year>
Reference-contexts: Research in machine learning attempts to solve the knowledge acquisition problem by developing systems that automatically acquire the requisite knowledge from experience. However, empirical learning systems <ref> [ 36; 22; 41 ] </ref> do not take significant advantage of existing domain knowledge and explanation-based learning systems [ 8; 25 ] require a complete and correct domain theory.
Reference: [23] <author> R. S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In R. S. Michal-ski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 83-134. </pages> <publisher> Tioga, </publisher> <year> 1983. </year>
Reference-contexts: Figure 6 illustrates how a theory can have gaps at various levels. Previous research has focused on handling gaps at a particular level in a theory. For example, some research in constructive induction <ref> [ 10; 23 ] </ref> assumes that the existing domain theory defines a set of intermediate concepts (derived features) in terms of observables. The rules connecting these intermediate concepts to the categories are assumed to be missing and must be learned using induction.
Reference: [24] <author> R. S. Michalski and S. Chilausky. </author> <title> Learning by being told and learning from examples: An experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> Journal of Policy Analysis and Information Systems, </journal> <volume> 4(2) </volume> <pages> 126-161, </pages> <year> 1980. </year>
Reference-contexts: This is because Either's goal is to produce a minimally revised Horn-clause theory and Kbann has no such bias. 7.2 Soybean Results In order to demonstrate Either's ability to revise multiple category theories, Either was used to refine the expert rules given in <ref> [ 24 ] </ref> . This is a theory for diagnosing soybean 7 EXPERIMENTAL RESULTS 29 diseases that distinguishes between nineteen possible soybean diseases using examples that are described with thirty five features. The original experiments compared expert-rules to induction from examples. <p> Each point on the curves was computed from a 22 sample average. Note that even with the flexible tester, the accuracy of the original rules was only 51%, as compared to 73% for the original results presented in <ref> [ 24 ] </ref> . Overall, the accuracy of the initial rules is increased by 26 percentage points when Either is trained using 100 training examples. Compared to pure induction, Either maintains its initial performance advantage over the entire training interval.
Reference: [25] <author> T. M. Mitchell, R. Keller, and S. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: Research in machine learning attempts to solve the knowledge acquisition problem by developing systems that automatically acquire the requisite knowledge from experience. However, empirical learning systems [ 36; 22; 41 ] do not take significant advantage of existing domain knowledge and explanation-based learning systems <ref> [ 8; 25 ] </ref> require a complete and correct domain theory. Consequently, a number of recent research projects have focused on integrating these two basic approaches to machine learning [ 42; 3 ] .
Reference: [26] <author> R. J. Mooney and D. Ourston. </author> <title> Induction over the unexplained: Integrated learning of concepts with both explainable and conventional aspects. </title> <booktitle> In Proceedings of the Sixth International Conference on Machine Learning, </booktitle> <pages> pages 5-7, </pages> <address> Ithaca, NY, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Some previous systems are only capable of generalizing an overly specific theory [ 49; 7; 48; 44 ] while others are only capable of specializing an overly general theory <ref> [ 12; 26; 6 ] </ref> . Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] .
Reference: [27] <author> R. J. Mooney and D. Ourston. </author> <title> Theory refinement with noisy data. </title> <type> Technical Report AI91-153, </type> <institution> Artificial Intelligence Laboratory, University of Texas, Austin, TX, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Another approach to improving efficiency is to only partially fit the theory to the training data. Existing experiments with a version of Either that computes only partial covers of the failing positive and failing negative examples have demonstrated that this technique can significantly increase efficiency without significantly affecting accuracy <ref> [ 27 ] </ref> 8 . <p> The examples used in the tests consisted of 53 positive and 53 negative examples assembled from the biological literature. The initial theory classified none of the positive examples 8 Incomplete covering was originally developed to deal with noisy data as discussed in <ref> [ 27; 32 ] </ref> 7 EXPERIMENTAL RESULTS 27 and all of the negative examples correctly, thus indicating that the initial theory was entirely overly specific. In each test, classification accuracy was measured using twenty-six disjoint test examples.
Reference: [28] <author> S. Muggleton. Duce, </author> <title> an oracle based approach to constructive induction. </title> <booktitle> In Proceedings of the Tenth International Joint conference on Artificial intelligence, </booktitle> <pages> pages 287-292, </pages> <address> Milan, Italy, </address> <month> Aug </month> <year> 1987. </year>
Reference-contexts: Consequent identification, section 5.1, identifies the level in the theory that needs correcting. Concept utilization, section 5.2, employs existing rules in the theory to derive high-level features from the data. Concept creation, section 5.3, employs inverse resolution operators <ref> [ 28 ] </ref> to introduce new intermediate concepts in order to fill a gap in the theory spanning multiple levels. 5.1 Consequent Identification The basic Either procedure focuses on rules at the "bottom" of the theory, where changes generally have fewer ramifications and can improve multiple categories. <p> The concept creation algorithm used by Either is based on the inverse resolution technique of Muggleton and Buntine [ 29 ] . In particular, Either uses the intra-construction, inter-construction, and absorption operators for compacting the revised rules. 5.3.1 The Inverse Resolution Operators In Duce <ref> [ 28 ] </ref> , sets of rules are compared in order to identify common patterns, and then combined and compressed using one of the inverse resolution operators. The inter-construction and intra-construction operators introduce new concepts in the process.
Reference: [29] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 339-352, </pages> <address> Ann Arbor, MI, </address> <month> June </month> <year> 1988. </year> <note> REFERENCES 37 </note>
Reference-contexts: This process serves the twin purposes of compressing the rulebase and identifying new intermediate concepts. The concept creation algorithm used by Either is based on the inverse resolution technique of Muggleton and Buntine <ref> [ 29 ] </ref> . <p> Many ideas from Either are currently being incorporated in a new system, Forte [ 40 ] , which can revise theories expressed using first-order Horn clauses. Forte also incorporates many ideas from the work on Foil [ 38 ] and inverse resolution <ref> [ 29 ] </ref> . A fourth shortcoming in Either's knowledge representation is an inability to revise probabilistic rules. Many existing expert rule bases employ some form of probabilistic reasoning.
Reference: [30] <author> H. T. Ng and R. J. Mooney. </author> <title> Abductive explanations for text understanding: Some problems and solutions. </title> <type> Technical Report AI89-116, </type> <institution> Artificial Intelligence Laboratory, University of Texas, Austin, TX, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: The proof supported by each such set is called a partial proof. Either currently uses an abductive component that employs exhaustive search to find all partial proofs of each failing positive example <ref> [ 30 ] </ref> . Partial proofs are used to indicate conflicting antecedents that, if retracted, would allow the example to become provable.
Reference: [31] <author> H. T. Ng and R. J. Mooney. </author> <title> An efficient first-order abduction system based on the atms. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <address> Anaheim, CA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: For example, the time complexity of Either's abduction algorithm is exponential in the size of the theory. However, this algorithm could be exchanged for one using an Atms (Assumption-based Truth Maintenance System) and beam search <ref> [ 31 ] </ref> to improve efficiency, without noticeably affecting the remainder of the system. 3 The Basic Theory Revision Algorithm This section details Either's method for modifying leaf rules, which are rules whose antecedents include an observable or an intermediate concept that is not the consequent of any existing rule. <p> Clearly, the bottlenecks are the calculation of the partial proofs and possible proofs. In the case of the partial proofs, heuristic methods are available for improving the efficiency of abduction by 7 EXPERIMENTAL RESULTS 26 using beam search to explore only the k partial proofs with the fewest assumptions <ref> [ 31 ] </ref> . In addition, reducing the number of partial proofs would directly impact the minimum antecedent cover calculations at the potential cost of increasing the size of the eventual cover. Computing all possible proofs remains an exponential problem.
Reference: [32] <author> D. Ourston. </author> <title> Using Explanation-Based and Empirical Methods in Theory Revision. </title> <type> PhD thesis, </type> <institution> University of Texas, Austin, TX, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: analyzes Either's ability to converge to a correct hypothesis given sufficient number of examples and evaluates the computational complexity of the revision algorithm. 6.1 Convergence Results The Either algorithm has been analyzed within the context of PAC (Probably Approximately Correct) learnability theory [ 47 ] , with details presented in <ref> [ 32 ] </ref> . In summary, we can apply the following result (Theorem 4.4) from [ 17 ] : Let H be a hypothesis space and L be a learning algorithm that uses H consistently (see definition below). <p> A detailed argument that Either uses this hypothesis space consistently is given in <ref> [ 32 ] </ref> . The argument hinges on the fact that the algorithm finds a cover of rules for fixing all of the failing examples for both generalization and specialization and that these two processes do not interfere with each other. <p> No other existing theory revision system guarantees consistency with the training examples, which means they cannot claim PAC convergence. In practice, other systems may converge to local minima and miss the correct concept altogether. 6.2 Computational Complexity Table 1 summarizes the results of the complexity analysis from <ref> [ 32 ] </ref> . In the table, n refers to the number of input examples, s refers to the size of the input theory, and b refers to the average number of rules for a concept (disjunctive branching factor). <p> The results from both of these domains is discussed in the remainder of this section. Further information on these tests, including the actual initial and revised theories, is given in <ref> [ 32 ] </ref> . 7.1 DNA Results Either was first tested on a theory for recognizing biological concepts in DNA sequences. The original theory is described in [ 46 ] , it contains 11 rules with a total of 76 propositional symbols. <p> The examples used in the tests consisted of 53 positive and 53 negative examples assembled from the biological literature. The initial theory classified none of the positive examples 8 Incomplete covering was originally developed to deal with noisy data as discussed in <ref> [ 27; 32 ] </ref> 7 EXPERIMENTAL RESULTS 27 and all of the negative examples correctly, thus indicating that the initial theory was entirely overly specific. In each test, classification accuracy was measured using twenty-six disjoint test examples.
Reference: [33] <author> D. Ourston and R. J. Mooney. </author> <title> Improving shared rules in multiple category domain theories. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 534-538, </pages> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: For example, if the system is trained only on cups the system can improve its classification performance on pots and pans by modifying its shared sub-theory for graspability. Empirical results on cross-category transfer in Either are reported in <ref> [ 33 ] </ref> . Because of these considerations, Either initially starts with leaf rules and only modifies higher-level rules if necessary 6 . If the rules in the initial cover have no overlapping examples, then no changes to higher-level rules are required.
Reference: [34] <author> M. Pazzani and C. Brunk. </author> <title> Detecting and correcting errors in rule-based expert systems: An integration of empirical and explanation-based learning. </title> <booktitle> In Proceedings of the 5th Knowledge Acquisition for Knowledge-Based Systems Workshop, </booktitle> <address> Banff, Canada, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: Also, the original Focl system does not revise the underlying domain theory. Kr-Focl is a recent theory-revision version <ref> [ 34 ] </ref> ; however, it requires direct interaction with the user to determine which part of the theory to modify instead of using the complexity of the required change. Finally, Focl cannot guarantee consistency with the training data since it uses hill-climbing and may encounter local maxima.
Reference: [35] <author> M. Pazzani, C. Brunk, and G. Silverstein. </author> <title> A knowledge-intensive approach to learning relational concepts. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 432-436, </pages> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Many systems do not revise the theory itself but instead revise the operational definition of a concept <ref> [ 2; 18; 35 ] </ref> . Still other systems rely on active experimentation rather than a provided training set to detect and correct errors [ 39 ] . <p> Finally, previous systems do not have Either's modularity and therefore cannot easily take advantage of advances in the individual areas of deduction, abduction, and induction. 8 RELATED RESEARCH 31 Rtls [ 14 ] , Kbann [ 46 ] , Focl <ref> [ 35 ] </ref> , and Ductor [ 4 ] are theory revision systems that come the closest to handling as many types of imperfections as Either. Each of these systems is discussed in more detail below.
Reference: [36] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Research in machine learning attempts to solve the knowledge acquisition problem by developing systems that automatically acquire the requisite knowledge from experience. However, empirical learning systems <ref> [ 36; 22; 41 ] </ref> do not take significant advantage of existing domain knowledge and explanation-based learning systems [ 8; 25 ] require a complete and correct domain theory. <p> In both cases, Either uses the output of abduction and deduction to determine an appropriately labeled subset of the training examples to pass to induction in order to form a consistent correction. Either currently uses a version of Id3 <ref> [ 36 ] </ref> as its inductive component. The decision trees returned by Id3 are translated into equivalent Horn-clause rules [ 37 ] . The remaining components of the Either system constitute generalization and specialization control algorithms, which identify and specify the types of corrections to be made to the theory.
Reference: [37] <author> J. R. Quinlan. </author> <title> Generating production rules from decision trees. </title> <booktitle> In Proceedings of the Tenth International Joint conference on Artificial intelligence, </booktitle> <pages> pages 304-307, </pages> <address> Milan, Italy, </address> <month> Aug </month> <year> 1987. </year>
Reference-contexts: Either currently uses a version of Id3 [ 36 ] as its inductive component. The decision trees returned by Id3 are translated into equivalent Horn-clause rules <ref> [ 37 ] </ref> . The remaining components of the Either system constitute generalization and specialization control algorithms, which identify and specify the types of corrections to be made to the theory. One of the main advantages of the Either architecture is its modularity. <p> The extra (not (has-handle)) antecedent on the second rule is a side-effect of translating Id3 decision trees into rules. It does not effect the semantics of the new concept and could be deleted using the sort of rule simplification methods discussed in <ref> [ 37 ] </ref> . 6 Analysis This section analyzes Either's ability to converge to a correct hypothesis given sufficient number of examples and evaluates the computational complexity of the revision algorithm. 6.1 Convergence Results The Either algorithm has been analyzed within the context of PAC (Probably Approximately Correct) learnability theory [
Reference: [38] <author> J.R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Finally, as discussed in Section 7.1, Kbann is not focussed on minimally changing the existing theory. Focl (First-Order Combined Learner) is a hybrid system that uses Foil <ref> [ 38 ] </ref> as its inductive component. It is capable of handling both incomplete and incorrect first-order Horn-clause theories. Focl is based on the process of operationalization using a technique similar to that employed in Ml-smart [ 2 ] . <p> Many ideas from Either are currently being incorporated in a new system, Forte [ 40 ] , which can revise theories expressed using first-order Horn clauses. Forte also incorporates many ideas from the work on Foil <ref> [ 38 ] </ref> and inverse resolution [ 29 ] . A fourth shortcoming in Either's knowledge representation is an inability to revise probabilistic rules. Many existing expert rule bases employ some form of probabilistic reasoning.
Reference: [39] <author> S. A. Rajamoney. </author> <title> A computational approach to theory revision. </title> <editor> In J. Shrager and P. Langley, editors, </editor> <booktitle> Computational Models of Scientific Discovery and Theory Formation, </booktitle> <pages> pages 225-254. </pages> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] . Still other systems rely on active experimentation rather than a provided training set to detect and correct errors <ref> [ 39 ] </ref> . <p> In addition, case-based reasoning has been shown to be an effective adjunct to a rule-based system for exception processing [ 16 ] . Finally, when insufficient training data is available, some form of active knowledge acquisition, like experimentation, is required <ref> [ 39 ] </ref> . In each of these cases, using the basic Either algorithm to focus the knowledge acquisition should improve both comprehensibility and accuracy.
Reference: [40] <author> B. Richards and R. J. Mooney. </author> <title> First-order theory revision. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 447-451, </pages> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: A third obvious limitation is Either's restriction to propositional Horn clauses. This prevents the system from applying to domains requiring structural descriptions or relational predicates. Many ideas from Either are currently being incorporated in a new system, Forte <ref> [ 40 ] </ref> , which can revise theories expressed using first-order Horn clauses. Forte also incorporates many ideas from the work on Foil [ 38 ] and inverse resolution [ 29 ] . A fourth shortcoming in Either's knowledge representation is an inability to revise probabilistic rules.
Reference: [41] <author> D. E. Rumelhart, G. E. Hinton, and J. R. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> Vol. I, </volume> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <note> REFERENCES 38 </note>
Reference-contexts: Research in machine learning attempts to solve the knowledge acquisition problem by developing systems that automatically acquire the requisite knowledge from experience. However, empirical learning systems <ref> [ 36; 22; 41 ] </ref> do not take significant advantage of existing domain knowledge and explanation-based learning systems [ 8; 25 ] require a complete and correct domain theory. <p> This domain theory was also used to test the Kbann system [ 46 ] , which translates the initial theory into an equivalent neural net, and then applies the backpropagation algorithm <ref> [ 41 ] </ref> to revise the network. Kbann performs somewhat better in this domain than Either (a test accuracy of 92% with 105 training examples). <p> Kbann (Knowledge-based Artificial Neural Networks) is an approach to theory refinement that uses the backpropagation algorithm for multi-layer neural networks <ref> [ 41 ] </ref> as a method for correcting a domain theory. The technique first translates the existing domain theory into an equivalent neural network, then refines the weights in the network to fit the training examples. It then re-translates the corrected network into an approximately equivalent set of rules.
Reference: [42] <editor> A. Segre, editor. </editor> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning: Section on Combining Empirical and Explanation-Based Learning, </booktitle> <address> Ithaca, NY, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Consequently, a number of recent research projects have focused on integrating these two basic approaches to machine learning <ref> [ 42; 3 ] </ref> .
Reference: [43] <author> M. E. Stickel. </author> <title> A prolog-like inference system for computing minimum-cost abductive explanations in natural-language interpretation. </title> <type> Technical Report Technical Note 451, </type> <institution> SRI International, </institution> <address> Menlo Park, CA, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: The assumptions A are said to explain the observation. Legal assumptions are frequently restricted, such as allowing only instances of certain predicates (predicate specific abduction) or requiring that assumptions not be provable from more basic assumptions (most-specific abduction) <ref> [ 43 ] </ref> . In order to focus on leaf rules, Either's abductive component backchains as far as possible before making an assumption (most-specific abduction). The consistency constraint is removed in order to allow assumptions to be viewed as antecedent retractions.
Reference: [44] <author> G. D. Tecuci and R. S. Michalski. </author> <title> A method for multistrategy task-adaptive learning based on plausible justifications. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 549-553, </pages> <address> Evanston, IL, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Some previous systems are only capable of generalizing an overly specific theory <ref> [ 49; 7; 48; 44 ] </ref> while others are only capable of specializing an overly general theory [ 12; 26; 6 ] . Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] .
Reference: [45] <author> G. Towell and J. Shavlik. </author> <title> Refining symbolic knowledge using neural networks. </title> <booktitle> In Proceedings of the International Workshop on Multistrategy Learning, </booktitle> <address> Harper's Ferry, W.Va., </address> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Finally, it should be noted that when Kbann translated its results into Horn clauses, the resulting theory was significantly more complicated than Either's <ref> [ 45 ] </ref> .
Reference: [46] <author> G. G. Towell, J. W. Shavlik, and Michiel O. Noordewier. </author> <title> Refinement of approximate domain theories by knowledge-based artificial neural networks. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pages 861-866, </pages> <address> Boston, MA, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Further information on these tests, including the actual initial and revised theories, is given in [ 32 ] . 7.1 DNA Results Either was first tested on a theory for recognizing biological concepts in DNA sequences. The original theory is described in <ref> [ 46 ] </ref> , it contains 11 rules with a total of 76 propositional symbols. The purpose of the theory is to recognize promoters in strings of nucleotides. A promoter is a genetic region which initiates the first step in the expression of an adjacent gene (transcription). <p> This indicates that the original concept that promoter sequences are indicated by particular nucleotide configurations within certain regions of the nucleotide chain were valid, although the original rules themselves were overly-specific. This domain theory was also used to test the Kbann system <ref> [ 46 ] </ref> , which translates the initial theory into an equivalent neural net, and then applies the backpropagation algorithm [ 41 ] to revise the network. Kbann performs somewhat better in this domain than Either (a test accuracy of 92% with 105 training examples). <p> Finally, previous systems do not have Either's modularity and therefore cannot easily take advantage of advances in the individual areas of deduction, abduction, and induction. 8 RELATED RESEARCH 31 Rtls [ 14 ] , Kbann <ref> [ 46 ] </ref> , Focl [ 35 ] , and Ductor [ 4 ] are theory revision systems that come the closest to handling as many types of imperfections as Either. Each of these systems is discussed in more detail below. <p> A more general approach would be to provide a variety of inductive learners, where the selection of a particular algorithm is dictated by the current problem. For example, it has been shown that neural networks are particularly suitable for learning concepts involving N out of M functions <ref> [ 46 ] </ref> . In addition, case-based reasoning has been shown to be an effective adjunct to a rule-based system for exception processing [ 16 ] . Finally, when insufficient training data is available, some form of active knowledge acquisition, like experimentation, is required [ 39 ] .
Reference: [47] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: [ 37 ] . 6 Analysis This section analyzes Either's ability to converge to a correct hypothesis given sufficient number of examples and evaluates the computational complexity of the revision algorithm. 6.1 Convergence Results The Either algorithm has been analyzed within the context of PAC (Probably Approximately Correct) learnability theory <ref> [ 47 ] </ref> , with details presented in [ 32 ] . In summary, we can apply the following result (Theorem 4.4) from [ 17 ] : Let H be a hypothesis space and L be a learning algorithm that uses H consistently (see definition below).
Reference: [48] <author> B. L. Whitehall. </author> <title> Knowledge-Based Learning: An Integration of Deductive and Inductive Learning for Knowledge Base Completion. </title> <type> PhD thesis, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> Oct </month> <year> 1990. </year> <note> Also appears as Technical Report UILU-ENG-90-1776. </note>
Reference-contexts: Some previous systems are only capable of generalizing an overly specific theory <ref> [ 49; 7; 48; 44 ] </ref> while others are only capable of specializing an overly general theory [ 12; 26; 6 ] . Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] .
Reference: [49] <author> D. C. Wilkins. </author> <title> Knowlege base refinement using apprenticeship learning techniques. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pages 646-651, </pages> <address> St. Paul, MN, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Some previous systems are only capable of generalizing an overly specific theory <ref> [ 49; 7; 48; 44 ] </ref> while others are only capable of specializing an overly general theory [ 12; 26; 6 ] . Many systems do not revise the theory itself but instead revise the operational definition of a concept [ 2; 18; 35 ] .
Reference: [50] <author> P. H. Winston, T. O. Binford, B. Katz, and M. Lowry. </author> <title> Learning physical descriptions from functional definitions, examples, and precedents. </title> <booktitle> In Proceedings of National Conference on Artificial Intelligence, </booktitle> <pages> pages 433-439, </pages> <address> Washington, D.C., </address> <month> Aug </month> <year> 1983. </year>
Reference-contexts: When the initial theory is empty, the problem reduces to that of finding a minimal Horn-clause theory for a set of examples. A sample theory suitable for Either is a version of the cup theory <ref> [ 50 ] </ref> shown in for illustrative purposes. Figure 2 shows six examples that are consistent with this theory, three positive examples of cup and three negative examples. Each example is described in terms of twelve observable features.
References-found: 50

