URL: http://www.cs.pitt.edu/~gupta/research/Comp/ftwk.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/dm.html
Root-URL: 
Title: Replicating Statement Execution for Fault Detection on Distributed Memory Multiprocessors  
Author: Chun Gong, Rami Melhem and Rajiv Gupta 
Address: Pittsburgh Pittsburgh, PA 15260  
Affiliation: Department of Computer Science The University of  
Abstract: A compiler-assisted methodology is proposed for fault detection on distributed-memory systems. Selected instances of program statements are replicated in a way that ensures appropriate coverage. Replication strategies for the detection of permanent and transient faults are presented. These strategies use idle processor times for replicating statement execution, whenever possible. Two approaches are also discussed for implementing the proposed strategies on single program, multiple data (SPMD) parallel execution platforms. The first approach replicates program statements through source-to-source program transformations while the second approach achieves the repli cation of program statements indirectly by replicating data on multiple processors.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alewine, S. Chen, C. Li, W. Fuchs, and W. Hwu. </author> <title> Branch recovery with compiler-assisted multiple instruction retry. </title> <booktitle> In The 22nd Annual International Symposium on Fault-Tolerant Computing, </booktitle> <year> 1992. </year>
Reference-contexts: This has resulted in the development of techniques that achieve fault detection by replicating computations and comparing the results of these computations [7] [15]. Ideally by utilizing the spare capacity of the system to execute replicated computations, fault detection and tolerance can be achieved at a minimal cost. In <ref> [1] </ref>, the authors develop a compiler-assisted scheme to enable a process to quickly recover from transient faults, and in [4], the authors present a method that utilizes the VLIW compiler to schedule redundant operations on idle functional units for fault detection purposes.
Reference: [2] <author> J.M. Anderson and M.S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN Conf. on Programming Language Design and Implementation, </booktitle> <year> 1993. </year>
Reference-contexts: Thus, the function is defined at statement level rather than loop iteration level. 3. The compiler automatically selects : Heuristics are developed to select in conjunction with data distribution. The goal of the heuristic is to balance parallelism and communication so as to achieve good performance <ref> [2] </ref>. A computation C is considered to be data parallel for a given data distribution and scheduling function if it can be executed in parallel by the processors in three distinct steps: operand communication, computation, and result communication.
Reference: [3] <author> V. Balasubramanian and P. Banerjee. </author> <title> Compiler-assisted synthesis of algorithm-based checking in multiprocessors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 39, </volume> <month> 4 </month> <year> 1990. </year>
Reference-contexts: In [12], compiler techniques are used to insert checkpoints into a program so that both the desired checkpoint intervals and reproducible locations are maintained. In <ref> [3] </ref>, the authors describe a source-to-source restructuring compiler for the synthesis of low-cost checks for numerical programs using the notion of algorithm-based checking. Replication of computations has been carried out at various levels of granularity. <p> This approach allows the compiler to utilize idle resources for fault detection purposes and it is applicable to both permanent and transient faults. It differs from the approach of <ref> [3] </ref> in that it presents a systematic approach to utilizing the spare processors' capacity for introducing redundancy in distributed memory environments.
Reference: [4] <author> D. Blough and A. Nicolau. </author> <title> Fault tolerance in super-scalar and vliw processors. </title> <booktitle> In IEEE Workshop on Fault-Tolerant Parallel and Distributed Systems. IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: Ideally by utilizing the spare capacity of the system to execute replicated computations, fault detection and tolerance can be achieved at a minimal cost. In [1], the authors develop a compiler-assisted scheme to enable a process to quickly recover from transient faults, and in <ref> [4] </ref>, the authors present a method that utilizes the VLIW compiler to schedule redundant operations on idle functional units for fault detection purposes. In [12], compiler techniques are used to insert checkpoints into a program so that both the desired checkpoint intervals and reproducible locations are maintained.
Reference: [5] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> The Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <year> 1988. </year>
Reference-contexts: Our approach also provides a means for analyzing the resulting overhead. 1 When a shared name space is used for programming distributed memory machines, the compiler typically translates the shared memory program into one that executes under the single-program, multiple-data (SPMD) execution model <ref> [5] </ref>. Under SPMD, the same program is distributed to all processors, and each statement or statement instance in the program is either executed on all the processors or is executed on only one processor. <p> Similar transformations may be applied to implement the transient fault detection strategy of Figure 4. 4.2 Duplication through Owner-computes Implementation The owner computes rule is a powerful approach to compile SPMD programs for distributed-memory systems <ref> [5] </ref> [11] [14]. This approach uses the data distribution, ff, to specify the scheduling function .
Reference: [6] <institution> Cm fortran user's guide for the cm-5. Thinking Machines, </institution> <year> 1992. </year>
Reference-contexts: The user specifies : Languages such as Kali and the CRAY T3D Fortran [13] allow the specification of for scheduling of loop iterations on specific processors [11]. 2. The compiler uses to follow the "owner computes rule": In compilers for languages such as the Fortran D and CM Fortran <ref> [6] </ref>, is chosen such that each statement is executed by the processor that owns the variable whose value is being computed [10]. Thus, the function is defined at statement level rather than loop iteration level. 3.
Reference: [7] <author> A. Dahbura, K. Sabnani, and W. Hery. </author> <title> Spare capacity as a means of fault detection and diagnosis in multiprocessor systems. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 38, </volume> <month> 6 </month> <year> 1989. </year>
Reference-contexts: Recently, it has been realized that the computing power of a multiprocessor system is rarely completely used. This has resulted in the development of techniques that achieve fault detection by replicating computations and comparing the results of these computations <ref> [7] </ref> [15]. Ideally by utilizing the spare capacity of the system to execute replicated computations, fault detection and tolerance can be achieved at a minimal cost.
Reference: [8] <author> C. Gong, R. Melhem, and R. Gupta. </author> <title> Compiler assisted fault detection for distributed-memory systems. </title> <booktitle> Proc. of SHPCC, Scalable High Performance Computing Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Hence, for a statement, S of the form A = f (d 1 ; : : : ; d n ), the mapping function is given by r (S) = ff r (A). Detailed implementations of this duplication technique are given in <ref> [8] </ref>. These implementations are obtained by modifying the communicator modules that exchange data between owners and consumers during SPMD execution. Replicated execution of computation instance i in a loop is achieved through data ownership replication. <p> We have analyzed, in some details, the application of the methodology to a general class of parallel loops and we have discussed two different methods for duplicating com putation instances. The details of implementing the two methods are presented in <ref> [8] </ref> and [9], respectively, along with experimental results showing that the duplication overhead is, in general, relatively low. We are currently studying efficient replication strategies for program constructs that are more general than the loops considered in this paper.
Reference: [9] <author> C. Gong, R. Melhem, and R. Gupta. </author> <title> Loop transformation for fault detection on massively parallel systems. </title> <type> Technical Report 94-39, </type> <institution> Department of Computer Science, The University of Pittsburgh, </institution> <year> 1994. </year>
Reference-contexts: We have analyzed, in some details, the application of the methodology to a general class of parallel loops and we have discussed two different methods for duplicating com putation instances. The details of implementing the two methods are presented in [8] and <ref> [9] </ref>, respectively, along with experimental results showing that the duplication overhead is, in general, relatively low. We are currently studying efficient replication strategies for program constructs that are more general than the loops considered in this paper.
Reference: [10] <author> S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, and C. Tseng. </author> <title> An overview of the fortran d programming system. </title> <booktitle> In Proc. of the Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <year> 1991. </year>
Reference-contexts: The compiler uses to follow the "owner computes rule": In compilers for languages such as the Fortran D and CM Fortran [6], is chosen such that each statement is executed by the processor that owns the variable whose value is being computed <ref> [10] </ref>. Thus, the function is defined at statement level rather than loop iteration level. 3. The compiler automatically selects : Heuristics are developed to select in conjunction with data distribution. The goal of the heuristic is to balance parallelism and communication so as to achieve good performance [2].
Reference: [11] <author> C. Koelbel, P. Mehrotra, and J. Rosendale. </author> <title> Supporting shared data structure on distributed memory architectures. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, </booktitle> <pages> pages 177-186. </pages> <booktitle> SIGPLAN, ACM, </booktitle> <year> 1990. </year>
Reference-contexts: The following methods are commonly used to specify . 1. The user specifies : Languages such as Kali and the CRAY T3D Fortran [13] allow the specification of for scheduling of loop iterations on specific processors <ref> [11] </ref>. 2. The compiler uses to follow the "owner computes rule": In compilers for languages such as the Fortran D and CM Fortran [6], is chosen such that each statement is executed by the processor that owns the variable whose value is being computed [10]. <p> Similar transformations may be applied to implement the transient fault detection strategy of Figure 4. 4.2 Duplication through Owner-computes Implementation The owner computes rule is a powerful approach to compile SPMD programs for distributed-memory systems [5] <ref> [11] </ref> [14]. This approach uses the data distribution, ff, to specify the scheduling function .
Reference: [12] <author> J. Long, W. Fuchs, and J. Abraham. </author> <title> Compiler-assisted static checkpoint insertion. </title> <booktitle> In The 22nd Annual International Symposium on Fault-Tolerant Computing, </booktitle> <year> 1992. </year>
Reference-contexts: In [1], the authors develop a compiler-assisted scheme to enable a process to quickly recover from transient faults, and in [4], the authors present a method that utilizes the VLIW compiler to schedule redundant operations on idle functional units for fault detection purposes. In <ref> [12] </ref>, compiler techniques are used to insert checkpoints into a program so that both the desired checkpoint intervals and reproducible locations are maintained. In [3], the authors describe a source-to-source restructuring compiler for the synthesis of low-cost checks for numerical programs using the notion of algorithm-based checking.
Reference: [13] <author> T. MacDonald, D. Pase, and A. Meltzer. </author> <title> Addressing in cray research's mpp fortran. </title> <booktitle> Third Workshop on Compilers for parallel Computers, </booktitle> <year> 1992. </year>
Reference-contexts: For each instance S j of a private statement, S, the function (S j ) identifies the processor that will execute S j . The following methods are commonly used to specify . 1. The user specifies : Languages such as Kali and the CRAY T3D Fortran <ref> [13] </ref> allow the specification of for scheduling of loop iterations on specific processors [11]. 2.
Reference: [14] <author> M. Quinn and P. Hatcher. </author> <title> Compiling simd programs for mimd architecthres. </title> <booktitle> In Proceedings of International Conference on Computer Languages, </booktitle> <pages> pages 291-296, </pages> <year> 1990. </year>
Reference-contexts: Similar transformations may be applied to implement the transient fault detection strategy of Figure 4. 4.2 Duplication through Owner-computes Implementation The owner computes rule is a powerful approach to compile SPMD programs for distributed-memory systems [5] [11] <ref> [14] </ref>. This approach uses the data distribution, ff, to specify the scheduling function .
Reference: [15] <author> S. Tridandapani and A. Somani. </author> <title> Efficient utilization of spare capacity for fault detection and location in multiprocessor systems. </title> <booktitle> In International Symposium on Fault-Tolerant Computing. IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: Recently, it has been realized that the computing power of a multiprocessor system is rarely completely used. This has resulted in the development of techniques that achieve fault detection by replicating computations and comparing the results of these computations [7] <ref> [15] </ref>. Ideally by utilizing the spare capacity of the system to execute replicated computations, fault detection and tolerance can be achieved at a minimal cost.
References-found: 15

