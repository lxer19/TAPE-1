URL: http://robotics.eecs.berkeley.edu/~emiris/papers/focs91journal.ps.gz
Refering-URL: http://robotics.eecs.berkeley.edu/~emiris/
Root-URL: 
Title: A GENERAL APPROACH TO REMOVING DEGENERACIES  
Author: IOANNIS Z. EMIRIS AND JOHN F. CANNY 
Keyword: Key words. Input degeneracy, ill-conditioned problems, symbolic perturbation, infinitesimals, randomization, determinants, roots of polynomials, algorithmic complexity  
Note: AMS subject classifications. 68Q10, 68Q20, 68Q25, 68U05  
Abstract: We wish to increase the power of an arbitrary algorithm designed for non-degenerate input, by allowing it to execute on all inputs. We concentrate on infinitesimal symbolic perturbations that do not affect the output for inputs in general position. Otherwise, if the problem mapping is continuous, the input and output space topology are at least as coarse as the real euclidean one and the output space is connected, then our perturbations make the algorithm produce an output arbitrarily close or identical to the correct one. For a special class of algorithms, which includes several important algorithms in computational geometry, we describe a deterministic method that requires no symbolic computation. Ignoring polylogarithmic factors, this method increases only the worst-case bit complexity by a multiplicative factor which is linear in the dimension of the geometric space. For general algorithms, a randomized scheme with arbitrarily high probability of success is proposed; the bit complexity is then bounded by a small-degree polynomial in the original worst-case complexity. In addition to being simpler than previous ones, these are the first efficient perturbation methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. E. Hopcroft and J. D. Ullman, </author> <title> The Design and Analysis of Computer Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: Model of computation. Our results hold for any infinite ordered field, yet we present them in terms of the reals R. We choose the real-arithmetic Random Access Machine (RAM) as our model; it is described in [18] and is a more powerful version of the simple RAM defined in <ref> [1] </ref>. An input of size N consists of a finite real vector x = (x 1 ; : : : ; x N ) and a particular input instance is a = (a 1 ; : : : ; a N ) 2 R N . <p> For integers of size b, addition and subtraction have cost O (b), while the cost of multiplication and division, due to an algorithm by Schonhage and Strassen is O (b log b log log b), <ref> [1] </ref>. For rationals, the Greatest Common Divisor (GCD) is factored out at every arithmetic operation, and finding it takes O (b log 2 b log log b) time, [1]. <p> the cost of multiplication and division, due to an algorithm by Schonhage and Strassen is O (b log b log log b), <ref> [1] </ref>. For rationals, the Greatest Common Divisor (GCD) is factored out at every arithmetic operation, and finding it takes O (b log 2 b log log b) time, [1]. Let M (b) = O (b log 2 b log log b) bound the bit complexity of any operation on two rational numbers, each represented by a pair of O (b)-bit integers. <p> Suppose that each finite field Z q is defined by a constant-size prime integer q which can be obtained in constant time from an existing and sufficiently long list of primes. Following the exposition in <ref> [1] </ref>, the first stage consists of mapping each matrix element into its k residues, the second stage performs the particular computation in k different finite fields and the third stage applies the Chinese Remainder Theorem to find the answer from its k residues. <p> Proof. Each operation in f+; ; fi; =g involves multiplication of *-polynomials and a Greatest Common Divisor computation to reduce to lowest terms so that the degree bound D is observed. The multiplication takes time O (D log D) and the GCD O (D log 2 D), <ref> [1] </ref>. Branching instructions must find the lowest non-vanishing term in the corresponding *-polynomial, which takes O (D) time. Degree D cannot be bounded in general by a polynomial in the algebraic complexity, which implies that the perturbation may be prohibitively expensive under the algebraic model.
Reference: [2] <author> L. Blum, M. Shub and S. Smale, </author> <title> On a theory of computation and complexity over the real numbers: NP-completeness, recursive functions and universal machines, </title> <journal> Bull. Amer. Math. Soc., </journal> <volume> 21 (1989), </volume> <pages> pp. 1-46. </pages>
Reference-contexts: In Section 5 we shall require an extension of the model, namely that there exists an explicit finite integer bound D on the total degree in x of any polynomial computed in the course of the program. The concept of this bound appears in the Machine of <ref> [2] </ref> and in the algebraic decision tree of [18]. Under the algebraic model, the worst-case complexity of an algorithm equals the maximum number of arithmetic operations, branching and memory access instructions REMOVING DEGENERACIES 3 executed on any input.
Reference: [3] <author> J. Bochnak, M. Coste and M. F. Roy, </author> <title> Geometrie Algebrique Reelle, </title> <journal> Ergebnisse der Math-ematik 3, </journal> <volume> No. 12, </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: Infinitesimals. Our approach in removing degeneracies is to add to the input values arbitrarily small quantities. To this effect we make use of infinitesimals. The process of extending the field of reals by an infinitesimal is a classical technique, formalized in <ref> [3] </ref>, and used by the second author in [4]. Definition 2.1. We call * infinitesimal with respect to R if the extension R (*) is ordered so that * is positive but smaller than any positive element of R.
Reference: [4] <author> J. F. Canny, </author> <title> Computing roadmaps of semi-algebraic sets, </title> <booktitle> Proc. 9th Symp. on Applied Algebra, Algebraic Algorithms and Error-Corr. Codes, Lecture Notes in Computer Science, </booktitle> <volume> No. 539, </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991, </year> <pages> pp. 94-107. </pages>
Reference-contexts: Infinitesimals. Our approach in removing degeneracies is to add to the input values arbitrarily small quantities. To this effect we make use of infinitesimals. The process of extending the field of reals by an infinitesimal is a classical technique, formalized in [3], and used by the second author in <ref> [4] </ref>. Definition 2.1. We call * infinitesimal with respect to R if the extension R (*) is ordered so that * is positive but smaller than any positive element of R. Clearly, the sign of any polynomial in * is the sign of the non-zero term of lowest degree. <p> The interesting feature of their technique is that it controls the direction of perturbation. In particular, since the facet structure is given, the polytope vertices are forced to be perturbed outward. In a slightly different vein, Canny used a structural perturbation in <ref> [4] </ref> to ensure that the input semi-algebraic sets are in general position. One immediate application is to motion-planning algorithms, where these sets describe obstacles or prohibited space. The perturbation preserves emptiness and number of connected components of the original sets by using sequences or towers of infinitesimals.
Reference: [5] <author> D. Coppersmith and S. Winograd, </author> <title> Matrix multiplication via arithmetic progressions, </title> <journal> J. Symb. Comput., </journal> <volume> 9 (1990), </volume> <pages> pp. 251-280. </pages>
Reference-contexts: We now prove the efficiency of this approach. Let MM (k) denote the number of multiplications and divisions needed to multiply two k fi k matrices, which is currently O (k 2:376 ) <ref> [5] </ref>. Lemma 4.3. Computing the sign of perturbed determinants detfl d+1 (*) and det d (*) can be done in O (MM (d) log d) arithmetic steps. Proof.
Reference: [6] <author> G. B. Dantzig, </author> <title> Linear Programming and Extensions, </title> <publisher> Princeton University Press, Princeton, </publisher> <year> 1963. </year>
Reference-contexts: Random perturbations are frequently alluded to and one such scheme is studied in this article. Their main feature is that they trade randomness for efficiency. Symmetry breaking rules in Linear Programming are the earliest systematic approaches to the problem. Dantzig presents such a method in <ref> [6] </ref> which relies on an infinitesimal *. Consider a Linear Program reduced to finding non-negative values for the m + n variables x j , such that the sum of all slack variables P m+n j&gt;n x j is minimized.
Reference: [7] <author> J. H. Davenport, Y. Siret and E. Tournier, </author> <title> Computer Algebra, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1988. </year>
Reference-contexts: The first and third stages have both bit complexity O (M (k) log k) while that of the second stage depends on the computation performed. The modular method is applicable to rational inputs with the same asymptotic complexity <ref> [7] </ref>. Let s be the maximum bit size of any input parameter with s = (log n), since we have assumed that a constant fraction of input points are distinct. Theorem 4.4.
Reference: [8] <author> K. Dobrindt, K. Mehlhorn and M. Yvinec, </author> <title> A complete framework for the intersection of a general polyhedron with a convex one, </title> <booktitle> Proc. 3rd Workshop Algorithms Data Struct., Lecture Notes in Computer Science, </booktitle> <volume> No. 709, </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993, </year> <pages> pp. 314-324. </pages>
Reference-contexts: The post-processing necessary to recover the exact answer is usually a very case-specific process. We discuss the case of convex hulls at the end of Section 4 and also refer the reader to [21], [12] and <ref> [8] </ref>. 3. Other Work. The most naive approach is to handle each special case separately, which is tedious for implementors and unattractive for theoreticians. Random perturbations are frequently alluded to and one such scheme is studied in this article. Their main feature is that they trade randomness for efficiency. <p> On the average, only a few partial 8 I. Z. EMIRIS AND J. F. CANNY derivatives will have to be evaluated, but at worst, all of them have to be computed and the complexity is (m n ). Dobrindt, Mehlhorn and Yvinec <ref> [8] </ref> studied the problem of intersecting an arbitrary polytope with a convex one in three dimensions, proposed an efficient perturbation and discussed post-processing in this context. The interesting feature of their technique is that it controls the direction of perturbation.
Reference: [9] <author> H. Edelsbrunner, </author> <title> Edge-skeletons in arrangements with applications, </title> <journal> Algorithmica, </journal> <volume> 1 (1986), </volume> <pages> pp. 93-109. </pages> <booktitle> [10] , Algorithms in Combinatorial Geometry, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1987. </year>
Reference-contexts: Edelsbrunner and Mucke systematize in [12] a scheme called Simulation of Simplicity (SoS for short), already presented in <ref> [9] </ref>, [11], [13] and [10]. It applies to algorithms that accept n input objects, each specified by d parameters, and whose tests are determinants in the nd parameters, just as our deterministic perturbation (1) of the next section.
Reference: [11] <author> H. Edelsbrunner and L. J. Guibas, </author> <title> Topologically sweeping an arrangement, </title> <booktitle> Proc. 18th ACM Symp. on Theory of Computing, </booktitle> <year> 1986, </year> <pages> pp. 389-403. </pages>
Reference-contexts: Edelsbrunner and Mucke systematize in [12] a scheme called Simulation of Simplicity (SoS for short), already presented in [9], <ref> [11] </ref>, [13] and [10]. It applies to algorithms that accept n input objects, each specified by d parameters, and whose tests are determinants in the nd parameters, just as our deterministic perturbation (1) of the next section. <p> In a dual setting, such as in <ref> [11] </ref>, the input objects are hyperplanes in (d 1)- dimensional space and the test indicates on which side of the first hyperplane lies the intersection of the other d 1 hyperplanes.
Reference: [12] <author> H. Edelsbrunner and E. P. M ucke, </author> <title> Simulation of simplicity: A technique to cope with degenerate cases in geometric algorithms, </title> <journal> ACM Trans. Graphics, </journal> <volume> 9 (1990), </volume> <pages> pp. 67-104. </pages>
Reference-contexts: In this article we describe efficient methods for systematically removing such degeneracies using symbolic infinitesimal perturbations. Our methods apply to every algorithm that can be implemented on a real RAM. This work is influenced by the treatment of the problem in <ref> [12] </ref> and, in a more general context, [21]. The main contribution of this article is to introduce the first general and efficient perturbations from the viewpoint of worst-case complexity. Previous methods incurred an extra computational cost that was exponential in some parameter of the input size. <p> The post-processing necessary to recover the exact answer is usually a very case-specific process. We discuss the case of convex hulls at the end of Section 4 and also refer the reader to [21], <ref> [12] </ref> and [8]. 3. Other Work. The most naive approach is to handle each special case separately, which is tedious for implementors and unattractive for theoreticians. Random perturbations are frequently alluded to and one such scheme is studied in this article. <p> Edelsbrunner and Mucke systematize in <ref> [12] </ref> a scheme called Simulation of Simplicity (SoS for short), already presented in [9], [11], [13] and [10]. <p> Every v i is a positive integer less than or equal to d and for every i &lt; j, v i v j . In <ref> [12] </ref> every such vector is associated with a distinct minor that may have to be evaluated. This analysis pertains to fl matrices, to be defined in the next section. Matrices of the second kind, the matrices, require more steps in the worst case, for the same order. <p> This test is sometimes called the Orientation test, since it may be regarded as deciding the relative orientation of the d + 1 points in the sense of <ref> [12] </ref>. In fact, the column of ones should be rightmost, but it is a constant-time operation to obtain the orientation of the points from the sign of detfl d+1 .
Reference: [13] <author> H. Edelsbrunner and R. Waupotitsch, </author> <title> Computing a ham-sandwich cut in two dimensions, </title> <journal> J. Symb. Comput., </journal> <volume> 2 (1986), </volume> <pages> pp. 171-178. </pages>
Reference-contexts: Edelsbrunner and Mucke systematize in [12] a scheme called Simulation of Simplicity (SoS for short), already presented in [9], [11], <ref> [13] </ref> and [10]. It applies to algorithms that accept n input objects, each specified by d parameters, and whose tests are determinants in the nd parameters, just as our deterministic perturbation (1) of the next section.
Reference: [14] <author> I. Emiris and J. Canny, </author> <title> An efficient approach to removing geometric degeneracies, </title> <booktitle> Proc. 8th ACM Symp. on Computational Geometry, </booktitle> <year> 1992, </year> <pages> pp. 74-82. </pages>
Reference-contexts: In addition to its efficiency, this scheme is easy to implement, which makes it attractive for practical use <ref> [14] </ref>. The perturbation, although defined in terms of a symbolic infinitesimal variable, does not require any symbolic computation. <p> The perturbation preserves emptiness and number of connected components of the original sets by using sequences or towers of infinitesimals. Perturbation methods have been applied in other cases to eliminate degeneracies with respect to particular problems, as in [17] for instance. Lastly, Emiris and Canny in <ref> [14] </ref> extend the applicability of the deterministic perturbation introduced in this article to another two geometric branching tests, most importantly to the InSphere test. <p> We concentrate on two specific types of determinants that cover important algorithms, such as those computing Convex Hulls and Hyperplane Arrangements. Our approach can be applied to other types of determinants too, as demonstrated in <ref> [14] </ref>. Assume that the input parameters represent n input objects p 1 ; p 2 ; : : : p n , each specified by d parameters. <p> Both methods are characterized by their conceptual simplicity and are significantly faster than previous ones. Examining branching tests that come up in other geometric algorithms and trying to improve on efficiency are natural extensions to this work, partly fulfilled in <ref> [14] </ref>. It is also interesting to attempt extending the notion of degeneracy over finite fields, where the lack of order makes our definition of degeneracy invalid.
Reference: [15] <author> J. von zur Gathen, </author> <title> Algebraic complexity theory, </title> <booktitle> Annual Review of Computer Science, </booktitle> <volume> No. 3, </volume> <editor> J. Traub ed., </editor> <booktitle> Annual Reviews, </booktitle> <address> Palo Alto, </address> <year> 1988, </year> <pages> pp. 317-347. </pages>
Reference-contexts: Proof. The previous lemma proves the claim on the algebraic complexity since the original complexity of computing a d fi d determinant is fi (MM (d)) <ref> [15] </ref>. In what follows we concentrate without loss of generality to the Sidedness test. In the original setting, the worst-case bit size of the determinant is fi (ds) and using modular arithmetic requires k = fi (ds) distinct finite fields.
Reference: [16] <author> W. Keller-Gehrig, </author> <title> Fast algorithms for the characteristic polynomial, </title> <journal> Theor. Comp. Sci., </journal> <volume> 36 (1985), </volume> <pages> pp. 309-317. </pages>
Reference-contexts: Computing det (M * I d+1 ) or det (N * I d ) is a characteristic polynomial computation for which there exists an algorithm by Keller-Gehrig <ref> [16] </ref> requiring O (MM (d) log d) operations. This algorithm is purely numeric as it transforms matrix M or N respectively to a new matrix that contains the coefficients of the characteristic polynomial in the last column.
Reference: [17] <author> C. Monma, M. Paterson, S. Suri and F. Yao, </author> <title> Computing euclidean maximum spanning trees, </title> <booktitle> Proc. 4th ACM Symp. on Computational Geometry, </booktitle> <year> 1988, </year> <pages> pp. 241-251. </pages>
Reference-contexts: The perturbation preserves emptiness and number of connected components of the original sets by using sequences or towers of infinitesimals. Perturbation methods have been applied in other cases to eliminate degeneracies with respect to particular problems, as in <ref> [17] </ref> for instance. Lastly, Emiris and Canny in [14] extend the applicability of the deterministic perturbation introduced in this article to another two geometric branching tests, most importantly to the InSphere test.
Reference: [18] <author> F. P. Preparata and M. I. Shamos, </author> <title> Computational Geometry, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Preliminaries. 2.1. Model of computation. Our results hold for any infinite ordered field, yet we present them in terms of the reals R. We choose the real-arithmetic Random Access Machine (RAM) as our model; it is described in <ref> [18] </ref> and is a more powerful version of the simple RAM defined in [1]. <p> The concept of this bound appears in the Machine of [2] and in the algebraic decision tree of <ref> [18] </ref>. Under the algebraic model, the worst-case complexity of an algorithm equals the maximum number of arithmetic operations, branching and memory access instructions REMOVING DEGENERACIES 3 executed on any input. More realistically, we may wish to consider the effect of the operands' bit size on the speed of arithmetic operations.
Reference: [19] <author> J. T. Schwartz, </author> <title> Fast probabilistic algorithms for verification of polynomial identities, </title> <journal> J. ACM, </journal> <volume> 27 (1980), </volume> <pages> pp. 701-717. </pages>
Reference-contexts: The total number of polynomials appearing at the numerator or denominator of a branch expression is at most 2 3 T , where T is the maximum number of branches on any execution path. Schwartz's lemma <ref> [19] </ref> requires that the range of the random values contains at least as many values as the product of c and the total degree of the polynomial whose roots we wish to avoid. <p> Since D bounds the total degree of any polynomial g, the total degree of G is at most 2 3 T D. Now we apply a lemma proven in <ref> [19] </ref>. The probability that r, chosen uniformly at random with the given size, is a 14 I. Z. EMIRIS AND J. F. CANNY root of G (a + 1r) is at most 1=c. All claims that follow concern the particular r and hold with probability at least 1 1=c.
Reference: [20] <author> A. Tarski, </author> <title> A Decision Method for Elementary Algebra and Geometry, </title> <institution> University of California Press, Berkeley, </institution> <year> 1948. </year>
Reference-contexts: The smallest positive root in any of these zero sets is larger than some positive real * 0 , hence it suffices that * = * 0 . This idea may be seen as a special case of the "Transfer Principle" <ref> [20] </ref>. An immediate consequence is that symbolic perturbations of the input by *- polynomials are equivalent to defining a new real instance by setting * equal to * 0 .
Reference: [21] <author> C.-K. Yap, </author> <title> Symbolic treatment of geometric degeneracies, </title> <journal> J. Symb. Comput., </journal> <volume> 10 (1990), </volume> <pages> pp. </pages> <month> 349-370. </month> <title> [22] , A geometric consistency theorem for a symbolic perturbation scheme, </title> <journal> J. Comp. Sys. Sci., </journal> <volume> 40 (1990), </volume> <pages> pp. 2-18. </pages>
Reference-contexts: In this article we describe efficient methods for systematically removing such degeneracies using symbolic infinitesimal perturbations. Our methods apply to every algorithm that can be implemented on a real RAM. This work is influenced by the treatment of the problem in [12] and, in a more general context, <ref> [21] </ref>. The main contribution of this article is to introduce the first general and efficient perturbations from the viewpoint of worst-case complexity. Previous methods incurred an extra computational cost that was exponential in some parameter of the input size. <p> An input degeneracy may depend not only on the particular problem but also on the 4 I. Z. EMIRIS AND J. F. CANNY algorithm. An algorithm-induced degeneracy for the Gaussian Elimination algorithm without pivoting arises at a matrix with a singular principal minor. Yap in <ref> [21] </ref> uses the Convex Hull problem in the plane to distinguish between intrinsic and algorithm-induced degeneracies. Assume that in the output space topology polytopes of distinct combinatorial structure lie in disjoint components. <p> The post-processing necessary to recover the exact answer is usually a very case-specific process. We discuss the case of convex hulls at the end of Section 4 and also refer the reader to <ref> [21] </ref>, [12] and [8]. 3. Other Work. The most naive approach is to handle each special case separately, which is tedious for implementors and unattractive for theoreticians. Random perturbations are frequently alluded to and one such scheme is studied in this article. <p> This analysis pertains to fl matrices, to be defined in the next section. Matrices of the second kind, the matrices, require more steps in the worst case, for the same order. In short, SoS incurs a worst-case exponential overhead in d. Yap in <ref> [21] </ref> provides a more general framework, which includes SoS as a special case, where branching occurs at arbitrary rational functions. His technique is consistent relative to infinitesimal perturbations [22] and valid; here we examine it as applied to polynomial tests.
Reference: [23] <author> R. Zippel, </author> <title> Interpolating polynomials from their values, </title> <journal> J. Symb. Comput., </journal> <volume> 9 (1990), </volume> <pages> pp. 375-403. </pages>
Reference-contexts: Lemma 4.3. Computing the sign of perturbed determinants detfl d+1 (*) and det d (*) can be done in O (MM (d) log d) arithmetic steps. Proof. The determinant and the inverse of a d fi d Vandermonde matrix takes at most O (d 2 ) arithmetic steps <ref> [23] </ref>, while computing M or N as a matrix product takes O (MM (d)) operations. Computing det (M * I d+1 ) or det (N * I d ) is a characteristic polynomial computation for which there exists an algorithm by Keller-Gehrig [16] requiring O (MM (d) log d) operations.
References-found: 21

