URL: http://www.cs.columbia.edu/robotics/publications/abrams-ra93.ps.gz
Refering-URL: http://www.cs.columbia.edu/~abrams/
Root-URL: http://www.cs.columbia.edu
Title: Dynamic Sensor Planning  
Author: Steven Abrams Peter K. Allen Konstantinos A. Tarabanis 
Address: Yorktown Heights, NY 10598  New York, NY 10027  
Affiliation: Center for Research in Intelligent Systems IBM T. J. Watson Research Center Computer Science Department  Columbia University  
Abstract: In this paper, we describe a method of extending the sensor planning abilities of the MVP Machine Vision Planning system to plan viewpoints for monitoring a preplanned robot task. The dynamic sensor planning system presented here analyzes geometric models of the environment and of the planned motions of the robot, as well as optical models of the vision sensor. Using a combination of swept volumes and a temporal interval search technique, it computes a series of viewpoints, each of which provides a valid viewpoint for a different interval of the task. By mounting a camera on another manipulator, the viewpoints can be executed at appropriate times during the task so that there is always a robust view suitable for monitoring the task. Experimental results monitoring a simulated robot operation are presented, and directions for future research are discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Steven Abrams and Peter K. Allen. </author> <title> Sensor planning in an active robotic work cell. </title> <booktitle> In DARPA 1992 Image Understanding Workshop. Also in Proceedings SPIE Intelligent Robotic Systems Conference on Sensor Fusion IV: Control Paradigms and Data Structures, </booktitle> <address> Boston, MA, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: We have been exploring methods of extending the sensor planning abilities of the MVP Machine Vision Planning [7, 8] system to function in environments where objects are moving, such as an active robot work-cell. In previous work <ref> [1] </ref>, we described a technique for sensor planning in a dynamic environment, which was implemented using a simulated model of a simple moving object. Here, we present a detailed analysis of the dynamic sensor planning problem and improved versions of the original algorithms.
Reference: [2] <author> Stephen Alan Cameron. </author> <title> Modelling Solids in Motion. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Edinburgh, </institution> <year> 1984. </year>
Reference-contexts: This observation was made by Cameron in <ref> [2] </ref> for the clash detection (robot collision avoidance) problem. Let V represent visibility volume for S (T; O). V is the set of all points (in 3-space) which give views of the target which have no obstructions (due to O) for the entire time interval T .
Reference: [3] <author> C. K. Cowan and A. Bergman. </author> <title> Model based synthesis of sensor locations. </title> <booktitle> In Proceedings 1989 IEEE International Conference on Robotics and Automation, </booktitle> <month> December </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Recently, there has been much research in the field of sensor planning <ref> [3, 4, 5, 8] </ref>. The basic problem is that in setting up an automated system for monitoring some process, the effectiveness of the system can largely be determined by the locations, types and configurations of the sensors used.
Reference: [4] <author> S. A. Hutchinson and A. C. Kak. </author> <title> Planning sensing strategies in robot work cell with multi-sensor capabilities. </title> <booktitle> In Proceedings 1989 IEEE International Conference on Robotics and Automation, </booktitle> <month> December </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Recently, there has been much research in the field of sensor planning <ref> [3, 4, 5, 8] </ref>. The basic problem is that in setting up an automated system for monitoring some process, the effectiveness of the system can largely be determined by the locations, types and configurations of the sensors used.
Reference: [5] <author> K. Ikeuchi and T. Kanade. </author> <title> Modeling sensors: Towards automatic generation of object recognition programs. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 48 </volume> <pages> 50-79, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Recently, there has been much research in the field of sensor planning <ref> [3, 4, 5, 8] </ref>. The basic problem is that in setting up an automated system for monitoring some process, the effectiveness of the system can largely be determined by the locations, types and configurations of the sensors used.
Reference: [6] <author> James Korein. </author> <title> A Geometric Investigation of Reach. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: An articulated robot arm moves strictly in rotations about its joint axes, so the resulting swept volumes are not polyhedral (they would contain circular arcs, spherical patches, and other curved surfaces). These objects would not be usable in MVP. Korein gives an algorithm for computing polyhedral approximations <ref> [6] </ref> of the swept volumes formed by the motion of articulated robot links. These techniques may be used to simplify the computation of the swept volumes.
Reference: [7] <author> Konstantinos Tarabanis. </author> <title> Sensor Planning and Modeling for machine vision tasks. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Teleoperators can have the robot system guarantee robust viewpoints during the operation. The intelligent motion plans which researchers spend so much effort computing can be monitored in an intelligent fashion. We have been exploring methods of extending the sensor planning abilities of the MVP Machine Vision Planning <ref> [7, 8] </ref> system to function in environments where objects are moving, such as an active robot work-cell. In previous work [1], we described a technique for sensor planning in a dynamic environment, which was implemented using a simulated model of a simple moving object. <p> In addition, experimental results using a model of a dual-robot work-cell are presented in which we automatically monitor a task in the work-cell. 2 Overview of Static Planning A complete description of the MVP system is beyond the scope of this paper. For details, see <ref> [7, 8, 9] </ref>. In brief, MVP takes a constraint based description of the vision task requirements and synthesizes what has been termed a gen-eralized viewpoint, which is an eight-dimensional vector incorporating sensor location, orientation, and lens parameters including aperture and effective focal length.
Reference: [8] <author> Konstantinos Tarabanis, Roger Y. Tsai, and Steven Abrams. </author> <title> Planning viewpoints that simultaneously satisfy several feature detectability constraints for robotic vision. </title> <booktitle> In Proceedings Fifth Inernational Conference of Advanced Robotics, </booktitle> <year> 1991. </year>
Reference-contexts: 1 Introduction Recently, there has been much research in the field of sensor planning <ref> [3, 4, 5, 8] </ref>. The basic problem is that in setting up an automated system for monitoring some process, the effectiveness of the system can largely be determined by the locations, types and configurations of the sensors used. <p> Teleoperators can have the robot system guarantee robust viewpoints during the operation. The intelligent motion plans which researchers spend so much effort computing can be monitored in an intelligent fashion. We have been exploring methods of extending the sensor planning abilities of the MVP Machine Vision Planning <ref> [7, 8] </ref> system to function in environments where objects are moving, such as an active robot work-cell. In previous work [1], we described a technique for sensor planning in a dynamic environment, which was implemented using a simulated model of a simple moving object. <p> In addition, experimental results using a model of a dual-robot work-cell are presented in which we automatically monitor a task in the work-cell. 2 Overview of Static Planning A complete description of the MVP system is beyond the scope of this paper. For details, see <ref> [7, 8, 9] </ref>. In brief, MVP takes a constraint based description of the vision task requirements and synthesizes what has been termed a gen-eralized viewpoint, which is an eight-dimensional vector incorporating sensor location, orientation, and lens parameters including aperture and effective focal length.
Reference: [9] <author> Kostantinos Tarabanis, Roger Y. Tsai, and Peter K. Allen. </author> <title> Automated sensor planning and modeling for robotic vision tasks. </title> <booktitle> In Proceedings 1991 IEEE International Conference on Robotics and Automation, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: In addition, experimental results using a model of a dual-robot work-cell are presented in which we automatically monitor a task in the work-cell. 2 Overview of Static Planning A complete description of the MVP system is beyond the scope of this paper. For details, see <ref> [7, 8, 9] </ref>. In brief, MVP takes a constraint based description of the vision task requirements and synthesizes what has been termed a gen-eralized viewpoint, which is an eight-dimensional vector incorporating sensor location, orientation, and lens parameters including aperture and effective focal length.
Reference: [10] <author> John D. Weld and Ming C. Leu. </author> <title> Geometric representation of swept volumes with application to polyhedral objects. </title> <journal> International Journal of Robotics Research, </journal> <volume> 9(5) </volume> <pages> 105-117, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: The critical times are the endpoints of the intervals, i.e. the times at which the sensor must be moved. The computation of swept volumes is central to this algorithm. If piecewise linear translational motion is all that is allowed, then the computation of swept volumes is certainly tractable <ref> [10] </ref>. Unfortunately, sweeping is not closed over the set of polyhedra when rotational motion is permitted. An articulated robot arm moves strictly in rotations about its joint axes, so the resulting swept volumes are not polyhedral (they would contain circular arcs, spherical patches, and other curved surfaces).
References-found: 10

